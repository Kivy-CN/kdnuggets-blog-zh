- en: Demystifying Decision Trees for the Real World
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让决策树在现实世界中变得清晰
- en: 原文：[https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)
- en: '![Decision Trees for Real World](../Images/ea4f96c2e9a77ccb1faac326d2e08a98.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![现实世界中的决策树](../Images/ea4f96c2e9a77ccb1faac326d2e08a98.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Decision trees break down difficult decisions into straightforward, easily followed
    phases, thereby functioning like human brains.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树将复杂的决策分解为简单、易于遵循的阶段，因此类似于人类大脑的功能。
- en: In data science, these strong instruments are extensively applied to assist
    in data analysis and the direction of decision-making.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，这些强大的工具被广泛应用于数据分析和决策指导。
- en: In this article, I will go over how decision trees operate, give real-world
    examples, and give some tips for enhancing them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍决策树的运作方式，提供现实世界的例子，并给出一些提升决策树效果的建议。
- en: '**Structure of Decision Trees**'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**决策树的结构**'
- en: Fundamentally, decision trees are simple and clear tools. They break down difficult
    options into simpler, sequential choices, therefore reflecting human decision-making.
    Let us now explore the main elements forming a decision tree.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上说，决策树是简单明了的工具。它们将复杂的选项分解为更简单的顺序选择，从而反映了人类的决策过程。现在让我们深入探讨构成决策树的主要元素。
- en: '**Nodes, Branches, and Leaves**'
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**节点、分支和叶子**'
- en: 'Three basic components define a decision tree: leaves, branches, and nodes.
    Every one of these is absolutely essential for the process of making decisions.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 三个基本组件定义了一个决策树：叶子、分支和节点。每一个都是决策过程中的绝对关键。
- en: 'Nodes: They are decision points whereby the tree decides depending on the input
    data. When representing all the data, the root node is the starting point.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点：它们是决策点，通过这些点，树根据输入数据做出决定。在表示所有数据时，根节点是起始点。
- en: 'Branches: They relate the result of a decision and link nodes. Every branch
    matches a potential result or value of a decision node.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支：它们关联决策的结果并连接节点。每个分支对应一个潜在的结果或决策节点的值。
- en: 'Leaves: The decision tree''s ends are leaves, sometimes known as leaf nodes.
    Each leaf node offers a certain consequence or label; they reflect the last choice
    or classification.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叶子：决策树的终点是叶子，有时称为叶节点。每个叶节点提供一个特定的结果或标签；它们反映最后的选择或分类。
- en: '**Conceptual Example**'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**概念示例**'
- en: Suppose you are choosing whether to venture outside depending on the temperature.
    "Is it raining?" the root node would ask. If so, you might find a branch headed
    toward "Take an umbrella." This should not be the case; another branch could say,
    "Wear sunglasses."
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在根据温度决定是否外出。“下雨吗？”根节点会问。如果是的话，你可能会找到一条指向“带伞”的分支。但这种情况不应该发生；另一条分支可以说“戴太阳镜”。
- en: These structures make decision trees easy to interpret and visualize, so they
    are popular in various fields.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结构使得决策树易于解读和可视化，因此在各个领域都很受欢迎。
- en: '**Real-World Example: The Loan Approval Adventure**'
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**现实世界示例：贷款审批冒险**'
- en: 'Picture this: You''re a wizard at Gringotts Bank, deciding who gets a loan
    for their new broomstick.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：你是格林戈茨银行的一名巫师，决定谁能获得贷款购买他们的新扫帚。
- en: 'Root Node: "Is their credit score magical?"'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根节点：“他们的信用评分是否很神奇？”
- en: If yes → Branch to "Approve faster than you can say Quidditch!"
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是 → 分支到“批准，快得比你说魁地奇还快！”
- en: If no → Branch to "Check their goblin gold reserves."
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果否 → 分支到“检查他们的精灵金币储备。”
- en: If high →, "Approve, but keep an eye on them."
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果高 →，“批准，但要留意他们。”
- en: If low → "Deny faster than a Nimbus 2000."
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果低 → “拒绝，速度比Nimbus 2000还快。”
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here is the output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Structure of Decision Trees in Machine Learning](../Images/3e9b93689e0ded4344ef485f406e1e7c.png) When
    you run this spell, you''ll see a tree appear! It''s like the Marauder''s Map
    of loan approvals:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![机器学习中的决策树结构](../Images/3e9b93689e0ded4344ef485f406e1e7c.png) 当你运行这个魔法时，你会看到一棵树出现！它就像贷款批准的掠夺者地图：'
- en: The root node splits on Credit_Score
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根节点在 Credit_Score 上进行划分
- en: If it's ≤ 675, we venture left
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果小于等于 675，我们向左前进
- en: If it's > 675, we journey right
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果大于 675，我们向右行进
- en: 'The leaves show our final decisions: "Yes" for approved, "No" for denied'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叶子节点显示我们的最终决定：“是”表示批准，“否”表示拒绝
- en: Voila! You've just created a decision-making crystal ball!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你刚刚创建了一个决策制定的水晶球！
- en: 'Mind Bender: If your life were a decision tree, what would be the root node
    question? "Did I have coffee this morning?" might lead to some interesting branches!'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 思维挑战：如果你的生活是一个决策树，根节点问题会是什么？“今天早上喝咖啡了吗？”可能会引出一些有趣的分支！
- en: '**Decision Trees: Behind the Branches**'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**决策树：在分支背后**'
- en: Decision trees function similarly to a flowchart or tree structure, with a succession
    of decision points. They begin by dividing a dataset into smaller pieces, and
    then they build a decision tree to go along with it. The way these trees deal
    with data splitting and different variables is something we should look at.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树的功能类似于流程图或树状结构，通过一系列的决策点来工作。它们从将数据集划分为更小的部分开始，然后建立一个决策树来配合它。我们应该关注这些树如何处理数据划分和不同变量的方式。
- en: '**Splitting Criteria: Gini Impurity and Information Gain**'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**划分标准：基尼不纯度和信息增益**'
- en: Choosing the best quality to divide the data is the primary goal of building
    a decision tree. It is possible to determine this procedure using criteria provided
    by Information Gain and Gini Impurity.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳质量来划分数据是构建决策树的主要目标。可以通过信息增益和基尼不纯度提供的标准来确定这个过程。
- en: 'Gini Impurity: Picture yourself in the midst of a game of guessing. How often
    would you be mistaken if you randomly selected a label? That''s what Gini Impurity
    measures. We can make better guesses and have a happier tree with a lower Gini
    coefficient.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基尼不纯度：想象一下你在玩猜测游戏。如果你随机选择一个标签，你会经常出错吗？这就是基尼不纯度所衡量的。基尼系数越低，我们的猜测越准确，树也就越快乐。
- en: 'Information gain: The "aha!" moment in a mystery story is what you may compare
    this to. How much a hint (attribute) aids in solving the case is measured by it.
    A bigger "aha!" means more gain, which means an ecstatic tree!'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息增益：你可以将其比作神秘故事中的“啊哈！”时刻。信息增益衡量提示（属性）在解决案件中所起的帮助程度。更大的“啊哈！”意味着更多的增益，这意味着树更加兴奋！
- en: To predict whether a customer would buy a product from your dataset, you can
    start with basic demographic information like age, income, and purchasing history.
    The approach takes all of these into account and finds the one that separates
    the buyers from the others.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要预测客户是否会从你的数据集中购买某个产品，你可以从基本的人口统计信息开始，比如年龄、收入和购买历史。这个方法考虑了所有这些因素，并找出能够将买家和其他人区分开的因素。
- en: '**Handling Continuous and Categorical Data**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**处理连续数据和分类数据**'
- en: There are no types of info that our tree detectives can't look into.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的树探员可以调查所有类型的信息。
- en: For features that are easy to change, like age or income, the tree sets up a
    speed trap. "Anyone over 30, this way!"
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于容易改变的特征，如年龄或收入，树设置了一个测速点。“30岁以上的人，请走这边！”
- en: When it comes to categorical data, like gender or product type, it's more of
    a lineup. "Smartphones stand on the left; laptops on the right!"
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类数据，如性别或产品类型，这更像是一种排列。“智能手机在左边；笔记本电脑在右边！”
- en: '**Real-World Cold Case: The Customer Purchase Predictor**'
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**现实世界的冷案：客户购买预测器**'
- en: 'To better understand how decision trees work, let''s look at a real-life example:
    using a customer''s age and income to guess whether they will buy a product.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解决策树的工作原理，我们来看看一个实际的例子：使用客户的年龄和收入来预测他们是否会购买产品。
- en: To guess what people will buy, we'll make a simple collection and a decision
    tree.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测人们会买什么，我们将创建一个简单的集合和决策树。
- en: A description of the code
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的描述
- en: We import libraries like pandas to work with the data, DecisionTreeClassifier
    from scikit-learn to build the tree, and matplotlib to show the results.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们导入像 pandas 这样的库来处理数据，从 scikit-learn 导入 DecisionTreeClassifier 来构建树，使用 matplotlib
    来展示结果。
- en: 'Create Dataset: Age, income, and buying status are used to make a sample dataset.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建数据集：使用年龄、收入和购买状态来制作一个样本数据集。
- en: 'Get Features and Goals Ready: The goal variable (Purchased) and features (Age,
    Income) are set up.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备特征和目标：目标变量（购买）和特征（年龄、收入）已经设置好。
- en: 'Train the Model: The information is used to set up and train the decision tree
    classifier.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型：利用这些信息设置和训练决策树分类器。
- en: 'See the Tree: Finally, we draw the decision tree so that we can see how choices
    are made.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看决策树：最后，我们绘制决策树，以便观察决策过程。
- en: Here is the code.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码。
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here is the output.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Behind the Branches of Decision Trees in Machine Learning](../Images/7f5d804f75257f96f06d7adfdd01c418.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习中的决策树背后的秘密](../Images/7f5d804f75257f96f06d7adfdd01c418.png)'
- en: The final decision tree will show how the tree splits up based on age and income
    to figure out if a customer is likely to buy a product. Each node is a decision
    point, and the branches show different outcomes. The final decision is shown by
    the leaf nodes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最终决策树将展示如何根据年龄和收入来划分树，以确定客户是否可能购买某个产品。每个节点是一个决策点，分支显示不同的结果。最终决策由叶节点展示。
- en: Now, let's look at how interviews can be used in the real world!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看面试在现实世界中的应用吧！
- en: '**Real-World Applications**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**现实世界应用**'
- en: '![Real World Applications for Decision Trees](../Images/b89c0285925b1a8b2b25a340d3d31864.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![决策树的现实世界应用](../Images/b89c0285925b1a8b2b25a340d3d31864.png)'
- en: This project is designed as a take-home assignment for Meta (Facebook) data
    science positions. The objective is to build a classification algorithm that predicts
    whether a movie on Rotten Tomatoes is labeled 'Rotten', 'Fresh', or 'Certified
    Fresh.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目被设计为Meta（Facebook）数据科学职位的家庭作业，目标是构建一个分类算法，预测Rotten Tomatoes上的电影是否标记为“烂片”、“新鲜”或“认证新鲜”。
- en: 'Here is the link to this project: [https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction](https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该项目的链接：[https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction](https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)
- en: Now, let’s break down the solution into codeable steps.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将解决方案拆解为可编码的步骤。
- en: '**Step-by-Step Solution**'
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**逐步解决方案**'
- en: 'Data Preparation: We will merge the two datasets on the rotten_tomatoes_link
    column. This will give us a comprehensive dataset with movie information and critic
    reviews.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备：我们将根据rotten_tomatoes_link列合并两个数据集。这将为我们提供一个包含电影信息和评论的综合数据集。
- en: 'Feature Selection and Engineering: We will select relevant features and perform
    necessary transformations. This includes converting categorical variables to numerical
    ones, handling missing values, and normalizing the feature values.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征选择与工程：我们将选择相关特征并执行必要的转换，包括将类别变量转换为数值变量、处理缺失值和标准化特征值。
- en: 'Model Training: We will train a decision tree classifier on the processed dataset
    and use cross-validation to evaluate the model''s robust performance.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练：我们将对处理后的数据集训练决策树分类器，并使用交叉验证评估模型的稳定性。
- en: 'Evaluation: Finally, we will evaluate the model''s performance using metrics
    like accuracy, precision, recall, and F1-score.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估：最后，我们将使用准确率、精确率、召回率和F1分数等指标来评估模型的性能。
- en: Here is the code.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码。
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here is the output.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Real World Applications for Decision Trees](../Images/deacf1b18f3680ce5099414ce3641d35.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![决策树的现实世界应用](../Images/deacf1b18f3680ce5099414ce3641d35.png)'
- en: The model shows high accuracy and F1 scores across the classes, indicating good
    performance. Let’s see the key takeaways.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在各类中显示出高准确率和F1分数，表明性能良好。让我们来看一下关键要点。
- en: Key Takeaways
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要点
- en: Feature selection is crucial for model performance. Content rating genres directors'
    runtime and ratings proved valuable predictors.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征选择对模型性能至关重要。内容评分、类型、导演、时长和评分被证明是有价值的预测因子。
- en: A decision tree classifier effectively captures complex relationships in movie
    data.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树分类器有效捕捉了电影数据中的复杂关系。
- en: Cross-validation ensures model reliability across different data subsets.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交叉验证确保模型在不同数据子集上的可靠性。
- en: High performance in the "Certified-Fresh" class warrants further investigation
    into potential class imbalance.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“认证新鲜”类别中表现出色的情况下，值得进一步调查可能的类别不平衡。
- en: The model shows promise for real-world application in predicting movie ratings
    and enhancing user experience on platforms like Rotten Tomatoes.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型在预测电影评分和提升如Rotten Tomatoes平台的用户体验方面显示出良好的前景。
- en: '**Enhancing Decision Trees: Turning Your Sapling into a Mighty Oak**'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提升决策树：将你的幼苗成长为参天大树**'
- en: So, you've grown your first decision tree. Impressive! But why stop there? Let's
    turn that sapling into a forest giant that would make even Groot jealous. Ready
    to beef up your tree? Let's dive in!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经成长了第一棵决策树。令人印象深刻！但为何止步于此？让我们将这棵幼苗变成一棵森林巨人，让Groot也感到嫉妒。准备好增强你的树了吗？让我们深入了解吧！
- en: '**Pruning Techniques**'
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**剪枝技术**'
- en: Pruning is a method used to cut a decision tree's size by eliminating parts
    that have minimal ability in target variable prediction. This helps to reduce
    overfitting in particular.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 剪枝是一种通过去除对目标变量预测能力较小的部分来缩减决策树大小的方法。这有助于特别减少过拟合。
- en: 'Pre-pruning: Often referred to as early stopping, this entails stopping the
    tree''s growth right away. Before training, the model is specified parameters,
    including maximum depth (max_depth), minimum samples required to split a node
    (min_samples_split), and minimum samples required at a leaf node (min_samples_leaf).
    This keeps the tree from growing overly complicated.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前剪枝：通常称为早期停止，这涉及立即停止树的生长。在训练之前，模型会被指定参数，包括最大深度（max_depth）、分裂节点所需的最小样本数（min_samples_split）和叶节点所需的最小样本数（min_samples_leaf）。这防止了树的过度复杂化。
- en: 'Post-pruning: This method grows the tree to its maximum depth and removes nodes
    that don''t offer much power. Though more computationally taxing than pre-pruning,
    post-pruning can be more successful.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后剪枝：这种方法将树生长到最大深度，然后移除那些贡献不大的节点。虽然计算成本比前剪枝更高，但后剪枝可能更有效。
- en: '**Ensemble Methods**'
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**集成方法**'
- en: Ensemble techniques combine several models to generate performance above that
    of any one model. Two primary forms of ensemble techniques applied with decision
    trees are bagging and boosting.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 集成技术将多个模型结合以产生超过单一模型的性能。应用于决策树的两种主要集成技术是装袋法和提升法。
- en: 'Bagging (Bootstrap Aggregating): This method trains several decision trees
    on several subsets of the data (generated by sampling with replacement) and then
    averages their predictions. One often used bagging technique is Random Forest.
    It lessens variance and aids in overfit prevention. Check out "[Decision Tree
    and Random Forest Algorithm](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)"
    to deeply address everything related to the Decision Tree algorithm and its extension
    “Random Forest algorithm”.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 装袋法（Bootstrap Aggregating）：该方法在数据的多个子集（通过有放回抽样生成）上训练多个决策树，然后对它们的预测结果取平均。一个常用的装袋技术是随机森林。它减少了方差并有助于防止过拟合。查看
    "[决策树与随机森林算法](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)"
    深入了解决策树算法及其扩展“随机森林算法”相关的一切。
- en: 'Boosting: Boosting creates trees one after the other as each one seeks to fix
    the mistakes of the next one. Boosting techniques abound in algorithms including
    AdaBoost and Gradient Boosting. By emphasizing challenging-to-predict examples,
    these algorithms sometimes provide more exact models.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升：提升方法依次创建树，每棵树都试图修正下一棵树的错误。提升技术在算法中包括AdaBoost和梯度提升。这些算法通过强调难以预测的示例，有时能提供更精确的模型。
- en: '**Hyperparameter Tuning**'
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**超参数调优**'
- en: Hyperparameter tuning is the process of determining the optimal hyperparameter
    set for a decision tree model to raise its performance. Using methods like Grid
    Search or Random Search, whereby several combinations of hyperparameters are assessed
    to identify the best configuration, this can be accomplished.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优是确定决策树模型的最佳超参数集合以提升其性能的过程。可以通过使用如网格搜索或随机搜索等方法，评估多个超参数组合以找出最佳配置。
- en: '**Conclusion**'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: In this article, we’ve discussed the structure, working mechanism, real-world
    applications, and methods for enhancing decision tree performance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了决策树的结构、工作机制、实际应用以及提升决策树性能的方法。
- en: Practicing decision trees is crucial to mastering their use and understanding
    their nuances. Working on real-world data projects can also provide valuable experience
    and improve problem-solving skills.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 练习决策树对于掌握其使用和理解其细微差别至关重要。处理实际数据项目也可以提供宝贵的经验，提升解决问题的技能。
- en: '[](https://twitter.com/StrataScratch)****[Nate Rosidi](https://twitter.com/StrataScratch)****
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of StrataScratch, a platform helping data scientists
    prepare for their interviews with real interview questions from top companies.
    Nate writes on the latest trends in the career market, gives interview advice,
    shares data science projects, and covers everything SQL.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://twitter.com/StrataScratch)****[内特·罗西迪](https://twitter.com/StrataScratch)****
    是一名数据科学家，专注于产品策略。他还是一位兼职教授，教授分析学，并且是 StrataScratch 的创始人，该平台帮助数据科学家通过来自顶级公司的真实面试问题准备面试。内特撰写关于职业市场的最新趋势，提供面试建议，分享数据科学项目，并涵盖所有
    SQL 相关内容。'
- en: More On This Topic
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Machine Learning from Scratch: Decision Trees](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从零开始的机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
- en: '[Decision Trees vs Random Forests, Explained](https://www.kdnuggets.com/2022/08/decision-trees-random-forests-explained.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树与随机森林，解释说明](https://www.kdnuggets.com/2022/08/decision-trees-random-forests-explained.html)'
- en: '[Generalized and Scalable Optimal Sparse Decision Trees(GOSDT)](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通用可扩展的最优稀疏决策树(GOSDT)](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)'
- en: '[Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的人工智能：10个 Python 库帮助解密模型决策](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
- en: '[Demystifying Bad Science](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解密糟糕的科学](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
- en: '[Demystifying Machine Learning](https://www.kdnuggets.com/demystifying-machine-learning)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解密机器学习](https://www.kdnuggets.com/demystifying-machine-learning)'
