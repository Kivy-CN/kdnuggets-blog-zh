- en: GPU-Powered Data Science (NOT Deep Learning) with RAPIDS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU驱动的数据科学（非深度学习）与RAPIDS
- en: 原文：[https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html](https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html](https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![Header image](../Images/d3c4ef08dfa0e0885360d379295720aa.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![头图](../Images/d3c4ef08dfa0e0885360d379295720aa.png)'
- en: '**Image source**: [Pixabay](https://pixabay.com/photos/pc-hardware-geforce-radeon-6113265/) (Free
    image)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**: [Pixabay](https://pixabay.com/photos/pc-hardware-geforce-radeon-6113265/)
    (免费图片)'
- en: Are you looking for “GPU-powered data science”?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你在寻找“GPU驱动的数据科学”吗？
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 加速你的网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持你组织的IT需求'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Imagine yourself to be a data scientist, or a business analyst, or an academic
    researcher in Physics/Economics/Neuroscience…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你自己是一名数据科学家、商业分析师或物理学/经济学/神经科学的学术研究员…
- en: You do a lot of **data wrangling, cleaning, statistical tests, visualizations** on
    a regular basis. You also tinker with a lot of **linear models** fitting data
    and occasionally venture into **RandomForest**. You are also into **clustering** large
    datasets. Sounds familiar enough?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常进行**数据处理、清洗、统计测试、可视化**。你还经常处理**线性模型**的拟合数据，并偶尔涉足**随机森林**。你还进行**大数据集的聚类**。听起来很熟悉吗？
- en: However, given the nature of the datasets you work on (mostly tabular and structured),
    you don’t venture into deep learning that much. You would rather put all the hardware
    resources you have into the things that you actually do on a day-to-day basis,
    than spending on some fancy deep learning model. Again, familiar?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，鉴于你处理的数据集的性质（主要是表格和结构化数据），你不会过多涉足深度学习。你宁愿将所有的硬件资源投入到你日常实际工作的事务中，而不是花费在一些花哨的深度学习模型上。再说一次，熟悉吗？
- en: You hear about the awesome power and the blazing-fast computation prowess of [GPU
    systems like the ones from NVidia for all kinds of industrial and scientific applications.](https://www.nvidia.com/en-us/deep-learning-ai/products/solutions/)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过[GPU系统，如NVidia提供的各种工业和科学应用的系统](https://www.nvidia.com/en-us/deep-learning-ai/products/solutions/)的强大能力和飞快的计算能力。
- en: And, you keep on thinking — “***What’s there for me? How can I take advantage
    of these powerful pieces of semiconductor in my specific workflow***?”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你不断思考——“***这对我来说有什么好处？我如何在特定的工作流程中利用这些强大的半导体组件***？”
- en: You are searching for GPU-powered data science.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你在寻找GPU驱动的数据科学。
- en: One of your best (and fastest) options to evaluate this approach is to use the
    combination of [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)** + **[**RAPIDS**](https://rapids.ai/)**. **Let
    me explain in detail…
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 评估这种方法的最佳（且最快）选项之一是使用[**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)**
    + **[**RAPIDS**](https://rapids.ai/)**。**让我详细解释一下…
- en: GPUs in the AI/ML folklore have primarily been for deep learning
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在AI/ML的传说中，GPU主要用于深度学习
- en: While the use of GPUs and distributed computing is widely discussed in the academic
    and business circles for core AI/ML tasks (e.g. running a [1000-layer deep neural
    network](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) for
    image classification or [billion-parameter BERT](https://arxiv.org/abs/1909.08053) speech
    synthesis model), they have found less coverage when it comes to their utility
    for regular data science and data engineering tasks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在学术界和商业界对核心 AI/ML 任务中（例如运行 [1000 层深度神经网络](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)
    进行图像分类或 [十亿参数的 BERT](https://arxiv.org/abs/1909.08053) 语音合成模型）的 GPU 和分布式计算的使用有广泛讨论，但它们在常规数据科学和数据工程任务中的实用性却得到的关注较少。
- en: Nonetheless, **data-related tasks are the essential precursor to any ML workload
    in an AI pipeline** and they often constitute [a majority percentage of the time
    and intellectual effort ](https://www.infoworld.com/article/3228245/the-80-20-data-science-dilemma.html)spent
    by a data scientist or even an ML engineer. Recently, the famous AI pioneer
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，**数据相关任务是 AI 流水线中任何 ML 负载的关键前置条件**，它们通常占据了数据科学家或甚至 ML 工程师的 **[大部分时间和智力投入](https://www.infoworld.com/article/3228245/the-80-20-data-science-dilemma.html)**。最近，这位著名的
    AI 先锋
- en: '[Andrew Ng](https://medium.com/u/592ce2a67248?source=post_page-----29f9ed8d51f3--------------------------------)
    talked about [**moving from a model-centric to a data-centric approach to AI**](https://www.youtube.com/watch?v=06-AZXmwHjo) tools
    development. This means spending much more time with the raw data and preprocessing
    it before an actual AI workload executes on your pipeline.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[安德鲁·吴](https://medium.com/u/592ce2a67248?source=post_page-----29f9ed8d51f3--------------------------------)
    讨论了 [**从模型中心化转向数据中心化的 AI**](https://www.youtube.com/watch?v=06-AZXmwHjo) 工具开发方法。这意味着在实际
    AI 负载在你的流水线中执行之前，需要花费更多的时间处理原始数据和预处理数据。'
- en: So, the important question is: ***Can we leverage the power of GPU and distributed
    computing for regular data processing jobs***?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，重要的问题是：***我们能否利用 GPU 和分布式计算的力量来处理常规数据处理工作***？
- en: '![](../Images/cfe568cb012bc33d8646f653e9cad210.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfe568cb012bc33d8646f653e9cad210.png)'
- en: '**Image source**: Author created collage from free images ([Pixabay](https://pixabay.com/vectors/squirrel-reading-books-surprise-304021/))'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**：作者从免费图片（[Pixabay](https://pixabay.com/vectors/squirrel-reading-books-surprise-304021/)）创建的拼贴'
- en: While the use of GPUs and distributed computing is widely discussed in the academic
    and business circles for core AI/ML tasks, they have found less coverage in their
    utility for regular data science and data engineering tasks.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管在学术界和商业界对核心 AI/ML 任务中 GPU 和分布式计算的使用有广泛讨论，但它们在常规数据科学和数据工程任务中的实用性却得到的关注较少。
- en: The fantastic RAPIDS ecosystem
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 奇妙的 RAPIDS 生态系统
- en: The [RAPIDS suite of software libraries and APIs](https://rapids.ai/) give you
    — a regular data scientist (and not necessarily a deep learning practitioner)
    — the option and flexibility to execute **end-to-end data science and analytics
    pipelines entirely on GPUs.**
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[RAPIDS 软件库和 API 套件](https://rapids.ai/) 使你——一个普通数据科学家（而不一定是深度学习从业者）——有选择和灵活性来在
    GPU 上 **完全执行端到端的数据科学和分析流程**。'
- en: This open-source project was incubated by Nvidia by building tools to take advantage
    of CUDA primitives. It specifically focuses on **exposing GPU parallelism and
    high-bandwidth memory speed features through the data-science-friendly Python
    language**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个开源项目由 Nvidia 孵化，通过构建工具来利用 CUDA 原语。它特别关注于 **通过数据科学友好的 Python 语言暴露 GPU 并行性和高带宽内存速度特性**。
- en: '**Common data preparation and wrangling tasks** are highly valued in the RAPIDS
    ecosystem. It also lends a significant amount of **support for multi-node, multi-GPU
    deployment, and distributed processing**. Wherever possible, it integrates with
    other libraries which make **out-of-memory** (i.e. dataset size larger than individual
    computer RAM) data processing easy and accessible for individual data scientists.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**常见的数据准备和处理任务** 在 RAPIDS 生态系统中备受重视。它还提供了显著的 **对多节点、多 GPU 部署和分布式处理的支持**。在可能的情况下，它与其他库集成，使
    **超大内存**（即数据集大小大于单个计算机 RAM）数据处理对个体数据科学家变得简单易用。'
- en: '![](../Images/0829816c3ae29c222246fdfa91aae184.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0829816c3ae29c222246fdfa91aae184.png)'
- en: '**Image source**: Author created collage'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**：作者创建的拼贴'
- en: The three most prominent (and Pythonic) components — that are of particular
    interest to common data scientists — are,
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 三个最突出的（并且 Pythonic）组件——对普通数据科学家特别感兴趣——是，
- en: '[**CuPy**](https://docs.cupy.dev/en/stable/reference/comparison.html): A CUDA-powered
    array library that looks and feels just like Numpy, while using various CUDA libraries
    e.g., cuBLAS, cuDNN, cuRand, cuSolver, cuSPARSE, cuFFT, and NCCL to take full
    advantage of the GPU architecture underneath.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**CuPy**](https://docs.cupy.dev/en/stable/reference/comparison.html)：一个 CUDA
    驱动的数组库，其外观和感觉与 Numpy 一致，同时使用各种 CUDA 库，例如 cuBLAS、cuDNN、cuRand、cuSolver、cuSPARSE、cuFFT
    和 NCCL，以充分利用底层的 GPU 架构。'
- en: '**CuDF**: This is a GPU DataFrame library for loading, aggregating, joining,
    filtering, and manipulating data with a **pandas-like API. **Data engineers and
    data scientists can use it to easily accelerate their task flows using powerful
    GPUs without ever learning the nuts and bolts of CUDA programming.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CuDF**：这是一个 GPU DataFrame 库，用于加载、汇总、连接、过滤和处理数据，具有**类似 pandas 的 API**。数据工程师和数据科学家可以使用它来轻松加速他们的任务流程，无需深入了解
    CUDA 编程的细节。'
- en: '[**CuML**](https://github.com/rapidsai/cuml): This library enables data scientists,
    analysts, and researchers to run traditional/ classical ML algorithms and associated
    processing tasks fully leveraging the power of a GPU. Naturally, this is used
    mostly with tabular datasets. Think about Scikit-learn and what it could do with
    all those hundreds of Cuda and Tensor Cores on your GPU card! On cue to that,
    in most cases, cuML’s Python API matches that of Scikit-learn. Furthermore, it
    tries to offer **multi-GPU and multi-node-GPU support **byintegrating gracefully
    with [**Dask**](https://docs.dask.org/en/latest/), wherever it can, for taking
    advantage of true distributed processing/ cluster computing.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**CuML**](https://github.com/rapidsai/cuml)：这个库使数据科学家、分析师和研究人员能够运行传统/经典的机器学习算法和相关处理任务，充分利用
    GPU 的力量。自然，这主要用于表格数据集。想象一下 Scikit-learn 以及它可以用你 GPU 卡上的所有 CUDA 和 Tensor Cores
    做什么！与之相匹配的是，大多数情况下，cuML 的 Python API 与 Scikit-learn 一致。此外，它尝试通过与 [**Dask**](https://docs.dask.org/en/latest/)
    优雅地集成，提供**多 GPU 和多节点 GPU 支持**，以利用真正的分布式处理/集群计算。'
- en: '***Can we leverage the power of GPU and distributed computing for regular data
    processing jobs and machine learning with structured data?***'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***我们是否可以利用 GPU 和分布式计算的力量来处理常规数据处理任务和结构化数据的机器学习？***'
- en: Is it different from using Apache Spark?
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这与使用 Apache Spark 有什么不同吗？
- en: You may ask how this GPU-powered data processing is different than using Apache
    Spark. Actually, there are some subtle differences, and only recently, with Spark
    3.0, GPUs are a mainstream resource for Spark workloads.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，这种 GPU 驱动的数据处理与使用 Apache Spark 有什么不同。实际上，有一些微妙的区别，只有最近，随着 Spark 3.0 的发布，GPU
    才成为 Spark 工作负载的主流资源。
- en: '[**Accelerating Apache Spark 3.0 with GPUs and RAPIDS | NVIDIA Developer Blog**](https://developer.nvidia.com/blog/accelerating-apache-spark-3-0-with-gpus-and-rapids/)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[**使用 GPU 和 RAPIDS 加速 Apache Spark 3.0 | NVIDIA 开发者博客**](https://developer.nvidia.com/blog/accelerating-apache-spark-3-0-with-gpus-and-rapids/)'
- en: We do not have time or space to discuss the unique differences of this GPU-
    powered data science approach vs. Big Data tasks that are particularly suitable
    for Apache Spark. But ask yourself these questions and you will probably understand
    the subtle difference,
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有时间或空间讨论这种 GPU 驱动的数据科学方法与特别适合 Apache Spark 的大数据任务之间的独特差异。但问问自己这些问题，你可能会理解微妙的不同。
- en: “*As a data scientist who models economic transactions and portfolio management,
    I want to solve a *[*linear system of equations*](https://en.wikipedia.org/wiki/System_of_linear_equations)* with
    100,000 variables. Do I use a pure Linear Algebra library or Apache Spark*?”
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: “*作为一个建模经济交易和投资组合管理的数据科学家，我想解决一个*[*线性方程组*](https://en.wikipedia.org/wiki/System_of_linear_equations)*，其中有
    100,000 个变量。我应该使用纯线性代数库还是 Apache Spark*？”
- en: “*As part of an image compression pipeline, I want to use *[*Singular Value
    Decomposition*](https://towardsdatascience.com/understanding-singular-value-decomposition-and-its-application-in-data-science-388a54be95d)* on
    a large matrix of millions of entries. Is Apache Spark a good choice for that*?”
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: “*作为图像压缩管道的一部分，我想在一个包含数百万条目的大矩阵上使用*[*奇异值分解*](https://towardsdatascience.com/understanding-singular-value-decomposition-and-its-application-in-data-science-388a54be95d)*。Apache
    Spark 是一个好的选择吗*？”
- en: Big problem size does not always mean Apache Spark or Hadoop ecosystem. Big
    Computation is not equivalent to Big Data. As a well-rounded data scientist, you
    need to know both to tackle all kinds of problems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 大问题规模并不总是意味着 Apache Spark 或 Hadoop 生态系统。大计算并不等于大数据。作为一个全面的数据科学家，你需要了解这两者，以应对各种问题。
- en: RAPIDS specifically focuses on **exposing GPU parallelism and high-bandwidth
    memory speed features through Python APIs.**
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RAPIDS 专注于**通过 Python API 显示 GPU 并行性和高带宽内存速度特性。**
- en: What are we showing in this article?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们在这篇文章中展示了什么？
- en: Crisp examples of CuPy and CuML only
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仅 CuPy 和 CuML 的简洁示例
- en: So, in this article, we will just demonstrate crisp examples of CuPy and CuML,
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这篇文章中，我们将仅展示 CuPy 和 CuML 的简洁示例，
- en: how they compare (in speed) with corresponding Numpy and Scikit-learn functions/
    estimators
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们与对应的 Numpy 和 Scikit-learn 函数/估计器（速度方面）的比较
- en: how the data/problem size matters in this speed comparison.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据/问题规模在这种速度比较中的重要性。
- en: CuDF examples in a later article
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 后续文章中的 CuDF 示例
- en: Although data engineering examples akin to Pandas data processing are of high
    interest to many data scientists, we will cover the CuDF examples in a later article.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管类似 Pandas 数据处理的数据工程示例对许多数据科学家非常感兴趣，我们将在后续文章中介绍 CuDF 示例。
- en: What is my GPU-based hardware platform?
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我的 GPU 基础硬件平台是什么？
- en: I am using a [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article) Tesla
    T4 GPU instance as it is literally 5 minutes of work to spin up a [fully featured
    and loaded (with DS and AI libraries) compute resource on the cloud](https://www.saturncloud.io/s/nvidia/) for
    all my data science work with their service. **As long as I don’t exceed 10 hours
    of Jupyter Notebook usage per month, it’s Free**! If you want to read more about
    their service,
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用的是[**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)
    的 Tesla T4 GPU 实例，因为创建一个[功能齐全并加载了（数据科学和 AI 库）计算资源的云实例](https://www.saturncloud.io/s/nvidia/)
    只需 5 分钟时间。**只要我每月不超过 10 小时的 Jupyter Notebook 使用时间，它就是免费的**！如果你想了解更多关于他们服务的信息，
- en: 'Saturn Cloud Hosted Has Launched: GPU Data Science for Everyone!'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Saturn Cloud 托管现已上线：人人都能使用的 GPU 数据科学！
- en: '[**GPU computing is the future of data science. Packages such as RAPIDS, TensorFlow,
    and PyTorch enable lightning-fast…**](https://www.saturncloud.io/blog/saturn-cloud-hosted-has-launched-gpu-data-science-for-everyone/)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[**GPU 计算是数据科学的未来。像 RAPIDS、TensorFlow 和 PyTorch 这样的包使计算变得迅速…**](https://www.saturncloud.io/blog/saturn-cloud-hosted-has-launched-gpu-data-science-for-everyone/)'
- en: Apart from having the [Tesla T4 GPU](https://www.nvidia.com/en-us/data-center/tesla-t4/),
    it is a 4-core Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz machine with 16
    GB of RAM and 10 GB persistent disk. So, this is a quite normal setup from a hardware
    config point of view (limited hard drive because of the free tier) i.e. any data
    scientist may have this kind of hardware in his/her possession. The only distinguishing
    factor is the presence of the GPU and setting up all the CUDA and Python libraries
    in a proper way so that the RAPIDS suite works without any hiccup.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 除了拥有[Tesla T4 GPU](https://www.nvidia.com/en-us/data-center/tesla-t4/)，它还是一台4核
    Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz 机器，配有 16 GB RAM 和 10 GB 持久磁盘。因此，从硬件配置的角度来看，这是一个相当普通的设置（由于免费层，硬盘有限），即任何数据科学家都可能拥有这种硬件。唯一的区别在于
    GPU 的存在，以及正确设置所有 CUDA 和 Python 库，以确保 RAPIDS 套件正常运行。
- en: Big problem size does not always mean Apache Spark or Hadoop ecosystem. Big
    Computation is not equivalent to Big Data. As a well-rounded data scientist, you
    need to know both to tackle all kinds of problems.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大问题规模并不总意味着 Apache Spark 或 Hadoop 生态系统。大计算不等同于大数据。作为一个全面的数据科学家，你需要了解这两者，以解决各种问题。
- en: Solving a linear system of equations
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解线性方程组
- en: We create linear systems of equations of varying sizes and use the Numpy (and
    CuPy) `linalg.solve`routine to solve that with the following code,
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了不同大小的线性方程组，并使用 Numpy（和 CuPy）的`linalg.solve`例程通过以下代码解决它，
- en: '![](../Images/da82dcb41575536341d1705d43609761.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da82dcb41575536341d1705d43609761.png)'
- en: And, the code changes by a single letter (in multiple invocations) for the CuPy
    implementation!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，CuPy 实现的代码在多次调用中仅通过一个字母的变化就能完成！
- en: '![](../Images/a1bac98a78faba8d375bbea8b9339f76.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1bac98a78faba8d375bbea8b9339f76.png)'
- en: Also note, how we can create CuPy arrays from Numpy arrays as arguments.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，我们如何从 Numpy 数组创建 CuPy 数组作为参数。
- en: The result is dramatic though. CuPy starts slow or at a similar pace that of
    Numpy, but beats it squarely for large problem sizes (number of equations).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 结果却很显著。CuPy 开始时较慢或与 Numpy 的速度相似，但对于大规模问题（方程数量）表现得更为出色。
- en: '![](../Images/3eef97e201daaefe710505532167abe3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eef97e201daaefe710505532167abe3.png)'
- en: Singular value decomposition
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 奇异值分解
- en: Next, we tackle the problem of singular value decomposition using a randomly
    generated square matrix (drawn from a normal distribution) of varying sizes. We
    don’t repeat the code block here but just show the result for brevity.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用一个从正态分布中生成的随机方阵（具有不同大小）来解决奇异值分解问题。我们这里不重复代码块，仅展示结果以简洁起见。
- en: '![](../Images/c9e56c1ab31bb1185a08a915d28e1175.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9e56c1ab31bb1185a08a915d28e1175.png)'
- en: Significant to note that the CuPy algorithm does not show markedly superior
    performance to that of the Numpy algorithm in this problem class. Perhaps, this
    is something to be taken up by the CuPy developers to improve upon.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，CuPy 算法在此问题类别中并未显著优于 Numpy 算法。也许，这是 CuPy 开发者需要改进的地方。
- en: 'Going back to the basic: Matrix inversion'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归基础：矩阵求逆
- en: Lastly, we go back to the basics and consider the fundamental problem of matrix
    inversion (used in almost all machine learning algorithms). The result again shows
    strongly favorable performance gain by the CuPy algorithm over that from the Numpy
    package.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回到基础，考虑矩阵求逆这一基本问题（几乎在所有机器学习算法中都有使用）。结果再次显示 CuPy 算法在性能上明显优于 Numpy 包。
- en: '![](../Images/520e51bcb56b1e8fec32e0f8f078365b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/520e51bcb56b1e8fec32e0f8f078365b.png)'
- en: Tackling a K-means clustering problem
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理 K-means 聚类问题
- en: Next, we consider an unsupervised learning problem of clustering using the all-too-familiar
    k-means algorithm. Here, we are comparing a CuML function with an equivalent estimator
    from the Scikit-learn package.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们考虑一个无监督学习问题，使用众所周知的 k-means 算法进行聚类。在这里，我们比较了 CuML 函数与 Scikit-learn 包中的等效估计器。
- en: Just for reference, here is the API comparison between these two estimators.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 仅供参考，这里是这两个估计器的 API 比较。
- en: '![](../Images/facdccdbfe76522bafd1a3c7a968a4b3.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/facdccdbfe76522bafd1a3c7a968a4b3.png)'
- en: '**Image source**: [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and [CuML
    website](https://docs.rapids.ai/api/cuml/stable/api.html#k-means-clustering) (Open-source
    projects)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**： [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    和 [CuML 网站](https://docs.rapids.ai/api/cuml/stable/api.html#k-means-clustering)
    （开源项目）'
- en: Here is the result for a dataset with 10 features/dimensions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个具有 10 个特征/维度的数据集的结果。
- en: '![](../Images/6e741bf16eb344f368b8968ea9a58538.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e741bf16eb344f368b8968ea9a58538.png)'
- en: And, here is the result of another experiment with a 100-feature dataset.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个具有 100 个特征的数据集的实验结果。
- en: '![](../Images/c49a3e4ddf1e024f4f98159babf87482.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c49a3e4ddf1e024f4f98159babf87482.png)'
- en: Clearly, both the sample size (number of rows) and dimensionality (number of
    columns) mattered in how the GPU-based acceleration performed superior.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，样本数量（行数）和维度（列数）在 GPU 加速的性能表现中都起着重要作用。
- en: All-too-familiar linear regression problem
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 众所周知的线性回归问题
- en: Who can ignore a linear regression problem for speed comparison while dealing
    with tabular datasets? Following the cadence as before, we vary the problem size
    — this time both the number of samples and dimensions simultaneously — and compare
    the performance of CuML `LinearRegression` estimator to that obtained from the
    Scikit-learn stable.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理表格数据集时，谁能忽视线性回归问题的速度比较呢？按照以前的节奏，我们改变了问题的规模——这一次同时改变样本数量和维度——并比较了 CuML `LinearRegression`
    估计器与 Scikit-learn 稳定版的性能。
- en: The X-axis in the following figure represents the problem size — from 1,000
    samples/50 features to 20,000 samples/1000 features.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中的 X 轴表示问题规模——从 1,000 个样本/50 个特征到 20,000 个样本/1,000 个特征。
- en: Again, the CuML estimator performs much better as the problem complexity (sample
    size and dimensionality) grows.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，随着问题复杂性的增加（样本数量和维度），CuML 估计器的表现显著提升。
- en: '![](../Images/6e95f098dc9fe9c215df7cef5e96d97f.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e95f098dc9fe9c215df7cef5e96d97f.png)'
- en: Summary
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: We focused on two of the most fundamental components of the RAPIDS framework,
    which aims to bring the power of GPU to the everyday tasks of data analysis and
    machine learning, even when the data scientist does not perform any deep learning
    task.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们专注于 RAPIDS 框架的两个最基本组件，该框架旨在将 GPU 的强大计算能力带到数据分析和机器学习的日常任务中，即使数据科学家不进行任何深度学习任务。
- en: '![](../Images/99e2cd77dfaf96b3a37ddccb0662cae7.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99e2cd77dfaf96b3a37ddccb0662cae7.png)'
- en: '**Image source**: Made by the author with free Pixabay images ([Link-1](https://pixabay.com/photos/nvidia-graphic-card-bitcoin-gpu-5264921/), [Link-2](https://pixabay.com/vectors/cube-hexagon-stairs-152932/), [Link-3](https://pixabay.com/vectors/statistic-analytic-diagram-1564428/))'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**：由作者使用免费Pixabay图片制作（[链接-1](https://pixabay.com/photos/nvidia-graphic-card-bitcoin-gpu-5264921/), [链接-2](https://pixabay.com/vectors/cube-hexagon-stairs-152932/), [链接-3](https://pixabay.com/vectors/statistic-analytic-diagram-1564428/))'
- en: We used a [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)** Tesla
    T4 based instance for **[**easy, free, and quick setup**](https://www.saturncloud.io/s/freehosted/) and
    showed a few features of CuPy and CuML libraries and performance comparisons of
    widely used algorithms.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个 [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)** 基于Tesla
    T4的实例，进行 **[**简单、免费的快速设置**](https://www.saturncloud.io/s/freehosted/)**，并展示了一些CuPy和CuML库的功能以及广泛使用的算法性能比较。
- en: Not all algorithms from the RAPIDS libraries are vastly superior but most are.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非所有RAPIDS库中的算法都极为出色，但大多数都是。
- en: In general, the performance gain increases rapidly as the problem complexity
    (sample size and dimensionality) grows
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一般来说，随着问题复杂性（样本大小和维度）的增加，性能提升迅速。
- en: If you have a GPU, always give RAPIDS a try, compare and test if you are gaining
    any performance, and make it a trusted workhorse of your data science pipeline.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有GPU，始终尝试使用RAPIDS，比较和测试是否获得了性能提升，并使其成为你数据科学管道中值得信赖的工作马。
- en: The code change is minimal, almost non-existent for switching over.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码变更最小，几乎没有，切换过来几乎没有成本。
- en: '**Let the power of GPU jumpstart your analytics and data science workflow**.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**让GPU的力量启动你的分析和数据科学工作流程**。'
- en: You can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    code, ideas, and resources in machine learning and data science. If you are, like
    me, passionate about AI/machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter](https://twitter.com/tirthajyotiS).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看作者的 [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** 代码库**，获取机器学习和数据科学的代码、创意和资源。如果你像我一样，对AI/机器学习/数据科学充满热情，请随时 [在LinkedIn上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) 或 [关注我在Twitter上的账号](https://twitter.com/tirthajyotiS)。
- en: Thanks to Mel.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Mel。
- en: '[Original](https://medium.com/dataseries/gpu-powered-data-science-not-deep-learning-with-rapids-29f9ed8d51f3).
    Reposted with permission.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/dataseries/gpu-powered-data-science-not-deep-learning-with-rapids-29f9ed8d51f3)。经许可转载。'
- en: '**Related:**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to Use NVIDIA GPU Accelerated Libraries](/2021/07/nvidia-gpu-accelerated-libraries.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用NVIDIA GPU加速库](/2021/07/nvidia-gpu-accelerated-libraries.html)'
- en: '[Why and how should you learn “Productive Data Science”?](/2021/07/learn-productive-data-science.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你为什么以及如何学习“高效数据科学”？](/2021/07/learn-productive-data-science.html)'
- en: '[Not Only for Deep Learning: How GPUs Accelerate Data Science & Data Analytics](/2021/07/deep-learning-gpu-accelerate-data-science-data-analytics.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[不仅仅是深度学习：GPU如何加速数据科学和数据分析](/2021/07/deep-learning-gpu-accelerate-data-science-data-analytics.html)'
- en: More On This Topic
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为出色数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并通过目的来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
