- en: A Brief Introduction to Papers With Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《带代码的论文》简要介绍
- en: 原文：[https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)
- en: '![A Brief Introduction to Papers With Code](../Images/4e57e169b0ca69ae28701892e1390d35.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![简要介绍《带代码的论文》](../Images/4e57e169b0ca69ae28701892e1390d35.png)'
- en: Image by author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The name tells everything. [Papers with Code](https://paperswithcode.com/) is
    the platform that contains research papers with code implementations by the authors
    or community. Recently, Papers with Code have grown in both popularity and in
    terms of providing a complete ecosystem for machine learning research.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这个名称说明了一切。[带代码的论文](https://paperswithcode.com/)是一个包含作者或社区提供的代码实现的研究论文的平台。最近，《带代码的论文》在流行度和提供机器学习研究完整生态系统方面都得到了增长。
- en: You can reproduce the results by using the code, checking all the previous implementations
    with the model performance metrics, viewing the dataset, models, and methods used
    in the research paper. It is the next-generation knowledge-sharing platform that
    is community-driven and open to edits like Wikipedia under the CC-BY-SA license.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用代码、检查所有先前的实现与模型性能指标、查看数据集、模型和研究论文中使用的方法来再现结果。这是一个下一代知识共享平台，由社区驱动，开放编辑，类似于维基百科，采用CC-BY-SA许可证。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业之路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Apart from machine learning, the platform has [specialized portals](https://portal.paperswithcode.com/)
    for papers with code in astronomy, physics, computer sciences, mathematics, and
    statistics. You can also check all the stats on trending papers, frameworks, and
    code coverage.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 除了机器学习，该平台还有针对天文学、物理学、计算机科学、数学和统计学的[专业门户](https://portal.paperswithcode.com/)。你还可以查看关于热门论文、框架和代码覆盖率的所有统计数据。
- en: '![Papers With Code](../Images/d864940d66e4e70a911e5b5e3415c67d.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![带代码的论文](../Images/d864940d66e4e70a911e5b5e3415c67d.png)'
- en: Image from [Papers With Code](https://paperswithcode.com/)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [带代码的论文](https://paperswithcode.com/)
- en: Anyone can contribute by clicking on the edit button. If you want to add code
    to a paper, evaluation table, task or dataset then find the edit button on a particular
    page to modify it. The user interface is quite friendly so finding papers or adding
    resources is quite easy. All the submitted code and results are under the free
    [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0/) license.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 任何人都可以通过点击编辑按钮进行贡献。如果你想向论文、评估表、任务或数据集添加代码，可以在特定页面找到编辑按钮进行修改。用户界面非常友好，因此找到论文或添加资源都很容易。所有提交的代码和结果都在免费的[CC
    BY-SA](https://creativecommons.org/licenses/by-sa/4.0/)许可证下。
- en: State of the Art
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最新技术
- en: State of the Art section contains 6434 benchmark machine learning models, 2735
    tasks and sub-tasks (Knowledge Distillation, Few-Shot Image Classification), 65,649
    papers with code. These machine learning models are subcategorized by various
    fields of studies such as Computer Vision, Natural Language Processing, and Time
    Series.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最新技术部分包含6434个基准机器学习模型，2735个任务和子任务（知识蒸馏，少样本图像分类），65,649篇带代码的论文。这些机器学习模型按照计算机视觉、自然语言处理和时间序列等不同研究领域进行子分类。
- en: After selecting a field of study, you can explore various subfields and results.
    For example, Computer Vision sub-class **Image Classification** has the best accuracy
    score of 90.88% using the [CoAtNet-7](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)
    model. You can view the code implementations, read the paper, view parameters
    used in neural networks, and the results in the form of a detailed comparison
    on similar datasets.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个研究领域后，你可以探索各种子领域和结果。例如，计算机视觉子类别**图像分类**使用[CoAtNet-7](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)模型达到最佳准确率90.88%。你可以查看代码实现、阅读论文、查看神经网络中使用的参数，以及类似数据集的详细比较结果。
- en: '![ImageNet Benchmark](../Images/712c3cba6e1ffcc616d305743ada52be.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![ImageNet基准](../Images/712c3cba6e1ffcc616d305743ada52be.png)'
- en: Image from [ImageNet Benchmark](https://paperswithcode.com/sota/image-classification-on-imagenet)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[ImageNet基准](https://paperswithcode.com/sota/image-classification-on-imagenet)
- en: Datasets
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: The Datasets section contains 5,628 machine learning datasets and you can either
    search the dataset directly or filter them out on modality, tasks, and languages.
    You are not just getting access to the dataset you are getting full stats on what
    are popular datasets in particular category based on benchmark results and research
    papers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集部分包含5,628个机器学习数据集，你可以直接搜索数据集或根据模态、任务和语言进行筛选。你不仅能访问数据集，还能获得基于基准结果和研究论文的热门数据集的完整统计信息。
- en: Every dataset contains a link to the paper or website of which the original
    dataset. The Data page is easy to navigate and within a few minutes you can understand
    the modality, license information, papers published, and benchmark based on subcategories.
    For example, the benchmark for **Self-Supervised Image Classification** on **ImageNet**
    is [iBOT](https://paperswithcode.com/paper/ibot-image-bert-pre-training-with-online)
    with 82.3% accuracy.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据集都包含指向原始数据集论文或网站的链接。数据页面易于导航，几分钟内你可以了解模态、许可证信息、发表的论文和基于子类别的基准。例如，**自监督图像分类**在**ImageNet**上的基准是[iBOT](https://paperswithcode.com/paper/ibot-image-bert-pre-training-with-online)，其准确率为82.3%。
- en: To share your dataset with the ML community you need fill the form [Add a dataset](https://paperswithcode.com/contribute/dataset/new)
    and provide links and detailed information about dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要与ML社区分享你的数据集，你需要填写表单[添加数据集](https://paperswithcode.com/contribute/dataset/new)，并提供数据集的链接和详细信息。
- en: '![Machine Learning Datasets](../Images/41144080c92e0c0b2666d92c562d72a1.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习数据集](../Images/41144080c92e0c0b2666d92c562d72a1.png)'
- en: Image by [Machine Learning Datasets](https://paperswithcode.com/datasets)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于[机器学习数据集](https://paperswithcode.com/datasets)。
- en: Methods
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: The platform is well structured and organized as it divides various sections
    into smaller sub-sections. The state-of-the-art models are organized by various
    fields of machine learning (Computer Vision, Speech), and each field of study
    consists of tasks (Object Detection, Image Generation) and sub-tasks (Unsupervised
    Image Classification, Fine-Grained Image Classification). Finally, these sub-tasks
    are built using various methods (Stochastic Optimization, Convolutional Neural
    Networks).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该平台结构良好，组织有序，将各个部分划分为较小的子部分。最先进的模型按各种机器学习领域（计算机视觉、语音）组织，每个研究领域包含任务（目标检测、图像生成）和子任务（无监督图像分类、细粒度图像分类）。最后，这些子任务是使用各种方法（随机优化、卷积神经网络）构建的。
- en: The Method section is divided by type, and each type consists of various methods.
    For example, the General type consists of **Attention** and **Activation Functions**.
    Each method has some sort of variation that has been used to create models or
    used in processing the data. If you want to improve your current machine learning
    system then the Method section is the best place to find solutions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 方法部分按类型划分，每种类型包含各种方法。例如，通用类型包括**注意力机制**和**激活函数**。每种方法都有某种变体，用于创建模型或处理数据。如果你想改善当前的机器学习系统，那么方法部分是寻找解决方案的最佳地方。
- en: Example
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: Let’s discover what information we get on the [CoAtNet](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)
    page. The page consists of a complete research paper name and author names with
    social media links. You can read the abstract or even download the full paper
    from [arxiv](https://arxiv.org/) or general publications. If you like the research
    paper and want to know about code implementations and results then start scrolling
    down the page to discover multiple GitHub repositories links, tasks, datasets,
    results, and methods. The platform enhances the researcher’s experience by connecting
    various components of machine learning ecosystems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来发现 [CoAtNet](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)
    页面上获取了哪些信息。该页面包含完整的研究论文名称和作者姓名以及社交媒体链接。你可以阅读摘要或从 [arxiv](https://arxiv.org/) 或一般出版物下载完整论文。如果你喜欢这篇研究论文并想了解代码实现和结果，请开始向下滚动页面，以发现多个
    GitHub 存储库链接、任务、数据集、结果和方法。该平台通过连接机器学习生态系统的各种组件来提升研究人员的体验。
- en: '![example page](../Images/206f302a1e03b1ece4a0c27ded348244.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![示例页面](../Images/206f302a1e03b1ece4a0c27ded348244.png)'
- en: Gif from [CoAtNet](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Gif 来自 [CoAtNet](https://paperswithcode.com/paper/coatnet-marrying-convolution-and-attention)
- en: Conclusion
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Papers with Code have several features that enable machine learning practitioners
    and researchers to learn and contribute to cutting-edge technologies. The platform
    also provides a link to [Hugging Face Spaces](https://huggingface.co/spaces) with
    GitHub repository so that you can experience how the model works. Apart from that,
    you can [mirror the results](https://github.com/paperswithcode/paperswithcode-client)
    of competitions on Papers with Code. For example, you can add the results on the
    Hugging Face model, and it will show up on Papers with Code with the dataset,
    model, and model metrics.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Papers with Code 拥有多个功能，使机器学习从业者和研究人员能够学习和贡献前沿技术。该平台还提供了与 [Hugging Face Spaces](https://huggingface.co/spaces)
    的链接，并附有 GitHub 存储库，以便你体验模型的工作方式。除此之外，你还可以 [镜像结果](https://github.com/paperswithcode/paperswithcode-client)
    到 Papers with Code。例如，你可以将结果添加到 Hugging Face 模型中，它将显示在 Papers with Code 上，包括数据集、模型和模型指标。
- en: In this blog, we have explored various sections of the platform and how it is
    helping researchers all over the world to learn about top research papers. We
    have learned how state-of-the-art models, datasets, tasks, sub-tasks, and methods
    are interconnected to improve the reading experience. It is the most popular platform
    among the machine learning community because of integrations and universal inclusiveness.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们探索了平台的各个部分以及它如何帮助全球研究人员了解顶级研究论文。我们了解到，最先进的模型、数据集、任务、子任务和方法是如何互相连接以改善阅读体验的。由于集成和通用包容性，这是机器学习社区中最受欢迎的平台。
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证的数据科学专业人士，热衷于构建机器学习模型。目前，他专注于内容创作，并撰写关于机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是使用图神经网络构建一个人工智能产品，以帮助那些正在与心理健康问题作斗争的学生。'
- en: More On This Topic
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月27日：对 Papers With Code 的简要介绍；…](https://www.kdnuggets.com/2022/n17.html)'
- en: '[A Brief Introduction to Kalman Filters](https://www.kdnuggets.com/2022/12/brief-introduction-kalman-filters.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卡尔曼滤波器简介](https://www.kdnuggets.com/2022/12/brief-introduction-kalman-filters.html)'
- en: '[A Brief History of the Neural Networks](https://www.kdnuggets.com/a-brief-history-of-the-neural-networks)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络简史](https://www.kdnuggets.com/a-brief-history-of-the-neural-networks)'
- en: '[Everything You Need to Know About MLOps: A KDnuggets Tech Brief](https://www.kdnuggets.com/tech-brief-everything-you-need-to-know-about-mlops)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于 MLOps 的一切：KDnuggets 技术简报](https://www.kdnuggets.com/tech-brief-everything-you-need-to-know-about-mlops)'
- en: '[Duck, Duck, Code: An Introduction to Python''s Duck Typing](https://www.kdnuggets.com/duck-duck-code-an-introduction-to-pythons-duck-typing)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[鸭子、鸭子、代码：Python鸭子类型的介绍](https://www.kdnuggets.com/duck-duck-code-an-introduction-to-pythons-duck-typing)'
- en: '[Must Read NLP Papers from the Last 12 Months](https://www.kdnuggets.com/2023/03/must-read-nlp-papers-last-12-months.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[过去12个月必读的NLP论文](https://www.kdnuggets.com/2023/03/must-read-nlp-papers-last-12-months.html)'
