- en: Introduction to PyTorch for Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 深度学习简介
- en: 原文：[https://www.kdnuggets.com/2018/11/introduction-pytorch-deep-learning.html](https://www.kdnuggets.com/2018/11/introduction-pytorch-deep-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/introduction-pytorch-deep-learning.html](https://www.kdnuggets.com/2018/11/introduction-pytorch-deep-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![Image](../Images/601b7698df3c9c20b0c40518801cdfa0.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/601b7698df3c9c20b0c40518801cdfa0.png)'
- en: In this tutorial, you’ll get an introduction to **deep learning using the PyTorch
    framework**, and by its conclusion, you’ll be comfortable applying it to your
    deep learning models. Facebook launched PyTorch 1.0 early this year with integrations
    for [Google Cloud,](https://cloud.google.com/) [AWS](http://aws.amazon.com/),
    and [Azure Machine Learning.](https://azure.microsoft.com/en-us/services/machine-learning-studio/) In
    this tutorial, I assume that you’re already familiar with [Scikit-learn](http://scikit-learn.org/), [Pandas](https://pandas.pydata.org/), [NumPy](http://www.numpy.org/),
    and [SciPy](https://www.scipy.org/). These packages are important prerequisites
    for this tutorial.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将了解**使用 PyTorch 框架的深度学习**，并在完成后，你将能够舒适地将其应用于你的深度学习模型。Facebook 今年早些时候推出了
    PyTorch 1.0，并与[Google Cloud](https://cloud.google.com/)、[AWS](http://aws.amazon.com/)和[Azure
    机器学习](https://azure.microsoft.com/en-us/services/machine-learning-studio/)集成。在本教程中，我假设你已经熟悉[Scikit-learn](http://scikit-learn.org/)、[Pandas](https://pandas.pydata.org/)、[NumPy](http://www.numpy.org/)和[SciPy](https://www.scipy.org/)。这些包是本教程的重要前提条件。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Plan of Attack
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 攻击计划
- en: What is [deep learning](https://heartbeat.fritz.ai/introduction-to-deep-learning-with-keras-c7c3d14e1527)?
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是[深度学习](https://heartbeat.fritz.ai/introduction-to-deep-learning-with-keras-c7c3d14e1527)？
- en: Introduction to PyTorch
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch 简介
- en: Why you’d prefer PyTorch to other Python Deep Learning Libraries
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么你会选择 PyTorch 而非其他 Python 深度学习库
- en: PyTorch Tensors
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch 张量
- en: PyTorch Autograd
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch 自动求导
- en: PyTorch nn Module
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch nn 模块
- en: PyTorch optim Package
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch 优化包
- en: Custom nn Modules in PyTorch
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自定义 PyTorch nn 模块
- en: Putting it all Together and Further Reading
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 综合概述及进一步阅读
- en: What is Deep Learning?
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是深度学习？
- en: Deep learning is a subfield of machine learning with algorithms inspired by
    the working of the human brain. These algorithms are referred to as artificial
    neural networks. Examples of these neural networks include [Convolutional Neural
    Networks](https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed) that
    are used for image classification, Artificial Neural Networks and Recurrent Neural
    Networks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，其算法受到人脑工作方式的启发。这些算法被称为人工神经网络。这些神经网络的例子包括[卷积神经网络](https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed)，用于图像分类，人工神经网络和递归神经网络。
- en: Introduction to PyTorch
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 简介
- en: 'PyTorch is a Python machine learning package based on[ Torch](https://en.wikipedia.org/wiki/Torch_%28machine_learning%29),
    which is an open-source machine learning package based on the programming language [Lua](https://en.wikipedia.org/wiki/Lua_%28programming_language%29).
    PyTorch has two main features:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个基于[Torch](https://en.wikipedia.org/wiki/Torch_%28machine_learning%29)的
    Python 机器学习包，而 Torch 是一个基于编程语言[Lua](https://en.wikipedia.org/wiki/Lua_%28programming_language%29)的开源机器学习包。PyTorch
    具有两个主要特性：
- en: '[Tensor](https://www.kdnuggets.com/2018/05/wtf-tensor.html) computation (like
    NumPy) with strong GPU acceleration'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Tensor](https://www.kdnuggets.com/2018/05/wtf-tensor.html) 计算（类似于 NumPy）具有强大的
    GPU 加速'
- en: Automatic differentiation for building and training neural networks
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动微分用于构建和训练神经网络
- en: Why you might prefer PyTorch to other Python deep learning libraries
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么你可能会倾向于使用 PyTorch 而非其他 Python 深度学习库
- en: 'There are a few reason you might prefer PyTorch to other deep learning libraries:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会倾向于使用 PyTorch 而非其他深度学习库有几个原因：
- en: Unlike other libraries like TensorFlow where you have to first define an entire
    computational graph before you can run your model, PyTorch allows you to define
    your graph dynamically.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与其他库如 TensorFlow 不同，你必须首先定义整个计算图才能运行模型，PyTorch 允许你动态定义计算图。
- en: PyTorch is also great for deep learning research and provides maximum flexibility
    and speed.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch 对于深度学习研究也非常出色，提供了最大的灵活性和速度。
- en: PyTorch Tensors
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 张量
- en: '**PyTorch Tensors** are very similar to NumPy arrays with the addition that
    they can run on the GPU. This is important because it helps accelerate numerical
    computations, which can increase the speed of neural networks by 50 times or greater.
    In order to use PyTorch, you’ll need to head over to[https://PyTorch.org/](https://pytorch.org/) and
    install PyTorch. If you’re using Conda, you can install PyTorch by running this
    simple command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch 张量**与 NumPy 数组非常相似，区别在于它们可以在 GPU 上运行。这一点很重要，因为它有助于加速数值计算，这可以将神经网络的速度提高
    50 倍或更多。要使用 PyTorch，你需要访问[https://PyTorch.org/](https://pytorch.org/)并安装 PyTorch。如果你使用
    Conda，可以通过运行以下简单命令安装 PyTorch：'
- en: 'In order to define a PyTorch tensor, start by importing the `torch` package.
    PyTorch allows you to define two types of[ tensors](https://pytorch.org/docs/0.3.1/tensors.html) — a
    CPU and GPU tensor. For this tutorial, I’ll assume you’re running a CPU machine,
    but I’ll also show you how to define tensors in a GPU:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义一个 PyTorch 张量，首先需要导入 `torch` 包。PyTorch 允许你定义两种类型的[张量](https://pytorch.org/docs/0.3.1/tensors.html)——CPU
    张量和 GPU 张量。在本教程中，我会假设你正在使用 CPU 机器，但我也会展示如何在 GPU 上定义张量：
- en: 'The default tensor type in PyTorch is a float tensor defined as `**torch.FloatTensor**`**. **As
    an example, you’ll create a tensor from a Python list:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 中的默认张量类型是一个浮点张量，定义为 `**torch.FloatTensor**`。作为示例，你将从一个 Python 列表中创建一个张量：
- en: 'If you’re using a GPU-enabled machine, you’ll define the tensor as shown below:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是支持 GPU 的机器，你将按照下面的方式定义张量：
- en: 'You can also perform mathematical computations such as addition and subtraction
    using PyTorch tensors:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 PyTorch 张量进行数学计算，如加法和减法：
- en: 'You can also define matrices and perform matrix operations. Let’s see how you’d
    define a matrix and transpose it:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以定义矩阵并进行矩阵操作。让我们看看如何定义一个矩阵并进行转置：
- en: PyTorch Autograd
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 自动微分
- en: PyTorch uses a technique called[ **automatic differentiation**](https://en.wikipedia.org/wiki/Automatic_differentiation) that
    numerically evaluates the derivative of a function. Automatic differentiation
    computes backward passes in neural networks. In training neural networks weights
    are randomly initialized to numbers that are near zero but not zero. **Backward
    pass** is the process by which these weights are adjusted from right to left,
    and a forward pass is the inverse (left to right).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 使用一种称为[**自动微分**](https://en.wikipedia.org/wiki/Automatic_differentiation)的技术来数值评估函数的导数。自动微分在神经网络中计算反向传播。在训练神经网络时，权重被随机初始化为接近零但不为零的数字。**反向传播**是调整这些权重的过程，从右到左，而前向传播则是其逆过程（从左到右）。
- en: '`torch.autograd` is the library that supports automatic differentiation in
    PyTorch. The central class of this package is `torch.Tensor`**.** To track all
    operations on it, set `.requires_grad`as`True`**. **To compute all gradients,
    call `.backward()`**.** The gradient for this tensor will be accumulated in the `**.**grad`attribute.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.autograd` 是支持 PyTorch 中自动微分的库。该包的核心类是 `torch.Tensor`。要跟踪所有操作，将 `.requires_grad`
    设置为 `True`。要计算所有梯度，调用 `.backward()`。该张量的梯度将累积在 `**.**grad` 属性中。'
- en: If you want to detach a tensor from computation history, call the `**.**detach()`function.
    This will also prevent future computations on the tensor from being tracked. Another
    way to prevent history tracking is by wrapping your code with `torch.no_grad():`
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想将张量从计算历史中分离，可以调用 `**.**detach()` 函数。这也将防止对张量的未来计算进行跟踪。另一种防止历史跟踪的方法是使用 `torch.no_grad():`
    包装你的代码。
- en: The `Tensor` and `Function`classes are interconnected to build an acyclic graph
    that encodes a complete history of the computation. The `.grad_fn`attribute of
    the tensor references the `Function`that created the tensor. To compute derivatives,
    call `.backward()`on a`Tensor`*.*If the `Tensor`contains one element, you don’t
    have to specify any parameters for the `backward()`function. If the `Tensor`contains
    more than one element, specify a gradient that’s a tensor of matching shape.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tensor` 和 `Function` 类是相互连接的，以构建一个无环图，该图编码了计算的完整历史。张量的 `.grad_fn` 属性引用创建该张量的
    `Function`。要计算导数，请在 `Tensor` 上调用 `.backward()`。如果 `Tensor` 只包含一个元素，你无需为 `backward()`
    函数指定任何参数。如果 `Tensor` 包含多个元素，则需要指定一个形状匹配的梯度张量。'
- en: As an example, you’ll create two tensors, one with `requires_grad`as `True`and
    the other as `False`. You’ll then use these two tensors to perform addition and
    sum operations. Thereafter, you’ll compute the gradient of one of the tensors.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，你将创建两个张量，一个的 `requires_grad` 为 `True`，另一个为 `False`。然后你将使用这两个张量进行加法和求和操作。之后，你将计算其中一个张量的梯度。
- en: Calling `**.**grad`on `b` will return nothing since you didn’t set `requires_grad`
    to `True` on it.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `**.**grad` 在 `b` 上将不会返回任何内容，因为你没有将 `requires_grad` 设置为 `True`。
- en: PyTorch nn Module
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch nn 模块
- en: 'This is the module for building neural networks in PyTorch. `nn` depends on `autograd` to
    define models and differentiate them. Let’s start by defining the procedure for **training
    a neural network**:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于在 PyTorch 中构建神经网络的模块。`nn` 依赖于 `autograd` 来定义模型和对其进行微分。让我们从定义 **训练神经网络**
    的过程开始：
- en: Define the neural network with some learnable parameters, referred to as weights.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个具有可学习参数的神经网络，这些参数称为权重。
- en: Iterate over a dataset of inputs.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历输入数据集。
- en: Process input through the network.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过网络处理输入。
- en: Compare predicted results to actual values and measure the error.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果与实际值进行比较，并测量误差。
- en: Propagate gradients back into the network’s parameters.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将梯度传播回网络的参数中。
- en: 'Update the weights of the network using a simple update rule:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用简单的更新规则更新网络的权重：
- en: '`weight = weight — learning_rate * gradient`'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`weight = weight — learning_rate * gradient`'
- en: 'You’ll now use the `nn` package to create a two-layer neural network:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你将使用 `nn` 包来创建一个两层的神经网络：
- en: 'Let’s explain some of the parameters used above:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下上述使用的一些参数：
- en: '`N` is batch size. Batch size is the number of observations after which the
    weights will be updated.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`N` 是批量大小。批量大小是权重将在更新后更新的观察数量。'
- en: '`D_in` is the input dimension'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`D_in` 是输入维度'
- en: '`H` is the hidden dimension'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`H` 是隐藏维度'
- en: '`D_out` is the output dimension'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`D_out` 是输出维度'
- en: '`torch.randn` defines a matrix of the specified dimensions'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.randn` 定义了一个具有指定维度的矩阵'
- en: '`torch.nn.Sequential` initializes a linear stack of layers'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.nn.Sequential` 初始化一个线性层堆栈'
- en: '`torch.nn.Linear`applies a linear transformation to the incoming data'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.nn.Linear` 对输入数据应用线性变换'
- en: '`torch.nn.ReLU`applies the rectified linear unit function element-wise'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.nn.ReLU` 元素级地应用修正线性单元函数'
- en: '`torch.nn.MSELoss`creates a criterion that measures the mean squared error
    between n elements in the input x and target y'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch.nn.MSELoss` 创建一个度量输入 x 和目标 y 之间的均方误差的标准'
- en: PyTorch optim Package
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch optim 包
- en: Next you’ll use the `optim` package to **define an optimizer** that will update
    the weights for you. The `optim` package abstracts the idea of an optimization
    algorithm and provides implementations of commonly used optimization algorithms
    such as AdaGrad, RMSProp and Adam. We’ll use the Adam optimizer, which is one
    of the more popular optimizers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将使用 `optim` 包来 **定义一个优化器**，它将为你更新权重。`optim` 包抽象了优化算法的概念，并提供了常用优化算法的实现，如
    AdaGrad、RMSProp 和 Adam。我们将使用 Adam 优化器，它是更受欢迎的优化器之一。
- en: The first argument this optimizer takes is the tensors, which it should update.
    In the forward pass you’ll compute the predicted y by passing x to the model.
    After that, compute and print the loss. Before running the backward pass, zero
    all the gradients for the variables that will be updated using the optimizer.
    This is done because, by default, gradients are not overwritten when `.backward()`is
    called. Thereafter, call the step function on the optimizer, and this updates
    its parameters. How you’d implement this is shown below,
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该优化器接受的第一个参数是张量，它应该更新。在前向传递中，你将通过将 x 传递给模型来计算预测的 y。之后，计算并打印损失。在运行反向传递之前，将所有梯度归零，以便更新优化器中的变量。这是因为默认情况下，`.backward()`
    被调用时梯度不会被覆盖。之后，调用优化器的 step 函数，这将更新其参数。如何实现如下所示，
- en: Custom nn Modules in PyTorch
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch 中的自定义 nn 模块
- en: 'Sometimes you’ll need to build your own custom modules. In these cases you’ll
    subclass the `nn.Module`**. **You’ll then need to define a `forward`that will
    receive input tensors and produce output tensors. How to implement a two-layer
    network using `nn.Module`is shown below*.* The model is very similar to the one
    above, but the difference is you’ll use `torch.nn.Module`to create the neural
    network. The other difference is the use of `stochastic gradient descent optimizer`instead
    of Adam. You can implement a custom nn module as shown below:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你需要构建自己的自定义模块。在这些情况下，你将子类化 `nn.Module`**。**然后你需要定义一个 `forward`，它将接收输入张量并产生输出张量。如何使用
    `nn.Module` 实现一个两层网络如下所示*。*该模型与上面的模型非常相似，但不同之处在于你将使用 `torch.nn.Module` 来创建神经网络。另一个不同之处是使用
    `随机梯度下降优化器` 而不是 Adam。你可以按下面所示实现一个自定义 nn 模块：
- en: Putting it all Together and Further Reading
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 综合所有内容与进一步阅读
- en: PyTorch allows you to implement different types of layers such as [convolutional
    layers,](https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed) [recurrent
    layers](https://pytorch.org/docs/stable/index.html), and [linear layers,](https://pytorch.org/docs/stable/nn.html) among
    others. You can learn more about PyTorch from its official[ documentation](https://pytorch.org/docs/stable/).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 允许你实现不同类型的层，如 [卷积层，](https://heartbeat.fritz.ai/a-beginners-guide-to-convolutional-neural-networks-cnn-cf26c5ee17ed)
    [递归层](https://pytorch.org/docs/stable/index.html)，以及 [线性层，](https://pytorch.org/docs/stable/nn.html)
    等等。你可以通过其官方 [文档](https://pytorch.org/docs/stable/) 了解更多有关 PyTorch 的信息。
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [德里克·穆伊提](https://derrickmwiti.com/)** 是一位数据分析师、作家和导师。他致力于在每个任务中取得优异的成果，并且是
    Lapid Leaders Africa 的导师。'
- en: '[Original](https://heartbeat.fritz.ai/introduction-to-pytorch-for-deep-learning-5b437cea90ac).
    Reposted with permission.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/introduction-to-pytorch-for-deep-learning-5b437cea90ac)。转载经许可。'
- en: '**Related:**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Introduction to Deep Learning with Keras](/2018/10/introduction-deep-learning-keras.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras 深度学习入门](/2018/10/introduction-deep-learning-keras.html)'
- en: '[Simple Derivatives with PyTorch](/2018/05/simple-derivatives-pytorch.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的简单导数](/2018/05/simple-derivatives-pytorch.html)'
- en: '[PyTorch Tensor Basics](/2018/05/pytorch-tensor-basics.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 张量基础](/2018/05/pytorch-tensor-basics.html)'
- en: More On This Topic
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库简介：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整的免费 PyTorch 深度学习课程](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
- en: '[A Practical Guide to Transfer Learning using PyTorch](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的迁移学习实用指南](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 还是 TensorFlow？对比流行的机器学习框架](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的 PyTorch 神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[How to Start Using Natural Language Processing With PyTorch](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何开始使用 PyTorch 进行自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
