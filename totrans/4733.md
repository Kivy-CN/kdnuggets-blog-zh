# 快速轻松解决任何图像分类问题

> 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)

**由 [Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)，科学家、工程师及企业家**

![Header image](../Images/0b4cbd51df6a71c1196bb2c9006f0001.png)

[Chris Ried](https://unsplash.com/photos/ieic5Tq8YMk) 在 [Unsplash](https://unsplash.com/search/photos/programming-python) 上的代码之美

* * *

## 我们的前 3 名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

**深度学习** 正迅速成为人工智能应用中的关键工具（LeCun et al. 2015）。例如，在计算机视觉、自然语言处理和语音识别等领域，深度学习取得了显著的成果。因此，对深度学习的兴趣日益增长。

深度学习擅长解决的一个问题是 **图像分类**（Rawat & Wang 2017）。图像分类的目标是根据一组可能的类别对特定图片进行分类。图像分类的经典例子是识别一组图片中的猫和狗（例如 [Dogs vs. Cats Kaggle Competition](https://www.kaggle.com/c/dogs-vs-cats)）。

从深度学习的角度来看，图像分类问题可以通过 **迁移学习** 来解决。实际上，图像分类中的几个最先进的结果都基于迁移学习解决方案（Krizhevsky et al. 2012, Simonyan & Zisserman 2014, He et al. 2016）。Pan & Yang（2010）提供了关于迁移学习的综合评述。

**本文展示了如何实现图像分类问题的迁移学习解决方案。** 本文提出的实现方案基于 Keras（Chollet 2015），使用编程语言 Python。按照这一实现方法，你将能够快速且轻松地解决任何图像分类问题。

文章的组织方式如下：

1.  迁移学习

1.  卷积神经网络

1.  重新利用预训练模型

1.  迁移学习过程

1.  深度卷积神经网络上的分类器

1.  示例

1.  摘要

1.  参考文献

### 1\. 迁移学习

迁移学习是计算机视觉中一种流行的方法，因为它允许我们以**节省时间的方式构建准确的模型**（Rawat & Wang 2017）。通过迁移学习，你不是从头开始学习，而是从解决不同问题时学到的模式开始。这样，你可以利用之前的学习成果，避免从头开始。可以把它看作是深度学习版本的[Chartres](https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants)的“站在巨人的肩膀上”。

在计算机视觉中，迁移学习通常通过使用**预训练模型**来表现。预训练模型是指在大型基准数据集上训练的模型，用于解决与我们想要解决的问题类似的任务。因此，由于训练此类模型的计算成本，通常会从已发表的文献中导入和使用模型（例如，[VGG](https://arxiv.org/pdf/1409.1556.pdf)、[Inception](https://arxiv.org/pdf/1512.00567.pdf)、[MobileNet](https://arxiv.org/pdf/1704.04861.pdf)）。Canziani等人（2016）对使用ImageNet（Deng et al. 2009）挑战赛数据的预训练模型在计算机视觉问题上的表现进行了全面评审。

### 2\. 卷积神经网络

一些在迁移学习中使用的预训练模型基于大型**卷积神经网络**（CNN）（Voulodimos et al. 2018）。一般来说，CNN在广泛的计算机视觉任务中表现出色（Bengio 2009）。其高性能和易于训练是近年来CNN受欢迎的主要因素之一。

一个典型的CNN有两个部分：

1.  **卷积基础**，由一系列卷积层和池化层组成。卷积基础的主要目标是从图像中生成特征。有关卷积层和池化层的直观解释，请参考Chollet（2017）。

1.  **分类器**，通常由全连接层组成。分类器的主要目标是根据检测到的特征对图像进行分类。全连接层是指其神经元与前一层的所有激活都有完全连接的层。

图1显示了基于CNN的**模型架构**。请注意，这只是一个简化版本，适合本文本的目的。实际上，这种模型的架构比我们在这里建议的要复杂得多。

![](../Images/2d7c77156366d480bd5e8c2be6c4da35.png)

图1\. 基于CNN的模型架构。

这些深度学习模型的一个重要方面是它们可以自动学习**层次特征表示**。这意味着第一层计算的特征是通用的，可以在不同问题领域中重复使用，而最后一层计算的特征是特定的，依赖于所选择的数据集和任务。根据 Yosinski 等人（2014）的说法，‘*如果第一层特征是通用的而最后一层特征是特定的，那么网络中必须有一个从通用到特定的过渡*’。因此，我们的 CNN 的卷积基础——特别是其较低层（即靠近输入的层）——指的是通用特征，而分类器部分以及卷积基础中的一些较高层则指的是专用特征。

### 3\. 重新利用预训练模型

当你为了自己的需求重新利用预训练模型时，你首先要移除原有的分类器，然后添加一个适合你目的的新分类器，最后你必须**根据三种策略之一对模型进行微调**：

1.  **训练整个模型。** 在这种情况下，你使用预训练模型的架构，并根据你的数据集对其进行训练。你是从头开始学习模型，因此你需要一个大数据集（以及大量计算能力）。

1.  **训练某些层，保持其他层冻结。** 正如你所记得的，较低层指的是通用特征（与问题无关），而较高层指的是特定特征（与问题相关）。在这里，我们通过选择调整网络权重的程度来玩弄这种对立关系（冻结层在训练过程中不会改变）。通常，如果你有一个小数据集和大量参数，你会保持更多层被冻结以避免过拟合。相反，如果数据集很大而参数数量很少，你可以通过训练更多层来提高模型，因为过拟合不是问题。

1.  **冻结卷积基础。** 这种情况对应于训练/冻结权衡的极端情况。主要思路是保持卷积基础的原始形式，然后利用其输出作为分类器的输入。你将预训练模型用作固定的特征提取机制，这在计算能力有限、数据集较小和/或预训练模型解决的问题与您要解决的问题非常相似时可能会很有用。

图 2 以示意图展示了这三种策略。

![](../Images/01215828d6dedde4541e9b70fbe56de4.png)

图 2\. 微调策略。

与**策略 3**不同，**策略 3**的应用是**直接的**，**策略 1**和**策略 2**要求你**小心**卷积部分使用的学习率。学习率是一个超参数，它控制着你调整网络权重的幅度。当你使用基于 CNN 的预训练模型时，使用较小的学习率是明智的，因为高学习率会增加丢失先前知识的风险。假设预训练模型已经经过良好的训练，这个假设是合理的，保持较小的学习率将确保你不会过早或过多地扭曲 CNN 权重。

### 4. 迁移学习过程

从实际的角度来看，整个迁移学习过程可以总结如下：

1.  **选择一个预训练模型**。在众多可用的预训练模型中，你选择一个看起来适合你问题的模型。例如，如果你使用 Keras，你可以立即访问一系列模型，如 VGG（Simonyan & Zisserman 2014）、InceptionV3（Szegedy 等 2015）和 ResNet5（He 等 2015）。[这里](https://keras.io/applications/)你可以查看 Keras 上所有可用的模型。

1.  **根据大小-相似性矩阵对你的问题进行分类。** 在图 3 中，你会看到“矩阵”控制你的选择。这个矩阵根据数据集的大小及其与预训练模型训练数据集的相似性来分类你的计算机视觉问题。作为一个经验法则，如果你的数据集每类图像少于 1000 张，那么可以认为你的数据集很小。至于数据集的相似性，还是以常识为主。例如，如果你的任务是识别猫和狗，ImageNet 就是一个类似的数据集，因为它包含猫和狗的图像。然而，如果你的任务是识别癌细胞，那么 ImageNet 就不能算作一个类似的数据集。

1.  **微调你的模型。** 在这里，你可以使用大小-相似性矩阵来指导你的选择，然后参考我们之前提到的关于重新利用预训练模型的三种选项。图 4 提供了后续文本的视觉总结。

+   **象限 1**。大型数据集，但与预训练模型的数据集不同。这种情况将引导你到*策略 1*。由于你有一个大型数据集，你可以从头开始训练模型并进行任何你想做的事情。尽管数据集不相似，但实际上，从预训练模型初始化你的模型，使用其架构和权重，仍然可能是有用的。

+   **象限2。** 大数据集且类似于预训练模型的数据集。在这里，你处于“梦想乐园”。任何选项都可以使用。最有效的选项可能是*策略2*。由于我们有一个大数据集，过拟合不应成为问题，因此我们可以尽可能多地学习。然而，由于数据集相似，我们可以通过利用先前的知识来避免大量的训练工作。因此，只需训练分类器和卷积基的顶部层就足够了。

+   **象限3。** 小数据集且与预训练模型的数据集不同。这是计算机视觉问题中的2-7不同花色的手牌。一切都对你不利。如果抱怨不是一个选项，你唯一的希望是*策略2*。在训练和冻结的层数之间找到平衡将是困难的。如果你深入你的模型可能会过拟合，如果你保持在浅层，你将无法学到任何有用的东西。可能，你需要比象限2更深入，并且需要考虑数据增强技术（[这里](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)提供了数据增强技术的不错总结）。

+   **象限4。** 小数据集，但与预训练模型的数据集相似。我问了尤达大师，他告诉我‘*最佳选择应该是策略3*’。我不知道你怎么想，但我不会低估原力。因此，选择*策略3*。你只需去掉最后一个全连接层（输出层），将预训练模型作为固定特征提取器运行，然后使用结果特征训练新的分类器。

![](../Images/cefb71a15b54427582c7d4e630e3e3dc.png) ![](../Images/7b543ae2e3f06d6e2c2c072741aca2fb.png)

图3和图4。大小相似性矩阵（左）和用于微调预训练模型的决策图（右）。

### 5. 深度卷积神经网络上的分类器

如前所述，**图像分类模型**，它们是基于**预训练卷积神经网络**的迁移学习方法的结果，通常由**两个部分**组成：

1.  **卷积基**，用于特征提取。

1.  **分类器**，根据卷积基提取的特征对输入图像进行分类。

由于在本节中我们重点关注分类器部分，我们必须首先说明，构建分类器可以遵循不同的方法。其中一些最受欢迎的方法是：

1.  **全连接层。** 对于图像分类问题，标准的方法是使用一系列全连接层，后跟一个softmax激活层（Krizhevsky等人，2012年；Simonyan & Zisserman，2014年；Zeiler & Fergus，2014年）。softmax层输出每个可能类别标签的概率分布，然后我们只需要根据最可能的类别来对图像进行分类。

1.  **全局平均池化。**Lin等人（2013）提出了一种基于全局平均池化的不同方法。在这种方法中，我们不是在卷积基的顶部添加全连接层，而是添加一个全局平均池化层，并将其输出直接输入到softmax激活层中。Lin等人（2013）提供了关于这种方法的优缺点的详细讨论。

1.  **线性支持向量机。**线性支持向量机（SVM）是另一种可能的方法。根据Tang（2013）的研究，我们可以通过在卷积基提取的特征上训练线性SVM分类器来提高分类准确性。有关SVM方法的优缺点的详细信息可以在论文中找到。

### 更多相关话题

+   [NExT-GPT介绍：任意对任意的多模态大型语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)

+   [机器学习并不像你的大脑 第6部分：精确突触权重的重要性](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)

+   [轻松从网站上抓取图像，无需编码](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)

+   [在你的笔记本电脑上轻松探索LLMs，使用openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)

+   [轻松将LLMs集成到你的Scikit-learn工作流程中，使用Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)

+   [使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
