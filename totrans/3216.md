# 初学者的前10大机器学习算法

> 原文：[https://www.kdnuggets.com/2017/10/top-10-machine-learning-algorithms-beginners.html](https://www.kdnuggets.com/2017/10/top-10-machine-learning-algorithms-beginners.html)

![](../Images/c9c27633e28613cfa8923640c7a1149f.png)

### I. 介绍

对于机器学习算法的研究在哈佛商业评论[文章](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century)将‘数据科学家’称为‘21世纪最性感的工作’之后，获得了巨大的关注。因此，对于那些刚入门机器学习领域的人，我们决定重启我们极受欢迎的黄金博客[机器学习工程师需要知道的10个算法](/2016/08/10-algorithms-machine-learning-engineers.html)——尽管这篇文章的目标是初学者。

机器学习算法是那些可以从数据中学习并从经验中改进的算法，无需人工干预。学习任务可能包括学习将输入映射到输出的函数、学习未标记数据中的隐藏结构；或‘基于实例的学习’，通过将新实例（行）与训练数据中的实例进行比较，生成一个类别标签，该实例被存储在记忆中。‘基于实例的学习’不从特定实例创建抽象。

### II. 机器学习算法的类型

机器学习算法有3种类型：

**1\. 监督学习：**

监督学习可以解释为：使用标记的训练数据来学习从输入变量（X）到输出变量（Y）的映射函数。

*Y = f (X)*

监督学习问题可以分为两种类型：

*a. 分类*：预测给定样本的结果，其中输出变量为类别形式。例子包括标签如男性和女性、病人和健康人。

*b. 回归*：预测给定样本的结果，其中输出变量为实际值。例子包括表示降雨量的实值标签、一个人的身高。

我们在这篇博客中涵盖的前5个算法——线性回归、逻辑回归、CART、朴素贝叶斯、KNN是监督学习的例子。

集成学习是一种监督学习的方法。它意味着将多个不同的弱机器学习模型的预测结果结合起来，以预测新的样本。我们涵盖的第9-10算法——随机森林的袋装方法、XGBoost的提升方法就是集成技术的例子。

**2\. 无监督学习：**

无监督学习问题仅具备输入变量（X），但没有相应的输出变量。它使用未标记的训练数据来建模数据的潜在结构。

无监督学习问题可以分为两种类型：

*a. 关联*：发现集合中项共同出现的概率。这在市场篮子分析中应用广泛。例如：如果客户购买了面包，他80%也会购买鸡蛋。

*b. 聚类*：将样本分组，使得同一簇中的对象彼此之间比与其他簇中的对象更相似。

*c. 降维*：顾名思义，降维指的是减少数据集中的变量数量，同时确保重要信息仍然传达。降维可以通过特征提取方法和特征选择方法来完成。特征选择选择原始变量的子集。特征提取则将数据从高维空间转换为低维空间。例如：PCA算法是一种特征提取方法。

我们在此介绍的算法6-8——Apriori、K-means、PCA是无监督学习的例子。

**3\. 强化学习：**

强化学习是一种机器学习算法，允许代理基于当前状态决定最佳的下一步行动，通过学习能够最大化奖励的行为。

强化算法通常通过反复试验学习最佳动作。它们通常用于机器人技术——在这种情况下，机器人可以通过在碰撞障碍物后接收到负面反馈来学习避免碰撞，以及在视频游戏中——试错揭示了可以提升玩家奖励的具体动作。代理可以利用这些奖励来理解游戏的最佳状态并选择下一个动作。

### III. 量化机器学习算法的受欢迎程度

调查论文[如这些](http://www.cs.uvm.edu/~icdm/algorithms/10Algorithms-08.pdf)量化了10种最受欢迎的数据挖掘算法。然而，这些列表是主观的，如引用的论文所述，参与者的样本量非常有限，且由数据挖掘的高级从业者组成。被调查者包括ACM KDD创新奖、IEEE ICDM研究贡献奖的获奖者；KDD-06、ICDM’06和SDM’06的程序委员会成员；以及ICDM’06的145名与会者。

本博客中的前10名算法适合初学者，主要是我在孟买大学计算机工程本科课程中的‘数据仓库与挖掘’（DWM）课程中学习的算法。DWM课程是机器学习算法领域的一个很好的入门课程。我特别包括了最后两个算法（集成方法），基于它们在[Kaggle竞赛中的普遍性](http://www.datasciencecentral.com/profiles/blogs/want-to-win-at-kaggle-pay-attention-to-your-ensembles)。希望你喜欢这篇文章！

### IV. 有监督学习算法

**1\. 线性回归**

在机器学习中，我们有一组输入变量（x），用于确定输出变量（y）。输入变量和输出变量之间存在关系。机器学习的目标是量化这种关系。

![](../Images/a1ae8980334e4a697589004f968e799e.png)

图1：线性回归表示为形式为 y = a + bx 的直线。[来源](http://bhagyeshvikani.blogspot.ca/2015/10/linear-regression.html)在线性回归中，输入变量（x）和输出变量（y）之间的关系以方程的形式表示为 y = a + bx。因此，线性回归的目标是找出系数 a 和 b 的值。这里，a 是截距，b 是直线的斜率。

图1 显示了数据集的 x 和 y 值的绘图。目标是拟合一条最接近大多数点的直线。这将减少数据点的 y 值与直线之间的距离（‘误差’）。

**2\. 逻辑回归**

线性回归的预测值是连续的数值（降雨量以厘米为单位），而逻辑回归的预测值是离散的值（学生是否通过/失败），这是在应用了转换函数之后的结果。

逻辑回归最适用于二分类（数据集中 y = 0 或 1，其中 1 表示默认类别。例如：在预测事件是否会发生时，事件发生的情况被分类为 1。在预测一个人是否会生病时，生病的实例表示为 1）。它的名称来源于其使用的转换函数，称为逻辑函数 h(x)= 1/ (1 + e^x)，它是一个 S 形曲线。

在逻辑回归中，输出以默认类别的概率形式存在（不同于线性回归，线性回归直接给出输出）。由于是概率，输出值在0到1的范围内。输出（y值）是通过对x值进行对数转换，使用逻辑函数 h(x)= 1/ (1 + e^ -x) 生成的。然后应用一个阈值将该概率强制转换为二分类。

![](../Images/4c145ea1c19f29d1a5af2933df8d96f1.png)

图2：逻辑回归用于确定肿瘤是恶性还是良性。如果概率 h(x)>= 0.5，则分类为恶性。[来源](https://athemathmo.github.io/2016/03/07/rusty-machine.html)在图2中，为了确定肿瘤是否恶性，默认变量是 y=1（肿瘤= 恶性）；x 变量可能是肿瘤的测量值，如肿瘤的大小。如图所示，逻辑函数将数据集中各种实例的 x 值转换到 0 到 1 的范围内。如果概率超过 0.5 的阈值（由水平线表示），则肿瘤被分类为恶性。

逻辑回归方程 *P(x) = e ^ (b0 +b1*x) / (1 + e^(b0 + b1*x))* 可以转换为 *ln(p(x) / 1-p(x)) = b0 + b1*x*。

逻辑回归的目标是利用训练数据找到系数 b0 和 b1 的值，以最小化预测结果与实际结果之间的误差。这些系数通过最大似然估计方法来估算。

**3\. CART**

分类与回归树（CART）是一种决策树的实现方法，其他如 ID3、C4.5 等也是决策树的实现方法。

非终端节点包括根节点和内部节点。终端节点是叶节点。每个非终端节点表示一个单独的输入变量（x）和该变量上的一个分裂点；叶节点表示输出变量（y）。模型的使用方法如下：沿着树的分裂走到叶节点，并输出叶节点上存在的值。

图3中的决策树根据一个人的年龄和婚姻状况来判断他是否会买一辆跑车或厢式车。如果此人超过30岁且未婚，我们按如下方式遍历树：‘超过30岁？’ -> 是 -> ’已婚？’ -> 否。因此，模型输出一辆跑车。

![](../Images/b6949b5859022506961fc0ced7a7b482.png)

图3：决策树的部分。 [来源](http://www.hypertextbookshop.com/dataminingbook/public_version/contents/chapters/chapter001/section002/green/page001.html)

**4\. 朴素贝叶斯**

要计算事件发生的概率，给定另一个事件已经发生的情况下，我们使用贝叶斯定理。要计算给定某变量值的结果的概率，即计算假设(h)为真的概率，给定我们已有的知识(d)，我们使用贝叶斯定理如下：

*P(h|d)= (P(d|h) * P(h)) / P(d)*

where

+   P(h|d) = 后验概率。给定数据 d，假设 h 为真的概率，其中 P(h|d)= P(d1| h)* P(d2| h)*....*P(dn| h)* P(d)

+   P(d|h) = 似然。给定假设 h 为真的情况下，数据 d 的概率。

+   P(h) = 类别先验概率。假设 h 为真的概率（不考虑数据）

+   P(d) = 预测先验概率。数据的概率（不考虑假设）

这个算法被称为‘朴素’，因为它假设所有变量相互独立，而在现实世界中这是一个朴素的假设。

![](../Images/f2dc03a423162be40bd2e9876237bb27.png)

图4：使用朴素贝叶斯预测‘玩’的状态，使用变量‘天气’。以图4为例，如果天气=‘晴天’，结果是什么？

要确定给定变量天气=‘晴天’的情况下，玩= ‘是’ 还是 ‘否’，计算 P(yes|sunny) 和 P(no|sunny) 并选择概率较高的结果。

->P(yes|sunny)= (P(sunny|yes) * P(yes)) /  P(sunny)

= (3/9  * 9/14 ) / (5/14)

= 0.60

-> P(no|sunny)=  (P(sunny|no) * P(no)) /  P(sunny)

= (2/5  * 5/14 ) / (5/14)

= 0.40

因此，如果天气=‘晴天’，结果是玩= ‘是’。

**5\. KNN**

k-最近邻算法使用整个数据集作为训练集，而不是将数据集拆分为训练集和测试集。

当需要为一个新的数据实例获得结果时，KNN算法会遍历整个数据集以找到与新实例最接近的k个实例，或与新记录最相似的k个实例，然后输出这些结果的均值（对于回归问题）或众数（最频繁的类别，对于分类问题）。k的值由用户指定。

实例之间的相似性使用诸如欧几里得距离和汉明距离等度量方法来计算。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯的捷径。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 在IT领域支持你的组织

* * *

### 了解更多相关内容

+   [打造强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [停止学习数据科学去寻找目的，并找到目的去…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [一个90亿美元的人工智能失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)
