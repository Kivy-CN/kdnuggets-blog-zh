- en: A Beginner’s Guide to Linear Regression in Python with Scikit-Learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scikit-Learn的Python线性回归初学者指南
- en: 原文：[https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)
- en: '[comments](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html?page=2#comments)![Figure](../Images/356303905f8bf03d1984d3975e42033d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html?page=2#comments)![图示](../Images/356303905f8bf03d1984d3975e42033d.png)'
- en: '[Source](https://www.disruptordaily.com/category/digital-transformation/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://www.disruptordaily.com/category/digital-transformation/)'
- en: 'There are two types of supervised machine learning algorithms: Regression and
    classification. The former predicts continuous value outputs while the latter
    predicts discrete outputs. For instance, predicting the price of a house in dollars
    is a regression problem whereas predicting whether a tumor is malignant or benign
    is a classification problem.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习算法有两种类型：回归和分类。前者预测连续值输出，而后者预测离散输出。例如，预测房屋价格（以美元计）是一个回归问题，而预测肿瘤是恶性还是良性则是一个分类问题。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article, we will briefly study what linear regression is and how it
    can be implemented for both two variables and multiple variables using **Scikit-Learn,** which
    is one of the most popular machine learning libraries for Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将简要学习什么是线性回归，以及如何使用**Scikit-Learn**这一最受欢迎的Python机器学习库之一实现二变量和多变量线性回归。
- en: '**Linear Regression Theory**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**线性回归理论**'
- en: The term “linearity” in algebra refers to a linear relationship between two
    or more variables. If we draw this relationship in a two-dimensional space (between
    two variables), we get a straight line.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 代数中的“线性”一词指的是两个或多个变量之间的线性关系。如果我们在二维空间（两个变量之间）绘制这种关系，我们会得到一条直线。
- en: Linear regression performs the task to predict a dependent variable value (y)
    based on a given independent variable (x). So, this regression technique finds
    out a linear relationship between x (input) and y(output). Hence, the name is
    Linear Regression. If we plot the independent variable (x) on the x-axis and dependent
    variable (y) on the y-axis, linear regression gives us a straight line that best
    fits the data points, as shown in the figure below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归执行预测任务，根据给定的自变量（x）预测因变量值（y）。因此，这种回归技术发现了x（输入）和y（输出）之间的线性关系。因此，命名为线性回归。如果我们将自变量（x）绘制在x轴上，将因变量（y）绘制在y轴上，线性回归将给出一条最佳拟合数据点的直线，如下图所示。
- en: 'We know that the equation of a straight line is basically:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，直线的方程基本上是：
- en: '![Figure](../Images/841ab07c32a291e11b30076660e2d9e7.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/841ab07c32a291e11b30076660e2d9e7.png)'
- en: '[source](https://pythonprogramming.net/regression-introduction-machine-learning-tutorial/)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://pythonprogramming.net/regression-introduction-machine-learning-tutorial/)'
- en: 'The equation of the above line is :'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 上述直线的方程是：
- en: '**Y= mx + b**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**Y= mx + b**'
- en: Where b is the intercept and m is the slope of the line. So basically, the linear
    regression algorithm gives us the most optimal value for the intercept and the
    slope (in two dimensions). The y and x variables remain the same, since they are
    the data features and cannot be changed. The values that we can control are the
    intercept(b) and slope(m). There can be multiple straight lines depending upon
    the values of intercept and slope. Basically what the linear regression algorithm
    does is it fits multiple lines on the data points and returns the line that results
    in the least error.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中 b 是截距，m 是直线的斜率。因此，线性回归算法为我们提供了截距和斜率（在二维情况下）的最优值。y 和 x 变量保持不变，因为它们是数据特征，无法更改。我们可以控制的值是截距（b）和斜率（m）。根据截距和斜率的值，可能会有多条直线。线性回归算法的基本工作原理是，它在数据点上拟合多条直线，并返回误差最小的那条直线。
- en: 'This same concept can be extended to cases where there are more than two variables.
    This is called multiple linear regression. For instance, consider a scenario where
    you have to predict the price of the house based upon its area, number of bedrooms,
    the average income of the people in the area, the age of the house, and so on.
    In this case, the dependent variable(target variable) is dependent upon several
    independent variables. A regression model involving multiple variables can be
    represented as:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念可以扩展到变量多于两个的情况。这称为多元线性回归。例如，考虑一个情境，你需要根据房屋的面积、卧室数量、该地区的平均收入、房屋的年龄等预测房价。在这种情况下，因变量（目标变量）依赖于多个自变量。涉及多个变量的回归模型可以表示为：
- en: '**y = b[***0***] + m[***1***]b[***1***] + m[***2***]b[***2***] + m[***3***]b[***3***]
    + ... m[***n***]b[***n***]**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**y = b[***0***] + m[***1***]b[***1***] + m[***2***]b[***2***] + m[***3***]b[***3***]
    + ... m[***n***]b[***n***]**'
- en: This is the equation of a [hyperplane](https://en.wikipedia.org/wiki/Hyperplane).
    Remember, a linear regression model in two dimensions is a straight line; in three
    dimensions it is a plane, and in more than three dimensions, a hyperplane.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个[超平面](https://en.wikipedia.org/wiki/Hyperplane)的方程。请记住，二维中的线性回归模型是一条直线；三维中是一个平面，超过三维则是一个超平面。
- en: In this section, we will see how Python’s Scikit-Learn library for machine learning
    can be used to implement regression functions. We will start with simple linear
    regression involving two variables and then we will move towards linear regression
    involving multiple variables.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何使用 Python 的 Scikit-Learn 库来实现回归函数。我们将从涉及两个变量的简单线性回归开始，然后转向涉及多个变量的线性回归。
- en: '**Simple Linear Regression**'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**简单线性回归**'
- en: '![Figure](../Images/613e8158b697fafba5ecfb203ea7df14.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/613e8158b697fafba5ecfb203ea7df14.png)'
- en: Linear Regression
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归
- en: While exploring the Aerial Bombing Operations of World War Two dataset and recalling
    that the D-Day landings were nearly postponed due to poor weather, I downloaded
    these weather reports from the period to compare with missions in the bombing
    operations dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索二战的空袭操作数据集时，并且回忆到诺曼底登陆几乎因天气恶劣而被推迟时，我下载了这一时期的天气报告，以便与空袭操作数据集中的任务进行比较。
- en: You can download the dataset from [**here**](https://drive.google.com/open?id=1fiHg5DyvQeRC4SyhsVnje5dhJNyVWpO1).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[**这里**](https://drive.google.com/open?id=1fiHg5DyvQeRC4SyhsVnje5dhJNyVWpO1)下载数据集。
- en: The dataset contains information on weather conditions recorded on each day
    at various weather stations around the world. Information includes precipitation,
    snowfall, temperatures, wind speed and whether the day included thunderstorms
    or other poor weather conditions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含全球各个天气站每日记录的天气条件信息。信息包括降水量、降雪量、温度、风速以及是否有雷暴或其他恶劣天气条件。
- en: So our task is to predict the maximum temperature taking input feature as minimum
    temperature.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的任务是预测最大温度，以最低温度作为输入特征。
- en: 'Let''s start coding :'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始编码：
- en: 'Import all the required libraries :'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 导入所有所需的库：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following command imports the CSV dataset using pandas:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令使用 pandas 导入 CSV 数据集：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s explore the data a little bit by checking the number of rows and columns
    in our datasets.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过检查数据集中行和列的数量来稍微探索一下数据。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You should receive output as (119040, 31), which means the data contains 119040
    rows and 31 columns.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会收到输出 (119040, 31)，这意味着数据包含 119040 行和 31 列。
- en: 'To see the statistical details of the dataset, we can use `describe()`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看数据集的统计细节，我们可以使用`describe()`：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure](../Images/95dd67f2c1cfc57f012b1cacb85b4921.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/95dd67f2c1cfc57f012b1cacb85b4921.png)'
- en: statistical view of the dataset
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的统计视图
- en: 'And finally, let’s plot our data points on a 2-D graph to eyeball our dataset
    and see if we can manually find any relationship between the data using the below
    script :'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们在 2-D 图上绘制数据点，以便大致查看数据集，并使用以下脚本手动查找数据之间的关系：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have taken MinTemp and MaxTemp for doing our analysis. Below is a 2-D graph
    between MinTemp and MaxTemp.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已选择 MinTemp 和 MaxTemp 进行分析。以下是 MinTemp 和 MaxTemp 之间的 2-D 图。
- en: '![](../Images/4f691610ca26b042c2037848bb977a42.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f691610ca26b042c2037848bb977a42.png)'
- en: Let’s check the average max temperature and once we plot it we can observe that
    the Average Maximum Temperature is Between Nearly 25 and 35.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查平均最高温度，一旦绘制出来，我们可以观察到平均最高温度接近 25 和 35 之间。
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure](../Images/4d2a30c5da6ae5bf33274839cf4367a2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/4d2a30c5da6ae5bf33274839cf4367a2.png)'
- en: Average maximum temperature which is in between 25 and 35.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 平均最高温度在 25 和 35 之间。
- en: Our next step is to divide the data into “attributes” and “labels”.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是将数据分为“属性”和“标签”。
- en: Attributes are the independent variables while labels are dependent variables
    whose values are to be predicted. In our dataset, we only have two columns. We
    want to predict the MaxTemp depending upon the MinTemp recorded. Therefore our
    attribute set will consist of the “MinTemp” column which is stored in the X variable,
    and the label will be the “MaxTemp” column which is stored in y variable.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 属性是独立变量，而标签是依赖变量，其值需要预测。在我们的数据集中，我们只有两列。我们希望根据记录的 MinTemp 预测 MaxTemp。因此，我们的属性集将包括存储在
    X 变量中的“MinTemp”列，而标签将是存储在 y 变量中的“MaxTemp”列。
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Next, we split 80% of the data to the training set while 20% of the data to
    test set using below code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用以下代码将 80% 的数据分配给训练集，而将 20% 的数据分配给测试集。
- en: The test_size variable is where we actually specify the proportion of the test
    set.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: test_size 变量是我们实际指定测试集比例的地方。
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After splitting the data into training and testing sets, finally, the time is
    to train our algorithm. For that, we need to import LinearRegression class, instantiate
    it, and call the `fit()` method along with our training data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据分为训练集和测试集后，最终是训练我们的算法。为此，我们需要导入 LinearRegression 类，实例化它，并调用 `fit()` 方法以及我们的训练数据。
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we have discussed that the linear regression model basically finds the best
    value for the intercept and slope, which results in a line that best fits the
    data. To see the value of the intercept and slop calculated by the linear regression
    algorithm for our dataset, execute the following code.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所讨论的，线性回归模型基本上找到截距和斜率的最佳值，从而得到最适合数据的直线。要查看线性回归算法为我们的数据集计算的截距和斜率的值，请执行以下代码。
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The result should be approximately 10.66185201 and 0.92033997 respectively.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该分别约为 10.66185201 和 0.92033997。
- en: This means that for every one unit of change in Min temperature, the change
    in the Max temperature is about 0.92%.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每变化一个单位的 Min 温度，Max 温度的变化约为 0.92%。
- en: 'Now that we have trained our algorithm, it’s time to make some predictions.
    To do so, we will use our test data and see how accurately our algorithm predicts
    the percentage score. To make predictions on the test data, execute the following
    script:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了我们的算法，是时候进行一些预测了。为此，我们将使用我们的测试数据，看看算法预测的百分比得分有多准确。要对测试数据进行预测，请执行以下脚本：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now compare the actual output values for `X_test` with the predicted values,
    execute the following script:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将 `X_test` 的实际输出值与预测值进行比较，执行以下脚本：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure](../Images/696c3cda82e3d3e4ba71b48ae9e8ecea.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/696c3cda82e3d3e4ba71b48ae9e8ecea.png)'
- en: comparison of Actual and Predicted value
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 实际值与预测值的比较
- en: 'We can also visualize comparison result as a bar graph using the below script :'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下脚本将比较结果可视化为条形图：
- en: 'Note: As the number of records is huge, for representation purpose I’m taking
    just 25 records.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由于记录数量庞大，为了表示目的，我仅取了 25 条记录。
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure](../Images/7b628b084f3c68daaf6554a4977a3dad.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/7b628b084f3c68daaf6554a4977a3dad.png)'
- en: Bar graph showing the comparison of Actual and Predicted values.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 显示实际值与预测值比较的条形图。
- en: Though our model is not very precise, the predicted percentages are close to
    the actual ones.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的模型不是很精确，但预测的百分比接近实际值。
- en: 'Let''s plot our straight line with the test data :'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用测试数据绘制直线：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Figure](../Images/c923a92e331e7fbae77751d4f607d7a7.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c923a92e331e7fbae77751d4f607d7a7.png)'
- en: prediction vs test data
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 预测与测试数据
- en: The straight line in the above graph shows our algorithm is correct.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '-   上图中的直线表明我们的算法是正确的。'
- en: 'The final step is to evaluate the performance of the algorithm. This step is
    particularly important to compare how well different algorithms perform on a particular
    dataset. For regression algorithms, three evaluation metrics are commonly used:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '-   最后的步骤是评估算法的性能。此步骤对于比较不同算法在特定数据集上的表现特别重要。对于回归算法，常用的评估指标有：'
- en: '**1\. Mean Absolute Error **(MAE) is the mean of the absolute value of the
    errors. It is calculated as:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **1. 平均绝对误差** (MAE) 是误差绝对值的均值。其计算公式为：'
- en: '![](../Images/cedb5bff739e459b15fe7db3b7512a94.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cedb5bff739e459b15fe7db3b7512a94.png)'
- en: '**2\. Mean Squared Error** (MSE) is the mean of the squared errors and is calculated
    as:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **2. 均方误差** (MSE) 是误差平方的均值，其计算公式为：'
- en: '![](../Images/0f81969d38f5691f4279106f9bbee73f.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f81969d38f5691f4279106f9bbee73f.png)'
- en: '**3\. Root Mean Squared Error** (RMSE) is the square root of the mean of the
    squared errors:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **3. 均方根误差** (RMSE) 是误差平方均值的平方根：'
- en: '![](../Images/3203e40e4845fb4cc39c83007d1d37e5.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3203e40e4845fb4cc39c83007d1d37e5.png)'
- en: Luckily, we don’t have to perform these calculations manually. The Scikit-Learn
    library comes with pre-built functions that can be used to find out these values
    for us.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '-   幸运的是，我们不需要手动进行这些计算。Scikit-Learn 库提供了预构建的函数，可以用来为我们计算这些值。'
- en: Let’s find the values for these metrics using our test data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '-   让我们使用测试数据来查找这些指标的值。'
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You should receive output like this (but probably slightly different):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '-   你应该会得到类似这样的输出（但可能会稍有不同）：'
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You can see that the value of root mean squared error is 4.19, which is more
    than 10% of the mean value of the percentages of all the temperature i.e. 22.41\.
    This means that our algorithm was not very accurate but can still make reasonably
    good predictions.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '-   你可以看到均方根误差的值为 4.19，这超过了所有温度百分比均值（即 22.41）的 10%。这意味着我们的算法并不是非常准确，但仍然能够进行相对较好的预测。'
- en: More On This Topic
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Making Predictions: A Beginner''s Guide to Linear Regression in Python](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[预测：Python 中线性回归的初学者指南](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)'
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较线性回归和逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用线性回归模型而非…的 3 个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 22:n12，3月23日：最佳数据科学书籍](https://www.kdnuggets.com/2022/n12.html)'
- en: '[Linear Regression for Data Science](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的线性回归](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
