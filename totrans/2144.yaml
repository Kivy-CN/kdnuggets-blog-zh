- en: 6 Problems of LLMs That LangChain is Trying to Assess
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/6-problems-of-llms-that-langchain-is-trying-to-assess](https://www.kdnuggets.com/6-problems-of-llms-that-langchain-is-trying-to-assess)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![6 Problems of LLMs That LangChain is Trying to Assess](../Images/9796dbede1367593fc71890ba082eea6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In the ever-evolving landscape of technology, the surge of large language models
    (LLMs) has been nothing short of a revolution. Tools like ChatGPT and Google BARD
    are at the forefront, showcasing the art of the possible in digital interaction
    and application development.
  prefs: []
  type: TYPE_NORMAL
- en: The success of models such as ChatGPT has spurred a surge in interest from companies
    eager to harness the capabilities of these advanced language models.
  prefs: []
  type: TYPE_NORMAL
- en: Yet, the true power of LLMs doesn't just lie in their standalone abilities.
  prefs: []
  type: TYPE_NORMAL
- en: Their potential is amplified when they are integrated with additional computational
    resources and knowledge bases, creating applications that are not only smart and
    linguistically skilled but also richly informed by data and processing power.
  prefs: []
  type: TYPE_NORMAL
- en: And this integration is exactly what LangChain tries to assess.
  prefs: []
  type: TYPE_NORMAL
- en: Langchain is an innovative framework crafted to unleash the full capabilities
    of LLMs, enabling a smooth symbiosis with other systems and resources. It's a
    tool that gives data professionals the keys to construct applications that are
    as intelligent as they are contextually aware, leveraging the vast sea of information
    and computational variety available today.
  prefs: []
  type: TYPE_NORMAL
- en: It's not just a tool, it's a transformational force that is reshaping the tech
    landscape.
  prefs: []
  type: TYPE_NORMAL
- en: 'This prompts the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: How will LangChain redefine the boundaries of what LLMs can achieve?
  prefs: []
  type: TYPE_NORMAL
- en: Stay with me and let’s try to discover it all together.
  prefs: []
  type: TYPE_NORMAL
- en: What is LangChain?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangChain is an open-source framework built around LLMs. It provides developers
    with an arsenal of tools, components, and interfaces that streamline the architecture
    of LLM-driven applications.
  prefs: []
  type: TYPE_NORMAL
- en: However, it is not just another tool.
  prefs: []
  type: TYPE_NORMAL
- en: Working with LLMs can sometimes feel like trying to fit a square peg into a
    round hole.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some common problems that I bet most of you have already experienced
    yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: How to standardize prompt structures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to make sure LLM’s output can be used by other modules or libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to easily switch from one LLM model to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to keep some record of memory when needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to deal with data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All these problems bring us to the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: How to develop a whole complex application being sure that the LLM model will
    behave as expected.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The prompts are riddled with repetitive structures and text, the responses are
    as unstructured as a toddler's playroom, and the memory of these models? Let's
    just say it's not exactly elephantine.
  prefs: []
  type: TYPE_NORMAL
- en: So… how can we work with them?
  prefs: []
  type: TYPE_NORMAL
- en: Trying to develop complex applications with AI and LLMs can be a complete headache.
  prefs: []
  type: TYPE_NORMAL
- en: And this is where LangChain steps in as the problem-solver.
  prefs: []
  type: TYPE_NORMAL
- en: At its core, LangChain is made up of several ingenious components that allow
    you to easily integrate LLM in any development.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is generating enthusiasm for its ability to amplify the capabilities
    of potent large language models by endowing them with memory and context. This
    addition enables the simulation of "reasoning" processes, allowing for the tackling
    of more intricate tasks with greater precision.
  prefs: []
  type: TYPE_NORMAL
- en: For developers, the appeal of LangChain lies in its innovative approach to creating
    user interfaces. Rather than relying on traditional methods like drag-and-drop
    or coding, users can articulate their needs directly, and the interface is constructed
    to accommodate those requests.
  prefs: []
  type: TYPE_NORMAL
- en: It is a framework designed to supercharge software developers and data engineers
    with the ability to seamlessly integrate LLMs into their applications and data
    workflows.
  prefs: []
  type: TYPE_NORMAL
- en: So this brings us to the following question…
  prefs: []
  type: TYPE_NORMAL
- en: How is LangChain trying to solve all these problems?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing current LLMs present 6 main problems, now we can see how LangChain is
    trying to assess them.
  prefs: []
  type: TYPE_NORMAL
- en: '![6 Problems of LLMs That LangChain is Trying to Assess](../Images/755bed3be93c07ec17c9052b5e3a237d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Prompts are way too complex now
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s try to recall how the concept of prompt has rapidly evolved during these
    last months.
  prefs: []
  type: TYPE_NORMAL
- en: 'It all started with a simple string describing an easy task to perform:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: However, over time people realized this was way too simple. We were not providing
    LLMs enough context to understand their main task.
  prefs: []
  type: TYPE_NORMAL
- en: Today we need to tell any LLM much more than simply describing the main task
    to fulfill. We have to describe the AI’s high-level behavior, the writing style
    and include instructions to make sure the answer is accurate. And any other detail
    to give a more contextualized instruction to our model.
  prefs: []
  type: TYPE_NORMAL
- en: 'So today, rather than using the very first prompt, we would submit something
    more similar to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Right?
  prefs: []
  type: TYPE_NORMAL
- en: However, as most of you have already realized, I can ask for a different task
    but still keep the same high-level behavior of the LLM. This means that most parts
    of the prompt can remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: This is why we should be able to write this part just one time and then add
    it to any prompt you need.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain fixes this repeat text issue by offering templates for prompts.
  prefs: []
  type: TYPE_NORMAL
- en: These templates mix the specific details you need for your task (asking exactly
    for the scatter chart) with the usual text (like describing the high-level behavior
    of the model).
  prefs: []
  type: TYPE_NORMAL
- en: 'So our final prompt template would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'With two main input variables:'
  prefs: []
  type: TYPE_NORMAL
- en: type of chart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: python library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Responses Are Unstructured by Nature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We humans interpret text easily, This is why when chatting with any AI-powered
    chatbot like ChatGPT, we can easily deal with plain text.
  prefs: []
  type: TYPE_NORMAL
- en: However, when using these very same AI algorithms for apps or programs, these
    answers should be provided in a set format, like CSV or JSON files.
  prefs: []
  type: TYPE_NORMAL
- en: Again, we can try to craft sophisticated prompts that ask for specific structured
    outputs. But we cannot be 100% sure that this output will be generated in a structure
    that is useful for us.
  prefs: []
  type: TYPE_NORMAL
- en: This is where LangChain’s Output parsers kick in.
  prefs: []
  type: TYPE_NORMAL
- en: This class allows us to parse any LLM response and generate a structured variable
    that can be easily used. Forget about asking ChatGPT to answer you in a JSON,
    LangChain now allows you to parse your output and generate your own JSON.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. LLMs Have No Memory - but some applications might need them to.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now just imagine you are talking with a company’s Q&A chatbot. You send a detailed
    description of what you need, the chatbot answers correctly and after a second
    iteration… it is all gone!
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty much what happens when calling any LLM via API. When using GPT
    or any other user-interface chatbot, the AI model forgets any part of the conversation
    the very moment we pass to our next turn.
  prefs: []
  type: TYPE_NORMAL
- en: They do not have any, or much, memory.
  prefs: []
  type: TYPE_NORMAL
- en: And this can lead to confusing or wrong answers.
  prefs: []
  type: TYPE_NORMAL
- en: As most of you have already guessed, LangChain again is ready to come to help
    us.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain offers a class called memory. It allows us to keep the model context-aware,
    be it keeping the whole chat history or just a summary so it does not get any
    wrong replies.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Why choose a single LLM when you can have them all?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We all know OpenAI’s GPT models are still in the realm of LLMs. However… There
    are plenty of other options out there like Meta’s Llama, Claude, or Hugging Face
    Hub open-source models.
  prefs: []
  type: TYPE_NORMAL
- en: If you only design your program for one company's language model, you're stuck
    with their tools and rules.
  prefs: []
  type: TYPE_NORMAL
- en: Using directly the native API of a single model makes you depend totally on
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine if you built your app's AI features with GPT, but later found out you
    need to incorporate a feature that is better assessed using Meta’s Llama.
  prefs: []
  type: TYPE_NORMAL
- en: You will be forced to start all over from scratch… which is not good at all.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain offers something called an LLM class. Think of it as a special tool
    that makes it easy to change from one language model to another, or even use several
    models at once in your app.
  prefs: []
  type: TYPE_NORMAL
- en: This is why developing directly with LangChain allows you to consider multiple
    models at once.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Passing Data to the LLM is Tricky
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Language models like GPT-4 are trained with huge volumes of text. This is why
    they work with text by nature. However, they usually struggle when it comes to
    working with data.
  prefs: []
  type: TYPE_NORMAL
- en: Why? You might ask.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two main issues can be differentiated:'
  prefs: []
  type: TYPE_NORMAL
- en: When working with data, we first need to know how to store this data, and how
    to effectively select the data we want to show to the model. LangChain helps with
    this issue by using something called indexes. These let you bring in data from
    different places like databases or spreadsheets and set it up so it's ready to
    be sent to the AI piece by piece.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, we need to decide how to put that data into the prompt you
    give the model. The easiest way is to just put all the data directly into the
    prompt, but there are smarter ways to do it, too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this second case, LangChain has some special tools that use different methods
    to give data to the AI. Be it using direct Prompt stuffing, which allows you to
    put the whole data set right into the prompt, or using more advanced options like
    Map-reduce, Refine, or Map-rerank, LangChain eases the way we send data to any
    LLM.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Standardizing Development Interfaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It's always tricky to fit LLMs into bigger systems or workflows. For instance,
    you might need to get some info from a database, give it to the AI, and then use
    the AI's answer in another part of your system.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain has special features for these kinds of setups.
  prefs: []
  type: TYPE_NORMAL
- en: Chains are like strings that tie different steps together in a simple, straight
    line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agents are smarter and can make choices about what to do next, based on what
    the AI says.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LangChain also simplifies this by providing standardized interfaces that streamline
    the development process, making it easier to integrate and chain calls to LLMs
    and other utilities, enhancing the overall development experience.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In essence, LangChain offers a suite of tools and features that make it easier
    to develop applications with LLMs by addressing the intricacies of prompt crafting,
    response structuring, and model integration.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is more than just a framework, it's a game-changer in the world of
    data engineering and LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: It's the bridge between the complex, often chaotic world of AI and the structured,
    systematic approach needed in data applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we wrap up this exploration, one thing is clear:'
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is not just shaping the future of LLMs, it's shaping the future of
    technology itself.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[LangChain + Streamlit + Llama: Bringing Conversational AI to Your…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LangChain 101: Build Your Own GPT-Powered Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Transforming AI with LangChain: A Text Data Game Changer](https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LangChain Cheat Sheet](https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Make Large Language Models Play Nice with Your Software…](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparative Analysis of LangChain and LlamaIndex](https://www.kdnuggets.com/comparative-analysis-of-langchain-and-llamaindex)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
