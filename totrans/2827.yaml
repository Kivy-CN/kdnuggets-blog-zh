- en: Serverless Machine Learning with R on Cloud Run
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/serverless-machine-learning-r-cloud-run.html](https://www.kdnuggets.com/2020/02/serverless-machine-learning-r-cloud-run.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Timothy Lin](https://www.linkedin.com/in/timothy-lin-0600ba141/), Data
    Scientist, Econometrician**'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the main challenges that every data scientist face is model deployment.
    Unless you are one of the lucky few who has loads of data engineers to help you
    deploy a model, it’s really an issue in enterprise projects. I am not even implying
    that the model needs to be production ready but even a seemingly basic issue of
    making the model and insights accessible to business users is more of a hassle
    then it needs to be. There used to be 2 main ways of solving the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: Ad-hoc manual runs at every request
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hosting the code on a server and writing an API interface to make the results
    available
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These are two ends of the spectrum. Ad-hoc runs are just too tedious and clients
    typically demand for some self-serve interface but good luck trying to get a permanent
    server to host your code. Turns out there is a third way - the serverless way!
    AWS Lambdas and Google Cloud Platform Cloud Functions have really opened up a
    new way of serving results without having to manage any infrastructure. If you
    have access to the cloud, this is a very attractive option.
  prefs: []
  type: TYPE_NORMAL
- en: If you are from the javascript or python world you might have already used some
    of these tools. The problem with cloud functions is that it is restricted to particular
    environments. However, with the recent introduction of GCP’s [Cloud Run](https://cloud.google.com/run/docs/reference/container-contract),
    we are no longer limited by this problem. Cloud run allows custom docker images
    to be served on the cloud, opening up the serverless realm to many interesting
    possibilities. This means that R users can also finally have a way to develop
    and deploy serverless ML models!????¹
  prefs: []
  type: TYPE_NORMAL
- en: This post documents some of my experience with cloud run and hopefully serves
    as a good reference template for anyone who might want to try it out. I take inspiration
    from two other sources, namely [Mark’s blog](https://code.markedmondson.me/googleCloudRunner-intro/) and [Eric’s
    post](https://ericjinks.com/blog/2019/serverless-R-cloud-run/). Mark actually
    has a package on CRAN that automates some of the deployment work and Eric has
    a nice bit on continuous integration pipelines so do check it out.
  prefs: []
  type: TYPE_NORMAL
- en: This post is more of a practical guide with a real world machine learning application
    that an analyst might develop and wish to deploy, which I think makes the application
    a lot more concrete and useful. It’s also a really fun little side project.
  prefs: []
  type: TYPE_NORMAL
- en: If you are a coding person, you could skip the rest of the post and dive into
    the [github code](https://github.com/timlrx/serverless-ml), otherwise read on
    :)
  prefs: []
  type: TYPE_NORMAL
- en: Will My Project Run on the Cloud Run?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud run is not a panacea. Check out the [requirement specification](https://cloud.google.com/run/docs/reference/container-contract) and [limits](https://cloud.google.com/run/quotas) for
    more details but here are some limitations that you should be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: States are not persisted (if you want to persist them you need an external database)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum memory limit is 2GB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The container must start a server within 4 minutes after receiving a request
    and it times out after 15 minutes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This makes it well suited for short computations, but not tasks which might
    require lots of memory or are very CPU intensive. 15 minutes in reality is not
    too bad! You could probably run some regressions, decision trees, even solve a
    linear programming problem but maybe not train a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Twitter Project ????
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../Images/42efd06b01197b8373875beb2914f7ee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here’s my fun serverless-ml weekend project: an application that analyzes the
    twitter-verse. I wanted to generate two plots: a graph which compares the frequency
    of tweets over time and another one which does a sentiment analysis on the tweets.
    As an added bonus, I decided to make it interactive - this means serving static
    plots as well as interactive plotly results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main package I used were: rtweet, dplyr, ggplot2, tidytext, tidyr and stringr.
    If you are new to tidytext, check out some of my previous posts such as this one
    way back in 2017 which analyzes [recipe books](https://www.timlrx.com/2017/06/24/thesis-thursday-4-analysing-recipes/).'
  prefs: []
  type: TYPE_NORMAL
- en: rtweet provides a convenient api to collect users timeline information. You
    would need a twitter API account to get started. It’s a simple process and you
    can register for one here: [https://developer.twitter.com/en/apply-for-access](https://developer.twitter.com/en/apply-for-access).
  prefs: []
  type: TYPE_NORMAL
- en: Take note of the four keys/tokens. They should be saved as an environment variable
    in your system.² These four keys correspond to API_KEY, API_SECRET_KEY, ACCESS_TOKEN
    and ACCESS_SECRET in the tweet.R file and will be retrieved programmatically when
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/66daf56784262c7a5fe71ed865665954.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Tweet.R](https://www.timlrx.com/2020/01/22/serverless-machine-learning-with-r-on-cloud-run/(https://github.com/timlrx/serverless-ml/blob/master/twitter-r/tweet.R))'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Won’t go much into the data science code but you can check it out over [here](https://github.com/timlrx/serverless-ml/blob/master/twitter-r/tweet.R).
    The important part of it is that we are encapsulating each part as a function
    which we then call in the main api routing file (app.R).
  prefs: []
  type: TYPE_NORMAL
- en: For the sentiment analysis, we are counting the number of positive and negative
    words as matched by a dictionary.³ The lexical dictionary is from [Bing Liu et
    al.](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html). Doesn’t this require
    at external database? Not really - external dependencies or data files are fine,
    as long as they are stateless. We can package it together with our docker file
    or in this case it comes installed with the tidytext package!
  prefs: []
  type: TYPE_NORMAL
- en: '[App.R](https://github.com/timlrx/serverless-ml/blob/master/twitter-r/app.R)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This file contains the serving logic. We are using the [plumber package](https://www.rplumber.io/) which
    allows us to create a REST API in R by decorating it in with some markup. You
    can specify query parameters by using a `#* @param` markup and specify the type
    of output to return such as `#* @png` for a static image or `#* @html` for html.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an added bonus, there’s also an out of the box option to make htmlwidgets
    work (`#* @serializer htmlwidget`). This makes our serving plotly results really
    simple. I decided to create two paths for each plot, a static one as well as a
    plotly interactive result. So in total we have four paths:'
  prefs: []
  type: TYPE_NORMAL
- en: /frequency (ggplot)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: /html/frequency (plotly)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: /sentiment (ggplot)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: /html/sentiment (plotly)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The functions all accept two arguments: `n` - the number of tweets, and `users` which
    could be a comma separated list of user IDs which we will then query the twitter
    API via rtweet for the relevant information.
  prefs: []
  type: TYPE_NORMAL
- en: '[Server.R](https://github.com/timlrx/serverless-ml/blob/master/twitter-r/server.R)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the bit of code that starts our plumber server. We infer the port as
    defined by an environment variable (PORT).
  prefs: []
  type: TYPE_NORMAL
- en: That’s it for the R code. Now you should have a working application which you
    can run locally from your computer. Next, we get into the grimy details of ML-ops
    ????‍♀. This involves packaging our dependencies with docker and deploying it
    on cloud run.
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Docker is a platform which packages different software, configurations and environments
    into containers which neatly encapsulate your application. The end user just needs
    to list out the installation steps to build the image which can subsequently be
    run on the docker platform ????.
  prefs: []
  type: TYPE_NORMAL
- en: 'To jump start the configuration, we build on top of the official [r-base image](https://hub.docker.com/_/r-base).
    It’s a Linux image and we need to install some additional dependencies to make
    the application work, namely libssl-dev for rtweet and pandoc for dealing with
    htmlwidgets. This forms the start of our [Dockerfile](https://github.com/timlrx/serverless-ml/blob/master/twitter-r/Dockerfile):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we copy the scripts in our directory to the app directory in the container
    and install the necessary R libraries using the Rscript function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We expose port 8000 (this is more for documentation) and run the server when
    the container is launched:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'let’s build the docker image and give it a run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`${IMAGE}` here represents the name which you can assign to the image. Remember
    the environment variables that we need for the application? Port for plumber and
    the API keys to access twitter API? We pass it to the container when we are running
    it. Note: The build process is quite long, with the image being 1.22GB big.⁴'
  prefs: []
  type: TYPE_NORMAL
- en: If the image runs successfully, you should be able to access the routes on your
    browser. Now, we can take it from your local machine to the web!
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Run
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can use my [deploy.sh](https://github.com/timlrx/serverless-ml/blob/master/twitter-r/deploy.sh) script
    as a guide on how to build and deploy your image. Before doing so, I recommend
    that you assign the Cloud Run Admin role to the account or user you are running
    the script in order for it to be deployed correctly. You can do it from the [IAM
    panel](https://console.cloud.google.com/iam-admin) within GCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the script, I retrieved the project ID programmatically, but feel free to
    substitute it with your GCP project. All the script does is to upload the local
    docker image to Google’s container repository and run cloud run to deploy the
    image from the repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We add an `allow-unauthenticated` to allow public traffic and increase the
    memory as the default was too low. You can start with the default 256MB first
    but if you encounter any errors, do check the cloud run logs which is very useful
    for debugging any errors. If all goes well, you should be greeted with an image
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b85f4c428b7b6a3c3679eb5f06c07c18.png)'
  prefs: []
  type: TYPE_IMG
- en: Our twitter project is now successfully hosted on Cloud Run!
  prefs: []
  type: TYPE_NORMAL
- en: Test it out
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here’s the fun part - try it out and visualize and analyse live twitter data!
  prefs: []
  type: TYPE_NORMAL
- en: You can try out my hosted cloud run with one of the 4 endpoints listed above: [https://twitter-r-cvdvxo3vga-uc.a.run.app/](https://twitter-r-cvdvxo3vga-uc.a.run.app/)
  prefs: []
  type: TYPE_NORMAL
- en: Some fun examples!
  prefs: []
  type: TYPE_NORMAL
- en: Frequency of Obama tweets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most followed person on Twitter with 112 million followers does not actually
    tweet too frequently ????:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://twitter-r-cvdvxo3vga-uc.a.run.app/frequency?n=500&users=BarackObama](https://twitter-r-cvdvxo3vga-uc.a.run.app/frequency?n=500&users=BarackObama)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7f9e48e5df9219eff0f80ab9524e028d.png)'
  prefs: []
  type: TYPE_IMG
- en: Sentiment analysis comparison between BBCworld and realDonaldTrump
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sad!⁵
  prefs: []
  type: TYPE_NORMAL
- en: '[https://twitter-r-cvdvxo3vga-uc.a.run.app/sentiment?n=1000&users=BBCWorld,realDonaldTrump](https://twitter-r-cvdvxo3vga-uc.a.run.app/sentiment?n=1000&users=BBCWorld,realDonaldTrump)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/42efd06b01197b8373875beb2914f7ee.png)'
  prefs: []
  type: TYPE_IMG
- en: What do politicians and entertainers have in common?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: They are overwhelmingly positive (here we use our plotly html endpoint)
  prefs: []
  type: TYPE_NORMAL
- en: '[https://twitter-r-cvdvxo3vga-uc.a.run.app/html/sentiment?n=500&users=narendramodi,TheEllenShow](https://twitter-r-cvdvxo3vga-uc.a.run.app/html/sentiment?n=500&users=narendramodi,TheEllenShow)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a5195bfb62dc19b985472e8f761d1d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: That’s it for this serverless + R tutorial. Hope you managed to learn something
    useful or at the very least find the twitter analysis interesting ????. The nice
    part about having this application running is that you can analyze real-time twitter
    frequency or sentiment plots with whatever account you choose (even your own),
    so feel free to try it out.⁶
  prefs: []
  type: TYPE_NORMAL
- en: There are some very nice benefits of using a serverless stack as well such as
    per second billing, automatically scalable containers which makes it a perfect
    fit to deploy a hobby project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are in R, you can call `Sys.setenv()` or just export it using the CLI
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://www.tidytextmining.com/sentiment.html](https://www.tidytextmining.com/sentiment.html)[↩](https://www.timlrx.com/2020/01/22/serverless-machine-learning-with-r-on-cloud-run/#fnref3)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I took about 15 minutes to build the image. That’s one of the downsides of R
    - it’s really convenient for analyzing data but not really friendly for production.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are some issues scraping data from realDonaldTrump ([https://github.com/ropensci/rtweet/issues/382](https://github.com/ropensci/rtweet/issues/382))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I will keep it up and running as long as I can as long as the usage does not
    suddenly spike up and exceed the free tier limit
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bio: [Timothy Lin](https://www.linkedin.com/in/timothy-lin-0600ba141/)**
    is a Data Scientist and Econometrician. Timothy''s is interested in applying data
    science techniques to solve business problems. He consults for multiple companies
    on projects involving big data analysis, consumer research, and graph theory.
    While not at work, he often muses about how models can be better deployed in productions
    settings and blog about his latest findings at [https://www.timlrx.com](https://www.timlrx.com)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.timlrx.com/2020/01/22/serverless-machine-learning-with-r-on-cloud-run/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Customer Segmentation for R Users](/2019/09/customer-segmentation-r-users.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beginner’s Guide to K-Nearest Neighbors in R: from Zero to Hero](/2020/01/beginners-guide-nearest-neighbors-r.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[R Users’ Salaries from the 2019 Stackoverflow Survey](/2019/08/r-users-salaries-2019-stackoverflow-survey.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Schedule & Run ETLs with Jupysql and GitHub Actions](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn How to Run Alpaca-LoRA on Your Device in Just a Few Steps](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Run an LLM Locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyTest: Effortlessly Write and Run Tests in Python](https://www.kdnuggets.com/getting-started-with-pytest-effortlessly-write-and-run-tests-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Distribute and Run LLMs with llamafile in 5 Simple Steps](https://www.kdnuggets.com/distribute-and-run-llms-with-llamafile-in-5-simple-steps)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
