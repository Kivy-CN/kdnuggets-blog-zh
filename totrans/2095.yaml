- en: 'Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![3 Simple Steps to Local RAG with Your Content](../Images/c90e6a1c2995d52c9c4f9fc3fc7dc6dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author | Midjourney & Canva
  prefs: []
  type: TYPE_NORMAL
- en: Do you want local RAG with minimal trouble? Do you have a bunch of documents
    you want to treat as a knowledge base to augment a language model with? Want to
    build a chatbot that knows about what you want it to know about?
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Well, here's arguably the easiest way.
  prefs: []
  type: TYPE_NORMAL
- en: I might not be the most optimized system for inference speed, vector precision,
    or storage, but it is super easy. Tweaks can be made if desired, but even without,
    what we do in this short tutorial should get your local RAG system fully operational.
    And since we will be using Llama 3, we can also hope for some great results.
  prefs: []
  type: TYPE_NORMAL
- en: 'What are we using as our tools today? 3 llamas: Ollama for model management,
    Llama 3 as our language model, and LlamaIndex as our RAG framework. Llama, llama,
    llama.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Ollama, for Model Management'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ollama can be used to both manage and interact with language models. Today we
    will be using it both for model management and, since LlamaIndex is able to interact
    directly with Ollama-managed models, indirectly for interaction as well. This
    will make our overall process even easier.
  prefs: []
  type: TYPE_NORMAL
- en: We can install Ollama by following the system-specific directions on the application's
    [GitHub repo](https://github.com/ollama/ollama).
  prefs: []
  type: TYPE_NORMAL
- en: Once installed, we can launch Ollama from the terminal and specify the model
    we wish to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Llama 3, the Language Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once Ollama is installed and operational, we can download any of the models
    listed on its GitHub repo, or create our own Ollama-compatible model from other
    existing language model implementations. Using the Ollama run command will download
    the specified model if it is not present on your system, and so downloading Llama
    3 8B can be accomplished with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Just make sure you have the local storage available to accommodate the 4.7 GB
    download.
  prefs: []
  type: TYPE_NORMAL
- en: Once the Ollama terminal application starts with the Llama 3 model as the backend,
    you can go ahead and minimize it. We'll be using LlamaIndex from our own script
    to interact.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: LlamaIndex, the RAG Framework'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last piece of this puzzle is [LlamaIndex](https://www.llamaindex.ai/), our
    RAG framework. To use LlamaIndex, you will need to ensure that it is installed
    on your system. As the LlamaIndex packaging and namespace has made recent changes,
    it's best to check the official documentation to get LlamaIndex installed on your
    local environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once up and running, and with Ollama running with the Llama3 model active,
    you can save the following to file (adapted from [here](https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This script is doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Documents are stored in the "data" folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embeddings model being used to create your RAG documents embeddings is a BGE
    variant from Hugging Face
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language model is the aforementioned Llama 3, accessed via Ollama
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The query being asked of our data ("What are the 5 stages of RAG?") is fitting
    as I dropped a number of RAG-related documents in the data folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And the output of our query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that we would likely want to optimize the script in a number of ways to
    facilitate faster search and maintaining some state (embeddings, for instance),
    but I will leave that for the interested reader to explore.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well, we did it. We managed to get a LlamaIndex-based RAG application using
    Llama 3 being served by Ollama locally in 3 fairly easy steps. There is a lot
    more you could do with this, including optimizing, extending, adding a UI, etc.,
    but simple fact remains that we were able to get our baseline model built with
    but a few lines of code across a minimal set of support apps and libraries.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you enjoyed the process.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[LangChain + Streamlit + Llama: Bringing Conversational AI to Your…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Running a Small Language Model on a Local CPU](https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GPT4All is the Local ChatGPT for your Documents and it is Free!](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Simple Guide to Running LlaMA 2 Locally](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Octoparse 8.5: Empowering Local Scraping and More](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
