- en: How ML Model Explainability Accelerates the AI Adoption Journey for Financial
    Services
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型解释性如何加速金融服务的 AI 采用之旅
- en: 原文：[https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)
- en: Financial services firms are increasingly employing artificial intelligence
    to better not just their operational operations, but also business-related tasks,
    including assigning credit scores, identifying fraud, optimizing investment portfolios,
    and supporting innovations. AI improves the speed, precision, and efficacy of
    human efforts in these operations, and it can automate data management chores
    that are currently done manually. However, as AI advances, new challenges arise.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 金融服务公司越来越多地使用人工智能来改进其运营操作，以及业务相关任务，包括分配信用评分、识别欺诈、优化投资组合和支持创新。AI 提高了这些操作中人类工作的速度、精确度和效率，并且可以自动化目前由人工完成的数据管理任务。然而，随着
    AI 的进步，新挑战也随之而来。
- en: 'The real issue is transparency: when individuals don''t comprehend or only
    a few people understand the reasoning behind AI models, AI algorithms may inadvertently
    bake in bias or fail.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 真实的问题是透明度：当人们不理解或只有少数人理解 AI 模型背后的推理时，AI 算法可能会无意中引入偏见或失败。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Analytics leaders today often witness hesitation from the leadership while deploying
    black box AI-powered solutions. This has accelerated the need for explainability
    in ML models across industries. In fact, according to Gartner, by 2025, 30% of
    government and large enterprise contracts for the purchase of AI products and
    services will require the use of explainable and ethical AI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现今，分析领导者常常目睹领导层在部署黑箱 AI 驱动解决方案时的犹豫。这加快了对行业中机器学习模型解释性的需求。事实上，根据 Gartner 的数据，到
    2025 年，30% 的政府和大型企业 AI 产品及服务采购合同将要求使用可解释和道德的 AI。
- en: While AI in financial services is currently limited to tasks such as process
    automation and marketing, it might get complex and evolve in the future, making
    the black box model approach risky. Black box AI provides no explainability and
    transparency, leaving the stakeholders with questions as to why a model failed
    or how it arrived at a particular decision. To deal with this, banking and financial
    institutions are exploring explainability in AI models across various applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管当前金融服务中的 AI 仅限于流程自动化和营销等任务，但未来它可能会变得复杂并不断发展，使得黑箱模型方法具有风险。黑箱 AI 无法提供解释性和透明度，使得利益相关者对模型失败的原因或如何做出特定决策感到困惑。为应对这一挑战，银行和金融机构正在探索各种应用中的
    AI 模型解释性。
- en: What is Explainable AI?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是可解释的 AI？
- en: Explainable AI models allow stakeholders to comprehend the main drivers of model-driven
    decisions and interpret the decisions made by AI and ML models. In fact, the European
    GDPR regulation states that the existence of automated decision-making should
    carry meaningful information about the logic involved. Explainable models must
    be able to explain their rationale, characterize their strengths and weaknesses,
    and convey an understanding of how they will behave in the future, overcoming
    the challenges of black box AI which cannot explain why and how a model reached
    a specific decision point.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释的人工智能模型允许利益相关者理解模型驱动决策的主要驱动因素，并解释人工智能和机器学习模型做出的决策。事实上，欧洲GDPR规定，自动化决策的存在应提供关于涉及逻辑的有意义信息。可解释的模型必须能够解释其理由，描述其优缺点，并传达对未来行为的理解，从而克服无法解释为何以及如何达到特定决策点的黑箱人工智能的挑战。
- en: Explainable AI overcomes trust issues and the possibility of bias creeping in
    due to prejudice of designers, faulty training data, or no proper business context.
    It makes ML algorithms transparent, robust and accountable. It does so by assigning
    reason codes to decisions and making them visible to users. Stakeholders can review
    these codes to both explain decisions and verify outcomes. Good explainable AI
    must be highly scalable, easy to understand, highly personalized, and comply with
    regulatory and privacy requirements as per the use case and country.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释的人工智能克服了信任问题和由于设计者偏见、错误的训练数据或缺乏适当的业务背景而可能出现的偏见。它使机器学习算法变得透明、稳健和负责任。通过为决策分配理由代码并使其对用户可见，解决这些问题。利益相关者可以审查这些代码，以解释决策并验证结果。好的可解释人工智能必须具有高度的可扩展性、易于理解、高度个性化，并根据用例和国家遵守监管和隐私要求。
- en: '![How ML Model Explainability Accelerates the AI Adoption Journey for Financial
    Services](../Images/98c15215fe214b760f4c881ea8e1a6ca.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![如何让机器学习模型的可解释性加速金融服务领域的人工智能应用](../Images/98c15215fe214b760f4c881ea8e1a6ca.png)'
- en: 'Fig: Working of a Blackbox AI vs Explainable AI models'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图：黑箱人工智能与可解释人工智能模型的工作原理
- en: Why is Explainable AI Crucial in Financial Institutions?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么可解释的人工智能对金融机构至关重要？
- en: Financial institutions follow strict regulatory policies, and any incorrect
    decision can cost millions of dollars and damage consumer confidence. It is, therefore,
    imperative for financial companies to subject AI models to rigorous, dynamic model
    risk management and validation. The bank must ensure that the proposed AI solution
    can provide the required transparency depending on the use case.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 金融机构遵循严格的监管政策，任何不正确的决定都可能花费数百万美元并损害消费者信任。因此，金融公司必须对人工智能模型进行严格、动态的模型风险管理和验证。银行必须确保所提出的人工智能解决方案可以根据用例提供所需的透明度。
- en: Having a solid and practical explainable governance framework could help financial
    organizations to understand their obligations regarding AI explainability and
    how to operationalize them. Below we discuss a few use cases where AI in financial
    services is extensively used and why explainable models are crucial in each scenario.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个扎实且实际的可解释治理框架可以帮助金融机构理解其关于人工智能可解释性的义务以及如何将其付诸实践。下面我们讨论了几个金融服务领域广泛使用人工智能的应用案例，以及为什么在每种场景中可解释模型都是至关重要的。
- en: '**Consumer credit:** A popular use case of AI in banking, it is used to decide
    the lending standards. It is crucial that the banks understand why or why not
    the AI is making decisions about offering or rejecting loans to customers. AI
    explainability ensures that decision is fair and not biased based on gender or
    race.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**消费者信用：** 在银行业中，人工智能的一个常见应用是决定贷款标准。银行必须理解人工智能为何做出贷款批准或拒绝的决定。人工智能的可解释性确保决策是公平的，不会因性别或种族而产生偏见。'
- en: '**Anti-money laundering (AML):** AML extensively uses AI and demands explainability
    to understand the model output if it suggests anomalous behavior or suspicious
    activity in a transaction.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**反洗钱（AML）：** 反洗钱广泛使用人工智能，并要求其可解释性，以理解模型输出是否建议交易中的异常行为或可疑活动。'
- en: '**Customer onboarding:** Financial institutions lose millions of dollars due
    to insufficient customer onboarding processes, and AI ensures that the process
    is smooth with minimal loss. Explainable AI provides a system for eligibility
    checks and risk management while maintaining transparency.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**客户入驻：** 金融机构因客户入驻流程不足而损失数百万美元，而人工智能确保流程顺畅，损失最小。可解释的人工智能提供了一个进行资格检查和风险管理的系统，同时保持透明度。'
- en: '**Risk Management:** Using the historical structured and unstructured data,
    AI helps the banks and financial institutions track fraud and signs of potential
    risks in advance. Model explainability must suggest why they identified an activity
    as risky to be able to manage it and maintain a better customer experience.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**风险管理：** 使用历史结构化和非结构化数据，AI 帮助银行和金融机构跟踪欺诈和潜在风险的迹象。模型的可解释性必须说明为何将某项活动识别为风险，以便能够管理风险并保持更好的客户体验。'
- en: '**Forecasting:** AI forecasting models help in monitoring and forecasting incoming
    financial transaction parameters in real-time. Explainability ensures the accuracy
    and dynamic nature of automated predictions.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测：** AI 预测模型帮助实时监控和预测金融交易参数。可解释性确保了自动预测的准确性和动态特性。'
- en: How to Ensure Explainability in AI Models?
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何确保 AI 模型的可解释性？
- en: The more robust the AI technology, the more challenging it is to explain its
    reasoning because of the complex neural network architecture designed to execute
    AI. It also demands different stakeholders to have different levels of explanation.
    They must be able to provide a reason for each decision. For instance, in the
    case of loan approval AI systems, if the system denies a loan application, it
    should be able to explain why it denied the application while also suggesting
    if the outcome is correct or not. The model should be able to answer the following
    questions to understand if the model is working correctly or not.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能技术越强大，其推理过程的解释就越具挑战性，因为它涉及复杂的神经网络架构来执行 AI。此外，不同的利益相关者需要不同层次的解释。他们必须能够为每个决策提供理由。例如，在贷款审批的
    AI 系统中，如果系统拒绝了一份贷款申请，它应该能够解释为何拒绝申请，并且建议结果是否正确。模型应该能够回答以下问题，以了解模型是否正常工作。
- en: What algorithm is it using?
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用了什么算法？
- en: How does the model work?
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是如何工作的？
- en: Which data is it considering to determine output?
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型在确定输出时考虑了哪些数据？
- en: Which variables contributed to the model decision?
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些变量对模型决策产生了影响？
- en: Does the model decision hold true against regulatory guidance?
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的决策是否符合监管指导？
- en: Is there even a slight possibility that the model might be discriminatory against
    certain groups/gender/ethnicity?
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型是否有可能对某些群体/性别/种族产生歧视？
- en: While explainable AI models are an ideal scenario, it might become increasingly
    challenging to create them as models grow in complexity and precision. There are
    also concerns about competitors reverse-engineering the proprietary machine learning
    models and algorithms. There may also be a risk of launching adversarial attacks
    leading to malfunction. To overcome these challenges many financial institutions
    are starting to leverage state-of-the-art algorithms while maintaining explainability.
    A deep understanding of data and processes can help data scientists build custom
    architectures and ensure explainability in AI models by
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可解释的 AI 模型是理想的情形，但随着模型复杂性和精确度的增加，创建这些模型可能变得越来越具有挑战性。此外，还存在竞争对手逆向工程专有机器学习模型和算法的担忧。还有可能面临敌对攻击导致故障的风险。为了克服这些挑战，许多金融机构开始利用最先进的算法，同时保持可解释性。对数据和过程的深入理解可以帮助数据科学家构建定制架构，并通过以下方式确保
    AI 模型的可解释性
- en: Choosing the algorithms carefully keeping explainability in mind
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在选择算法时，要仔细考虑可解释性
- en: Controlling the span of the model without compromising accuracy
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在不影响准确性的情况下控制模型的跨度
- en: Building economic and regulatory assumptions in model training
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型训练中构建经济和监管假设
- en: Building MLOps pipelines
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建 MLOps 管道
- en: Ensuring strong model monitoring frameworks
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保强大的模型监控框架
- en: '![How ML Model Explainability Accelerates the AI Adoption Journey for Financial
    Services](../Images/69c02723d4510f2d06cf2e220faca039.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![如何通过可解释的机器学习模型加速金融服务的 AI 采用之旅](../Images/69c02723d4510f2d06cf2e220faca039.png)'
- en: 'Fig: Points to keep in mind to ensure explainability in AI models'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图：确保 AI 模型可解释性需要注意的要点
- en: Conclusion
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Explainability and good model governance reduce risk and create the framework
    for ethical and transparent AI in financial services that eliminates bias. As
    AI use cases grow, it will be of paramount importance to create transparent and
    explainable AI models to explain critical decisions. Integrating AI and ML model
    explainability into the processes will pave the way for the future.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 解释性和良好的模型治理可以降低风险，并为金融服务中的道德和透明 AI 创建框架，消除偏见。随着 AI 用例的增长，创建透明且可解释的 AI 模型以解释关键决策将变得至关重要。将
    AI 和机器学习模型的解释性整合到流程中，将为未来铺平道路。
- en: Financial institutions can choose AI partners with extensive experience to ensure
    explanation and transparency in AI models while meeting global compliance requirements
    at scale. The partner should be able to develop ethical safeguards for designing,
    developing, deploying, and operating AI systems. A transparent ML framework will
    bring accountability to models and reliance on complex AI solutions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 金融机构可以选择具有丰富经验的 AI 合作伙伴，以确保 AI 模型的解释性和透明度，同时满足全球合规要求。合作伙伴应能够为 AI 系统的设计、开发、部署和运营制定道德保护措施。一个透明的机器学习框架将为模型带来问责制，并增强对复杂
    AI 解决方案的依赖。
- en: '**[Yuktesh Kashyap](https://www.linkedin.com/in/yuktesh-kashyap-77336286/?originalSubdomain=in)**
    AVP of Data Science at Sigmoid. He has almost a decade of experience in implementing
    machine learning-based decisions and monitoring solutions in financial services
    domains.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Yuktesh Kashyap](https://www.linkedin.com/in/yuktesh-kashyap-77336286/?originalSubdomain=in)**，Sigmoid
    数据科学副总裁。他在金融服务领域实施基于机器学习的决策和监控解决方案方面有近十年的经验。'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[A Comprehensive Survey on Trustworthy Graph Neural Networks:…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于可信图神经网络的综合调查：…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
- en: '[Cloud Storage Adoption is the Need of the Hour for Business](https://www.kdnuggets.com/2022/02/cloud-storage-adoption-need-hour-business.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[云存储采纳是企业的迫切需求](https://www.kdnuggets.com/2022/02/cloud-storage-adoption-need-hour-business.html)'
- en: '[How Has the Adoption of AI in Algorithmic Trading Affected the…](https://www.kdnuggets.com/2022/04/adoption-ai-algorithmic-trading-affected-finance-industry.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 在算法交易中的采纳对金融行业的影响](https://www.kdnuggets.com/2022/04/adoption-ai-algorithmic-trading-affected-finance-industry.html)'
- en: '[The Promise of Edge AI and Approaches for Effective Adoption](https://www.kdnuggets.com/the-promise-of-edge-ai-and-approaches-for-effective-adoption)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[边缘 AI 的前景及其有效采纳的方法](https://www.kdnuggets.com/the-promise-of-edge-ai-and-approaches-for-effective-adoption)'
- en: '[Map out your journey towards SAS Certification](https://www.kdnuggets.com/2022/11/sas-map-journey-towards-sas-certification.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[规划通向 SAS 认证的旅程](https://www.kdnuggets.com/2022/11/sas-map-journey-towards-sas-certification.html)'
- en: '[Make Quantum Leaps in Your Data Science Journey](https://www.kdnuggets.com/2023/02/make-quantum-leaps-data-science-journey.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在数据科学旅程中实现质的飞跃](https://www.kdnuggets.com/2023/02/make-quantum-leaps-data-science-journey.html)'
