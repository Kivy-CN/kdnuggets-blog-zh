- en: 5 Reasons Why You Should Use Cross-Validation in Your Data Science Projects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么你应该在数据科学项目中使用交叉验证的5个理由
- en: 原文：[https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html](https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html](https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Dima Shulga](https://www.linkedin.com/in/shudima/), Data Scientist at
    HiredScore**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Dima Shulga](https://www.linkedin.com/in/shudima/)，HiredScore 数据科学家**'
- en: '![Image](../Images/4976e41f789dca5a0f59be94e53ac73c.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/4976e41f789dca5a0f59be94e53ac73c.png)'
- en: Cross-Validation is an essential tool in the Data Scientist toolbox. It allows
    us to utilize our data better. Before I present you my five reasons to use cross-validation,
    I want to briefly go over what cross-validation is and show some common strategies.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是数据科学家工具箱中的一个重要工具。它使我们能够更好地利用我们的数据。在我给你介绍使用交叉验证的五个理由之前，我想简单讲解一下交叉验证是什么，并展示一些常见的策略。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: When we’re building a machine learning model using some data, we often split
    our data into training and validation/test sets. The training set is used to train
    the model, and the validation/test set is used to validate it on data it has never
    seen before. The classic approach is to do a simple 80%-20% split, sometimes with
    different values like 70%-30% or 90%-10%. In cross-validation, we do more than
    one split. We can do 3, 5, 10 or any K number of splits. Those splits called Folds,
    and there are many strategies we can create these folds with.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用数据构建机器学习模型时，我们通常会将数据拆分为训练集和验证/测试集。训练集用于训练模型，而验证/测试集用于验证模型在从未见过的数据上的表现。经典的方法是进行简单的80%-20%拆分，有时也会用70%-30%或90%-10%。在交叉验证中，我们会进行多次拆分。我们可以进行3次、5次、10次或任何K次拆分。这些拆分称为折叠（Folds），我们可以使用多种策略来创建这些折叠。
- en: '![](../Images/ccdb7f20adbd1b949b3adc9d14249f58.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccdb7f20adbd1b949b3adc9d14249f58.png)'
- en: Diagram of k-fold cross-validation with k=4.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: k折交叉验证的图示，k=4。
- en: '**Simple K-Folds** — We split our data into K parts, let’s use K=3 for a toy
    example. If we have 3000 instances in our dataset, We split it into three parts,
    part 1, part 2 and part 3\. We then build three different models, each model is
    trained on two parts and tested on the third. Our first model is trained on part
    1 and 2 and tested on part 3\. Our second model is trained to on part 1 and part
    3 and tested on part 2 and so on.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单K折交叉验证** — 我们将数据拆分为K个部分，以K=3作为玩具示例。如果我们有3000个实例的数据集，我们将其拆分为三个部分，部分1、部分2和部分3。然后我们构建三个不同的模型，每个模型在两个部分上训练，并在第三个部分上测试。我们的第一个模型在部分1和2上训练，并在部分3上测试。我们的第二个模型在部分1和3上训练，并在部分2上测试，以此类推。'
- en: '**Leave One Out** — This is the most extreme way to do cross-validation. For
    each instance in our dataset, we build a model using all other instances and then
    test it on the selected instance.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**留一法** — 这是最极端的交叉验证方式。对于数据集中的每个实例，我们使用所有其他实例构建一个模型，然后在选定的实例上进行测试。'
- en: '**Stratified Cross Validation** — When we split our data into folds, we want
    to make sure that each fold is a good representative of the whole data. The most
    basic example is that we want the same proportion of different classes in each
    fold. Most of the times it happens by just doing it randomly, but sometimes, in
    complex datasets, we have to enforce a correct distribution for each fold.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**分层交叉验证** — 当我们将数据拆分为折叠时，我们希望确保每个折叠都能很好地代表整个数据。最基本的例子是，我们希望每个折叠中的不同类别的比例相同。大多数时候，通过随机拆分就能实现，但有时在复杂的数据集中，我们必须强制每个折叠中有正确的分布。'
- en: 'Here are my five reasons why you should use Cross-Validation:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我建议你使用交叉验证的五个理由：
- en: '****1\. Use All Your Data****'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****1\. 使用你所有的数据****'
- en: '![](../Images/994975e2fa3dc155e143adf59ec7bb68.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/994975e2fa3dc155e143adf59ec7bb68.png)'
- en: When we have very little data, splitting it into training and test set might
    leave us with a very small test set. Say we have only 100 examples, if we do a
    simple 80–20 split, we’ll get 20 examples in our test set. It is not enough. We
    can get almost any performance on this set only due to chance. The problem is
    even worse when we have a multi-class problem. If we have 10 classes and only
    20 examples, It leaves us with only 2 examples for each class on average. Testing
    anything on only 2 examples can’t lead to any real conclusion.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有的数据非常少时，将其分割为训练集和测试集可能会导致测试集非常小。例如，如果我们只有 100 个样本，简单的 80-20 划分会得到 20 个测试样本。这是不够的。我们几乎只能因为运气而在这个集合上获得任何性能。当我们遇到多类问题时，情况更糟。如果我们有
    10 个类别，只有 20 个样本，那么平均每个类别只有 2 个样本。仅在 2 个样本上测试是无法得出任何实际结论的。
- en: 'If we use cross-validation in this case, we build K different models, so we
    are able to make predictions on **all **of our data. For each instance, we make
    a prediction by a model that didn’t see this example, and so we are getting 100
    examples in our test set. For the multi-class problem, we get 10 examples for
    each class on average, and it’s much better than just 2\. After we evaluated our
    learning algorithm (see #2 below) we are now can train our model on all our data
    because if our 5 models had similar performance using different train sets, we
    assume that by training it on all the data will get similar performance.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '如果在这种情况下使用交叉验证，我们会构建 K 个不同的模型，从而能够对**所有**数据进行预测。对于每个实例，我们通过一个没有见过这个示例的模型来做出预测，因此我们在测试集上获得了
    100 个样本。对于多类问题，我们平均每个类别得到 10 个样本，这比仅有的 2 个样本要好得多。在评估我们的学习算法之后（见下文第 #2 点），我们现在可以在所有数据上训练模型，因为如果我们的
    5 个模型在使用不同训练集时具有相似的性能，我们假设在所有数据上训练会得到类似的性能。'
- en: By doing cross-validation, we’re able to use all our 100 examples both for training
    and for testing while evaluating our learning algorithm on examples it has never
    seen before.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进行交叉验证，我们能够将所有 100 个样本同时用于训练和测试，同时在从未见过的样本上评估我们的学习算法。
- en: '****2\. Get More Metrics****'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****2\. 获取更多的指标****'
- en: '![](../Images/de73243befaa07c4d2dc12c86ef034c4.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de73243befaa07c4d2dc12c86ef034c4.png)'
- en: 'As mentioned in #1, when we create five different models using our learning
    algorithm and test it on five different test sets, we can be more confident in
    our algorithm performance. When we do a single evaluation on our test set, we
    get only one result. This result may be because of chance or a biased test set
    for some reason. By training five (or ten) different models we can understand
    better what’s going on. Say we trained five models and we use accuracy as our
    measurement. We could end up in several different situations. The best scenario
    is that our accuracy is similar in all our folds, say 92.0, 91.5, 92.0, 92.5 and
    91.8\. This means that our algorithm (and our data) is consistent and we can be
    confident that by training it on all the data set and deploy it in production
    will lead to similar performance.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '如第 #1 点所述，当我们使用学习算法创建五个不同的模型并在五个不同的测试集上进行测试时，我们可以对算法的性能更有信心。当我们在测试集上进行单次评估时，我们只会得到一个结果。这个结果可能是由于运气或某种原因造成的偏差测试集。通过训练五个（或十个）不同的模型，我们可以更好地了解情况。例如，我们训练了五个模型，并以准确率作为衡量标准。我们可能会遇到几种不同的情况。最佳情况是我们的准确率在所有折叠中都相似，比如
    92.0、91.5、92.0、92.5 和 91.8。这意味着我们的算法（和数据）是一致的，我们可以确信在所有数据集上训练并部署到生产中将会得到类似的性能。'
- en: However, we could end up in a slightly different scenario, say 92.0, **44.0**,
    91.5, 92.5 and 91.8\. These results look very strange. It looks like one of our
    folds is from a different distribution, we have to go back and make sure that
    our data is what we think it is.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们可能会遇到稍微不同的情况，比如 92.0、**44.0**、91.5、92.5 和 91.8。这些结果看起来很奇怪。看起来我们的一个折叠来自不同的分布，我们必须回去确认我们的数据是否如我们所想。
- en: The worst scenario we can end up in is when we have considerable variation in
    our results, say 80, 44, 99, 60 and 87\. Here it looks like that our algorithm
    or our data (or both) is no consistent, it could be that our algorithm is unable
    to learn, or our data is very complicated.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能面临的最糟糕的情况是结果有很大的差异，比如 80、44、99、60 和 87。这里看起来我们的算法或数据（或两者）都不一致，可能是我们的算法无法学习，或者数据非常复杂。
- en: By using Cross-Validation, we are able to get more metrics and draw important
    conclusion both about our algorithm and our data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用交叉验证，我们能够获得更多的指标，并对我们的算法和数据得出重要结论。
- en: '****3\. Use Models Stacking****'
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****3\. 使用模型堆叠****'
- en: '![](../Images/8eb32c29f7ba3197e5d825ae0bec11b5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8eb32c29f7ba3197e5d825ae0bec11b5.png)'
- en: Sometimes we want to (or have to) build a pipeline of models to solve something.
    Think about Neural Networks for example. We can create many layers. Each layer
    may use previews layer output and learn a new representation of our data so eventually,
    it will be able to produce good predictions. We are able to train those different
    layers because we use the back-propagation algorithm. Each layer computes its
    error and passes it back to the previous layer.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们希望（或必须）构建一个模型管道来解决问题。例如，考虑神经网络。我们可以创建多个层。每一层可以使用前一层的输出，并学习数据的新表示，因此最终能够产生良好的预测。我们能够训练这些不同的层，因为我们使用了反向传播算法。每一层计算其误差并将其传递给前一层。
- en: When we do something similar but not using Neural Networks, we can’t train it
    in the same way because there’s not always a clear “error” (or derivative) that
    we can pass back.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们做类似的事情但不使用神经网络时，我们不能以相同的方式进行训练，因为并不总是有一个明确的“误差”（或导数）可以传递回去。
- en: For example, we may create a Random Forest Model that predicts something for
    us, and right after that, we want to do a Linear Regression that will rely on
    previous predictions and produce some real number.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可能创建一个随机森林模型来为我们做预测，然后我们希望进行线性回归，依赖于之前的预测并产生一些实际的数字。
- en: The critical part here is that our second model must learn on the **predictions**of
    our first model**. **The best solution here is to use two different datasets for
    each model. We train our Random Forest on dataset A. Then we use dataset B to
    make a prediction using it. Then we use the dataset B predictions to train our
    second model (the logistic regression) and finally, we use dataset C to evaluate
    our complete solution. We make predictions using the first model, pass them to
    our second model and then compare it to the ground truth.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键部分是我们的第二个模型必须学习**第一个模型**的**预测**。最好的解决方案是为每个模型使用两个不同的数据集。我们在数据集A上训练随机森林。然后我们使用数据集B来进行预测。接着我们使用数据集B的预测来训练我们的第二个模型（逻辑回归），最后我们使用数据集C来评估我们的完整解决方案。我们使用第一个模型进行预测，将其传递给我们的第二个模型，然后与真实值进行比较。
- en: When we have limited data (as in most cases), we can’t really do it. Also, we
    can’t train both our models on the same dataset because then, our second model
    learns on predictions that our first model already seen. These will probably be
    over-fitted or at least have better results than on a different set. This means
    that our second algorithm is trained not on what it will be tested on. This may
    lead to different effects in our final evaluations that will be hard to understand.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有有限的数据（在大多数情况下），我们实际上无法做到这一点。此外，我们不能在相同的数据集上训练两个模型，因为这样，第二个模型会在第一个模型已经看到的预测上进行学习。这些预测可能会过拟合，或者至少在不同的数据集上效果更好。这意味着我们的第二个算法并不是在其将被测试的内容上进行训练的。这可能会在最终评估中导致不同的效果，这将很难理解。
- en: By using cross-validation, we can make predictions on our dataset in the same
    way as described before and so our second’s models input will be real predictions
    on data that our first model never seen before.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用交叉验证，我们可以以之前描述的相同方式对数据集进行预测，从而使第二个模型的输入将是真实的预测，而这些数据是第一个模型之前从未见过的。
- en: '****4\. Work with Dependent/Grouped Data****'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****4\. 处理依赖/分组数据****'
- en: '![](../Images/f0e6430b16700ab9e95e29df5417f7b7.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0e6430b16700ab9e95e29df5417f7b7.png)'
- en: When we perform a random train-test split of our data, we assume that our examples
    are independent. That means that by knowing/seeing some instance will not help
    us understand other instances. However, that’s not always the case.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对数据进行随机训练-测试拆分时，我们假设我们的样本是独立的。这意味着知道/看到某个实例不会帮助我们理解其他实例。然而，这并不总是如此。
- en: Consider a speech recognition system. Our data may include different speakers
    saying different words. Let’s look at spoken digits recognition. In [this dataset](https://github.com/Jakobovski/free-spoken-digit-dataset),
    for example, there are 3 speakers and 1500 recordings (500 for each speaker).
    If we do a random split, our training and test set will share the same speaker
    saying the same words! This is, of course, will boost our algorithm performance
    but once tested on a new speaker, our results will be much worse.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以语音识别系统为例。我们的数据可能包括不同的发言者说不同的词。以[这个数据集](https://github.com/Jakobovski/free-spoken-digit-dataset)为例，其中有3个发言者和1500个录音（每个发言者500个）。如果我们进行随机拆分，我们的训练集和测试集将会包含相同发言者说的相同词！这当然会提升我们的算法性能，但一旦在新发言者上测试，我们的结果将会大幅下滑。
- en: The proper way to do it is to split the speakers, i.e., use 2 speakers for training
    and use the third for testing. However, then we’ll test our algorithm only on
    one speaker. It is not enough. We need to know how our algorithm performs on different
    speakers.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的方法是将发言者分开，即使用2个发言者进行训练，使用第三个发言者进行测试。然而，这样我们只能在一个发言者上测试我们的算法，这还不够。我们需要了解我们的算法在不同发言者上的表现。
- en: We can use cross-validation on the speakers level. We will train 3 models, each
    time using one speaker for testing and two others for training. This way we’ll
    be able to evaluate better our algorithm (as described above) and finally build
    our model on all speakers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在发言者层面上使用交叉验证。我们将训练3个模型，每次使用一个发言者进行测试，其他两个进行训练。这样我们可以更好地评估我们的算法（如上所述），最终在所有发言者上构建我们的模型。
- en: '****5\. Parameters Fine-Tuning****'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****5\. 参数微调****'
- en: '![](../Images/735866753376dc9ee7c3c391fbf49994.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/735866753376dc9ee7c3c391fbf49994.png)'
- en: This is one of the most common and obvious reasons to do cross validation. Most
    of the learning algorithms require some parameters tuning. It could be the number
    of trees in Gradient Boosting classifier, hidden layer size or activation functions
    in a Neural Network, type of kernel in an SVM and many more. We want to find the
    best parameters for our problem. We do it by trying different values and choosing
    the best ones. There are many methods to do this. It could be a manual search,
    a grid search or some more sophisticated optimization. However, in all those cases
    we can’t do it on our training test and not on our test set of course. We have
    to use a third set, a validation set.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是进行交叉验证最常见和明显的原因之一。大多数学习算法需要进行一些参数调整。这可能是梯度提升分类器中的树木数量，神经网络中的隐藏层大小或激活函数，支持向量机中的核类型等等。我们希望找到适合我们问题的最佳参数。我们通过尝试不同的值并选择最佳值来实现。方法有很多，可以是手动搜索、网格搜索或更复杂的优化。然而，在所有这些情况下，我们不能仅在训练测试集上进行，也不能在测试集上进行。我们必须使用第三组数据，即验证集。
- en: By splitting our data into three sets instead of two, we’ll tackle all the same
    issues we talked about before, especially if we don’t have a lot of data. By doing
    cross-validation, we’re able to do all those steps using a single set.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的数据拆分成三组而不是两组，我们将处理之前讨论过的所有相同问题，尤其是在数据量不多的情况下。通过交叉验证，我们能够使用单一数据集完成所有这些步骤。
- en: '****Conclusion****'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****结论****'
- en: Cross-Validation is a very powerful tool. It helps us better use our data, and
    it gives us much more information about our algorithm performance. In complex
    machine learning models, it’s sometimes easy not pay enough attention and use
    the same data in different steps of the pipeline. This may lead to good but not
    real performance in most cases, or, introduce strange side effects in others.
    We have to pay attention that we’re confident in our models. Cross-Validation
    helps us when we’re dealing with non-trivial challenges in our Data Science projects.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是一个非常强大的工具。它帮助我们更好地利用数据，并提供有关算法性能的更多信息。在复杂的机器学习模型中，有时很容易没有足够注意，并在管道的不同步骤中使用相同的数据。这可能导致大多数情况下的良好但不真实的性能，或者在其他情况下引入奇怪的副作用。我们必须确保对我们的模型充满信心。交叉验证帮助我们应对数据科学项目中的非平凡挑战。
- en: If you want to read more about different pitfalls that may occur in the Data
    Science pipeline, you’re welcome to read my post about [How to Lie With Data Science](https://towardsdatascience.com/how-to-lie-with-data-science-5090f3891d9c)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于数据科学管道中可能出现的不同陷阱，欢迎阅读我关于[如何在数据科学中撒谎](https://towardsdatascience.com/how-to-lie-with-data-science-5090f3891d9c)的文章。
- en: If you want to read some other 5 reasons to do something, you’re welcome to
    read my post [5 Reasons “Logistic Regression” should be the first thing you learn
    when becoming a Data Scientist](https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想阅读一些其他的做事理由，欢迎阅读我的文章 [5 个理由为什么“逻辑回归”应该是你成为数据科学家时首先学习的内容](https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4)
- en: '**Bio: [Dima Shulga](https://www.linkedin.com/in/shudima/)** is a Data Scientist
    at HiredScore.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[迪玛·舒尔加](https://www.linkedin.com/in/shudima/)** 是 HiredScore 的数据科学家。'
- en: '[Original](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79).
    Reposted with permission.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79)。经授权转载。'
- en: '**Related:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Building Reliable Machine Learning Models with Cross-validation](/2018/08/building-reliable-machine-learning-models-cross-validation.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过交叉验证构建可靠的机器学习模型](/2018/08/building-reliable-machine-learning-models-cross-validation.html)'
- en: '[5 Reasons Logistic Regression should be the first thing you learn when becoming
    a Data Scientist](/2018/05/5-reasons-logistic-regression-first-data-scientist.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个理由为什么逻辑回归应该是你成为数据科学家时首先学习的内容](/2018/05/5-reasons-logistic-regression-first-data-scientist.html)'
- en: '[How to Lie with Data Science](/2018/07/how-lie-data-science.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在数据科学中撒谎](/2018/07/how-lie-data-science.html)'
- en: More On This Topic
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你为何应该使用线性回归模型而不是…的 3 个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[3 Reasons Why Data Scientists Should Use LightGBM](https://www.kdnuggets.com/2022/01/data-scientists-reasons-lightgbm.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家为何应该使用 LightGBM 的 3 个理由](https://www.kdnuggets.com/2022/01/data-scientists-reasons-lightgbm.html)'
- en: '[Top 5 Reasons Why You Should Avoid a Data Science Career](https://www.kdnuggets.com/2022/04/top-5-reasons-avoid-data-science-career.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该避免数据科学职业的 5 个理由](https://www.kdnuggets.com/2022/04/top-5-reasons-avoid-data-science-career.html)'
- en: '[5 Reasons Why You Should Get Certified](https://www.kdnuggets.com/2023/05/sas-5-reasons-get-certified.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该获得认证的 5 个理由](https://www.kdnuggets.com/2023/05/sas-5-reasons-get-certified.html)'
- en: '[4 Reasons Why You Shouldn’t Use Machine Learning](https://www.kdnuggets.com/2021/12/4-reasons-shouldnt-machine-learning.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你不应该使用机器学习的 4 个理由](https://www.kdnuggets.com/2021/12/4-reasons-shouldnt-machine-learning.html)'
- en: '[7 Reasons Why You''re Struggling to Land a Data Science Job](https://www.kdnuggets.com/7-reasons-why-youre-struggling-to-land-a-data-science-job)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你为何难以找到数据科学工作的 7 个理由](https://www.kdnuggets.com/7-reasons-why-youre-struggling-to-land-a-data-science-job)'
