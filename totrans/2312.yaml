- en: 'Explainable AI: 10 Python Libraries for Demystifying Your Model’s Decisions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释人工智能：10个 Python 库解密您的模型决策
- en: 原文：[https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)
- en: '![Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](../Images/8eb96b67e4f791d4df13c6b2556316e6.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![可解释人工智能：10个 Python 库解密您的模型决策](../Images/8eb96b67e4f791d4df13c6b2556316e6.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: XAI is artificial intelligence that allows humans to understand the results
    and decision-making processes of the model or system.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: XAI 是一种人工智能，允许人类理解模型或系统的结果和决策过程。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The 3 Stages of Explanation
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释的3个阶段
- en: Pre-modeling Explainability
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型前解释性
- en: Explainable AI starts with explainable data and clear, interpretable feature
    engineering.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释人工智能从可解释的数据和清晰、可解释的特征工程开始。
- en: Modeling Explainability
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型解释性
- en: When choosing a model for a particular problem, it is generally best to use
    the most interpretable model that still achieves good predictive results.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择适用于特定问题的模型时，通常最好使用最具可解释性的模型，同时仍能实现良好的预测结果。
- en: Post-model Explainability
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型后解释性
- en: This includes techniques such as perturbation, where the effect of changing
    a single variable on the model's output is analyzed such as SHAP values for after
    training.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括像扰动这样的技术，即分析单个变量对模型输出的影响，如训练后的 SHAP 值。
- en: Python Libraries for AI Explainability
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能解释性的 Python 库
- en: 'I found these 10 Python libraries for AI explainability:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我找到这10个用于人工智能解释性的 Python 库：
- en: SHAP (SHapley Additive exPlanations)
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SHAP (SHapley Additive exPlanations)
- en: SHAP is a model agnostic and works by breaking down the contribution of each
    feature and attributing a score to each feature.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 是一种模型无关的方法，通过分解每个特征的贡献并为每个特征分配分数来工作。
- en: LIME (Local Interpretable Model-agnostic Explanations)
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LIME (Local Interpretable Model-agnostic Explanations)
- en: LIME is another model agnostic method that works by approximating the behavior
    of the model locally around a specific prediction.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: LIME 是另一种模型无关的方法，通过局部近似模型的行为来工作，围绕特定的预测。
- en: ELi5
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ELi5
- en: Eli5 is a library for debugging and explaining classifiers. It provides feature
    importance scores, as well as "reason codes" for scikit-learn, Keras, xgboost,
    LightGBM, CatBoost.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Eli5 是一个用于调试和解释分类器的库。它提供特征重要性分数，以及 scikit-learn、Keras、xgboost、LightGBM、CatBoost
    的“原因代码”。
- en: Shapash
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Shapash
- en: Shapash is a Python library which aims to make machine learning interpretable
    and understandable to everyone. Shapash provides several types of visualization
    with explicit labels.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Shapash 是一个 Python 库，旨在使机器学习对所有人都可解释和易于理解。 Shapash 提供几种类型的可视化，具有明确的标签。
- en: Anchors
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Anchors
- en: Anchors is a method for generating human-interpretable rules that can be used
    to explain the predictions of a machine learning model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Anchors 是一种生成可供人类理解的规则的方法，可以用来解释机器学习模型的预测。
- en: XAI (eXplainable AI)
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XAI (eXplainable AI)
- en: XAI is a library for explaining and visualizing the predictions of machine learning
    models including feature importance scores.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: XAI 是一个用于解释和可视化机器学习模型预测的库，包括特征重要性分数。
- en: BreakDown
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BreakDown
- en: BreakDown is a tool that can be used to explain the predictions of linear models.
    It works by decomposing the model's output into the contribution of each input
    feature.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: BreakDown 是一个可以用来解释线性模型预测的工具。它通过将模型输出分解为每个输入特征的贡献来工作。
- en: interpret-text
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: interpret-text
- en: interpret-text is a library for explaining the predictions of natural language
    processing models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: interpret-text 是一个用于解释自然语言处理模型预测的库。
- en: iml (Interpretable Machine Learning)
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: iml（可解释的机器学习）
- en: iml currently contains the interface and IO code from the Shap project, and
    it will potentially also do the same for the Lime project.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: iml 目前包含 Shap 项目的接口和 IO 代码，并且可能也会为 Lime 项目提供相同的功能。
- en: aix360 (AI Explainability 360)
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: aix360（AI Explainability 360）
- en: aix360 includes a comprehensive set of algorithms that cover different dimensions
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: aix360 包含一套全面的算法，涵盖不同的维度
- en: OmniXAI
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OmniXAI
- en: OmniXAI (short for Omni eXplainable AI), addresses several problems with interpreting
    judgments produced by machine learning models in practice.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: OmniXAI（全称为 Omni eXplainable AI）解决了实践中解释机器学习模型所产生判断的若干问题。
- en: Have I forgotten any libraries?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我是否遗漏了任何库？
- en: '**Sources**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源**'
- en: '[Top Explainable AI (XAI) Python Frameworks in 2022](https://lnkd.in/dzvgSe24)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022 年顶级可解释 AI（XAI）Python 框架](https://lnkd.in/dzvgSe24)'
- en: '**[Maryam Miradi](https://www.linkedin.com/in/maryammiradi/)** is an AI and
    Data Science Lead with a PhD in Machine Learning and Deep learning, specialised
    in NLP and Computer Vision. She has 15+ years of experience creating successful
    AI solutions with a track record of delivering over 40 successful projects. She
    has worked for 12 different organisations in a variety of industries, including
    Detecting Financial Crime, Energy, Banking, Retail, E-commerce, and Government.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**[玛丽亚姆·米拉迪](https://www.linkedin.com/in/maryammiradi/)** 是一位人工智能和数据科学专家，拥有机器学习和深度学习的博士学位，专注于自然语言处理和计算机视觉。她拥有
    15 年以上的经验，成功开发了超过 40 个项目。她曾为 12 家不同的组织工作，涉及金融犯罪检测、能源、银行、零售、电子商务和政府等多个行业。'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Driving Better Business Decisions](https://www.kdnuggets.com/2022/04/informs-driving-better-business-decisions.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更好的商业决策](https://www.kdnuggets.com/2022/04/informs-driving-better-business-decisions.html)'
- en: '[Reinforcement Learning: Teaching Computers to Make Optimal Decisions](https://www.kdnuggets.com/2023/07/reinforcement-learning-teaching-computers-make-optimal-decisions.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[强化学习：教计算机做出最佳决策](https://www.kdnuggets.com/2023/07/reinforcement-learning-teaching-computers-make-optimal-decisions.html)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最先进的深度学习技术在可解释的预测和现在预测中的应用](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Demystifying Bad Science](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开坏科学的面纱](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
- en: '[Demystifying Machine Learning](https://www.kdnuggets.com/demystifying-machine-learning)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开机器学习的面纱](https://www.kdnuggets.com/demystifying-machine-learning)'
- en: '[Demystifying Decision Trees for the Real World](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开决策树在现实世界中的面纱](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)'
