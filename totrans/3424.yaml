- en: The Gentlest Introduction to Tensorflow – Part 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html/2](https://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Training Variation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Stochastic, Mini-batch, Batch**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the training above, we feed a single datapoint at each epoch. This is known
    as *stochastic* gradient descent. We can feed a bunch of datapoints at each epoch,
    which is known as *mini-batch* gradient descent, or even feed all the datapoints
    at each epoch, known as *batch* gradient descent. See the graphical comparison
    below and note the 2 differences between the 3 diagrams:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of datapoints (upper-right of each diagram) fed to TF.Graph at each
    epoch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of datapoints for the gradient descent optimizer to consider when
    tweaking W, b to reduce cost (bottom-right of each diagram)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Image](../Images/b79b5679f1ceeb28278aaab148182ea2.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Stochastic gradient descent*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/33557bec9cb92d4fdb6e45778da7e05d.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Mini-batch gradient descent*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/427edda0188c06a578eea475cdd2f31c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Batch gradient descent*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of datapoints used at each epoch has 2 implications. With more datapoints:'
  prefs: []
  type: TYPE_NORMAL
- en: Computational resource (subtractions, squares, and additions) needed to calculate
    the cost and perform gradient descent increases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speed at which the model can learn and generalize increases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pros and cons of doing stochastic, mini-batch, batch gradient descent can
    be summarized in the diagram below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/4dd4d20bd311d1735880a43acfa54df3.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Pros and cons of stochastic, mini-batch & batch gradient descent*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To switch between stochastic/mini-batch/batch gradient descent, we just need
    to prepare the datapoints into different batch sizes before feeding them into
    the training step [D], i.e., use the snippet below for[C]:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Learn Rate Variation**'
  prefs: []
  type: TYPE_NORMAL
- en: Learn rate is how big an increment/decrement we want gradient descent to tweak
    W, b, once it decides whether to increment/decrement them. With a small learn
    rate, we will proceed slowly but surely towards minimal cost, but with a larger
    learn rate, we can reach the minimal cost faster, but at the risk of ‘overshooting’,
    and never finding it.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this, many ML practitioners use a large learn rate initially (with
    the assumption that initial cost is far away from minimum), and then decrease
    the learn rate gradually after each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: TF provides 2 ways to do so as wonderfully explained in this StackOverflow [thread](http://stackoverflow.com/questions/33919948/how-to-set-adaptive-learning-rate-for-gradientdescentoptimizer),
    but here is the summary.
  prefs: []
  type: TYPE_NORMAL
- en: Use Gradient Descent Optimizer Variants
  prefs: []
  type: TYPE_NORMAL
- en: TF comes with various gradient descent optimizer, which supports learn rate
    variation, such as [tf.train.AdagradientOptimizer](http://www.tensorflow.org/api_docs/python/train.html#AdagradOptimizer),
    and[tf.train.AdamOptimizer](http://www.tensorflow.org/api_docs/python/train.html#AdamOptimizer).
  prefs: []
  type: TYPE_NORMAL
- en: Use *tf.placeholder* for Learn Rate
  prefs: []
  type: TYPE_NORMAL
- en: As you have learned previously, if we declare a *tf.placeholder*, in this case
    for learn rate, and use it within the *tf.train.GradientDescentOptimizer*, we
    can feed a different value to it at each training epoch, much like how we feed
    different datapoints to x, y_, which are also *tf.placeholders*, at each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need 2 slight modifications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Wrapping Up
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We illustrated what machine learning ‘training’ is, and how to perform it using
    Tensorflow with just model & cost definitions, and looping through the training
    step, which feeds datapoints into the gradient descent optimizer. We also discussed
    the common variations in training, namely changing the size of datapoints the
    model uses for learning at each epoch, and varying the learn rate of gradient
    descent optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: '**Coming Up Next**'
  prefs: []
  type: TYPE_NORMAL
- en: Set up Tensor Board to visualize TF execution to detect problems in our model,
    cost function, or gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform linear regression with multiple features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources**'
  prefs: []
  type: TYPE_NORMAL
- en: The code on [Github](https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The slides on [SlideShare](http://www.slideshare.net/KhorSoonHin/gentlest-intro-to-tensorflow-part-2-62006222)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The video on [YouTube](https://www.youtube.com/watch?v=Trc52FvMLEg)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bio: [Soon Hin Khor](https://twitter.com/neth_6)**, Ph.D is using tech to
    make the world more caring, and responsible. Contributor of ruby-tensorflow. Co-organizer
    for Tokyo Tensorflow meetup.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/@khor/gentlest-introduction-to-tensorflow-part-2-ed2a0a7a624f).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[The Good, Bad & Ugly of TensorFlow](/2016/05/good-bad-ugly-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Multi-Task Learning in Tensorflow: Part 1](/2016/07/multi-task-learning-tensorflow-part-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Understanding Deep Learning](/2016/01/seven-steps-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The "Hello World" of Tensorflow](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free TensorFlow 2.0 Complete Course](https://www.kdnuggets.com/2023/02/free-tensorflow-20-complete-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
