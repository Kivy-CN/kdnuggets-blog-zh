- en: Writing Your First Neural Net in Less Than 30 Lines of Code with Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/10/writing-first-neural-net-less-30-lines-code-keras.html](https://www.kdnuggets.com/2019/10/writing-first-neural-net-less-30-lines-code-keras.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [David Gündisch](https://www.linkedin.com/in/david-gundisch/), Cloud Architect**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/4c65340c70db0e311f666addd510dbfb.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://unsplash.com/@tvick](https://unsplash.com/@tvick)'
  prefs: []
  type: TYPE_NORMAL
- en: Reminiscing back to when I first started my journey into AI, I remember all
    too well how daunting some of the concepts seemed. Reading a simple explanation
    on what a Neural Network is can quickly lead to a scientific paper where every
    second sentence is a formula with symbols you’ve never even seen before. While
    these papers hold incredible insights and depth to help you build up your expertise,
    getting started with writing your first Neural Net is a lot easier than it sounds!
  prefs: []
  type: TYPE_NORMAL
- en: OK… but what even is a Neural Network???
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Good Question! Before we jump into writing our own Python implementation of
    a simple Neural Network or NN for short, we should probably unpack what they are,
    and why they are so exciting!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d103aaba7b4d5462965e523aef9e2e3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Dr. Robert Hecht-Nielsen, co-founder of HNC Software, puts it simply.
  prefs: []
  type: TYPE_NORMAL
- en: '*…a computing system made up of a number of simple, highly interconnected processing
    elements, which process information by their dynamic state response to external
    inputs. — *“Neural Network Primer: Part I” by Maureen Caudill, AI Expert, Feb.
    1989'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In essence, a Neural Network is a set of mathematical expressions that are really
    good at recognizing patterns in information, or data. A NN accomplishes this through
    a kind of human emulated perception, but instead of seeing, say an image, like
    a human would, the NN expresses this information numerically contained within
    a Vector or Scalar (a Vector only containing one number).
  prefs: []
  type: TYPE_NORMAL
- en: It passes this information through layers where the output of one layer, acts
    as the input into the next. While traveling through these layers the input is
    modified by weight and bias and sent to the activation function to map the output.
    The learning then occurs via a Cost function, that compares the actual output
    and the desired output, which in turn helps the function alters and adjusts the
    weights and biases to minimize the cost via a process called backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: I would highly encourage you to watch the below video for an in-depth and visual
    explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 3Blue1Brown’s video on Neural Networks
  prefs: []
  type: TYPE_NORMAL
- en: For our example NN implementation we are going to be using the MNIST data set.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e205dfefcfece63acf61fd6eb80ddc4a.png)'
  prefs: []
  type: TYPE_IMG
- en: MNIST Sample Dataset
  prefs: []
  type: TYPE_NORMAL
- en: MNIST can be seen as the ‘Hello World’ dataset because it is able to demonstrate
    the capabilities of NNs quite succinctly. The dataset is made up of handwritten
    digits, which we will train our NN to recognize and classify.
  prefs: []
  type: TYPE_NORMAL
- en: Enter the drago… I mean Keras
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To facilitate our implementation we are going to be using the Keras framework.
    Keras is a high-level API written in Python which runs on-top of popular frameworks
    such as TensorFlow, Theano, etc. to provide the machine learning practitioner
    with a layer of abstraction to reduce the inherent complexity of writing NNs.
  prefs: []
  type: TYPE_NORMAL
- en: I would encourage you to delve into the Keras [documentation](https://keras.io/) to
    really become familiar with the API. Additionally, I would highly recommend the
    book *Deep Learning with Python* by Francois Chollet, which inspired this tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: Time to burn some GPUs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this tutorial, we will be using Keras with the TensorFlow backend, so if
    you haven’t installed either of these, now is a good time to do so. You can accomplish
    this simply by running these commands in your terminal. When you move beyond simple
    introductory examples it is best to set up your [Anaconda ](https://docs.anaconda.com/anaconda/)environment
    and install the below with conda instead.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now that you’ve installed everything standing between you and your first NN,
    go ahead and open your favorite IDE and let’s dive into importing our required
    Python modules!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Keras has a number of datasets you can use to help you learn and luckily for
    us MNIST is one of them! Models and Layers are both modules which will help us
    build out our NN and to_categorical is used for our data encoding… but more on
    that later!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our required modules imported we will want to split our dataset
    into train and test sets. This can be accomplished simply with the following line.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this example, our NN learns by comparing its output against labeled data.
    You can think of this as us making the NN guess a large number of handwritten
    digits, and then comparing the guesses against the actual label. The result of
    this will then feed into how the model adjusts its weights and biases in order
    to minimize the overall cost.
  prefs: []
  type: TYPE_NORMAL
- en: With our training and test data set-up, we are now ready to build our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: I know… I know… it might seem like a lot, but let’s break it down together!
    We initialize a sequential model called network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: And we add our NN layers. For this example, we will be using dense layers. A
    dense layer simply means that each neuron receives input from all the neurons
    in the previous layer. [784] and [10] refer to the dimensionality of the output
    space, we can think of this as the number of inputs for the subsequent layers,
    and since we are trying to solve a classification problem with 10 possible categories
    (numbers 0 to 9) the final layer has a potential output of 10 units. The activation
    parameter refers to the activation function we want to use, in essence, an activation
    function calculates an output based on a given input. And finally, the input shape
    of [28 * 28] refers to the image’s pixel width and height.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once our model is defined, and we have added our NN layers, we simply compile
    the model with our optimizer of choice, our loss function of choice, and the metrics
    we want to use to judge our model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations!!! You’ve just built your first Neural Network!!
  prefs: []
  type: TYPE_NORMAL
- en: Now you still might have some questions, such as; What are relu and softmax?
    and Who the hell is adam? And those are all valid questions… An in-depth explanation
    of these falls slightly out of scope for our initial journey into NN but we will
    cover these in later posts.
  prefs: []
  type: TYPE_NORMAL
- en: Before we can feed our data into our newly created model we will need to reshape
    our input into a format that the model can read. The original shape of our input
    was [60000, 28, 28] which essentially represents 60000 images with a pixel height
    and width of 28 x 28\. We can reshape our data and split it between train [60000]
    images and test [10000] images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In addition to reshaping our data, we will also need to encode it. For this
    example, we will use categorical encoding, which in essence turns a number of
    features in numerical representations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: With our dataset split into a training and test set, with our model compiled
    and with our data reshaped and encoded, we are now ready to train our NN! To do
    this we will call the *fit *function and pass in our required parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We pass in our training images and their labels as well as epochs, which dictate
    the number of backward and forward propagations, and the batch_size, which indicates
    the number of training samples per backward/forward propagation.
  prefs: []
  type: TYPE_NORMAL
- en: We will also want to set our performance measuring parameters so we can identify
    how well our model is working.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: And voila!!! You have just written your own Neural Network, reshaped and encoded
    a dataset and fit your model to train! When you run the Python script for the
    first time Keras will download the MNIST dataset and begin training for 5 epochs!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/887944752d7aef7096225a9f70ea6bb1.png)'
  prefs: []
  type: TYPE_IMG
- en: Training cycle with Test output
  prefs: []
  type: TYPE_NORMAL
- en: You should get an accuracy of around 98 percent for your test accuracy, which
    means that the model has predicted the correct digit 98 percent of the time while
    running its tests, not bad for your first NN! In practice, you’ll want to look
    at both the testing and training results to get a good idea if your model is overfitted/underfitted.
  prefs: []
  type: TYPE_NORMAL
- en: I’d encourage you to play around with the number of layers, the optimizer and
    loss function, as well as the epoch and batch_size to see what the impact of each
    would be to your model’s overall performance!
  prefs: []
  type: TYPE_NORMAL
- en: You’ve just taken the difficult first step in your long and exciting learning
    journey! Feel free to reach out for any additional clarification or feedback!
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading — and stay curious! ????
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: David Gündisch** is a Cloud Architect. He is passionate about researching
    the applications of Artificial Intelligence within the fields of Philosophy, Psychology
    and Cyber Security.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/writing-your-first-neural-net-in-less-than-30-lines-of-code-with-keras-18e160a35502).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction to Artificial Neural Networks](/2019/10/introduction-artificial-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Gentle Introduction to PyTorch 1.2](/2019/09/gentle-introduction-pytorch-12.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow vs PyTorch vs Keras for NLP](/2019/09/tensorflow-pytorch-keras-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Multi-modal deep learning in less than 15 lines of code](https://www.kdnuggets.com/2023/01/predibase-multi-modal-deep-learning-less-15-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Algorithms Explained in Less Than 1 Minute Each](https://www.kdnuggets.com/2022/07/machine-learning-algorithms-explained-less-1-minute.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Become a Business Intelligence Analyst in Less Than 6 Months](https://www.kdnuggets.com/become-a-business-intelligence-analyst-in-less-than-6-months)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mastering Python: 7 Strategies for Writing Clear, Organized, and…](https://www.kdnuggets.com/mastering-python-7-strategies-for-writing-clear-organized-and-efficient-code)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
