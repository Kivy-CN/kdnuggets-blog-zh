# 使用K-最近邻算法进行心脏病分类

> 原文：[https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html](https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html?page=2#comments)

对象分类是许多领域中重要的研究和应用领域。在了解基本概率的情况下，贝叶斯决策理论提供了最优的错误率。在没有这些信息的情况下，许多算法利用样本之间的距离或相似性来进行分类。

本文分为两部分。第一部分将讨论K-NN机器学习算法，第二部分我们将实现K-NN于实际生活中并对心脏病患者进行分类。

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速通道进入网络安全职业

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的IT组织

* * *

**内容表**

1.  K-NN算法是什么？

1.  K-NN算法是如何工作的？

1.  什么时候选择K-NN？

1.  如何选择K的最佳值？

1.  维度诅咒是什么？

1.  使用python sci-kit learn构建K-NN分类器。

1.  如何提高分类器的性能？

### K-NN算法是什么？

![](../Images/fe225aa90f1f3ec39506d32db01afc17.png)

[K-NN算法表示](https://acadgild.com/blog/k-nearest-neighbor-algorithm)

K-NN或K-最近邻算法是目前业界最著名的分类算法之一，原因在于它的简单性和准确性。

K-NN是一个简单的算法，它存储所有可用的案例，并基于相似性度量（例如，距离函数）对新案例进行分类。KNN早在1970年代初就作为一种非参数技术被用于统计估计和模式识别。

该算法假设相似的事物存在于近邻中。换句话说，相似的实体是聚集在一起的。

### K-NN算法是如何工作的？

在K-NN中，K是最近邻的数量。邻居的数量是核心决定因素。**当类别数量为2时，K通常是奇数**。当K=1时，该算法被称为最近邻算法。这是最简单的情况。

在下图中，假设黄色“**?**”表示点 P，它是需要预测标签的点。首先，找到离 P 最近的一个点，然后将最近点的标签分配给 P。

![](../Images/861a2f7b786e09051bbd0d37b8db1857.png)

首先，你找到与 P 最近的 k 个点，然后通过其 K 个邻居的多数投票对点进行分类。每个对象对其类别进行投票，得到最多投票的类别作为预测结果。为了寻找最相似的点，我们使用欧几里得距离、汉明距离、曼哈顿距离和明可夫斯基距离等距离度量方法来计算点之间的距离。该算法的基本步骤如下：

1.  计算距离

1.  寻找最近的邻居

1.  标签投票

![](../Images/be2fc1f9343745ff2ec1e5a9747b2f7a.png)

用于计算点 P 与其最近邻之间距离的三种最常用的距离度量表示为：

![](../Images/82d48a4486aae9019ed734c5115b1878.png)

在本文中，我们将使用欧几里得距离，因此让我们先了解它。

**欧几里得距离：** 这是最常用的距离度量，也称为简单距离。建议在数据密集或连续时使用欧几里得距离度量。欧几里得距离是最佳的接近度量。两点之间的欧几里得距离是连接它们的路径的长度。毕达哥拉斯定理给出了两点之间的距离。

下图展示了如何计算二维平面中两点之间的欧几里得距离。

![图示](../Images/181a263e28b55514150e7ae38d495336.png)

[2维空间中两点之间的欧几里得距离](https://mccormickml.com/2013/08/15/the-gaussian-kernel/)

### 何时使用 K-NN 算法？

KNN 可以用于分类和回归预测问题。然而，在行业中，它在分类问题中的应用更为广泛。为了评估任何技术，我们通常关注 3 个重要方面：

1.  输出的易解释性

1.  算法的计算时间

1.  预测能力

让我们将 KNN 与不同模型进行比较：

![图示](../Images/d52f21040e5ef16e8e24e34609aa2528.png)

来源：Analytics Vidhya

如你所见，K-NN 在我们考虑的方面上超越了逻辑回归、CART 和随机森林。

### 如何选择 K 的最佳值？

K-NN 中的邻居数量 (K) 是一个超参数，你需要在构建模型时选择。你可以将 K 视为预测模型的控制变量。

现在，选择 K 的最佳值最好通过先检查数据来完成。一般而言，较大的 K 值更为准确，因为它减少了整体噪音，但并没有保证。交叉验证是另一种方法，通过使用独立的数据集来验证 K 值，从而回顾性地确定一个好的 K 值。历史上，大多数数据集的最佳 K 值在 3 到 10 之间。这比 1NN（当 K=1 时）产生了更好的结果。

通常，如果类别数量是偶数，则选择奇数。你也可以通过在不同的 K 值上生成模型并检查它们的性能来进行验证。

### 维度灾难

K-NN 在特征数量较少时表现更好，而不是特征数量较多时。你可以说，当特征数量增加时，需要更多的数据。维度增加也会导致过拟合问题。为了避免过拟合，当你增加维度数量时，需要的数据将呈指数增长。这个高维度问题被称为维度灾难。

![](../Images/40e1bba71a6b963a2370165dc5a23d79.png)

从上述图形表示中，可以清楚地看到，随着特征（维度）数量的增加，你的模型性能会下降。

为了解决维度灾难问题，你需要在应用任何机器学习算法之前进行主成分分析（PCA），或者你也可以使用特征选择方法。研究表明，在高维度下，欧几里得距离不再有用。因此，你可以选择其他度量方法，如余弦相似度，这些方法对高维度的影响较小。

> **KNN 算法可以与最准确的模型竞争，因为它能做出高度准确的预测。因此，你可以在需要高准确度但不需要可读模型的应用中使用 KNN 算法。 — **来源：[IBM](https://www.ibm.com/support/knowledgecenter/en/SS6NHC/com.ibm.swg.im.dashdb.analytics.doc/doc/r_knn_usage.html)

计算 K-NN 算法的步骤：

1.  确定参数 K = 最近邻居的数量。

1.  计算查询实例与所有训练样本之间的距离。

1.  对距离进行排序，并根据第 K 个最小距离确定最近邻居。

1.  收集最近邻居的类别

1.  使用最近邻居类别的简单多数作为查询的预测值。

在下一部分，我们将使用 K-NN 算法解决一个实际场景。

### 更多相关话题

+   [从理论到实践：构建 k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [分类的最近邻居](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn 中的 K 最近邻](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [使用 BERT 对长文本进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)

+   [使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)

+   [如何使用 Python 确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)
