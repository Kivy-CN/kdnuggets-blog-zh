- en: Artificial Intelligence, Deep Learning, and Neural Networks, Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能、深度学习和神经网络的解释
- en: 原文：[https://www.kdnuggets.com/2016/10/artificial-intelligence-deep-learning-neural-networks-explained.html](https://www.kdnuggets.com/2016/10/artificial-intelligence-deep-learning-neural-networks-explained.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/10/artificial-intelligence-deep-learning-neural-networks-explained.html](https://www.kdnuggets.com/2016/10/artificial-intelligence-deep-learning-neural-networks-explained.html)
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: '*Artificial intelligence (AI)*, *deep learning*, and *neural networks* represent
    incredibly exciting and powerful machine learning-based techniques used to solve
    many real-world problems. For a primer on machine learning, you may want to read
    this five-part [series](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/) that
    I wrote.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能 (AI)*、*深度学习* 和 *神经网络* 代表了极其令人兴奋和强大的基于机器学习的技术，用于解决许多现实世界的问题。关于机器学习的入门，你可能想阅读我写的这五部分的
    [系列](http://www.innoarchitech.com/machine-learning-an-in-depth-non-technical-guide/)。'
- en: While human-like deductive reasoning, inference, and decision-making by a computer
    is still a long time away, there have been remarkable gains in the application
    of AI techniques and associated algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管计算机进行类人推理、推断和决策还有很长的路要走，但在 AI 技术及相关算法的应用方面已经取得了显著的进展。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织在 IT 领域'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The concepts discussed here are extremely technical, complex, and based on mathematics,
    statistics, probability theory, physics, signal processing, machine learning,
    computer science, psychology, linguistics, and neuroscience.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的概念极其技术性、复杂，并且基于数学、统计学、概率论、物理学、信号处理、机器学习、计算机科学、心理学、语言学和神经科学。
- en: '![InnoArchiTech post image](../Images/93a1ca286541e8415a9614f2ec80ddac.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![InnoArchiTech 帖子图片](../Images/93a1ca286541e8415a9614f2ec80ddac.png)'
- en: That said, this article is not meant to provide such a technical treatment,
    but rather to explain these concepts at a level that can be understood by most
    non-practitioners, and can also serve as a reference or review for technical folks
    as well.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，本文并非旨在提供如此技术性的处理，而是以大多数非专业人士能够理解的水平来解释这些概念，同时也可以作为技术人员的参考或复习。
- en: The primary motivation and driving force for these areas of study, and for developing
    these techniques further, is that the solutions required to solve certain problems
    are incredibly complicated, not well understood, nor easy to determine manually.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些研究领域的主要动机和推动力是，解决某些问题所需的解决方案极其复杂、难以理解，也不容易手动确定。
- en: Increasingly, we rely on these techniques and machine learning to solve these
    problems for us, without requiring explicit programming instructions. This is
    critical for two reasons. The first is that we likely wouldn’t be able, or at
    least know how to write the programs required to model and solve many problems
    that AI techniques are able to solve. Second, even if we did know how to write
    the programs, they would be inordinately complex and nearly impossible to get
    right.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们越来越依赖这些技术和机器学习来为我们解决这些问题，而无需明确的编程指令。这一点至关重要，原因有二。首先，我们可能无法，或至少不知道如何编写所需的程序来建模和解决许多
    AI 技术能够解决的问题。其次，即便我们知道如何编写这些程序，它们也会非常复杂，几乎不可能正确实现。
- en: Luckily for us, machine learning and AI algorithms, along with properly selected
    and prepared training data, are able to do this for us.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，机器学习和 AI 算法，以及适当选择和准备的训练数据，能够为我们完成这些任务。
- en: So with that, let’s get started!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧！
- en: Artificial Intelligence Overview
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能概述
- en: 'In order to define AI, we must first define the concept of *intelligence* in
    general. A paraphrased definition based on Wikipedia is:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义人工智能，我们必须首先定义一般意义上的*智能*。根据维基百科的释义，智能是：
- en: Intelligence can be generally described as the ability to perceive information,
    and retain it as knowledge to be applied towards adaptive behaviors within an
    environment or context.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 智能通常可以描述为感知信息的能力，并将其作为知识保留，用于在某个环境或背景中实现适应性行为。
- en: While there are many different definitions of intelligence, they all essentially
    involve learning, understanding, and the application of the knowledge learned
    to achieve one or more goals.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然对智能的定义有很多不同的说法，但它们本质上都涉及学习、理解以及将所学知识应用于实现一个或多个目标。
- en: It’s therefore a natural extension to say that AI can be described as intelligence
    exhibited by machines. So what does that mean exactly, when is it useful, and
    how does it work?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以自然地认为人工智能可以被描述为机器所表现出的智能。那么，这到底是什么意思？它何时有用？它是如何工作的？
- en: A familiar instance of an AI solution includes *IBM’s Watson*, which was made
    famous by beating the two greatest *Jeopardy* champions in history, and is now
    being used as a *question answering computing system* for commercial applications. *Apple’s
    Siri* and*Amazon’s Alexa* are similar examples as well.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个熟悉的人工智能解决方案是*IBM的沃森*，它因战胜了历史上两位最伟大的*危险边缘*冠军而闻名，现在被用作*问答计算系统*用于商业应用。*苹果的Siri*和*亚马逊的Alexa*也是类似的例子。
- en: In addition to speech recognition and natural language (processing, generation,
    and understanding) applications, AI is also used for other recognition tasks (pattern,
    text, audio, image, video, facial, …), autonomous vehicles, medical diagnoses,
    gaming, search engines, spam filtering, crime fighting, marketing, robotics, remote
    sensing, computer vision, transportation, music recognition, classification, and
    so on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了语音识别和自然语言（处理、生成和理解）应用外，人工智能还用于其他识别任务（模式、文本、音频、图像、视频、面部等）、自动驾驶车辆、医学诊断、游戏、搜索引擎、垃圾邮件过滤、打击犯罪、营销、机器人技术、遥感、计算机视觉、交通、音乐识别、分类等。
- en: Something worth mentioning is a concept known as the *AI effect*. This describes
    the case where once an AI application has become somewhat mainstream, it’s no
    longer considered by many as AI. It happens because people’s tendency is to no
    longer think of the solution as involving real intelligence, and only being a
    application of normal computing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是一个叫做*人工智能效应*的概念。这个效应描述了当一个人工智能应用变得有些主流时，它不再被许多人认为是人工智能。发生这种情况是因为人们倾向于不再认为该解决方案涉及真正的智能，只是正常计算的应用。
- en: This despite the fact that these applications still fit the definition of AI
    regardless of widespread usage. The key takeaway here is that today’s AI is not
    necessarily tomorrow’s AI, at least not in some people’s minds anyway.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些应用仍然符合人工智能的定义，尽管它们被广泛使用。这里的关键是，今天的人工智能不一定是明天的人工智能，至少在一些人的观念中如此。
- en: There are many different goals of AI as mentioned, with different techniques
    used for each. The primary topics of this article are artificial neural networks
    and an advanced version known as deep learning.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，人工智能有许多不同的目标，每个目标使用不同的技术。本文的主要话题是人工神经网络及其高级版本，即深度学习。
- en: '![InnoArchiTech post image](../Images/7ac6a32a14ccbe2e182793abe4be37f7.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![InnoArchiTech 文章图片](../Images/7ac6a32a14ccbe2e182793abe4be37f7.png)'
- en: Biological Neural Networks Overview
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生物神经网络概述
- en: The human brain is exceptionally complex and quite literally the most powerful
    computing machine known.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 人脑极其复杂，确切地说是已知的最强大计算机器。
- en: The inner-workings of the human brain are often modeled around the concept of*neurons* and
    the networks of neurons known as *biological neural networks*. According to Wikipedia,
    it’s estimated that the human brain contains roughly 100 billion neurons, which
    are connected along pathways throughout these networks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 人脑的内部工作机制通常围绕*神经元*的概念以及被称为*生物神经网络*的神经元网络进行建模。根据维基百科的估计，人脑中大约有1000亿个神经元，这些神经元沿着这些网络的通路连接在一起。
- en: At a very high level, neurons interact and communicate with one another through
    an interface consisting of *axon terminals* that are connected to *dendrites* across
    a gap (*synapse*) as shown here.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从很高的层次来看，神经元通过由*轴突末端*和跨越间隙（*突触*）连接的*树突*组成的界面进行互动和通信。
- en: '![By LadyofHats [Public domain], via Wikimedia Commons | https://upload.wikimedia.org/wikipedia/commons/a/a9/Complete_neuron_cell_diagram_en.svg](../Images/75941c9da6dbb22d72c7dd0ebc1fb72c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![由LadyofHats [公有领域]提供，来自Wikimedia Commons | https://upload.wikimedia.org/wikipedia/commons/a/a9/Complete_neuron_cell_diagram_en.svg](../Images/75941c9da6dbb22d72c7dd0ebc1fb72c.png)'
- en: In plain english, a single neuron will pass a message to another neuron across
    this interface if the sum of *weighted input signals* from one or more neurons
    (*summation*) into it is great enough (exceeds a *threshold*) to cause the message
    transmission. This is called *activation* when the threshold is exceeded and the
    message is passed along to the next neuron.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 用简单的语言来说，如果一个神经元接收到来自一个或多个神经元的*加权输入信号*的总和（*求和*）足够大（超过*阈值*），它就会将消息传递给另一个神经元。当阈值被超过且消息被传递到下一个神经元时，这称为*激活*。
- en: '![By Chrislb (created by Chrislb) [GFDL (http://www.gnu.org/copyleft/fdl.html)
    or CC-BY-SA-3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia
    Commons | https://upload.wikimedia.org/wikipedia/commons/6/60/ArtificialNeuronModel_english.png](../Images/42fd960f63c56ebdf87bbe59f461b516.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![由Chrislb（Chrislb创作） [GFDL (http://www.gnu.org/copyleft/fdl.html) 或 CC-BY-SA-3.0
    (http://creativecommons.org/licenses/by-sa/3.0/)]提供，来自Wikimedia Commons | https://upload.wikimedia.org/wikipedia/commons/6/60/ArtificialNeuronModel_english.png](../Images/42fd960f63c56ebdf87bbe59f461b516.png)'
- en: The *summation* process can be mathematically complex. Each neuron’s input signal
    is actually a *weighted combination* of potentially many input signals, and the
    weighting of each input means that that input can have a different influence on
    any subsequent calculations, and ultimately on the final output of the entire
    network.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*求和*过程可以在数学上是复杂的。每个神经元的输入信号实际上是潜在多个输入信号的*加权组合*，每个输入的权重意味着该输入对任何后续计算以及最终网络的输出都会产生不同的影响。'
- en: In addition, each neuron applies a function or *transformation* to the weighted
    inputs, which means that the combined weighted input signal is transformed mathematically
    prior to evaluating if the *activation threshold* has been exceeded. This combination
    of weighted input signals and the functions applied are typically either linear
    or nonlinear.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个神经元对加权输入应用一个函数或*变换*，这意味着组合加权输入信号在评估是否超过*激活阈值*之前会在数学上进行变换。这些加权输入信号和应用的函数通常是线性或非线性的。
- en: These input signals can originate in many ways, with our senses being some of
    the most important, as well as ingestion of gases (breathing), liquids (drinking),
    and solids (eating) for example. A single neuron may receive hundreds of thousands
    of input signals at once that undergo the summation process to determine if the
    message gets passed along, and ultimately causes the brain to instruct actions,
    memory recollection, and so on.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些输入信号可以通过多种方式产生，我们的感官是其中一些最重要的来源，例如气体（呼吸）、液体（饮水）和固体（进食）的摄取。一个神经元可能一次接收数十万条输入信号，这些信号经过求和过程以确定消息是否被传递，并最终导致大脑发出行动指令、记忆回忆等。
- en: The ‘thinking’ or processing that our brain carries out, and the subsequent
    instructions given to our muscles, organs, and body are the result of these neural
    networks in action. In addition, the brain’s neural networks continuously change
    and update themselves in many ways, including modifications to the amount of weighting
    applied between neurons. This happens as a direct result of learning and experience.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的大脑进行的“思考”或处理，以及随后给肌肉、器官和身体的指令，都是这些神经网络发挥作用的结果。此外，大脑的神经网络不断以多种方式变化和更新，包括对神经元之间施加的权重的修改。这是学习和经验的直接结果。
- en: Given this, it’s a natural assumption that for a computing machine to replicate
    the brain’s functionality and capabilities, including being ‘intelligent’, it
    must successfully implement a computer-based or artificial version of this network
    of neurons.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，合理的假设是，为了让计算机机器复制大脑的功能和能力，包括“智能”，它必须成功实现这种神经网络的计算机化或人工版本。
- en: This is the genesis of the advanced statistical technique and term known as *artificial
    neural networks*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是被称为*人工神经网络*的高级统计技术和术语的起源。
- en: Artificial Neural Networks Overview
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工神经网络概述
- en: '*Artificial neural networks* (*ANNs*) are statistical models directly inspired
    by, and partially modeled on biological neural networks. They are capable of modeling
    and processing nonlinear relationships between inputs and outputs in parallel.
    The related algorithms are part of the broader field of machine learning, and
    can be used in many applications as discussed.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工神经网络*（*ANNs*）是直接受到生物神经网络启发并部分模拟的统计模型。它们能够并行地建模和处理输入与输出之间的非线性关系。相关算法是机器学习广泛领域的一部分，并可以用于许多讨论中的应用。'
- en: Artificial neural networks are characterized by containing *adaptive weights* along
    paths between neurons that can be tuned by a *learning algorithm* that *learns* from
    observed data in order to improve the model. In addition to the learning algorithm
    itself, one must choose an appropriate *cost function*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络的特点是包含在神经元之间路径上的*自适应权重*，这些权重可以通过*学习算法*进行调整，学习算法从观察到的数据中*学习*以改进模型。除了学习算法本身，还必须选择合适的*成本函数*。
- en: The cost function is what’s used to *learn* the optimal solution to the problem
    being solved. This involves determining the best values for all of the tunable
    model parameters, with neuron path adaptive weights being the primary target,
    along with algorithm tuning parameters such as the *learning rate*. It’s usually
    done through*optimization* techniques such as *gradient descent* or *stochastic
    gradient descent*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 成本函数用于*学习*解决问题的最佳方案。这涉及到确定所有可调模型参数的最佳值，其中神经元路径的自适应权重是主要目标，还有算法调优参数，如*学习率*。通常通过*优化*技术，如*梯度下降*或*随机梯度下降*来完成。
- en: These optimization techniques basically try to make the ANN solution be as close
    as possible to the optimal solution, which when successful means that the ANN
    is able to solve the intended problem with high performance.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优化技术基本上试图使人工神经网络的解决方案尽可能接近最佳解决方案，当成功时，意味着人工神经网络能够以高性能解决预期的问题。
- en: Architecturally, an artificial neural network is modeled using layers of *artificial
    neurons*, or computational units able to receive input and apply an activation
    function along with a threshold to determine if messages are passed along.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构上看，人工神经网络是使用*人工神经元*层进行建模的，这些计算单元能够接收输入并应用激活函数以及阈值来决定是否传递消息。
- en: In a simple model, the first layer is the *input* layer, followed by one *hidden* layer,
    and lastly by an *output* layer. Each layer can contain one or more neurons.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个简单的模型中，第一层是*输入*层，接下来是一个*隐藏*层，最后是*输出*层。每一层可以包含一个或多个神经元。
- en: Models can become increasingly complex, and with increased abstraction and problem
    solving capabilities by increasing the number of *hidden layers*, the number of
    neurons in any given layer, and/or the number of paths between neurons. Note that
    an increased chance of *overfitting* can also occur with increased model complexity.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以变得越来越复杂，通过增加*隐藏层*的数量、每个层中的神经元数量和/或神经元之间的路径数量，模型的抽象和问题解决能力也会增加。请注意，模型复杂度增加也可能会增加*过拟合*的风险。
- en: '![InnoArchiTech post image](../Images/681d2512d53ae39a82645d503e395470.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![InnoArchiTech 发布的图片](../Images/681d2512d53ae39a82645d503e395470.png)'
- en: Model architecture and tuning are therefore major components of ANN techniques,
    in addition to the actual learning algorithms themselves. All of these characteristics
    of an ANN can have significant impact on the performance of the model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型架构和调优是人工神经网络技术的重要组成部分，除了实际的学习算法。这些人工神经网络的所有特性都可能对模型的性能产生重大影响。
- en: Additionally, models are characterized and tunable by the *activation function* used
    to convert a neuron’s weighted input to its output activation. There are many
    different types of transformations that can be used as the activation function,
    and a discussion of them is out of scope for this article.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型的特征和调优由*激活函数*决定，激活函数用于将神经元的加权输入转换为其输出激活。可以使用许多不同类型的变换作为激活函数，对它们的讨论超出了本文的范围。
- en: The abstraction of the output as a result of the transformations of input data
    through neurons and layers is a form of *distributed representation*, as contrasted
    with*local representation*. The meaning represented by a single artificial neuron
    for example is a form of local representation. The meaning of the entire network
    however, is a form of distributed representation due to the many transformations
    across neurons and layers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将输出抽象为输入数据通过神经元和层的变换结果是一种*分布式表示*，与*局部表示*形成对比。例如，单个人工神经元表示的意义是一种局部表示。然而，整个网络的意义由于神经元和层之间的许多变换，形成了一种分布式表示。
- en: One thing worth noting is that while ANNs are extremely powerful, they can also
    be very complex and are considered *black box* algorithms, which means that their
    inner-workings are very difficult to understand and explain. Choosing whether
    to employ ANNs to solve problems should therefore be chosen with that in mind.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，虽然人工神经网络（ANNs）非常强大，但它们也可能非常复杂，并被认为是*黑箱*算法，这意味着它们的内部工作机制非常难以理解和解释。因此，在选择是否使用ANNs解决问题时，应考虑这一点。
- en: Deep Learning Introduction
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习简介
- en: '*Deep learning*, while sounding flashy, is really just a term to describe certain
    types of neural networks and related algorithms that consume often very *raw* input
    data. They process this data through many layers of nonlinear transformations
    of the input data in order to calculate a target output.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习*，虽然听起来很华丽，实际上只是一个用来描述某些类型的神经网络及相关算法的术语，这些算法通常处理非常*原始*的输入数据。它们通过许多层的非线性变换来处理这些数据，以计算目标输出。'
- en: Unsupervised *feature extraction* is also an area where deep learning excels.
    Feature extraction is when an algorithm is able to automatically derive or construct
    meaningful features of the data to be used for further learning, generalization,
    and understanding. The burden is traditionally on the data scientist or programmer
    to carry out the feature extraction process in most other machine learning approaches,
    along with feature selection and engineering.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督*特征提取*也是深度学习擅长的领域。特征提取是指算法能够自动推导或构造有意义的数据特征，用于进一步学习、概括和理解。在大多数其他机器学习方法中，传统上由数据科学家或程序员承担特征提取过程，以及特征选择和工程。
- en: Feature extraction usually involves some amount dimensionality reduction as
    well, which is reducing the amount of input features and data required to generate
    meaningful results. This has many benefits, which include simplification, computational
    and memory power reduction, and so on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取通常还涉及一定程度的维度减少，即减少生成有意义结果所需的输入特征和数据量。这有许多好处，包括简化、计算和内存功耗减少等。
- en: More generally, deep learning falls under the group of techniques known as *feature
    learning* or *representation learning*. As discussed so far, feature extraction
    is used to ‘learn’ which features to focus on and use in machine learning solutions.
    The machine learning algorithms themselves ‘learn’ the optimal parameters to create
    the best performing model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，深度学习属于*特征学习*或*表示学习*这类技术。正如前面讨论的那样，特征提取用于“学习”应关注和使用哪些特征以进行机器学习解决方案。机器学习算法本身“学习”出创建最佳表现模型的最佳参数。
- en: Paraphrasing Wikipedia, *feature learning* algorithms allow a machine to both
    learn for a specific task using a well-suited set of features, and also learn
    the features themselves. In other words, these algorithms *learn how to learn*!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据维基百科的解释，*特征学习*算法使机器能够通过使用合适的特征集来针对特定任务进行学习，同时也能学习这些特征本身。换句话说，这些算法*学会如何学习*！
- en: Deep learning has been used successfully in many applications, and is considered
    to be one of the most cutting-edge machine learning and AI techniques at the time
    of this writing. The associated algorithms are often used for *supervised*, *unsupervised*,
    and *semi-supervised* learning problems.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经在许多应用中取得了成功，并被认为是截至目前最前沿的机器学习和人工智能技术之一。相关算法通常用于*监督学习*、*无监督学习*和*半监督学习*问题。
- en: For neural network-based deep learning models, the number of layers are greater
    than in so-called *shallow learning* algorithms. Shallow algorithms tend to be
    less complex and require more up-front knowledge of optimal features to use, which
    typically involves feature selection and engineering.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于神经网络的深度学习模型，层数要比所谓的*浅层学习*算法多。浅层算法往往较少复杂，且需要更多的前期知识来选择最优特征，这通常涉及特征选择和工程。
- en: In contrast, deep learning algorithms rely more on optimal model selection and
    optimization through model tuning. They are more well suited to solve problems
    where prior knowledge of features is less desired or necessary, and where labeled
    data is unavailable or not required for the primary use case.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，深度学习算法更依赖于通过模型调整进行的最优模型选择和优化。它们更适合解决那些对特征的先验知识需求较少或不必要的问题，以及在主要用例中没有标签数据或不需要标签数据的情况。
- en: In addition to statistical techniques, neural networks and deep learning leverage
    concepts and techniques from signal processing as well, including nonlinear processing
    and/or transformations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 除了统计技术外，神经网络和深度学习还利用了信号处理中的概念和技术，包括非线性处理和/或变换。
- en: You may recall that a nonlinear function is one that is not characterized simply
    by a straight line. It therefore requires more than just a slope to model the
    relationship between the input, or independent variable, and the output, or dependent
    variable. Nonlinear functions can include polynomial, logarithmic, and exponential
    terms, as well as any other transformation that isn’t linear.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能记得，非线性函数并非仅仅由一条直线来描述。因此，它需要的不仅仅是一个斜率来建模输入或自变量与输出或因变量之间的关系。非线性函数可以包括多项式、对数和指数项，以及任何其他非线性变换。
- en: Many phenomena observed in the physical universe are actually best modeled with
    nonlinear transformations. This is true as well for transformations between inputs
    and the target output in machine learning and AI solutions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在物理宇宙中观察到的现象实际上最适合用非线性变换来建模。在机器学习和人工智能解决方案中，输入和目标输出之间的变换也同样如此。
- en: '![InnoArchiTech post image](../Images/7fc91ad8cc6140a0b8d27f274cb8bdca.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![InnoArchiTech post image](../Images/7fc91ad8cc6140a0b8d27f274cb8bdca.png)'
- en: A Deeper Dive into Deep Learning - No Pun Intended
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深入探讨深度学习 - 并非玩笑
- en: As mentioned, input data is transformed throughout the layers of a deep learning
    neural network by artificial neurons or processing units. The chain of transformations
    that occur from input to output is known as the *credit assignment path*, or *CAP*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，输入数据在深度学习神经网络的各层之间通过人工神经元或处理单元进行转换。从输入到输出的转换链称为*信用分配路径*，或*CAP*。
- en: The CAP value is a proxy for the measurement or concept of ‘depth’ in a deep
    learning model architecture. According to Wikipedia, most researchers in the field
    agree that deep learning has multiple nonlinear layers with a CAP greater than
    two, and some consider a CAP greater than ten to be *very deep learning*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: CAP值是深度学习模型架构中“深度”的测量或概念的代理。根据维基百科，大多数领域的研究者一致认为深度学习具有多个非线性层，CAP大于二，有些人认为CAP大于十为*非常深度学习*。
- en: 'While a detailed discussion of the many different deep-learning model architectures
    and learning algorithms is beyond the scope of this article, some of the more
    notable ones include:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然对许多不同的深度学习模型架构和学习算法的详细讨论超出了本文的范围，但一些较为显著的包括：
- en: Feed-forward neural networks
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前馈神经网络
- en: Recurrent neural network
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: Multi-layer perceptrons (MLP)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多层感知器（MLP）
- en: Convolutional neural networks
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Recursive neural networks
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归神经网络
- en: Deep belief networks
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度置信网络
- en: Convolutional deep belief networks
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积深度置信网络
- en: Self-Organizing Maps
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自组织映射
- en: Deep Boltzmann machines
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度玻尔兹曼机
- en: Stacked de-noising auto-encoders
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠去噪自编码器
- en: It’s worth pointing out that due to the relative increase in complexity, deep
    learning and neural network algorithms can be prone to overfitting. In addition,
    increased model and algorithmic complexity can result in very significant computational
    resource and time requirements.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，由于相对增加的复杂性，深度学习和神经网络算法可能容易过拟合。此外，增加的模型和算法复杂性可能导致非常显著的计算资源和时间需求。
- en: It’s also important to consider that solutions may represent *local minima* as
    opposed to a global optimal solution. This is due to the complex nature of these
    models when combined with optimization techniques such as gradient descent.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要考虑到解决方案可能代表*局部最小值*而不是全局最优解。这是因为这些模型在结合如梯度下降等优化技术时的复杂性。
- en: Given all of this, proper care must be taken when leveraging artificial intelligence
    algorithms to solve problems, including the selection, implementation, and performance
    assessment of algorithms themselves. While out of scope for this article, the
    field of machine learning includes many techniques that can help with these areas.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些情况，在利用人工智能算法解决问题时必须谨慎，包括算法的选择、实施和性能评估。虽然这超出了本文的范围，但机器学习领域包括许多可以帮助这些方面的技术。
- en: Summary
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: AI is an extremely powerful and exciting field. It’s only going to become more
    important and ubiquitous moving forward, and will certainly continue to have very
    significant impacts on modern society.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是一个极其强大且令人兴奋的领域。它将变得越来越重要和普遍，并且无疑将继续对现代社会产生重大影响。
- en: Artificial neural networks (ANNs) and the more complex deep learning technique
    are some of the most capable AI tools for solving very complex problems, and will
    continue to be developed and leveraged in the future.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANNs）和更复杂的深度学习技术是解决非常复杂问题的一些最强大的人工智能工具，未来将继续发展和利用。
- en: While a terminator-like scenario is unlikely any time soon, the progression
    of artificial intelligence techniques and applications will certainly be very
    exciting to watch!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管像终结者那样的场景不太可能很快发生，但人工智能技术和应用的发展肯定会让人非常兴奋！
- en: '[Alex Castrounis](https://www.whyofai.com/alex-castrounis) is the founder and
    CEO of [Why of AI](https://www.whyofai.com/) and the author of [AI for People
    and Business](https://www.whyofai.com/ai-book). He is also an adjunct for Northwestern
    University’s Kellogg / McCormick MBAi program.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[亚历克斯·卡斯特罗尼斯](https://www.whyofai.com/alex-castrounis)是[Why of AI](https://www.whyofai.com/)的创始人兼首席执行官，并且是[《AI
    for People and Business》](https://www.whyofai.com/ai-book)的作者。他还是西北大学凯洛格/麦考密克MBAi项目的兼职讲师。'
- en: This post was originally published on the [InnoArchiTech Blog](http://www.innoarchitech.com/artificial-intelligence-deep-learning-neural-networks-explained/?utm_source=kdnuggets&utm_medium=post&utm_content=postlink&utm_campaign=republish).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 本文最初发布在[InnoArchiTech 博客](http://www.innoarchitech.com/artificial-intelligence-deep-learning-neural-networks-explained/?utm_source=kdnuggets&utm_medium=post&utm_content=postlink&utm_campaign=republish)上。
- en: '**Related:**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning Key Terms, Explained](/2016/10/deep-learning-key-terms-explained.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习关键术语解析](/2016/10/deep-learning-key-terms-explained.html)'
- en: '[9 Key Deep Learning Papers, Explained](/2016/09/9-key-deep-learning-papers-explained.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9篇关键深度学习论文解析](/2016/09/9-key-deep-learning-papers-explained.html)'
- en: '[Deep Learning Reading Group: Deep Networks with Stochastic Depth](/2016/09/deep-learning-reading-group-stochastic-depth-networks.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习阅读小组：具有随机深度的深度网络](/2016/09/deep-learning-reading-group-stochastic-depth-networks.html)'
- en: More On This Topic
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并以寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的人工智能失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
