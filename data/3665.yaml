- en: 'Falcon LLM: The New King of Open-Source LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Falcon LLM: 开源 LLM 新霸主'
- en: 原文：[https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)
- en: '![Falcon LLM: The New King of Open-Source LLMs](../Images/e6655f57a0e9e55dd8af87cd304a08a2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Falcon LLM: 开源 LLM 新霸主](../Images/e6655f57a0e9e55dd8af87cd304a08a2.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑提供
- en: We’ve been seeing large language models (LLMs) spitting out every week, with
    more and more chatbots for us to use. However, it can be hard to figure out which
    is the best, the progress on each and which one is most useful.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到每周都有大量语言模型（LLMs）问世，更多的聊天机器人供我们使用。然而，确定哪个是最好的，了解每个模型的进展以及哪个最有用，可能会很困难。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
    has an Open LLM Leaderboard which tracks, evaluates and ranks LLMs as they are
    being released. They use a unique framework which is used to test generative language
    models on different evaluation tasks.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
    拥有一个开放的 LLM 排行榜，跟踪、评估和排名正在发布的 LLM。它们使用独特的框架来测试生成性语言模型在不同评估任务上的表现。'
- en: Of recent, LLaMA (Large Language Model Meta AI) was at the top of the leaderboard
    and has been recently dethroned by a new pre-trained LLM - Falcon 40B.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，LLaMA（大型语言模型 Meta AI）曾位居排行榜首位，但近期被新预训练的 LLM - Falcon 40B 取代。
- en: '![Falcon LLM: The New King of Open-Source LLMs](../Images/628ceb31ddac43c869db931454ce2c4f.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Falcon LLM: 开源 LLM 新霸主](../Images/628ceb31ddac43c869db931454ce2c4f.png)'
- en: Image by [HuggingFace Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [HuggingFace 开放 LLM 排行榜](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
    提供
- en: About Technology Innovation Institute
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于技术创新研究所
- en: '[Falcon LLM](https://falconllm.tii.ae/) was Founded and built by the [Technology
    Innovation Institute](https://www.tii.ae/) (TII), a company that is part of the
    Abu Dhabi Government’s Advanced Technology Research Council. The government oversees
    technology research in the whole of the United Arab Emirates, where the team of
    scientists, researchers and engineers focus on delivering transformative technologies
    and discoveries in science.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[Falcon LLM](https://falconllm.tii.ae/) 由 [技术创新研究所](https://www.tii.ae/)（TII）创立并开发，TII
    是阿布扎比政府高级技术研究委员会的一部分。该政府机构监管阿联酋的技术研究，科学家、研究人员和工程师的团队专注于提供变革性技术和科学发现。'
- en: What is Falcon 40B?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Falcon 40B？
- en: '[Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) is a foundational LLM
    with 40B parameters, training on one trillion tokens. Falcon 40B is an autoregressive
    decoder-only model. An autoregressive decoder-only model means that the model
    is trained to predict the next token in a sequence given the previous tokens.
    The GPT model is a good example of this.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) 是一个具有 40B 参数的基础 LLM，训练数据为一万亿个标记。Falcon
    40B 是一个自回归解码器模型。自回归解码器模型意味着该模型被训练来预测序列中给定先前标记后的下一个标记。GPT 模型是一个很好的例子。'
- en: The architecture of Falcon has been shown to significantly outperform GPT-3
    for only 75% of the training compute budget, as well as only requiring ? of the
    compute at inference time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Falcon 的架构在仅使用 75% 的训练计算预算的情况下，已显著超越 GPT-3，并且在推理时仅需要 ? 的计算量。
- en: Data quality at scale was an important focus of the team at the Technology Innovation
    Institute, as we know that LLMs are highly sensitive to the quality of training
    data. The team built a data pipeline which scaled to tens of thousands of CPU
    cores for fast processing and was able to extract high-quality content from the
    web using extensive filtering and deduplication.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量在规模化方面是技术创新研究所团队的重要关注点，因为我们知道LLM对训练数据的质量非常敏感。该团队建立了一个数据管道，扩展到数万个CPU核心以进行快速处理，并能够通过广泛的过滤和去重从网络中提取高质量内容。
- en: 'They also have another smaller version: [Falcon-7B](https://huggingface.co/tiiuae/falcon-7b)
    which has 7B parameters, trained on 1,500B tokens. Aswell as a [Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct),
    and [Falcon-7B-Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) models
    available, if you are looking for a ready-to-use chat model.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还有一个较小的版本：[Falcon-7B](https://huggingface.co/tiiuae/falcon-7b)，具有7B参数，训练于1500B个token。此外，还有一个[Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct)和[Falcon-7B-Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct)模型可供使用，如果你在寻找一个现成的聊天模型。
- en: What can Falcon 40B do?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Falcon 40B可以做什么？
- en: 'Similar to other LLMs, Falcon 40B can:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他LLM类似，Falcon 40B可以：
- en: Generate creative content
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成创意内容
- en: Solve complex problems
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决复杂问题
- en: Customer service operations
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户服务操作
- en: Virtual assistants
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟助手
- en: Language Translation
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言翻译
- en: Sentiment analysis.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析。
- en: Reduce and automate “repetitive” work.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少和自动化“重复性”工作。
- en: Help Emirati companies become more efficient
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助阿联酋公司提高效率
- en: How was Falcon 40B trained?
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Falcon 40B是如何训练的？
- en: Being trained on 1 trillion tokens, it required 384 GPUs on AWS, over two months. 
    Trained on 1,000B tokens of [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb),
    a massive English web dataset built by TII.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练了1万亿个token，它在AWS上需要384个GPU，耗时超过两个月。训练于1000B个token的[RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)，这是TII构建的大型英语网页数据集。
- en: Pretraining data consisted of a collection of public data from the web, using
    [CommonCrawl](https://commoncrawl.org/). The team went through a thorough filtering
    phase to remove machine-generated text, and adult content as well as any deduplication
    to produce a pretraining dataset of nearly five trillion tokens was assembled.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练数据包括来自网络的公共数据集，使用了[CommonCrawl](https://commoncrawl.org/)。团队经过了严格的过滤阶段，以去除机器生成的文本和成人内容，并进行了去重，从而组装了一个近五万亿token的预训练数据集。
- en: Built on top of CommonCrawl, the RefinedWeb dataset has shown models to achieve
    a better performance than models that are trained on curated datasets. RefinedWeb
    is also multimodal-friendly.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于CommonCrawl构建的RefinedWeb数据集显示，使用此数据集训练的模型比使用策划数据集训练的模型表现更好。RefinedWeb也是多模态友好的。
- en: Once it was ready, Falcon was validated against open-source benchmarks such
    as EAI Harness, HELM, and BigBench.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦准备好，Falcon就通过了如EAI Harness、HELM和BigBench等开源基准测试的验证。
- en: Falcon LLM is Open-Source
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Falcon LLM是开源的
- en: They have [open-sourced Falcon LLM](https://huggingface.co/tiiuae) to the public,
    making Falcon 40B and 7B more accessible to researchers and developers as it is
    based on the Apache License Version 2.0 release.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 他们已将[Falcon LLM开源](https://huggingface.co/tiiuae)给公众，使Falcon 40B和7B对研究人员和开发人员更加可及，因为它基于Apache
    License Version 2.0发布。
- en: The LLM which was once for research and commercial use only, has now become
    open-source to cater to the global demand for inclusive access to AI. It is now
    free of royalties for commercial use restrictions, as the UAE are committed to
    changing the challenges and boundaries within AI and how it plays a significant
    role in the future.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经仅用于研究和商业用途的LLM，现在已成为开源，以满足全球对AI包容性访问的需求。它现在在商业使用中不再受版税限制，因为阿联酋致力于改变AI中的挑战和边界，并在未来发挥重要作用。
- en: Aiming to cultivate an ecosystem of collaboration, innovation, and knowledge
    sharing in the world of AI, Apache 2.0 ensures security and safe open-source software.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在培养一个合作、创新和知识共享的AI生态系统，Apache 2.0确保了安全和安全的开源软件。
- en: How to Use Falcon-7B Instruct LLM
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Falcon-7B Instruct LLM
- en: If you want to try out a simpler version of Falcon-40B which is better suited
    for generic instructions in the style of a chatbot, you want to be using Falcon-7B.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试一个更简单的Falcon-40B版本，适合处理通用指令风格的聊天机器人，你可以使用Falcon-7B。
- en: So let’s get started…
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们开始吧…
- en: 'If you haven’t already, install the following packages:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有，请安装以下软件包：
- en: '[PRE0]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you have installed these packages, you can then move on to running the
    code provided for [Falcon 7-B Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您安装了这些包，您可以继续运行[Falcon 7-B Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct)提供的代码。
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Wrapping it up
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'Standing as the best open-source model available, Falcon has taken the LLaMAs
    crown, and people are amazed at its strongly optimized architecture, open-source
    with a unique license, and it is available in two sizes: 40B and 7B parameters.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最好的开源模型，Falcon已经接过LLaMAs的王冠，人们对其强大的优化架构、具有独特许可的开源性质以及提供40B和7B参数两种尺寸感到惊讶。
- en: Have you had a try? If you have, let us know in the comments what you think.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你尝试过了吗？如果尝试过，请在评论中告诉我们你的想法。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist,
    Freelance Technical Writer and Community Manager at KDnuggets. She is particularly
    interested in providing Data Science career advice or tutorials and theory based
    knowledge around Data Science. She also wishes to explore the different ways Artificial
    Intelligence is/can benefit the longevity of human life. A keen learner, seeking
    to broaden her tech knowledge and writing skills, whilst helping guide others.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**[尼莎·阿娅](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一位数据科学家、自由技术作家以及KDnuggets的社区经理。她特别感兴趣于提供数据科学职业建议或教程以及基于数据科学的理论知识。她还希望探索人工智能如何/可以如何有助于人类寿命的延续。作为一个热心学习者，她寻求拓宽自己的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Fasten Your Seatbelt: Falcon 180B is Here!](https://www.kdnuggets.com/fasten-your-seatbelt-falcon-180b-is-here)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[系好安全带：Falcon 180B来了！](https://www.kdnuggets.com/fasten-your-seatbelt-falcon-180b-is-here)'
- en: '[Introduction to Streaming-LLM: LLMs for Infinite-Length Inputs](https://www.kdnuggets.com/introduction-to-streaming-llm-llms-for-infinite-length-inputs)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Streaming-LLM介绍：适用于无限长度输入的LLM](https://www.kdnuggets.com/introduction-to-streaming-llm-llms-for-infinite-length-inputs)'
- en: '[Easily Integrate LLMs into Your Scikit-learn Workflow with Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[轻松将LLMs集成到您的Scikit-learn工作流程中，使用Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
- en: '[Web LLM: Bring LLM Chatbots to the Browser](https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Web LLM：将LLM聊天机器人带到浏览器](https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html)'
- en: '[Mistral 7B-V0.2: Fine-Tuning Mistral’s New Open-Source LLM with…](https://www.kdnuggets.com/mistral-7b-v02-fine-tuning-mistral-new-open-source-llm-with-hugging-face)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mistral 7B-V0.2：用…微调Mistral的新开源LLM](https://www.kdnuggets.com/mistral-7b-v02-fine-tuning-mistral-new-open-source-llm-with-hugging-face)'
- en: '[Introducing MPT-7B: A New Open-Source LLM](https://www.kdnuggets.com/2023/05/introducing-mpt7b-new-opensource-llm.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍MPT-7B：一种新的开源LLM](https://www.kdnuggets.com/2023/05/introducing-mpt7b-new-opensource-llm.html)'
