- en: 'HuggingGPT: The Secret Weapon to Solve Complex AI Tasks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'HuggingGPT: 解决复杂 AI 任务的秘密武器'
- en: 原文：[https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)
- en: '![HuggingGPT: The Secret Weapon to Solve Complex AI Tasks](../Images/c3a67fbc0536fa8043d01f54b81d98c1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![HuggingGPT: 解决复杂 AI 任务的秘密武器](../Images/c3a67fbc0536fa8043d01f54b81d98c1.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Have you heard of the term Artificial General Intelligence (AGI)? If not, let
    me clarify. AGI can be thought of as an AI system that can understand, process,
    and respond the intellectual tasks just like humans do. It's a challenging task
    that requires an in-depth understanding of how the human brain works so we can
    replicate it. However, the advent of ChatGPT has drawn immense interest from the
    research community to develop such systems. Microsoft has released one such key
    AI-powered system called HuggingGPT (Microsoft Jarvis). It is one of the most
    mind-blowing things that I have come across.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过“通用人工智能”（AGI）这个术语吗？如果没有，我来解释一下。AGI 可以被认为是一种能像人类一样理解、处理和响应智力任务的 AI 系统。这是一个具有挑战性的任务，需要深入了解人脑的运作方式，以便我们可以复制它。然而，ChatGPT
    的出现引起了研究界对开发这种系统的巨大兴趣。微软发布了一个这样的关键 AI 系统，名为 HuggingGPT（微软贾维斯）。这是我遇到的最令人惊叹的事物之一。
- en: Before I dive into the details of what is new in HuggingGPT and how it works,
    let us first understand the issue with ChatGPT and why it struggles to solve complex
    AI tasks. Large Language models like ChatGPT excel at interpreting textual data
    and handling general tasks. However,  they often struggle with specific tasks
    and may generate absurd responses. You might have encountered bogus replies from
    ChatGPT while solving complex mathematical problems. On the other side, we have
    expert AI models like Stable Diffusion, and DALL-E that have a deeper understanding
    of their subject area but struggle with the broader tasks. We cannot fully harness
    the potential of LLMs to solve challenging AI tasks unless we develop a connection
    between them and the Specialized AI models. This is what HuggingGPT did. It combined
    the strengths of both to create more efficient, accurate, and versatile AI systems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解 HuggingGPT 的新功能和工作原理之前，让我们首先了解一下 ChatGPT 存在的问题以及为什么它在解决复杂 AI 任务时会遇到困难。像
    ChatGPT 这样的大型语言模型在解释文本数据和处理一般任务方面表现出色。然而，它们在处理特定任务时经常会遇到困难，可能会产生荒谬的回应。你可能在解决复杂的数学问题时遇到过
    ChatGPT 的虚假回答。另一方面，我们有像 Stable Diffusion 和 DALL-E 这样的专家 AI 模型，它们对其领域有更深入的理解，但在处理更广泛的任务时却存在困难。我们不能充分发挥
    LLM 的潜力来解决具有挑战性的 AI 任务，除非我们在它们与专业 AI 模型之间建立连接。这就是 HuggingGPT 所做的。它结合了两者的优势，创造了更高效、更准确、更全面的
    AI 系统。
- en: What is HuggingGPT?
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 HuggingGPT？
- en: According to a [recent paper](https://arxiv.org/abs/2303.17580) published by
    Microsoft, HuggingGPT leverages the power of LLMs by using it as a controller
    to connect them to various AI models in Machine Learning communities (HuggingFace).
    Rather than training the ChatGPT for various tasks, we enable it to use external
    tools for greater efficiency. [HuggingFace](https://huggingface.co/) is a website
    that provides numerous tools and resources for developers and researchers. It
    also has a wide variety of specialized and high-accuracy models. HuggingGPT uses
    these models for sophisticated AI tasks in different domains and modalities thereby
    achieving impressive results. It has similar multimodal capabilities to OPenAI
    GPT-4 when it comes to text and images. But, it also connected you to the Internet
    and you can provide an external web link to ask questions about it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 根据微软发布的一篇[近期论文](https://arxiv.org/abs/2303.17580)，HuggingGPT 利用 LLM 的强大功能，将其作为控制器连接到机器学习社区（HuggingFace）的各种
    AI 模型上。与其对 ChatGPT 进行各种任务的训练，不如让它使用外部工具以提高效率。[HuggingFace](https://huggingface.co/)
    是一个为开发者和研究人员提供大量工具和资源的网站。它还拥有各种专业和高精度的模型。HuggingGPT 使用这些模型来处理不同领域和模式的复杂 AI 任务，从而取得了令人印象深刻的结果。在文本和图像方面，它具有类似于
    OpenAI GPT-4 的多模态能力。而且，它还可以连接到互联网，你可以提供外部网页链接以询问相关问题。
- en: Suppose you want the model to generate an audio reading of the text written
    on an image. HuggingGPT will perform this task serially using the best-suited
    models. Firstly, it will generate the image from text and use its result for audio
    generation. You can check the response details in the image below. Simply Amazing!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你希望模型生成一段关于图像上文字的音频朗读。HuggingGPT 将使用最合适的模型按顺序执行此任务。首先，它会从文本生成图像，并利用该结果进行音频生成。你可以在下面的图像中查看响应细节。简直令人惊叹！
- en: '![HuggingGPT: The Secret Weapon to Solve Complex AI Tasks](../Images/6dd819fb645e69a61220b3f7328ccd66.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![HuggingGPT: 解决复杂 AI 任务的秘密武器](../Images/6dd819fb645e69a61220b3f7328ccd66.png)'
- en: Qualitative analysis of multi-model cooperation on video and audio modalities
    ([Source](https://arxiv.org/abs/2303.17580))
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 多模型协作在视频和音频模态下的定性分析 ([来源](https://arxiv.org/abs/2303.17580))
- en: How Does HuggingGPT Work?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HuggingGPT 是如何工作的？
- en: '![HuggingGPT: The Secret Weapon to Solve Complex AI Tasks](../Images/4158bcf3dc73ee7c60466ea16263076c.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![HuggingGPT: 解决复杂 AI 任务的秘密武器](../Images/4158bcf3dc73ee7c60466ea16263076c.png)'
- en: Image by Author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'HuggingGPT is a collaborative system that uses LLMs as an interface to send
    user requests to expert models. The complete process starting from the user prompt
    to the model till receiving the response can be broken down into the following
    discrete steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingGPT 是一个协作系统，使用 LLM 作为接口将用户请求发送到专家模型。整个过程从用户提示到模型，再到接收响应，可以分解为以下几个离散的步骤：
- en: 1\. Task Planning
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 任务规划
- en: In this stage, HuggingGPT makes use of ChatGPT to understand the user prompt
    and then breaks down the query into small actionable tasks. It also determines
    the dependencies of these tasks and defines their execution sequence. HuggingGPT
    has four slots for task parsing i.e. task type, task ID, task dependencies, and
    task arguments. Chat logs between the HuggingGPT and the user are recorded and
    displayed on the screen that shows the history of the resources.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，HuggingGPT 利用 ChatGPT 理解用户提示，然后将查询分解为小的可执行任务。它还确定这些任务的依赖关系并定义其执行顺序。HuggingGPT
    有四个任务解析槽位，即任务类型、任务 ID、任务依赖关系和任务参数。HuggingGPT 和用户之间的聊天记录会被记录并显示在屏幕上，显示资源的历史记录。
- en: 2\. Model Selection
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 模型选择
- en: Based on the user context and the available models, HuggingGPT uses an in-context
    task-model assignment mechanism to select the most appropriate model for a particular
    task. According to this mechanism, the selection of a model is considered a single-choice
    problem and it initially filters out the model based on the type of the task.
    After that, the models are ranked based on the number of downloads as it is considered
    a reliable measure that reflects the quality of the model. “Top-K” models are
    selected based on this ranking. Here K is just a constant that reflects the number
    of models, for example, if it is set to 3 then it will select 3 models with the
    highest number of downloads.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用户的上下文和可用模型，HuggingGPT 使用上下文任务模型分配机制来选择最合适的模型进行特定任务。根据这一机制，模型的选择被视为一个单项选择问题，最初会根据任务类型筛选出模型。之后，模型会根据下载数量进行排序，因为下载量被认为是反映模型质量的可靠指标。根据这个排名选择“Top-K”模型。这里的
    K 只是一个常数，表示模型的数量，例如，如果设置为 3，则会选择下载量最高的 3 个模型。
- en: 3\. Task Execution
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 任务执行
- en: Here the task is assigned to a specific model, it performs the inference on
    it and returns the result. To enhance the efficiency of this process, HuggingGPT
    can run different models at the same time as long as they don’t need the same
    resources. For example, if I give a prompt to generate pictures of cats and dogs
    then separate models can run in parallel to execute this task. However, sometimes
    models may need the same resources which is why HuggingGPT maintains an **<resource>**
    attribute to keep the track of the resources. It ensures that the resources are
    being used effectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，任务被分配给特定模型，模型执行推理并返回结果。为了提高这一过程的效率，HuggingGPT 可以同时运行不同的模型，只要它们不需要相同的资源。例如，如果我给出一个生成猫和狗图片的提示，那么不同的模型可以并行执行这个任务。然而，有时模型可能需要相同的资源，这就是为什么
    HuggingGPT 维护一个**<resource>** 属性来跟踪资源使用情况。它确保资源得到有效利用。
- en: 4\. Response Generation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 响应生成
- en: The final step involves generating the response to the user. Firstly, it integrates
    all the information from the previous stages and the inference results. The information
    is presented in a structured format. For example, if the prompt was to detect
    the number of lions in an image, it will draw the appropriate bounding boxes with
    detection probabilities. The LLM (ChatGPT) then uses this format and presents
    it in human-friendly language.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是生成对用户的响应。首先，它整合了来自前几个阶段的信息和推理结果。信息以结构化的格式呈现。例如，如果提示是检测图像中的狮子数量，它将绘制适当的边界框并标注检测概率。LLM（ChatGPT）然后使用这种格式，并以人类友好的语言呈现。
- en: Setting Up HuggingGPT
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 HuggingGPT
- en: 'HuggingGPT is built on top of Hugging Face''s state-of-the-art GPT-3.5 architecture,
    which is a deep neural network model that can generate natural language text.
    Here is how you can set it up on your local computer:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingGPT 基于 Hugging Face 的最先进 GPT-3.5 架构构建，这是一种能够生成自然语言文本的深度神经网络模型。以下是如何在本地计算机上进行设置：
- en: System Requirements
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统要求
- en: The default configuration requires Ubuntu 16.04 LTS, VRAM of at least 24GB,
    RAM of at least 12GB (minimal), 16GB (standard), or 80GB (full), and disk space
    of at least 284 GB. Additionally, you'll need 42GB of space for damo-vilab/text-to-video-ms-1.7b,
    126GB for ControlNet, 66GB for stable-diffusion-v1-5, and 50GB for other resources.
    For the "lite" configuration, you'll only need Ubuntu 16.04 LTS.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 默认配置要求 Ubuntu 16.04 LTS、至少 24GB 的 VRAM、最少 12GB（最低）、16GB（标准）或 80GB（完整）的 RAM，以及至少
    284GB 的磁盘空间。此外，你还需要 42GB 的空间用于 damo-vilab/text-to-video-ms-1.7b，126GB 用于 ControlNet，66GB
    用于 stable-diffusion-v1-5，以及 50GB 用于其他资源。对于 "lite" 配置，你只需要 Ubuntu 16.04 LTS。
- en: Steps to Get Started
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入门步骤
- en: First, replace the OpenAI Key and the Hugging Face Token in the server/configs/config.default.yaml
    file with your keys. Alternatively, you can put them in the environment variables
    **OPENAI_API_KEY** and **HUGGINGFACE_ACCESS_TOKEN**, respectively
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，替换 server/configs/config.default.yaml 文件中的 OpenAI Key 和 Hugging Face Token
    为你的密钥。或者，你可以将它们分别放入环境变量 **OPENAI_API_KEY** 和 **HUGGINGFACE_ACCESS_TOKEN** 中。
- en: 'Run the following commands:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令：
- en: '**For Server:**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于服务器：**'
- en: Set up the Python environment and install the required dependencies.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 Python 环境并安装所需的依赖项。
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Download the required models.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载所需的模型。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Run the server
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行服务器
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now you can access Jarvis'' services by sending HTTP requests to the Web API
    endpoints. Send a request to :'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以通过向 Web API 端点发送 HTTP 请求来访问 Jarvis 的服务。发送请求到：
- en: '**/hugginggpt** endpoint using the POST method to access the full service.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 POST 方法访问 **/hugginggpt** 端点以获取完整服务。
- en: '**/tasks** endpoint using the POST method to access intermediate results for
    Stage #1'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 POST 方法访问 **/tasks** 端点以获取阶段 #1 的中间结果。'
- en: '**/results** endpoint using the POST method to access intermediate results
    for Stages #1-3.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 POST 方法访问 **/results** 端点以获取阶段 #1-3 的中间结果。'
- en: The requests should be in JSON format and should include a list of messages
    that represent the user's inputs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请求应为 JSON 格式，并应包括表示用户输入的消息列表。
- en: '**For Web:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于 Web：**'
- en: Install node js and npm on your machine after starting your application awesome_chat.py
    in server mode.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以服务器模式启动应用程序 awesome_chat.py 后，安装 node js 和 npm。
- en: Navigate to the web directory and install the following dependencies
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 web 目录并安装以下依赖项。
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Set http://{LAN_IP_of_the_server}:{port}/ to HUGGINGGPT_BASE_URL of web/src/config/index.ts, 
    in case you are running the web client on another machine.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 http://{LAN_IP_of_the_server}:{port}/ 设置为 web/src/config/index.ts 中的 HUGGINGGPT_BASE_URL，以防你在另一台机器上运行
    web 客户端。
- en: If you want to use the video generation feature, compile ffmpeg manually with
    H.264.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想使用视频生成特性，请手动编译 ffmpeg，并启用 H.264。
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Double-click on the setting icon to switch back to ChatGPT.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 双击设置图标以切换回 ChatGPT。
- en: '**For CLI:**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于 CLI：**'
- en: 'Setting up Jarvis using CLI is quite simple. Just run the command mentioned
    below:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CLI 设置 Jarvis 非常简单。只需运行以下命令：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**For Gradio:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于 Gradio：**'
- en: '[Gradio demo](https://huggingface.co/spaces/microsoft/HuggingGPT) is also being
    hosted on Hugging Face Space. You can experiment with it after entering the OPENAI_API_KEY
    and HUGGINGFACE_ACCESS_TOKEN.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gradio 演示](https://huggingface.co/spaces/microsoft/HuggingGPT)也托管在 Hugging
    Face Space 上。你可以在输入 OPENAI_API_KEY 和 HUGGINGFACE_ACCESS_TOKEN 后进行实验。'
- en: 'To run it locally:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地运行：
- en: Install the required dependencies, clone the project repository from the Hugging
    Face Space, and navigate to the project directory
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装所需的依赖项，从 Hugging Face Space 克隆项目仓库，并导航到项目目录。
- en: 'Start the model server followed by the Gradio demo using:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动模型服务器，然后使用以下命令启动 Gradio 演示：
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Access the demo in your browser at [http://localhost:7860](http://localhost:7860)
    and test by entering various inputs
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在浏览器中访问 [http://localhost:7860](http://localhost:7860) 并通过输入各种数据进行测试
- en: 'Optionally, you can also run the demo as a Docker image by running the following
    command:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，您还可以通过运行以下命令将演示作为 Docker 镜像运行：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note: In case of any issue please refer to the [official Github Repo](https://github.com/microsoft/JARVIS).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如遇任何问题，请参考 [官方 GitHub 仓库](https://github.com/microsoft/JARVIS)。
- en: Final Thoughts
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: HuggingGPT also has certain limitations that I want to highlight here. For instance,
    the efficiency of the system is a major bottleneck and during all the stages mentioned
    earlier, HuggingGPT requires multiple interactions with LLMs. These interactions
    can lead to degraded user experience and increased latency. Similarly, the maximum
    context length is also limited by the number of allowed tokens. Another problem
    is the System's reliability, as the LLMs may misinterpret the prompt and generate
    a wrong sequence of tasks which in turn affects the whole process. Nonetheless,
    it has significant potential to solve complex AI tasks and is an excellent advancement
    toward AGI. Let's see in which direction this research leads us too. That’s a
    wrap, feel free to express your views in the comment section below.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingGPT 也有一些限制，我在这里想要强调。例如，系统的效率是一个主要瓶颈，在之前提到的所有阶段，HuggingGPT 需要与 LLMs 进行多次交互。这些交互可能导致用户体验下降和延迟增加。类似地，最大上下文长度也受限于允许的令牌数量。另一个问题是系统的可靠性，因为
    LLMs 可能误解提示并生成错误的任务序列，从而影响整个过程。尽管如此，它在解决复杂 AI 任务方面具有显著潜力，是通向 AGI 的重要进展。让我们看看这项研究会带我们走向何方。这就是总结，请随时在下方评论区表达您的观点。
- en: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** is an aspiring
    software developer with a keen interest in data science and applications of AI
    in medicine. Kanwal was selected as the Google Generation Scholar 2022 for the
    APAC region. Kanwal loves to share technical knowledge by writing articles on
    trending topics, and is passionate about improving the representation of women
    in tech industry.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** 是一名有志的软件开发者，对数据科学和
    AI 在医学中的应用充满兴趣。Kanwal 被选为 2022 年 APAC 区域的 Google Generation Scholar。Kanwal 喜欢通过撰写关于热门话题的文章来分享技术知识，并热衷于提高女性在科技行业中的代表性。'
- en: '* * *'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[GPT-4: 8 Models in One; The Secret is Out](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT-4：8 个模型合一；秘密已揭晓](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
- en: '[Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用 LLMOps：无缝互动背后的秘密](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)'
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[想用您的数据技能解决全球问题？了解更多……](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学项目，帮助您解决现实世界问题](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
- en: '[How to Use NumPy to Solve Systems of Nonlinear Equations](https://www.kdnuggets.com/how-to-use-numpy-to-solve-systems-of-nonlinear-equations)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 NumPy 解决非线性方程组](https://www.kdnuggets.com/how-to-use-numpy-to-solve-systems-of-nonlinear-equations)'
- en: '[Solving 5 Complex SQL Problems: Tricky Queries Explained](https://www.kdnuggets.com/2022/07/5-hardest-things-sql.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解决 5 个复杂的 SQL 问题：难解的查询解析](https://www.kdnuggets.com/2022/07/5-hardest-things-sql.html)'
