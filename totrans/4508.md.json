["```py\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.filters import threshold_otsu\nimport numpy as np\nfrom glob import glob\nimport scipy.misc\nfrom matplotlib.patches import Circle,Ellipse\nfrom matplotlib.patches import Rectangle\nimport os\nfrom PIL import Imageimport keras\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport gzip\n%matplotlib inline\nfrom keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop\nfrom keras.layers.normalization import BatchNormalization\n```", "```py\ndata = glob('./drive/My Drive/fingerprint/DB*/*')images = []\ndef readImages(data):\n    for i in range(len(data)):\n        img = scipy.misc.imread(data[i])\n        img = scipy.misc.imresize(img,(224,224))\n        images.append(img)\n    return imagesimages = readImages(data)\n```", "```py\nimages_arr = np.asarray(images)\nimages_arr = images_arr.astype('float32')\nimages_arr.shape\n```", "```py\nprint(\"Dataset (images) shape: {shape}\".format(shape=images_arr.shape))##Dataset (images) shape: (320, 224, 224)\n```", "```py\n# Display the first 5 images in training data\nfor i in range(5):\n    plt.figure(figsize=[5, 5])\n    curr_img = np.reshape(images_arr[i], (224,224))\n    plt.imshow(curr_img, cmap='gray')\n    plt.show()\n```", "```py\nimages_arr = images_arr.reshape(-1, 224,224, 1)\nimages_arr.shape##(320, 224, 224, 1)\n```", "```py\nimages_arr.dtype\n```", "```py\nnp.max(images_arr)\nimages_arr = images_arr / np.max(images_arr)\n```", "```py\nnp.max(images_arr), np.min(images_arr)\n```", "```py\nfrom sklearn.model_selection import train_test_split\ntrain_X,valid_X,train_ground,valid_ground = train_test_split(images_arr,images_arr,test_size=0.2,random_state=13)\n```", "```py\nbatch_size = 128\nepochs = 300\nx, y = 224, 224\ninput_img = Input(shape = (x, y, 1))\n```", "```py\ndef autoencoder(input_img):\n    #encoder\n    #input = 28 x 28 x 1 (wide and thin)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)#decoder\n    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128\n    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64\n    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n    return decodedautoencoder = Model(input_img, autoencoder(input_img))\n```", "```py\nautoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n```", "```py\n#Training\nautoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))\n```", "```py\nloss = autoencoder_train.history['loss']\nval_loss = autoencoder_train.history['val_loss']\nepochs = range(300)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\n```", "```py\n#Prediction\npred = autoencoder.predict(valid_X)#Reconstruction of Test Images\nplt.figure(figsize=(20, 4))\nprint(\"Test Images\")\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(valid_ground[i, ..., 0], cmap='gray')\nplt.show()    \nplt.figure(figsize=(20, 4))\nprint(\"Reconstruction of Test Images\")\nfor i in range(5):\n    plt.subplot(1, 5, i+1)\n    plt.imshow(pred[i, ..., 0], cmap='gray')  \nplt.show()\n```"]