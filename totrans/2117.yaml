- en: 5 Ways To Use LLMs On Your Laptop
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你的笔记本电脑上使用LLMs的5种方法
- en: 原文：[https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop](https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop](https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop)
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/959531228a0af4fd6fcf399f422784d8.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![在你的笔记本电脑上使用LLMs的5种方法](../Images/959531228a0af4fd6fcf399f422784d8.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Accessing ChatGPT online is very simple - all you need is an internet connection
    and a good browser. However, by doing so, you may be compromising your privacy
    and data. OpenAI stores your prompt responses and other metadata to retrain the
    models. While this might not be a concern for some, others who are privacy-conscious
    may prefer to use these models locally without any external tracking.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在线访问ChatGPT非常简单——你只需一个互联网连接和一个好的浏览器。然而，这样做可能会妨碍你的隐私和数据。OpenAI会存储你的提示响应和其他元数据以重新训练模型。虽然这对一些人来说可能不是问题，但注重隐私的人可能更愿意在本地使用这些模型，而没有任何外部跟踪。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业领域。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this post, we will discuss five ways to use large language models (LLMs)
    locally. Most of the software is compatible with all major operating systems and
    can be easily downloaded and installed for immediate use. By using LLMs on your
    laptop, you have the freedom to choose your own model. You just need to download
    the model from the HuggingFace hub and start using it. Additionally, you can grant
    these applications access to your project folder and generate context-aware responses.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨五种在本地使用大语言模型（LLMs）的方法。大部分软件兼容所有主要操作系统，并可以轻松下载和安装以供立即使用。通过在你的笔记本电脑上使用LLMs，你可以自由选择自己的模型。你只需从HuggingFace中心下载模型并开始使用。此外，你可以授权这些应用访问你的项目文件夹并生成上下文相关的响应。
- en: 1\. GPT4All
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. GPT4All
- en: '[GPT4All](https://gpt4all.io/index.html) is a cutting-edge open-source software
    that enables users to download and install state-of-the-art open-source models
    with ease.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT4All](https://gpt4all.io/index.html)是一个前沿的开源软件，使用户能够轻松下载和安装最先进的开源模型。'
- en: Simply download GPT4ALL from the website and install it on your system. Next,
    choose the model from the panel that suits your needs and start using it. If you
    have CUDA (Nvidia GPU) installed, GPT4ALL will automatically start using your
    GPU to generate quick responses of up to 30 tokens per second.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 只需从网站上下载GPT4ALL并在系统上安装。接下来，从面板中选择适合你需求的模型并开始使用。如果你安装了CUDA（Nvidia GPU），GPT4ALL将自动开始使用你的GPU以每秒最多生成30个token的快速响应。
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/c68d67ddd46c9442bee98a695cfe0c78.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![在你的笔记本电脑上使用LLMs的5种方法](../Images/c68d67ddd46c9442bee98a695cfe0c78.png)'
- en: You can provide access to multiple folders containing important documents and
    code, and GPT4ALL will generate responses using Retrieval-Augmented Generation.
    GPT4ALL is user-friendly, fast, and popular among the AI community.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以提供对包含重要文档和代码的多个文件夹的访问权限，GPT4ALL将使用检索增强生成（Retrieval-Augmented Generation）生成响应。GPT4ALL用户友好、快速，并且在AI社区中很受欢迎。
- en: 'Read the blog about GPT4ALL to learn more about features and use cases: [The
    Ultimate Open-Source Large Language Model Ecosystem](/2023/05/ultimate-opensource-large-language-model-ecosystem.html).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读有关GPT4ALL的博客，了解更多功能和用例：[终极开源大语言模型生态系统](/2023/05/ultimate-opensource-large-language-model-ecosystem.html)。
- en: 2\. LM Studio
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. LM Studio
- en: '[LM Studio](https://lmstudio.ai/) is a new software that offers several advantages
    over GPT4ALL. The user interface is excellent, and you can install any model from
    Hugging Face Hub with a few clicks. Additionally, it provides GPU offloading and
    other options that are not available in GPT4ALL. However, LM Studio is a closed
    source, and it doesn''t have the option to generate context-aware responses by
    reading project files.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[LM Studio](https://lmstudio.ai/) 是一个新软件，相较于 GPT4ALL 提供了多个优势。用户界面非常出色，你可以通过几次点击安装
    Hugging Face Hub 中的任何模型。此外，它提供 GPU 卸载和 GPT4ALL 中没有的其他选项。然而，LM Studio 是封闭源代码的，无法通过读取项目文件生成上下文相关的响应。'
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/4f5f0c4245979ed4d3f59ee7f7e28f52.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![5 Ways To Use LLMs On Your Laptop](../Images/4f5f0c4245979ed4d3f59ee7f7e28f52.png)'
- en: LM Studio offers access to thousands of open-source LLMs, allowing you to start
    a local inference server that behaves like OpenAI's API. You can modify your LLM's
    response through the interactive user interface with multiple options.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LM Studio 提供对数千个开源 LLM 的访问，使你能够启动一个本地推理服务器，其行为类似于 OpenAI 的 API。你可以通过互动用户界面和多个选项修改
    LLM 的响应。
- en: Also, read [Run an LLM Locally with LM Studio](/run-an-llm-locally-with-lm-studio)
    to learn more about LM Studio and its key features.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请阅读 [Run an LLM Locally with LM Studio](/run-an-llm-locally-with-lm-studio)
    以了解更多有关 LM Studio 及其关键功能的信息。
- en: 3\. Ollama
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. Ollama
- en: '[Ollama](https://github.com/ollama/ollama) is a command-line interface (CLI)
    tool that enables speedy operation for large language models such as Llama 2,
    Mistral, and Gemma. If you are a hacker or developer, this CLI tool is a fantastic
    option. You can download and install the software and use `the llama run llama2`
    command to start using the LLaMA 2 model. You can find other model commands in
    the GitHub repository.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ollama](https://github.com/ollama/ollama) 是一个命令行界面 (CLI) 工具，能够快速操作大型语言模型，如
    Llama 2、Mistral 和 Gemma。如果你是黑客或开发人员，这个 CLI 工具是一个极好的选择。你可以下载并安装软件，并使用 `the llama
    run llama2` 命令开始使用 LLaMA 2 模型。你可以在 GitHub 仓库中找到其他模型命令。'
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/33c8e965b3f5c20325e58d9f9749d31c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![5 Ways To Use LLMs On Your Laptop](../Images/33c8e965b3f5c20325e58d9f9749d31c.png)'
- en: It also allows you to start a local HTTP server that can be integrated with
    other applications. For instance, you can use the Code GPT VSCode extension by
    providing the local server address and start using it as an AI coding assistant.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 它还允许你启动一个本地 HTTP 服务器，并与其他应用程序集成。例如，你可以通过提供本地服务器地址来使用 Code GPT VSCode 扩展，开始将其用作
    AI 编程助手。
- en: Improve your coding and data workflow with these [Top 5 AI Coding Assistants](/top-5-ai-coding-assistants-you-must-try).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些 [Top 5 AI Coding Assistants](/top-5-ai-coding-assistants-you-must-try)
    改善你的编码和数据工作流程。
- en: 4\. LLaMA.cpp
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. LLaMA.cpp
- en: '[LLaMA.cpp](https://github.com/ggerganov/llama.cpp) is a tool that offers both
    a CLI and a Graphical User Interface (GUI). It allows you to use any open-source
    LLMs locally without any hassle. This tool is highly customizable and provides
    fast responses to any query, as it is entirely written in pure C/C++.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[LLaMA.cpp](https://github.com/ggerganov/llama.cpp) 是一个提供 CLI 和图形用户界面 (GUI)
    的工具。它允许你在本地无障碍地使用任何开源 LLM。该工具高度可定制，并能快速响应任何查询，因为它完全用纯 C/C++ 编写。'
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/e9ff13b2925d46e2dde511a831ca7d36.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![5 Ways To Use LLMs On Your Laptop](../Images/e9ff13b2925d46e2dde511a831ca7d36.png)'
- en: LLaMA.cpp supports all types of operating systems, CPUs, and GPUs. You can also
    use multimodal models such as LLaVA, BakLLaVA, Obsidian, and ShareGPT4V.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA.cpp 支持所有类型的操作系统、CPU 和 GPU。你还可以使用多模态模型，如 LLaVA、BakLLaVA、Obsidian 和 ShareGPT4V。
- en: Learn how to [Run Mixtral 8x7b On Google Colab For Free](/running-mixtral-8x7b-on-google-colab-for-free)
    using LLaMA.cpp and Google GPUs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 了解如何 [Run Mixtral 8x7b On Google Colab For Free](/running-mixtral-8x7b-on-google-colab-for-free)
    使用 LLaMA.cpp 和 Google GPUs。
- en: 5\. NVIDIA Chat with RTX
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. NVIDIA Chat with RTX
- en: To use [NVIDIA Chat with RTX](https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/),
    you need to download and install the Windows 11 application on your laptop. This
    application is compatible with laptops that have a 30 series or 40 series RTX
    NVIDIA graphics card with at least 8GB of RAM and 50GB of free storage space.
    Additionally, your laptop should have at least 16GB of RAM to run Chat with RTX
    smoothly.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 [NVIDIA Chat with RTX](https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/)，你需要在笔记本电脑上下载并安装
    Windows 11 应用程序。该应用程序兼容于具有 30 系列或 40 系列 RTX NVIDIA 显卡、至少 8GB 内存和 50GB 可用存储空间的笔记本电脑。此外，你的笔记本电脑应至少具有
    16GB 内存，以便顺畅运行 Chat with RTX。
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/62b35ec13c71bd6451ed392e51013cb6.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![5 Ways To Use LLMs On Your Laptop](../Images/62b35ec13c71bd6451ed392e51013cb6.png)'
- en: With Chat with RTX, you can run LLaMA and Mistral models locally on your laptop.
    It's a fast and efficient application that can even learn from documents you provide
    or YouTube videos. However, it's important to note that Chat with RTX relies on
    TensorRTX-LLM, which is only supported on 30 series GPUs or newer.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Chat with RTX，你可以在笔记本电脑上本地运行 LLaMA 和 Mistral 模型。这是一个快速高效的应用程序，甚至可以从你提供的文档或
    YouTube 视频中学习。然而，需要注意的是，Chat with RTX 依赖于 TensorRTX-LLM，该技术仅支持 30 系列或更新的 GPU。
- en: Conclusion
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: If you want to take advantage of the latest LLMs while keeping your data safe
    and private, you can use tools like GPT4All, LM Studio, Ollama, LLaMA.cpp, or
    NVIDIA Chat with RTX. Each tool has its own unique strengths, whether it's an
    easy-to-use interface, command-line accessibility, or support for multimodal models.
    With the right setup, you can have a powerful AI assistant that generates customized
    context-aware responses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在确保数据安全和隐私的同时利用最新的 LLMs，可以使用 GPT4All、LM Studio、Ollama、LLaMA.cpp 或 NVIDIA
    Chat with RTX 等工具。每种工具都有其独特的优势，无论是易于使用的界面、命令行访问，还是对多模态模型的支持。通过正确的设置，你可以拥有一个强大的
    AI 助手，生成定制化的上下文感知响应。
- en: I suggest starting with GPT4All and LM Studio as they cover most of the basic
    needs. After that, you can try Ollama and LLaMA.cpp, and finally, try Chat with
    RTX.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议从 GPT4All 和 LM Studio 开始，因为它们涵盖了大部分基本需求。之后，你可以尝试 Ollama 和 LLaMA.cpp，最后尝试
    Chat with RTX。
- en: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) is a certified data
    scientist professional who loves building machine learning models. Currently,
    he is focusing on content creation and writing technical blogs on machine learning
    and data science technologies. Abid holds a Master''s degree in technology management
    and a bachelor''s degree in telecommunication engineering. His vision is to build
    an AI product using a graph neural network for students struggling with mental
    illness.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) 是一位认证的数据科学专业人士，喜欢构建机器学习模型。目前，他专注于内容创作，并撰写关于机器学习和数据科学技术的技术博客。Abid
    拥有技术管理硕士学位和电信工程学士学位。他的愿景是使用图神经网络构建一个 AI 产品，帮助那些面临心理健康问题的学生。'
- en: More On This Topic
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过 openplayground 在你的笔记本电脑上轻松探索 LLMs](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
- en: '[Turn Your Laptop Into a Personal Analytics Engine with DuckDB and…](https://www.kdnuggets.com/turn-your-laptop-into-a-personal-analytics-engine-with-duckdb-and-motherduck)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 DuckDB 和… 将你的笔记本电脑变成个人分析引擎](https://www.kdnuggets.com/turn-your-laptop-into-a-personal-analytics-engine-with-duckdb-and-motherduck)'
- en: '[5 Ways of Converting Unstructured Data into Structured Insights with LLMs](https://www.kdnuggets.com/5-ways-of-converting-unstructured-data-into-structured-insights-with-llms)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 LLMs 将非结构化数据转换为结构化洞察的 5 种方法](https://www.kdnuggets.com/5-ways-of-converting-unstructured-data-into-structured-insights-with-llms)'
- en: '[5 Ways To Use AI For Supply Chain Management](https://www.kdnuggets.com/2022/02/5-ways-ai-supply-chain-management.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 AI 进行供应链管理的 5 种方法](https://www.kdnuggets.com/2022/02/5-ways-ai-supply-chain-management.html)'
- en: '[5 Ways You Can Use ChatGPT''s Code Interpreter For Data Science](https://www.kdnuggets.com/2023/08/5-ways-chatgpt-code-interpreter-data-science.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你可以利用 ChatGPT 的代码解释器进行数据科学的 5 种方式](https://www.kdnuggets.com/2023/08/5-ways-chatgpt-code-interpreter-data-science.html)'
- en: '[5 Ways You Can Use ChatGPT Vision for Data Analysis](https://www.kdnuggets.com/5-ways-you-can-use-chatgpt-vision-for-data-analysis)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 ChatGPT Vision 进行数据分析的 5 种方法](https://www.kdnuggets.com/5-ways-you-can-use-chatgpt-vision-for-data-analysis)'
