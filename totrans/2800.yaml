- en: Decision Boundary for a Series of Machine Learning Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/03/decision-boundary-series-machine-learning-models.html](https://www.kdnuggets.com/2020/03/decision-boundary-series-machine-learning-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Matthew Smith](https://www.linkedin.com/in/msmithsm14/), Complutense
    University Madrid**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine Learning at the Boundary:'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is nothing new in the fact that machine learning models can outperform
    traditional econometric models but I want to show as part of my research why and
    how some models make given predictions or in this instance classifications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: I wanted to show the decision boundary in which my binary classification model
    was making. That is, I wanted to show the partition space that splits my classification
    into each class. The problem and code can be split into a multi-classification
    problem with some tweeks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialisation:'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I first load in a series of packages and initialise a logistic function to convert
    log-odds to a logistic probability function later on.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The data:'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I use the `iris` dataset which contains information on 3 different plant variables
    collected by British statistican Ronald Fisher in 1936\. The dataset consists
    of 44 different characteristics of plant species which should uniquely distinguish
    the 33 different species (*Setosa*, *Virginica* and *Versicolor*). However, my
    problem required a binary classification problem and not a multi-classifciation
    problem. In the following code I import the `iris` data and remove a type of plant
    Species `virginica` to bring it from a multi-classification to a binary classification
    problem.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I plot the data by first storing the `ggplot` objects changing only the `x` and `y` variables
    in each of the `plt`’s.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: I also wanted to use the new `patchwork` package which makes displaying `ggplot` plots
    very easy. i.e the below code plots our graphics as its written (1 top plot stretching
    the length of the grid space, 2 middle plots, another single plot and a further
    2 more plots at the bottom.)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/1b8077e556fd77387eefecc1d37dfdb5.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: 'Alternatively, we can re-arrange the plots into any way we wish and plot them
    in the following way:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/21bf1cf183f88129d3cac813ff18747a.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Which I think looks awesome.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Objective
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The objective is to build a classification algorithm to distinguish between
    the two classes and then compute the decision boundaries in order to better see
    how the models made such predictions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是构建一个分类算法，以区分这两类，并计算决策边界，以便更好地了解模型如何做出这些预测。
- en: In order to create the decision boundary plots for each variable combination
    we need the different combinatons of variables in the data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建每个变量组合的决策边界图，我们需要数据中不同的变量组合。
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Table 1: Variable Combinations
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：变量组合
- en: '| Var1 | Var2 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 变量1 | 变量2 |'
- en: '| --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Sepal.Width | Sepal.Length |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 花萼宽度 | 花萼长度 |'
- en: '| Petal.Length | Sepal.Length |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣长度 | 花萼长度 |'
- en: '| Petal.Width | Sepal.Length |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣宽度 | 花萼长度 |'
- en: '| Sepal.Length | Sepal.Width |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 花萼长度 | 花萼宽度 |'
- en: '| Petal.Length | Sepal.Width |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣长度 | 花萼宽度 |'
- en: '| Petal.Width | Sepal.Width |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 花瓣宽度 | 花萼宽度 |'
- en: Next, I want to use the different variable combinations previously and create
    lists (one for each variable combination) and populate these lists with synthetic
    data - or data from the minimum to maximum value of each variable combination.
    This will act as our synthetically created test data in which we make predictions
    on and build the decision boundary.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我想使用之前的不同变量组合，创建列表（每个变量组合一个）并用合成数据填充这些列表——或者说从每个变量组合的最小值到最大值的数据。这将作为我们合成创建的测试数据，我们在其上进行预测并构建决策边界。
- en: It’s important to note that the plots will eventually be 2 dimensional for illustrative
    purposes, therefore we only train the Machine Learning models on two variables,
    but for each combination of the two variables, these variables are the first two
    variables in the `boundary_lists` data frames.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，图形最终会是二维的以便于说明，因此我们只对两个变量训练机器学习模型，但对于每个变量组合，这些变量是`boundary_lists`数据框中的前两个变量。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can see how the first 4 observations of the first and last two lists look
    like:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看看前四个观测值和最后两个列表的样子：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Training time:'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练时间：
- en: 'Now that we have the synthetically created testing data set up, I want to train
    the models on the actual observed observations. I use each data point in the plots
    above as my training data. I apply the following models:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了合成创建的测试数据集，我想用实际观察到的数据来训练模型。我使用上述图中的每个数据点作为训练数据。我应用以下模型：
- en: Logistic Model
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑模型
- en: Support Vector Machine with a linear kernel
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带线性核的支持向量机
- en: Support Vector Machine with a polynomial kernel
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带多项式核的支持向量机
- en: Support Vector Machine with a radial kernel
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带径向核的支持向量机
- en: Support Vector Machine with a sigmoid kernel
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带sigmoid核的支持向量机
- en: Random Forest
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Extreme Gradiant Boosting (XGBoost) model with default parameters
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有默认参数的极端梯度提升（XGBoost）模型
- en: Single layer Keras Neural Network (with linear components)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单层Keras神经网络（含线性组件）
- en: Deeper layer Keras Neural Network (with linear components)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更深层的Keras神经网络（含线性组件）
- en: Deeper’er layer Keras Neural Network (with linear components)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更深层的Keras神经网络（含线性组件）
- en: Light Gradient Boosting model (LightGBM) with default parameters
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有默认参数的轻量级梯度提升模型（LightGBM）
- en: 'Side note: I am not an expert in Deep learning/Keras/Tensorflow, so I am sure
    better models will yield better decision boundaries but it was a fun task getting
    the different Machine Learning models to fit inside a `purrr`, `map` call.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 附注：我不是深度学习/Keras/Tensorflow的专家，所以我相信更好的模型会产生更好的决策边界，但将不同的机器学习模型适配到`purrr`、`map`调用中是一个有趣的任务。
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Testing time:'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试时间：
- en: Now that the models have been trained, we can begin makign the predictions on
    the synthetically created data we created in the `boundary_lists` data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练好，我们可以开始对我们在`boundary_lists`数据中创建的合成数据进行预测。
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Calibrating the data
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 校准数据
- en: Now we have our trained models, along with predictions we can `map` these predictions
    into data which we can plot using `ggplot` and then arrange using `patchwork`!.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了训练好的模型，以及预测结果，我们可以将这些预测`map`到数据中，然后使用`ggplot`绘制，再用`patchwork`进行排列！
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that we have our predictions we can create the `ggplots`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了预测结果，可以创建`ggplots`。
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Plot all the different combinations of the decision boundaries. **Note**: The
    above code will work better in your console, when I ran the code to compile the
    blog post the plots were too small. Therefore, I provide individual plots for
    a sample of the models & variable combinations.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制所有不同的决策边界组合。**注意**：上述代码在您的控制台中效果更好，当我运行代码编译博客时，图形太小了。因此，我提供了模型和变量组合的单独样本图。
- en: I first needed to select the first two columns which are the variables of interest
    (Petal.Width, Petal.Length, Sepal.Width and Sepal.Length). Then I wanted to take
    a random sample of the columns thereafter (which are the different Machine Learning
    Model predictions).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先需要选择前两列，即感兴趣的变量（花瓣宽度、花瓣长度、萼片宽度和萼片长度）。然后我想对其后的列（即不同的机器学习模型预测）进行随机抽样。
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Next I can make the plots by taking a random sample of the lists.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我可以通过从列表中随机抽样来制作图表。
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/f0fcc6e0ae7a8ae8efa079465e409ee9.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0fcc6e0ae7a8ae8efa079465e409ee9.png)'
- en: 'Some other random models:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他随机模型：
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/a28b0c6d73afaef699016b5019757ae5.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a28b0c6d73afaef699016b5019757ae5.png)'
- en: '[PRE23]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/0b740f0c10626aa86bb96289baed5b95.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b740f0c10626aa86bb96289baed5b95.png)'
- en: '[PRE24]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/f326ef09871b151259e191ae8e8530ed.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f326ef09871b151259e191ae8e8530ed.png)'
- en: '[PRE25]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/2fddfb7ddadda0f1f9a329327673d3d8.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fddfb7ddadda0f1f9a329327673d3d8.png)'
- en: '[PRE26]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](../Images/fe78f389f3683f2e013bc223a3c7b6ab.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe78f389f3683f2e013bc223a3c7b6ab.png)'
- en: Natually the linear models made a linear decision boundary. It looks like the
    random forest model overfit a little the data, where as the XGBoost and LightGBM
    models were able to make better, more generalisable decision boundaries. The Keras
    Neural Networks performed poorly because they should be trained better.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，线性模型形成了线性决策边界。看起来随机森林模型在数据上稍微过拟合了，而XGBoost和LightGBM模型能够形成更好、更具泛化能力的决策边界。Keras神经网络表现不佳，因为它们需要更好的训练。
- en: '`glm` = Logistic Model'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`glm` = 逻辑回归模型'
- en: '`keras.engine.sequential.Sequential Prediction...18` = Single layer Neural
    Network'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras.engine.sequential.Sequential Prediction...18` = 单层神经网络'
- en: '`keras.engine.sequential.Sequential Prediction...18` = Deeper layer Neural
    Network'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras.engine.sequential.Sequential Prediction...18` = 更深层的神经网络'
- en: '`keras.engine.sequential.Sequential Prediction...22` = Deeper’er layer Neural
    Network'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras.engine.sequential.Sequential Prediction...22` = 更深层的神经网络'
- en: '`lgb.Booster Prediction` = Light Gradient Boosted Model'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lgb.Booster Prediction` = 轻量级梯度提升模型'
- en: '`randomForest.formula Prediction` = Random Forest Model'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`randomForest.formula Prediction` = 随机森林模型'
- en: '`svm.formula Prediction...10` = Support Vector Machine with a Sigmoid Kernel'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm.formula Prediction...10` = 带有Sigmoid核的支持向量机'
- en: '`svm.formula Prediction...12` = Support Vector Machine with a Radial Kernel'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm.formula Prediction...12` = 带有径向核的支持向量机'
- en: '`svm.formula Prediction...6` = Support Vector Machine with a Linear Kernel'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm.formula Prediction...6` = 带有线性核的支持向量机'
- en: '`svm.formula Prediction...8` = Support Vector Machine with a Polynomial Kernel'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svm.formula Prediction...8` = 带有多项式核的支持向量机'
- en: '`xgb.Booster Prediction` = Extreme Gradient Boosting Model'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xgb.Booster Prediction` = 极端梯度提升模型'
- en: In many of the combinations the Keras Neural Network model just predicted all
    observations to be of a specific class (again by my poor tuning of the models
    and the fact that the Neural Networks only had 100 observations to learn from
    and 40,000 observation to predict on). That is, it coloured the whole background
    blue or red and made many mis-classifications. In some of the plots the Neural
    Networks managed to mae perfect classifications, in other it made strange decision
    boundaries. - Neural Networks are fun.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多组合中，Keras神经网络模型只是将所有观测值预测为特定类别（这再次是由于我对模型的调整不佳以及神经网络只有100个观测值用于学习和40,000个观测值用于预测）。也就是说，它将整个背景涂成了蓝色或红色，并且做出了许多误分类。在一些图表中，神经网络成功进行了完美分类，而在其他图表中，它做出了奇怪的决策边界。-
    神经网络很有趣。
- en: As some brief analysis of the plots, it looks like the simple logistic model
    made near-perfect classifications. Which isn’t suprising given that each of the
    variable ralationships are linearly seperable. However, I have a preferece for
    XGBoost and LightGBM models since they can handle non-linear relationships through
    the incorporation of regularisation in its objective functions which allows them
    to make more robust decision boundaries. Random Forest models fail here which
    is why their decision boundary appears to do a good job but is also slightly erratic
    and sharpe in it’s decision boundaries.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表的简要分析来看，简单的逻辑回归模型几乎完美地进行了分类。考虑到每个变量之间的关系都是线性可分的，这并不令人惊讶。然而，我更偏爱XGBoost和LightGBM模型，因为它们可以通过在目标函数中引入正则化来处理非线性关系，从而做出更稳健的决策边界。随机森林模型在这里失败了，因此它们的决策边界看起来虽然做得很好，但也略显不稳定和尖锐。
- en: Of course it goes without saying that these decision boundaries can become significantly
    more complex and non-linear with the inclusion of more variables and higher dimensions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，随着更多变量和更高维度的引入，这些决策边界可能会变得显著更复杂和非线性。
- en: '[PRE29]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'End note:'
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束说明：
- en: I wrote this model on an Amazon Ubuntu EC2 Instance however, when I went to
    compile the blog post in R on my Windows system I ran into some problems. These
    problems were mostly down to installing the `lightgbm` package and package versions.
    The code was working without error using the following package versions (i.e. using
    the most up-to-date package versions)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一个亚马逊 Ubuntu EC2 实例上编写了这个模型，但当我在 Windows 系统上用 R 编译博客文章时遇到了一些问题。这些问题主要是由于安装
    `lightgbm` 包和包版本造成的。使用以下包版本（即使用最新包版本）时，代码正常运行没有错误。
- en: '[PRE30]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**Bio: [Matthew Smith](https://www.linkedin.com/in/msmithsm14/)** ([@MatthewSmith786](https://twitter.com/MatthewSmith786))
    is a PhD student at the Complutense University Madrid. His research focuses on
    Machine Learning methods applied to Economics and Finance. [He writes about topics](https://lf0.com/)
    in R, Python and C++.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Matthew Smith](https://www.linkedin.com/in/msmithsm14/)** ([@MatthewSmith786](https://twitter.com/MatthewSmith786))
    是马德里康普顿斯大学的博士生。他的研究专注于应用于经济学和金融学的机器学习方法。[他撰写的主题](https://lf0.com/)涵盖了 R、Python
    和 C++。'
- en: '[Original](https://lf0.com/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions/).
    Reposted with permission.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始文章](https://lf0.com/post/machine-learning-boundary-conditions/machine-learning-boundary-conditions/)。经许可转载。'
- en: '**Related:**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Getting Started with R Programming](/2020/02/getting-started-r-programming.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R 编程入门](/2020/02/getting-started-r-programming.html)'
- en: '[Serverless Machine Learning with R on Cloud Run](/2020/02/serverless-machine-learning-r-cloud-run.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R 在 Cloud Run 上的无服务器机器学习](/2020/02/serverless-machine-learning-r-cloud-run.html)'
- en: '[Basics of Audio File Processing in R](/2020/02/basics-audio-file-processing-r.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R 中音频文件处理的基础](/2020/02/basics-audio-file-processing-r.html)'
- en: More On This Topic
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Time Series Analysis: ARIMA Models in Python](https://www.kdnuggets.com/2023/08/times-series-analysis-arima-models-python.html)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[时间序列分析：Python 中的 ARIMA 模型](https://www.kdnuggets.com/2023/08/times-series-analysis-arima-models-python.html)'
- en: '[Machine Learning from Scratch: Decision Trees](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从零开始的机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
- en: '[Simplifying Decision Tree Interpretability with Python & Scikit-learn](https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 和 Scikit-learn 简化决策树的可解释性](https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html)'
- en: '[Decision Tree Algorithm, Explained](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树算法详解](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
- en: '[Understanding by Implementing: Decision Tree](https://www.kdnuggets.com/2023/02/understanding-implementing-decision-tree.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过实现理解：决策树](https://www.kdnuggets.com/2023/02/understanding-implementing-decision-tree.html)'
- en: '[Telling a Great Data Story: A Visualization Decision Tree](https://www.kdnuggets.com/2021/02/telling-great-data-story-visualization-decision-tree.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[讲述精彩的数据故事：可视化决策树](https://www.kdnuggets.com/2021/02/telling-great-data-story-visualization-decision-tree.html)'
