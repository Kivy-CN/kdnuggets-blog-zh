["```py\n\n# read in data\nfilename = 'weather.npz'\ndata = np.load(filename)\ndaily = data['daily']\nweekly = data['weekly']\n\nnum_weeks = len(weekly)\ndates = np.array([datetime.datetime.strptime(str(int(d)),\n        '%Y%m%d') for d in weekly[:,0]])\n\n```", "```py\n\nnum_weeks = len(weekly)\n\n```", "```py\n\ndates = np.array([datetime.datetime.strptime(str(int(d)),\n        '%Y%m%d') for d in weekly[:,0]])\n\n```", "```py\n\ndef assign_season(date):\n  ''' Assign season based on meteorological season.\n      Spring - from Mar 1 to May 31\n      Summer - from Jun 1 to Aug 31\n      Autumn - from Sep 1 to Nov 30\n      Winter - from Dec 1 to Feb 28 (Feb 29 in a leap year)\n  '''\n  month = date.month\n  # spring = 0\n  if 3 <= month < 6:\n     season = 0\n  # summer = 1\n  elif 6 <= month < 9:\n    season = 1\n  # autumn = 2\n  elif 9 <= month < 12:\n    season = 2\n  # winter = 3\n  elif month == 12 or month < 3:\n    season = 3\n  return season\n\n```", "```py\n\n# There are 4 seasons\nnum_classes = 4\n\n# and 5 variables\nnum_inputs = 5\n\n# And a state of 11 numbers\nstate_size = 11\n\n```", "```py\n\nlabels = np.zeros([num_weeks,num_classes])\n\n# read and convert to one-hot\n\nfor i,d in enumerate(dates):\n\nlabels[i,assign_season(d)] = 1\n\n```", "```py\n\n# extract and scale training data\n\ntrain = weekly[:,1:]\n\ntrain = train - np.average(train,axis=0)\n\ntrain = train / train.std(axis=0)\n\n```", "```py\n\n# These will be inputs\n\nx = tf.placeholder(\"float\", [None, num_inputs])\n\n# TF likes a funky input to RNN\n\nx_ = tf.reshape(x, [1, num_weeks, num_inputs])\n\n```", "```py\n\ny_ = tf.placeholder(\"float\", [None,num_classes])\n\n```", "```py\n\ncell = tf.nn.rnn_cell.BasicRNNCell(state_size)\n\n```", "```py\n\noutputs, states = tf.nn.dynamic_rnn(cell,x_,\n\ndtype=tf.nn.dtypes.float32, initial_state=None)\n\n```", "```py\n\nW1 = tf.Variable(tf.truncated_normal([state_size,num_classes],\n        stddev=1./math.sqrt(num_inputs)))\n\nb1 = tf.Variable(tf.constant(0.1,shape=[num_classes]))\n\n# reshape the output for traditional usage\nh1 = tf.reshape(outputs,[-1,state_size])\n\n```", "```py\n\n# Climb on cross-entropy\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y + 1e-50, y_))\n\n# How we train\ntrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\n# Define accuracy\ncorrect_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n```", "```py\n\n# Actually train\nepochs = 100\ntrain_acc = np.zeros(epochs//10)\n\nfor i in tqdm(range(epochs), ascii=True):\n    if i % 10 == 0:\n\n   # Record summary data, and the accuracy\n     # Check accuracy on train set \n     A = accuracy.eval(feed_dict={x: train, y_: labels})\n     train_acc[i//10] = A\n\n   train_step.run(feed_dict={x: train, y_: labels})\n\n```"]