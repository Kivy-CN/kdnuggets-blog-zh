- en: 'Machine Learning Model Development and Model Operations: Principles and Practices'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型开发与模型操作：原则与实践
- en: 原文：[https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html](https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html](https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/), Principal Solution
    Architect, DXC Technology**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/), DXC Technology
    首席解决方案架构师**'
- en: 1\. Introduction
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The use of Machine Leaning (ML) has increased substantially in enterprise data
    analytics scenarios to extract valuable insights from the business data. Hence,
    it is very important to have an ecosystem to build, test, deploy, and maintain
    the enterprise grade machine learning models in production environments. The ML
    model development involves data acquisition from multiple trusted sources, data
    processing to make suitable for building the model, choose algorithm to build
    the model, build model, compute performance metrics and choose best performing
    model. The model maintenance plays critical role once the model is deployed into
    production. The maintenance of machine learning model includes keeping the model
    up to date and relevant in tune with the source data changes as there is a risk
    of model becoming outdated in course of time. Also, the configuration management
    of ML model play an important role in model management as the number of models
    grow. This article focuses on principles and industry standard practices, including
    the tools and technologies used for ML model development, deployment, and maintenance
    in an enterprise environment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）的使用在企业数据分析场景中显著增加，以从业务数据中提取有价值的洞见。因此，在生产环境中建立、测试、部署和维护企业级机器学习模型的生态系统非常重要。ML
    模型开发涉及从多个可信来源获取数据、处理数据以适合构建模型、选择算法构建模型、建立模型、计算性能指标并选择最佳性能模型。一旦模型部署到生产中，模型维护扮演了关键角色。机器学习模型的维护包括使模型保持最新，并与源数据变化保持相关，因为模型有过时的风险。此外，随着模型数量的增加，ML
    模型的配置管理在模型管理中也发挥着重要作用。本文重点介绍原则和行业标准实践，包括在企业环境中用于 ML 模型开发、部署和维护的工具和技术。
- en: 2\. Model Development
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 模型开发
- en: '**Machine Learning (ML) Model Lifecycle** refers to the process that covers
    right from source data identification to model development, model deployment and
    model maintenance. At high level, the entire activities fall under two broad categories,
    such as ML Model Development and ML Model Operations.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型生命周期** 指的是从源数据识别到模型开发、模型部署和模型维护的整个过程。从高层次看，所有活动大致分为两个主要类别，如 ML
    模型开发和 ML 模型操作。'
- en: '**Machine Learning (ML) model development** includes a series of steps as mentioned
    in the Fig. 1.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型开发** 包括图 1 中提到的一系列步骤。'
- en: '![Figure](../Images/65ad4640976073749d0b838990e29200.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/65ad4640976073749d0b838990e29200.png)'
- en: '**Fig 1:** Machine Learning (ML) Model Development Lifecyle'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1:** 机器学习（ML）模型开发生命周期'
- en: The ML model development lifecycle steps can be broadly classified as – data
    exploration, model building, model hyperparameters tuning and model selection
    with optimum performance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ML 模型开发生命周期步骤大致可以分为：数据探索、模型构建、模型超参数调整和性能最优的模型选择。
- en: '**Exploratory data analysis** is an important step that starts once business
    hypothesis is ready. This step takes 40-50% of total project time as the model
    outcome depends on the quality of input data being fed to train the model. Exploratory
    data analysis involves data attributes identification, data preprocessing and
    feature engineering. Attributes’ identification involves identification of predictor/features
    variables (inputs) and target/class variable (output), along its data types (string
    or numeric or datetime) and classification of features into categorical and continuous
    variables that helps in applying appropriate treatment to be given to the variable
    by the algorithm while building the model. Data pre-processing involves identification
    of missing values and outliers and fill these gaps by computing mean or median
    for quantitative attributes and mode for qualitative attributes of data to improve
    the predictive power of model. The outliers cause increased mean and standard
    deviation, that can be eliminated by taking natural log value which reduces the
    variation caused by extreme values.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析**是一个重要的步骤，它在商业假设准备好后开始。这个步骤占据了整个项目时间的40-50%，因为模型的结果依赖于输入数据的质量。探索性数据分析涉及数据属性识别、数据预处理和特征工程。属性识别包括预测变量/特征变量（输入）和目标/分类变量（输出）的识别，以及其数据类型（字符串、数值或日期时间），并将特征分类为类别变量和连续变量，这有助于在构建模型时算法对变量进行适当的处理。数据预处理包括识别缺失值和异常值，并通过计算定量属性的均值或中位数以及定性属性的众数来填补这些空缺，以提高模型的预测能力。异常值会导致均值和标准差的增加，通过取自然对数值可以消除这些异常值，从而减少极端值引起的变异。'
- en: '**Feature Engineering** is the next most important step in exploratory data
    analysis where the raw dataset is processed to convert data types of string or
    datetime or numeric ones to numeric vectors for an ML algorithm to understand
    and build efficient predictive model. Also, the labelled categorical data (e.g.,
    color red, green, blue; performance → poor, fair, good, very good, excellent;
    risk → low, medium, high; status → started, in-progress, on-hold, closed; gender
    → male/female; is_loan_approved/is_claim_fraudulent → yes/no) cannot be understood
    by an ML algorithm in its true context, hence it is required to be converted into
    numeric data. Feature Encoding is the widely used technique to transform the categorical
    data into continuous (numerical) values, e.g., Encode color as 1,2,3; performance
    as 1,2,3,4,5; risk as 1,2,3; status as 1,2,3,4; gender / is_loan_approved / is_claim_fraudulent
    as 0/1 etc. It is recommended to use label encoding in case categorical variables
    have no ordered relationship (e.g., color and status), ordinal encoding in case
    categorical variables have an ordered relationship (e.g., performance, risk) and
    one hot encoding in case categorical variable data is binary in nature (e.g.,
    gender, is_loan_approved, is_claim_fraudulent). A set of libraries are available
    in R or Python to implement these encoding methods. In some cases, a set of dummy
    variables or derived variables are created, especially in handling ‘date’ data
    types. Once the categorical text data is converted into numeric data, the data
    is ready to be fed to the model; As a last step, it is required to choose the
    appropriate features that help in improving the accuracy of model, by using the
    techniques such as Univariate Selection (statistical measure), Feature Importance
    (model property) and Correlation Matrix (identifies which features are most related
    to the target variable). These methods detect Collinearity between two variables
    where they are highly correlated and contain similar information about the variance
    within a given dataset. One may find the Variance Inflation Factor (VIF) useful
    to detect Multicollinearity where highly correlated three or more variables are
    included in the model. The key points in exploratory data analysis are represented
    in Fig.2, as shown below.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**是探索性数据分析中的下一个重要步骤，在此过程中，原始数据集被处理以将字符串、日期时间或数值类型的数据转换为数值向量，以便机器学习算法理解并构建高效的预测模型。此外，带标签的类别数据（例如，颜色：红色、绿色、蓝色；表现：差、一般、好、非常好、优秀；风险：低、中、高；状态：已开始、进行中、暂停、已关闭；性别：男性/女性；是否批准贷款/是否欺诈索赔：是/否）在机器学习算法中不能被正确理解，因此需要转换为数值数据。特征编码是将类别数据转换为连续（数值）值的广泛使用的技术，例如，将颜色编码为1、2、3；表现编码为1、2、3、4、5；风险编码为1、2、3；状态编码为1、2、3、4；性别/是否批准贷款/是否欺诈索赔编码为0/1等。推荐在类别变量没有顺序关系的情况下使用标签编码（例如，颜色和状态），在类别变量有顺序关系的情况下使用有序编码（例如，表现、风险），在类别变量数据是二元性质的情况下使用独热编码（例如，性别、是否批准贷款、是否欺诈索赔）。在R或Python中有一系列库可用于实现这些编码方法。在某些情况下，尤其是在处理“日期”数据类型时，会创建一组虚拟变量或派生变量。一旦将类别文本数据转换为数值数据，数据就可以输入到模型中；最后一步是选择适当的特征，以帮助提高模型的准确性，使用的方法包括单变量选择（统计度量）、特征重要性（模型属性）和相关矩阵（识别哪些特征与目标变量最相关）。这些方法检测两个变量之间的共线性，即它们高度相关并包含关于给定数据集中的方差的相似信息。可以使用方差膨胀因子（VIF）来检测多重共线性，其中三个或更多高度相关的变量被纳入模型中。探索性数据分析中的关键点在下图（图
    2）中表示。'
- en: '![Figure](../Images/d185e9dfbfb0d279fbe7c621987ac415.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/d185e9dfbfb0d279fbe7c621987ac415.png)'
- en: '**Fig 2:** Exploratory Data Analysis'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2：** 探索性数据分析'
- en: '**Building an ML Model** requires splitting of data into two sets, such as
    ‘training set’ and ‘testing set’ in the ratio of 80:20 or 70:30; A set of supervised
    (for labelled data) and unsupervised (for unlabeled data) algorithms are available
    to choose from depending on the nature of input data and business outcome to predict.
    In case of labelled data, it is recommended to choose logistic regression algorithm
    if the outcome to predict is of binary (0/1) in nature; choose decision tree classifier
    (or) Random Forest® classifier (or) KNN if the outcome to predict is of multi-class
    (1/2/3/...) in nature; and choose linear regression algorithm (e.g., decision
    tree regressor, random forest regressor) if the outcome to predict is continuous
    in nature. The clustering (Unsupervised) algorithm is preferred to analyze unlabeled
    / unstructured (text) data (e.g., k-means clustering). Artificial Neural Network
    (ANN) algorithms are suggested to analyze other unstructured (image/voice) data
    types, such as Convolutional Neural Networks (CNN) for image recognition and Recurrent
    Neural Networks (RNN) for voice recognition and Natural Language Processing (NLP).
    The model is built using training dataset and make prediction using test dataset.
    Use of deep learning (neural networks) models is preferred over regression models
    (ML models) for better performance as these models introduce extra layer of non-linearity
    with the introduction of Activation Function (AF). The algorithm selection under
    various scenarios has been represented in Fig.3, as shown below.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建机器学习模型** 需要将数据分为两组，例如按80:20或70:30的比例分为“训练集”和“测试集”；根据输入数据的性质和业务结果的预测，可以选择一组监督（用于有标签数据）和无监督（用于无标签数据）算法。如果是有标签数据，如果预测的结果是二元（0/1）性质，建议选择逻辑回归算法；如果预测的结果是多类（1/2/3/...）性质，则选择决策树分类器（或）随机森林®分类器（或）KNN；如果预测的结果是连续性数据，则选择线性回归算法（例如，决策树回归器、随机森林回归器）。对于无标签/非结构化（文本）数据，建议使用聚类（无监督）算法（例如，k-means聚类）。建议使用人工神经网络（ANN）算法来分析其他非结构化（图像/语音）数据类型，例如用于图像识别的卷积神经网络（CNN）和用于语音识别及自然语言处理（NLP）的递归神经网络（RNN）。模型使用训练数据集进行构建，并使用测试数据集进行预测。相比回归模型（机器学习模型），推荐使用深度学习（神经网络）模型来获得更好的性能，因为这些模型通过引入激活函数（AF）增加了额外的非线性层。不同场景下的算法选择在图3中表示，如下所示。'
- en: '![Figure](../Images/fcbcb5d5eb3c35362f7a46ed449200f8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/fcbcb5d5eb3c35362f7a46ed449200f8.png)'
- en: '**Fig 3:** Choose Right Algorithm'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3：** 选择正确的算法'
- en: '**Computation of Model Performance** is next logical step to choose the right
    model. The model performance metrics will decide on final model selection, that
    include computation of accuracy, precision, recall, F1 score (weighted average
    of precision and recall) , along with confusion matrix for classification models
    and co-efficient of determination for regression models. It is not recommended
    to use accuracy as a measure to determine the performance of classification models
    that are trained with imbalanced/skewed datasets, rather precision and recall
    are recommended to be computed to choose right classification model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能计算** 是选择正确模型的下一个逻辑步骤。模型性能指标将决定最终模型选择，包括计算准确性、精确度、召回率、F1分数（精确度和召回率的加权平均），以及分类模型的混淆矩阵和回归模型的决定系数。对于用不平衡/偏斜数据集训练的分类模型，不建议使用准确性作为衡量标准，而是建议计算精确度和召回率，以选择正确的分类模型。'
- en: '**Model Hyperparameters Tuning** is highly recommended step in the process,
    continue till the model performance reach around 80%-85%. For example, the Random
    Forest algorithm takes maximum depth, maximum number of features, number of trees
    etc., as hyperparameters which can be intuitively tuned for improving model accuracy.
    Similarly, Neural Networks algorithm takes number of layers, batch size, number
    of epochs, number of samples etc. It is recommended to use Grid-search method
    to find the optimal hyperparameters of a model which results in the most ‘accurate’
    predictions. Besides this, it is also recommended to perform cross-validation
    as sometimes improvement in model accuracy may be due to overfitting (too sensitive
    model, unable to generalize) or underfitting (very generalized model) of model,
    using k-fold cross validation technique. To avoid overfitting, increase training
    data sample size that introduces more patterns or, reduce number of features that
    avoids complexity or, perform data regularization data using Ridge and Lasso regularization
    methods that reduces error/penalty. Similarly, to avoid underfitting, increase
    model complexity such as moving from linear to non-linear or adding more hidden
    layers (epochs) to neural network or add more features that introduce hidden patterns.
    However, adding more data volume does not solve the problem of underfitting, rather
    it hampers the model performance.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型超参数调优** 是流程中非常推荐的步骤，持续进行直到模型性能达到大约80%-85%。例如，随机森林算法使用最大深度、最大特征数、树的数量等作为超参数，这些可以直观地调整以提高模型准确性。类似地，神经网络算法使用层数、批量大小、训练轮数、样本数量等。建议使用网格搜索方法来寻找模型的最佳超参数，以获得最‘准确’的预测。此外，还推荐进行交叉验证，因为模型准确性的提升有时可能由于过拟合（模型过于敏感，无法泛化）或欠拟合（模型过于泛化），使用k折交叉验证技术可以解决这一问题。为了避免过拟合，可以增加训练数据样本量以引入更多模式，或减少特征数量以避免复杂性，或使用岭回归和套索回归方法进行数据正则化以减少误差/惩罚。同样，为了避免欠拟合，可以增加模型复杂性，例如从线性模型转为非线性模型，或为神经网络添加更多隐藏层（训练轮次），或添加更多特征以引入隐藏模式。然而，增加数据量并不能解决欠拟合问题，反而会影响模型性能。'
- en: Finally. choose the model with optimum performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，选择性能最佳的模型。
- en: '**ML Model Development Best Practices:** The recommended ML Model Development
    Best Practices are (1) Perform clear hypothesis for the identified business problem
    before attributes identification itself; (2) Build the model using a basic algorithm
    first, like a logistic regression or decision tree and compile performance metrics,
    that gives enough confidence about relevance of data before going for a fancier
    algorithms, like neural networks; (3) Keep intermediate checkpoints in building
    the model to keep track of its model hyperparameters and its associated performance
    metrics that gives an ability to train the model incrementally and make good judgement
    when it comes to performance vs training time; (4) Use real-world production data
    for training the model to improve correctness of predictions.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习模型开发最佳实践：** 推荐的机器学习模型开发最佳实践包括：（1）在属性识别之前，针对已识别的业务问题制定明确的假设；（2）首先使用基础算法构建模型，例如逻辑回归或决策树，并编译性能指标，这可以在使用更复杂的算法（如神经网络）之前，提供足够的数据相关性信心；（3）在构建模型过程中保持中间检查点，以跟踪模型超参数及其相关性能指标，这可以使模型逐步训练，并在性能与训练时间之间做出良好判断；（4）使用真实生产数据进行模型训练，以提高预测的正确性。'
- en: Model Operations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型操作
- en: '**Machine Leaning (ML) Model Operations** refers to implementation of processes
    to maintain the ML models in production environments. The common challenge encountered
    in a typical enterprise scenario is that the ML models worked in lab environment
    will remain stay at the proof-of-concept stage in many cases. If the model is
    rolled out into production, it becomes stale due to frequent source data changes
    that requires rebuilding of model. As the models are retrained multiple times,
    it is required to keep track for model performance and corresponding features
    and hyperparameters that are used for retraining the model. To perform all these
    operations, there should be a well-defined reproducible process in-place to implement
    the end-to-end machine learning operations (MLOps) that keeps the model current
    and accurate in production environment. The ML model operations lifecycle process
    is as shown in Fig. 4 that covers entire process of model development to model
    deployment to model performance monitoring in a seamless manner.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习 (ML) 模型操作** 指的是实施过程以维护生产环境中的 ML 模型。在典型企业场景中，常见的挑战是实验室环境中的 ML 模型在很多情况下停留在概念验证阶段。如果模型被推出到生产环境中，它会因为频繁的数据源变化变得过时，这需要重新构建模型。由于模型会被多次重新训练，需要跟踪模型性能及用于重新训练模型的相应特征和超参数。为了执行所有这些操作，应当有一个定义明确的可重复过程来实现端到端的机器学习操作
    (MLOps)，以保持模型在生产环境中的最新和准确。ML 模型操作生命周期过程如图 4 所示，涵盖了从模型开发到模型部署，再到模型性能监控的整个过程，确保其无缝衔接。'
- en: '![Figure](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
- en: '**Fig 4:** Machine Learning (ML) Model Operations Lifecyle'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4：** 机器学习 (ML) 模型操作生命周期'
- en: The model retraining is very important at regular intervals, say fortnightly
    or monthly or quarterly or on-demand basis as it is very likely that the underlying
    source data will change over a period in the real-world scenario. A cron job is
    scheduled to retrain the model at the predefined intervals, or as and when the
    source data is changed, or as and when the model performance is degraded. There
    could be some changes to the model code due to hyperparameter tuning during model
    re-training.it is required to automate these model operations by having an automated
    model pipeline.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 定期重新训练模型非常重要，例如每两周、每月、每季度或按需进行，因为在实际场景中，底层数据源很可能会随着时间发生变化。可以通过定时任务在预定的间隔时间内重新训练模型，或者在数据源变化时，或在模型性能下降时重新训练模型。模型代码可能会因超参数调整而有所变化，因此需要通过自动化模型管道来自动化这些模型操作。
- en: The typical automated model pipeline in enterprise production environments include
    3 types of stores, such as **feature store****,** **metadata store and model registry**.
    The **feature store** contains data extracted from various source systems and
    transformed into the features as required by the model. The ML pipeline takes
    the data in batches from the feature store to train the model. The **metadata
    store** is a centralized model tracking (bookkeeping) system, maintained at the
    enterprise level, contains the model metadata at each stage of pipeline. The model
    metadata store facilitates the model stage transition, say from staging to production
    to archived. The model training is performed in one environment and deployment
    in other environments where the model inference will be performed just by specifying
    the remote model file path. The model metadata store is used for model experiments
    tracking and compare model experiments w.r.t. its performance. The model metadata
    includes training data set version, links to training runs and experiments. The
    **model registry** contains data of all trained models such as trained model version,
    model training date, model training metrics, hyperparameters used for training
    the model, predicted outcomes, and diagnostic charts (confusion matrix, ROC curves).
    The appropriate model will be picked from the model registry based on the intended
    target user’s requirement. The model metadata store & model registry can be implemented
    (custom) using a light-weight database, such as SQLite and a set of python functions;
    or a set of open-source/proprietary products, such as MLflow (community edition/managed
    service from Databricks). This tool provides an ability to manage models using
    a GUI or a set of APIs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业生产环境中，典型的自动化模型管道包括 3 种类型的存储，例如**特征存储**、**元数据存储和模型注册中心**。**特征存储**包含从各种源系统提取的数据，并转换为模型所需的特征。机器学习管道从特征存储中批量获取数据以训练模型。**元数据存储**是一个集中式模型跟踪（记录）系统，在企业级维护，包含管道每个阶段的模型元数据。模型元数据存储促进模型阶段的过渡，例如从暂存到生产到归档。模型训练在一个环境中进行，而部署在另一个环境中进行，只需指定远程模型文件路径即可执行模型推断。模型元数据存储用于跟踪模型实验并根据其性能比较模型实验。模型元数据包括训练数据集版本、训练运行和实验的链接。**模型注册中心**包含所有训练模型的数据，如训练模型版本、模型训练日期、模型训练指标、用于训练模型的超参数、预测结果和诊断图表（混淆矩阵、ROC
    曲线）。将根据目标用户的需求从模型注册中心中选择适当的模型。模型元数据存储和模型注册中心可以使用轻量级数据库（如 SQLite）和一组 python 函数，或一组开源/专有产品（如
    MLflow（社区版/Databricks 提供的托管服务））来实现。该工具提供了通过 GUI 或一组 API 管理模型的功能。
- en: '**Model Deployment:** The models can be deployed in production environments
    to perform prediction either in batch inference mode or on-line inference mode.
    The batch inference can be achieved by scheduling as a job to run at a time interval
    and send the results via email to the intended users. The on-line inference can
    be achieved by exposing the model as a web service using frameworks such as python
    flask library or streamlit library to develop interactive web applications and
    invoke the model using its HTTP endpoint.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型部署：** 模型可以在生产环境中进行部署，以执行批量推断模式或在线推断模式。批量推断可以通过安排任务在特定时间间隔运行，并通过电子邮件将结果发送给目标用户来实现。在线推断可以通过将模型公开为网络服务来实现，使用如
    python flask 库或 streamlit 库来开发交互式 Web 应用程序，并通过 HTTP 端点调用模型。'
- en: '**Model Packaging/Distribution:** The trained ML model is serialized into various
    formats to be able to distribute the model for deployment into TEST/PROD environments.
    The most common formats are pickle (for machine learning or deep learning models
    developed in python), ONNX (Open Neural Network Exchange format, for deep learning
    models), and PMML(Predictive Model Markup Language XML-based format, specifically
    for models developed using logistic regression and neural networks). The model
    can be packaged as a .jar file or as a docker container image and deployed as
    a prediction service into production.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型打包/分发：** 训练好的机器学习模型被序列化成各种格式，以便将模型分发到 TEST/PROD 环境中进行部署。最常见的格式有 pickle（用于在
    python 中开发的机器学习或深度学习模型）、ONNX（开放神经网络交换格式，用于深度学习模型）和 PMML（预测模型标记语言基于 XML 的格式，专门用于使用逻辑回归和神经网络开发的模型）。模型可以打包为
    .jar 文件或 docker 容器镜像，并作为预测服务部署到生产环境中。'
- en: '**Model Containerization** can be achieved by building a docker image, bundled
    with training and inference code, along with the necessary training and testing
    data and the model file for future predictions. Once the docker file is created
    bundled with necessary ML model, a CI/CD pipeline can be built using a tool, such
    as Jenkins. This docker container image can be exposed as a REST API, so that
    any external stakeholders can consume this ML model, either from on-premises or
    public cloud (in case of high compute requirements for building a deep learning
    model). In case of packaging and managing multiple docker containers, **Kubeflow**,
    the ML toolkit for Kubernetes can be used.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型容器化**可以通过构建一个包含训练和推理代码的 Docker 镜像来实现，并且将必要的训练和测试数据以及模型文件一起打包以用于未来的预测。一旦创建了包含必要机器学习模型的
    Docker 文件，就可以使用诸如 Jenkins 之类的工具构建 CI/CD 流水线。这个 Docker 容器镜像可以作为 REST API 进行暴露，以便任何外部利益相关者都可以从本地或公共云（在构建深度学习模型时计算需求较高的情况下）访问这个机器学习模型。在包装和管理多个
    Docker 容器的情况下，可以使用 **Kubeflow**，这是一个适用于 Kubernetes 的机器学习工具包。'
- en: '**Model Performance Monitoring** is an important activity where the predicted
    outcome (e.g., predicted sale price of an item) vs. actual value (actual sale
    price) is continuously monitored. And it is recommended to understand the end
    users’ reaction to the final predictions. In some scenarios, it is recommended
    to keep old model and new model running in-parallel to understand the variation
    in performance in both the models (model validation). It is mandatory to address
    performance degradation that arise due to ‘data drift’ (underlying source data
    pattern changes due to seasonality and trend, e.g., year-end sales data (or) addition
    of new categories (or) one particular attribute is not being generated by the
    upstream systems) and ‘model drift’ (statistical properties of target variable
    changes, e.g., definition of a fraudulent transaction itself changes). The most
    accurate way to measure the model drift is by measuring the F1 Score that combines
    the precision and the recall of a classifier into a single metric by taking their
    harmonic mean. The model will be retrained as an when the model drift (F1 Score)
    falls below certain threshold or at regular intervals (batch mode) or train the
    model as soon as the data is available (online training). It is very important
    to collect model logs and prediction logs by using popular logging tools such
    as elasticstack, and fluentd.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能监控**是一项重要活动，其中预测结果（例如，项目的预测销售价格）与实际值（实际销售价格）会持续进行监控。同时建议了解最终预测的最终用户反应。在某些场景下，建议保持旧模型和新模型并行运行，以了解两种模型的性能变化（模型验证）。必须解决由于“数据漂移”（由于季节性和趋势导致的底层源数据模式变化，例如年终销售数据（或）新增类别（或）某个属性未由上游系统生成）和“模型漂移”（目标变量的统计属性变化，例如欺诈交易的定义本身发生变化）而导致的性能下降。测量模型漂移的最准确方法是通过测量
    F1 分数，该分数将分类器的精确度和召回率结合成一个单一指标，并取其调和均值。模型会在模型漂移（F1 分数）低于某个阈值时，或在定期间隔（批处理模式）时，或一旦数据可用时（在线训练）进行重新训练。使用流行的日志记录工具如
    elasticstack 和 fluentd 来收集模型日志和预测日志是非常重要的。'
- en: '**Model version management** is a mandatory activity in ML model management
    as the model will be retrained at regular intervals due to changes in the underlying
    source data or as demanded by audit and compliance purposes. The source data,
    the model training scripts, model experiment, and the trained model are versioned
    together in the code repository. There are open-source tools available, such as
    Data Version Control (DVC) or AWS CodeCommit that uses Git as underlying code
    repository for model version management purposes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型版本管理**是机器学习模型管理中的一项强制性活动，因为模型会由于底层源数据的变化或审计和合规要求定期进行重新训练。源数据、模型训练脚本、模型实验和训练好的模型都在代码仓库中进行版本管理。现在有一些开源工具可用，如数据版本控制（Data
    Version Control，DVC）或 AWS CodeCommit，它们使用 Git 作为底层代码仓库来进行模型版本管理。'
- en: '**ML Project Development Roles:** There are various roles involved in implementing
    ML model development and operations. Data Engineer analyzes the business data
    from various sources and ensures right and up-to-date data is accessible at the
    required granularity and quality in cost effective way. Data Scientists look at
    the data, performs data pre-processing and feature engineering, model building
    and choose right model that best fits the predictive/prescriptive requirements
    of business. Usually, Data Scientists take hypothesis-based approach to choose
    the model that fits the requirements. ML Engineer makes sure that the built model
    is giving the results reliably and assess the need for re-training the model by
    monitoring its outcome. Web App Developer builds the required presentation layer
    component to invoke and present the results to the intended stakeholders. The
    ML projects also require DevOps engineers to enable continuous delivery and data
    visualization experts to produce fancy dashboards.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**ML 项目开发角色：** 在实现 ML 模型开发和操作过程中涉及各种角色。数据工程师分析来自不同来源的业务数据，确保以成本有效的方式访问正确且最新的数据，且数据具有所需的粒度和质量。数据科学家查看数据，进行数据预处理和特征工程、模型构建，并选择最符合业务预测/处方要求的模型。通常，数据科学家采用基于假设的方法选择适合要求的模型。ML
    工程师确保构建的模型可靠地提供结果，并通过监控结果来评估是否需要重新训练模型。Web 应用开发人员构建所需的展示层组件，以调用和向相关利益相关者展示结果。ML
    项目还需要 DevOps 工程师以实现持续交付，并需要数据可视化专家以生成精美的仪表板。'
- en: '**ML Model Deployment Best Practices:** The recommended model deployment best
    practices are (1) Automate the steps required for ML model development and deployment,
    by leveraging DevOps tools that gives some extra time for model retraining; (2)
    Perform continuous model testing, performance monitoring and retraining after
    its production deployment to keep the model relevant/current as the source data
    changes to predict the desired outcome(s); (3) Implement logging while exposing
    ML models as APIs, that includes capturing input features/model output (to track
    model drift), application context (for debugging production errors), model version
    (if multiple re-trained models are deployed in production); (4) Manage all the
    model metadata in a single repository.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**ML 模型部署最佳实践：** 推荐的模型部署最佳实践是 (1) 自动化 ML 模型开发和部署所需的步骤，通过利用 DevOps 工具为模型重新训练提供额外的时间；(2)
    在生产部署后执行持续的模型测试、性能监控和重新训练，以保持模型的相关性/当前性，因为源数据的变化可能会影响预测结果；(3) 在将 ML 模型暴露为 API
    时实现日志记录，包括捕获输入特征/模型输出（以跟踪模型漂移）、应用上下文（用于调试生产错误）、模型版本（如果生产中部署了多个重新训练的模型）；(4) 在单一存储库中管理所有模型元数据。'
- en: '**Bio: [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/)** works with
    an IT company ([DXC Technology](https://dxc.com/us/en), erstwhile CSC India Limited))
    as Principal Solution Architect. Suresh comes with 20+ years of IT experience,
    focusing on Data Architecture, Big Data Analytics, Artificial Intelligence and
    Machine Learning. He has been involved in building Data & Analytics solutions
    to his customers across various domains such as Banking, Finance, and Insurance,
    including AI/ML for various insurance industry scenarios and presented them in
    various technology forums with in DXC. Suresh has also published a [paper](https://ieeexplore.ieee.org/document/7823950)
    in an IEEE Data Science conference conducted in India.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [苏雷什·亚拉姆](https://www.linkedin.com/in/sureshyaram/)** 在一家 IT 公司（[DXC
    Technology](https://dxc.com/us/en)，前身为 CSC India Limited）担任首席解决方案架构师。苏雷什拥有 20
    多年的 IT 经验，专注于数据架构、大数据分析、人工智能和机器学习。他参与了为客户在银行、金融和保险等多个领域构建数据与分析解决方案，包括针对保险行业场景的
    AI/ML，并在 DXC 的各种技术论坛上进行了展示。苏雷什还在印度举行的 IEEE 数据科学会议上发表了一篇 [论文](https://ieeexplore.ieee.org/document/7823950)。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Overview of Different Approaches to Deploying Machine Learning Models in Production](/2019/06/approaches-deploying-machine-learning-production.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[部署机器学习模型到生产环境的不同方法概述](/2019/06/approaches-deploying-machine-learning-production.html)'
- en: '[Overview of MLOps](/2021/03/overview-mlops.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 概述](/2021/03/overview-mlops.html)'
- en: '[MLOps is an Engineering Discipline: A Beginner’s Overview](/2021/07/mlops-engineering-discipline.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 是一门工程学科：初学者概述](/2021/07/mlops-engineering-discipline.html)'
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，然后寻找目的…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
