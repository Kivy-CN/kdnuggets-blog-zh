["```py\n!pip install datasets\nimport datasets\n```", "```py\nfrom datasets import list_datasets\nlist_datasets()\n```", "```py\ndata = load_dataset(\"jeffnyman/emotions\")\n```", "```py\nDatasetDict({\ntrain: Dataset({\nfeatures: ['text', 'label'],\nnum_rows: 16000\n})\nvalidation: Dataset({\nfeatures: ['text', 'label'],\nnum_rows: 2000\n})\ntest: Dataset({\nfeatures: ['text', 'label'],\nnum_rows: 2000\n})\n})\n```", "```py\ntrain_data = all_data[\"train\"]\n```", "```py\nlen(train_data)\n```", "```py\n16000\n```", "```py\ntrain_data[3]\n```", "```py\n{'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n'label': 2}\n```", "```py\nprint(train_ds[:100])\n```", "```py\n{'text': ['i didnt feel humiliated', ...],\n'label': [0, ...]}\n```", "```py\ntrain_data[3][\"text\"]\n```", "```py\nurl = \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\ndataset = load_dataset('csv', data_files=url)\n```", "```py\npenguins = dataset[\"train\"].to_pandas()\npenguins.head()\n```"]