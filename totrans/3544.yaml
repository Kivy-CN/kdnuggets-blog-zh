- en: 'Interview: Arno Candel, H2O.ai on the Basics of Deep Learning to Get You Started'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2015/01/interview-arno-candel-0xdata-deep-learning.html](https://www.kdnuggets.com/2015/01/interview-arno-candel-0xdata-deep-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![arno-candel-h2o](../Images/915c9cd9cd7e3bbf26e24989162a0a16.png)**Dr. Arno
    Candel**](https://www.linkedin.com/in/candel) is a Physicist & Hacker at [**H2O.ai**](http://h2o.ai/).
    Prior to that, he was a founding Senior MTS at Skytree where he designed and implemented
    high-performance machine learning algorithms. He has over a decade of experience
    in high-performance computing and had access to the world’s largest supercomputers
    as a Staff Scientist at SLAC National Accelerator Laboratory where he participated
    in U.S. DOE scientific computing initiatives and collaborated with CERN. Arno
    has authored dozens of scientific papers and is a sought-after conference speaker.'
  prefs: []
  type: TYPE_NORMAL
- en: He holds a PhD and Masters summa cum laude in Physics from ETH Zurich. Arno
    was named [2014 Big Data All-Star](http://fortune.com/2014/08/03/meet-fortunes-2014-big-data-all-stars/)
    by Fortune Magazine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my interview with him:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Anmol Rajpurohit](http://www.linkedin.com/inviteFromProfile?from=profile&key=60636115&firstName=Anmol&lastName=Rajpurohit):
    Q1\. How do you define Deep Learning? How do you differentiate it from the rest
    of Machine Learning technologies?**'
  prefs: []
  type: TYPE_NORMAL
- en: '![deep-learning](../Images/3d42302764687297c91a0081ec4d6ba0.png)[**Dr. Arno
    Candel**](https://www.linkedin.com/in/candel): Deep Learning methods use a composition
    of multiple non-linear transformations to model high-level abstractions in data.
    [M](https://en.wikipedia.org/wiki/Feedforward_neural_network)[ulti-layer feed-forward](https://en.wikipedia.org/wiki/Feedforward_neural_network)
    [artificial n](https://en.wikipedia.org/wiki/Feedforward_neural_network)[eural
    networks](https://en.wikipedia.org/wiki/Feedforward_neural_network) are some of
    the oldest and yet most useful such techniques. We are now reaping the benefits
    of over [60 years of evolution in Deep Learning](http://arxiv.org/abs/1404.7828)
    that began in the late 1950s when the term [*Machine Learning*](https://en.wikipedia.org/wiki/Machine_learning)
    was coined. Large parts of the growing success of Deep Learning in the past decade
    can be attributed to Moore’s law and the exponential speedup of computers, but
    there were also many algorithmic breakthroughs that enabled robust training of
    deep learners.'
  prefs: []
  type: TYPE_NORMAL
- en: Compared to more interpretable Machine Learning techniques such as tree-based
    methods, conventional Deep Learning (using [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)
    and [back-propagation](https://en.wikipedia.org/wiki/Backpropagation)) is a rather
    “brute-force” method that optimizes lots of coefficients (it is a *parametric*
    method) starting from random noise by continuously looking at examples from the
    training data. It follows the basic idea of “(good) practice makes perfect” (similar
    to a real brain) without any strong guarantees on the quality of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Today’s typical Deep Learning models have thousands of neurons and learn millions
    of free parameters (connections between neurons), and yet are not even rivaling
    the size of a fruit fly’s brain in terms of neurons (~100,000). The most advanced
    dedicated Deep Learning systems are learning tens of billions of parameters, which
    is still about 10,000x less than the number of neuron connections in a human brain.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, even some remarkably small Deep Learning models already outperform
    humans in many tasks, so the space of Artificial Intelligence is definitely getting
    more interesting.
  prefs: []
  type: TYPE_NORMAL
- en: '**AR: Q2\. What characteristics enable Deep Learning to deliver such superior
    results for standard Machine Learning problems? Is there a specific subset of
    problems for which Deep Learning is more effective than other options?**'
  prefs: []
  type: TYPE_NORMAL
- en: '**AC:** Deep Learning is really effective at [learning non-linear derived features](http://www.slideshare.net/0xdata/mlconfsfh2odeeplearningarnocandel111414/21)
    from the raw input features, unlike standard Machine Learning methods such as
    linear or tree-based methods. For example, if age and income are the two features
    used to predict spending, then a linear model would greatly benefit from [manually
    splitting](https://www.kaggle.com/c/avazu-ctr-prediction/forums/t/10821/beat-the-benchmark-with-h2o-lb-0-4033703)
    age and income ranges into distinct groups; while a tree-based model would learn
    to automatically dissect the two-dimensional space.'
  prefs: []
  type: TYPE_NORMAL
- en: A Deep Learning model builds hierarchies of (hidden) derived non-linear features
    that get composed to approximate arbitrary functions such as sqrt((*age-40)*^2+0.3*log(*income+1)*-4)
    with much less effort than with other methods. Traditionally, data scientists
    [perform many of these transformations explicitly](http://learn.h2o.ai/content/hands-on_training/tools.html)
    based on domain knowledge and experience, but [Deep Learning has been shown to
    be](https://www.youtube.com/watch?v=1FWmd7LKUbk&index=33) [extremely](https://www.youtube.com/watch?v=1FWmd7LKUbk&index=33)
    [effective](https://www.youtube.com/watch?v=1FWmd7LKUbk&index=33) at coming up
    with those transformations, often outperforming standard Machine Learning models
    by a substantial margin.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning is also very good at [predicting high-cardinality class memberships](http://www.slideshare.net/0xdata/mlconfsfh2odeeplearningarnocandel111414/17),
    such as in image or voice recognition problems, or in predicting the best item
    to recommend to a user. Another strength of Deep Learning is that it can also
    be used for unsupervised learning where it *just* learns the intrinsic structure
    of the data without making predictions (remember the [Google cat](https://static.googleusercontent.com/media/research.google.com/en/us/archive/unsupervised_icml2012.pdf)?).
    This is useful in cases where there are no training labels, or for various other
    use cases such as [anomaly detection](http://learn.h2o.ai/content/hands-on_training/anomaly_detection.html).
  prefs: []
  type: TYPE_NORMAL
- en: '![anomaly-detection-h2o](../Images/8fed5b8a9dd0e5cc0c947dad9830eb56.png)'
  prefs: []
  type: TYPE_IMG
- en: '**AR: Q3\. What are the key components of H2O architecture? What are the unique
    advantages of using H2O for Deep Learning pursuits?**'
  prefs: []
  type: TYPE_NORMAL
- en: '![h2o](../Images/e7d951ab76eaa6088bbbb6944bd1134b.png)**AC:** H2O is unique
    in that it’s the [#1 Java-based open-source Machine Learning project](https://github.com/search?l=Java&o=desc&q=machine+learning&ref=searchresults&s=stars&type=Repositories)
    on [GitHub](https://github.com/h2oai/h2o) (and we’re in the final phases of a
    more [developer-friendly rewrite](https://github.com/h2oai/h2o-dev)). It is built
    on top of a distributed key-value store that’s based on the world’s fastest non-blocking
    hash table, written by our CTO and co-founder [Cliff Click](http://www.infoq.com/presentations/api-memory-analytics),
    who is known for his contributions to the fast Java HotSpot compiler.'
  prefs: []
  type: TYPE_NORMAL
- en: H2O is designed to process large datasets (e.g., from HDFS, S3 or NFS) at FORTRAN
    speeds using a [highly efficient (fine-grain) in-memory implementation of the
    famous Mapreduce paradigm with built-in lossless columnar compression](https://www.youtube.com/watch?v=WPGPiPGzVCs)
    (that often beats gzip on disk). H2O doesn’t require Hadoop, but it can be [launched
    on Hadoop clusters](https://www.youtube.com/watch?v=VHwJ117Nk9M) by MRv1, YARN
    or Mesos, for seamless data ingest from HDFS.
  prefs: []
  type: TYPE_NORMAL
- en: '![sparkling-water](../Images/b96b7edc1c85745fad7c4a0c31036377.png)[Sparkling
    Water](https://databricks.com/blog/2014/06/30/sparkling-water-h20-spark.html)
    tightly integrates the data pipelines in Apache Spark with H2O. In addition to
    native [Java](https://github.com/h2oai) and [Scala](https://github.com/h2oai/sparkling-water/tree/master/examples/src/main/scala/org/apache/spark/examples/h2o)
    APIs, H2O also provides a powerful REST API to connect from [R](http://h2o.gitbooks.io/h2o-and-r/),
    [Python](https://github.com/h2oai/h2o-dev/blob/master/h2o-py/src/main/py/deepLearningDemo.py),
    or [Tableau](https://www.youtube.com/watch?v=Mn8S0cTls9A) clients. It also powers
    our [easy-to-use Web API](http://0xdata.com/blog/2014/11/introducing-flow/) for
    interactive exploration of H2O’s capabilities. There''s also auto-generated Java
    code to [take the models directly into production](http://learn.h2o.ai/content/demos/streaming_data.html)
    (e.g., with Storm), which many enterprise customers find useful.'
  prefs: []
  type: TYPE_NORMAL
- en: 'H2O and its methods are also backed by [venture capital](https://www.youtube.com/watch?v=rAK5f6c-wTI&list=PLNtMya54qvOFQhSZ4IKKXRbMkyLMn0caa&index=16)
    and some of the most knowledgeable experts in Machine Learning: Stanford professors
    [Trevor Hastie](https://www.youtube.com/watch?v=wPqtzj5VZus&list=PLNtMya54qvOFQhSZ4IKKXRbMkyLMn0caa&index=15),
    [Rob Tibshirani](http://statweb.stanford.edu/~tibs/) and [Steven Boyd](http://stanford.edu/~boyd/).
    Other independent mentors include Java API expert [Josh Bloch](https://www.youtube.com/watch?v=ege-kub1qtk&list=PLNtMya54qvOFQhSZ4IKKXRbMkyLMn0caa&index=23)
    and Founder of S and R-core member [John Chambers](https://www.youtube.com/watch?v=UBMCqwa4UEI&list=PLNtMya54qvOFQhSZ4IKKXRbMkyLMn0caa&index=26).
    We’ve literally spent days discussing algorithms, APIs and code together, which
    is a great honor and privilege. Of course, customers and users from the open source
    community are constantly validating our algorithms as well.'
  prefs: []
  type: TYPE_NORMAL
- en: '![h2o-architecture](../Images/88b0f57ea2fef35c8caf13996a5c461d.png)'
  prefs: []
  type: TYPE_IMG
- en: For H2O Deep Learning, we put lots of little tricks together to make it a very
    powerful method right out of the box. For example, it features automatic adaptive
    weight initialization, automatic data standardization, expansion of categorical
    data, automatic handling of missing values, automatic adaptive learning rates,
    various regularization techniques, automatic performance tuning, load balancing,
    grid-search, N-fold cross-validation, checkpointing, and different distributed
    training modes on clusters for large datasets. And the best thing is that the
    user doesn’t need to know anything about Neural Networks, [there’s no complicated
    configuration files](https://www.youtube.com/watch?v=1FWmd7LKUbk&index=33&list=PLNtMya54qvOFQhSZ4IKKXRbMkyLMn0caa).
    It’s just as easy to train as a Random Forest and simply makes predictions for
    supervised regression or classification problems. For power users, there’s also
    quite a few (well-documented) options that enable fine-control of the learning
    process. By default, [H2O Deep Learning will fully utilize every single CPU core
    on your entire cluster](https://twitter.com/arnocandel/status/499715893505454080)
    and is [highly optimized](https://github.com/h2oai/h2o/blob/master/src/main/java/hex/deeplearning/Neurons.java#L1090-L1112)
    for maximum performance.
  prefs: []
  type: TYPE_NORMAL
- en: I share our CEO and co-founder [SriSatish Ambati](http://venturebeat.com/2014/11/07/h2o-funding/)’s
    vision that a whole ecosystem of smart applications can emerge from these recent
    advances in machine intelligence and fundamentally enrich our lives.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Second part of the interview**](/2015/01/interview-arno-candel-h20-deep-learning.html).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Arno Candel on How to Quick Start Deep Learning with H2O](/2015/01/interview-arno-candel-h20-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Arno Candel on the Journey from Physics to Machine Learning](/2015/01/interview-arno-candel-h2o-physics-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Research Leaders on Data Mining, Data Science, and Big Data key trends, top
    papers](/2015/01/research-leaders-data-science-big-data-key-trends-top-papers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[7 Beginner-Friendly Projects to Get You Started with ChatGPT](https://www.kdnuggets.com/2023/08/7-beginnerfriendly-projects-get-started-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Federated Learning: Collaborative Machine Learning with a Tutorial…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Upskilling in Data Vis Matters (& How to Get Started)](https://www.kdnuggets.com/2022/07/sphere-upskilling-data-vis-matters.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Benefits to A/B Testing (+ Where to Get Started)](https://www.kdnuggets.com/2022/08/sphere-3-benefits-ab-testing-get-started.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Free Must-Take Data Science Courses to Get Started](https://www.kdnuggets.com/10-free-must-take-data-science-courses-to-get-started)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Only Interview Prep Course You Need for Deep Learning](https://www.kdnuggets.com/the-only-interview-prep-course-you-need-for-deep-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
