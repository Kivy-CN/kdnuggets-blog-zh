- en: 'Thought Propagation: An Analogical Approach to Complex Reasoning with Large
    Language Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维传播：大型语言模型的类比推理方法
- en: 原文：[https://www.kdnuggets.com/thought-propagation-an-analogical-approach-to-complex-reasoning-with-large-language-models](https://www.kdnuggets.com/thought-propagation-an-analogical-approach-to-complex-reasoning-with-large-language-models)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/thought-propagation-an-analogical-approach-to-complex-reasoning-with-large-language-models](https://www.kdnuggets.com/thought-propagation-an-analogical-approach-to-complex-reasoning-with-large-language-models)
- en: '![Thought Propagation: An Analogical Approach to Complex Reasoning with Large
    Language Models](../Images/0312168e6257c21dcf33fe00142a7d83.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![思维传播：大型语言模型的类比推理方法](../Images/0312168e6257c21dcf33fe00142a7d83.png)'
- en: '## Key Takeaways'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '## 关键要点'
- en: Thought Propagation (TP) is a novel method that enhances the complex reasoning
    abilities of Large Language Models (LLMs).
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维传播（TP）是一种新颖的方法，可以提升大型语言模型（LLMs）的复杂推理能力。
- en: TP leverages analogous problems and their solutions to improve reasoning, rather
    than making LLMs reason from scratch.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP 利用类比问题及其解决方案来改善推理，而不是让 LLMs 从零开始推理。
- en: Experiments across various tasks show TP substantially outperforms baseline
    methods, with improvements ranging from 12% to 15%.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种任务的实验表明，TP 在性能上显著优于基线方法，改进范围从 12% 到 15%。
- en: '* * *'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: TP first prompts LLMs to propose and solve a set of analogous problems that
    are related to the input one. Then, TP reuses the results of analogous problems
    to directly yield a new solution or derive a knowledge-intensive plan for execution
    to amend the initial solution obtained from scratch.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TP 首先促使 LLMs 提出并解决一组与输入问题相关的类比问题。然后，TP 重用类比问题的结果，以直接得出新的解决方案或推导出知识密集型执行计划来修正从零开始获得的初始解决方案。
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The versatility and computational power of Large Language Models (LLMs) are
    undeniable, yet they are not without limit. One of the most significant and consistent
    challenges to LLMs is their general approach to problem-solving, consisting of
    reasoning from first principles for every new task encountered. This is problematic,
    as it allows for a high degree of adaptability, but also increases the likelihood
    of errors, particularly in tasks that require multi-step reasoning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的多样性和计算能力无可否认，但它们并非没有限制。LLMs 面临的最显著且持续的挑战之一是它们的通用问题解决方法，即每遇到一个新任务时都从第一原则推理。这是有问题的，因为它允许高度的适应性，但也增加了出错的可能性，特别是在需要多步骤推理的任务中。
- en: The challenge of "reasoning from scratch" is especially pronounced in complex
    tasks that demand multiple steps of logic and inference. For example, if an LLM
    is asked to find the shortest path in a network of interconnected points, it typically
    would not leverage prior knowledge or analogous problems to find a solution. Instead,
    it would attempt to solve the problem in isolation, which can lead to suboptimal
    results or even outright errors. Enter [Thought Propagation](https://arxiv.org/abs/2310.03965v2)
    (TP), a method designed to augment the reasoning capabilities of LLMs. TP aims
    to overcome the inherent limitations of LLMs by allowing them to draw from a reservoir
    of analogous problems and their corresponding solutions. This innovative approach
    not only improves the accuracy of LLM-generated solutions but also significantly
    enhances their ability to tackle multi-step, complex reasoning tasks. By leveraging
    the power of analogy, TP provides a framework that amplifies the innate reasoning
    capabilities of LLMs, bringing us one step closer to the realization of truly
    intelligent artificial systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: “从头推理”的挑战在于那些需要多步骤逻辑和推理的复杂任务。例如，如果要求LLM在一个互联点的网络中找到最短路径，它通常不会利用先前的知识或类比问题来寻找解决方案。相反，它会尝试孤立地解决问题，这可能导致次优结果甚至明显错误。进入[思想传播](https://arxiv.org/abs/2310.03965v2)（TP），这是一种旨在增强LLM推理能力的方法。TP旨在通过允许LLM从类比问题及其相应解决方案的储备中汲取经验，克服LLM固有的局限性。这种创新的方法不仅提高了LLM生成解决方案的准确性，还显著增强了其处理多步骤复杂推理任务的能力。通过利用类比的力量，TP提供了一个框架，放大了LLM的固有推理能力，使我们更接近实现真正智能的人工系统。
- en: Understanding Thought Propagation
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解思想传播
- en: 'Thought Propagation involves two main steps:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 思想传播包括两个主要步骤：
- en: First, the LLM is prompted to propose and solve a set of analogous problems
    related to the input problem
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，LLM被提示提出并解决一组与输入问题相关的类比问题
- en: Next, the solutions to these analogous problems are used to either directly
    yield a new solution or to amend the initial solution
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，这些类比问题的解决方案被用来直接产生新的解决方案或修正初步解决方案
- en: The process of identifying analogous problems allows the LLM to reuse problem-solving
    strategies and solutions, thereby improving its reasoning abilities. TP is compatible
    with existing prompting methods, providing a generalizable solution that can be
    incorporated into various tasks without significant task-specific engineering.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 识别类比问题的过程使得LLM能够重复使用问题解决策略和解决方案，从而提升其推理能力。TP与现有的提示方法兼容，提供了一个可泛化的解决方案，可以被纳入各种任务中，而无需进行显著的任务特定工程。
- en: '![Thought Propagation process](../Images/fbbafecf6b71c1e84f2fc31deef5317b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![思想传播过程](../Images/fbbafecf6b71c1e84f2fc31deef5317b.png)'
- en: '**Figure 1**: The Thought Propagation process (Image from paper)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**：思想传播过程（图片来自论文）'
- en: Moreover, the adaptability of TP should not be underestimated. Its compatibility
    with existing prompting methods makes it a highly versatile tool. This means that
    TP is not limited to any specific kind of problem-solving domain. This opens up
    exciting avenues for task-specific fine-tuning and optimization, thereby elevating
    the utility and efficacy of LLMs in a broad spectrum of applications.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，TP的适应性不应被低估。它与现有提示方法的兼容性使其成为一个高度通用的工具。这意味着TP不限于任何特定类型的问题解决领域。这为任务特定的微调和优化打开了激动人心的途径，从而提升了LLM在广泛应用中的实用性和有效性。
- en: Implementing Thought Propagation
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施思想传播
- en: The implementation of Thought Propagation can be integrated into the workflow
    of existing LLMs. For example, in a Shortest-path Reasoning task, TP could first
    solve a set of simpler, analogous problems to understand various possible paths.
    It would then use these insights to solve the complex problem, thereby increasing
    the likelihood of finding the optimal solution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 思想传播的实施可以集成到现有LLM的工作流程中。例如，在最短路径推理任务中，TP可以首先解决一组更简单的类比问题，以了解各种可能的路径。然后，它会利用这些见解来解决复杂问题，从而增加找到最佳解决方案的可能性。
- en: '**Example 1**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例1**'
- en: '**Task**: Shortest-path Reasoning'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务**：最短路径推理'
- en: '**Analogous Problems**: Shortest path between point A and B, Shortest path
    between point B and C'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类比问题**：点A和B之间的最短路径，点B和C之间的最短路径'
- en: '**Final Solution**: Optimal path from point A to C considering the solutions
    of analogous problems'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终解决方案**：考虑到类比问题的解决方案，从点A到C的最佳路径'
- en: '**Example 2**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例2**'
- en: '**Task**: Creative Writing'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务**：创造性写作'
- en: '**Analogous Problems**: Write a short story about friendship, Write a short
    story about trust'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类似问题**：写一个关于友谊的短篇故事，写一个关于信任的短篇故事'
- en: '**Final Solution**: Write a complex short story that integrates themes of friendship
    and trust'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终解决方案**：写一个融合友谊和信任主题的复杂短篇故事'
- en: The process involves solving these analogous problems first, and then using
    the insights gained to tackle the complex task at hand. This method has demonstrated
    its effectiveness across multiple tasks, showcasing substantial improvements in
    performance metrics.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程首先涉及解决这些类似问题，然后利用获得的见解来处理复杂任务。这种方法在多个任务中证明了其有效性，展示了性能指标的显著改进。
- en: Thought Propagation's implications go beyond merely improving existing metrics.
    This prompting technique has the potential to alter how we understand and deploy
    LLMs. The methodology underscores a shift from isolated, atomic problem-solving
    towards a more holistic, interconnected approach. It prompts us to consider how
    LLMs can learn not just from data, but from the process of problem-solving itself.
    By continuously updating their understanding through the solutions to analogous
    problems, LLMs equipped with TP are better prepared to tackle unforeseen challenges,
    rendering them more resilient and adaptable in rapidly evolving environments.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 思维传播的影响超出了仅仅改善现有指标的范畴。这种提示技术有可能改变我们理解和应用大语言模型的方式。该方法强调从孤立的、原子化的问题解决转向更整体、相互关联的方法。它促使我们考虑大语言模型如何不仅从数据中学习，还从问题解决的过程本身中学习。通过不断更新对类似问题的解决方案的理解，配备思维传播的大语言模型更好地准备应对不可预见的挑战，使它们在快速变化的环境中更具韧性和适应性。
- en: Conclusion
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Thought Propagation is a promising addition to the toolbox of prompting methods
    aimed at enhancing the capabilities of LLMs. By allowing LLMs to leverage analogous
    problems and their solutions, TP provides a more nuanced and effective reasoning
    method. Experiments confirm its efficacy, making it a candidate strategy for improving
    the performance of LLMs across a variety of tasks. TP may ultimately represent
    a significant step forward in the search for more capable AI systems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 思维传播是增强大语言模型能力的提示方法工具箱中的一项有前景的补充。通过允许大语言模型利用类似问题及其解决方案，思维传播提供了一种更细致有效的推理方法。实验验证了其有效性，使其成为提高各种任务中大语言模型性能的候选策略。思维传播最终可能代表了在寻求更强大AI系统中的一项重要进步。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[马修·梅奥](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为[KDnuggets](https://www.kdnuggets.com/)和[Statology](https://www.statology.org/)的管理编辑以及[Machine
    Learning Mastery](https://machinelearningmastery.com/)的贡献编辑，Matthew 旨在使复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、语言模型、机器学习算法以及探索新兴的人工智能。他致力于在数据科学社区中普及知识。Matthew
    从6岁起就开始编程。'
- en: More On This Topic
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Unraveling the Power of Chain-of-Thought Prompting in Large Language Models](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示链式思维提示在大语言模型中的威力](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)'
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级开源大语言模型](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
- en: '[More Free Courses on Large Language Models](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更多免费大语言模型课程](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
- en: '[Learn About Large Language Models](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解大语言模型](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[John Snow Labs 推出的医疗专用大语言模型](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
- en: '[What are Large Language Models and How Do They Work?](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是大语言模型，它们是如何工作的？](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
