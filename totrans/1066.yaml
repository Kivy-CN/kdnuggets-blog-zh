- en: How to Generate Synthetic Tabular Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How to Generate Synthetic Tabular Dataset](../Images/a1d5f83ff8498849deb3ba47907a9ccc.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Companies often come across the problem where they don't have enough real-life
    data or they cannot use actual data due to privacy concerns. This is where synthetic
    data generation comes to the rescue. Researchers and data scientists are using
    synthetic data to build new products, improve the performance of machine learning
    models, replace sensitive data, and save costs in acquiring the data. Read more
    at [The Ultimate Guide to Synthetic Data](https://research.aimultiple.com/synthetic-data/).
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The synthetic data is used in the healthcare sector, self-driving cars, financial
    sectors, maintaining a high level of privacy, and for research purposes - [Towards
    Data Science](https://towardsdatascience.com/synthetic-data-key-benefits-types-generation-methods-and-challenges-11b0ad304b55).
    Last year the entire Kaggle’s [Tabular Playground Series](https://www.kaggle.com/c/tabular-playground-series-apr-2021)
    dataset was developed using CTGANs. The Kaggle team has used the old datasets
    from various competitions to generate artificial datasets. It was a genius move
    by Kaggle as it made cheating hard. In this blog, we are going to learn about
    various methods to generate tabular data using [SDV’s](https://sdv.dev/SDV/#)
    Python library.
  prefs: []
  type: TYPE_NORMAL
- en: CTGANs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[CTGAN](https://arxiv.org/abs/1907.00503) uses several [GAN-based](https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/)
    methods to learn from original data and generate highly realistic tabular data.
    To produce synthetic tabular data, we will use conditional generative adversarial
    networks from open-source Python libraries called [CTGAN](https://pypi.org/project/ctgan/)
    and Synthetic Data Vault ([SDV](https://sdv.dev/)). The SDV allows data scientists
    to learn and generate data sets from single tables, relational data, and time
    series. It is the one-stop solution for all kinds of tabular data.'
  prefs: []
  type: TYPE_NORMAL
- en: With a few lines of code, our deep learning model can learn and generate sample
    tabular data. In the example below, we have initialized the model, trained it
    on real data, saved the model, and then generated 200 samples. This is just a
    start, we will also learn various ways to generate artificial data and then evaluate
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Generate Synthetic Tabular Dataset](../Images/7d9b8b958865d9e407e605cacfe3e8ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we are going to use the [Food Demand Forecasting | Kaggle](https://www.kaggle.com/kannanaikkal/food-demand-forecasting)
    (under [DbCL](https://opendatacommons.org/licenses/dbcl/1-0/) license) dataset
    to create a synthetic dataset. We will experiment with a vanilla model, custom
    model and finally evaluate results. The results will help us determine the quality
    of generated data. We will be using a [Deepnote](https://deepnote.com/) cloud
    notebook for generating the results.
  prefs: []
  type: TYPE_NORMAL
- en: CTGANSynthesizer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we need to install the CTGAN library by using ` pip install ctgan` and
    then load our dataset using Pandas. We are shuffling the dataset to get truly
    randomized two thousand samples. We are using a lower number of samples to reduce
    training duration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Before we start model training let's observe our actual dataset so that we can
    see the difference between real and artificial.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![How to Generate Synthetic Tabular Dataset](../Images/3c690c93a910e65edacf933f3f52d126.png)'
  prefs: []
  type: TYPE_IMG
- en: In order to train our CTGAN model, we need to provide a list of discrete columns,
    batch size, and the number of epochs. The API is similar to [Scikit-learn](https://scikit-learn.org/)
    where we initialize the model with hyperparameters and then train the model using
    `.fit()`. After successfully training the model, we are going to save our model
    to reproduce similar results. With `ctgan.sample(2000)` we are going to generate
    2k samples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As we can observe, the output is quite similar to the original data. The results
    are acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Generate Synthetic Tabular Dataset](../Images/1a26cf80589b30adf5411e35c8776e27.png)'
  prefs: []
  type: TYPE_IMG
- en: SDV
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this part, we are going to use the [SDV](https://sdv.dev/SDV/) library to
    generate data. SDV provides us with multiple single table models and also provides
    more features to run data generation experiments.
  prefs: []
  type: TYPE_NORMAL
- en: First, we are going to initialize the model by providing a primary key and decimal
    places for floating features. Then, we are going to train our model and generate
    200 samples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the id column started with 0 and the overall data looks clean.
    To fully understand our synthetic data, we need to evaluate the dataset using
    similarity metrics and comparing the data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Generate Synthetic Tabular Dataset](../Images/3c192f11c664fe8dc1686b606d09ee60.png)'
  prefs: []
  type: TYPE_IMG
- en: Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be using the SDV evaluate function to analyze the similarity between
    real and fake datasets. This function displays aggregated results of all of the
    similarity metrics from 0 to 1, where 0 begins worst and 1 is ideal. In our case,
    the similarity metric is **(0.34)** which is bad and we need to work more on hyperparameter
    optimization to get better results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[TableEvaluator](https://pypi.org/project/table-evaluator/) is used to evaluate
    the similarity between a synthesized and a real dataset. It was exclusively built
    for analyzing the performance of GAN-based tabular models. By writing a few lines
    of code, we can compare both datasets on the absolute log mean, distribution of
    all features, correlation matrix, and first two components of [PCA](https://www.keboola.com/blog/pca-machine-learning).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: By observing all the visualizing, we can conclude that the data features distribution
    is somehow similar but principal component analysis distribution is completely
    different from real data.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Generate Synthetic Tabular Dataset](../Images/e37e1772e4003f50070cb3afa1fb5c5f.png)'
  prefs: []
  type: TYPE_IMG
- en: '![How to Generate Synthetic Tabular Dataset](../Images/264bb0bb3ad5633d3e2be96acd065cb4.png)'
  prefs: []
  type: TYPE_IMG
- en: '![How to Generate Synthetic Tabular Dataset](../Images/540039a27ab33660f9a3b8781baf32f3.png)'
  prefs: []
  type: TYPE_IMG
- en: Custom Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s create a customized model to improve the similarity metric by changing,
    number of epochs, bach_size, generator dimensions, and discriminator dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can also customize the generated dataset by creating constants. Let's say
    we want to generate data for *center_id 161\.* We will first create a dictionary
    of "conditions" and pass it to a sample function as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![How to Generate Synthetic Tabular Dataset](../Images/889ae70d040607bc4d50ba13fcff4852.png)'
  prefs: []
  type: TYPE_IMG
- en: With light hyper-parameter optimization we have achieved a better similarity
    score **(0.53)** as shown below. If your generated dataset is soaring between
    0.6 to 0.7 then your dataset is ready for production.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: SDV for Relational and Time Series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can also use the SDV library to generate relational dataset using `sdv.relational.HMA1`
    and time series data using `sdv.timeseries.PAR`. The API works similar CTGAN model,
    we just need to train the model and then generate **N** numbers of samples.
  prefs: []
  type: TYPE_NORMAL
- en: Relational Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Hierarchical Modeling Algorithm](https://sdv.dev/SDV/user_guides/relational/hma1.html)
    is an algorithm that allows one to recursively walk through a relational dataset
    and apply tabular models across all the tables. In this way, models learn how
    all the fields from all the tables are related.'
  prefs: []
  type: TYPE_NORMAL
- en: Time Series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Probabilistic AutoRegressive](https://sdv.dev/SDV/user_guides/timeseries/par.html#what-is-par)
    allows learning multi-type, multivariate time series data and later on generates
    new synthetic data that has the same format and properties as the learned one.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I use CTGANs to improve my machine learning model performance and assess model
    accuracy on the unseen dataset. It has also helped me with an unbalanced class
    dataset. If you have limited training data and you want to develop an AI product
    without investing a lot of money in occurring data then you should consider generating
    synthetic datasets. The synthetic dataset is not limited to tabular as we can
    now use GANs to generate images, audio, and text dataset. Creating artificial
    data is an ever-growing field. In the future, it will surpass the real dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we have learned about CTGANs and how to use the SDV library to
    generate the tabular dataset. We have also learned that we can generate relation
    and times series data with a similar API. I hope you enjoyed the short tutorial
    and if you have any questions about debugging the code, comment below.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Generate Synthetic Time-series Data with Open-source Tools](https://www.kdnuggets.com/2022/06/generate-synthetic-timeseries-data-opensource-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data-centric AI and Tabular Data](https://www.kdnuggets.com/2022/09/datacentric-ai-tabular-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4 Ways to Generate Passive Income Using ChatGPT](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Generate Music From Text Using Google MusicLM](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Ways to Generate Hyper-Realistic Faces Using Stable Diffusion](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Combining Data Management and Data Storytelling to Generate Value](https://www.kdnuggets.com/combining-data-management-and-data-storytelling-to-generate-value)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
