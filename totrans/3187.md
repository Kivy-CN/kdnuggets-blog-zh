# 开始使用 TensorFlow：机器学习教程

> 原文：[https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html](https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2017/12/getting-started-tensorflow.html/2#comments)

**作者：[Dino Causevic](https://www.toptal.com/resume/dino-causevic)，Toptal**。

TensorFlow 是 Google 创建的一个开源软件库，用于实现机器学习和深度学习系统。这两个名称包含了一系列强大的算法，面临一个共同的挑战——使计算机能够自动识别复杂的模式和/或做出最佳决策。

如果你对这些系统的细节感兴趣，可以从 Toptal 博客上的[机器学习](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)和[深度学习](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)文章中了解更多。

![](../Images/6e3b08444cb7bdaecec1e430278822de.png)

TensorFlow 本质上是一个数据流编程库。它利用各种优化技术，使得数学表达式的计算更加容易和高效。

TensorFlow 的一些关键特性包括：

+   高效处理涉及多维数组的数学表达式

+   对深度神经网络和机器学习概念的良好支持

+   GPU/CPU 计算中相同的代码可以在这两种架构上执行

+   高度可扩展的跨机器计算和处理巨大数据集

这些特性使 TensorFlow 成为在生产规模上进行机器智能的完美框架。

在这个 TensorFlow 教程中，你将学习如何在 TensorFlow 中使用简单却强大的机器学习方法，以及如何使用一些辅助库来调试、可视化和调整用它创建的模型。

**安装 TensorFlow**

我们将使用 TensorFlow Python API，它适用于 Python 2.7 和 Python 3.3+。GPU 版本（仅限 Linux）需要 Cuda Toolkit 7.0+ 和 cuDNN v2+。

我们将使用 Conda 包管理系统来安装 TensorFlow。Conda 允许我们在一台机器上分隔多个环境。你可以从[这里](https://conda.io/docs/user-guide/install/index.html)学习如何安装 Conda。

安装 Conda 后，我们可以创建将用于 TensorFlow 安装和使用的环境。以下命令将创建我们的环境，并包含一些额外的库，如[NumPy](https://www.numpy.org/)，这在我们开始使用 TensorFlow 时非常有用。

本环境中安装的 Python 版本是 2.7，我们将在本文中使用这个版本。

```py
conda create --name TensorflowEnv biopython
```

*为了简化操作，我们在这里安装了 biopython，而不仅仅是 NumPy。这包括 NumPy 以及我们将需要的一些其他包。你可以随时使用 `conda install` 或 `pip install` 命令来安装所需的包。*

以下命令将激活创建的 Conda 环境。我们将能够使用其中安装的包，而不会与全局或其他环境中安装的包混合。

```py
source activate TensorFlowEnv
```

pip 安装工具是 Conda 环境的标准部分。我们将使用它来安装 TensorFlow 库。在此之前，一个好的第一步是使用以下命令将 pip 更新到最新版本：

```py
pip install --upgrade pip
```

现在我们准备通过运行以下命令来安装 TensorFlow：

```py
pip install tensorflow
```

TensorFlow 的下载和构建可能需要几分钟时间。在撰写本文时，这将安装 TensorFlow 1.1.0。

**数据流图**

在 TensorFlow 中，计算是通过数据流图来描述的。图中的每个节点代表一个数学操作（如加法、除法或乘法）的实例，每条边缘是一个多维数据集（张量），操作将在其上执行。

![](../Images/1a9f8cab43009efda34fad441f236123.png)

由于 TensorFlow 处理计算图，它们被管理，其中每个节点代表操作的实例，每个操作具有零个或多个输入和零个或多个输出。

在 TensorFlow 中，边缘可以分为两类：普通边缘传输数据结构（张量），在这种情况下，一个操作的输出可能成为另一个操作的输入；特殊边缘用于控制两个节点之间的依赖关系，以设置操作的顺序，其中一个节点等待另一个节点完成。

**简单表达式**

在讨论 TensorFlow 的元素之前，我们将先进行一个使用 TensorFlow 的会话，以了解 TensorFlow 程序的样子。

让我们从简单的表达式开始，并假设由于某种原因，我们想要以 TensorFlow 的方式计算函数 `y = 5*x + 13`。

在简单的 Python 代码中，它看起来像这样：

```py
x = -2.0
y = 5*x + 13
print y
```

这在这种情况下给出了结果 3.0。

现在我们将把上述表达式转换为 TensorFlow 术语。

**常量**

在 TensorFlow 中，常量是通过函数 constant 创建的，其签名为 `constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`，其中 `value` 是将用于后续计算的实际常量值，`dtype` 是数据类型参数（例如 float32/64，int8/16 等），`shape` 是可选的维度，`name` 是张量的可选名称，最后一个参数是一个布尔值，指示是否验证值的形状。

如果你在训练模型中需要具有特定值的常量，则可以使用 `constant` 对象，如下例所示：

```py
z = tf.constant(5.2, name="x", dtype=tf.float32)
```

**变量**

TensorFlow中的变量是包含张量的内存缓冲区，这些张量必须显式初始化并在图中使用，以在会话之间保持状态。只需调用构造函数，变量就会添加到计算图中。

变量在开始训练模型时特别有用，它们用于保存和更新参数。作为构造函数参数传递的初始值代表一个张量或对象，可以转换或返回为张量。这意味着，如果我们想用一些预定义的或随机的值填充变量以供之后的训练过程使用并在迭代中更新，我们可以按如下方式定义它：

```py
k = tf.Variable(tf.zeros([1]), name="k")
```

在TensorFlow中使用变量的另一种方法是进行计算，其中该变量不可训练，可以按如下方式定义：

```py
k = tf.Variable(tf.add(a, b), trainable=False)
```

**会话**

为了实际评估节点，我们必须在会话中运行计算图。

会话封装了TensorFlow运行时的控制和状态。没有参数的会话将使用当前会话中创建的默认图，否则会话类接受一个图参数，该图参数用于在该会话中执行。

下面是一个简短的代码片段，展示了如何在TensorFlow中使用上述定义的术语来计算一个简单的线性函数。

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init)
    print session.run(y)

```

**使用TensorFlow：定义计算图**

使用数据流图的好处是执行模型与其执行（在CPU、GPU或某些组合上）分离，一旦实现，TensorFlow中的软件可以在CPU或GPU上使用，所有与代码执行相关的复杂性都被隐藏。

计算图可以在使用TensorFlow库的过程中构建，无需显式实例化[Graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph)对象。

TensorFlow中的Graph对象可以通过像`c = tf.add(a, b)`这样的简单代码行创建。这将创建一个操作节点，该节点接受两个张量`a`和`b`，并将它们的和`c`作为输出。

计算图是一个内置过程，它使用库而无需直接调用[graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph)对象。TensorFlow中的图对象包含一组操作和张量作为数据单元，在操作之间使用，允许相同的过程，并包含多个图，其中每个图将分配给不同的会话。例如，简单的代码行`c = tf.add(a, b)`将创建一个操作节点，该节点接受两个张量`a`和`b`作为输入，并生成它们的和`c`作为输出。

TensorFlow还提供了一个馈送机制，用于将张量传递到图中的任何操作，其中馈送用张量值替换操作的输出。馈送数据作为`run()`函数调用中的参数传递。

占位符是 TensorFlow 允许开发者通过占位符将数据注入计算图中的方式，占位符在某些表达式内部绑定。占位符的签名是：

```py
placeholder(dtype, shape=None, name=None)
```

其中 dtype 是张量中元素的类型，可以提供要填充张量的形状和操作的名称。

如果没有传递形状，该张量可以接收任何形状。一个重要的说明是占位符张量必须用数据填充，否则，在执行会话时，如果该部分缺失，占位符将产生以下结构的错误：

```py
InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype float
```

占位符的优点在于它们允许开发者创建操作以及计算图，而无需提前提供数据，数据可以在运行时从外部源添加。

让我们以 TensorFlow 风格的两个整数 `x` 和 `y` 相乘的简单问题为例，其中将使用占位符以及通过会话 `run` 方法的填充机制。

```py
import tensorflow as tf

x = tf.placeholder(tf.float32, name="x")
y = tf.placeholder(tf.float32, name="y")

z = tf.multiply(x, y, name="z")

with tf.Session() as session:
    print session.run(z, feed_dict={x: 2.1, y: 3.0})

```

**使用 TensorBoard 可视化计算图**

TensorBoard 是一个用于分析数据流图的可视化工具。这有助于更好地理解机器学习模型。

使用 TensorBoard，你可以深入了解有关参数的不同统计信息以及计算图部分的详细信息。深度神经网络通常有大量节点。TensorBoard 允许开发者深入了解每个节点及其在 TensorFlow 运行时的计算执行情况。

![](../Images/48d7c35fa2fff56b5635fa7bdf908e1c.png)

现在让我们回到 TensorFlow 教程开始时的示例，我们定义了一个格式为 `y = a*x + b` 的线性函数。

为了记录来自会话的事件以供 TensorBoard 后续使用，TensorFlow 提供了 `FileWriter` 类。它可用于创建存储 [摘要](https://www.tensorflow.org/api_guides/python/summary) 和 [事件](https://www.tensorflow.org/api_docs/python/tf/Event) 的事件文件，构造函数接受六个参数，格式如下：

```py
__init__(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None)
```

其中 logdir 参数是必需的，其他参数有默认值。图参数将从训练程序中创建的会话对象传递。完整的示例代码如下：

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    merged = tf.summary.merge_all() // new
    writer = tf.summary.FileWriter("logs", session.graph) // new

    session.run(init)
    print session.run(y)
```

我们仅添加了两行新代码。我们合并了在默认图中收集的所有摘要，`FileWriter`用于将事件转储到文件中，如上所述。

运行程序后，我们在目录 logs 中有了文件，最后一步是运行 `tensorboard`：

```py
tensorboard --logdir logs/
```

现在 TensorBoard 已经启动并运行在默认端口 6006。打开 https://localhost:6006 并点击页面顶部的 Graphs 菜单项，你将能看到图形，如下图所示：

![](../Images/d7def7e0a9ba10e06df3f474264fe157.png)

TensorBoard 为常量和汇总节点标记特定的符号，下面进行了描述。

![](../Images/f39a2398dc314d85d44d6734a1ae94b9.png)

**TensorFlow 数学**

张量是 TensorFlow 中的基本数据结构，它们表示数据流图中的连接边缘。

张量简单地标识一个多维数组或列表。张量结构可以通过三个参数来识别：秩、形状和类型。

+   秩：标识张量的维度数量。秩也称为张量的阶数或 n-维度，例如秩 1 张量是向量，秩 2 张量是矩阵。

+   形状：张量的形状是它的行数和列数。

+   类型：分配给张量元素的数据类型。

要在 TensorFlow 中构建张量，我们可以构建一个 n 维数组。这可以通过使用 NumPy 库轻松完成，或者通过将 Python n 维数组转换为 TensorFlow 张量来完成。

![](../Images/54429bdf3b195d6b7305c5e32546eff4.png)

要构建一个 1-d 张量，我们将使用 NumPy 数组，通过传递一个内置的 Python 列表来构造它。

```py
import numpy as np
tensor_1d = np.array([1.45, -1, 0.2, 102.1])
```

处理这种数组与处理内置的 Python 列表类似。主要区别在于 NumPy 数组还包含一些额外的属性，如维度、形状和类型。

```py
>> print tensor_1d
[   1.45   -1\.      0.2   102.1 ]

>> print tensor_1d[0]
1.45

>> print tensor_1d[2]
0.2

>> print tensor_1d.ndim
1

>> print tensor_1d.shape
(4,)

>> print tensor_1d.dtype
float64

```

NumPy 数组可以通过辅助函数 [convert_to_tensor](https://www.tensorflow.org/versions/master/api_docs/python/tf/convert_to_tensor) 轻松转换为 TensorFlow 张量，该函数帮助开发者将 Python 对象转换为张量对象。此函数接受张量对象、NumPy 数组、Python 列表和 Python 标量。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
```

现在，如果我们将张量绑定到 TensorFlow 会话中，我们将能够看到转换的结果。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)

with tf.Session() as session:
    print session.run(tensor)
    print session.run(tensor[0])
    print session.run(tensor[1])

```

输出：

```py
[   1.45   -1\.      0.2   102.1 ]
1.45
-1.0

```

我们可以以类似的方式创建一个 2-d 张量或矩阵：

```py
tensor_2d = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_1 = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_2 = np.array(np.random.rand(4, 4), dtype='float32')

m1 = tf.convert_to_tensor(tensor_2d)
m2 = tf.convert_to_tensor(tensor_2d_1)
m3 = tf.convert_to_tensor(tensor_2d_2)
mat_product = tf.matmul(m1, m2)
mat_sum = tf.add(m2, m3)
mat_det = tf.matrix_determinant(m3)

with tf.Session() as session:
    print session.run(mat_product)
    print session.run(mat_sum)
    print session.run(mat_det)

```

**张量操作**

在上面的例子中，我们对向量和矩阵引入了一些 TensorFlow 操作。这些操作对张量执行特定的计算。这些计算具体是什么，如下表所示。

上表中列出的 TensorFlow 操作处理张量对象，并逐元素执行。因此，如果你想计算向量 x 的余弦，TensorFlow 操作将对传递的张量中的每个元素进行计算。

```py
tensor_1d = np.array([0, 0, 0])
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
with tf.Session() as session:
    print session.run(tf.cos(tensor))

```

输出：

```py
[ 1\.  1\.  1.]

```

**矩阵操作**

矩阵操作对机器学习模型非常重要，例如线性回归，因为它们通常会被用到。TensorFlow 支持所有最常见的矩阵操作，如 [乘法](https://www.tensorflow.org/versions/master/api_docs/python/tf/matmul)、[转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、[逆矩阵](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_inverse)、计算 [行列式](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_determinant)、解决 [线性方程](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_solve) 等等。

接下来，我们将解释一些矩阵操作。它们在机器学习模型中往往非常重要，例如在线性回归中。让我们编写一些代码，进行基本的矩阵操作，如乘法、获取 [转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、获取行列式、乘法、解方程等等。

以下是调用这些操作的基本示例。

```py
import tensorflow as tf
import numpy as np

def convert(v, t=tf.float32):
    return tf.convert_to_tensor(v, dtype=t)

m1 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m2 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m3 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m4 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m5 = convert(np.array(np.random.rand(4, 4), dtype='float32'))

m_tranpose = tf.transpose(m1)
m_mul = tf.matmul(m1, m2)
m_det = tf.matrix_determinant(m3)
m_inv = tf.matrix_inverse(m4)
m_solve = tf.matrix_solve(m5, [[1], [1], [1], [1]])

with tf.Session() as session:
    print session.run(m_tranpose)
    print session.run(m_mul)
    print session.run(m_inv)
    print session.run(m_det)
    print session.run(m_solve)

```

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的IT需求

* * *

### 主题更多信息

+   [联邦学习：协作机器学习教程…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)

+   [开始使用 Scikit-learn 进行机器学习分类](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)

+   [开始进行自动化文本摘要](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)

+   [开始清理数据](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)

+   [开始使用 SQL 备忘单](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)

+   [开始使用 spaCy 进行 NLP](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
