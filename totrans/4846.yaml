- en: Simple Derivatives with PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html](https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: Derivatives are simple with PyTorch. Like many other neural network libraries,
    PyTorch includes an automatic differentiation package, `[autograd](https://pytorch.org/docs/master/autograd.html)`,
    which does the heavy lifting. But derivatives seem especially simple with PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things I wish I had when first learning about how [derivatives and
    practical implementations of neural networks](https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html)
    fit together were concrete examples of using such neural network packages to find
    simple derivatives and perform calculations on them, separate from computation
    graphs in neural networks. PyTorch's architecture makes such pedagogical examples
    easy.
  prefs: []
  type: TYPE_NORMAL
- en: I can't really tell if this will be useful for people who want to see how PyTorch
    implements automatic differentiation, how to practically compute derivatives,
    or even learning what "finding the derivative" means, but let's give it a go anyways.
    There's a chance it isn't useful for any of these. :)
  prefs: []
  type: TYPE_NORMAL
- en: '![PyTorch](../Images/05892c36023f36e716584053fc6b9e7a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'First we will need a function for which to find the derivative. Arbitrarily,
    let''s use this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/f63c40b9d1ac08484e874bdc8ba90142.png)'
  prefs: []
  type: TYPE_IMG
- en: We would do well to recall here that the derivative of a function can be interpreted
    as the slope of a tangent to the curve represented by our function, as well as
    the function's rate of change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we use PyTorch to find the derivative to this function, let''s work
    it out first by hand:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/63f2148d099a0885d5fcf5aeb0161e92.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Equation](../Images/e9b358a522dc0f7f98dbb990318d9596.png)'
  prefs: []
  type: TYPE_IMG
- en: The above is the *first order derivative* of our original function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s find the value of our derivative function for a given value of *x*.
    Let''s arbitrarily use **2**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/c85e3f5373a0fb763a2f27eed1eb8bee.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Equation](../Images/f7e148a32128215ad6de52382a341e16.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Equation](../Images/90de01b6c4561049c41a251cdf100dc7.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Equation](../Images/69a4f46f44f8f44f74b2d1e673a6777b.png)'
  prefs: []
  type: TYPE_IMG
- en: Solving our derivative function for *x = 2* gives as **233**. This can be interpreted
    as the rate of change of *y* with respect to *x* in our formula is 233 when when
    *x = 2*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Using `autograd` to Find and Solve a Derivative**'
  prefs: []
  type: TYPE_NORMAL
- en: How can we do the same as above with PyTorch's `autograd` package?
  prefs: []
  type: TYPE_NORMAL
- en: 'First, it should be obvious that we have to represent our original function
    in Python as such:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Line by line, the above code:'
  prefs: []
  type: TYPE_NORMAL
- en: imports the torch library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: defines the function we want to compute the derivative of
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: defines the value (2) we want to compute the derivative with regard to as a
    PyTorch `Variable` object and specifies that it should be instantiated in such
    a way that it tracks where in the computation graph it connects to in order to
    perform differentiation by the chain rule (`requires_grad`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: uses `autograd`'s `[backward()](https://pytorch.org/docs/master/autograd.html#torch.autograd.backward)`
    to compute the sum of gradients, using the chain rule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: outputs the value stored in the *x* tensor's `grad` attribute, which, as shown
    below
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This value, 233, matches what we calculated by hand, above.
  prefs: []
  type: TYPE_NORMAL
- en: To take the next steps with using PyTorch, including using the `autograd` package
    and [`Tensor`](https://www.kdnuggets.com/2018/05/pytorch-tensor-basics.html) objects
    to build some basic neural networks, I suggest the official [PyTorch 60 Minute
    Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
    or [this tutorial](https://github.com/yunjey/pytorch-tutorial).
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PyTorch Tensor Basics](/2018/05/pytorch-tensor-basics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WTF is a Tensor?!?](/2018/05/wtf-tensor.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Boost your data science skills. Learn linear algebra.](/2018/05/boost-data-science-skills-learn-linear-algebra.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Simple Steps Series: Master Python, SQL, Scikit-learn, PyTorch &…](https://www.kdnuggets.com/5-simple-steps-series-master-python-sql-scikit-learn-pytorch-google-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tuning Adam Optimizer Parameters in PyTorch](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[YOLOv5 PyTorch Tutorial](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
