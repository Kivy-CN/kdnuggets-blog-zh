# 你已经创建了你的第一个线性回归模型。你验证过假设了吗？

> 原文：[https://www.kdnuggets.com/2017/11/first-linear-regression-assumptions.html](https://www.kdnuggets.com/2017/11/first-linear-regression-assumptions.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png)[评论](#comments)

**由 [Sudipto Dasgupta](https://www.linkedin.com/in/dsudipto/)，Flipkart.**

随着数据科学时代的到来，学习和应用算法的兴趣增加了，这不仅是商业分析师或数据科学家的事情，还有许多其他专业人士，虽然他们的核心工作可能不是处理数据或建立模型。如果一个人理解何时、为何以及如何应用这些出色的技术，那确实是一个好兆头。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的 IT

* * *

线性回归模型在某些假设下有效，这些假设包括：

**1\. Y（因变量）与 X（自变量）之间的线性关系**。如果你的散点图显示出曲线关系，请记住，高阶多项式（2 阶及以上）可能更适合建模数据。比较模型、统计数据，然后自行决定哪个模型最能解释你的数据。

**2\. 多重共线性** – 其缺乏性。对于线性回归模型的有效性，VIF（方差膨胀因子）不应过高。多高算过高？通常，VIF 值为 5 被视为阈值。有些人甚至使用 2.5。你可以自己研究一下，但几乎总是 VIF 高达 10 就过高了。高 VIF 表明存在多重共线性，即 IV 之间的高相关性。你可以通过移除一个或多个相关的 IV 并重新运行模型来测试你的模型。你还可以使用其他降维技术，如 PCA（主成分分析）。

**3\. 同方差性** – *Homo* 意味着相似，*scedasticity* 意味着误差项的分布。因此，同方差性意味着误差项的分布是类似的（即随机的）。如果误差项存在任何非随机行为，比如下面的残差与拟合图，那么模型就会出现一种称为异方差性的病症。这也可以通过 ncv 测试等方法来检测。通过 Box-Cox 等方法对变量进行变换，或尝试完全不同的变量，可以解决模型中的这个问题。

![](../Images/7ec18901b4ebf5f25ad517c8900d55b7.png)

**4\. 残差正态性**– 误差项也称为残差。它是因变量（DV(y)）的观测值与预测值（ŷ）之间的差异。误差项是阻碍我们进行完美预测的因素。请记住，在计算标准差时我们使用的是 {x-x̄}，而在卡方检验中我们使用的是 {Observed- Expected} 进行计算。残差分析是多种统计方法（包括线性回归）的一个重要部分。线性回归的假设是残差必须是独立且随机分布的，均值为零，这在技术上意味着残差应通过正态性检验。这可以通过提取残差并进行正态性检验（如Anderson-Darling检验或Shapiro检验）来测试，或者通过量化图或概率图等图形方法来检验。非随机行为的存在表明模型需要某些调整。异常值可能是原因，或者需要更高阶的项。在某些情况下，转换也可能会有所帮助。

**5\. 自相关** – 应该不存在。在前一点中，我提到过残差必须是独立且正态分布的。当残差的独立性受到违反时，我们可以看到如下图所示的模式，或者在残差与顺序图中出现向上或向下的周期性趋势。这也可以通过对数据进行Durbin-Watson检验来检测。解决方案可以有多种，例如使用不同的模型或转换一些变量。

![](../Images/22494367d7f53bdb4f12272b53361468.png)

简单线性回归，顾名思义，易于理解和应用。在我的项目中，我发现线性回归在数据建模方面表现得相当出色。因此，线性回归仍然是数据建模中最常用的算法之一也就不足为奇了。

**简历：Sudipto Dasgupta** 目前在印度最大的电子商务公司 Flipkart India Pvt. Ltd. 担任流程设计专家。他在软件、市场研究、教育和供应链等领域拥有超过15年的业务分析经验。他是一名经验丰富的六西格玛大师黑带和项目管理专业人士（PMP），拥有数学和统计学的教育背景。他对数据科学充满浓厚的兴趣。

**相关：**

+   [初学者的前10种机器学习算法](/2017/10/top-10-machine-learning-algorithms-beginners.html)

+   [使用R学习广义线性模型（GLM）](/2017/10/learn-generalized-linear-models-glm-r.html)

+   [回归分析真的属于机器学习吗？](/2017/06/regression-analysis-really-machine-learning.html)

### 了解更多相关话题

+   [XGBoost的假设是什么？](https://www.kdnuggets.com/2022/08/assumptions-xgboost.html)

+   [DataLang：数据科学家的新编程语言... 创建...](https://www.kdnuggets.com/2023/04/datalang-new-programming-language-data-scientists-chatgpt.html)

+   [我在3天内创建了一个AI应用](https://www.kdnuggets.com/2023/08/created-ai-app-3-days.html)

+   [线性回归模型选择：平衡简易性与复杂性](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)

+   [为什么你应该使用线性回归模型而不是...的3个原因](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [比较线性回归和逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)
