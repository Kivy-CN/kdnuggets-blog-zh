# 掌握新一代梯度提升

> 原文：[https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html](https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**由[Tal Peretz](https://www.linkedin.com/in/tal-per/)，数据科学家**

![Image](../Images/6f0021d10fa8e75d1f0681617209fb04.png)

Catboost

**梯度提升决策树**和随机森林是我最喜欢的用于异构表格数据集的机器学习模型。这些模型在*[Kaggle](https://www.kaggle.com/)*竞赛中表现最优，并在行业中广泛使用。

**Catboost**，这个新兴的模型，已经存在一年多了，并且正在威胁到*XGBoost*、*LightGBM*和*H2O*。

### 为什么选择Catboost？

**更好的结果**

Catboost在基准测试中取得了最佳结果，这很好，但我不确定是否会仅因略微减少的对数损失而替换一个已在生产中的模型（尤其是当进行基准测试的公司对Catboost有明显利益时????）。

尽管如此，当你查看**分类特征起重要作用**的数据集时，如*Amazon*和*Internet*数据集，这种改进变得显著且不可否认。

![](../Images/c0f56356b0efe76253f46b1b9e3e4db4.png)

GBDT算法基准

**更快的预测**

尽管训练时间可能比其他GBDT实现更长，但根据Yandex基准，预测时间比其他库快13-16倍。

![](../Images/b878dfec55b45c7736bc70937ced22a9.png)

左：CPU，右：GPU

**内置电池**

Catboost的默认参数比其他GBDT算法的起始点更好。这对希望开始体验树集成或参加Kaggle竞赛的初学者来说是个好消息。

然而，有一些非常重要的参数我们必须讨论，我们稍后会谈到这些。

![](../Images/1d04b9a46e27fdf79d1394772740d7c8.png)

GBDT算法默认参数基准

Catboost的一些更值得注意的进展包括特征交互、对象重要性和快照支持。

除了分类和回归，Catboost还**开箱即用地支持排名**。

**实战验证**

[Yandex](https://yandex.com/)严重依赖Catboost进行排名、预测和推荐。这个模型每月服务于超过7000万用户。

> CatBoost是一种**基于决策树的梯度提升**算法。由Yandex的研究人员和工程师开发，是广泛用于排名任务、预测和推荐的[**MatrixNet算法**](https://yandex.com/company/technologies/matrixnet/)的继任者。它具有通用性，能够应用于广泛的领域和多种问题。

![](../Images/c5da7f5f59cc6ccf130e81e835370235.png)

### 算法

**经典梯度提升**

![](../Images/5c4a3ead431e03d2e430b6f2cd022cf1.png)

维基百科上的梯度提升

![](../Images/d9ca34b445477fccd614b5d7fa7e7ae8.png)

### Catboost 秘密配方

Catboost 引入了两个关键的算法进展——**有序提升**的实现，这是经典算法的一种基于排列的替代方法，以及用于**处理类别特征**的创新算法。

这两种技术都使用训练样本的随机排列来对抗由于所有现有梯度提升算法中存在的一种特殊类型的*目标泄漏*所造成的*预测偏移*。

### **类别特征处理**

**有序目标统计**

大多数 GBDT 算法和 Kaggle 竞争者已经熟悉 Target Statistic（或目标均值编码）的使用。

这是一种简单而有效的方法，我们使用根据类别条件化的期望目标 y 的估计来对每个类别特征进行编码。

实际上，随意应用这种编码（在训练示例中具有相同类别的 y 的平均值）会导致目标泄漏。

为了应对这种*预测偏移*，CatBoost 使用了更有效的策略。它依赖于排序原则，并且受到在线学习算法的启发，这些算法按时间顺序获取训练示例。在这种情况下，每个示例的 TS 值仅依赖于观察到的历史。

为了将这一思想适应于标准离线设置，Catboost 引入了一个人工的“时间”——一个训练示例的随机排列*σ1*。

然后，对于每个示例，它使用所有可用的“历史”来计算其 Target Statistic。

请注意，使用仅一个随机排列会导致前面的示例在 Target Statistic 上的方差大于后续示例。为此，CatBoost 在梯度提升的不同步骤中使用不同的排列。

**独热编码**

Catboost 对所有具有最多 *one_hot_max_size* 个唯一值的特征使用独热编码。默认值为 2。

![](../Images/2f8ee6fadf0aa6b7e40160287f640d95.png)

Catboost 的秘密配方

### 有序提升

CatBoost 有两种选择树结构的模式：Ordered 和 Plain。**Plain 模式**对应于将标准 GBDT 算法与有序 Target Statistic 的组合。

在**有序模式**提升中，我们对训练示例进行随机排列——*σ2*，并维护 n 个不同的支持模型——*M1, . . . , Mn*，其中模型*Mi*仅使用排列中的前*i*个样本进行训练。

在每一步，为了获得*j*第*个样本的残差，我们使用模型*Mj−1*。

不幸的是，由于需要维护 n 个不同的模型，这增加了复杂性和内存需求，因此这种算法在大多数实际任务中不可行。Catboost 实现了这种算法的改进，基于梯度提升算法，使用一个由所有待建立模型共享的树结构。

![](../Images/7245343ce5d8d1988a29e6935d988b25.png)

Catboost 有序提升和树构建

为了避免*预测偏移*，Catboost 使用排列，使得*σ1* = *σ2*。这保证了目标-*yi* 既未用于训练*Mi*，也未用于目标统计计算或梯度估计。

### 实操

对于本节，我们将使用[*Amazon Dataset*](https://www.kaggle.com/c/amazon-employee-access-challenge/data)，因为它干净且强调类别特征。

![](../Images/54f9b2df0a33b9243c0edaeb7b2614e7.png)

数据集简述

### 调整 Catboost

**重要参数**

+   **cat_features** — 为了利用 Catboost 对类别特征的预处理，这个参数是必须的。如果你自己编码类别特征却没有将列索引作为*cat_features*传递，你将错过 Catboost 的精髓。*

+   ***one_hot_max_size**** — *如前所述，Catboost 对所有特征使用一个最多包含*one_hot_max_size* 个唯一值的独热编码。在我们的情况下，类别特征有很多唯一值，因此我们不会使用独热编码，但根据数据集的不同，调整此参数可能是个好主意。*

+   ***learning_rate* & *n_estimators*** — *学习率越小，需要的 n_estimators 越多来充分利用模型。通常的方法是从相对较高的*learning_rate*开始，调整其他参数，然后降低*learning_rate*，同时增加*n_estimators*。*

+   ***max_depth**** — *基础树的深度*，*这个参数对训练时间有很大的影响。*

+   ***subsample ****— *样本率，不能用于*Bayesian*增强类型设置。*

+   ***colsample_bylevel ****— *列的样本率。*

+   ***l2_leaf_reg ****— *L2 正则化系数。*

+   ***random_strength ****— *每个分裂都有一个分数，random_strength 为分数添加了一些随机性，有助于减少过拟合。*

### 使用 Catboost 进行模型探索

除了特征重要性之外，Catboost 还提供了**特征交互**和**对象（行）重要性**

![](../Images/082c2a9b1ba4d6c8314ba8aa236e987b.png)

Catboost 的特征重要性![](../Images/56623055e6f9f321c7421840035723e3.png)

Catboost 的特征交互![](../Images/aee63f4ec198f40df446c77d26da3020.png)

Catboost 的对象重要性![](../Images/cc8f573706b8833248e07619ab3f075f.png)

[SHAP](https://catboost.ai/news/new-ways-to-explore-your-data) 值也可以用于其他集成方法

### 完整的笔记本

查看一些有用的 Catboost 代码片段

Catboost 游乐场笔记本 ### 结论

![](../Images/ef39987d7aca7ca0507cfb9e7cd44cb7.png)

Catboost 与 XGBoost（默认、贪婪和全面参数搜索）

![](../Images/fc9fa159d967eadf6f7a1be280d62dca.png)

**总结**

+   Catboost 采用了与“旧一代”GBDT模型类似的方法和属性。

+   Catboost 的优势在于其 **分类特征预处理**、 **预测时间** 和 **模型分析**。

+   Catboost 的弱点在于其 **训练和优化时间**。

+   不要忘记将 ***cat_features*** 参数传递给分类器对象。没有这个参数，你并没有真正发挥 Catboost 的强大功能。

+   尽管 Catboost 在默认参数下表现良好，但有几个参数在调整时能显著改善结果。

**进一步阅读**

+   [Catboost 文档](https://tech.yandex.com/catboost/doc/dg/concepts/about-docpage/)

+   [Catboost Github](https://github.com/catboost/catboost)

+   [Catboost 官方网站](https://catboost.ai/)

+   我强烈推荐你深入阅读 [CatBoost: unbiased boosting with categorical features paper on arXiv](https://arxiv.org/abs/1706.09516)。

+   [Catboost 游乐场笔记本](https://gist.github.com/talperetz/6030f4e9997c249b09409dcf00e78f91)

+   [SHAP 值](https://github.com/slundberg/shap)

特别感谢 Catboost 团队负责人 [Anna Veronika Dorogush](https://medium.com/@a.v.dorogush)。

如果你喜欢这篇文章，可以点击点赞按钮 ????????，如果你对即将发布的文章感兴趣，请确保关注我。

**Medium:** [**https://medium.com/@talperetz24**](https://medium.com/@talperetz24) **Twitter:** [**https://twitter.com/talperetz24**](https://twitter.com/talperetz24) **LinkedIn:** [**https://www.linkedin.com/in/tal-per/**](https://www.linkedin.com/in/tal-per/)

像每年一样，我想提到 [DataHack](https://www.datahack.org.il/)，这是最好的数据驱动黑客马拉松。今年 [דור פרץ](https://medium.com/@sdorperetz) 和我在项目中使用了 Catboost，并获得了第一名 ????。

**简介: [Tal Peretz](https://www.linkedin.com/in/tal-per/)** 是一名数据科学家、软件工程师和持续学习者。他热衷于使用数据、代码和算法解决高价值潜力的复杂问题。他特别喜欢构建和改进模型，将零和一区分开来。0|1

[原文](https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2)。经许可转载。

**相关：**

+   [TensorFlow 中的梯度提升与 XGBoost](/2018/01/gradient-boosting-tensorflow-vs-xgboost.html)

+   [CatBoost 与 Light GBM 与 XGBoost](/2018/03/catboost-vs-light-gbm-vs-xgboost.html)

+   [直观的集成学习指南与梯度提升](/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html)

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT 部门

* * *

### 更多相关主题

+   [检索增强生成：信息检索与文本生成的交汇](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)

+   [终极指南：掌握季节性变化并提升业务成果](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)

+   [提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)

+   [Bark：终极音频生成模型](https://www.kdnuggets.com/2023/05/bark-ultimate-audio-generation-model.html)

+   [人工智能的未来：探索下一代生成模型](https://www.kdnuggets.com/2023/05/future-ai-exploring-next-generation-generative-models.html)

+   [揭示 Midjourney 5.2：AI 图像生成的飞跃](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)
