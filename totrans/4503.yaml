- en: Five Interesting Data Engineering Projects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 五个有趣的数据工程项目
- en: 原文：[https://www.kdnuggets.com/2020/03/data-engineering-projects.html](https://www.kdnuggets.com/2020/03/data-engineering-projects.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/data-engineering-projects.html](https://www.kdnuggets.com/2020/03/data-engineering-projects.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Dmitriy Ryaboy](https://www.linkedin.com/in/dmitriy-ryaboy/), VP Software
    Engineering at Zymergen**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[德米特里·里亚博伊](https://www.linkedin.com/in/dmitriy-ryaboy/)，Zymergen 的软件工程副总裁**。'
- en: There’s been a lot of activity in the data engineering world lately, and a ton
    of really interesting projects and ideas have come on the scene in the past few
    years. This post is an introduction to (just) five that I think a data engineer
    who wants to stay current needs to know about.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最近数据工程领域活动频繁，过去几年涌现出了大量有趣的项目和想法。这篇文章是对我认为数据工程师需要了解的五个项目的介绍。
- en: DBT
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DBT
- en: '![](../Images/3d4f5f9c0fe981793933a5ca46fb4a12.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d4f5f9c0fe981793933a5ca46fb4a12.png)'
- en: 'DBT, or “data build tool,” is a clean, well-executed take on what’s fundamentally
    a simple idea: SQL statements for doing important work should be version controlled,
    and it’d be nice if they could be easily parametrized, and maybe refer to each
    other. DBT is aimed at “data analysts” rather than data engineers (though there’s
    no reason data engineers wouldn’t use it). Everything is done in SQL (well, that
    and YAML).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: DBT，或称“数据构建工具”，是对一个本质上简单的想法的清晰且执行良好的实现：用于执行重要工作的 SQL 语句应进行版本控制，并且最好能轻松参数化，可能相互引用。DBT
    针对的是“数据分析师”，而不是数据工程师（尽管没有理由数据工程师不能使用它）。一切都在 SQL 中完成（嗯，还有 YAML）。
- en: By cleanly structuring how projects are laid out, how queries referring to other
    queries works, and what fields need to be populated in a config, DBT enforces
    a lot of great practices and vastly improves what can often be a messy workflow.
    With all this in place, it can run your workflow — and it can also generate documentation,
    help you run validation and testing queries, share code via packages, and more.
    It has a gentle on-ramp and gives the analyst many powerful tools if she chooses
    to take advantage of them — or stay out of the way, if not.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过清晰地构建项目的布局、查询如何引用其他查询的工作方式以及配置中需要填充的字段，DBT 强制执行了许多优秀的实践，并大大改进了经常是混乱的工作流程。有了这些功能，它不仅可以运行你的工作流，还可以生成文档、帮助你运行验证和测试查询、通过包共享代码等。它提供了一个温和的上手方式，并为分析师提供了许多强大的工具，如果她选择利用这些工具，就可以充分发挥作用——如果不利用，就可以不干涉。
- en: If you or someone in your life does a lot of SQL, they need to check out DBT.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你或你生活中的某个人经常使用 SQL，他们需要了解一下 DBT。
- en: Prefect
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Prefect
- en: '![](../Images/426e5b49e7ef2f1bf56d29090406bd29.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/426e5b49e7ef2f1bf56d29090406bd29.png)'
- en: 'Prefect is an up-and-coming challenger to AirFlow: [yet another data pipeline
    manager](https://github.com/pditommaso/awesome-pipeline) that helps set up DAGs
    of processes, parametrize them, react appropriately to error conditions, create
    schedules and processing triggers, and so on. If you look past their slightly
    arrogant marketing (apparently, Prefect is already a “global leader in dataflow
    automation,” and Airflow is just a “historically important tool”), Prefect has
    a few neat things going that earn it much praise from adopters:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Prefect 是一个新兴的 AirFlow 挑战者：[另一个数据管道管理器](https://github.com/pditommaso/awesome-pipeline)，它帮助设置
    DAG 过程、参数化它们、适当响应错误条件、创建时间表和处理触发器等。如果你忽略它们稍显傲慢的营销（显然，Prefect 已经是“数据流自动化的全球领导者”，而
    Airflow 只是一个“历史上重要的工具”），Prefect 有几个值得称道的地方，赢得了大量用户的赞誉：
- en: It cleanly separates the actual data flows from the scheduling/triggering aspect
    of job management, making things like backfills, ad-hoc runs, parallel workflow
    instances, etc., easier to achieve.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将实际的数据流与作业管理的调度/触发方面清晰分开，使得反向填充、临时运行、并行工作流实例等变得更容易实现。
- en: It’s got a neat functional (as well as an Airflow-like imperative-style) [API](https://docs.prefect.io/core/concepts/flows.html#apis)
    for creating DAGs.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有一个 neat 的功能性（以及类似 Airflow 的命令式风格）[API](https://docs.prefect.io/core/concepts/flows.html#apis)来创建
    DAG。
- en: It avoids the Airflow’s XCom trap of communicating data between tasks through
    a sort of weird side channel that occasionally blows up on you, and instead relies
    on transparent (except when *it *blows up on you) serialization and explicit inputs/outputs
    for individual tasks.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它避免了 Airflow 的 XCom 陷阱，即通过一种奇怪的侧通道在任务之间传递数据，这种方法偶尔会出现问题，而是依赖于透明的（除了*在它出问题的时候*）序列化和个别任务的显式输入/输出。
- en: It makes [dealing with parameters](https://docs.prefect.io/core/concepts/parameters.html)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使得 [处理参数](https://docs.prefect.io/core/concepts/parameters.html)
- en: You can do all this in Airflow, but the Prefect team argues their APIs make
    for a much cleaner and intuitive ways of addressing these and other challenges.
    They seem to have gained quite a few fans who agree.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 Airflow 中完成所有这些工作，但 Prefect 团队认为他们的 API 提供了更干净和直观的方式来解决这些及其他挑战。他们似乎赢得了不少赞同者。
- en: Dask
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dask
- en: '![](../Images/0b1d18ab2f26894dfe46c8345561261a.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b1d18ab2f26894dfe46c8345561261a.png)'
- en: Are people still sleeping on Dask? Stop sleeping on Dask.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 人们还在忽视 Dask 吗？停止忽视 Dask 吧。
- en: “[Dask](https://dask.org/) is a “flexible library for parallel computing in
    Python.” If you are using Python a lot for data work, mostly sticking to NumPy
    / Scikit-learn / Pandas, you might find that throwing Dask in makes things whirr
    incredibly easily. It’s lightweight and fast, it works great on a single machine
    or on a cluster, it [works well with RAPIDS](https://rapids.ai/dask.html) to get
    you GPU acceleration, and it’s likely going to be a much easier transition for
    scale-up than moving your python code over to PySpark. They have a surprisingly
    well-balanced doc talking about pros and cons vs. Spark here: [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html) .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: “[Dask](https://dask.org/) 是一个‘灵活的 Python 并行计算库’。如果你经常用 Python 进行数据工作，主要使用 NumPy
    / Scikit-learn / Pandas，你可能会发现引入 Dask 可以让事情变得非常顺畅。它轻量且快速，无论是在单机还是集群上都表现良好，它与 [RAPIDS](https://rapids.ai/dask.html)
    协同工作，以获得 GPU 加速，并且相对于将你的 Python 代码迁移到 PySpark，可能会更容易进行扩展。他们有一份意外平衡的文档，讨论了 Dask
    与 Spark 的优缺点，详细信息见 [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html)。”
- en: DVC
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DVC
- en: '![](../Images/91351f50fee592559d2d048429aa68aa.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91351f50fee592559d2d048429aa68aa.png)'
- en: DVC stands for “data version control.” This project invites data scientists
    and engineers to a Git-inspired world, where all workflow versions are tracked,
    along with all the data artifacts and models, as well as associated metrics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DVC 代表“数据版本控制”。这个项目邀请数据科学家和工程师进入一个受 Git 启发的世界，在这里，所有工作流版本都被跟踪，以及所有数据工件和模型，还有相关的指标。
- en: 'To be honest, I’m a bit of a skeptic on “git for data” and various automated
    data/workflow versioning schemes: various approaches I’ve seen in the past were
    either too partial to be useful, or required too drastic a change in how data
    scientists worked to get a realistic chance at adoption. So I ignored, or even
    explicitly avoided, checking DVC out as the buzz grew. I’ve finally checked it
    out and… it looks like maybe this has legs? Metrics tied to branches/versions
    are a great feature. Tying the idea of git-like braches to training multiple models
    makes the value prop clear. The implementation, using Git for code and datafile
    index storage, while leveraging scalable data stores for data, and trying to reduce
    overall storage cost by being clever about reuse, looks sane. A lot of what they
    have to say in [https://dvc.org/doc/understanding-dvc](https://dvc.org/doc/understanding-dvc) rings
    true. Thoughtworks used DVC as their demo tool of choice to [discuss “CD4ML”](https://martinfowler.com/articles/cd4ml.html).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，我对“数据的 git”以及各种自动化数据/工作流版本控制方案持有一些怀疑态度：我过去看到的各种方法要么过于局部而不够有用，要么需要数据科学家在工作方式上做出过于剧烈的改变，才有可能被实际采纳。因此，我忽略了，甚至有意回避了查看
    DVC。现在我终于看了一下……看起来也许这个方案有前途？与分支/版本关联的指标是一个很棒的功能。将类似 git 的分支概念与训练多个模型结合，使得价值主张变得清晰。它的实现方式是使用
    Git 进行代码和数据文件索引存储，同时利用可扩展的数据存储进行数据管理，通过聪明的重用来降低整体存储成本，看起来是合理的。他们在 [https://dvc.org/doc/understanding-dvc](https://dvc.org/doc/understanding-dvc)
    上提到的很多内容都很真实。Thoughtworks 使用 DVC 作为他们的演示工具来 [讨论“CD4ML”](https://martinfowler.com/articles/cd4ml.html)。
- en: On the other hand, I’m not super keen on handing over pipeline definition to
    DVC — Airflow or Prefect or a number of other tools appear to offer much more
    on that front. A casual perusal of internet resources revealed multiple mentions
    of using DVC alongside MLFlow or other tools, but it’s not clear how well that
    works and what one gives up.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我并不特别热衷于将管道定义交给 DVC —— Airflow 或 Prefect 或其他许多工具似乎在这方面提供了更多。对互联网资源的随意浏览揭示了多次提到将
    DVC 与 MLFlow 或其他工具一起使用，但尚不清楚这如何运作以及会放弃什么。
- en: Still — DVC is the technology that keeps coming up whenever the problem of “git
    for data” or “git for ML” comes up. It’s definitely worth checking out and keeping
    an eye on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，DVC 是每当出现“数据的 git”或“ML 的 git”问题时总会被提到的技术。它绝对值得关注和留意。
- en: Great Expectations
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Great Expectations
- en: '![](../Images/a08bbfba2cd52652d4134822e076bac9.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: Great Expectations is a really nice Python library that allows you to declare
    rules to which you expect certain datasets to confirm and validate those as you
    encounter (produce or consume) those datasets. These would be expectations such
    as *expect_colum_values_to_match_strftime_format or expect_column_distinct_values_to_be_in_set*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: It’s not wrong to think of these as assertions for data. Expectations can be
    evaluated using a number of common data compute environments (Spark, SQL, Pandas)
    and integrate cleanly into a number of various workflow engines, including DBT
    and Prefect discussed above (as well as Airflow, of course). The [introduction](https://docs.greatexpectations.io/en/latest/intro.html) and [glossary
    of expectations](https://docs.greatexpectations.io/en/latest/expectation_glossary.html) sections
    of their docs are fairly self-explanatory.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: On top of providing ways to define and validate these assertions, Great Expectations
    provides automated data profilers that will *generate the expectations and clean
    HTML data documentation*. How cool is that?!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: It’s not a completely novel idea, but it appears to be well-executed, and the
    library is gaining traction.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Bonus Round
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Maybe it’s a post-Hadoop effect, maybe it’s The Cloud, maybe it’s just that
    Python finally has type hints, but it’s downright difficult to narrow the list
    of interesting projects to five. Here are a few more that I personally would love
    to spend some time with, and think you, a reader so committed that you are still
    here, might enjoy as well, in alphabetical order:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[Amundsen](https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234)
    is an interesting “data discovery and metadata platform” from Lyft. Every self-respecting
    tech unicorn seems to have one of these now. Can we stop and choose a winner?'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cadence](http://cadenceworkflow.io/) is a “fault-oblivious stateful code platform”
    or, in other words, a way to outsource some of the common concerns about having
    long-lived state in your functions to somebody else. Anyway, find time to watch
    this video and consider where this might apply in your life: [https://www.youtube.com/watch?v=llmsBGKOuWI](https://www.youtube.com/watch?v=llmsBGKOuWI)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Calcite](https://calcite.apache.org/) is the core of the deconstructed database,
    providing a SQL parser, a database-agnostic query execution planner and optimizer,
    and more. It [can be found](https://calcite.apache.org/docs/powered_by.html) in
    a number of the “big data” projects that offer SQL support (Hive, Flink, Drill,
    Phoenix…)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dagster](https://github.com/dagster-io/dagster) is a data workflow engine
    from the creator of GraphQL, and aims to transform developer ergonomics for data
    engineers in the way GraphQL did for frontend engineers. It’s good stuff, and
    probably deserves a separate post.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Json-Schema](https://json-schema.org/) is not at all new, but for whatever
    reason, people seem to not know it exists. It exists, it’s been growing, and you
    should define and validate your dang schemas. There are specs, there are tools,
    you can hang this on your existing JSON APIs and not suffer Avro/Thrift/Proto
    envy.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Json-Schema](https://json-schema.org/) 并不是什么新东西，但出于某种原因，人们似乎不知道它的存在。它存在，它在不断发展，你应该定义和验证你的架构。这里有规格，这里有工具，你可以将它应用于现有的JSON
    API中，而不必羡慕Avro/Thrift/Proto。'
- en: '[Original](https://medium.com/@squarecog/five-interesting-data-engineering-projects-48ffb9c9c501).
    Reposted with permission.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@squarecog/five-interesting-data-engineering-projects-48ffb9c9c501)。已获授权转载。'
- en: '**Related:**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[7 Resources to Becoming a Data Engineer](https://www.kdnuggets.com/2020/01/resources-become-data-engineer.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为数据工程师的7个资源](https://www.kdnuggets.com/2020/01/resources-become-data-engineer.html)'
- en: '[The thin line between data science and data engineering](https://www.kdnuggets.com/2019/09/thin-line-between-data-science-data-engineering.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学与数据工程之间的微妙界限](https://www.kdnuggets.com/2019/09/thin-line-between-data-science-data-engineering.html)'
- en: '[A Beginner’s Guide to Data Engineering  –  Part I](https://www.kdnuggets.com/2018/01/beginners-guide-data-engineering-1.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据工程初学者指南 – 第一部分](https://www.kdnuggets.com/2018/01/beginners-guide-data-engineering-1.html)'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多此主题
- en: '[3 Interesting Uses of Python''s Context Managers](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python上下文管理器的三个有趣用法](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
- en: '[KDnuggets™ News 22:n03, Jan 19: A Deep Look Into 13 Data…](https://www.kdnuggets.com/2022/n03.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n03, 1月19日：深入探讨13个数据…](https://www.kdnuggets.com/2022/n03.html)'
- en: '[Become a Data Science Professional in Five Steps](https://www.kdnuggets.com/2022/03/become-data-science-professional-five-steps.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[五步成为数据科学专业人士](https://www.kdnuggets.com/2022/03/become-data-science-professional-five-steps.html)'
- en: '[Top Five SQL Window Functions You Should Know For Data Science Interviews](https://www.kdnuggets.com/2022/01/top-five-sql-window-functions-know-data-science-interviews.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试中你应该知道的五个SQL窗口函数](https://www.kdnuggets.com/2022/01/top-five-sql-window-functions-know-data-science-interviews.html)'
- en: '[Five Signs of an Effective Data Science Manager](https://www.kdnuggets.com/2022/06/five-signs-effective-data-science-manager.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[有效数据科学经理的五个标志](https://www.kdnuggets.com/2022/06/five-signs-effective-data-science-manager.html)'
- en: '[Five Ways to do Conditional Filtering in Pandas](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Pandas中进行条件筛选的五种方法](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
