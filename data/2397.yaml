- en: Does the Random Forest Algorithm Need Normalization?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林算法是否需要归一化？
- en: 原文：[https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html](https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html](https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html)
- en: '![Does the Random Forest Algorithm Need Normalization?](../Images/01e6640db11dfd6c875a881e214a27bf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林算法是否需要归一化？](../Images/01e6640db11dfd6c875a881e214a27bf.png)'
- en: '[Irina Iriser](https://unsplash.com/@iriser) via Unsplash'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Irina Iriser](https://unsplash.com/@iriser) 通过 Unsplash'
- en: I’m going to start off with some definitions, to understand this blog better.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我要从一些定义开始，以更好地理解这篇博客。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Random Forest is a tree-based algorithm consisting of multiple decision trees
    to improve decision-making. It is called a random forest because it is a forest
    of trees that uses bagging and feature randomness. These multiple trees are combined
    together to make predictions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一个基于树的算法，由多个决策树组成，以改善决策。它被称为随机森林，因为它是一个使用袋装和特征随机性的树的森林。这些多棵树结合在一起进行预测。
- en: Normalization is a technique that is done during the data preparation phase
    for machine learning. It is the process of organizing data in a dataset by creating
    new values and presenting the data so that it has a general distribution. It is
    a type of scaling technique where values are rescaled so they range between 0
    and 1 - this is also known as Min-Max scaling. This is done to reduce or completely
    remove redundant data, and data errors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化是一种在机器学习的数据准备阶段进行的技术。它是通过创建新值并展示数据，使其具有一般分布的过程。这是一种缩放技术，其中值被重新缩放到 0 和 1 之间——这也被称为
    Min-Max 缩放。这是为了减少或完全去除冗余数据和数据错误。
- en: How Do I normalize My Data?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何归一化我的数据？
- en: You can use the sklearn library to normalize your data by importing the MinMaxScaler
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 sklearn 库通过导入 MinMaxScaler 来归一化你的数据
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you google the question in the title, the majority of people will say ‘No’.
    Here’s why...
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在谷歌上搜索标题中的问题，大多数人会说‘不需要’。原因如下...
- en: Why Don’t I Need to Normalize Data for the Random Forest Algorithm?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么随机森林算法不需要归一化数据？
- en: The process of scaling data through normalization is to ensure that a specific
    feature is not prioritized over another. This technique is particularly important
    in algorithms that are distance-based, such as K nearest Neighbors and K-means
    as it requires Euclidean Distance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过归一化来缩放数据的过程是为了确保某个特征不会优先于另一个特征。这种技术在基于距离的算法中尤其重要，例如 K 最近邻和 K-means，因为它们需要欧几里得距离。
- en: However, the Random Forest algorithm is not a distance-based model - it is a
    tree-based model. Each node in a Random Forest is not comparing feature values,
    it is simply splitting a sorted list that requires absolute values for branching.
    The algorithm is based on partitioning the data to make predictions, therefore,
    it does not require normalization.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随机森林算法不是基于距离的模型——它是基于树的模型。随机森林中的每个节点不是比较特征值，而是简单地拆分一个需要绝对值的排序列表以进行分支。该算法基于数据分区来进行预测，因此不需要归一化。
- en: For example, a decision tree splits a node on a feature, where this feature
    is not influenced by another feature and neither influences another feature. This
    means that all the remaining features have no effect on the split - so we can
    say that tree-based algorithms are insensitive to the scaling of features.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，决策树在特征上拆分节点，而该特征不会被另一个特征影响，也不会影响另一个特征。这意味着所有剩余特征对拆分没有影响——所以我们可以说基于树的算法对特征的缩放不敏感。
- en: Gini Index
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基尼指数
- en: Rather than scaling features, the Random Forest algorithm allows us to further
    understand the importance of features through Gini index. Also known as Gini impurity,
    determines how well a decision tree, random forest, or another tree-based model
    was split.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法通过基尼指数进一步理解特征的重要性，而不是缩放特征。基尼不纯度也被称为基尼 impurity，决定了决策树、随机森林或其他基于树的模型的分裂效果。
- en: '**The formula:**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**公式：**'
- en: '![Gini Index](../Images/3bf349e90272695b3ad6a6e91126cee8.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![基尼指数](../Images/3bf349e90272695b3ad6a6e91126cee8.png)'
- en: It calculates the probability that a specific feature is classified incorrectly
    when selected randomly. Gini impurity scales between 0-0.5, where the minimum
    value of 0 is the best value (classification is pure) and 0.5 is the worst value
    we can get.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 它计算了一个特定特征在随机选择时被错误分类的概率。基尼 impurity 的范围在0到0.5之间，其中最小值0是最佳值（分类是纯的），0.5是我们能得到的最差值。
- en: Entropy
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 熵
- en: Entropy is the measure of impurity or randomness in the data points. When working
    with machine learning algorithms, your main aim should be to reduce the amount
    of uncertainty and randomness.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是数据点中不纯或随机性的度量。在使用机器学习算法时，你的主要目标应是减少不确定性和随机性。
- en: '![Entropy](../Images/48512193a267aadafb0cd2ac52a32033.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![熵](../Images/48512193a267aadafb0cd2ac52a32033.png)'
- en: Entropy is scaled between 0 and 1, where the minimum value of 0 is the best
    value (purity) and 1 is the worst value (high level of impurity)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 熵的范围从0到1，其中最小值0是最佳值（纯度），1是最差值（高水平的不纯）。
- en: Conclusion
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Normalization is a good technique to use when your data consists of being scaled
    and your choice of machine learning algorithm does not have the ability to make
    assumptions on the distribution of your data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的数据需要被缩放，且你选择的机器学习算法无法对数据的分布做出假设时，归一化是一个很好的技术。
- en: Tree-based models are not based on the distance where features have an effect
    on one another. Gini index and Entropy are both used to calculate information
    gain, therefore normalization is not required.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的模型并不依赖于特征间的距离关系。基尼指数和熵都用于计算信息增益，因此不需要归一化。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家和自由职业技术作家。她特别关注提供数据科学职业建议或教程及理论知识，同时希望探索人工智能如何有利于人类寿命的延续。作为一个热衷学习者，她寻求拓宽自己的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Random Forest vs Decision Tree: Key Differences](https://www.kdnuggets.com/2022/02/random-forest-decision-tree-key-differences.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[随机森林与决策树：关键区别](https://www.kdnuggets.com/2022/02/random-forest-decision-tree-key-differences.html)'
- en: '[Tuning Random Forest Hyperparameters](https://www.kdnuggets.com/2022/08/tuning-random-forest-hyperparameters.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调整随机森林超参数](https://www.kdnuggets.com/2022/08/tuning-random-forest-hyperparameters.html)'
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[K-Means聚类是什么，它的算法如何工作？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
- en: '[Data Transformation: Standardization vs Normalization](https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据转换：标准化与归一化](https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html)'
- en: '[Optimizing Data Storage: Exploring Data Types and Normalization in SQL](https://www.kdnuggets.com/optimizing-data-storage-exploring-data-types-and-normalization-in-sql)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据存储：SQL中的数据类型和归一化探索](https://www.kdnuggets.com/optimizing-data-storage-exploring-data-types-and-normalization-in-sql)'
- en: '[Naïve Bayes Algorithm: Everything You Need to Know](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[朴素贝叶斯算法：你需要知道的一切](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
