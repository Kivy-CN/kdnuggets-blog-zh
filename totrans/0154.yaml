- en: GPT4All is the Local ChatGPT for your Documents and it is Free!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT4All 是本地 ChatGPT，用于您的文档，并且它是免费的！
- en: 原文：[https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)
- en: In this article we will learn **how to deploy and use GPT4All model on your
    CPU only computer** (I am using a *Macbook Pro* without GPU!)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将学习 **如何在仅使用 CPU 的计算机上部署和使用 GPT4All 模型**（我使用的是 *Macbook Pro*，没有 GPU！）
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/164c034be698c48aeca6a7141b048cc9.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是本地 ChatGPT，用于您的文档，并且它是免费的！](../Images/164c034be698c48aeca6a7141b048cc9.png)'
- en: Use GPT4All on Your Computer — Picture by the author
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的计算机上使用 GPT4All — 图片由作者提供
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article we are going to install on our local computer GPT4All (a powerful
    LLM) and we will discover how to interact with our documents with python. A collection
    of PDFs or online articles will be the knowledge base for our question/answers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将安装 GPT4All（一个强大的大型语言模型）到本地计算机，并发现如何用 Python 与文档交互。一组 PDF 或在线文章将作为我们问题/答案的知识库。
- en: What is GPT4All
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 GPT4All
- en: From the [official website GPT4All](https://gpt4all.io/index.html) it is described
    as *a free-to-use, locally running, privacy-aware chatbot. ****No GPU or internet
    required.***
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [官方 GPT4All 网站](https://gpt4all.io/index.html) 可以看到，它被描述为 *一个免费使用、在本地运行、注重隐私的聊天机器人。*
    **无需 GPU 或互联网。**
- en: GTP4All is an ecosystem to train and deploy **powerful** and **customized** large
    language models that run **locally** on consumer grade CPUs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: GTP4All 是一个生态系统，用于训练和部署 **强大的** 和 **定制化的** 大型语言模型，这些模型在 **消费者级** CPU 上 **本地**
    运行。
- en: Our GPT4All model is a 4GB file that you can download and plug into the GPT4All
    open-source ecosystem software. *Nomic AI* facilitates high quality and secure
    software ecosystems, driving the effort to enable individuals and organizations
    to effortlessly train and implement their own large language models locally.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 GPT4All 模型是一个 4GB 的文件，您可以下载并接入 GPT4All 开源生态系统软件。 *Nomic AI* 促进高质量和安全的软件生态系统，推动个人和组织轻松在本地训练和实现自己的大型语言模型。
- en: How it will work?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它将如何运作？
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/d2645a736b7389d955c7058f9ea42dc4.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是本地 ChatGPT，用于您的文档，并且它是免费的！](../Images/d2645a736b7389d955c7058f9ea42dc4.png)'
- en: Workflow of the QnA with GPT4All — created by the author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GPT4All 的问答工作流程 — 作者创建
- en: 'The process is really simple (when you know it) and can be repeated with other
    models too. The steps are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程非常简单（当你知道如何做时），也可以用其他模型重复。步骤如下：
- en: load the GPT4All model
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载 GPT4All 模型
- en: use *Langchain* to retrieve our documents and Load them
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 *Langchain* 来检索我们的文档并加载它们
- en: split the documents in small chunks digestible by Embeddings
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文档拆分成适合嵌入的较小块
- en: Use FAISS to create our vector database with the embeddings
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 FAISS 创建我们的向量数据库并加入嵌入
- en: 'Perform a similarity search (semantic search) on our vector database based
    on the question we want to pass to GPT4All: this will be used as a *context* for
    our question'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对我们的向量数据库执行相似度搜索（语义搜索），根据我们要传递给 GPT4All 的问题：这将作为我们问题的 *上下文*
- en: Feed the question and the context to GPT4All with *Langchain* and wait for the
    the answer.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用 *Langchain* 将问题和上下文提供给 GPT4All，并等待答案。
- en: 'So what we need is Embeddings. An embedding is a numerical representation of
    a piece of information, for example, text, documents, images, audio, etc. The
    representation captures the semantic meaning of what is being embedded, and this
    is exactly what we need. For this project we cannot rely on heavy GPU models:
    so we will download the Alpaca native model and use from *Langchain* the *LlamaCppEmbeddings*.
    Don’t worry! Everything is explained step by step'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们需要的是嵌入。嵌入是信息的数值表示，例如文本、文档、图像、音频等。这种表示捕捉了被嵌入内容的语义意义，这正是我们所需要的。对于这个项目，我们不能依赖重型
    GPU 模型：因此我们将下载 Alpaca 原生模型并从 *Langchain* 使用 *LlamaCppEmbeddings*。别担心！一切都会一步一步地解释清楚
- en: Let’s start coding
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始编码吧
- en: Create a Virtual Environment
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建虚拟环境
- en: 'Create a new folder for your new Python project, for example GPT4ALL_Fabio
    (put your name…):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的文件夹用于你的新 Python 项目，例如 GPT4ALL_Fabio（放上你的名字……）：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, create a new Python virtual environment. If you have more than one python
    version installed, specify your desired version: in this case I will use my main
    installation, associated to python 3.10.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的 Python 虚拟环境。如果你安装了多个 Python 版本，请指定你想要的版本：在这个例子中，我将使用我的主要安装，与 Python
    3.10 相关联。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The command `python3 -m venv .venv` creates a new virtual environment named `.venv` (the
    dot will create a hidden directory called venv).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 命令 `python3 -m venv .venv` 创建了一个名为 `.venv` 的新虚拟环境（点会创建一个名为 venv 的隐藏目录）。
- en: A virtual environment provides an isolated Python installation, which allows
    you to install packages and dependencies just for a specific project without affecting
    the system-wide Python installation or other projects. This isolation helps maintain
    consistency and prevent potential conflicts between different project requirements.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境提供了一个隔离的 Python 安装，它允许你只为特定项目安装包和依赖项，而不会影响系统范围的 Python 安装或其他项目。这种隔离有助于保持一致性并防止不同项目需求之间的潜在冲突。
- en: 'Once the virtual environment is created, you can activate it using the following
    command:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦虚拟环境创建完成，你可以使用以下命令激活它：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/3ee7e916d5dcc6c4d1a6da8715b77627.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你的文档的本地 ChatGPT，并且是免费的！](../Images/3ee7e916d5dcc6c4d1a6da8715b77627.png)'
- en: Activated virtual environment
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 已激活虚拟环境
- en: The libraries to install
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需要安装的库
- en: 'For the project we are building we don’t need too many packages. We need only:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们正在构建的项目，我们不需要太多的包。我们只需要：
- en: python bindings for GPT4All
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4All 的 Python 绑定
- en: Langchain to interact with our documents
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Langchain 与我们的文档进行交互
- en: LangChain is a framework for developing applications powered by language models.
    It allows you not only to call out to a language model via an API, but also connect
    a language model to other sources of data and allow a language model to interact
    with its environment.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个用于开发由语言模型驱动的应用程序的框架。它不仅允许你通过 API 调用语言模型，还可以将语言模型连接到其他数据源，并允许语言模型与其环境进行交互。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For LangChain you see that we specified also the version. This library is receiving
    a lot of updates recently, so to be certain the our setup is going to work also
    tomorrow it is better to specify a version we know is working fine. Unstructured
    is a required dependency for the pdf loader and *pytesseract* and *pdf2image* as
    well.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 LangChain，你会看到我们也指定了版本。这个库最近收到很多更新，因此为了确保我们的设置明天也能正常工作，最好指定一个我们知道运行良好的版本。Unstructured
    是 pdf loader 的必需依赖，*pytesseract* 和 *pdf2image* 也是如此。
- en: '**NOTE**: on the GitHub repository there is a requirements.txt file (suggested
    by [jl adcr](https://medium.com/u/816bd47943c0?source=post_page-----df1016bc335--------------------------------))
    with all the versions associated to this project. You can do the installation
    in one shot, after downloading it into the main project file directory with the
    following command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：在 GitHub 仓库中有一个 requirements.txt 文件（由 [jl adcr](https://medium.com/u/816bd47943c0?source=post_page-----df1016bc335--------------------------------)
    提供），其中包含与此项目相关的所有版本。你可以在下载到主项目文件目录后，使用以下命令一次性完成安装：'
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: At the end of the article I created a [section for the troubleshooting](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#3706).
    The GitHub repo has also an updated READ.ME with all these information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在文章末尾，我创建了一个[故障排除部分](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#3706)。GitHub
    仓库也更新了包含所有这些信息的 READ.ME 文件。
- en: Bear in mind that some **libraries have versions available depending on the
    python version** you are running on your virtual environment.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，一些 **库的版本取决于你在虚拟环境中运行的 python 版本**。
- en: Download on your PC the models
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在你的 PC 上下载模型
- en: This is a really important step.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常重要的步骤。
- en: For the project we certainly need GPT4All. The process described on Nomic AI
    is really complicated and requires hardware that not all of us have (like me).
    So [here is the link to the model](https://huggingface.co/mrgaang/aira/blob/main/gpt4all-converted.bin) already
    converted and ready to be used. Just click on download.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于项目，我们确实需要 GPT4All。Nomic AI 上描述的过程非常复杂，并且需要不是我们所有人都有的硬件（像我）。所以 [这是转换后的模型链接](https://huggingface.co/mrgaang/aira/blob/main/gpt4all-converted.bin)，已经转换并准备使用。只需点击下载。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/d2c094d736d30e97efaf5e8ca711fa8b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你的文档本地 ChatGPT，而且是免费的！](../Images/d2c094d736d30e97efaf5e8ca711fa8b.png)'
- en: Download the GPT4All model
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 GPT4All 模型
- en: As described briefly in the introduction we need also the model for the embeddings,
    a model that we can run on our CPU without crushing. Click the [link here to download
    the alpaca-native-7B-ggml](https://huggingface.co/Pi3141/alpaca-native-7B-ggml/tree/397e872bf4c83f4c642317a5bf65ce84a105786e) already
    converted to 4-bit and ready to use to act as our model for the embedding.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如简介中简要描述的，我们还需要用于嵌入的模型，一个可以在 CPU 上运行而不会崩溃的模型。点击 [这里的链接下载 alpaca-native-7B-ggml](https://huggingface.co/Pi3141/alpaca-native-7B-ggml/tree/397e872bf4c83f4c642317a5bf65ce84a105786e)，它已经转换为
    4-bit，并准备作为我们的嵌入模型使用。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/c7ba2460adee0a81425d5fdcdd3541d4.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你的文档本地 ChatGPT，而且是免费的！](../Images/c7ba2460adee0a81425d5fdcdd3541d4.png)'
- en: Click the download arrow next to [ggml-model-q4_0.bin](https://huggingface.co/Pi3141/alpaca-native-7B-ggml/blob/397e872bf4c83f4c642317a5bf65ce84a105786e/ggml-model-q4_0.bin)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 [ggml-model-q4_0.bin](https://huggingface.co/Pi3141/alpaca-native-7B-ggml/blob/397e872bf4c83f4c642317a5bf65ce84a105786e/ggml-model-q4_0.bin)
    旁边的下载箭头
- en: Why we need embeddings? If you remember from the flow diagram the first step
    required, after we collect the documents for our knowledge base, is to *embed *them.
    The LLamaCPP embeddings from this Alpaca model fit the job perfectly and this
    model is quite small too (4 Gb). By the way you can also use the Alpaca model
    for your QnA!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要嵌入？如果你记得流程图，收集知识库文档后的第一步是 *嵌入* 它们。来自 Alpaca 模型的 LLamaCPP 嵌入非常适合这个任务，而且这个模型也相当小（4
    Gb）。顺便说一下，你也可以使用 Alpaca 模型进行问答！
- en: 'Update 2023.05.25: Mani Windows users are facing problems to use the llamaCPP
    embeddings. This mainly happens because during the installation of the python
    package llama-cpp-python with:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 更新于 2023.05.25：Mani Windows 用户在使用 llamaCPP 嵌入时遇到问题。这主要是因为在安装 python 包 llama-cpp-python
    时：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: the pip package is going to compile from source the library. Windows usually
    does not have CMake or C compiler installed by default on the machine. But don’t
    warry there is a solution
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: pip 包将从源代码编译库。Windows 通常默认未安装 CMake 或 C 编译器。但不用担心，这里有解决方案。
- en: Running the installation of llama-cpp-python, required by LangChain with the
    llamaEmbeddings, on windows CMake C complier is not installed by default, so you
    cannot build from source.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上安装 llama-cpp-python（LangChain 所需的 llamaEmbeddings）时，CMake C 编译器默认未安装，因此你无法从源代码构建。
- en: On Mac Users with Xtools and on Linux, usually the C complier is already available
    on the OS.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Mac 用户使用 Xtools 和 Linux 上，通常 C 编译器已在操作系统中提供。
- en: To avoid the issue **you MUST use pre complied wheel**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这个问题 **你必须使用预编译的 wheel**。
- en: Go here [https://github.com/abetlen/llama-cpp-python/releases](https://github.com/abetlen/llama-cpp-python/releases)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 [https://github.com/abetlen/llama-cpp-python/releases](https://github.com/abetlen/llama-cpp-python/releases)
- en: and look for the complied wheel for your architecture and python version — **you
    MUST take Weels Version 0.1.49 **because higher versions are not compatible.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 并且寻找与你的架构和 python 版本相匹配的编译好的 wheel — **你必须使用 Weels 版本 0.1.49**，因为更高版本不兼容。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/059c34d6ca9fb76e5db455d7252a6238.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你的文档本地 ChatGPT，而且是免费的！](../Images/059c34d6ca9fb76e5db455d7252a6238.png)'
- en: Screenshot from [https://github.com/abetlen/llama-cpp-python/releases](https://github.com/abetlen/llama-cpp-python/releases)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 截图来自 [https://github.com/abetlen/llama-cpp-python/releases](https://github.com/abetlen/llama-cpp-python/releases)
- en: In my case I have Windows 10, 64 bit, python 3.10
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我的情况是 Windows 10，64 位，python 3.10
- en: so my file is llama_cpp_python-0.1.49-cp310-cp310-win_amd64.whl
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我的文件是 llama_cpp_python-0.1.49-cp310-cp310-win_amd64.whl
- en: This [issue is tracked on the GitHub repository](https://github.com/fabiomatricardi/GPT4All_Medium/issues/2)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个[问题在 GitHub 仓库中跟踪](https://github.com/fabiomatricardi/GPT4All_Medium/issues/2)
- en: After downloading you need to put the two models in the models directory, as
    shown below.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下载后，你需要将两个模型放入模型目录，如下所示。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/2fdc93855b6963db59ee794c8fd8e21f.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你文档的本地 ChatGPT，并且是免费的！](../Images/2fdc93855b6963db59ee794c8fd8e21f.png)'
- en: Directory structure and where to put the model files
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目录结构以及模型文件的放置位置
- en: Basic Interaction with GPT4All
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 GPT4All 的基本互动
- en: Since we want to have control of our interaction the the GPT model, we have
    to create a python file (let’s call it *pygpt4all_test.py*), import the dependencies
    and give the instruction to the model. You will see that is quite easy.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们想要控制与 GPT 模型的交互，我们需要创建一个 Python 文件（我们称之为*pygpt4all_test.py*），导入依赖项并给模型下达指令。你会发现这很简单。
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is the python binding for our model. Now we can call it and start asking.
    Let’s try a creative one.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们模型的 Python 绑定。现在我们可以调用它并开始提问。让我们试一个创意的。
- en: We create a function that read the callback from the model, and we ask GPT4All
    to complete our sentence.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个函数来读取模型的回调，并要求 GPT4All 完成我们的句子。
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The first statement is telling our program where to find the model (remember
    what we did in the section above)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个声明是告诉我们的程序在哪里找到模型（记住我们在上面部分做了什么）
- en: The second statement is asking the model to generate a response and to complete
    our prompt "Once upon a time,".
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个声明是要求模型生成回应，并完成我们的提示“从前，一次…”
- en: 'To run it, make sure that the virtual environment is still activated and simply
    run :'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行它，请确保虚拟环境仍然激活，然后简单地运行：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You should se a loading text of the model and the completion of the sentence.
    Depending on your hardware resources it may take a little time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到模型的加载文本和句子的完成。根据你的硬件资源，这可能需要一点时间。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/2c46d0381e481042610ded3f36e4bde4.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你文档的本地 ChatGPT，并且是免费的！](../Images/2c46d0381e481042610ded3f36e4bde4.png)'
- en: The result may be different from yours… But for us the important is that it
    is working and we can proceed with LangChain to create some advanced stuff.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能与您的不同……但对我们来说，重要的是它在工作，我们可以继续使用 LangChain 创建一些高级功能。
- en: '**NOTE (updated 2023.05.23)**: if you face an error related to pygpt4all, check
    the troubleshooting section on this topic with the solution given by [Rajneesh
    Aggarwal](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#25f6) or [by
    Oscar Jeong.](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#a6a6)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意（更新于 2023.05.23）**：如果遇到与 pygpt4all 相关的错误，请查看本主题的故障排除部分，解决方案由[Rajneesh Aggarwal](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#25f6)
    或 [Oscar Jeong](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335#a6a6)
    提供。'
- en: LangChain template on GPT4All
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 在 GPT4All 上的模板
- en: LangChain framework is a really amazing library. It provides *Components* to
    work with language models in a easy to use way, and it also provides *Chains*.
    Chains can be thought of as assembling these components in particular ways in
    order to best accomplish a particular use case. These are intended to be a higher
    level interface through which people can easily get started with a specific use
    case. These chains are also designed to be customizable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 框架是一个非常了不起的库。它提供了 *组件* 以一种易于使用的方式与语言模型进行工作，同时也提供了 *链*。链可以被视为以特定方式组装这些组件，以最佳方式完成特定用例。这些旨在成为一个高级接口，通过它人们可以轻松开始特定用例。这些链也被设计为可自定义的。
- en: In our next python test we will use a *Prompt Template*. Language models take
    text as input — that text is commonly referred to as a prompt. Typically this
    is not simply a hardcoded string but rather a combination of a template, some
    examples, and user input. LangChain provides several classes and functions to
    make constructing and working with prompts easy. Let’s see how we can do it too.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们下一个 Python 测试中，我们将使用 *Prompt Template*。语言模型接受文本作为输入——这些文本通常被称为提示。通常，这不仅仅是一个硬编码的字符串，而是模板、一些示例和用户输入的组合。LangChain
    提供了几个类和函数，使构造和使用提示变得容易。让我们看看如何做到这一点。
- en: Create a new python file and call it *my_langchain.py*
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的 Python 文件，并称其为 *my_langchain.py*
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We imported from LangChain the Prompt Template and Chain and GPT4All llm class
    to be able to interact directly with our GPT model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 LangChain 中导入了 Prompt Template 和 Chain 以及 GPT4All llm 类，以便能够直接与我们的 GPT 模型进行交互。
- en: Then, after setting our llm path (as we did before) we instantiate the callback
    managers so that we are able to catch the responses to our query.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在设置好我们的 llm 路径（如我们之前所做的）之后，我们实例化回调管理器，以便能够捕获对我们查询的响应。
- en: 'To create a template is really easy: following the [documentation tutorial](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html) we
    can use something like this…'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模板其实非常简单：按照 [文档教程](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)
    的指导，我们可以使用类似这样的东西……
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The *template* variable is a multi-line string that contains our interaction
    structure with the model: in curly braces we insert the external variables to
    the template, in our scenario is our *question*.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*template* 变量是一个多行字符串，包含了我们与模型交互的结构：在花括号中插入外部变量，在我们的场景中是我们的 *question*。'
- en: 'Since it is a variable you can decide if it is an hard-coded question or an
    user input question: here the two examples.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个变量，你可以决定它是一个硬编码问题还是用户输入的问题：以下是两个示例。
- en: '[PRE11]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For our test run we will comment the user input one. Now we only need to link
    together our template, the question and the language model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的测试运行，我们将注释掉用户输入部分。现在我们只需要将模板、问题和语言模型连接起来。
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Remember to verify your virtual environment is still activated and run the
    command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 记得检查你的虚拟环境是否仍然激活，并运行以下命令：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You may get a different results from mine. What is amazing is that you can see
    the entire reasoning followed by GPT4All trying to get an answer for you. Adjusting
    the question may give you better results too.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会得到与我不同的结果。令人惊讶的是，你可以看到 GPT4All 尝试为你找到答案的整个推理过程。调整问题也可能会给你更好的结果。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/37f6fc0d50f8004779fd138b45aca20f.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是您文档的本地 ChatGPT，它是免费的！](../Images/37f6fc0d50f8004779fd138b45aca20f.png)'
- en: Langchain with Prompt Template on GPT4All
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain 与 GPT4All 上的 Prompt Template
- en: Answering Question About your Documents Using LangChain and GPT4All
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 和 GPT4All 回答有关您文档的问题
- en: Here we start the amazing part, because we are going to talk to our documents
    using GPT4All as a chatbot who replies to our questions.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进入了令人兴奋的部分，因为我们将使用 GPT4All 作为聊天机器人与我们的文档对话，回答我们的提问。
- en: The sequence of steps, referring to *Workflow of the QnA with GPT4All*, is to
    load our pdf files, make them into chunks. After that we will need a Vector Store
    for our embeddings. We need to feed our chunked documents in a vector store for
    information retrieval and then we will embed them together with the similarity
    search on this database as a context for our LLM query.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤序列，参见 *QnA with GPT4All 的工作流程*，是加载我们的 PDF 文件，将它们拆分成块。之后我们将需要一个向量存储来存储我们的嵌入。我们需要将分块的文档放入向量存储中进行信息检索，然后将它们与此数据库上的相似性搜索一起嵌入，作为我们
    LLM 查询的上下文。
- en: 'For this purposes we are going to use FAISS directly from *Langchain* library.
    FAISS is an open-source library from Facebook AI Research, designed to quickly
    find similar items in big collections of high-dimensional data. It offers indexing
    and searching methods to make it easier and faster to spot the most similar items
    within a dataset. It is particularly convenient for us because it simplifies **information
    retrieval **and allow us to save locally the created database: this means that
    after the first creation it will be loaded very fast for any further usage.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为此目的，我们将直接使用 *Langchain* 库中的 FAISS。FAISS 是 Facebook AI Research 提供的开源库，旨在快速找到大规模高维数据集中相似的项目。它提供了索引和搜索方法，使得在数据集中快速找到最相似的项目变得更加容易和迅速。它对我们特别方便，因为它简化了
    **信息检索** 并允许我们将创建的数据库本地保存：这意味着在第一次创建之后，它会非常快速地加载以便进一步使用。
- en: Creation of the vector index db
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量索引数据库的创建
- en: Create a new file and call it *my_knowledge_qna.py*
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新文件，并命名为 *my_knowledge_qna.py*
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The first libraries are the same we used before: in addition we are using *Langchain* for
    the vector store index creation, the *LlamaCppEmbeddings* to interact with our
    Alpaca model (quantized to 4-bit and compiled with the cpp library) and the PDF
    loader.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个库与我们之前使用的相同：此外，我们还使用了 *Langchain* 来创建向量存储索引，*LlamaCppEmbeddings* 用于与我们的 Alpaca
    模型（量化为 4 位并与 cpp 库编译）交互，以及 PDF 加载器。
- en: 'Let’s also load our LLMs with their own paths: one for the embeddings and one
    for the text generation.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还加载带有各自路径的 LLM：一个用于嵌入，另一个用于文本生成。
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For test let’s see if we managed to read all the pfd files: the first step
    is to declare 3 functions to be used on each single document. The first is to
    split the extracted text in chunks, the second is to create the vector index with
    the metadata (like page numbers etc…) and the last one is for testing the similarity
    search (I will explain better later).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试，我们来看看是否成功读取了所有的 pfd 文件：第一步是声明三个函数，用于每一个单独的文档。第一个是将提取的文本分割成块，第二个是使用元数据（如页码等）创建向量索引，最后一个是测试相似性搜索（稍后我会详细解释）。
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now we can test the index generation for the documents in the *docs* directory:
    we need to put there all our pdfs. *Langchain* has also a method for loading the
    entire folder, regardless of the file type: since it is complicated the post process,
    I will cover it in the next article about LaMini models.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以测试 *docs* 目录中文档的索引生成：我们需要将所有 PDF 文件放到那里。*Langchain* 也有一个加载整个文件夹的方法，无论文件类型如何：由于后处理比较复杂，我将在下一篇关于
    LaMini 模型的文章中介绍。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/08db5a1bdd2f487dab7db09671d6910f.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是您文档的本地 ChatGPT，并且是免费的！](../Images/08db5a1bdd2f487dab7db09671d6910f.png)'
- en: my docs directory contains 4 pdf files
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我的 docs 目录包含 4 个 PDF 文件。
- en: We will apply our functions to the first document in the list
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对列表中的第一个文档应用我们的函数。
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the first lines we use os library to get the **list of pdf files** inside
    the docs directory. We then load the first document (*doc_list[0]*) from the docs
    folder with *Langchain*, split in chunks and then we create the vector database
    with the *LLama* embeddings.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几行中，我们使用 os 库来获取 docs 目录中的 **pdf 文件列表**。然后，我们用 *Langchain* 从 docs 文件夹加载第一个文档
    (*doc_list[0]*)，将其分割成块，然后用 *LLama* 嵌入创建向量数据库。
- en: 'As you saw we are using the [pyPDF method](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html?highlight=pypdf#using-pypdf).
    This one is a bit longer to use, since you have to load the files one by one,
    but loading PDF using `pypdf` into array of documents allows you to have an array
    where each document contains the page content and metadata with `page` number.
    This is really convenient when you want to know the sources of the context we
    will give to GPT4All with our query. Here the example from the readthedocs:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们正在使用 [pyPDF 方法](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html?highlight=pypdf#using-pypdf)。这个方法使用起来有点长，因为你需要逐个加载文件，但使用
    `pypdf` 加载 PDF 到文档数组中可以让你拥有一个数组，其中每个文档包含页面内容和带有 `page` 号的元数据。这在你想知道我们将给 GPT4All
    查询的上下文来源时非常方便。这里是来自 readthedocs 的示例：
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/57c5bcbffab238b4be4b1c8fdabbfa8f.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是您文档的本地 ChatGPT，并且是免费的！](../Images/57c5bcbffab238b4be4b1c8fdabbfa8f.png)'
- en: Screenshot from [Langchain documentation](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [Langchain 文档](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/pdf.html)
    的截图
- en: 'We can run the python file with the command from terminal:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过终端命令运行 Python 文件：
- en: '[PRE18]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After the loading of the model for embeddings you will see the tokens at work
    for the indexing: don’t freak out since it will take time, specially if you run
    only on CPU, like me (it took 8 minutes).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载嵌入模型后，你会看到用于索引的 token 在工作：不要惊慌，因为这会花费一些时间，特别是如果你只在 CPU 上运行，就像我一样（花了 8 分钟）。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/7c0e84382e2c6cec24cb602d31b91ab4.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是您文档的本地 ChatGPT，并且是免费的！](../Images/7c0e84382e2c6cec24cb602d31b91ab4.png)'
- en: Completion of the first vector db
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个向量数据库的完成
- en: As I was explaining the pyPDF method is slower but gives us additional data
    for the similarity search. To iterate through all our files we will use a convenient
    method from FAISS that allows us to MERGE different databases together. What we
    do now is that we use the code above to generate the first db (we will call it *db0*)
    and the with a for loop we create the index of the next file in the list and merge
    it immediately with *db0*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我所解释的，pyPDF 方法较慢，但可以为我们提供额外的数据用于相似性搜索。为了遍历所有文件，我们将使用 FAISS 提供的一个便捷方法，它允许我们将不同的数据库合并在一起。我们现在所做的是使用上述代码生成第一个数据库（我们称之为
    *db0*），然后使用 for 循环创建列表中下一个文件的索引，并立即将其与 *db0* 合并。
- en: 'Here is the code: note that I added some logs to give you the status of the
    progress using *datetime.datetime.now()* and printing the delta of end time and
    start time to calculate how long the operation took (you can remove it if you
    don’t like it).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：注意我添加了一些日志，用*datetime.datetime.now()* 显示进度状态，并打印结束时间和开始时间的差值来计算操作花费了多长时间（如果你不喜欢可以删除它）。
- en: The merge instructions is like this
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 合并指令如下
- en: '[PRE19]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'One of the last instructions is for saving our database locally: the entire
    generation can take even hours (depends on how many documents you have) so it
    is really good that we have to do it only once!'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条指令是将我们的数据库保存在本地：整个生成过程可能需要几个小时（取决于你有多少文档），所以我们只需做一次真的很不错！
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here the entire code. We will comment many part of it when we interact with
    GPT4All loading the index directly from our folder.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是完整的代码。当我们与 GPT4All 互动时，我们将直接从文件夹加载索引，并注释掉代码的许多部分。
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/b7462d11c62eb0ad963007bac8f2c01f.png)Running
    the python file took 22 minutes'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![GPT4All 是你文档的本地 ChatGPT，而且是免费的！](../Images/b7462d11c62eb0ad963007bac8f2c01f.png)运行
    Python 文件花费了 22 分钟'
- en: Ask questions to GPT4All on your documents
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向 GPT4All 提问关于你的文档
- en: Now we are here. We have our index, we can load it and with a Prompt Template
    we can ask GPT4All to answer our questions. We start with an hard-coded question
    and then we will loop through our input questions.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在这里了。我们有了索引，可以加载它，并通过提示模板要求 GPT4All 回答我们的问题。我们从一个硬编码的问题开始，然后我们将循环遍历输入的问题。
- en: Put the following code inside a python file *db_loading.py* and run it with
    the command from terminal *python3 db_loading.py*
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码放入 Python 文件*db_loading.py*中，并使用终端命令*python3 db_loading.py*运行它
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The printed text is the list of the 3 sources that best matches with the query,
    giving us also the document name and the page number.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 打印的文本是与查询最匹配的 3 个来源的列表，还包括文档名称和页码。
- en: '![GPT4All is the Local ChatGPT for your Documents and it is Free!](../Images/cb666d32a09071a7e154c4b2610c1394.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![GPT4All 是你文档的本地 ChatGPT，而且是免费的！](../Images/cb666d32a09071a7e154c4b2610c1394.png)'
- en: Results of the semantic search running the file *db_loading.py*
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 运行文件*db_loading.py*的语义搜索结果
- en: 'Now we can use the similarity search as the context for our query using the
    prompt template. After the 3 functions just replace all the code with the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用相似性搜索作为我们查询的上下文，通过提示模板进行操作。在这 3 个函数之后，将所有代码替换为以下内容：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: After running you will get a result like this (but may vary). Amazing no!?!?
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 运行后你将得到类似这样的结果（但可能有所不同）。惊人吧！？!
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If you want a user-input question to replace the line
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想用用户输入的问题来替换这一行
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'with something like this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 用这样的东西：
- en: '[PRE26]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Conclusions
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'It is time for you to experiment. Ask different questions on all the topics
    related to your documents, and see the results. There is a big room for improvement,
    certainly on the prompt and template: you can have a look [here for some inspirations](https://github.com/hwchase17/langchain/blob/master/docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb).
    But *Langchain* documentation is really amazing (I could follow it!!).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是你进行实验的时候了。对与你的文档相关的所有主题提出不同的问题，看看结果如何。确实有很大的改进空间，尤其是在提示和模板上：你可以查看[这里的一些灵感](https://github.com/hwchase17/langchain/blob/master/docs/modules/prompts/prompt_templates/examples/custom_prompt_template.ipynb)。但*Langchain*文档真的很棒（我可以跟着它！！）。
- en: You can follow the code from the article or check it on [my github repo](https://github.com/fabiomatricardi/GPT4All_Medium).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照文章中的代码，或者在[我的 GitHub 仓库](https://github.com/fabiomatricardi/GPT4All_Medium)中查看它。
- en: '**[Fabio Matricardi](https://www.linkedin.com/in/fabio-matricardi-29354835/)**
    an educator, teacher, engineer and learning enthusiast. He have been teaching
    for 15 years to young students, and now he train new employees at Key Solution
    Srl. He started my career as Industrial Automation Engineer in 2010\. Passionate
    about programming since he was a teenager, he discovered the beauty of building
    software and Human Machine Interfaces to bring something to life. Teaching and
    coaching is part of my daily routine, as well as studying and learning how to
    be a passionate leader with up to date management skills. Join me in the journey
    toward a better design, a predictive system integration using Machine Learning
    and Artificial Intelligence throughout the entire engineering lifecycle.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Fabio Matricardi](https://www.linkedin.com/in/fabio-matricardi-29354835/)**
    是一位教育工作者、教师、工程师和学习爱好者。他已在年轻学生中教授了 15 年课程，现在在 Key Solution Srl 培训新员工。他在 2010 年开始了工业自动化工程师的职业生涯。自青少年时期起，他就对编程充满热情，发现了构建软件和人机界面的美妙，以便赋予事物生命。教学和辅导是他的日常工作的一部分，同时他也在学习和研究如何成为一名充满激情的领导者，掌握最新的管理技能。加入我，一同踏上设计改进之旅，利用机器学习和人工智能在整个工程生命周期中实现预测系统集成。'
- en: '[Original](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335).
    Reposted with permission.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://artificialcorner.com/gpt4all-is-the-local-chatgpt-for-your-documents-and-it-is-free-df1016bc335)。转载经许可。'
- en: More On This Topic
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Classifying Long Text Documents Using BERT](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 BERT 对长文本文档进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
- en: '[Convert Text Documents to a TF-IDF Matrix with tfidfvectorizer](https://www.kdnuggets.com/2022/09/convert-text-documents-tfidf-matrix-tfidfvectorizer.html)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 tfidfvectorizer 将文本文档转换为 TF-IDF 矩阵](https://www.kdnuggets.com/2022/09/convert-text-documents-tfidf-matrix-tfidfvectorizer.html)'
- en: '[Converting Text Documents to Token Counts with CountVectorizer](https://www.kdnuggets.com/2022/10/converting-text-documents-token-counts-countvectorizer.html)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 CountVectorizer 将文本文档转换为词频计数](https://www.kdnuggets.com/2022/10/converting-text-documents-token-counts-countvectorizer.html)'
- en: '[LangChain + Streamlit + Llama: Bringing Conversational AI to Your…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LangChain + Streamlit + Llama: 将对话 AI 带入你的…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
- en: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Llama, Llama, Llama: 使用你的内容进行本地 RAG 的 3 个简单步骤](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
- en: '[ChatGPT CLI: Transform Your Command-Line Interface Into ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT CLI: 将你的命令行界面转变为 ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
