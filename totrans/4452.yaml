- en: Getting Started with TensorFlow 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html](https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: But wait… What is Tensorflow?
  prefs: []
  type: TYPE_NORMAL
- en: Tensorflow is a Deep Learning Framework by Google, which released its 2nd version
    in 2019\. It is one of the world's most famous Deep Learning frameworks widely
    used by Industry Specialists and Researchers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/27d7d21c1f39e5d239bfde9d58901f9c.png)'
  prefs: []
  type: TYPE_IMG
- en: Tensorflow v1 was difficult to use and understand as it was less Pythonic, but
    with v2 released with Keras now fully synchronized with Tensorflow.keras, it is
    easy to use, easy to learn, and simple to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, this is not a post on Deep Learning so I expect you to be aware of
    Deep Learning terms and the basic ideas behind it.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore the world of Deep Learning with a very famous data set known
    as the IRIS data set.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s jump straight into code to understand what is happening.
  prefs: []
  type: TYPE_NORMAL
- en: Importing and understanding the dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now this *iris *is a dictionary. We can see it’s keys using
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: So our data is in *data *key, *target *is in *target *key, and so on. If you
    want to see details of this dataset, you can use *iris['DESCR']*.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have to import other important libraries which will help us in creating
    our neural network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here we have imported 2 main things from *tensorflow*, which are *Dense *and *Sequential*.
    Dense as we have imported it from *tensorflow.keras.layers* is a type of layer
    which is densely connected. The densely connected layer means that all nodes of
    previous layers are connected to all nodes of the current layers.
  prefs: []
  type: TYPE_NORMAL
- en: '*Sequential *is an API from Keras commonly known as Sequential API that we
    will use to make our neural network.'
  prefs: []
  type: TYPE_NORMAL
- en: To understand the data better, we can convert it into a data frame. Let’s do
    it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1a17ff1a41c152e622471e6fd6c98472.png)'
  prefs: []
  type: TYPE_IMG
- en: '*X.head()*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that here we have set *columns = iris.feature_names* where *feature_names* is
    a key with the name of all 4 features.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly for targets,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0eac9b8469dbf8748e065646effff790.png)'
  prefs: []
  type: TYPE_IMG
- en: '*y.head()*'
  prefs: []
  type: TYPE_NORMAL
- en: To explore number of classes in our target set, we can use
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/0560867fbbaed129cfdede35d6c8aa1d.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see that we have 3 classes, each with labels 0,1, and 2\. To see
    the label name, we can use
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b91e865e6854978c5a5257f86f22cdc8.png)'
  prefs: []
  type: TYPE_IMG
- en: These are the names of the classes which we have to predict.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing for machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, the first step for machine learning is data preprocessing. The main steps
    in data preprocessing are
  prefs: []
  type: TYPE_NORMAL
- en: Filling missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting of data into training and validation sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalization of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversion of categorical data into one-hot vector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To check if we have any missing values, we can use *pandas.DataFrame.info()* method
    to check.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/fe8d25e4564ba83ca6e87ad6976cc8e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see that we have no missing value (luckily) and all our features
    are in *float64*.
  prefs: []
  type: TYPE_NORMAL
- en: Splitting into train and test sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To split the data into the training and test sets, we can use *train_test_split* from *sklearn.model_selection* previously
    imported.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: where *test_size* is the argument that tells us that we want our test data to
    be 10% of the whole data.
  prefs: []
  type: TYPE_NORMAL
- en: Normalization of data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Typically, we normalize the data when we have a high amount of variance in it.
    To check the variance, we can use *var()* function from *panadas.DataFrame* to
    check var of all columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7fdeaec43949d8c7924abe329fcc3d20.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see that both *X_train* and *X_test *have very low variance, so
    no need to normalize the data.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical data into one-hot vector
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we know that our output data is one of 3 classes already checked using *iris.target_names*,
    the good thing is that when we loaded the targets, they were already in 0, 1,
    2 format where 0=1st class, 1=2nd class, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with this representation is that our model might give higher numbers
    more priority, which can lead to results that are biased. So to tackle this, we
    are going to use one-hot representation. You can learn more about one-hot vectors [here](https://towardsdatascience.com/tagged/one-hot-encoder).
    We can either use the Keras built-in *to_categorical* or use *OneHotEncoder *from *sklearn*.
    We will use *to_categorical*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We will review the first 5 rows only to check if it has converted it correctly
    or not.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d3ed2e9fbc7510745ddd4041088ff1a3.png)'
  prefs: []
  type: TYPE_IMG
- en: And yes, we have converted it into a one-hot representation.
  prefs: []
  type: TYPE_NORMAL
- en: One last thing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One last thing we can do is to convert our data back to *numpy* arrays so that
    we can use some extra functions that will help us later in our model. To do this
    we can use
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see what the result of the 1st training example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/04d96ffa5100df2a7b9e4703fd801307.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see the value of 4 features in the 1st training example, and its
    shape is (4,)
  prefs: []
  type: TYPE_NORMAL
- en: Our target labels were already in array format when we used *to_categorical *on
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now finally, we are ready to create our model and train it. We will start from
    a simple model, and then we will go to complex model structures where we will
    cover different tips and techniques in Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Lets code our basic model
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: First, we have to create a Sequential Object. Now, to create a model, all we
    have to do is to add different types of layers as per our choice. We will make
    a 10 Dense layers model so that we can observe over-fitting, and reduce it later
    by different Regularization techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Notice that in our first layer, we have used an extra argument of *input_shape.*
    This argument specifies the dimension of the first layer. We do not care about
    the number of training examples in this case. Instead, we only care about the
    number of features. So we pass in the shape of any training example, in our case,
    it was *(4,)* inside *input_shape*.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we have used *softmax *the activation function in our output layer
    because it is a multi-class classification problem. If it was a binary classification
    problem, we would have used *sigmoid *the activation function instead.
  prefs: []
  type: TYPE_NORMAL
- en: We can pass in any activation function we want such as *sigmoid *or *linear *or *tanh*,
    but it is proved via experiments that *relu *performs best in these kinds of models.
  prefs: []
  type: TYPE_NORMAL
- en: Now when we have defined the shape of our model, the next step is to specify
    it’s *loss*, *optimizer*, and *metrics*. We specify these using *compile *method
    in Keras.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Here we can use any *optimizer *such as Stochastic Gradient Descent, RMSProp,
    etc., but we will use Adam.
  prefs: []
  type: TYPE_NORMAL
- en: We are using* categorical_crossentropy* here because we have a multi-class classification
    problem, if we have a binary class classification problem, we would have used *binary_crossentropy* instead.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are important to evaluate one’s model. There are different metrics on
    the basis of which we can evaluate our model. For classification problems, the
    most important metric is accuracy, which tells how accurate our predictions are.
  prefs: []
  type: TYPE_NORMAL
- en: The last step in our model is to *fit *it on training data and training labels.
    Let's code it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*fit *returns a callback that has all the history of our training, which we
    can use to do different useful tasks such as plotting etc.'
  prefs: []
  type: TYPE_NORMAL
- en: History callback has an attribute named as *history *that we can access as *history.histor*y, which
    is a dictionary having all the history of losses and metrics, i.e., in our case,
    it has a history of *loss*, *acc*, *val_loss*, and *val_acc *and we can access
    every single one as *history.history.loss* or *history.history['val_acc']* etc.
  prefs: []
  type: TYPE_NORMAL
- en: We have a specified number of epochs to 800, batch size to 40, and validation
    split to 0.1, meaning that we have now 10% validation data which we will use to
    analyze our training. Using 800 epochs will overfit the data, which means it will
    perform very well on training data, but not on testing data.
  prefs: []
  type: TYPE_NORMAL
- en: While the model is training, we can see our loss and accuracy both on the training
    and validation set.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c7de26eaff37ce5a7ae933093179dd0f.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we can see that our training accuracy is 100% and validation accuracy is
    67% which is pretty good for such a model. Let’s plot it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/f2b06dab8c76bc54892942f9cef732a1.png)'
  prefs: []
  type: TYPE_IMG
- en: We can clearly see that accuracy for the training set is much higher than the
    accuracy for the validation set.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we can plot Loss as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/c0346f3004ad5b809b658278d9ddc2d6.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can clearly see that our Validation Loss is much higher than our Training
    Loss, which is because we have overfitted the data.
  prefs: []
  type: TYPE_NORMAL
- en: To check the model performance, we can use *model.evaluate* to check the performance
    of the model. We need to pass data and labels in evaluate method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/b9696ef0ade7616e2f860f2e0e08106c.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we can see that our model is giving 88% accuracy, which is pretty good
    for an overfitted model.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s make it better by adding regularization into our model. Regularization
    will reduce overfitting from our model and will improve our model.
  prefs: []
  type: TYPE_NORMAL
- en: We will add L2 regularization in our model. Learn more about L2 regularization [here](https://towardsdatascience.com/concept-of-regularization-28f593cf9f8c#:~:text=The%20idea%20behind%20L1%20regularization,absolute%20value%20of%20the%20coefficients.).
    To add L2 regularization in our model, we have to specify the layers, in which
    we want to add regularization and give an additional parameter which is *kernel_regularizer*,
    and pass *tf.keras.regularizers.l2()*.
  prefs: []
  type: TYPE_NORMAL
- en: We will also implement some dropout in our model, which will help us reduce
    the overfitting better, and hence a better performing model. To read more about
    the theory and motivation behind dropout, refer to [this](https://medium.com/towards-artificial-intelligence/an-introduction-to-dropout-for-regularizing-deep-neural-networks-4e0826c10395) article.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s remake the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: If you notice closely, we have all the layers and parameters the same except
    we have added 2 dropout layers and regularization in each dense layer.
  prefs: []
  type: TYPE_NORMAL
- en: We will keep all other things (loss, optimizer, epochs, etc.) the same.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now evaluate the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/896442fe9c63adaa29f8e114f2540f5e.png)'
  prefs: []
  type: TYPE_IMG
- en: And guess what? We improved our accuracy from 88% to 94% just by adding regularization
    and dropout. If we add batch normalization to it, it will improve further.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s plot it.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/34d8f3d812ad25df126fa15aa6a85cf8.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/30516b12b65b5845fa8587a5b27685c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Insights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here we can see that we have successfully removed the overfitting from over
    model, and improve our model by almost 6%, which is a good improvement for such
    a small dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[TensorFlow 2.0 Tutorial: Optimizing Training Time Performance](https://www.kdnuggets.com/2020/03/tensorflow-optimizing-training-time-performance.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow 2.0: Dynamic, Readable, and Highly Extended](https://www.kdnuggets.com/2019/08/tensorflow-20.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Avoid Overfitting with Regularization](https://www.kdnuggets.com/2018/02/avoid-overfitting-regularization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
