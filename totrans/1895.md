# 21 个必须知道的数据科学面试问题与答案，第 2 部分

> 原文：[https://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers-part2.html](https://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers-part2.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](2016/02/21-data-science-interview-questions-answers-part2.html/3#comments) KDnuggets 上的帖子[20 个识别伪数据科学家的问题](/2016/01/20-questions-to-detect-fake-data-scientists.html)非常受欢迎——本月浏览量最多的帖子。

然而，这些问题仍未得到解答，因此 KDnuggets 编辑们聚集在一起，撰写了[答案](/2016/02/21-data-science-interview-questions-answers.html)。以下是第 2 部分的答案，从一个“奖励”问题开始。

* * *

### 奖励问题：解释什么是过拟合以及如何控制它

这个问题不是原始 20 个问题的一部分，但可能是区分真正的数据科学家和伪数据科学家最重要的问题。

**答案由 [Gregory Piatetsky](/author/gregory-piatetsky) 提供。**

过拟合是指发现虚假的结果，这些结果是由于偶然因素造成的，并且无法通过后续研究重复。

我们经常看到新闻报道有关推翻之前发现的研究，例如鸡蛋不再对健康有害，或者[饱和脂肪与心脏病无关](http://well.blogs.nytimes.com/2014/03/17/study-questions-fat-and-heart-disease-link/)。在我们看来，问题在于许多研究人员，特别是在社会科学或医学领域，过于频繁地犯了数据挖掘的基本罪过——**过拟合数据**。

研究人员测试了太多假设而没有适当的统计控制，直到偶然发现一些有趣的东西并报告出来。不出所料，下次这个效应（至少部分是由于偶然因素）会小得多或完全不存在。

这些研究实践的缺陷由 John P. A. Ioannidis 在他开创性的论文[*为什么大多数已发布的研究发现是错误的*](http://www.plosmedicine.org/article/info%3Adoi%2F10.1371%2Fjournal.pmed.0020124)（PLoS Medicine，2005）中识别并报告。Ioannidis 发现，结果往往被夸大，或者发现无法重复。在他的论文中，他提供了统计证据，证明大多数声称的研究发现确实是虚假的。

Ioannidis 指出，为了使研究发现可靠，应该具备以下条件：

+   大样本量和大效应

+   测试关系的数量更多，但选择的测试关系较少

+   设计、定义、结果和分析模式上的更大灵活性

+   由于财务和其他因素（包括该科学领域的受欢迎程度）造成的最小偏差

不幸的是，这些规则经常被违反，从而产生了不可重复的结果。例如，S&P 500指数被发现与孟加拉国的黄油生产（19891年至1993年）有很强的关系（[这里是PDF](http://nerdsonwallstreet.typepad.com/my_weblog/files/dataminejune_2000.pdf)）

![S&P 500与孟加拉国黄油的相关性](../Images/9b3e97a5a2730530c90aea057bbe45f7.png)

查看更多有趣（且完全虚假的）发现，你可以使用[Google correlate](https://www.google.com/trends/correlate/)或[Spurious correlations](http://www.tylervigen.com/discover)（由泰勒·维根提供）的工具自行探索。

可以使用几种方法来避免“过拟合”数据

+   尽量找到最简单的假设

+   [正则化](https://en.wikipedia.org/wiki/Regularization_(mathematics))（对复杂性加以惩罚）

+   随机化测试（随机化类别变量，尝试在这些数据上应用你的方法——如果发现相同的强结果，则可能存在问题）

+   嵌套交叉验证（在一个层级上进行特征选择，然后在外层级上运行整个方法进行交叉验证）

+   调整[虚假发现率](https://en.wikipedia.org/wiki/False_discovery_rate)

+   使用[可重复的保留方法](/2015/08/feldman-avoid-overfitting-holdout-adaptive-data-analysis.html)——这是2015年提出的突破性方法

优秀的数据科学处于世界科学理解的前沿，数据科学家有责任避免数据过拟合，并向公众和媒体普及不良数据分析的危险。

另见

+   [数据挖掘和数据科学的根本罪过：过拟合](/2014/06/cardinal-sin-data-mining-data-science.html)

+   [避免过拟合的重大理念：可重复的保留以保持自适应数据分析的有效性](/2015/08/feldman-avoid-overfitting-holdout-adaptive-data-analysis.html)

+   [用可重复的保留方法克服过拟合：在自适应数据分析中保持有效性](/2015/08/reusable-holdout-preserving-validity-adaptive-data-analysis.html)

+   [11种聪明的过拟合方法及如何避免它们](/2015/01/clever-methods-overfitting-avoid.html)

+   [标签：过拟合](/tag/overfitting)

* * *

### Q12\. 举一个你如何使用实验设计来回答关于用户行为的问题的例子。

由[**Bhavya Geethika**](/author/geethika)回答。

**步骤 1：制定研究问题：**

页面加载时间对用户满意度评分有什么影响？

**步骤 2：识别变量：**

我们识别因果关系。自变量——页面加载时间，因变量——用户满意度评分

**步骤 3：生成假设：**

更低的页面下载时间对网页的用户满意度评分将产生更大影响。我们在此分析的因素是页面加载时间。

![实验设计中的缺陷](../Images/25ad9ff6b6030b72983b2a7d7bba18bd.png)

图 12：您的实验设计存在缺陷（漫画来自 [这里](https://sites.psu.edu/academy/2014/10/29/a-lesson-on-experimental-design/))

**步骤 4：确定实验设计。**

我们考虑实验的复杂性，即一次变更一个因素或同时变更多个因素，在这种情况下我们使用因子设计（2^k 设计）。设计的选择还基于目标类型（比较、筛选、响应面）和因素的数量。

在这里，我们还会识别参与者内设计、参与者间设计和混合模型。例如：一个页面有两个版本，一个版本的“购买”按钮（行动号召）在左侧，另一个版本的按钮在右侧。

参与者内设计- 两组用户都看到两个版本。

参与者间设计- 一组用户看到版本 A，另一组用户看到版本 B。

**步骤 5：制定实验任务与程序：**

实验步骤的详细描述、用于测量用户行为的工具、目标和成功指标应予以定义。收集关于用户参与的定性数据以进行统计分析。

**步骤 6：确定操控与测量**

操控：一个因素的水平将被控制，另一个将被操控。我们还识别行为测量指标：

1.  延迟- 提示与行为发生之间的时间（用户在看到产品后点击购买所需的时间）。

1.  频率- 行为发生的次数（用户在特定时间内点击某页面的次数）

1.  持续时间- 特定行为持续的时间（添加所有产品所花费的时间）

1.  强度- 行为发生的力度（用户购买产品的速度）

**步骤 7：分析结果**

识别用户行为数据并根据观察结果支持或反驳假设，例如，大多数用户的满意度评分与页面加载时间的比较。

* * *

### Q13\. “长”（“高”）格式数据和“宽”格式数据之间有什么区别？

**由 [Gregory Piatetsky](/author/gregory-piatetsky) 提供的答案。**

在大多数数据挖掘/数据科学应用中，记录（行）通常远多于特征（列）——这种数据有时被称为“高”数据（或“长”数据）。

在一些应用中，如基因组学或生物信息学，您可能只有少量记录（例如 100 个患者），但每个患者可能有 20,000 个观察数据。适用于“高”数据的标准方法会导致数据过拟合，因此需要特别的方法。

![宽数据 高数据](../Images/dce8c3fc8418ba05b251e8955b61d6ca.png)

**图 13：高数据和宽数据的不同处理方法**，出自演示文稿 [Sparse Screening for Exact Data Reduction](http://www.slideshare.net/BigDataMining/screening-ye14)，作者：Jieping Ye。

问题不仅仅是重塑数据（这里有[有用的R包](https://psychwire.wordpress.com/2011/05/16/reshape-package-in-r-long-data-format-to-wide-back-to-long-again/)），还包括通过减少特征数量来避免假阳性，以找到最相关的特征。

像Lasso这样的特征降维方法在[《统计学习与稀疏性：Lasso及其推广》](http://web.stanford.edu/~hastie/StatLearnSparsity/)一书中得到了很好的介绍，作者为Hastie、Tibshirani和Wainwright。（你可以免费下载这本书的PDF）

### 更多相关内容

+   [检测假数据科学家的20个问题（及答案）：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)

+   [检测假数据科学家的20个问题（及答案）：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)

+   [7个数据分析面试问题及答案](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)

+   [5个Python面试问题及答案](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)

+   [数据科学面试指南 - 第2部分：面试资源](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)

+   [KDnuggets新闻，5月4日：9门免费哈佛课程学习数据…](https://www.kdnuggets.com/2022/n18.html)
