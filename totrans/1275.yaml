- en: Model Experiments, Tracking and Registration using MLflow on Databricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html](https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Dash Desai](https://www.linkedin.com/in/dash-desai/), Director of Platform
    and Technical Evangelism at StreamSets**'
  prefs: []
  type: TYPE_NORMAL
- en: Learn how StreamSets, [a modern data integration platform for DataOps](https://streamsets.com/),
    can help expedite operations at some of the most crucial stages of Machine Learning
    Lifecycle and MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Data Acquisition And Preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning models are only as good as the quality of data and the size
    of datasets used to train the models. [Data has shown](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#282426e76f63) that
    data scientists spend around 80% of their time on preparing and managing data
    for analysis and 57% of the data scientists regard cleaning and organizing data
    as the least enjoyable part of their work. This further validates the idea of 
    MLOps and the need for collaboration between data scientists and data engineers.
  prefs: []
  type: TYPE_NORMAL
- en: During this crucial phase of data acquisition and preparation, data scientists
    identify what types of (trusted) datasets are needed to train models and work
    closely with data engineers to acquire data from viable data sources.
  prefs: []
  type: TYPE_NORMAL
- en: How Can StreamSets Help
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some of the common data sources for acquiring datasets for data science projects
    include: Amazon S3, Microsoft Azure Blob Storage, Google Cloud Storage, Kafka,
    Hadoop, on-prem and cloud data warehouses. StreamSets DataOps Platform provides
    easy-to-use GUI for building smart data pipelines for streaming and batch dataflows
    for fast data ingestion of large amounts of data from distributed systems–including
    all of the common sources mentioned above.'
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect of the data ingestion process is the storage–in some cases, companies
    may already have a data lake or a data warehouse and in some cases they may need
    to build one. StreamSets DataOps Platform is capable of connecting to existing
    data lakes and data warehouses (on-prem or in the cloud) and also has built-in
    capabilities of creating new ones.
  prefs: []
  type: TYPE_NORMAL
- en: '![Modern Data Integration for DataOps](../Images/12bff326545c71bc6f41afffdea07c7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As part of building these data pipelines, data engineers can also perform some
    of the key transformations needed by data scientists. Some of the common transformations
    required during data preparation include: data type conversion for fields/columns/features,
    renaming fields/columns/features, joining datasets, merging datasets, repartitioning,
    dataset data format conversion (for example, JSON to Parquet for efficient downstream
    analysis in Apache Spark), etc. All of these transformations and many more are
    readily supported by StreamSets DataOps Platform.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Imp Note: Extensive and thorough feature engineering tasks and in depth analysis
    of features, their correlation with the target variable, feature importances,
    etc. is best suited for and better performed on interactive tools, such as, Databricks
    Notebook, Jupyter, RStudio, and ML platforms.*'
  prefs: []
  type: TYPE_NORMAL
- en: Model Experiments, Tracking, And Registration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Experimentation is a big precursor to model development where data scientists
    take sufficient subsets of trusted datasets and create several models in a rapid,
    iterative manner.
  prefs: []
  type: TYPE_NORMAL
- en: Without proper industry standards, data scientists have to rely on manual tracking
    of models, inputs, hyperparameters, outputs and any other such artifacts throughout
    the model experimentation and development process. This results in very long model
    deployment/release cycles, which effectively prevents organizations from adapting
    to dynamic changes, gaining competitive advantage, and in some cases staying in
    compliance with changing governance and regulations.
  prefs: []
  type: TYPE_NORMAL
- en: How Can StreamSets Help
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using StreamSets Transformer, [a Spark ETL engine](https://streamsets.com/products/dataops-platform/transformer-etl/),
    it’s easy to integrate with [MLflow](https://mlflow.org/) using its PySpark or
    Scala APIs.
  prefs: []
  type: TYPE_NORMAL
- en: This MLflow integration allows for tracking and versioning of model training
    code, data, config, hyperparameters as well as register and manage models in a
    central repository in MLflow from Transformer. This is critical for retraining
    models and/or for reproducing experiments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html),
    this creates a powerful and seamless solution because [Transformer can run on
    Databricks](https://streamsets.com/solutions/streamsets-for-databricks/) clusters
    and Databricks comes bundled with MLflow server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end Use Case
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s walk through an end-to-end scenario where we’ll ingest data from a cloud
    object storage (for example, Amazon S3), perform necessary transformations, and
    train a regression model. The dataset consists of a set of houses with features
    like number of bedrooms, bathrooms, square footage, etc. and the price it was
    sold at.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from tracking, versioning, and registering models in MLflow with every
    run we’d also like the pipeline to automatically promote models from “*staging*”
    to “*production*” provided they meet a certain set of conditions. For example,
    if *r2 >= ${r2Threshold} or rmse <= ${rmseThreshold},* then the model needs to
    be promoted to “Production” on MLflow server on Databricks. This can be one of
    the requirements and part of the specification given by the data scientists to
    the data engineering team responsible for deploying the models.
  prefs: []
  type: TYPE_NORMAL
- en: Pipeline Overview
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The StreamSets Transformer pipeline shown below is designed to load training
    data from [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Origins/AmazonS3.html#concept_gww_1kw_shb),
    perform transformations like [remove](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/FieldRemover.html#concept_svw_dxf_fhb) row
    id, rename target column “*mdev*” to “*label*” (which is required by SparkMLlib),
    train **Gradient Boosted Regression** model using [PySpark](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) processor
    and archive the training data in [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Destinations/AmazonS3-D.html#concept_ymh_534_d3b).
  prefs: []
  type: TYPE_NORMAL
- en: More importantly, the pipeline also integrates with [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html) to
    track and version model training code including hyperparameters, model evaluation
    metrics, and register models.
  prefs: []
  type: TYPE_NORMAL
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/b18bd6ccd1ef4da94c8ad40ce57f779c.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Training And Experimentation**'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the code snippet of interest in [PySpark Processor](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) —
    this is part of the pipeline that trains the Gradient Boosted Regression model
    and tracks everything in MLflow including promoting models from “*staging*” to
    “*production*” based on certain conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Show All ▼
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Tracking in MLflow On Databricks**'
  prefs: []
  type: TYPE_NORMAL
- en: Here are the model training runs from the Transformer pipeline tracked in MLflow.
  prefs: []
  type: TYPE_NORMAL
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/621550444f5f5e9f78ea27f94aeda536.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Versioning in MLflow On Databricks**'
  prefs: []
  type: TYPE_NORMAL
- en: Here are the model versions registered from the Transformer pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/71af7b1d9949d7e5d7bde0d90f25de9f.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Comparison in MLflow On Databricks**'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a side-by-side comparison of two selected models created from the Transformer
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/a9f6c3ab266eb42837024a2c6d8e62c6.png)**'
  prefs: []
  type: TYPE_NORMAL
- en: Model Retraining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, a very common requirement is to automate the process of retraining the
    model as and when more data becomes available–especially if the model hasn’t yet
    met the evaluation criteria. For example, accuracy can be one of the metrics on
    how a particular model is evaluated. This type of automation can be implemented
    by setting up an [orchestrator pipeline](https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title) as
    shown below.
  prefs: []
  type: TYPE_NORMAL
- en: The orchestrator pipeline is designed to continuously run and “wait” for training
    dataset  files to be uploaded on Amazon S3\. As soon as a training dataset is
    uploaded, this pipeline triggers/starts the model (re)training job described earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '![Model Experiments, Tracking and Registration using MLflow on StreamSets and
    Databricks](../Images/303066fe0a00df998d4f07c69006e900.png)'
  prefs: []
  type: TYPE_IMG
- en: Also note that there are two hyperparameters ***maxIter*** and ***numberOfCVFolds*** passed
    in the pipeline so there’s no need to hard code them, and can be dynamically passed
    into the pipeline during model retraining and experimentation. The StreamSets
    DataOps Platform also provides ways to check the status of jobs that are currently
    running so that actions can be taken based on the status as shown above in the
    pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Pipelines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you’re interested in additional technical details and sample pipelines,
    please reach out to me: dash at streamsets dot com or [@iamontheinet](https://twitter.com/iamontheinet).'
  prefs: []
  type: TYPE_NORMAL
- en: Get Started With Your Own Model Experiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: StreamSets DataOps Platform is not a machine learning platform, but it does
    provide important capabilities and extensibility that can help and expedite operations
    at some of the most crucial stages of the ML Lifecycle and MLOps.
  prefs: []
  type: TYPE_NORMAL
- en: Learn more about [StreamSets For Databricks](https://streamsets.com/products/cloud/streamsets-for-databricks-marketplace/) available
    on AWS Marketplace and Microsoft Azure Marketplace.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Dash Desai](https://www.linkedin.com/in/dash-desai/)** is Director
    of Platform and Technical Evangelism at StreamSets, and has 18+ years of hands-on
    software and data engineering background. With recent experience in Big Data,
    Data Science, and Machine Learning, Dash applies his technical skills to help
    build solutions that solve business problems and surface trends that shape markets
    in new ways. Dash has worked for global enterprises and tech startups in agile
    environments as an engineer and a solutions architect. As a Platform and Technical
    Evangelist, he is passionate about evaluating new ideas to help articulate how
    technology can address a given business problem. He also enjoys writing technical
    blog posts, hands-on tutorials, and conducting technical workshops.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://streamsets.com/blog/model-experiments-tracking-and-registration-using-mlflow-on-databricks/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[MLOps Is Changing How Machine Learning Models Are Developed](/2020/12/mlops-changing-machine-learning-developed.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical
    Performance](/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Managing Machine Learning Cycles: Five Learnings from comparing Data Science
    Experimentation/ Collaboration Tools](/2020/01/managing-machine-learning-cycles.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Versioning Machine Learning Experiments vs Tracking Them](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Package and Distribute Machine Learning Models with MLFlow](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Developing an Open Standard for Analytics Tracking](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Best Tools for Machine Learning Experiment Tracking](https://www.kdnuggets.com/2023/02/7-best-tools-machine-learning-experiment-tracking.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Design Experiments for Data Collection](https://www.kdnuggets.com/2022/04/design-experiments-data-collection.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
