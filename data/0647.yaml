- en: Crop Disease Detection Using Machine Learning and Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习和计算机视觉检测作物疾病
- en: 原文：[https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html](https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html](https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn), ZS New York
    AI Center of Excellence**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn)，ZS 纽约 AI 卓越中心**'
- en: International Conference on Learning Representations (ICLR) and Consultative
    Group on International Agricultural Research (CGIAR) jointly conducted a [challenge](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    where over 800 data scientists globally competed to detect diseases in crops based
    on close shot pictures. The objective of this challenge is to build a machine
    learning algorithm to correctly classify if a plant is healthy, has stem rust,
    or has leaf rust.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 国际学习表示大会（ICLR）与国际农业研究咨询小组（CGIAR）联合开展了一项 [挑战赛](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)，全球超过800名数据科学家参与，通过近景图片检测作物疾病。该挑战的目标是构建一个机器学习算法，以准确分类植物是否健康、是否有茎锈病或叶锈病。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Wheat rust is a devastating plant disease affecting many crops, reducing yields
    and affecting the livelihoods of farmers and decreasing food security across Africa.
    The disease is difficult to monitor at a large scale, making it difficult to control
    and eradicate. An accurate image recognition model that can detect wheat rust
    from any image will enable a crowd-sourced approach to monitor crops.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 小麦锈病是一种严重的植物病害，影响许多作物，减少产量，影响农民生计，并降低非洲的食品安全。该疾病在大规模监测时很难控制和根除。一个能够从任何图像中检测小麦锈病的准确图像识别模型，将使众包监测作物成为可能。
- en: Data
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: The imagery data came from a variety of sources. The bulk of the data was collected
    in-field by International Maize and Wheat Improvement Center ([CIMMYT](https://www.cimmyt.org/))
    and their partners in Ethiopia and Tanzania. The remainder of the data were sourced
    from public images found on Google Images. For this challenge, external data,
    other than the data provided, was prohibited. Below are a few examples of data
    by category viz., healthy wheat, leaf rust and stem rust.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据来自多个来源。大部分数据由国际玉米和小麦改良中心 ([CIMMYT](https://www.cimmyt.org/)) 及其在埃塞俄比亚和坦桑尼亚的合作伙伴在田间收集。其余数据来自谷歌图片上的公开图像。在此挑战中，禁止使用提供的数据以外的外部数据。以下是按类别分类的数据示例，即健康小麦、叶锈病和茎锈病。
- en: Healthy wheat
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 健康小麦
- en: '![Figure](../Images/f152ee4e2a672c6878282994bcdc7eb6.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/f152ee4e2a672c6878282994bcdc7eb6.png)'
- en: Leaf rust
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 叶锈病
- en: '![Figure](../Images/1c4d05b37984b6c1b8753aa42a214d31.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/1c4d05b37984b6c1b8753aa42a214d31.png)'
- en: Stem rust
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 茎锈病
- en: '![Figure](../Images/79d22c1450c08fbfb4ff82378cbc9d5c.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/79d22c1450c08fbfb4ff82378cbc9d5c.png)'
- en: '**Figure 1\. Sample images of different categories**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1\. 不同类别的示例图像**'
- en: There were 876 images in the data that were provided to train the AI model (142
    healthy, 358 leaf rust and 376 stem rust). The test data on which the final performance
    would be measured, had 610 images and their labels were not revealed to the participants
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的训练AI模型的数据中共有876张图片（142张健康，358张叶锈病和376张茎锈病）。最终性能测试的数据有610张图片，标签未向参与者透露。
- en: Methodology
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方法论
- en: The state of the art approach for determining a plant’s health based on pictures
    is a type of deep learning called Convolutional Neural Network ([CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)).
    The overall modeling process required several steps for effectively preparing
    the data for the CNN model to yield a good result. Figure 2 below illustrates
    the detailed set of steps involved.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图片确定植物健康状态的最先进方法是一种称为卷积神经网络（[CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)）的深度学习方法。整体建模过程需要几个步骤来有效地准备数据，使
    CNN 模型能产生良好的结果。下图 2 展示了涉及的详细步骤。
- en: '![Figure](../Images/76522f67abe91265c5480c2bc8a2199b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/76522f67abe91265c5480c2bc8a2199b.png)'
- en: '**Figure 2\. Model Pipeline**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2\. 模型流程**'
- en: Of the various steps in the pipeline, Data Augmentation particularly played
    a significant role in increasing the model performance. We used multiple data
    augmentation techniques -illustrated below.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个流程的各个步骤中，数据增强特别在提升模型性能方面发挥了重要作用。我们使用了多种数据增强技术 - 如下图所示。
- en: '![Figure](../Images/66a72d0df3223327852648b549ef3114.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/66a72d0df3223327852648b549ef3114.png)'
- en: '**a. Vertical and Horizontal Flip**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**a. 垂直和水平翻转**'
- en: '![Figure](../Images/66a72d0df3223327852648b549ef3114.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/66a72d0df3223327852648b549ef3114.png)'
- en: '**b. Lighting standardization**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**b. 光照标准化**'
- en: '![Figure](../Images/331d9fd11ff318b8e24337fd64df2b6a.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/331d9fd11ff318b8e24337fd64df2b6a.png)'
- en: '**c. Zoom and Crop**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**c. 缩放和裁剪**'
- en: '![Figure](../Images/0e26a9dcb0dc6154b8cd486b1c09f709.png)![Figure](../Images/f77b3def7e9cc27b180629433d112363.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/0e26a9dcb0dc6154b8cd486b1c09f709.png)![图](../Images/f77b3def7e9cc27b180629433d112363.png)'
- en: '**Figure 3\. Data augmentation illustration**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3\. 数据增强示意图**'
- en: The next critical step is the CNN model architecture design. We used [transfer
    learning](https://en.wikipedia.org/wiki/Transfer_learning) to build on the existing
    [ImageNet](http://www.image-net.org/) models. While there are multiple pre-trained
    models available (viz., VGG, ResNet, InceptionV3, DenseNet, EfficientNet, etc.)
    we chose [DenseNet201](https://www.kaggle.com/pytorch/densenet201) for its lower
    complexity, fewer parameters and cost-effective computation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的关键步骤是 CNN 模型架构设计。我们使用了[迁移学习](https://en.wikipedia.org/wiki/Transfer_learning)来基于现有的[ImageNet](http://www.image-net.org/)模型进行构建。虽然有多个预训练模型可用（例如
    VGG、ResNet、InceptionV3、DenseNet、EfficientNet 等），我们选择了[DenseNet201](https://www.kaggle.com/pytorch/densenet201)因为它的复杂性较低、参数较少且计算成本更为经济。
- en: '![Figure](../Images/9b59e849c35984083589dd4bc5ae7885.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/9b59e849c35984083589dd4bc5ae7885.png)'
- en: '**Figure 4\. DenseNet201 model architecture**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4\. DenseNet201 模型架构**'
- en: We tuned the model, along with different data augmentation methods iteratively
    before we achieved our final performance. For reference, we show how the model
    performance has evolved over the iterations in Figure 5.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在达到最终性能之前，反复调整模型及不同的数据增强方法。作为参考，我们在图 5 中展示了模型性能在迭代过程中的演变。
- en: '![Figure](../Images/1b124886c32e7916d0f07d82ea1916dd.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/1b124886c32e7916d0f07d82ea1916dd.png)'
- en: '**Figure 5\. Model performance over iterations**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 5\. 模型性能随迭代变化**'
- en: Results
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果
- en: Our final score was a log loss of 0.288 on the test dataset ranking 53^(rd)
    on the [final leaderboard](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    among 839 participants. Over the test sample of 610 images, this translated to
    approximately 580 correctly classified instances – in other words, the model accuracy
    is 95%. This is quite good for practical usage and considering that we trained
    only on the limited competition dataset, the accuracy can be further improved
    by adding more data points.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终得分是在测试数据集上获得的对数损失为 0.288，在 839 名参与者中排名第 53^(rd) [最终排行榜](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)。在
    610 张测试图像样本中，这相当于约 580 个正确分类的实例——换句话说，模型准确率为 95%。这对于实际使用来说相当好，并且考虑到我们仅在有限的比赛数据集上进行训练，通过添加更多的数据点可以进一步提高准确率。
- en: Performance is great but, [what] has the model learnt?
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能非常出色，但[模型学到了什么]？
- en: '**a. Model explanations**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**a. 模型说明**'
- en: Outside of competition setting, if we expect our model to be used in practical
    applications, it is important to explain why the model classified a given image.
    We explored a few examples using an explainable AI technique called Gradient-weighted
    Class Activation Map (Grad-CAM) to highlight the areas of images that the model
    based its decision on. Figure 6 illustrates a couple examples.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在竞赛环境之外，如果我们期望模型在实际应用中使用，解释模型为何对给定图像进行分类是很重要的。我们探索了一些使用可解释AI技术（称为梯度加权类别激活图（Grad-CAM））的示例，以突出模型基于哪些图像区域作出决策。图
    6 展示了一些例子。
- en: 'Leaf Rust: Original Image (Left) and Grad-CAM Heatmap Image (Right)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 叶锈病：原始图像（左）和Grad-CAM热图图像（右）
- en: '![Figure](../Images/d60821983ec7ad8c1c91b022893db7c1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/d60821983ec7ad8c1c91b022893db7c1.png)'
- en: 'Stem Rust: Original Image (Left) and Grad-CAM Heatmap Image (Right)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 茎锈病：原始图像（左）和Grad-CAM热图图像（右）
- en: '![Figure](../Images/4e4828a96bc8973466d35ba1c840b7b2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/4e4828a96bc8973466d35ba1c840b7b2.png)'
- en: '**Figure 6\. Explaining model predictions using Grad-CAM**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 6\. 使用Grad-CAM解释模型预测**'
- en: From the explanation, we can see that the model managed to latch on to the rust
    portions of leaf and stem to accurately classify the category.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从解释中我们可以看到，模型能够准确分类的原因在于它抓住了叶子和茎上的锈斑部分。
- en: '**b. Inferring how the models see the different classes using Deep Dream**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**b. 通过深度梦境推断模型如何识别不同类别**'
- en: One way to visualize what the model has learnt is to turn the network upside
    down and ask it to enhance an input image in such a way as to elicit an output
    class. Say you want to know what sort of image would result in “Banana”, start
    with an image full of random noise, then gradually tweak the image towards what
    the neural net considers a banana. This is called Deep Dream
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可视化模型学习内容的方法是将网络倒置，并让其增强输入图像，以便引发特定的输出类别。假设你想知道什么样的图像会产生“香蕉”的分类，从一个充满随机噪声的图像开始，然后逐渐调整图像，直到它被神经网络认为是香蕉。这被称为深度梦境（Deep
    Dream）。
- en: '![Figure](../Images/48f343a79fab473ab89fe078e91d94de.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/48f343a79fab473ab89fe078e91d94de.png)'
- en: '**Figure 7\. An Example to let trained model generate Image for Class Banana**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 7\. 让训练后的模型为香蕉类别生成图像的示例**'
- en: We applied the deep dream approach on our model and generated the figures for
    the respective classes. The below figures each specify what the model thinks in
    general an image looks like for a respective class.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在模型上应用了深度梦境方法，并生成了相应类别的图像。下面的图像分别说明了模型通常认为某一类别图像的样子。
- en: '![Figure](../Images/f17acab9a85e050f6ec1be0c7108733f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/f17acab9a85e050f6ec1be0c7108733f.png)'
- en: '**Figure 8\. Deep Dream Results for all classes based on our model**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 8\. 基于我们模型的所有类别的深度梦境结果**'
- en: 'We notice for different classes, our model has found important distinguishing
    patterns:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到对于不同的类别，模型发现了重要的区分模式：
- en: 'Healthy Wheat: Major color is green, has leaf-like features, no rust-related
    colors such as yellow/orange'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康小麦：主要颜色为绿色，具有叶状特征，没有锈斑相关的颜色如黄色/橙色
- en: 'Leaf Rust: Has mixture of colors, has leaf-like pattern and there are rust-related
    colors (yellow/orange) on leaf-like pattern'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 叶锈病：颜色混合，具有叶子状特征，并且叶子状特征上有锈斑相关的颜色（黄色/橙色）
- en: 'Stem Rust: Has tube-like pattern and there are rust-related colors (yellow/orange)
    on tube-like pattern'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 茎锈病：具有管状模式，并且管状模式上有锈斑相关的颜色（黄色/橙色）
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have shown how deep learning techniques can be applied to
    detect wheat rust in crops based on close shot images. In addition to good prediction
    accuracy, we have also demonstrated that the model is able to effectively learn
    the right representations through the explanations inferred from class activation
    maps. When scaled, this approach can help in digitally monitoring crop health
    and could lead to significant improvement in the agriculture productivity and
    yield.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了如何将深度学习技术应用于基于近距离图像检测作物小麦锈病。除了良好的预测准确性，我们还展示了模型如何通过从类别激活图推断的解释来有效学习正确的表示。当扩展应用时，这种方法可以帮助数字监测作物健康，并可能显著提高农业生产力和产量。
- en: The ZS AI team ranked in the top 6% on the [final leaderboard](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    with a prediction accuracy of 95%.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ZS AI团队在[最终排行榜](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)中排名前6%，预测准确率为95%。
- en: '**Bio: [Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn)** leads
    the ZS New York AI Center of Excellence. He has 15+ years of experience in helping
    clients across industries in designing and implementing AI solutions.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn)** 领导ZS纽约AI卓越中心。他拥有超过15年的经验，帮助各行业客户设计和实施AI解决方案。'
- en: '**Related:**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Satellite Image Analysis with fast.ai for Disaster Recovery](/2020/05/satellite-image-analysis-fast-ai-disaster-recovery.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用fast.ai进行卫星图像分析以应对灾难恢复](/2020/05/satellite-image-analysis-fast-ai-disaster-recovery.html)'
- en: '[Using AI to Identify Wildlife in Camera Trap Images from the Serengeti](/2020/02/using-ai-identify-wildlife-images-serengeti.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用AI识别塞伦盖蒂相机陷阱图像中的野生动物](/2020/02/using-ai-identify-wildlife-images-serengeti.html)'
- en: '[Machine Learning in Agriculture: Applications and Techniques](/2019/05/machine-learning-agriculture-applications-techniques.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[农业中的机器学习：应用与技术](/2019/05/machine-learning-agriculture-applications-techniques.html)'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻2022年3月9日：在5…中构建机器学习Web应用程序](https://www.kdnuggets.com/2022/n10.html)'
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你需要知道的6件关于数据管理的事以及为何重要…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉中的TensorFlow - 轻松实现迁移学习](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索计算机视觉的世界：介绍MLM的最新…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的5个应用](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2：Meta AI的自监督计算机视觉模型](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
