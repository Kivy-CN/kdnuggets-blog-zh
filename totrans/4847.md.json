["```py\nimport torch\n\n# Create a Torch tensor\nt = torch.Tensor([[1, 2, 3], [4, 5, 6]])\nt\n\n```", "```py\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.]])\n\n```", "```py\n# Transpose\nt.t()\n\n# Transpose (via permute)\nt.permute(-1,0)\n\n```", "```py\ntensor([[ 1.,  4.],\n        [ 2.,  5.],\n        [ 3.,  6.]])\n\n```", "```py\n# Reshape via view\nt.view(3,2)\n\n```", "```py\ntensor([[ 1.,  2.],\n        [ 3.,  4.],\n        [ 5.,  6.]])\n\n```", "```py\n# View again...\nt.view(6,1)\n\n```", "```py\ntensor([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [ 5.],\n        [ 6.]])\n\n```", "```py\n# Create tensor of zeros\nt = torch.zeros(3, 3)\nt\n\n```", "```py\ntensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])\n\n```", "```py\n# Create tensor from normal distribution randoms\nt = torch.randn(3, 3)\nt\n\n```", "```py\ntensor([[ 1.0274, -1.3727, -0.2196],\n        [-0.7258, -2.1236, -0.8512],\n        [ 0.0392,  1.2392,  0.5460]])\n\n```", "```py\n# Some tensor info\nprint('Tensor shape:', t.shape)   # t.size() gives the same\nprint('Number of dimensions:', t.dim())\nprint('Tensor type:', t.type())   # there are other types\n\n```", "```py\nTensor shape: torch.Size([3, 3])\nNumber of dimensions: 2\nTensor type: torch.FloatTensor\n\n```", "```py\n# Slicing\nt = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Every row, only the last column\nprint(t[:, -1])\n\n# First 2 rows, all columns\nprint(t[:2, :])\n\n# Lower right most corner\nprint(t[-1:, -1:])\n\n```", "```py\ntensor([ 3.,  6.,  9.])\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.]])\ntensor([[ 9.]])\n\n```", "```py\n# Numpy ndarray <--> PyTorch tensor\nimport numpy as np\n\n# ndarray to tensor\na = np.random.randn(3, 5)\nt = torch.from_numpy(a)\nprint(a)\nprint(t)\nprint(type(a))\nprint(type(t))\n\n```", "```py\n[[-0.52192738 -1.11579634  1.26925835  0.10449378 -1.02894372]\n [-0.78707263 -0.05350072 -0.65815075  0.18810677 -0.52795765]\n [-0.41677548  0.82031861 -2.46699201  0.60320375 -1.69778546]]\ntensor([[-0.5219, -1.1158,  1.2693,  0.1045, -1.0289],\n        [-0.7871, -0.0535, -0.6582,  0.1881, -0.5280],\n        [-0.4168,  0.8203, -2.4670,  0.6032, -1.6978]], dtype=torch.float64)\n<class 'numpy.ndarray'>\n<class 'torch.Tensor'>\n\n```", "```py\n# tensor to ndarray\nt = torch.randn(3, 5)\na = t.numpy()\nprint(t)\nprint(a)\nprint(type(t))\nprint(type(a))\n\n```", "```py\ntensor([[-0.1746, -2.4118,  0.4688, -0.0517, -0.2706],\n        [-0.8402, -0.3289,  0.4170,  1.9131, -0.8601],\n        [-0.6688, -0.2069, -0.8106,  0.8582, -0.0450]])\n[[-0.17455131 -2.4117854   0.4688457  -0.05168453 -0.2706456 ]\n [-0.8402392  -0.3289494   0.41703534  1.9130518  -0.86014426]\n [-0.6688193  -0.20693372 -0.8105542   0.8581988  -0.04502954]]\n<class 'torch.Tensor'>\n<class 'numpy.ndarray'>\n\n```", "```py\n# Compute cross product\nt1 = torch.randn(4, 3)\nt2 = torch.randn(4, 3)\nt1.cross(t2)\n\n```", "```py\ntensor([[ 2.6594, -0.5765,  1.4313],\n        [ 0.4710, -0.3725,  2.1783],\n        [-0.9134,  1.6253,  0.7398],\n        [-0.4959, -0.4198,  1.1338]])\n```", "```py\n# Compute matrix product\nt = (torch.Tensor([[2, 4], [5, 10]]).mm(torch.Tensor([[10], [20]])))\nt\n\n```", "```py\ntensor([[ 100.],\n        [ 250.]])\n```", "```py\n# Elementwise multiplication\nt = torch.Tensor([[1, 2], [3, 4]])\nt.mul(t)\n\n```", "```py\ntensor([[  1.,   4.],\n        [  9.,  16.]])\n```", "```py\n# Is CUDA GPU available?\ntorch.cuda.is_available()\n\n# How many CUDA devices?\ntorch.cuda.is_available()\n\n# Move to GPU\nt.cuda()\n\n```"]