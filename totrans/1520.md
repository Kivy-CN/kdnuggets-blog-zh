# 朴素贝叶斯：机器学习分类性能的基线模型

> 原文：[https://www.kdnuggets.com/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html/2](https://www.kdnuggets.com/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html/2)

### 多项式朴素贝叶斯

首先，需要对分类变量进行编码。

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行 IT 工作

* * *

```py
o = {'sunny': 1, 'overcast': 2, 'rainy': 3}
data.outlook = [o[item] for item in data.outlook.astype(str)]

t = {'hot': 1, 'mild': 2, 'cool': 3}
data.temp = [t[item] for item in data.temp.astype(str)]

h = {'high': 1, 'normal': 2}
data.humidity = [h[item] for item in data.humidity.astype(str)]

w = {'True': 1, 'False': 2}
data.windy = [w[item] for item in data.windy.astype(str)]

```

然后我们可以创建训练集和测试集

```py
x = tennis.iloc[:,0:-1] # X is the features in our dataset
y = tennis.iloc[:,-1]   # y is the Labels in our dataset

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

```

接下来，我们可以继续调整模型并进行预测

```py
modelM = MultinomialNB().fit(X_train, y_train)
predM = model.predict(X_test)
predM

```

```py
 array(['yes', 'yes', 'yes', 'yes', 'yes'], dtype='<U3') 
```

看起来预测结果全部返回了'yes'。这将在评估模型时产生影响，正如你将看到的。

让我们用 pandas 制作混淆矩阵，因为我个人不喜欢 Scikitlearn 中的混淆矩阵。

```py
pd.crosstab(y_test, predy, rownames=['Actual'], colnames=['Predicted'], margins=True)

```

```py
 Predicted 	yes All
Actual
no 	         2  2
yes 	         3  3
All 	         5  5 
```

```py
accuracy_score = accuracy_score(y_test, predy)
print('The accuracy of the Multinomial model is ', accuracy_score)

```

```py
 The accuracy of the Multinomial model is 0.6 
```

多项式模型给出了 60% 的准确率

**模型的召回率（真正例率）为100%，因为没有假阴性，因为没有预测出'0'类别。召回率的计算公式是[真正例/(真正例+假阴性)]。** 不幸的是，这在实际情况中是不现实的，因为在现实世界中达到100%的召回率几乎是不可能的。这只是数学在发挥作用，需要人工解释以评估其适用性。

### 高斯朴素贝叶斯

由于高斯朴素贝叶斯更偏好连续数据，我们将使用[Pima 印第安人糖尿病数据集](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

```py
diabetes = pd.read_csv('diabetes.csv')

```

```py
diabetes.dtypes

```

```py
 Pregnancies                   int64
  Glucose                       int64
  BloodPressure                 int64
  SkinThickness                 int64
  Insulin                       int64
  BMI                         float64
  DiabetesPedigreeFunction    float64
  Age                           int64
  Outcome                       int64
  dtype: object 
```

如我们所见，所有特征都是连续的。

现在让我们测试特征是否遵循高斯分布（正态分布），因为这是高斯朴素贝叶斯模型的一个必要假设（尽管如果数据不符合正态分布，它仍然可以使用）

循环将告诉我们数据是否符合正态分布，使用著名的 Shapiro-Wilkes 检验。

```py
  for i in range(0,9):
      stat,p = shapiro(diabetes[diabetes.columns[i]])
      print(diabetes.columns[i], 'Test-Statistic=%.3f, p-value=%.3f' % (stat, p));
      alpha = 0.05
      if p > alpha:
          print(diabetes.columns[i], 'looks Gaussian (fail to reject H0)')
          print('---------------------------------------')
      else:
          print(diabetes.columns[i],'does not look Gaussian (reject H0)')
          print('---------------------------------------')

```

```py
 Pregnancies Test-Statistic=0.904, p-value=0.000
  Pregnancies does not look Gaussian (reject H0)
  ---------------------------------------
  Glucose Test-Statistic=0.970, p-value=0.000
  Glucose does not look Gaussian (reject H0)
  ---------------------------------------
  BloodPressure Test-Statistic=0.819, p-value=0.000
  BloodPressure does not look Gaussian (reject H0)
  ---------------------------------------
  SkinThickness Test-Statistic=0.905, p-value=0.000
  SkinThickness does not look Gaussian (reject H0)
  ---------------------------------------
  Insulin Test-Statistic=0.722, p-value=0.000
  Insulin does not look Gaussian (reject H0)
  ---------------------------------------
  BMI Test-Statistic=0.950, p-value=0.000
  BMI does not look Gaussian (reject H0)
  ---------------------------------------
  DiabetesPedigreeFunction Test-Statistic=0.837, p-value=0.000
  DiabetesPedigreeFunction does not look Gaussian (reject H0)
  ---------------------------------------
  Age Test-Statistic=0.875, p-value=0.000
  Age does not look Gaussian (reject H0)
  ---------------------------------------
  Outcome Test-Statistic=0.603, p-value=0.000
  Outcome does not look Gaussian (reject H0)
  --------------------------------------- 
```

**没有特征似乎呈现正态分布。**

让我们进一步一步，来可视化它们的分布

```py
diabetes.hist(figsize=(20, 10));

```

![pima-diabetes-histogram](../Images/1f931e10b3854819507e2bba3e123b3b.png)

Pima 糖尿病特征的直方图

通过目视检查，BMI 和血压似乎符合正态分布，但两侧的异常值和假设检验会让我们有不同的想法。尽管如此，假设

如果不满足，我们仍然可以继续调整模型。

```py
  xG = diabetes.iloc[:,0:-1] # X is the features in our dataset
  yG = diabetes.iloc[:,-1]   # y is the Labels in our dataset

  X_trainG, X_testG, y_trainG, y_testG = train_test_split(xG, yG, test_size=0.33, random_state=42)

```

```py
modelG = GaussianNB().fit(X_trainG, y_trainG)
predG = modelG.predict(X_testG)

```

```py
pd.crosstab(y_testG, predG, rownames=['Actual'], colnames=['Predicted'], margins=True)

```

```py
 Predicted 	0 	1 	All
Actual
0 	        136 	32 	168
1             	33 	53 	86
All 	        169 	85 	254 
```

这一次我们可以计算召回率（真正例率），因为现在两个类别都已经被预测。

```py
recall = recall_score(y_testG, predG, average='binary')
print('The Recall of the Gaussian model is', recall)

```

```py
 The Recall of the Gaussian model is 0.6162790697674418 
```

我使用`average='binary'`因为我们的目标变量是二分类目标（0和1）。

模型给出了62%的真正率（召回率）。

我在获取模型的准确度时遇到了困难，所以我们可以手动计算：

```py
tn, fn, fp, tp = confusion_matrix(y_testG, predG).ravel()
accuracy = (tp + tn) /(tp+fp+tn+fn)
print('The accuracy of the Gaussian model is', accuracy)

```

```py
 The accuracy of the Gaussian model is 0.7440944881889764 
```

高斯模型给出了74%的准确度

### 朴素贝叶斯的优点

1.  可以处理缺失值

    +   在准备模型时，缺失值被忽略，并且在计算类别值的概率时也会被忽略。

1.  可以处理小样本量。

    +   朴素贝叶斯不需要大量的训练数据。它仅需要足够的数据来理解每个属性与目标变量之间的概率关系。**如果只有少量训练数据可用，朴素贝叶斯通常会比其他模型表现更好**。

1.  尽管独立性假设被违反，但仍表现良好

    +   即使独立性在现实数据中很少成立，模型仍会如常表现。

1.  相比之下，容易解释且预测时间较快。

    +   朴素贝叶斯不是一个黑箱算法，最终结果可以很容易地向观众解释。

1.  可以处理数值数据和分类数据。

    +   朴素贝叶斯是一种分类器，因此在处理分类数据时表现更好。虽然数值数据也能满足要求，但它假设所有数值数据都是正态分布的，这在现实数据中不太可能。

### 朴素贝叶斯的缺点

1.  **朴素假设**

    +   朴素贝叶斯假设所有特征彼此独立。在现实生活中，几乎不可能获得一组完全独立的预测变量。

1.  无法处理特征之间的交互作用。

1.  模型的表现对偏斜的数据非常敏感。

    +   当训练集不能代表整体人群的类别分布时，先验估计将不正确。

1.  **零频率问题**

    +   测试数据中存在但训练数据中没有的分类变量将被分配一个**零（0）**的概率，并且无法做出预测。

    +   *作为解决方案，必须对类别应用**平滑技术**。最简单和最著名的技术之一是[拉普拉斯平滑技术](https://stats.stackexchange.com/questions/108797/in-naive-bayes-why-bother-with-laplacian-smoothing-when-we-have-unknown-words-i)。Python的Sklearn默认实现了拉普拉斯平滑。*

1.  数据集中相关的特征必须被移除，否则会在模型中被重复计算，从而**过度夸大该特征的重要性**。

### 为什么使用朴素贝叶斯作为性能基准分类器？

我认为为什么朴素贝叶斯应该是第一个创建和比较的模型是因为：

+   **它在预测时严重依赖先验目标类别概率。不准确或不现实的先验可能导致误导性的结果。由于朴素贝叶斯是基于概率的机器学习技术，目标的概率将极大地影响最终预测。**

+   由于不需要移除缺失值，因此你不会面临丢失原始数据的风险。

+   独立性假设在实践中几乎从未满足，因此由于其最基本的假设存在缺陷，结果并不非常可靠。

+   模型没有考虑特征之间的交互。然而，现实世界中的特征几乎总是存在交互的。

+   不是要最小化误差或方差，而是要寻找在给定预测变量的情况下类别的更高概率。

上述所有点都可以作为其他分类器应该建立以超越朴素贝叶斯模型的有效依据。虽然朴素贝叶斯在**垃圾邮件过滤**和**推荐系统**方面表现优异，但在大多数其他应用中可能并不理想。

### 结论

总体而言，朴素贝叶斯方法速度快、强大且易于解释。然而，过度依赖目标变量的先验概率可能会产生非常误导和不准确的结果。像决策树、逻辑回归、随机森林和集成方法这样的分类器应该能够超越朴素贝叶斯，成为实际有用的工具。这并不排除朴素贝叶斯作为一个强大分类器的地位。独立性假设、无法处理交互和高斯分布假设使其成为一个非常难以信任的算法，因为这些模型需要持续更新。

**相关：**

+   [仅使用Python从零开始实现朴素贝叶斯 – 无需高级框架](/2018/10/naive-bayes-from-scratch-python.html)

+   [机器学习以88%准确率识别“假新闻”](/2017/04/machine-learning-fake-news-accuracy.html)

+   [从零开始展开朴素贝叶斯](/2018/09/unfolding-naive-bayes.html)

### 更多关于此主题

+   [高斯朴素贝叶斯解释](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)

+   [朴素贝叶斯算法：你需要知道的一切](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)

+   [KDnuggets新闻，4月13日：数据科学家应该关注的Python库…](https://www.kdnuggets.com/2022/n15.html)

+   [更多分类问题的性能评估指标…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)

+   [使用Tensorflow训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)

+   [理解分类指标：评估模型的指南…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)
