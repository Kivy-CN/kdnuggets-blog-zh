# 机器学习以88%的准确率发现“虚假新闻”

> 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)

**乔治·麦金泰尔，贡献数据科学撰稿人，ODSC**

![特朗普](../Images/c4c806c5213c7410a605b76b4daa4706.png)

> ### “谎言在真相来得及穿上裤子之前，就已经传遍了半个世界。”
> ### 
> * * *
> 
> ## 我们的前三名课程推荐
> ## 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路。
> 
> ![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平
> 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的IT
> 
> * * *
> 
> – 温斯顿·丘吉尔

自2016年总统选举以来，一个主导政治讨论的话题是“虚假新闻”问题。许多政治评论员声称，显著偏见和/或虚假的新闻影响了选举，尽管[斯坦福大学和纽约大学的研究](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)得出了不同的结论。尽管如此，虚假新闻帖子已经利用Facebook用户的信息流在互联网中传播。

****“什么是虚假新闻？”****

显然，一个故意误导的故事就是“虚假新闻”，但最近喧闹的社交媒体讨论正在改变它的定义。一些人现在使用这个术语来拒绝与他们偏好的观点相悖的事实，最突出的例子是[特朗普总统](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd)。这样的模糊定义的术语很容易被玩弄。

数据科学社区已经做出回应，[采取行动来解决这个问题](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/)。有一个类似Kaggle的比赛，称为“[虚假新闻挑战](http://www.fakenewschallenge.org/)”，而[Facebook正在使用AI](https://techcrunch.com/2016/11/14/facebook-fake-news/)来过滤用户信息流中的虚假新闻。打击虚假新闻是一个经典的文本分类项目，提出了一个直接的问题：***你能建立一个区分“真实”新闻和“虚假”新闻的模型吗？***

这正是我为这个项目所尝试做的。我组建了一个包含虚假新闻和真实新闻的数据集，并使用了一个[朴素贝叶斯](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)分类器，以便创建一个模型，根据文章中的词汇和短语将其分类为虚假或真实。

### 数据收集/整理

数据获取过程分为两个部分：获取“假新闻”和获取真实新闻。第一部分很快，Kaggle 发布了一个[fake news dataset](https://www.kaggle.com/mrisdal/fake-news)，包含了在2016年选举周期内发布的13,000篇文章。

第二部分要困难得多。为了获取数据集中真实新闻的部分，我转向了[All Sides](http://www.allsides.com/)，这是一个致力于汇集政治光谱各方新闻和观点文章的网站。该网站上的文章按主题（环境、经济、堕胎等）和政治倾向（左派、中立、右派）进行分类。我使用All Sides，因为这是从众多媒体渠道中抓取成千上万篇文章的最佳方式。此外，它还允许我下载文章的完整文本，这一点是《纽约时报》和 NPR API 所不具备的。经过漫长而艰辛的过程，我最终抓取了**5279篇文章**。我的真实新闻数据集中的文章来自于《纽约时报》、华尔街日报、彭博社、NPR 和《卫报》，并且这些文章发表于2015年或2016年。

我决定将我的完整数据集构建为假新闻和真实新闻各占一半，从而使模型的空白准确率为50%。我随机选择了5279篇假新闻文章用于我的完整数据集，其余的文章则留作测试集，以便在我的模型完成时使用。

我最终的数据集包含了10558篇文章，包括它们的标题、完整正文和标签（真实与假）。数据存放在这个[github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset)中。

### 目的与期望

当我刚开始这个项目时，我承认这不会是一个完美的项目。这个项目的目的是看看我能在创建假新闻分类器上走多远，并从中获得什么见解，然后用于改进模型。我的计划是将这个项目视为一个常规的垃圾邮件检测项目。

基于计数向量化器（使用词频统计）或 tfidf 矩阵（词频相对于它们在数据集中其他文章中的使用频率）来构建模型只能取得一定的效果。这些方法没有考虑重要的特质，比如词序和上下文。两个在词频上类似的文章，其含义可能完全不同。我并没有期望我的模型能够熟练处理那些词语和短语重叠的假新闻和真实新闻。然而，我期待这个项目能够提供一些有价值的见解。

### 建模

由于这是一个文本分类项目，我只使用了朴素贝叶斯分类器，这是文本数据科学项目中的标准做法。

制定模型的真正工作是文本转换（**计数向量器**与**tfidf向量器**）和选择使用哪种类型的文本（标题与全文）。这给了我四对重新配置的数据集来进行操作。

下一步是确定**计数向量器**或**tfidf向量器**的最优参数。对于那些不熟悉文本机器学习的人来说，这意味着使用n个最常见的词，使用词和/或短语，是否小写，去除停用词（如the、when和there）以及仅使用在文本语料库中出现至少指定次数的词（文本数据集或文本集合的术语）。

为了测试多个参数及其众多组合的性能，我利用了Sci-kit Learn的GridSearch功能来高效地执行此任务。要了解如何**优化算法参数**，请查看[这个教程](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)。

在网格搜索交叉验证过程之后，我发现我的模型在使用**计数向量器**而不是**tfidf**时效果最佳，并且在用文章的全文训练时比训练在标题上产生了更高的分数。**计数向量器**的最佳参数是不进行小写转换、使用两词短语而非单个词，并且仅使用在语料库中出现至少三次的词。

鉴于我在帖子中之前概述的期望，我对模型产生的高分感到惊讶甚至有些困惑。我的模型的交叉验证准确率为91.7%，召回率（真正率）为92.6%，AUC分数为95%。

这是我模型的ROC曲线。

[![ROC 曲线](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)

如果我基于此图决定模型的阈值，我会选择一个在0.08左右产生假阳性率（FPR）和在0.90左右产生真正率（TPR）的阈值，因为在图中此点假阳性与真正率之间的权衡是平衡的。

### 结果与结论

我的模型质量的真正考验是看它能多准确地分类测试集中（未用于模型创建的假新闻文章）假新闻文章。

**在5234篇其他假新闻数据集中，我的模型能够正确识别88.2%的假新闻。** 这比我的交叉验证准确率低了3.5个百分点，但在我看来，这是对我的模型的相当不错的评估。

事实证明，我预测模型在分类新闻文章时会遇到困难的假设是相当错误的。我原本认为60多或70多的准确率是**优秀的**，但我设法显著超越了这个预期。

尽管我创建了一个看似相当不错的模型，但考虑到任务的复杂性，我并不完全相信它的表现如同表面上看起来的那样，这就是原因所在。

为了更好地理解为什么会发生这种情况，我们来看看数据中的“最虚假”和“最真实”词汇——我会解释我的意思。

使用我从数据学校的Kevin Markham那里借用的技术，这里是我如何得出语料库中“最虚假”和“最真实”词汇的方法。我首先使用了一个宽两列、长10558行的表格（这就是语料库中的词汇数量）。第一列表示一个词在被分类为“虚假”的文章中出现的次数，第二列表示一个词在“真实”文章中出现的次数。然后，我将虚假列的数值除以我模型分类的虚假文章总数，真实列也做了同样的处理。接着，我在数据的每个值上加了一，因为我创建了一个新的“虚假:真实”比率列，不想因为除以零而产生错误。这个“虚假:真实”是衡量某个词汇“虚假”或“真实”的一个相当不错但并不完美的指标。逻辑很简单，如果一个词在“虚假”文章中频繁出现而在“真实”文章中很少出现，那么它的虚假与真实比率分数将会很高。

这里是我数据集中前20个“最虚假”和“最真实”的词汇。

[![最虚假](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)

[![最真实](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)

这两个图表展示了一些令人困惑的结果。“虚假”图表中的词汇种类繁杂，包括一些典型的互联网术语，如PLEASE、Share、Posted、html和Widget，以及一些甚至不是真正的词汇，如tzrwu。然而，看到infowars被提及以及“羊群”和“UFO”等词汇进入前20个“最虚假”词汇并不令人惊讶。Infowars是由Alex Jones领导的一个右翼阴谋论媒体，推广关于化学轨迹和9/11的阴谋理论。

“真实”的图表主要由名字、政治家以及在政治文章中经常使用的词汇构成，占据了图表中60%的条形图。二十个词汇中有七个，包括前六名中的四个，是政治家名字。这引发了一个问题，即关于政治家的文章是否更有可能是真实的？当然不是，如果有什么的话，你会预期有大量的虚假新闻传播关于政治家的虚假信息。如果我得出提到政治家的文章更有可能真实的结论，那将是一个巨大的错误。

这个项目的一个重要假设是，各类文章所涵盖的主题有相当大的重叠。正如我们上面所见，仅仅因为某个词在“真实”新闻中出现得比在“虚假”新闻中多，并不意味着包含这些词的文章一定是“真实”的，而只是这些词可能在真实新闻数据集中更常见，而虚假新闻数据集中则反之。

我和另一方对塑造这个数据集有相当大的影响。我决定了哪些文章用于“真实”数据集。“虚假”数据集中的文章是由[一个名为“BS Detector”的Chrome扩展程序](https://github.com/selfagency/bs-detector)确定的，该程序由Daniel Sieradski制作。确定什么是“虚假新闻”、什么不是“虚假新闻”时存在显著的主观性。政治人物的名字被高评级为“真实”的原因，很可能是因为这部分语料库不成比例地来自政治新闻。此外，我确实发现了一些我认为来自可靠新闻来源的文章。其中一篇文章来自The Intercept，一个具有高新闻标准的新闻组织。是的，我的模型确实将这篇所谓的“虚假新闻”文章标记为真实。

使事情变得更加复杂的是，我们必须决定如何为我们的模型设置阈值概率。如果我是一名在 Facebook 的数据科学家，负责实现一个筛选用户动态中真实与虚假新闻的模型，我将面临选择一个屏蔽所有或大部分虚假新闻和一些真实新闻的模型，还是一个允许所有或大部分真实新闻和一些虚假新闻的模型的困境。但在做出决定之前，我需要弄清楚未能阻止虚假新闻与阻挡真实新闻的成本是什么？如何尝试回答这样一个抽象的问题？除非我们能训练一个100%真阳性率和0%假阳性率的模型，否则我们将被困在这个困境中。

总之，虽然我认为标准的朴素贝叶斯文本分类模型可以提供一些解决这个问题的见解，但在专业环境中，应使用更强大的深度学习工具来对抗虚假新闻。

对“虚假新闻”的分类为数据科学界提供了一个新挑战。在许多机器学习项目中，你想要预测的不同类别之间的区别是明确的，而在这种情况下则要模糊得多。这个项目验证了数据科学中的一种观点，即对数据的直觉和熟悉程度与任何模型或工具一样重要，甚至更为重要。

**简介：[乔治·麦金泰尔](https://opendatascience.com/author/george-mcintire/)** 是一位转行的数据科学家/记者混合型人才。寻找数据科学和/或新闻学方面的机会。对新事物充满好奇和热情。在完成Metis数据科学训练营之前，他曾在旧金山为Vice、Salon、SF Weekly、San Francisco Magazine等媒体担任自由记者。

[原文](https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/)。已获授权转载。

**相关内容：**

+   [这里越来越热：数据科学与假新闻](/2017/03/getting-hot-here-data-science-vs-fake-news.html)

+   [昨晚瑞典发生了什么：数据科学与假新闻](/2017/03/last-night-sweden-data-science-vs-fake-news.html)

+   [警惕两种数据混淆策略](/2017/04/beware-two-data-obfuscation-tactics.html)

### 更多相关内容

+   [假到成功：生成真实的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)

+   [识别假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)

+   [识别假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)

+   [我应该使用哪种指标？准确性与AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)

+   [分类指标解析：逻辑回归与…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)

+   [天高任鸟飞：了解JetBlue如何使用蒙特卡罗方法和Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)
