- en: A Single Function to Streamline Image Classification with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简化使用Keras进行图像分类的单一函数
- en: 原文：[https://www.kdnuggets.com/2019/09/single-function-streamline-image-classification-keras.html](https://www.kdnuggets.com/2019/09/single-function-streamline-image-classification-keras.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/09/single-function-streamline-image-classification-keras.html](https://www.kdnuggets.com/2019/09/single-function-streamline-image-classification-keras.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: Plenty has been written about deep learning frameworks such as [Keras](https://towardsdatascience.com/introduction-to-deep-learning-with-keras-17c09e4f0eb2) and [PyTorch](https://www.analyticsvidhya.com/blog/2018/02/pytorch-tutorial/),
    and how [powerful yet simple to use](https://towardsdatascience.com/keras-vs-pytorch-for-deep-learning-a013cb63870d) they
    are for constructing and playing with wonderful deep learning models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 关于深度学习框架，如[Keras](https://towardsdatascience.com/introduction-to-deep-learning-with-keras-17c09e4f0eb2)和[PyTorch](https://www.analyticsvidhya.com/blog/2018/02/pytorch-tutorial/)，以及它们是如何[强大且易于使用](https://towardsdatascience.com/keras-vs-pytorch-for-deep-learning-a013cb63870d)来构建和操作优秀的深度学习模型，已经有很多文章进行了讨论。
- en: There are so many tutorials/articles already written about model architecture
    and optimizers— the concept of [convolution, max pooling, optimizers](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) such
    as [ADAM](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) or [RMSprop](https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有很多教程/文章讨论了模型架构和优化器——例如[卷积、最大池化、优化器](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)如[ADAM](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)或[RMSprop](https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b)。
- en: What if, all you wanted, is a single function to pull automatically images from
    a specified directory on your disk, and give you back a fully trained neural net
    model, ready to be used for prediction?
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你只想要一个功能，能够自动从磁盘上的指定目录中提取图片，并返回一个完全训练好的神经网络模型，随时可以用于预测，这该怎么办？
- en: '![](../Images/e43d04889cb61613bb095a2467c3a66a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e43d04889cb61613bb095a2467c3a66a.png)'
- en: Therefore, in this article, **we focus on how to use a couple of utility methods
    from the Keras (TensorFlow) API to streamline the training of such models** (specifically
    for a classification task) with a proper data pre-processing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本文中，**我们专注于如何使用Keras（TensorFlow）API中的几个实用方法来简化此类模型的训练**（特别是用于分类任务），并进行适当的数据预处理。
- en: Basically, we want to,
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们想要的是，
- en: grab some data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取一些数据
- en: put them inside a directory/folder arranged by classes
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们放入按类别排列的目录/文件夹中
- en: train a neural net model with minimum code/fuss
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最少的代码/麻烦训练神经网络模型
- en: In the end, we aim to write **a single utility function**, which can take just
    the name of your folder where training images are stored, and give you back a
    fully trained CNN model.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最终，我们的目标是编写**一个实用工具函数**，它只需输入存放训练图片的文件夹名称，就可以返回一个完全训练好的CNN模型。
- en: The dataset
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集
- en: We use a dataset consisting of 4000+ images of flowers for this demo. The dataset
    can be [downloaded from the Kaggle website here](https://www.kaggle.com/alxmamaev/flowers-recognition).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个演示中使用了一个包含4000多张花卉图片的数据集。该数据集可以通过[从Kaggle网站下载](https://www.kaggle.com/alxmamaev/flowers-recognition)。
- en: The data collection is based on the data Flickr, Google images, Yandex images.
    The pictures are divided into five classes,
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集基于Flickr、Google图片、Yandex图片。这些图片被分成五个类别，
- en: daisy,
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雏菊，
- en: tulip,
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郁金香，
- en: rose,
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玫瑰，
- en: sunflower,
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向日葵，
- en: dandelion.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒲公英。
- en: For each class, there are about 800 photos. Photos are not high resolution,
    about 320 x 240 pixels. Photos are not reduced to a single size, they have different
    proportions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每个类别大约有800张照片。照片分辨率不高，大约为320 x 240像素。照片的大小不一致，具有不同的比例。
- en: However, they come **organized neatly in five directories named with the corresponding
    class labels**. We can take advantage of this organization and apply the Keras
    methods to streamline the training of our convolutional network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们**已经整齐地组织在五个目录中，并以相应的类别标签命名**。我们可以利用这种组织方式，应用Keras方法来简化我们卷积网络的训练。
- en: The code repo
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码仓库
- en: The full Jupyter notebook is [**here in my Github repo**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keras_flow_from_directory.ipynb).
    Feel free to fork and extend it, and give it a star if you like it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 Jupyter notebook 见[**我的 GitHub 仓库中的这里**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keras_flow_from_directory.ipynb)。如果你喜欢，可以随意
    Fork 并扩展它，并给它一个星标。
- en: We will use bits and pieces of the code in this article to show the important
    parts for illustration.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本文中使用代码的部分片段来展示重要的部分以作说明。
- en: Should you use a GPU?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 是否应该使用 GPU？
- en: It is recommended to run this script on a GPU (with `TensorFlow-GPU`), as we
    will build a CNN with five convolutional layers and consequently, the training
    process with thousands of images can be computationally intensive and slow if
    you are not using some sort of GPU.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐在 GPU 上运行此脚本（使用 `TensorFlow-GPU`），因为我们将构建一个具有五个卷积层的 CNN，因此如果不使用某种 GPU，处理成千上万张图片的训练过程可能会计算密集且较慢。
- en: For the Flowers dataset, a single epoch took ~ 1 minute on my modest laptop
    with NVidia GTX 1060 Ti GPU (6 GB Video RAM), Core i-7 8770 CPU, 16 GB DDR4 RAM.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Flowers 数据集，在我那台配置较低的笔记本电脑上（配有 NVidia GTX 1060 Ti GPU（6 GB 视频 RAM）、Core i-7
    8770 CPU、16 GB DDR4 RAM），单个 epoch 大约需要 1 分钟。
- en: Alternatively, you can take advantage of [Google Colab](https://colab.research.google.com/notebooks/basic_features_overview.ipynb),
    but [loading and pre-processing the datasets](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory) can
    be a bit of hassle there.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以利用[Google Colab](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)，但[加载和预处理数据集](https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)
    可能会有些麻烦。
- en: Data pre-processing
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Housekeeping and showing images
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 家务工作和显示图像
- en: Note that the first part of the data pre-processing section of the notebook
    code is not essential for the training of the neural net. This set of code is
    just for illustration purpose and showing a few training images as an example.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，笔记本代码数据预处理部分的第一部分对于神经网络的训练不是必需的。这段代码仅用于说明目的，并展示一些训练图像作为示例。
- en: On my laptop, the data is stored in a folder one level above my Notebooks folder.
    Here is the organization,
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的笔记本电脑上，数据存储在比我的笔记本文件夹高一级的文件夹中。这里是组织结构，
- en: '![](../Images/7c85736a9fee0c34dfa5d24fea44a7eb.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c85736a9fee0c34dfa5d24fea44a7eb.png)'
- en: With some basic Python code, we can traverse the sub-directories, count the
    images, and show a sample of them.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一些基本的 Python 代码，我们可以遍历子目录，计算图像数量，并展示其中的一些示例。
- en: Some daisy pictures,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一些雏菊的图片，
- en: '![](../Images/ba7a7b581635931f71e6f6755295800c.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba7a7b581635931f71e6f6755295800c.png)'
- en: And some beautiful roses,
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些美丽的玫瑰，
- en: '![](../Images/aa32d62c2441e728c92853a77277d9dd.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa32d62c2441e728c92853a77277d9dd.png)'
- en: Note, the pictures vary in their sizes and aspect ratios.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，图片的大小和纵横比各不相同。
- en: Building the `ImageDataGenerator` object
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建 `ImageDataGenerator` 对象
- en: This is where the actual magic happens.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是实际魔法发生的地方。
- en: The [official description](https://keras.io/preprocessing/image/) of the `ImageDataGenerator` class
    says "*Generate batches of tensor image data with real-time data augmentation.
    The data will be looped over (in batches).*"
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator` 类的[官方描述](https://keras.io/preprocessing/image/) 说 "*生成带有实时数据增强的张量图像数据批次。这些数据将被循环处理（以批次形式）。*"'
- en: Basically, it can be used **to augment image data with a lot of built-in pre-processing
    such as scaling, shifting, rotation, noise, whitening, etc**. Right now, we just
    use the `rescale` attribute to scale the image tensor values between 0 and 1.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，它可以用来 **增强图像数据，提供大量内置的预处理功能，如缩放、平移、旋转、噪声、去白化等**。现在，我们只使用 `rescale` 属性将图像张量值缩放到
    0 和 1 之间。
- en: Here is a useful article on this aspect of the class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一篇关于该类的有用文章。
- en: '[Image Augmentation using Keras ImageDataGenerator](https://medium.com/@arindambaidya168/https-medium-com-arindambaidya168-using-keras-imagedatagenerator-b94a87cdefad?source=post_page-----bd04f5cfe6df----------------------)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用 Keras ImageDataGenerator 进行图像增强](https://medium.com/@arindambaidya168/https-medium-com-arindambaidya168-using-keras-imagedatagenerator-b94a87cdefad?source=post_page-----bd04f5cfe6df----------------------)'
- en: A blog for implementation of our custom generator in combination with Keras’
    ImageDataGenerator to perform various…
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关于将我们自定义生成器与 Keras 的 ImageDataGenerator 结合使用以执行各种操作的博客…
- en: But the real utility of this class for the current demonstration is the super
    useful method `flow_from_directory` which can **pull image files one after another** from
    the specified directory.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于当前演示来说，这个类的真正实用性在于超实用的方法 `flow_from_directory`，它可以 **一个接一个地从指定目录中提取图像文件**。
- en: Note that, **this directory just has to be the top-level directory where all
    the sub-directories of individual classes can be stored separately**. The `flow_from_directory` method
    automatically scans through all the sub-directories and sources the images along
    with their appropriate labels.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，**这个目录必须是所有单独类的子目录可以单独存储的顶级目录**。`flow_from_directory`方法会自动扫描所有子目录，并获取带有适当标签的图像。
- en: We can specify the class names (as we did here with the `classes` argument)
    but this is optional. However, we will later see, how this can be useful for **selective
    training from a large trove of data**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以指定类名（就像我们在这里使用`classes`参数一样），但这是可选的。不过，稍后我们会看到，这对于**从大量数据中选择性训练**是多么有用。
- en: Another useful argument is the `target_size`, which **lets us resize the source
    images to a uniform size of 200 x 200, no matter the original size of the image**.
    That is some cool image-processing right there with a simple function argument.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的参数是`target_size`，它**使我们能够将源图像调整为统一的200 x 200尺寸，无论原始图像的大小如何**。这是一种通过简单函数参数进行的酷炫图像处理。
- en: We also specify the batch size. If you leave `batch_size` unspecified, by default,
    it will be set to 32.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还指定了批量大小。如果你不指定`batch_size`，默认情况下将设置为32。
- en: We choose the `class_mode` as `categorical` as we are doing a multi-class classification
    here.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择`class_mode`为`categorical`，因为我们在这里进行的是多类分类。
- en: When you run this code, the Keras function scans through the top-level directory,
    finds all the image files, and automatically labels them with the proper class
    (based on the sub-directory they were in).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，Keras函数会扫描顶级目录，找到所有图像文件，并自动用正确的类标签（基于它们所在的子目录）对它们进行标记。
- en: '![](../Images/117569aa643d22de129442fb159fdb8d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/117569aa643d22de129442fb159fdb8d.png)'
- en: Isn’t that cool?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是很酷吗？
- en: But wait, there is more. This is a [**Python generator object**](https://realpython.com/introduction-to-python-generators/) and
    that means it will be used to ‘***yield’ the data one by one*** during the training.
    This significantly reduces the problem of dealing with a very large dataset, whose
    contents cannot be fitted into memory at one go. Look at this article to understand
    it better,
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等，还有更多。这是一个[**Python生成器对象**](https://realpython.com/introduction-to-python-generators/)，这意味着它将用于在训练过程中‘***逐一产生数据***’。这大大减少了处理非常大数据集的问题，这些数据集的内容无法一次性装入内存。查看这篇文章以更好地理解，
- en: '[Python’s Generator Expressions: Fitting Large Datasets into Memory](https://towardsdatascience.com/pythons-list-generators-what-when-how-and-why-2a560abd3879?source=post_page-----bd04f5cfe6df----------------------)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[Python的生成器表达式：将大型数据集适配到内存中](https://towardsdatascience.com/pythons-list-generators-what-when-how-and-why-2a560abd3879?source=post_page-----bd04f5cfe6df----------------------)'
- en: Generator Expressions are an interesting feature in Python, which allows us
    to create lazily generated iterable objects…
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器表达式是Python中的一个有趣特性，它允许我们创建惰性生成的可迭代对象…
- en: Building the conv net model
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建卷积网络模型
- en: As promised, we will not spend time or energy on analyzing the code behind the
    CNN model. In brief, it consists of five convolutional layers/max-pooling layers
    and 128 neurons at the end followed by a 5 neuron output layer with a softmax
    activation for the multi-class classification.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如承诺的，我们不会花时间或精力分析CNN模型背后的代码。简而言之，它由五个卷积层/最大池化层和最后的128个神经元组成，随后是一个5神经元的输出层，并使用softmax激活进行多类分类。
- en: We use RMSprop with an initial learning rate of 0.001.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用RMSprop，初始学习率为0.001。
- en: '[Here is the code again](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keras_flow_from_directory.ipynb).
    Feel free to experiment with the network architecture and the optimizer.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[这是代码再现](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keras_flow_from_directory.ipynb)。随意尝试网络架构和优化器。'
- en: '![](../Images/ec1844ddbc936768a42135a2f127071b.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec1844ddbc936768a42135a2f127071b.png)'
- en: Training with the ‘*fit_generator’* method
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用‘*fit_generator*’方法进行训练
- en: We discussed before what cool things the `train_generator` object does with
    the `flow_from_directory` method and with its arguments.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论了`train_generator`对象在`flow_from_directory`方法及其参数下所做的酷炫事情。
- en: Now, we utilize this object in the `fit_generator` method of the CNN model,
    defined above.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在上面定义的CNN模型的`fit_generator`方法中使用这个对象。
- en: Note the `steps_per_epoch` argument to `fit_generator`. Since `train_generator` is
    a generic [Python generator](https://realpython.com/introduction-to-python-generators/),
    it never stops and therefore the `fit_generator` will not know where a particular
    epoch is ending and the next one is starting. **We have to let it know the steps
    in a single epoch**. This is, in most cases, the length of the total training
    sample divided by the batch size.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 `steps_per_epoch` 参数的设置，因为 `train_generator` 是一个通用的 [Python 生成器](https://realpython.com/introduction-to-python-generators/)，它不会停止，因此
    `fit_generator` 无法知道特定的轮次何时结束以及下一轮次何时开始。**我们必须让它知道一个轮次中的步骤数**。在大多数情况下，这是总训练样本长度除以批量大小。
- en: In the previous section, we found out the total sample size as `total_sample`.
    Therefore, in this particular case, the `steps_per_epoch` is set to `int(total_sample/batch_size)` which
    is `34`. Therefore, you will see 34 steps per epoch in the training log below.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们找出了总样本量为 `total_sample`。因此，在这种情况下，`steps_per_epoch` 设置为 `int(total_sample/batch_size)`
    即 `34`。因此，你将在下面的训练日志中看到每轮 34 个步骤。
- en: Partial training log…
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 部分训练日志…
- en: '![](../Images/ffe4fef38eeb911981d9b247da03b91b.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffe4fef38eeb911981d9b247da03b91b.png)'
- en: We can check the accuracy/loss with the usual plot code.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用常见的绘图代码检查准确率/损失。
- en: '![](../Images/3dc7a46e5f494022a881e85c1ffbc13d.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dc7a46e5f494022a881e85c1ffbc13d.png)'
- en: '![](../Images/bb2e7ed1557565344a66f0d4ead27b99.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb2e7ed1557565344a66f0d4ead27b99.png)'
- en: OK. What have we accomlished so far?
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 好的，我们到目前为止完成了什么？
- en: We have been able to utilize Keras `ImageDataGenerator` and `fit_generator` methods
    to pull images automatically from a single directory, label them, resize and scale
    them, and flow them one by one (in batches) for training a neural network.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经能够利用 Keras `ImageDataGenerator` 和 `fit_generator` 方法从单个目录自动提取图像，对其进行标记、调整大小和缩放，并逐个（以批次）流动用于训练神经网络。
- en: Can we encapsulate all of these in a single function?
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以将这些都封装在一个函数中吗？
- en: Encapsulate all of these in a single function?
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将这些都封装在一个函数中吗？
- en: One of the central goals of making useful software/computing systems is [**abstraction**](https://en.wikipedia.org/wiki/Abstraction_(computer_science))** i.e.
    hide the gory details of internal computation and data manipulation and present
    a simple and intuitive working interface/ API to the user**.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 制作有用的软件/计算系统的核心目标之一是 [**抽象**](https://en.wikipedia.org/wiki/Abstraction_(computer_science))**，即隐藏内部计算和数据操作的详细信息，并向用户呈现一个简单直观的工作接口/API**。
- en: Just as a practice towards that goal, we can try to encapsulate the process
    we followed above, in a single function. Here is the idea,
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作为实现目标的一个练习，我们可以尝试将我们上面遵循的过程封装在一个函数中。以下是思路，
- en: '![](../Images/cc97728e7a4241619a357939fe64a06b.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc97728e7a4241619a357939fe64a06b.png)'
- en: Aim for a flexible API with useful arguments
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标是提供一个灵活的 API，并具有有用的参数
- en: When you are designing a high-level API, **why not go for more generalization
    than what is required for this particular demo with flowers dataset**? With that
    in our mind, we can think of providing additional arguments to this function for
    making it applicable to other image classification cases (we will see an example
    soon).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当你设计高层 API 时，**为什么不考虑比这次特定的花卉数据集演示所需的更通用的方案**？考虑到这一点，我们可以想到为这个函数提供额外的参数，使其适用于其他图像分类场景（我们将很快看到一个示例）。
- en: Specifically, we provide the following arguments in the function,
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们在函数中提供以下参数，
- en: '`train_directory`: The directory where the training images are stored in separate
    folders. These folders should be named as per the classes.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_directory`: 存储训练图像的目录，图像按照类别分开存放。这些文件夹应该按照类别命名。'
- en: '`target_size`: Target size for the training images. A tuple e.g. (200,200)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size`: 训练图像的目标大小。例如 (200,200) 的元组'
- en: '`classes`: A Python list with the classes, for which we want the training to
    happen. This forces the generator to choose specific files from the `train_directory` and
    not look at all the data.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classes`: 包含要进行训练的类别的 Python 列表。这会强制生成器从 `train_directory` 中选择特定文件，而不是查看所有数据。'
- en: '`batch_size`: Batch size for training'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`: 训练的批量大小'
- en: '`num_epochs`: Number of epochs for training'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_epochs`: 训练的轮数'
- en: '`num_classes`: Number of output classes to consider'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_classes`: 输出类别的数量'
- en: '`verbose`: Verbosity level of the training, passed on to the `fit_generator` method'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`verbose`: 训练的详细程度，传递给 `fit_generator` 方法'
- en: Of course, we could have provided additional arguments corresponding to the
    whole model architecture or optimizer settings. This article is not focused on
    such issues, and therefore, we keep it compact.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以提供额外的参数以对应整个模型架构或优化器设置。本文不集中于这些问题，因此我们保持其简洁。
- en: Again, the full code is in the Github repo. Below, we just show the docstring
    portion to emphasis on the point of making it a flexible API,
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，完整代码在 Github 仓库中。以下，我们只展示了文档字符串部分以强调将其做成灵活 API 的重点，
- en: '![](../Images/b30a61c123d0e0f598657cd7a3c40b9d.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b30a61c123d0e0f598657cd7a3c40b9d.png)'
- en: Testing our utility function
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试我们的实用函数
- en: Now we test our `train_CNN` function by simply supplying a folder/directory
    name and getting back a trained model which can be used for predictions!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过简单地提供一个文件夹/目录名称并获得一个可以用于预测的训练模型来测试我们的 `train_CNN` 函数！
- en: Let’s also suppose that we want to train only for ‘daisy’, ‘rose’, and ‘tulip’
    now and ignore the other two flowers’ data. We simply pass on a list to the `classes` argument.
    In this case, don't forget to set the `num_classes` argument to 3\. You will notice
    how the steps per epoch are automatically reduced to 20 as the number of training
    samples is less than the case above.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设现在只想训练“雏菊”、“玫瑰”和“郁金香”，忽略其他两种花的数据。我们只需将一个列表传递给 `classes` 参数。在这种情况下，不要忘记将
    `num_classes` 参数设置为 3。你会注意到，由于训练样本数量少于上述情况，每个 epoch 的步骤自动减少为 20。
- en: Also, note that the `verbose` is set to 0 by default in the function above,
    and therefore you need to specify explicitly `verbose=1` if you want to monitor
    the progress of the training epoch-wise!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，请注意，`verbose` 在上述函数中默认设置为 0，因此如果你希望监控训练的进度，你需要明确指定 `verbose=1`！
- en: Basically, we are able to get a fully trained CNN model with 2 lines of code
    now!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们现在只用两行代码就能获得一个完全训练好的 CNN 模型！
- en: Is the function useful for another dataset?
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 该函数对另一个数据集是否有用？
- en: This is an acid test for the utility of such a function.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对该函数实用性的严格测试。
- en: Can we just take it and apply to another dataset without much modification?
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们能否直接应用于另一个数据集而无需太多修改？
- en: Caltech-101
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Caltech-101
- en: A rich yet manageable image classification dataset is Caltech-101\. By *manageable* I
    meant, not as large as the ImageNet database, which requires massive hardware
    infrastructure to train, and therefore, out of bounds, for testing cool ideas
    quickly on your laptop, yet diverse enough for practicing and learning the tricks
    and trades of convolutional neural networks.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个丰富而又易于管理的图像分类数据集是 Caltech-101。通过*易于管理*的意思是，它不如 ImageNet 数据库庞大，这需要大规模的硬件基础设施来训练，因此，在你的笔记本电脑上快速测试酷点子超出范围，但它足够多样化，可以练习和学习卷积神经网络的技巧。
- en: '![](../Images/8359b9ee76f7e1baadf3f4b32d961dbe.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8359b9ee76f7e1baadf3f4b32d961dbe.png)'
- en: Caltech-101 is an image dataset of diverse types of objects belonging to 101
    categories. There are about 40 to 800 images per category. Most categories have
    about 50 images. The size of each image is roughly 300 x 200 pixels.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Caltech-101 是一个包含 101 类物体的图像数据集。每个类别大约有 40 到 800 张图像。大多数类别有约 50 张图像。每张图像的大小大约为
    300 x 200 像素。
- en: The dataset was built by none other than Prof. Fei Fei Li and her colleagues
    (Marco Andreetto, and Marc ‘Aurelio Ranzato) at Caltech in 2003 when she was a
    graduate student there. We can surmise, therefore, that Caltech-101 was a direct
    precursor for her work on the ImageNet.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集由**费菲·李**教授及其同事（Marco Andreetto 和 Marc ‘Aurelio Ranzato）于2003年在加州理工学院建立，当时她还是一名研究生。因此，我们可以推测，Caltech-101
    是她在 ImageNet 上工作的直接前身。
- en: Training Caltech-101 with two lines of codes
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用两行代码训练 Caltech-101
- en: We downloaded the dataset and uncompressed the contents in the same Data folder
    as before. The directory looks like following,
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载了数据集并将其解压缩到与之前相同的 Data 文件夹中。目录如下所示，
- en: '![](../Images/b9207cf56ceebcd84c3e7a1ade89abcd.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9207cf56ceebcd84c3e7a1ade89abcd.png)'
- en: So, we have what we want — a top-level directory with sub-directories containing
    training images.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们得到了我们想要的——一个包含训练图像的顶级目录及其子目录。
- en: And then, the same two lines as before,
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，和之前一样的两行代码，
- en: '**All we did is to pass on the address of this directory to the function and
    choose what categories of the image we want to train the model for**. Let’s say
    we want to train the model for classification between ***‘cup’*** and ***‘crab’***.
    We can just pass their names as a list to the `classes` argument as before.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们所做的只是将该目录的地址传递给函数，并选择我们希望训练模型的图像类别**。假设我们想训练模型以区分***‘杯子’***和***‘螃蟹’***。我们可以像之前一样将它们的名称作为列表传递给`classes`参数。'
- en: Also, note that we may have to reduce the `batch_size` significantly for this
    dataset as the total number of training images will be much lower compared to
    the Flowers dataset and if the `batch_size` is higher than the total sample then
    we will have `steps_per_epoch` equal to 0 and that will create an error during
    training.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，由于训练图像的总数比 Flowers 数据集要少得多，我们可能需要显著减少`batch_size`，如果`batch_size`高于总样本数，则`steps_per_epoch`将等于0，这会在训练过程中产生错误。
- en: Voila! The function finds the relevant images (130 of them in total) and trains
    the model, 4 per batch, i.e. 33 steps per epoch.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！函数找到了相关的图像（总共130张），并训练了模型，每批4张图像，即每个周期33步。
- en: '![](../Images/bbf9e270c2f083f78c355b501268ecfc.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bbf9e270c2f083f78c355b501268ecfc.png)'
- en: Testing our model
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试我们的模型
- en: So, we saw how easy it was to just pass on the training images’ directory address
    to the function and train a CNN model with our chosen classes.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，只需将训练图像的目录地址传递给函数，即可训练一个 CNN 模型，并使用我们选择的类别。
- en: '**Is the model any good? **Let’s find out by testing it with random pictures
    downloaded from the internet.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型效果如何？**让我们通过用从互联网上下载的随机图片测试它来找出答案。'
- en: Remember, the Caltech-101 dataset was created by Fei Fei Li and colleagues back
    in 2003\. So, there is little chance that any of the newer images on the internet
    will be in the dataset.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Caltech-101 数据集是由 Fei Fei Li 和同事们于 2003 年创建的。因此，互联网上任何较新的图像都不太可能出现在数据集中。
- en: We downloaded following random pictures of ‘crabs’ and ‘cups’.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载了以下‘螃蟹’和‘杯子’的随机图片。
- en: '![](../Images/e5005cd4508526f6259b4767507918ec.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5005cd4508526f6259b4767507918ec.png)'
- en: '![](../Images/a100c7f85dd007056158ef9ac466ad75.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a100c7f85dd007056158ef9ac466ad75.png)'
- en: '![](../Images/91583cb839fe20bb9e30e02ee44dbba0.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91583cb839fe20bb9e30e02ee44dbba0.png)'
- en: After some rudimentary image processing (resizing and dimension expansion to
    match the model), we get the following result,
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行了一些基本的图像处理（调整大小和扩展维度以匹配模型）后，我们得到了以下结果，
- en: '[PRE0]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The model predicted the class correctly for the crab test image.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 模型正确预测了螃蟹测试图像的类别。
- en: '[PRE1]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/8d7689c0379eba91c30364fa91844a33.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d7689c0379eba91c30364fa91844a33.png)'
- en: The model predicted the class correctly for the cup test image.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 模型正确预测了杯子测试图像的类别。
- en: But what about for this one?
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 那这个怎么办？
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So, the model predicts the test image as a cup. Almost fair, isn’t it?
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型将测试图像预测为杯子。几乎公平，不是吗？
- en: Validation set and other extensions
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 验证集及其他扩展
- en: So far, inside the `fit_generator` we only had a `train_generator` object for
    training. But what about a validation set? It follows exactly the same concept
    as a `train_generator`. You can randomly split from your training images a validation
    set and set them aside in a separate directory (same sub-directory structures
    as the training directory) and you should be able to pass that on to the `fit_generator` function.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在`fit_generator`中我们只有一个`train_generator`对象用于训练。但验证集怎么办？它遵循与`train_generator`完全相同的概念。您可以从训练图像中随机分割出一个验证集，将其放在一个单独的目录中（与训练目录相同的子目录结构），然后您应该能够将其传递给`fit_generator`函数。
- en: There is even a method of `flow_from_dataframe` for the `ImageDataGenerator` class,
    where you can pass on the names of the image files as contained in a Pandas DataFrame
    and the training can proceed.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator`类中甚至有一个`flow_from_dataframe`方法，您可以将图像文件的名称作为 Pandas DataFrame
    中的内容传递，训练即可进行。'
- en: Feel free to experiment with these extensions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎随意尝试这些扩展功能。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: In this article we went over a couple of utility methods from Keras, that can
    help us construct a compact utility function for efficiently training a CNN model
    for an image classification task. If we can organize training images in sub-directories
    under a common directory, then this function may allow us to train models with
    a couple of lines of codes only.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了几个 Keras 的实用方法，可以帮助我们构建一个紧凑的实用函数，以高效地训练一个用于图像分类任务的 CNN 模型。如果我们可以将训练图像组织在一个共同目录下的子目录中，那么这个函数可能只需几行代码即可训练模型。
- en: This makes sense since rather than individually scraping and pre-processing
    images using other libraries (such as PIL or Scikit-image), with these built-in
    classes/methods and our utility function, we can keep the code/data flow entirely
    within Keras and train a CNN model in a compact fashion.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做是有道理的，因为与其使用其他库（如 PIL 或 Scikit-image）单独抓取和预处理图像，不如利用这些内置的类/方法和我们的实用函数，我们可以将代码/数据流程完全保持在
    Keras 内部，以紧凑的方式训练 CNN 模型。
- en: If you have any questions or ideas to share, please contact the author at [**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com).
    Also, you can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    other fun code snippets in Python, R, and machine learning resources. If you are,
    like me, passionate about machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter.](https://twitter.com/tirthajyotiS)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或想法要分享，请通过 [**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com)
    联系作者。此外，你还可以查看作者的 [**GitHub**](https://github.com/tirthajyoti?tab=repositories)**
    仓库 **，获取其他有趣的 Python、R 和机器学习资源代码片段。如果你像我一样，对机器学习/数据科学充满热情，请随时 [在 LinkedIn 上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)
    或 [在 Twitter 上关注我](https://twitter.com/tirthajyotiS)。
- en: '[Original](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df).
    Reposted with permission.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)。经许可转载。'
- en: '**Related:**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Object-oriented programming for data scientists: Build your ML estimator](/2019/08/object-oriented-programming-data-scientists-estimator.html)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[面向数据科学家的面向对象编程：构建你的机器学习估计器](/2019/08/object-oriented-programming-data-scientists-estimator.html)'
- en: '[How a simple mix of object-oriented programming can sharpen your deep learning
    prototype](/2019/08/simple-mix-object-oriented-programming-sharpen-deep-learning-prototype.html)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单的面向对象编程如何提升你的深度学习原型](/2019/08/simple-mix-object-oriented-programming-sharpen-deep-learning-prototype.html)'
- en: '[What is Benford’s Law and why is it important for data science?](/2019/08/benfords-law-data-science.html)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本福特定律是什么？它为何对数据科学如此重要？](/2019/08/benfords-law-data-science.html)'
- en: '* * *'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Streamline Your Machine Learning Workflow with Scikit-learn Pipelines](https://www.kdnuggets.com/streamline-your-machine-learning-workflow-with-scikit-learn-pipelines)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Scikit-learn 管道简化机器学习工作流程](https://www.kdnuggets.com/streamline-your-machine-learning-workflow-with-scikit-learn-pipelines)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
- en: '[5 Concepts You Should Know About Gradient Descent and Cost Function](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于梯度下降和成本函数你应该知道的 5 个概念](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)'
- en: '[What is a Function?](https://www.kdnuggets.com/2022/11/function.html)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是函数？](https://www.kdnuggets.com/2022/11/function.html)'
- en: '[3 More SQL Aggregate Function Interview Questions for Data Science](https://www.kdnuggets.com/2023/01/3-sql-aggregate-function-interview-questions-data-science.html)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的 3 个 SQL 聚合函数面试问题](https://www.kdnuggets.com/2023/01/3-sql-aggregate-function-interview-questions-data-science.html)'
