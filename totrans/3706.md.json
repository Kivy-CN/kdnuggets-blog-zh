["```py\nimport pandas as pd\nfrom top2vec import Top2Vec\n\nfile_path = \"McDonalds-Yelp-Sentiment-DFE.csv\"\ndf = pd.read_csv(\n    file_path,\n    usecols=[\"_unit_id\", \"city\", \"review\"],\n    encoding=\"unicode_escape\",\n)\ndf.head()\ndocs_bad = df[\"review\"].values.tolist()\n```", "```py\ntopic_model = Top2Vec(\n    docs_bad,\n    embedding_model=\"universal-sentence-encoder\",\n    speed=\"deep-learn\",\n    tokenizer=tok,\n    ngram_vocab=True,\n    ngram_vocab_args={\"connector_words\": \"phrases.ENGLISH_CONNECTOR_WORDS\"},\n)\n```", "```py\ntopic_model.get_num_topics() #3\ntopic_words, word_scores, topic_nums = topic_model.get_topics(3)\n\nfor topic in topic_nums:\n    topic_model.generate_topic_wordcloud(topic)\n```", "```py\n(\n    documents,\n    document_scores,\n    document_ids,\n) = topic_model.search_documents_by_keywords(\n    keywords=[\"wrong\", \"slow\"], num_docs=5\n)\nfor doc, score, doc_id in zip(documents, document_scores, document_ids):\n    print(f\"Document: {doc_id}, Score: {score}\")\n    print(\"-----------\")\n    print(doc)\n    print(\"-----------\")\n    print()\n```", "```py\nDocument: 707, Score: 0.5517634093633295\n-----------\nhorrible.... that is all. do not go there.\n-----------\n\nDocument: 930, Score: 0.4242547340973836\n-----------\nno drive through :-/\n-----------\n\nDocument: 185, Score: 0.39162203345993046\n-----------\nthe drive through line is terrible. they are painfully slow.\n-----------\n\nDocument: 181, Score: 0.3775083338082392\n-----------\nawful service and extremely slow. go elsewhere.\n-----------\n\nDocument: 846, Score: 0.35400602635951994\n-----------\nthey have bad service and very rude\n-----------\n```", "```py\nmodel_path_bad = 'model/bert_bad'\ntopic_model_bad = train_bert(docs_bad,model_path_bad)\nfreq_df = topic_model_bad.get_topic_info()\nprint(\"Number of topics: {}\".format( len(freq_df)))\nfreq_df['Percentage'] = round(freq_df['Count']/freq_df['Count'].sum() * 100,2)\nfreq_df = freq_df.iloc[:,[0,1,3,2]]\nfreq_df.head()\n```"]