# MLOps 概述

> 原文：[https://www.kdnuggets.com/2021/03/overview-mlops.html](https://www.kdnuggets.com/2021/03/overview-mlops.html)

[评论](#comments)

**由[Steve Shwartz](https://www.aiperspectives.com/)，AI 作者、投资者和连续创业者**。

![](../Images/48afb2bff1fb2e3e30045c24f69e1f4c.png)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT 部门

* * *

*图片来源：iStockPhoto / NanoStockk*

通常需要相当的数据科学专业知识来创建数据集并构建特定应用的模型。但仅仅构建一个好的模型通常是不够的。实际上，远远不够。如下面所示，开发和测试模型只是第一步。

![](../Images/2c877ece7473a610986f63f263699983.png)

*机器学习模型生命周期。*

机器学习操作（MLOps）是使该模型有用的所有其他要求，包括自动化开发和部署管道、监控、生命周期管理和治理的能力，如上所示。让我们逐一探讨这些内容。

### 自动化管道

创建生产级 ML 系统需要多个步骤：首先，数据必须经过一系列转换。然后，模型进行训练。通常，这需要对不同的网络架构和超参数进行实验。经常需要返回数据，尝试不同的特征。接下来，模型必须通过单元测试和集成测试进行验证。它需要通过数据和模型偏差以及可解释性的测试。最后，它被部署到公共云、内部环境或混合环境中。此外，过程中某些步骤可能需要审批流程。

如果这些步骤每一步都手动执行，开发过程通常会很慢且容易出错。幸运的是，许多 MLOps 工具存在，可以自动化这些步骤，从数据转换到端到端部署。当需要重新训练时，它是一个自动化、可靠且可重复的过程。

### 监控

ML 模型在首次部署时往往表现良好，但随着时间推移效果会逐渐下降。正如 Forrester 分析师 Dr. Kjell Carlsson [所说](https://go.forrester.com/blogs/no-deploy-no-joy-leverage-modelops-to-operationalize-ai-and-machine-learning/)：“AI 模型就像隔离中的六岁孩子：它们需要持续关注……否则，某些东西会坏掉。”

部署时包括各种监控类型至关重要，这样当问题发生时，ML团队可以收到警报。性能可能因基础设施问题如CPU或内存不足而下降。当作为模型输入的自变量的真实数据开始呈现与训练数据不同的特征时，性能也可能下降，这种现象称为数据漂移。

同样，由于现实条件的变化，模型可能变得不再适用，这种现象称为概念漂移。例如，许多关于客户和供应商行为的预测模型在COVID-19疫情中发生了剧烈变化。

一些公司还监控替代模型（例如，不同的网络架构或不同的超参数），以查看这些“挑战者”模型是否有更好的表现。

通常，为模型做出的决策设置保护措施是合理的。这些保护措施是简单的规则，可以触发警报、阻止决策或将决策放入需要人工审批的工作流程中。

### 生命周期管理

当模型性能因数据或模型漂移开始下降时，需要进行模型再训练，甚至可能需要重新架构模型。然而，数据科学团队不应从头开始。在开发原始模型时，或许在之前的再架构中，他们已经测试了许多架构、超参数和特性。记录所有这些先前的实验（和结果）至关重要，以便数据科学团队不必从头再来。这也对数据科学团队成员之间的沟通和协作至关重要。

### 治理

机器学习模型被用于许多影响人们的应用场景，如银行贷款决策、医疗诊断和招聘/解雇决策。机器学习模型在决策中的使用受到批评的原因有两个：首先，这些模型可能存在偏见，尤其是当训练数据导致模型基于种族、肤色、民族、国籍、宗教、性别、性取向或其他受保护类别进行歧视时。其次，这些模型往往是黑箱，无法解释其决策过程。

因此，使用基于机器学习的决策制定的组织面临着确保其模型不歧视且能够解释其决策的压力。许多MLOps供应商正在结合基于学术研究的工具（例如，[SHAP](https://arxiv.org/pdf/1705.07874.pdf)和[Grad-CAM](https://arxiv.org/pdf/1610.02391.pdf)），帮助解释模型决策，并使用各种技术来确保数据和模型不带有偏见。此外，他们还在监控协议中加入了偏见和可解释性测试，因为模型可能会随着时间的推移变得有偏见或失去解释能力。

组织还需要建立信任，并开始确保持续的性能、无偏见和可解释性是可审计的。这要求建立模型目录，不仅记录所有的数据、参数和架构决策，还要记录每个决策，并提供可追溯性，以便确定每个决策所使用的数据、模型和参数，何时对模型进行再训练或其他修改，以及谁做了每个更改。审计人员还需要能够重复历史交易，并使用“假设”场景测试模型决策的边界。

安全和数据隐私也是使用机器学习的组织面临的关键问题。必须确保个人信息得到保护，并且基于角色的数据访问能力至关重要，尤其是对于受监管的行业。

世界各国政府也在迅速采取行动，对影响人们的机器学习决策进行监管。欧盟通过其 GDPR 和 CRD IV 规章走在了前列。在美国，包括美国联邦储备银行和 FDA 在内的多个监管机构已经为金融和医疗决策的机器学习决策制定了规章。更全面的法律《2020年数据问责和透明度法案》计划于 2021 年提交国会审议。法规可能会发展到 CEO 需要对其机器学习模型的可解释性和无偏见性进行签字确认的程度。

### 机器学习运维领域

随着我们进入 2021 年，机器学习运维市场正在爆炸性增长。根据分析公司 Cognilytica 的数据，预计到 2025 年将成为一个 [$40 亿市场](https://www.cognilytica.com/2020/04/02/infographic-the-rapid-growth-of-mlops/)。

机器学习运维领域有大玩家也有小玩家。主要的机器学习平台供应商，如 Amazon、Google、Microsoft、IBM、Cloudera、Domino、DataRobot 和 H2O，正将机器学习运维能力融入其平台中。根据 Crunchbase 的数据，机器学习运维领域有 35 家私营公司已筹集了 180 万美元到 10 亿美元的融资，并在 LinkedIn 上有 3 到 2800 名员工：

|  | **融资（百万美元）** | **员工数量** | **描述** |
| --- | --- | --- | --- |
| Cloudera | 1000 | 2803 | Cloudera 提供一个企业数据云，适用于任何数据，从边缘到人工智能。 |
| Databricks | 897 | 1757 | Databricks 是一个软件平台，帮助客户统一其业务、数据科学和数据工程方面的分析。 |
| DataRobot | 750 | 1105 | DataRobot 将 AI 技术和 ROI 使能服务带给全球企业。 |
| Dataiku | 246 | 556 | Dataiku 作为一个企业人工智能和机器学习平台运营。 |
| Alteryx | 163 | 1623 | Alteryx 通过统一分析、数据科学和自动化流程来加速数字化转型。 |
| H2O | 151 | 257 | H2O.ai 是 AI 和自动化机器学习的开源领导者，使命是让 AI 对所有人开放 |
| Domino | 124 | 232 | Domino 是全球领先的企业数据科学平台，为超过 20% 的《财富》100 强公司提供数据科学支持 |
| Iguazio | 72 | 83 | Iguazio 数据科学平台使你能够以规模和实时开发、部署和管理 AI 应用程序 |
| Explorium.ai | 50 | 96 | Explorium 提供一个数据科学平台，支持增强的数据发现和特征工程 |
| Algorithmia | 38 | 63 | Algorithmia 是一个机器学习模型部署和管理解决方案，自动化组织的 MLOps |
| Paperspace | 23 | 37 | Paperspace 支持基于 GPU 的下一代应用程序 |
| Pachyderm | 21 | 32 | Pachyderm 是一个企业级数据科学平台，使可解释、可重复和可扩展的 AI/ML 成为现实 |
| Weights and Biases | 20 | 58 | Weights and Biases 是用于实验跟踪、提升模型性能和结果协作的工具 |
| OctoML | 19 | 37 | OctoML 正在改变开发人员优化和部署机器学习模型以满足 AI 需求的方式 |
| Arthur AI | 18 | 28 | Arthur AI 是一个监控机器学习模型生产力的平台 |
| Truera | 17 | 26 | Truera 提供一个模型智能平台，帮助企业分析机器学习 |
| Snorkel AI | 15 | 39 | Snorkel AI 专注于通过 Snorkel Flow 使 AI 实用：一个以数据为中心的企业 AI 平台 |
| Seldon.io | 14 | 48 | 机器学习部署平台 |
| Fiddler Labs | 13 | 46 | Fiddler 使用户能够创建透明、可解释和易于理解的 AI 解决方案 |
| run.ai | 13 | 26 | Run:AI 开发了一种自动化分布式训练技术，可以虚拟化并加速深度学习 |
| ClearML (Allegro) | 11 | 29 | ML / DL 实验管理器和 ML-Ops 开源解决方案，端到端产品生命周期管理企业解决方案 |
| Verta | 10 | 15 | Verta 构建软件基础设施，帮助企业数据科学和机器学习（ML）团队开发和部署 ML 模型 |
| cnvrg.io | 8 | 38 | cnvrg.io 是一个全栈数据科学平台，帮助团队管理模型并构建自适应机器学习管道 |
| Datatron | 8 | 19 | Datatron 提供一个统一的模型治理（管理）平台，适用于所有生产中的 ML、AI 和数据科学模型 |
| Comet | 7 | 19 | Comet.ml 是一个机器学习平台，旨在帮助 AI 从业者和团队构建可靠的机器学习模型 |
| ModelOp | 6 | 39 | 监管、监控和管理企业中的所有模型 |
| WhyLabs | 4 | 15 | WhyLabs 是 AI 可观察性和监控公司 |
| Arize AI | 4 | 14 | Arize AI 提供一个平台，用于解释和排查生产中的 AI |
| DarwinAI | 4 | 31 | DarwinAI 的生成合成 'AI 构建 AI' 技术实现了优化和可解释的深度学习。 |
| Mona | 4 | 11 | Mona 是一个用于数据和 AI 驱动系统的 SaaS 监控平台。 |
| Valohai | 2 | 13 | 您的托管机器学习平台，让数据科学家能够构建、部署和跟踪机器学习模型。 |
| Modzy | 0 | 31 | 安全的 ModelOps 平台，用于发现、部署、管理和治理大规模的机器学习——更快实现价值。 |
| Algomox | 0 | 17 | 激发您的 AI 转型 |
| Monitaur | 0 | 8 | Monitaur 是一家提供审计、透明度和治理的软件公司，专注于使用机器学习软件的公司。 |
| Hydrosphere.io | 0 | 3 | Hydrosphere.io 是一个用于 AI/ML 操作自动化的平台 |

这些公司中的许多专注于 MLOps 的一个细分领域，如自动化管道、监控、生命周期管理或治理。[一些人认为](https://www.oreilly.com/radar/why-best-of-breed-is-a-better-choice-than-all-in-one-platforms-for-data-science/) 使用多个最佳产品的 MLOps 产品比单一平台更适合数据科学项目。有些公司正在为特定垂直领域构建 MLOps 产品。例如，[Monitaur](https://monitaur.ai/) 将自己定位为能够与任何平台协作的最佳治理解决方案。Monitaur 还为受监管的行业（首先是保险）构建了行业特定的 MLOps 治理能力。（完全披露：我是一位 Monitaur 的投资者）。

还有许多开源的 MLOps 项目，包括：

+   **MLFlow** 管理 ML 生命周期，包括实验、可重复性和部署，并包括一个模型注册中心。

+   **DVC** 管理 ML 项目的版本控制，使其可分享和可重复。

+   **Polyaxon** 具有实验、生命周期自动化、协作和部署的能力，并包括一个模型注册中心。

+   **Metaflow** 是 Netflix 以前的项目，用于管理自动化管道和部署。

+   **Kubeflow** 具有 Kubernetes 容器中的工作流自动化和部署能力。

2021 年承诺将是 MLOps 的一个有趣年份。我们可能会看到快速增长、巨大的竞争，以及最可能的一些整合。

**Bio:** [Steve Shwartz](https://www.linkedin.com/in/steveshwartz/) ([@sshwartz](https://twitter.com/sshwartz)) 多年前在耶鲁大学开始他的 AI 职业生涯，是一位成功的连续创业者和投资者，并著有《邪恶机器人、致命计算机及其他神话：关于 AI 和人类未来的真相》。

**相关：**

+   [机器学习模型监控检查表：7 个跟踪项](https://www.kdnuggets.com/2021/03/machine-learning-model-monitoring-checklist.html)

+   [如何使用 MLOps 进行有效的 AI 策略](https://www.kdnuggets.com/2021/01/mlops-effective-ai-strategy.html)

+   [MLOps：模型监控基础](https://www.kdnuggets.com/2021/01/mlops-model-monitoring-101.html)

### 更多相关话题

+   [MLOps 中的机器学习设计模式](https://www.kdnuggets.com/2022/02/design-patterns-machine-learning-mlops.html)

+   [MLOps 是一团糟，但这在意料之中](https://www.kdnuggets.com/2022/03/mlops-mess-expected.html)

+   [MLOps 综合指南](https://www.kdnuggets.com/2023/08/comprehensive-guide-mlops.html)

+   [Ploomber 与 Kubeflow：让 MLOps 更加简单](https://www.kdnuggets.com/2022/02/ploomber-kubeflow-mlops-easier.html)

+   [在纽约的 Rev 3 上与数据科学社区联系，全球第一…](https://www.kdnuggets.com/2022/03/domino-connect-data-science-community-nyc-mlops-conference.html)

+   [什么是 MLOps 工程师？](https://www.kdnuggets.com/2022/03/mlops-engineer.html)
