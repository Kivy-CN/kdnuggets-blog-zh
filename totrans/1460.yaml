- en: Types of Bias in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/08/types-bias-machine-learning.html](https://www.kdnuggets.com/2019/08/types-bias-machine-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)![figure-name](../Images/932d35c45727fe84810f1f53cdde168b.png)https://www.infoq.com/presentations/unconscious-bias-machine-learning/'
  prefs: []
  type: TYPE_NORMAL
- en: In one my [previous posts](/2019/07/bias-machine-learning-bad.html) I talke
    about the biases that are to be expected in machine learning and can actually
    help build a better model. Here is the follow-up post to show some of the bias
    to be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Sample Bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We all have to consider sampling bias on our training data as a result of human
    input. Machine learning models are predictive engines that train on a large mass
    of data based on the past. They are made to predict **based on what they have
    been trained to predict.** These predictions are only as reliable as the human
    collecting and analyzing the data. The decision makers have to remember that if
    humans are involved at any part of the process, there is a greater chance of bias
    in the model.
  prefs: []
  type: TYPE_NORMAL
- en: The sample data used for training has to be as close a representation of the
    real scenario as possible. There are many factors that can bias a sample from
    the beginning and those reasons differ from each domain (i.e. business, security,
    medical, education etc.)
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Prejudice Bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This again is a cause of human input. Prejudice occurs as a result of cultural
    stereotypes in the people involved in the process. Social class, race, nationality,
    gender can creep into a model that can completely and **unjustly** skew the results
    of your model. Unfortunately it is not hard to believe that it may have been the
    intention or just neglected throughout the whole process.
  prefs: []
  type: TYPE_NORMAL
- en: Involving some of these factors in statistical modelling for research purposes
    or to understand a situation at a point in time is completely different to predicting
    who should get a loan when the training data is skewed against people of a certain
    race, gender and/or nationality.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Confirmation Bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Confirmation bias, the tendency to process information by looking for, or interpreting,
    information that is consistent with one’s existing beliefs. *Source [https://www.britannica.com/science/confirmation-bias](https://www.britannica.com/science/confirmation-bias)*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is a well-known bias that has been studied in the field of psychology and
    directly applicable to how it can affect a machine learning process. If the people
    of intended use have a pre-existing hypothesis that they would like to confirm
    with machine learning *(there are probably simple ways to do it depending on the
    context)* the people involved in the modelling process might be inclined to intentionally
    manipulate the process towards finding that answer. I would personally think it
    is more common than we think just because heuristically, many of us in industry
    might be pressured to get a certain answer before even starting the process than
    just looking to see what the data is actually saying.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Group attribution Bias
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This type of bias results from when you train a model with data that contains
    an asymmetric view of a certain group. For example, in a certain sample dataset
    if the majority of a certain gender would be more successful than the other or
    if the majority of a certain race makes more than another, your model will be
    inclined to believe these falsehoods. There is label bias in these cases. In actuality,
    these sorts of labels should not make it into a model in the first place. The
    sample used to understand and analyse the current situation cannot just be used
    as training data without the appropriate pre-processing to account for any potential
    unjust bias. Machine learning models are becoming more ingrained in society without
    the ordinary person even knowing which makes group attribution bias just as likely
    to punish a person unjustly because the necessary steps were not taken to account
    for the bias in the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Literacy: Using the Socratic Method](/2019/06/data-literacy-socratic-method.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[All Models Are Wrong – What Does It Mean?](/2019/06/all-models-are-wrong.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What 70% of Data Science Learners Do Wrong](/2019/08/what-data-science-learners-do-wrong.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
