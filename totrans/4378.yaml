- en: 'Pandas on Steroids: End to End Data Science in Python with Dask'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习中的 Pandas：使用 Dask 进行端到端数据科学
- en: 原文：[https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html](https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html](https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Ravi Shankar](https://www.linkedin.com/in/ravi-shankar-83863441/), Data
    Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Ravi Shankar](https://www.linkedin.com/in/ravi-shankar-83863441/)，数据科学家**'
- en: '![Figure](../Images/2dba06d5b5ef5894865533eb15a7b35a.png)Dask - Familiar pandas
    with superpowers'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![图示](../Images/2dba06d5b5ef5894865533eb15a7b35a.png)Dask - 拥有超级能力的 pandas'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As the saying goes, a data scientist spends 90% of their time in cleaning data
    and 10% in complaining about the data. Their complaints may range from data size,
    faulty data distributions, Null values, data randomness, systematic errors in
    data capture, differences between train and test sets and the list just goes on
    and on.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如俗话所说，数据科学家花费 90% 的时间在清理数据上，10% 的时间抱怨数据。他们的抱怨可能涉及数据大小、数据分布不准确、空值、数据随机性、数据捕捉中的系统性错误、训练集和测试集之间的差异等等。
- en: One common bottleneck theme is the enormity of data size where either the data
    doesn't fit into memory or the processing time is so large(In order of multi-mins)
    that the inherent pattern analysis goes for a toss. Data scientists by nature
    are curious human beings who want to identify and interpret patterns normally
    hidden from cursory Drag-N-Drop glance. They need to wear multiple hats and make
    the data confess via repeated tortures(read iterations ????)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的瓶颈主题是数据大小的庞大，数据无法适配内存或处理时间过长（以分钟为单位），导致内在模式分析难以进行。数据科学家本质上是好奇的，他们希望识别和解释那些通常在表面拖拽观察中隐藏的模式。他们需要戴上多顶帽子，通过反复的折磨（即多次迭代）让数据“坦白”。
- en: 'They wear multiple hats during exploratory data analysis and from a minimal
    dataset with 6 columns on New York Taxi Fare dataset([https://www.kaggle.com/c/new-york-city-taxi-fare-prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction))
    - ID, Fare, Time of Trip, Passengers and Location, their questions may range from:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索性数据分析中，他们戴上了多种帽子，从包含 6 列的纽约出租车费用数据集([https://www.kaggle.com/c/new-york-city-taxi-fare-prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction))
    - ID、费用、旅行时间、乘客和位置，他们的问题可能包括：
- en: How the fares have changed Year-Over-Year?
  id: totrans-14
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 费用年复一年地变化情况如何？
- en: Has the number of trips increased across the years?
  id: totrans-15
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 年复一年，旅行次数是否增加了？
- en: Do people prefer traveling alone or they have company?
  id: totrans-16
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人们更喜欢单独旅行还是有同行？
- en: Has the small distance rides increased as people have become lazier?
  id: totrans-17
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随着人们变得更加懒惰，小距离的骑行是否增加了？
- en: What time of the day and day of week do people want to travel?
  id: totrans-18
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人们希望在一天中的什么时间和一周中的哪几天旅行？
- en: Is there emergence of new hotspots in the city recently except the regular Air
    Port pickup and drop?
  id: totrans-19
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最近城市中是否出现了新的热点区域，除了常规的机场接送？
- en: Are people taking more inter-city trips?
  id: totrans-20
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人们是否在进行更多的城际旅行？
- en: Has the traffic increased leading to more fares/time taken for the same distances?
  id: totrans-21
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交通量是否增加，导致相同距离的费用/时间增加？
- en: Are there cluster of pick-up and Drop points or areas which see high traffic?
  id: totrans-22
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否存在接送点的集群或高流量区域？
- en: Are there outliers in data i.e 0 distance and fare of $100+ and so on?
  id: totrans-23
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据中是否存在异常值，如 0 距离和超过 $100 的费用等？
- en: Do the demand change during Holiday season and airport trips increase?
  id: totrans-24
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需求是否在节假日季节变化，机场接送是否增加？
- en: Is there any correlation of weather i.e rain or snow with the taxi demand?
  id: totrans-25
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有天气因素（如雨雪）与出租车需求的相关性？
- en: Even after answering these questions, multiple sub-threads can emerge i.e can
    we predict how the Covid affected New year is going to be, How the annual NY marathon
    shifts taxi demand, If a particular route if more prone to have multiple passengers(Party
    hub) vs Single Passengers( Airport to Suburbs).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 即使回答了这些问题，仍然可能会出现多个子线程，例如我们能否预测新年受 Covid 影响的情况、年度纽约马拉松如何影响出租车需求、某个特定路线是否更容易有多个乘客（聚会中心）与单个乘客（机场到郊区）？
- en: 'To quench these curiosities, time is of the essence and its criminal to keep
    the data scientists waiting for 5+ minutes to read a csv file(55 Mn rows) or do
    a column add followed by aggregation. Also, since the majority of Data Scientists
    are self-taught and they have been so much used to pandas data frame API that
    they wouldn''t want to start the learning process all over again with a different
    API like numba, Spark or datatable. I have tried juggling between DPLYR(R), Pandas(Python)
    and pyspark(Spark) and it is a bit unfulfilling/unproductive considering the need
    for a uniform pipeline and code syntax. However, for the curious folks, I have
    written a pyspark starter guide here: [https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些好奇心，时间至关重要。如果让数据科学家等待 5 分钟以上来读取一个 csv 文件（5500 万行）或进行列添加和后续聚合，那是犯罪行为。此外，由于大多数数据科学家是自学成才的，他们已经习惯了
    pandas 数据框 API，不愿意用不同的 API，如 numba、Spark 或 datatable，重新开始学习过程。我曾尝试在 DPLYR（R）、Pandas（Python）和
    pyspark（Spark）之间来回切换，这有点令人失望/不高效，因为需要一个统一的管道和代码语法。然而，对于好奇的人，我在这里写了一个 pyspark 入门指南：[https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)
- en: 'In subsequent sections, I am trying to provide a hands on guide to Dask with
    minimal architectural change from our beloved Pandas:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续部分，我尝试提供一个 Dask 的实用指南，尽量减少与我们钟爱的 Pandas 的架构差异：
- en: '**1\. Data Read and Profiling**'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1. 数据读取和分析**'
- en: Dask vs Pandas speed
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 与 Pandas 的速度对比
- en: How is Dask able to process data ~90X faster i.e Sub 1 secs to 91 secs in pandas.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 如何能够将数据处理速度提高 ~90 倍，即在 pandas 中从 1 秒以下到 91 秒。
- en: '![Figure](../Images/76f6d452602d9621a742e24474e658c1.png)*Source: *[*https://dask.org/*](https://dask.org/)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/76f6d452602d9621a742e24474e658c1.png)*来源：*[*https://dask.org/*](https://dask.org/)'
- en: What makes Dask so popular is the fact that it makes analytics scalable in Python
    and not necessarily need switching back and forth between SQL, Scala and Python.The
    magical feature is that this tool requires minimum code changes. It breaks down
    computation into pandas data frames and thus operates in parallel to enable fast
    calculations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 之所以如此受欢迎，是因为它使 Python 中的分析具有可扩展性，并且不一定需要在 SQL、Scala 和 Python 之间来回切换。它的神奇之处在于这个工具需要最小的代码更改。它将计算分解为
    pandas 数据框，从而并行操作以实现快速计算。
- en: '![Figure](../Images/643af4e780c97b3377bbe76e9f67246e.png)*Source:* [*https://docs.dask.org/en/latest/*](https://docs.dask.org/en/latest/)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/643af4e780c97b3377bbe76e9f67246e.png)*来源：*[*https://docs.dask.org/en/latest/*](https://docs.dask.org/en/latest/)'
- en: '**2\. Data Aggregation**'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**2. 数据聚合**'
- en: With absolutely 0 change from Pandas API, it is able to perform aggregation
    and sorting in milliseconds. Please note .**compute() **function at the end of
    lazy computation which brings the results of big data to memory in Pandas Data
    Frame.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 完全没有改变 Pandas API 的情况下，它能够在毫秒级别执行聚合和排序操作。请注意，**compute()** 函数在延迟计算结束时，将大数据的结果带到
    Pandas 数据框中。
- en: '**3\. Machine Learning**'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3. 机器学习**'
- en: Code snippet below provides a working example of feature engineering and ML
    model building in Dask using XGBoost
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段提供了使用 XGBoost 在 Dask 中进行特征工程和 ML 模型构建的工作示例
- en: Feature Engineering and ML Model with Dask
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程和 Dask 的 ML 模型
- en: '**Conclusion:**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论：**'
- en: Dask is a powerful tool offering parallel computing, big data handling and creating
    end to end Data Science pipeline. It has a steep learning curve as the API is
    almost similar to pandas and it can handle Out Of Memory computations(~10X of
    RAM) like a breeze.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 是一个强大的工具，提供并行计算、大数据处理以及创建端到端的数据科学管道。它有一个陡峭的学习曲线，因为它的 API 与 pandas 几乎相似，而且可以轻松处理超出内存限制的计算（~10倍
    RAM）。
- en: Since it is a living blog, I will be writing subsequent parts in Dask series
    where we will be targeting Kaggle leaderboard using parallel processing. Let me
    know in comments if you are facing any issues in setting up Dask or unable to
    perform any Dask Operations or even for a general chit-chat. Happy Learning!!!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个动态博客，我将继续编写Dask系列的后续部分，我们将通过并行处理来瞄准Kaggle排行榜。如果你在设置Dask或执行任何Dask操作时遇到问题，或者只是想聊聊，请在评论中告诉我。祝学习愉快!!!
- en: 'Sources:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 资源：
- en: '[https://ml.dask.org/](https://ml.dask.org/)'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://ml.dask.org/](https://ml.dask.org/)'
- en: '[https://dask.org/](https://dask.org/)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://dask.org/](https://dask.org/)'
- en: '[https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)'
- en: '[https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138](https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138)'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138](https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138)'
- en: '[https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask)'
- en: '[https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57](https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57](https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57)'
- en: '**Bio: [Ravi Shankar](https://www.linkedin.com/in/ravi-shankar-83863441/)**
    is a Data Scientist-II at Amazon Pricing.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Ravi Shankar](https://www.linkedin.com/in/ravi-shankar-83863441/)** 是亚马逊定价部门的数据科学家-II。'
- en: '[Original](https://medium.com/analytics-vidhya/pandas-on-steroids-dask-end-to-end-data-science-with-python-code-1845d3722c8a).
    Reposted with permission.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/analytics-vidhya/pandas-on-steroids-dask-end-to-end-data-science-with-python-code-1845d3722c8a)。转载已获许可。'
- en: '**Related:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine Learning in Dask](/2020/06/machine-learning-dask.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Dask中进行机器学习](/2020/06/machine-learning-dask.html)'
- en: '[Data Science in the Cloud with Dask](/2020/10/data-science-cloud-dask.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在云中使用Dask进行数据科学](/2020/10/data-science-cloud-dask.html)'
- en: '[Why and How to Use Dask with Big Data](/2020/04/dask-big-data.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么以及如何在大数据中使用Dask](/2020/04/dask-big-data.html)'
- en: More On This Topic
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为伟大数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
