- en: 'Essential Math for Data Science: Probability Density and Probability Mass Functions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/12/essential-math-data-science-probability-density-probability-mass-functions.html](https://www.kdnuggets.com/2020/12/essential-math-data-science-probability-density-probability-mass-functions.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)[![Image](../Images/45c05efbbd9635efb62adde614427da4.png)](https://www.essentialmathfordatascience.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: In the chapter 02 of [Essential Math for Data Science](https://www.essentialmathfordatascience.com/),
    you can learn about basic descriptive statistics and probability theory. We’ll
    cover probability mass and probability density function in this sample. You’ll
    see how to understand and represent these distribution functions and their link
    with histograms.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deterministic* processes give the same results when they are repeated multiple
    times. This is not the case for random variables, which describe *stochastic* events,
    in which randomness characterizes the process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that random variables can take various values. How can you describe
    and compare these values? One good way is to use the probability that each outcome
    will occur. The probability distribution of a random variable is a function that
    takes the sample space as input and returns probabilities: in other words, it
    maps possible outcomes to their probabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you’ll learn about probability distributions for discrete and
    continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: Probability Mass Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Probability functions of discrete random variables are called *probability
    mass functions* (or PMF). For instance, let’s say that you’re running a dice-rolling
    experiment. You call *X* the random variable corresponding to this experiment.
    Assuming that the die is fair, each outcome is *equiprobable*: if you run the
    experiment a large number of times, you will get each outcome approximately the
    same number of times. Here, there are six possible outcomes, so you have one chance
    over six to draw each number.'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the probability mass function describing *X* returns 1616 for each possible
    outcome and 0 otherwise (because you can’t get something different than 1, 2,
    3, 4, 5 or 6).
  prefs: []
  type: TYPE_NORMAL
- en: You can write ![Equation](../Images/944ab155d2ca6389ef670d7175c38c1e.png), ![Equation](../Images/e7d852811ec6153c664b976269cd4a3f.png)
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Properties of Probability Mass Functions**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not every function can be considered as a probability mass function. A probability
    mass function must satisfy the following two conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The function must return values between 0 and 1 for each possible outcome:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Equation](../Images/615eed300fd9a3963781b55e746998a3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The sum of probabilities corresponding to all the possible outcomes must be
    equal to 1:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Equation](../Images/3561975a6327b827f5465d5035123bc2.png)'
  prefs: []
  type: TYPE_IMG
- en: The value of *x* can be any real number because values outside of the sample
    space are associated with a probability of 0\. Mathematically, for any value *x* not
    in the sample space *S*, *P(x)=0*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Simulation of the Dice Experiment**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s simulate a die experiment using the function `np.random.randint(low,
    high, size)` from Numpy which draw *n* (`size`) random integers between `low` and `high` (excluded).
    Let’s simulate 20 die rolls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This array contains the 20 outcomes of the experiment. Let’s call *X* the discrete
    random variable corresponding to the die rolling experiment. The probability mass
    function of *X* is defined only for the possible outcomes and gives you the probability
    for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming the die is fair, you should have an *uniform distribution*, that is,
    equiprobable outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s visualize the quantity of each outcome you got in the random experiment.
    You can divide by the number of trials to get the probability. Let’s use `plt.stem()` from
    Matplotlib to visualize these probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 1: Probability mass function of the random variable $\rx$ corresponding
    to a die rolling a six-sided die estimated from 20 rolls.](../Images/b191220c424acb083f88b09f97db59d9.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1: Probability mass function of the random variable *X* corresponding
    to a die rolling a six-sided die estimated from 20 rolls.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'With a uniform distribution, the plot would have the same height for each outcome
    (since the height corresponds to the probability, which is the same for each outcome
    of a die throw). However, the distribution shown in Figure 1 doesn’t look uniform.
    That’s because you didn’t repeat the experiment enough: the probabilities will
    stand when you repeat the experiment a large number of times (in theory, an infinite
    number of times).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s increase the number of trials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 2: Probability mass function of the random variable $\rx$ corresponding
    to a die rolling experiment estimated from 100,000 rolls.](../Images/b1700a8ba7a9c2288e651054db0ce46c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2: Probability mass function of the random variable *X* corresponding
    to a die rolling experiment estimated from 100,000 rolls.*'
  prefs: []
  type: TYPE_NORMAL
- en: With enough trials, the probability mass function showed in Figure 2 looks uniform.
    This underline the importance of the number of trials from a frequentist probability
    point of view.
  prefs: []
  type: TYPE_NORMAL
- en: Probability Density Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With continuous variables, there is an infinite number of possible outcomes
    (limited by the number of decimals you use). For instance, if you were drawing
    a number between 0 and 1 you might get an outcome of, for example, 0.413949834\.
    The probability of drawing each number tends towards zero: if you divide something
    by a very large number (the number of possible outcomes), the result will be very
    small, close to zero. This is not very helpful in describing random variables.'
  prefs: []
  type: TYPE_NORMAL
- en: It is better to consider the probability of getting a specific number within
    a range of values. The *y*-axis of probability density functions is not a probability.
    It is called a *probability density* or just *density*. Thus, probability distributions
    for continuous variables are called *probability density functions* (or PDF).
  prefs: []
  type: TYPE_NORMAL
- en: The integral of the probability density function over a particular interval
    gives you the probability that a random variable takes a value in this interval.
    This probability is thus given by the area under the curve in this interval (as
    you can see in [Essential Math for Data Science](https://www.essentialmathfordatascience.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Notation**'
  prefs: []
  type: TYPE_NORMAL
- en: Here, I’ll denote probability density functions using a lowercase *p*. For instance,
    the function *p(x)* gives you the density corresponding to the value *x*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s inspect an example of probability density function. You can randomly draw
    data from a normal distribution using the Numpy function `np.random.normal` (you’ll
    find more details about the normal distribution in [Essential Math for Data Science](https://www.essentialmathfordatascience.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: You can choose the parameters of the normal distribution (the mean and the standard
    deviation) and the number of samples. Let’s create a variable `data` with 1,000
    values drawn randomly from a normal distribution with a mean of 0.3 and a standard
    deviation of 0.1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the shape of the distribution using an histogram. The function `plt.hist()` returns
    the exact values for the *x*- and *y*-coordinates of the histogram. Let’s store
    this in a variable called `hist` for latter use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 3: Histogram of the data generated from a normal distribution. The
    $x$-axis is the value of the element in the vector and the $y$-axis the number
    of elements (count) that are in the corresponding range.](../Images/de9103afff39a0117ba3182af6b2ff40.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3: Histogram of the data generated from a normal distribution. The *x*-axis
    is the value of the element in the vector and the *y*-axis the number of elements
    (count) that are in the corresponding range.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Histograms**'
  prefs: []
  type: TYPE_NORMAL
- en: Histograms show how values are distributed. It is a way to model a probability
    distribution using a finite number of values from the distribution. Since we're
    dealing with continuous distributions, this histogram corresponds to the number
    of values for specific intervals (the intervals depends on the parameter `bins` in
    the function `hist()`).
  prefs: []
  type: TYPE_NORMAL
- en: For instance, Figure 3 shows that there are around 347 elements in the interval
    (0.2, 0.3). Each bin corresponds to a width of 0.1, since we used 13 bins to represent
    data in the range -0.3 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a closer look at the distribution with more bins. You can use the
    parameter `density` to make the *y*-axis correspond to the probability density
    instead of the count of values in each bin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 4: Histogram using 30 bins and density instead of counts.](../Images/f13e4fb6b410e792eb6fb8f3a5a667a4.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4: Histogram using 30 bins and density instead of counts.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in Figure 4 that there are more bins in this histogram (24 instead
    of 13). This means that each bin has now a smaller width. The *y*-axis is also
    on a different scale: it corresponds to the density, not the counter of values
    as before.'
  prefs: []
  type: TYPE_NORMAL
- en: To calculate the probability to draw a value in a certain range from the density,
    you need to use the area under the curve. In the case of histograms, this is the
    area of the bars.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example with the bar ranging from 0.2 to 0.25, associated with
    the following density:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Since there are 24 bins and the range of possible outcomes is from -0.2 to 1,
    each bar corresponds to a range of ![Equation](../Images/a56a6a76393cd90053517cb4aad48ca1.png).
    In our example, the height of the bar (the one from 0.2 to 0.25) is around 2.8,
    so the area of this bar is ![Equation](../Images/4dffef186e6e810b5534a9603eb1eb5e.png).
    This means that the probability of getting a value between 0.2 and 0.25 is around
    0.14, or 14%.
  prefs: []
  type: TYPE_NORMAL
- en: 'You saw that the sum of the probabilities must be equal to one, so the sum
    of the bar’s areas should be equal to one. Let’s check that: you can take the
    vector containing the densities (`hist[0]`) and multiply it by the bar width (0.05):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'All good: the sum of the probabilities is equal to one.'
  prefs: []
  type: TYPE_NORMAL
- en: '**From Histograms to Continuous Probability Density Functions**'
  prefs: []
  type: TYPE_NORMAL
- en: Histograms represent a binned version of the probability density function. Figure
    5 shows a representation of the true probability density function. The blue shaded
    area in the figure corresponds to the probability of getting a number between
    0 and 0.2 (the area under the curve between 0 and 0.2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted
    area under the curve.](../Images/893b87fda444981f3206ef399f6a4747.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5: The probability to draw a number between 0 and 0.2 is the highlighted
    area under the curve.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Properties of Probability Density Functions**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like probability mass functions, probability density functions must satisfy
    some requirements. The first is that it must return only non negative values.
    Mathematically written:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/50e026edde51f73f6106666afc436f0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The second requirement is that the total area under the curve of the probability
    density function must be equal to 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/709478cb987edef0a65c9dbe81a8f3ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this part on probability distributions, you saw that probability mass functions
    are for discrete variables and probability density functions for continuous variables.
    Keep in mind that the value on the *y* axis of probability mass functions are
    probabilities, which is not the case for probability density functions. Look at
    the density values (for instance in Figure 4): they can be larger than one, which
    shows that they are not probabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Hadrien Jean](https://hadrienj.github.io/)** is a machine learning
    scientist. He owns a Ph.D in cognitive science from the Ecole Normale Superieure,
    Paris, where he did research on auditory perception using behavioral and electrophysiological
    data. He previously worked in industry where he built deep learning pipelines
    for speech processing. At the corner of data science and environment, he works
    on projects about biodiversity assessement using deep learning applied to audio
    recordings. He also periodically creates content and teaches at Le Wagon (data
    science Bootcamp), and writes articles in his blog ([hadrienj.github.io](http://hadrienj.github.io)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://hadrienj.github.io/posts/Essential-Math-probability-distributions/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Integrals And Area Under The Curve](/2020/11/essential-math-data-science-integrals-area-under-curve.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Boost your data science skills. Learn linear algebra.](/2018/05/boost-data-science-skills-learn-linear-algebra.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science:  ‘Why’ and ‘How’](/2018/09/essential-math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How To Overcome The Fear of Math and Learn Math For Data Science](https://www.kdnuggets.com/2021/03/overcome-fear-learn-math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 6: 12 Essential Data Science VSCode…](https://www.kdnuggets.com/2022/n27.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Eigenvectors and Application to PCA](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Visual Introduction to Singular…](https://www.kdnuggets.com/2022/06/essential-math-data-science-visual-introduction-singular-value-decomposition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Essential Pandas Functions Every Data Scientist Should Know](https://www.kdnuggets.com/10-essential-pandas-functions-every-data-scientist-should-know)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Density Kernel Depth for Outlier Detection in Functional Data](https://www.kdnuggets.com/density-kernel-depth-for-outlier-detection-in-functional-data)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
