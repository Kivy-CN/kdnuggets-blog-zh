- en: 'Text Summarization Development: A Python Tutorial with GPT-3.5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/04/text-summarization-development-python-tutorial-gpt35.html](https://www.kdnuggets.com/2023/04/text-summarization-development-python-tutorial-gpt35.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Text Summarization Development: A Python Tutorial with GPT-3.5](../Images/e90954496b2af8e6bb05cee51d68e352.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [frimufilms](https://www.freepik.com/free-photo/opened-ai-chat-laptop_38259334.htm#query=chatgpt&position=0&from_view=search&track=sph)
    on [Freepik](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: This is an era where AI breakthrough is coming daily. We didn’t have many AI-generated
    in public a few years ago, but now the technology is accessible to everyone. It’s
    excellent for many individual creators or companies that want to significantly
    take advantage of the technology to develop something complex, which might take
    a long time.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most incredible breakthroughs that change how we work is the release
    of the [GPT-3.5 model by OpenAI](https://platform.openai.com/docs/models/gpt-3-5).
    What is the GPT-3.5 model? If I let the model talk for themselves. In that case,
    the answer is “**a highly advanced AI model in the field of natural language processing,
    with vast improvements in generating contextually accurate and relevant tex**t”.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI provides an API for the GPT-3.5 model that we can use to develop a simple
    app, such as a text summarizer. To do that, we can use Python to integrate the
    model API into our intended application seamlessly. What does the process look
    like? Let’s get into it.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a few prerequisites before following this tutorial, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '- Knowledge of Python, including knowledge of using external libraries and
    IDE'
  prefs: []
  type: TYPE_NORMAL
- en: '- Understanding of APIs and handling the endpoint with Python'
  prefs: []
  type: TYPE_NORMAL
- en: '- Having access to the OpenAI APIs'
  prefs: []
  type: TYPE_NORMAL
- en: To obtain OpenAI APIs access, we must register on the [OpenAI Developer Platform](https://platform.openai.com/overview)
    and visit the View API keys within your profile. On the web, click the “Create
    new secret key” button to acquire API access (See image below). Remember to save
    the keys, as they will not be shown the keys after that.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Summarization Development: A Python Tutorial with GPT-3.5](../Images/7978f98c4ae019e66b98f06f9b76c9f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: With all the preparation ready, let’s try to understand the basic of the OpenAI
    APIs model.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding GPT-3.5 OpenAI API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [GPT-3.5 family model](https://platform.openai.com/docs/models/gpt-3-5)
    was specified for many language tasks, and each model in the family excels in
    some tasks. For this tutorial example, we would use the `gpt-3.5-turbo` as it
    was the recommended current model when this article was written for its capability
    and cost-efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: We often use the `text-davinci-003` in the OpenAI tutorial, but we would use
    the current model for this tutorial. We would rely on the [ChatCompletion](https://platform.openai.com/docs/api-reference/chat/create)
    endpoint instead of Completion because the current recommended model is a chat
    model. Even if the name was a chat model, it works for any language task.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try to understand how the API works. First, we need to install the current
    OpenAI packages.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After we have finished installing the package, we will try to use the API by
    connecting via the ChatCompletion endpoint. However, we need to set the environment
    before we continue.
  prefs: []
  type: TYPE_NORMAL
- en: In your favorite IDE (for me, it’s VS Code), create two files called `.env`
    and `summarizer_app.py`, similar to the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Summarization Development: A Python Tutorial with GPT-3.5](../Images/74073bce3a80f216eb7daf5aabb43fad.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The `summarizer_app.py` is where we would build our simple summarizer application,
    and the `.env` file is where we would store our API Key. For security reasons,
    it is always advised to separate our API key in another file rather than hard-code
    them in the Python file.
  prefs: []
  type: TYPE_NORMAL
- en: In the `.env` file put the following syntax and save the file. Replace your_api_key_here
    with your actual API key. Don’t change the API key into a string object; let them
    as it is.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To understand the GPT-3.5 API better; we would use the following code to generate
    the word summarizer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The above code is how we interact with the OpenAI APIs GPT-3.5 model. Using
    the ChatCompletion API, we create a conversation and will get the intended result
    after passing the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s break down each part to understand them better. In the first line, we
    use the `openai.ChatCompletion.create` code to create the response from the prompt
    we would pass into the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next line, we have our hyperparameters that we use to improve our text
    tasks. Here is the summary of each hyperparameter function:'
  prefs: []
  type: TYPE_NORMAL
- en: '`model`: The model family we want to use. In this tutorial, we use the current
    recommended model (`gpt-3.5-turbo`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_tokens`: The upper limit of the generated words by the model. It helps
    to limit the length of the generated text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature`: The randomness of the model output, with a higher temperature,
    means a more diverse and creative result. The value range is between 0 to infinity,
    although values more than 2 are not common.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`top_p`: Top P or top-k sampling or nucleus sampling is a parameter to control
    the sampling pool from the output distribution. For example, value 0.1 means the
    model only samples the output from the top 10% of the distribution. The value
    range was between 0 and 1; higher values mean a more diverse result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`frequency_penalty`: The penalty for the repetition token from the output.
    The value range between -2 to 2, where positive values would suppress the model
    from repeating token while negative values encourage the model to use more repetitive
    words. 0 means no penalty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`messages`: The parameter where we pass our text prompt to be processed with
    the model. We pass a list of dictionaries where the key is the role object (either
    "system", "user", or "assistant") that helps the model to understand the context
    and structure while the values are the context.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The role “system” is the set guidelines for the model “assistant” behavior,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The role “user” represents the prompt from the person interacting with the model,
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The role “assistant” is the response to the “user” prompt
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Having explained the parameter above, we can see that the `messages` parameter
    above has two dictionary object. The first dictionary is how we set the model
    as a text summarizer. The second is where we would pass our text and get the summarization
    output.
  prefs: []
  type: TYPE_NORMAL
- en: In the second dictionary, you will also see the variable `person_type` and `prompt`.
    The `person_type` is a variable I used to control the summarized style, which
    I will show in the tutorial. While the `prompt` is where we would pass our text
    to be summarized.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with the tutorial, place the below code in the `summarizer_app.py`
    file and we will try to run through how the function below works.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The code above is where we create a Python function that would accept various
    parameters that we have discussed previously and return the text summary output.
  prefs: []
  type: TYPE_NORMAL
- en: Try the function above with your parameter and see the output. Then let’s continue
    the tutorial to create a simple application with the streamlit package.
  prefs: []
  type: TYPE_NORMAL
- en: Text Summarization Application with Streamlit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Streamlit](https://docs.streamlit.io/) is an open-source Python package designed
    for creating machine learning and data science web apps. It’s easy to use and
    intuitive, so it is recommended for many beginners.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s install the streamlit package before we continue with the tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: After the installation is finished, put the following code into the `summarizer_app.py`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Try to run the following code in your command prompt to initiate the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If everything works well, you will see the following application in your default
    browser.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Summarization Development: A Python Tutorial with GPT-3.5](../Images/c7cc819309edb8f6b8a59183bcb7dafd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what happened in the code above? Let me briefly explain each function we
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`.st.title`: Provide the title text of the web application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.write`: Writes the argument into the application; it could be anything
    but mainly a string text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.text_area`: Provide an area for text input that can be stored in the variable
    and used for the prompt for our text summarizer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.columns`: Object containers to provide side-by-side interaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.slider`: Provide a slider widget with set values that the user can interact
    with. The value is stored on a variable used as the model parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.selectbox`: Provide a selection widget for users to select the summarization
    style they want. In the example above, we use five different styles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.expander`: Provide a container that users can expand and hold multiple
    objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`.st.button`: Provide a button that runs the intended function when the user
    presses it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As streamlit would automatically design the UI following the given code from
    top to bottom, we could focus more on the interaction.
  prefs: []
  type: TYPE_NORMAL
- en: With all the pieces in place, let’s try our summarization application with a
    text example. For our example, I would use the [Theory of Relativity Wikipedia
    page](https://en.wikipedia.org/wiki/Theory_of_relativity) text to be summarized.
    With a default parameter and second-grader style, we obtain the following result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You might obtain a different result than the above one. Let’s try the Housewives
    style and tweak the parameter a bit (Token 100, Temperature 0.5, Nucleus Sampling
    0.5, Frequency Penalty 0.3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, there is a difference in style for the same text we provide.
    With a change prompt and parameter, our application can be more functional.
  prefs: []
  type: TYPE_NORMAL
- en: The overall look of our text summarizer application can be seen in the image
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Summarization Development: A Python Tutorial with GPT-3.5](../Images/175fe28b77724fddeb13f214e08bf433.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: That is the tutorial on creating text summarizer application development with
    GPT-3.5\. You could tweak the application even further and deploy the application.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI is rising, and we should utilize the opportunity by creating a
    fantastic application. In this tutorial, we will learn how the GPT-3.5 OpenAI
    APIs work and how to use them to create a text summarizer application with the
    help of Python and streamlit package.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Free Tools For Detecting ChatGPT, GPT3, and GPT2](https://www.kdnuggets.com/2023/02/5-free-tools-detecting-chatgpt-gpt3-gpt2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Approaches to Text Summarization: An Overview](https://www.kdnuggets.com/2019/01/approaches-text-summarization-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Summarization with GPT-3](https://www.kdnuggets.com/2022/04/packt-summarization-gpt3.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlocking GPT-4 Summarization with Chain of Density Prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Extractive Summarization with LLM using BERT](https://www.kdnuggets.com/extractive-summarization-with-llm-using-bert)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
