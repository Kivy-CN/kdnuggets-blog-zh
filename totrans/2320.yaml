- en: Getting Started with Scikit-learn for Classification in Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Getting Started with Scikit-learn for Classification in Machine Learning](../Images/4be6f969347a4aa304e4b7200ee7f90a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn is one of the most commonly used machine-learning libraries built
    in python. Its popularity can be attributed to its easy and consistent code structure
    which is friendly for beginner developers. Also, there is a high level of support
    available along with flexibility to integrate third-party functionalities which
    makes the library robust and suitable for production. The library contains multiple
    machine learning models for classification, regression, and clustering. In this
    tutorial, we will explore the problem of multiclass classification through various
    algorithms. Let’s dive right into it and build our scikit-learn models.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Install the Latest Version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Loading the Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the “Wine” dataset available in the datasets module of scikit-learn.
    This dataset consists of 178 samples and 3 classes in total. The dataset is already
    pre-processed and converted to feature vectors hence, we can directly use it to
    train our models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Creating Training and Testing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will keep 67% of the data for training and the rest 33% for testing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will experiment with 5 different models of differing complexities and
    evaluate their results on our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: K-Nearest Neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Output **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Upon changing the parameter ‘n_neighbors=2’ we observe a decrease in the value
    of accuracy. Hence, it shows that the data is simple enough and achieves better
    learning with a single neighbor to consider.
  prefs: []
  type: TYPE_NORMAL
- en: '**Output **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Decision Tree Classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Random Forest Classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**Output**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In this algorithm, we performed some hyperparameter tuning to achieve the best
    accuracy. We defined a parameter grid consisting of multiple values to choose
    from for each parameter. Further, we used the Randomized Search CV algorithm to
    search the best parameter space for the model. Finally we feed the obtained parameters
    to the classifier and train the model.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '| **Models** | **Accuracy** | **Observations** |'
  prefs: []
  type: TYPE_TB
- en: '| Logistic Regression | 98.30% | Achieves great accuracy. Model is able to
    generalize well on the test dataset. |'
  prefs: []
  type: TYPE_TB
- en: '| K-Nearest Neighbors | 77.96% | The algorithm is not able to learn the data
    representation well. |'
  prefs: []
  type: TYPE_TB
- en: '| Naive Bayes | 100% | The model is less complex hence it overfits the data
    to obtain absolute accuracy. |'
  prefs: []
  type: TYPE_TB
- en: '| Decision Tree Classifier | 96.61% | Achieves decent accuracy. |'
  prefs: []
  type: TYPE_TB
- en: '| Random Forest Classifier | 98.30% | Being an ensemble-based approach it performs
    better than Decision Tree. Performing hyperparameter tuning makes it achieve similar
    accuracy to logistic regression. |'
  prefs: []
  type: TYPE_TB
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we learned how to get started to build and train machine learning
    models in scikit-learn. We implemented and evaluated a few algorithms to get a
    basic idea about their performance. One can always adopt advanced strategies for
    feature engineering, hyperparameter tuning or training to improve performance.
    To read more about the functionalities that scikit-learn offers, head over to
    the official documentation - [Introduction to machine learning with scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html),
    [Machine Learning in Python with scikit-learn](https://scikit-learn.org/stable/).
  prefs: []
  type: TYPE_NORMAL
- en: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** is a passionate
    AI developer and writer pursuing Master’s in Machine Learning from Université
    de Montréal. Yesha is intrigued to explore responsible AI techniques to solve
    challenges that benefit society and share her learnings with the community.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Machine Learning Algorithms for Classification](https://www.kdnuggets.com/2022/03/machine-learning-algorithms-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started Cleaning Data](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with SQL Cheatsheet](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with spaCy for NLP](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyCaret](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
