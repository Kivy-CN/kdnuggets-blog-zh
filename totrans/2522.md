# 与 Github Actions、Iterative.ai、Label Studio 和 NBDEV 一起探索 MLOps

> 原文：[https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html](https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html)

[评论](#comments)

**由 [Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/) 和 [Will Kunz](https://www.linkedin.com/in/willkunz/)**

在为我们的项目设计 MLOps 堆栈时，我们需要一个允许高度自定义和灵活演变的解决方案，以适应我们的实验需求。我们考虑了涵盖许多功能的大型平台，但在一些关键领域发现其限制。最终，我们决定采用将标签、数据版本控制和持续集成分别实现的专用工具的方法。本文记录了我们构建这种定制 MLOps 方法的经验。

![](../Images/1de6ffdf729c70393d5fa10dec24c761.png)

图片由 [Finding Dan | Dan Grinwis](https://unsplash.com/@finding_dan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 提供，来源于 [Unsplash](https://unsplash.com/s/photos/unknown?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

## NBDEV

![](../Images/c7067d28a0d19f6b72674420ae109bc3.png)

(摘自 [https://github.com/fastai/nbdev](https://github.com/fastai/nbdev))

使用 Jupyter 进行开发的经典问题是，从原型到生产的过渡需要将代码从笔记本复制粘贴到 Python 模块中。NBDEV 自动化了笔记本与模块之间的过渡，从而使 Jupyter 笔记本成为生产流程的正式部分。NBDEV 允许开发者指定笔记本应该创建哪个模块，哪些笔记本单元应推送到模块中，以及哪些笔记本单元是测试。NBDEV 的一个关键功能是其在笔记本中进行测试的方法，NBDEV 模板甚至提供了一个基础 Github Action 以在 CI/CD 框架中实现测试。生成的 Python 模块无需开发者编辑，可以轻松地使用内置的 Python 导入功能集成到其他笔记本或整个项目中。

## Iterative.ai: DVC/CML

![](../Images/8ddbc52ba48451e1af2a6aa73e4bd4eb.png)

(摘自 [https://iterative.ai/](https://iterative.ai/))

机器学习流水线中使用的文件通常是大型的二进制/压缩文件档案，这些文件对现有的版本控制解决方案如git既不可访问又成本高昂。DVC通过将大型数据集表示为文件内容的哈希值来解决数据版本控制问题，从而使DVC能够跟踪更改。它的工作原理类似于git（例如 `dvc add`、`dvc push`）。当你在数据集上运行`dvc add`时，它会被添加到`.gitignore`中，并由`dvc`跟踪更改。CML是一个项目，提供将模型工件从Github Actions工作流发布到附加到Github Issues、Pull Requests等的评论中的功能。这一点很重要，因为它帮助我们开始填补Pull Requests中训练数据变化和模型准确性及效果的差距。

## Github Actions

![](../Images/986a4058fc9c06b2bca4e15d272a9a31.png)

（取自 [https://github.com/features/actions](https://github.com/features/actions)）

我们希望自动化代码测试，包括在自动化测试流水线中构建模型。Github Actions与CircleCI、Travis、Jenkins竞争，这些工具用于自动化测试代码推送、提交、拉取请求等。由于我们已经使用Github来托管我们的代码库，我们通过使用Actions来避免另一个第三方应用。在这个项目中，我们需要使用Github自托管的运行器在本地GPU集群上运行作业。

## Label Studio

![](../Images/6fc4d94e308f6e66b77a6e2c52de00ec.png)

（取自 [https://labelstud.io/](https://labelstud.io/)）

我们深入了解了我们如何使用Label Studio，详细信息见 [这里](https://towardsdatascience.com/development-of-a-benchmark-dataset-with-an-interface-to-the-fastai-dataloader-using-label-studio-d3aa3c26661f)。Label Studio是一个用于标注数据的解决方案。它运行良好，并且可以灵活地在各种环境中运行。

## 为什么要一起使用它们？

这个设置旨在加快模型的部署速度。这意味着，更多的数据科学家可以协同工作，代码库中的透明度提高，新人员的入职时间缩短。目标是标准化数据科学家在项目中需要执行的活动类型，并为他们提供清晰的指示。

以下是我们希望通过该系统设计简化的任务列表：

1.  自动化从Label Studio的获取，并提供一个将其整合到模型训练和评估活动中的单一入口点。

1.  对数据管道代码进行自动化测试，即单元测试和容器的重新部署。

1.  对模型代码进行自动化测试，即单元测试和容器的重新部署。

1.  启用自动化测试，包括模型再训练和评估标准。当模型代码发生变化时，使用新代码训练模型，并将其与现有的旧模型进行比较。

1.  当训练数据发生变化时，触发模型再训练。

以下是每个任务的流水线描述。

## 传统CI/CD流水线

该管道为每个拉取请求实施了自动化测试反馈，包括语法、单元、回归和集成测试的评估。该过程的结果是一个功能测试过的 docker 镜像，存储在我们的私有存储库中。此过程最大限度地提高了最新最佳代码以完全测试过的镜像形式在存储库中可用于下游任务的可能性。以下是新功能上下文中的开发生命周期工作方式：

![](../Images/a4761dfdadbb159032a87bf8245781ca.png)

这里展示了在编辑代码时工作流程函数的运行方式。使用 NBDEV 使我们能够直接从 Jupyter notebooks 中工作，包括直接在笔记本中编写测试。NBDEV 要求所有笔记本中的单元格都必须无例外地运行（除非单元格被标记为不运行）。 (图片由作者提供)

## 数据管道

Label Studio 目前缺乏启用对标签数据更改更新的事件钩子。因此，我们采用了 `cron` 触发的方法，每小时更新数据集。此外，尽管标签工作室的训练数据集足够小，但更新也可以作为训练管道的一部分进行。我们可以使用 Github Actions 界面按需触发数据管道刷新。

![](../Images/576cc3526614e7f27fd041cfba29247a.png)

数据管道从 Label Studio 提取，并将数据集的每个版本及相关输入持久化到存储在 AWS S3 中的 DVC 缓存中。（图片由作者提供）

## 模型管道

建模管道将模型训练集成到存储库的 CI/CD 管道中。这使得每个拉取请求可以评估代码库上配置的语法、单元、集成和回归测试，同时也可以提供包括评估新生成模型的反馈。

![](../Images/2a951bf045884ee15bffc2627b7c0e24.png)

在这种情况下，工作流程运行配置文件（model_params.yaml）中指定的模型训练实验并更新模型工件（best-model.pth）（图片由作者提供）

## 基准评估管道

基准测试管道形成了一个“官方提交”过程，以确保所有建模活动都按照项目的指标进行测量。

![](../Images/6efd84d0d1769b4a465bcff6626bcd4f.png)

新训练的模型（best-model.pth）与基准数据集进行评估，结果用最新提交的哈希标记，并持久化到 AWS S3 中。（图片由作者提供）

## 工作流程

这是 DVC 使用的 DAG 定义文件。它捕捉了工作流程步骤及其输入，并允许用户和机器之间的可重复性。

```py
stages:
  labelstudio_export_trad:
    cmd: python pipelines/1_labelstudio_export.py --config_fp pipelines/traditional_pipeline.yaml
      --ls_token *** --proj_root "."
    params:
    - pipelines/traditional_pipeline.yaml:
      - src.host
      - src.out_fp
      - src.proj_id
  dataset_create_trad:
    cmd: python pipelines/2_labelstudio_todataset.py --config_fp pipelines/create_traditional.yaml
      --proj_root "."
    deps:
    - data/raw_labels/traditional.json
    params:
    - pipelines/create_traditional.yaml:
      - dataset.bmdata_fp
      - dataset.labels_map
      - dataset.out_fp
      - dataset.rawdata_dir
  train_model_trad:
    cmd: python pipelines/3_train_model.py --config_fp pipelines/model_params.yaml
      --proj_root "."
    deps:
    - data/traditional_labeling
    params:
    - pipelines/model_params.yaml:
      - dataloader.bs
      - dataloader.size
      - dataloader.train_fp
      - dataloader.valid_fp
      - learner.backbone
      - learner.data_dir
      - learner.in_checkpoint
      - learner.metrics
      - learner.n_out
      - learner.wandb_project_name
      - train.cycles
  labelstudio_export_bench:
    cmd: python pipelines/1_labelstudio_export.py --config_fp pipelines/benchmark_pipeline.yaml
      --ls_token *** --proj_root "."
    params:
    - pipelines/benchmark_pipeline.yaml:
      - src.host
      - src.out_fp
      - src.proj_id
  dataset_create_bench:
    cmd: python pipelines/2_labelstudio_todataset.py --config_fp pipelines/create_benchmark.yaml
      --proj_root "."
    deps:
    - data/raw_labels/benchmark.json
    params:
    - pipelines/create_benchmark.yaml:
      - dataset.bmdata_fp
      - dataset.labels_map
      - dataset.out_fp
      - dataset.rawdata_dir
  eval_model_trad:
    cmd: python pipelines/4_eval_model.py --config_fp pipelines/bench_eval.yaml --proj_root
      "."
    deps:
    - data/models/best-model.pth
    params:
    - pipelines/bench_eval.yaml:
      - eval.bench_fp
      - eval.label_config
      - eval.metrics_fp
      - eval.model_conf
      - eval.overlay_dir
```

## 发现

1.  Github Actions 工作流的 `cron` 触发器并不是非常可靠。它不保证时间。

1.  DVC 在触发推送的 Github Action 工作流中无法以清晰的方式运行。它会更改源受控的跟踪器，当这些更改被提交时，会创建另一个 Github 操作。

1.  使用 Github Actions 作为运行模型的机制需要一个自托管的运行器来使用 GPU。这意味着需要连接到云中的 GPU 实例或本地 GPU，这会带来访问控制问题。例如，我们不能在不移除自托管运行器配置的情况下开源确切的仓库，否则随机的人可以通过将代码推送到项目中在我们的训练服务器上运行工作负载。

1.  NBDEV 内置的工作流是在错误的地方测试代码。它是在测试 notebook，而不是编译后的包。一方面，能够说“测试可以直接写入 notebook”是件好事。另一方面，直接测试 notebook 仍然存在可能性，即使 notebook 运行了，NBDEV 创建的代码包也可能失败。我们需要的是能够直接测试 NBDEV 编译的包。

1.  NBDEV 不与“传统” Python 开发进行互操作，因为 NBDEV 是单向的。它仅允许项目以交互式 Jupyter notebook 的风格进行开发。它使得直接开发 Python 模块变得不可能。如果在任何时候，项目想要转换为“传统” Python 开发，则需要通过其他方式进行测试。

1.  一开始，我们使用 Weights & Biases 作为我们的实验跟踪仪表盘，但在将其部署到 Github Action 时出现了问题。我们可以说，实现 `wandb` 的用户体验在 Action Workflow 中遇到了第一个困难。移除 Weights & Biases 立即解决了这个问题。在此之前，`wandb` 在 MLOps 中脱颖而出，提供了最佳的用户体验。

## **结论**

最终，完成这些工具的实施花费了一周时间，用于管理我们的代码，包括 Github Actions、Iterative.ai 工具（DVC & CML）和 NBDEV。这为我们提供了以下功能：

1.  从 Jupyter notebooks 开始，将其作为代码的记录系统。我们喜欢 Jupyter。它主要的用途是让我们能够通过在任何可以 SSH 连接的硬件上托管 Jupyter 服务器，并将其转发到桌面上来直接工作。需要明确的是，即使我们不使用 NBDev，我们也会这样做，因为替代方法是使用 Vim 或其他我们不太喜欢的工具。以往尝试使用 VS Code 或 Pycharm 连接远程服务器的实验失败了。因此我们选择了 Jupyter。

1.  测试代码，以及测试它创建的模型。现在，作为 CI/CD 流水线的一部分，我们可以评估从仓库更改所生成的模型是否更好、更差或保持不变。这一切都可以在合并到 `main` 之前在拉取请求中进行评估。

1.  使用 Github Actions 服务器作为训练运行的协调器开始允许多个数据科学家以更清晰的方式同时工作。未来，我们将看到这种设置在协作数据科学过程中的局限性。

**[Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/)** 曾担任数据科学家和软件工程师，解决金融、预测维护和体育领域的问题。他目前在 Hoplabs 担任机器学习系统顾问，专注于多摄像头计算机视觉应用。

**[Will Kunz](https://www.linkedin.com/in/willkunz/)** 是一名后端软件开发人员，带着积极的态度和顽强的决心应对各种挑战。不论是追踪难以捉摸的 bug 还是快速适应新技术，只要有解决方案，Will 就想找到它。

[原文](https://towardsdatascience.com/machine-learning-lifecycle-with-mlops-github-actions-label-studio-iterative-ai-and-nbdev-30515f444a3e)。已获许可转载。

**相关：**

+   [MLOps 最佳实践](/2021/07/mlops-best-practices.html)

+   [MLOps 是一门工程学科：初学者概述](/2021/07/mlops-engineering-discipline.html)

+   [MLOps 和机器学习路线图](/2021/08/mlops-machine-learning-roadmap.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的 IT 部门

* * *

### 更多相关内容

+   [使用 Jupysql 和 GitHub Actions 计划与运行 ETL](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)

+   [GitHub Actions 机器学习初学者指南](https://www.kdnuggets.com/github-actions-for-machine-learning-beginners)

+   [多标签自然语言处理：类别不平衡和损失函数分析…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)

+   [如何利用机器学习自动标注数据](https://www.kdnuggets.com/2022/02/machine-learning-automatically-label-data.html)

+   [使用 LM Studio 本地运行 LLM](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)

+   [免费使用 Lightning AI Studio](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)
