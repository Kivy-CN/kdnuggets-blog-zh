- en: The Gap Between Deep Learning and Human Cognitive Abilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html](https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![The Gap Between Deep Learning and Human Cognitive Abilities](../Images/43a8377c5f6fc2d5c4ac39328d20d5bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [David Cassolato](https://www.pexels.com/photo/person-holding-string-lights-photo-818563/)
  prefs: []
  type: TYPE_NORMAL
- en: Hi! I am Bohdan Ponomar, CEO at the [AI HOUSE](https://aihouse.org.ua/) community.
    We are part of the ecosystem being built up by [Roosh](https://jobs.dou.ua/companies/roosh/)
    technology company. Roosh creates ML/AI projects and invests in innovative ideas
    in the industry. Our ecosystem also includes Pawa venture studio, Roosh Ventures
    venture fund, SET University technological university, Reface and ZibraAI startups,
    and Neurons Lab company.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In August 2022, we launched a new educational project 'AI for Ukraine' — a series
    of workshops and lectures held by international artificial intelligence experts
    to support the development of Ukraine’s tech community.
  prefs: []
  type: TYPE_NORMAL
- en: The first lecture of the series was delivered by Yoshua Bengio, professor at
    the University of Montreal, founder and scientific director of the Quebec Artificial
    Intelligence Institute, head of the CIFAR Learning in Machines & Brains program,
    and one of the leading experts in the AI industry. In 2022, he became the computer
    scientist with the highest h-index in the world.
  prefs: []
  type: TYPE_NORMAL
- en: During the lecture, the professor covers his research project, which aimed to
    bridge the gap between modern AI based on Deep Learning, and human intelligence
    featuring creativity. The full recording is available [here](https://aiforukraine.aihouse.club/#agenda)
    for a donation, and in this article, we cover the main points of the lecture.
  prefs: []
  type: TYPE_NORMAL
- en: Systematic Generalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Current Machine Learning has issues with reliability due to the poor performance
    of OOD (Out-Of-Distribution) sample representation. We are used to relying on
    the IID (Independent & Identically Distributed) hypothesis that the test distribution
    and the training distribution are the same. But without this assumption, we need
    some alternative hypothesis to perform the generalization.
  prefs: []
  type: TYPE_NORMAL
- en: 'This results in a research question: how exactly can distributions change?
    Let''s consider how humans usually cope with such tasks, as this can inspire AI
    learning methods development.'
  prefs: []
  type: TYPE_NORMAL
- en: For many years linguists have been studying systematic generalization, which
    is easily observed in natural language. A human can take familiar concepts and
    arrange them in a new order, while the meaning of the statement remains fully
    clear.
  prefs: []
  type: TYPE_NORMAL
- en: We can even create such configurations that would have zero probability according
    to the training distribution. For example, a driver generalizes his knowledge
    of driving laws in his home country to other countries where road rules may be
    slightly different. However, Deep Learning hasn’t yet achieved similar results.
    This shows the nature of the gap between state-of-the-art AI systems and human
    intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Compositional Knowledge Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have large language models, but they require a huge amount of data, which
    makes their use senseless. This is a problem of sample complexity — the number
    of samples needed for training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we shouldn’t consider quantitative scaling, but the qualitative
    development of Deep Learning. And the questions are:'
  prefs: []
  type: TYPE_NORMAL
- en: How can these systems be generalized to new out-of-distribution settings?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How quickly can they adapt to these settings (transfer learning)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These questions are directly related to human’s ability to establish and identify
    causal relationships. Humans can make new conclusions by combining and recombining
    pieces of their previous knowledge. This compositional ability to represent knowledge
    in natural language also allows us to consider the course of future AI generations
    development.
  prefs: []
  type: TYPE_NORMAL
- en: Conscious Processing of Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Everything we covered above was related to one key ability of humans that is
    currently beyond the AI’s reach. This is the conscious information processing
    performed by our brain.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, what happens when a driver starts driving in a foreign country?
    Let's assume the driver is used to left-hand traffic, but now he has to adapt
    to driving on right. He cannot fully apply his previous experience here, because
    that would bring the car to the oncoming lane. But he can focus on the task, constantly
    reminding himself of the difference in road rules. And this is where his previous
    driving experience helps.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, when humans face a new situation, they call to conscious attention in
    order to combine relevant pieces of knowledge on-the-fly, analyze them, and in
    the end successfully complete the task. Such conscious information processing
    differs by its nature from the one we are guided by in our routine (see "Thinking,
    Fast and Slow" by D. Kahneman).
  prefs: []
  type: TYPE_NORMAL
- en: Current Deep Learning systems successfully reproduce fast thinking with a simple
    sequence of actions, when there is no need to solve a non-trivial issue. But the
    reproduction of more complex and algorithmic slow thinking is a challenge for
    future industry development.
  prefs: []
  type: TYPE_NORMAL
- en: For this, we need to organize knowledge in a way to make it easy to select the
    relevant pieces of knowledge out of the training distribution to reuse when solving
    a new problem. The analogy can be a program code consisting of independent modules
    and functions.
  prefs: []
  type: TYPE_NORMAL
- en: Causal Relationship
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A human is able to distinguish two perspectives of their knowledge about the
    world:'
  prefs: []
  type: TYPE_NORMAL
- en: those depending on immutable physical laws; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: those associated with dynamically changing conditions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This differs from the usual IID assumption, for things that are preserved in
    distributions and related to physical laws in fact remain unchanged. And things
    related to variable conditions change.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the goal of Deep Learning is to discover such a knowledge representation
    that reflects the cause-and-effect relationship of variable factors. In other
    words, the outcome depends on the actions taken.
  prefs: []
  type: TYPE_NORMAL
- en: Inductive Biases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A human can receive and share a lot of information using a language. The most
    suitable for verbalization is the knowledge that relies on inductive biases, such
    as the use of abstract named objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, I hold a ball in my hand. This sentence contains named objects:
    me, the hand, and the ball. Each of them has its own features, like coordinates
    in space. If I suddenly drop the ball, they can be used to predict the coordinates
    of the ball each next moment while it falls. This prediction is accurate, though
    it is based on a few variables only.'
  prefs: []
  type: TYPE_NORMAL
- en: But this approach will not work if applied at the pixel level. It is impossible
    to accurately predict the state of a pixel itself. But you can predict the state
    of the pixel, related to an abstract named object, like a ball. Because the statistical
    structure of such named objects differs from ordinary pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, causal relationships between abstract objects are reusable. No matter
    what object falls as a result of dropping — a ball, a phone, or else — the mechanism
    remains the same.
  prefs: []
  type: TYPE_NORMAL
- en: GFlowNets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In neuroscience, there is a random factor: in a certain situation, a human
    can have this or that thought. So there is some discrete stochastic aspect of
    thinking that cannot be accounted for in advance. Then, from a Machine Learning
    point of view, we need a probabilistic neural network that can generate thoughts
    from a selected distribution, such as Bayesian posterior probability.'
  prefs: []
  type: TYPE_NORMAL
- en: GFlowNets is a versatile probabilistic modeling tool. Such networks make it
    possible to model distributions by composite objects and to estimate such quantities
    as normalizing constants or conditional probabilities. The easiest way to imagine
    this structure is the hypograph.
  prefs: []
  type: TYPE_NORMAL
- en: How do GFlowNets generate such structured objects as graphs? For several years
    now, we have known networks that take not a set of fixed-size vectors, but a graph
    as an input. Now we consider getting a graph as an output. This process is similar
    to how the brain generates thoughts. To create a composite structure, we add one
    element at a time. I.e., we take a partially constructed thought as the input
    and derive a distribution as the output, that determines all possible potential
    further actions. Thus, we get the desired outcome step by step.
  prefs: []
  type: TYPE_NORMAL
- en: GFlowNets can be organized as different modules specializing in different types
    of knowledge. Competing with each other, they provide the normalized estimations
    as the output. Moreover, each module shares information with others — this is
    how short-term working memory is formed. Finally, one of the estimates is stochastically
    chosen, such as the process of initiating conscious processing in the human brain.
  prefs: []
  type: TYPE_NORMAL
- en: Causal Relationships Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with such a neural network the main challenge is to correctly identify
    and model the causal structure. Because if you simply take two A and B variables
    with a correlation between them, then there’s no knowing which one of them triggers
    another one. But we can assume that this connection will change due to external
    factors. For example, if we change the state of A, which also changes B, then
    it is likely that A has an effect on B and not vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Causal relationships are asymmetric. If you don’t understand it perfectly, you
    can make big mistakes. For instance, it can cause ambiguity, like has a patient
    been cured by the new medicine, or due to some other reason?
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is necessary to build such models that can cover the entire set
    of possible causal explanations. In their thinking humans are able to make similar
    hypotheses. For AI, this task is solved by Bayesian posterior causal models.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the gap between Deep Learning and human cognitive abilities is significant.
    After all, people can generalize their knowledge, apply slow thinking and use
    it to solve non-trivial issues, consciously process information, and understand
    the cause-and-effect relationship between phenomena.
  prefs: []
  type: TYPE_NORMAL
- en: However, world-leading AI experts work on bridging this gap and improving AI
    capabilities, inspired by studying the principles of the human brain function.
    Joshua Bengio's team in Montreal researches probabilistic neural networks to make
    a step toward the next generation of Deep Learning.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Bohdan Ponomar](https://www.linkedin.com/in/bogdan-ponomar-41866328/)**
    is CEO at the [AI HOUSE](https://aihouse.org.ua/) community. He is creating a
    leading AI ecosystem for students and experts to build world-class AI ventures
    in Ukraine.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The AI Education Gap and How to Close It](https://www.kdnuggets.com/2022/11/ai-education-gap-close.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Is There a Way to Bridge the MLOps Tools Gap?](https://www.kdnuggets.com/2022/08/way-bridge-mlops-tools-gap.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Scientist''s Guide to Cognitive Biases: A Free eBook](https://www.kdnuggets.com/2023/05/data-scientist-guide-cognitive-biases-free-ebook.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Between Dreams and Reality: Generative Text and Hallucinations](https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Difference Between Training and Testing Data in Machine Learning](https://www.kdnuggets.com/2022/08/difference-training-testing-data-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
