- en: A Beginner’s Guide to Neural Networks with Python and SciKit Learn 0.18!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2](https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data Preprocessing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The neural network may have difficulty converging before the maximum number
    of iterations allowed if the data is not normalized. Multi-layer Perceptron is
    sensitive to feature scaling, so it is highly recommended to scale your data.
    Note that you must apply the same scaling to the test set for meaningful results.
    There are a lot of different methods for normalization of data, we will use the
    built-in StandardScaler for standardization.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]   StandardScaler(copy=True, with_mean=True, with_std=True)   [PRE1]`'
  prefs: []
  type: TYPE_NORMAL
- en: Training the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now it is time to train our model. SciKit Learn makes this incredibly easy,
    by using estimator objects. In this case we will import our estimator (the Multi-Layer
    Perceptron Classifier model) from the neural_network library of SciKit-Learn!
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we create an instance of the model, there are a lot of parameters you
    can choose to define and customize here, we will only define the hidden_layer_sizes.
    For this parameter you pass in a tuple consisting of the number of neurons you
    want at each layer, where the nth entry in the tuple represents the number of
    neurons in the nth layer of the MLP model. There are many ways to choose these
    numbers, but for simplicity we will choose 3 layers with the same number of neurons
    as there are features in our data set:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the model has been made we can fit the training data to our model,
    remember that this data has already been processed and scaled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2] MLPClassifier(activation=''relu'', alpha=0.0001, batch_size=''auto'',
    beta_1=0.9,         beta_2=0.999, early_stopping=False, epsilon=1e-08,         hidden_layer_sizes=(30,
    30, 30), learning_rate=''constant'',         learning_rate_init=0.001, max_iter=200,
    momentum=0.9,         nesterovs_momentum=True, power_t=0.5, random_state=None,         shuffle=True,
    solver=''adam'', tol=0.0001, validation_fraction=0.1,         verbose=False, warm_start=False)
    [PRE3]`'
  prefs: []
  type: TYPE_NORMAL
- en: You can see the output that shows the default values of the other parameters
    in the model. I encourage you to play around with them and discover what effects
    they have on your model!
  prefs: []
  type: TYPE_NORMAL
- en: Predictions and Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have a model it is time to use it to get predictions! We can do
    this simply with the predict() method off of our fitted model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can use SciKit-Learn''s built in metrics such as a classification report
    and confusion matrix to evaluate how well our model performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4] [[50  3]   [ 0 90]] [PRE5]` [PRE6] [PRE7]``'
  prefs: []
  type: TYPE_NORMAL
