["```py\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n```", "```py\nTrain_Data = pd.read_csv(\"/.../bioinformatics/data_set_ALL_AML_train.csv\")\nTest_Data = pd.read_csv(\"/.../bioinformatics/data_set_ALL_AML_independent.csv\")\nlabels = pd.read_csv(\"/.../bioinformatics/actual.csv\", index_col = 'patient')Train_Data.head()\n```", "```py\nTest_Data.head()\n```", "```py\nprint(Train_Data.isna().sum().max())\nprint(Test_Data.isna().sum().max())\n```", "```py\ncols = [col for col in Test_Data.columns if 'call' in col]\ntest = Test_Data.drop(cols, 1)\ncols = [col for col in Train_Data.columns if 'call' in col]\ntrain = Train_Data.drop(cols, 1)\n```", "```py\npatients = [str(i) for i in range(1, 73, 1)]\ndf_all = pd.concat([train, test], axis = 1)[patients]\ndf_all = df_All.T\n```", "```py\ndf_all[\"patient\"] = pd.to_numeric(patients)\nlabels[\"cancer\"]= pd.get_dummies(Actual.cancer, drop_first=True)\n```", "```py\nData = pd.merge(df_all, labels, on=\"patient\")\nData.head()\n```", "```py\nX, y = Data.drop(columns=[\"cancer\"]), Data[\"cancer\"]\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test =  train_test_split(X,y,test_size = 0.25, random_state= 0)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\n```", "```py\nfrom sklearn.decomposition import PCA\npca = PCA() \nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\ntotal=sum(pca.explained_variance_)\nk=0\ncurrent_variance=0\nwhile current_variance/total < 0.90:\n    current_variance += pca.explained_variance_[k]\n    k=k+1\n```", "```py\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 38)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)cum_sum = pca.explained_variance_ratio_.cumsum()\ncum_sum = cum_sum*100\nplt.bar(range(38), cum_sum)\nplt.ylabel(\"Cumulative Explained Variance\")\nplt.xlabel(\"Principal Components\")\nplt.title(\"Around 90% of variance is explained by the First 38 columns \")\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVCparameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]search = GridSearchCV(SVC(), parameters, n_jobs=-1, verbose=1)\nsearch.fit(X_train, y_train)\n```", "```py\nbest_parameters = search.best_estimator_\n```", "```py\nmodel = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='linear', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False)\n\nmodel.fit(X_train, y_train)\n```", "```py\ny_pred=model.predict(X_test)\n```", "```py\nfrom sklearn.metrics import accuracy_score, confusion_matrixfrom sklearn import metrics\nprint('Accuracy Score:',round(accuracy_score(y_test, y_pred),2))\n#confusion matrix\ncm = confusion_matrix(y_test, y_pred)Output: \nAccuracy Score: 0.67\n```", "```py\nclass_names=[1,2,3]\nfig, ax = plt.subplots()from sklearn.metrics import confusion_matrix\nimport seaborn as snscm = confusion_matrix(y_test, y_pred)class_names=['ALL', 'AML']\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"viridis\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n```"]