- en: XGBoost, a Top Machine Learning Method on Kaggle, Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XGBoost，Kaggle上的顶级机器学习方法解析
- en: 原文：[https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html](https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html](https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html)
- en: '![XGBoost](../Images/cd6c6f40e9b8754536de6a0b3bd3a202.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![XGBoost](../Images/cd6c6f40e9b8754536de6a0b3bd3a202.png)'
- en: '*What is XGBoost?*'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*什么是XGBoost？*'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: XGBoost has become a widely used and really popular tool among Kaggle competitors
    and Data Scientists in industry, as it has been battle tested for production on
    large-scale problems. It is a highly flexible and versatile tool that can work
    through most regression, classification and ranking problems as well as user-built
    objective functions. As an open-source software, it is easily accessible and it
    may be used through different platforms and interfaces. The amazing portability
    and compatibility of the system permits its usage on all three Windows, Linux
    and OS X. It also supports training on distributed cloud platforms like AWS, Azure,
    GCE among others and it is easily connected to large-scale cloud dataflow systems
    such as Flink and Spark. Although it was built and initially used in the Command
    Line Interface (CLI) by its creator (Tianqi Chen), it can also be loaded and used
    in various languages and interfaces such as Python, C++, R, Julia, Scala and Java.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost已成为Kaggle竞争者和工业界数据科学家广泛使用且非常流行的工具，因为它在大规模问题上的生产环境中经过了实战测试。它是一个高度灵活和多功能的工具，可以处理大多数回归、分类和排序问题以及用户自定义目标函数。作为一个开源软件，它易于访问，可以通过不同的平台和接口使用。该系统的惊人可移植性和兼容性允许在Windows、Linux和OS
    X三大操作系统上使用。它还支持在如AWS、Azure、GCE等分布式云平台上训练，并且可以轻松连接到如Flink和Spark等大规模云数据流系统。尽管它是由其创建者（Tianqi
    Chen）在命令行界面（CLI）中构建和最初使用的，但也可以在Python、C++、R、Julia、Scala和Java等各种语言和接口中加载和使用。
- en: Its name stands for **eXtreme Gradient Boosting**, it was developed by Tianqi
    Chen and now is part of a wider collection of open-source libraries developed
    by the Distributed Machine Learning Community (DMLC). XGBoost is a scalable and
    accurate implementation of gradient boosting machines and it has proven to push
    the limits of computing power for boosted trees algorithms as it was built and
    developed for the sole purpose of model performance and computational speed. Specifically,
    it was engineered to exploit every bit of memory and hardware resources for tree
    boosting algorithms.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 它的名称代表**极端梯度提升**，由Tianqi Chen开发，现在是Distributed Machine Learning Community (DMLC)开发的开源库集合的一部分。XGBoost是梯度提升机器的可扩展且准确的实现，它已被证明能够推动提升树算法计算能力的极限，因为它是为了模型性能和计算速度的目的而构建和开发的。具体而言，它被设计用于充分利用每一位内存和硬件资源来提升树算法。
- en: The implementation of XGBoost offers several advanced features for model tuning,
    computing environments and algorithm enhancement. It is capable of performing
    the three main forms of gradient boosting (Gradient Boosting (GB), Stochastic
    GB and Regularized GB) and it is robust enough to support fine tuning and addition
    of regularization parameters. According to Tianqi Chen, the latter is what makes
    it superior and different to other libraries.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost的实现提供了多种先进的模型调优、计算环境和算法增强功能。它能够执行三种主要形式的梯度提升（梯度提升（GB）、随机GB和正则化GB），并且足够稳健，支持精细调节和正则化参数的添加。根据Tianqi
    Chen的说法，这正是它优于其他库的原因。
- en: “…xgboost used a more regularized model formalization to control over-fitting,
    which gives it better performance.”- Tianqi Chen on [Quora](https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting)
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “……xgboost使用了更规范化的模型形式来控制过拟合，这使其表现更佳。”- Tianqi Chen在[Quora](https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting)
- en: System-wise, the library’s portability and flexibility allow the use of a wide
    variety of computing environments like parallelization for tree construction across
    several CPU cores; distributed computing for large models; Out-of-Core computing;
    and Cache Optimization to improve hardware usage and efficiency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从系统角度来看，该库的可移植性和灵活性允许使用各种计算环境，例如树构建的CPU核心并行化；大模型的分布式计算；外存计算；以及缓存优化，以提高硬件使用和效率。
- en: The algorithm was developed to efficiently reduce computing time and allocate
    an optimal usage of memory resources. Important features of implementation include
    handling of missing values (Sparse Aware), Block Structure to support parallelization
    in tree construction and the ability to fit and boost on new data added to a trained
    model (Continued Training).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的开发目的是有效减少计算时间，并优化内存资源的使用。实现的重要特性包括处理缺失值（稀疏感知）、支持树构建并行化的块结构以及在训练模型后对新数据进行拟合和提升的能力（持续训练）。
- en: '*Why use XGBoost?*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么使用XGBoost？*'
- en: As we already mentioned, the key features of this library rely on *model performance
    and execution speed*. A well-structured clear benchmark done by [Szilard Pafka](http://datascience.la/benchmarking-random-forest-implementations/),
    shows how XGBoost outperforms several other well-known implementations of gradient
    tree boosting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，这个库的关键特性依赖于*模型性能和执行速度*。由[Szilard Pafka](http://datascience.la/benchmarking-random-forest-implementations/)进行的结构化基准测试，展示了XGBoost如何超越几种其他知名的梯度树提升实现。
- en: '![xgboost benchmarks](../Images/b7b2c95f91556bd75215178b20aacc52.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![xgboost benchmarks](../Images/b7b2c95f91556bd75215178b20aacc52.png)'
- en: This comparison in Figure 1 helps us grasp the power of the tool and see how
    well balanced its benefits are, i.e., it does not seem to sacrifice speed over
    accuracy or vice versa. It starts to become clear why more Kagglers are using
    it every day, it is a semi-perfect equilibrium of both performance and time-efficiency.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图1中的比较帮助我们掌握工具的强大性能，并查看其好处的平衡，即它似乎没有在速度和准确性之间做出牺牲。越来越多的Kagglers每天使用它，逐渐明白为什么，它在性能和时间效率之间达到了半完美的平衡。
- en: '*How does it work?*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*它是如何工作的？*'
- en: Before moving on to the details of the algorithm, let’s set some basic definitions
    to make our life easier and get an intuitive and complete understanding of this
    popular tool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入算法细节之前，让我们设定一些基本定义，以便更容易理解，并对这个流行工具有一个直观和完整的了解。
- en: First, let’s clarify the concept of boosting. This is an ensemble method that
    seeks to create a strong classifier (model) based on “weak” classifiers. In this
    context, weak and strong refer to a measure of how correlated are the learners
    to the actual target variable. By adding models on top of each other iteratively,
    the errors of the previous model are corrected by the next predictor, until the
    training data is accurately predicted or reproduced by the model. If you want
    to dig into boosting a bit more, check out information about a popular implementation
    called AdaBoost (Adaptive Boosting) [here](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们澄清“boosting”的概念。这是一种集成方法，旨在基于“弱”分类器创建一个强大的分类器（模型）。在这个上下文中，弱和强是指学习者与实际目标变量的相关程度。通过迭代地将模型叠加在一起，前一个模型的错误会被下一个预测器纠正，直到训练数据被模型准确预测或重现。如果你想更深入地了解boosting，可以查看有关一种流行实现叫做AdaBoost（自适应提升）的信息，[点击这里](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)。
- en: Now, gradient boosting also comprises an ensemble method that sequentially adds
    predictors and corrects previous models. However, instead of assigning different
    weights to the classifiers after every iteration, this method fits the new model
    to new residuals of the previous prediction and then minimizes the loss when adding
    the latest prediction. So, in the end, you are updating your model using gradient
    descent and hence the name, gradient boosting. This is supported for both regression
    and classification problems. XGBoost specifically, implements this algorithm for
    decision tree boosting with an additional custom regularization term in the objective
    function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，梯度提升还包括一种集成方法，它顺序地添加预测器并纠正先前的模型。然而，与每次迭代后给分类器分配不同权重的方法不同，这种方法将新模型拟合到先前预测的新残差中，然后在添加最新预测时最小化损失。因此，最终你是使用梯度下降来更新你的模型，因此得名梯度提升。这适用于回归和分类问题。XGBoost
    特别实现了这个算法，用于决策树提升，并在目标函数中增加了额外的自定义正则化项。
- en: '*Getting started with XGBoost*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*开始使用 XGBoost*'
- en: You may download and install XGBoost regardless of which interface you are using.
    To learn more on how to use on each specific platform please follow the instructions
    on this link. You will also find official documentation and tutorials [here](https://xgboost.readthedocs.io/en/latest/get_started/index.html).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用的是哪个接口，你都可以下载并安装 XGBoost。要了解如何在每个平台上使用它，请按照此链接中的说明操作。你还可以在 [这里](https://xgboost.readthedocs.io/en/latest/get_started/index.html)
    找到官方文档和教程。
- en: For further information on the source code and examples, you may visit this
    [DMLC repository on Github](https://github.com/dmlc/xgboost).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有关源代码和示例的更多信息，你可以访问这个 [DMLC GitHub 仓库](https://github.com/dmlc/xgboost)。
- en: 'For more information on boosting and gradient boosting the following resources
    might be helpful:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于提升和梯度提升的更多信息，以下资源可能会有所帮助：
- en: The official published paper by Tianqi Chen is available for download from [Arxiv](https://arxiv.org/abs/1603.02754)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 Tianqi Chen 发布的官方论文可以从 [Arxiv](https://arxiv.org/abs/1603.02754) 下载。
- en: The official documentation [XGBoost page](http://xgboost.readthedocs.io/en/latest/model.html)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方文档 [XGBoost 页面](http://xgboost.readthedocs.io/en/latest/model.html)
- en: '[Here](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf) is
    a great presentation that summarizes the math in a very intuitive way'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[这里](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)
    是一份很好的演示文稿，它以非常直观的方式总结了数学原理'
- en: 'Some [Wikipedia Articles](https://en.wikipedia.org/wiki/Gradient_boosting)
    give a good general idea of the history and the math behind the algorithms:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些 [维基百科文章](https://en.wikipedia.org/wiki/Gradient_boosting) 对于算法的历史和数学原理提供了很好的概述：
- en: Thanks to Jason Brownlee for the inspiration of this post, more resources on
    Boosting and XGBoost are available on [his post](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢 Jason Brownlee 为这篇文章提供的灵感，更多关于 Boosting 和 XGBoost 的资源可以在 [他的文章](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)
    中找到。
- en: '**Related:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Lessons Learned From Benchmarking Fast Machine Learning Algorithms](/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从基准测试快速机器学习算法中得到的经验教训](/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
- en: '[A Simple XGBoost Tutorial Using the Iris Dataset](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用鸢尾花数据集的简单 XGBoost 教程](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
- en: '[XGBoost: Implementing the Winningest Kaggle Algorithm in Spark and Flink](/2016/03/xgboost-implementing-winningest-kaggle-algorithm-spark-flink.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost：在 Spark 和 Flink 中实现最成功的 Kaggle 算法](/2016/03/xgboost-implementing-winningest-kaggle-algorithm-spark-flink.html)'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学统计学习的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并找到目的去……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一项 90 亿美元的 AI 失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
