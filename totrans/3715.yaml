- en: Getting Started with spaCy for NLP
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Getting Started with spaCy for NLP
- en: 原文：[https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
- en: '![Getting Started with spaCy for NLP](../Images/229bca305b47c63570cb9b57e3f926b9.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Getting Started with spaCy for NLP](../Images/229bca305b47c63570cb9b57e3f926b9.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Image by Editor
- en: Nowadays, NLP is one of the most emerging trends of AI as its applications are
    widespread across several industries such as Healthcare, Retail, and Banking to
    name a few. As there is an increasing need to develop fast and scalable solutions,
    spaCy is one of the go-to NLP libraries for developers. NLP products are developed
    to make sense of the existing text data. It mainly revolves around solving questions
    such as ‘What is the context of data?’, ‘Does it represent any bias?’, ‘Is there
    some similarity among words?’ etc. to build valuable solutions?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，NLP 是人工智能中最具前景的趋势之一，因为它的应用广泛涵盖了医疗、零售和银行等多个行业。由于对快速和可扩展解决方案的需求日益增加，spaCy 成为开发人员的首选
    NLP 库之一。NLP 产品旨在理解现有的文本数据。它主要围绕解决诸如‘数据的背景是什么？’，‘它是否存在任何偏见？’，‘单词之间是否存在相似性？’等问题来构建有价值的解决方案。
- en: Therefore, spaCy is a library that helps to deal with such questions and it
    provides a bunch of modules that are easy to plug and play. It is an open-source
    and production-friendly library that makes development and deployment smooth and
    efficient. Moreover, spaCy was not built with a research-oriented approach hence
    it provides a limited set of functionalities for the users to choose from instead
    of multiple options to develop quickly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，spaCy 是一个帮助处理此类问题的库，它提供了一系列易于插拔的模块。它是一个开源且适合生产的库，使开发和部署变得顺畅高效。此外，spaCy 的构建并不是以研究为导向，因此它为用户提供了一组有限的功能，而不是多个选项来快速开发。
- en: In this blog, we will explore how to get started with spaCy right from the installation
    to explore the various functionalities it provides.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将探讨如何从安装开始，了解 spaCy 提供的各种功能。
- en: Installation
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Installation
- en: 'To install spaCy enter the following command:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 spaCy，请输入以下命令：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: spaCy generally requires trained pipelines to be loaded in order to access most
    of its functionalities. These pipelines contained pretrained models which perform
    prediction for some of the commonly used tasks. The pipelines are available in
    multiple languages and in multiple sizes. Here, we will install the small and
    medium size pipelines for English.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 通常需要加载训练好的管道以访问大多数功能。这些管道包含预训练模型，用于执行一些常见任务的预测。这些管道有多种语言和多种尺寸。在这里，我们将安装英文的小型和中型管道。
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Voila! You are now all set to start using spaCy.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Voila! 你现在已准备好开始使用 spaCy。
- en: Loading the Pipeline
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Loading the Pipeline
- en: Here, we will load the smaller pipeline version of English.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将加载英文的较小管道版本。
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The pipeline is now loaded into the nlp object.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，管道已加载到 nlp 对象中。
- en: Next, we will be exploring the various functionalities of spaCy using an example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过示例探索 spaCy 的各种功能。
- en: Tokenization
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tokenization
- en: Tokenization is a process of splitting the text into smaller units called tokens.
    For example, in a sentence tokens would be words whereas in a paragraph tokens
    could be sentences. This step helps to understand the content by making it easy
    to read and process.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Tokenization 是将文本分割成更小的单元称为 tokens 的过程。例如，在一句话中，tokens 是单词，而在一个段落中，tokens 可能是句子。这一步有助于通过使内容易于阅读和处理来理解内容。
- en: We first define a string.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个字符串。
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now we call the ‘nlp’ object on ‘text’ and store it in a ‘doc’ object. The object
    ‘doc’ would be containing all the information about the text - the words, the
    whitespaces etc.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在 ‘text’ 上调用 ‘nlp’ 对象，并将其存储在 ‘doc’ 对象中。‘doc’ 对象将包含关于文本的所有信息——单词、空格等。
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '‘doc’ can be used as an iterator to parse through the text. It contains a ‘.text’
    method which can give the text of every token like:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ‘doc’ 可以用作迭代器来解析文本。它包含一个 ‘.text’ 方法，可以给出每个 token 的文本，例如：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**output:**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**output:**'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In addition to splitting the words by white spaces, the tokenization algorithm
    also performs double-checks on the split text.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过空格分割单词外，tokenization 算法还对分割后的文本进行双重检查。
- en: '![Getting Started with spaCy for NLP](../Images/101b1489919b38d00512b294cff9b53b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![Getting Started with spaCy for NLP](../Images/101b1489919b38d00512b294cff9b53b.png)'
- en: 'Source: [spaCy documentation](https://spacy.io/usage/spacy-101)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[spaCy documentation](https://spacy.io/usage/spacy-101)
- en: As shown in the above image, after splitting the words by white spaces, the
    algorithm checks for exceptions. The word ‘Let’s’ is not in its root form hence
    it is again split into ‘Let’ and ‘’s’. The punctuation marks are also split. Moreover,
    the rule makes sure not to split words like ‘N.Y.’ and considers them like a single
    token.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Stop Words
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the important preprocessing steps in NLP is to remove stop words from
    text. Stop words are basically connector words such as ‘to’, ‘with’, ‘is’, etc.
    which provide minimal context. spaCy allows easy identification of stop words
    with an attribute of the ‘doc’ object called ‘is_stop’.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘is_stop’ method.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**output:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Lemmatization
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lemmatization is another important preprocessing step for NLP pipelines. It
    helps to remove different versions of a single word to reduce redundancy of same-meaning
    words as it converts the words to their root lemmas. For example, it will convert
    ‘is’ -> ‘be’, ‘eating’ -> ‘eat’, and ‘N.Y.’ -> ‘n.y.’. With spaCy, the words can
    be easily converted to their lemmas using a ‘.lemma_’ attribute of the ‘doc’ object.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.lemma_’ method.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**output: **'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Part-of-Speech (POS) Tagging
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automated POS tagging enables us to get an idea of the sentence structure by
    knowing what category of words dominate the content and vice versa. This information
    forms an essential part in understanding the context. spaCy allows parsing the
    content and tagging the individual tokens with their respective parts of speech
    through the ‘.pos_’ attribute of the ‘doc’ object.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.pos_’ method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**output: **'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Dependency Parsing
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every sentence has an inherent structure in which the words have an interdependent
    relationship with each other. Dependency parsing can be thought of as a directed
    graph wherein the nodes are words and the edges are relationships between the
    words. It extracts the information on what one word means to another grammatically;
    whether it is a subject, an auxiliary verb, or a root, and so on. spaCy has a
    method ‘.dep_’ of the ‘doc’ object which describes the syntactic dependencies
    of the tokens.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.dep_’ method.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**output: **'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Named Entity Recognition
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the real-world objects have a name assigned to them for recognition and
    likewise, they are grouped into a category. For instance, the terms ‘India’, ‘U.K.’,
    and ‘U.S.’ fall under the category of countries whereas ‘Microsoft’, ‘Google’,
    and ‘Facebook’ belong to the category of organizations. spaCy already has trained
    models in the pipeline that can determine and predict the categories of such named
    entities.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: We will access the named entities by using the ‘.ents’ method over the ‘doc’
    object. We will display the text, start character, end character, and label of
    the entity.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**output: **'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Word Vectors and Similarity
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often in NLP, we wish to analyze the similarity of words, sentences, or documents
    which can be used for applications such as recommender systems or plagiarism detection
    tools to name a few. The similarity score is calculated by finding the distance
    between the word embeddings, i.e., the vector representation of words. spaCy provides
    this functionality with medium and large pipelines. The larger pipeline is more
    accurate as it contains models trained on more and diverse data. However, we will
    use the medium pipeline here just for the sake of understanding.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理（NLP）中，我们常常希望分析词语、句子或文档的相似性，这可以用于推荐系统或抄袭检测工具等应用。相似度得分通过查找词嵌入之间的距离来计算，即词的向量表示。spaCy通过中型和大型管道提供了这一功能。较大的管道更为准确，因为它包含了在更多样化数据上训练的模型。然而，我们这里只是为了理解而使用中型管道。
- en: We first define the sentences to be compared for similarity.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义要比较相似性的句子。
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**output: **'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Rule-based Matching
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于规则的匹配
- en: Rule-based matching can be considered similar to regex wherein we can mention
    the specific pattern to be found in the text. spaCy’s matcher module not only
    does the mentioned task but also provides access to the document information such
    as tokens, POS tags, lemmas, dependency structures, etc. which makes extraction
    of words possible on multiple additional conditions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 基于规则的匹配可以被认为类似于正则表达式，我们可以在文本中指定要查找的特定模式。spaCy的匹配器模块不仅完成了上述任务，还提供了对文档信息的访问，例如词汇、词性标签、词元、依赖结构等，这使得在多个附加条件下提取词汇成为可能。
- en: Here, we will first create a matcher object to contain all the vocabulary. Next,
    we will define the pattern of text to be looked for and add that as a rule to
    the matcher module. Finally, we will call the matcher module over the input sentence.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先创建一个匹配器对象来包含所有词汇。接下来，我们将定义要查找的文本模式，并将其作为规则添加到匹配器模块中。最后，我们将对输入句子调用匹配器模块。
- en: '[PRE19]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**output: **'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE20]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**output: **'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE22]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this blog, we looked at how to install and get started with spaCy. We also
    explored the various basic functionalities it provides such as tokenization, lemmatization,
    dependency parsing, parts-of-speech tagging, named entity recognition and so on.
    spaCy is a really convenient library when it comes to developing NLP pipelines
    for production purposes. Its detailed documentation, simplicity of use, and variety
    of functions make it one of the widely used libraries for NLP.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们讨论了如何安装和开始使用spaCy。我们还探索了它提供的各种基本功能，如分词、词形还原、依赖分析、词性标注、命名实体识别等。spaCy在开发用于生产的NLP管道时非常方便。其详细的文档、易用性和多样的功能使其成为NLP领域广泛使用的库之一。
- en: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** is a passionate
    AI developer and writer pursuing Master’s in Machine Learning from Université
    de Montréal. Yesha is intrigued to explore responsible AI techniques to solve
    challenges that benefit society and share her learnings with the community.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** 是一位热情的AI开发者和作家，目前在蒙特利尔大学攻读机器学习硕士学位。Yesha对探索负责任的AI技术以解决有益于社会的挑战感兴趣，并与社区分享她的学习成果。'
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织在IT方面'
- en: '* * *'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Natural Language Processing with spaCy](https://www.kdnuggets.com/2023/01/natural-language-processing-spacy.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用spaCy进行自然语言处理](https://www.kdnuggets.com/2023/01/natural-language-processing-spacy.html)'
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[入门自动文本摘要](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
- en: '[Getting Started Cleaning Data](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据清理入门](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
- en: '[Getting Started with PyCaret](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyCaret 入门](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning 入门](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Getting Started with Scikit-learn for Classification in Machine Learning](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Scikit-learn 进行机器学习分类入门](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)'
