- en: 5 Machine Learning Papers to Read in 2024
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2024年值得阅读的5篇机器学习论文
- en: 原文：[https://www.kdnuggets.com/5-machine-learning-papers-to-read-in-2024](https://www.kdnuggets.com/5-machine-learning-papers-to-read-in-2024)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/5-machine-learning-papers-to-read-in-2024](https://www.kdnuggets.com/5-machine-learning-papers-to-read-in-2024)
- en: '![5 Machine_Learning_Papers_to_Read_in_2024](../Images/cfbdb31e9704a2fad133a5ec2a989901.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![2024年值得阅读的5篇机器学习论文](../Images/cfbdb31e9704a2fad133a5ec2a989901.png)'
- en: Image generated with DALL-E 3
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DALL-E 3生成的图像
- en: Machine learning is a subset of artificial intelligence that could bring value
    to the business by providing efficiency and predictive insight. It’s a valuable
    tool for any business.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子集，它通过提供效率和预测性洞察来为企业带来价值。它是任何企业的宝贵工具。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We know that last year was full of machine learning breakthrough, and this year
    is not any different. There is just so much to learn about.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道去年充满了机器学习的突破，今年也不例外。需要学习的内容实在太多了。
- en: With so much to learn, I select a few papers in 2024 that you should read to
    improve your knowledge.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在如此多的学习内容中，我挑选了2024年几篇值得阅读的论文，以提升您的知识。
- en: What are these papers? Let’s get into it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些论文是什么？让我们深入了解一下。
- en: 'HyperFast: Instant Classification for Tabular Data'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HyperFast：表格数据的即时分类
- en: HyperFast is a meta-trained hypernetwork model developed by [Bonet *et al.*
    (2024)](https://arxiv.org/pdf/2402.14335v1.pdf) research. It’s designed to provide
    a classification model that is capable of instant classification of tabular data
    in a single forward pass.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: HyperFast是由[Bonet *et al.* (2024)](https://arxiv.org/pdf/2402.14335v1.pdf)研究开发的一个元训练超网络模型。它旨在提供一个能够在一次前向传递中即时分类表格数据的分类模型。
- en: The author stated that the HyperFast could generate a task-specific neural network
    for an unseen dataset that can be directly used for classification prediction
    and eliminate the need for training a model. This approach would significantly
    reduce the computational demands and time required to deploy machine learning
    models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者表示，HyperFast可以生成一个任务特定的神经网络，用于未见数据集的分类预测，且无需训练模型。这种方法可以显著减少计算需求和部署机器学习模型所需的时间。
- en: The HyperFast Framework shows that the input data is transformed through standardization
    and dimensionality reduction, followed by a sequence of hypernetworks that produce
    weights for the network's layers, which include a nearest neighbor-based classification
    bias.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: HyperFast框架展示了输入数据通过标准化和降维处理，然后经过一系列超网络生成网络层的权重，这些权重包括基于最近邻的分类偏差。
- en: Overall, the results show that HyperFast performed excellently. It is faster
    than many classical methods without the need for fine-tuning. The paper concludes
    that HyperFast could become a new approach that can be applied in many real-life
    cases.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，结果显示HyperFast表现出色。它比许多经典方法更快，无需微调。论文总结道，HyperFast可能成为一种可以应用于许多实际案例的新方法。
- en: 'EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender
    Systems'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EasyRL4Rec：一个用户友好的基于强化学习的推荐系统代码库
- en: The next paper we will discuss is about a new library proposed by [Yu *et al.*
    (2024)](https://arxiv.org/pdf/2402.15164v1.pdf) called EasyRL4Rec.The point of
    the paper is about a user-friendly code library designed for developing and testing
    Reinforcement Learning (RL)-based Recommender Systems (RSs) called EasyRL4Rec.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的论文讨论的是由[Yu *et al.* (2024)](https://arxiv.org/pdf/2402.15164v1.pdf)提出的新库EasyRL4Rec。这篇论文的重点是一个旨在开发和测试基于强化学习（RL）的推荐系统（RSs）的用户友好型代码库，名为EasyRL4Rec。
- en: The library offers a modular structure with four core modules (Environment,
    Policy, StateTracker, and Collector), each addressing different stages of the
    Reinforcement Learning process.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 该库提供了一个具有四个核心模块（环境、策略、状态跟踪器和收集器）的模块化结构，每个模块处理强化学习过程的不同阶段。
- en: The overall structure shows that it works around the core modules for the Reinforcement
    Learning workflow—including Environments (Envs) for simulating user interactions,
    a Collector for gathering data from interactions, a State Tracker for creating
    state representations, and a Policy module for decision-making. It also includes
    a data layer for managing datasets and an Executor layer with a Trainer Evaluator
    for overseeing the learning and performance assessment of the RL agent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 整体结构表明，它围绕强化学习工作流的核心模块进行操作，包括用于模拟用户交互的环境（Envs）、用于收集交互数据的收集器、用于创建状态表示的状态跟踪器以及用于决策的策略模块。它还包括一个用于管理数据集的数据层和一个包含训练评估器的执行器层，用于监督
    RL 代理的学习和性能评估。
- en: The author concludes that EasyRL4Rec contains a user-friendly framework that
    could address practical challenges in RL for recommender systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作者总结道，EasyRL4Rec 包含一个用户友好的框架，可以解决推荐系统中 RL 的实际挑战。
- en: Label Propagation for Zero-shot Classification with Vision-Language Models
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签传播用于视觉语言模型的零-shot 分类
- en: The paper by [Stojnic *et al.* (2024)](https://arxiv.org/pdf/2404.04072v1.pdf)
    introduces a technique called ZLaP, which stands for Zero-shot classification
    with Label Propagation. It’s an enhancement for the Zero-Shot Classification of
    Vision Language Models by utilizing geodesic distances for classification.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[Stojnic *et al.* (2024)](https://arxiv.org/pdf/2404.04072v1.pdf) 的论文介绍了一种名为
    ZLaP 的技术，即 Zero-shot Classification with Label Propagation。它是通过利用测地距离进行分类的视觉语言模型零-shot
    分类的增强方法。'
- en: As we know Vision Models such as GPT-4V or LLaVa, are capable of zero-shot learning,
    which can perform classification without labeled images. However, it can still
    be enhanced further which is why the research group developed the ZLaP technique.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，像 GPT-4V 或 LLaVa 这样的视觉模型具备零-shot 学习能力，可以在没有标注图像的情况下进行分类。然而，这些模型仍然可以进一步增强，这也是研究小组开发
    ZLaP 技术的原因。
- en: The ZLaP core idea is to utilize label propagation on a graph-structured dataset
    comprising both image and text nodes. ZLaP calculates geodesic distances within
    this graph to perform classification. The method is also designed to handle the
    dual modalities of text and images.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ZLaP 的核心思想是利用图结构数据集中的标签传播，该数据集包括图像和文本节点。ZLaP 在此图中计算测地距离以进行分类。该方法还设计用于处理文本和图像的双重模态。
- en: Performance-wise, ZLaP shows results that consistently outperform other state-of-the-art
    methods in zero-shot learning by leveraging both transductive and inductive inference
    methods across 14 different dataset experiments.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能方面，ZLaP 显示了在零-shot 学习中持续超越其他最先进方法的结果，通过在 14 个不同数据集实验中利用转导和归纳推理方法。
- en: Overall, the technique significantly improved classification accuracy across
    multiple datasets, which showed promise for the ZLaP technique in the Vision Language
    Model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，该技术显著提高了多个数据集上的分类准确性，这表明 ZLaP 技术在视觉语言模型中的前景广阔。
- en: 'Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不留任何上下文：使用 Infini-attention 的高效无限上下文 Transformer
- en: The fourth paper we will discuss is by [Munkhdalai *et al.*(2024).](https://arxiv.org/pdf/2404.07143v1.pdf)
    Their paper introduces a method to scale Transformer-based Large Language Models
    (LLMs) that could handle infinitely long inputs with a limited computational capability
    called Infini-attention.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的第四篇论文由 [Munkhdalai *et al.* (2024)](https://arxiv.org/pdf/2404.07143v1.pdf)
    发表。该论文介绍了一种名为 Infini-attention 的方法，以在有限计算能力下处理无限长输入，来扩展基于 Transformer 的大型语言模型（LLMs）。
- en: The Infini-attention mechanism integrates a compressive memory system into the
    traditional attention framework. Combining a traditional causal attention model
    with compressive memory can store and update historical context and efficiently
    process the extended sequences by aggregating long-term and local information
    within a transformer network.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Infini-attention 机制将压缩内存系统集成到传统的注意力框架中。将传统的因果注意力模型与压缩内存结合，可以存储和更新历史上下文，并通过在
    Transformer 网络内聚合长期和局部信息来高效处理扩展序列。
- en: Overall, the technique performs superior tasks involving long-context language
    modelings, such as passkey retrieval from long sequences and book summarization,
    compared to currently available models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，该技术在处理长上下文语言建模任务方面表现优越，例如从长序列中检索密码和书籍总结，相较于当前可用模型。
- en: The technique could provide many future approaches, especially to applications
    that require the processing of extensive text data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术可能提供许多未来的应用途径，尤其是对需要处理大量文本数据的应用。
- en: 'AutoCodeRover: Autonomous Program Improvement'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'AutoCodeRover: 自主程序改进'
- en: The last paper we will discuss is by [Zhang *et al.* (2024)](https://arxiv.org/pdf/2404.05427v2.pdf).
    The main focus of this paper is on the tool called AutoCodeRover, which utilizes
    Large Language Models (LLMs) that are able to perform sophisticated code searches
    to automate the resolution of GitHub issues, mainly bugs, and feature requests.
    By using LLMs to parse and understand issues from GitHub, AutoCodeRover can navigate
    and manipulate the code structure more effectively than traditional file-based
    approaches to solve the issues.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的最后一篇论文由 [Zhang *et al.* (2024)](https://arxiv.org/pdf/2404.05427v2.pdf)
    撰写。该论文的主要关注点是名为 AutoCodeRover 的工具，它利用能够执行复杂代码搜索的大型语言模型（LLMs）来自动解决 GitHub 问题，主要是错误和功能请求。通过使用
    LLM 解析和理解 GitHub 上的问题，AutoCodeRover 可以比传统的基于文件的方法更有效地导航和操作代码结构以解决问题。
- en: 'There are two main stages of how AutoCodeRover works: Context Retrieval Stage
    and Patch Generation target. It works by analyzing the results to check if enough
    information has been gathered to identify the buggy parts of the code and attempts
    to generate a patch to fix the issues.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: AutoCodeRover 的工作有两个主要阶段：上下文检索阶段和补丁生成目标。它通过分析结果来检查是否已收集到足够的信息以识别代码中的错误部分，并尝试生成补丁来修复问题。
- en: The paper shows that AutoCodeRover improves performance compared to previous
    methods. For example, it solved 22-23% of issues from the SWE-bench-lite dataset,
    which resolved 67 issues in an average time of less than 12 minutes each. This
    is an improvement as on average it could take two days to solve.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 论文表明，AutoCodeRover 相较于之前的方法提升了性能。例如，它解决了 SWE-bench-lite 数据集中 22-23% 的问题，平均每个问题的解决时间少于
    12 分钟。这是一个改进，因为通常解决这些问题需要两天时间。
- en: Overall, the paper shows promise as AutoCodeRover is capable of significantly
    reducing the manual effort required in program maintenance and improvement tasks.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，论文显示出前景，因为 AutoCodeRover 能显著减少程序维护和改进任务所需的人工努力。
- en: Conclusion
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: 'There are many machine learning papers to read in 2024, and here are my recommendation
    papers to read:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 2024 年有许多机器学习论文可读，以下是我推荐的论文：
- en: 'HyperFast: Instant Classification for Tabular Data'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'HyperFast: 表格数据的即时分类'
- en: 'EasyRL4Rec: A User-Friendly Code Library for Reinforcement Learning Based Recommender
    Systems'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'EasyRL4Rec: 面向基于强化学习的推荐系统的用户友好型代码库'
- en: Label Propagation for Zero-shot Classification with Vision-Language Models
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用视觉-语言模型进行零样本分类的标签传播
- en: 'Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 留住上下文：具有 Infini-attention 的高效无限上下文变换器
- en: 'AutoCodeRover: Autonomous Program Improvement'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'AutoCodeRover: 自主程序改进'
- en: I hope it helps!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这些对你有帮助！
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** 是数据科学助理经理和数据撰稿人。在全职工作于
    Allianz Indonesia 的同时，他喜欢通过社交媒体和写作媒体分享 Python 和数据技巧。Cornellius 撰写了多种 AI 和机器学习主题的文章。'
- en: More On This Topic
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4 月 27 日：代码论文简要介绍；…](https://www.kdnuggets.com/2022/n17.html)'
- en: '[Top Machine Learning Papers to Read in 2023](https://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023 年顶级机器学习论文](https://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html)'
- en: '[Must Read NLP Papers from the Last 12 Months](https://www.kdnuggets.com/2023/03/must-read-nlp-papers-last-12-months.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[过去 12 个月必须阅读的 NLP 论文](https://www.kdnuggets.com/2023/03/must-read-nlp-papers-last-12-months.html)'
- en: '[Generative Agent Research Papers You Should Read](https://www.kdnuggets.com/generative-agent-research-papers-you-should-read)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该阅读的生成式智能体研究论文](https://www.kdnuggets.com/generative-agent-research-papers-you-should-read)'
- en: '[Machine Learning Books You Need To Read In 2022](https://www.kdnuggets.com/2022/04/machine-learning-books-need-read-2022.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年你需要阅读的机器学习书籍](https://www.kdnuggets.com/2022/04/machine-learning-books-need-read-2022.html)'
- en: '[A Brief Introduction to Papers With Code](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于论文与代码的简要介绍](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)'
