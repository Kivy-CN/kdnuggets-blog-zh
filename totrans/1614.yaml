- en: '6 Steps To Write Any Machine Learning Algorithm From Scratch: Perceptron Case
    Study'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始编写任何机器学习算法的 6 个步骤：感知器案例研究
- en: 原文：[https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html](https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html](https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By John Sullivan,** [**DataOptimal**](https://www.dataoptimal.com/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：约翰·沙利文，** [**DataOptimal**](https://www.dataoptimal.com/)'
- en: Writing an [algorithm from scratch](https://www.dataoptimal.com/machine-learning-from-scratch/)
    is a rewarding experience, providing you with that "ah ha!" moment where it finally
    clicks, and you understand what's really going on under the hood.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个[从头开始的算法](https://www.dataoptimal.com/machine-learning-from-scratch/)是一次有价值的经历，它能带给你“啊哈！”的时刻，让你真正明白底层是怎么运作的。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全领域的职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Am I saying that even if you've implemented the algorithm before with [scikit-learn](http://scikit-learn.org/stable/index.html),
    it's going to be easy to write from scratch? Absolutely not.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我是否在说，即使你之前已经用过[scikit-learn](http://scikit-learn.org/stable/index.html)实现过这个算法，从头编写也会很容易？绝对不是。
- en: Some algorithms are just more complicated than others, so start with something
    simple, such as the single layer [Perceptron](https://en.wikipedia.org/wiki/Perceptron).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一些算法比其他算法更复杂，所以从一些简单的东西开始，比如单层[感知器](https://en.wikipedia.org/wiki/Perceptron)。
- en: I'll walk you through a [6-step process to write algorithms from scratch](https://www.dataoptimal.com/machine-learning-from-scratch/),
    using the Perceptron as a case-study. This methodology can easily be translated
    to other machine learning algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我将带你通过一个[从头开始编写算法的 6 步骤](https://www.dataoptimal.com/machine-learning-from-scratch/)，以感知器作为案例。这种方法可以很容易地转化为其他机器学习算法。
- en: '![Machine Learning Algorithm](../Images/4b81fa33346d72d5c70e3448dbeff8f2.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/4b81fa33346d72d5c70e3448dbeff8f2.png)'
- en: '**Get a Basic Understanding of the Algorithm**'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**掌握算法的基本理解**'
- en: 'This goes back to what I originally stated. If you don’t understand the basics,
    don’t tackle an algorithm from scratch. At the very least, you should be able
    to answer the following questions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这回到我最初所说的。如果你不了解基础知识，不要从头开始研究算法。至少，你应该能够回答以下问题：
- en: What is it?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是什么？
- en: What is it typically used for?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通常用于什么？
- en: When CAN’T I use this?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么时候我不能使用这个？
- en: 'For the Perceptron, let’s go ahead and answer these questions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于感知器，让我们继续回答这些问题：
- en: The single layer Perceptron is the most basic neural network. It’s typically
    used for binary classification problems (1 or 0, “yes” or “no”).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单层感知器是最基础的神经网络。它通常用于二分类问题（1 或 0，“是”或“否”）。
- en: It’s a linear classifier, so it can only really be used when there’s a linear
    decision boundary. Some simple uses might be sentiment analysis (positive or negative
    response) or loan default prediction (“will default”, “will not default”). For
    both cases, the decision boundary would need to be linear.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个线性分类器，因此它只能在存在线性决策边界时使用。一些简单的应用可能是情感分析（积极或消极反应）或贷款违约预测（“会违约”，“不会违约”）。在这两种情况下，决策边界都需要是线性的。
- en: If the decision boundary is non-linear, you really can’t use the Perceptron.
    For those problems, you’ll need to use something different.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果决策边界是非线性的，你真的不能使用感知器。对于这些问题，你需要使用其他方法。
- en: '![Linear vs Nonlinear](../Images/0306980e0facdaf5f2331addb1d39bc3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![线性与非线性](../Images/0306980e0facdaf5f2331addb1d39bc3.png)'
- en: '**Find Some Different Learning Sources**'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**寻找一些不同的学习资源**'
- en: After you have a basic understanding of the model, it’s time to start doing
    your research. I recommend using numerous sources. Some people learn better with
    textbooks, some people learn
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在你对模型有了基本了解后，是时候开始做研究了。我建议使用大量的资源。有些人用教科书学得更好，有些人则不是。
- en: better with video. Personally, I like to bounce around and use various types
    of sources. For the mathematical details, textbooks do a great job, but for more
    practical examples, I prefer blog posts and YouTube videos.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 视频效果更佳。就我个人而言，我喜欢在不同的资源之间切换。对于数学细节，教科书做得很好，但对于更多实际示例，我更喜欢博客文章和YouTube视频。
- en: 'For the perceptron, here''s some great resources:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于感知机，这里有一些很好的资源：
- en: 'Textbooks:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教科书：
- en: '[The Elements of Statistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf),
    Section 4.5.1'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学习的元素](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)，第4.5.1节'
- en: '[Understanding Machine Learning: From Theory To Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf),
    Section 21.4'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解机器学习：从理论到算法](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)，第21.4节'
- en: 'Blogs:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 博客：
- en: Jason Brownlee’s article on his Machine Learning Mastery blog, [How To Implement
    The Perceptron Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/)
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jason Brownlee 在他的机器学习精通博客上发表的文章，[如何从头开始在 Python 中实现感知机算法](https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/)
- en: Sebastian Raschka’s blog post, [Single-Layer Neural Networks and Gradient Descent](https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastian Raschka 的博客文章，[单层神经网络和梯度下降](https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)
- en: 'Videos:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频：
- en: '[Perceptron Training](https://www.youtube.com/watch?v=5g0TPrxKK6o)'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[感知机训练](https://www.youtube.com/watch?v=5g0TPrxKK6o)'
- en: '[How the Perceptron Algorithm Works](https://www.youtube.com/watch?v=1XkjVl-j8MM)'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[感知机算法的工作原理](https://www.youtube.com/watch?v=1XkjVl-j8MM)'
- en: '![Understanding Machine Learning book](../Images/db7cde17660e8739987822512d67dca2.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![理解机器学习书籍](../Images/db7cde17660e8739987822512d67dca2.png)'
- en: '**Break the algorithm into chunks**'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**将算法分解为几个部分**'
- en: Now that we’ve gathered our sources, it’s time to start learning. Start by grabbing
    some paper and a pencil. Rather than read a chapter or blog post all the way through,
    start by skimming for section headings, and other important info. Write down bullet
    points, and try to outline the algorithm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经收集了资源，是时候开始学习了。从拿起纸和铅笔开始。与其通读一章或一篇博客文章，不如先浏览章节标题和其他重要信息。记下要点，并尝试概述算法。
- en: 'After going through the sources, I’ve broken down the Perceptron algorithm
    into the following chunks:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读过相关资料后，我将感知机算法分解为以下几个部分：
- en: Initialize the weights
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化权重
- en: Multiply weights by inputs and sum them up
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乘以权重并求和
- en: Compare the result against the threshold to compute the output (1 or 0)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果与阈值进行比较以计算输出 (1 或 0)
- en: Update the weights
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新权重
- en: Repeat
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复
- en: 'Breaking the algorithm up into chunks like this makes it easier to learn. Basically
    I’ve outlined the algorithm with pseudocode, and now I can go back and fill in
    the fine details. Here’s a picture of my notes for the second step, which is the
    dot product of the weights and inputs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将算法分解成几个部分可以让学习变得更容易。基本上，我用伪代码概述了算法，现在可以回过头来填补细节。这是我第二步笔记的图片，即权重和输入的点积：
- en: '![Breaking the algorithm into chunks](../Images/71149fd3ff8a3c8366ee4543c134714b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![将算法分解为几个部分](../Images/71149fd3ff8a3c8366ee4543c134714b.png)'
- en: '**Start with a simple example**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从简单的例子开始**'
- en: 'After I’ve put together my notes on the algorithm, It’s time to start implementing
    it in code. Before I dive in to a complicated problem, I like to start with a
    simple example. For the Perceptron, a [NAND gate](https://en.wikipedia.org/wiki/NAND_gate)
    is a perfect simple data set. If both inputs are true (1) then the output is false
    (0), otherwise, the output is true. Here’s an example of what the data set looks
    like:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我整理完算法笔记后，是时候开始在代码中实现它了。在深入解决复杂问题之前，我喜欢从简单的例子开始。对于感知机，一个 [NAND门](https://en.wikipedia.org/wiki/NAND_gate)
    是一个完美的简单数据集。如果两个输入都为真 (1)，则输出为假 (0)，否则输出为真。以下是数据集的示例：
- en: '![Simple Data Set](../Images/d493d481cc91becd452580782930498a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![简单数据集](../Images/d493d481cc91becd452580782930498a.png)'
- en: Now that I have a simple data set, I’ll start implementing the algorithm that
    I outlined in Step 3\. It’s good practice to write the algorithm in chunks and
    test it, rather than trying to write it all in one sitting. This makes it easier
    to debug when you’re first starting out. Of course at the end you can go back
    and clean it up to make it look a little nicer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我有了一个简单的数据集，我将开始实现我在第3步中概述的算法。分块编写算法并进行测试是一种良好的实践，而不是一次性完成全部编写。这使得在刚开始时调试变得更容易。当然，在最后，你可以回过头来整理一下，使其看起来更漂亮。
- en: 'Here’s an example of the Python code for the dot product part of the algorithm
    that I outlined in Step 3:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第3步中概述的算法的点积部分的 Python 代码示例：
- en: '![Python code dot product](../Images/b7e7c39fd4317a23be668a6f8796ccca.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Python 代码点积](../Images/b7e7c39fd4317a23be668a6f8796ccca.png)'
- en: '**Validate with a trusted implementation**'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用可靠的实现进行验证**'
- en: Now that we’ve written up our code and tested it against a small data set, it’s
    time to scale things up to a [larger dataset](https://github.com/dataoptimal/posts/tree/master/algorithms
    from scratch). To make sure that our code is working correctly on this more complicated
    dataset, it’s good to test it against a trusted implementation. For the Perceptron
    we can use the implementation from [sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经编写了代码并在小数据集上进行了测试，是时候将其扩展到一个[更大的数据集](https://github.com/dataoptimal/posts/tree/master/algorithms%20from%20scratch)了。为了确保我们的代码在这个更复杂的数据集上正确工作，最好将其与一个可靠的实现进行测试。对于
    Perceptron，我们可以使用[sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)中的实现。
- en: '![Python sci-kit code](../Images/3a654185564dafe9a220fdf9aab15d56.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Python sci-kit 代码](../Images/3a654185564dafe9a220fdf9aab15d56.png)'
- en: To test [my code](https://github.com/dataoptimal/posts/tree/master/algorithms
    from scratch) I’m going to look at the weights. If I’ve implemented the algorithm
    correctly, my weights should match up with those of the sci-kit learn Perceptron.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试[我的代码](https://github.com/dataoptimal/posts/tree/master/algorithms%20from%20scratch)，我将查看权重。如果我正确实现了算法，我的权重应该与
    sci-kit learn Perceptron 的权重一致。
- en: '![Test code](../Images/5e20ea4c8902f4813b4496c38479e0b9.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![测试代码](../Images/5e20ea4c8902f4813b4496c38479e0b9.png)'
- en: At first, I didn’t get the same weights, and this is because I had to tweak
    the default settings in the scikit-learn Perceptron. I wasn’t implementing a new
    random state every time, just a fixed seed, so I had to turn this off. The same
    goes for shuffling, I also needed to turn that off. To match my learning rate,
    I changed eta0 to 0.1\. Finally, I turned off the fit_intercept option. I included
    a dummy column of 1’s in my feature dataset, so I was already automatically fitting
    the intercept (aka bias term).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我没有得到相同的权重，这是因为我必须调整 scikit-learn Perceptron 的默认设置。我并没有每次都实现一个新的随机状态，只是一个固定的种子，所以我必须将其关闭。洗牌也是一样，我也需要关闭它。为了匹配我的学习率，我将
    eta0 改为 0.1。最后，我关闭了 fit_intercept 选项。我在特征数据集中包含了一列全为 1 的虚拟列，因此我已经在自动拟合截距（即偏差项）。
- en: This brings up another important point. When you validate against an existing
    implementation of a model, you need to be very aware of the inputs to the model.
    You should never blindly use a model, always question your assumptions, and exactly
    what each input means.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这提出了另一个重要点。当你对模型的现有实现进行验证时，你需要非常清楚模型的输入。你不应该盲目使用模型，总是要质疑你的假设，以及每个输入的确切含义。
- en: '**Write up your process**'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**记录你的过程**'
- en: 'This last step in the process is probably the most important. You’ve just gone
    through all the work of learning, taking notes, writing the algorithm from scratch,
    and comparing it with a trusted implementation. Don’t let all that good work go
    to waste! Writing up the process is important for two reasons:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程中的最后一步可能是最重要的。你刚刚完成了学习、做笔记、从头编写算法和与可靠实现进行比较的所有工作。不要让所有这些好工作白费！记录过程是重要的，有两个原因：
- en: You’ll gain an even deeper understanding because you’re teaching others what
    you just learned.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将获得更深刻的理解，因为你正在教别人你刚刚学到的内容。
- en: You can showcase it to potential employers. It’s one thing to show that you
    can implement an algorithm from a machine learning library, but it’s even more
    impressive if you can implement it yourself from scratch.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以向潜在雇主展示它。展示你能够实现一个机器学习库中的算法是一回事，但如果你能从头开始自己实现一个，那就更令人印象深刻了。
- en: A great way to showcase your work is with a [GitHub Pages](https://pages.github.com/)
    portfolio.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 展示你的工作的一个好方法是通过[GitHub Pages](https://pages.github.com/)作品集。
- en: '![GitHub pages](../Images/0caf7b335e22b399e5383a40fc1c2260.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![GitHub 页面](../Images/0caf7b335e22b399e5383a40fc1c2260.png)'
- en: '**Conclusion**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Writing an algorithm from scratch can be a very rewarding experience. It’s a
    great way to gain a deeper understanding of the model, while building an impressive
    portfolio project at the same time.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始编写算法可以是一种非常有益的经历。这是深入理解模型的绝佳方式，同时还能建立一个令人印象深刻的作品集项目。
- en: Remember to take it slow, and start with something simple. Most importantly,
    make sure to document and share your work.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 记住要慢慢来，从简单的开始。最重要的是，确保记录并分享你的工作。
- en: '**Bio**: John Sullivan is the founder of the data science learning blog, DataOptimal.
    You can follow him on Twitter [@DataOptimal](https://twitter.com/dataoptimal).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介**：约翰·沙利文是数据科学学习博客 DataOptimal 的创始人。你可以在 Twitter 上关注他 [@DataOptimal](https://twitter.com/dataoptimal)。'
- en: '**Related:**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Top /r/MachineLearning posts, August 2018: Everybody Dance Now; Stanford class
    Machine Learning cheat sheets; Academic Torrents for sharing enormous datasets](https://www.kdnuggets.com/2018/09/top-reddit-machine-learning-august.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Top /r/MachineLearning 帖子，2018 年 8 月：大家一起跳舞；斯坦福大学机器学习课堂作弊单；用于分享巨大数据集的学术种子](https://www.kdnuggets.com/2018/09/top-reddit-machine-learning-august.html)'
- en: '[Key Takeaways from KDD 2018: a Deconfounder, Machine Learning at Pinterest,
    Knowledge Graph](https://www.kdnuggets.com/2018/09/kdd-2018-key-takeaways.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDD 2018 的关键收获：去混淆器、Pinterest 上的机器学习、知识图谱](https://www.kdnuggets.com/2018/09/kdd-2018-key-takeaways.html)'
- en: '[Everything You Need to Know About AutoML and Neural Architecture Search](https://www.kdnuggets.com/2018/09/everything-need-know-about-automl-neural-architecture-search.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你需要了解的 AutoML 和神经网络架构搜索的一切](https://www.kdnuggets.com/2018/09/everything-need-know-about-automl-neural-architecture-search.html)'
- en: More On This Topic
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主题更多
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学来寻找目标，并通过……来寻找目标](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一项 90 亿美元的 AI 失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
