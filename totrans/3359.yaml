- en: Generative Adversarial Networks – Hot Topic in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络 – 机器学习的热门话题
- en: 原文：[https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html](https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html](https://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)
- en: '**By Al Gharakhanian.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Al Gharakhanian。**'
- en: NIPS2016 (Neural Information Processing System) is an annual event that attracts
    the best and the brightest of the field of Machine Learning both from academia
    as well as industry. I attended this event last week for the very first time and
    was blown away by the volume and diversity of the presentations. One unusual observation
    was that a large chunk of exhibitors were hedge funds in search of ML talent.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: NIPS2016（神经信息处理系统）是一个年度盛会，吸引了来自学术界和工业界的机器学习领域的顶尖人才。我上周第一次参加了这个活动，被演讲的数量和多样性震撼了。一个不寻常的观察是，大量展位是寻求机器学习人才的对冲基金。
- en: Some of the papers were highly abstract and theoretical while others quite pragmatic
    from the likes of Google, Facebook. The topics were wide-ranging but there were
    two topics stood out attracting a sizable attention.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 有些论文高度抽象和理论化，而另一些则来自于如 Google 和 Facebook 等公司的务实研究。这些话题范围广泛，但有两个话题脱颖而出，吸引了大量关注。
- en: The first was “Generative Adversarial Networks” (GANs for short), while the
    second was “Reinforcement Learning” (RL for short). My plan is to cover GANs in
    this post and hope to do the same for RL in a future post.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是“生成对抗网络”（简称 GANs），第二个是“强化学习”（简称 RL）。我的计划是这篇文章覆盖 GANs，希望未来的文章能同样介绍 RL。
- en: GAN is a relatively new Machine Learning architecture for neural networks pioneered
    by Ian Goodfellow and his colleagues at University of Montreal in 2014\. In order
    to fully understand GANs, one has to understand the difference between Supervised
    and Unsupervised learning machines. Supervised machines are trained and tested
    based on large quantities of “labeled” samples. In other words, they require large
    datasets containing the “features” or “predictors” as well as its corresponding
    labels. As an example, a supervised image classifier engine would require a set
    of images with correct labels (e.g. cars, flowers, tables, . . .). Unsupervised
    learners don’t have this luxury and they learn on the job as they go. They learn
    from mistakes and try not to make similar errors in the future.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 是一种相对较新的神经网络机器学习架构，由 Ian Goodfellow 和他在蒙特利尔大学的同事们于 2014 年开创。为了全面理解 GANs，必须了解监督学习和无监督学习机器之间的区别。监督学习机器基于大量的“标记”样本进行训练和测试。换句话说，它们需要包含“特征”或“预测因子”以及相应标签的大型数据集。例如，一个监督图像分类引擎需要一组带有正确标签的图像（例如，汽车、花朵、桌子等）。无监督学习者没有这种奢侈条件，它们在实际操作中学习，从错误中吸取教训，力求不再犯类似的错误。
- en: The disadvantage of supervised machines is their need for large sums of labeled
    data. Labeling large number of samples is costly and time consuming. Unsupervised
    learners don’t have this disadvantage but they tend to be less accurate. Naturally
    there is a strong motivation to improve the unsupervised machines and to lessen
    the reliance on the supervised ones. You can view GANs and RLs means of improving
    unsupervised machines (neural networks).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的缺点是需要大量的标记数据。标记大量样本既昂贵又耗时。无监督学习则没有这一缺点，但通常准确性较低。自然地，有强烈的动机去改进无监督机器，并减少对监督学习的依赖。你可以将
    GANs 和 RLs 视为改进无监督机器（神经网络）的手段。
- en: The second useful concept to remember is the concept of “Generative Models”. These
    are models that predict by generating the most likely outcome given a sequence
    of input samples. As an example, a generative model can generate the next likely video
    frame based on the previous frames. Another example is search engines that try
    to predict the next likely word before it is entered by the user.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个值得记住的有用概念是“生成模型”。这些模型通过生成给定一系列输入样本的最可能结果来进行预测。例如，生成模型可以基于之前的帧生成下一个最可能的视频帧。另一个例子是搜索引擎在用户输入之前尝试预测下一个最可能的词。
- en: Keeping these two concepts in mind, we now can tackle GANs. You can view a GAN
    as a new architecture for an unsupervised neural network able to achieve far better
    performance compared to traditional nets. To be more precise GANs are a new way
    of training a neural net. GANs contain not one but two independent nets that work
    separately and act as adversaries (see the diagram below). The first neural net
    is called the Discriminator (D) and is the net that has to undergo training. D
    is the classifier that will do the heavy lifting during the normal operation once
    the training is complete. The second network is called the Generator (G) and is
    tasked to generate random samples that resemble real samples with a twist rendering
    them as fake samples.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这两个概念，我们现在可以探讨GAN。你可以将GAN视为一种新的无监督神经网络架构，相比传统网络能够实现更好的性能。更准确地说，GAN是一种训练神经网络的新方式。GAN包含两个独立的网络，它们各自工作并充当对手（见下图）。第一个神经网络称为**判别器**（D），它是需要接受训练的网络。D是分类器，在训练完成后在正常操作过程中将承担繁重的任务。第二个网络称为**生成器**（G），其任务是生成随机样本，这些样本与真实样本相似，但带有一些变动，使其成为假样本。
- en: '![generative-adversarial-network](../Images/288714ba25f18f97439b63ab4e75bf53.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![generative-adversarial-network](../Images/288714ba25f18f97439b63ab4e75bf53.png)'
- en: As an example, consider an image classifier D designed to identify a series
    of images depicting various animals. Now consider an adversary (G) with the mission
    to fool D using carefully crafted images that look almost right but not quite.
    This is done by picking a legitimate sample randomly from training set (latent
    space) and synthesizing a new image by randomly altering its features (by adding
    random noise). As an example, G can fetch the image of a cat and can add an extra
    eye to the image converting it to a false sample. The result is an image very
    similar to a normal cat with the exception of the number of eye.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个设计用于识别各种动物图像的图像分类器D。现在考虑一个对手（G），其任务是通过精心制作的图像来欺骗D，这些图像看起来几乎正确但又不完全对。这是通过从训练集（潜在空间）中随机挑选一个合法样本，并通过随机改变其特征（添加随机噪声）来合成新图像。例如，G可以获取一只猫的图像，并在图像上添加一个额外的眼睛，将其转换为假样本。结果是一个非常类似正常猫的图像，唯一的区别是眼睛的数量。
- en: During training, D is presented with a random mix of legitimate images from
    training data as well as fake images generated by G. Its task is to identify correct
    and fake inputs. Based on the outcome, both machines try to fine-tune their parameters
    and become better in what they do. If D makes the right prediction, G updates
    its parameters in order to generate better fake samples to fool D. If D’s prediction
    is incorrect, it tries to learn from its mistake to avoid similar mistakes in
    the future. The reward for net D is the number of right predictions and the reward
    for G is the number D’s errors. This process continues until an equilibrium is
    established and D’s training is optimized.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，D会收到来自训练数据的真实图像与G生成的假图像的随机混合。其任务是识别正确和假输入。根据结果，两个网络都尝试微调它们的参数，变得更出色。如果D做出正确的预测，G会更新其参数，以生成更好的假样本来欺骗D。如果D的预测不正确，它会试图从错误中学习，以避免未来类似的错误。网络D的奖励是正确预测的数量，G的奖励是D的错误数量。这个过程持续进行，直到达到平衡，D的训练得到优化。
- en: One of the weaknesses of early GANs was stability but we have seen very promising
    work that can alleviate this problem (details are beyond the scope of this post). In
    a way of an analogy, GANs act like the political environment of a country with
    two rival political parties. Each party continuously attempts to improve on its
    weaknesses while trying to find and leverage vulnerabilities in their adversary
    to push their agenda. Over time both parties become better operators.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 早期GAN的一个弱点是稳定性，但我们已经看到了一些非常有前景的工作可以缓解这个问题（详细信息超出了本文的范围）。从某种程度上来说，GAN就像是一个拥有两个对立政党的国家的政治环境。每个党派不断尝试改善自己的弱点，同时试图发现和利用对方的漏洞，以推动自己的议程。随着时间的推移，两党都成为了更好的操作员。
- en: As for the impact of RLs and GANs on semiconductors, both new architectures
    need significantly more gates, more CPU cycles, and more Memory. Nothing to complain
    about.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 至于RL和GAN对半导体的影响，这两种新架构需要显著更多的门、更高的CPU周期和更多的内存。这没什么好抱怨的。
- en: '[Original](https://www.linkedin.com/pulse/gans-one-hottest-topics-machine-learning-al-gharakhanian?trk=pulse_spock-articles).
    Reposted by Permission.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.linkedin.com/pulse/gans-one-hottest-topics-machine-learning-al-gharakhanian?trk=pulse_spock-articles)。经许可转载。'
- en: '**Bio:** [****Al Gharakhanian** **](https://www.linkedin.com/in/algharakhanian)is
    well-rounded executive with extensive experience in Product Marketing, Sales,
    and Business Development in Semiconductors, Machine Learning, and Data Science.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [****Al Gharakhanian**](https://www.linkedin.com/in/algharakhanian)
    是一位全面发展的高管，拥有在半导体、机器学习和数据科学领域的产品营销、销售和业务发展方面的丰富经验。'
- en: '**Related:**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning Research Review: Generative Adversarial Nets](/2016/10/deep-learning-research-review-generative-adversarial-networks.html)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习研究综述：生成对抗网络](/2016/10/deep-learning-research-review-generative-adversarial-networks.html)'
- en: '[Are Deep Neural Networks Creative?](/2016/05/deep-neural-networks-creative-deep-learning-art.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络是否具备创造力？](/2016/05/deep-neural-networks-creative-deep-learning-art.html)'
- en: '[Up to Speed on Deep Learning: August Update, Part 2](/2016/09/deep-learning-august-update-part-2.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习最新动态：8 月更新，第二部分](/2016/09/deep-learning-august-update-part-2.html)'
- en: '* * *'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的 3 大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT 需求'
- en: '* * *'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Topic Modeling Approaches: Top2Vec vs BERTopic](https://www.kdnuggets.com/2023/01/topic-modeling-approaches-top2vec-bertopic.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[主题建模方法：Top2Vec 与 BERTopic](https://www.kdnuggets.com/2023/01/topic-modeling-approaches-top2vec-bertopic.html)'
- en: '[Pandas: How to One-Hot Encode Data](https://www.kdnuggets.com/2023/07/pandas-onehot-encode-data.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas：如何进行独热编码](https://www.kdnuggets.com/2023/07/pandas-onehot-encode-data.html)'
- en: '[Dive into the Future with Kaggle''s AI Report 2023 – See What''s Hot](https://www.kdnuggets.com/dive-into-the-future-with-kaggle-ai-report-2023-see-what-hot)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深入了解 Kaggle 的 AI 报告 2023 – 了解最新热点](https://www.kdnuggets.com/dive-into-the-future-with-kaggle-ai-report-2023-see-what-hot)'
- en: '[What is Adversarial Machine Learning?](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是对抗性机器学习？](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
- en: '[25 Free Courses to Master Data Science, Data Engineering, Machine…](https://www.kdnuggets.com/25-free-courses-to-master-data-science-data-engineering-machine-learning-mlops-and-generative-ai)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25 门免费课程，掌握数据科学、数据工程、机器学习……](https://www.kdnuggets.com/25-free-courses-to-master-data-science-data-engineering-machine-learning-mlops-and-generative-ai)'
- en: '[Neural Networks and Deep Learning: A Textbook (2nd Edition)](https://www.kdnuggets.com/2023/07/aggarwal-neural-networks-deep-learning-textbook-2nd-edition.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络与深度学习：教科书（第二版）](https://www.kdnuggets.com/2023/07/aggarwal-neural-networks-deep-learning-textbook-2nd-edition.html)'
