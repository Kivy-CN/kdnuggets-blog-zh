- en: Three techniques to improve machine learning model performance with imbalanced
    datasets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升机器学习模型在不平衡数据集上的表现的三种技术
- en: 原文：[https://www.kdnuggets.com/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html](https://www.kdnuggets.com/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html](https://www.kdnuggets.com/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
- en: '**By [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/), Computational
    Geophysicist and Machine Learning Enthusiast**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)，计算地球物理学家和机器学习爱好者**'
- en: '![Image](../Images/d95931c8777822e1ce4b0bdff0d5f216.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/d95931c8777822e1ce4b0bdff0d5f216.png)'
- en: This project was part of one my recent job interview skill test for a “Machine
    learning engineer” position. I had to complete the project in 48 hours which includes
    writing a 10-page report in latex. The dataset has classes and highly imbalanced.
    The primary objective of this project was to handle data imbalance issue. In the
    following subsections, I describe three techniques I used to overcome the data
    imbalance problem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目是我最近的一次“机器学习工程师”职位面试技能测试的一部分。我需要在 48 小时内完成这个项目，其中包括用 LaTeX 撰写 10 页报告。数据集具有类别且高度不平衡。这个项目的主要目标是处理数据不平衡问题。在以下小节中，我将描述我用来克服数据不平衡问题的三种技术。
- en: '*First, let’s get started familiarizing with datasets:*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*首先，让我们开始熟悉数据集：*'
- en: '**Datasets:** There are three labels [1, 2, 3] in the training data which makes
    the problem a multi-class problem. Training datasets have 17 features and 38829
    individual data point. Whereas in testing data, there are 16 features without
    the label and have 16641 data points. The training dataset is very unbalanced.
    The majority of the data belongs to class-1 (95%) whereas class-2 and class-3
    have 3.0% and 0.87% data respectively. Since the datasets do not have any null
    values and already scaled, I did not do any further processing. Due to some internal
    reasons, I am not going to share the datasets but the detail results and techniques.
    The following figure show data imbalance.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集：** 训练数据中有三个标签 [1, 2, 3]，这使得问题成为一个多类别问题。训练数据集有 17 个特征和 38829 个数据点。而在测试数据中，有
    16 个特征没有标签，并且有 16641 个数据点。训练数据集非常不平衡。大多数数据属于类别 1（95%），而类别 2 和类别 3 分别有 3.0% 和 0.87%
    的数据。由于数据集没有任何空值且已进行缩放，因此我没有进行进一步处理。由于一些内部原因，我不会分享数据集，但会分享详细的结果和技术。以下图展示了数据不平衡情况。'
- en: '![](../Images/0dd80c79593879c874f341bf5cc91ca6.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dd80c79593879c874f341bf5cc91ca6.png)'
- en: 'Figure 1: The graph shows the data imbalance in training dataset. The majority
    of the data belongs to class-1 (95%) whereas class-2 and class-3 have 3.0% and
    0.87% data respectively'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：该图展示了训练数据集中的数据不平衡情况。大多数数据属于类别 1（95%），而类别 2 和类别 3 分别有 3.0% 和 0.87% 的数据。
- en: '**Algorithm:** After preliminary observation, I decided to use Random forest
    (RF) algorithm since it outperforms the other algorithms such as support vector
    machine, Xgboost, LightGBM, etc. RF is a bagging type of ensemble classifier that
    uses many such single trees to make predictions. There are a couple of reasons
    for choosing RF in this project:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法：** 在初步观察后，我决定使用随机森林（RF）算法，因为它优于其他算法，如支持向量机、Xgboost、LightGBM 等。RF 是一种集成分类器，它使用多个这样的单棵树来进行预测。选择
    RF 的原因有几点：'
- en: RF is robust to overfitting (thus solving one of the most significant disadvantages
    of single decision tree).
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RF 对过拟合具有鲁棒性（因此解决了单棵决策树的一个重大缺点）。
- en: Parameterization remains quite intuitive and straightforward.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数化保持相当直观和简单。
- en: There are many successful use cases where the random forest algorithm was used
    in highly unbalanced datasets as we have in this project.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有许多成功的案例表明，随机森林算法在我们这个项目中的高度不平衡数据集上表现良好。
- en: I have prior implementation experience of the algorithm.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我有该算法的先前实现经验。
- en: To find the best parameters, I performed a grid search over specified parameter
    values using *scikit-sklearn* implemented GridSearchCV. More details can be found
    on the [Github](https://github.com/msahamed/handle_imabalnce_class).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最佳参数，我使用 *scikit-sklearn* 实现的 GridSearchCV 执行了指定参数值的网格搜索。更多详细信息可以在 [Github](https://github.com/msahamed/handle_imabalnce_class)
    上找到。
- en: '**To handle data imbalance issue, I have used the following three techniques :**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**为了解决数据不平衡问题，我使用了以下三种技术：**'
- en: '**A. Use Ensemble Cross-Validation (CV):** In this project, I used cross-validation
    to justify the model robustness. The entire datasets were divided into five subsets.
    In each CV, 4 out of 5 subsets are used for training, and remaining set was used
    to validate the model. In each CV, the model also predicts (probabilities, not
    the class) the test data. At the end of the cross-validation, we have five testing
    prediction probabilities. Finally, I average the prediction probabilities for
    all class. Training performance of the model was steady and has the almost constant
    recall and f1 score on each CV. This technique helped me predicting test data
    very well in one of the Kaggle competitions in which I became top 25th out of
    5355 which is top 1%. The following partial code snippets shows the implementation
    of the Ensemble cross-validation:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**A. 使用集成交叉验证 (CV):** 在这个项目中，我使用交叉验证来验证模型的稳健性。整个数据集被分为五个子集。在每次交叉验证中，5个子集中有4个用于训练，剩下的一个用于验证模型。在每次交叉验证中，模型还会对测试数据进行预测（预测概率，而不是类别）。交叉验证结束时，我们得到了五组测试预测概率。最后，我对所有类别的预测概率取平均。模型的训练性能稳定，并且在每次交叉验证中几乎保持恒定的召回率和F1分数。这项技术帮助我在一次Kaggle竞赛中很好地预测了测试数据，我在5355名参赛者中排名第25位，属于前1%。以下部分代码片段展示了集成交叉验证的实现：'
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**B. Set Class Weight/Importance:** Cost-sensitive learning is among the many
    other approaches to make the random forest more suitable for learning from very
    imbalanced data. The RF has the tendency to be biased on the majority class. Therefore,
    imposing a costly penalty on the minority class misclassification can be useful.
    Since this technique is proven the way of improving model performance, I assign
    a high weight to the minority class (i.e., higher misclassification cost). The
    class weights are then incorporated into the RF algorithm. I determine a class
    weight from the ratio between the number of the dataset in class-1 and the number
    of the dataset in the class. For example, the ratio between the number of datasets
    in class-1 and class-3 is approximately 110, and the ratio for class-1 and class-2
    is about 26\. Later, I slightly modify the number for improving the model performance
    in trail and error basis. The following code snippets show the implementation
    of the different class weights.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**B. 设置类别权重/重要性:** 成本敏感学习是使随机森林更适合从高度不平衡数据中学习的众多方法之一。随机森林倾向于对多数类别有偏见。因此，对少数类别误分类施加高额惩罚可能会有帮助。由于这项技术已被证明能提高模型性能，我为少数类别分配了较高的权重（即，较高的误分类成本）。然后，将类别权重纳入随机森林算法中。我根据类别1和类别中的数据集数量之比来确定类别权重。例如，类别1和类别3的数据集数量之比约为110，类别1和类别2的比率约为26。之后，我稍微调整了这些数值，以在试验和错误的基础上提高模型性能。以下代码片段展示了不同类别权重的实现。'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**C. Over-Predict a Label than Under-Predict:** This is technique is optional.
    I have applied this technique since I was asked to implement. It looks to me this
    method is very effecting to improve minority class performance. In brief, the
    technique is to penalize the model most if it misclassified class-3, a little
    less for class-2 and the least for class-1.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**C. 过度预测标签而非欠预测:** 这是一种可选的技术。我应用了这种技术，因为我被要求实现。对我来说，这种方法在提高少数类别的性能方面非常有效。简而言之，该技术是对模型的误分类类别3给予最大惩罚，对类别2给予较少的惩罚，对类别1给予最少的惩罚。'
- en: To implement the method, I changed the probability threshold for each class.
    To do so, I set the probability for class-3, class-2 and class-1 in increasing
    order (i.e, class-3 = 0.25, class-2 = 0.35, class-1 = 0.50), so that the model
    is forced to over predict class. Detail implementation of this algorithm can be
    found on this project [Github page](https://github.com/msahamed/handle_imabalnce_class).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现该方法，我为每个类别调整了概率阈值。为此，我按照递增顺序设置了类别3、类别2和类别1的概率（即，类别3 = 0.25，类别2 = 0.35，类别1
    = 0.50），以迫使模型过度预测类别。该算法的详细实现可以在本项目的[Github页面](https://github.com/msahamed/handle_imabalnce_class)找到。
- en: 'Final Result:'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终结果：
- en: The following results show that how the above three techniques helped improving
    the model performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果展示了上述三种技术如何帮助提高模型性能。
- en: '**1\. Result with ensemble cross-validation:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 使用集成交叉验证的结果：**'
- en: '![](../Images/7e6e91a0261e4ccef8b4c66c382c4743.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e6e91a0261e4ccef8b4c66c382c4743.png)'
- en: '**2\. Result with ensemble cross-validation + class weight:**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 使用集成交叉验证 + 类别权重的结果：**'
- en: '![](../Images/f9b62acb4bcfb59d2baa192d99f976c6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9b62acb4bcfb59d2baa192d99f976c6.png)'
- en: '**3\. Result with ensemble cross-validation + class weight+ over-predict a
    label:**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 使用集成交叉验证 + 类别权重 + 过度预测标签的结果：**'
- en: '![](../Images/d1a9e45d40d5bfdb074b638f74d497e3.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1a9e45d40d5bfdb074b638f74d497e3.png)'
- en: '**Conclusion**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Since I had minimal experience in implementing the technique, initially over-prediction
    seems to be tricky to me. However, researching on the method helps me find a way
    to get around the problem. Due to time constrained I could not focus on fine-tuning
    and feature engineering of the model. There are many scopes to improve the model
    further. For example, deleting unnecessary features and adding some extra feature
    by engineering. I have tried LightGBM and XgBoost as well. But in this short time,
    I found Random forest outperforms the other algorithms. We might try some other
    algorithms including a neural network to improve the model. Finally, I would say,
    from this data challenge I learned how to handle unbalanced data in a well-organized
    way.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我在实施该技术方面的经验有限，最初过度预测对我来说似乎很棘手。然而，研究该方法帮助我找到了解决问题的方法。由于时间有限，我无法专注于模型的微调和特征工程。还有许多改进模型的空间。例如，删除不必要的特征和通过特征工程添加一些额外特征。我还尝试了
    LightGBM 和 XgBoost。但在这段时间里，我发现随机森林的表现优于其他算法。我们可能会尝试包括神经网络在内的其他算法来改进模型。最后，我要说的是，从这次数据挑战中，我学会了如何以良好的组织方式处理不平衡数据。
- en: Thank you very much reading. The full code can be found on [Github](https://github.com/msahamed/handle_imabalnce_class).
    Let me know if you have any question or this article needs any correction.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢您的阅读。完整代码可以在 [Github](https://github.com/msahamed/handle_imabalnce_class)
    上找到。如果您有任何问题或这篇文章需要更正，请告诉我。
- en: '**Bio: [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)** is the
    Founder of [xoolooloo.com](https://www.xoolooloo.com/). Computational Geophysicist
    and Machine Learning Enthusiast.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)** 是 [xoolooloo.com](https://www.xoolooloo.com/)
    的创始人。计算地球物理学家和机器学习爱好者。'
- en: '[Original](https://medium.com/@sabber/working-with-highly-imbalanced-datasets-in-machine-learning-projects-c70c5f2a7b16).
    Reposted with permission.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@sabber/working-with-highly-imbalanced-datasets-in-machine-learning-projects-c70c5f2a7b16)。已获得许可转载。'
- en: '**Related:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[7 Techniques to Handle Imbalanced Data](/2017/06/7-techniques-handle-imbalanced-data.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理不平衡数据的 7 种技术](/2017/06/7-techniques-handle-imbalanced-data.html)'
- en: '[Learning from Imbalanced Classes](/2016/08/learning-from-imbalanced-classes.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从不平衡类别中学习](/2016/08/learning-from-imbalanced-classes.html)'
- en: '[Dealing with Unbalanced Classes, SVMs, Random Forests, and Decision Trees
    in Python](/2016/04/unbalanced-classes-svm-random-forests-python.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理不平衡类别、支持向量机、随机森林和决策树的 Python 实现](/2016/04/unbalanced-classes-svm-random-forests-python.html)'
- en: '* * *'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[7 Techniques to Handle Imbalanced Data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理不平衡数据的 7 种技术](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
- en: '[KDnuggets News, August 31: The Complete Data Science Study Roadmap…](https://www.kdnuggets.com/2022/n35.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8月31日：完整的数据科学学习路线图…](https://www.kdnuggets.com/2022/n35.html)'
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无监督解缠表示学习在类别不平衡数据集中的应用…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
- en: '[Overcoming Imbalanced Data Challenges in Real-World Scenarios](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克服现实世界场景中的数据不平衡挑战](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应该知道的三个 R 语言库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Sky''s the Limit: Learn how JetBlue uses Monte Carlo and Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无极限：了解 JetBlue 如何利用 Monte Carlo 和 Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
