- en: A 2019 Guide to Semantic Segmentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html/2](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html?page=2#comments)'
  prefs: []
  type: TYPE_IMG
- en: Multi-Scale Context Aggregation by Dilated Convolutions (ICLR, 2016)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this paper, a convolution network module that blends multi-scale context
    information without loss of resolution is developed. This module can then be plugged
    into existing architectures at any resolution. The module is based on [dilated
    convolutions](https://www.kdd.org/kdd2018/accepted-papers/view/smoothed-dilated-convolutions-for-improved-dense-prediction).
  prefs: []
  type: TYPE_NORMAL
- en: '[**Multi-Scale Context Aggregation by Dilated Convolutions**](https://arxiv.org/abs/1511.07122?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*State-of-the-art models for semantic segmentation are based on adaptations
    of convolutional networks that had...*'
  prefs: []
  type: TYPE_NORMAL
- en: The module was tested on the Pascal VOC 2012 dataset. It proves that adding
    a context module to existing semantic segmentation architectures improves their
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/7b31b59519ee3e707e8990ce830359c1.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1511.07122)'
  prefs: []
  type: TYPE_NORMAL
- en: The front-end module trained in experimentation achieves 69.8% mean IoU on the
    VOC-2012 validation set and 71.3% mean IoU on the test set. The prediction accuracy
    of this model on different objects is shown below
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/69426a7b1e59ea33190b47e6bbf40b28.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1511.07122)'
  prefs: []
  type: TYPE_NORMAL
- en: 'DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution,
    and Fully Connected CRFs (TPAMI, 2017)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this paper the authors make the following contributions to the task of semantic
    segmentation with deep learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutions with upsampled filters for dense prediction tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Atrous spatial pyramid pooling (ASPP) for segmenting objects at multiple scales
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving localization of object boundaries by using DCNNs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully...**](https://arxiv.org/abs/1606.00915?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*In this work we address the task of semantic image segmentation with Deep
    Learning and make three main contributions...*'
  prefs: []
  type: TYPE_NORMAL
- en: The paper’s proposed DeepLab system achieves a 79.7% mIOU on the PASCAL VOC-2012
    semantic image segmentation task.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/01f79fab4b9e140c47232232a501d9ac.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1606.00915)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The paper tackles the main challenges of using deep CNNs in semantic segmentation,
    which include:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduced feature resolution caused by a repeated combination of max-pooling and
    downsampling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Existence of objects at multiple scales.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduced localization accuracy caused by DCNN’s invariance since an object-centric
    classifier requires invariance to spatial transformations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure](../Images/0b565a8a78333d41537f308caabde165.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1606.00915)'
  prefs: []
  type: TYPE_NORMAL
- en: Atrous convolution is applied by either upsampling the filters by inserting
    zeros or sparsely sampling the input feature maps. The second method entails subsampling
    the input feature maps by a factor equal to the atrous convolution rate r, and
    deinterlacing it to produce r^2 reduced resolution maps, one for each of the r×r
    possible shifts. After this, a standard convolution is applied to the immediate
    feature maps, interlacing them with the image’s original resolution.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/378c73a5645fb156805f9e89ebeb46e4.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1606.00915)'
  prefs: []
  type: TYPE_NORMAL
- en: Rethinking Atrous Convolution for Semantic Image Segmentation (2017)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This paper addresses two challenges (mentioned previously) in using DCNNs for
    semantic segmentation; reduced feature resolution that occurs when consecutive
    pooling operations are applied and the existence of objects at multiple scales.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587?source=post_page---------------------------)**'
  prefs: []
  type: TYPE_NORMAL
- en: '*In this work, we revisit atrous convolution, a powerful tool to explicitly
    adjust filter''s field-of-view as well as...*'
  prefs: []
  type: TYPE_NORMAL
- en: In order to address the first problem, the paper suggests the use of atrous
    convolution, also known as dilated convolution. It proposes solving the second
    problem using atrous convolution to enlarge the field of view and hence include
    multi-scale context.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/3c33eb86cdc88eede6b9bd18d33b2e50.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1706.05587.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The paper’s ‘DeepLabv3’ achieves a performance of 85.7% on the PASCAL VOC 2012
    test set without DenseCRF post-processing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e2214bef39b3eb6d6164ee06edb8551d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1706.05587.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation
    (ECCV, 2018)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This paper’s approach ‘DeepLabv3+’ achieves the test set performance of 89.0%
    and 82.1% without any post-processing on PASCAL VOC 2012 and Cityscapes datasets.
    This model is an extension of DeepLabv3 by adding a simple decoder module to refine
    the segmentation results.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Papers With Code : Encoder-Decoder with Atrous Separable Convolution for
    Semantic Image...**](https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*???? SOTA for Semantic Segmentation on PASCAL VOC 2012(Mean IoU metric)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/bb5dce103215c636b6e086a85413794f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1802.02611v3.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The paper implements two types of neural networks that use a spatial pyramid
    pooling module for semantic segmentation. One captures contextual information
    by pooling features at different resolutions, while the other obtain sharp object
    boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/2d03bc0ce0b093742ea7c906dc1fc8f7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1802.02611v3.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation
    (2019)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This paper proposes a joint upsampling module named Joint Pyramid Upsampling
    (JPU) to replace the dilated convolutions that consume a lot of time and memory.
    It works by formulating the function of extracting high-resolution maps as a joint
    upsampling problem.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Papers With Code : FastFCN: Rethinking Dilated Convolution in the Backbone
    for Semantic...**](https://paperswithcode.com/paper/fastfcn-rethinking-dilated-convolution-in-the?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*???? SOTA for Semantic Segmentation on PASCAL Context(mIoU metric)*'
  prefs: []
  type: TYPE_NORMAL
- en: This method achieves a performance of mIoU of 53.13% on the Pascal Context dataset
    and runs 3 times faster.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e0703ffa8618c145755c0fc9dab0e42d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1903.11816v1.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The method implements a fully-connected network(FCN) as the backbone while applying
    JPU to upsample the low-resolution final feature maps, resulting in high-resolution
    feature maps. Replacing the dilated convolutions with the JPU does not result
    in any loss of performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/410cb503d4162b164e84717edb16b04a.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1903.11816v1.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Joint sampling uses low-resolution target images and high-resolution guidance
    images. It then generates high-resolution target images by transferring the structure
    and details of the guidance image.
  prefs: []
  type: TYPE_NORMAL
- en: Improving Semantic Segmentation via Video Propagation and Label Relaxation (CVPR,
    2019)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This paper proposes a video-based method to scale the training set by synthesizing
    new training samples. This is aimed at improving the accuracy of semantic segmentation
    networks. It explores the ability of video prediction models to predict future
    frames in order to predict future labels.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Papers With Code : Improving Semantic Segmentation via Video Propagation
    and Label Relaxation**](https://paperswithcode.com/paper/improving-semantic-segmentation-via-video?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*???? SOTA for Semantic Segmentation on Cityscapes(Mean IoU metric)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/4deeb32092f38d2a5da84d20ff655615.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1812.01593v3.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: The paper demonstrates that training segmentation networks on datasets from
    synthesized data lead to improved prediction accuracy. The methods proposed in
    this paper achieve mIoUs of 83.5% on [Cityscapes](https://www.cityscapes-dataset.com/) and
    82.9% on [CamVid](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/7cf5ebc3ee5d35ffef467de891ea805c.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1812.01593v3.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The paper proposes two ways of predicting future labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Label Propagation (LP) **creating new training samples by pairing a propagated
    label with the original future frame'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Joint image-label Propagation (JP) **creating new training samples by pairing
    a propagated label with the corresponding propagated image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The paper has three main propositions; utilizing video prediction models to
    propagate labels to immediate neighbor frames, introducing joint image-label propagation
    to deal with the misalignment problem, and relaxing one-hot label training by
    maximizing the likelihood of the union of class probabilities along the boundary.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/d6168cf5a46fda0f9565c98783d0acd6.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/pdf/1812.01593v3.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Gated-SCNN: Gated Shape CNNs for Semantic Segmentation (2019)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This paper is the newest kid on the semantic segmentation block. The authors
    proposes a two-stream CNN architecture. In this architecture, shape information
    is processed as a separate branch. This shape stream processes only boundary related
    information. This is enforced by the model’s Gated Convolution Layer (GCL) and
    local supervision.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Gated-SCNN: Gated Shape CNNs for Semantic Segmentation**](https://arxiv.org/abs/1907.05740?source=post_page---------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Current state-of-the-art methods for image segmentation form a dense image
    representation where the color, shape and...*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e0c0fa9198af1bb5c32cd5ac5e5f2c1f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1907.05740)'
  prefs: []
  type: TYPE_NORMAL
- en: This model outperforms the DeepLab-v3+ by 1.5 % on mIoU and 4% in F-boundary
    score. The model has been evaluated using the Cityscapes benchmark. On smaller
    and thinner objects, the model achieves an improvement of 7% on IoU.
  prefs: []
  type: TYPE_NORMAL
- en: The table below shows the performance of the Gated-SCNN in comparison to other
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/bab352e5f44b2d7a50f1d9f0aac5364f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://arxiv.org/abs/1907.05740)'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should now be up to speed on some of the most common — and a couple of very
    recent — techniques for performing semantic segmentation in a variety of contexts.
  prefs: []
  type: TYPE_NORMAL
- en: The papers/abstracts mentioned and linked to above also contain links to their
    code implementations. We’d be happy to see the results you obtain after testing
    them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[A 2019 Guide to Object Detection](/2019/08/2019-guide-object-detection.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Object Detection with Luminoth](/2019/03/object-detection-luminoth.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automated Machine Learning in Python](/2019/01/automated-machine-learning-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Misconceptions About Semantic Segmentation Annotation](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Power of a Semantic Layer: A Data Engineer''s Guide](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Semantic Search with Vector Databases](https://www.kdnuggets.com/semantic-search-with-vector-databases)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Semantic Layer: The Backbone of AI-powered Data Experiences](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Reasons Why a Universal Semantic Layer is Beneficial to Your Data Stack](https://www.kdnuggets.com/2024/01/cube-6-reasons-why-a-universal-semantic-layer-is-beneficial)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
