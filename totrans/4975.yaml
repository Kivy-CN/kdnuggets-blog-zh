- en: 'K-Means & Other Clustering Algorithms: A Quick Intro with Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html](https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Nikos Koufos, [LearnDataSci](http://www.learndatasci.com/) Author.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Clustering is the grouping of objects together so that objects belonging in
    the same group (cluster) are more similar to each other than those in other groups
    (clusters). In this intro cluster analysis tutorial, we'll check out a few algorithms
    in Python so you can get a basic understanding of the fundamentals of clustering
    on a real dataset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: The Dataset
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'For the clustering problem, we will use the famous *Zachary’s Karate Club*
    dataset. The story behind the data set is quite simple: There was a Karate Club
    that had an administrator “John A” and an instructor “Mr. Hi” (both pseudonyms).
    Then a conflict arose between them, causing the students (Nodes) to split into
    two groups. One that followed John and one that followed Mr. Hi.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualization of Karate Club Clustering](../Images/f34f92e5fccc0a8debafe667480bffb6.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikipedia](https://en.wikipedia.org/wiki/Zachary''s_karate_club)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with Clustering in Python
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: But enough with the introductory talk, let’s get to main reason you are here,
    the code itself. First of all, you need to install both [scikit-learn](http://scikit-learn.org/)
    and [networkx](https://networkx.github.io/) libraries to complete this tutorial.
    If you don’t know how, the links above should help you. Also, feel free to follow
    along by grabbing the source code for this tutorial over on [Github](https://github.com/LearnDataSci/blog-post-resources/blob/master/Karate%20Club%20Clustering/Classifiers.py).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, the datasets that we want to examine are available in text form (JSON,
    Excel, simple txt file, etc.) but in our case, [networkx](https://networkx.github.io/)
    provide it for us. Also, to compare our algorithms, we want the truth about the
    members (who followed whom) which unfortunately is not provided. But with these
    two lines of code, you will be able to load the data and store the truth (from
    now on we will refer it as ground truth):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The final step of the data preprocessing, is to transform the graph into a
    matrix (desirable input for our algorithms). This is also quite simple:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Before we get going with the Clustering Techniques, I would like you to get
    a visualization on our data. So, let’s compile a simple function to do that:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入聚类技术之前，我希望你能对我们的数据有一个可视化。所以，让我们编写一个简单的函数来实现这一点：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: What that function does is to simply extract the number of clusters that are
    in our result and then assign a different color to each of them (up to 10 for
    the given time is fine) before plotting them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的作用是简单地提取结果中的聚类数量，然后为每个聚类分配不同的颜色（对于给定时间最多10个颜色即可），然后进行绘图。
- en: '![zacharys karate club cluster nodes](../Images/3f4fd1bd77a0f8eccd8114e9294a882b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![zacharys karate club cluster nodes](../Images/3f4fd1bd77a0f8eccd8114e9294a882b.png)'
- en: Clustering Algorithms
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类算法
- en: Some clustering algorithms will cluster your data quite nicely and others will
    end up failing to do so. That is one of the main reasons why clustering is such
    a difficult problem. But don’t worry, we won’t let you drown in an ocean of choices.
    We'll go through a few algorithms that are known to perform very well.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一些聚类算法会很好地对你的数据进行聚类，而另一些可能会失败。这是聚类问题如此困难的主要原因之一。但不用担心，我们不会让你在选择的海洋中迷失。我们将讨论几种已知表现非常好的算法。
- en: '**K-Means Clustering**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-均值聚类**'
- en: '![k-means clustering](../Images/2320bd58c7dced4d4b53fa875a2d2e61.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![k-means clustering](../Images/2320bd58c7dced4d4b53fa875a2d2e61.png)'
- en: 'Source: [github.com/nitoyon/tech.nitoyon.com](https://github.com/nitoyon/tech.nitoyon.com)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[github.com/nitoyon/tech.nitoyon.com](https://github.com/nitoyon/tech.nitoyon.com)
- en: 'K-means is considered by many the gold standard when it comes to clustering
    due to its simplicity and performance, and it''s the first one we''ll try out.
    When you have no idea at all what algorithm to use, K-means is usually the first
    choice. Bear in mind that K-means might under-perform sometimes due to its concept:
    spherical clusters that are separable in a way so that the mean value converges
    towards the cluster center. To simply construct and train a K-means model, use
    the follow lines:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: K-均值被许多人认为是聚类的黄金标准，因为它的简单性和性能，它是我们将尝试的第一个算法。当你完全不知道使用哪个算法时，K-均值通常是首选。请记住，K-均值有时可能表现不佳，因为它的概念是：球形聚类可分离，以便均值收敛到聚类中心。要简单地构建和训练一个
    K-均值模型，请使用以下几行：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Agglomerative Clustering**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚合聚类**'
- en: 'The main idea behind agglomerative clustering is that each node starts in its
    own cluster, and recursively merges with the pair of clusters that minimally increases
    a given linkage distance. The main advantage of agglomerative clustering (and
    hierarchical clustering in general) is that you don’t need to specify the number
    of clusters. That of course, comes with a price: performance. But, in scikit’s
    implementation, you can specify the number of clusters to assist the algorithm’s
    performance. To create and train an agglomerative model use the following code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合聚类的主要思想是每个节点从自己的聚类开始，然后递归地与增加最小链接距离的聚类对合并。聚合聚类（以及一般的层次聚类）的主要优点是你不需要指定聚类的数量。当然，这也有代价：性能。不过，在
    scikit 的实现中，你可以指定聚类的数量以帮助算法的性能。要创建和训练一个聚合模型，请使用以下代码：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Spectral**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**光谱**'
- en: 'The Spectral clustering technique applies clustering to a projection of the
    normalized Laplacian. When it comes to image clustering, spectral clustering works
    quite well. See the next few lines of Python for all the magic:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 光谱聚类技术将聚类应用于归一化拉普拉斯的投影。在图像聚类方面，光谱聚类效果非常好。请查看以下几行 Python 代码，了解所有的魔法：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Affinity Propagation**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**亲和传播**'
- en: 'Well this one is a bit different. Unlike the previous algorithms, you can see
    AF does not require the number of clusters to be determined before running the
    algorithm. AF, performs really well on several computer vision and biology problems,
    such as clustering pictures of human faces and identifying regulated transcripts:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法有些不同。与之前的算法不同，你会发现 AF 在运行算法之前不需要确定聚类的数量。AF 在处理许多计算机视觉和生物学问题上表现非常好，比如人脸图像聚类和识别调控转录本：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Metrics & Plotting
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标与绘图
- en: 'Well, it is time to choose which algorithm is more suitable for our data. A
    simple visualization of the result might work on small datasets, but imagine a
    graph with one thousand, or even ten thousand, nodes. That would be slightly chaotic
    for the human eye. So, let me show how to calculate the Adjusted Rand Score (ARS)
    and the Normalized Mutual Information (NMI):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you''re unfamiliar with these metrics, here''s a quick explanation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '**Normalized Mutual Information (NMI)**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Mutual Information of two random variables is a measure of the mutual dependence
    between the two variables. Normalized Mutual Information is a normalization of
    the Mutual Information (MI) score to scale the results between 0 (no mutual information)
    and 1 (perfect correlation). In other words, 0 means dissimilar and 1 means perfect
    match.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Adjusted Rand Score (ARS)**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Adjusted Rand Score on the other hand, computes a similarity measure between
    two clusters by considering all pairs of samples and counting pairs that are assigned
    in the same or different clusters in the predicted and true clusters. If that's
    a little weird to think about, have in mind that, for now, 0 is the lowest similarity
    and 1 is the highest.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: So, to get a combination of these metrics (the NMI and ARS), we simply calculate
    the average value of their sum. And remember, the higher the number, the better
    the result.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Below, I have plotted the score evaluation so we can get a better understanding
    of our results. We could plot them in many ways, as points, as a straight line,
    but I think a bar chart is the better choice for our case. To do so, just use
    the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see in the chart below, K-means and Agglomerative clustering have
    the best results for our dataset (best possible outcome). That of course, does
    not mean that Spectral and AF are low-performing algorithms, just that the did
    not fit in our data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![Clustering Score Evaluation](../Images/bc767fb2612fb0eac38cb7a8b335e5bb.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Well, that's it for this one!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for joining me in this clustering intro. I hope you found some value
    in seeing how we can easily manipulate a public dataset and apply several different
    clustering algorithms in Python. Let me know if you have any questions in the
    comments below, and feel free to attach a clustering project you've experimented
    with!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: Nikos Koufos** is a **[LearnDataSci](http://www.learndatasci.com/)**
    Author, postgraduate in Computer Science & Engineering at the University Ioannina,
    Greece, and Computer Science undergraduate teaching assistant.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://www.learndatasci.com/k-means-clustering-algorithms-python-intro/).
    Reposted with permission.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[Comparing Clustering Techniques: A Concise Technical Overview](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automatically Segmenting Data With Clustering](/2017/02/automatically-segmenting-data-clustering.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Clustering Key Terms, Explained](/2016/10/clustering-key-terms-explained.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hands-On with Unsupervised Learning: K-Means Clustering](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Quick Data Science Tips and Tricks to Learn SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
