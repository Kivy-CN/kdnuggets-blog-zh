- en: 'DINOv2: Self-Supervised Computer Vision Models by Meta AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/4aed096f2f8f55aecaf8fd2ae15116b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Bing Image Creator
  prefs: []
  type: TYPE_NORMAL
- en: Meta AI has just released open-source **DINOv2 models** the first method that
    uses self-supervised learning to train computer vision models. The DINOv2 models
    achieve results that match or are even better than the standard approach and models
    in the field.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The models achieved strong performance without the need to fine-tune which makes
    a perfect choice for many different computer vision tasks and applications. DINOv2
    can learn from various collections of images and features such as depth estimation
    without the need for explicit training thanks to the self-supervised training
    method.
  prefs: []
  type: TYPE_NORMAL
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/e00ff5643fe40dad69f9071451809fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: DINOv2: Self-Supervised Computer Vision Models by Meta AI'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. The Need for Self-Surprised Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1.1\. No fine-tuning is required
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Self-supervised learning is a powerful method used to train machine learning
    models without the need for large amounts of labeled data. DINOv2 models can be
    trained on image corpus without the need for related metadata, specific hashtag,
    or image caption. DinoV2 models, unlike several recent self-supervised learning
    approaches, do not necessitate fine-tuning, thus producing high-performance features
    for different computer vision applications.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2\. Overcoming human annotation limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the past few years, [image-text pre-training](https://arxiv.org/pdf/2210.09263.pdf)
    has become the predominant method for various computer vision applications. However,
    due to its dependence on human-labeled captions to learn the semantic meaning
    of images. This approach often overlooks crucial information that is not explicitly
    included in those captions. For example, a human label caption of a picture of
    a red table in a yellow room might be “A red wooden table”. This caption will
    miss some important information about the background, the position, and the size
    of the table. This will cause a lack of understanding of local information and
    will result in poor performance on tasks that require detailed localization information.
  prefs: []
  type: TYPE_NORMAL
- en: Also, the need for human labels and annotation will limit the amount of data
    that we can collect to train the models. This becomes much harder for certain
    applications for example annotating a cell requires a certain level of human expertise
    that will not be available at the scale required. Using a self-supervised training
    approach on cellular imagery opens the way for a more foundational model and as
    a result, will improve [biological discovery](https://arxiv.org/pdf/2209.07819.pdf).
    The same applies to similar advanced fields as the estimation of [animal density](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS1574954122001844&h=AT2tgMG2np9tKP9LiOPVXwDdkQAlcdDjdBj3xzNdDNvurZkHdzEwyCtKds5-08oeQcJISJklzVm6wKOElXMj9jnYGtK8GAmLPJtKJ4NNNF31w2aj0Nnl5hLcOrMZWWZpZyM).
  prefs: []
  type: TYPE_NORMAL
- en: Moving from DINO to DINOv2 required overcoming several challenges such as
  prefs: []
  type: TYPE_NORMAL
- en: Creating a large and curated training dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving the training algorithm and implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a functional distillation pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. From DINO to DINOv2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/6fab47982db50fa2316c10a565e7eb3c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: DINO v1 Vs v2 comparison of segmentation precision'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Creating a large, curated, and diverse image dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the main steps to building the DINOv2 is to train larger architectures
    and models to enhance the model's performance. However, larger models require
    large datasets to be efficiently trained. Since there were no large datasets available
    that meet the requirements researchers leveraged publicly crawled web data and
    built a pipeline to select only useful data as in [LASER](https://ai.facebook.com/blog/laser-multilingual-sentence-embeddings/).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, two main tasks should be done to be able to use these datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: Balance the data across different concepts and tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove irrelevant images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As this task can be accomplished manually, they curated a set of seed images
    from approximately 25 third-party datasets and expanded it by fetching images
    that are closely related to those seed images. This approach allowed them to produce
    a pertaining dataset of a total of 142 million images out of 1.2 billion images.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Algorithmic and technical improvements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although using larger models and datasets will lead to better results it comes
    with major challenges. Two of the main challenges are potential instability and
    remaining tractable during training. To make the training more stable DINOv2 includes
    additional regularization methods which were inspired by [similarity search](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F1806.03198&h=AT24VgJn3tbvHSzZQuScS7olEVE3k0ON36WLWv1MIwGvSVDzbGuRHljJq9PcTTD8B8E6JJ6TJcSlk7oKjUhlKM8azoaXKfbckLW-3dYD3G0nL6APxji3pnAGEO9AEF6-1eg)
    and [classification](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F2204.07118&h=AT0uq-EmQFlt_8QbvXmuLC9n7uqnix4IkQwsreJ9VO7xBtPZtlH06fddPmcB4kW_8RLWfSJJXwhfJBUNgLyn_HlgctcwgUYNZyNDSAxpDaz4ZQ1NJihZdK7v_-_o9D3q_1U)
    literature.
  prefs: []
  type: TYPE_NORMAL
- en: The training process of DINOv2 integrates the latest mixed-precision and distributed
    training implementations provided by the cutting-edge [PyTorch 2](https://l.facebook.com/l.php?u=https%3A%2F%2Fpytorch.org%2F&h=AT2AFAD7WXt6mwgAVGfHVYaqGLTztSUIiS8u9jHa6TcCViFrqmD0_RBFUkSTCKnRMBwqV3wn9nifClNi5aajRuwy6BHIADrrN5ecjMhzyZ9PFcYF2b_5IkDmi1hPLAYyb6o).
    This allowed faster implementation of the codes and using the same hardware for
    training DINO models resulted in double the speed and a third of the memory usage
    which allowed scaling in data and model size.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Decreasing inference time using models distillation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Running large models in inference requires powerful hardware which will limit
    the practical use of the methods for different use cases. To overcome this problem,
    researchers used model distillation to compress the knowledge of the large models
    into smaller ones. By utilizing this approach, researchers were able to condense
    high-performance architectures into smaller ones with negligible performance costs.
    This resulted in strong ViT-Small, ViT-Base, and ViT-Large models.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Getting Started with DINOv2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The training and evaluation code requires PyTorch 2.0 and [xFormers](https://github.com/facebookresearch/xformers)
    0.0.18 as well as many other 3rd party packages and also the code expects a Linux
    environment. The following instructions outline how to configure all necessary
    dependencies for training and evaluation purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: Install PyTorch using the instruction [here](https://pytorch.org/get-started/locally/).
    It is advised to install PyTorch with CUDA support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clone the DINOv2 repository using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Proceed to create and activate a Conda environment named "dinov2" using the
    provided environment definition:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: To install the dependencies required for this project, utilize the provided
    requirements.txt file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you can load the models using the code below:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, the release of DINOv2 models by Meta AI marks a significant milestone.
    The self-supervised learning approach used by DINOv2 models provides a powerful
    way to train machine learning models without the need for large amounts of labeled
    data. With the ability to achieve high accuarcy without the demand for fine-tuning,
    these models are suitable for various computer vision tasks and applications.
    Moreover, DINOv2 can learn from different collections of images and can learn
    from features such as depth estimation without explicit training. The availability
    of DINOv2 as an open-source model opens the doors for researchers and developers
    to explore new possibilities in computer vision tasks and applications.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[DINOv2: State-of-the-art computer vision models with self-supervised learning](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Youssef Rafaat](https://www.linkedin.com/in/youssef-hosni-b2960b135)** is
    a computer vision researcher & data scientist. His research focuses on developing
    real-time computer vision algorithms for healthcare applications. He also worked
    as a data scientist for more than 3 years in the marketing, finance, and healthcare
    domain.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Meta’s New Data Analyst Professional Certification Has Dropped!](https://www.kdnuggets.com/metas-new-data-analyst-professional-certification-has-dropped)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
