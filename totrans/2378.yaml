- en: 7 Techniques to Handle Imbalanced Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Ye Wu & Rick Radewagen**'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What have datasets in domains like, fraud detection in banking, real-time bidding
    in marketing or intrusion detection in networks, in common?
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Data used in these areas often have less than 1% of rare, but “interesting”
    events (e.g. fraudsters using credit cards, user clicking advertisement or corrupted
    server scanning its network). However, most machine learning algorithms do not
    work very well with imbalanced datasets. The following seven techniques can help
    you, to train a classifier to detect the abnormal class.
  prefs: []
  type: TYPE_NORMAL
- en: '![Imbalanced data image](../Images/c9cbb484ef13d59bff657b921d1b6624.png)'
  prefs: []
  type: TYPE_IMG
- en: 1\. Use the right evaluation metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying inappropriate evaluation metrics for model generated using imbalanced
    data can be dangerous. Imagine our training data is the one illustrated in graph
    above. If accuracy is used to measure the goodness of a model, a model which classifies
    all testing samples into “0” will have an excellent accuracy (99.8%), but obviously,
    this model won’t provide any valuable information for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, other alternative evaluation metrics can be applied such as:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Precision/Specificity: how many selected instances are relevant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recall/Sensitivity: how many relevant instances are selected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'F1 score: harmonic mean of precision and recall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MCC: correlation coefficient between the observed and predicted binary classifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AUC: relation between true-positive rate and false positive rate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Resample the training set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apart from using different evaluation criteria, one can also work on getting
    different dataset. Two approaches to make a balanced dataset out of an imbalanced
    one are under-sampling and over-sampling.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Under-sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Under-sampling balances the dataset by reducing the size of the abundant class.
    This method is used when quantity of data is sufficient. By keeping all samples
    in the rare class and randomly selecting an equal number of samples in the abundant
    class, a balanced new dataset can be retrieved for further modelling.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Over-sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On the contrary, oversampling is used when the quantity of data is insufficient.
    It tries to balance dataset by increasing the size of rare samples. Rather than
    getting rid of abundant samples, new rare samples are generated by using e.g.
    repetition, bootstrapping or SMOTE (Synthetic Minority Over-Sampling Technique)
    [1].
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is no absolute advantage of one resampling method over another.
    Application of these two methods depends on the use case it applies to and the
    dataset itself. A combination of over- and under-sampling is often successful
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Use K-fold Cross-Validation in the Right Way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is noteworthy that cross-validation should be applied properly while using
    over-sampling method to address imbalance problems.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that over-sampling takes observed rare samples and applies bootstrapping
    to generate new random data based on a distribution function. If cross-validation
    is applied after over-sampling, basically what we are doing is overfitting our
    model to a specific artificial bootstrapping result. That is why cross-validation
    should always be done before over-sampling the data, just as how feature selection
    should be implemented. Only by resampling the data repeatedly, randomness can
    be introduced into the dataset to make sure that there won’t be an overfitting
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Ensemble Different Resampled Datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The easiest way to successfully generalize a model is by using more data. The
    problem is that out-of-the-box classifiers like logistic regression or random
    forest tend to generalize by discarding the rare class. One easy best practice
    is building n models that use all the samples of the rare class and n-differing
    samples of the abundant class. Given that you want to ensemble 10 models, you
    would keep e.g. the 1.000 cases of the rare class and randomly sample 10.000 cases
    of the abundant class. Then you just split the 10.000 cases in 10 chunks and train
    10 different models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Imbalanced data image](../Images/ede2a66de5495ee740d8657b7358922b.png)'
  prefs: []
  type: TYPE_IMG
- en: This approach is simple and perfectly horizontally scalable if you have a lot
    of data, since you can just train and run your models on different cluster nodes.
    Ensemble models also tend to generalize better, which makes this approach easy
    to handle.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Resample with Different Ratios
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous approach can be fine-tuned by playing with the ratio between the
    rare and the abundant class. The best ratio  heavily depends on the data and the
    models that are used. But instead of training all models with the same ratio in
    the ensemble, it is worth trying to ensemble different ratios.  So if 10 models
    are trained, it might make sense to have a model that has a ratio of 1:1 (rare:abundant)
    and another one with 1:3, or even 2:1\. Depending on the model used this can influence
    the weight that one class gets.
  prefs: []
  type: TYPE_NORMAL
- en: '![Imbalanced data image](../Images/788030e4729ffd21c9d6304c5c969c8f.png)'
  prefs: []
  type: TYPE_IMG
- en: 6\. Cluster the abundant class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An elegant approach was proposed by Sergey on Quora [2]. Instead of relying
    on random samples to cover the variety of the training samples, he suggests clustering
    the abundant class in r groups, with r being the number of cases in r. For each
    group, only the medoid (centre of cluster) is kept. The model is then trained
    with the rare class and the medoids only.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Design Your Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the previous methods focus on the data and keep the models as a fixed component.
    But in fact, there is no need to resample the data if the model is suited for
    imbalanced data. The famous XGBoost is already a good starting point if the classes
    are not skewed too much, because it internally takes care that the bags it trains
    on are not imbalanced. But then again, the data is resampled, it is just happening
    secretly.
  prefs: []
  type: TYPE_NORMAL
- en: By designing a cost function that is penalizing wrong classification of the
    rare class more than wrong classifications of the abundant class, it is possible
    to design many models that naturally generalize in favour of the rare class. For
    example, tweaking an SVM to penalize wrong classifications of the rare class by
    the same ratio that this class is underrepresented.
  prefs: []
  type: TYPE_NORMAL
- en: '![Imbalanced data image](../Images/dd60769bef964bfc7705cdcd2c2baa54.png)'
  prefs: []
  type: TYPE_IMG
- en: Final Remarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is not an exclusive list of techniques, but rather a starting point to
    handle imbalanced data. There is no best approach or model suited for all problems
    and it is strongly recommended to try different techniques and models to evaluate
    what works best. Try to be creative and combine different approaches. It is also
    important, to be aware that in many domains (e.g. fraud detection, real-time-bidding),
    where imbalanced classes occur, the “market-rules” are constantly changing. So,
    check if past data might have become obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: '[1] [arxiv.org/pdf/1106.1813.pdf](https://arxiv.org/pdf/1106.1813.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set/answers/1144228?srid=h3G6o](https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set/answers/1144228?srid=h3G6o)'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Ye Wu**](https://www.linkedin.com/in/ye-wu-424350b6/) is Senior Data Analyst
    at FARFETCH. She has a background in Accounting and hands-on experience in Marketing
    and Sales Forecasting.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Rick Radewagen**](https://www.linkedin.com/in/radewagen/) is co-creator
    of Sled and aspiring Data Scientist with a background in Computer Science.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, August 31: The Complete Data Science Study Roadmap…](https://www.kdnuggets.com/2022/n35.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Overcoming Imbalanced Data Challenges in Real-World Scenarios](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Handle Missing Data with Scikit-learn''s Imputer Module](https://www.kdnuggets.com/how-to-handle-missing-data-with-scikit-learns-imputer-module)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Masked Arrays in NumPy to Handle Missing Data](https://www.kdnuggets.com/masked-arrays-in-numpy-to-handle-missing-data)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Handle Outliers in Dataset with Pandas](https://www.kdnuggets.com/how-to-handle-outliers-in-dataset-with-pandas)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
