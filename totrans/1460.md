# 机器学习中的偏见类型

> 原文：[https://www.kdnuggets.com/2019/08/types-bias-machine-learning.html](https://www.kdnuggets.com/2019/08/types-bias-machine-learning.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)![figure-name](../Images/932d35c45727fe84810f1f53cdde168b.png) https://www.infoq.com/presentations/unconscious-bias-machine-learning/

在我[之前的帖子](/2019/07/bias-machine-learning-bad.html)中，我谈到了机器学习中预期的偏见，这些偏见实际上可以帮助构建更好的模型。这里是后续帖子，展示一些应避免的偏见。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT

* * *

### 1\. 采样偏差

我们都必须考虑由于人为输入造成的训练数据中的采样偏差。机器学习模型是基于过去大量数据训练的预测引擎。它们被训练来**根据它们被训练来预测的内容**进行预测。这些预测的可靠性仅与收集和分析数据的人有关。决策者必须记住，如果在任何过程中涉及到人类，那么模型中的偏见可能性会更大。

用于训练的样本数据必须尽可能接近实际情况。许多因素可能从一开始就使样本产生偏差，这些原因在不同领域（如商业、安全、医疗、教育等）各不相同。

### 2\. 偏见偏差

这再次是由于人为输入所导致的。偏见发生是因为参与过程中存在的文化刻板印象。社会阶层、种族、国籍、性别可能会渗透到模型中，从而完全且**不公正**地扭曲你的模型结果。不幸的是，这可能是有意为之或在整个过程中被忽视的，也并不难以相信。

将这些因素纳入统计建模中用于研究目的或在某个时间点理解情况与预测在训练数据偏向某种种族、性别和/或国籍的人时谁应该获得贷款是完全不同的。

### 3\. 确认偏差

> 确认偏差，即通过寻找或解释与个人现有信念一致的信息来处理信息的倾向。*来源 [https://www.britannica.com/science/confirmation-bias](https://www.britannica.com/science/confirmation-bias)*

这是一个在心理学领域广泛研究的偏差，直接影响机器学习过程。如果预期使用者有一个希望通过机器学习确认的假设*（根据上下文可能有简单的方法来实现）*，参与建模过程的人可能会倾向于故意操控过程，以寻找那个答案。我个人认为这比我们想象的更常见，因为启发式地，很多行业中的我们可能会面临在开始过程之前就需要得到某个特定答案的压力，而不是单纯地看看数据实际反映了什么。

### 4\. 群体归因偏差

这种偏差来源于当你用包含某个群体不对称视角的数据来训练模型时。例如，在某个样本数据集中，如果某个性别的成功率高于另一个性别，或者某个种族的收入高于另一个种族，你的模型将倾向于相信这些虚假信息。在这些情况下存在标签偏差。实际上，这些标签本不应该进入模型中。用于理解和分析当前情况的样本不能仅仅作为训练数据使用，而没有经过适当的预处理以考虑任何潜在的不公正偏差。机器学习模型在社会中的应用越来越广泛，而普通人往往没有意识到，这使得群体归因偏差同样可能会不公正地惩罚某个人，因为没有采取必要措施来考虑训练数据中的偏差。

**相关**：

+   [数据素养：使用苏格拉底方法](/2019/06/data-literacy-socratic-method.html)

+   [所有模型都是错误的——这意味着什么？](/2019/06/all-models-are-wrong.html)

+   [70% 数据科学学习者犯的错误](/2019/08/what-data-science-learners-do-wrong.html)

### 更多相关话题

+   [停止学习数据科学以寻找目的，并为……寻找目的](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [90亿美元的人工智能失败，深度剖析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [是什么让 Python 成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每位数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)
