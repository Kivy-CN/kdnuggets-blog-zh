- en: 'Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程中的并行处理：Skeleton-of-Thought 技术
- en: 原文：[https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)
- en: '![Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique](../Images/70a8efecb730ab3d06fda0aab1695595.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![提示工程中的并行处理：Skeleton-of-Thought 技术](../Images/70a8efecb730ab3d06fda0aab1695595.png)'
- en: Image created by Author with Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 Midjourney 创建
- en: Key Takeaways
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要要点
- en: Skeleton-of-Thought (SoT) is an innovative prompt engineering technique that
    minimizes generation latency in Large Language Models (LLMs), enhancing their
    efficiency
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Skeleton-of-Thought**（SoT）是一种创新的提示工程技术，旨在最小化大型语言模型（LLMs）的生成延迟，提高其效率。'
- en: By creating a skeleton of the answer and then parallelly elaborating on each
    point, SoT emulates human thinking, promoting more reliable and on-target AI responses
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过创建答案的骨架并平行地详细阐述每个要点，SoT 模拟人类思维，促进更可靠和准确的 AI 响应。
- en: Implementing SoT in projects can significantly expedite problem-solving and
    answer generation, especially in scenarios demanding structured and efficient
    output from AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目中实施 SoT 可以显著加快问题解决和答案生成，特别是在需要 AI 结构化和高效输出的场景中。
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能。'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT。'
- en: '* * *'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: SoT is an initial attempt at data-centric optimization for efficiency, and reveal
    the potential of pushing LLMs to think more like a human for answer quality.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: SoT 是数据中心优化的初步尝试，揭示了推动 LLMs 更像人类思考的潜力，以提高答案质量。
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Prompt engineering is ground zero in the battle for leveraging the potential
    of generative AI. By devising effective prompts, and prompt-writing methodologies,
    we can guide AI in understanding the user's intentions and addressing these intentions
    effectively. One notable technique in this realm is the [Chain-of-Thought](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)
    (CoT) method, which instructs the generative AI model to elucidate its logic step-by-step
    while approaching a task or responding to a query. Building upon CoT, a new and
    promising technique called [Skeleton-of-Thought](https://arxiv.org/abs/2307.15337)
    (SoT) has emerged, which aims to refine the way AI processes and outputs information,
    in the hopes of consequently promoting more reliable and on-target responses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是利用生成 AI 潜力的起点。通过设计有效的提示和提示编写方法，我们可以引导 AI 理解用户的意图并有效地应对这些意图。在这个领域，一种值得注意的技术是
    [Chain-of-Thought](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)（CoT）方法，它指示生成
    AI 模型在处理任务或回应查询时逐步阐明其逻辑。在 CoT 的基础上，出现了一种新的有前景的技术 [Skeleton-of-Thought](https://arxiv.org/abs/2307.15337)（SoT），旨在改进
    AI 处理和输出信息的方式，从而促进更可靠和准确的响应。
- en: Understanding Skeleton-of-Thought
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Skeleton-of-Thought
- en: The genesis of Skeleton-of-Thought arises from the endeavor to minimize the
    generation latency inherent in large language models (LLMs). Unlike the sequential
    decoding approach, SoT emulates human thinking by first generating an answer's
    skeleton, then filling in the details in parallel, speeding up the inference process
    significantly​. When compared to CoT, SoT not only encourages a structured response
    but also efficiently organizes the generation process for enhanced performance
    in generative text systems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 思维骨架的起源来自于减少大型语言模型（LLMs）固有生成延迟的努力。与顺序解码方法不同，SoT通过首先生成答案的骨架，然后平行填充细节来模拟人类思维，从而显著加快推理过程。与CoT（链式思维）相比，SoT不仅鼓励结构化的响应，还有效组织生成过程，以提高生成文本系统的性能。
- en: '![SoT process depicted](../Images/307200c4823f5be0707a533f7e1b00ba.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![SoT过程示意图](../Images/307200c4823f5be0707a533f7e1b00ba.png)'
- en: '**Figure 1**: The Skeleton-of-Thought process (from [Skeleton-of-Thought: Large
    Language Models Can Do Parallel Decoding](https://arxiv.org/abs/2307.15337))'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**：思维骨架过程（来源：[思维骨架：大型语言模型可以进行并行解码](https://arxiv.org/abs/2307.15337)）'
- en: Implementing Skeleton-of-Thought
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施思维骨架
- en: As mentioned above, implementing SoT entails prompting the LLM to create a skeleton
    of the problem-solving or answer-generating process, followed by parallel elaboration
    on each point. This method can be particularly useful in scenarios requiring efficient
    and structured output from AI. For instance, when processing large datasets or
    answering complex queries, SoT can significantly expedite the response time, providing
    a streamlined workflow. By integrating SoT into existing prompt engineering strategies,
    prompt engineers can harness the potential of generative text more effectively,
    reliably, and quickly.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，实施SoT（思维骨架）涉及引导LLM（大型语言模型）创建问题解决或答案生成过程的骨架，然后对每一点进行平行详细阐述。这种方法在需要AI高效且结构化输出的场景中尤其有用。例如，在处理大规模数据集或回答复杂查询时，SoT可以显著加快响应时间，提供一个简化的工作流程。通过将SoT融入现有的提示工程策略，提示工程师可以更有效、可靠和快速地利用生成文本的潜力。
- en: Perhaps the best way to demonstrate SoT is by example prompts.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 也许展示SoT的最佳方式是通过示例提示。
- en: Example 1
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例1
- en: '**Question**: Describe the process of photosynthesis.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：描述光合作用的过程。'
- en: '**Skeleton**: Photosynthesis occurs in plants, involves converting light energy
    to chemical energy, creating glucose and oxygen.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**骨架**：光合作用发生在植物中，涉及将光能转化为化学能，生成葡萄糖和氧气。'
- en: '**Point-expansion**: Elaborate on light absorption, chlorophyll''s role, the
    Calvin cycle, and oxygen release.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要点扩展**：详细阐述光的吸收、叶绿素的作用、卡尔文循环和氧气释放。'
- en: Example 2
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例2
- en: '**Question**: Explain the causes of the Great Depression.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：解释大萧条的原因。'
- en: '**Skeleton**: The Great Depression was caused by stock market crash, bank failures,
    and reduced consumer spending.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**骨架**：大萧条是由于股市崩盘、银行倒闭和消费者支出减少引起的。'
- en: '**Point-expansion**: Delve into Black Tuesday, the banking crisis of 1933,
    and the impact of reduced purchasing power.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**要点扩展**：深入探讨“黑色星期二”、1933年的银行危机以及减少购买力的影响。'
- en: 'These examples demonstrate how SoT prompts facilitate a structured, step-by-step
    approach to answering complex questions. It also shows the workflow: pose a question
    or define a goal, give the LLM a broad or inclusive answer from which to elaborate
    supportive reasoning backward from, and then explicitly present those supportive
    reasoning issues and ask specifically prompt it to do so.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了SoT提示如何促进结构化的、逐步的回答复杂问题的方法。它还展示了工作流程：提出问题或定义目标，给LLM一个广泛或全面的答案作为阐述支持性推理的基础，然后明确地呈现这些支持性推理问题并特意提示其进行操作。
- en: '![XXX](../Images/4a81acb4e5bcaf7bdff079f5647fea03.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![XXX](../Images/4a81acb4e5bcaf7bdff079f5647fea03.png)'
- en: '**Figure 2**: The Skeleton-of-Though simplified process (Image by Author)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2**：思维骨架简化过程（作者图片）'
- en: While SoT offers a structured approach to problem-solving, it may not be suitable
    for all scenarios. Identifying the right use cases and understanding its implementation
    are important. Moreover, the transition from sequential to parallel processing
    might require a shift in system design or additional resources. However, overcoming
    these hurdles can unveil the potential of SoT in enhancing the efficiency and
    reliability of generative text tasks.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然SoT提供了一种结构化的问题解决方法，但它可能并不适用于所有场景。识别合适的应用案例和理解其实现是重要的。此外，从顺序处理到并行处理的过渡可能需要系统设计的调整或额外的资源。然而，克服这些障碍可以揭示SoT在提升生成文本任务的效率和可靠性方面的潜力。
- en: Conclusion
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The SoT technique, building on the CoT method, offers a new approach in prompt
    engineering. It not only expedites the generation process but also fosters a structured
    and reliable output. By exploring and integrating SoT in projects, practitioners
    can significantly enhance the performance and usability of generative text, driving
    towards more efficient and insightful solutions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SoT技术在CoT方法的基础上，提供了一种新的提示工程方法。它不仅加速了生成过程，还促进了结构化和可靠的输出。通过在项目中探索和整合SoT，实践者可以显著提升生成文本的性能和可用性，推动更高效和更具洞察力的解决方案。
- en: '[**Matthew Mayo**](https://www.linkedin.com/in/mattmayo13/) ([**@mattmayo13**](https://twitter.com/mattmayo13))
    holds a Master''s degree in computer science and a graduate diploma in data mining.
    As Editor-in-Chief of KDnuggets, Matthew aims to make complex data science concepts
    accessible. His professional interests include natural language processing, machine
    learning algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[**马修·梅奥**](https://www.linkedin.com/in/mattmayo13/) ([**@mattmayo13**](https://twitter.com/mattmayo13))
    拥有计算机科学硕士学位和数据挖掘研究生文凭。作为KDnuggets的总编辑，马修的目标是让复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、机器学习算法和探索新兴的人工智能。他致力于在数据科学社区中普及知识。马修从6岁起便开始编程。'
- en: More On This Topic
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多信息
- en: '[Parallel Processing Large File in Python](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python中的大文件并行处理](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)'
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，7月20日：机器学习算法解释…](https://www.kdnuggets.com/2022/n29.html)'
- en: '[Automating the Chain of Thought: How AI Can Prompt Itself to Reason](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动化思维链：人工智能如何自我提示进行推理](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
- en: '[The Art of Prompt Engineering: Decoding ChatGPT](https://www.kdnuggets.com/2023/06/art-prompt-engineering-decoding-chatgpt.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程的艺术：解码ChatGPT](https://www.kdnuggets.com/2023/06/art-prompt-engineering-decoding-chatgpt.html)'
- en: '[Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一些提升我们LLM模型的强大提示工程技巧](https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models)'
- en: '[Why Prompt Engineering is a Fad](https://www.kdnuggets.com/why-prompt-engineering-is-a-fad)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么提示工程是个潮流](https://www.kdnuggets.com/why-prompt-engineering-is-a-fad)'
