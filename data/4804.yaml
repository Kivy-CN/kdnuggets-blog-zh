- en: 'Only Numpy: Implementing GANs and Adam Optimizer using Numpy'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仅使用 Numpy：使用 Numpy 实现 GAN 和 Adam 优化器
- en: 原文：[https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html](https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html](https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Jae Duk Seo](https://jaedukseo.me/), Ryerson University**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Jae Duk Seo](https://jaedukseo.me/)，瑞尔森大学**'
- en: So today I was inspired by this blog post, “[Generative Adversarial Nets in
    TensorFlow](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)” and
    I wanted to implement GAN myself using Numpy. Here is the [original GAN paper](https://arxiv.org/abs/1406.2661) by [**@**goodfellow_ian](https://twitter.com/goodfellow_ian).
    Below is a gif of all generated images from Simple GAN.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我受到这篇博客 “[生成对抗网络在 TensorFlow 中的实现](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)”
    的启发，想要用 Numpy 自行实现 GAN。以下是 [**@**goodfellow_ian](https://twitter.com/goodfellow_ian)
    的 [原始 GAN 论文](https://arxiv.org/abs/1406.2661)。下面是从 Simple GAN 生成的所有图像的 gif。
- en: '![](../Images/53ba5fda91dd8892b617e9c6df1f6ef4.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53ba5fda91dd8892b617e9c6df1f6ef4.png)'
- en: Before reading along, please note that I won’t be covering too much of math.
    Rather the implementation of the code and results, I will cover the math maybe
    later. And I am using Adam Optimizer, however, I won’t go into explaining the
    implementation of Adam at this post.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续阅读之前，请注意我不会涉及太多数学内容。我会侧重于代码的实现和结果，数学部分可能会在以后讨论。我正在使用 Adam 优化器，但在这篇文章中我不会解释
    Adam 的实现。
- en: '**Forward Feed / Partial Back Propagation of Discriminator in GAN**'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GAN 中判别器的前向传播 / 部分反向传播**'
- en: '![](../Images/92e29f62d3b24fb4a204a0ef4016facb.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92e29f62d3b24fb4a204a0ef4016facb.png)'
- en: Again, I won’t go into too much details, but please note the Red Boxed Region
    called Data. For the Discriminator Network in GAN, that Data either can be Real
    Image or Fake Image Generated by the Generator Network. Our images are (1,784)
    vector of MNIST data set.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，我不会深入详细讲解，但请注意红色框中的数据区域。在 GAN 的判别网络中，这些数据可以是真实图像或由生成网络生成的虚假图像。我们的图像是 (1,784)
    的 MNIST 数据集向量。
- en: One more thing to note is **Red (L2A) and Blue (L2A)**. Red (L2A) is the final
    output of our Discriminator Network with Real Image as input. And Blue (L2A) is
    the final output of our Discriminator Network with Fake Image as input.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一点需要注意的是 **红色 (L2A) 和蓝色 (L2A)**。红色 (L2A) 是我们判别网络在真实图像输入下的最终输出。而蓝色 (L2A) 是我们判别网络在虚假图像输入下的最终输出。
- en: '![](../Images/621c48ea875a48847e0c6708185cdf6e.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/621c48ea875a48847e0c6708185cdf6e.png)'
- en: The way we implement this is by getting the real image, and fake data before
    putting them both into the network.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现方式是先获取真实图像和虚假数据，然后将它们输入网络中。
- en: Line 128 — Getting the Real Image Data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 128 行——获取真实图像数据
- en: Line 147 — Getting the Fake Image Data (Generated By Generator Network)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 147 行——获取虚假图像数据（由生成网络生成）
- en: Line 162 — Cost Function of our Discriminator Network.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 162 行——我们判别网络的成本函数。
- en: Also, please take note of the Blue Box Region, that is our cost function. Lets
    compare the cost function from the original paper, shown below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意蓝色框区域，即我们的成本函数。让我们比较一下原始论文中的成本函数，如下所示。
- en: '![](../Images/357d14a736bed4c408f787a3a28772b0.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/357d14a736bed4c408f787a3a28772b0.png)'
- en: Image[ from original Paper](https://arxiv.org/pdf/1406.2661.pdf)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片 [来自原始 论文](https://arxiv.org/pdf/1406.2661.pdf)
- en: The difference is the fact that we are putting a (-) negative sign in front
    of the first term log(L2A).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 区别在于我们在第一个术语 log(L2A) 前面加了一个 (-) 负号。
- en: '![](../Images/7e31bc8abaeb8cf6f9311a0630fd5b4d.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e31bc8abaeb8cf6f9311a0630fd5b4d.png)'
- en: Image [from Agustinus Kristiadi](https://wiseodd.github.io/techblog/2016/12/24/conditional-gan-tensorflow/)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片 [来自 Agustinus Kristiadi](https://wiseodd.github.io/techblog/2016/12/24/conditional-gan-tensorflow/)
- en: As seen above, in TensorFlow implementation we flip the signs if we want to
    Maximize some value, since TF auto differentiation only can Minimize.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，在 TensorFlow 实现中，我们如果要最大化某个值时会翻转符号，因为 TF 的自动微分只能最小化。
- en: I thought about this and I decided to implement in a similar way. Cuz I wanted
    to Maximize the chance of our discriminator guessing right for real image while
    Minimize the chance of our discriminator guessing wrong for fake images, and I
    wanted the sum of those values to balance out. However, I am not 100 % sure of
    this part as of yet, and will revisit this matter soon.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我考虑了这一点，决定以类似的方式实现。因为我想最大化我们判别器对真实图像正确猜测的机会，同时最小化判别器对假图像错误猜测的机会，并且希望这些值的总和能够平衡。然而，我对此部分尚未百分之百确定，会尽快重新审视这个问题。
- en: '**Forward Feed / Partial Back Propagation of Generator in GAN**'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**前向传播/生成器在GAN中的部分反向传播**'
- en: '![](../Images/271b5c892299581325f4b6e3aeaf0aea.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/271b5c892299581325f4b6e3aeaf0aea.png)'
- en: The Back Propagation process for generator network in GAN is bit complicated.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: GAN中生成器网络的反向传播过程有点复杂。
- en: Blue Box — Generated Fake Data from the Generator Network
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色框——来自生成器网络的生成假数据
- en: Green Box (Left Corner) — Discriminator Takes the Generated (Blue Box) Input
    and perform Forward Feed process
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色框（左下角）——判别器接收生成的（蓝色框）输入并执行前向传播过程
- en: Orange Box — Cost Function for Generator Network (Again we want to Maximize
    the chance of producing a Realistic Data)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 橙色框——生成器网络的成本函数（我们再次希望最大化生成真实数据的机会）
- en: Green Box (Right Corner) — Back Propagation Process for Generator Network, but
    we have to pass Gradient all the way Discriminator Network.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色框（右上角）——生成器网络的反向传播过程，但我们必须将梯度传递整个判别器网络。
- en: Below is the screen shot of implemented code.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是已实现代码的截图。
- en: '![](../Images/96b04dff34b3a7adb53d5c755e74d033.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96b04dff34b3a7adb53d5c755e74d033.png)'
- en: Standard Back propagation, nothing too special.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的反向传播，没什么特别的。
- en: '**Training Results: Failed Attempts**'
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**训练结果：失败的尝试**'
- en: I quickly realized that training GAN is extremely hard, even with Adam Optimizer,
    the network just didn’t seem to converge well. So, I will first present you all
    of the failed attempts and it’s network architectures.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我很快意识到训练GAN是非常困难的，即使使用Adam优化器，网络似乎也没有很好地收敛。因此，我将首先向你展示所有失败的尝试及其网络架构。
- en: '*1\. Generator, 2 Layers: 200, 560 Hidden Neurons, Input Vector Size 100*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*1\. 生成器，2层：200，560个隐藏神经元，输入向量大小100*'
- en: '![](../Images/db544005fa036d235b647301bdccc234.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db544005fa036d235b647301bdccc234.png)'
- en: '*2\. Generator, tanh() Activation, 2 Layers: 245, 960 Hidden Neurons, IVS 100*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*2\. 生成器，tanh() 激活函数，2层：245，960个隐藏神经元，输入向量大小100*'
- en: '![](../Images/05c0c34086bb1bc162a0b272c34575e8.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05c0c34086bb1bc162a0b272c34575e8.png)'
- en: '*3\. Generator, 3 Layers: 326, 356,412 Hidden Neurons, Input Vector Size 326*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*3\. 生成器，3层：326，356，412个隐藏神经元，输入向量大小326*'
- en: '![](../Images/fca293dfd8d27c1253a9645494278ece.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fca293dfd8d27c1253a9645494278ece.png)'
- en: '*4\. Generator, 2 Layers: 420, 640 Hidden Neurons, Input Vector Size 350*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*4\. 生成器，2层：420，640个隐藏神经元，输入向量大小350*'
- en: '![](../Images/9ed74e5863193c43fbbbbf3183f3a7a3.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ed74e5863193c43fbbbbf3183f3a7a3.png)'
- en: '*5\. Generator, 2 Layers: 660, 780 Hidden Neurons, Input Vector Size 600*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*5\. 生成器，2层：660，780个隐藏神经元，输入向量大小600*'
- en: '![](../Images/116ef5a027168b5c5a72867a841bc824.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/116ef5a027168b5c5a72867a841bc824.png)'
- en: '*6\. Generator, 2 Layers: 320, 480 Hidden Neurons, Input Vector Size 200*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*6\. 生成器，2层：320，480个隐藏神经元，输入向量大小200*'
- en: '![](../Images/7db05c1d1e38126e17de30b621ba359b.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7db05c1d1e38126e17de30b621ba359b.png)'
- en: So as seen above, all of them seems to learn something, but not really LOL.
    However, I was able to use one neat trick to generate an image that kinda look
    like numbers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，它们似乎都学到了一些东西，但实际上并没有哈哈。然而，我能够使用一个很棒的技巧生成一种看起来像数字的图像。
- en: '**Extreme Step Wise Gradient Decay**'
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**极端步进梯度衰减**'
- en: '![](../Images/1e679f74769b9f026b2939639a473771.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e679f74769b9f026b2939639a473771.png)'
- en: Above is a gif, I know the difference is subtle but trust me [I ain’t Rick Rollying](https://www.youtube.com/watch?v=dQw4w9WgXcQ)
    you. The trick is extremely simple and easy to implement. We first set the learning
    rate high rate for the first training, and after the first training we set the
    decay the learning rate by factor of 0.01\. And for unknown reason (I want to
    investigate further more into this), this seems to work.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上面是一个gif，我知道区别很细微，但相信我 [我不是在整蛊你](https://www.youtube.com/watch?v=dQw4w9WgXcQ)。这个技巧非常简单且易于实现。我们首先设定一个较高的学习率进行第一次训练，然后在第一次训练后将学习率衰减因子设置为0.01。由于某些未知原因（我想进一步调查），这似乎有效。
- en: But with a huge cost, I think we are converging to a ‘place’ where the network
    is only able to generate only certain kind of data. Meaning, from the uniform
    distribution of numbers between -1 and 1\. The Generator will only generate image
    that ONLY looks like a 3 or a 2 etc... But the key point here is that the network
    is not able to generate different set of numbers. This is evidence by the fact
    that, well, all of the numbers represented in the image look like 3.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 但代价非常高，我认为我们正趋向于一个“地方”，在这里网络只能生成某种类型的数据。也就是说，从-1到1之间的均匀分布的数字来看，生成器只会生成仅仅看起来像3或2等的图像……但关键点在于，网络无法生成不同的一组数字。这一点从图像中所有的数字都看起来像3这一事实中可以得到证明。
- en: However, it is some what reasonable image that looks like a number. So lets
    see some more results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些图像在某种程度上看起来像数字。所以，让我们再看看一些结果。
- en: '![](../Images/41b171e99a5b6f1692fa0017c4de70fe.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41b171e99a5b6f1692fa0017c4de70fe.png)'
- en: As seen above, as time goes on, the numbers become sharper. A good example is
    the generated image of 3 or 9.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，随着时间的推移，数字变得更加清晰。一个好的例子是生成的3或9的图像。
- en: '**Interactive Code**'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**互动代码**'
- en: '![](../Images/871598a423ec4616a213c205f4edb3a3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/871598a423ec4616a213c205f4edb3a3.png)'
- en: '*Update: I moved to Google Colab for Interactive codes! So you would need a
    google account to view the codes, also you can’t run read only scripts in Google
    Colab so make a copy on your play ground. Finally, I will never ask for permission
    to access your files on Google Drive, just FYI. Happy Coding!*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*更新：我已经迁移到 Google Colab 进行交互式代码演示！因此，您需要一个 Google 账号来查看代码，并且您不能在 Google Colab
    中运行只读脚本，所以请在您的工作区复制一份。最后，我绝不会请求访问您 Google Drive 上的文件，仅供参考。祝编程愉快！*'
- en: Please click[ here to access the interactive code, online.](https://colab.research.google.com/notebook#fileId=1D2kF1uBbJlVuglpuBSrw7A_3ws-Nvxk-)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请点击 [这里访问在线互动代码](https://colab.research.google.com/notebook#fileId=1D2kF1uBbJlVuglpuBSrw7A_3ws-Nvxk-)
- en: '![](../Images/b8e73637d1e0084468998e3abe489d41.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8e73637d1e0084468998e3abe489d41.png)'
- en: When running the code, make sure you are on the ‘main.py’ tap, as seen above
    in the Green Box. The program will ask you a random number for seeding, as seen
    in the Blue Box. After it will generate one image, to view that image please click
    on the click me tab above, Red Box.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码时，请确保您在“main.py”标签页上，如上图绿色框中所示。程序会要求您输入一个随机数作为种子，如蓝色框中所示。之后，它将生成一张图像，查看该图像请点击上方的“点击我”标签，红色框所示。
- en: '**Final Words**'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结语**'
- en: Training GAN to even partially work is a huge chunk of work, I want to investigate
    on more effective way of training of GAN’s. One last thing, shout out to [**@**replit](https://twitter.com/replit),
    these guys are amazing!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 GAN 即使是部分有效也是一项巨大的工作，我想研究更有效的 GAN 训练方法。最后，感谢 [**@**replit](https://twitter.com/replit)，这些家伙太棒了！
- en: If any errors are found, please email me at jae.duk.seo@gmail.com.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发现任何错误，请通过电子邮件联系我：jae.duk.seo@gmail.com。
- en: Meanwhile follow me on my twitter [here](https://twitter.com/JaeDukSeo), and
    visit [my website](https://jaedukseo.me/), or my [Youtube channel](https://www.youtube.com/c/JaeDukSeo) for
    more content. I also did comparison of Decoupled Neural Network [here if you](https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af) are
    interested.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请在我的 Twitter 上关注我 [这里](https://twitter.com/JaeDukSeo)，访问 [我的网站](https://jaedukseo.me/)，或我的
    [YouTube 频道](https://www.youtube.com/c/JaeDukSeo) 获取更多内容。如果您感兴趣，我还对解耦神经网络进行了比较
    [这里](https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af)。
- en: '**References**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., … & Bengio, Y. (2014). Generative adversarial nets. In *Advances in neural
    information processing systems* (pp. 2672–2680).
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., … & Bengio, Y. (2014). 生成对抗网络。见 *神经信息处理系统的进展* (第2672–2680页)。
- en: Free Online Animated GIF Maker — Make GIF Images Easily. (n.d.). Retrieved January
    31, 2018, from [http://gifmaker.me/](http://gifmaker.me/)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 免费在线 GIF 制作工具——轻松制作 GIF 图像。（无日期）。于 2018 年 1 月 31 日检索自 [http://gifmaker.me/](http://gifmaker.me/)
- en: Generative Adversarial Nets in TensorFlow. (n.d.). Retrieved January 31, 2018,
    from [https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow 中的生成对抗网络。（无日期）。于 2018 年 1 月 31 日检索自 [https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)
- en: J. (n.d.). Jrios6/Adam-vs-SGD-Numpy. Retrieved January 31, 2018, from [https://github.com/jrios6/Adam-vs-SGD-Numpy/blob/master/Adam%20vs%20SGD%20-%20On%20Kaggles%20Titanic%20Dataset.ipynb](https://github.com/jrios6/Adam-vs-SGD-Numpy/blob/master/Adam%20vs%20SGD%20-%20On%20Kaggles%20Titanic%20Dataset.ipynb)
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: J. (无日期). Jrios6/Adam-vs-SGD-Numpy。检索于2018年1月31日，来自 [https://github.com/jrios6/Adam-vs-SGD-Numpy/blob/master/Adam%20vs%20SGD%20-%20On%20Kaggles%20Titanic%20Dataset.ipynb](https://github.com/jrios6/Adam-vs-SGD-Numpy/blob/master/Adam%20vs%20SGD%20-%20On%20Kaggles%20Titanic%20Dataset.ipynb)
- en: Ruder, S. (2018, January 19). An overview of gradient descent optimization algorithms.
    Retrieved January 31, 2018, from [http://ruder.io/optimizing-gradient-descent/index.html#adam](http://ruder.io/optimizing-gradient-descent/index.html#adam)
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ruder, S. (2018年1月19日). 梯度下降优化算法概述。检索于2018年1月31日，来自 [http://ruder.io/optimizing-gradient-descent/index.html#adam](http://ruder.io/optimizing-gradient-descent/index.html#adam)
- en: E. (1970, January 01). Eric Jang. Retrieved January 31, 2018, from [https://blog.evjang.com/2016/06/generative-adversarial-nets-in.html](https://blog.evjang.com/2016/06/generative-adversarial-nets-in.html)
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: E. (1970年1月1日). Eric Jang. 检索于2018年1月31日，来自 [https://blog.evjang.com/2016/06/generative-adversarial-nets-in.html](https://blog.evjang.com/2016/06/generative-adversarial-nets-in.html)
- en: '**Bio: [Jae Duk Seo](https://jaedukseo.me/)** is a fourth year computer scientist
    at Ryerson University.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Jae Duk Seo](https://jaedukseo.me/)** 是赖尔森大学的四年级计算机科学学生。'
- en: '[Original](https://towardsdatascience.com/only-numpy-implementing-gan-general-adversarial-networks-and-adam-optimizer-using-numpy-with-2a7e4e032021).
    Reposted with permission.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/only-numpy-implementing-gan-general-adversarial-networks-and-adam-optimizer-using-numpy-with-2a7e4e032021).
    经许可转载。'
- en: '**Related:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容:**'
- en: '[Inside the Mind of a Neural Network with Interactive Code in Tensorflow](/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过Tensorflow中的交互式代码洞悉神经网络的思维](/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html)'
- en: '[Building Convolutional Neural Network using NumPy from Scratch](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用NumPy从零开始构建卷积神经网络](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
- en: '[How I Used CNNs and Tensorflow and Lost a Silver Medal in Kaggle Challenge](/2018/05/lost-silver-medal-kaggle-mercari-price-suggestion-challenge-cnns-tensorflow.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我如何使用CNN和Tensorflow，并在Kaggle挑战赛中失去了银牌](/2018/05/lost-silver-medal-kaggle-mercari-price-suggestion-challenge-cnns-tensorflow.html)'
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 为你的组织提供IT支持'
- en: '* * *'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Tuning Adam Optimizer Parameters in PyTorch](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在PyTorch中调整Adam优化器参数](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90亿美元AI失败的分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学学习统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
