- en: Why are Machine Learning Projects so Hard to Manage?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/machine-learning-projects-manage.html](https://www.kdnuggets.com/2020/02/machine-learning-projects-manage.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Lukas Biewald](https://twitter.com/l2k), Founder/CEO of Weights and Biases**.'
  prefs: []
  type: TYPE_NORMAL
- en: I’ve watched lots of companies attempt to deploy machine learning — some succeed
    wildly, and some fail spectacularly. One constant is that machine learning teams
    have a hard time setting goals and setting expectations. Why is this?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cea8236a453e807ed5a339d72d25f435.png)'
  prefs: []
  type: TYPE_IMG
- en: 1\. It’s really hard to tell in advance what’s hard and what’s easy.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Is it harder to beat Kasparov at chess or pick up and physically move the chess
    pieces? Computers beat the world champion chess player over twenty years ago,
    but reliably grasping and lifting objects is still an unsolved research problem.
    Humans are not good at evaluating what will be hard for AI and what will be easy.
    Even within a domain, performance can vary wildly. What’s good accuracy for predicting
    sentiment? On movie reviews, there is a lot of text, and writers tend to be fairly
    clear about what they think and these days 90–95% accuracy is expected. On Twitter,
    two humans might only agree on the sentiment of a tweet 80% of the time. It might
    be possible to get 95% accuracy on the sentiment of tweets about certain airlines
    by just always predicting that the sentiment is going to be negative.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics can also increase a lot in the early days of a project and then suddenly
    hit a wall. I once ran a Kaggle competition where thousands of people competed
    around the world to model my data. In the first week, the accuracy went from 35%
    to 65% percent, but then over the next several months it never got above 68%.
    68% accuracy was clearly the limit on the data with the best most up-to-date machine
    learning techniques. Those people competing in the Kaggle competition worked incredibly
    hard to get that 68% accuracy and I’m sure felt like it was a huge achievement.
    But for most use cases, 65% vs. 68% is totally indistinguishable. If that had
    been an internal project, I would have definitely been disappointed by the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: My friend Pete Skomoroch was recently telling me how frustrating it was to do
    engineering standups as a data scientist working on machine learning. Engineering
    projects generally move forward, but machine learning projects can completely
    stall. It’s possible, even common, for a week spent on modeling data to result
    in no improvement whatsoever.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/344aa757e20c4a4556bec5285d52dfaf.png)'
  prefs: []
  type: TYPE_IMG
- en: ‍
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Machine Learning is prone to fail in unexpected ways.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning generally works well as long as you have lots of training data
    *and* the data you’re running on in production looks a lot like your training
    data. Humans are so good at generalizing from training data that we have terrible
    intuitions about this. I built a little robot with a camera and a vision model
    trained on the millions of images of ImageNet, which were taken off the web. I
    preprocessed the images on my robot camera to look like the images from the web
    but the accuracy was much worse than I expected. Why? Images off the web tend
    to frame the object in question. My robot wouldn’t necessarily look right at an
    object in the same way a human photographer would. Humans likely not even notice
    the difference but modern deep learning networks suffered a lot. There are ways
    to deal with this phenomenon, but I only noticed it because the degradation in
    performance was so jarring that I spent a lot of time debugging it.
  prefs: []
  type: TYPE_NORMAL
- en: Much more pernicious are the subtle differences that lead to degraded performance
    that are hard to spot. Language models trained on the New York Times don’t generalize
    well to social media texts. We might expect that. But apparently, models trained
    on text from 2017 experience degraded performance on text written in 2018\. Upstream
    distributions shift over time in lots of ways. Fraud models break down completely
    as adversaries adapt to what the model is doing.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Machine Learning requires lots and lots of relevant training data.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Everyone knows this, and yet it’s such a huge barrier. Computer vision can do
    amazing things, provided you are able to collect and label a massive amount of
    training data. For some use cases, the data is a free byproduct of some business
    process. This is where machine learning tends to work really well. For many other
    use cases, training data is incredibly expensive and challenging to collect. A
    lot of medical use cases seem perfect for machine learning — crucial decisions
    with lots of weak signals and clear outcomes — but the data is locked up due to
    important privacy issues or not collected consistently in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Many companies don’t know where to start investing in collecting training data.
    It’s a significant effort and it’s hard to predict a priori how well the model
    will work.
  prefs: []
  type: TYPE_NORMAL
- en: What are the best practices to deal with these issues?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**1\. Pay a lot of attention to your training data.**'
  prefs: []
  type: TYPE_NORMAL
- en: Look at the cases where the algorithm is misclassifying data that it was trained
    on. These are almost always mislabels or strange edge cases. Either way, you really
    want to know about them. Make everyone working on building models look at the
    training data and label some of the training data themselves. For many use cases,
    it’s very unlikely that a model will do better than the rate at which two independent
    humans agree.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Get something working end-to-end right away, then improve one thing at
    a time.**'
  prefs: []
  type: TYPE_NORMAL
- en: Start with the simplest thing that might work and get it deployed. You will
    learn a ton from doing this. Additional complexity at any stage in the process
    always improves models in research papers, but it seldom improves models in the
    real world. Justify every additional piece of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Getting something into the hands of the end-user helps you get an early read
    on how well the model is likely to work and it can bring up crucial issues like
    a disagreement between what the model is optimizing and what the end-user wants.
    It also may make you reassess the kind of training data you are collecting. It’s
    much better to discover those issues quickly.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Look for graceful ways to handle the inevitable cases where the algorithm
    fails.**'
  prefs: []
  type: TYPE_NORMAL
- en: Nearly all machine learning models fail a fair amount of the time, and how this
    is handled is absolutely crucial. Models often have a reliable confidence score
    that you can use. With batch processes, you can build human-in-the-loop systems
    that send low confidence predictions to an operator to make the system work reliably
    end to end and collect high-quality training data. With other use cases, you might
    be able to present low confident predictions in a way that potential errors are
    flagged or are less annoying to the end-user.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s an example of a failure that wasn’t handled gracefully. Microsoft hadn’t
    predicted how quickly their Tay bot would learn bad behavior from trolls on Twitter.
  prefs: []
  type: TYPE_NORMAL
- en: ‍![](../Images/82515c2a691c6c6dc75ff4e3cf64a1ee.png)
  prefs: []
  type: TYPE_NORMAL
- en: ‍
  prefs: []
  type: TYPE_NORMAL
- en: What’s Next?‍
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The original goal of machine learning was mostly around smart decision making,
    but more and more we are trying to put machine learning into products we use.
    As we start to rely more and more on machine learning algorithms, machine learning
    becomes an engineering discipline as much as a research topic. I’m incredibly
    excited about the opportunity to build completely new kinds of products but worried
    about the lack of tools and best practices. So much so that I started a company
    to help with this called [Weights and Biases](http://wandb.com/). If you’re interested
    in learning more, check out what we’re up to.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks, [Yan-David Erlich](https://medium.com/u/6e3bf872645a?source=post_page-----8e9b9cf49641----------------------), [James
    Cham](https://medium.com/u/86a8b1c606a8?source=post_page-----8e9b9cf49641----------------------), [Noga
    Leviner](https://medium.com/u/585926b0286?source=post_page-----8e9b9cf49641----------------------),
    and [Carey Phelps](https://medium.com/u/569a4293d9d2?source=post_page-----8e9b9cf49641----------------------) for
    reading early versions of this and [Peter Skomoroch](https://medium.com/u/5f3569495efc?source=post_page-----8e9b9cf49641----------------------) for
    getting me thinking about this topic.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio:** [Lukas Biewald](https://twitter.com/l2k) is the founder of Weights
    & Biases, and previously, the founder of Figure Eight (formerly CrowdFlower).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[9 Reasons why your machine learning project will fail](https://www.kdnuggets.com/2018/07/why-machine-learning-project-fail.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Turn your Data Science Projects into a Success](https://www.kdnuggets.com/2017/07/olavlaudy-turn-data-science-projects-into-success.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Reasons Why Big Data, Data Science, Analytics Initiatives Fail](https://www.kdnuggets.com/2016/12/top-reasons-big-data-science-analytics-fail.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Hard Coding in a Data Science Project - Use Config Files Instead](https://www.kdnuggets.com/2023/06/stop-hard-coding-data-science-project-config-files-instead.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Hard Python Coding Interview Questions For Data Science](https://www.kdnuggets.com/2023/03/3-hard-python-coding-interview-questions-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Hard is it to Get into FAANG Companies](https://www.kdnuggets.com/2023/05/hard-get-faang-companies.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Want to Become a Data Scientist? Part 1: 10 Hard Skills You Need](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why are More Developers Using Python for Their Machine Learning Projects?](https://www.kdnuggets.com/2022/01/developers-python-machine-learning-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 10 MLOps Tools to Optimize & Manage Machine Learning Lifecycle](https://www.kdnuggets.com/2022/10/top-10-mlops-tools-optimize-manage-machine-learning-lifecycle.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
