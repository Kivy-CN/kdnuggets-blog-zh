["```py\n$ pip install fastapi uvicorn\n\n```", "```py\n$ pip install tensorflow==2.0.0\n\n```", "```py\n$ sudo snap install --classic heroku\n\n```", "```py\n$ brew tap heroku/brew && brew install heroku\n\n```", "```py\n$ sudo apt install git-all\n\n```", "```py\ngit --version\n\n```", "```py\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nimport re\n\n```", "```py\ndata = pd.read_csv('archive/Sentiment.csv')\n\n# Keeping only the neccessary columns\ndata = data[['text','sentiment']]\n\n```", "```py\ndef preProcess_data(text):\n   text = text.lower()\n   new_text = re.sub('[^a-zA-z0-9\\s]','',text)\n   new_text = re.sub('rt', '', new_text)\n   return new_text\n\ndata['text'] = data['text'].apply(preProcess_data)\n\n```", "```py\nmax_fatures = 2000\n\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X, 28) \n\nY = pd.get_dummies(data['sentiment']).values\n\n```", "```py\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20)\n\n```", "```py\nembed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.3, recurrent_dropout=0.2, return_sequences=True))\nmodel.add(LSTM(128,recurrent_dropout=0.2))\nmodel.add(Dense(3,activation='softmax'))\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n\n```", "```py\nbatch_size = 512\n\nmodel.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, validation_data=(X_test, Y_test))\n\n```", "```py\nmodel.save('sentiment.h5')\n\n```", "```py\nimport numpy as np\nfrom fastapi import FastAPI, Form\nimport pandas as pd\nfrom starlette.responses import HTMLResponse\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nimport re\n\n```", "```py\napp = FastAPI()\n\n@app.get('/predict', response_class=HTMLResponse)\ndef take_inp():\n    return '''\n        <form method=\"post\">\n        <input maxlength=\"28\" name=\"text\" type=\"text\" value=\"Text Emotion to be tested\" />\n        <input type=\"submit\" />'''\n\n```", "```py\nuvicorn app:app --reload\n\n```", "```py\ndata = pd.read_csv('archive/Sentiment.csv')\ntokenizer = Tokenizer(num_words=2000, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\n\ndef preProcess_data(text):\n    text = text.lower()\n    new_text = re.sub('[^a-zA-z0-9\\s]','',text)\n    new_text = re.sub('rt', '', new_text)\n    return new_text\n\ndef my_pipeline(text):\n    text_new = preProcess_data(text)\n    X = tokenizer.texts_to_sequences(pd.Series(text_new).values)\n    X = pad_sequences(X, maxlen=28)\n    return X\n\n```", "```py\n@app.post('/predict')\ndef predict(text:str = Form(...)):\n    clean_text = my_pipeline(text) #clean, and preprocess the text through pipeline\n    loaded_model = tf.keras.models.load_model('sentiment.h5') #load the saved model \n    predictions = loaded_model.predict(clean_text) #predict the text\n    sentiment = int(np.argmax(predictions)) #calculate the index of max sentiment\n    probability = max(predictions.tolist()[0]) #calulate the probability\n    if sentiment==0:\n         t_sentiment = 'negative' #set appropriate sentiment\n    elif sentiment==1:\n         t_sentiment = 'neutral'\n    elif sentiment==2:\n         t_sentiment='postive'\n    return { #return the dictionary for endpoint\n         \"ACTUALL SENTENCE\": text,\n         \"PREDICTED SENTIMENT\": t_sentiment,\n         \"Probability\": probability\n    }\n\n```", "```py\n$ uvicorn app:app --reload\n\n```", "```py\n@app.get('/')\ndef basic_view():\n    return {\"WELCOME\": \"GO TO /docs route, or /post or send post request to /predict \"}\n\n```", "```py\npython-3.6.13\n\n```", "```py\nweb: uvicorn app:app --host=0.0.0.0 --port=${PORT:-5000}\n\n```", "```py\nsklearn\nfastapi\npandas\npydantic\ntensorflow==2.0.0\nuvicorn\nh5py==2.10.0\npython-multipart\n\n```", "```py\n__pycache__\nmodel.py\n\n```", "```py\n$ git init\n\n```", "```py\n$ git add -A\n\n```", "```py\n$ git commit -m \"first commit\"\n\n```", "```py\n$ git branch -M main\n\n```", "```py\n$ git remote add origin https://github.com/username/reponame.git\n\n```", "```py\n$ git push -u origin main\n\n```", "```py\nimport requests #install using pip if not already\n\nurl = 'https://sentiment-analysis-gopdebate.herokuapp.com/predict'\ndata = {'text':'Testing Sentiments'} #test is the function params\n\nresp = requests.post(url, data=data) #post request\nprint(resp.content)\n\n```", "```py\n$ curl -X 'POST' \\\n   'https://sentiment-analysis-gopdebate.herokuapp.com/predict' \\\n   -H 'accept: application/json' \\\n   -H 'Content-Type: application/x-www-form-urlencoded' \\\n   -d 'text=WORST%20SHOW%20EVER\n\n```"]