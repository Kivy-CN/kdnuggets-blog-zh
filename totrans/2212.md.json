["```py\nimport numpy as np\n\ndef gradient_descent(X, y, learning_rate=0.01, num_iterations=1000):\n    m, n = X.shape\n    theta = np.zeros(n)  # Initialize weights/parameters\n    cost_history = []  # To store values of the cost function over iterations\n\n    for _ in range(num_iterations):\n        predictions = X.dot(theta)\n        errors = predictions - y\n        gradient = (1/m) * X.T.dot(errors)\n        theta -= learning_rate * gradient\n\n        # Compute and store the cost for current iteration\n        cost = (1/(2*m)) * np.sum(errors**2)\n        cost_history.append(cost)\n\n    return theta, cost_history\n\n# Example usage:\n# Assuming X is your feature matrix with m samples and n features\n# and y is your target vector with m samples.\n# Note: You should add a bias term (column of ones) to X if you want a bias term in your model.\n\n# Sample data\nX = np.array([[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]])\ny = np.array([2, 4, 5, 4, 5])\n\ntheta, cost_history = gradient_descent(X, y)\n\nprint(\"Optimal parameters:\", theta)\nprint(\"Cost history:\", cost_history)\n```"]