# 什么是层次聚类？

> 原文：[https://www.kdnuggets.com/2019/09/hierarchical-clustering.html](https://www.kdnuggets.com/2019/09/hierarchical-clustering.html)

[评论](#comments)

**什么是聚类？**

**聚类**是一种技术，将相似的对象分组，使得同一组中的对象彼此之间比其他组中的对象更相似。相似对象的组称为**集群**。

![图](../Images/d864c96c4c7666187cbf8c49c37b343e.png)

聚类的数据点

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT管理

* * *

数据科学家需要了解5种流行的聚类算法：

1.  **K均值聚类**：要了解更多信息，请点击[这里](https://towardsdatascience.com/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3)。

1.  **层次聚类**：我们将在这里详细讨论该算法。

1.  **均值漂移聚类：**要了解更多信息，请点击[这里](https://spin.atomicobject.com/2015/05/26/mean-shift-clustering/)。

1.  **基于密度的空间聚类应用与噪声（DBSCAN）：**要了解更多信息，请点击[这里](https://en.wikipedia.org/wiki/DBSCAN)。

1.  **期望最大化（EM）聚类使用高斯混合模型（GMM）：**要了解更多信息，请点击[这里](https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e)。

**层次聚类算法**

也称为**层次集群分析**或**HCA**，是一种无监督聚类算法，涉及创建具有从上到下主导排序的集群。

例如：我们硬盘上的所有文件和文件夹都是按层次结构组织的。

该算法将相似的对象分组为称为***集群***的组。最终结果是一组集群或组，其中每个集群彼此不同，每个集群内的对象相互之间大致相似。

这种聚类技术分为两种类型：

1.  聚合层次聚类

1.  分裂层次聚类

### **聚合层次聚类**

聚合层次聚类是最常见的层次聚类类型，用于根据对象的相似性将对象分组。它也被称为AGNES（聚合嵌套）。这是一种“[自下而上](https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design)”的方法：***每个观察点从自己的集群开始，随着层次结构的上升，集群逐对合并。***

**它是如何工作的？**

1.  将每个数据点做成单点簇 → 形成N个簇

1.  取两个最接近的数据点，并将它们合并为一个簇 → 形成N-1个簇

1.  取两个最接近的簇，并将它们合并为一个簇 → 形成N-2个簇。

1.  重复第3步，直到只剩下一个簇。

请查看下图的Agglomerative Hierarchical Clustering（凝聚层次聚类）的可视化表示，以便更好地理解：

![图](../Images/2d5c84fed59033b3130bd242b7e92738.png)

[凝聚层次聚类](https://gfycat.com/somelonelycaterpillar)

有几种方法可以测量簇之间的距离，以决定聚类规则，这些方法通常被称为链接方法。一些常见的链接方法包括：

+   **完全链接：** 两个簇之间的距离定义为每个簇中两个点之间的*最长*距离。

+   **单链接：** 两个簇之间的距离定义为每个簇中两个点之间的*最短*距离。此链接方法可用于检测数据集中可能的异常值，因为它们会在最后合并。

+   **平均链接：** 两个簇之间的距离定义为一个簇中每个点到另一个簇中每个点的平均距离。

+   **质心链接：** 找到簇1和簇2的质心，然后计算两个质心之间的距离，再进行合并。

选择链接方法完全取决于你，没有一种固定的方法能始终给出良好的结果。不同的链接方法会导致不同的簇。

进行这些操作的目的是展示层次聚类的工作方式，它保持了我们经过此过程的记忆，而这种记忆存储在**树状图**中。

**树状图是什么？**

Dendrogram（树状图）是一种显示不同数据集之间层次关系的树状图。

如前所述，树状图包含层次聚类算法的记忆，因此通过查看树状图，你可以知道簇是如何形成的。

![图](../Images/21be7560a8fe5a22873d0b7907c2d922.png)

[树状图](https://giphy.com/explore/dendrogram)

**注意：-**

1.  数据点之间的距离表示不相似性。

1.  块的高度表示簇之间的距离。

从上图可以观察到，最初P5和P6这两个彼此最接近的点被合并成一个簇，然后P4被合并到同一簇（C2）。接着P1和P2合并成一个簇，然后P0被合并到同一簇（C4）。现在P3被合并到簇C2中，最终两个簇被合并为一个。

**树状图的部分**

![图](../Images/61b86c9b3b38eb3d02057b488973efc2.png)

[图片来源](https://www.statisticshowto.datasciencecentral.com/hierarchical-clustering/)

一个树状图可以是列图（如下面的图像）或行图。一些树状图是圆形的或具有流动形状，但软件通常会生成行图或列图。无论形状如何，基本图形由相同的部分组成：

+   ***分支***是按照相似性（或不相似性）排列的。相近高度的分支彼此相似；高度不同的分支则不相似——**高度差异越大，不相似度越高。**

+   每个分支都有一个或多个***叶子***。

+   叶子A、B和C彼此之间比与叶子D、E或F之间更相似。

+   叶子D和E彼此之间比与叶子A、B、C或F之间更相似。

+   叶子F与其他所有叶子有显著不同。

从理论上讲，一个分支可以有无限多个叶子。然而，叶子越多，图形用肉眼阅读就会越困难。

**一个可能会让你感兴趣的问题是，如何决定何时停止合并簇？**

你用一条水平线切割树状图，切割高度应使得线在不与合并点相交的情况下，能够上下移动最大距离。

例如，在下图中，L3能够在不与合并点相交的情况下上下移动最大距离。因此，我们画一条水平线，它所交叉的垂直线的数量就是最佳的簇数。

![图](../Images/e468c33d0dae5aa5b033ffad73e4c21b.png)

[选择最佳的簇数。](https://www.google.com/imgres?imgurl=https%3A%2F%2Fars.els-cdn.com%2Fcontent%2Fimage%2F3-s2.0-B978012811654800004X-f04-03-9780128116548.jpg&imgrefurl=https%3A%2F%2Fwww.sciencedirect.com%2Ftopics%2Fcomputer-science%2Fagglomerative-algorithm&docid=4v7-F4YYs4wofM&tbnid=ZDsxb9kaKxWmWM%3A&vet=12ahUKEwizmMT5vtTkAhWHad4KHXc5ByQ4rAIQMygvMC96BAgBEDE..i&w=314&h=226&bih=691&biw=1440&q=dendrogram%20explained&ved=2ahUKEwizmMT5vtTkAhWHad4KHXc5ByQ4rAIQMygvMC96BAgBEDE&iact=mrc&uact=8)

**此情况下的簇数 = 3。**

### 分裂型层级聚类

在*分裂型*或DIANA（分裂分析聚类）中，这是一种自上而下的聚类方法，我们将所有观测值分配到一个单一的簇中，然后将该簇划分为两个最不相似的簇。最后，我们对每个簇递归进行操作，直到每个观测值有一个簇。所以这种聚类方法正好与凝聚型聚类相反。

![图](../Images/fcda2a4b265cb4b2bf061a6726d9e62c.png)

[图片来源](https://www.researchgate.net/figure/Conceptual-dendrogram-for-agglomerative-and-divisive-Hierarchical-based-clustering-19_fig2_321399805)

有证据表明，在某些情况下，分裂算法产生的层级结构比凝聚算法更准确，但在概念上更复杂。

在聚合层次聚类和分裂层次聚类中，用户需要指定期望的簇数作为终止条件（停止合并的时机）。

### 衡量簇的优良性

好的，有很多方法可以衡量，可能最流行的是`Dunn's Index`。Dunn's指数是最小簇间距离与最大簇内直径的比率。簇的直径是其两个最远点之间的距离。为了获得良好分离和紧凑的簇，你应该追求更高的Dunn's指数。

现在让我们使用聚合层次聚类算法实现一个使用案例。数据集包含一个特定购物中心的客户详细信息以及他们的消费得分。

你可以从[这里](https://www.kaggle.com/shwetabh123/mall-customers)下载数据集。

让我们从导入3个基本库开始：

```py
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

加载数据集：

```py
dataset = pd.read_csv('/.../Mall_Customers.csv')
```

![图](../Images/daaa2201747eb4c09b8c92b61d618025.png)

原始数据集

所以我们的目标是根据客户的消费得分进行聚类。

在所有特征中，`CustomerID` 和 `Genre` 是无关字段，可以删除，并通过仅选择 `Age` 和 `Annual Income` 来创建一个独立变量矩阵。

```py
X = dataset.iloc[:, [3, 4]].values
```

接下来，我们需要选择簇的数量，为此我们将使用树状图。

```py
import scipy.cluster.hierarchy as sch
dendrogrm = sch.dendrogram(sch.linkage(X, method = 'ward'))
plt.title('Dendrogram')
plt.xlabel('Customers')
plt.ylabel('Euclidean distance')
plt.show()
```

![](../Images/3f388b0ef4b8de84cbd26d87f31da321.png)

正如我们已经讨论的，为了选择簇的数量，我们绘制一条水平线，通过最大距离上下不交叉合并点的最长线。我们绘制一条水平线，它交叉的垂直线数量就是最佳的簇数。

在这种情况下，簇数为5。因此，让我们将我们的聚合模型拟合到5个簇。

```py
from sklearn.cluster import AgglomerativeClustering
hc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')
y_hc = hc.fit_predict(X)
```

可视化结果。

```py
# Visualising the clusters
plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 50, c = 'red', label = 'Careful')
plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 50, c = 'blue', label = 'Standard')
plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 50, c = 'green', label = 'Target')
plt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 50, c = 'cyan', label = 'Careless')
plt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 50, c = 'magenta', label = 'Sensible')
plt.title('Clusters of customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()
```

![图](../Images/5aca25e413a6f4f2840bf998959e4520.png)

基于客户的年收入和消费得分的客户簇。

### 结论

层次聚类是一种非常有用的分割方式。不需要预先定义簇的数量使得它比k-Means更具优势。然而，当数据量巨大时，它的效果不是很好。

好了，这篇文章就到此为止。希望你们喜欢阅读它。请在评论区分享你的想法/评论/疑问。

你可以通过[LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/?source=post_page---------------------------)联系我，任何问题都可以咨询。

![](../Images/36fac5b8825e21f2e39f62ab62445132.png)

感谢阅读！！！

**个人简介：[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)** 是CirrusLabs的Big Data开发人员。他在电信、分析、销售、数据科学等多个领域拥有超过4年的工作经验，专注于各种Big Data组件。

[原文](https://medium.com/swlh/what-is-hierarchical-clustering-c04e9972e002)。经许可转载。

**相关：**

+   [使用卷积神经网络和 OpenCV 预测年龄和性别](/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)

+   [K-Means 聚类图像分割简介](/2019/08/introduction-image-segmentation-k-means-clustering.html)

+   [使用 K-近邻分类心脏病](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

### 更多相关话题

+   [揭示隐藏模式：层次聚类简介](https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering)

+   [聚类解密：理解 K-Means 聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)

+   [如何在 Pandas 中使用 MultiIndex 进行层次数据组织](https://www.kdnuggets.com/how-to-use-multiindex-for-hierarchical-data-organization-in-pandas)

+   [机器学习中的 DBSCAN 聚类算法](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)

+   [什么是 K-Means 聚类及其算法如何运作？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)

+   [使用 scikit-learn 进行聚类：无监督学习教程](https://www.kdnuggets.com/2023/05/clustering-scikitlearn-tutorial-unsupervised-learning.html)
