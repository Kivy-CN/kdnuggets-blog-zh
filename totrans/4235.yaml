- en: GPU-Powered Data Science (NOT Deep Learning) with RAPIDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html](https://www.kdnuggets.com/2021/08/gpu-powered-data-science-deep-learning-rapids.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Header image](../Images/d3c4ef08dfa0e0885360d379295720aa.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image source**: [Pixabay](https://pixabay.com/photos/pc-hardware-geforce-radeon-6113265/) (Free
    image)'
  prefs: []
  type: TYPE_NORMAL
- en: Are you looking for “GPU-powered data science”?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine yourself to be a data scientist, or a business analyst, or an academic
    researcher in Physics/Economics/Neuroscience…
  prefs: []
  type: TYPE_NORMAL
- en: You do a lot of **data wrangling, cleaning, statistical tests, visualizations** on
    a regular basis. You also tinker with a lot of **linear models** fitting data
    and occasionally venture into **RandomForest**. You are also into **clustering** large
    datasets. Sounds familiar enough?
  prefs: []
  type: TYPE_NORMAL
- en: However, given the nature of the datasets you work on (mostly tabular and structured),
    you don’t venture into deep learning that much. You would rather put all the hardware
    resources you have into the things that you actually do on a day-to-day basis,
    than spending on some fancy deep learning model. Again, familiar?
  prefs: []
  type: TYPE_NORMAL
- en: You hear about the awesome power and the blazing-fast computation prowess of [GPU
    systems like the ones from NVidia for all kinds of industrial and scientific applications.](https://www.nvidia.com/en-us/deep-learning-ai/products/solutions/)
  prefs: []
  type: TYPE_NORMAL
- en: And, you keep on thinking — “***What’s there for me? How can I take advantage
    of these powerful pieces of semiconductor in my specific workflow***?”
  prefs: []
  type: TYPE_NORMAL
- en: You are searching for GPU-powered data science.
  prefs: []
  type: TYPE_NORMAL
- en: One of your best (and fastest) options to evaluate this approach is to use the
    combination of [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)** + **[**RAPIDS**](https://rapids.ai/)**. **Let
    me explain in detail…
  prefs: []
  type: TYPE_NORMAL
- en: GPUs in the AI/ML folklore have primarily been for deep learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the use of GPUs and distributed computing is widely discussed in the academic
    and business circles for core AI/ML tasks (e.g. running a [1000-layer deep neural
    network](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) for
    image classification or [billion-parameter BERT](https://arxiv.org/abs/1909.08053) speech
    synthesis model), they have found less coverage when it comes to their utility
    for regular data science and data engineering tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, **data-related tasks are the essential precursor to any ML workload
    in an AI pipeline** and they often constitute [a majority percentage of the time
    and intellectual effort ](https://www.infoworld.com/article/3228245/the-80-20-data-science-dilemma.html)spent
    by a data scientist or even an ML engineer. Recently, the famous AI pioneer
  prefs: []
  type: TYPE_NORMAL
- en: '[Andrew Ng](https://medium.com/u/592ce2a67248?source=post_page-----29f9ed8d51f3--------------------------------)
    talked about [**moving from a model-centric to a data-centric approach to AI**](https://www.youtube.com/watch?v=06-AZXmwHjo) tools
    development. This means spending much more time with the raw data and preprocessing
    it before an actual AI workload executes on your pipeline.'
  prefs: []
  type: TYPE_NORMAL
- en: So, the important question is: ***Can we leverage the power of GPU and distributed
    computing for regular data processing jobs***?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cfe568cb012bc33d8646f653e9cad210.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image source**: Author created collage from free images ([Pixabay](https://pixabay.com/vectors/squirrel-reading-books-surprise-304021/))'
  prefs: []
  type: TYPE_NORMAL
- en: While the use of GPUs and distributed computing is widely discussed in the academic
    and business circles for core AI/ML tasks, they have found less coverage in their
    utility for regular data science and data engineering tasks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The fantastic RAPIDS ecosystem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [RAPIDS suite of software libraries and APIs](https://rapids.ai/) give you
    — a regular data scientist (and not necessarily a deep learning practitioner)
    — the option and flexibility to execute **end-to-end data science and analytics
    pipelines entirely on GPUs.**
  prefs: []
  type: TYPE_NORMAL
- en: This open-source project was incubated by Nvidia by building tools to take advantage
    of CUDA primitives. It specifically focuses on **exposing GPU parallelism and
    high-bandwidth memory speed features through the data-science-friendly Python
    language**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Common data preparation and wrangling tasks** are highly valued in the RAPIDS
    ecosystem. It also lends a significant amount of **support for multi-node, multi-GPU
    deployment, and distributed processing**. Wherever possible, it integrates with
    other libraries which make **out-of-memory** (i.e. dataset size larger than individual
    computer RAM) data processing easy and accessible for individual data scientists.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0829816c3ae29c222246fdfa91aae184.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image source**: Author created collage'
  prefs: []
  type: TYPE_NORMAL
- en: The three most prominent (and Pythonic) components — that are of particular
    interest to common data scientists — are,
  prefs: []
  type: TYPE_NORMAL
- en: '[**CuPy**](https://docs.cupy.dev/en/stable/reference/comparison.html): A CUDA-powered
    array library that looks and feels just like Numpy, while using various CUDA libraries
    e.g., cuBLAS, cuDNN, cuRand, cuSolver, cuSPARSE, cuFFT, and NCCL to take full
    advantage of the GPU architecture underneath.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CuDF**: This is a GPU DataFrame library for loading, aggregating, joining,
    filtering, and manipulating data with a **pandas-like API. **Data engineers and
    data scientists can use it to easily accelerate their task flows using powerful
    GPUs without ever learning the nuts and bolts of CUDA programming.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**CuML**](https://github.com/rapidsai/cuml): This library enables data scientists,
    analysts, and researchers to run traditional/ classical ML algorithms and associated
    processing tasks fully leveraging the power of a GPU. Naturally, this is used
    mostly with tabular datasets. Think about Scikit-learn and what it could do with
    all those hundreds of Cuda and Tensor Cores on your GPU card! On cue to that,
    in most cases, cuML’s Python API matches that of Scikit-learn. Furthermore, it
    tries to offer **multi-GPU and multi-node-GPU support **byintegrating gracefully
    with [**Dask**](https://docs.dask.org/en/latest/), wherever it can, for taking
    advantage of true distributed processing/ cluster computing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Can we leverage the power of GPU and distributed computing for regular data
    processing jobs and machine learning with structured data?***'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is it different from using Apache Spark?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may ask how this GPU-powered data processing is different than using Apache
    Spark. Actually, there are some subtle differences, and only recently, with Spark
    3.0, GPUs are a mainstream resource for Spark workloads.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Accelerating Apache Spark 3.0 with GPUs and RAPIDS | NVIDIA Developer Blog**](https://developer.nvidia.com/blog/accelerating-apache-spark-3-0-with-gpus-and-rapids/)'
  prefs: []
  type: TYPE_NORMAL
- en: We do not have time or space to discuss the unique differences of this GPU-
    powered data science approach vs. Big Data tasks that are particularly suitable
    for Apache Spark. But ask yourself these questions and you will probably understand
    the subtle difference,
  prefs: []
  type: TYPE_NORMAL
- en: “*As a data scientist who models economic transactions and portfolio management,
    I want to solve a *[*linear system of equations*](https://en.wikipedia.org/wiki/System_of_linear_equations)* with
    100,000 variables. Do I use a pure Linear Algebra library or Apache Spark*?”
  prefs: []
  type: TYPE_NORMAL
- en: “*As part of an image compression pipeline, I want to use *[*Singular Value
    Decomposition*](https://towardsdatascience.com/understanding-singular-value-decomposition-and-its-application-in-data-science-388a54be95d)* on
    a large matrix of millions of entries. Is Apache Spark a good choice for that*?”
  prefs: []
  type: TYPE_NORMAL
- en: Big problem size does not always mean Apache Spark or Hadoop ecosystem. Big
    Computation is not equivalent to Big Data. As a well-rounded data scientist, you
    need to know both to tackle all kinds of problems.
  prefs: []
  type: TYPE_NORMAL
- en: RAPIDS specifically focuses on **exposing GPU parallelism and high-bandwidth
    memory speed features through Python APIs.**
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What are we showing in this article?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Crisp examples of CuPy and CuML only
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So, in this article, we will just demonstrate crisp examples of CuPy and CuML,
  prefs: []
  type: TYPE_NORMAL
- en: how they compare (in speed) with corresponding Numpy and Scikit-learn functions/
    estimators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how the data/problem size matters in this speed comparison.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CuDF examples in a later article
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although data engineering examples akin to Pandas data processing are of high
    interest to many data scientists, we will cover the CuDF examples in a later article.
  prefs: []
  type: TYPE_NORMAL
- en: What is my GPU-based hardware platform?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I am using a [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article) Tesla
    T4 GPU instance as it is literally 5 minutes of work to spin up a [fully featured
    and loaded (with DS and AI libraries) compute resource on the cloud](https://www.saturncloud.io/s/nvidia/) for
    all my data science work with their service. **As long as I don’t exceed 10 hours
    of Jupyter Notebook usage per month, it’s Free**! If you want to read more about
    their service,
  prefs: []
  type: TYPE_NORMAL
- en: 'Saturn Cloud Hosted Has Launched: GPU Data Science for Everyone!'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**GPU computing is the future of data science. Packages such as RAPIDS, TensorFlow,
    and PyTorch enable lightning-fast…**](https://www.saturncloud.io/blog/saturn-cloud-hosted-has-launched-gpu-data-science-for-everyone/)'
  prefs: []
  type: TYPE_NORMAL
- en: Apart from having the [Tesla T4 GPU](https://www.nvidia.com/en-us/data-center/tesla-t4/),
    it is a 4-core Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz machine with 16
    GB of RAM and 10 GB persistent disk. So, this is a quite normal setup from a hardware
    config point of view (limited hard drive because of the free tier) i.e. any data
    scientist may have this kind of hardware in his/her possession. The only distinguishing
    factor is the presence of the GPU and setting up all the CUDA and Python libraries
    in a proper way so that the RAPIDS suite works without any hiccup.
  prefs: []
  type: TYPE_NORMAL
- en: Big problem size does not always mean Apache Spark or Hadoop ecosystem. Big
    Computation is not equivalent to Big Data. As a well-rounded data scientist, you
    need to know both to tackle all kinds of problems.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Solving a linear system of equations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We create linear systems of equations of varying sizes and use the Numpy (and
    CuPy) `linalg.solve`routine to solve that with the following code,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da82dcb41575536341d1705d43609761.png)'
  prefs: []
  type: TYPE_IMG
- en: And, the code changes by a single letter (in multiple invocations) for the CuPy
    implementation!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a1bac98a78faba8d375bbea8b9339f76.png)'
  prefs: []
  type: TYPE_IMG
- en: Also note, how we can create CuPy arrays from Numpy arrays as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: The result is dramatic though. CuPy starts slow or at a similar pace that of
    Numpy, but beats it squarely for large problem sizes (number of equations).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3eef97e201daaefe710505532167abe3.png)'
  prefs: []
  type: TYPE_IMG
- en: Singular value decomposition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, we tackle the problem of singular value decomposition using a randomly
    generated square matrix (drawn from a normal distribution) of varying sizes. We
    don’t repeat the code block here but just show the result for brevity.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c9e56c1ab31bb1185a08a915d28e1175.png)'
  prefs: []
  type: TYPE_IMG
- en: Significant to note that the CuPy algorithm does not show markedly superior
    performance to that of the Numpy algorithm in this problem class. Perhaps, this
    is something to be taken up by the CuPy developers to improve upon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to the basic: Matrix inversion'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lastly, we go back to the basics and consider the fundamental problem of matrix
    inversion (used in almost all machine learning algorithms). The result again shows
    strongly favorable performance gain by the CuPy algorithm over that from the Numpy
    package.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/520e51bcb56b1e8fec32e0f8f078365b.png)'
  prefs: []
  type: TYPE_IMG
- en: Tackling a K-means clustering problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, we consider an unsupervised learning problem of clustering using the all-too-familiar
    k-means algorithm. Here, we are comparing a CuML function with an equivalent estimator
    from the Scikit-learn package.
  prefs: []
  type: TYPE_NORMAL
- en: Just for reference, here is the API comparison between these two estimators.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/facdccdbfe76522bafd1a3c7a968a4b3.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image source**: [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and [CuML
    website](https://docs.rapids.ai/api/cuml/stable/api.html#k-means-clustering) (Open-source
    projects)'
  prefs: []
  type: TYPE_NORMAL
- en: Here is the result for a dataset with 10 features/dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e741bf16eb344f368b8968ea9a58538.png)'
  prefs: []
  type: TYPE_IMG
- en: And, here is the result of another experiment with a 100-feature dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c49a3e4ddf1e024f4f98159babf87482.png)'
  prefs: []
  type: TYPE_IMG
- en: Clearly, both the sample size (number of rows) and dimensionality (number of
    columns) mattered in how the GPU-based acceleration performed superior.
  prefs: []
  type: TYPE_NORMAL
- en: All-too-familiar linear regression problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Who can ignore a linear regression problem for speed comparison while dealing
    with tabular datasets? Following the cadence as before, we vary the problem size
    — this time both the number of samples and dimensions simultaneously — and compare
    the performance of CuML `LinearRegression` estimator to that obtained from the
    Scikit-learn stable.
  prefs: []
  type: TYPE_NORMAL
- en: The X-axis in the following figure represents the problem size — from 1,000
    samples/50 features to 20,000 samples/1000 features.
  prefs: []
  type: TYPE_NORMAL
- en: Again, the CuML estimator performs much better as the problem complexity (sample
    size and dimensionality) grows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6e95f098dc9fe9c215df7cef5e96d97f.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We focused on two of the most fundamental components of the RAPIDS framework,
    which aims to bring the power of GPU to the everyday tasks of data analysis and
    machine learning, even when the data scientist does not perform any deep learning
    task.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99e2cd77dfaf96b3a37ddccb0662cae7.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Image source**: Made by the author with free Pixabay images ([Link-1](https://pixabay.com/photos/nvidia-graphic-card-bitcoin-gpu-5264921/), [Link-2](https://pixabay.com/vectors/cube-hexagon-stairs-152932/), [Link-3](https://pixabay.com/vectors/statistic-analytic-diagram-1564428/))'
  prefs: []
  type: TYPE_NORMAL
- en: We used a [**Saturn Cloud**](https://saturncloud.io/?utm_source=Tirtha&utm_medium=GPU-powered%20Data%20Science%20Article)** Tesla
    T4 based instance for **[**easy, free, and quick setup**](https://www.saturncloud.io/s/freehosted/) and
    showed a few features of CuPy and CuML libraries and performance comparisons of
    widely used algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Not all algorithms from the RAPIDS libraries are vastly superior but most are.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In general, the performance gain increases rapidly as the problem complexity
    (sample size and dimensionality) grows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a GPU, always give RAPIDS a try, compare and test if you are gaining
    any performance, and make it a trusted workhorse of your data science pipeline.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code change is minimal, almost non-existent for switching over.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Let the power of GPU jumpstart your analytics and data science workflow**.'
  prefs: []
  type: TYPE_NORMAL
- en: You can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    code, ideas, and resources in machine learning and data science. If you are, like
    me, passionate about AI/machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter](https://twitter.com/tirthajyotiS).
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to Mel.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/dataseries/gpu-powered-data-science-not-deep-learning-with-rapids-29f9ed8d51f3).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to Use NVIDIA GPU Accelerated Libraries](/2021/07/nvidia-gpu-accelerated-libraries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why and how should you learn “Productive Data Science”?](/2021/07/learn-productive-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Not Only for Deep Learning: How GPUs Accelerate Data Science & Data Analytics](/2021/07/deep-learning-gpu-accelerate-data-science-data-analytics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
