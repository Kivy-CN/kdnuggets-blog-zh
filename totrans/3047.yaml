- en: Variational Autoencoders Explained in Detail
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变分自编码器详细解析
- en: 原文：[https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html](https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html](https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![](../Images/1286eca0c2755dee82f0ae1831d7ab32.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1286eca0c2755dee82f0ae1831d7ab32.png)'
- en: In the [previous post](http://anotherdatum.com/vae.html) of this series I introduced
    the Variational Autoencoder (VAE) framework, and explained the theory behind it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这系列的 [上一篇文章](http://anotherdatum.com/vae.html)中，我介绍了变分自编码器（VAE）框架，并解释了其背后的理论。
- en: In this post I’ll explain the VAE in more detail, or in other words — I’ll provide
    some code :)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将更详细地解释 VAE，换句话说——我将提供一些代码 :)
- en: After reading this post, you’ll understand the technical details needed to implement
    VAE.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本文后，你将理解实现 VAE 所需的技术细节。
- en: As a bonus point, I’ll show you how by imposing a special role to some of the
    latent vector’s dimensions, the model can generate images conditioned on the digit
    type.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个额外的点，我将向你展示如何通过对一些潜在向量维度施加特殊角色，模型可以生成基于数字类型的图像。
- en: The model will be trained on [MNIST](https://en.wikipedia.org/wiki/MNIST_database) — handwritten
    digits dataset. The input is an image in ℝ[28∙28].
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型将使用 [MNIST](https://en.wikipedia.org/wiki/MNIST_database) 进行训练——手写数字数据集。输入是
    ℝ[28∙28] 中的图像。
- en: Next we’ll define the hyperparameters we’re going to use.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义我们要使用的超参数。
- en: Feel free to play with different values to get a feeling of how the model is
    affected. The notebook can be found [here](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/vae2/vae2.ipynb).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随意尝试不同的值，以感受模型如何受到影响。笔记本可以在 [这里](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/vae2/vae2.ipynb)找到。
- en: The model
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 该模型
- en: '![](../Images/3b3da4fde243cf4db3f55e8861f5a65a.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b3da4fde243cf4db3f55e8861f5a65a.png)'
- en: 'The model is composed of three sub-networks:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型由三个子网络组成：
- en: Given *x*(image), encode it into a distribution over the latent space — referred
    to as *Q*(*z*|*x*) in the previous post.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定 *x*（图像），将其编码为潜在空间上的分布——在上一篇文章中称之为 *Q*(*z*|*x*)。
- en: Given *z*in latent space (code representation of an image), decode it into the
    image it represents — referred to as *f*(*z*) in the previous post.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定 *z* 在潜在空间中（图像的代码表示），将其解码为它所表示的图像——在上一篇文章中称之为 *f*(*z*)。
- en: Given *x*, classify its digit by mapping it to a layer of size 10 where the
    i’th value contains the probability of the i’th digit.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定 *x*，通过将其映射到大小为 10 的层来分类其数字，其中第 i 个值包含第 i 个数字的概率。
- en: The first two sub-networks are the vanilla VAE framework.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个子网络是基本的 VAE 框架。
- en: 'The third one is used as an [auxiliary task](http://ruder.io/multi-task/index.html),
    which will enforce some of the latent dimensions to encode the digit found in
    an image. Let me explain the motivation: in the previous post I explained that
    we don’t care what information each dimension of the latent space holds. The model
    can learn to encode whatever information it finds valuable for its task. Since
    we’re familiar with the dataset, we know the digit type should be important. We
    want to help the model by providing it with this information. Moreover, we’ll
    use this information to generate images conditioned on the digit type, as I’ll
    explain later.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个子网络用作 [辅助任务](http://ruder.io/multi-task/index.html)，它将强制某些潜在维度编码图像中的数字。让我解释一下动机：在上一篇文章中我解释过，我们不在乎潜在空间的每个维度持有什么信息。模型可以学习编码它认为对任务有价值的任何信息。由于我们对数据集非常熟悉，我们知道数字类型应该很重要。我们希望通过提供这些信息来帮助模型。此外，我们将使用这些信息生成基于数字类型的图像，稍后我会解释。
- en: Given the digit type, we’ll encode it using one hot encoding, that is, a vector
    of size 10\. These 10 numbers will be concatenated into the latent vector, so
    when decoding that vector into an image, the model will make use of the digit
    information.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数字类型，我们将其使用 one hot 编码，即大小为 10 的向量。这 10 个数字将被连接到潜在向量中，因此在将该向量解码成图像时，模型将利用数字信息。
- en: 'There are two ways to provide the model with a one hot encoding vector:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以为模型提供 one hot 编码向量：
- en: Add it as an input to the model.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其作为输入添加到模型中。
- en: 'Add it as a label so the model will have to predict it by itself: we’ll add
    another sub-network that predicts a vector of size 10 where the loss is the cross
    entropy with the expected one hot vector.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其作为标签添加，这样模型将必须自行预测：我们将添加另一个子网络来预测大小为 10 的向量，其中损失是与期望的 one hot 向量的交叉熵。
- en: 'We’ll go with the second option. Why? Well, in test time we can use the model
    in two ways:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将选择第二个选项。为什么？嗯，在测试时我们可以以两种方式使用模型：
- en: Provide an image as input, and infer a latent vector.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一张图像作为输入，并推断出一个潜在向量。
- en: Provide a latent vector as input, and generate an image.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个潜在向量作为输入，并生成一张图像。
- en: Since we want to support the first option too, we can’t provide the model with
    the digit as input, since we won’t know it in test time. Hence, the model must
    learn to predict it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们也想支持第一个选项，因此我们不能向模型提供数字作为输入，因为在测试时我们将不知道它。因此，模型必须学习预测它。
- en: Now that we understand all the sub-networks composing the model, we can code
    them. The mathematical details behind the encoder and decoder can be found in
    the previous post.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了组成模型的所有子网络，我们可以对其进行编码。编码器和解码器背后的数学细节可以在上一篇文章中找到。
- en: Training
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练
- en: '![](../Images/d94560854f9b4a91929db09f7f3861cd.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d94560854f9b4a91929db09f7f3861cd.png)'
- en: We’ll train the model to optimize the two losses — the VAE loss and the classification
    loss — using [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练模型来优化两个损失——VAE 损失和分类损失——使用 [SGD](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)。
- en: 'At the end of every epoch we’ll sample latent vectors and decode them into
    images, so we can visualize how the generative power of the model improves over
    the epochs. The sampling method is as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个纪元结束时，我们将采样潜在向量并将其解码成图像，以便我们可以可视化模型的生成能力如何随着纪元的推移而改善。采样方法如下：
- en: Deterministically set the dimensions which are used for digit classification
    according to the digit we want to generate an image for. If for example we want
    to generate an image of the digit 2, these dimensions will be set to [0010000000].
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据我们想要生成图像的数字，确定用于数字分类的维度。如果我们想生成数字 2 的图像，这些维度将设置为 [0010000000]。
- en: Randomly sample the other dimensions according to the prior — a multivariate
    Gaussian. We’ll use these sampled values for all the different digits we generate
    in a given epoch. This way we can have a feeling of what is encoded in the other
    dimensions, for example stroke style.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机采样其他维度，根据先验——多变量高斯分布。我们将使用这些采样值来生成给定纪元中的所有不同数字。通过这种方式，我们可以感受到其他维度中编码了什么，例如笔画风格。
- en: The intuition behind step 1 is that after convergence the model should be able
    to classify the digit in an input image using these dimensions. On the other hand,
    these dimensions are also used in the decoding step to generate the image. It
    means the decoder sub-network learns that when these dimensions have the values
    corresponding to the digit 2, it should generate an image of that digit. Therefore,
    if we manually set these dimensions to contain the information of the digit 2,
    we’ll get a generated image of that digit.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 1 的直觉是，在收敛之后，模型应该能够使用这些维度来分类输入图像中的数字。另一方面，这些维度也用于解码步骤以生成图像。这意味着解码器子网络学会了当这些维度具有与数字
    2 相对应的值时，它应该生成该数字的图像。因此，如果我们手动设置这些维度以包含数字 2 的信息，我们将得到该数字的生成图像。
- en: 'Let’s verify both losses look good, that is — decreasing:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证两个损失是否看起来不错，即——是否在减少：
- en: '![](../Images/0548475d920b2aa89d6e12cc74b9364d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0548475d920b2aa89d6e12cc74b9364d.png)'
- en: 'Additionally, let’s plot the generated images to see if indeed the model was
    able to generate images of digits:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们绘制生成的图像，看看模型是否确实能够生成数字的图像：
- en: '![](../Images/53f3601c848327e3e915709f0c622828.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53f3601c848327e3e915709f0c622828.png)'
- en: Final thoughts
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终想法
- en: It’s nice to see that using a simple feed forward network (no fancy convolutions)
    we’re able to generate nice looking images after merely 20 epochs. The model learned
    to use the special digit dimensions quite fast — at epoch 9 we already see the
    sequence of digits we were trying to generate.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 很高兴看到使用简单的前馈网络（没有花哨的卷积）我们能够在仅仅 20 个纪元后生成漂亮的图像。模型学会了相当快地使用特殊的数字维度——在第 9 纪元时，我们已经看到了我们尝试生成的数字序列。
- en: Every epoch used different random values for the other dimensions, so we can
    see how the style differs between epochs, and is similar inside every epoch — at
    least for some of the epochs. At epoch 18 for instance all the digits are bolder
    compared to epoch 20.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 每个纪元使用不同的随机值来处理其他维度，因此我们可以看到风格在不同纪元之间的差异，并且在每个纪元内部是相似的——至少在一些纪元中是这样。例如，在第18纪元中，所有数字都比第20纪元更粗体。
- en: I invite you to open [this notebook](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/vae2/vae2.ipynb) and
    play around with the VAE. The hyperparameter values for instance have a great
    effect over the generated images. Have fun :)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我邀请你打开 [这个笔记本](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/vae2/vae2.ipynb) 并玩一玩
    VAE。例如，超参数的值对生成的图像有很大的影响。玩得开心 :)
- en: '**Bio**: [Yoel Zeldes](https://medium.com/@yoelzeldes) is a Algorithms Engineer
    at Taboola and is also a Machine Learning enthusiast, who especially enjoys the
    insights of Deep Learning.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**： [Yoel Zeldes](https://medium.com/@yoelzeldes) 是 Taboola 的算法工程师，也是一位对深度学习特别感兴趣的机器学习爱好者。'
- en: '[Original](https://towardsdatascience.com/variational-autoencoders-explained-in-detail-d585327c660a).
    Reposted with permission.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/variational-autoencoders-explained-in-detail-d585327c660a)。经许可转载。'
- en: '**Resources:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning Performance Cheat Sheet](https://www.kdnuggets.com/2018/11/deep-learning-performance-cheat-sheet.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习性能备忘单](https://www.kdnuggets.com/2018/11/deep-learning-performance-cheat-sheet.html)'
- en: '[How to Engineer Your Way Out of Slow Models](https://www.kdnuggets.com/2018/11/engineer-slow-models.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何解决模型运行缓慢的问题](https://www.kdnuggets.com/2018/11/engineer-slow-models.html)'
- en: '[Deep Learning Cheat Sheets](https://www.kdnuggets.com/2018/11/deep-learning-cheat-sheets.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习备忘单](https://www.kdnuggets.com/2018/11/deep-learning-cheat-sheets.html)'
- en: '* * *'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Database Key Terms, Explained](https://www.kdnuggets.com/2016/07/database-key-terms-explained.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据库关键术语解释](https://www.kdnuggets.com/2016/07/database-key-terms-explained.html)'
- en: '[Descriptive Statistics Key Terms, Explained](https://www.kdnuggets.com/2017/05/descriptive-statistics-key-terms-explained.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[描述性统计关键术语解释](https://www.kdnuggets.com/2017/05/descriptive-statistics-key-terms-explained.html)'
- en: '[Decision Tree Algorithm, Explained](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树算法解释](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
- en: '[Key-Value Databases, Explained](https://www.kdnuggets.com/2021/04/nosql-explained-understanding-key-value-databases.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[键值数据库解释](https://www.kdnuggets.com/2021/04/nosql-explained-understanding-key-value-databases.html)'
- en: '[Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[F1 分数的微观、宏观和加权平均值，清晰解释](https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html)'
- en: '[Gaussian Naive Bayes, Explained](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯朴素贝叶斯解释](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
