- en: 'Introducing Falcon2: Next-Gen Language Model by TII'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/introducing-falcon2-next-gen-language-model-by-tii](https://www.kdnuggets.com/introducing-falcon2-next-gen-language-model-by-tii)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Falcon2](../Images/d2e9caefaf85567b2d00eb13c5cadc25.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'The Technology Innovation Institute (TII) in Abu Dhabi released its next series
    of Falcon language models on May 14\. The new models match the TII mission as
    technology enablers and are available as open-source models on HuggingFace. They
    released two variants of the Falcon 2 models: **Falcon-2-11B** and **Falcon-2-11B-VLM**.
    The new VLM model promises exceptional multi-model compatibilities that perform
    on par with other open-source and closed-source models.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Model Features and Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The recent Falcon-2 language model has 11 billion parameters and is trained
    on 5.5 trillion tokens from the [falcon-refinedweb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)
    dataset. The newer, more efficient models compete well against the Meta’s recent
    Llama3 model with 8 billion parameters. The results are summarized in the below
    table shared by TII:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Falcon 2 Results](../Images/3be394b7d26dd694b77312d3b8ddb8a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [TII](https://falconllm.tii.ae/falcon-2.html)
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the Falcon-2 model fares well against Google’s Gemma with 7 billion
    parameters. Gemma-7B outperforms the Falcon-2 average performance by only 0.01\.
    In addition, the model is multi-lingual, trained on commonly used languages inclduing
    English, French, Spanish and German amongst others.
  prefs: []
  type: TYPE_NORMAL
- en: However, the groundbreaking achievement is the release of Falcon-2-11B Vision
    Language Model that adds image understanding and multi-modularity to the same
    language model. The image-to-text conversation capability with comparable capabilities
    with recent models like Llama3 and Gemma is a significant advancement.
  prefs: []
  type: TYPE_NORMAL
- en: How to Use the Models for Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s get to the coding part so we can run the model on our local system and
    generate responses. First, like any other project, let us set up a fresh environment
    to avoid dependency conflicts. Given the model is released recently, we will the
    need the latest versions of all libraries to avoid missing support and pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Python virtual environment and activate it using the below commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we have a clean environment, we can install our required libraries and dependencies
    using Python package manager. For this project, we will use images available on
    the internet and load them in Python. The requests and Pillow library are suitable
    for this purpose. Moreover, for loading the model, we will you use the transformers
    library that has internal support for HuggingFace model loading and inference.
    We will use bitsandbytes, PyTorch and accelerate as a model loading utility and
    quantization.
  prefs: []
  type: TYPE_NORMAL
- en: 'To ease up the set up process, we can create a simple requirements text file
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now install all the dependencies in a single line using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We can now start working on our code to use the model for inference. Let’s start
    by loading the model in our local system. The model is available on [HuggingFace](https://huggingface.co/tiiuae/falcon-11B-vlm)
    and the total size exceeds 20GB of memory. We can not load the model in consumer
    grade GPUs which usually have around 8-16GB RAM. Hence, we will need to quantize
    the model i.e. we will load the model in 4-bit floating point numbers instead
    of the usual 32-bit precision to decrease the memory requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bitsandbytes library provides an easy interface for quantization of Large
    Language Models in HuggingFace. We can initalize a quantization configuration
    that can be passed to the model. HuggingFace internally handles all required operations
    and sets the correct precision and adjustments for us. The config can be set as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This allows the model to fit in under 16GB GPU RAM, making it easier to load
    the model without offloading and distribution. We can now load the Falcon-2B-VLM.
    Being a multi-modal model, we will be handling images alongside textual prompts.
    The LLava model and pipelines are designed for this purpose as they allow CLIP-based
    image embeddings to be projected to language model inputs. The transformers library
    has built-in Llava model processors and pipelines. We can then load the model
    as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We pass the model url from the HuggingFace model card to the processor and generator.
    We also pass the bitsandbytes quantization config to the generative model, so
    it will be automatically loaded in 4-bit precision.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now start using the model to generate responses! To explore the multi-modal
    nature of Falcon-11B, we will need to load an image in Python. For a test sample,
    let us load this standard image available [here](http://images.cocodataset.org/val2017/000000039769.jpg).
    To load an image from a web URL, we can use the Pillow and requests library as
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The requests library downloads the image from the URL, and the Pillow library
    can read the image from bytes to a standard image format. Now that can have our
    test image, we can now generate a sample response from our model.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s set up a sample prompt template that the model is sensitive to.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The prompt template itself is self-explanatory and we need to follow it for
    best responses from the VLM. We pass the prompt and the image to the Llava image
    processor. It internally uses CLIP to create a combined embedding of the image
    and the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The returned tensor embedding acts as an input for the generative model. We
    pass the embeddings and the transformer-based Falcon-11B model generates a textual
    response based on the image and instruction provided originally.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can generate the response using the below code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: There we have it! The generated_captions variable is a string that contains
    the generated response from the model.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We tested various images using the above code and the responses for some of
    them are summarized in this image below. We see that the Falcon-2 model has a
    strong understanding of the image and generates legible answers to show its comprehension
    of the scenarios in the images. It can read text and also highlights the global
    information as a whole. To summarize, the model has excellent capabilities for
    visual tasks, and can be used for image-based conversations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Falcon 2 Inference Results](../Images/69694f523f6c6f8effcbbe361ca41ddd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author| Inference images from the Internet. Sources: [Cats Image](http://images.cocodataset.org/val2017/000000039769.jpg),
    [Card Image](https://usa.visa.com/dam/VCOM/global/common-assets/cards/visa-prepaid-card-800x450.png),
    [Football Image](https://static.theprint.in/wp-content/uploads/2020/07/football.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: License and Compliance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to being open-source, the models are released with the Apache2.0
    License making them available for Open Access. This allows the modification and
    distribution of the model for personal and commercial uses. This means that you
    can now use Falcon-2 models to supercharge your LLM-based applications and open-source
    models to provide multi-modal capabilities for your users.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overall, the new Falcon-2 models show promising results. But that is not all!
    TII is already working on the next iteration to further push performance. They
    look to integrate the Mixture-of-Experts (MoE) and other machine learning capabilities
    into their models to improve accuracy and intelligence. If Falcon-2 seems like
    an improvement, be ready for their next announcement.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal is a machine learning engineer and a technical writer with a profound passion
    for data science and the intersection of AI with medicine. She co-authored the
    ebook "Maximizing Productivity with ChatGPT". As a Google Generation Scholar 2022
    for APAC, she champions diversity and academic excellence. She''s also recognized
    as a Teradata Diversity in Tech Scholar, Mitacs Globalink Research Scholar, and
    Harvard WeCode Scholar. Kanwal is an ardent advocate for change, having founded
    FEMCodes to empower women in STEM fields.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introducing the Testing Library for Natural Language Processing](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing TPU v4: Googles Cutting Edge Supercomputer for Large…](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing OpenChat: The Free & Simple Platform for Building…](https://www.kdnuggets.com/2023/06/introducing-openchat-free-simple-platform-building-custom-chatbots-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing OpenLLM: Open Source Library for LLMs](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
