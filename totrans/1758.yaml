- en: 'Data Science for Newbies: An Introductory Tutorial Series for Software Engineers'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html](https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Harris Brakmić, Software Engineer.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Editor''s note**: This is an overview of a multi-part tutorial on data science
    for newbies. The author has given the series a different -- tongue-in-cheek --
    title; take it in stride and recognize that the series'' approach and content
    is a fresh look at getting started with various aspects of data science from a
    software engineering perspective.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '![PySpark console](../Images/4ae095edf852180b5162a23294b12e52.png)'
  prefs: []
  type: TYPE_IMG
- en: The PySpark console.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 1: Getting Started](http://blog.brakmic.com/data-science-for-losers/)**'
  prefs: []
  type: TYPE_NORMAL
- en: To do some serious statistics with Python one should use a proper distribution
    like the one provided by Continuum Analytics. Of course, a manual installation
    of all the needed packages (Pandas, NumPy, Matplotlib etc.) is possible but beware
    the complexities and convoluted package dependencies. In this article we’ll use
    the Anaconda Distribution. The installation under Windows is straightforward but
    avoid the usage of multiple Python installations (for example, Python3 and Python2
    in parallel). It’s best to let Anaconda’s Python binary be your standard Python
    interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2: Analyzing Reddit Comments & Querying Databases](http://blog.brakmic.com/data-science-for-losers-part-2/)**'
  prefs: []
  type: TYPE_NORMAL
- en: Patterns are everywhere but many of them can’t be immediately recognized. This
    is one of the reasons why we’re digging deep holes in our databases, data warehouses,
    and other silos. In this article we’ll use a few more methods from Pandas’ DataFrames
    and generate plots. We’ll also create pivot tables and query an MS SQL database
    via ODBC. SqlAlchemy will be our helper in this case and we’ll see that even Losers
    like us can easily merge and filter SQL tables without touching the SQL syntax.
    No matter the task you always need a powerful tool-set in the first place. Like
    the Anaconda Distribution which we’ll be using here. Our data sources will be
    things like JSON files containing reddit comments or SQL-databases like Northwind.
    Many 90’es kids used Northwind to learn SQL.
  prefs: []
  type: TYPE_NORMAL
- en: '![Reddit comment ratings](../Images/cee5b84ed2764fddb38d5668cbeb509b.png)'
  prefs: []
  type: TYPE_IMG
- en: Highest rated comments for all available sub-reddits.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2 Addendum: Playing SQL with DataFrames](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**'
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s talk about a few features from Pandas I’ve forgot to mention in the
    last two articles.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 3: Scala & Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'By its own definition Spark is a fast, general engine for large-scale data
    processing. Well, someone would say: but we already have Hadoop, so why should
    we use Spark? Such a question I’d answer with a remark that Hadoop is EJB reinvented
    and that we need something more flexible, more general, more expandable and…much
    faster than MapReduce. Spark handles both batch and streaming processing at a
    very fast rate.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 4: Machine Learning](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'From my non-scientist perspective I’d define ML as a subset of the Artificial
    Intelligence research which develops self-learning (or self-improving?) algorithms
    that try to gain knowledge from data and make predictions based on it. However,
    ML is not only reserved for academia or some “enlightened circles”. We use ML
    every day without being aware of its existence and usefulness. A few examples
    of ML in the wild would be: spam filters, speech-recognition software, automatic
    text-analysis, “intelligent game characters”, or the upcoming self-driving cars.
    All these entities make decisions based on some ML algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)'
  prefs: []
  type: TYPE_IMG
- en: DataFrames in the Spark stack.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 5: Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**'
  prefs: []
  type: TYPE_NORMAL
- en: Before we start using DataFrames we first have to prepare our environment which
    will run in Jupyter (formerly known as “IPython”). After you’ve downloaded and
    unpacked the Spark Package you’ll find some important Python libraries and scripts
    inside the python/pyspark directory. These files are used, for example, when you
    start the PySpark REPL in the console. As you may know, Spark supports Java, Scala,
    Python and R. Python-based REPL called PySpark offers a nice option to control
    Spark via Python scripts
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 6: Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**'
  prefs: []
  type: TYPE_NORMAL
- en: In this article we’ll explore Microsoft’s Azure Machine Learning environment
    and how to combine Cloud technologies with Python and Jupyter. As you may know
    I’ve been extensively using them throughout this article series so I have a strong
    opinion on how a Data Science-friendly environment should look like. Of course,
    there’s nothing against other coding environments or languages, for example R,
    so your opinion may greatly differ from mine and this is fine. Also AzureML offers
    a very good R-support! So, feel free to adapt everything from this article to
    your needs. And before we begin, a few words about how I came to the idea to write
    about Azure and Data Science.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 7: Using Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**'
  prefs: []
  type: TYPE_NORMAL
- en: While finishing my Data Science and ML Essentials course, I discovered that
    Azure ML has a built-in support for Jupyter and Python which, of course, made
    it very interesting to me because it makes Azure ML an ideal ground for experimentation.
    They even call one of their working areas “Experiments” so one can expect good
    Python (and R) support and many cool off-the-shelf modules. Being no different
    than other tech-enthusiasts I quickly decided to write an article describing some
    of the key parts of Azure ML.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Harris Brakmić](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic))
    is a Software Developer at Advarics GmbH. He writes WebApps with Ractive, React,
    Backbone & DevExtreme, and Azure-based backends with C#.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An Introduction to the MXNet Python API ](/2017/05/intro-mxnet-python-api.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Into Data Science: What You Need to Know](/2017/05/data-science-need-to-know.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reinforcement Learning for Newbies](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software Developer vs Software Engineer](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[We Don''t Need Data Scientists, We Need Data Engineers](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Do Data Scientists and Data Engineers Work Together?](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
