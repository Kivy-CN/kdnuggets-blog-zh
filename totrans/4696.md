# 使用 Python 的遗传算法进行特征选择

> 原文：[https://www.kdnuggets.com/2019/03/feature-reduction-genetic-algorithm-python.html/2](https://www.kdnuggets.com/2019/03/feature-reduction-genetic-algorithm-python.html/2)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/03/feature-reduction-genetic-algorithm-python.html?page=2#comments)

在准备好特征、类别标签和GA参数后，我们可以按照下述代码进行GA的迭代。首先，通过调用GA文件中定义的名为**cal_pop_fitness()**的适应度函数来计算所有解的适应度值。该函数接受当前种群、提取的特征、类别标签、训练索引和测试索引。函数将所有解的适应度值返回到名为**fitness**的变量中。请记住，适应度值表示分类准确率。最佳（即最高）分类准确率被保存到**best_outputs**列表中。

根据计算出的适应度值，使用**select_mating_pool()**函数选择分类准确率最高的最佳解作为交配池中的父代。该函数接受当前种群、适应度值和要返回的父代数量，并将选择的父代返回到**parents**变量中。

```py
for generation in range(num_generations):

    print("Generation : ", generation)

    # Measuring the fitness of each chromosome in the population.

    fitness = GA.cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)

    best_outputs.append(numpy.max(fitness))

    # The best result in the current iteration.

    print("Best result : ", best_outputs[-1])

    # Selecting the best parents in the population for mating.

    parents = GA.select_mating_pool(new_population, fitness, num_parents_mating)

    # Generating next generation using crossover.

    offspring_crossover = GA.crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))

    # Adding some variations to the offspring using mutation.

    offspring_mutation = GA.mutation(offspring_crossover, num_mutations=num_mutations)

    # Creating the new population based on the parents and offspring.

    new_population[0:parents.shape[0], :] = parents

    new_population[parents.shape[0]:, :] = offspring_mutation
```

接下来是对选择的父代应用交叉操作以创建后代。这是在GA.py文件中定义的**crossover()**函数中完成的。它接受父代和稍后返回的后代数组的形状，并将结果存入**offspring_crossover**变量中。然后，对该数组应用突变操作，使用GA.py文件中的**mutation()**函数。此外，该函数还接受突变的数量。

由于新种群包含选择的父代和后代，因此将**parents**和**offspring_mutation**数组保存到**new_population**变量中。之后，对新种群应用新的代际。

在所有代际完成后，执行下一段代码以返回最佳选择的特征元素集和选定的元素数量。在完成100代后，算法使用了174个特征元素，以达到99.59%的准确率。

```py
fitness = GA.cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)

# Then return the index of that solution corresponding to the best fitness.

best_match_idx = numpy.where(fitness == numpy.max(fitness))[0]

best_match_idx = best_match_idx[0]

best_solution = new_population[best_match_idx, :]

best_solution_indices = numpy.where(best_solution == 1)[0]

best_solution_num_elements = best_solution_indices.shape[0]

best_solution_fitness = fitness[best_match_idx]

print("best_match_idx : ", best_match_idx)

print("best_solution : ", best_solution)

print("Selected indices : ", best_solution_indices)

print("Number of selected elements : ", best_solution_num_elements)

print("Best solution fitness : ", best_solution_fitness)

matplotlib.pyplot.plot(best_outputs)

matplotlib.pyplot.xlabel("Iteration")

matplotlib.pyplot.ylabel("Fitness")

matplotlib.pyplot.show()
```

上述代码还显示了一个图形，展示了GA在所有代际中的进展，如下所示。

![遗传算法进展](../Images/ccd232bf7d3840d9cc79d648f2d92c8d.png)

以下是主文件的完整代码。

```py

import numpy
import GA
import pickle
import matplotlib.pyplot

f = open("dataset_features.pkl", "rb")
data_inputs = pickle.load(f)
f.close()

f = open("outputs.pkl", "rb")
data_outputs = pickle.load(f)
f.close()

num_samples = data_inputs.shape[0]
num_feature_elements = data_inputs.shape[1]

train_indices = numpy.arange(1, num_samples, 4)
test_indices = numpy.arange(0, num_samples, 4)
print("Number of training samples: ", train_indices.shape[0])
print("Number of test samples: ", test_indices.shape[0])

"""
Genetic algorithm parameters:
    Population size
    Mating pool size
    Number of mutations
"""
sol_per_pop = 8 # Population size.
num_parents_mating = 4 # Number of parents inside the mating pool.
num_mutations = 3 # Number of elements to mutate.

# Defining the population shape.
pop_shape = (sol_per_pop, num_feature_elements)

# Creating the initial population.
new_population = numpy.random.randint(low=0, high=2, size=pop_shape)
print(new_population.shape)

best_outputs = []
num_generations = 100
for generation in range(num_generations):
    print("Generation : ", generation)
    # Measuring the fitness of each chromosome in the population.
    fitness = GA.cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)

    best_outputs.append(numpy.max(fitness))
    # The best result in the current iteration.
    print("Best result : ", best_outputs[-1])

    # Selecting the best parents in the population for mating.
    parents = GA.select_mating_pool(new_population, fitness, num_parents_mating)

    # Generating next generation using crossover.
    offspring_crossover = GA.crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))

    # Adding some variations to the offspring using mutation.
    offspring_mutation = GA.mutation(offspring_crossover, num_mutations=num_mutations)

    # Creating the new population based on the parents and offspring.
    new_population[0:parents.shape[0], :] = parents
    new_population[parents.shape[0]:, :] = offspring_mutation

# Getting the best solution after iterating finishing all generations.
# At first, the fitness is calculated for each solution in the final generation.
fitness = GA.cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)
# Then return the index of that solution corresponding to the best fitness.
best_match_idx = numpy.where(fitness == numpy.max(fitness))[0]
best_match_idx = best_match_idx[0]

best_solution = new_population[best_match_idx, :]
best_solution_indices = numpy.where(best_solution == 1)[0]
best_solution_num_elements = best_solution_indices.shape[0]
best_solution_fitness = fitness[best_match_idx]

print("best_match_idx : ", best_match_idx)
print("best_solution : ", best_solution)
print("Selected indices : ", best_solution_indices)
print("Number of selected elements : ", best_solution_num_elements)
print("Best solution fitness : ", best_solution_fitness)

matplotlib.pyplot.plot(best_outputs)
matplotlib.pyplot.xlabel("Iteration")
matplotlib.pyplot.ylabel("Fitness")
matplotlib.pyplot.show()
```

### GA.py 实现

`GA.py` 文件的实现如下。**cal_pop_fitness()** 函数中，SVC 根据每个解选择的特征元素进行训练。在训练之前，特征会根据选定的元素进行筛选，这些基因的值为 1。这一步骤在 **reduce_features()** 函数中完成。它接受当前解以及所有样本的完整特征。

训练完成后，使用 **classification_accuracy()** 函数计算其分类准确率。该函数返回的准确率存储在 **cal_pop_fitness()** 函数中的一个名为 accuracies 的数组里。

**crossover()** 和 **mutation()** 函数的实现与我之前的教程“**Python 中的遗传算法实现**”中讨论的非常相似。主要区别在于，**mutation()** 函数通过翻转基因值来改变随机选择的基因，因为我们使用的是二进制表示。

```py

import numpy

import sklearn.svm

def reduce_features(solution, features):

    selected_elements_indices = numpy.where(solution == 1)[0]

    reduced_features = features[:, selected_elements_indices]

    return reduced_features

def classification_accuracy(labels, predictions):

    correct = numpy.where(labels == predictions)[0]

    accuracy = correct.shape[0]/labels.shape[0]

    return accuracy

def cal_pop_fitness(pop, features, labels, train_indices, test_indices):

    accuracies = numpy.zeros(pop.shape[0])

    idx = 0

    for curr_solution in pop:

        reduced_features = reduce_features(curr_solution, features)

        train_data = reduced_features[train_indices, :]

        test_data = reduced_features[test_indices, :]

        train_labels = labels[train_indices]

        test_labels = labels[test_indices]

        SV_classifier = sklearn.svm.SVC(gamma='scale')

        SV_classifier.fit(X=train_data, y=train_labels)

        predictions = SV_classifier.predict(test_data)

        accuracies[idx] = classification_accuracy(test_labels, predictions)

        idx = idx + 1

    return accuracies

def select_mating_pool(pop, fitness, num_parents):

    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.

    parents = numpy.empty((num_parents, pop.shape[1]))

    for parent_num in range(num_parents):

        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))

        max_fitness_idx = max_fitness_idx[0][0]

        parents[parent_num, :] = pop[max_fitness_idx, :]

        fitness[max_fitness_idx] = -99999999999

    return parents

def crossover(parents, offspring_size):

    offspring = numpy.empty(offspring_size)

    # The point at which crossover takes place between two parents. Usually, it is at the center.

    crossover_point = numpy.uint8(offspring_size[1]/2)

    for k in range(offspring_size[0]):

        # Index of the first parent to mate.

        parent1_idx = k%parents.shape[0]

        # Index of the second parent to mate.

        parent2_idx = (k+1)%parents.shape[0]

        # The new offspring will have its first half of its genes taken from the first parent.

        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]

        # The new offspring will have its second half of its genes taken from the second parent.

        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]

    return offspring

def mutation(offspring_crossover, num_mutations=2):

    mutation_idx = numpy.random.randint(low=0, high=offspring_crossover.shape[1], size=num_mutations)

    # Mutation changes a single gene in each offspring randomly.

    for idx in range(offspring_crossover.shape[0]):

        # The random value to be added to the gene.

        offspring_crossover[idx, mutation_idx] = 1 - offspring_crossover[idx, mutation_idx]

    return offspring_crossover

```

### 联系作者

+   电子邮件：[ahmed.f.gad@gmail.com](https://mailto:ahmed.f.gad@gmail.com)

+   LinkedIn: [https://linkedin.com/in/ahmedfgad/](https://linkedin.com/in/ahmedfgad/)

+   KDnuggets: [https://www.kdnuggets.com/author/ahmed-gad](/author/ahmed-gad)

+   YouTube: [https://youtube.com/AhmedGadFCIT](https://youtube.com/AhmedGadFCIT)

+   TowardsDataScience: [https://towardsdatascience.com/@ahmedfgad](https://towardsdatascience.com/@ahmedfgad)

+   GitHub: [https://github.com/ahmedfgad](https://github.com/ahmedfgad)

**简历：[Ahmed Gad](https://www.linkedin.com/in/ahmedfgad/)** 于 2015 年 7 月从埃及梅努菲亚大学计算机与信息学院（FCI）获得信息技术荣誉学士学位。由于在学院中排名第一，他在 2015 年被推荐到埃及的一所学院担任助教，随后在 2016 年继续担任助教及研究员。他当前的研究兴趣包括深度学习、机器学习、人工智能、数字信号处理和计算机视觉。

[原文](https://www.linkedin.com/pulse/feature-reduction-using-genetic-algorithm-ahmed-gad/)。经授权转载。

**相关：**

+   [特征工程快速指南](/2019/02/quick-guide-feature-engineering.html)

+   [使用 NumPy 和图像分类的人工神经网络实现](/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html)

+   [Python 中的遗传算法实现](/2018/07/genetic-algorithm-implementation-python.html)

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 更多相关话题

+   [遗传算法关键术语解析](https://www.kdnuggets.com/2018/04/genetic-algorithm-key-terms-explained.html)

+   [利用遗传算法优化基因](https://www.kdnuggets.com/2022/04/optimizing-genes-genetic-algorithm.html)

+   [数据科学中的降维技术](https://www.kdnuggets.com/2022/09/dimensionality-reduction-techniques-data-science.html)

+   [Feature Store 峰会 2022：关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)

+   [Python 中的遗传编程：背包问题](https://www.kdnuggets.com/2023/01/knapsack-problem-genetic-programming-python.html)

+   [在 Python 中理解和实现遗传算法](https://www.kdnuggets.com/understanding-and-implementing-genetic-algorithms-in-python)
