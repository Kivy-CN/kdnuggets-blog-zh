- en: 'Kedro-Airflow: Orchestrating Kedro Pipelines with Airflow'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/03/kedro-airflow-orchestrating-pipelines.html](https://www.kdnuggets.com/2021/03/kedro-airflow-orchestrating-pipelines.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Jo Stichbury](https://www.linkedin.com/in/jostichbury/), Technical Writer
    & [Yetunde Dada](https://www.linkedin.com/in/yetudada/), Product Manager at QuantumBlack**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Kedro](https://github.com/quantumblacklabs/kedro) is an [open-source Python
    framework](https://kedro.readthedocs.io/en/stable/) for creating reproducible,
    maintainable, and modular data science code. Its focus is on authoring code and
    not orchestrating, scheduling and monitoring pipeline runs. We emphasise infrastructure
    independence, and this is crucial for consultancies such as QuantumBlack, where
    Kedro was born.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/e0ed876d1b2801def9b0e141ee177d22.png)'
  prefs: []
  type: TYPE_IMG
- en: Kedro is not an orchestrator. It aims to stay very lean and unopinionated about
    where and how your pipeline will be run.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can deploy your Kedro projects virtually anywhere with minimal effort as
    long as you can run Python. Our users have the freedom to choose their deployment
    targets. The future of deploying Kedro pipelines is in designing a deployment
    process with a great developer experience in mind.
  prefs: []
  type: TYPE_NORMAL
- en: One of the benefits of being an open source community is that we can explore
    partnerships with other, like-minded frameworks and technologies. We are particularly
    excited to work with the Astronomer team, who helps organisations adopt Apache
    Airflow, the leading open-source data workflow orchestration platform.
  prefs: []
  type: TYPE_NORMAL
- en: Workflows in Airflow are modelled and organised as [DAGs](https://en.wikipedia.org/wiki/Directed_acyclic_graph),
    making it a suitable engine to orchestrate and execute a pipeline authored with
    Kedro. To keep the workflow seamless, we are pleased to unveil the latest version
    of the [Kedro-Airflow plugin](https://github.com/quantumblacklabs/kedro-airflow),
    which simplifies deployment of a Kedro project on Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: Our work with Astronomer provides a simple way for our users to deploy their
    pipelines. We would like to continue our work and make the process even smoother
    and eventually achieve a “one-click-deployment” workflow for Kedro pipelines on
    Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: '**We have edited the conversation for length and clarity.**'
  prefs: []
  type: TYPE_NORMAL
- en: Pete DeJoy, you’re a Product Manager at Astronomer. Tell us a little about yourself!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Image for post](../Images/4dcafef1338f0d1e2ad883dc5878cf95.png)'
  prefs: []
  type: TYPE_IMG
- en: I’m one of the founding team members at Astronomer, where we’ve built a company
    around the open source orchestration framework Apache Airflow. I’ve done many
    things here through the years, but have spent most of my energy working on our
    product as it has developed from an idea on a whiteboard to a high-scale system
    supporting thousands of users.
  prefs: []
  type: TYPE_NORMAL
- en: What prompted the creation of Airflow 2.0? And what does the success of this
    version of Airflow look like?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Airflow has evolved quite a lot since its inception in 2014; it now has over
    20,000 stars on Github, 600k downloads/month, and tens of thousands of users worldwide.
    Airflow 1.x solved a lot of first-order problems for developers, but an uptick
    in enterprise requirements followed Airflow’s widespread adoption, along with
    increased pressure to improve the developer experience. Airflow 2.0 meets the
    needs of users with a handful of much anticipated features. These include:'
  prefs: []
  type: TYPE_NORMAL
- en: A highly available, horizontally scalable scheduler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An upgraded, stable REST API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decoupled workflow integrations (called “providers” in Airflow) as independently
    versioned and maintained python package and [much more](https://www.astronomer.io/blog/introducing-airflow-2-0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We see 2.0 as a major milestone for the project; not only does it significantly
    improve the scalability of Airflow, but also it sets a foundation upon which we
    can continuously build new features.
  prefs: []
  type: TYPE_NORMAL
- en: How did you find out about Kedro? When did you realise it was compatible with
    Airflow for users?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I had chatted with a few data scientists who were using Kedro to author their
    pipelines and looking for a good way to deploy those pipelines to Airflow. Kedro
    does an outstanding job of allowing data scientists to apply good software engineering
    principles to their code and make it modular, but Kedro pipelines need a separate
    scheduling and execution environment to run at scale. Given this need, there was
    a natural bond between Kedro pipeline and Airflow: we wanted to do everything
    we could to build a great developer experience at the intersection of the two
    tools.'
  prefs: []
  type: TYPE_NORMAL
- en: Where do you think Kedro-Airflow could go, in terms of future development?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Airflow 2.0 extends and upgrades the Airflow REST API, allowing it to be robust
    in the coming years. As the API develops, there will be new opportunities for
    specific abstraction layers to assist with DAG authoring and deployment, leading
    to a richer plugin ecosystem. There will be extra opportunity to integrate the `kedro-airflow` package
    with the Airflow API for a great developer experience.
  prefs: []
  type: TYPE_NORMAL
- en: What is the future of Airflow?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we look towards Airflow 3.0 and beyond, building upon developer love and
    trust is inevitable. But it won’t stop there. As data orchestration becomes critical
    to a growing number of business units, we want Airflow to become a medium for
    making data engineering more approachable. We seek to democratise access such
    that product owners and data scientists alike can leverage Airflow’s distributed
    execution and scheduling power without being a master in Python or Kubernetes.
    Empowering users to author and deploy data pipelines from a framework of their
    choice will become increasingly important in that journey.
  prefs: []
  type: TYPE_NORMAL
- en: What is the future of workflow orchestration technologies?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Airflow’s inception kicked off a “data pipelines as code” movement that changed
    the way enterprises thought about workflow orchestration. For many years, job
    scheduling was handled by a combination of legacy drag-and-drop frameworks and
    complex networks of cron jobs. As we transitioned into the “big data” era and
    companies began building dedicated teams to operationalise their siloed data,
    the need for additional flexibility, control, and governance became apparent.
  prefs: []
  type: TYPE_NORMAL
- en: When Maxime Beauchemin and the folks at Airbnb [built and open sourced Airflow](https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8) with
    flexible, codified data pipelines as a first-class feature, they propelled code-driven
    orchestration into the spotlight. Airflow solved many first-order problems for
    data engineers, which explains its explosive adoption. But with that early adoption
    came some pitfalls; since Airflow is highly configurable by design, users began
    applying it to use cases it was not necessarily designed for. This imposed evolutionary
    stress on the project, pushing the community to add additional configuration options
    to “mould” Airflow to various use cases.
  prefs: []
  type: TYPE_NORMAL
- en: While the added configuration options helped Airflow extend to accommodate these
    additional use cases, they introduced a new class of user needs. Data platform
    owners and administrators now need a way to deliver standard patterns to their
    pipeline authors to abate business risk. Likewise, pipeline authors need additional
    guardrails to be sure they don’t “use Airflow wrong”. Finally, engineers with
    a pythonic background now need to learn how to operationalise big data infrastructure
    for stable & reliable orchestration at scale.
  prefs: []
  type: TYPE_NORMAL
- en: We see the future of workflow orchestration technology accommodating some of
    these categorical changes in the needs of the user. If the journey thus far has
    been one of “[The Rise of the Data Engineer](https://www.freecodecamp.org/news/the-rise-of-the-data-engineer-91be18f1e603/)”,
    we see the future as “The Democratisation of Data Engineering”. All users — from
    the data scientists to the data platform owner — will have access to powerful,
    distributed, flexible data pipeline orchestration. They’ll benefit as it integrates
    from the authoring tools that they know and love, but has guardrails to accommodate
    specific usage patterns that prevent folks from straying off of the happy path.
  prefs: []
  type: TYPE_NORMAL
- en: '*You can find out more about the Kedro-Airflow plugin in the *[*Kedro documentation*](https://kedro.readthedocs.io/en/stable/10_deployment/11_airflow_astronomer.html)* and
    check out the *[*GitHub repository too*](https://github.com/quantumblacklabs/kedro-airflow)*.
    This article was edited by *[*Jo Stichbury *](https://www.linkedin.com/in/jostichbury/)*—
    Technical Writer and *[*Yetunde Dada*](https://www.linkedin.com/in/yetudada/)* —
    Product Manager, with input from *[*Ivan Danov*](https://www.linkedin.com/in/idanov/)* (Tech
    Lead at Kedro) and *[*Lim Hoang*](https://www.linkedin.com/in/limhn/)* (Senior
    Software Engineer at Kedro).*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/quantumblack/kedro-airflow-0-4-0-orchestrating-kedro-pipelines-with-airflow-23fb1283f24d).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Simplified Mixed Feature Type Preprocessing in Scikit-Learn with Pipelines](/2020/06/simplifying-mixed-feature-type-preprocessing-scikit-learn-pipelines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Step Guide to Scalable Deep Learning Pipelines with d6tflow](/2019/09/5-step-guide-scalable-deep-learning-pipelines-d6tflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Tour of End-to-End Machine Learning Platforms](/2020/07/tour-end-to-end-machine-learning-platforms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Airflow Alternatives for Data Orchestration](https://www.kdnuggets.com/5-airflow-alternatives-for-data-orchestration)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Answering Questions with HuggingFace Pipelines and Streamlit](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beyond Pipelines: Graphs as Scikit-Learn Metaestimators](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple NLP Pipelines with HuggingFace Transformers](https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unify Batch and ML Systems with Feature/Training/Inference Pipelines](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building Data Science Pipelines Using Pandas](https://www.kdnuggets.com/building-data-science-pipelines-using-pandas)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
