# 快速AutoML与FLAML + Ray Tune

> 原文：[https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html](https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html)

[comments](#comments)

**由[Qingyun Wu](https://twitter.com/qingyun_wu)、[Chi Wang](https://www.linkedin.com/in/chi-wang-49b15b16/)、[Antoni Baum](https://www.linkedin.com/in/yard1/)、[Richard Liaw](https://twitter.com/richliaw)和[Michael Galarnyk](https://twitter.com/GalarnykMichael)撰写**

![Image](../Images/de7c7c129074f49504448e84d6e97174.png)

[FLAML](https://github.com/microsoft/FLAML)是微软研究院推出的轻量级Python库，使用[前沿](https://arxiv.org/abs/2005.01571)算法以高效经济的方式找到准确的机器学习模型，这些算法旨在资源高效且易于并行化。FLAML还可以利用[Ray Tune](https://docs.ray.io/en/master/tune/index.html)进行分布式超参数调优，以便在集群上扩展这些AutoML方法。

本博客重点介绍：

+   对经济高效AutoML方法的需求

+   经济高效的AutoML与FLAML

+   如何使用Ray Tune扩展FLAML的优化算法

## 对经济高效AutoML方法的需求

AutoML因涉及试错以寻找表现良好的超参数配置而被认为是资源和时间密集型操作。由于可能配置值的空间通常非常大，因此需要一种经济高效的AutoML方法来更有效地搜索这些配置。

AutoML中超参数搜索的高资源和时间消耗归结为以下两个因素：

1.  需要大量候选超参数配置（试验）以找到性能良好的配置

1.  每个超参数的高‘评估’成本，因为评估涉及使用给定的训练数据训练和验证机器学习模型。

为了应对这两个因素，微软研究人员开发了[FLAML](https://github.com/microsoft/FLAML)（快速轻量级AutoML）。

### **什么是FLAML？**

FLAML是新发布的库，包含最先进的超参数优化算法。FLAML利用搜索空间的结构，同时优化成本和模型性能。它包含了微软研究院开发的两种新方法：

+   成本节俭优化（CFO）

+   BlendSearch

成本节俭优化（CFO）是一种以成本感知的方式进行搜索过程的方法。搜索方法从低成本的初始点开始，逐渐向高成本区域移动，同时优化给定目标（如模型损失或准确性）。

Blendsearch是CFO的扩展，结合了CFO的节俭性和贝叶斯优化的探索能力。像CFO一样，BlendSearch需要一个低成本的初始点作为输入（如果存在的话），并从那里开始搜索。然而，与CFO不同的是，BlendSearch不会在尝试新的起始点之前等待局部搜索完全收敛。

FLAML中的经济型HPO方法受到两个关键见解的启发：

1.  许多机器学习算法都有可能导致训练成本大幅变化的超参数。例如，10棵树的XGBoost模型训练速度会比1000棵树的模型快得多。

1.  参数的“成本”通常是‘连续且一致的’——评估树=10的成本低于评估树=100，而评估树=100的成本又低于评估树=500。

这些见解提供了关于成本空间中超参数的有用*结构信息*。这些方法，即CFO和BlendSearch，能够有效地利用这些见解来减少沿途产生的成本，而不影响收敛到最优解。

### **FLAML有效吗？**

在最新的[AutoML benchmark](https://openml.github.io/automlbenchmark/)中，[FLAML](https://arxiv.org/pdf/1911.04706.pdf)能够在超过62%的任务上只使用10%的计算资源，实现与最先进AutoML解决方案相同或更好的性能。

FLAML的性能归因于其经济型优化方法。新的HPO方法（CFO，BlendSearch）利用搜索空间的结构来选择优化的搜索顺序，以兼顾良好的性能和低成本。在预算限制下，这可以大大提高搜索效率。

图1显示了FLAML和最先进的超参数调整库[Optuna](https://github.com/optuna/optuna)调整LightGBM的典型结果，使用9维超参数。你可以看到，FLAML能够在更短的时间内实现更好的解决方案。

![](../Images/6b87b2f4515439e522f2a79d7adf4781.png)

图1\. 调整LightGBM在[classification dataset](https://www.openml.org/d/23517)上的验证损失（1-auc）曲线。线条和阴影区域显示了10次运行中验证损失的均值和标准差。本图中的结果来自于使用1个CPU且未并行化的实验（图像由作者提供）。

以下代码示例展示了如何仅用几行代码开始使用FLAML（假设训练数据集已提供并保存为`X_train`，`y_train`）。任务是在60秒的时间预算内调整LightGBM模型的超参数。

```py
**from** flaml **import** AutoML
automl = AutoML()
automl.fit(X_train=X_train, y_train=y_train, time_budget=60, estimator_list=['lgbm'])

''' retrieve best model and best configuration found'''
print('Best ML model:', automl.model)
print('Best hyperparameter config:', automl.best_config)
```

在这个示例中，我们在LightGBM的默认搜索空间中进行搜索，这个空间已经在FLAML中提供。FLAML提供了丰富的自定义选项，如学习器类、搜索空间、评估指标等。

## 一个示例演示

现在我们使用一个示例来演示CFO在调整XGBoost的两个超参数（树的数量和叶子数量）时的成本节约行为。

```py
'''create an XGBoost learner class with a customized search space'''
**from** flaml.model **import** XGBoostSklearnEstimator
**from** flaml **import** tune

**class** **MyXGB**(XGBoostSklearnEstimator):
​​    '''XGBoostSklearnEstimator with a customized search space'''
    @classmethod
    **def** **search_space**(cls, data_size, **params):
        upper = min(2**15, int(data_size))
        **return** {
            'n_estimators': {
                'domain': tune.lograndint(lower=4, upper=upper),
                'low_cost_init_value': 4,
            },
            'max_leaves': {
                'domain': tune.lograndint(lower=4, upper=upper),
                'low_cost_init_value': 4,
            },
        }

'''Use CFO in FLAML to tune XGBoost'''
**from** flaml **import** AutoML
automl = AutoML()
automl.add_learner(learner_name='my_xgboost', learner_class=MyXGB)
automl.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='cfo')
```

## CFO和BlendSearch如何工作

以下两个GIF分别展示了CFO在损失和评估成本（即评估时间）空间中的搜索轨迹。CFO从低成本初始点（通过`low_cost_init_value`在搜索空间中指定）开始，按照其随机局部搜索策略进行局部更新。采用这种策略，CFO可以快速移动到低损失区域，显示出良好的收敛特性。此外，CFO倾向于在必要时才探索高成本区域。这种搜索策略进一步通过[可证明的收敛速率和期望的有界成本](https://arxiv.org/abs/2005.01571)得到了支持。

![](../Images/cd50c94bbee1cf7e9397ad9f8c1d2775.png)

图2\. CFO在调整XGBoost的叶子数和树木数时的表现。这两个热图展示了所有配置的损失和成本分布。黑点是CFO评估的点，黑点通过线连接的点表示评估时产生更好损失表现的点（图片由作者提供）。

BlendSearch进一步将CFO使用的局部搜索策略与全局搜索相结合。它利用了CFO的节俭性和全局搜索方法如贝叶斯优化的空间探索能力。具体来说，BlendSearch保持一个全局搜索模型，并逐渐根据全局模型提出的超参数配置创建局部搜索线程。它根据实时性能和成本进一步优先考虑全局搜索线程和多个局部搜索线程。它可以在具有复杂搜索空间的任务中进一步提高CFO的效率，例如包含多个不连续子空间的搜索空间。

## FLAML与贝叶斯优化性能对比

图3展示了FLAML中经济HPO方法（图中CFO标记为`LS`）与用于调整11个超参数的XGBoost的贝叶斯优化（BO）方法的典型行为。

从图3(a)中，我们观察到BO中提出的配置的评估时间可能非常长。当总资源有限时，例如1个CPU小时（或更少），BO无法提供令人满意的结果（图3(b)）。

FLAML的CFO（标记为LS）和BlendSearch在快速找到良好配置方面具有明显优势：它们能够集中在评估时间低的配置上，同时导航那些具有良好性能的配置，即低损失。

![](../Images/48ce7d9823e8612a6841e19d5028e40d.png)

图3. (a) 是不同方法提出的超参数配置的散点图，x轴和y轴分别为评估时间和损失。超参数配置的评估时间是指在训练数据上训练一个机器学习模型并在验证数据集上验证其性能所需的时间。损失是验证损失。 (b) 显示了不同方法在墙钟时间上获得的最佳损失。 ([image source](https://openreview.net/pdf?id=VbLH04pRA3))

## 如何利用 Ray Tune 的分布式调优扩展 CFO 和 BlendSearch

为了加速超参数优化，你可能希望将超参数搜索进行并行化。例如，BlendSearch 能够在并行设置中良好工作：它利用可以独立执行的多个搜索线程，且性能不会明显下降。这种理想特性并不总是适用于现有的优化算法，如贝叶斯优化。

为了实现并行化，FLAML 与 Ray Tune 集成。Ray Tune 是一个 Python 库，通过允许你利用前沿优化算法进行大规模加速超参数调整。Ray Tune 还允许你将超参数搜索从你的笔记本电脑扩展到集群，而无需更改代码。你可以在 FLAML 中使用 Ray Tune，也可以在 Ray Tune 中运行 FLAML 的超参数搜索方法来并行化搜索。以下代码示例展示了前者的用法，通过简单地配置 FLAML 中的 `n_concurrent_trials` 参数实现。

```py
'''Use BlendSearch for hyperparameter search, and Ray Tune for parallelizing concurrent trials (when n_concurrent_trials > 1) in FLAML to tune XGBoost'''
**from** flaml **import** AutoML
automl = AutoML()
automl.add_learner(learner_name='my_xgboost', learner_class=MyXGB)
automl.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='bs', n_concurrent_trials=8)
```

![](../Images/a14bf0e97837d77213d5398128880542.png)

Logo 来源 ([XGBoost](https://github.com/dmlc/xgboost), [FLAML](https://github.com/microsoft/FLAML), [Ray Tune](https://github.com/ray-project/ray))

下面的代码展示了后者的用法，即如何在 Ray Tune 中使用 BlendSearch 的端到端示例。

```py
**from** ray **import** tune 
**from** flaml **import** CFO, BlendSearch
**import** time

**def** **training_func**(config):
    '''evaluate a hyperparameter configuration'''
    # we use a toy example with 2 hyperparameters
    metric = (round(config['x'])-85000)**2 - config['x']/config['y']

    # usually the evaluation takes a non-neglible cost
    # and the cost could be related to certain hyperparameters
    # in this example, we assume it's proportional to x
    time.sleep(config['x']/100000)
    # use tune.report to report the metric to optimize    
    tune.report(metric=metric) 

# provide the search space
search_space = {
        'x': tune.lograndint(lower=1, upper=100000),
        'y': tune.randint(lower=1, upper=100000)
    }

# provide the low cost partial config
low_cost_partial_config={'x':1}

# set up BlendSearch
blendsearch = BlendSearch(
    metric="metric", mode="min",
    space=search_space,
    low_cost_partial_config=low_cost_partial_config)

blendsearch.set_search_properties(config={"time_budget_s": 60})

analysis = tune.run(
    training_func,    # the function to evaluate a config
    config=search_space,
    metric='metric',    # the name of the metric used for optimization
    mode='min',         # the optimization mode, 'min' or 'max'
    num_samples=-1,    # the maximal number of configs to try, -1 means infinite
    time_budget_s=60,   # the time budget in seconds
    local_dir='logs/',  # the local directory to store logs
    search_alg=blendsearch  # or cfo
    )

print(analysis.best_trial.last_result)  # the best trial's result
print(analysis.best_config)  # the best config
```

其他主要 Ray Tune 功能包括：

+   与 Tensorboard 和 Weights/Biases 等实验跟踪工具的自动集成

+   支持 GPU

+   提前停止

+   一个 scikit-learn API，方便与[XGBoost](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)、[LightGBM](https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray)、[Scikit-Learn](https://github.com/ray-project/tune-sklearn)等集成。

## 基准结果

我们进行了一项实验，以检查在高度并行化环境中，BlendSearch 与 Optuna（使用多变量 TPE 采样器）和随机搜索的表现对比。我们使用了来自[AutoML Benchmark](https://www.openml.org/s/218)的12个数据集的子集。每次优化运行均以16个并行试验进行，为期20分钟，采用3折交叉验证，使用 ROC-AUC（多类数据集的加权一对其余）。这些运行重复三次，使用不同的随机种子。复现代码可以在[这里](https://github.com/Yard1/Blendsearch-on-Ray-benchmark)找到。

![](../Images/d8580e50635a1d1a0d2d0cdd7c82268e.png)

图片由作者提供

BlendSearch 在 12 个数据集中的 6 个数据集中达到了最佳的交叉验证得分。此外，BlendSearch 比随机搜索的平均提升了 2.52%，而 Optuna 的提升为 1.96%。值得注意的是，BlendSearch 使用的是单变量的 Optuna-TPE 作为其全局搜索器——使用多变量 TPE 很可能会进一步提高得分。

![](../Images/c286e797360d45720a6c4d34881c0612.png)

图片由作者提供

此外，由于其节省成本的方法，BlendSearch 在相同的时间限制内平均评估的试验次数是其他搜索器的两倍。这表明，随着时间预算的增加，BlendSearch 与其他算法之间的差距将会扩大。

## 结论

FLAML 是一个新发布的库，包含了 [最先进的](https://arxiv.org/abs/2005.01571) 超参数优化算法，这些算法利用搜索空间的结构来同时优化成本和模型性能。FLAML 还可以利用 [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) 进行分布式超参数调优，以在集群中扩展这些经济高效的 AutoML 方法。

欲了解更多关于 FLAML 的信息，请参见 [GitHub 仓库](https://github.com/microsoft/FLAML) 和 [项目页面](https://aka.ms/flaml)。如果您希望跟进 Ray 的最新动态，请考虑 [关注 @raydistributed 在 Twitter 上](https://twitter.com/raydistributed) 并 [注册新闻简报](https://anyscale.us5.list-manage.com/subscribe?u=524b25758d03ad7ec4f64105f&id=d94e960a03)。

[原文](https://towardsdatascience.com/fast-automl-with-flaml-ray-tune-64ff4a604d1c)。已获许可转载。

**相关：**

+   [使用 TPOT 进行机器学习管道优化](/2021/05/machine-learning-pipeline-optimization-tpot.html)

+   [自动化机器学习中的二分类](/2021/05/binary-classification-automated-machine-learning.html)

+   [Hugging Face 的 AutoNLP 概述及示例项目](/2021/06/overview-autonlp-hugging-face-example-project.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的 IT

* * *

### 更多相关话题

+   [如何微调 ChatGPT 3.5 Turbo](https://www.kdnuggets.com/how-to-finetune-chatgpt-35-turbo)

+   [如何使用 Hugging Face AutoTrain 微调 LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)

+   [如何使用 Hugging Face Transformers 微调 BERT 进行情感分析](https://www.kdnuggets.com/how-to-fine-tune-bert-sentiment-analysis-hugging-face-transformers)

+   [BERT 在稀疏性下能有多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)

+   [通过快速克里金（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)

+   [如何让 Python 代码运行得极快](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)
