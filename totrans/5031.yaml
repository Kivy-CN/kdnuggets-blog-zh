- en: America’s Next Topic Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/07/americas-next-topic-model.html](https://www.kdnuggets.com/2016/07/americas-next-topic-model.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Lev Konstantinovskiy, RaRe Technologies**.'
  prefs: []
  type: TYPE_NORMAL
- en: '"How to choose the best topic model?" is the #1 question on our community mailing
    list. At RaRe Technologies I manage the community for the Python open source topic
    modeling package [gensim](https://github.com/RaRe-Technologies/gensim). As so
    many people are looking for the answer, we’ve recently released an updated gensim
    0.13.1 incorporating several new exciting features which evaluate if your model
    is any good, helping you to select the best topic model.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Probably words](../Images/92cd05203ef7dab55314f8d5d082f309.png)](https://i.imgur.com/9UesuuB.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Fig 1**. Top: 15 most probable words for four selected topics. Bottom: a
    text document with words colored according to which topic they belong to. Taken
    from [Latent Dirichlet Allocation paper by David M. Blei.](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)*'
  prefs: []
  type: TYPE_NORMAL
- en: What is Topic Modeling?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Topic modeling is a technique for taking some unstructured text and automatically
    extracting its common themes, using machine learning. It is a great way to get
    a bird's eye view on a large text collection.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick recap on what topic modeling does: a topic is a probability distribution
    over the vocabulary. For example, if we were to create three topics for the Harry
    Potter series of books manually, we might come up with something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: (*the Muggle topic*) 50% “Muggle”, 25% “Dursey”, 10% “Privet”, 5% “Mudblood”...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (*the Voldemort topic*) 65% “Voldemort”, 12% “Death”, 10% “Horcrux”, 5% “Snake”...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (*the Harry topic*) 42% “Harry Potter”, 15% “Scar”, 7% “Quidditch”, 7% “Gryffindor”...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the same way, we can represent individual documents as a probability distribution
    over topics. For example, Chapter 1 of Harry Potter book 1 introduces the Dursley
    family and has Dumbledore discuss Harry’s parent’s death. If we take this chapter
    to be a single document, it could be broken up into topics like this: 40% Muggle
    topic, 30% Voldemort topic, and the remaining 30% is the Harry topic.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we don’t want to extract the topics and document probabilities by
    hand like this. We want the machine to do it automatically using our unlabelled
    text collection as the only input. Because there is no document labeling nor human
    annotations, topic modeling an example of an unsupervised machine learning technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another, more practical example would be breaking your internal company documents
    into topics, providing a bird''s eye view of their contents for convenient visualization
    and browsing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Bird''s eye view](../Images/4e3270245e3fcacb881162095bf3ca66.png)](/wp-content/uploads/birds-eye-view.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Fig 2**. Use topic models to create bird’s eye view of internal company
    documents, with an option to drill down into individual documents by their topic
    (rather than just keywords).*'
  prefs: []
  type: TYPE_NORMAL
- en: Latent Dirichlet Allocation = LDA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most popular topic model in use today is [Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).
    To understand how this works, Edwin Chen’s [blog post](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/)
    is a very good resource. This [link](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation)
    has a nice repository of explanations of LDA, which might require a little mathematical
    background. This [paper](https://www.cs.princeton.edu/~blei/papers/Blei2012.pdf)
    by David Blei is a good go-to as it sums up various types of topic models which
    have been developed to date.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to get your hands dirty with some nice LDA and vector space code,
    the [gensim tutorial](https://radimrehurek.com/gensim/tutorial.html) is always
    handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing the Best Topic Model: Coloring words'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once you have your topics the next step is to determine if they are any good
    or not. If they are, then you would simply go ahead and plug them into your collection
    browser or classifier. If not, maybe you should train the model a bit more or
    with different parameters.
  prefs: []
  type: TYPE_NORMAL
- en: One of the ways to analyze the model is to color document words depending on
    the topic they belong to. This feature was recently added to gensim by our 2016
    Google Summer of Code student Bhargav. You can take a look at the Python code
    in this [notebook](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb).
    Figure 1 above is an example of this functionality from the original LDA paper
    by David Blei.
  prefs: []
  type: TYPE_NORMAL
- en: An interesting example would be the word ‘bank’ which could mean ‘a financial
    institution’ or ‘a river bank’. A good topic modeling algorithm can tell the difference
    between these two meanings based on context. Coloring words is a quick way to
    assess if the model understands their meaning and if it is any good.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we trained two topic models on a toy corpus of nine documents.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: One LDA model is trained for 50 iterations and another is trained for just one
    iteration. We expect the model to get better the longer we train it.
  prefs: []
  type: TYPE_NORMAL
- en: You may notice that the texts above don’t look like the texts we are used to,
    instead they are actually Python lists. It is because we converted them to a [Bag
    of Words](https://en.wikipedia.org/wiki/Bag-of-words_model) representation. That
    is how the LDA model sees text. The word order doesn’t matter and some very frequent
    words are removed. For example 'A bank of a fast river.' becomes ['bank', 'river',
    'fast'] in Bag of Words format.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how good the two models are at distinguishing between a ‘river bank’
    and a ‘financial bank. If all the words in a document are about nature then our
    swing word ‘bank’ should become a “river bank” colored in the nature topic color
    of ‘blue’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`**bank river water tree**`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`**bank river water tree**`'
  prefs: []
  type: TYPE_NORMAL
- en: The good model successfully completes this task while the bad model thinks it
    is a ‘financial bank’ and colors it red.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing the Best Topic Model: pyLDAvis'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can also tell the better trained model fits quite well because it has clear
    Nature and Finance topics. The visualisation below is from pyLDAvis, a wonderful
    visualisation tool for qualitative assessment of Topic Models. You can play interactively
    with this particular visualization in this [Jupyter notebook](http://nbviewer.jupyter.org/github/dsquareindia/gensim/blob/a4b2629c0fdb0a7932db24dfcf06699c928d112f/docs/notebooks/topic_coherence_tutorial.ipynb).There
    is also a great introduction to pyLDAvis from its creator Ben Mabey in [his talk
    on YouTube](https://www.youtube.com/watch?v=tGxW2BzC_DU&index=4&list=PLykRMO7ZuHwP5cWnbEmP_mUIVgzd5DZgH).
  prefs: []
  type: TYPE_NORMAL
- en: '[![Good topic model](../Images/66ad9397f4928b9457fe6df1984cfc20.png)](/wp-content/uploads/good-model-pyldavis.gif)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Fig 3**. Good Topic Model in pyLDAvis. Most relevant words are shown on
    the right for the circle (topic) highlighted in red. The blue bar next to the
    word, for example ‘bank’, corresponds to the frequency of the word ‘bank’ appearing
    in the collection of documents. The red part of the bar is the frequency of the
    term ‘bank’ in the selected topic. We can confidently name topic #1 a Finance
    topic because the words shown next to it are exactly what we would expect in Finance:
    ‘bank’, ‘trading’, ‘option’ and ’rate’. Also the word ‘bank’ appears most often
    in this topic as it has a large red bar.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Bad topic model](../Images/0d8af773b538237e0830383560b66655.png)](/wp-content/uploads/bad-model-pyldavis.gif)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Fig 4**. Bad Topic Model in pyLDAvis. The words inside a topic don’t relate
    to each other. Let’s compare a good model trained for 50 iterations (9*50 = 450
    total documents) to a bad untrained model, trained only for 1 iteration (nine
    documents). It has very unrelated words in one topic. Both ‘tree’ and ‘trading’
    appear in the list for the same topic #2\. We would expect to see them in different
    ones: ‘tree’ relates to Nature and ‘trading’ should be in Finance. So this topic
    model doesn’t make sense.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing the Best Topic Model: Quantitative approach'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is a new gensim feature to automatically choose the best model without
    a manual visualisation in pyLDAvis or word coloring. It is called ‘topic coherence’.
     One of the students currently enrolled in our [Incubator program](http://rare-technologies.com/incubator/),
    Devashish, has implemented this in Python based on paper by [Michael Röder et
    al](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an interesting twist here. Surprisingly, a mathematically rigorous
    calculation of model fit (data likelihood, perplexity) doesn''t always agree with
    human opinion about the quality of the model, as shown in a well-titled paper
    "[Reading Tea Leaves: How Humans Interpret Topic Models](https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models)".
    But another [formula](http://palmetto.aksw.org/palmetto-webapp/) has been found
    to correlate well with human judgement. It is called ''C_v topic coherence''.
    It measures how often the topic words appear together in the corpus. Of course,
    the trick is how to define ‘together’. Gensim supports several topic coherence
    measures including C_v. You can explore them in this [Jupyter notebook](http://nbviewer.jupyter.org/github/dsquareindia/gensim/blob/a4b2629c0fdb0a7932db24dfcf06699c928d112f/docs/notebooks/topic_coherence_tutorial.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: As expected from our manual inspections above, the model which trained for 50
    epochs has higher coherence. Now you can automatically choose the best model using
    this number.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have covered three ways to evaluate a topic model – coloring words, pyLDAvis
    and topic coherence. The one you choose depends on the number of models and topics.
    If you have a handful of models and a small number of topics, then you could run
    the manual inspections in a reasonable amount of time. Coloring swing words in
    your specific domain is an important one to get right. In other situations manual
    inspections are not feasible. For example, if you’ve run an LDA parameter grid
    search and have a lot of models, or if you have thousands of topics. In that case
    the only way is the automated topic coherence to find the most coherent model,
    then a quick manual validation of the winner with word coloring and pyLDAvis.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you find these model selection techniques useful in your NLP applications!
    Let us know if you have any questions about them on the [gensim mailing list](https://groups.google.com/forum/#!forum/gensim).
    We also offer [NLP consulting services](http://rare-technologies.com/services/)
    at RaRe Technologies.
  prefs: []
  type: TYPE_NORMAL
- en: '![Lev KDN.jpg](../Images/ff97d9ccca765b9680325f8b10afbfec.png)**Bio: Lev Konstantinovskiy**,
    an expert in natural language processing, is a Python and Java developer. Lev
    has extensive experience working with financial institutions and is RaRe’s manager
    of open source communities including [gensim](https://github.com/RaRe-Technologies/gensim),
    an open source machine learning toolkit for understanding human language. Lev
    holds the position of Open Source Evangelist, R&D at [RaRe Technologies](http://rare-technologies.com).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[HPE Haven OnDemand Text Extraction API Cheat Sheet for Developers](/2016/06/hpe-haven-ondemand-text-extraction-cheat-sheet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mining Twitter Data with Python Part 1: Collecting Data](/2016/06/mining-twitter-data-python-part-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Text Mining 101: Topic Modeling](/2016/07/text-mining-101-topic-modeling.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Topic Modeling Approaches: Top2Vec vs BERTopic](https://www.kdnuggets.com/2023/01/topic-modeling-approaches-top2vec-bertopic.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Falcon2: Next-Gen Language Model by TII](https://www.kdnuggets.com/introducing-falcon2-next-gen-language-model-by-tii)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Advance your data science career to the next level](https://www.kdnuggets.com/2021/12/sas-advance-data-science-career-next-level.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Junior Data Scientist: The Next Level](https://www.kdnuggets.com/2022/02/junior-data-scientist-next-level.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24 SQL Questions You Might See on Your Next Interview](https://www.kdnuggets.com/2022/06/24-sql-questions-might-see-next-interview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
