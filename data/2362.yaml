- en: Top 5 Machine Learning Practices Recommended by Experts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专家推荐的前 5 种机器学习最佳实践
- en: 原文：[https://www.kdnuggets.com/2022/09/top-5-machine-learning-practices-recommended-experts.html](https://www.kdnuggets.com/2022/09/top-5-machine-learning-practices-recommended-experts.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/09/top-5-machine-learning-practices-recommended-experts.html](https://www.kdnuggets.com/2022/09/top-5-machine-learning-practices-recommended-experts.html)
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/75a17310ddc230734baba2099a6c2b0d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前 5 种机器学习最佳实践](../Images/75a17310ddc230734baba2099a6c2b0d.png)'
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT 维护'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Machine learning has been a subject of intense media hype with more organizations
    adopting this technology to handle their everyday tasks. Machine learning practitioners
    may be able to present the solution but enhancing the model performance can be
    very challenging at times. It is something that comes with practice and experience.
    Even after trying out all the strategies, we often fail to improve the accuracy
    of the model. Therefore, this article is intended to help beginners improve their
    model structure by listing the best practices recommended by machine learning
    Experts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习一直是媒体热炒的话题，越来越多的组织采用这种技术来处理日常任务。机器学习从业者可能能够提出解决方案，但提升模型性能有时可能非常具有挑战性。这需要实践和经验。即使尝试了所有策略，我们仍然经常无法提高模型的准确性。因此，本文旨在通过列出机器学习专家推荐的最佳实践，帮助初学者改进他们的模型结构。
- en: Best Practices
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳实践
- en: 1\. Focusing on the data
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 专注于数据
- en: 'The importance of the data cannot be ignored in the world of machine learning.
    Both the quality and the quantity of the data can lead to stronger model performance.
    It''s often time taking and more complex than crafting the machine learning models
    themselves. This step is often referred to as data preparation. It can be further
    classified into the following steps:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的世界中，数据的重要性不容忽视。数据的质量和数量都能显著提升模型性能。这通常比制作机器学习模型本身更耗时和复杂。这个步骤通常被称为数据准备。它可以进一步细分为以下步骤：
- en: '**Articulating the Problem** **-** To avoid overcomplicating your project try
    to get an in-depth knowledge of the underlying problem that you are trying to
    solve. Categorize your problem into classification, regression, clustering or
    recommendation, etc. This simple segmentation can help you collect the relevant
    dataset that is most suitable for your scenario.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**明确问题** **-** 为了避免使项目过于复杂，尽量深入了解您要解决的根本问题。将问题分类为分类、回归、聚类或推荐等。这种简单的细分可以帮助您收集最适合您情境的相关数据集。'
- en: '**Data Collection** **-** Data collection can be a tedious task. As the name
    suggests, it is the collection of historic data to find recurring patterns. It
    can be categorized into structured (excel or .csv files) and unstructured data
    (photos, videos, etc). Some of the famous sources to borrow your dataset are:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集** **-** 数据收集可能是一个繁琐的任务。顾名思义，它是收集历史数据以寻找重复模式。数据可以分为结构化（例如 Excel 或 .csv
    文件）和非结构化数据（例如照片、视频等）。一些著名的数据集来源包括：'
- en: '[DataSet Search (Google)](https://datasetsearch.research.google.com/)'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据集搜索 (Google)](https://datasetsearch.research.google.com/)'
- en: '[OpenML](https://www.openml.org/)'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenML](https://www.openml.org/)'
- en: '[Kaggle](https://www.kaggle.com/datasets)'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle](https://www.kaggle.com/datasets)'
- en: '[VisualData Discovery](https://visualdata.io/discovery)'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VisualData Discovery](https://visualdata.io/discovery)'
- en: '[Amazon Datasets](https://registry.opendata.aws/)'
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Amazon 数据集](https://registry.opendata.aws/)'
- en: '**Data Exploration** **-** This step involves identifying the problems and
    patterns in the dataset with the help of statistical and visualization techniques.
    You have to perform various tasks like spotting the outliers, identifying the
    data distribution and relationship between the features, looking out for inconsistent
    and missing values, etc. **Microsoft Excel** is a popular manual tool used for
    this step.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索** **-** 这一步骤涉及利用统计和可视化技术识别数据集中的问题和模式。你需要执行各种任务，如发现异常值、识别数据分布及特征之间的关系、查找不一致和缺失值等。**Microsoft
    Excel** 是用于此步骤的一个流行手动工具。'
- en: '**Data Cleaning and Validation** **-** It involves weeding out the irrelevant
    information and addressing the missing values by various imputation tools**.**
    Identify and remove the redundant data. A lot of open source options like [OpenRefine](https://openrefine.org/)
    and  [Pandera](https://pypi.org/project/pandera/) etc are available to cleanse
    and validate data.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据清洗和验证** **-** 这涉及到剔除无关信息并通过各种插补工具解决缺失值**。**识别并删除冗余数据。许多开源选项如[OpenRefine](https://openrefine.org/)和[
    Pandera](https://pypi.org/project/pandera/)等可用于清洗和验证数据。'
- en: 2\. Feature Engineering
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 特征工程
- en: 'It is another essential technique to improve model performance and speed up
    data transformation.  Feature engineering involves infusing new features into
    your model from features that are already available. It can help us identify the
    robust features and remove the correlated or redundant ones. However, it requires
    domain expertise and may not be feasible if our initial baseline already includes
    a diverse set of features. Let''s understand it from an example. Consider that
    you have a dataset containing the length, width, and price of the house as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一种提高模型性能和加快数据转换的基本技术。特征工程涉及从已有特征中注入新特征到模型中。它可以帮助我们识别强健的特征并去除相关或冗余的特征。然而，它需要领域专业知识，如果我们的初始基线已经包含多样的特征，可能不可行。让我们通过一个例子来理解这一点。假设你有一个数据集，包含房屋的长度、宽度和价格，如下所示：
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/7480347eeecdb6aa0dfd3d08d3a31dca.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前 5 个机器学习实践](../Images/7480347eeecdb6aa0dfd3d08d3a31dca.png)'
- en: Instead of going with the above dataset, we can introduce another feature named
    “Area” and measure only the impact of that variable on the Price of the house.
    This process falls under the category of **Feature Creation.**
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与其使用上述数据集，我们可以引入另一个名为“面积”的特征，并仅测量该变量对房价的影响。这个过程属于**特征创建**的范畴。
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/239a4cf0346ed5456a62a7c61caac8d5.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前 5 个机器学习实践](../Images/239a4cf0346ed5456a62a7c61caac8d5.png)'
- en: Similarly, **Feature Transformation** and **Feature Extraction** can prove valuable
    depending on our project domain. Feature Transformation involves applying the
    transformation function on a feature for a better visualization while in Feature
    Extraction, we compress the amount of data by only extracting the relevant features.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，**特征转换**和**特征提取**根据我们的项目领域可能会证明有价值。特征转换涉及对特征应用转换函数以获得更好的可视化，而在特征提取中，我们通过仅提取相关特征来压缩数据量。
- en: 'Although, **Feature Scaling** is also a part of Feature Engineering I have
    discussed it separately to focus on its importance. Feature Scaling is the method
    used to normalize the range of independent variables and features. **Why is this
    step so important?** Most algorithms like linear regressions, logistic regression,
    and neural networks make use of gradient descent as an optimization technique.
    Gradient descent heavily depends upon the range of features to determine the step
    size towards the minima but most of our data vary drastically in terms of ranges.
    This thing compels us to normalize or standardize our data before feeding it into
    the model. The two most important techniques in this regard are:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**特征缩放**也是特征工程的一部分，我单独讨论了它，以强调其重要性。特征缩放是用于标准化自变量和特征范围的方法。**为什么这个步骤如此重要？**大多数算法如线性回归、逻辑回归和神经网络使用梯度下降作为优化技术。梯度下降严重依赖于特征的范围来确定向最小值的步长，但我们的大多数数据在范围上变化剧烈。这迫使我们在将数据输入模型之前进行标准化或规范化。对此，最重要的两种技术是：
- en: '**Normalization** **-**  Normalization is the technique to bound your data
    typically between ranges [0,1] but you can also define your range [a,b] where
    a and b are real numbers.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化** **-** 归一化是一种将数据限制在通常范围[0,1]之间的技术，但你也可以定义范围[a,b]，其中a和b是实数。'
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/050cdba749c836c4a1ef8f8dcd4e1657.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前五大机器学习实践](../Images/050cdba749c836c4a1ef8f8dcd4e1657.png)'
- en: '**Standardization** **-** Standardization transforms your data to have a mean
    of 0 and a variance of 1\. We first calculate the standard deviation and mean
    of the feature and then calculate the new value using this formula:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化** **-** 标准化将数据转换为均值为0，方差为1。我们首先计算特征的标准差和均值，然后使用以下公式计算新值：'
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/5d629fc90db84cc81bcbc7775a31eaea.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前五大机器学习实践](../Images/5d629fc90db84cc81bcbc7775a31eaea.png)'
- en: There has been a lot of debate to determine which one is better and some findings
    showed that for a gaussian distribution, standardization was more helpful as it
    was not affected by the presence of outliers and vice versa. But, it depends upon
    the type of problem that you are working on. Hence, it's highly recommended to
    test both and compare performance to figure out what works best for you.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于哪一种更好的讨论已经很多，一些研究表明，对于高斯分布，标准化更有帮助，因为它不受异常值的影响，反之亦然。但这取决于你所处理的问题类型。因此，强烈建议同时测试两者并比较性能，以找出最适合你的方法。
- en: 3\. Play with regularization
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 玩转正则化
- en: 'You might have encountered a situation when your machine learning models perform
    exceptionally well on your training data but fails to perform well on the test
    data. This happens when your model is **overfitting** your training data. Although
    there are a lot of methods to combat overfitting like dropping out layers, reducing
    the network capacity, Early stopping, etc but regularization outperforms all.
    **What exactly is Regularization?** Regularization is a technique that prevents
    overfitting by shrinking the coefficients. This results in a simplified model
    that performs more efficiently while making predictions. There are two types of
    regularization:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能遇到过这种情况：你的机器学习模型在训练数据上表现得非常好，但在测试数据上表现不佳。这发生在你的模型**过拟合**了训练数据。尽管有很多方法可以应对过拟合，比如丢弃层、减少网络容量、提前停止等，但正则化的表现超过所有方法。**什么是正则化？**
    正则化是一种通过缩小系数来防止过拟合的技术。这会导致一个简化的模型，在进行预测时表现得更加高效。正则化有两种类型：
- en: '**L1 Regularization** **-** It is also known as Lasso Regression. It forces
    some of the coefficients estimates to exactly become zero by adding a penalty
    to the absolute value of the magnitude of coefficients. It forms a sparse model
    and is useful for feature selection.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L1 正则化** **-** 也被称为套索回归。它通过向系数绝对值的大小添加惩罚，迫使一些系数估计值恰好为零。它形成一个稀疏模型，对特征选择有用。'
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/4d1b9343fd3381b6c575eedd8ecd03c0.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前五大机器学习实践](../Images/4d1b9343fd3381b6c575eedd8ecd03c0.png)'
- en: '**L2 Regularization** **-** It is also known as Ridge Regression. It penalizes
    the model by adding the square of the absolute value of the magnitude of the coefficients.
    Hence, it forces the coefficients to have a value close to zero but not exactly
    zero. It improves the interpretability of the model.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L2 正则化** **-** 也被称为岭回归。它通过添加系数绝对值的平方来惩罚模型。因此，它迫使系数的值接近零但不完全为零。它提高了模型的可解释性。'
- en: '![Top 5 Machine Learning Practices Recommended by Experts](../Images/1109a6d2b02c79f8caecbbd6a4125ba7.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![专家推荐的前五大机器学习实践](../Images/1109a6d2b02c79f8caecbbd6a4125ba7.png)'
- en: Although L2 regularization gives a more accurate prediction than L1 it comes
    at the cost of computational power. L2 may not be the best choice in case of outliers
    as the cost increases exponentially due to the presence of a square. Hence, L1
    is more robust as compared to L2.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管L2正则化比L1给出更准确的预测，但这以计算能力为代价。在存在异常值的情况下，L2可能不是最佳选择，因为由于平方的存在，成本会呈指数增长。因此，与L2相比，L1更具鲁棒性。
- en: 4\. Identifiying the errors
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 识别错误
- en: 'It is really important that we keep the track of what kind of errors our model
    is making for optimization purposes. This task can be performed by means of various
    visualization plots depending upon the type of problem to be solved. Some of them
    are discussed below:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是我们要跟踪模型所犯的错误，以便进行优化。这个任务可以通过各种可视化图来完成，具体取决于待解决问题的类型。以下是一些讨论的内容：
- en: '**Classification** **-** Classification models are the subset of supervised
    learning that classifies the input into one or more categories based on the generated
    output. Classification models can be visualized by means of various tools such
    as:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类 -** 分类模型是监督学习的一个子集，根据生成的输出将输入分类为一个或多个类别。可以通过各种工具来可视化分类模型，例如：'
- en: '**Classification Report - **It is an evaluation metric that shows the precision,
    F1 score, Recall, and Support. It gives a good overall understanding of your model’s
    performance.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类报告 -** 这是一个评估指标，显示了精确度、F1 分数、召回率和支持度。它提供了对模型性能的整体理解。'
- en: '**Confusion Matrix -** It compares the true values with the predicted ones.
    As compared to the classification report, It provides a deeper insight into the
    classification of individual data points rather than top-level scores.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混淆矩阵 -** 它将真实值与预测值进行比较。与分类报告相比，它提供了对单个数据点分类的更深入的见解，而不仅仅是顶层分数。'
- en: '**Regression** **-** A Regression model predicts the relationship between the
    independent and dependent variables by providing the desired function. It makes
    the predictions in continuous space and the following are the evaluation metrics
    used for it:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归 -** 回归模型通过提供期望的函数来预测自变量和因变量之间的关系。它在连续空间中进行预测，以下是用于回归的评估指标：'
- en: '**Residual Plots -** It shows the independent variables along the horizontal
    axis and the residuals on the vertical axis. If the data points are randomly dispersed
    across the horizontal axis then a linear model is a more appropriate fit and vice
    versa.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残差图 -** 它显示水平轴上的自变量和垂直轴上的残差。如果数据点在水平轴上随机分布，则线性模型更适合，反之亦然。'
- en: '**Prediction Error Plots -** It shows the actual target against the predicted
    values to give an idea about the variance. A 45-degree line is where the prediction
    exactly matches the model.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测误差图 -** 它显示实际目标与预测值的对比，以提供关于方差的想法。45度线是预测与模型完全匹配的地方。'
- en: 5\. Hyperparameter tunining
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 超参数调优
- en: 'Hyperparameters are set of parameters that cannot be learned by the algorithm
    itself and are set before the learning process begins e.g learning_rate (alpha),mini-batch
    size, No of layers, No of hidden units, etc. **Hyperparameter tuning** refers
    to the process of selecting the most optimal hyperparameters for a learning algorithm
    that minimizes the loss function. In a simpler network, we experiment on separate
    versions of the model and with different combinations of the hyperparameters but
    this may not be the suitable option for the more complex networks. In that case,
    we make the optimal selection based on prior knowledge. Some of the widely used
    hyperparameter tuning methods to make an appropriate selection from the range
    of a hyperparameter space are as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是一组不能由算法本身学习的参数，并在学习过程开始之前设置，例如学习率（alpha）、小批量大小、层数、隐藏单元数等。**超参数调优** 指的是选择最优超参数的过程，以最小化损失函数。在简单的网络中，我们对模型的不同版本和超参数组合进行实验，但对于更复杂的网络，这可能不是合适的选择。在这种情况下，我们根据先前的知识进行最优选择。以下是一些广泛使用的超参数调优方法，以便在超参数空间范围内进行适当的选择：
- en: '**Grid Search** **-** It is the traditional and most commonly used method for
    hyperparameter tuning. It involves selecting the best set from the grid containing
    all the possible combinations of hyperparameters. However, it needs more computational
    power and time to perform its operation.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索 -** 这是传统的和最常用的超参数调优方法。它涉及从包含所有可能超参数组合的网格中选择最佳集合。然而，它需要更多的计算能力和时间来执行操作。'
- en: '**Random Search** **-** Instead of trying every combination, it selects the
    set of values in a random fashion from the grid to find the most optimum ones.
    It saves unnecessary computational power and time as compared to Grid search.
    Since no intelligence is being used, so luck plays a part in it and it yields
    high variance.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索** **-** 它不是尝试每一种组合，而是从网格中随机选择一组值来找到最优值。与网格搜索相比，它节省了不必要的计算能力和时间。由于没有使用智能，因此运气也起到作用，结果的方差较高。'
- en: '**Bayesian Search** **-** It is used in applied machine learning and outperforms
    Random Search. It makes use of the **Bayes theorem** and takes into account the
    result of the previous iteration to improve the result of the next one. It needs
    an objective function that minimizes the loss. It works by creating a surrogate
    probability model of the objective function, then finding the best hyperparameters
    for the surrogate model, it is then applied to the original model and updates
    the surrogate model, and estimates the objective function. This process is repeated
    until we find the optimum solution for the original model. It does take less iteration
    but a longer time is required for each iteration.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯搜索** **-** 它在应用机器学习中被使用，且优于随机搜索。它利用**贝叶斯定理**并考虑前一轮的结果，以改进下一轮的结果。它需要一个能够最小化损失的目标函数。它通过创建目标函数的代理概率模型来工作，然后寻找代理模型的最佳超参数，接着将其应用到原始模型中，并更新代理模型，估计目标函数。这一过程会被重复，直到找到原始模型的最佳解。它确实需要较少的迭代，但每次迭代需要较长时间。'
- en: In the above-mentioned methods, there is a trade-off between the number of iterations,
    runtime, and maximizing performance. Hence, the ideal method for your case depends
    on your priorities.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述方法中，迭代次数、运行时间和性能最大化之间存在权衡。因此，您案例中的理想方法取决于您的优先事项。
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Machine learning and deep learning require good computational resources and
    subject matter expertise. Building ML models is an iterative process that involves
    realizing various tips to improve the overall model performance. I have listed
    down some of the best practices recommended by the ML experts to access the deficiencies
    in your current model. However, as I always say everything comes with sufficient
    practice and patience so keep on learning from your mistakes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和深度学习需要良好的计算资源和专业知识。构建机器学习模型是一个迭代过程，涉及实现各种技巧以提高整体模型性能。我列出了ML专家推荐的一些最佳实践，以便访问您当前模型的不足之处。然而，正如我总是说的，一切都需要足够的实践和耐心，所以请继续从错误中学习。
- en: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)** is aspiring
    Software Developer who believes in consistent hard work and commitment. She is
    an ambitious programmer with a keen interest in the field of Data Science and
    Machine Learning.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)** 是一名有志的软件开发人员，她相信持续的努力和承诺。她是一名雄心勃勃的程序员，对数据科学和机器学习领域有浓厚的兴趣。'
- en: More On This Topic
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Simple Salary Guide for Tech Experts 2022](https://www.kdnuggets.com/2022/07/simple-salary-guide-tech-experts-2022.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年技术专家简单薪资指南](https://www.kdnuggets.com/2022/07/simple-salary-guide-tech-experts-2022.html)'
- en: '[Why the Newest LLMs use a MoE (Mixture of Experts) Architecture](https://www.kdnuggets.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为何最新的LLMs使用MoE（专家混合）架构](https://www.kdnuggets.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture)'
- en: '[MLOps: The Best Practices and How To Apply Them](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：最佳实践及如何应用](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
- en: '[Best Practices for Creating Domain-Specific AI Models](https://www.kdnuggets.com/2022/07/best-practices-creating-domainspecific-ai-models.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[创建领域特定AI模型的最佳实践](https://www.kdnuggets.com/2022/07/best-practices-creating-domainspecific-ai-models.html)'
- en: '[Integrating ChatGPT Into Data Science Workflows: Tips and Best Practices](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将ChatGPT集成到数据科学工作流中：技巧和最佳实践](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
- en: '[Data Warehousing and ETL Best Practices](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据仓库和ETL最佳实践](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
