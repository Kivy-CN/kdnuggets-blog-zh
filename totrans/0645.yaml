- en: 'Bias in AI: A Primer'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/06/bias-ai-primer.html](https://www.kdnuggets.com/2020/06/bias-ai-primer.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bias in AI is as important now as it ever has been; it has always been an important
    topic, but it seems to be getting more attention as time goes on, attention it
    rightfully deserves. No longer an afterthought in relevant courseware and texts,
    AI bias and the related concepts of ethics, inclusion, and diversity are core
    and early topics in courses such as Stanford''s CS224n: [Natural Language Processing
    with Deep Learning](/2020/05/best-nlp-deep-learning-course-free.html), and the
    upcoming book from the Fast.ai folks titled [Deep Learning for Coders with fastai
    and PyTorch](/2020/06/fastai-book-free-ebook.html), to name but two specific examples.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Aside from the gradually-increasing interest and inclusion of AI bias and ethics
    concerns from and by a wide variety of practitioners in their daily work, numerous
    researchers today are making a focused and very conscious impact as well. [Margaret
    Mitchell](http://m-mitchell.com/) is one such researcher working in this area.
    Mitchell ([@mmitchell_ai](https://twitter.com/mmitchell_ai)) is a Senior Research
    Scientist in Google''s Research & Machine Intelligence group. From her [website](http://m-mitchell.com/),
    as pertains to what it is that she does:'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: My research generally involves vision-language and grounded language generation,
    focusing on how to evolve artificial intelligence towards positive goals. This
    includes research on helping computers to communicate based on what they can process,
    as well as projects to create assistive and clinical technology from the state
    of the art in AI.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'While Margaret''s work obviously goes well beyond the basics, she did give
    an introductory talk on the topic of AI bias for the [winter 2019 iteration](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/)
    of Stanford''s CS224n: Natural Language Processing with Deep Learning, the slides
    for which are available on the course website. The slides (and talk) are titled
    **[Bias in the Vision and Language of Artificial Intelligence](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf)**,
    and are a great resource for those interested in AI bias and ethics but lack an
    entry point.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/42f68e7509eca52bef16da16150e573b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1.** Evaluate for Fairness & Inclusion: Confusion Matrix (from Margaret
    Mitchell''s [Bias in the Vision and Language of Artificial Intelligence slides](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: The talk is a self-contained, single class session of Natural Language Processing
    with Deep Learning (though it covers language, vision, and more "general" AI)
    and is easily digestible in one setting, either via the slides alone or alongside
    the accompanying talk video (see below).
  prefs: []
  type: TYPE_NORMAL
- en: First off, the slides cover (unsurprisingly) a number of specific biases and
    how they affect different aspects of AI systems, including human reporting biases,
    biases in data, interpretation biases, algorithmic biases, and many more. Also
    treated are a number of closely related concepts, such as the effects of prototype
    theory, fairness and inclusion, feedback loops, and unjust AI outcomes, to name
    a few. Additionally, questionable (and worse) projects such as predicting criminality
    from facial images are also discussed, along with their downfalls and biases in
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout, there is an emphasis on the human role in AI bias. Far from being
    an isolated, self-contained technology that exists in a vacuum separate from the
    humans that develop, train, curate data for, operate, and gain insights from,
    AI is a direct reflection of those humans which build and interact with these
    systems. As Mitchell states, "[i]t’s up to us to influence how AI evolves," and
    concrete examples are given of how we can do so.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/54810b601491dd74cad9c3fda41f1715.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2.** Examples of human biases in data and human biases in data collection
    and annotation (from Margaret Mitchell''s [Bias in the Vision and Language of
    Artificial Intelligence slides](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf)).'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned above, the content of the slides is also covered in a video of
    Mitchell's in-class talk which is also freely-available for anyone to view (see
    below), in which you can listen to the author expand upon the material in the
    slides in the hour long effort.
  prefs: []
  type: TYPE_NORMAL
- en: AI bias is a robust domain of study. More importantly, however, while it can
    be treated as its own entity worthy of devoted exploration, it is important that
    non-experts keep bias in mind in the context of AI in general. Simply put, bias
    in artificial intelligence is a concern for all, stakeholders and non-stakeholders,
    technical and non-technical, from researchers to engineers to practitioners to
    product designers and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: It's up to everyone involved to do our collective best to build AI as free from
    bias as possible. As such, gaining a solid understanding of the relevant issues
    in AI bias is a must for everyone, and Margaret Mitchell's slides and accompanying
    talk are a great place to start.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Google Open Sources TFCO to Help Build Fair Machine Learning Models](2020/03/google-open-sources-tfco-fair-machine-learning-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best NLP with Deep Learning Course is Free](/2020/05/best-nlp-deep-learning-course-free.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways to Apply Ethics to AI](/2019/12/5-ways-apply-ethics-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding Bias-Variance Trade-Off in 3 Minutes](https://www.kdnuggets.com/2020/09/understanding-bias-variance-trade-off-3-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dealing with Position Bias in Recommendations and Search](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Bias-Variance Trade-off](https://www.kdnuggets.com/2022/08/biasvariance-tradeoff.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Statistics: A Statology Primer](https://www.kdnuggets.com/introduction-to-statistics-statology-primer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Probability: A Statology Primer](https://www.kdnuggets.com/probability-statology-primer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Describing Data: A Statology Primer](https://www.kdnuggets.com/describing-data-statology-primer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
