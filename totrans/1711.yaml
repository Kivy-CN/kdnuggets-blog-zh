- en: 'Process Mining with R: Introduction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用R进行过程挖掘：介绍
- en: 原文：[https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html](https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html](https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html)
- en: '**By Seppe vanden Broucke, KU Leuven**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Seppe vanden Broucke, KU Leuven**'
- en: Today’s organizations employ a wide range of information support systems to
    support their business processes. Such support systems record and log an abundance
    of data, containing a variety of *events* that can be linked back to the occurrence
    of a task in an originating business process. The field of [*process mining*](http://www.dataminingapps.com/dma_research/process-analytics/) starts
    from these event logs as the cornerstone of analysis and aims to derive knowledge
    to model, improve and extend operational processes “as they happen” in the organization. As
    such, process mining can be situated at the intersection of the fields of Business
    Process Management (BPM) and data mining.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的组织机构采用了各种信息支持系统来支持他们的业务流程。这些支持系统记录并记录了大量的数据，包含各种*事件*，这些事件可以与源业务流程中任务发生的时刻关联起来。而[*过程挖掘*](http://www.dataminingapps.com/dma_research/process-analytics/)以这些事件日志作为分析的基石，旨在从中获取知识，对操作流程进行建模、改进和扩展以“实时”地发生在组织机构中。因此，过程挖掘可以被视为业务流程管理（BPM）和数据挖掘领域的交叉点。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速迈向网络安全的职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 在IT领域支持您的组织'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The most well-known task within the area of process mining is called *process
    discovery* (sometimes also called process identification), where analysts aim
    to derive an as-is process model, starting from the data as it is recorded in
    process-aware information support systems, instead of starting from a to-be descriptive
    model and trying to align the actual data to this model. Process mining builds
    upon existing approaches, though the particular setting and requirements that
    come with event data has led to the creation of various specific tools and algorithms.
    Compared to traditional data mining, where an analyst works (most frequently)
    with a flat table of instances, process mining starts from a *hierarchical and
    intrinsically ordered* data set. Hierarchical as an event log is composed out
    of multiple trails recording the execution of one process instance, which in itself
    is composed out of multiple events. These events are ordered based on their order
    of execution. A prime use case in process mining is hence to abstract this complex
    data set to a visual representation, a process model, highlighting frequent behavior,
    bottlenecks, or any other data dimension that might be of interest to the end
    user.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在过程挖掘领域中最著名的任务被称为*过程发现*（有时也被称为过程识别），分析师的目标是从记录在过程感知信息支持系统中的数据中推导出一个现状流程模型，而不是从一个描述性模型开始，然后尽力使实际数据与此模型对齐。过程挖掘建立在现有方法的基础上，尽管事件数据带来的特定环境和需求导致了各种特定工具和算法的创建。与传统的数据挖掘相比，数据挖掘最初是使用一个平坦的实例表的方式进行的，而过程挖掘则从一个*层次化的和内在有序*的数据集开始。层次化是指事件日志由多个记录一个过程实例的迹组成，而一个过程实例本身由多个事件组成。这些事件基于它们的执行顺序进行排序。因此，过程挖掘的一个主要用例是将这个复杂的数据集抽象成一个可视化的表示，即一个过程模型，突出显示频繁的行为、瓶颈或任何其他可能对最终用户感兴趣的数据维度。
- en: 'Traditional data mining tooling like R, SAS, or Python are powerful to filter,
    query, and analyze flat tables, but are not yet widely used by the process mining
    community to achieve the aforementioned tasks, due to the atypical nature of event
    logs. Instead, an ecosystem of separate tools has appeared, including, among others:
    Disco, Minit, ProcessGold, Celonis Discovery, ProM, and others. In this article,
    we want to provide a quick whirlwind tour on how to create rich process maps using
    a more traditional data science programming language: R. This can come in helpful
    in cases where the tools listed above might not be available, but also provides
    hints on how typical process mining tasks can be enhanced by or more easily combined
    with other more data mining related tasks that are performed in this setting.
    In addition, the direct hands-on approach of working with data will show that
    getting started with process discovery is very approachable. We pick R here as
    our “working language” as the fluidity of modern R (i.e. the “tidyverse” packages,
    with especially “dplyr“) makes for a relatively readable and concise approach,
    though there is no reason why other tools such as Python wouldn’t work just as
    well.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的数据挖掘工具如R、SAS或Python非常强大，可以过滤、查询和分析平面表格，但由于事件日志的非典型特性，尚未被过程挖掘社区广泛采用来实现前述任务。相反，出现了一系列独立的工具生态系统，包括但不限于：Disco，Minit，ProcessGold，Celonis
    Discovery，ProM等。在本文中，我们想要通过使用更传统的数据科学编程语言R，快速介绍如何创建丰富的过程地图。当上述工具可能无法使用时，这将很有帮助，并且还提供了有关如何通过或更容易地结合在此环境中执行的与数据挖掘相关的其他任务来增强典型的过程挖掘任务的提示。此外，直接处理数据的实践方法将显示，开始进行过程发现非常容易。我们选择R作为我们的“工作语言”，因为现代R的流畅性（即“整洁宇宙”包，特别是“dplyr”）使得相对可读且简明的方法成为可能，虽然没有理由认为其他工具如Python也能同样完美地运行。
- en: 'We’re going to use the “[example event log](http://www.dataminingapps.com/dma_research/process-analytics/)”
    provided by Disco as a running example. First, we load in some libraries we’ll
    need and define a few helper functions and load in the event log:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Disco提供的“[示例事件日志](http://www.dataminingapps.com/dma_research/process-analytics/)”作为运行示例。首先，我们加载一些我们需要的库，并定义一些辅助函数并加载事件日志：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next up is the key step of the analysis process: for every event line in the
    event log, we want to figure out (i) the preceding activity, i.e. the activity
    that stopped most recently before the start of this activity in the same case
    and (ii) the following activity, i.e. the activity that started most quickly after
    the completion of this activity in the same case. To do so, we’ll first assign
    an increasing row number to each event and use that to construct two new columns
    to refer to the following and previous event in the event log:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是分析过程的关键步骤：对于事件日志中的每一行事件，我们希望找出（i）前一活动，即在同一案例中在此活动开始之前最近停止的活动，并且（ii）后续活动，即在同一案例中在此活动完成后最快开始的活动。为此，我们首先为每个事件分配一个递增的行号，并使用它来构建两个新列，以引用事件日志中的后续事件和前一个事件：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Using this prepared event log data set, we can already obtain a lot of interesting
    descriptive statistics and insights. For instance, the following block of code
    provides an overview of the different variants (pathways) in the event log:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种准备好的事件日志数据集，我们已经可以获得许多有趣的描述性统计和见解。例如，以下代码块提供了事件日志中不同变体（路径）的概述：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As is the case with many processes, there are a few variants making up the
    largest part of the process instances, followed by a “long tail” of behavior:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多过程相同，有几个变体构成了过程实例的最大部分，其后是“长尾行为”：
- en: '![](../Images/e8a0c33bdf2881846042dc9a1b798f31.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8a0c33bdf2881846042dc9a1b798f31.png)'
- en: 'Next, we construct two data frames containing only the columns we’ll need to
    visualize our process maps, for the activities and edges respectively. We’ll also
    calculate the event durations in this step:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们构建包含活动和边缘的两个数据帧，仅包含我们在可视化过程地图中所需的列。我们还将计算事件持续时间：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This latter requires some considerate thinking. Even although a distinct list
    of (ActivityA-ActivityB)-pairs is sufficient to construct the process map, we
    do need to take into account the correct number of times an arc appears in order
    to calculate frequency and other metrics. We hence first merge the (Case Identifier,
    RowNum, NextNum) listing with (Case Identifier, PrevNum, RowNum) and filter out
    all entries where an endpoint of the arc equals NA. We then apply the “distinct”
    operator to make sure we get a unique listing, albeit at the row number level,
    and not at the activity name level. This makes sure our frequency counts remain
    correct. We can then figure out the endpoints per arc at the activity level by
    joining the event log on itself on both endpoints. We then select, for each arc,
    the case identifier, endpoint row numbers (“a” and “b”), the activity names of
    the endpoints, the activity start and completion times of the endpoints, and the
    duration of the arc based on the endpoints, i.e. the waiting time of the arc.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 后者需要一些周到的思考。尽管一个明确的（活动A-活动B）对列表足以构建流程图，但我们需要考虑弧线出现的次数以计算频率和其他指标。因此，我们首先将（Case
    Identifier，RowNum，NextNum）列表与（Case Identifier，PrevNum，RowNum）合并，并过滤出端点等于NA的所有条目。然后，我们应用“distinct”操作符以确保获得唯一列表，尽管在行号级别上而不是活动名称级别上。这样可以确保我们的频率计数保持正确。然后，我们可以通过在事件日志上两次连接自身来找出每个弧线的活动级端点。然后，我们选择每个弧线的案例标识符，端点行号（“a”和“b”），端点的活动名称，端点的活动开始和完成时间，以及基于端点的弧线持续时间，即弧线的等待时间。
- en: This is all the information we need to start constructing process maps. We’ll
    use the excellent “igraph” package to visualize the process maps. Plotting it
    directly in R, however, gives non-appealing results by default. Sadly, igraph,
    like most graphing tools, is built with the assumption that graphs can be very
    unstructured (think social network graphs), so that the layout for process oriented
    graphs does not look very appealing. Luckily, igraph comes with powerful export
    capabilities that we can use to our benefit. Here, we’ll export our graphs to
    the dot file format and use “Graphviz” to perform the actual layout and generation
    of a resulting image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们开始构建流程图所需的所有信息。我们将使用优秀的“igraph”包来可视化流程图。然而，在R中直接绘制它会得到默认的不吸引人的结果。不幸的是，igraph和大多数图形工具一样，都建立在图形可以非常无结构的假设之上（想象一下社交网络图），因此面向过程的图形的布局看起来并不吸引人。幸运的是，igraph带有强大的导出功能，我们可以利用这个功能。在这里，我们将将图形导出为dot文件格式，并使用“Graphviz”执行实际的布局和生成结果图像。
- en: 'Let’s try this out by creating a process map annotated with median duration
    times for the activities and arcs. First, we’ll define two color gradients for
    the activities and edges respectively, as well as another small helper function,
    and then construct two new activity and edges data frames with the duration information:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试创建一个流程图，其中包含对活动和弧线的中位持续时间的注释。首先，我们将定义两个活动和边缘的颜色渐变，以及另一个小的辅助函数，然后使用持续时间信息构建两个新的活动和边缘数据框：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: More On This Topic
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多关于这个话题的内容
- en: '[How to Process a DataFrame with Millions of Rows in Seconds](https://www.kdnuggets.com/2022/01/process-dataframe-millions-rows-seconds.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在几秒钟内处理数百万行的 DataFrame](https://www.kdnuggets.com/2022/01/process-dataframe-millions-rows-seconds.html)'
- en: '[Frameworks for Approaching the Machine Learning Process](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习过程的框架](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)'
- en: '[3 Ways to Process CSV Files in Python](https://www.kdnuggets.com/2022/10/3-ways-process-csv-files-python.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 处理 CSV 文件的 3 种方法](https://www.kdnuggets.com/2022/10/3-ways-process-csv-files-python.html)'
- en: '[A Gentle Introduction to Natural Language Processing](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理简介](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
- en: '[An Introduction to Hill Climbing Algorithm in AI](https://www.kdnuggets.com/2022/07/introduction-hill-climbing-algorithm-ai.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能中的爬山算法介绍](https://www.kdnuggets.com/2022/07/introduction-hill-climbing-algorithm-ai.html)'
- en: '[An Introduction to SMOTE](https://www.kdnuggets.com/2022/11/introduction-smote.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SMOTE 简介](https://www.kdnuggets.com/2022/11/introduction-smote.html)'
