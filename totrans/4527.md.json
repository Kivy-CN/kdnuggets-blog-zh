["```py\nfrom sklearn.datasets import make_classificationX, y = make_classification(\n    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n    n_informative=3, n_redundant=1, flip_y=0,\n    n_features=20, n_clusters_per_class=1,\n    n_samples=100, random_state=10\n)X = pd.DataFrame(X)\nX['target'] = y\n```", "```py\nnum_0 = len(X[X['target']==0])\nnum_1 = len(X[X['target']==1])\nprint(num_0,num_1)# random undersampleundersampled_data = pd.concat([ X[X['target']==0].sample(num_1) , X[X['target']==1] ])\nprint(len(undersampled_data))# random oversampleoversampled_data = pd.concat([ X[X['target']==0] , X[X['target']==1].sample(num_0, replace=True) ])\nprint(len(oversampled_data))------------------------------------------------------------\nOUTPUT:\n90 10\n20\n180\n```", "```py\nfrom imblearn.under_sampling import TomekLinkstl = TomekLinks(return_indices=True, ratio='majority')X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n```", "```py\nfrom imblearn.over_sampling import SMOTEsmote = SMOTE(ratio='minority')X_sm, y_sm = smote.fit_sample(X, y)\n```", "```py\nfrom sklearn.linear_model import LogisticRegression*clf =* LogisticRegression(*class_weight={0:1,1:10}*)\n```", "```py\nLoss = −*y*log(*p)* − (1−*y*)log(1−*p*)\n```", "```py\nNewLoss = −20**y*log(*p)* − *1**(1−*y*)log(1−*p*)\n```", "```py\nfrom sklearn.utils.class_weight import compute_class_weightclass_weights = compute_class_weight('balanced', np.unique(y), y)\n```", "```py\nfrom sklearn.metrics import f1_score\ny_true = [0, 1, 1, 0, 1, 1]\ny_pred = [0, 0, 1, 0, 0, 1]\n*f1_score(y_true, y_pred)*\n```", "```py\n# y_pred is an array of predictions\ndef bestThresshold(y_true,y_pred):\n    best_thresh = None\n    best_score = 0\n    for thresh in np.arange(0.1, 0.501, 0.01):\n        score = f1_score(y_true, np.array(y_pred)>thresh)\n        if score > best_score:\n            best_thresh = thresh\n            best_score = score\n    return best_score , best_thresh\n```"]