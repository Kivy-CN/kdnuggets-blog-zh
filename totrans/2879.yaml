- en: Scikit-Learn & More for Synthetic Dataset Generation for Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html](https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: It is becoming increasingly clear that the big tech giants such as Google, Facebook,
    and Microsoft are extremely generous with their latest machine learning algorithms
    and packages (they give those away freely) because the entry barrier to the world
    of algorithms is pretty low right now. The open-source community and tools (such
    as scikit-learn) have come a long way, and [plenty of open-source initiatives
    are propelling the vehicles of data science](https://insidebigdata.com/2015/03/16/open-source-software-fuels-a-revolution-in-data-science/),
    digital analytics, and machine learning. Standing in 2018 we can safely say that, [algorithms,
    programming frameworks, and machine learning packages (or even tutorials and courses
    how to learn these techniques) are not the scarce resource but high-quality data
    is.](https://hbr.org/2015/03/data-monopolists-like-google-are-threatening-the-economy)
  prefs: []
  type: TYPE_NORMAL
- en: This often becomes a thorny issue on the side of the practitioners in data science
    (DS) and machine learning (ML) when it comes to tweaking and fine-tuning those
    algorithms. It will also be wise to point out, at the very beginning, that the
    current article pertains to the scarcity of data for algorithmic investigation,
    pedagogical learning, and model prototyping, and not for scaling and running a
    commercial operation. It is not a discussion about how to get quality data for
    the cool travel or fashion app you are working on. That kind of consumer, social,
    or behavioral data collection presents its own issues. However, even something
    as simple as having access to quality datasets for testing out the limitations
    and vagaries of a particular algorithmic method, often turns out, not so simple.
  prefs: []
  type: TYPE_NORMAL
- en: Why Do You Need a Synthetic Dataset?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: If you are learning from scratch, the most sound advice would be to start with
    simple, small-scale datasets which you can plot in two dimensions to understand
    the patterns visually and see for yourself the working of the ML algorithm in
    an intuitive fashion.
  prefs: []
  type: TYPE_NORMAL
- en: As the dimensions of the data explode, however, the visual judgment must extend
    to more complicated matters – concepts like *learning and sample complexity, computational
    efficiency, class imbalance,* etc.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the trade-off between experimental flexibility and the nature
    of the dataset comes into play. **You can always find yourself a large real-life
    dataset to practice the algorithm on. But that is still a fixed dataset, with
    a fixed number of samples, a fixed underlying pattern, and a fixed degree of class
    separation** between positive and negative samples. You must also investigate,
  prefs: []
  type: TYPE_NORMAL
- en: How the chosen fraction of test and train data affects the algorithm’s performance
    and robustness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How robust the metrics are in the face of varying degree of class imbalance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What kind of bias-variance trade-offs must be made.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How the algorithm performs under various noise signature in the training as
    well as test data (i.e., noise in the label as well as in the feature set).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do you experiment and tease out the weakness of your ML algorithm?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It turns out that these are quite difficult to do with a single real-life dataset
    and therefore, you must be willing to work with synthetic data which are random
    enough to capture all the vagaries of a real-life dataset but controllable enough
    to help you scientifically investigate the strength and weakness of the particular
    ML pipeline you are building.
  prefs: []
  type: TYPE_NORMAL
- en: Although we won’t discuss the matter in this article, the potential benefit
    of such synthetic datasets can easily be gauged for sensitive applications – medical
    classifications or financial modeling, where getting hands on a high-quality labeled
    dataset is often expensive and prohibitive.
  prefs: []
  type: TYPE_NORMAL
- en: Essential Features of a Synthetic Dataset for ML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is understood, at this point, that a synthetic dataset is generated programmatically,
    and not sourced from any kind of social or scientific experiment, business transactional
    data, sensor reading, or manual labeling of images. However, such datasets are
    definitely not completely random, and the generation and usage of synthetic data
    for ML must be guided by some overarching needs. In particular,
  prefs: []
  type: TYPE_NORMAL
- en: It can be numeric, binary, or categorical (ordinal or non-ordinal) and the number
    of features and length of the dataset could be arbitrary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There must be some degree of randomness to it but, at the same time, the user
    should be able to choose a wide variety of statistical distribution to base this
    data upon, i.e., the underlying random process can be precisely controlled and
    tuned.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it is used for classification algorithms, then the degree of class separation
    should be controllable to make the learning problem easy or hard.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random noise can be interjected in a controllable manner.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speed of generation should be quite high to enable experimentation with a large
    variety of such datasets for any particular ML algorithms, i.e., if the synthetic
    data is based on data augmentation on a real-life dataset, then the augmentation
    algorithm must be computationally efficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a regression problem, a complex, non-linear generative process can be used
    for sourcing the data – real physics models may come to aid in this endeavor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will show, in the next section, how using some of the most popular ML libraries,
    and programmatic techniques, one is able to generate suitable datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Standard regression, classification, and clustering dataset generation using
    scikit-learn and Numpy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Scikit-learn is the most popular ML library in the Python-based software stack
    for data science. Apart from the well-optimized ML routines and pipeline building
    methods, it also boasts of a solid collection of utility methods for synthetic
    data generation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression with scikit-learn**'
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn’s *dataset.make_regression* function can create random regression
    problem with arbitrary number of input features, output targets, and **controllable
    degree of informative coupling** between them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/657ba8203365893684bc10b7db422899.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Classification with Scikit-learn**'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the regression function above, dataset.make_classification generates
    a random multi-class classification problem with **controllable class separation
    and added noise**. You can also randomly flip any percentage of output signs to
    create a harder classification dataset if you want.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ea8b00bc786b5565f57c111dfeac9e3.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Clustering with Scikit-learn**'
  prefs: []
  type: TYPE_NORMAL
- en: A variety of clustering problems can be generated by scikit-learn utility functions.
    The most straightforward is to use the *datasets.make_blobs*, which generates
    arbitrary number of clusters with controllable distance parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/292621726f680a7ab94415b03c6614d6.png)'
  prefs: []
  type: TYPE_IMG
- en: For testing affinity-based clustering algorithm or Gaussian mixture models,
    it is useful to have clusters generated in a special shape. We can use *datasets.make_circles* function
    to accomplish that.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e97c95527cd22b85be131fed2dba304e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/fb15c4e64f19a76d77bcc3c90df44c21.png)'
  prefs: []
  type: TYPE_IMG
- en: For testing non-linear kernel methods with **support vector machine (SVM)** algorithm,
    nearest-neighbor methods like **k-NN**, or even testing out a simple neural network,
    it is often advisable to experiment with certain shaped data. We can generate
    such data using *dataset.make_moon* function with controllable noise.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7071bf9188177f34d4eb9a2683e1c008.png)'
  prefs: []
  type: TYPE_IMG
- en: '**A gaussian mixture model with Scikit-learn**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Gaussian mixture models (GMM) are fascinating objects to study for unsupervised
    learning and topic modeling in the text processing/NLP tasks. Here is an illustration
    of a simple function to show how easy it is to generate synthetic data for such
    a model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/10dbf89f56b673447617cbaf6bc9ea3f.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/d6a42569513170155593f3da14baf48d.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/28a084e2eeef1eed3a1d81895575456e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/f8e0eb7264d15906f91821e7a858789d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Beyond scikit-learn: Synthetic data from symbolic input'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the functions above may be sufficient for many problems, the data generated
    is truly random, and the user has less control on the actual mech
  prefs: []
  type: TYPE_NORMAL
- en: anics of the generation process. In many situations, one may require a controllable
    way to generate regression or classification problems based on a well-defined
    analytical function (involving linear, nonlinear, rational, or even transcendental
    terms). The following article shows how one can **combine the symbolic mathematics
    package SymPy and functions from SciPy** to generate synthetic regression and
    classification problems from given symbolic expressions.
  prefs: []
  type: TYPE_NORMAL
- en: '[Random regression and classification problem generation with symbolic expression](https://towardsdatascience.com/random-regression-and-classification-problem-generation-with-symbolic-expression-a4e190e37b8d)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d2ec41a8a3cd5fcdb2fb338f13c7151.png)'
  prefs: []
  type: TYPE_IMG
- en: Regression dataset generated from a given symbolic expression.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3b57cc7402e8accd19850f7225bbda9.png)'
  prefs: []
  type: TYPE_IMG
- en: Classification dataset generated from a given symbolic expression.
  prefs: []
  type: TYPE_NORMAL
- en: '**Image data augmentation using scikit-image**'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning systems and algorithms are voracious consumers of data. However,
    to test the limitations and robustness of a deep learning algorithm, one often
    needs to feed the algorithm with subtle variations of similar images. **Scikit-image** is
    an amazing image processing library, built on the same design principle and API
    pattern as that of scikit-learn, offering hundreds of cool functions to accomplish
    this image data augmentation task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following article does a great job of providing a comprehensive overview
    of a lot of these ideas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Augmentation | How to use Deep Learning when you have Limited Data.](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)'
  prefs: []
  type: TYPE_NORMAL
- en: We show some chosen examples of this augmentation process, starting with a single
    image and creating tens of variations on the same to **effectively multiply the
    dataset manifold and create a synthetic dataset of gigantic size** to train deep
    learning models in a robust manner.
  prefs: []
  type: TYPE_NORMAL
- en: '**Hue, Saturation, Value channels**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b34127d9031309c2ca1ce6f8bb1abab.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Cropping**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03b7fa3370116c332105da6c2b9dcd55.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Random noise**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/461cc92ce173811ad8d5d6ab971c9cf0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Rotation**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2b4cb1495a328907c8ac9186f9fcfbf.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Swirl**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/95a563dff0ffbfbc70f721178a37346a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Random image synthesizer with segmentation**'
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA offers a UE4 plugin called NDDS to empower computer vision researchers
    to export high-quality synthetic images with metadata. It supports images, segmentation,
    depth, object pose, bounding box, keypoints, and custom stencils. In addition
    to the exporter, the plugin includes various components enabling the generation
    of randomized images for data augmentation and object detection algorithm training.
    The randomization utilities include lighting, objects, camera position, poses,
    textures, and distractors. Together, these components allow deep learning engineers
    to easily create randomized scenes for training their CNN. Here is the Github
    link,
  prefs: []
  type: TYPE_NORMAL
- en: '[NVIDIA Deep Learning Data Synthesizer](https://github.com/NVIDIA/Dataset_Synthesizer)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Categorical data generation using pydbgen**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pydbgen* is a [lightweight, pure-python library](https://github.com/tirthajyoti/pydbgen) to
    generate random useful entries (e.g. name, address, credit card number, date,
    time, company name, job title, license plate number, etc.) and save them in either
    Pandas dataframe object, or as a SQLite table in a database file, or in an MS
    Excel file. [You can read the documentation here](https://pydbgen.readthedocs.io/en/latest/).
    Here is an article describing its use and utilities,'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introducing pydbgen: A random dataframe/database table generator](https://towardsdatascience.com/introducing-pydbgen-a-random-dataframe-database-table-generator-b5c7bdc84be5)'
  prefs: []
  type: TYPE_NORMAL
- en: Here are a few illustrative examples,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/929da64192dc0676df83ebf465f4decb.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/d296932c57b43adf13658bccefae99d7.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/34f20a7b06934eae55bcd9b99fc3cbd7.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Synthesizing time series dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are quite a few papers and code repositories for generating synthetic
    time-series data using special functions and patterns observed in real-life multivariate
    time series. A simple example is given in the following Github link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Synthetic Time Series](https://nbviewer.jupyter.org/github/tirthajyoti/Machine-Learning-with-Python/blob/master/Synthetic_data_generation/Synth_Time_series.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/096403f26039965b65caae44e143feb2.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Synthetic audio signal dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: Audio/speech processing is a domain of particular interest for deep learning
    practitioners and ML enthusiasts. **Google’s NSynth dataset** is a synthetically
    generated (using neural autoencoders and a combination of human and heuristic
    labeling) library of short audio files sound made by musical instruments of various
    kinds. Here is the detailed description of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[The NSynth dataset](https://magenta.tensorflow.org/datasets/nsynth)'
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic environments for reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**OpenAI Gym**'
  prefs: []
  type: TYPE_NORMAL
- en: The greatest repository for synthetic learning environment for reinforcement
    ML is **OpenAI Gym**. It consists of a large number of pre-programmed environments
    onto which users can implement their reinforcement learning algorithms for benchmarking
    the performance or troubleshooting hidden weakness.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e4d973a51aa33a052967f89f9ca2238d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Random Grid World**'
  prefs: []
  type: TYPE_NORMAL
- en: For beginners in reinforcement learning, it often helps to practice and experiment
    with a simple grid world where an agent must navigate through a maze to reach
    a terminal state with given reward/penalty for each step and the terminal states.
  prefs: []
  type: TYPE_NORMAL
- en: With few simple lines of code, one can synthesize grid world environments with
    arbitrary size and complexity (with a user-specified distribution of terminal
    states and reward vectors).
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at this Github repo for ideas and code examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/tirthajyoti/RL_basics](https://github.com/tirthajyoti/RL_basics)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we went over a few examples of synthetic data generation for
    machine learning. It should be clear to the reader that, by no means, these represent
    the exhaustive list of data generating techniques. In fact, many commercial apps
    other than scikit-learn are offering the same service as the need for training
    your ML model with a variety of data is increasing at a fast pace. However, if,
    as a data scientist or ML engineer, you create your programmatic method of synthetic
    data generation, it saves your organization money and resources to invest in a
    third-party app and also lets you plan the development of your ML pipeline in
    a holistic and organic fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Hope you enjoyed this article and can start using some of the techniques, described
    here, in your projects soon.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://blog.exxactcorp.com/scikit-learn-and-more-synthetic-dataset-generation-for-ml/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[An Introduction to Scikit Learn: The Gold Standard of Python Machine Learning](https://www.kdnuggets.com/2019/02/introduction-scikit-learn-gold-standard-python-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways to Deal with the Lack of Data in Machine Learning](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Synthetic Data Generation: A must-have skill for new data scientists](https://www.kdnuggets.com/2018/12/synthetic-data-generation-must-have-skill.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to Generate Synthetic Tabular Dataset](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How To Use Synthetic Data To Overcome Data Shortages For Machine…](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Synthetic Data for Machine Learning](https://www.kdnuggets.com/synthetic-data-for-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Community for Synthetic Data is Here and This is Why We Need It](https://www.kdnuggets.com/2022/04/community-synthetic-data-need.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
