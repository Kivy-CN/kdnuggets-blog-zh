- en: A Comprehensive Guide to Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络综合指南
- en: 原文：[https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)
- en: '[Artificial Intelligence](https://saturncloud.io/glossary/artificial-intelligence/) has
    been witnessing monumental growth in bridging the gap between the capabilities
    of humans and machines. Researchers and enthusiasts alike, work on numerous aspects
    of the field to make amazing things happen. One of many such areas is the domain
    of [Computer Vision](https://saturncloud.io/glossary/computer-vision).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[人工智能](https://saturncloud.io/glossary/artificial-intelligence/) 近年来在缩小人类与机器能力之间的差距方面取得了巨大进展。研究人员和爱好者们在该领域的多个方面进行工作，创造出令人惊叹的成果。诸如此类的一个领域是
    [计算机视觉](https://saturncloud.io/glossary/computer-vision)。'
- en: The agenda for this field is to enable machines to view the world as humans
    do, perceive it in a similar manner, and even use the knowledge for a multitude
    of tasks such as Image & Video recognition, Image Analysis & Classification, Media
    Recreation, Recommendation Systems, [Natural Language Processing](https://saturncloud.io/glossary/natural-language-processing-nlp/),
    etc. The advancements in [Computer Vision](https://saturncloud.io/glossary/computer-vision/) with [Deep
    Learning](https://saturncloud.io/glossary/deep-learning/) have been constructed
    and perfected with time, primarily over one particular [algorithm](https://saturncloud.io/glossary/algorithm) —
    a **Convolutional Neural Network**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域的目标是使机器能够像人类一样看待世界，以类似的方式感知它，甚至利用这些知识完成多种任务，如图像和视频识别、图像分析与分类、媒体再创作、推荐系统、[自然语言处理](https://saturncloud.io/glossary/natural-language-processing-nlp/)
    等。计算机视觉在 [深度学习](https://saturncloud.io/glossary/deep-learning/) 的进步中得到了构建和完善，主要是通过一个特定的
    [算法](https://saturncloud.io/glossary/algorithm)——**卷积神经网络**。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT 工作'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/6c3e53a0b1e8c71f5964729635e036d3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/6c3e53a0b1e8c71f5964729635e036d3.png)'
- en: A CNN sequence to classify handwritten digits
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于分类手写数字的 CNN 序列
- en: A **Convolutional Neural Network (ConvNet/CNN)** is a [Deep Learning](https://saturncloud.io/glossary/deep-learning) algorithm
    that can take in an input image, assign importance (learnable weights and biases)
    to various aspects/objects in the image, and be able to differentiate one from
    the other. The pre-processing required in a ConvNet is much lower as compared
    to other classification algorithms. While in primitive methods filters are hand-engineered,
    with enough training, ConvNets have the ability to learn these filters/characteristics.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络 (ConvNet/CNN)** 是一种 [深度学习](https://saturncloud.io/glossary/deep-learning)
    算法，它能够接受输入图像，对图像中的各个方面/对象赋予重要性（可学习的权重和偏置），并能够区分它们。与其他分类算法相比，ConvNet 所需的预处理要低得多。虽然在原始方法中过滤器是手工设计的，但经过足够的训练，ConvNets
    有能力学习这些过滤器/特征。'
- en: The architecture of a ConvNet is analogous to that of the connectivity pattern
    of Neurons in the Human Brain and was inspired by the organization of the Visual
    Cortex. Individual neurons respond to stimuli only in a restricted region of the
    visual field known as the Receptive Field. A collection of such fields overlap
    to cover the entire visual area.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ConvNet 的架构类似于人脑中神经元的连接模式，并且受到视觉皮层组织的启发。单个神经元仅对称称为感受野的视觉区域内的刺激作出反应。这些区域的集合重叠以覆盖整个视觉区域。
- en: Why ConvNets over Feed-Forward Neural Nets?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 ConvNets 而不是前馈神经网络？
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/b5e9e919d3baca94fdd076a5ad5d6195.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络全面指南](../Images/b5e9e919d3baca94fdd076a5ad5d6195.png)'
- en: Flattening of a 3x3 image matrix into a 9x1 vector
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个3x3的图像矩阵展平为9x1的向量
- en: An image is nothing but a matrix of pixel values, right? So why not just flatten
    the image (e.g. 3x3 image matrix into a 9x1 vector) and feed it to a Multi-Level [Perceptron](https://saturncloud.io/glossary/perceptron) for
    classification purposes? Uh.. not really.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图像无非就是像素值的矩阵，对吧？那么为什么不将图像展平（例如3x3的图像矩阵展平为9x1的向量）然后送入多层[感知机](https://saturncloud.io/glossary/perceptron)进行分类呢？嗯，不完全是这样。
- en: In cases of extremely basic binary images, the method might show an average [precision](https://saturncloud.io/glossary/precision) score
    while performing prediction of classes but would have little to no accuracy when
    it comes to complex images having pixel dependencies throughout.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于极其简单的二值图像，这种方法在执行类别预测时可能会显示出一个平均的[精度](https://saturncloud.io/glossary/precision)得分，但对于具有像素依赖的复杂图像，准确率可能会很低或没有准确率。
- en: A ConvNet is able to **successfully capture the Spatial and Temporal dependencies** in
    an image through the application of relevant filters. The architecture performs
    a better fitting to the image dataset due to the reduction in the number of parameters
    involved and the reusability of weights. In other words, the network can be trained
    to understand the sophistication of the image better.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ConvNet 能够通过应用相关滤波器**成功捕捉图像中的空间和时间依赖性**。由于参数数量的减少和权重的可重用性，该架构能够更好地拟合图像数据集。换句话说，网络可以被训练得更好地理解图像的复杂性。
- en: Input Image
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入图像
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/7ed1ca092a9f77e56a2d865497452d1b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络全面指南](../Images/7ed1ca092a9f77e56a2d865497452d1b.png)'
- en: 4x4x3 RGB Image
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 4x4x3 RGB 图像
- en: In the figure, we have an RGB image that has been separated by its three color
    planes — Red, Green, and Blue. There are a number of such color spaces in which
    images exist — Grayscale, RGB, HSV, CMYK, etc.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们有一张RGB图像，该图像已被分离成其三个颜色通道——红色、绿色和蓝色。图像存在于多种颜色空间中——灰度、RGB、HSV、CMYK等。
- en: You can imagine how computationally intensive things would get once the images
    reach dimensions, say 8K (7680×4320). The role of ConvNet is to reduce the images
    into a form that is easier to process, without losing features that are critical
    for getting a good prediction. This is important when we are to design an architecture
    that is not only good at learning features but also scalable to massive datasets.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，当图像达到例如8K (7680×4320)的尺寸时，计算量会变得多么庞大。ConvNet 的作用是将图像缩减成一种更易处理的形式，同时不丢失对获得良好预测至关重要的特征。当我们设计一种不仅擅长学习特征而且能够扩展到大规模数据集的架构时，这一点尤为重要。
- en: Convolution Layer — The Kernel
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层——卷积核
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/485b4c8ce8f612cfd67196203cdc04be.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络全面指南](../Images/485b4c8ce8f612cfd67196203cdc04be.png)'
- en: Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 用一个3x3x1的核对一个5x5x1的图像进行卷积以获得一个3x3x1的卷积特征
- en: Image Dimensions = 5 (Height) x 5 (Breadth) x 1 (Number of channels, eg. RGB)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图像尺寸 = 5（高度）x 5（宽度）x 1（通道数，例如RGB）
- en: In the above demonstration, the green section resembles our **5x5x1 input image,
    I**. The element involved in the convolution operation in the first part of a
    Convolutional Layer is called the **Kernel/Filter, K**, represented in color yellow.
    We have selected **K as a 3x3x1 matrix.**
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述演示中，绿色部分类似于我们的**5x5x1输入图像，I**。卷积层第一部分中涉及的元素被称为**卷积核/滤波器，K**，用黄色表示。我们选择了**K作为一个3x3x1矩阵**。
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Kernel shifts 9 times because of **Stride Length = 1 (Non-Strided)**, every
    time performing an **elementwise** **multiplication operation ([Hadamard Product](https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29#:~:text=In%20mathematics%2C%20the%20Hadamard%20product,elements%20i%2C%20j%20of%20the))
    between K and the portion P of the image** over which the kernel is hovering.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于**步幅长度 = 1（无步幅）**，卷积核移动9次，每次执行**逐元素****乘法操作**（[哈达玛积](https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29#:~:text=In%20mathematics%2C%20the%20Hadamard%20product,elements%20i%2C%20j%20of%20the)），在卷积核悬停的图像区域`K`和`P`部分之间。
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/5bcc8d31581243408fe4807d14d41171.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/5bcc8d31581243408fe4807d14d41171.png)'
- en: Movement of the Kernel
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核的移动
- en: The filter moves to the right with a certain Stride Value till it parses the
    complete width. Moving on, it hops down to the beginning (left) of the image with
    the same Stride Value and repeats the process until the entire image is traversed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器以一定的步幅值向右移动，直到遍历完整的宽度。接着，它跳回图像的开始（左侧），以相同的步幅值重复这个过程，直到整个图像被遍历。
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/5a4a214e679921ebf1b3a0c71136b38c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/5a4a214e679921ebf1b3a0c71136b38c.png)'
- en: Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个MxNx3图像矩阵上进行的卷积操作，使用3x3x3卷积核。
- en: In the case of images with multiple channels (e.g. RGB), the Kernel has the
    same depth as that of the input image. Matrix Multiplication is performed between
    Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed
    with the bias to give us a squashed one-depth channel Convoluted Feature Output.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有多个通道（例如RGB）的图像，卷积核的深度与输入图像相同。进行`Kn`与`In`堆叠（[K1, I1]; [K2, I2]; [K3, I3]）之间的矩阵乘法，并将所有结果与偏差相加，以给出一个压缩的一深度通道卷积特征输出。
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/78ec4701f2bf7c3b122ac76e569c04ff.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/78ec4701f2bf7c3b122ac76e569c04ff.png)'
- en: Convolution Operation with Stride Length = 2
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅长度 = 2的卷积操作
- en: The objective of the Convolution Operation is to **extract the high-level features** such
    as edges, from the input image. ConvNets need not be limited to only one Convolutional
    Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level
    features such as edges, color, gradient orientation, etc. With added layers, the
    architecture adapts to the High-Level features as well, giving us a network that
    has a wholesome understanding of images in the dataset, similar to how we would.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作的目标是**提取高级特征**，如边缘，从输入图像中。卷积网络不必仅限于一个卷积层。传统上，第一个卷积层负责捕捉低级特征，如边缘、颜色、梯度方向等。通过添加更多层，架构还适应高级特征，给我们一个对数据集中的图像有全面理解的网络，就像我们自己一样。
- en: There are two types of results to the operation — one in which the convolved
    feature is reduced in dimensionality as compared to the input, and the other in
    which the dimensionality is either increased or remains the same. This is done
    by applying **Valid Padding** in the case of the former, or **Same Padding** in
    the case of the latter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 操作有两种结果——一种是卷积特征的维度相对于输入减少，另一种是维度增加或保持不变。这通过在前者情况下应用**有效填充**，或在后者情况下应用**相同填充**来实现。
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/783dd304339da33464092f06b02b1620.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/783dd304339da33464092f06b02b1620.png)'
- en: When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1
    kernel over it, we find that the convolved matrix turns out to be of dimensions
    5x5x1\. Hence the name — **Same Padding**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将5x5x1图像扩展到6x6x1图像，并对其应用3x3x1卷积核时，我们发现卷积矩阵的尺寸为5x5x1。因此，称之为**相同填充**。
- en: On the other hand, if we perform the same operation without padding, we are
    presented with a matrix that has dimensions of the Kernel (3x3x1) itself — **Valid
    Padding**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们在没有填充的情况下执行相同的操作，我们会得到一个尺寸为卷积核本身（3x3x1）的矩阵——**有效填充**。
- en: The following repository houses many such GIFs which would help you get a better
    understanding of how Padding and Stride Length work together to achieve results
    relevant to our needs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下仓库包含许多这样的GIF，有助于更好地理解填充和步幅长度如何协同工作，以实现与我们需求相关的结果。
- en: '[**vdumoulin/conv_arithmetic**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[**vdumoulin/conv_arithmetic**](https://github.com/vdumoulin/conv_arithmetic)'
- en: A technical report on convolution arithmetic in the context of deep learning
    - vdumoulin/conv_arithmeticgithub.com](https://github.com/vdumoulin/conv_arithmetic)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 关于深度学习中的卷积算术的技术报告 - [vdumoulin/conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic)
- en: Pooling Layer
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/6e6b343ded97d184ff5caabfc332274a.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/6e6b343ded97d184ff5caabfc332274a.png)'
- en: Similar to the Convolutional Layer, the Pooling layer is responsible for reducing
    the spatial size of the Convolved Feature. This is to **decrease the computational
    power required to process the data** through [dimensionality reduction](https://saturncloud.io/glossary/dimensionality-reduction).
    Furthermore, it is useful for **extracting dominant features** which are rotational
    and positional invariant, thus maintaining the process of effectively training
    the model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于卷积层，池化层负责减少卷积特征的空间大小。这样做是为了**降低处理数据所需的计算能力**，通过[降维](https://saturncloud.io/glossary/dimensionality-reduction)。此外，它对于**提取主导特征**非常有用，这些特征在旋转和位置上是不变的，从而保持了有效训练模型的过程。
- en: There are two types of Pooling: [Max Pooling](https://saturncloud.io/glossary/max-pooling) and
    Average Pooling. **Max Pooling** returns the **maximum value** from the portion
    of the image covered by the Kernel. On the other hand, **Average Pooling** returns
    the **average of all the values** from the portion of the image covered by the
    Kernel.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 池化有两种类型：[最大池化](https://saturncloud.io/glossary/max-pooling)和平均池化。**最大池化**返回内核覆盖的图像部分的**最大值**。另一方面，**平均池化**返回内核覆盖的图像部分的**所有值的平均值**。
- en: Max Pooling also performs as a **Noise Suppressant**. It discards the noisy
    activations altogether and also performs de-noising along with dimensionality
    reduction. On the other hand, Average Pooling simply performs dimensionality reduction
    as a noise-suppressing mechanism. Hence, we can say that **Max Pooling performs
    a lot better than Average Pooling**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化还充当**噪声抑制器**。它完全丢弃噪声激活，并且在降维的同时也进行去噪处理。另一方面，平均池化仅作为噪声抑制机制执行降维。因此，我们可以说**最大池化比平均池化效果要好得多**。
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/b1198726781dbb61c45ebd6bea03a031.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/b1198726781dbb61c45ebd6bea03a031.png)'
- en: Types of Pooling
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 池化类型
- en: The Convolutional Layer and the Pooling Layer, together form the i-th layer
    of a Convolutional Neural Network. Depending on the complexities in the images,
    the number of such layers may be increased for capturing low-level details even
    further, but at the cost of more computational power.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层和池化层共同构成卷积神经网络的第i层。根据图像中的复杂性，这些层的数量可能会增加，以进一步捕捉低级细节，但这也需要更多的计算能力。
- en: After going through the above process, we have successfully enabled the model
    to understand the features. Moving on, we are going to flatten the final output
    and feed it to a regular Neural Network for classification purposes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 经过上述过程后，我们成功地使模型理解了特征。接下来，我们将展平最终输出，并将其输入到一个普通的神经网络中进行分类。
- en: Classification — Fully Connected Layer (FC Layer)
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类 — 全连接层（FC层）
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/f3ecb787dda963fbf5e949d260f7358f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络综合指南](../Images/f3ecb787dda963fbf5e949d260f7358f.png)'
- en: Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear
    combinations of the high-level features as represented by the output of the convolutional
    layer. The Fully-Connected layer is learning a possibly non-linear function in
    that space.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个全连接层通常是一种廉价的方法，用于学习卷积层输出表示的高级特征的非线性组合。全连接层在该空间中学习一个可能的非线性函数。
- en: Now that we have converted our input image into a suitable form for our Multi-Level
    Perceptron, we shall flatten the image into a column vector. The flattened output
    is fed to a feed-forward neural network and backpropagation is applied to every
    iteration of training. Over a series of epochs, the model is able to distinguish
    between dominating and certain low-level features in images and classify them
    using the **Softmax Classification** technique.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将输入图像转换为适合我们的多层感知机的形式，我们将把图像展平成列向量。展平后的输出被输入到前馈神经网络中，并在每次训练迭代中应用反向传播。经过多次训练周期，模型能够区分图像中的主导特征和某些低级特征，并使用**Softmax分类**技术对其进行分类。
- en: 'There are various architectures of CNNs available which have been key in building
    algorithms which power and shall power AI as a whole in the foreseeable future.
    Some of them have been listed below:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有各种CNN架构可供使用，它们在构建算法方面发挥了关键作用，并将在可预见的未来继续推动整体人工智能的发展。以下是其中一些架构：
- en: LeNet
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LeNet
- en: AlexNet
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AlexNet
- en: VGGNet
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: VGGNet
- en: GoogLeNet
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GoogLeNet
- en: ResNet
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ResNet
- en: ZFNet
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ZFNet
- en: '**[Sumit Saha](https://in.linkedin.com/in/linksumitsaha)** is a data scientist
    and machine learning engineer currently working on building AI-driven products.
    He is passionate about the applications of AI for social good, especially in the
    domain of medicine and healthcare. Occasionally I do some technical blogging too.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Sumit Saha](https://in.linkedin.com/in/linksumitsaha)** 是一位数据科学家和机器学习工程师，目前致力于构建以人工智能驱动的产品。他对人工智能在社会公益方面的应用充满热情，尤其是在医学和医疗保健领域。我有时也会进行一些技术博客写作。'
- en: '[Original](https://saturncloud.io/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way/).
    Reposted with permission.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://saturncloud.io/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way/)。已获许可转载。'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Survey on Trustworthy Graph Neural Networks:…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于可信赖图神经网络的全面调查：…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在使用神经网络之前尝试的10件简单事情](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch进行可解释的神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引导我们迈向AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
