- en: A Tour of Python NLP Libraries
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python NLP库概览
- en: 原文：[https://www.kdnuggets.com/a-tour-of-python-nlp-libraries](https://www.kdnuggets.com/a-tour-of-python-nlp-libraries)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/a-tour-of-python-nlp-libraries](https://www.kdnuggets.com/a-tour-of-python-nlp-libraries)
- en: '![A Tour of Python NLP Libraries](../Images/58939d9717841e882b2724e949acdeaf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Python NLP库概览](../Images/58939d9717841e882b2724e949acdeaf.png)'
- en: Image Generated with DALL·E 3
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DALL·E 3生成的图像
- en: NLP, or Natural Language Processing, is a field within Artificial Intelligence
    that focuses on the interaction between human language and computers. It tries
    to explore and apply text data so computers can understand the text meaningfully.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: NLP，即自然语言处理，是人工智能领域中的一个领域，专注于人类语言与计算机之间的互动。它试图探索和应用文本数据，使计算机能够有意义地理解文本。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As the NLP field research progresses, how we process text data in computers
    has evolved. Modern times, we have used Python to help explore and process data
    easily.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着NLP领域研究的进展，我们处理计算机中文本数据的方式也在不断发展。在现代，我们使用Python来帮助轻松探索和处理数据。
- en: With Python becoming the go-to language for exploring text data, many libraries
    have been developed specifically for the NLP field. In this article, we will explore
    various incredible and useful NLP libraries.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Python成为探索文本数据的首选语言，许多库被专门为NLP领域开发。在这篇文章中，我们将探索各种令人惊叹和实用的NLP库。
- en: So, let’s get into it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始吧。
- en: NLTK
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLTK
- en: '[NLTK](https://www.nltk.org/), or Natural Language Tool Kit, is an NLP Python
    library with many text-processing APIs and industrial-grade wrappers. It’s one
    of the biggest NLP Python libraries used by researchers, data scientists, engineers,
    and others. It’s a standard NLP Python library for NLP tasks.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[NLTK](https://www.nltk.org/)，或自然语言工具包，是一个具有许多文本处理API和工业级封装的NLP Python库。它是研究人员、数据科学家、工程师等使用的最大NLP
    Python库之一。它是进行NLP任务的标准Python库。'
- en: Let’s try to explore what NLTK could do. First, we would need to install the
    library with the following code.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试探索一下NLTK能做什么。首先，我们需要使用以下代码安装该库。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we would see what NLTK could do. First, NLTK can perform the tokenization
    process using the following code:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看NLTK能做什么。首先，NLTK可以使用以下代码进行分词处理：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Tokenization basically would divide each word in a sentence into individual
    data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 分词基本上将句子中的每个单词划分为单独的数据。
- en: With NLTK, we can also perform Part-of-Speech (POS) Tags on the text sample.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NLTK，我们还可以对文本样本进行词性标注（POS）。
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The output of the POS tagger with NLTK is each token and its intended POS tags.
    For example, the word Fruit is Noun (NN), and the word ‘a’ is Determinant (DT).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK的词性标注器的输出是每个词元及其预期的词性标记。例如，单词“Fruit”是名词（NN），而单词“a”是限定词（DT）。
- en: It’s also possible to perform Stemming and Lemmatization with NLTK. Stemming
    is reducing a word to its base form by cutting its prefixes and suffixes, while
    Lemmatization also transforms to the base form by considering the words' POS and
    morphological analysis.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NLTK也可以进行词干提取和词形还原。词干提取是通过剪切前缀和后缀将单词还原为其基本形式，而词形还原则通过考虑单词的词性和形态分析来转换为基本形式。
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You can see that the stemming and lentmatization processes have slightly different
    results from the words.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到词干提取和词形还原的过程对单词的结果略有不同。
- en: That’s the simple usage of NLTK. You can still do many things with them, but
    the above APIs are the most commonly used.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是NLTK的简单使用方法。你仍然可以做很多事情，但上述API是最常用的。
- en: SpaCy
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SpaCy
- en: '[SpaCy](https://spacy.io/) is an NLP Python library that is designed specifically
    for production use. It’s an advanced library, and SpaCy is known for its performance
    and ability to handle large amounts of text data. It’s a preferable library for
    industry use in many NLP cases.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[SpaCy](https://spacy.io/) 是一个专门为生产环境设计的 NLP Python 库。它是一个高级库，因其性能和处理大量文本数据的能力而闻名。它是许多
    NLP 应用中首选的工业用库。'
- en: To install SpaCy, you can look at their [usage page](https://spacy.io/usage).
    Depending on your requirements, there are many combinations to choose from.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 SpaCy，你可以查看他们的 [使用页面](https://spacy.io/usage)。根据你的需求，有许多组合可供选择。
- en: Let’s try using SpaCy for the NLP task. First, we would try performing Named
    Entity Recognition (NER) with the library. NER is a process of identifying and
    classifying named entities in text into predefined categories, such as person,
    address, location, and more.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用 SpaCy 进行 NLP 任务。首先，我们将尝试使用库进行命名实体识别 (NER)。NER 是一种将文本中的命名实体识别并分类到预定义类别（如人、地址、地点等）的过程。
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, the SpaCy pre-trained model understands which word within the
    document can be classified.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，SpaCy 预训练模型了解文档中的哪个词可以被分类。
- en: Next, we can use SpaCy to perform Dependency Parsing and visualize them. Dependency
    Parsing is a process of understanding how each word relates to the other by forming
    a tree structure.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用 SpaCy 进行依存关系解析并进行可视化。依存关系解析是理解每个词如何通过形成树形结构与其他词相关的过程。
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The output should include all the words with their POS and where they are related.
    The code above would also provide tree visualization in your Jupyter Notebook.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应包括所有单词及其词性和相关位置。上述代码还会在你的 Jupyter Notebook 中提供树形可视化。
- en: Lastly, let’s try performing text similarity with SpaCy. Text similarity measures
    how similar or related two pieces of text are. It has many techniques and measurements,
    but we will try the simplest one.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试使用 SpaCy 进行文本相似性分析。文本相似性测量两个文本片段的相似程度或相关性。它有许多技术和测量方法，但我们将尝试最简单的一种。
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The similarity measure measures the similarity between texts by providing an
    output score, usually between 0 and 1\. The closer the score is to 1, the more
    similar both texts are.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度度量通过提供一个输出分数来测量文本之间的相似性，通常在 0 和 1 之间。分数越接近 1，两篇文本的相似度越高。
- en: There are still many things you can do with SpaCy. Explore the documentation
    to find something useful for your work.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以用 SpaCy 做很多事情。探索文档以找到对你工作有用的内容。
- en: TextBlob
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TextBlob
- en: '[TextBlob](https://textblob.readthedocs.io/en/dev/) is an NLP Python library
    for processing textual data built on top of NLTK. It simplifies many of NLTK''s
    usage and can streamline text processing tasks.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[TextBlob](https://textblob.readthedocs.io/en/dev/) 是一个建立在 NLTK 之上的 NLP Python
    库，用于处理文本数据。它简化了许多 NLTK 的用法，并可以简化文本处理任务。'
- en: 'You can install TextBlob using the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码安装 TextBlob：
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: First, let’s try to use TextBlob for NLP tasks. The first one we would try is
    to do sentiment analysis with TextBlob. We can do that with the code below.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们尝试使用 TextBlob 进行 NLP 任务。我们首先尝试的是使用 TextBlob 进行情感分析。我们可以通过下面的代码实现这一点。
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The output is a polarity and subjectivity score. Polarity is the sentiment of
    the text where the score ranges from -1 (negative) to 1 (positive). At the same
    time, the subjectivity score ranges from 0 (objective) to 1 (subjective).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是极性和主观性分数。极性是文本的情感，分数范围从 -1（负面）到 1（正面）。同时，主观性分数范围从 0（客观）到 1（主观）。
- en: We can also use TextBlob for text correction tasks. You can do that with the
    following code.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 TextBlob 进行文本校正任务。你可以使用以下代码来完成这一点。
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Try to explore the TextBlob packages to find the APIs for your text tasks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试探索 TextBlob 包，以找到适合你文本任务的 API。
- en: Gensim
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Gensim
- en: '[Gensim](https://radimrehurek.com/gensim/) is an open-source Python NLP library
    specializing in topic modeling and document similarity analysis, especially for
    big and streaming data. It focuses more on industrial real-time applications.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gensim](https://radimrehurek.com/gensim/) 是一个开源的 Python NLP 库，专注于主题建模和文档相似性分析，特别适用于大数据和流数据。它更关注工业实时应用。'
- en: 'Let’s try the library. First, we can install them using the following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试这个库。首先，我们可以使用以下代码进行安装：
- en: '[PRE18]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: After the installation is finished, we can try the Gensim capability. Let’s
    try to do topic modeling with LDA using Gensim.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们可以尝试 Gensim 的功能。让我们尝试使用 Gensim 进行 LDA 主题建模。
- en: '[PRE19]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The output is a combination of words from the document samples that cohesively
    become a topic. You can evaluate whether the result makes sense or not.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果是文档样本中词语的组合，形成一个有机的话题。你可以评估结果是否有意义。
- en: Gensim also provides a way for users to embed content. For example, we use Word2Vec
    to create embedding from words.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Gensim还提供了一种用户嵌入内容的方式。例如，我们使用Word2Vec从词语中创建嵌入。
- en: '[PRE21]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: There are still many applications you can use with Gensim. Try to see the documentation
    and evaluate your needs.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Gensim还有许多应用场景。尝试查看文档并评估你的需求。
- en: Conclusion
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this article, we explored several Python NLP libraries essential for many
    text tasks. All of these libraries would be useful for your work, from Text Tokenization
    to Word Embedding. The libraries we are discussing are:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了几种对许多文本任务至关重要的Python NLP库。所有这些库都对你的工作有用，从文本分词到词嵌入。我们讨论的库包括：
- en: NLTK
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NLTK
- en: SpaCy
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SpaCy
- en: TextBlob
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TextBlob
- en: Gensim
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gensim
- en: I hope it helps
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这对你有帮助
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** 是一名数据科学助理经理和数据撰稿人。在全职工作于安联印尼期间，他热衷于通过社交媒体和写作媒体分享Python和数据技巧。Cornellius涉猎各种AI和机器学习主题。'
- en: More On This Topic
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Top 38 Python Libraries for Data Science, Data Visualization &…](https://www.kdnuggets.com/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学、数据可视化等领域的前38个Python库](https://www.kdnuggets.com/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html)'
- en: '[Python Libraries Data Scientists Should Know in 2022](https://www.kdnuggets.com/2022/04/python-libraries-data-scientists-know-2022.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年数据科学家应了解的Python库](https://www.kdnuggets.com/2022/04/python-libraries-data-scientists-know-2022.html)'
- en: '[Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的人工智能：揭开模型决策的面纱的10个Python库](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
- en: '[Introduction to Python Libraries for Data Cleaning](https://www.kdnuggets.com/2023/03/introduction-python-libraries-data-cleaning.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python数据清洗库简介](https://www.kdnuggets.com/2023/03/introduction-python-libraries-data-cleaning.html)'
- en: '[Beyond Numpy and Pandas: Unlocking the Potential of Lesser-Known…](https://www.kdnuggets.com/2023/08/beyond-numpy-pandas-unlocking-potential-lesserknown-python-libraries.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越Numpy和Pandas：挖掘鲜为人知的潜力…](https://www.kdnuggets.com/2023/08/beyond-numpy-pandas-unlocking-potential-lesserknown-python-libraries.html)'
- en: '[Level 50 Data Scientist: Python Libraries to Know](https://www.kdnuggets.com/level-50-data-scientist-python-libraries-to-know)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Level 50数据科学家：必知的Python库](https://www.kdnuggets.com/level-50-data-scientist-python-libraries-to-know)'
