- en: Fast AutoML with FLAML + Ray Tune
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用FLAML + Ray Tune进行快速AutoML
- en: 原文：[https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html](https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html](https://www.kdnuggets.com/2021/09/fast-automl-flaml-ray-tune.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Qingyun Wu](https://twitter.com/qingyun_wu), [Chi Wang](https://www.linkedin.com/in/chi-wang-49b15b16/),
    [Antoni Baum](https://www.linkedin.com/in/yard1/), [Richard Liaw](https://twitter.com/richliaw)
    & [Michael Galarnyk](https://twitter.com/GalarnykMichael)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[吴庆云](https://twitter.com/qingyun_wu)、[王驰](https://www.linkedin.com/in/chi-wang-49b15b16/)、[安东尼·鲍姆](https://www.linkedin.com/in/yard1/)、[理查德·廖](https://twitter.com/richliaw)和[迈克尔·加拉尼克](https://twitter.com/GalarnykMichael)**'
- en: '![Image](../Images/de7c7c129074f49504448e84d6e97174.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/de7c7c129074f49504448e84d6e97174.png)'
- en: '[FLAML](https://github.com/microsoft/FLAML) is a lightweight Python library
    from Microsoft Research that finds accurate machine learning models in an efficient
    and economical way using [cutting edge](https://arxiv.org/abs/2005.01571) algorithms
    designed to be resource-efficient and easily parallelizable. FLAML can also utilize [Ray
    Tune](https://docs.ray.io/en/master/tune/index.html) for distributed hyperparameter
    tuning to scale up these AutoML methods across a cluster.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[FLAML](https://github.com/microsoft/FLAML)是微软研究院推出的轻量级Python库，利用[前沿](https://arxiv.org/abs/2005.01571)算法以高效和经济的方式寻找准确的机器学习模型，这些算法旨在节省资源并易于并行化。FLAML还可以利用[Ray
    Tune](https://docs.ray.io/en/master/tune/index.html)进行分布式超参数调优，将这些AutoML方法扩展到集群中。'
- en: 'This blog highlights:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本博客重点介绍：
- en: The need for economical AutoML methods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对经济高效AutoML方法的需求
- en: Economical AutoML with FLAML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经济高效的AutoML与FLAML
- en: How to scale FLAML’s optimization algorithms with Ray Tune
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何用Ray Tune扩展FLAML的优化算法
- en: The need of economical AutoML methods
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对经济高效AutoML方法的需求
- en: AutoML is known to be a resource and time consuming operation as it involves
    trials and errors to find a hyperparameter configuration with good performance.
    Since the space of possible configuration values is often very large, there is
    a need for an economical AutoML method that can more effectively search them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 众所周知，AutoML是一项资源和时间消耗大的操作，因为它涉及通过试错找到性能良好的超参数配置。由于可能的配置值空间通常非常大，因此需要一种经济高效的AutoML方法来更有效地进行搜索。
- en: 'The high resource and time consumption of hyperparameter search in AutoML boils
    down to the following two factors:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML中超参数搜索的高资源和时间消耗归结为以下两个因素：
- en: large number of candidate hyperparameter configurations (trial) needed to find
    a configuration with good performance
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要大量候选超参数配置（试验）来找到性能良好的配置
- en: high ‘evaluation’ cost of each hyperparameter as the evaluation involves training
    and validating a machine learning model with the given training data.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个超参数的高‘评估’成本，因为评估涉及使用给定的训练数据训练和验证机器学习模型。
- en: To address both of these factors, Microsoft Researchers have developed [FLAML](https://github.com/microsoft/FLAML) (Fast
    Lightweight AutoML).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这两个因素，微软研究人员开发了[FLAML](https://github.com/microsoft/FLAML)（快速轻量级AutoML）。
- en: '**What is FLAML?**'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**什么是FLAML？**'
- en: 'FLAML is a newly released library containing state-of-the-art hyperparameter
    optimization algorithms. FLAML leverages the structure of the search space to
    optimize for both cost and model performance simultaneously. It contains two new
    methods developed by Microsoft Research:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML是一个新发布的库，包含最先进的超参数优化算法。FLAML利用搜索空间的结构，同时优化成本和模型性能。它包含微软研究院开发的两种新方法：
- en: Cost-Frugal Optimization (CFO)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本节俭优化（CFO）
- en: BlendSearch
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BlendSearch
- en: Cost-Frugal Optimization (CFO) is a method that conducts its search process
    in a cost-aware fashion. The search method starts from a low-cost initial point
    and gradually moves towards a higher cost region while optimizing the given objective
    (like model loss or accuracy).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 成本节俭优化（CFO）是一种以成本感知方式进行搜索过程的方法。搜索方法从低成本初始点开始，逐渐向高成本区域移动，同时优化给定的目标（如模型损失或准确率）。
- en: Blendsearch is an extension of CFO that combines the frugality of CFO and the
    exploration ability of Bayesian optimization. Like CFO, BlendSearch requires a
    low-cost initial point as input if such point exists, and starts the search from
    there. However, unlike CFO, BlendSearch will not wait for the local search to
    fully converge before trying new start points.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Blendsearch是CFO的扩展，结合了CFO的节俭性和贝叶斯优化的探索能力。像CFO一样，BlendSearch需要一个低成本的初始点作为输入（如果存在），并从那里开始搜索。然而，与CFO不同的是，BlendSearch不会等待局部搜索完全收敛后再尝试新的起始点。
- en: 'The economical HPO methods in FLAML are inspired by two key insights:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML中的经济HPO方法灵感来源于两个关键见解：
- en: Many machine learning algorithms have hyperparameters that can cause a large
    variation in the training cost. For example, an XGBoost model with 10 trees will
    train much quicker than a model with 1000 trees.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 许多机器学习算法有超参数会导致训练成本的大幅变化。例如，10棵树的XGBoost模型比1000棵树的模型训练速度要快得多。
- en: The “cost” for parameters is often ‘continuous and consistent’ — evaluating
    trees=10 is cheaper than evaluating trees=100, which itself is cheaper than evaluating
    trees=500.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数的“成本”通常是‘连续且一致的’——评估树=10的成本低于评估树=100，而评估树=100的成本又低于评估树=500。
- en: Together, these insights provide useful* structural information* about the hyperparameters
    in the cost space. The methods, i.e., CFO and BlendSearch, are able to effectively
    leverage these insights to reduce the cost incurred along the way without affecting
    the convergence to the optimal solution.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些见解一起提供了关于成本空间中超参数的有用*结构信息*。这些方法，即CFO和BlendSearch，能够有效利用这些见解来减少沿途产生的成本，而不会影响到达最优解的收敛。
- en: '**Does FLAML Work?**'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**FLAML有效吗？**'
- en: In the latest [AutoML benchmark](https://openml.github.io/automlbenchmark/), [FLAML](https://arxiv.org/pdf/1911.04706.pdf) is
    able to achieve the same or better performance as the state-of-the-art AutoML
    solutions using only 10% of the computation resource on over 62% of the tasks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在最新的[AutoML基准](https://openml.github.io/automlbenchmark/)中，[FLAML](https://arxiv.org/pdf/1911.04706.pdf)能够在62%以上的任务中，仅使用10%的计算资源，实现与最先进AutoML解决方案相同或更好的性能。
- en: FLAML’s performance is attributed to its economical optimization methods. The
    new HPO methods (CFO, BlendSearch) leverage the structure of the search space
    to choose search orders optimized for both good performance and low cost. This
    can make a big difference in search efficiency under budget constraints.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML的性能归功于其经济优化方法。新的HPO方法（CFO、BlendSearch）利用搜索空间的结构来选择优化的搜索顺序，以兼顾良好的性能和低成本。这在预算限制下可以显著提高搜索效率。
- en: Figure 1 shows a typical result obtained from FLAML and a state-of-the-art hyperparameter
    tuning library [Optuna](https://github.com/optuna/optuna) for tuning LightGBM
    with 9-dimensional hyperparameters. You can see that FLAML is able to achieve
    a better solution in a much shorter amount of time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图1显示了从FLAML和最先进的超参数调整库[Optuna](https://github.com/optuna/optuna)中获得的典型结果，用于调整9维超参数的LightGBM。你可以看到FLAML在更短的时间内能够获得更好的解决方案。
- en: '![](../Images/6b87b2f4515439e522f2a79d7adf4781.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b87b2f4515439e522f2a79d7adf4781.png)'
- en: Figure 1\. Validation loss (1-auc) curve for tuning LightGBM on a [classification
    dataset](https://www.openml.org/d/23517). The lines and shaded area show the mean
    and standard deviation of validation loss over 10 runs. Results in this figure
    are obtained from experiments with 1 cpu without parallelization (image by authors).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 在[classification dataset](https://www.openml.org/d/23517)上调整LightGBM的验证损失（1-auc）曲线。线条和阴影区域显示了10次运行中验证损失的均值和标准差。该图中的结果是从使用1个CPU而不进行并行计算的实验中获得的（图像由作者提供）。
- en: The following code example shows how to get started with FLAML with just several
    lines of code (assuming the training dataset is provided and saved as `X_train`, `y_train`).
    The task is to tune hyperparameters of the LightGBM model with a time budget of
    60 seconds.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了如何用仅几行代码开始使用FLAML（假设训练数据集已经提供并保存为`X_train`、`y_train`）。任务是在60秒的时间预算内调整LightGBM模型的超参数。
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, we search over a default search space for LightGBM, which is
    already provided in FLAML. FLAML provides rich customization options about one’s
    concerned task, such as the learner class, the search space, the evaluation metric,
    etc.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们在LightGBM的默认搜索空间上进行搜索，该搜索空间已经在FLAML中提供。FLAML提供了丰富的定制选项，涉及到关注的任务，例如学习器类、搜索空间、评估指标等。
- en: A walkthrough example
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个演示示例
- en: 'Now we use a toy example to demonstrate cost-frugal behavior of CFO in tuning
    XGBoost with two hyperparameters: # of trees and # of leaves.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用一个示例来展示CFO在调整XGBoost的两个超参数（树的数量和叶子的数量）时的成本节约行为。
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How CFO and BlendSearch Work
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CFO和BlendSearch的工作原理
- en: The two GIFs below demonstrate the search trajectory of CFO in the loss and
    evaluation cost (i.e., the evaluation time ) space respectively. CFO begins with
    a low-cost initial point (specified through `low_cost_init_value` in the search
    space) and performs local updates following its randomized local search strategy.
    With such a strategy, CFO can quickly move toward the low-loss region, showing
    a good convergence property. Additionally, CFO tends to avoid exploring the high-cost
    region until necessary. This search strategy is further grounded with a [provable
    convergence rate and bounded cost in expectation](https://arxiv.org/abs/2005.01571).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个GIF分别展示了CFO在损失和评估成本（即评估时间）空间中的搜索轨迹。CFO从一个低成本的初始点（通过`low_cost_init_value`在搜索空间中指定）开始，并根据其随机化的局部搜索策略执行局部更新。采用这种策略，CFO可以快速向低损失区域移动，显示出良好的收敛特性。此外，CFO倾向于避免探索高成本区域，直到必要时才会进行。这种搜索策略通过一个[可证明的收敛速率和期望的有界成本](https://arxiv.org/abs/2005.01571)进一步得到支持。
- en: '![](../Images/cd50c94bbee1cf7e9397ad9f8c1d2775.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd50c94bbee1cf7e9397ad9f8c1d2775.png)'
- en: 'Figure 2\. CFO in tuning the # of leaves and the # of trees for XGBoost. The
    two heatmaps show the loss and cost distribution of all configurations. The black
    dots are the points evaluated in CFO. Black dots connected by lines are points
    that yield better loss performance when evaluated (image by authors).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图2展示了CFO在调整XGBoost的叶子数和树数时的表现。两个热力图显示了所有配置的损失和成本分布。黑点是CFO评估的点，黑点通过线连接表示评估时产生更好损失表现的点（图像由作者提供）。
- en: BlendSearch further combines this local search strategy used in CFO with global
    search. It leverages the frugality of CFO and the space exploration capability
    of global search methods such as Bayesian optimization. Specifically, BlendSearch
    maintains one global search model, and gradually creates local search threads
    over time based on the hyperparameter configurations proposed by the global model.
    It further prioritizes the global search thread and multiple local search threads
    depending on their real-time performance and cost. It can further improve the
    efficiency of CFO in tasks with complicated search space, e.g., a search space
    that contains multiple disjoint, non-continuous subspaces.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: BlendSearch进一步将CFO使用的局部搜索策略与全局搜索结合。它利用CFO的节俭性和全局搜索方法（如贝叶斯优化）的空间探索能力。具体来说，BlendSearch维护一个全局搜索模型，并根据全局模型提出的超参数配置逐渐创建局部搜索线程。它根据实时性能和成本优先考虑全局搜索线程和多个局部搜索线程。这可以进一步提高CFO在复杂搜索空间任务中的效率，例如包含多个不连续子空间的搜索空间。
- en: FLAML vs Bayesian Optimization Performance
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FLAML与贝叶斯优化性能
- en: Figure 3 shows typical behaviors of the economical HPO methods in FLAML (CFO
    is labeled `LS’ in this figure) versus a Bayesian Optimization (BO) method for
    tuning XGBoost with 11 hyperparameters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图3展示了FLAML中经济型HPO方法（在此图中CFO标记为`LS`）与用于调整具有11个超参数的XGBoost的贝叶斯优化（BO）方法的典型行为。
- en: From Figure 3(a), we observe that the evaluation time for the proposed configurations
    in BO can be very long. When the total resource is limited, e.g., 1 cpu-hour (or
    less), BO is not able to give a satisfying result (Figure 3(b)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从图3(a)中，我们观察到BO提出的配置的评估时间可能非常长。当总资源有限时，例如1个cpu小时（或更少），BO无法给出令人满意的结果（图3(b)）。
- en: 'FLAML’s CFO (labeled LS) and BlendSearch have clear advantages in finding good
    configurations quickly: they are able to concentrate on configurations that have
    low evaluation time, while navigating ones with good performance, i.e., low loss.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML的CFO（标记为LS）和BlendSearch在快速找到良好配置方面具有明显优势：它们能够集中于评估时间较短的配置，同时导航于表现良好的配置，即低损失。
- en: '![](../Images/48ce7d9823e8612a6841e19d5028e40d.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48ce7d9823e8612a6841e19d5028e40d.png)'
- en: Figure 3\. (a) is a scatter plot of the hyperparameter configurations proposed
    by different methods, with x-axis and y-axis being the evaluation time and loss.
    The evaluation time of a hyperparameter configuration is the time taken for training
    a machine learning model with the hyperparameter configuration on the training
    data and validating its performance on a validation dataset. The loss is the validation
    loss. (b) shows the best loss obtained by different methods over wall-clock time.
    ([image source](https://openreview.net/pdf?id=VbLH04pRA3))
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. (a) 是不同方法提出的超参数配置的散点图，x 轴和 y 轴分别为评估时间和损失。超参数配置的评估时间是指在训练数据上训练机器学习模型并在验证数据集上验证其性能所花费的时间。损失是验证损失。
    (b) 展示了不同方法在墙钟时间上的最佳损失。 ([image source](https://openreview.net/pdf?id=VbLH04pRA3))
- en: How to scale up CFO and BlendSearch with Ray Tune’s distributed tuning
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何通过 Ray Tune 的分布式调优扩展 CFO 和 BlendSearch
- en: 'To speed up hyperparameter optimization, you may want to parallelizeyour hyperparameter
    search. For example, BlendSearch is able to work well in a parallel setting: It
    leverages multiple search threads that can be independently executed without obvious
    degradation of performance. This desirable property is not always true for existing
    optimization algorithms such as Bayesian Optimization.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加速超参数优化，你可能需要并行化你的超参数搜索。例如，BlendSearch 能够在并行设置中良好运行：它利用多个搜索线程，这些线程可以独立执行而性能不会明显下降。这种理想的属性在现有优化算法（如贝叶斯优化）中并不总是成立。
- en: To achieve parallelization, FLAML is integrated with Ray Tune. Ray Tune is a
    Python library that accelerates hyperparameter tuning by allowing you to leverage
    cutting edge optimization algorithms at scale. Ray Tune also allows you to scale
    out hyperparameter search from your laptop to a cluster without changing your
    code. You can either use Ray Tune in FLAML or run the hyperparameter search methods
    from FLAML in Ray Tune to parallelize your search. The following code example
    shows the former usage, which is achieved by simply configuring the `n_concurrent_trials` argument
    in FLAML.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现并行化，FLAML 与 Ray Tune 集成。Ray Tune 是一个 Python 库，通过允许你利用最前沿的优化算法来加速超参数调优。Ray
    Tune 还允许你将超参数搜索从你的笔记本电脑扩展到集群，而无需更改代码。你可以在 FLAML 中使用 Ray Tune，或在 Ray Tune 中运行 FLAML
    的超参数搜索方法以并行化你的搜索。以下代码示例展示了前一种用法，只需通过配置 `n_concurrent_trials` 参数即可实现。
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/a14bf0e97837d77213d5398128880542.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a14bf0e97837d77213d5398128880542.png)'
- en: Logo source ([XGBoost](https://github.com/dmlc/xgboost), [FLAML](https://github.com/microsoft/FLAML), [Ray
    Tune](https://github.com/ray-project/ray))
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Logo 来源 ([XGBoost](https://github.com/dmlc/xgboost)、[FLAML](https://github.com/microsoft/FLAML)、[Ray
    Tune](https://github.com/ray-project/ray))
- en: The code below shows the latter usage, an end-to-end example of how to use BlendSearch
    with Ray Tune.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码展示了后者用法，即如何在 Ray Tune 中使用 BlendSearch 的端到端示例。
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Other key Ray Tune features include:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 其他关键的 Ray Tune 功能包括：
- en: Automatic integration with experiment tracking tools like Tensorboard and Weights/Biases
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动集成实验跟踪工具，如 Tensorboard 和 Weights/Biases
- en: Support for GPUs
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 GPU
- en: Early stopping
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提前停止
- en: A scikit-learn API to easily integrate with [XGBoost](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray), [LightGBM](https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray), [Scikit-Learn](https://github.com/ray-project/tune-sklearn),
    etc.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 scikit-learn API 以便轻松集成 [XGBoost](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)、[LightGBM](https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray)、[Scikit-Learn](https://github.com/ray-project/tune-sklearn)
    等。
- en: Benchmark results
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试结果
- en: We have conducted an experiment to check how well BlendSearch stacks up to Optuna
    (with multivariate TPE sampler) and random search in a highly parallelized setting.
    We have used a subset of 12 datasets from the [AutoML Benchmark](https://www.openml.org/s/218).
    Each optimization run was conducted with 16 trials in parallel for 20 minutes,
    using 3-fold cross-validation, using ROC-AUC (weighted one-vs-rest for multiclass
    datasets). The runs were repeated three times with different random seeds. Reproduction
    code can be found [here](https://github.com/Yard1/Blendsearch-on-Ray-benchmark).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了一项实验，以检查 BlendSearch 在高度并行化设置中与 Optuna（使用多变量 TPE 采样器）和随机搜索的对比。我们使用了来自 [AutoML
    Benchmark](https://www.openml.org/s/218) 的 12 个数据集的子集。每次优化运行使用 16 个并行试验进行 20 分钟，采用
    3 折交叉验证，使用 ROC-AUC（针对多类数据集的加权一对多）。这些运行重复三次，使用不同的随机种子。重现代码可以在 [这里](https://github.com/Yard1/Blendsearch-on-Ray-benchmark)
    找到。
- en: '![](../Images/d8580e50635a1d1a0d2d0cdd7c82268e.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8580e50635a1d1a0d2d0cdd7c82268e.png)'
- en: Image by authors
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: BlendSearch achieved the best cross-validation score in 6 out of 12 datasets.
    Furthermore, BlendSearch had an average of 2.52% improvement over random search,
    compared to Optuna’s 1.96%. It is worth noting that BlendSearch was using univariate
    Optuna-TPE as its global searcher — using multivariate TPE would most likely improve
    the scores further.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: BlendSearch 在 12 个数据集中的 6 个上实现了最佳交叉验证得分。此外，BlendSearch 相比随机搜索平均提高了 2.52%，而 Optuna
    则为 1.96%。值得注意的是，BlendSearch 使用了单变量的 Optuna-TPE 作为全局搜索器——使用多变量 TPE 很可能进一步提高得分。
- en: '![](../Images/c286e797360d45720a6c4d34881c0612.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c286e797360d45720a6c4d34881c0612.png)'
- en: image by authors
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: In addition, thanks to its cost-frugal approach, BlendSearch evaluated, on average,
    twice the number of trials than the other searchers in the same time limit. This
    shows that the gap between BlendSearch and the other algorithms will increase
    with bigger time budgets.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于其节省成本的方式，BlendSearch 平均在相同时间限制内评估的试验次数是其他搜索器的两倍。这表明，随着时间预算的增加，BlendSearch
    与其他算法之间的差距将会扩大。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: FLAML is a newly released library containing [state-of-the-art](https://arxiv.org/abs/2005.01571) hyperparameter
    optimization algorithms that leverages the structure of the search space to optimize
    for both cost and model performance simultaneously. FLAML can also utilize [Ray
    Tune](https://docs.ray.io/en/latest/tune/index.html) for distributed hyperparameter
    tuning to scale up these economical AutoML methods across a cluster.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: FLAML 是一个新发布的库，包含了 [最先进的](https://arxiv.org/abs/2005.01571) 超参数优化算法，利用搜索空间的结构同时优化成本和模型性能。FLAML
    还可以利用 [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) 进行分布式超参数调优，以在集群中扩展这些经济高效的
    AutoML 方法。
- en: For more information on FLAML, please see the [GitHub repository](https://github.com/microsoft/FLAML) and
    the [project page](https://aka.ms/flaml). If you would like to keep up to date
    with all things Ray, consider [following @raydistributed on twitter](https://twitter.com/raydistributed) and [sign
    up for the newsletter](https://anyscale.us5.list-manage.com/subscribe?u=524b25758d03ad7ec4f64105f&id=d94e960a03).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 FLAML 的更多信息，请参见 [GitHub 仓库](https://github.com/microsoft/FLAML) 和 [项目页面](https://aka.ms/flaml)。如果你想及时了解
    Ray 的一切，请考虑 [关注 @raydistributed 的 Twitter](https://twitter.com/raydistributed)
    并 [订阅新闻通讯](https://anyscale.us5.list-manage.com/subscribe?u=524b25758d03ad7ec4f64105f&id=d94e960a03)。
- en: '[Original](https://towardsdatascience.com/fast-automl-with-flaml-ray-tune-64ff4a604d1c).
    Reposted with permission.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/fast-automl-with-flaml-ray-tune-64ff4a604d1c)。转载已获许可。'
- en: '**Related:**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine Learning Pipeline Optimization with TPOT](/2021/05/machine-learning-pipeline-optimization-tpot.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TPOT 机器学习管道优化](/2021/05/machine-learning-pipeline-optimization-tpot.html)'
- en: '[Binary Classification with Automated Machine Learning](/2021/05/binary-classification-automated-machine-learning.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[二分类自动机器学习](/2021/05/binary-classification-automated-machine-learning.html)'
- en: '[Overview of AutoNLP from Hugging Face with Example Project](/2021/06/overview-autonlp-hugging-face-example-project.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Hugging Face AutoNLP 概述及示例项目](/2021/06/overview-autonlp-hugging-face-example-project.html)'
- en: '* * *'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How To Fine-Tune ChatGPT 3.5 Turbo](https://www.kdnuggets.com/how-to-finetune-chatgpt-35-turbo)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何微调 ChatGPT 3.5 Turbo](https://www.kdnuggets.com/how-to-finetune-chatgpt-35-turbo)'
- en: '[How to Use Hugging Face AutoTrain to Fine-tune LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face AutoTrain 微调 LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
- en: '[How to Fine-Tune BERT for Sentiment Analysis with Hugging Face Transformers](https://www.kdnuggets.com/how-to-fine-tune-bert-sentiment-analysis-hugging-face-transformers)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face Transformers 对 BERT 进行情感分析的微调](https://www.kdnuggets.com/how-to-fine-tune-bert-sentiment-analysis-hugging-face-transformers)'
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 在稀疏化条件下能达到多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过快速克里金（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何让 Python 代码运行得惊人迅速](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
