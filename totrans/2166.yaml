- en: Understanding the Basics of Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning](https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Understanding the Basics of Reinforcement Learning](../Images/ae95ebb172fd241073ad13c19e1f1377.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor | Ideogram
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning is the area of AI focused on building systems that learn
    from experience or trial and error. This post uncovers the basic concepts and
    applications of this intriguing part of AI in a nontechnical and approachable
    way.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: What is Reinforcement Learning?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reinforcement Learning (RL) is a branch of AI where an agent — typically a software
    program — gradually learns to make decisions intelligently through interaction
    with its environment.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand the rationale behind RL, a common comparison is that of
    a young kid learning to ride a bicycle. At first, the kid initially tries out
    different actions, often leading to a fall. Every time the kid falls off the bike,
    (s)he experiences pain (punishment), whereas if the kid manages to ride a few
    meters without falling, (s)he feels satisfied (reward). The kid gradually internalizes
    which actions -or sequences of actions- lead to smooth riding, applying them and
    improving their riding skills.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, in RL an agent performs actions that lead to rewards or punishments
    and iteratively adjusts its behavior to improve its performance over time.
  prefs: []
  type: TYPE_NORMAL
- en: Elements of an RL Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step to understanding the basics of RL is introducing the key elements
    of an RL algorithm. These elements are illustrated in the diagram below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Elements of an RL algorithm](../Images/392daabd31142d084e1bffe0470668d4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Agent:** a software entity that makes decisions and takes actions in an environment
    to achieve a goal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment:** The digital or physical setting the agent interacts with,
    by executing actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**State:** The environment is composed of states, such that the agent is in
    a certain state at a given time. In other words, a state represents the current
    environment situation, being "analyzed" by the agent to make decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Action:** Any move or decision made by the agent in a given state, normally
    leading to a new state as a result of the action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reward:** A value or feedback received by the agent as a result of taking
    an action leading to a new state. It can be positive or negative (punishment),
    indicating an immediate success or failure of the action made concerning the objective
    defined. Positive rewards tend to bring the agent closer to such an objective,
    and vice versa.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How Does an RL Agent Learn?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our next question to answer is: how does the agent learn to choose actions
    that lead to maximum rewards, both in the short and the long term? Put another
    way, which elements does the agent utilize during the learning process to improve
    its decision-making capabilities over actions at different states? This is where
    the concepts of policy and value function come into the scene.'
  prefs: []
  type: TYPE_NORMAL
- en: A **policy** is the strategy used by the agent to decide which action to take
    at every possible state. In the simplest case, the policy can be a states-actions
    lookup table, but normally it is defined by a more complex mathematical function
    that maps states to possible actions. For example, an agent who learns to play
    a platform-based video game whose controlled character is currently standing on
    a platform (state) can walk forward, backward, or jump in either direction (actions).
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, the **reward function** quantifies the positive or negative reward
    the agent receives upon executing an action at a given state. Mathematically,
    it maps a state-action pair to a numerical reward. In the video game example,
    if the character is on an edge and jumps forward, it may reach another platform
    opposite him (positive reward), whereas if it decides to walk forward without
    jumping, it will fall (negative reward).
  prefs: []
  type: TYPE_NORMAL
- en: When observed jointly, these elements allow the agent to gradually learn the
    best courses of action leading to maximizing a reward and eventually achieving
    the goal pursued.
  prefs: []
  type: TYPE_NORMAL
- en: Model-based vs Model-free RL Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Where do the policies and reward functions come from? Does someone formulate
    this information about environment states, actions, and their rewards? The short
    answer is: it depends. This information is gathered differently depending on the
    type of RL approach used. There are two broad approaches under this perspective:
    model-based RL and model-free RL.'
  prefs: []
  type: TYPE_NORMAL
- en: Model-based RL uses a model of the environment (often learned upon data via
    machine learning or deep learning) to assess the outcomes of actions taken, whereas
    model-free RL gradually constructs this model through direct environment interaction,
    relying on pure "trial and error" rather than predictions or estimates.
  prefs: []
  type: TYPE_NORMAL
- en: Real-World Impact and Hurdles in RL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications and Latest Trends
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At an experimental level, RL has historically been applied to solving games
    and problems in simulated environments. Still, its application areas have rapidly
    expanded to areas like robotics and recommender engines, where real-time decisions
    in dynamic environments are required. Latest application trends of RL include
    autonomous vehicle control, and its integration with Generative AI (for instance,
    language models), to improve content generation decisions in complex or highly
    changeable settings.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and Limitations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the major challenges of RL is its high computational and data consumption
    cost, due to intensive interactions with the environment to learn effectively,
    thereby making its application in certain real-world scenarios more difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Wrap-Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this article, we walked through the basic concepts surrounding RL algorithms
    and their central component: agents with a goal that perform actions by interacting
    with an environment and gradually learn from the result of these actions. We also
    outlined the salient real applications and challenges of implementing RL solutions.
    While challenging, RL is currently experiencing a lot of popularity due to its
    symbiotic relationship with Gen-AI solutions, making them much more effective
    at content generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.linkedin.com/in/ivanpc/)****[Iván Palomares Carrascosa](https://www.linkedin.com/in/ivanpc/)****
    is a leader, writer, speaker, and adviser in AI, machine learning, deep learning
    & LLMs. He trains and guides others in harnessing AI in the real world.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Back to Basics Week 3: Introduction to Machine Learning](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back To Basics, Part Dos: Gradient Descent](https://www.kdnuggets.com/2023/03/back-basics-part-dos-gradient-descent.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn MLOps Basics with This Free eBook](https://www.kdnuggets.com/2023/08/learn-mlops-basics-free-ebook.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Basics: Syntax, Data Types, and Control Structures](https://www.kdnuggets.com/python-basics-syntax-data-types-and-control-structures)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Basics Week 1: Python Programming & Data Science Foundations](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Basics Week 4: Advanced Topics and Deployment](https://www.kdnuggets.com/back-to-basics-week-4-advanced-topics-and-deployment)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
