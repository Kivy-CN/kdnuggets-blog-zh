- en: Explainable and Reproducible Machine Learning Model Development with DALEX and
    Neptune
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DALEX和Neptune进行可解释且可复现的机器学习模型开发
- en: 原文：[https://www.kdnuggets.com/2020/08/explainable-reproducible-machine-learning-model-development-dalex-neptune.html](https://www.kdnuggets.com/2020/08/explainable-reproducible-machine-learning-model-development-dalex-neptune.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/08/explainable-reproducible-machine-learning-model-development-dalex-neptune.html](https://www.kdnuggets.com/2020/08/explainable-reproducible-machine-learning-model-development-dalex-neptune.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Jakub Czakon](https://www.linkedin.com/in/jakub-czakon-2b797b69/), Sr
    Data Scientist at neptune.ai, [Przemysław Biecek](https://www.linkedin.com/in/pbiecek/),
    Founder of MI2DataLab & Adam Rydelek, Research Engineer at MI2DataLab**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Jakub Czakon](https://www.linkedin.com/in/jakub-czakon-2b797b69/)、neptune.ai的高级数据科学家，[Przemysław
    Biecek](https://www.linkedin.com/in/pbiecek/)、MI2DataLab创始人以及MI2DataLab的研究工程师Adam
    Rydelek**'
- en: '![](../Images/f6bf1686db1df1c4f1f5dfd97c02ac5f.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6bf1686db1df1c4f1f5dfd97c02ac5f.png)'
- en: Machine learning model development is hard, especially in the real world.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型开发是困难的，尤其是在现实世界中。
- en: 'Typically, you need to:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你需要：
- en: understand the business problem,
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解业务问题，
- en: gather the data,
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据，
- en: explore it,
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索它，
- en: set up a proper validation scheme,
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置合适的验证方案，
- en: implement models and tune parameters,
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现模型并调整参数，
- en: deploy them in a way that makes sense for the business,
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以对业务有意义的方式部署它们，
- en: inspect model results only to find out new problems that you have to deal with.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查模型结果只会发现你必须处理的新问题。
- en: And that is not all.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这还不是全部。
- en: You should have the **experiments** you run and **models** you train **versioned** in
    case you or anyone else needs to inspect them or reproduce the results in the
    future. From my experience, this moment comes when you least expect it and the
    feeling of “I wish I had thought about it before” is so very real (and painful).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该对你运行的**实验**和训练的**模型**进行**版本控制**，以便你或其他人需要检查它们或在未来复现结果时使用。从我的经验来看，这一刻总是出乎意料，“我希望我早些考虑到这一点”的感觉非常真实（且痛苦）。
- en: But there is even more.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但还有更多内容。
- en: With ML models serving real people, misclassified cases (which are a natural
    consequence of using ML) are affecting peoples’ lives and sometimes treating them
    very unfairly.  It makes the ability to **explain your models’ predictions** a
    requirement rather than just a nice to have.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习模型服务于真实的人，误分类案例（这是使用机器学习的自然结果）影响了人们的生活，有时还非常不公平。这使得**解释模型预测的能力**成为一种必要，而不仅仅是一个附加功能。
- en: So what can you do about it?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你可以做些什么呢？
- en: Fortunately, today there are tools that make dealing with both of those problems
    possible.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，如今有工具可以解决这两个问题。
- en: The best part is you can combine them to **have your models versioned, reproducible,
    and explainable**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最棒的是，你可以将它们结合起来**使你的模型具有版本控制、可复现和可解释性**。
- en: '**Read on to learn how to:**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**继续阅读以了解如何：**'
- en: explain machine learning models with **DALEX** explainers
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**DALEX**解释器解释机器学习模型
- en: make your models versioned and experiments reproducible with **Neptune**
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Neptune**使你的模型有版本控制并使实验可复现
- en: automatically save model explainers and interactive explanation charts for every
    training run with **Neptune + DALEX integration**
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Neptune + DALEX集成**自动保存每次训练运行的模型解释器和交互式解释图表
- en: compare, debug, and audit every model you build with **versioned explainers**
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**版本控制的解释器**比较、调试和审计你构建的每个模型
- en: Let’s dive in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解一下。
- en: Explainable Machine Learning with DALEX
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用DALEX进行可解释的机器学习
- en: Nowadays a model that scores high on the test set is often not enough. That’s
    why there is a growing interest in eXplainable Artificial Intelligence (**XAI**),
    which is a set of methods and techniques that make you understand the model’s
    behavior.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，仅仅在测试集上得分高的模型通常是不够的。这就是为什么对可解释人工智能（**XAI**）的兴趣日益增长，XAI是一套让你理解模型行为的方法和技术。
- en: There are many XAI methods available in multiple programming languages. Some
    of the most commonly used in machine learning are *LIME*, *SHAP, *or *PDP*, but
    there are many more.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可解释人工智能（XAI）方法在多种编程语言中可用。在机器学习中一些最常用的方法是*LIME*、*SHAP*或*PDP*，但还有许多其他方法。
- en: It is easy to get lost in the vast amount of techniques and that is where the **eXplainable
    Artificial Intelligence pyramid** comes in handy. It gathers the needs related
    to the exploration of models into an extensible drill-down map. The left side
    is about needs related to a single instance, the right side to a model as a whole.
    Consecutive layers dig into more and more detailed questions about the model behavior
    (local or global).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多技术中很容易迷失方向，这时**可解释人工智能金字塔**派上用场。它将与模型探索相关的需求汇聚成一个可扩展的逐层地图。左侧关于单个实例的需求，右侧关于整个模型的需求。连续的层次深入探讨有关模型行为的更多详细问题（局部或全局）。
- en: '![Figure](../Images/0a85199219440aaa9d112da40313744e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/0a85199219440aaa9d112da40313744e.png)'
- en: XAI pyramide | Find more in the [Explanatory Model Analysis ebook](https://pbiecek.github.io/ema/)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: XAI pyramide | 了解更多请参见[解释模型分析电子书](https://pbiecek.github.io/ema/)
- en: DALEX (available in R and Python) is a tool that **helps you to understand how** complex
    models are working. It currently works for tabular data only (but text and vision
    will come in the future).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: DALEX（适用于R和Python）是一个**帮助你理解**复杂模型工作原理的工具。它目前仅适用于表格数据（但未来将支持文本和视觉）。
- en: It is integrated with most popular frameworks used for building machine learning
    models like *keras, sklearn, xgboost, lightgbm, H2O *and many more!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 它与用于构建机器学习模型的最流行框架集成，如*keras, sklearn, xgboost, lightgbm, H2O*等！
- en: The core object in **DALEX** is an **explainer**. It connects training or evaluation
    data and a trained model and extracts all the information that you need to explain
    it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**DALEX**的核心对象是**解释器**。它连接训练或评估数据和训练好的模型，并提取你需要解释的所有信息。'
- en: Once you have it you can create visualizations, show model parameters, and dive
    into other model-related information. You can share it with your team or save
    it for later.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦拥有它，你可以创建可视化，展示模型参数，并深入挖掘其他与模型相关的信息。你可以与团队分享，或保存以备后用。
- en: Creating an explainer for any model is really easy, as you can see in this example
    using *sklearn*!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为任何模型创建解释器非常简单，如在这个使用*sklearn*的示例中所示！
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Model explanation for observations (local explanations)**'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**模型解释（局部解释）**'
- en: When you want to understand **why your model made a particular prediction**,
    local explanations are your best friend.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想理解**为何你的模型做出特定预测**时，局部解释是你最好的朋友。
- en: It all starts with a prediction and moving down the left half of the pyramid
    above you can explore and understand what happened.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一切从预测开始，向下移动到上面金字塔的左半部分，你可以探索和理解发生了什么。
- en: 'DALEX gives you a bunch of methods that show the influence of each variable
    locally:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: DALEX提供了一系列方法，展示每个变量的局部影响：
- en: '[SHAP](https://github.com/slundberg/shap): calculates contributions of features
    to the model prediction using classic Shapley values'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP](https://github.com/slundberg/shap): 使用经典的Shapley值计算特征对模型预测的贡献'
- en: '[Break Down](https://pbiecek.github.io/breakDown/): decomposes predictions
    into parts that can be attributed to each variable with so-called “greedy explanations”'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Break Down](https://pbiecek.github.io/breakDown/): 将预测分解成可以归因于每个变量的部分，使用所谓的“贪婪解释”'
- en: '[Break Down with interactions](https://pbiecek.github.io/breakDown/reference/break_down.html):
    extends “greedy explanations” to account for feature interactions'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Break Down with interactions](https://pbiecek.github.io/breakDown/reference/break_down.html):
    扩展“贪婪解释”以考虑特征交互'
- en: Moving down the pyramid, the next crucial part of local explanations is **understanding
    the sensitivity of the model **to changes in feature values.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 向下移动金字塔，局部解释的下一个关键部分是**理解模型对特征值变化的敏感性**。
- en: 'There is an easy way to plot such information in DALEX:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在DALEX中有一种简单的方法来绘制这些信息：
- en: '[Ceteris Paribus](https://github.com/pbiecek/ceterisParibus): shows changes
    in model prediction allowing for differences only in a single variable while keeping
    all others constant'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ceteris Paribus](https://github.com/pbiecek/ceterisParibus): 显示模型预测的变化，仅允许单个变量的差异，同时保持其他变量不变'
- en: Following up on our example Random Forest model created on the Titanic dataset,
    we can easily create the plots mentioned above.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们在泰坦尼克数据集上创建的随机森林模型示例，我们可以轻松创建上述提到的图。
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![local explanations dalex](../Images/af80b569c95394071aa04cf71a65a0de.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![本地解释 dalex](../Images/af80b569c95394071aa04cf71a65a0de.png)'
- en: '**Model understanding (global explanations)**'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**模型理解（全局解释）**'
- en: When you want to understand **which features are generally important for your
    model** when it makes decisions you should look into global explanations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想了解**在模型做出决策时哪些特征通常重要**时，你应查看全局解释。
- en: To understand the model on the global level DALEX provides you with the variable
    importance plots. Variable importance plots, specifically [permutation feature
    importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html),
    enable the user to understand each variable’s influence on the model as a whole,
    and distinguish the most important ones.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从全局层面理解模型，DALEX 提供了变量重要性图。变量重要性图，特别是[置换特征重要性](https://christophm.github.io/interpretable-ml-book/feature-importance.html)，使用户能够了解每个变量对整体模型的影响，并区分出最重要的变量。
- en: Such visualizations can be seen as a global equivalent of SHAP and Break Down
    plots which depict similar information for a single observation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可视化可以被看作是 SHAP 和 Break Down 图的全局等效物，它们描绘了单个观察的类似信息。
- en: Moving down the pyramid, on a dataset level, there are techniques such as Partial
    Dependence Profiles and Accumulated Local Dependence that let you **visualize
    the way the model reacts as a function of selected variables.**
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集层面，下降到金字塔下，有一些技术，如部分依赖图和累计局部依赖图，让你**可视化模型对选定变量反应的方式**。
- en: Now let’s create some global explanations for our example.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们为示例创建一些全局解释。
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![global explanations dalex](../Images/af19a0391f6e9c8dde1f156b86505d31.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![全局解释 dalex](../Images/af19a0391f6e9c8dde1f156b86505d31.png)'
- en: '**Reusable and organized explanation objects**'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**可重复使用且有组织的解释对象**'
- en: A clean, structured, and easy to use collection  of XAI visualizations is great
    but there is more to DALEX than that.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一个干净、结构化且易于使用的 XAI 可视化集合很好，但 DALEX 还有更多功能。
- en: Packaging your models in **DALEX explainers** gives you a **reusable and organized
    way of storing and versioning** any work you do with machine learning **models**.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 将你的模型打包在**DALEX 解释器**中，提供了一个**可重复使用且有组织的存储和版本控制**任何你进行的机器学习**模型**工作的方式。
- en: 'The explainer object created using DALEX contains:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DALEX 创建的解释对象包含：
- en: a model to be explained,
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要解释的模型，
- en: model name and class,
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型名称和类别，
- en: task type,
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务类型，
- en: data which will be used to calculate the explanations,
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于计算解释的数据，
- en: model predictions for such data,
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 针对这些数据的模型预测，
- en: predict function,
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测函数，
- en: model residuals,
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型残差，
- en: sampling weights for observations,
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对观察的采样权重，
- en: additional model information (package, version, etc.)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的模型信息（包、版本等）
- en: Having all this information stored in a single object makes creating local and
    global explanations easy (as we saw before).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些信息存储在一个对象中，使得创建本地和全局解释变得容易（正如我们之前所见）。
- en: It also makes reviewing, sharing, and comparing models and explanations at every
    stage of model development possible.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 它还使得在模型开发的每个阶段，审查、共享和比较模型及解释成为可能。
- en: Experiment and model versioning with Neptune
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Neptune 进行实验和模型版本控制
- en: In the perfect world, all your machine learning models and experiments are versioned
    in the same way as you version your software projects.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，你的所有机器学习模型和实验都应以与版本化软件项目相同的方式进行版本控制。
- en: Unfortunately, to keep track of your ML projects you need way more than just
    committing your code to Github.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，要跟踪你的 ML 项目，你需要的远远不止于将代码提交到 Github。
- en: 'In a nutshell, to **version machine learning models properly** you should keep
    track of:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**正确版本化机器学习模型** 你应当跟踪：
- en: code, notebooks, and configuration files
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码、笔记本和配置文件
- en: environment
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境
- en: parameters
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数
- en: datasets
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集
- en: model files
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型文件
- en: results like evaluation metrics, performance charts or predictions
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果如评估指标、性能图表或预测
- en: Some of those things work nicely with .git (code, environment configs) but others
    not so much.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有些内容与 .git 很匹配（代码、环境配置），但其他的则不太合适。
- en: Neptune makes it easy to keep track of all that by letting you log everything
    and anything you feel is important.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Neptune 通过让你记录所有你认为重要的内容，使得跟踪这些内容变得简单。
- en: 'You just add a few lines to your scripts:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需在脚本中添加几行：
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And every experiment or model training you run is versioned and waiting for
    you in the Neptune app (and database ????).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你运行的实验或模型训练都会被版本控制，并在 Neptune 应用程序（和数据库 ????）中等待你。
- en: '![Figure](../Images/5c1627d06e0e3712b005925b22acce45.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5c1627d06e0e3712b005925b22acce45.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-79/details)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-79/details)'
- en: Your team can access all of the experiments and models, compare results, and
    find the information quickly.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你的团队可以访问所有实验和模型，比对结果，快速找到信息。
- en: 'You may be thinking: “Ok great, so I have my models versioned but”:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在想：“好的，很棒，我的模型已经版本化了，但”：
- en: what if I want to debug the model weeks or months after they were trained?
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我想在模型训练后的几周或几个月后调试它怎么办？
- en: what if I want to see the prediction explanations or variable importance for
    every experiment run?
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我想查看每次实验运行的预测解释或变量重要性怎么办？
- en: what if somebody asks me to check if this model is unfairly biased and I don’t
    have the code or data it was trained on?
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有人让我检查这个模型是否存在不公平偏见，而我没有训练它的代码或数据怎么办？
- en: I hear you, and that’s where DALEX integration comes in!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我听到了，这就是 DALEX 集成发挥作用的地方！
- en: DALEX + Neptune = versioned and explainable models
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DALEX + Neptune = 版本化和可解释的模型
- en: Why not have your DALEX **explainers logged and versioned for every experiment** with
    interactive explanation charts rendered in a nice UI, easy to share with anyone
    you want.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不让你的 DALEX **解释器在每个实验中都被记录和版本控制**，并使用交互式解释图表在一个友好的用户界面中呈现，方便与任何你想分享的人共享呢？
- en: Exactly, why not!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，为什么不呢！
- en: With Neptune-DALEX integration, you can get all that at a cost of 3 additional
    lines.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Neptune-DALEX 集成，你可以以额外 3 行代码的成本获得所有这些。
- en: 'Also, there are some very real benefits that come with this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些非常实际的好处：
- en: You can **review models** that others created and share yours easily
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以 **审查** 其他人创建的模型，并轻松分享你的模型
- en: You can **compare** the behavior of any of the created models
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以 **比较** 任何创建的模型的行为
- en: You can **trace and audit every model** for unwanted bias and other problems
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以 **追踪和审计每个模型** 以发现不希望有的偏见和其他问题
- en: You can **debug** and compare models for which the training data, code or parameters
    are missing
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以 **调试** 和比较那些缺少训练数据、代码或参数的模型
- en: Ok, it sounds cool, but how does it actually work?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这听起来很酷，但它实际上是如何工作的呢？
- en: Let’s get into this now.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在深入了解一下。
- en: '**Version local explanations**'
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**本地解释的版本控制**'
- en: 'To log local model explanations you just need to:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要记录本地模型解释，你只需：
- en: Create an observation vector
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个观察向量
- en: Create your DALEX explainer object
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建你的 DALEX 解释器对象
- en: Pass them to the `log_local_explanations` function from `neptunecontrib`
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们传递给 `log_local_explanations` 函数来自 `neptunecontrib`
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Interactive explanation charts will be waiting for you in the “Artifacts” section
    of the Neptune app:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式解释图表将在 Neptune 应用的“Artifacts”部分等待你：
- en: '![Figure](../Images/354524bc9f4a79a229dbf7c8eb896a22.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/354524bc9f4a79a229dbf7c8eb896a22.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/shared/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=SHAP.html)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/shared/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=SHAP.html)'
- en: 'The following plots are created:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表被创建：
- en: variable importance
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量重要性
- en: partial dependence (if numerical features are specified)
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部分依赖（如果指定了数值特征）
- en: accumulated dependence (if categorical features are specified)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 累积依赖（如果指定了类别特征）
- en: '**Version global explanations**'
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**全局解释的版本控制**'
- en: 'With global model explanations it’s even simpler:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于全局模型解释，更简单：
- en: Create your DALEX explainer object
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建你的 DALEX 解释器对象
- en: Pass it to the `log_global_explanations` function from `neptunecontrib`
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其传递给 `log_global_explanations` 函数来自 `neptunecontrib`
- en: (optional) specify categorical features for which you would like to plot
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）指定你希望绘制的类别特征
- en: '[PRE5]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That’s it. Now you can go to the “Artifacts” section and find your local explanations
    charts:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。现在你可以前往“Artifacts”部分，找到你的本地解释图表：
- en: '![Figure](../Images/8a1ad29846aabf8b31bcc54d6e62aaa6.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/8a1ad29846aabf8b31bcc54d6e62aaa6.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=Variable%20Importance.html)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=Variable%20Importance.html)'
- en: 'The following plots are created:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表被创建：
- en: break down,
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 细分，
- en: break down with interactions,
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过交互进行细分，
- en: shap,
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: shap
- en: ceteris paribus for numeric variables,
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值变量的 ceteris paribus，
- en: ceteris paribus for categorical variables
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别变量的 ceteris paribus
- en: '**Version explainer objects **'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**版本化解释器对象**'
- en: But if you really want to version your explanations you should **version the
    explainer object** itself.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你真的想对解释进行版本控制，你应该 **对解释器对象本身进行版本控制**。
- en: 'The benefits of saving it?:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 保存它的好处是什么？：
- en: You can always create a visual representation of it later
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你总是可以在之后创建它的可视化表示
- en: You can dive into details in the tabular format
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在表格格式中深入了解细节
- en: You can use it however you like (even if you don’t know how at the moment ????)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以随意使用它（即使你目前不知道怎么做????）
- en: 'and it’s super simple:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 并且这非常简单：
- en: '[PRE6]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You may be thinking:  “How else am I going to use the explainer objects?”
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想：“我还可以如何使用解释器对象？”
- en: Let me show you in the next sections.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我在接下来的部分展示给你。
- en: '**Fetch and analyze explanations of trained models**'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**获取并分析训练模型的解释**'
- en: 'First of all, if you logged your explainer to Neptune you can fetch it directly
    into your script or notebook:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果你将解释器记录到 Neptune，你可以直接将其提取到你的脚本或笔记本中：
- en: '[PRE7]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now that you have the model explanation you can debug your model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了模型解释，你可以调试你的模型。
- en: One possible scenario is that you have an observation for which your model fails
    miserably.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能的场景是，你有一个观察点，但你的模型却失败得很惨。
- en: You want to figure out why.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你想弄清楚原因。
- en: 'If you have your DALEX explainer object saved you can:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你保存了 DALEX 解释器对象，你可以：
- en: create local explanations and see what happened.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建本地解释并查看发生了什么。
- en: check how changing features affect the results.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查特征变化如何影响结果。
- en: '![Figure](../Images/8b46514b05aa3005b55ae67533d11601.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/8b46514b05aa3005b55ae67533d11601.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/shared/dalex-integration/n/6b9d8213-9d1c-4a7d-a448-d2d9e29f7878/66389c83-b397-4ec6-a1fc-8b5847980fe5)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/shared/dalex-integration/n/6b9d8213-9d1c-4a7d-a448-d2d9e29f7878/66389c83-b397-4ec6-a1fc-8b5847980fe5)'
- en: Of course, you can do way more, especially if you want to compare models and
    explanations.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以做更多的事情，特别是如果你想比较模型和解释的话。
- en: Let’s dive into that now!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在来深入了解一下！
- en: '**Compare models and explanations **'
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**比较模型和解释**'
- en: 'What if you want to:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想：
- en: compare the current model idea with the models that are running in production?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将当前模型想法与在生产中运行的模型进行比较？
- en: see whether experimental ideas from last year would work better on freshly collected
    data?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看去年的实验性想法是否在新收集的数据上表现更好？
- en: Having a clean structure of experiments and models and a single place where
    you store them makes it really easy to do.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有清晰的实验和模型结构以及存储它们的单一位置使得这变得非常简单。
- en: 'You can compare experiments based on parameters, data version, or metrics in
    the Neptune UI:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据参数、数据版本或指标在 Neptune UI 中比较实验：
- en: '![Figure](../Images/264e24ab0f479d0ae3aea82e2c3eec12.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/264e24ab0f479d0ae3aea82e2c3eec12.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/o/shared/org/dalex-integration/compare?shortId=%5B%22DAL-78%22%2C%22DAL-77%22%2C%22DAL-76%22%2C%22DAL-75%22%2C%22DAL-72%22%5D&viewId=495b4a41-3424-4d01-9064-70be82716196)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/o/shared/org/dalex-integration/compare?shortId=%5B%22DAL-78%22%2C%22DAL-77%22%2C%22DAL-76%22%2C%22DAL-75%22%2C%22DAL-72%22%5D&viewId=495b4a41-3424-4d01-9064-70be82716196)'
- en: You **see the diffs in two clicks** and can drill down to whatever info you
    need with one or two more.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你**只需两次点击即可查看差异**，并且可以通过一到两次点击深入查看所需的信息。
- en: Ok, it is really useful when it comes to comparing hyperparameters and metrics
    but what about the explainers?
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，它在比较超参数和指标时确实非常有用，但解释器呢？
- en: You can go into each experiment and [look at the interactive explanation charts](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=Break%20Down%20Interactions.html) to
    see if there is something fishy going on with your model.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以进入每个实验并[查看交互式解释图表](https://ui.neptune.ai/o/shared/org/dalex-integration/e/DAL-78/artifacts?path=charts%2F&file=Break%20Down%20Interactions.html)以查看模型是否存在异常情况。
- en: What’s better, Neptune lets you access all the information you logged programmatically,
    including model explainers.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是，Neptune 让你以编程方式访问所有记录的信息，包括模型解释器。
- en: 'You can **fetch explainer objects for each experiment and compare them**. Just
    use `get_pickle` function from `neptunecontrib` and then visualize multiple explainers
    with DALEX `.plot`:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以**获取每个实验的解释器对象并进行比较**。只需使用来自 `neptunecontrib` 的 `get_pickle` 函数，然后使用 DALEX
    `.plot` 可视化多个解释器：
- en: '[PRE8]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure](../Images/6169f3b94a4c2d57e5fa4cc80356ca92.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/6169f3b94a4c2d57e5fa4cc80356ca92.png)'
- en: '[See it in Neptune](https://ui.neptune.ai/o/shared/org/dalex-integration/n/comparison-6b9d8213-9d1c-4a7d-a448-d2d9e29f7878/4bf30571-1ef1-4c63-9241-6d3b2cab65a7)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[在 Neptune 中查看](https://ui.neptune.ai/o/shared/org/dalex-integration/n/comparison-6b9d8213-9d1c-4a7d-a448-d2d9e29f7878/4bf30571-1ef1-4c63-9241-6d3b2cab65a7)'
- en: That is the beauty of DALEX plots. You can pass multiple explainers and they
    will do the magic.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 DALEX 图表的魅力。你可以传递多个解释器，它们将发挥魔力。
- en: Of course, you can compare previously trained models with the one that you are
    currently working on to see if you are going in the right direction. Just append
    it to the list of explainers and pass to the `.plot` method.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以将以前训练的模型与当前正在工作的模型进行比较，以查看你是否在正确的方向上。只需将其附加到解释器列表中并传递给 `.plot` 方法。
- en: '**Final thoughts**'
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**最后思考**'
- en: Ok, to sum up.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，总结一下。
- en: 'In this article, you’ve learned about:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你了解了：
- en: Various model explanation techniques and how to package those explanations with 
    DALEX explainers
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种模型解释技术以及如何将这些解释与 DALEX 解释器打包
- en: How you can version machine learning models and experiments with Neptune
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Neptune 对机器学习模型和实验进行版本控制
- en: How to version model explainers and interactive explanation charts for every
    training you run with Neptune + DALEX integration
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为每次训练版本化模型解释器和交互式解释图表，并与 Neptune + DALEX 集成
- en: How to compare and debug models you train with explainers
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何比较和调试你训练的模型与解释器
- en: With all that information, I hope your model development process will now be
    more organized, reproducible, and explainable.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 希望有了这些信息，你的模型开发过程现在会更加有组织、可重复和可解释。
- en: Happy training!
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 祝训练愉快！
- en: '[![](../Images/c89ec4635ace581269125d4065e3d508.png)](https://docs.neptune.ai/integrations/dalex.html)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/c89ec4635ace581269125d4065e3d508.png)](https://docs.neptune.ai/integrations/dalex.html)'
- en: '[**Jakub Czakon**](https://www.linkedin.com/in/jakub-czakon-2b797b69/) is Senior
    Data Scientist at neptune.ai.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Jakub Czakon**](https://www.linkedin.com/in/jakub-czakon-2b797b69/) 是 neptune.ai
    的高级数据科学家。'
- en: '[**Przemysław Biecek**](https://www.linkedin.com/in/pbiecek/) is Founder of
    MI2DataLab, Principal Data Scientist at Samsung R&D Institute Poland.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Przemysław Biecek**](https://www.linkedin.com/in/pbiecek/) 是 MI2DataLab
    的创始人，三星研发中心波兰的首席数据科学家。'
- en: '**Adam Rydelek** is a Research Engineer at MI2DataLab, Student in Data Science
    at Warsaw University of Technology.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**Adam Rydelek** 是 MI2DataLab 的研究工程师，华沙理工大学数据科学专业的学生。'
- en: '[Original](https://neptune.ai/blog/explainable-and-reproducible-machine-learning-with-dalex-and-neptune).
    Reposted with permission.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://neptune.ai/blog/explainable-and-reproducible-machine-learning-with-dalex-and-neptune)。已获许可转载。'
- en: '**Related:**'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[A simple and interpretable performance measure for a binary classifier](/2020/03/interpretable-performance-measure-binary-classifier.html)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一种简单且可解释的二分类器性能度量](/2020/03/interpretable-performance-measure-binary-classifier.html)'
- en: '[Explaining “Blackbox” Machine Learning Models: Practical Application of SHAP](/2020/05/explaining-blackbox-machine-learning-models-practical-application-shap.html)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解释“黑箱”机器学习模型：SHAP 的实际应用](/2020/05/explaining-blackbox-machine-learning-models-practical-application-shap.html)'
- en: '[Interpretability part 3: opening the black box with LIME and SHAP](/2019/12/interpretability-part-3-lime-shap.html)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释性第 3 部分：通过 LIME 和 SHAP 打开黑箱](/2019/12/interpretability-part-3-lime-shap.html)'
- en: '* * *'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 领域'
- en: '* * *'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Build a Reproducible and Maintainable Data Science Project: A Free…](https://www.kdnuggets.com/2022/08/free-book-build-reproducible-maintainable-data-science-project.html)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个可重复和可维护的数据科学项目：一本免费书…](https://www.kdnuggets.com/2022/08/free-book-build-reproducible-maintainable-data-science-project.html)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的预测和现在预测，采用最先进的深度学习技术…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的 AI：揭示模型决策的 10 个 Python 库](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弥合人类理解与机器学习之间的差距：……](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
- en: '[Open Assistant: Explore the Possibilities of Open and Collaborative…](https://www.kdnuggets.com/2023/04/open-assistant-explore-possibilities-open-collaborative-chatbot-development.html)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开放助手：探索开放和协作的可能性……](https://www.kdnuggets.com/2023/04/open-assistant-explore-possibilities-open-collaborative-chatbot-development.html)'
- en: '[12 VSCode Tips and Tricks for Python Development](https://www.kdnuggets.com/2023/05/12-vscode-tips-tricks-python-development.html)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12个VSCode技巧和窍门用于Python开发](https://www.kdnuggets.com/2023/05/12-vscode-tips-tricks-python-development.html)'
