- en: 'Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical
    Performance'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产机器学习监控：异常值、漂移、解释器与统计性能
- en: 原文：[https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html](https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html](https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Alejandro Saucedo](https://www.linkedin.com/in/axsaucedo/), Engineering
    Director at Seldon**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[亚历杭德罗·索塞多](https://www.linkedin.com/in/axsaucedo/)，Seldon的工程总监**'
- en: '![Figure](../Images/5adde1d0c003e4c846241add464f5b86.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5adde1d0c003e4c846241add464f5b86.png)'
- en: Image by Author
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: “The lifecycle of a machine learning model only begins once it’s in production”
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “机器学习模型的生命周期只有在生产环境中开始”
- en: In this article we present an end-to-end example showcasing best practices,
    principles, patterns and techniques around monitoring of machine learning models
    in production. We will show how to adapt standard microservice monitoring techniques
    towards deployed machine learning models, as well as more advanced paradigms including
    concept drift, outlier detection and AI explainability.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了一个端到端的示例，展示了生产中机器学习模型监控的最佳实践、原则、模式和技术。我们将展示如何将标准的微服务监控技术适应于已部署的机器学习模型，以及更高级的范式，包括概念漂移、异常检测和人工智能解释。
- en: We will train an image classification machine learning model from scratch, deploy
    it as a microservice in Kubernetes, and introduce a broad range of advanced monitoring
    components. The monitoring components will include outlier detectors, drift detectors,
    AI explainers and metrics servers — we will cover the underlying architectural
    patterns used for each, which are developed with scale in mind, and designed to
    work efficiently across hundreds or thousands of heterogeneous machine learning
    models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从头开始训练一个图像分类机器学习模型，将其作为微服务部署在Kubernetes中，并引入广泛的高级监控组件。这些监控组件将包括异常检测器、漂移检测器、AI解释器和指标服务器——我们将涵盖每个组件的底层架构模式，这些模式考虑了规模的需求，并设计为在数百或数千个异构机器学习模型中高效工作。
- en: You can also view this blog post in video form, which was presented as the keynote
    at the PyCon Hong Kong 2020 — the main delta is that the talk uses an Iris Sklearn
    model for the e2e example instead of the CIFAR10 Tensorflow model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以以视频形式查看这篇博客文章，该视频作为PyCon香港2020的主题演讲——主要的区别在于演讲使用了Iris Sklearn模型作为端到端示例，而不是CIFAR10
    Tensorflow模型。
- en: End to end machine learning monitoring example
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端机器学习监控示例
- en: In this article we present an end-to-end hands on example covering each of the
    high level concepts outlined in the sections below.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了一个端到端的实际示例，涵盖了下面部分中概述的每个高级概念。
- en: Introduction to Monitoring Complex ML Systems
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复杂机器学习系统监控介绍
- en: CIFAR10 Tensorflow Renset32 model training
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CIFAR10 Tensorflow Renset32模型训练
- en: Model Packaging & Deployment
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型打包与部署
- en: Performance monitoring
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 性能监控
- en: Eventing Infrastructure for Monitoring
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件基础设施监控
- en: Statistical monitoring
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 统计监控
- en: Outlier detection monitoring
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 异常检测监控
- en: Concept drift monitoring
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 概念漂移监控
- en: Explainability monitoring
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释性监控
- en: 'We will be using the following open source frameworks in this tutorial:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用以下开源框架：
- en: '[**Tensorflow **](https://github.com/tensorflow/tensorflow)— Widely used machine
    learning framework.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Tensorflow**](https://github.com/tensorflow/tensorflow) — 广泛使用的机器学习框架。'
- en: '[**Alibi Explain**](https://github.com/SeldonIO/alibi) — White-box and black-box
    ML model explanation library.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Alibi Explain**](https://github.com/SeldonIO/alibi) — 白盒和黑盒机器学习模型解释库。'
- en: '[**Albi Detect **](https://github.com/SeldonIO/alibi-detect)— Advanced machine
    learning monitoring algorithms for concept drift, outlier detection and adversarial
    detection.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Albi Detect**](https://github.com/SeldonIO/alibi-detect) — 先进的机器学习监控算法，用于概念漂移、异常检测和对抗性检测。'
- en: '[**Seldon Core**](https://github.com/SeldonIO/seldon-core/) — Machine learning
    deployment and orchestration of the models and monitoring components.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Seldon Core**](https://github.com/SeldonIO/seldon-core/) — 机器学习模型的部署与编排及监控组件。'
- en: You can find the full code for this article in the [jupyter notebook provided](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb) which
    will allow you to run all relevant steps throughout the model monitoring lifecycle.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [提供的 jupyter notebook](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb) 中找到本文的完整代码，这将允许你运行模型监控生命周期中的所有相关步骤。
- en: Let’s get started.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 1\. Introduction to Monitoring Complex ML Systems
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 复杂机器学习系统监控简介
- en: Monitoring of production machine learning is hard, and it becomes exponentially
    more complex once the number of models and advanced monitoring components grows.
    This is partly due to how different production machine learning systems are compared
    to traditional software microservice-based systems — some of these key differences
    are outlined below.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生产机器学习的监控很困难，而且随着模型数量和高级监控组件的增加，复杂性呈指数级增长。这部分是因为生产机器学习系统与传统的软件微服务系统的差异——以下概述了一些关键差异。
- en: '![Figure](../Images/0c0298d101c1be5bc129ca939d2ccf2c.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/0c0298d101c1be5bc129ca939d2ccf2c.png)'
- en: Image by Author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: '**Specialized hardware** —Optimized implementation of machine learning algorithms
    often require access to GPUs, larger amounts of RAM, specialised TPUs/FPGAs, and
    other even dynamically changing requirements. This results in the need for specific
    configuration to ensure this specialised hardware can produce accurate usage metrics,
    and more importantly that these can be linked to the respective underlying algorithms.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用硬件** — 优化的机器学习算法实现通常需要访问 GPU、更大的 RAM、专用的 TPU/FPGAs 以及其他动态变化的需求。这导致需要特定的配置，以确保这些专用硬件可以产生准确的使用指标，更重要的是，这些指标可以与相应的底层算法关联。'
- en: '**Complex Dependency Graphs **— The tools and underlying data involves complex
    dependencies that can span across complex graph structures. This means that the
    processing of a single datapoint may require stateful metric assessment across
    multiple hops, potentially introducing additional layers of domain-specific abstraction
    which may have to be taken into consideration for reliable interpretation of monitoring
    state.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂的依赖图** — 工具和基础数据涉及复杂的依赖关系，这些关系可能跨越复杂的图结构。这意味着处理单个数据点可能需要在多个跳跃之间进行状态评估，这可能会引入额外的领域特定抽象层，需要在可靠解读监控状态时考虑。'
- en: '**Compliance Requirements** — Production systems, especially in highly regulated
    environments may involve complex policies around auditing, data requirements,
    as well as collection of resources and artifacts at each stage of execution. Sometimes
    the metrics that are being displayed and analysed will have to be limited to the
    relevant individuals, based on the specified policies, which can vary in complexity
    across use-cases.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合规要求** — 生产系统，特别是在高度监管的环境中，可能涉及复杂的审计政策、数据要求以及在每个执行阶段收集资源和文档的要求。有时，显示和分析的指标必须根据指定的政策限制给相关人员，这些政策的复杂性可能因用例而异。'
- en: '**Reproducibility **— On top of these complex technical requirements, there
    is a critical requirement around reproducibility of components, ensuring that
    the components that are run can be executed at another point with the same results.
    When it comes to monitoring, it is important that the systems are built with this
    in mind such that it’s possible to re-run particular machine learning executions
    to reproduce particular metrics, whether for monitoring or for auditing purposes.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复性** — 除了这些复杂的技术要求外，还需要组件的可重复性，确保运行的组件可以在另一个时间点以相同的结果执行。对于监控系统，重要的是系统在设计时考虑到这一点，以便能够重新运行特定的机器学习执行，以重现特定的指标，无论是用于监控还是审计目的。'
- en: The anatomy of production machine learning involves a broad range of complexities
    that range across the multiple stages of the model’s lifecycle. This includes
    experimentation, scoring, hyperparameter tuning, serving, offline batch, streaming
    and beyond. Each of these stages involve potentially different systems with a
    broad range of heterogeneous tools. This is why it is key to ensure we not only
    learn how we are able to introduce model-specific metrics to monitor, but that
    we identify the higher level architectural patterns that can be used to enable
    the deployed models to be monitored effectively at scale. This is what we will
    cover in each of the sections below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 生产机器学习的构造涉及多阶段模型生命周期中的广泛复杂性。这包括实验、评分、超参数调整、服务、离线批处理、流处理等。每个阶段可能涉及不同的系统和各种异质工具。因此，确保我们不仅学习如何引入特定于模型的指标进行监控，而且要识别可以用于在规模上有效监控部署模型的更高级别的架构模式，这一点至关重要。这是我们在下面每个部分中将要覆盖的内容。
- en: 2\. CIFAR10 Tensorflow Renset32 model training
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. CIFAR10 Tensorflow Resnet32模型训练
- en: '![Figure](../Images/e0fc7f608ee02bb318b6d800cfffeb2a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/e0fc7f608ee02bb318b6d800cfffeb2a.png)'
- en: Image from the open source [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 来自开源的[CIFAR10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)的图像
- en: We will be using the intuitive [**CIFAR10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html).
    This dataset consists of images that can be classified across one of 10 classes.
    The model will take as an input an array of shape 32x32x3 and as output an array
    with 10 probabilities for which of the classes it belongs to.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用直观的[**CIFAR10数据集**](https://www.cs.toronto.edu/~kriz/cifar.html)。这个数据集包含的图像可以被分类为10个类别之一。模型将以形状为32x32x3的数组作为输入，并以一个包含10个概率的数组作为输出，表示该图像属于哪个类别。
- en: 'We are able to load the data from the Tensorflow datasets — namely:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够从Tensorflow数据集中加载数据——即：
- en: The 10 classes include: `cifar_classes = [“airplane”, “automobile”, “bird”,
    “cat”, “deer”, “dog”, “frog”, “horse”, “ship”, “truck”]`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 10个类别包括：`cifar_classes = [“airplane”, “automobile”, “bird”, “cat”, “deer”, “dog”,
    “frog”, “horse”, “ship”, “truck”]`。
- en: In order for us to train and deploy our machine learning model, we will follow
    the traditional machine learning workflow outlined in the diagram below. We will
    be training a model which we will then be able to export and deploy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练和部署我们的机器学习模型，我们将遵循下图所示的传统机器学习工作流程。我们将训练一个模型，然后可以将其导出和部署。
- en: '![Image for post](../Images/dc4efbfe55db9179d41c9b3cd37bb2ba.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/dc4efbfe55db9179d41c9b3cd37bb2ba.png)'
- en: We will be using Tensorflow to train this model, leveraging the [Residual Network](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035) which
    is arguably one of the most groundbreaking architectures as it makes it possible
    to train up to hundreds or even thousands of layers with good performance. For
    this tutorial we will be using the Resnet32 implementation, which fortunately
    we’ll be able to use through the utilities provided by the Alibi Detect Package.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Tensorflow来训练这个模型，利用[Residual Network](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)，这无疑是最具突破性的架构之一，因为它使得训练多达数百甚至上千层的网络成为可能，并且性能良好。在这个教程中，我们将使用Resnet32实现，幸运的是，我们可以通过Alibi
    Detect包提供的工具使用它。
- en: Using my GPU this model took about 5 hours to train, luckily we will be able
    to use a pre-trained model which can be retrieved using the Alibi Detect `fetch_tf_model` utils.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我的GPU，这个模型训练了大约5小时，幸运的是，我们可以使用通过Alibi Detect `fetch_tf_model`工具检索的预训练模型。
- en: If you want to still train the CIFAR10 resnet32 tensorflow model, you can use
    the helper utilities provided by the Alibi Detect package as outlined below, or
    even just import the raw Network and train it yourself.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然想训练CIFAR10 resnet32 tensorflow模型，你可以使用Alibi Detect包提供的辅助工具，如下所述，或者直接导入原始网络并自行训练。
- en: We can now test the trained model on “unseen data”. We can test it using a CIFAR10
    datapoint that would be classified as a truck. We can have a look at the datapoint
    by plotting it using Matplotlib.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在“未见数据”上测试训练好的模型。我们可以使用一个被分类为卡车的CIFAR10数据点来测试它。我们可以通过Matplotlib绘制数据点来查看。
- en: '![Image for post](../Images/c13d881447de9a1cb03b023f153b0927.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/c13d881447de9a1cb03b023f153b0927.png)'
- en: We can now process that datapoint through the model, which as you can imagine
    should be predicted as a “truck”.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过模型处理该数据点，你可以想象它应该被预测为“卡车”。
- en: We can find the class predicted by finding the index with the highest probability,
    which in this case it is `index 9`with a high probability of 99%. From the names
    of the classes (e.g. `cifar_classes[ np.argmax( X_curr_pred )]`) we can see that
    class 9 is “truck”.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过找到概率最高的索引来确定预测的类别，在这种情况下，它是`index 9`，概率为99%。从类别名称（例如`cifar_classes[ np.argmax(
    X_curr_pred )]`）可以看出，第9类是“卡车”。
- en: 3\. Package & deploy Model
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 打包与部署模型
- en: We will be using Seldon Core for the deployment of our model into Kubernetes,
    which provides multiple options to convert our model into a fully fledged microservice
    exposing REST, GRPC and Kafka interfaces.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Seldon Core将模型部署到Kubernetes中，它提供了多种选项将我们的模型转换为一个完全成熟的微服务，暴露REST、GRPC和Kafka接口。
- en: The options we have to deploy models with Seldon Core include 1) the [Language
    Wrappers](https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html) to
    deploy our Python, Java, R, etc code classes, or 2) the [Prepackaged Model Servers](https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html) to
    deploy model artifacts directly. In this tutorial we will be using the [Tensorflow
    Prepackaged Model](https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html) server
    to deploy the Resnet32 model we were using earlier.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用Seldon Core部署模型时的选项包括 1) 使用[语言封装](https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html)来部署我们的Python、Java、R等代码类，或
    2) 使用[预打包模型服务器](https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html)直接部署模型工件。在本教程中，我们将使用[Tensorflow预打包模型](https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html)服务器来部署我们之前使用的Resnet32模型。
- en: This approach will allow us to take advantage of the cloud native architecture
    of Kubernetes which powers large scale microservice systems through horizontally
    scalable infrastructure. We will be able to learn about and leverage cloud native
    and microservice patterns adopted to machine learning throughout this tutorial.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将使我们能够利用Kubernetes的云原生架构，它通过水平可扩展的基础设施支持大规模微服务系统。在本教程中，我们将深入了解和利用应用于机器学习的云原生和微服务模式。
- en: The diagram below summarises the options available to deploy model artifacts
    or the code itself, together with the abilities we have to deploy either a single
    model, or build complex inference graphs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表总结了部署模型工件或代码本身的选项，以及我们可以选择部署单个模型或构建复杂的推理图的能力。
- en: '![Image for post](../Images/a78e2d4a97e0799410efad8c75bdd0b3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/a78e2d4a97e0799410efad8c75bdd0b3.png)'
- en: As a side note, you can get set up you on Kubernetes using a development environment
    like [KIND (Kubernetes in Docker)](https://github.com/kubernetes-sigs/kind) or [Minikube,](https://github.com/kubernetes/minikube) and
    then following the instructions in the [Notebook for this example](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb),
    or in the [Seldon documentation](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html).
    You will need to make sure you install Seldon with a respective ingress provider
    like Istio or Ambassador so you can send the REST requests.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 顺便提一下，您可以使用[KIND（Kubernetes in Docker）](https://github.com/kubernetes-sigs/kind)或[Minikube](https://github.com/kubernetes/minikube)等开发环境在Kubernetes上进行设置，然后按照[此示例的笔记本](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb)或[Seldon文档](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html)中的说明进行操作。您需要确保安装Seldon，并配置相应的Ingress提供者，如Istio或Ambassador，以便发送REST请求。
- en: 'To simplify the tutorial, we have already uploaded the trained Tensorflow Resnet32
    model, which can be found this public Google bucket: `gs://seldon-models/tfserving/cifar10/resnet32`.
    If you have trained your model, you are able to upload it to the bucket of your
    choice, which can be Google Bucket, Azure, S3 or local Minio. Specifically for
    Google you can do it using the `gsutil` command line with the command below:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化教程，我们已经上传了训练好的Tensorflow Resnet32模型，可以在这个公共Google桶中找到：`gs://seldon-models/tfserving/cifar10/resnet32`。如果您已经训练了自己的模型，可以将其上传到您选择的桶中，可以是Google桶、Azure、S3或本地Minio。对于Google，您可以使用下面的`gsutil`命令行进行操作：
- en: We can deploy our model with Seldon using the custom resource definition configuration
    file. Below is the script that converts the model artifact into a fully fledged
    microservice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Seldon通过自定义资源定义配置文件部署模型。下面是将模型工件转换为完全成熟的微服务的脚本。
- en: We can now see that the model has been deployed and is currently running.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到模型已经部署并正在运行。
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We can now test our deployed model by sending the same image of the truck, and
    see if we still have the same prediction.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过发送相同的卡车图像来测试已部署的模型，看看我们是否仍然得到相同的预测。
- en: '![Figure](../Images/c13d881447de9a1cb03b023f153b0927.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c13d881447de9a1cb03b023f153b0927.png)'
- en: Datapoint displayed with `plt.imshow(X_curr[0])`
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点通过`plt.imshow(X_curr[0])`显示
- en: We will be able to do this by sending a REST request as outlined below, and
    then print the results.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过发送如下所述的REST请求来实现，然后打印结果。
- en: The output of the code above is the JSON response of the POST request to the
    url that Seldon Core provides us through [the ingress](https://docs.seldon.io/projects/seldon-core/en/latest/ingress/istio.html).
    We can see that the prediction is correctly resulting in the “truck” class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出是对Seldon Core提供的URL的POST请求的JSON响应。我们可以看到预测正确地结果为“卡车”类别。
- en: '[PRE1]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 4\. Performance Monitoring
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 性能监控
- en: The first monitoring pillar we will be covering is the good old performance
    monitoring, which is the traditional and standard monitoring features that you
    would find in the microservices and infrastructure world. Of course in our case
    we will be adopting it towards deployed machine learning models.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖的第一个监控支柱是传统的性能监控，这是你在微服务和基础设施领域中会找到的传统和标准监控功能。当然，在我们的案例中，我们将其应用于已部署的机器学习模型。
- en: 'Some high level principles of machine learning monitoring include:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习监控的高级原则包括：
- en: '**Monitoring the performance of the running ML service**'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控运行中的ML服务性能**'
- en: '**Identifying potential bottlenecks or runtime red flags**'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**识别潜在瓶颈或运行时警告**'
- en: '**Debugging and diagnosing unexpected performance of ML services**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试和诊断ML服务的意外性能**'
- en: 'For this we will be able to introduce the first two core frameworks which are
    commonly used across production systems:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将介绍在生产系统中常用的前两个核心框架：
- en: Elasticsearch for logs — A document key-value store that is commonly used to
    store the logs from containers, which can then be used to diagnose errors through
    stack traces or information logs. In the case of machine learning we don’t only
    use it to store logs but also to store pre-processed inputs and outputs of machine
    learning models for further processing.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch用于日志——一个文档键值存储系统，通常用于存储容器的日志，这些日志可以用于通过堆栈跟踪或信息日志诊断错误。在机器学习的情况下，我们不仅用它来存储日志，还用来存储机器学习模型的预处理输入和输出，以便进一步处理。
- en: Prometheus for metrics —A time-series store that is commonly used to store real-time
    metrics data, which can then be visusalised leveraging tools like Grafana.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus用于指标——一个时间序列存储系统，通常用于存储实时指标数据，然后可以利用像Grafana这样的工具进行可视化。
- en: Seldon Core provides integration with Prometheus and Elasticsearch out of the
    box for any model deployed. During this tutorial we will be referencing Elasticsearch
    but to simplify the intuitive grasp of several advanced monitoring concepts we
    will be using mainly Prometheus for metrics and Grafana for the visualisations.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Seldon Core为任何已部署的模型提供了开箱即用的Prometheus和Elasticsearch集成。在本教程中，我们将参考Elasticsearch，但为了简化对几个高级监控概念的直观理解，我们将主要使用Prometheus进行指标和Grafana进行可视化。
- en: In the diagram below you can visualise how the exported microservice enables
    any containerised model to export both metrics and logs. The metrics are scraped
    by prometheus, and the logs are forwarded by the model into elasticsearch (which
    happens through the eventing infrastructure we cover in the next section. For
    explicitness it is worth mentioning that Seldon Core also supports Open Tracing
    metrics using Jaeger, which shows the latency throughout all microservice hops
    in the Seldon Core model graph.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到导出的微服务如何使任何容器化的模型能够导出指标和日志。指标由Prometheus抓取，日志由模型转发到Elasticsearch（通过我们在下一部分中介绍的事件基础设施进行）。值得明确的是，Seldon
    Core还支持使用Jaeger的Open Tracing指标，显示了Seldon Core模型图中所有微服务跳跃的延迟。
- en: '![Figure](../Images/c143b6a1cd7220fe395eb48ec970de53.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c143b6a1cd7220fe395eb48ec970de53.png)'
- en: Image by Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Some examples of performance monitoring metrics that are exposed by Seldon
    Core models, and that can be also added through further integrations include:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一些由Seldon Core模型暴露的性能监控指标示例，也可以通过进一步集成添加：
- en: '**Requests per second**'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每秒请求数**'
- en: '**Latency per request**'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每个请求的延迟**'
- en: '**CPU/memory/data utilisation**'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU/内存/数据利用率**'
- en: '**Custom application metrics**'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义应用指标**'
- en: For this tutorial you can set up Prometheus and Grafana by using the [Seldon
    Core Analytics package](https://docs.seldon.io/projects/seldon-core/en/latest/examples/metrics.html#Install-Seldon-Analytics) that
    sets everything up for metrics to be collected in real time, and then visualised
    on the dashboards.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你可以使用[Seldon Core Analytics包](https://docs.seldon.io/projects/seldon-core/en/latest/examples/metrics.html#Install-Seldon-Analytics)来设置Prometheus和Grafana，该包会设置一切，以便实时收集指标，然后在仪表板上进行可视化。
- en: We can now visualise the utilization metrics of the deployed models relative
    to their specific infrastructure. When deploying a model with Seldon you will
    have multiple attributes that you will want to take into consideration to ensure
    optimal processing of your models. This includes the allocated CPU, Memory and
    Filesystem store reserved for the application, but also the respective configuration
    for running processes and threads relative to the allocated resources and expected
    requests.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以可视化部署模型相对于其特定基础设施的利用率指标。使用Seldon部署模型时，你需要考虑多个属性，以确保模型的最佳处理。这包括分配的CPU、内存和为应用程序保留的文件系统存储，还包括相应的配置，用于相对于分配的资源和预期请求运行进程和线程。
- en: '![Figure](../Images/d0cc2829de8a477556017a2a4e626f43.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/d0cc2829de8a477556017a2a4e626f43.png)'
- en: Image by Author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Similarly, we are also able to monitor the usage of the model itself — every
    seldon model exposes model usage metrics such as requests-per-second, latency
    per request, success/error codes for models, etc. These are important as they
    are able to map into the mode advanced/specialised concepts of the underlying
    machine learning model. Large latency spikes could be diagnosed and explained
    based on the underlying requirements of the model. Similarly errors that the model
    displays are abstracted into simple HTTP error codes, which allows for standardisation
    of advanced ML components into microservice patterns that then can be managed
    more easily at scale by DevOps / IT managers.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们也能够监控模型本身的使用情况——每个Seldon模型都暴露模型使用指标，如每秒请求数、每个请求的延迟、模型的成功/错误代码等。这些指标很重要，因为它们能够映射到底层机器学习模型的更高级/专用概念。大的延迟峰值可以根据模型的底层需求进行诊断和解释。模型显示的错误也被抽象成简单的HTTP错误代码，这有助于将先进的机器学习组件标准化为微服务模式，从而使DevOps
    / IT管理人员更容易大规模管理。
- en: '![Figure](../Images/07c8b6943074a75ba76ace141563087f.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/07c8b6943074a75ba76ace141563087f.png)'
- en: Image by Author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 5\. Eventing Infrastructure for Monitoring
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 监控的事件基础设施
- en: In order for us to be able to leverage the more advanced monitoring techniques,
    we will first introduce briefly the eventing infrastructure that allows Seldon
    to use advanced ML algorithms for monitoring of data asynchronously and in a scalable
    architecture.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够利用更高级的监控技术，我们将首先简要介绍事件基础设施，这使得Seldon可以使用先进的机器学习算法进行异步数据监控，并在可扩展的架构中运行。
- en: Seldon Core leverages [KNative Eventing](https://knative.dev/docs/eventing/) to
    enable Machine Learning models to forward the inputs and outputs of the model
    into the more advanced machine learning monitoring components like outlier detectors,
    concept drift detectors, etc.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Seldon Core利用[KNative Eventing](https://knative.dev/docs/eventing/)来使机器学习模型能够将模型的输入和输出转发到更高级的机器学习监控组件，如异常检测器、概念漂移检测器等。
- en: '![Image for post](../Images/a57c4af6face082e2133f577a4bef0a1.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![文章图像](../Images/a57c4af6face082e2133f577a4bef0a1.png)'
- en: We will not be going into too much detail on the eventing infrastructure that
    KNative introduces, but if you are curious there are multiple hands on examples
    in the Seldon Core documentation in regards to how it leverages the KNative Eventing
    infrastructure to [forward payloads to further components](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/log_level.html) such
    as Elasticsearch, as well as how Seldon models can also be connected to [process
    events](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细介绍KNative引入的事件基础设施，但如果你感兴趣，Seldon Core文档中有多个实际示例，展示了如何利用KNative事件基础设施将有效负载[转发到进一步的组件](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/log_level.html)如Elasticsearch，以及Seldon模型如何连接到[处理事件](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html)。
- en: For this tutorial, we need to enable our model to forward all the payload inputs
    and ouputs processed by the model into the KNative Eventing broker, which will
    enable all other advanced monitoring components to subscribe to these events.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们需要使模型能够将所有处理过的负载输入和输出转发到KNative Eventing代理，这将使所有其他高级监控组件能够订阅这些事件。
- en: The code below adds a “logger” attribute to the deployment configuration which
    specifies the broker location.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码向部署配置中添加了一个“logger”属性，用于指定代理位置。
- en: 6\. Statistical monitoring
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6. 统计监控
- en: Performance metrics are useful for general monitoring of microservices, however
    for the specialised world of machine learning, there are widely-known and widely-used
    metrics that are critical throughout the lifecycle of the model beyond the training
    phase. More common metrics can include accuracy, precision, recall, but also metrics
    like [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation), [KL Divergence](https://en.wikipedia.org/wiki/Relative_entropy),
    between many many more.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 性能指标对于微服务的常规监控是有用的，然而对于机器学习的专业领域，有一些广为人知和广泛使用的指标在模型生命周期的训练阶段之外都至关重要。更常见的指标包括准确率、精确度、召回率，但也包括像[均方根误差](https://en.wikipedia.org/wiki/Root-mean-square_deviation)、[KL散度](https://en.wikipedia.org/wiki/Relative_entropy)等更多指标。
- en: The core theme of this article is not just to specify how these metrics can
    be calculated, as it’s not an arduous task to enable an individual microservice
    to expose this through some Flask-wrapper magic. The key here is to identify scalable
    architectural patterns that we can introduce across hundreds or thousands of models.
    This means that we require a level of standardisation on the interfaces and patterns
    that are required to map the models into their relevant infrastructure.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的核心主题不仅仅是指定如何计算这些指标，因为通过一些Flask包装魔法使单个微服务暴露这些指标并不是一项艰巨的任务。关键在于识别可以在数百或数千个模型中引入的可扩展架构模式。这意味着我们需要对接口和模式进行一定程度的标准化，以便将模型映射到相关基础设施中。
- en: 'Some high level principles that revolve around more specialised machine learning
    metrics are the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一些高级原则围绕更专业的机器学习指标，如下所示：
- en: '**Monitoring specific to statistical ML performance**'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对统计机器学习性能的监控**'
- en: '**Benchmarking multiple different models or different versions**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基准测试多个不同模型或不同版本**'
- en: '**Specialised for the data-type and the input/output format**'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对数据类型和输入/输出格式的专业化**'
- en: '**Stateful asynchronous provisioning of “feedback” on previous requests (such
    as “annotations” or “corrections”)**'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有状态的异步“反馈”提供（如“注释”或“修正”）**'
- en: 'Given that we have these requirements, Seldon Core introduces a set of architectural
    patterns that allow us to introduce the concept of “Extensible Metrics Servers”.
    These metric servers contain out-of-the-box ways to process data that the model
    processes by subscribing to the respective eventing topics, to ultimately expose
    metrics such as:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些需求，Seldon Core引入了一套架构模式，允许我们引入“可扩展指标服务器”的概念。这些指标服务器包含现成的处理模型处理数据的方法，通过订阅相应的事件主题，最终暴露出如下一些指标：
- en: '**Raw metrics: True-Positives, True-Negatives, False-Positives, False-Negatives**'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原始指标：真正例、假负例、假正例、真正负例**'
- en: '**Basic metrics: Accuracy, precision, recall, specificity**'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本指标：准确率、精确度、召回率、特异性**'
- en: '**Specialised metrics: KL Divergence, RMSE, etc**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专业指标：KL散度、均方根误差等**'
- en: '**Breakdowns per class, features, and other metadata**'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按类别、特征和其他元数据的细分**'
- en: '![Figure](../Images/30cca19ad85dee2babd4ed75c402ce5f.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/30cca19ad85dee2babd4ed75c402ce5f.png)'
- en: Image by Author
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: From an architectural perspective, this can be visualised more intuitively in
    the diagram above. This showcases how a single datapoint can be submitted through
    the model, and then processed by any respective Metric Servers. The metric servers
    can also process the “correct/annotated” labels once they are provided, which
    can be linked with the unique prediction ID that Seldon Core adds on every request.
    The specialised metrics are calculated and exposed by fetching the relevant data
    from the Elasticsearch store.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构的角度来看，这可以通过上面的图示更加直观地展示。这展示了如何通过模型提交单个数据点，然后由任何相应的指标服务器处理。指标服务器还可以在提供“正确/注释”标签后处理这些标签，这些标签可以与Seldon
    Core在每个请求中添加的唯一预测ID关联。通过从Elasticsearch存储中提取相关数据来计算和暴露专业指标。
- en: 'Currently, Seldon Core provides the following set of out-of-the-box Metrics
    Servers:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Seldon Core提供了一套开箱即用的Metrics Servers：
- en: BinaryClassification — Processes data in the form of binary classifications
    (e.g. 0 or 1) to expose raw metrics to show basic statistical metrics (accuracy,
    precision, recall and specificity).
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BinaryClassification — 处理以二元分类形式出现的数据（例如0或1），以暴露原始指标以显示基本统计指标（准确率、精确度、召回率和特异性）。
- en: MultiClassOneHot — Processes data in the form of one hot predictions for classification
    tasks (e.g. [0, 0, 1] or [0, 0.2, 0.8]), which can then expose raw metrics to
    show basic statistical metrics.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MultiClassOneHot — 处理以one hot预测形式出现的数据用于分类任务（例如[0, 0, 1]或[0, 0.2, 0.8]），然后可以暴露原始指标以显示基本统计指标。
- en: MultiClassNumeric — Processes data in the form of numeric datapoints for classification
    tasks (e.g. 1, or [1]), which can then expose raw metrics to show basic statistical
    metrics.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MultiClassNumeric — 处理分类任务中以数值数据点形式出现的数据（例如1，或[1]），然后可以暴露原始指标以显示基本统计指标。
- en: For this example we will be able to deploy a Metric Server of the type “MulticlassOneHot”
    — you can see the parameters used in the summarised code below, but you can find
    the full YAML in the jupyter notebook.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将能够部署一个类型为“MulticlassOneHot”的Metric Server——你可以在下面总结的代码中看到使用的参数，但完整的YAML文件可以在jupyter
    notebook中找到。
- en: Once we deploy our metrics server, we can now just send requests and feedback
    to our CIFAR10 model, through the same microservice endpoint. To simplify the
    workflow, we will not send asynchronous feedback (which would perform the comparisons
    with the elasticsearch data), but instead we’ll send “self-contained” feedback
    requests, which contain the inference “response” and the inference “truth”.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们部署了我们的指标服务器，现在我们只需通过相同的微服务端点向我们的CIFAR10模型发送请求和反馈。为了简化工作流程，我们将不发送异步反馈（这会与elasticsearch数据进行比较），而是发送“自包含”的反馈请求，其中包含推断“响应”和推断“真实值”。
- en: The following function provides us with a way to send a bunch of feedback requests
    to achieve an approximate accuracy percent (number of correct vs incorrect predictions)
    for our usecase.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数为我们提供了一种发送大量反馈请求的方法，以获得我们用例的大致准确率（正确预测与错误预测的数量）。
- en: Now we can first send feedback to get 90% accuracy, and then to make sure our
    graphs look pretty, we can send another batch request that would result in 40%
    accuracy.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以首先发送反馈以获得90%的准确率，然后为了确保我们的图表看起来漂亮，我们可以发送另一批请求，这将导致40%的准确率。
- en: This now basically gives us the ability to visualise the metrics that the MetricsServer
    calculates in real time.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上赋予我们实时可视化MetricsServer计算的指标的能力。
- en: '![Figure](../Images/331608e4580c21ee4dc09de8b432720f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/331608e4580c21ee4dc09de8b432720f.png)'
- en: Image by Author
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: From the dashboard above we can get a high level intuition of the type of metrics
    that we are able to get through this architectural pattern. The stateful statistical
    metrics above in particular require extra metadata to be provided asynchronously,
    however even though the metrics themselves may have very different ways of being
    calculated, we can see that the infrastructural and architectural requirements
    can be abstracted and standardised in order for these to be approached in a more
    scalable way.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的仪表板中，我们可以对通过这种架构模式能够获得的指标类型有一个高层次的直觉。上述状态统计指标特别需要异步提供额外的元数据，然而，即使指标本身的计算方法可能非常不同，我们可以看到基础设施和架构要求可以被抽象和标准化，以便这些指标能够以更可扩展的方式处理。
- en: We will continue seeing this pattern as we delve further into the more advanced
    statistical monitoring techniques.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们深入研究更高级的统计监控技术，我们将继续看到这种模式。
- en: 7\. Outlier detection monitoring
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7\. 异常检测监控
- en: For a more advanced monitoring technique, we will be leveraging the Alibi Detect
    library, particularly around some of the advanced outlier detector algorithms
    it provides. Seldon Core provides us with a way to perform the deployment of outlier
    detectors as an architectural pattern, but also provides us with a prepackaged
    server that is optimized to serve Alibi Detect outlier detector models.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的监控技术，我们将利用Alibi Detect库，特别是它提供的一些高级异常检测算法。Seldon Core为我们提供了一种将异常检测器作为架构模式进行部署的方法，还为我们提供了一个经过优化的预打包服务器，以服务Alibi
    Detect异常检测模型。
- en: 'Some of the key principles for outlier detection include:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测的一些关键原则包括：
- en: Detecting anomalies in data instances
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测数据实例中的异常
- en: Flagging / alerting when outliers take place
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当出现异常值时进行标记/警报
- en: Identifying potential metadata that could help diagnose outliers
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别可能有助于诊断异常值的潜在元数据
- en: Enable drill down of outliers that are identified
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用对已识别异常值的深入分析
- en: Enabling for continuous / automated retraining of detectors
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用检测器的持续/自动化再训练
- en: In the case of outlier detectors it is especially important to allow for the
    calculations to be performed separate to the model, as these tend to be much heaver
    and may require more specialised components. An outlier detector that is deployed,
    may come with similar complexities to the ones from a machine learning model,
    so it’s important that the same concepts of compliance, governance and lineage
    are covered with these advanced components.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 对于异常值检测器，尤其重要的是允许计算在模型之外进行，因为这些计算通常比较重，并且可能需要更多专业化的组件。已部署的异常值检测器可能会带来与机器学习模型类似的复杂性，因此在这些高级组件中覆盖相同的合规性、治理和血统概念是很重要的。
- en: The diagram below shows how the requests are forwarded by the model using the
    eventing infrastructure. The outlier detector then processes the datapoint to
    calculate whether it’s an outlier. The component is then able to store the outlier
    data in the respective request entry asynchronously, or alternatively it is able
    to expose the metrics to prometheus, which is what we will visualise in this section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了模型如何通过事件基础设施转发请求。异常值检测器随后处理数据点，以计算其是否为异常值。该组件能够将异常值数据异步存储在相应的请求条目中，或者它能够将指标暴露给
    Prometheus，这也是我们在本节中将要可视化的内容。
- en: '![Figure](../Images/c8cff05e54c48ecdbb2c4093776237fd.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/c8cff05e54c48ecdbb2c4093776237fd.png)'
- en: Image by Author
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: For this example we will be using the [Alibi Detect Variational Auto Encoder](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html) outlier
    detector technique. The outlier detector is trained on a batch of unlabeled but
    normal (inlier) data. The VAE detector tries to reconstruct the input it receives,
    if the input data cannot be reconstructed well, then it is flagged as an outlier.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将使用[Alibi Detect 变分自编码器](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html)异常值检测器技术。异常值检测器在一批未标记但正常（内点）数据上进行训练。VAE
    检测器尝试重建其接收到的输入数据，如果输入数据无法被很好地重建，则会被标记为异常值。
- en: Alibi Detect provides us with utilities that allow us to export the outlier
    detector from scratch. We can fetch it using the `fetch_detector` function.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Alibi Detect 提供了允许我们从零开始导出异常值检测器的工具。我们可以使用`fetch_detector`函数来获取它。
- en: If you want to train the outlier, you can do so by simply leveraging the `OutlierVAE` class
    together with the respective encoder and decoders.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想训练异常值检测器，可以通过简单地利用`OutlierVAE`类及其相应的编码器和解码器来实现。
- en: To test the outlier detector we can take the same picture of the truck and see
    how the outlier detector behaves if noise is added to the image increasingly.
    We will also be able to plot it using the Alibi Detect visualisation function `plot_feature_outlier_image`.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试异常值检测器，我们可以拍摄相同的卡车图像，并观察如果在图像中逐渐添加噪声，异常值检测器的表现如何。我们还可以使用 Alibi Detect 可视化函数`plot_feature_outlier_image`来绘制这些结果。
- en: We can create a set of modified images and run it through the outlier detector
    using the code below.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一组修改过的图像，并通过以下代码将其传递给异常值检测器。
- en: We now have an array of modified samples in the variable `all_X_mask` , each
    with an increasing amount of noise. We can now run all these 10 through the outlier
    detector.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在在变量`all_X_mask`中拥有一组修改过的样本，每个样本都带有逐渐增加的噪声。我们现在可以将这 10 个样本全部通过异常值检测器进行检测。
- en: When looking at the results, we can see that the first 3 were not marked as
    outliers, whereas the rest were marked as outliers — we can see it by printing
    the value `print(od_preds[“data”][“is_outlier”])`. Which displays the array below,
    where 0 is non-outliers and 1 is outliers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看结果时，我们可以看到前 3 个数据点没有被标记为异常值，而其余的数据点被标记为异常值——我们可以通过打印值`print(od_preds[“data”][“is_outlier”])`来查看这一点。该命令会显示如下数组，其中
    0 表示非异常值，1 表示异常值。
- en: '[PRE2]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can now visualise how the outlier instance level score maps against the threshold,
    which reflects the results in the array above.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以可视化异常值实例级别的评分如何与阈值映射，这反映了上述数组中的结果。
- en: '![Image for post](../Images/e223f2ae51a8eef73b4d5f7c5d778253.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/e223f2ae51a8eef73b4d5f7c5d778253.png)'
- en: Similarly we can dive deeper into the intuition of what the outlier detector
    score channels look like, as well as the reconstructed images, which should provide
    a clear picture of how its internals operate.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以深入了解异常值检测器评分通道的直观感受，以及重建的图像，这应能清晰地展示其内部操作方式。
- en: '![Image for post](../Images/2354074d9c4f8cd0c9d6d6b73aa0dc2e.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![帖子中的图片](../Images/2354074d9c4f8cd0c9d6d6b73aa0dc2e.png)'
- en: We will now be able to productionise our outlier detector. We will be leveraging
    a similar architectural pattern to the one from the metric servers. Namely the
    Alibi Detect Seldon Core server, which will be listening to the inference input/output
    of the data. For every data point that goes through the model, the respective
    outlier detector will be able to process it.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以将异常值检测器投入生产。我们将利用与指标服务器类似的架构模式，即 Alibi Detect Seldon Core 服务器，它将监听数据的推理输入/输出。每个通过模型的数据点，相关的异常值检测器将能够处理它。
- en: The main step required will be to first ensure the outlier detector we trained
    above is uploaded to an object store like Google bucket. We have already uploaded
    it to `gs://seldon-models/alibi-detect/od/OutlierVAE/cifar10,` but if you wish
    you can upload it and use your own model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 主要步骤是首先确保我们上面训练的异常值检测器已上传到 Google 桶等对象存储中。我们已经将其上传到 `gs://seldon-models/alibi-detect/od/OutlierVAE/cifar10`，但如果你愿意，可以上传并使用自己的模型。
- en: Once we deploy our outlier detector, we will be able to send a bunch of requests,
    many which will be outliers and others that won’t be.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们部署了异常值检测器，我们将能够发送大量请求，其中许多将是异常值，其他的则不是。
- en: We can now visualise some outliers in the dashboard — for every data point there
    will be a new entry point and will include whether it would be an outlier or not.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以在仪表盘上可视化一些异常值——每个数据点都会有一个新的入口，并包括它是否为异常值。
- en: '![Figure](../Images/22fab564c5d242a7368693f631b1c0d1.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/22fab564c5d242a7368693f631b1c0d1.png)'
- en: Image by Author
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 8\. Drift monitoring
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8. 漂移监测
- en: As time passes, data in real life production environments can change. Whilst
    this change is not drastic, it can be identified through drifts in the distribution
    of the data itself particularly in respect to the predicted outputs of the model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，实际生产环境中的数据可能会发生变化。虽然这种变化不是剧烈的，但可以通过数据分布的漂移来识别，尤其是在模型预测输出方面。
- en: 'Key principles in drift detection include:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 漂移检测的关键原则包括：
- en: Identifying drift in data distribution, as well as drifts in the relationship
    between input and output data from a model
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别数据分布中的漂移，以及模型输入和输出数据之间关系的漂移。
- en: Flagging drift that is found together with the relevant datapoints where it
    was identified
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记出找到的漂移以及发现漂移时的相关数据点
- en: Allowing for the ability to drill down into the data that was used to calculate
    the drift
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许深入查看用于计算漂移的数据
- en: In the concept of drift detection we deal with further complexities when compared
    to the outlier detection usecase. The main one being the requirement to run each
    drift prediction on a batch input as opposed to a single datapoint. The diagram
    below shows a similar workflow to the one outlied in the outlier detector pattern,
    the main difference is that it keeps a tumbling or sliding window of data to perform
    the processing against.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在漂移检测的概念中，与异常值检测用例相比，我们面临进一步的复杂性。主要是需要对每个漂移预测进行批量输入，而不是单个数据点。下图展示了与异常值检测器模式类似的工作流程，主要区别在于它保持一个滚动窗口或滑动窗口来进行处理。
- en: '![Figure](../Images/ff4154ac5d02e9d857b37971c4855fb7.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/ff4154ac5d02e9d857b37971c4855fb7.png)'
- en: Image by Author
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: For this example we will once again be using the Alibi Detect library, which
    provides us with the [Kolmogorov-Smirnov data drift detector on CIFAR-10](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将再次使用 Alibi Detect 库，它为我们提供了 [Kolmogorov-Smirnov 数据漂移检测器用于 CIFAR-10](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html)。
- en: For this technique will be able to use the `KSDrift` class to create and train
    the drift detector, which also requires a preprocessing step which uses an “Untrained
    Autoencoder (UAE)”.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种技术，将能够使用 `KSDrift` 类来创建和训练漂移检测器，这还需要一个使用“未训练自编码器 (UAE)”的预处理步骤。
- en: In order for us to test the outlier detector we will generate a set of detectors
    with corrupted data. Alibi Detect provides a great set of utilities that we can
    use to generate corruption/noise into images in an increasing way. In this case
    we will be using the following noise: `[‘gaussian_noise’, ‘motion_blur’, ‘brightness’,
    ‘pixelate’].` These will be generated with the code below.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试异常检测器，我们将生成一组带有损坏数据的检测器。Alibi Detect 提供了一套很好的工具，我们可以用来以逐渐增加的方式生成图像的损坏/噪声。在这种情况下，我们将使用以下噪声：`[‘gaussian_noise’,
    ‘motion_blur’, ‘brightness’, ‘pixelate’]`。这些将使用下面的代码生成。
- en: Below is one datapoint from the created corrupted dataset, which contains images
    with an increasing amount of corruption of the different types outlined above.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个来自创建的损坏数据集的数据点，其中包含上述不同类型的逐渐增加的损坏图像。
- en: '![Image for post](../Images/c2995ccd6c4acf96339a6c0835fbe4ac.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图像](../Images/c2995ccd6c4acf96339a6c0835fbe4ac.png)'
- en: We can now attempt to run a couple of datapoints to compute whether drift is
    detected or not. The initial batch will consist of datapoints from the original
    dataset.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以尝试运行一些数据点以计算是否检测到漂移。初始批次将由来自原始数据集的数据点组成。
- en: This as expected outputs: `Drift? No!`
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这会如预期输出：`漂移？没有！`
- en: Similarly we can run it against the corrupted dataset.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以在损坏的数据集上运行它。
- en: 'And we can see that all of them are marked as drift as expected:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到所有请求都被标记为漂移，如预期的那样：
- en: '[PRE3]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Deploy Drift Detector
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署漂移检测器
- en: Now we can move towards deploying our drift detector following the architectural
    pattern provided above. Similar to the outlier detector we first have to make
    sure that the drift detector we trained above can be uploaded to an object store.
    We currently will be able to use the Google bucket that we have prepared under `gs://seldon-models/alibi-detect/cd/ks/drift` to
    perform the deployment.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以按照上述架构模式部署我们的漂移检测器。与异常检测器类似，我们首先必须确保我们训练的漂移检测器可以上传到对象存储。我们目前可以使用我们准备好的
    Google 存储桶 `gs://seldon-models/alibi-detect/cd/ks/drift` 进行部署。
- en: This will have a similar structure, the main difference is that we will also
    specify the desired batch size to use for the Alibi Detect server to keep as a
    buffer before running against the model. In this case we select a batch size of
    1000.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这将具有类似的结构，主要区别是我们还将指定 Alibi Detect 服务器使用的所需批量大小，以便在运行模型之前作为缓冲。在这种情况下，我们选择批量大小为
    1000。
- en: Now that we have deployed our outlier detector, we first try sending 1000 requests
    from the normal dataset.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经部署了异常检测器，首先尝试从正常数据集中发送 1000 个请求。
- en: Next we can send the corrupted data, which would result in drift detected after
    sending the 10k datapoints.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们可以发送损坏的数据，这将在发送 10k 数据点后导致检测到漂移。
- en: We are able to visualise each of the different drift points detected in the
    Grafana dashboard.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Grafana 仪表盘上可视化检测到的不同漂移点。
- en: '![Figure](../Images/895a3bbbb20901101dfc4bd59edbb935.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/895a3bbbb20901101dfc4bd59edbb935.png)'
- en: Image by Author
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 9\. Explainability monitoring
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9. 可解释性监控
- en: 'AI Explainability techniques are key to understanding the behaviour of complex
    black box machine learning models. There is a broad range of content that explores
    the different algorithmic techniques that can be used in different contexts. Our
    current focus in this context is to provide an intuition and a practical example
    of the architectural patterns that can allow for explainer components to be deployed
    at scale. Some key principles of model explainability include:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可解释性技术对于理解复杂的黑箱机器学习模型的行为至关重要。当前的重点是提供对可解释组件可以大规模部署的架构模式的直观理解和实际示例。模型可解释性的关键原则包括：
- en: '**Human-interpretable insights for model behaviour**'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对模型行为进行人类可解释的洞察**'
- en: '**Introducing use-case-specific explainability capabilities**'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**引入特定用例的可解释性功能**'
- en: '**Identifying key metrics such as trust scores or statistical perf. thresholds**'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**识别关键指标，例如信任评分或统计性能阈值**'
- en: '**Enabling for use of some more complex ML techniques**'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启用使用一些更复杂的机器学习技术**'
- en: 'There are a broad range of different techniques available around explainability,
    but it’s important to understand the high level themes around the different types
    of Explainers. These include:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 关于可解释性有广泛的不同技术，但理解不同类型的解释器的高层主题很重要。这些包括：
- en: '**Scope (local vs global)**'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**范围（本地 vs 全局）**'
- en: '**Model type (black vs white box)**'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型类型（黑箱 vs 白箱）**'
- en: '**Task (classification, regression, etc)**'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务（分类、回归等）**'
- en: '**Data type (tabular, images, text, etc)**'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据类型（表格、图像、文本等）**'
- en: '**Insight (feature attributions, counterfactuals, influential training instances,
    etc)**'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**洞察（特征归因、对比事实、影响训练实例等）**'
- en: For explainers as interfaces, these have similarities in the data flow patterns.
    Namely many of them require interacting with the data that the model processes,
    as well as the ability to interact with the model itself — for black box techniques
    it includes the inputs/outputs whereas for white-box techniques it includes the
    internals of the models themselves.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 作为接口的解释器在数据流模式上有相似之处。即许多解释器需要与模型处理的数据进行互动，并且能够与模型本身进行互动——对于黑箱技术，这包括输入/输出，而对于白箱技术，则包括模型本身的内部。
- en: '![Figure](../Images/81d115b32de0b5399e611f38e790c06d.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/81d115b32de0b5399e611f38e790c06d.png)'
- en: Image by Author
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: From an architectural perspective, this involves primarily a separate microservice
    which instead of just receiving an inference request, it would be able to interact
    with the respective model and “reverse engineer” the model by sending the relevant
    data. This is shown in the diagram above, but it will become more intuitive once
    we dive into the example.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构的角度来看，这主要涉及一个独立的微服务，该服务不仅接收推断请求，还能够与相关模型互动，通过发送相关数据“反向工程”模型。这在上面的图示中有所展示，但一旦我们深入到示例中，这将变得更加直观。
- en: For the example, we will be using the Alibi Explain framework, and we will use
    the [Anchor Explanation](https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_image_imagenet.html) technique.
    This local explanation technique tells us what are the features in a particular
    data point with the highest predictive power.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们将使用 Alibi Explain 框架，并使用[Anchor Explanation](https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_image_imagenet.html)技术。该本地解释技术告诉我们在特定数据点中具有最高预测能力的特征。
- en: We can simply create our Anchor explainer by specifying the structure of our
    dataset, together with a `lambda` that allows the explainer to interact with the
    model’s predict function.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以简单地通过指定数据集的结构以及一个允许解释器与模型的预测功能互动的`lambda`来创建我们的 Anchor 解释器。
- en: We are able to identify what are the anchors in our model that would predict
    in this case the image of the truck.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够识别模型中在此案例中预测图像的锚点。
- en: '![Image for post](../Images/c13d881447de9a1cb03b023f153b0927.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/c13d881447de9a1cb03b023f153b0927.png)'
- en: We can visualise the anchors by displaying the output anchor of the explanation
    itself.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过显示解释本身的输出锚点来可视化锚点。
- en: We can see that the anchors of the image include the windshield and the wheels
    of the truck.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到图像的锚点包括卡车的挡风玻璃和轮子。
- en: '![Image for post](../Images/902de571fd0d5b33d84174f68044924c.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/902de571fd0d5b33d84174f68044924c.png)'
- en: Here you can see that the explainer interacts with our deployed model. When
    deploying the explainer we will be following the same principle but instead of
    using a `lambda` that runs the model locally, this will be a function that will
    call the remote model microservice.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到解释器与我们部署的模型互动。在部署解释器时，我们将遵循相同的原则，但与使用在本地运行模型的`lambda`不同，这将是一个调用远程模型微服务的函数。
- en: We will follow a similar approach where we’ll just need to upload the image
    above to an object store bucket. Similar to the previous example, we have provided
    a bucket under `gs://seldon-models/tfserving/cifar10/explainer-py36–0.5.2`. We
    will now be able to deploy an explainer, which can be deployed as part of the
    CRD of the Seldon Deployment.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用类似的方法，只需将上面的图像上传到对象存储桶。与之前的示例类似，我们提供了一个存储桶，路径为`gs://seldon-models/tfserving/cifar10/explainer-py36–0.5.2`。我们现在可以部署一个解释器，该解释器可以作为
    Seldon 部署的 CRD 部分进行部署。
- en: 'We can check that the explainer is running with `kubectl get pods | grep cifar` ,
    which should output both running pods:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过运行`kubectl get pods | grep cifar`来检查解释器是否正在运行，这应当会输出两个正在运行的 pod：
- en: '[PRE4]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Similar to how we send a request to the model, we are able to send a request
    to the explainer path. This is where the explainer will interact with the model
    itself and print the reverse engineered explanation.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们向模型发送请求的方式，我们也能够向解释器路径发送请求。在这里，解释器将与模型本身互动，并打印出反向工程的解释。
- en: We can see that the output of the explanation is the same as the one we saw
    above.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到解释的输出与我们上面看到的一样。
- en: '![Image for post](../Images/902de571fd0d5b33d84174f68044924c.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/902de571fd0d5b33d84174f68044924c.png)'
- en: Finally we can also see some of the metric related components that come out
    of the explainer themselves, which can then be visualised through dashboards.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还可以看到一些来自解释器本身的与指标相关的组件，这些组件可以通过仪表板进行可视化。
- en: '[PRE5]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Similar to the other microservice based machine learning components deployed,
    the explainers also can expose these and other more specialised metrics for performance
    or advanced monitoring.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他基于微服务的机器学习组件类似，解释器也可以暴露这些和其他更专业的性能或高级监控指标。
- en: Closing Thoughts
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: Before wrapping up, one thing to outline is the importance of abstracting these
    advanced machine learning concepts into standardised architectural patterns. The
    reason why this is crucial is primarily to enable machine learning systems for
    scale, but also to allow for advanced integration of components across the stack.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结之前，需要指出的是将这些高级机器学习概念抽象为标准化架构模式的重要性。这样做的原因主要是为了使机器学习系统具备规模化的能力，同时也便于在整个技术栈中进行高级组件的集成。
- en: All the advanced architectures covered above not only are applicable across
    each of the advanced components, but it is also possible to enable for what we
    can refer to as “ensemble patterns” — that is, connecting advanced components
    on the outputs of other advanced components.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 上述提到的所有高级架构不仅适用于各个高级组件，而且还可以启用我们可以称之为“集成模式”的功能——即将高级组件连接到其他高级组件的输出上。
- en: '![Figure](../Images/0ea18befddfeb5c06aa892b9de841118.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/0ea18befddfeb5c06aa892b9de841118.png)'
- en: Image by Author
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: It is also important to ensure there are structured and standardised architectural
    patterns also enable developers to provide the monitoring components, which are
    also advanced machine learning models, have the same level of governance, compliance
    and lineage required in order to manage the risk efficiently.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要确保结构化和标准化的架构模式，使开发人员能够提供监控组件，这些组件也是高级机器学习模型，具备与之管理风险所需的治理、合规性和追溯相同的水平。
- en: These patterns are continuously being refined and evolved through the Seldon
    Core project, and advanced state of the art algorithms on outlier detection, concept
    drift, explainability, etc are improving continuously — if you are interested
    on furthering the discussion, please feel free to reach out. All the examples
    in this tutorial are open source, so suggestions are greatly appreciated.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模式通过 Seldon Core 项目不断被优化和发展，前沿的异常检测、概念漂移、可解释性等算法也在不断改进——如果你对进一步讨论感兴趣，请随时联系。此教程中的所有示例都是开源的，欢迎提出建议。
- en: 'If you are interested in further hands on examples of scalable deployment strategies
    of machine learning models, you can check out:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对机器学习模型的可扩展部署策略的更多实际示例感兴趣，你可以查看：
- en: '[Batch Processing with Argo Workflows](https://docs.seldon.io/projects/seldon-core/en/latest/examples/argo_workflows_batch.html)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Argo 工作流的批处理](https://docs.seldon.io/projects/seldon-core/en/latest/examples/argo_workflows_batch.html)'
- en: '[Serverless eventing with Knative](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Knative 的无服务器事件处理](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html)'
- en: '[AI Explainability Patterns with Alibi](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Alibi 的 AI 解释模式](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html)'
- en: '[Seldon Model Containerisation Notebook](https://docs.seldon.io/projects/seldon-core/en/latest/examples/sklearn_spacy_text_classifier_example.html)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Seldon 模型容器化笔记本](https://docs.seldon.io/projects/seldon-core/en/latest/examples/sklearn_spacy_text_classifier_example.html)'
- en: '[Kafka Seldon Core Stream Processing Deployment Notebook](https://github.com/SeldonIO/seldon-core/blob/master/examples/kafka/sklearn_spacy/README.ipynb)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kafka Seldon Core 流处理部署笔记本](https://github.com/SeldonIO/seldon-core/blob/master/examples/kafka/sklearn_spacy/README.ipynb)'
- en: '**Bio: [Alejandro Saucedo](https://www.linkedin.com/in/axsaucedo/)** is the
    Engineering Director at Seldon, Chief Scientist at The Institute for Ethical AI,
    and an ACM Council Member-at-Large.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Alejandro Saucedo](https://www.linkedin.com/in/axsaucedo/)** 是 Seldon
    的工程总监、The Institute for Ethical AI 的首席科学家，以及 ACM 委员会成员。'
- en: '[Original](https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158).
    Reposted with permission.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158)。经许可转载。'
- en: '**Related:**'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Interpretability, Explainability, and Machine Learning – What Data Scientists
    Need to Know](/2020/11/interpretability-explainability-machine-learning.html)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释性、可说明性与机器学习——数据科学家需要了解的内容](/2020/11/interpretability-explainability-machine-learning.html)'
- en: '[Deploying Trained Models to Production with TensorFlow Serving](/2020/11/serving-tensorflow-models.html)'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow Serving 部署训练好的模型到生产环境](/2020/11/serving-tensorflow-models.html)'
- en: '[AI Is More Than a Model: Four Steps to Complete Workflow Success](/2020/11/mathworks-ai-four-steps-workflow.html)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 不仅仅是一个模型：实现完整工作流成功的四个步骤](/2020/11/mathworks-ai-four-steps-workflow.html)'
- en: '* * *'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT 需求'
- en: '* * *'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Eurybia 检测数据漂移以确保生产 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[Managing Model Drift in Production with MLOps](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 MLOps 管理生产中的模型漂移](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
- en: '[Fighting AI with AI Fraud Monitoring for Deepfake Applications](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 AI 对抗 AI：深度伪造应用的欺诈监测](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)'
- en: '[Removing Outliers Using Standard Deviation in Python](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用标准差在 Python 中去除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)'
- en: '[How to Handle Outliers in Dataset with Pandas](https://www.kdnuggets.com/how-to-handle-outliers-in-dataset-with-pandas)'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Pandas 处理数据集中的异常值](https://www.kdnuggets.com/how-to-handle-outliers-in-dataset-with-pandas)'
- en: '[A Full End-to-End Deployment of a Machine Learning Algorithm into a…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将机器学习算法完整部署到生产环境](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
