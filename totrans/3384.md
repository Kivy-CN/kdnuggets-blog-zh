# 卷积神经网络的直观解释

> 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2)

另一种理解卷积操作的好方法是查看下面的**图 6**中的动画：

![giphy.gif](../Images/03afaa451f7141fd7a9b9a4ecb9d13c6.png)

###### 图 6：卷积操作。来源 [9]

一个带有红色轮廓的滤波器在输入图像上滑动（卷积操作），以生成特征图。另一个带有绿色轮廓的滤波器在相同图像上的卷积生成了不同的特征图，如所示。需要注意的是，卷积操作捕捉了原始图像中的局部依赖关系。还要注意这两个不同的滤波器如何从相同的原始图像生成不同的特征图。记住，上述图像和两个滤波器只是我们之前讨论过的数字矩阵。

在实践中，CNN 在训练过程中*学习*这些滤波器的值（虽然我们仍然需要在训练过程之前指定一些参数，如滤波器的数量、滤波器的大小、网络的结构等）。我们拥有的滤波器数量越多，提取的图像特征就越多，我们的网络在识别未见图像中的模式时也会更好。

特征图（卷积特征）的大小由我们需要在卷积步骤之前决定的三个参数 [4] 控制：

+   **深度：** 深度对应于我们用于卷积操作的滤波器数量。在**图 7**中所示的网络中，我们使用三个不同的滤波器对原始船只图像进行卷积，从而生成了三个不同的特征图。你可以将这三个特征图视为堆叠的二维矩阵，因此，特征图的“深度”将是三。

![Screen Shot 2016-08-10 at 3.42.35 AM](../Images/04434b802022918265ef4d1b9a70996a.png)

###### 图 7

+   **步幅：** 步幅是我们在输入矩阵上滑动滤波器矩阵的像素数量。当步幅为 1 时，我们一次移动一个像素。当步幅为 2 时，滤波器在滑动时每次跳过 2 个像素。较大的步幅会生成较小的特征图。

+   **零填充：** 有时，将输入矩阵的边界填充零是方便的，以便我们可以将滤波器应用于输入图像矩阵的边界元素。零填充的一个好处是它允许我们控制特征图的大小。添加零填充也被称为*宽卷积*，而不使用零填充则是*窄卷积*。这在 [14] 中已经清楚地解释了。

#### 引入非线性（ReLU）

在上面的**图 3**中，每次卷积操作后都使用了一个额外的操作叫做 ReLU。ReLU 代表修正线性单元，是一种非线性操作。它的输出由以下公式给出：

![Screen Shot 2016-08-10 at 2.23.48 AM.png](../Images/f884f902a6eaab07c2e0655b59f3c524.png)

###### 图 8: ReLU 操作

ReLU 是逐元素操作（逐像素应用），将特征图中的所有负像素值替换为零。ReLU 的目的是在我们的卷积网络中引入非线性，因为我们希望卷积网络学习的大多数现实世界数据都是非线性的（卷积是线性操作——逐元素的矩阵乘法和加法，因此我们通过引入像 ReLU 这样的非线性函数来考虑非线性）。

ReLU 操作可以从下面的**图 9**中清楚地理解。它展示了对**图 6**中获得的一个特征图应用 ReLU 操作。这里的输出特征图也称为“校正”特征图。

![Screen Shot 2016-08-07 at 6.18.19 PM.png](../Images/b7752825316c6b5e7742808da7e2888b.png)

###### 图 9: ReLU 操作。来源 [10]

其他非线性函数，如**tanh**或**sigmoid**，也可以用来代替 ReLU，但在大多数情况下，ReLU 被发现表现更好。

#### 池化步骤

空间池化（也称为下采样或降采样）减少了每个特征图的维度，但保留了最重要的信息。空间池化可以有不同的类型：最大池化、平均池化、求和池化等。

在最大池化的情况下，我们定义一个空间邻域（例如，一个 2×2 的窗口），并从该窗口中的校正特征图中取出最大的元素。除了取最大元素，我们也可以取该窗口中所有元素的平均值（平均池化）或总和。在实践中，最大池化显示出更好的效果。

**图 10** 显示了使用 2×2 窗口在一个校正特征图（卷积 + ReLU 操作后得到）上进行最大池化操作的示例。

![Screen Shot 2016-08-10 at 3.38.39 AM.png](../Images/4aecf0fe58685bdfc7e82e425977ebb3.png)

###### 图 10: 最大池化。来源 [4]

我们将 2 x 2 窗口滑动 2 个单元（也称为“步幅”），并在每个区域中取最大值。如**图 10**所示，这减少了我们特征图的维度。

在**图 11**中所示的网络中，池化操作分别应用于每个特征图（请注意，由于此原因，我们从三个输入图获得了三个输出图）。

![Screen Shot 2016-08-07 at 6.19.37 PM.png](../Images/0229193e9d8a3fc3c5c0a01f9c57ec3e.png)

###### 图 11: 应用于校正特征图的池化

**图 12** 显示了池化对我们在**图 9**中获得的校正特征图的影响。

![Screen Shot 2016-08-07 at 6.11.53 PM.png](../Images/dcb2453efd17a687f7790c3527cc1475.png)

###### 图 12: 池化。来源 [10]

池化的功能是逐步减少输入表示的空间大小[4]。特别地，池化

+   使输入表示（特征维度）变得更小、更易于管理

+   减少网络中的参数和计算数量，从而控制[过拟合](https://en.wikipedia.org/wiki/Overfitting)[4]

+   使网络对输入图像中的小变换、失真和转换具有不变性（输入中的小失真不会改变池化的输出——因为我们在局部邻域中取最大/平均值）。

+   帮助我们获得几乎尺度不变的图像表示（确切术语是“等变”）。这非常强大，因为我们可以检测图像中的物体，无论它们的位置在哪里（详细信息请阅读[18]和[19]）。

#### 到目前为止的故事

![Screen Shot 2016-08-08 at 2.26.09 AM.png](../Images/7f6e70b60b1771cafb71566ed7d80ab1.png)

###### 图13

到目前为止，我们已经看到卷积、ReLU和池化如何工作。重要的是要理解这些层是任何CNN的基本构建块。如**图13**所示，我们有两组卷积、ReLU和池化层——第二个卷积层对第一个池化层的输出进行卷积，使用六个滤波器生成六个特征图。然后对这六个特征图逐个应用ReLU。接着，我们分别对每个经过修正的六个特征图执行最大池化操作。

这些层共同提取图像中的有用特征，引入网络中的非线性，并在旨在使特征对尺度和转换具有一定的等变性[18]的同时减少特征维度。

第二个池化层的输出作为全连接层的输入，我们将在下一节讨论。

#### 全连接层

全连接层是一个传统的多层感知器，它在输出层使用了softmax激活函数（其他分类器如SVM也可以使用，但在此帖中将坚持使用softmax）。术语“全连接”意味着前一层的每个神经元都连接到下一层的每个神经元。如果你对多层感知器不熟悉，建议[阅读这篇文章](http://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)。

卷积和池化层的输出代表了输入图像的高级特征。全连接层的目的是利用这些特征将输入图像分类到基于训练数据集的各种类别中。例如，我们设定的图像分类任务有四个可能的输出，如下**图14**所示（请注意图14未显示全连接层中节点之间的连接）

![Screen Shot 2016-08-06 at 12.34.02 AM.png](../Images/493fc738b0366d0bca616f59fc9f3766.png)

###### 图14：全连接层 - 每个节点与相邻层中的所有其他节点相连接

除了分类之外，添加一个完全连接层也是一种（通常）廉价的方法来学习这些特征的非线性组合。卷积层和池化层中的大多数特征可能适合分类任务，但这些特征的组合可能更好[11]。

完全连接层的输出概率之和为1。这是通过在完全连接层的输出层使用[Softmax](http://cs231n.github.io/linear-classify/#softmax)作为激活函数来确保的。Softmax 函数将一个任意实值分数向量压缩成一个介于零和一之间的值向量，其总和为一。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 需求

* * *

### 了解更多相关话题

+   [协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)

+   [卷积神经网络（CNNs）图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)

+   [卷积神经网络综合指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)

+   [使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)

+   [支持向量机：直观的方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)

+   [线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)
