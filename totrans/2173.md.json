["```py\nimport numpy as np\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\n\n# Load pre-trained VGG16 model (without the top layers for classification)\nbase_model = VGG16(weights='imagenet', include_top=False)\n\n# Function to extract features from an image\ndef extract_features(img_path):\n    img = image.load_img(img_path, target_size=(224, 224))  # Load image and resize\n    x = image.img_to_array(img)  # Convert image to numpy array\n    x = np.expand_dims(x, axis=0)  # Add batch dimension\n    x = preprocess_input(x)  # Preprocess input according to model's requirements\n    features = base_model.predict(x)  # Extract features using VGG16 model\n    return features.flatten()  # Flatten to a 1D array for simplicity\n\n# Example usage\nimage_path = 'path_to_your_image.jpg'\nimage_features = extract_features(image_path)\nprint(f\"Extracted features shape: {image_features.shape}\") \n```", "```py\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Example data (replace with your dataset)\ntexts = [\"I love this product!\", \"This is not what I expected.\", ...]\nlabels = [1, 0, ...]  # 1 for positive sentiment, 0 for negative sentiment, etc.\n\n# Load pre-trained BERT model and tokenizer\nmodel_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Example: binary classification\n\n# Tokenize input texts and create DataLoader\ninputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\ndataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], torch.tensor(labels))\ndataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n\n# Fine-tuning parameters\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Fine-tune BERT model\nmodel.train()\nfor epoch in range(3):  # Example: 3 epochs\n    for batch in dataloader:\n        optimizer.zero_grad()\n        input_ids, attention_mask, target = batch\n        outputs = model(input_ids, attention_mask=attention_mask, labels=target)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step() \n```", "```py\n# Function to adapt text style \ndef adapt_text_style(text):\n    # Example: replace social media language with product review-like language\n    adapted_text = text.replace(\"excited\", \"positive\").replace(\"#innovation\", \"new technology\")\n    return adapted_text\n\n# Example usage of domain adaptation\nsocial_media_post = \"Excited about the new tech! #innovation\"\nadapted_text = adapt_text_style(social_media_post)\nprint(f\"Adapted text: {adapted_text}\")\n\n# Use sentiment classifier trained on product reviews\n# Example: sentiment_score = sentiment_classifier.predict(adapted_text) \n```"]