- en: 'AutoML: An Introduction Using Auto-Sklearn and Auto-PyTorch'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoML：使用 Auto-Sklearn 和 Auto-PyTorch 的介绍
- en: 原文：[https://www.kdnuggets.com/2021/10/automl-introduction-auto-sklearn-auto-pytorch.html](https://www.kdnuggets.com/2021/10/automl-introduction-auto-sklearn-auto-pytorch.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/automl-introduction-auto-sklearn-auto-pytorch.html](https://www.kdnuggets.com/2021/10/automl-introduction-auto-sklearn-auto-pytorch.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![autoML.png](../Images/62f872662eee3e99a9dd99ba62bc7d95.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![autoML.png](../Images/62f872662eee3e99a9dd99ba62bc7d95.png)'
- en: Getting a Computer to Do What You Want Automatically
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让计算机自动完成你想要的任务
- en: '[Machine learning (ML)](https://www.exxactcorp.com/blog/Deep-Learning/a-breakdown-of-deep-learning-frameworks) now
    impacts a wide swath of business, engineering, and research domains, to the extent
    where you’d be hard-pressed to find a niche where machine learning is totally
    uninvolved. Progress in ML has come on the coattails of broader trends in software
    and automation: Wherever human activity depends on doing repetitive tasks that
    can be readily described in a way that a computer can handle, it’s generally useful
    to write down a recipe (or program) for the task that the computer can follow.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[机器学习 (ML)](https://www.exxactcorp.com/blog/Deep-Learning/a-breakdown-of-deep-learning-frameworks)现在影响着广泛的商业、工程和研究领域，以至于很难找到一个完全未涉及机器学习的领域。机器学习的进展伴随着软件和自动化的广泛趋势：只要人类活动依赖于可以以计算机可以处理的方式描述的重复任务，通常编写一个计算机可以遵循的配方（或程序）是很有用的。'
- en: Using ML now means that for many useful tasks it’s no longer necessary to manually
    write a program, or even to know exactly how to solve the problem. Instead we
    can approach many problems by defining a search space and a learning algorithm,
    and then let the machine figure it out.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用机器学习意味着对于许多有用的任务，已经不再需要手动编写程序，甚至不需要准确知道如何解决问题。相反，我们可以通过定义一个搜索空间和一个学习算法来解决许多问题，然后让机器来解决。
- en: 'Modern machine learning is sometimes referred to as “software 2.0” and is a
    trend that has been super-charged by the effectiveness of, and ensuing research
    and development interest in, deep learning. There are obvious applications that
    make a good fit for this approach: like fitting a statistical model to data, for
    example; but there are more esoteric and impressive examples that were never so
    obvious in the days of statistical or old-school machine learning.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现代机器学习有时被称为“软件 2.0”，这一趋势受到深度学习效果以及随之而来的研究和开发兴趣的推动。显而易见，这种方法非常适合一些应用：例如，拟合统计模型到数据上；但也有一些更深奥和令人印象深刻的例子，在统计学或旧式机器学习时代并不明显。
- en: In the last few years we’ve seen machine learning predict protein folding better
    than any other method, beat expert human game players in Go, Dota II, Starcraft
    II, and more, and create reasonably coherent text and speech responses (though
    the last accomplishment can be hit or miss).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，我们看到机器学习比其他任何方法更好地预测蛋白质折叠，在围棋、Dota II、星际争霸 II 等游戏中击败了顶级人类玩家，并创造出相对连贯的文本和语音回应（尽管最后的成就有时可能会有偏差）。
- en: Still, these projects almost always require the application of substantial world-class
    engineering and research talent. That’s not entirely surprising, as coaxing a
    computer program, even one equipped with sophisticated state-of-the-art machine
    learning algorithms, to accomplish completely new objectives still requires human
    innovation. That may change in the future, when AI researchers create new machine
    learning agents that crack the human expert-level AI researcher threshold.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这些项目几乎总是需要大量世界级工程和研究人才的应用。这并不完全令人惊讶，因为即使是配备了先进最尖端机器学习算法的计算机程序，要实现全新的目标仍然需要人类的创新。这种情况可能会在未来发生变化，当人工智能研究人员创造出突破人类专家级别的人工智能研究者门槛的新机器学习代理时。
- en: For now, while groundbreaking AI science is still difficult to automate, there’s
    an ever-growing volume of ML applications where a [human engineer isn’t necessarily
    needed to optimize a model](https://www.exxactcorp.com/blog/Deep-Learning/how-ai-is-changing-the-construction-industry) for
    a given task. In fact, in some tasks, leaving the task of choosing a specific
    model and stirring the learning hyperparameters up to human judgment might actually
    slow things down or lead to sub-par results. A human might do a poor job of exploring
    hyperparameter space, might tend to favor their preferred types of models for
    bad reasons, or might stop and start training runs more often than is good for
    effectively training the model for the task (which can also be bad for their mental
    state).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，尽管突破性的人工智能科学仍然难以实现自动化，但有越来越多的机器学习应用场景中，*不一定需要人工工程师来优化模型*以完成特定任务。实际上，在某些任务中，将选择具体模型和调整学习超参数的任务交给人工判断，实际上可能会拖慢进度或导致结果不佳。人类可能在探索超参数空间时表现不佳，可能因为错误的原因偏向自己喜欢的模型类型，或者可能比实际训练模型所需的更频繁地开始和停止训练（这对他们的心理状态也不好）。
- en: Instead, a good ML practitioner should take advantage of all the tools at their
    disposal, which now includes open source off-the-shelf tools and best practices
    for applying ML to ML. In other words, **AutoML**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，一个好的机器学习从业者应该充分利用所有可用的工具，现在这些工具包括开源现成工具和应用机器学习的最佳实践。换句话说，**AutoML**。
- en: '![automl.png](../Images/928bab5e5c050b1c0d88ea047058bf05.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![automl.png](../Images/928bab5e5c050b1c0d88ea047058bf05.png)'
- en: What is AutoML?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是AutoML？
- en: AutoML is a broad category of techniques and tools for applying automated search
    to your automated search and learning to your learning. These range from applying
    Bayesian optimization to the hyperparameters for a statistical learning algorithm,
    to neural architecture search for deep learning models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML是一个广泛的技术和工具类别，用于将自动化搜索应用于您的自动化搜索，并将学习应用于您的学习。这些技术从对统计学习算法的超参数应用贝叶斯优化，到对深度学习模型进行神经网络结构搜索。
- en: The field is quite active and diverse, with a healthy ecosystem of contests,
    many of which are cataloged at[ automl.ai](https://automl.ai/competitions/). In
    fact, one of the most prominent AutoML packages, [Auto-SciKit-Learn](https://github.com/automl/auto-sklearn) (Auto-Sklearn),
    got started as the[ winner](/2016/08/winning-automl-challenge-auto-sklearn.html) of
    the 2014 to 2016 ChaLearn AutoML challenge.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域非常活跃且多样化，拥有健康的竞赛生态系统，其中许多竞赛都在[automl.ai](https://automl.ai/competitions/)上进行了记录。事实上，最著名的AutoML包之一，[Auto-SciKit-Learn](https://github.com/automl/auto-sklearn)（Auto-Sklearn），起初是2014年至2016年ChaLearn
    AutoML挑战赛的[获胜者](/2016/08/winning-automl-challenge-auto-sklearn.html)。
- en: Auto-Sklearn was developed by one of the most notable research groups pursuing
    Automated machine learning in the pre-eminent [AutoML supergroup](https://www.automl.org/automl/) from
    Germany. This[ collaboration](https://www.automl.org/) is made up of labs at the
    University of Freiburg and the University of Hannover. Other noteworthy contributors
    to the field include the scientists behind [Auto-WEKA](https://www.automl.org/automl/autoweka/),
    one of the first popular AutoML toolkits, and its successor Auto-WEKA 2.0\. These
    researchers are mostly scattered around North America but with a nucleus at the
    University of British Columbia in Canada. Whereas Auto-WEKA works with the open-source
    WEKA software and Java, Auto-Sklearn is a Python package and is built to closely
    follow the usage patterns of SciKit-Learn (hence the name "Auto-SciKit-Learn").
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-Sklearn由德国著名的[AutoML超级组织](https://www.automl.org/automl/)中追求自动化机器学习的最著名研究小组之一开发。这个[合作组织](https://www.automl.org/)由弗赖堡大学和汉诺威大学的实验室组成。其他在这一领域有显著贡献的研究者包括[Auto-WEKA](https://www.automl.org/automl/autoweka/)背后的科学家，Auto-WEKA是最早的流行AutoML工具包之一，以及其继任者Auto-WEKA
    2.0。这些研究人员主要分布在北美，但以加拿大的不列颠哥伦比亚大学为中心。而Auto-WEKA与开源WEKA软件和Java一起工作，Auto-Sklearn是一个Python包，并且旨在紧密遵循SciKit-Learn的使用模式（因此得名“Auto-SciKit-Learn”）。
- en: In addition to Auto-Sklearn, the Freiburg-Hannover AutoML group has also developed
    an [Auto-PyTorch](https://github.com/automl/Auto-PyTorch) library. We’ll use both
    of these as our entry point into AutoML in the following simple tutorial.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Auto-Sklearn，弗赖堡-汉诺威AutoML小组还开发了一个[Auto-PyTorch](https://github.com/automl/Auto-PyTorch)库。我们将在接下来的简单教程中使用这两个库作为我们进入AutoML的起点。
- en: AutoML Tutorial Demo
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoML教程演示
- en: First we’ll set up our needed packages and dependencies. We're using Python3’s
    virtualenv to manage a virtual environment for this project, but you’ll find similar
    instructions should work if you prefer Anaconda (especially if you use pip in
    Anaconda).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将设置所需的包和依赖项。我们使用 Python3 的 virtualenv 来管理项目的虚拟环境，但如果你更喜欢 Anaconda（特别是如果你在
    Anaconda 中使用 pip），你会发现类似的说明应该也能奏效。
- en: The following are commands to set up your environment from the command line
    on a unix-based system like Ubuntu, or from something like Anaconda prompt if
    you happen to be using Windows. The Auto-Sklearn documentation recommends installing
    from their requirements.txt dependency file first, but we haven’t found it necessary
    for the code used in this tutorial.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从基于 Unix 的系统（如 Ubuntu）或类似 Anaconda 提示符的 Windows 系统的命令行设置环境的命令。Auto-Sklearn
    文档建议首先从其 requirements.txt 依赖文件安装，但我们发现对于本教程中使用的代码没有必要这样做。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You’re likely to run into conflicts if you use the same environment for both
    AutoML libraries, so make a second environment for Auto-PyTorch. Note that this
    environment needs to use Python of version greater than or equal to 3.7.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在同一环境中同时使用 AutoML 库，可能会遇到冲突，因此请为 Auto-PyTorch 创建第二个环境。请注意，此环境需要使用版本大于或等于
    3.7 的 Python。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note the extra two install statements following pip install -e . In our hands,
    upgrading the NumPy version to 1.20.0 fixed a strange error, reproduced below.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在 `pip install -e .` 后还有额外的两个安装语句。在我们的操作中，将 NumPy 版本升级到 1.20.0 解决了一个奇怪的错误，下面重现了该错误。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you want to contribute to the project, or just want to view the latest work-in-progress
    code, check out the development branch.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想为项目做贡献，或只是想查看最新的进行中的代码，请查看开发分支。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The rest of the code for this tutorial is in Python, so spin up your Python
    prompt, Jupyter notebook, or text editor.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的其余代码是 Python 代码，因此请启动你的 Python 提示符、Jupyter notebook 或文本编辑器。
- en: This tutorial will consist of minimal demonstrations of classification using
    standard SciKit-Learn, Auto-Sklearn, and Auto-PyTorch classifiers. We'll use one
    of the built-in datasets from SciKit-Learn for each scenario, and each demonstration
    shares some code to import common dependencies and load and split the dataset.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将包含使用标准 SciKit-Learn、Auto-Sklearn 和 Auto-PyTorch 分类器进行分类的最少演示。我们将为每种情况使用
    SciKit-Learn 提供的内置数据集，每个演示都共享一些代码以导入公共依赖项、加载和拆分数据集。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code for setting up the dataset above will be used for every demo in this
    tutorial.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 上述设置数据集的代码将用于本教程中的每个演示。
- en: We're using the small “iris” dataset (150 samples, 4 features, and 3 label categories)
    in the interest of time, but you may want to try more complex datasets once you’ve
    been through the examples.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了小型的“iris”数据集（150 个样本，4 个特征和 3 个标签类别），以节省时间，但在完成示例后，你可能会想尝试更复杂的数据集。
- en: Other classification datasets from sklearn.datasets to try include the diabetes
    (**load_diabetes**) dataset and the digits dataset (**load_digits**). The diabetes
    dataset has 569 samples with 30 features each and 2 label categories, while the
    digits set has 1797 samples with 64 features each (corresponding to 8 by 8 images)
    with 10 label categories.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其他可以尝试的 sklearn.datasets 中的分类数据集包括糖尿病 (**load_diabetes**) 数据集和手写数字数据集 (**load_digits**)。糖尿病数据集有
    569 个样本，每个样本有 30 个特征和 2 个标签类别，而手写数字数据集有 1797 个样本，每个样本有 64 个特征（对应 8x8 的图像）和 10
    个标签类别。
- en: Before we start working with the AutoML classifier from sklearn, let’s train
    a few standard classifiers from vanilla sklearn with default settings. There are
    plenty to choose from, but we’ll stick to a k-nearest neighbors classifier, a
    support vector machine classifier, and a multilayer perceptron.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用 sklearn 的 AutoML 分类器之前，让我们先使用 vanilla sklearn 的默认设置训练几个标准分类器。可以选择很多，但我们将坚持使用
    k-最近邻分类器、支持向量机分类器和多层感知器。
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: SciKit-Learn uses a friendly fit/predict API, making training models a snap,
    and Auto-Sklearn and Auto-PyTorch retain the same API. This is a major factor
    in ease-of-use, as training a model in any of the three packages feels very much
    the same.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: SciKit-Learn 使用友好的 fit/predict API，使得训练模型变得非常简单，Auto-Sklearn 和 Auto-PyTorch
    也保留了相同的 API。这是易用性的一个重要因素，因为在这三个包中训练模型的体验非常相似。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Likewise, evaluating your models is simple. SciKit-Learn classification models
    have a predict method that takes input data and predicts the labels, which can
    then be passed to **sklearn.metrics.accuracy_score** to calculate the accuracy.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，评估你的模型也很简单。SciKit-Learn 分类模型有一个 predict 方法，该方法接收输入数据并预测标签，然后可以将结果传递给 **sklearn.metrics.accuracy_score**
    以计算准确率。
- en: The code below can be used to calculate predictions and prediction accuracy
    on the held-out test set using the k-nearest neighbors, support vector machine,
    and multilayer perceptron classifiers trained in the last snippet.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以用来计算预测和在保留的测试集上的预测准确率，使用的是在上一段代码中训练的k最近邻、支持向量机和多层感知器分类器。
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Figure](../Images/49b5f26a303ba61bd253033cfca7c7d9.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/49b5f26a303ba61bd253033cfca7c7d9.png)'
- en: Sklearn classifiers on iris dataset image
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Sklearn 分类器在鸢尾花数据集上的图像
- en: These models were pretty effective on the iris training dataset, but there was
    a significant gap between the training and test set.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型在鸢尾花训练数据集上相当有效，但训练集和测试集之间存在显著差距。
- en: Next let’s use the class
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用这个类
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: from
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 来源于
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The code for using this basic AutoML class looks exactly like training a single
    model in the example above, but in fact it performs a hyperparameter search over
    multiple types of machine learning models and retains the best as an ensemble.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个基本 AutoML 类的代码看起来和上面示例中训练单个模型的代码完全相同，但实际上它会对多种机器学习模型进行超参数搜索，并保留最佳模型作为集成。
- en: After bringing in common imports and setting up our training and test dataset
    split, we’ll need to import and instantiate the AutoML classifier.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在引入常用库并设置好训练和测试数据集分割后，我们需要导入并实例化 AutoML 分类器。
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Figure](../Images/f43d91f167d3b49fd419adad11f63c6f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/f43d91f167d3b49fd419adad11f63c6f.png)'
- en: Auto-Sklearn classifier ensemble on iris dataset
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-Sklearn 分类器集成在鸢尾花数据集上的图示
- en: Running the fit method with an **AutoSklearnClassifier **will take a significant
    amount of time if you don’t reset `time_left_for_this_task` as the default value
    is 3600 seconds (one hour). That’s substantial overkill for our simple iris dataset.
    Judging from the package documentation, the time limit is supposed to be settable
    as an input argument when initializing the classifier object, but in our experience
    (version 0.13.0) this wasn’t the case.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不重置`time_left_for_this_task`，使用**AutoSklearnClassifier**运行`fit`方法将会花费大量时间，因为默认值是3600秒（一小时）。对于我们简单的鸢尾花数据集来说，这是过度的。从包文档来看，时间限制应该可以作为初始化分类器对象时的输入参数设置，但在我们的经验（版本
    0.13.0）中并非如此。
- en: You can also try running the fit method with cross validation enabled, and if
    you choose to do so you’ll need to train again using the method
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以尝试启用交叉验证来运行 `fit` 方法，如果选择这样做，你需要再次使用该方法进行训练。
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: to train on the entire training dataset with the best models and hyperparameters.
    We found a slight improvement in the test set accuracy from 80% to 86.67% when
    using cross-validation and refit as compared to the default settings.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 用最佳模型和超参数训练整个训练数据集。我们发现，当使用交叉验证和重训练相比于默认设置时，测试集准确率从80%提高到了86.67%。
- en: Remember, when you run inference after fitting an **AutoSklearnClassifier **object
    with the predict method, you’re actually taking advantage of an ensemble of the
    best models found during the AutoML hyperparameter search.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，当你在使用`predict`方法对**AutoSklearnClassifier**对象进行推断时，你实际上是在利用在 AutoML 超参数搜索过程中找到的最佳模型的集成。
- en: '| **Method** | **Training Accuracy** | **Test Accuracy** | **Run Time** |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **训练准确率** | **测试准确率** | **运行时间** |'
- en: '| Default KNN | 0.9833 | 0.8000 | **0.6 ms total** |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 默认 KNN | 0.9833 | 0.8000 | **0.6 ms 总计** |'
- en: '| Default SVM | 0.9667 | 0.7000 | **0.6 ms total** |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 默认 SVM | 0.9667 | 0.7000 | **0.6 ms 总计** |'
- en: '| Default MLP | 0.9833 | 0.7667 | **0.6 ms total** |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 默认 MLP | 0.9833 | 0.7667 | **0.6 ms 总计** |'
- en: '| Auto-Sklearn | 1.000 | 0.8000 | 291.390 s |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Auto-Sklearn | 1.000 | 0.8000 | 291.390 s |'
- en: '| Auto-Sklearn(with cv + refit) | 1.000 | 0.8667 | 918.658 s |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| Auto-Sklearn (含 cv + refit) | 1.000 | 0.8667 | 918.658 s |'
- en: '| Auto-PyTorch | **0.9917** | **0.9667** | 302.236 s |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Auto-PyTorch | **0.9917** | **0.9667** | 302.236 s |'
- en: Finally, let’s try an AutoML package that caters to deep learning enthusiasts.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们尝试一个适合深度学习爱好者的 AutoML 包。
- en: 'Auto-PyTorch, like Auto-Sklearn, is built to be extremely simple to use. To
    run the next bit of code, remember to switch to your Auto-PyTorch environment
    to ensure the correct dependencies are available. After importing common imports
    and splitting up the data:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Auto-Sklearn 一样，Auto-PyTorch 也旨在极其简单易用。要运行下一段代码，请记得切换到你的 Auto-PyTorch 环境，以确保正确的依赖项可用。在导入常用库并拆分数据之后：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure](../Images/bb6f6cfaecf6d13a62ae45c38c3558ac.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bb6f6cfaecf6d13a62ae45c38c3558ac.png)'
- en: Auto-PyTorch classifier on iris dataset diagram
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-PyTorch 分类器在鸢尾花数据集上的图示
- en: As you’ll notice in the results table, Auto-PyTorch is efficient and effective
    at fitting the iris dataset, yielding training and test accuracy in the mid to
    high 90s. This is moderately better than the automatic SciKit-Learn classifier
    we trained earlier and much better than the standard sklearn classifiers with
    default parameters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在结果表中看到的，Auto-PyTorch在拟合鸢尾花数据集时非常高效和有效，训练和测试准确率达到了90多%。这比我们之前训练的自动SciKit-Learn分类器稍微好一点，比使用默认参数的标准sklearn分类器要好得多。
- en: Will AutoML Replace Data Scientists?
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AutoML会取代数据科学家吗？
- en: No, not necessarily. AutoML promises to improve the utility, performance, and
    efficiency of typical data science and machine learning workflows. The additional
    layer of abstraction and automated best-practices hyperparameter search certainly
    can make a big difference if used properly. For the packages we experimented with
    in today’s tutorial, we would describe their level of readiness as working research
    prototypes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不，未必。AutoML承诺改善典型数据科学和机器学习工作流的实用性、性能和效率。额外的抽象层和自动化的最佳实践超参数搜索，如果使用得当，确实可以带来显著的不同。对于我们在今天教程中实验的这些软件包，我们将其准备程度描述为正在进行的研究原型。
- en: There were a number of little fixes we had to go through to get everything to
    work properly, like upgrading NumPy to 1.20.0 to fix a cryptic error message,
    not being able to set the run time limits as n input argument (as suggested in
    the documentation for Auto-Sklearn), and not being able to use a single virtual
    environment for both package due to some cryptic conflicts. There’s also some
    humor to the fact that AutoML’s value comes from automating hyperparameter search,
    but the auto-classifiers themselves have quite a few parameters that can have
    a big impact on ultimate results.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要进行许多小修小补才能使一切正常工作，例如将NumPy升级到1.20.0以修复模糊的错误消息，无法将运行时间限制设置为输入参数（如Auto-Sklearn文档所建议），以及由于一些模糊的冲突而无法使用单个虚拟环境同时支持两个软件包。此外，AutoML的价值在于自动化超参数搜索，但自动分类器本身有许多参数，这些参数对最终结果有很大影响，这也让人忍俊不禁。
- en: All that being said, we think AutoML is a valuable addition to any ML or data
    science practitioner’s toolbox, whether they use Auto-Sklearn/Auto-PyTorch, Auto-WEKA,
    some other package, or even roll their own solutions. When the AutoML tool fits,
    it not only should give a boost to your project’s performance, but a decrease
    in the economic and energetic (including environmental) costs of a long meandering
    hyperparameter and architecture search.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们认为AutoML是任何机器学习或数据科学从业者工具箱中有价值的补充，无论他们使用Auto-Sklearn/Auto-PyTorch、Auto-WEKA、其他软件包，还是自行开发解决方案。当AutoML工具适合时，它不仅能提升项目的性能，还能减少经济和能源（包括环境）成本，从而避免长时间的超参数和架构搜索。
- en: Even if some of the tools still have plenty of rough edges, that’s only a good
    excuse and motivation to contribute to the projects yourself. Auto-PyTorch is
    available under an Apache 2.0 license, while Auto-Sklearn uses a BSD 3-Clause
    license.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 即使一些工具仍有许多粗糙的地方，这也只是一个很好的理由和动力，让你自己参与到这些项目中。Auto-PyTorch在Apache 2.0许可证下提供，而Auto-Sklearn使用BSD
    3-Clause许可证。
- en: '**Bio: [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact
    Corp blog and works with many of its talented authors who write about different
    aspects of Deep Learning.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** 负责管理Exxact Corp博客，并与许多才华横溢的作者合作，他们撰写有关深度学习不同方面的文章。'
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/automl-an-introduction-using-auto-sklearn-and-auto-pytorch).
    Reposted with permission.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.exxactcorp.com/blog/Deep-Learning/automl-an-introduction-using-auto-sklearn-and-auto-pytorch)。经授权转载。'
- en: '**Related:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Introduction to Automated Machine Learning](/2021/09/introduction-automated-machine-learning.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动化机器学习简介](/2021/09/introduction-automated-machine-learning.html)'
- en: '[How to Create an AutoML Pipeline Optimization Sandbox](/2021/09/automl-pipeline-optimization-sandbox.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何创建AutoML管道优化沙盒](/2021/09/automl-pipeline-optimization-sandbox.html)'
- en: '[Machine Learning Pipeline Optimization with TPOT](/2021/05/machine-learning-pipeline-optimization-tpot.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用TPOT进行机器学习管道优化](/2021/05/machine-learning-pipeline-optimization-tpot.html)'
- en: '* * *'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT 需求'
- en: '* * *'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[No Brainer AutoML with AutoXGB](https://www.kdnuggets.com/2022/02/no-brainer-automl-autoxgb.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 AutoXGB 的无脑 AutoML](https://www.kdnuggets.com/2022/02/no-brainer-automl-autoxgb.html)'
- en: '[Nota AI releases beta version of NetPresso Model Search, their…](https://www.kdnuggets.com/2022/04/nota-ai-releases-beta-version-netpresso-model-search-hardwareaware-automl-tool.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Nota AI 发布 NetPresso 模型搜索的测试版，他们的…](https://www.kdnuggets.com/2022/04/nota-ai-releases-beta-version-netpresso-model-search-hardwareaware-automl-tool.html)'
- en: '[The Top AutoML Frameworks You Should Consider in 2023](https://www.kdnuggets.com/2023/05/best-automl-frameworks-2023.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023 年你应该考虑的顶级 AutoML 框架](https://www.kdnuggets.com/2023/05/best-automl-frameworks-2023.html)'
- en: '[Introduction to Data Visualization Using Matplotlib](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Matplotlib 进行数据可视化简介](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
- en: '[Introduction to Numpy and Pandas](https://www.kdnuggets.com/introduction-to-numpy-and-pandas)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Numpy 和 Pandas 简介](https://www.kdnuggets.com/introduction-to-numpy-and-pandas)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库简介：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
