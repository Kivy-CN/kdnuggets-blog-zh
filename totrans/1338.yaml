- en: Feature Engineering for Numerical Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值数据的特征工程
- en: 原文：[https://www.kdnuggets.com/2020/09/feature-engineering-numerical-data.html](https://www.kdnuggets.com/2020/09/feature-engineering-numerical-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/09/feature-engineering-numerical-data.html](https://www.kdnuggets.com/2020/09/feature-engineering-numerical-data.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: Numeric data is almost a blessing. Why almost? Well, because it is already in
    a format that is ingestible by Machine Learning models. However, if we translate
    it into human-relatable terms, just because a PhD level textbook is written in
    English — I speak, read and write in English — does not mean that I am capable
    of understanding the textbook well enough to derive useful insights. What would
    make the textbook useful to me is if it epitomizes the most important information
    in a manner that considers the assumptions of my mental model, such as “Maths
    is a myth” (which, by the way, is no longer my view since I am really starting
    to enjoying it). In the same way, a good feature should represent salient aspects
    of the data, as well as taking the shape of the assumptions that are made by the
    Machine Learning model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数值数据几乎是一个福音。为什么说几乎呢？因为它已经是机器学习模型可以处理的格式。然而，如果我们将其翻译成易于理解的术语，仅仅因为一本博士级教材是用英语写的——我会说、读和写英语——并不意味着我能够充分理解这本教材以得出有用的见解。使教材对我有用的，应该是它以一种考虑到我心理模型假设的方式总结最重要的信息，比如“数学是一种神话”（顺便说一下，我现在已经不再这样看待了，因为我真的开始享受数学了）。同样，一个好的特征应该能够代表数据的显著方面，并且符合机器学习模型所做的假设。
- en: '![Data Engineering](../Images/efe8223e7c92f882a8d32fd9e5e37cb1.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![数据工程](../Images/efe8223e7c92f882a8d32fd9e5e37cb1.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 部门'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[Feature engineering](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html)
    is the process of extracting features from raw data and transforming them into
    formats that can be ingested by a machine learning model. Transformations are
    often required to ease the difficulty of modelling and boost the results of our
    models. Therefore, techniques to engineer numeric data types are fundamental tools
    for Data Scientist (Machine Learning Engineers alike) to add to their artillery.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[特征工程](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html)是从原始数据中提取特征并将其转换为机器学习模型可以处理的格式的过程。通常需要进行转换以降低建模难度并提升模型结果。因此，工程化数值数据的技术是数据科学家（机器学习工程师也一样）必须掌握的基本工具。'
- en: “data is like the *crude oil* of machine learning, which means it has to be
    refined into *features *— predictor variables — to be useful for training a model.” —
    [Will Koehrsen](https://medium.com/u/e2f299e30cb9?source=post_page-----e20167ec18----------------------)
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “数据就像是机器学习的*原油*，这意味着它必须被提炼成*特征*——预测变量——才能对训练模型有用。” — [Will Koehrsen](https://medium.com/u/e2f299e30cb9?source=post_page-----e20167ec18----------------------)
- en: As we strive for mastery, it is important to note that it is never enough to
    know why a mechanism works and what it can do. Mastery knows how something is
    done, has an intuition for the underlying principles, and has the neural connections
    that make drawing the correct tool a seamless procedure when faced with a challenge.
    That will not come from reading this article, but from the deliberate practice
    of which this article will open the door for you to do by providing the intuition
    behind the techniques so that you may understand how and when to apply them.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求精通的过程中，重要的是要注意，仅仅知道一个机制如何工作以及它能做什么是不够的。精通意味着知道某事如何完成，对基本原理有直觉，并具备在面对挑战时快速选择正确工具的神经连接。这不会仅仅通过阅读这篇文章来获得，而是通过有意识的练习来实现，本文将为你提供这些技术背后的直觉，以便你理解如何以及何时应用它们。
- en: The features in your data will directly influence the predictive models you
    use and the results you can achieve.” — [Jason Brownlee](https://medium.com/u/f374d0159316?source=post_page-----e20167ec18----------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “数据中的特征将直接影响你使用的预测模型以及你能取得的结果。” — [杰森·布朗利](https://medium.com/u/f374d0159316?source=post_page-----e20167ec18----------------------)
- en: '*Note: You can find the code used for this article on my [Github page](https://github.com/kurtispykes/demo/tree/master).*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：你可以在我的 [Github 页面](https://github.com/kurtispykes/demo/tree/master) 找到用于本文的代码。*'
- en: There may be occasions where data is collected on a feature that accumulates,
    thereby having an infinite upper boundary. Examples of this type of continuous
    data may be a tracking system that monitors the number of visits that all of my
    blog posts receive on a daily basis. This type of data easily attracts outliers
    since there could be some unpredictable event that affects the total traffic that
    my articles are accumulating. For instance, one day, people may decide they want
    to be able to do data analysis, so my article on [Effective data visualization](https://towardsdatascience.com/effective-data-visualization-ef30ae560961) may
    spike for that day. In other words, when data can be collected quickly and in
    large amounts, then it is likely that it would contain some extreme values that
    would need engineering.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有数据收集到一个特征上，这个特征是累积的，因此具有无限的上限。这种类型的连续数据的例子可能是一个跟踪系统，监控我所有博客帖子每日收到的访问次数。这种数据容易吸引异常值，因为可能会有一些不可预测的事件影响我文章的总流量。例如，有一天，人们可能决定他们想进行数据分析，因此我关于
    [有效数据可视化](https://towardsdatascience.com/effective-data-visualization-ef30ae560961)
    的文章当天可能会出现激增。换句话说，当数据可以快速且大量收集时，那么它很可能包含一些需要工程处理的极端值。
- en: 'Some methods to handle this instance are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这种情况的一些方法包括：
- en: Quantization
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 量化
- en: This method contains the scale of the data by grouping the values into bins.
    Therefore, quantization maps a continuous value into a discrete value, and, conceptually,
    this can be thought of as an ordered sequence of bins. To implement this, we must
    consider the width of bins that we create, of which the solutions fall into two
    categories, fixed-width bins or adaptive bins.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过将数据值分组到区间中来包含数据的尺度。因此，量化将连续值映射到离散值，从概念上讲，可以将其视为有序的区间序列。为了实现这一点，我们必须考虑创建区间的宽度，这些解决方案分为两类：固定宽度区间或自适应区间。
- en: '*Note: This is particularly useful for linear models. In tree-based models,
    this is not useful because tree-based models make their own splits.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*注意：这对线性模型特别有用。在基于树的模型中，这并不有用，因为基于树的模型会自行进行分割。*'
- en: In the fixed-width scenario, the value is automatically or custom-designed to
    segment data into discrete bins — they can also be linearly scaled or exponentially
    scaled. A popular example is separating ages of people into partitions by decade
    intervals such that bin 1 contains ages 0–9, bin 2 has 10–19 etc.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在固定宽度的情况下，值被自动或自定义设计为将数据分割成离散的区间——这些区间也可以是线性缩放或指数缩放的。一个常见的例子是将人的年龄按十年间隔分区，例如区间
    1 包含 0–9 岁，区间 2 包含 10–19 岁，等等。
- en: 'Note that if the values span across a large magnitude of numbers, then a better
    method may be to group the values into powers of a constant, such as to the power
    of 10: 0–9, 10–99, 100–999, 1000–9999\. Notice that the bin widths grow exponentially,
    hence in the case of 1000–9999, the bin width is O(10000), whereas 0–9 is O(10).
    Take the log of the count to map from the count to the bin of the data.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果值跨越了很大的数值范围，那么一个更好的方法可能是将值分组为常数的幂，例如10的幂：0–9、10–99、100–999、1000–9999。注意分箱宽度呈指数增长，因此在1000–9999的情况下，分箱宽度为O(10000)，而0–9为O(10)。取计数的对数以将计数映射到数据的分箱中。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Adaptive bins are a better fit when there are large gaps within the counts.
    When there are large margins in-between the values of the counts, then some of
    the fixed-width bins would be empty.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当计数之间存在较大间隙时，自适应分箱更合适。当计数值之间存在较大差距时，一些固定宽度的分箱可能会为空。
- en: To do adaptive binning, we can make use of the quantiles of the data — the values
    that divide the data into equal portions like the median.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行自适应分箱，我们可以利用数据的分位数——将数据划分为相等部分的值，例如中位数。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Power Transformations
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 幂变换
- en: 'We have already seen an example of this: the log transformation is part of
    a family of variance stabilizing transformations know as power transformations.
    Wikipedia describes power transformations as a *“technique used to stabilize variance,
    make the data more normal distribution-like, improve the validity of measures
    of association such as the Pearson correlation between variables and for other
    data stabilization procedures.”*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到一个例子：对数变换是方差稳定变换家族的一部分，这些变换被称为幂变换。维基百科将幂变换描述为*“用于稳定方差，使数据更接近正态分布，提高变量之间的皮尔逊相关系数等关联测量的有效性，并用于其他数据稳定化过程的技术。”*
- en: Why would we want to transform our data to fit the Normal Distribution? Great
    question! You may want to use a parametric model — a model that makes assumptions
    of the data — rather than a non-parametric model. When the data is normally distributed,
    parametric models are powerful. However, in some cases, the data we have may need
    a helping hand to bring out the beautiful bell-shaped curve of the normal distribution.
    For instance, the data may be skewed, so we apply a power transformation to assist
    in helping our feature look more Gaussian.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们要将数据转换为符合正态分布？这是个好问题！你可能希望使用参数模型——一种对数据做出假设的模型——而不是非参数模型。当数据呈正态分布时，参数模型非常强大。然而，在某些情况下，我们的数据可能需要一些帮助，以展现正态分布的美丽钟形曲线。例如，数据可能存在偏斜，因此我们应用幂变换以帮助特征看起来更像高斯分布。
- en: 'The code below leverages data science frameworks such as pandas, scipy, and
    numpy to demonstrate power transformations and visualize them using the Plotly.py
    framework for interactive plots. The dataset used is the [*House Prices: Advanced
    regression techniques*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) from
    Kaggle, which you can easily download ([Click here for access data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '下面的代码利用了数据科学框架，如 pandas、scipy 和 numpy，来演示幂变换，并使用 Plotly.py 框架进行交互式图表的可视化。使用的数据集是[*House
    Prices: Advanced regression techniques*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)来自
    Kaggle，你可以轻松下载（[点击此处访问数据](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)）。'
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0128765b007865d69c64281134a0a389.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0128765b007865d69c64281134a0a389.png)'
- en: '*Figure 1: Visualizing the original data and various power transforms power
    transformations.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1：可视化原始数据和各种幂变换。*'
- en: '*Note: Box-cox transformations only work when the data is non-negative*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：Box-Cox 变换仅在数据为非负数时有效*'
- en: “Which of these is best? You cannot know beforehand. You must try them and evaluate
    the results to achieve on your algorithm and performance measures.” — [Jason Brownlee](https://medium.com/u/f374d0159316?source=post_page-----e20167ec18----------------------)
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “这些中哪个最好？你无法事先知道。你必须尝试它们并评估结果，以实现你的算法和性能指标。” — [杰森·布朗利](https://medium.com/u/f374d0159316?source=post_page-----e20167ec18----------------------)
- en: Feature Scaling
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征缩放
- en: As the name implies, feature scaling (also referred to as feature normalization)
    is concerned with changing the scale of features. When the features of a dataset
    differ greatly in scale, then a model that is sensitive to the scale of the input
    features (i.e., linear regression, logistic regression, neural networks) would
    be affected. Ensuring features are within a similar scale is imperative. Whereas,
    models such as tree-based models (i.e., Decision Trees, Random Forest, Gradient
    boosting) do not care about scale.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，特征缩放（也称为特征归一化）涉及到改变特征的尺度。当数据集中各特征的尺度差异很大时，敏感于输入特征尺度的模型（如线性回归、逻辑回归、神经网络）将会受到影响。确保特征在相似的尺度内是至关重要的。而像树模型（如决策树、随机森林、梯度提升）这样的模型不关心尺度。
- en: Common ways to scale features include min-max scaling, standardization, and
    L² normalization. The following is a brief introduction and implementation in
    python.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放特征的常见方法包括最小-最大缩放、标准化和L²归一化。以下是简要介绍及其在Python中的实现。
- en: '**Min-Max Scaling** - The feature is scaled to a fixed range (which is usually
    between 0–1), meaning that we will have reduced standard deviations, therefore,
    suppressing the effect of outliers on the feature. Where x is the individual value
    of the instance (i.e., person 1, feature 2), max(x), min(x) is the maximum and
    minimum values of the feature — see Figure 2\. For more on this, see the [sklearn
    documentation.](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小-最大缩放** - 特征被缩放到一个固定范围（通常在0到1之间），这意味着我们将减少标准差，从而抑制异常值对特征的影响。其中x是实例的个体值（如，个人1，特征2），max(x)，min(x)是特征的最大值和最小值
    — 见图2。有关更多信息，请参见[sklearn文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)。'
- en: '![](../Images/157fdaa503f0d1e9470d4abdfecbed6d.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/157fdaa503f0d1e9470d4abdfecbed6d.png)'
- en: '*Figure 2: Formula for Min-max scaling.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2：最小-最大缩放的公式。*'
- en: '**Standardization **- The feature values will be rescaled so that they fit
    the properties of a normal distribution where the mean is 0, and the standard
    deviation is 1\. To do this, we subtract the mean of the feature — taken over
    all the instances — from the feature instance value, then divide by the variance
    — see Figure 3\. Refer to the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) for
    standardization.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准化** - 特征值将被重新缩放，以符合正态分布的性质，其中均值为0，标准差为1。为此，我们从特征实例值中减去特征的均值（在所有实例上计算），然后除以方差
    — 见图3。有关标准化，请参阅[sklearn文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)。'
- en: '![](../Images/eb10ee1da49f806d2f3c13d7c09bfc86.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb10ee1da49f806d2f3c13d7c09bfc86.png)'
- en: '*Figure 3: Formula for standardization.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3：标准化的公式。*'
- en: '**L² Normalization** - This technique divides the original feature value by
    the l² norm (also euclidean distance) — the second equation in Figure 4\. L² norm
    takes the sum of squares of the values in the feature set across all instances.
    Refer to the sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer) for
    L² Norm (note that there is also the option to do L¹ normalization by setting
    the norm parameter to "l1" ).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**L² 归一化** - 该技术将原始特征值除以l²范数（也称为欧几里得距离）— 图4中的第二个公式。L²范数取所有实例中特征集值的平方和。有关L²范数，请参阅sklearn的[文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer)（注意，还可以通过将norm参数设置为"l1"来进行L¹归一化）。'
- en: '![](../Images/7152bbf318af813b1bb26af628e98fb2.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7152bbf318af813b1bb26af628e98fb2.png)'
- en: '*Figure 4: Formula for L² Normalization.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4：L² 归一化的公式。*'
- en: '*Visualization of the effects of feature scaling will give a better image of
    what is going on. For this, I am using the wine dataset that can be imported from
    sklearn datasets.*'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*特征缩放效果的可视化将更好地展示发生了什么。为此，我使用了可以从sklearn数据集中导入的葡萄酒数据集。*'
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/89d92631e43a8a4e64462d398d69b551.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89d92631e43a8a4e64462d398d69b551.png)'
- en: '*Figure 5: The plots for the original feature and various scaling implementations.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5：原始特征和各种缩放实现的图示。*'
- en: Feature Interactions
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征交互
- en: We can create the logical AND function by using the product of pairwise interactions
    between features. In tree-based models, these interactions occur implicitly, but
    in models that assume independence of the features, we can explicitly declare
    interactions between features to improve the output of the model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用特征之间的配对交互的乘积来创建逻辑与函数。在基于树的模型中，这些交互是隐式发生的，但在假设特征独立的模型中，我们可以显式地声明特征之间的交互，以提高模型的输出。
- en: 'Think of a simple linear model that uses a linear combination of the input
    features to predict the output y:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 设想一个简单的线性模型，该模型使用输入特征的线性组合来预测输出 y：
- en: '![](../Images/bfcaba2049dd879a6c88b78eb18ed3ef.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bfcaba2049dd879a6c88b78eb18ed3ef.png)'
- en: '*Figure 6: Formula for a linear model.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6：线性模型的公式。*'
- en: We can extend the linear model to capture the interactions that occur between
    features.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以扩展线性模型以捕捉特征之间发生的交互。
- en: '![](../Images/72d7a01b39fe9a925af4ba2d08d110f7.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72d7a01b39fe9a925af4ba2d08d110f7.png)'
- en: '*Figure 7: Extending the linear model.*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7：扩展线性模型。*'
- en: '*Note: Linear functions are expensive to use, and the scoring and training
    of a linear model with a pairwise interaction would go from O(n) to O(n²). However,
    you could perform feature extraction to overcome this problem (feature extraction
    is beyond the scope of this article, but will be something I discuss in a future
    article).*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：线性函数的使用代价较高，线性模型的配对交互的评分和训练复杂度从 O(n) 增加到 O(n²)。然而，你可以进行特征提取来克服这个问题（特征提取超出了本文的范围，但我将在未来的文章中讨论）。*'
- en: 'Let’s code this in python, I am going to leverage the scitkit-learn *PolynomialFeatures *class,
    and you can read more about it in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Python中编写代码，我将利用scikit-learn的*PolynomialFeatures*类，你可以在[文档](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)中阅读更多内容：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*This article was heavily inspired by the book [Feature Engineering for Machine
    Learning: Principles and Techniques for Data Scientists](https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC),
    which I''d definitely recommend reading. Though it was published in 2016, it is
    still very informative and clearly explained, even for those without a mathematical
    background.*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章深受书籍[《机器学习特征工程：数据科学家的原则与技术》](https://www.amazon.co.uk/Feature-Engineering-Machine-Learning-Principles-ebook/dp/B07BNX4MWC)的启发，我强烈推荐阅读。尽管该书于2016年出版，但即便是没有数学背景的人也能从中获得非常有用的信息和清晰的解释。*'
- en: Conclusion
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: There we have it. In this article, we discussed techniques to deal with numerical
    features, such as quantization, power transformations, feature scaling, and interaction
    features (which can be applied to various data types). This is by no means the
    be-all and end-all of feature engineering, and there is always much more to learn
    on a daily basis. Feature engineering is an art and will take practice, so now
    that you have the intuition, you are ready to begin practicing.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。在这篇文章中，我们讨论了处理数值特征的技术，如量化、幂变换、特征缩放以及交互特征（这些技术可以应用于各种数据类型）。这绝不是特征工程的全部内容，我们每天都可以学到更多。特征工程是一门艺术，需要练习，所以现在你有了直觉，就可以开始实践了。
- en: '[Original](https://towardsdatascience.com/feature-engineering-for-numerical-data-e20167ec18).
    Reposted with permission.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/feature-engineering-for-numerical-data-e20167ec18)。转载已获许可。'
- en: '**Bio:** [Kurtis Pykes](https://www.linkedin.com/in/kurtispykes/) is a Machine
    Learning Engineer Intern at Codehouse. He is passionate about harnessing the power
    of machine learning and data science to help people become more productive and
    effective.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：** [Kurtis Pykes](https://www.linkedin.com/in/kurtispykes/) 是Codehouse的机器学习工程实习生。他热衷于利用机器学习和数据科学的力量来帮助人们变得更高效和有效。'
- en: '**Related:**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Feature Engineering in SQL and Python: A Hybrid Approach](https://www.kdnuggets.com/2020/07/feature-engineering-sql-python-hybrid-approach.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL和Python中的特征工程：混合方法](https://www.kdnuggets.com/2020/07/feature-engineering-sql-python-hybrid-approach.html)'
- en: '[Data Transformation: Standardization vs Normalization](https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据转换：标准化与归一化](https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html)'
- en: '[4 Tips for Advanced Feature Engineering and Preprocessing](https://www.kdnuggets.com/2019/08/4-tips-advanced-feature-engineering-preprocessing.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高级特征工程和预处理的4个技巧](https://www.kdnuggets.com/2019/08/4-tips-advanced-feature-engineering-preprocessing.html)'
- en: More On This Topic
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关主题
- en: '[Feature Store Summit 2022: A free conference on Feature Engineering](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022特征商店峰会：关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
- en: '[Building a Tractable, Feature Engineering Pipeline for Multivariate…](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为多变量时间序列构建可处理的特征工程管道](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
- en: '[Using RAPIDS cuDF to Leverage GPU in Feature Engineering](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用RAPIDS cuDF在特征工程中利用GPU](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
- en: '[A Practical Approach To Feature Engineering In Machine Learning](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中特征工程的实用方法](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
- en: '[Feature Engineering for Beginners](https://www.kdnuggets.com/feature-engineering-for-beginners)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者的特征工程](https://www.kdnuggets.com/feature-engineering-for-beginners)'
- en: '[Feature Selection: Where Science Meets Art](https://www.kdnuggets.com/2021/12/feature-selection-science-meets-art.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征选择：科学与艺术的交汇点](https://www.kdnuggets.com/2021/12/feature-selection-science-meets-art.html)'
