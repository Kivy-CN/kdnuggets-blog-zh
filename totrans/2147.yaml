- en: 7 Steps to Running a Small Language Model on a Local CPU
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在本地 CPU 上运行小型语言模型的 7 个步骤
- en: 原文：[https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu](https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu](https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu)
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/7ae0f82f255702a62401f793c6c1eed3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![在本地 CPU 上运行小型语言模型的 7 个步骤](../Images/7ae0f82f255702a62401f793c6c1eed3.png)'
- en: Image by [Freepik](https://www.freepik.com/free-vector/isometric-npl-illustration_22379496.htm#query=Small%20language%20models%20in%20Deep%20learning&position=1&from_view=search&track=ais)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由 [Freepik](https://www.freepik.com/free-vector/isometric-npl-illustration_22379496.htm#query=Small%20language%20models%20in%20Deep%20learning&position=1&from_view=search&track=ais)
    提供
- en: 'Step 1: Introduction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 步：介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织在 IT 方面'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Language models have revolutionized the field of natural language processing.
    While large models like GPT-3 have grabbed headlines, small language models are
    also advantageous and accessible for various applications. In this article, we
    will explore the importance and use cases of small language models with all the
    implementation steps in detail.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型已经彻底改变了自然语言处理领域。虽然像 GPT-3 这样的巨大模型常常成为新闻头条，但小型语言模型同样具有优势，适用于各种应用。在本文中，我们将详细探讨小型语言模型的重要性及其使用场景，并逐步讲解所有实施步骤。
- en: 'Small language models are compact versions of their larger counterparts. They
    offer several advantages. Some of the advantages are as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 小型语言模型是其大型对应模型的紧凑版本。它们提供了几个优点。以下是一些优点：
- en: '**Efficiency:** Compared to large models, small models require less computational
    power, making them suitable for environments with constrained resources.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**效率：** 与大型模型相比，小型模型需要的计算能力较少，使它们适合资源有限的环境。'
- en: '**Speed:** They can do the computation faster, such as generating the texts
    based on given input more quickly, making them ideal for real-time applications
    where you can have high daily traffic.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**速度：** 它们可以更快地进行计算，例如更快地生成基于给定输入的文本，使它们非常适合实时应用程序，这些应用程序可能会有高频次的日常流量。'
- en: '**Customization:** You can fine-tune small models based on your requirements
    for domain-specific tasks.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定制：** 您可以根据领域特定任务的需求对小型模型进行微调。'
- en: '**Privacy:** Smaller models can be used without external servers, which ensures
    data privacy and integrity.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**隐私：** 小型模型可以在没有外部服务器的情况下使用，从而确保数据隐私和完整性。'
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/bcc70933cc67ee67b3088c7e79050eb5.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![在本地 CPU 上运行小型语言模型的 7 个步骤](../Images/bcc70933cc67ee67b3088c7e79050eb5.png)'
- en: Image by Author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Several use cases for small language models include chatbots, content generation,
    sentiment analysis, question-answering, and many more.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 小型语言模型的多个使用场景包括聊天机器人、内容生成、情感分析、问答等。
- en: 'Step 2: Setting Up the Environment'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 步：设置环境
- en: Before we start deep diving into the working of small language models, you need
    to set up your environment, which involves installing the necessary libraries
    and dependencies. Selecting the right frameworks and libraries to build a language
    model on your local CPU becomes crucial. Popular choices include Python-based
    libraries like TensorFlow and PyTorch. These frameworks provide many pre-built
    tools and resources for machine learning and deep learning-based applications.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨小型语言模型的工作原理之前，您需要设置您的环境，包括安装必要的库和依赖项。选择合适的框架和库来在本地 CPU 上构建语言模型变得至关重要。常见的选择包括基于
    Python 的库，如 TensorFlow 和 PyTorch。这些框架提供了许多用于机器学习和深度学习应用的预构建工具和资源。
- en: '**Installing Required Libraries**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**安装所需库**'
- en: In this step, we will install the "llama-cpp-python" and ctransformers library
    to introduce you to small language models. You must open your terminal and run
    the following commands to install it. While running the following commands, ensure
    you have Python and pip installed on your system.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将安装 "llama-cpp-python" 和 ctransformers 库，以便向你介绍小型语言模型。你必须打开终端并运行以下命令来安装它。在运行以下命令时，请确保你的系统上已安装
    Python 和 pip。
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Output:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/01fe915b4721b7e1233794435f8ddae1.png)![7
    Steps to Running a Small Language Model on a Local CPU](../Images/375abba9015582bee318c04e89d01609.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/01fe915b4721b7e1233794435f8ddae1.png)![7
    Steps to Running a Small Language Model on a Local CPU](../Images/375abba9015582bee318c04e89d01609.png)'
- en: 'Step 3: Acquiring a Pre-Trained Small Language Model'
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三步：获取预训练的小型语言模型
- en: Now that our environment is ready, we can get a pre-trained small language model
    for local use. For a small language model, we can consider simpler architectures
    like LSTM or GRU, which are computationally less intensive than more complex models
    like transformers. You can also use pre-trained word embeddings to enhance your
    model's performance while reducing the training time. But for quick working, we
    will download a pre-trained model from the web.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的环境已经准备好，我们可以获取一个用于本地使用的预训练小型语言模型。对于小型语言模型，我们可以考虑像 LSTM 或 GRU 这样较简单的架构，这些架构在计算上比像
    transformers 这样更复杂的模型要轻量。你还可以使用预训练的词嵌入来提高模型的性能，同时减少训练时间。但为了快速工作，我们将从网络上下载一个预训练模型。
- en: Downloading a Pre-trained Model
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载预训练模型
- en: You can find pretrained small language models on platforms like Hugging Face
    ([https://huggingface.co/models](https://huggingface.co/models)). Here is a quick
    tour of the website, where you can easily observe the sequences of models provided,
    which you can download easily by logging into the application as these are open-source.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在像 Hugging Face ([https://huggingface.co/models](https://huggingface.co/models))
    这样的平台上找到预训练的小型语言模型。这里是一个快速浏览网站的指南，你可以轻松观察到提供的模型序列，并通过登录应用程序下载这些开源模型。
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/95f996d9660da8c90a148e026e863475.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/95f996d9660da8c90a148e026e863475.png)'
- en: You can easily download the model you need from this link and save it to your
    local directory for further use.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过这个链接轻松下载所需的模型，并将其保存到本地目录以备后续使用。
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 4: Loading the Language Model'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四步：加载语言模型
- en: In the above step, we have finalized the pre-trained model from Hugging Face.
    Now, we can use that model by loading it into our environment. We import the AutoModelForCausalLM
    class from the ctransformers library in the code below. This class can be used
    for loading and working with models for causal language modeling.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步中，我们已经确定了来自 Hugging Face 的预训练模型。现在，我们可以通过将其加载到我们的环境中来使用这个模型。我们在下面的代码中从 ctransformers
    库中导入了 AutoModelForCausalLM 类。这个类可以用于加载和使用因果语言建模的模型。
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/997afa55a93d0ef4844e0ad9369c9376.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/997afa55a93d0ef4844e0ad9369c9376.png)'
- en: Image from [Medium](https://medium.com/@cltkzl12)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Medium](https://medium.com/@cltkzl12)
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Output:**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/a48491310e495ff5994b42e6367084fe.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/a48491310e495ff5994b42e6367084fe.png)'
- en: 'Step 5: Model Configuration'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五步：模型配置
- en: Small language models can be fine-tuned based on your specific needs. If you
    have to use these models in real-life applications, the main thing to remember
    is efficiency and scalability. So, to make the small language models efficient
    compared to large language models, you can adjust the context size and batching(partition
    data into smaller batches for faster computation), which also results in overcoming
    the scalability problem.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 小型语言模型可以根据你的具体需求进行微调。如果你需要在实际应用中使用这些模型，主要需要记住的是效率和可扩展性。因此，为了使小型语言模型在性能上优于大型语言模型，你可以调整上下文大小和批处理（将数据划分为较小的批次以加快计算速度），这也有助于解决可扩展性问题。
- en: '**Modifying Context Size**'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**修改上下文大小**'
- en: The context size determines how much text the model considers. Based on your
    need, you can choose the value of context size. In this example, we will set the
    value of this hyperparameter as 128 tokens.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文大小决定了模型考虑多少文本。根据你的需求，你可以选择上下文大小的值。在这个示例中，我们将此超参数的值设置为 128 个标记。
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Batching for Efficiency
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提高效率的批处理
- en: By introducing the batching technique, it is possible to process multiple data
    segments simultaneously, which can handle the queries parallely and help scale
    the application for a large set of users. But while deciding the batch size, you
    must carefully check your system's capabilities. Otherwise, your system can cause
    issues due to heavy load.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入批处理技术，可以同时处理多个数据片段，这可以并行处理查询，并帮助扩展应用程序以支持大量用户。但在决定批量大小时，必须仔细检查系统的能力。否则，系统可能因负载过重而出现问题。
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Step 6: Generating Text'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6步：生成文本
- en: Up to this step, we are done with making the model, tuning that model, and saving
    it. Now, we can quickly test it based on our use and check whether it provides
    the same output we expect. So, let's give some input queries and generate the
    text based on our loaded and configured model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经完成了模型的创建、调优和保存。现在，我们可以根据我们的使用情况快速测试模型，并检查它是否提供了我们期望的输出。因此，让我们输入一些查询并基于我们加载和配置的模型生成文本。
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Output:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '![7 Steps to Running a Small Language Model on a Local CPU](../Images/d00ad1eeed215b4112fa4bb0afb81c3b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![在本地CPU上运行小型语言模型的7个步骤](../Images/d00ad1eeed215b4112fa4bb0afb81c3b.png)'
- en: 'Step 7: Optimizations and Troubleshooting'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步：优化和故障排除
- en: To get the appropriate results for most of the input queries out of your small
    language model, the following things can be considered.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得适当的结果以满足大多数输入查询，您可以考虑以下事项。
- en: '**Fine-Tuning:** If your application demands high performance, i.e., the output
    of the queries to be resolved in significantly less time, then you have to fine-tune
    your model on your specific dataset, the corpus on which you are training your
    model.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调：** 如果您的应用程序需要高性能，即查询的输出需要在显著更短的时间内解决，那么您需要在特定的数据集上对模型进行微调，即您正在训练模型的语料库。'
- en: '**Caching:** By using the caching technique, you can store commonly used data
    based on the user in RAM so that when the user demands that data again, it can
    easily be provided instead of fetching again from the disk, which requires relatively
    more time, due to which it can generate results to speed up future requests.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缓存：** 通过使用缓存技术，您可以将基于用户的常用数据存储在内存中，以便当用户再次请求这些数据时，可以轻松提供，而不是从磁盘中重新提取，这样会花费相对更多的时间，从而有助于加快未来请求的处理速度。'
- en: '**Common Issues:** If you encounter problems while creating, loading, and configuring
    the model, you can refer to the documentation and user community for troubleshooting
    tips.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**常见问题：** 如果在创建、加载和配置模型时遇到问题，您可以参考文档和用户社区的故障排除提示。'
- en: Wrapping it Up
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this article, we discussed how you can create and deploy a small language
    model on your local CPU by following the seven straightforward steps outlined
    in this article. This cost-effective approach opens the door to various language
    processing or computer vision applications and serves as a stepping stone for
    more advanced projects. But while working on projects, you have to remember the
    following things to overcome any issues:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了如何通过遵循文章中概述的七个简单步骤，在本地CPU上创建和部署小型语言模型。这种经济高效的方法为各种语言处理或计算机视觉应用打开了大门，并为更高级的项目提供了一个踏脚石。但在进行项目时，您需要记住以下事项以克服任何问题：
- en: Regularly save checkpoints during training to ensure you can continue training
    or recover your model in case of interruptions.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练过程中定期保存检查点，以确保您可以在中断时继续训练或恢复您的模型。
- en: Optimize your code and data pipelines for efficient memory usage, especially
    when working on a local CPU.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化您的代码和数据管道，以提高内存使用效率，特别是在使用本地CPU时。
- en: Consider using GPU acceleration or cloud-based resources if you need to scale
    up your model in the future.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您将来需要扩展模型，考虑使用GPU加速或基于云的资源。
- en: In conclusion, small language models offer a versatile and efficient solution
    for various language processing tasks. With the correct setup and optimization,
    you can leverage their power effectively.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，小型语言模型为各种语言处理任务提供了多功能且高效的解决方案。通过正确的设置和优化，您可以有效地利用它们的强大功能。
- en: '**[](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)**[Aryan Garg](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)****
    is a B.Tech. Electrical Engineering student, currently in the final year of his
    undergrad. His interest lies in the field of Web Development and Machine Learning.
    He have pursued this interest and am eager to work more in these directions.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)**[Aryan Garg](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)****
    是一名电气工程学的B.Tech.学生，目前正在本科的最后一年。他的兴趣领域包括网页开发和机器学习。他已经追求了这一兴趣，并渴望在这些方向上做更多的工作。'
- en: More On This Topic
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关话题
- en: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Llama, Llama, Llama: 3个简单步骤将本地RAG与你的内容结合](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
- en: '[7 Steps to Mastering Large Language Model Fine-tuning](https://www.kdnuggets.com/7-steps-to-mastering-large-language-model-fine-tuning)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握大型语言模型微调的7个步骤](https://www.kdnuggets.com/7-steps-to-mastering-large-language-model-fine-tuning)'
- en: '[Effective Small Language Models: Microsoft’s 1.3 Billion Parameter phi-1.5](https://www.kdnuggets.com/effective-small-language-models-microsoft-phi-15)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[有效的小型语言模型：微软的13亿参数phi-1.5](https://www.kdnuggets.com/effective-small-language-models-microsoft-phi-15)'
- en: '[GPT4All is the Local ChatGPT for your Documents and it is Free!](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT4All是本地ChatGPT，适用于你的文档，并且是免费的！](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)'
- en: '[LangChain + Streamlit + Llama: Bringing Conversational AI to Your…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LangChain + Streamlit + Llama: 将对话AI带入你的…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
- en: '[Octoparse 8.5: Empowering Local Scraping and More](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Octoparse 8.5: 增强本地抓取及更多功能](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)'
