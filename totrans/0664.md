# 使用卷积神经网络和 OpenCV 预测年龄和性别

> 原文：[https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)

[评论](#comments) ![图示](../Images/ab74974a523a926ad87742cfb6a68feb.png)

来源: [https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/](https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/)

> 自动年龄和性别分类在应用程序中变得越来越重要，特别是随着社交平台和社交媒体的兴起。然而，与最近报告的面部识别相关任务的巨大性能提升相比，现有方法在真实世界图像上的表现仍然显著不足。 — [**使用卷积神经网络进行年龄和性别分类**](https://talhassner.github.io/home/publication/2015_CVPR)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 介绍

年龄和性别这两个关键的面部特征，在社交互动中起着非常基础的作用，使得从单一面部图像中估计年龄和性别成为智能应用中的一个重要任务，如访问控制、人机交互、执法、市场情报和视觉监控等。

**现实世界中的应用案例：**

![图示](../Images/e68f5884c27d59a18cd0b74421bc2c24.png)

来源: [https://www.kiwi-digital.com/produkty/age-gender-detection](https://www.kiwi-digital.com/produkty/age-gender-detection)

最近我遇到了 [**Quividi**](https://www.quividi.com/)，这是一个人工智能软件应用，通过在线面部分析来检测经过用户的年龄和性别，并根据目标受众自动播放广告。

另一个例子是 [**AgeBot**](https://play.google.com/store/apps/details?id=com.testa.agebot&hl=en_IN)，这是一个安卓应用程序，可以通过面部识别从你的照片中确定你的年龄。它不仅可以猜测你的年龄和性别，还可以在一张照片中找到多个面孔，并为每个面孔估计年龄。

受到上述用例的启发，我们将在这篇详细的文章中构建一个简单的年龄和性别检测模型。让我们从我们的用例开始：

**使用案例**——我们将进行一些面部识别、面部检测工作，并且，我们将使用 CNN（卷积神经网络）从 YouTube 视频中进行年龄和性别预测，你不需要下载视频，只需视频 URL 即可。值得注意的是，在视频 URL 上使用 CNN 进行年龄和性别预测是非常有趣的。

**要求：**

pip install OpenCV-python

numpy

pip install pafy

pip install youtube_dl（了解更多关于 [youtube_dl](https://rg3.github.io/youtube-dl/)的信息）

**pafy**：Pafy 库用于检索 YouTube 内容和元数据（如标题、评分、观看次数、时长、评分、作者、缩略图、关键词等）。了解更多关于 [pafy](https://pypi.org/project/pafy/)的信息。让我们看一个示例：

```py
import pafy

url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'
vPafy = pafy.new(url)
print vPafy.title
print vPafy.rating
print vPafy.viewcount
print vPafy.author
print vPafy.length
print vPafy.description
```

输出：

```py
Testing file uploads with Postman (multipart/form-data)
4.87096786499
11478
Valentin Despa
1688
➡️➡️➡️ ???? Check my online course on Postman. Get it for only $10 (limited supply):
https://www.udemy.com/postman-the-complete-guide/?couponCode=YOUTUBE10

I will show you how to debug an upload script and demonstrate it with a tool that can make requests encoded as "multipart/form-data" so that you can send also a file.

After this, we will go even further and write tests and begin automating the process.

Here is the Git repository containing the files used for this tutorial:
https://github.com/vdespa/postman-testing-file-uploads
```

**步骤：**

1.  从 YouTube 获取视频 URL。

1.  使用 Haar cascades 进行面部检测

1.  使用 CNN 进行性别识别

1.  使用 CNN 进行年龄识别

**1. 从 YouTube 获取视频 URL：**

获取 YouTube 视频 URL 并尝试使用上面所述的 pafy 获取视频的属性。

**2. 使用 Haar cascades 进行面部检测：**

这是我们大多数人至少听说过的一部分。OpenCV/JavaCV 提供了直接导入 Haar-cascades 的方法，并利用它们进行面部检测。我不会深入讲解这一部分。你们可以参考我之前的 [文章](https://medium.com/analytics-vidhya/how-to-build-a-face-detection-model-in-python-8dc9cecadfe9)，了解更多关于使用 OpenCV 进行面部检测的信息。

**3. 使用 CNN 进行性别识别：**

使用 OpenCV 的 fisherfaces 实现进行性别识别非常流行，你们中的一些人可能已经尝试过或读到过。但在这个例子中，我将使用一种不同的方法来识别性别。这个方法由两位以色列研究人员 Gil Levi 和 Tal Hassner 于 2015 年提出。我在这个示例中使用了他们训练的 CNN 模型。我们将使用 OpenCV 的 dnn 包，即“深度神经网络”。

在 dnn 包中，OpenCV 提供了一个叫做 Net 的类，可以用来填充神经网络。此外，这些包支持从著名的深度学习框架如 caffe、tensorflow 和 torch 导入神经网络模型。我之前提到的研究人员已经将他们的 CNN 模型发布为 caffe 模型。因此，我们将使用 CaffeImporter 将该模型导入到我们的应用程序中。

**4. 使用 CNN 进行年龄识别**

这部分几乎与性别检测类似，只是对应的 prototxt 文件和 caffe 模型文件是 “deploy_agenet.prototxt” 和 “age_net.caffemodel”。此外，这个 CNN 的输出层（概率层）包括 8 个值，表示 8 个年龄类别（“0–2”，“4–6”，“8–13”，“15–20”，“25–32”，“38–43”，“48–53” 和 “60-”）

一个 caffe 模型有两个相关文件，

**1 .prototxt**——CNN 的定义在这里。这个文件定义了神经网络中的层，每一层的输入、输出和功能。

**2 .caffemodel**——这包含了训练神经网络（训练模型）的信息。

从[这里](https://talhassner.github.io/home/publication/2015_CVPR)下载.prtotxt和.caffemodel。

从[这里](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)下载用于面部检测的haar cascade。

所以让我们开始编写我们的模型代码。

**源代码：**

```py
import cv2
import numpy as np
import pafy

#url of the video to predict Age and gender
url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'
vPafy = pafy.new(url)
play = vPafy.getbest(preftype="mp4")

cap = cv2.VideoCapture(play.url)

cap.set(3, 480) #set width of the frame
cap.set(4, 640) #set height of the frame

MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)

age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']

gender_list = ['Male', 'Female']

def load_caffe_models():

 age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')

gender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')

return(age_net, gender_net)

def video_detector(age_net, gender_net):
  font = cv2.FONT_HERSHEY_SIMPLEX

while True:

  ret, image = cap.read()

  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')

  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  faces = face_cascade.detectMultiScale(gray, 1.1, 5)

if(len(faces)>0):
   print("Found {} faces".format(str(len(faces))))

for (x, y, w, h )in faces:
   cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)

#Get Face 
   face_img = image[y:y+h, h:h+w].copy()
   blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)

#Predict Gender
   gender_net.setInput(blob)
   gender_preds = gender_net.forward()
   gender = gender_list[gender_preds[0].argmax()]
   print("Gender : " + gender)

#Predict Age
   age_net.setInput(blob)
   age_preds = age_net.forward()
   age = age_list[age_preds[0].argmax()]
   print("Age Range: " + age)

overlay_text = "%s %s" % (gender, age)
   cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)

cv2.imshow('frame', image)  
#0xFF is a hexadecimal constant which is 11111111 in binary.
if cv2.waitKey(1) & 0xFF == ord('q'): 
   break

if __name__ == "__main__":
age_net, gender_net = load_caffe_models()

video_detector(age_net, gender_net)
```

现在让我们理解一下代码：

步骤1：导入所有必要的库。

```py
import cv2
import numpy as np
import pafy
```

步骤2：获取YouTube视频URL，并创建一个包含最佳视频分辨率的‘play’对象，格式为[webm](https://www.webmproject.org/about/)/mp4。

```py
url = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'
vPafy = pafy.new(url)
play = vPafy.getbest(preftype="mp4")
```

步骤3：通常，我们需要通过摄像头捕获实时流。OpenCV提供了一个非常简单的接口。我们可以从摄像头捕获视频，将其转换为灰度视频并显示。只是一个简单的开始任务。

要捕获视频，你需要创建一个视频捕获对象。其参数可以是设备索引或视频文件名。设备索引只是一个数字，用于指定哪个摄像头。通常一个摄像头会连接（就像我这种情况）。所以我简单地传递0（或-1）。你可以通过传递1来选择第二个摄像头，依此类推。之后，你可以逐帧捕获。

```py
cap = cv2.VideoCapture(0) #if you are using webcam
```

但在我的例子中，我正在读取一个在线视频URL，为此，我将‘play’对象传递给VideoCapture()。

```py
cap = cv2.VideoCapture(play.url)
```

步骤4：使用`set()`我将设置我们视频帧的高度和宽度。**cap.set(propId, value)**，其中3是宽度的propertyId，4是高度的propertyId。

```py
cap.set(3, 480) #set width of the frame
cap.set(4, 640) #set height of the frame
```

步骤5：创建3个单独的列表来存储Model_Mean_Values、年龄和性别。

```py
MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)
age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']
gender_list = ['Male', 'Female']
```

步骤6：我定义了一个函数来加载年龄和性别检测器的caffemodel和prototxt，这些基本上是经过预训练的CNN模型，它们将进行检测。

```py
def load_caffe_models():

 age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')

gender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')

return(age_net, gender_net)
```

步骤7：现在我们将执行人脸检测、年龄检测和性别检测，为此在主函数中创建一个函数**video_detector(age_net, gender_net)**，并将age_net和gender_net作为参数传递。

```py
if __name__ == "__main__":
age_net, gender_net = load_caffe_models()

video_detector(age_net, gender_net)
```

步骤8：读取在步骤3中使用VideoCapture()创建的cap对象。

**cap.read()**返回一个布尔值（True/False）。如果帧读取正确，它将是True。

#所以你可以通过检查这个返回值来检查视频的结束。

#有时，cap可能尚未初始化捕获。在这种情况下，此代码会显示错误。

#你可以通过方法cap.isOpened()检查它是否已初始化。如果是True，则正常。否则，使用cap.open()打开它。

```py
ret, image = cap.read()
```

步骤9：将图像转换为灰度图像，因为OpenCV人脸检测器期望的是[灰度图像](https://en.wikipedia.org/wiki/Grayscale)。

```py
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
```

步骤10：加载用于面部检测的预构建模型。

```py
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
```

步骤11：现在，我们如何使用CascadeClassifier从图像中检测人脸？

好吧，再次感谢OpenCV的CascadedClassifier，因为**detectMultiScale()**使其变得简单，它可以精确地检测到你需要的内容。

```py
detectMultiScale(image, scaleFactor, minNeighbors)
```

以下是应该传递给**detectMultiScale()**的参数。

这是一个通用函数来检测对象，在这种情况下，它将检测面孔，因为我们调用了面孔级联。如果它找到一个面孔，它将返回一个位置列表，以“Rect(x,y,w,h)”形式显示；如果没有，则返回“None”。

+   **Image:** 第一个输入是**灰度图像**。

+   **scaleFactor:** 这个函数补偿了当一个面孔由于离相机更近而显得比另一个面孔大时的错误感知。

+   **minNeighbors:** 检测算法使用移动窗口来检测对象，通过定义在当前对象附近找到多少个对象，然后才能声明面孔被找到。

```py
faces = face_cascade.detectMultiScale(gray, 1.1, 5)
```

步骤12：遍历人脸列表并在视频中的人脸上绘制矩形。基本上我们在找到面孔，处理面孔及其大小，并绘制矩形。

```py
for (x, y, w, h )in faces:
   cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)

# Get Face 
   face_img = image[y:y+h, h:h+w].copy()
```

步骤13: OpenCV提供了一个函数来促进深度学习分类的图像预处理：**blobFromImage()**。它执行：

+   均值减法

+   缩放

+   并可选择通道交换

> blobFromImage*创建4维的blob从图像中。可以选择从中心调整和裁剪图像，减去均值，通过scaleFactor缩放值，交换蓝色和红色通道*

```py
blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)
```

1.  **image:** 这是我们希望在通过深度神经网络进行分类之前预处理的输入图像。

1.  **scale factor:** 在进行均值减法后，我们可以选择按某个因子缩放我们的图像。该值默认为`1.0`（即，无缩放），但我们也可以提供其他值。还需要注意的是，缩放因子应为1/**σ**，因为我们实际上是在将输入通道（均值减法后）乘以缩放因子。

1.  **size:** 这里我们提供卷积神经网络所期望的空间大小。对于大多数当前最先进的神经网络，这通常是*224×224*，*227×227*，或*299×299*。

1.  **mean:** 这些是我们的均值减法值。它们可以是RGB均值的三元组，也可以是单一值，在这种情况下，提供的值从图像的每个通道中减去。如果你正在进行均值减法，确保你提供了`(R, G, B)`顺序的三元组，特别是在使用swapRB=True的默认行为时。

1.  **swapRB**: OpenCV假设图像为BGR通道顺序；然而，`mean`值假设我们使用RGB顺序。为了解决这个差异，我们可以通过将此值设置为`True`来交换图像中的R和B通道。默认情况下，OpenCV会为我们执行这个通道交换。

```py
blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)
```

步骤14：预测性别。

```py
#Predict Gender
gender_net.setInput(blob)
gender_preds = gender_net.forward()
gender = gender_list[gender_preds[0].argmax()]
```

步骤15：预测年龄。

```py
#Predict Age
age_net.setInput(blob)
age_preds = age_net.forward()
age = age_list[age_preds[0].argmax()]
```

步骤16：现在我们需要使用OpenCV的putText()模块在输出帧上添加文本。

cv2.putText()接受的参数有：

+   你想写的文本数据

+   设置你想放置它的位置坐标（即数据开始的左下角）。

+   字体类型（查看[**cv2.putText()**](https://docs.opencv.org/3.1.0/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576)文档以获取支持的字体）

+   字体缩放（指定字体的大小）

+   常见的属性如颜色、厚度、线型等。为了更好的效果，建议使用 lineType = cv2.LINE_AA。

```py
overlay_text = "%s %s" % (gender, age)
cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)
```

第 17 步：最后打印你的最终输出。

```py
cv2.imshow('frame', image)
```

最后我们有：

```py
if cv2.waitKey(1) & 0xFF == ord('q'):
   break
```

我们的程序会等待用户最多 1 毫秒按下一个键。然后，它会将读取到的键值与 `0xFF` 进行 AND 操作，这样可以去掉高于最低 8 位的部分，并将结果与字母 `q` 的 ASCII 码进行比较，这意味着用户决定通过按下键盘上的 `q` 来退出。

**输出**：视频网址-1：[https://www.youtube.com/watch?v=iH1ZJVqJO3Y](https://www.youtube.com/watch?v=iH1ZJVqJO3Y)

![图](../Images/a1c89e6e5e72c57f245f31473e3c5c13.png)

YouTube 视频 1

视频网址-2：[https://www.youtube.com/watch?v=qLNhVC296YI](https://www.youtube.com/watch?v=qLNhVC296YI)

![图](../Images/ebf2004b089b2167c848dfe2bf2a1645.png)

YouTube 视频 2

挺有趣的，不是吗？不过准确性不高。

**结论：**

正如我们在本文中所见，仅用几行代码我们就构建了一个年龄和性别检测模型，从这里开始，你还可以将情感检测和物体检测整合到同一模型中，创建一个功能齐全的应用程序。

希望你觉得这篇文章既有趣又有用，帮助你在识别一个人的年龄和性别方面。请在评论区告诉我你的疑问。

祝学习愉快 :)

在 [LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/) 上联系我。

**简历：[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)** 是一位数据科学爱好者，对大数据、Python 和机器学习感兴趣。

[原文](https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6)。经许可转载。

**相关：**

+   [初学者的 Python 线性回归指南（使用 Scikit-Learn）](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)

+   [如何在计算机视觉中做一切](/2019/02/everything-computer-vision.html)

+   [使用 RetinaNet 进行航拍图像中的行人检测](/2019/03/pedestrian-detection-aerial-images-retinanet.html)

### 更多相关内容

+   [停止学习数据科学以寻找目的，并寻找目的…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [一个 90 亿美元的 AI 失败，解析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [数据科学学习统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成功的数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [为什么 Python 是初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)
