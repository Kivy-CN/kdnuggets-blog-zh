- en: Introduction to the K-nearest Neighbour Algorithm Using Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/04/introduction-k-nearest-neighbour-algorithm-using-examples.html](https://www.kdnuggets.com/2020/04/introduction-k-nearest-neighbour-algorithm-using-examples.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Ranvir Singh](https://ranvir.xyz/), Open-source Enthusiast**'
  prefs: []
  type: TYPE_NORMAL
- en: '![KNN algorithm python](../Images/9904c91821787cffd5c0365e7a03a07e.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '`KNN` also known as K-nearest neighbour is a [supervised and pattern classification
    learning algorithm](https://ranvir.xyz/blog/how-to-evaluate-your-machine-learning-model-like-a-pro-metrics/#supervised-learning-and-classification-problems) which
    helps us find which class the new input(test value) belongs to when `k` nearest
    neighbours are chosen and distance is calculated between them.'
  prefs: []
  type: TYPE_NORMAL
- en: It attempts to estimate the conditional distribution of `Y` given `X`, and classify
    a given observation(test value) to the class with highest estimated probability.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It first identifies the `k` points in the training data that are closest to
    the `test value` and calculates the distance between all those categories. The
    test value will belong to the category whose distance is the least.![KNN algorithm
    distance](../Images/bab96a13fc6221a835a48218c68dacf3.png)
  prefs: []
  type: TYPE_NORMAL
- en: Probability of classification of test value in KNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It calculates the probability of test value to be in class `j` using this function
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/94c277b5f05dafe4a4924438759b7895.png)'
  prefs: []
  type: TYPE_IMG
- en: Ways to calculate the distance in KNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The distance can be calculated using different ways which include these methods,
  prefs: []
  type: TYPE_NORMAL
- en: Euclidean Method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manhattan Method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minkowski Method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: etc…
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on distance metrics which can be used, please read [this
    post on KNN](https://www.saedsayad.com/k_nearest_neighbors.htm).You can use any
    method from the list by passing `metric` parameter to the KNN object. Here is
    an answer on [Stack Overflow which will help](https://stackoverflow.com/questions/21052509/sklearn-knn-usage-with-a-user-defined-metric).
    You can even use some random distance metric.Also [read this answer as well](https://stackoverflow.com/questions/34408027/how-to-allow-sklearn-k-nearest-neighbors-to-take-custom-distance-metric) if
    you want to use your own method for distance calculation.
  prefs: []
  type: TYPE_NORMAL
- en: The process of KNN with Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s consider that we have a dataset containing heights and weights of dogs
    and horses marked properly. We will create a plot using weight and height of all
    the entries.Now whenever a new entry comes in, we will choose a value of `k`.For
    the sake of this example, let’s assume that we choose 4 as the value of `k`. We
    will find the distance of nearest four values and the one having the least distance
    will have more probability and is assumed as the winner.![KNN algorithm example](../Images/d5ed5cee01cf2aad966a1e23d1318165.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'KneighborsClassifier: KNN Python Example'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GitHub Repo: [KNN GitHub Repo](https://github.com/singh1114/ml/blob/master/datascience/Machine%20learning/knn/knn.ipynb)Data
    source used: [GitHub of Data Source](https://github.com/singh1114/ml/blob/master/datascience/Machine%20learning/knn/KNN_Project_Data)In
    K-nearest neighbours algorithm most of the time you don’t really know about the
    meaning of the input parameters or the classification classes available.In case
    of interviews this is done to hide the real customer data from the potential employee.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![KNN algorithm Head of dataframe](../Images/943f8d030780af21e4937ec3bf668a36.png)'
  prefs: []
  type: TYPE_IMG
- en: The head of the data clearly says that we have a few variables and a target
    class which contain different classes for given parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Why normalize/ standardize the variables for KNN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we can already see that the data in the data frame is not standardize, if
    we don’t normalize the data the outcome will be fairly different and we won’t
    be able to get the correct results.This happens because some feature have a good
    amount of deviation in them (values range from 1-1000). This will lead to a very
    bad plot producing a lot of defects in the model.For more info on normalization,
    check this answer on [stack exchange](https://stats.stackexchange.com/a/287439).Sklearn
    provides a very simple way to standardize your data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![KNN algorithm normalized data frame](../Images/8e89f347796245cfc68040ed56805082.png)'
  prefs: []
  type: TYPE_IMG
- en: Test/Train split using sklearn
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can simply [split the data using sklearn](https://ranvir.xyz/blog/how-to-evaluate-your-machine-learning-model-like-a-pro-metrics/#test-train-split-using-sklearn).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Using KNN and finding an optimal k value
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Choosing a good value of `k` can be a daunting task. We are going to automate
    this task using Python. We were able to find a good value of `k` which can minimize
    the error rate in the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Finding optimal k value](../Images/df8207c791896b95d54c50ca55e2e4b5.png)Seeing
    the graph, we can see that `k=30` gives a very optimal value of error rate.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the KNN model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Read the following post to learn more about evaluating a machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![confusion matrix and classification report](../Images/c6a18e3d0f4c354f208bcd472999ddcc.png)'
  prefs: []
  type: TYPE_IMG
- en: Benefits of using KNN algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: KNN algorithm is widely used for different kinds of learnings because of its
    uncomplicated and easy to apply nature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are only two metrics to provide in the algorithm. value of `k` and `distance
    metric`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Work with any number of classes not just binary classifiers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is fairly easy to add new data to algorithm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages of KNN algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cost of predicting the `k` nearest neighbours is very high.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doesn’t work as expected when working with big number of features/parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hard to work with categorical features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good read that [benchmarks various options present in sklearn for Knn](https://jakevdp.github.io/blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/)
  prefs: []
  type: TYPE_NORMAL
- en: Hope you liked the post. Feel free to share any issue or any question that you
    have in the comments below.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Ranvir Singh](https://ranvir.xyz/)** ([**@ranvirsingh1114**](https://twitter.com/ranvirsingh1114))
    is a web developer from India. He is a coding and Linux enthusiast who wants to
    learn as many things as possible. A FOSS lover and an open source contributor,
    he has also participated in Google Summer of Code 2017 with AboutCode organisation.
    He was also GSoC mentor in 2019 with the same organisation.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://ranvir.xyz/blog/k-nearest-neighbor-algorithm-using-sklearn-distance-metric/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[5 Great New Features in Latest Scikit-learn Release](/2019/12/5-features-scikit-learn-release-highlights.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Intermediate Machine Learning with Python — 2019 Edition](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Choosing the Right Clustering Algorithm for your Dataset](/2019/10/right-clustering-algorithm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Nearest Neighbors for Classification](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[K-nearest Neighbors in Scikit-learn](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SQL LIKE Operator Examples](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ensemble Learning with Examples](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Picking Examples to Understand Machine Learning Model](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
