- en: 'Neural Code Search: How Facebook Uses Neural Networks to Help Developers Search
    for Code Snippets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经代码搜索：Facebook 如何利用神经网络帮助开发者搜索代码片段
- en: 原文：[https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html](https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html](https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
- en: '![](../Images/080a800f2e408eaeed765a38fd92c8bb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/080a800f2e408eaeed765a38fd92c8bb.png)'
- en: Google and StackOverflow are every developer’s best friend these days. When
    working on a specific project, developers constantly resort to external sources
    of information to find solutions or code snippets to a given problem. However,
    the search resolution is mostly based on metadata and not in the information provided
    by the code itself. For instance, if a developer posts a code snippet to StackOverflow,
    it will typically include a description and tags that help to index it for future
    searches. This approach relies on the accuracy of that metadata in order to render
    accurate search results, but it also misses information that can be inferred directly
    from the code. To address this limitation, a team from Facebook AI Research (FAIR)
    has been working on an approach to use natural language processing (NLP) and information
    retrieval (IR) to infer search-relevant information directly from the source code
    text.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现如今，Google 和 StackOverflow 是每位开发者的好帮手。在进行特定项目时，开发者经常依赖外部信息来源来寻找解决方案或代码片段。然而，搜索结果通常基于元数据，而不是代码本身提供的信息。例如，如果开发者在
    StackOverflow 上发布一个代码片段，它通常会包括描述和标签，以帮助将其索引以便未来搜索。该方法依赖于元数据的准确性来提供准确的搜索结果，但也忽略了可以直接从代码中推断出的信息。为了应对这一限制，Facebook
    AI Research（FAIR）团队一直在研究一种方法，利用自然语言处理（NLP）和信息检索（IR）直接从源代码文本中推断搜索相关信息。
- en: 'The first materialization of the FAIR team efforts is a tool called Neural
    Code Search (NCS) which accepts a natural language query and returns results inferred
    directly from the code corpus. The techniques behind NCS were summarized in two
    research papers recently published:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: FAIR 团队努力的首次成果是一个名为 Neural Code Search (NCS) 的工具，它接受自然语言查询，并从代码语料库中直接推断结果。NCS
    背后的技术总结在最近发布的两篇研究论文中：
- en: '[**NCS**](https://dl.acm.org/citation.cfm?id=3211353&fbclid=IwAR3qdp2vDXwBuZb7uw2vR1op7SPngnRr0R6l3pxHrvqWH_0Unj0UXtTYpKA)**: **This
    paper describes a technique that uses an unsupervised model that combines NLP
    and IR techniques.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**NCS**](https://dl.acm.org/citation.cfm?id=3211353&fbclid=IwAR3qdp2vDXwBuZb7uw2vR1op7SPngnRr0R6l3pxHrvqWH_0Unj0UXtTYpKA)**:**
    这篇论文描述了一种利用无监督模型结合 NLP 和 IR 技术的技术。'
- en: '[**UNIF**](https://arxiv.org/pdf/1905.03813.pdf?fbclid=IwAR3_9ejBpho2yNLfMKVCp5rZ58gAD63T_peTg3RQh8tIRLZkYwH9SquLQI8)**: **This
    paper proposes an extension of NCS that uses a supervised neural network model
    to improve performance when good supervision data is available for training.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**UNIF**](https://arxiv.org/pdf/1905.03813.pdf?fbclid=IwAR3_9ejBpho2yNLfMKVCp5rZ58gAD63T_peTg3RQh8tIRLZkYwH9SquLQI8)**:**
    这篇论文提出了一种 NCS 的扩展，使用监督神经网络模型来提高在有良好监督数据可用于训练时的性能。'
- en: The principles behind both techniques, NCS and UNIF, is relatively similar.
    Both methods rely on vector representations of code snippets, which can be used
    to train a model such as semantically similar code snippets, and queries are close
    together in the vector space. This technique is able to answer natural language
    queries directly using the code snippets corpus without relying on external metadata.
    Although both techniques (NCS, UNIF) are relatively similar, UNIF extends NCS
    with a supervised model to create even more accurate answers to NLP queries.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: NCS 和 UNIF 两种技术背后的原理相对相似。这两种方法都依赖于代码片段的向量表示，这些向量可以用于训练模型，使语义相似的代码片段和查询在向量空间中彼此接近。这种技术能够直接使用代码片段语料库回答自然语言查询，而不依赖外部元数据。尽管
    NCS 和 UNIF 两种技术相对相似，但 UNIF 通过监督模型扩展了 NCS，从而能为 NLP 查询提供更准确的答案。
- en: NCS
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NCS
- en: The core principle behind is to use embeddings to generate a vector representation
    from a code corpus in a way in which similar code snippets are close to each other
    in the vector space. In the example below, there are two distinct method bodies
    that both pertain to closing or hiding the Android soft keyboard (the first question
    above). Since they share similar semantic meanings, even if they do not share
    the exact same lines of code, they are represented by points in the vector space
    that are close to each other. NCS uses method-level granularity to embed every
    code snippet in the vector space.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其核心原理是使用嵌入生成来自代码语料库的向量表示，使得相似的代码片段在向量空间中彼此靠近。以下示例中，有两个不同的方法体，它们都涉及关闭或隐藏 Android
    软件键盘（上面的第一个问题）。由于它们具有相似的语义含义，即使它们的代码行不完全相同，它们在向量空间中的表示点也彼此接近。NCS 使用方法级别的粒度在向量空间中嵌入每个代码片段。
- en: '![](../Images/697238c45896d8a3545d08028ae0dbf2.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/697238c45896d8a3545d08028ae0dbf2.png)'
- en: 'The process of creating the vector representation has three main steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 创建向量表示的过程包括三个主要步骤：
- en: 1) Extracting Words
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 提取词汇
- en: 2) Build Word Embeddings
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 构建词嵌入
- en: 3) Build Document Embeddings
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 构建文档嵌入
- en: 4)Natural Language Search Retrieval
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 4) 自然语言搜索检索
- en: '![](../Images/89c413a0e256dc571ed6f13139d6fe9b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89c413a0e256dc571ed6f13139d6fe9b.png)'
- en: Give a specific code snippet, NCS extracts different syntactic sections such
    as method names, method invocations, enums, string literals, and comments. Those
    artifacts are then tokenized using standards English conventions. For each document
    in the input corpus, NCS tokenizes the source code in a manner that can learn
    an embedding for each word. After this step, the list of words we extracted for
    each method body resembles a natural language document.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个特定的代码片段，NCS 提取不同的语法部分，如方法名、方法调用、枚举、字符串文字和注释。这些工件随后使用标准的英语约定进行分词。对于输入语料库中的每个文档，NCS
    以一种能够学习每个词的嵌入的方式对源代码进行分词。在这个步骤之后，我们为每个方法体提取的词列表类似于自然语言文档。
- en: After the word extraction, NCS proceeds to build the word embeddings using the [FastText
    framework](https://fasttext.cc/). During this process, FastText computes vector
    representations using a two-layer dense neural network that can be trained unsupervised
    on a large corpus. More specifically, NCS uses the skip-gram model, where the
    embedding for a target token is used to predict embeddings of context tokens within
    a fixed window size.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在词汇提取之后，NCS 继续使用 [FastText 框架](https://fasttext.cc/) 构建词嵌入。在此过程中，FastText 使用一个可以在大语料库上无监督训练的两层密集神经网络计算向量表示。更具体地说，NCS
    使用跳字模型，其中目标词的嵌入用于预测固定窗口大小内上下文词的嵌入。
- en: The final step of this phase is to express the general intent of a method body
    using the extracted word embeddings. NCS achieves that by calculating a weighted
    average of the word embedding vectors for the set of words in the method body.
    The result of this formula is known as a document embedding and is used to create
    an index of each method in the body for effective search retrieval.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的最终步骤是通过提取的词嵌入表示方法体的一般意图。NCS 通过计算方法体中一组词的词嵌入向量的加权平均值来实现这一点。这个公式的结果被称为文档嵌入，用于创建每个方法体的索引，以便进行有效的搜索检索。
- en: Using a vector representation as a starting point, NCS can now try to answer
    natural language queries related to code snippets. Given a natural language query,
    NCS follows a similar tokenization process using the FastText framework. Using
    the same FastText embedding matrix, NCS averages the vector representations of
    words to create a document embedding for the query sentence; out-of-vocab words
    are dropped. NCS then uses a standard similarity search algorithm, [FAISS](https://github.com/facebookresearch/faiss),
    to find the document vectors with closest cosine distance to the query.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用向量表示作为起点，NCS 现在可以尝试回答与代码片段相关的自然语言查询。给定自然语言查询，NCS 使用 FastText 框架遵循类似的分词过程。利用相同的
    FastText 嵌入矩阵，NCS 平均词的向量表示以创建查询句子的文档嵌入；不在词汇表中的词会被丢弃。NCS 然后使用标准相似度搜索算法，[FAISS](https://github.com/facebookresearch/faiss)
    来找到与查询最接近的文档向量。
- en: '![](../Images/4a1ffb905908fccc1f398da3fc34dc74.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a1ffb905908fccc1f398da3fc34dc74.png)'
- en: UNIF
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UNIF
- en: As an unsupervised technique, NCS has the advantage that it can build knowledge
    directly from the code corpus in a quick and easy manner. However, one of the
    main limitations of NCS is that the model implicitly assumes that the words in
    the query come from the same domain as the words extracted from source code, as
    the queries and the code snippets are both mapped to the same vector space. However,
    there are plenty of examples in which a code corpus does not convey any relevant
    semantic information. Take the example below of a code snippet that obtains available
    blocks in a memory space. Just by generating the word embeddings in an unsupervised
    way, NCS won’t be able to match relevant queries such as “Get free space on internal
    memory”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种无监督技术，NCS 的优势在于可以快速简便地直接从代码语料中构建知识。然而，NCS 的主要限制之一是模型隐含地假设查询中的词汇来自与源代码中提取的词汇相同的领域，因为查询和代码片段都映射到同一向量空间。然而，许多代码语料并不传达任何相关的语义信息。例如，下面的代码片段获取内存空间中的可用块。仅通过无监督方式生成词嵌入，NCS
    将无法匹配诸如“获取内部存储器上的空闲空间”这样的相关查询。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: UNIF is a supervised extension to NCS that attempts to bridge the gap between
    natural language words and source code words. Essentially, UNIF uses supervised
    learning to modify the initial token embedding matrix T and produce two embedding
    matrices, Tc and Tq, for code and query tokens, respectively. We also replace
    the TF-IDF weighing of code token embeddings with a learned attention-based weighing
    scheme. This twist essentially accounts for some of the semantic mismatches in
    code corpus.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: UNIF 是对 NCS 的一种监督扩展，旨在弥合自然语言词汇与源代码词汇之间的差距。UNIF 实质上使用监督学习来修改初始的词嵌入矩阵 T，并分别为代码和查询词生成两个嵌入矩阵
    Tc 和 Tq。我们还用基于学习的注意力加权方案替代了代码词嵌入的 TF-IDF 加权。这种变化实际上考虑了一些代码语料中的语义不匹配。
- en: '![](../Images/700f1ec76d6696dfe81212b8b3b9ece1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/700f1ec76d6696dfe81212b8b3b9ece1.png)'
- en: NCS and UNIF in Action
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NCS 和 UNIF 实践
- en: The FAIR team evaluates both NCS and UNIF against state-of-the-art information
    retrieval models. Using a starting dataset of StackOverflow questions, NCS was
    able to outperform the popular BM25 model across a diverse series of tasks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: FAIR 团队将 NCS 和 UNIF 与最先进的信息检索模型进行了比较。使用 StackOverflow 问题的起始数据集，NCS 在各种任务中超越了流行的
    BM25 模型。
- en: '![](../Images/a8d58432722c936eff7184903b511cae.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8d58432722c936eff7184903b511cae.png)'
- en: Similarly, adding the UNIF extension showed incremental improvements in the
    NCS performance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，添加 UNIF 扩展显示了 NCS 性能的逐步提升。
- en: '![](../Images/5189a0560330e460c9f8d40e98251857.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5189a0560330e460c9f8d40e98251857.png)'
- en: Both NCS and UNIF present a clever and yet simple-to-implement approach for
    information retrieval. Starting with code search is a trivial way to deliver immediate
    value, but the ideas behind NCS and UNIF are applicable to many neural search
    and information retrieval scenarios.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: NCS 和 UNIF 都提供了一种巧妙而简单的实现方法用于信息检索。以代码搜索开始是提供即时价值的一种简单方式，但 NCS 和 UNIF 背后的理念适用于许多神经搜索和信息检索场景。
- en: '[Original](https://towardsdatascience.com/neural-code-search-how-facebook-uses-neural-networks-to-help-developers-search-for-code-snippets-9db9e0090780).
    Reposted with permission.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/neural-code-search-how-facebook-uses-neural-networks-to-help-developers-search-for-code-snippets-9db9e0090780)。经许可转载。'
- en: '**Related:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Your Guide to Natural Language Processing (NLP)](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理 (NLP) 指南](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
- en: '[Extracting Knowledge from Knowledge Graphs Using Facebook’s Pytorch-BigGraph](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从知识图谱中提取知识，使用 Facebook 的 Pytorch-BigGraph](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
- en: '[Natural Language Processing Key Terms, Explained](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理关键术语解析](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Low Code: Are Developers Still Needed?](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[低代码：开发者还需要吗？](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)'
- en: '[How LinkedIn Uses Machine Learning To Rank Your Feed](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LinkedIn 如何利用机器学习来排名你的信息流](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
- en: '[Top Programming Languages and Their Uses](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[热门编程语言及其用途](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
- en: '[KDnuggets™ News 22:n04, Jan 26: The High Paying Side Hustles…](https://www.kdnuggets.com/2022/n04.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n04，1月26日：高薪副业…](https://www.kdnuggets.com/2022/n04.html)'
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月16日：LinkedIn 如何利用机器学习 •…](https://www.kdnuggets.com/2022/n45.html)'
- en: '[3 Interesting Uses of Python''s Context Managers](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 上下文管理器的 3 个有趣用途](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
