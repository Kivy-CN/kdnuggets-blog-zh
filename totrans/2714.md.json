["```py\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 512)               2560      \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_9 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_10 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_11 (Dense)             (None, 3)                 99        \n=================================================================\nTotal params: 177,219\nTrainable params: 177,219\nNon-trainable params: 0\n_________________________________________________________________\n\n```", "```py\nloss1, acc1, mse1 = model1.evaluate(X_test, y_test)\nprint(f\"Loss is {loss1},\\nAccuracy is {acc1*100},\\nMSE is {mse1}\")\n\n```", "```py\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.plot(hist.history['loss'], label = 'loss')\nplt.plot(hist.history['val_loss'], label='val loss')\nplt.title(\"Loss vs Val_Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n```", "```py\nplt.plot(hist.history['acc'], label = 'acc')\nplt.plot(hist.history['val_acc'], label='val acc')\nplt.title(\"acc vs Val_acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"acc\")\nplt.legend()\nplt.show()\n\n```", "```py\nloss2, acc2, mse2 = model2.evaluate(X_test, y_test)\nprint(f\"Loss is {loss2},\\nAccuracy is {acc2 * 100},\\nMSE is {mse2}\")\n\n```", "```py\nplt.plot(hist2.history[‘loss’], label = ‘loss’)\nplt.plot(hist2.history[‘val_loss’], label=’val loss’)\nplt.title(“Loss vs Val_Loss”)\nplt.xlabel(“Epochs”)\nplt.ylabel(“Loss”)\nplt.legend()\nplt.show()\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist2.history['acc'], label = 'acc')\nplt.plot(hist2.history['val_acc'], label='val acc')\nplt.title(\"acc vs Val_acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"acc\")\nplt.legend()\nplt.show()\n\n```", "```py\nmodel3 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape, kernel_regularizer='l1'),\n    Dense(512//2, activation='tanh', kernel_regularizer='l1'),\n    Dense(512//4, activation='tanh', kernel_regularizer='l1'),\n    Dense(512//8, activation='tanh', kernel_regularizer='l1'),\n    Dense(32, activation='relu', kernel_regularizer='l1'),\n    Dense(3, activation='softmax')\n])\nmodel3.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist3 = model3.fit(X_train, y_train, epochs=350, batch_size=128, validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss3, acc3, mse3 = model3.evaluate(X_test, y_test)\nprint(f\"Loss is {loss3},\\nAccuracy is {acc3 * 100},\\nMSE is {mse3}\")\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist3.history['loss'], label = 'loss')\nplt.plot(hist3.history['val_loss'], label='val loss')\nplt.title(\"Loss vs Val_Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist3.history['acc'], label = 'ACC')\nplt.plot(hist3.history['val_acc'], label='val acc')\nplt.title(\"acc vs Val_acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"acc\")\nplt.legend()\nplt.show()\n\n```", "```py\nmodel5 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape, kernel_regularizer='l2'),\n    Dense(512//2, activation='tanh'),\n    Dense(512//4, activation='tanh'),\n    Dense(512//8, activation='tanh'),\n    Dense(32, activation='relu'),\n    Dense(3, activation='softmax')\n])\nmodel5.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist5 = model5.fit(X_train, y_train, epochs=350, batch_size=128, validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss5, acc5, mse5 = model5.evaluate(X_test, y_test)\nprint(f\"Loss is {loss5},\\nAccuracy is {acc5 * 100},\\nMSE is {mse5}\")\n\n```", "```py\nmodel6 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape, kernel_regularizer='l2'),\n    Dense(512//2, activation='tanh', kernel_regularizer='l2'),\n    Dense(512//4, activation='tanh', kernel_regularizer='l2'),\n    Dense(512//8, activation='tanh', kernel_regularizer='l2'),\n    Dense(32, activation='relu', kernel_regularizer='l2'),\n    Dense(3, activation='softmax')\n])\nmodel6.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist6 = model6.fit(X_train, y_train, epochs=350, batch_size=128, validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss6, acc6, mse6 = model6.evaluate(X_test, y_test)\nprint(f\"Loss is {loss6},\\nAccuracy is {acc6 * 100},\\nMSE is {mse6}\")\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist6.history['loss'], label = 'loss')\nplt.plot(hist6.history['val_loss'], label='val loss')\nplt.title(\"Loss vs Val_Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n```", "```py\nimport tensorflow as tf\nmodel7 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape),\n    tf.keras.layers.Dropout(0.5), #dropout with 50% rate\n    Dense(512//2, activation='tanh'),\n\n    Dense(512//4, activation='tanh'),\n    Dense(512//8, activation='tanh'),\n    Dense(32, activation='relu'),\n    Dense(3, activation='softmax')\n])\nmodel7.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist7 = model7.fit(X_train, y_train, epochs=350, batch_size=128, validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss7, acc7, mse7 = model7.evaluate(X_test, y_test)\nprint(f\"Loss is {loss7},\\nAccuracy is {acc7 * 100},\\nMSE is {mse7}\")\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist7.history['loss'], label = 'loss')\nplt.plot(hist7.history['val_loss'], label='val loss')\nplt.title(\"Loss vs Val_Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n```", "```py\nmodel8 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape),\n    tf.keras.layers.Dropout(0.5),\n    Dense(512//2, activation='tanh'),\n    tf.keras.layers.Dropout(0.5),\n    Dense(512//4, activation='tanh'),\n    tf.keras.layers.Dropout(0.5),\n    Dense(512//8, activation='tanh'),\n    tf.keras.layers.Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dense(3, activation='softmax')\n])\nmodel8.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist8 = model8.fit(X_train, y_train, epochs=350, batch_size=128, validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss8, acc8, mse8 = model8.evaluate(X_test, y_test)\nprint(f\"Loss is {loss8},\\nAccuracy is {acc8 * 100},\\nMSE is {mse8}\")\n\n```", "```py\nplt.figure(figsize=(15,8))\nplt.plot(hist8.history['loss'], label = 'loss')\nplt.plot(hist8.history['val_loss'], label='val loss')\nplt.title(\"Loss vs Val_Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\n```", "```py\nmodel9 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape),\n    Dense(512//2, activation='tanh'),\n    tf.keras.layers.BatchNormalization(),\n    Dense(512//4, activation='tanh'),\n    Dense(512//8, activation='tanh'),\n    Dense(32, activation='relu'),\n    Dense(3, activation='softmax')\n])\nmodel9.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist9 = model9.fit(X_train, y_train, epochs=350,  validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss9, acc9, mse9 = model9.evaluate(X_test, y_test)\nprint(f\"Loss is {loss9},\\nAccuracy is {acc9 * 100},\\nMSE is {mse9}\")\n\n```", "```py\nmodel11 = Sequential([\n    Dense(512, activation='tanh', input_shape = X_train[0].shape),\n    tf.keras.layers.BatchNormalization(),\n    Dense(512//2, activation='tanh'),\n    tf.keras.layers.BatchNormalization(),\n    Dense(512//4, activation='tanh'),\n    tf.keras.layers.BatchNormalization(),\n    Dense(512//8, activation='tanh'),\n    tf.keras.layers.BatchNormalization(),\n    Dense(32, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    Dense(3, activation='softmax')\n])\nmodel11.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['acc', 'mse'])\nhist11 = model11.fit(X_train, y_train, epochs=350,  validation_data=(X_test,y_test), verbose=2)\n\n```", "```py\nloss11, acc11, mse11 = model11.evaluate(X_test, y_test)\nprint(f\"Loss is {loss11},\\nAccuracy is {acc11 * 100},\\nMSEis {mse11}\")\n\n```"]