- en: 'The Augmented Scientist Part 1: Practical Application Machine Learning in Classification
    of SEM Images'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强科学家系列 第1部分：机器学习在SEM图像分类中的实际应用
- en: 原文：[https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html](https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html](https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47), [Skellig.ai](https://www.skellig.ai/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47), [Skellig.ai](https://www.skellig.ai/)**'
- en: '![Augmented Science Graphic](../Images/475e10bf83a0678190e37f8e537318e8.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![增强科学图示](../Images/475e10bf83a0678190e37f8e537318e8.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织中的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Welcome to the first blog in our Augmented Scientist series, where we will be
    looking at how machine learning can be used to improve the way that Scientists
    work on a day-to-day basis. As this series grows we’ll be looking at more applications
    for ML to work as a research aid for scientists, removing a lot of repetitive
    analysis work and allowing them to explore their fields deeper. Both my wife and
    I come from science backgrounds, her chemistry and me physics. What struck me
    when I started working on machine learning is the enormous opportunity to speed
    up much of the tedious analysis that consumes so much time in research labs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到我们增强科学家系列的第一篇博客，在这里我们将探讨机器学习如何改善科学家日常工作的方式。随着这一系列的展开，我们将深入挖掘更多机器学习的应用，以作为科学研究的辅助工具，去除大量重复的分析工作，使科学家能更深入地探索他们的领域。我和我的妻子都来自科学背景，她是化学专业的，我是物理专业的。当我开始从事机器学习时，我被它加速处理繁琐分析工作的巨大潜力所打动，这些工作在研究实验室中消耗了大量时间。
- en: As our first exploration into the concept of the Augmented Scientist, our goal
    here is to see if we can build a classifier that can identify patterns in [Scanning
    Electron Microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope) (SEM)
    images, and compare the performance of our classifier to the current state-of-the-art.
    Later posts will investigate more focused applications of SEM image classification.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们对增强科学家概念的第一次探索，我们的目标是看看我们能否建立一个分类器，识别[扫描电子显微镜](https://en.wikipedia.org/wiki/Scanning_electron_microscope)（SEM）图像中的模式，并将我们分类器的性能与当前的最先进技术进行比较。后续文章将探讨SEM图像分类的更集中应用。
- en: What is SEM?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是SEM？
- en: The first area that we’re going to look at is SEM image analysis, a technique
    my wife, as an electrochemist, has worked with extensively throughout her career.
    SEM is used extensively in chemistry and biology to create images of surfaces
    at a nanometer scale. It works by scanning a surface with a focused electron beam.
    The reflection of electrons off the surface creates an image of the topography
    and composition of the surface.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先关注SEM图像分析，这是我妻子作为电化学家在职业生涯中广泛使用的技术。SEM广泛用于化学和生物学中，以纳米尺度创建表面图像。它通过用聚焦的电子束扫描表面来工作。电子从表面反射，形成表面的形貌和成分图像。
- en: '![Figure](../Images/e60e3debf9b711715a308547a15e58aa.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/e60e3debf9b711715a308547a15e58aa.png)'
- en: source: [https://en.wikipedia.org/wiki/Scanning_electron_microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://en.wikipedia.org/wiki/Scanning_electron_microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope)
- en: This type of detailed imaging has a vast array of applications, each one having
    different analysis requirements, such as optimizing the surfaces of electrodes
    in biosensors, or for producing electricity in fuel cells. The structure of the
    surface can tell us a lot about the properties and characteristics of an object.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种详细成像有广泛的应用，每种应用有不同的分析需求，比如优化生物传感器中的电极表面，或在燃料电池中产生电力。表面的结构可以告诉我们很多关于物体的属性和特征。
- en: 'Previous Work:'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 之前的工作：
- en: In this blog post we’re going to see if we can make any advancements on the
    work of [Modarres et al 2017](https://www.nature.com/articles/s41598-017-13565-z#Sec2),
    who previously looked at classifying the patterns in 18,577 SEM images (you can
    find the dataset [here](https://b2share.eudat.eu/records/19cc2afd23e34b92b36a1dfd0113a89f)).
    These examples show you the type of patterns categorised in Modarres et al 2017’s
    dataset, who’s labels are Tips, Particles, Patterned Surfaces, MEMS devices and
    electrodes, Nanowires, Porous Sponge, Biological, Powder, Films Coated Surfaces
    and Fibres.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将查看是否能在[Modarres et al 2017](https://www.nature.com/articles/s41598-017-13565-z#Sec2)的工作基础上取得任何进展，他们之前研究了分类18,577张SEM图像的模式（你可以在[这里](https://b2share.eudat.eu/records/19cc2afd23e34b92b36a1dfd0113a89f)找到数据集）。这些示例展示了Modarres
    et al 2017数据集中分类的模式类型，包括Tips、Particles、Patterned Surfaces、MEMS devices 和electrodes、Nanowires、Porous
    Sponge、Biological、Powder、Films Coated Surfaces 和Fibres。
- en: '![Figure](../Images/285f799e82ab7ee3482f1e3cfab59984.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/285f799e82ab7ee3482f1e3cfab59984.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
- en: The blow tables shows the distribution of images in the categories.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了各类别中图像的分布。
- en: '![Figure](../Images/fba5b29ddf02cdb4cd1a3450f3698937.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/fba5b29ddf02cdb4cd1a3450f3698937.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
- en: 'Using the pretrained Inception-v3 model, implemented in Tensorflow, Modarres
    et al achieved an accuracy of ~90%, with a precision of ~80% and a recall@1 of
    ~90%. Modarres et al also reported that an imbalance in the dataset had no effect
    on the classifier’s performance in accurately predicting the under represented
    categories. Their confusion matrix, shown below, shows that the least populated
    categories, Porous Sponge, Films Coated Surface and Fibers, all performed quite
    well. Modarres et al credited this to the distinct patterns of these categories.
    (Note: the values presented in Modarres et al’s confusion matrix are percentages
    of the validation sample for each actual/true label)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练的Inception-v3模型，该模型在Tensorflow中实现，Modarres等人达到了约90%的准确率，约80%的精确率和约90%的召回率@1。Modarres等人还报告称，数据集中的不平衡对分类器在准确预测欠代表类别方面没有影响。他们的混淆矩阵（见下图）显示，人口最少的类别，如多孔海绵、涂层表面和纤维，都表现得相当好。Modarres等人将此归因于这些类别的独特模式。（注意：Modarres等人混淆矩阵中展示的值是每个实际/真实标签的验证样本的百分比）
- en: '![Figure](../Images/ada5a524eed11450706d76ea8152fb76.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/ada5a524eed11450706d76ea8152fb76.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
- en: Two things that are worth bearing in mind at this point is that Modarres et
    al did not use any data augmentations, and the training process for the Inception-v3
    implementation took ~7 min on 2 GPUs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上需要记住两件事：Modarres等人没有使用任何数据增强技术，而Inception-v3实现的训练过程在2个GPU上花费了大约7分钟。
- en: 'Our Approach:'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们的方法：
- en: 'Wanting to see if we could achieve a higher accuracy than Modarres et al, we
    recreated their study with some of our own changes. First off we used the Resnet
    50 implementation on the Fastai v1 framework and executed on a Colab GPU. To avoid
    overfitting, we adopted two approaches introduced by Fast.ai: Data augmentation
    and progressive resizing.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 想要看看是否能比Modarres等人取得更高的准确率，我们在进行了一些自定义修改后重新进行了他们的研究。首先，我们使用了Fastai v1框架上的Resnet
    50实现，并在Colab GPU上执行。为了避免过拟合，我们采用了Fast.ai介绍的两种方法：数据增强和渐进式调整大小。
- en: 'Data Augmentation:'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强：
- en: Data augmentation is essentially altering/distorting each image, effectively
    creating a new image. Fastai v1 has a great tool called get_transforms that handles
    this process for us. The [get_transforms](https://docs.fast.ai/vision.transform.html) function
    transforms the images in a number of different ways, such as flipping, rotating,
    changing its contrast and distorting it, meaning that small datasets effectively
    become much bigger.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强本质上是改变/扭曲每张图像，有效地创建一张新图像。Fastai v1有一个很好的工具叫做get_transforms，处理这个过程。函数[get_transforms](https://docs.fast.ai/vision.transform.html)以多种不同的方式转换图像，例如翻转、旋转、改变对比度和扭曲，这意味着小数据集实际上变得更大。
- en: '![Figure](../Images/2d2d112b9a2c478b16cd2b7efcbba602.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/2d2d112b9a2c478b16cd2b7efcbba602.png)'
- en: sources: [https://docs.fast.ai/vision.transform.html](https://docs.fast.ai/vision.transform.html)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 资料来源：[https://docs.fast.ai/vision.transform.html](https://docs.fast.ai/vision.transform.html)
- en: 'Progressive Resizing:'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进阶调整大小：
- en: Progressive resizing is an approach that was introduced by [Jeremy Howard](https://twitter.com/jeremyphoward) at [Fast.ai](https://www.fast.ai/).
    The concept is to crop the images in the dataset to a much smaller size, then
    after we’ve trained the model on the cropped images we increase their size and
    train the model again. We repeat this process a number of times, each time increasing
    the size of the images in the dataset. In this case we started with images of
    size 64x64 pixels. We trained the Resnet 50 on this dataset for a total of 15
    epochs and then increased it iteratively to 128 and finally 224\. Progressive
    resizing has two advantages. First off a lot of the early training is carried
    out on smaller images, which means the computational cost is lower and training
    takes less time. Secondly, repeatedly changing the size of the images and retraining
    the model can make it very difficult for the model to overfit. This means that
    your final model is more stable on new data it’s never seen before.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 进阶调整大小是[Jeremy Howard](https://twitter.com/jeremyphoward)在[Fast.ai](https://www.fast.ai/)提出的一种方法。这个概念是将数据集中的图像裁剪成更小的尺寸，然后在裁剪图像上训练模型，接着增大图像尺寸并再次训练模型。我们重复这个过程多次，每次增加数据集中图像的尺寸。在这种情况下，我们从64x64像素的图像开始。我们在这个数据集上训练了Resnet
    50，总共15个epoch，然后将其逐步增大到128，最后到224。进阶调整大小有两个优点。首先，很多早期训练是在较小的图像上进行的，这意味着计算成本较低，训练时间更短。其次，反复更改图像的大小并重新训练模型可以使模型过拟合变得非常困难。这意味着你的最终模型在以前从未见过的新数据上会更稳定。
- en: 'Results:'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果：
- en: Our implementation can be found in our GitHub repository, [here](https://github.com/skellig-ai/ikeaney.github.io/blob/master/SEM_Classification_ResNet50.ipynb).
    We achieved an overall accuracy of 94.5%, more than 4.5% of an increase on the
    previous state-of-the-art by Modarres et al, although our training process did
    take nearly 400 mins. Given that there is an imbalance in the data set, it is
    useful to consider metrics other than accuracy, such as [precision and recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall).
    Precision is essentially what proportion of the positive identification is actually
    correct, while recall is the proportion of actual positives which were identified
    correctly. Our model, while slightly over-fitting, achieved a precision of 94.2%
    and a recall of 91.8%. Comparing these to the values that Modarres et al reported
    of ~80% and ~90% respectively indicates that our model also performs better on
    the underrepresented categories in the dataset.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现可以在我们的 GitHub 仓库中找到，[这里](https://github.com/skellig-ai/ikeaney.github.io/blob/master/SEM_Classification_ResNet50.ipynb)。我们实现了94.5%的总体准确率，比Modarres等人之前的最新技术提高了超过4.5%，尽管我们的训练过程确实花费了近400分钟。考虑到数据集的不平衡，考虑其他指标如[精确度和召回率](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)是有用的。精确度本质上是正识别的比例实际上是正确的，而召回率是实际正样本中被正确识别的比例。尽管我们的模型稍有过拟合，但实现了94.2%的精确度和91.8%的召回率。与Modarres等人报告的约80%和90%相比，这表明我们的模型在数据集中表现出更好的表现。
- en: 'Concluding Remarks:'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论：
- en: I hope you enjoyed the first blog post in our Augmented Scientist series. This
    series will explore more avenues where machine learning can be used to assist
    the work of Scientists across many disciplines. If you’re interested in getting
    involved, or have examples of where you’ve used machine learning to augment your
    own work please let us know, we’d love to hear from you.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢我们增强科学家系列的第一篇博客文章。这个系列将探讨更多机器学习可以用于协助科学家在各个学科中的工作的方法。如果你有兴趣参与，或有使用机器学习增强自己工作的例子，请告诉我们，我们很乐意听到你的意见。
- en: '**Bio: [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47)** ([**@Iain_Keaney**](https://twitter.com/Iain_Keaney))
    is a Machine Learning Engineer and Program Facilitator at [Skellig.ai](https://www.skellig.ai/).
    You can find the [Skellig.ai blog here](https://skellig-ai.github.io/).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47)** （[**@Iain_Keaney**](https://twitter.com/Iain_Keaney)）是
    [Skellig.ai](https://www.skellig.ai/) 的机器学习工程师和项目协调员。你可以在这里找到[Skellig.ai 博客](https://skellig-ai.github.io/)。'
- en: '[Original](https://skellig-ai.github.io/2020/02/03/The-Augmented-Scientist-Part-1.html).
    Reposted with permission.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://skellig-ai.github.io/2020/02/03/The-Augmented-Scientist-Part-1.html)。经许可转载。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning for Image Classification with Less Data](/2019/11/deep-learning-image-classification-less-data.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用更少数据进行图像分类的深度学习](/2019/11/deep-learning-image-classification-less-data.html)'
- en: '[What Does it Mean to Deploy a Machine Learning Model?](/2020/02/deploy-machine-learning-model.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[部署机器学习模型是什么意思？](/2020/02/deploy-machine-learning-model.html)'
- en: '[A Single Function to Streamline Image Classification with Keras](/2019/09/single-function-streamline-image-classification-keras.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Keras 简化图像分类的单一函数](/2019/09/single-function-streamline-image-classification-keras.html)'
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[认识 Gorilla：加州大学伯克利分校和微软的 API 增强型 LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与文本生成的交汇点](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[Essential Math for Data Science: Eigenvectors and Application to PCA](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的基本数学：特征向量及其在 PCA 中的应用](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
- en: '[Creating a Web Application to Extract Topics from Audio with Python](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[创建一个从音频中提取主题的 Python 网络应用](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)'
- en: '[Building a Geospatial Application in Python with Google Earth…](https://www.kdnuggets.com/2022/03/building-geospatial-application-python-google-earth-engine-greppo.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Google Earth 引擎在 Python 中构建地理空间应用](https://www.kdnuggets.com/2022/03/building-geospatial-application-python-google-earth-engine-greppo.html)'
- en: '[8 Ways to Improve Your Search Application this Week](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本周提升搜索应用的 8 种方法](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
