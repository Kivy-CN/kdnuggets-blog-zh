# 使用交叉验证的五个理由

> 原文：[https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html](https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**作者：[Dima Shulga](https://www.linkedin.com/in/shudima/)，HiredScore的数据科学家**

![Image](../Images/4976e41f789dca5a0f59be94e53ac73c.png)

交叉验证是数据科学家工具箱中的一个重要工具。它允许我们更好地利用数据。在我展示使用交叉验证的五个理由之前，我想简要介绍一下什么是交叉验证，并展示一些常见策略。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在的组织的信息技术

* * *

当我们使用某些数据构建机器学习模型时，我们通常将数据拆分为训练集和验证/测试集。训练集用于训练模型，验证/测试集用于在从未见过的数据上验证模型。经典方法是简单地进行80%-20%拆分，有时用70%-30%或90%-10%等不同的值。在交叉验证中，我们进行多个拆分。我们可以进行3次、5次、10次或任何K次拆分。这些拆分称为折，我们可以使用多种策略来创建这些折。

![](../Images/ccdb7f20adbd1b949b3adc9d14249f58.png)

k折交叉验证的图示，k=4。

**简单K折** — 我们将数据拆分为K个部分，以K=3为示例。如果我们有3000个实例，我们将其拆分为三部分：第1部分、第2部分和第3部分。然后，我们建立三个不同的模型，每个模型在两个部分上进行训练，在第三部分上进行测试。我们的第一个模型在第1部分和第2部分上训练，在第3部分上测试。我们的第二个模型在第1部分和第3部分上训练，在第2部分上测试，以此类推。

**留一交叉验证** — 这是最极端的交叉验证方法。对于数据集中的每个实例，我们使用所有其他实例建立一个模型，然后在选定的实例上进行测试。

**分层交叉验证** — 当我们将数据拆分为多个折时，我们希望确保每个折能很好地代表整个数据。最基本的例子是我们希望每个折中的不同类别的比例相同。大多数时候，只需随机进行即可，但在复杂数据集中，我们有时需要强制每个折有正确的分布。

这里是我认为你应该使用交叉验证的五个理由：

### ****1\. 使用所有数据****

![](../Images/994975e2fa3dc155e143adf59ec7bb68.png)

当我们数据非常少时，将数据分成训练集和测试集可能会导致测试集非常小。假设我们只有100个样本，如果我们进行简单的80-20分割，我们会在测试集中得到20个样本。这是不够的。我们几乎可以在这个测试集上得到任何表现，纯粹是因为偶然性。当我们面临多类问题时，情况更糟。如果我们有10个类别，只有20个样本，这样平均每个类别只有2个样本。仅用2个样本测试任何东西无法得出任何实际结论。

如果我们在这种情况下使用交叉验证，我们构建K个不同的模型，这样我们就能够对**所有**数据进行预测。对于每个实例，我们通过一个未见过这个样本的模型进行预测，因此我们在测试集中得到100个样本。对于多类问题，我们每个类别平均得到10个样本，这比仅有2个样本要好得多。在评估了我们的学习算法之后（见下面的#2），我们现在可以在所有数据上训练模型，因为如果我们的5个模型在不同训练集上的性能相似，我们假设通过在所有数据上进行训练将获得类似的性能。

通过进行交叉验证，我们能够利用所有100个样本进行训练和测试，同时在未见过的样本上评估我们的学习算法。

### ****2\. 获取更多度量指标****

![](../Images/de73243befaa07c4d2dc12c86ef034c4.png)

如#1所述，当我们使用学习算法创建五个不同的模型并在五个不同的测试集上进行测试时，我们可以更有信心地评估算法的性能。当我们在测试集上进行单次评估时，我们只能得到一个结果。这个结果可能是由于偶然性或某种原因导致的偏倚测试集。通过训练五个（或十个）不同的模型，我们可以更好地了解情况。假设我们训练了五个模型，并使用准确率作为测量标准。我们可能会遇到几种不同的情况。最佳情况是我们在所有折叠中的准确率相似，例如92.0、91.5、92.0、92.5和91.8。这意味着我们的算法（和数据）是一致的，我们可以确信通过在整个数据集上进行训练并在生产中部署，将会获得类似的性能。

然而，我们可能会遇到略微不同的情况，例如92.0、**44.0**、91.5、92.5和91.8。这些结果看起来非常奇怪。看起来我们的一个折叠来自不同的分布，我们必须回去确保我们的数据确实如我们所想的那样。

我们可能遇到的最糟糕的情况是结果有相当大的变化，比如80、44、99、60和87。在这里，看来我们的算法或数据（或两者）都不一致，可能是我们的算法无法学习，或者数据非常复杂。

通过使用交叉验证，我们能够获得更多的指标，并对我们的算法和数据得出重要结论。

### ****3\. 使用模型堆叠****

![](../Images/8eb32c29f7ba3197e5d825ae0bec11b5.png)

有时我们想（或必须）建立一个模型管道来解决问题。例如，考虑神经网络。我们可以创建多个层。每一层可能会使用前一层的输出并学习数据的新表示，因此最终能够产生好的预测。我们能够训练这些不同的层，因为我们使用了反向传播算法。每一层计算其错误并将其传递回前一层。

当我们做类似的事情但不使用神经网络时，我们不能以相同的方式进行训练，因为我们不总是能传递明确的“错误”（或导数）。

例如，我们可以创建一个随机森林模型来预测某些内容，然后我们想做一个线性回归，该回归依赖于之前的预测并生成一些真实数字。

这里的关键部分是我们的第二个模型必须学习第一个模型的**预测**。最好的解决方案是为每个模型使用两个不同的数据集。我们在数据集A上训练随机森林。然后我们使用数据集B进行预测。接着，我们使用数据集B的预测来训练我们的第二个模型（逻辑回归），最后，我们使用数据集C来评估我们的完整解决方案。我们使用第一个模型进行预测，将它们传递给第二个模型，然后与实际结果进行比较。

当我们拥有有限的数据（如大多数情况一样）时，我们实际上不能这样做。此外，我们不能在同一数据集上训练两个模型，因为这样，我们的第二个模型会在第一个模型已经见过的预测上进行学习。这些预测可能会被过拟合，或者至少在不同的数据集上效果更好。这意味着我们的第二个算法并不是在它将被测试的内容上进行训练。这可能导致最终评估中出现不同的效果，难以理解。

通过使用交叉验证，我们可以以之前描述的相同方式对数据集进行预测，从而使我们的第二个模型的输入将是第一模型从未见过的数据的真实预测。

### ****4\. 处理依赖/分组数据****

![](../Images/f0e6430b16700ab9e95e29df5417f7b7.png)

当我们对数据进行随机训练-测试划分时，我们假设我们的样本是独立的。这意味着知道/看到某些实例不会帮助我们理解其他实例。然而，这并不总是如此。

以语音识别系统为例。我们的数据可能包括不同的说话者说不同的单词。让我们看看口语数字识别。例如，在[this dataset](https://github.com/Jakobovski/free-spoken-digit-dataset)中，有3个说话者和1500个录音（每个说话者500个）。如果我们进行随机拆分，我们的训练集和测试集将共享相同的说话者说相同的单词！这当然会提高我们算法的性能，但一旦在新说话者上进行测试，我们的结果将会大幅下降。

正确的方法是将说话者分开，即使用2个说话者进行训练，使用第三个进行测试。然而，这样我们将只在一个说话者上测试算法。这还不够。我们需要知道我们的算法在不同说话者上的表现。

我们可以在说话者级别上使用交叉验证。我们将训练3个模型，每次使用一个说话者进行测试，另外两个用于训练。这样我们就能更好地评估我们的算法（如上所述），并最终在所有说话者上构建我们的模型。

### ****5\. 参数微调****

![](../Images/735866753376dc9ee7c3c391fbf49994.png)

这是进行交叉验证最常见和显而易见的原因之一。大多数学习算法需要对一些参数进行调优。这可能是梯度提升分类器中的树的数量、神经网络中的隐藏层大小或激活函数、支持向量机中的内核类型等等。我们希望找到适合我们问题的最佳参数。我们通过尝试不同的值并选择最佳值来实现这一点。有很多方法可以做到这一点。这可能是手动搜索、网格搜索或更复杂的优化。然而，在所有这些情况下，我们不能在训练测试上进行，也不能在测试集上进行。我们必须使用第三组数据，即验证集。

通过将数据拆分成三组而不是两组，我们将解决之前讨论的所有相同问题，特别是当我们没有很多数据时。通过交叉验证，我们能够使用一个数据集完成所有这些步骤。

### ****结论****

交叉验证是一个非常强大的工具。它帮助我们更好地利用数据，并提供了关于算法性能的更多信息。在复杂的机器学习模型中，有时容易忽视在流程的不同步骤中使用相同的数据。这在大多数情况下可能导致好的但不真实的性能，或者在其他情况下引入奇怪的副作用。我们必须确保对我们的模型充满信心。交叉验证在处理数据科学项目中的非平凡挑战时非常有帮助。

如果你想了解更多关于数据科学流程中可能出现的各种陷阱，欢迎阅读我关于[如何用数据科学说谎](https://towardsdatascience.com/how-to-lie-with-data-science-5090f3891d9c)的文章。

如果您想阅读其他关于为什么要做某事的5个原因，欢迎阅读我的文章[成为数据科学家时，逻辑回归应该是你学习的第一件事的5个原因](https://towardsdatascience.com/5-reasons-logistic-regression-should-be-the-first-thing-you-learn-when-become-a-data-scientist-fcaae46605c4)

**个人简介：[Dima Shulga](https://www.linkedin.com/in/shudima/)** 是HiredScore的数据科学家。

[原文](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79)，已获得授权转载。

**相关：**

+   [使用交叉验证构建可靠的机器学习模型](/2018/08/building-reliable-machine-learning-models-cross-validation.html)

+   [成为数据科学家时，逻辑回归应该是你学习的第一件事的5个原因](/2018/05/5-reasons-logistic-regression-first-data-scientist.html)

+   [如何用数据科学撒谎](/2018/07/how-lie-data-science.html)

### 更多关于此主题的内容

+   [为什么你应该使用线性回归模型而不是……的3个原因](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [为什么数据科学家应该使用LightGBM](https://www.kdnuggets.com/2022/01/data-scientists-reasons-lightgbm.html)

+   [为什么你应该避免数据科学职业的前5个原因](https://www.kdnuggets.com/2022/04/top-5-reasons-avoid-data-science-career.html)

+   [为什么你应该获得认证的5个原因](https://www.kdnuggets.com/2023/05/sas-5-reasons-get-certified.html)

+   [为什么你不应该使用机器学习的4个原因](https://www.kdnuggets.com/2021/12/4-reasons-shouldnt-machine-learning.html)

+   [7个原因为什么你难以找到数据科学工作](https://www.kdnuggets.com/7-reasons-why-youre-struggling-to-land-a-data-science-job)
