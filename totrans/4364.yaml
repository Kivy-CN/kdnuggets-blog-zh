- en: 'Essential Math for Data Science: Integrals And Area Under The Curve'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/11/essential-math-data-science-integrals-area-under-curve.html](https://www.kdnuggets.com/2020/11/essential-math-data-science-integrals-area-under-curve.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)[![Image](../Images/45c05efbbd9635efb62adde614427da4.png)](https://www.essentialmathfordatascience.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculus is a branch of mathematics that gives tools to study the rate of change
    of functions through two main areas: derivatives and integrals. In the context
    of machine learning and data science, you might use integrals to calculate the
    area under the curve (for instance, to evaluate the performance of a model with
    the ROC curve, or to calculate probability from densities.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, you’ll learn about integrals and the area under the curve using
    the practical data science example of the area under the ROC curve used to compare
    the performances of two machine learning models. Building from this example, you’ll
    see the notion of the area under the curve and integrals from a mathematical point
    of view (from my book Essential Math for Data Science).
  prefs: []
  type: TYPE_NORMAL
- en: Practical Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s say that you would like to predict the quality of wines from various of
    their chemical properties. You want to do a binary classification of the quality
    (distinguishing very good wines from not very good ones). You’ll develop methods
    allowing you to evaluate your models considering imbalanced data with the area
    under the Receiver Operating Characteristics (ROC) curve.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we’ll use a dataset showing various chemical properties of red
    wines and ratings of their quality. The dataset comes from here: https://archive.ics.uci.edu/ml/datasets/wine+quality.
    The related paper is Cortez, Paulo, et al. ”Modeling wine preferences by data
    mining from physicochemical properties.” Decision Support Systems 47.4 (2009):
    547-553.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/622f9846821726cb0886d511fd86d51c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1: Illustration of wine quality modeling.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in Figure 1, the dataset represents chemical analyses of wines
    (the features) and ratings of their quality. This rating is the target: this is
    what you’ll try to estimate.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s load the data and have a look at the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The last column `quality` is important as you’ll use it as the target of your
    classification. The quality is described by ratings from 3 to 8:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Since the goal is to classify red wines of *very good* quality, let’s decide
    that the wines are very good when ratings are 7 or 8 and not very good otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create the dataset with `y` being the quality (the dependent variable,
    0 for ratings less than 7 and 1 for ratings greater than or equal 7) and `X` containing
    all the other features.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first thing to do, before looking at the data, is to split it in a part
    for training your algorithms (the training set) and a part for testing them (the
    test set). This will allow you to evaluate the performance of your model on data
    unseen during the training.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Preprocessing**'
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, let’s standardize the data to help the convergence of the algorithm.
    You can use the class `StandardScaler` from Sklearn.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you don’t want to consider the data from the test set to do the standardization.
    The method `fit_transform()` calculates the parameters needed for the standardization
    and apply it at the same time. Then, you can apply the same standardization to
    the test set without fitting again.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**First Model**'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first model, let’s train a logistic regression on the training set and
    calculate the classification accuracy (the percentage of correct classifications)
    on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy is about 0.87, meaning that 87% of the test examples have been
    correctly classified. Should you be happy with this result?
  prefs: []
  type: TYPE_NORMAL
- en: Metrics for Imbalanced Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Imbalanced Dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we separated the data into very good wines and not very good wines, the
    dataset is *imbalanced*: there are different quantities of data corresponding
    to each target class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check how many observations you have in the negative (not very good wines)
    and positive classes (very good wines):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It shows that there are around 86.5% of the examples corresponding to class
    0 and 13.5% to class 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple Model**'
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this point about accuracy and imbalanced datasets, let’s creates
    a model as a baseline and look at its performance. It will help you to see the
    advantages to use other metrics than accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: A very simple model using the fact that the dataset is imbalanced would always
    estimate the class with the largest number of observations. In your case, such
    a model would always estimate that all wines are bad and get a decent accuracy
    doing that.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s simulate this model by creating random probabilities below 0.5 (for instance,
    a probability of 0.15 means that there is a 15% chance that the class is positive).
    We need these probabilities to calculate both the accuracy and other metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s say that if the probability is above 0.5, the class is estimated as positive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The variable `y_pred_random` contains only zeros. Let’s evaluate the accuracy
    of this random model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows that, even with a random model, the accuracy is not bad at all:
    it doesn’t mean that the model is good.'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, having a different number of observations corresponding to each
    class, you can’t rely on the accuracy to evaluate your model’s performance. In
    our example, the model could output only zeros and you would get around 86% accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: You need other metrics to assess the performance of models with imbalanced datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '**ROC Curves**'
  prefs: []
  type: TYPE_NORMAL
- en: 'A good alternative to the accuracy is the Receiver Operating Characteristics
    (ROC) curve. You can check the very good explanations of Aurélien Géron about
    ROC curves in Géron, Aurélien. Hands-on machine learning with Scikit-Learn, Keras,
    and TensorFlow: Concepts, tools, and techniques to build intelligent systems.
    O’Reilly Media, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main idea is to separate the estimations from the model into four categories:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The true positives (TP): the prediction is 1 and the true class is 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The false positives (FP): the prediction is 1 but the true class is 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The true negatives (TN): the prediction is 0 and the true class is 0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The false negatives (FN): the prediction is 0 but the true class is 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s calculate these values for your first logistic regression model. You
    can use the function `confusion_matrix` from Sklearn. It presents a table organized
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/3da6c540c32f461e174300a202c16a44.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2: Illustration of a confusion matrix.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You can see that there is no positive observation that has been correctly classified
    (TP) with the random model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision Threshold**'
  prefs: []
  type: TYPE_NORMAL
- en: In classification tasks, you want to estimate the class of data samples. For
    models like logistic regression which outputs probabilities between 0 and 1, you
    need to convert this score to the class 0 or 1 using a *decision threshold*, or
    just *threshold*. A probability above the threshold is considered as a positive
    class. For instance, using the default choice of the decision threshold at 0.5,
    you consider that the estimated class is 1 when the model outputs a score above
    0.5.
  prefs: []
  type: TYPE_NORMAL
- en: However, you can choose other thresholds, and the metrics you use to evaluate
    the performance of your model will depend on this threshold.
  prefs: []
  type: TYPE_NORMAL
- en: With the ROC curve, you consider multiple thresholds between 0 and 1 and calculate
    the true positive rate as a function of the false positive rate for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the function `roc_curve` from Sklearn to calculate the false positive
    rate (fpr) and the true positive rate (tpr). The function outputs also the corresponding
    thresholds. Let’s try it with our simulated random model where outputs are only
    values bellow 0.5 (`y_pred_random_proba`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s have a look at the outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now plot the ROC curve from these values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/0551fd39a886a7516aa8de613be795ad.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 3: ROC curve corresponding to the random model.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3 shows the ROC curve corresponding to the random model. It gives you
    the true positive rate as a function of the false positive rate for each threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, be careful, the thresholds are from 1 to 0\. For instance, the point
    at the bottom left corresponds to a threshold of 1: there is 0 true positive and
    0 false positive because it is not possible to have a probability above 1, so
    with a threshold of 1, no observation can be categorized as positive. At the top
    right, the threshold is 0, so all observations are categorized as positive, leading
    to 100% of true positive but also 100% of false positive.'
  prefs: []
  type: TYPE_NORMAL
- en: A ROC curve around the diagonal means that the model is not better than random
    which is the case here. A perfect model would be associated with a ROC curve with
    a true positive rate of 1 for all values of false positive rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now look at the ROC curve corresponding to the logistic regression model
    you trained earlier. You’ll need probabilities from the model, that you can get
    using `predict_proba()` instead of `predict`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The first column is the score for the class 0 and the second column for the
    score 1 (thus, the total of each row is 1), so you can keep the second column
    only.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/e3c42300bd0d64dc35a743fc87c27ab1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4: ROC curve corresponding to the logistic model.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see in Figure 4 that your model is actually better than a random model,
    which is not something you were able to know from the model accuracies (they were
    equivalent: around 0.86 for the random model and 0.87 for your model).'
  prefs: []
  type: TYPE_NORMAL
- en: Visual inspection is good, but it would also be crucial to have a single numerical
    metric to compare your models. This is usually provided by the area under the
    ROC curve. You’ll see what is the area under the curve and how you can calculate
    in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Integrals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Integration* is the inverse operation of differentiation. Take a function *f(x)* and
    calculate its derivative *f′(x)*, the *indefinite integral* (also called *antiderivative*)
    of *f′(x)* gives you back *f(x)* (up to a constant, as you’ll soon see).'
  prefs: []
  type: TYPE_NORMAL
- en: You can use integration to calculate the *area under the curve*, which is the
    area of the shape delimited by the function, as shown in Figure 5.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f07a129e494d5752224664b14379ba83.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5: Area under the curve.*'
  prefs: []
  type: TYPE_NORMAL
- en: A *definite integral* is the integral over a specific interval. It corresponds
    to the area under the curve in this interval.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll see through this example how to understand the relationship between the
    integral of a function and the area under the curve. To illustrate the process,
    you’ll approximate the integral of the function *g(x)=2x* using a discretization
    of the area under the curve.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example Description**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take again the example of the moving train. You saw that speed as a function
    of time was the derivative of distance as a function of time. These functions
    are represented in Figure 6.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/3111fddbf419701aa8e167755e97a86c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6: The left panel shows *f(x)* which is the distance as a function
    of time, and the right panel its derivative *g(x)*, which is the speed as a function
    of time.*'
  prefs: []
  type: TYPE_NORMAL
- en: The function shown in the left panel of Figure 6 is defined as *f(x)=x²*. Its
    derivative is defined as *g(x)=2x*.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you’ll learn how to find an approximation of the area under
    the curve of *g(x)*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Slicing the Function**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To approximate the area of a shape, you can use the slicing method: you cut
    the shape into small slices with an easy shape like rectangles, calculate the
    area of each of these slices and sum them.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll do exactly that to find an approximation of the area under the curve
    of *g(x)*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/1908cc700b096a7ac86f4da2dd4fb59c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7: Approximation of the area under the curve by discretizing the area
    under the curve of speed as a function of time.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7 shows the area under the curve of *f′(x)* sliced as one-second rectangles
    (let’s call this difference *Δx*). Note that we underestimate the area (look at
    the missing triangles), but we’ll fix that later.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to understand the meaning of the slices. Take the first one: its
    area is defined as 2⋅12⋅1\. The height of the slice is the speed at one second
    (the value is 2). So there are two units of speed by one unit of time for this
    first slice. The area corresponds to a multiplication between speed and time:
    this is a distance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if you drive at 50 miles per hour (speed) for two hours (time),
    you traveled *50⋅2=100 miles* (distance). This is because the unit of speed corresponds
    to a ratio between distance and time (like miles *per* hour). You get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/215aa2a2d5a353ae41f3c673251339f1.png)'
  prefs: []
  type: TYPE_IMG
- en: To summarize, the derivative of the distance by time function is the speed by
    time function, and the area under the curve of the speed by time function (its
    integral) gives you a distance. This is how derivatives and integrals are related.
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementation**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use slicing to approximate the integral of the function *g(x)=2x*. First,
    let’s define the function *g(x)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'As illustrated in Figure 7, you’ll consider that the function is discrete and
    take a step of *Δx=1*. You can create an *x*-axis with values from zero to six,
    and apply the function `g_2x()` for each of these values. You can use the Numpy
    method `arange(start, stop, step)` to create an array filled with values from `start` to `stop` (not
    included):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: You can then calculate the slice’s areas by iterating and multiplying the width
    (*Δx*) by the height (the value of *y* at this point). of the slice. As you saw,
    this area (`delta_x * y[i-1]` in the code below) corresponds to a distance (the
    distance of the moving train traveled during the *i*th slice). You can finally
    append the results to an array (`slice_area_all` in the code below).
  prefs: []
  type: TYPE_NORMAL
- en: Note that the index of `y` is `i-1` because the rectangle is on the left of
    the *x* value we estimate. For instance, the area is zero for *x=0* and *x=1*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: These values are the slice’s areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the distance traveled from the beginning to the corresponding
    time point (and not corresponding to each slice), you can calculate the cumulative
    sum of `slice_area_all` with the Numpy function `cumsum()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: This is the estimated values of the area under the curve of *g(x)* as a function
    of *x*. We know that the function *g(x)* is the derivative of *f(x)=x²*, so we
    should get back *f(x)* by the integration of *g(x)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s plot our estimation and f(x)f(x), which we’ll call the “true function”,
    to compare them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/7d1175a378bc8901953ffa92884e9a31.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8: Comparison of estimated and original function.*'
  prefs: []
  type: TYPE_NORMAL
- en: The estimation represented in Figure 8 shows that the estimation is not bad,
    but could be improved. This is because we missed all these triangles represented
    in red in Figure
  prefs: []
  type: TYPE_NORMAL
- en: One way to reduce the error is to take a smaller value for ΔxΔx, as illustrated
    in the right panel in Figure 9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure](../Images/ac06608555a71e705993b2faafb6a93e.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9: Missing parts in slices of the speed function (in red). The error
    is smaller with a smaller *Δx*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s estimate the integral function with *Δx=0.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/eb7532de963fc9ab64b708791ecd6004.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10: Smaller slice widths lead to a better estimation of the original
    function.*'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in Figure 10, we recovered (at least, up to an additive constant) the
    original function whose derivative we integrated.
  prefs: []
  type: TYPE_NORMAL
- en: '**Extension**'
  prefs: []
  type: TYPE_NORMAL
- en: In our previous example, you integrated the function *2x*, which is a linear
    function, but the principle is the same for any continuous function (see Figure
    11 for instance).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/baae33f15e4740d3b6e55eb126e4e935.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11: The slicing method can be used with many linear or nonlinear function,
    including all continuous functions.*'
  prefs: []
  type: TYPE_NORMAL
- en: Riemann Sum
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Approximating an integral using this slicing method is called a *Riemann sum*.
    Riemann sums can be calculated in different ways, as you can see in Figure 12.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/479e0604f9d8c94823f9a2b6ebf7a091.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12: Four kinds of Riemann sums for integral approximation.*'
  prefs: []
  type: TYPE_NORMAL
- en: As pictured in Figure 12, with the left Riemann sum, the curve is aligned with
    the left corner of the rectangle. With the right Riemann sum, the curve is aligned
    with the right corner of the rectangle. With the midpoint rule, the curve is aligned
    with the center of the rectangle. With the trapezoidal rule, a trapezoidal shape
    is used instead of a rectangle. The curve crosses both top corners of the trapezoid.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the last section, you saw the relationship between the area under the curve
    and integration (you got back the original function from the derivative). Let’s
    see now the mathematical definition of integrals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The integrals of the function *f(x)* with respect to *x* is denoted as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*∫f(x)dx*'
  prefs: []
  type: TYPE_NORMAL
- en: The symbol *dx* is called the *differential* of *x* and refers to the idea of
    an infinitesimal change of *x*. It is a difference in *x* that approaches 0\.
    The main idea of integrals is to sum an infinite number of slices which have an
    infinitely small width.
  prefs: []
  type: TYPE_NORMAL
- en: The symbol *∫* is the integral sign and refers to the sum of an infinite number
    of slices.
  prefs: []
  type: TYPE_NORMAL
- en: The height of each slice is the value *f(x)*. The multiplication of *f(x)* and *dx* is
    thus the area of each slice. Finally, *∫f(x):dx* is the sum of the slice areas
    over an infinite number of slices (the width of the slices tending to zero). This
    is the *area under the curve*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You saw in the last section how to approximate function integrals. But if you
    know the derivative of a function, you can retrieve the integral knowing that
    it is the inverse operation. For example, if you know that:'
  prefs: []
  type: TYPE_NORMAL
- en: '*d(x2)dx=2x*'
  prefs: []
  type: TYPE_NORMAL
- en: You can conclude that the integral of *2x* is *x2*. However, there is a problem.
    If you add a constant to our function the derivative is the same because the derivative
    of a constant is zero. For instance,
  prefs: []
  type: TYPE_NORMAL
- en: '*d(x²+3)dx=2x*'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is impossible to know the value of the constant. For this reason, you need
    to add an unknown constant to the expression, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*∫2xdx=x²+c*'
  prefs: []
  type: TYPE_NORMAL
- en: with cc being a constant.
  prefs: []
  type: TYPE_NORMAL
- en: '**Definite Integrals**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of *definite integrals*, you denote the interval of integration
    with numbers below and above the integral symbol, as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*∫baf(x)dx*'
  prefs: []
  type: TYPE_NORMAL
- en: It corresponds to the area under the curve of the function *f(x)* between *x=a* and *x=b*,
    as illustrated in Figure 13.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13: Area under the curve between $x=a$ and $x=b$.](../Images/3449d551c9a611e27e7626847a3037bc.png)*Figure
    13: Area under the curve between *x=a* and *x=b*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the ROC Curve
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you know how the area under the curve relates to integration, let’s
    see how to calculate it to compare numerically your models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that you had the ROC curves represented in Figure 14:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/00654d9a1a7a07306947b512ebcec2f4.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 14: ROC curves of the random model (blue) and the logistic regression
    model (green).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the random model. You want to sum each value of true positive
    rate multiplied by the width on the *x*-axis that is the difference between the
    corresponding value of false positive rate and the one before. You can obtain
    these differences with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'So the area under the ROC curve of the random model is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can simply use the function `roc_auc_score()` from Sklearn using the
    true target values and the probabilities as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: An area under the ROC curve of 0.5 corresponds to a model that is not better
    than random and an area of 1 corresponds to perfect predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s compare this value to the area under the ROC curve of your model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This shows that your model is actually not bad and your predictions of the quality
    of the wine are not random.
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, you can use a few lines of code to train complex algorithms.
    However, as you saw here, a bit of math can help you to make the most of it and
    speed up your work. It will give you more ease in various aspects of your discipline,
    even, for instance, understanding the documentation of machine learning libraries
    like Sklearn.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Hadrien Jean](https://hadrienj.github.io/)** is a machine learning
    scientist. He owns a Ph.D in cognitive science from the Ecole Normale Superieure,
    Paris, where he did research on auditory perception using behavioral and electrophysiological
    data. He previously worked in industry where he built deep learning pipelines
    for speech processing. At the corner of data science and environment, he works
    on projects about biodiversity assessement using deep learning applied to audio
    recordings. He also periodically creates content and teaches at Le Wagon (data
    science Bootcamp), and writes articles in his blog ([hadrienj.github.io](http://hadrienj.github.io)).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://hadrienj.github.io/posts/Essential-Math-Integrals/). Reposted
    with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Boost your data science skills. Learn linear algebra.](/2018/05/boost-data-science-skills-learn-linear-algebra.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Preprocessing for Deep Learning: From covariance matrix to image whitening](/2018/10/preprocessing-deep-learning-covariance-matrix-image-whitening.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science:  ‘Why’ and ‘How’](/2018/09/essential-math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How To Overcome The Fear of Math and Learn Math For Data Science](https://www.kdnuggets.com/2021/03/overcome-fear-learn-math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Eigenvectors and Application to PCA](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Visual Introduction to Singular…](https://www.kdnuggets.com/2022/06/essential-math-data-science-visual-introduction-singular-value-decomposition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Much Math Do You Need in Data Science?](https://www.kdnuggets.com/2020/06/math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Free Courses to Master Math for Data Science](https://www.kdnuggets.com/5-free-courses-to-master-math-for-data-science)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Free MIT Courses to Learn Math for Data Science](https://www.kdnuggets.com/5-free-mit-courses-to-learn-math-for-data-science)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
