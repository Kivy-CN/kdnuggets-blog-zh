- en: Pruning Machine Learning Models in TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在TensorFlow中剪枝机器学习模型
- en: 原文：[https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html](https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html](https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '[In a previous article](https://heartbeat.fritz.ai/research-guide-pruning-techniques-for-neural-networks-d9b8440ab10d),
    we reviewed some of the pre-eminent literature on pruning neural networks. We
    learned that pruning is a model optimization technique that involves eliminating
    unnecessary values in the weight tensor. This results in smaller models with accuracy
    very close to the baseline model.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[在上一篇文章中](https://heartbeat.fritz.ai/research-guide-pruning-techniques-for-neural-networks-d9b8440ab10d)，我们回顾了一些关于神经网络剪枝的权威文献。我们了解到，剪枝是一种模型优化技术，涉及消除权重张量中不必要的值。这导致模型更小，但准确性非常接近基线模型。'
- en: In this article, we’ll work through an example as we apply pruning and view
    the effect on the final model size and prediction errors.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将通过一个示例来应用剪枝，并查看对最终模型大小和预测误差的影响。
- en: Import the Usual Suspects
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入常见模块
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Our first step is to get a couple of imports out of the way:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是处理几个导入：
- en: '`Os` and `Zipfile` will help us in assessing the size of the models.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Os`和`Zipfile`将帮助我们评估模型的大小。'
- en: '`tensorflow_model_optimization` for model pruning.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorflow_model_optimization` 用于模型剪枝。'
- en: '`load_model` for loading a saved model.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`load_model` 用于加载已保存的模型。'
- en: and of course `tensorflow` and `keras`.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当然，还需要`tensorflow`和`keras`。
- en: 'Finally, we initialize TensorBoard so that we’ll able to visualize the models:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们初始化TensorBoard，以便可视化模型：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Dataset Generation
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集生成
- en: 'For this experiment, we’ll generate a regression dataset using scikit-learn.
    Thereafter, we split the dataset into a training and test set:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个实验，我们将使用scikit-learn生成一个回归数据集。之后，我们将数据集分成训练集和测试集：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Model Without Pruning
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 剪枝前的模型
- en: We’ll create a simple neural network to predict the target variable `y`. We’ll
    then check the mean squared error. After this, we’ll compare this with the entire
    model pruned, and then with just the `Dense` layer pruned.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个简单的神经网络来预测目标变量`y`。然后我们将检查均方误差。之后，我们将与整个模型剪枝后的结果进行比较，然后再与仅剪枝`Dense`层的结果进行比较。
- en: Next, we step up a callback to stop training the model once it stops improving,
    after 30 epochs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置一个回调函数，在训练停止改进后（30个epoch后）停止训练模型。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s print a summary of the model so that we can compare it with the summary
    of the pruned models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印出模型的摘要，以便与剪枝后的模型摘要进行比较。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Image for post](../Images/2557a1d142f91122421703dfb64bc1dd.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/2557a1d142f91122421703dfb64bc1dd.png)'
- en: Let’s compile the model and train it.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编译模型并进行训练。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since it’s a regression problem, we’re monitoring the mean absolute error and
    the mean squared error.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个回归问题，我们正在监控平均绝对误差和均方误差。
- en: Here’s the model plotted to an image. The input is 10 since the dataset we generated
    has 10 features.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是绘制到图像上的模型。输入是10，因为我们生成的数据集有10个特征。
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Image for post](../Images/17359d8f180680b7254944b99f740797.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/17359d8f180680b7254944b99f740797.png)'
- en: Let’s now check the mean squared error. We can move on to the next section and
    see how this error changes when we prune the entire model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查均方误差。我们可以继续下一部分，看看在剪枝整个模型时误差如何变化。
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Pruning the Entire Model with a ConstantSparsity Pruning Schedule
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用ConstantSparsity剪枝计划剪枝整个模型
- en: Let’s compared the above MSE with the one obtained upon pruning the entire model.
    The first step is to define the pruning parameters. The weight pruning is magnitude-based.
    This means that some weights are converted to zeros during the training process.
    The model becomes sparse, hence making it easier to compress. Sparse models also
    make inferencing faster since the zeros can be skipped.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将上面的均方误差与剪枝整个模型后获得的均方误差进行比较。第一步是定义剪枝参数。权重剪枝是基于幅度的。这意味着在训练过程中，一些权重会被转换为零。模型变得稀疏，因此更容易压缩。稀疏模型还使推理速度更快，因为可以跳过零值。
- en: The parameters expected are the pruning schedule, the block size, and the block
    pooling type.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的参数包括剪枝计划、块大小和块池化类型。
- en: In this case, we’re setting a 50% [sparsity](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/ConstantSparsity),
    meaning that 50% of the weights will be zeroed.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，我们设置了50% [剪枝稀疏度](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/ConstantSparsity)，这意味着50%的权重将被置为零。
- en: '`block_size` — The dimensions (height, weight) for the block'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_size` — 块的尺寸（高度，宽度）'
- en: sparse pattern in matrix weight tensors.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 矩阵权重张量中的稀疏模式。
- en: '`block_pooling_type` — The function to use to pool weights in the'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`block_pooling_type` — 用于在中池化权重的函数'
- en: block. Must be `AVG` or `MAX`.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: block。必须是 `AVG` 或 `MAX`。
- en: We can now prune the entire model by applying our pruning parameters.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过应用剪枝参数来剪枝整个模型。
- en: Let’s check the model summary. Compare this with the summary of the unpruned
    model. From the image below we can see that the entire model has been pruned—we’ll
    see the difference shortly with the summary obtained after pruning one dense layer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查模型摘要。将其与未剪枝模型的摘要进行比较。从下图中我们可以看到整个模型已被剪枝——稍后我们会看到剪枝一个密集层后的摘要差异。
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Image for post](../Images/600a83cad46033ad4505372e7850a817.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/600a83cad46033ad4505372e7850a817.png)'
- en: We have to compile the model before we can fit it to the training and testing
    set.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须在将模型拟合到训练集和测试集之前编译模型。
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Since we’re applying pruning, we have to define a couple of pruning callbacks
    in addition to the early stopping callback. We define the folder to log the model,
    then create a list with the callbacks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在应用剪枝，我们必须定义几个剪枝回调函数，除了早期停止回调函数。我们定义日志模型的文件夹，然后创建一个包含回调函数的列表。
- en: '`tfmot.sparsity.keras.UpdatePruningStep()` updates pruning wrappers with the
    optimizer step. Failure to specify it will result in an error.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfmot.sparsity.keras.UpdatePruningStep()` 通过优化器步骤更新剪枝包装器。不指定它会导致错误。'
- en: '`tfmot.sparsity.keras.PruningSummaries()` adds pruning summaries to the Tensorboard.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfmot.sparsity.keras.PruningSummaries()` 将剪枝摘要添加到 Tensorboard。'
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: With that out of the way, we can now fit the model to the training set.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完这些后，我们现在可以将模型拟合到训练集。
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Upon checking the mean squared error for this model, we notice that it’s slightly
    higher than the one for the unpruned model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 检查此模型的均方误差时，我们注意到它略高于未剪枝模型的均方误差。
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Pruning the Dense Layer Only with PolynomialDecay Pruning Schedule
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 仅使用多项式衰减剪枝计划剪枝密集层
- en: Let’s now implement the same model—but this time, we’ll prune the dense layer
    only. Notice the use of the `[PolynomialDecay](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay)`[ function](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay) in
    the pruning schedule.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们实现相同的模型——但这次我们只剪枝密集层。请注意在剪枝计划中使用了 `[PolynomialDecay](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay)`[ 函数](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay)。
- en: From the summary, we can see that only the first dense layer will be pruned.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从摘要中，我们可以看到只有第一个密集层会被剪枝。
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Image for post](../Images/cb575b67fcf38555ae54a9132353e9bc.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/cb575b67fcf38555ae54a9132353e9bc.png)'
- en: We then compile and fit the model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们编译并拟合模型。
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now, let’s check the mean squared error.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查均方误差。
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can’t compare the MSE obtained here with the previous one since we’ve used
    different pruning parameters. If you’d like to compare them, then ensure that
    the pruning parameters are similar. Upon testing, `layer_pruning_params` gave
    a lower error than the `pruning_params` for this specific case. Comparing the
    MSE obtained from different pruning parameters is useful so that you can settle
    for the one that doesn’t make the model’s performance worse.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能将这里获得的 MSE 与之前的结果进行比较，因为我们使用了不同的修剪参数。如果你想进行比较，请确保修剪参数相似。在测试中，`layer_pruning_params`
    在这个特定案例中给出的错误比 `pruning_params` 更低。比较不同修剪参数得到的 MSE 是有用的，以便你选择不会使模型性能变差的参数。
- en: Comparing Model Sizes
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较模型大小
- en: Let’s now compare the sizes of the models with and without pruning. We start
    by training and saving the model weights for later use.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们比较修剪前后模型的大小。我们从训练和保存模型权重开始，以备后用。
- en: We’ll set up our base model and load the saved weights. We then prune the entire
    model. We compile, fit the model, and visualize the results on Tensorboard.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置我们的基础模型并加载已保存的权重。然后对整个模型进行修剪。我们编译、拟合模型，并在 TensorBoard 上可视化结果。
- en: Here’s a single snapshot of the pruning summaries from TensorBoard.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是来自 TensorBoard 的修剪总结的单个快照。
- en: '![Image for post](../Images/869fe54127f831eb2c443bd69ffb8251.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/869fe54127f831eb2c443bd69ffb8251.png)'
- en: The other pruning summaries can also be viewed on Tensorboard.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其他修剪总结也可以在 TensorBoard 上查看。
- en: '![Image for post](../Images/1df0795bf97341e8e19402d6820ba186.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/1df0795bf97341e8e19402d6820ba186.png)'
- en: Let’s now define a function to compute the sizes of the models.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义一个函数来计算模型的大小。
- en: And now we define the model for export and then compute the sizes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们定义模型以进行导出，然后计算模型的大小。
- en: For a pruned model,` tfmot.sparsity.keras.strip_pruning()` is used to restore
    the original model with the sparse weights. Notice the difference in size for
    the stripped and unstripped models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于修剪后的模型，`tfmot.sparsity.keras.strip_pruning()` 用于恢复具有稀疏权重的原始模型。请注意修剪和未修剪模型之间的大小差异。
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Running predictions on both models, we see that they have the same mean squared
    error.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对两个模型进行预测，我们发现它们具有相同的均方误差。
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Final Thoughts
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终想法
- en: You can go ahead and test how different pruning schedules affect the size of
    the model. Obviously, the observations made here are not universal. You’ll have
    to try different pruning parameters and learn how they affect your model size,
    prediction error, and/or accuracy depending on your problem.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以继续测试不同修剪计划如何影响模型的大小。显然，这里的观察结果并非普遍适用。你需要尝试不同的修剪参数，了解它们如何影响你的模型大小、预测误差和/或准确性，具体取决于你的问题。
- en: To optimize the model even more, **you could quantize it**. If you’d like to
    explore that and more, check the repo and the resources below.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步优化模型，**你可以对其进行量化**。如果你想进一步探索这一点，请查看以下仓库和资源。
- en: Resources
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源
- en: '[**Pruning in Keras example | TensorFlow Model Optimization**](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Keras 中的修剪示例 | TensorFlow 模型优化**](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)'
- en: Welcome to an end-to-end example for magnitude-based weight pruning. For an
    introduction to what pruning is and to…
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到一个基于幅度的权重修剪的端到端示例。有关修剪是什么以及如何…
- en: '[**Pruning comprehensive guide | TensorFlow Model Optimization**](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[**全面修剪指南 | TensorFlow 模型优化**](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide)'
- en: TensorFlow Lite for mobile and embedded devices
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 用于移动和嵌入式设备
- en: '[**mwitiderrick/Pruning-in-TensorFlow**](https://github.com/mwitiderrick/Pruning-in-TensorFlow)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[**mwitiderrick/Pruning-in-TensorFlow**](https://github.com/mwitiderrick/Pruning-in-TensorFlow)'
- en: In this article, we comb through an example as we apply pruning and view the
    effect on the final model size …
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们逐步应用修剪，并查看其对最终模型大小的影响…
- en: '[**8-Bit Quantization and TensorFlow Lite: Speeding up mobile inference with
    low precision**](https://heartbeat.fritz.ai/8-bit-quantization-and-tensorflow-lite-speeding-up-mobile-inference-with-low-precision-a882dfcafbbd)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[**8 位量化与 TensorFlow Lite：通过低精度加速移动推断**](https://heartbeat.fritz.ai/8-bit-quantization-and-tensorflow-lite-speeding-up-mobile-inference-with-low-precision-a882dfcafbbd)'
- en: heartbeat.fritz.ai
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: heartbeat.fritz.ai
- en: '**Bio: Derrick Mwiti** is a data scientist who has a great passion for sharing
    knowledge. He is an avid contributor to the data science community via blogs such
    as Heartbeat, Towards Data Science, Datacamp, Neptune AI, KDnuggets just to mention
    a few. His content has been viewed over a million times on the internet. Derrick
    is also an author and online instructor. He also trains and works with various
    institutions to implement data science solutions as well as to upskill their staff.
    Derrick’s studied Mathematics and Computer Science from the Multimedia University,
    he also is an alumnus of the Meltwater Entrepreneurial School of Technology. If
    the world of Data Science, Machine Learning, and Deep Learning interest you, you
    might want to check his [Complete Data Science & Machine Learning Bootcamp in
    Python course](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：德里克·穆伊提** 是一位数据科学家，热衷于分享知识。他是数据科学社区的积极贡献者，通过 Heartbeat、Towards Data Science、Datacamp、Neptune
    AI、KDnuggets 等博客分享内容。他的内容在互联网上的浏览量已超过一百万次。德里克还是一位作者和在线讲师。他还与各种机构合作，实施数据科学解决方案以及提升员工技能。德里克曾在多媒体大学学习数学和计算机科学，也曾是
    Meltwater 创业技术学校的校友。如果你对数据科学、机器学习和深度学习的世界感兴趣，或许可以查看他的[完整数据科学与机器学习 Python 课程](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)。'
- en: '[Original](https://heartbeat.fritz.ai/model-pruning-in-tensorflow-e4e8f5646f6f).
    Reposted with permission.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/model-pruning-in-tensorflow-e4e8f5646f6f)。转载许可。'
- en: '**Related:**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Deploying Trained Models to Production with TensorFlow Serving](/2020/11/serving-tensorflow-models.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow Serving 部署训练好的模型](/2020/11/serving-tensorflow-models.html)'
- en: '[Dealing with Imbalanced Data in Machine Learning](/2020/10/imbalanced-data-machine-learning.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理机器学习中的数据不平衡](/2020/10/imbalanced-data-machine-learning.html)'
- en: '[How to deploy PyTorch Lightning models to production](/2020/11/deploy-pytorch-lightning-models-production.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何将 PyTorch Lightning 模型部署到生产环境](/2020/11/deploy-pytorch-lightning-models-production.html)'
- en: More On This Topic
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Decision Tree Pruning: The Hows and Whys](https://www.kdnuggets.com/2022/09/decision-tree-pruning-hows-whys.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树剪枝：为什么和如何](https://www.kdnuggets.com/2022/09/decision-tree-pruning-hows-whys.html)'
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 还是 TensorFlow？比较流行的机器学习框架](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 在计算机视觉中的应用 - 迁移学习简化](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[The "Hello World" of Tensorflow](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Tensorflow 的“Hello World”](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 训练图像分类模型的指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
