- en: 5 Advanced Features of Pandas and How to Use Them
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pandas 的 5 个高级功能及其使用方法
- en: 原文：[https://www.kdnuggets.com/2019/10/5-advanced-features-pandas.html](https://www.kdnuggets.com/2019/10/5-advanced-features-pandas.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/5-advanced-features-pandas.html](https://www.kdnuggets.com/2019/10/5-advanced-features-pandas.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![](../Images/fe9f215c9ed6ef36135e0104a0d1c0ae.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe9f215c9ed6ef36135e0104a0d1c0ae.png)'
- en: Pandas is the gold standard library for all things data. With the functionality
    to load, filter, manipulate, and explore data, it’s no wonder that it’s a [favorite
    among Data Scientists](https://www.kdnuggets.com/2018/06/top-20-python-libraries-data-science-2018.html).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 是处理数据的黄金标准库。具备加载、过滤、操作和探索数据的功能，难怪它是 [数据科学家们的最爱](https://www.kdnuggets.com/2018/06/top-20-python-libraries-data-science-2018.html)。
- en: Most of us naturally stick to the very basics of Pandas. Load up data from a
    CSV file, filter a few columns, and then jump right into the [data visualizations](https://towardsdatascience.com/5-quick-and-easy-data-visualizations-in-python-with-code-a2284bae952f).
    Yet Pandas actually comes with many lesser-known but useful functions that can
    make handling data a whole lot easier and cleaner.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大多数人自然会坚持使用 Pandas 的基础功能。从 CSV 文件中加载数据，过滤几个列，然后直接跳入 [数据可视化](https://towardsdatascience.com/5-quick-and-easy-data-visualizations-in-python-with-code-a2284bae952f)。然而，Pandas
    实际上包含了许多不太为人知但非常有用的函数，这些函数可以使数据处理变得更加简单和清晰。
- en: This tutorial will guide you through 5 of those more advanced functions — what
    they do and how to use them. Even more fun with data!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将引导你了解这些更高级的功能 — 它们的作用及如何使用。与数据一起玩得更开心！
- en: (1) Configuring Options and Settings
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (1) 配置选项和设置
- en: Pandas comes with a set of user-configurable options and settings. They’re huge
    productivity boosters since they let you tailor your Pandas environment exactly
    to your liking.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了一组用户可配置的选项和设置。这些设置是巨大的生产力提升工具，因为它们允许你根据自己的喜好精确调整 Pandas 环境。
- en: We can, for example, change some of Pandas’s display settings to change how
    many rows and columns are shown and to what precision floating point numbers are
    displayed.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以更改一些 Pandas 的显示设置，以改变显示的行和列数以及浮点数的显示精度。
- en: The code above ensures that Pandas always displays 10 rows and 10 columns at
    a maximum, with floating-point values showing 2 decimal places at most. That way,
    our terminal or Jupyter Notebook won’t look like a mess when we try to print out
    a big DataFrame!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码确保 Pandas 始终显示最多 10 行和 10 列，浮点值显示最多 2 位小数。这样，当我们尝试打印出一个大的 DataFrame 时，我们的终端或
    Jupyter Notebook 就不会看起来一团糟！
- en: That’s just a basic example. There’s a lot more to explore beyond the simple
    display settings. You can check out all the options in the [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个基本示例。除了简单的显示设置，还有很多东西可以探索。你可以查看所有选项的 [官方文档](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html)。
- en: (2) Combining DataFrames
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (2) 合并 DataFrame
- en: A relatively unknown part of Pandas DataFrames is that there are actually two
    different ways to combine them. Each method produces a different result, so selecting
    the proper one based on what you want to achieve is very important. In addition,
    they contain many parameters that further customize the merging. Let’s check them
    out.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas DataFrame 的一个相对不为人知的部分是，实际上有两种不同的方法来合并它们。每种方法产生不同的结果，因此根据你的需求选择合适的方法非常重要。此外，它们包含许多参数，可以进一步自定义合并。让我们来了解一下。
- en: '**Concatenating**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**拼接**'
- en: Concatenating is the most well-known method of combining DataFrames and can
    be thought of intuitively as “stacking.” That stacking can be done either horizontally
    or vertically.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 拼接是合并 DataFrame 的最常见方法，可以直观地理解为“堆叠”。这种堆叠可以是水平的，也可以是垂直的。
- en: Imagine that you have a huge dataset in CSV format. It makes sense to split
    it up into multiple files for easier handling (this is common practice for large
    datasets, referred to as *sharding*).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你有一个巨大的 CSV 格式数据集。将其拆分成多个文件以便于处理是有意义的（这在大数据集的处理中很常见，称为 *分片*）。
- en: When you load it into pandas you can vertically stack the DataFrame of each
    CSV to create one big DataFrame for all of the data. For example, if we have 3
    shards, each with 5 Million rows, then after we vertical stack them all, our final
    DataFrame will have 15 Million rows.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将数据加载到 Pandas 中时，你可以将每个 CSV 的 DataFrame 垂直堆叠，以创建一个包含所有数据的大 DataFrame。例如，如果我们有
    3 个分片，每个分片有 500 万行，那么在将它们垂直堆叠后，我们的最终 DataFrame 将有 1500 万行。
- en: The code below shows how to concatenate DataFrames in Pandas vertically.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码展示了如何在 Pandas 中垂直拼接 DataFrames。
- en: You can do something similar by splitting up your dataset according to the columns
    instead of the rows — a few columns for each CSV file (with all the rows of the
    dataset). It’s like we’re dividing up the dataset’s features into different shards.
    You would then horizontally stack them to combine those columns/features.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过根据列而不是行来拆分数据集，来做类似的操作——为每个 CSV 文件提供几个列（包含数据集的所有行）。这就像是将数据集的特征分成不同的碎片。然后你可以水平堆叠它们来组合这些列/特征。
- en: '**Merging**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**合并**'
- en: Merging is more complicated yet more powerful, combining Pandas DataFrames in
    an SQL-like style, i.e., the DataFrames will be joined by some common attribute.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 合并（Merging）更复杂但更强大，采用类似 SQL 的风格将 Pandas DataFrames 组合在一起，即通过某些共同的属性来连接 DataFrames。
- en: Imagine that you have two DataFrames describing your YouTube channel. One of
    them contains a list of user IDs and how much time each user has spent on your
    channel in total. The other contains a similar list of user IDs and how many videos
    each user has seen. Merging allows us to combine the 2 DataFrames into a single
    one by matching up the user IDs and then putting the ID, time spent, and video
    count into a single row for each user.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有两个描述你的 YouTube 频道的 DataFrames。其中一个包含用户 ID 列表以及每个用户在你的频道上花费的总时间。另一个包含类似的用户
    ID 列表以及每个用户观看的视频数量。合并允许我们通过匹配用户 ID 将这两个 DataFrames 组合成一个，通过将 ID、时间和视频数量放在每个用户的单独行中。
- en: Merging two DataFrames in Pandas is done with the *merge* function. You can
    see an example of how it works in the code below. The *left *and *right *parameters
    refer to the two DataFrames you wish to merge, while *on *specifies the column
    to be used for the matching.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pandas 中合并两个 DataFrames 是通过*merge*函数完成的。你可以在下面的代码中看到它是如何工作的。*left* 和 *right*
    参数指的是你希望合并的两个 DataFrames，而 *on* 指定了用于匹配的列。
- en: 'To go even further into emulating SQL joins, the *how *parameter allows you
    to select the type of SQL-style join you want to perform: inner, outer, left,
    or right. To learn more about SQL joins, see the [W3Schools tutorial](https://www.w3schools.com/sql/sql_join.asp).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更进一步模拟 SQL 连接，*how* 参数允许你选择要执行的 SQL 风格连接类型：内连接、外连接、左连接或右连接。要了解更多关于 SQL 连接的信息，请参见
    [W3Schools 教程](https://www.w3schools.com/sql/sql_join.asp)。
- en: (3) Reshaping DataFrames
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (3) 重塑 DataFrames
- en: There are **several **ways to reshape and restructure Pandas DataFrames. These
    range from simple and easy to powerful and complex. Let’s check out the three
    most common ones. For all of the following examples, we’ll be using this Dataset
    of superheroes!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有**几种**方法来重塑和重构 Pandas DataFrames。这些方法从简单易用到强大复杂。让我们来看看最常见的三种方法。在以下所有示例中，我们将使用这份超级英雄数据集！
- en: '**Transpose**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**转置**'
- en: The easiest of them all. Transposing swaps a DataFrame’s rows with its columns.
    If you have 5000 rows and 10 columns, and then transpose your DataFrame, you’ll
    end up with 10 rows and 5000 columns.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 其中最简单的。转置将 DataFrame 的行和列互换。如果你有 5000 行和 10 列，然后转置你的 DataFrame，你将得到 10 行和 5000
    列。
- en: '**Groupby**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**分组**'
- en: Groupby’s main usage is to split up DataFrames into multiple parts based on
    some keys. Once the DataFrame is split up into parts, you can loop through and
    apply some operations on each part independently.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 分组（Groupby）的主要用途是根据某些键将 DataFrames 拆分成多个部分。一旦 DataFrame 被拆分成多个部分，你可以遍历并对每个部分独立应用一些操作。
- en: For example, we can see how, in the code below, we created a DataFrame of Players
    with corresponding Years and Points. We then did a *groupby *to split up the DataFrame
    into multiple parts, according to the player. Thus, each player gets its own group
    showing how many points that player got for each year they were active.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到下面的代码中，我们创建了一个包含年份和得分的球员 DataFrame。然后我们进行了*groupby*操作，将 DataFrame 按照球员拆分成多个部分。因此，每个球员都有自己的组，显示该球员在每一年中获得的分数。
- en: '**Stacking**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**堆叠**'
- en: Stacking transforms the DataFrame into having a multi-level index, i.e., each
    row has multiple sub-parts. These sub-parts are created using the DataFrame’s
    columns, compressing them into the multi-index. Overall, stacking can be thought
    of as compressing columns into multi-index rows.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠（Stacking）将 DataFrame 转换为多层索引，即每一行具有多个子部分。这些子部分是通过 DataFrame 的列创建的，将它们压缩成多重索引。总体来说，堆叠可以看作是将列压缩成多重索引的行。
- en: This is best illustrated by an example, shown down below.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的例子最好地说明了这一点。
- en: (4) Working with time data
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (4) 处理时间数据
- en: The [Datetime library](https://docs.python.org/3.6/library/datetime.html) is
    a staple in Python. Whenever you’re dealing with anything related to real-world
    date and time information, it’s your go-to library. And lucky for us, Pandas also
    comes with functionality for using Datetime objects.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[Datetime 库](https://docs.python.org/3.6/library/datetime.html) 是 Python 的一个重要库。无论何时处理与现实世界日期和时间信息相关的内容，它都是你首选的库。幸运的是，Pandas
    也提供了使用 Datetime 对象的功能。'
- en: 'Let’s illustrate with an example. In the code below, we first create a DataFrame
    with 4 columns: Day, Month, Year, and data, and then sort it by year and month.
    As you can see, it’s quite messy; we’re using up 3 columns just to store the date,
    when in actuality, we know that a calendar date is just one value.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来说明。在下面的代码中，我们首先创建一个包含 4 列的 DataFrame：Day、Month、Year 和 data，然后按年份和月份进行排序。正如你所看到的，这样非常杂乱；我们使用了
    3 列来存储日期，但实际上我们知道一个日历日期只是一个值。
- en: We can clean things up with datetime.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 datetime 来整理数据。
- en: Pandas conveniently comes with a function called *to_datetime()* that can compress
    and convert multiple DataFrame columns into a single Datetime object. Once it’s
    in that format, you have all the flexibility of the Datetime library at your disposal.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 方便地提供了一个名为 *to_datetime()* 的函数，可以将多个 DataFrame 列压缩并转换为一个单一的 Datetime
    对象。一旦转化为这种格式，你就可以利用 Datetime 库的所有功能。
- en: To use the *to_datetime()* function, you’ll need to pass it all of the “date”
    data from the relevant columns. That’s the “Day”, “Month”, and “Year” columns.
    Once we have things in Datetime format, we no longer need the other columns and
    can simply drop them. Check out the code below to see how that all works!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 *to_datetime()* 函数时，你需要将所有相关列中的“日期”数据传递给它。这包括“Day”、“Month”和“Year”列。一旦我们将数据转化为
    Datetime 格式，我们就不再需要其他列，只需将其删除即可。查看下面的代码，了解具体的操作方法！
- en: (5) Mapping Items into Groups
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (5) 将项目映射到组
- en: Mapping is a neat trick that helps with organizing categorical data. Imagine,
    for example, that we have a huge DataFrame with thousands of rows where one of
    the columns has items we wish to categorize. Doing so can greatly simplify both
    the training of Machine Learning models and visualizing the data effectively.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 映射是一个有用的技巧，有助于组织分类数据。举个例子，假设我们有一个包含数千行的大型 DataFrame，其中一列包含我们希望分类的项目。这样做可以大大简化机器学习模型的训练和数据的有效可视化。
- en: Check out the code below for a mini example where we have a list of foods that
    we want to categorize.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的代码，了解我们如何将食品列表进行分类的迷你示例。
- en: In the code above, we put our list into a pandas series. We’ve also created
    a dictionary showing the mapping we want, categorizing each food item as a “Protein”
    or a “Carb.” This is a toy example, but if this series was at a large scale, say
    a length of 1,000,000 items, then looping through it wouldn’t be practical at
    all.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我们将列表放入了 pandas 系列中。我们还创建了一个字典，显示了我们想要的映射，将每个食品项分类为“Protein”或“Carb”。这是一个简单的示例，但如果这个系列的规模很大，比如有
    1,000,000 项，那么遍历它就不再实际。
- en: Instead of the basic for-loop, we can write a function using Pandas’s built-in *.map()* function
    to perform the mapping in an optimized way. Check out the code below to see the
    function and how it’s applied.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Pandas 内置的 *.map()* 函数来以优化的方式执行映射，而不是基本的 for 循环。查看下面的代码，了解函数及其应用。
- en: In the function, we first loop through our dictionary to create a new dictionary
    where the keys represent every possible item in the pandas series and the value
    represents the new mapped item, “Protein” or “Carbs”. Then, we simply apply Pandas’s
    built-in map function to map all of the values in the series
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数中，我们首先遍历字典，创建一个新字典，其中键表示 pandas 系列中的每一个可能项，而值表示新映射项，“Protein” 或 “Carbs”。然后，我们简单地应用
    Pandas 的内置映射函数来映射系列中的所有值。
- en: Check out the output below to see the results!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的输出以查看结果！
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Conclusion
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: So there you have it! Your 5 advanced features of Pandas and how to use them!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 所以就这样！这是 Pandas 的 5 个高级功能及其使用方法！
- en: If you’re hungry for more, not to worry! There’s a whole more to learn about
    Pandas and Data Science. As a recommended reading, the [KDNuggets website](https://www.kdnuggets.com/) is,
    of course, the best resource on the subject!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你渴望更多内容，不必担心！还有更多关于 Pandas 和数据科学的内容可以学习。作为推荐阅读，[KDNuggets 网站](https://www.kdnuggets.com/)
    当然是这个主题的最佳资源！
- en: '**Related:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Exploratory Data Analysis Using Python](https://www.kdnuggets.com/2019/08/activestate-exploratory-data-analysis-python.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 进行探索性数据分析](https://www.kdnuggets.com/2019/08/activestate-exploratory-data-analysis-python.html)'
- en: '[25 Tricks for Pandas](https://www.kdnuggets.com/2019/08/25-tricks-pandas.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas 的 25 个技巧](https://www.kdnuggets.com/2019/08/25-tricks-pandas.html)'
- en: '[Become a Pro at Pandas, Python’s Data Manipulation Library](https://www.kdnuggets.com/2019/06/pro-pandas-python-library.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为 Pandas 的专家，Python 的数据处理库](https://www.kdnuggets.com/2019/06/pro-pandas-python-library.html)'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 工作'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于这个话题的更多内容
- en: '[How to Use the pivot_table Function for Advanced Data Summarization…](https://www.kdnuggets.com/how-to-use-the-pivot_table-function-for-advanced-data-summarization-in-pandas)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 pivot_table 函数进行高级数据汇总…](https://www.kdnuggets.com/how-to-use-the-pivot_table-function-for-advanced-data-summarization-in-pandas)'
- en: '[Data Science Programming Languages and When To Use Them](https://www.kdnuggets.com/2022/02/data-science-programming-languages.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学编程语言及其使用时机](https://www.kdnuggets.com/2022/02/data-science-programming-languages.html)'
- en: '[Data Analytics: The Four Approaches to Analyzing Data and How To…](https://www.kdnuggets.com/2023/04/data-analytics-four-approaches-analyzing-data-effectively.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据分析：四种数据分析方法及其应用…](https://www.kdnuggets.com/2023/04/data-analytics-four-approaches-analyzing-data-effectively.html)'
- en: '[KDnuggets™ News 22:n06, Feb 9: Data Science Programming…](https://www.kdnuggets.com/2022/n06.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n06, 2月 9日：数据科学编程…](https://www.kdnuggets.com/2022/n06.html)'
- en: '[Converting JSONs to Pandas DataFrames: Parsing Them the Right Way](https://www.kdnuggets.com/converting-jsons-to-pandas-dataframes-parsing-them-the-right-way)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 JSON 转换为 Pandas DataFrames：正确解析的方式](https://www.kdnuggets.com/converting-jsons-to-pandas-dataframes-parsing-them-the-right-way)'
- en: '[MLOps: The Best Practices and How To Apply Them](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：最佳实践及其应用方法](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
