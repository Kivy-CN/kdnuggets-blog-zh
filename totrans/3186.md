# 开始使用 TensorFlow：机器学习教程

> 原文：[https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html](https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2017/12/getting-started-tensorflow.html/2#comments)

**由 [Dino Causevic](https://www.toptal.com/resume/dino-causevic), Toptal**。

TensorFlow 是由 Google 创建的开源软件库，用于实现机器学习和深度学习系统。这两个名字包含一系列强大的算法，它们面临一个共同的挑战——让计算机学会如何自动识别复杂模式和/或做出最佳决策。

如果你对这些系统的细节感兴趣，可以从 Toptal 博客文章中的 [机器学习](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer) 和 [深度学习](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks) 中了解更多。

![](../Images/6e3b08444cb7bdaecec1e430278822de.png)

TensorFlow 的核心是一个数据流编程库。它利用各种优化技术，使数学表达式的计算变得更简单和高效。

TensorFlow 的一些关键特性包括：

+   高效处理涉及多维数组的数学表达式

+   对深度神经网络和机器学习概念的良好支持

+   GPU/CPU 计算，允许在两种架构上执行相同的代码

+   高度可扩展的跨机器计算和巨大的数据集

这些特性使 TensorFlow 成为生产规模机器智能的完美框架。

在本 TensorFlow 教程中，你将学习如何在 TensorFlow 中使用简单而强大的机器学习方法，以及如何利用一些辅助库来调试、可视化和调整所创建的模型。

**安装 TensorFlow**

我们将使用 TensorFlow Python API，该 API 支持 Python 2.7 和 Python 3.3+。GPU 版本（仅限 Linux）需要 Cuda Toolkit 7.0+ 和 cuDNN v2+。

我们将使用 Conda 包依赖管理系统来安装 TensorFlow。Conda 允许我们在一台机器上分隔多个环境。你可以从 [这里](https://conda.io/docs/user-guide/install/index.html) 学习如何安装 Conda。

安装 Conda 后，我们可以创建用于 TensorFlow 安装和使用的环境。以下命令将创建我们的环境，并包含一些额外的库，如 [NumPy](https://www.numpy.org/)，在我们开始使用 TensorFlow 时非常有用。

该环境中安装的 Python 版本为 2.7，我们将在本文中使用此版本。

```py
conda create --name TensorflowEnv biopython
```

*为了简化操作，我们在这里安装 biopython 而不是仅仅安装 NumPy。这样不仅包含了 NumPy，还有其他一些我们将需要的包。你可以根据需要随时使用 `conda install` 或 `pip install` 命令来安装这些包。*

以下命令将激活创建的 Conda 环境。我们将能够使用在其中安装的包，而不会与全局或其他环境中安装的包混淆。

```py
source activate TensorFlowEnv
```

pip 安装工具是 Conda 环境的标准部分。我们将使用它来安装 TensorFlow 库。在此之前，一个好的第一步是使用以下命令将 pip 更新到最新版本：

```py
pip install --upgrade pip
```

现在我们准备安装 TensorFlow，运行以下命令：

```py
pip install tensorflow
```

TensorFlow 的下载和构建可能需要几分钟。写作时，这将安装 TensorFlow 1.1.0。

**数据流图**

在 TensorFlow 中，计算是通过数据流图来描述的。图的每个节点代表一个数学操作（如加法、除法或乘法）的实例，每条边是一个多维数据集（张量），操作在其上执行。

![](../Images/1a9f8cab43009efda34fad441f236123.png)

由于 TensorFlow 使用计算图，它们的管理方式是每个节点代表一个操作的实例，每个操作有零个或多个输入和零个或多个输出。

TensorFlow 中的边可以分为两类：普通边传输数据结构（张量），在这种情况下，一个操作的输出可能成为另一个操作的输入，特殊边则用于控制两个节点之间的依赖关系，以设置操作顺序，其中一个节点等待另一个节点完成。

**简单表达式**

在我们继续讨论 TensorFlow 元素之前，我们将首先进行一次与 TensorFlow 的操作，以了解 TensorFlow 程序的样子。

让我们从简单的表达式开始，假设出于某种原因，我们想要以 TensorFlow 的方式评估函数 `y = 5*x + 13`。

在简单的 Python 代码中，它的样子是：

```py
x = -2.0
y = 5*x + 13
print y
```

在这种情况下，结果为 3.0。

现在我们将把上述表达式转换为 TensorFlow 术语。

**常量**

在 TensorFlow 中，常量是使用函数 constant 创建的，函数签名为 `constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`，其中 `value` 是实际的常量值，将用于进一步计算，`dtype` 是数据类型参数（例如 float32/64、int8/16 等），`shape` 是可选的维度，`name` 是张量的可选名称，最后一个参数是一个布尔值，指示是否验证值的形状。

如果你在训练模型中需要具有特定值的常量，可以使用 `constant` 对象，如下例所示：

```py
z = tf.constant(5.2, name="x", dtype=tf.float32)
```

**变量**

TensorFlow 中的变量是包含张量的内存缓冲区，这些张量必须显式初始化并在图中使用，以在会话中保持状态。通过简单地调用构造函数，变量被添加到计算图中。

变量在开始训练模型时特别有用，它们用于保存和更新参数。作为构造函数参数传递的初始值代表一个张量或对象，可以转换或返回为张量。这意味着，如果我们希望用一些预定义或随机的值填充一个变量，以便在训练过程中使用并在迭代中更新，我们可以按如下方式定义它：

```py
k = tf.Variable(tf.zeros([1]), name="k")
```

在 TensorFlow 中使用变量的另一种方式是在计算中，其中该变量不是可训练的，可以按如下方式定义：

```py
k = tf.Variable(tf.add(a, b), trainable=False)
```

**会话**

为了实际评估节点，我们必须在会话中运行计算图。

会话封装了 TensorFlow 运行时的控制和状态。没有参数的会话将使用当前会话中创建的默认图，否则会话类接受一个图参数，该参数在该会话中用于执行。

下面是一个简短的代码片段，展示了如何在 TensorFlow 中使用上述定义的术语来计算一个简单的线性函数。

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init)
    print session.run(y)

```

**使用 TensorFlow：定义计算图**

使用数据流图的好处是执行模型与其执行（在 CPU、GPU 或某些组合上）是分开的，一旦实现，TensorFlow 中的软件可以在 CPU 或 GPU 上使用，其中所有与代码执行相关的复杂性都被隐藏。

计算图可以在使用 TensorFlow 库的过程中构建，而无需显式实例化 [Graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph) 对象。

在 TensorFlow 中，可以通过一行简单的代码 `c = tf.add(a, b)` 来创建一个 Graph 对象。这将创建一个操作节点，该节点接受两个张量 `a` 和 `b`，并将它们的和 `c` 作为输出。

计算图是一个内置过程，使用库而无需直接调用 [graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph) 对象。在 TensorFlow 中，图对象包含一组操作和张量作为数据单元，在操作之间使用，这允许相同的过程并包含多个图，其中每个图将分配给不同的会话。例如，一行简单的代码 `c = tf.add(a, b)` 将创建一个操作节点，该节点将两个张量 `a` 和 `b` 作为输入，并产生它们的和 `c` 作为输出。

TensorFlow 还提供了一个 feed 机制，用于将张量修补到图中的任何操作中，其中 feed 将操作的输出替换为张量值。feed 数据作为参数传递到 `run()` 函数调用中。

占位符是 TensorFlow 允许开发者通过在某些表达式中绑定的占位符将数据注入计算图的方式。占位符的签名是：

```py
placeholder(dtype, shape=None, name=None)
```

其中，`dtype` 是张量中元素的类型，可以提供要输入的张量的形状和操作的名称。

如果未传递形状，则该张量可以用任何形状进行馈送。一个重要的注意事项是，占位符张量必须被馈送数据，否则在会话执行时如果该部分缺失，占位符将生成如下结构的错误：

```py
InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype float
```

占位符的优势在于，它们允许开发者创建操作以及计算图，而无需事先提供数据，数据可以在运行时从外部源添加。

让我们以在 TensorFlow 中乘以两个整数 `x` 和 `y` 的简单问题为例，其中将使用占位符和通过会话 `run` 方法的馈送机制。

```py
import tensorflow as tf

x = tf.placeholder(tf.float32, name="x")
y = tf.placeholder(tf.float32, name="y")

z = tf.multiply(x, y, name="z")

with tf.Session() as session:
    print session.run(z, feed_dict={x: 2.1, y: 3.0})

```

**使用 TensorBoard 可视化计算图**

TensorBoard 是一个用于分析数据流图的可视化工具。这对于更好地理解机器学习模型非常有用。

使用 TensorBoard，您可以深入了解关于参数的不同统计信息以及计算图各部分的详细信息。深度神经网络拥有大量节点并不罕见。TensorBoard 允许开发者深入了解每个节点及其在 TensorFlow 运行时如何执行计算。

![](../Images/48d7c35fa2fff56b5635fa7bdf908e1c.png)

现在让我们回到本 TensorFlow 教程开始时的示例，我们定义了格式为 `y = a*x + b` 的线性函数。

为了记录来自会话的事件，以便稍后可以在 TensorBoard 中使用，TensorFlow 提供了 `FileWriter` 类。它可以用于创建用于存储 [摘要](https://www.tensorflow.org/api_guides/python/summary) 和 [事件](https://www.tensorflow.org/api_docs/python/tf/Event) 的事件文件，其中构造函数接受六个参数，形式如下：

```py
__init__(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None)
```

其中，`logdir` 参数是必需的，其他参数有默认值。`graph` 参数将从训练程序中创建的会话对象传递。完整的示例代码如下：

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    merged = tf.summary.merge_all() // new
    writer = tf.summary.FileWriter("logs", session.graph) // new

    session.run(init)
    print session.run(y)
```

我们只添加了两行新代码。我们将所有收集的摘要合并到默认图中，`FileWriter` 用于将事件转储到文件中，如上所述。

运行程序后，我们在目录 logs 中有文件，最后一步是运行 `tensorboard`：

```py
tensorboard --logdir logs/
```

现在 TensorBoard 已启动并在默认端口 6006 上运行。打开 https://localhost:6006 并点击页面顶部的 Graphs 菜单项，您将能够看到图，如下图所示：

![](../Images/d7def7e0a9ba10e06df3f474264fe157.png)

TensorBoard 用特定符号标记常量和摘要节点，具体描述如下。

![](../Images/f39a2398dc314d85d44d6734a1ae94b9.png)

**与 TensorFlow 的数学运算**

张量是 TensorFlow 中的基本数据结构，它们代表数据流图中的连接边。

张量简单地标识一个多维数组或列表。张量结构可以通过三个参数来识别：秩、形状和类型。

+   秩：识别张量的维度数量。秩被称为张量的阶数或 n 维度，例如秩为 1 的张量是向量，秩为 2 的张量是矩阵。

+   形状：张量的形状是指它的行数和列数。

+   类型：分配给张量元素的数据类型。

要在 TensorFlow 中构建张量，我们可以构建一个 n 维数组。这可以通过使用 NumPy 库来轻松完成，或者通过将 Python n 维数组转换为 TensorFlow 张量来实现。

![](../Images/54429bdf3b195d6b7305c5e32546eff4.png)

要构建 1 维张量，我们将使用一个 NumPy 数组，这个数组将通过传递一个内置的 Python 列表来构造。

```py
import numpy as np
tensor_1d = np.array([1.45, -1, 0.2, 102.1])
```

使用这种数组类似于使用内置的 Python 列表。主要区别在于，NumPy 数组还包含一些额外的属性，如维度、形状和类型。

```py
>> print tensor_1d
[   1.45   -1\.      0.2   102.1 ]

>> print tensor_1d[0]
1.45

>> print tensor_1d[2]
0.2

>> print tensor_1d.ndim
1

>> print tensor_1d.shape
(4,)

>> print tensor_1d.dtype
float64

```

NumPy 数组可以通过辅助函数 [convert_to_tensor](https://www.tensorflow.org/versions/master/api_docs/python/tf/convert_to_tensor) 轻松转换为 TensorFlow 张量，该函数帮助开发者将 Python 对象转换为张量对象。该函数接受张量对象、NumPy 数组、Python 列表和 Python 标量。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
```

现在，如果我们将张量绑定到 TensorFlow 会话中，我们将能够看到转换的结果。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)

with tf.Session() as session:
    print session.run(tensor)
    print session.run(tensor[0])
    print session.run(tensor[1])

```

输出：

```py
[   1.45   -1\.      0.2   102.1 ]
1.45
-1.0

```

我们可以以类似的方式创建一个 2 维张量或矩阵：

```py
tensor_2d = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_1 = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_2 = np.array(np.random.rand(4, 4), dtype='float32')

m1 = tf.convert_to_tensor(tensor_2d)
m2 = tf.convert_to_tensor(tensor_2d_1)
m3 = tf.convert_to_tensor(tensor_2d_2)
mat_product = tf.matmul(m1, m2)
mat_sum = tf.add(m2, m3)
mat_det = tf.matrix_determinant(m3)

with tf.Session() as session:
    print session.run(mat_product)
    print session.run(mat_sum)
    print session.run(mat_det)

```

**张量操作**

在上面的示例中，我们介绍了对向量和矩阵的一些 TensorFlow 操作。这些操作对张量执行某些计算。具体计算内容见下表。

上表列出的 TensorFlow 操作与张量对象一起工作，并且是逐元素执行的。因此，如果你想计算向量 x 的余弦，TensorFlow 操作将对传递的张量中的每个元素进行计算。

```py
tensor_1d = np.array([0, 0, 0])
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
with tf.Session() as session:
    print session.run(tf.cos(tensor))

```

输出：

```py
[ 1\.  1\.  1.]

```

**矩阵操作**

矩阵运算对机器学习模型非常重要，例如线性回归，因为它们常常被用到。TensorFlow 支持所有常见的矩阵运算，如 [乘法](https://www.tensorflow.org/versions/master/api_docs/python/tf/matmul)、[转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、[逆矩阵](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_inverse)、计算 [行列式](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_determinant)、求解 [线性方程](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_solve) 等等 [更多](https://www.tensorflow.org/versions/master/api_guides/python/math_ops#Matrix_Math_Functions)。

接下来，我们将解释一些矩阵运算。当涉及到机器学习模型时，它们往往非常重要，例如在线性回归中。让我们编写一些代码，执行基本的矩阵运算，如乘法、获取 [转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、获取行列式、乘法、解方程等。

以下是调用这些运算的基本示例。

```py
import tensorflow as tf
import numpy as np

def convert(v, t=tf.float32):
    return tf.convert_to_tensor(v, dtype=t)

m1 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m2 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m3 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m4 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m5 = convert(np.array(np.random.rand(4, 4), dtype='float32'))

m_tranpose = tf.transpose(m1)
m_mul = tf.matmul(m1, m2)
m_det = tf.matrix_determinant(m3)
m_inv = tf.matrix_inverse(m4)
m_solve = tf.matrix_solve(m5, [[1], [1], [1], [1]])

with tf.Session() as session:
    print session.run(m_tranpose)
    print session.run(m_mul)
    print session.run(m_inv)
    print session.run(m_det)
    print session.run(m_solve)

```

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT需求

* * *

### 相关主题

+   [联邦学习：带教程的协作机器学习…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)

+   [开始使用Scikit-learn进行机器学习分类](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)

+   [开始使用自动化文本摘要](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)

+   [开始清理数据](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)

+   [开始使用SQL备忘单](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)

+   [开始使用spaCy进行自然语言处理](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
