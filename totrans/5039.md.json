["```py\n[('ireland', 3163), ('england', 2584), ('wales', 2271), \n  ('', 2068), ('day', 1479), ('france', 1380), ('win', 1338), \n  ('rugby', 1253), ('points', 1221), ('title', 1180)]\n\n```", "```py\n[('ireland', 3163), ('england', 2584), ('wales', 2271), \n  ('day', 1479), ('france', 1380), ('win', 1338), ('rugby', 1253), \n  ('points', 1221), ('title', 1180), ('__SHAMROCK_SYMBOL__', 1154)]\n\n```", "```py\n[('#engvfra', 1701), ('#itavwal', 927), ('#rugby', 880), \n  ('#scovire', 692), ('#ireland', 686), ('#angfra', 554), \n  ('#xvdefrance', 508), ('#crunch', 500), ('#wales', 446), \n  ('#england', 406)]\n\n```", "```py\nfrom collections import defaultdict\n# remember to include the other import from the previous post\n\ncom = defaultdict(lambda : defaultdict(int))\n\n# f is the file pointer to the JSON data set\nfor line in f: \n    tweet = json.loads(line)\n    terms_only = [term for term in preprocess(tweet['text']) \n                  if term not in stop \n                  and not term.startswith(('#', '@'))]\n\n    # Build co-occurrence matrix\n    for i in range(len(terms_only)-1):            \n        for j in range(i+1, len(terms_only)):\n            w1, w2 = sorted([terms_only[i], terms_only[j]])                \n            if w1 != w2:\n                com[w1][w2] += 1\n\n```", "```py\ncom_max = []\n# For each term, look for the most common co-occurrent terms\nfor t1 in com:\n    t1_max_terms = sorted(com[t1].items(), key=operator.itemgetter(1), reverse=True)[:5]\n    for t2, t2_count in t1_max_terms:\n        com_max.append(((t1, t2), t2_count))\n# Get the most frequent co-occurrences\nterms_max = sorted(com_max, key=operator.itemgetter(1), reverse=True)\nprint(terms_max[:5])\n\n```", "```py\n[(('6', 'nations'), 845), (('champions', 'ireland'), 760), \n  (('nations', 'rbs'), 742), (('day', 'ireland'), 731), \n  (('ireland', 'wales'), 674)]\n\n```", "```py\nsearch_word = sys.argv[1] # pass a term as a command-line argument\ncount_search = Counter()\nfor line in f:\n    tweet = json.loads(line)\n    terms_only = [term for term in preprocess(tweet['text']) \n                  if term not in stop \n                  and not term.startswith(('#', '@'))]\n    if search_word in terms_only:\n        count_search.update(terms_only)\nprint(\"Co-occurrence for %s:\" % search_word)\nprint(count_search.most_common(20))\n\n```", "```py\n[('champions', 756), ('day', 727), ('nations', 659), ('wales', 654), ('2015', 638), \n  ('6', 613), ('rbs', 585), ('http://t.co/y0nvsvayln', 559), ('__SHAMROCK_SYMBOL__', 526), ('10', 522), \n  ('win', 377), ('england', 377), ('twickenham', 361), ('40', 360), ('points', 356), \n  ('sco', 355), ('ire', 355), ('title', 346), ('scotland', 301), ('turn', 295)]\n\n```", "```py\n[('day', 476), ('game', 160), ('ireland', 143), ('england', 132), ('great', 105), \n  ('today', 104), ('best', 97), ('well', 90), ('ever', 89), ('incredible', 87), \n  ('amazing', 84), ('done', 82), ('amp', 71), ('games', 66), ('points', 64), \n  ('monumental', 58), ('strap', 56), ('world', 55), ('team', 55), ('http://t.co/bhmeorr19i', 53)]\n\n```"]