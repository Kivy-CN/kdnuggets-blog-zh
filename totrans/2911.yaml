- en: 'Opening Black Boxes: How to leverage Explainable Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 打开黑箱：如何利用可解释的机器学习
- en: 原文：[https://www.kdnuggets.com/2019/08/open-black-boxes-explainable-machine-learning.html](https://www.kdnuggets.com/2019/08/open-black-boxes-explainable-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/08/open-black-boxes-explainable-machine-learning.html](https://www.kdnuggets.com/2019/08/open-black-boxes-explainable-machine-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/), Emset**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/)，Emset**。'
- en: As Machine Learning and AI are becoming more and more popular, an increasing
    number of organizations is adopting this new technology. Predictive modeling is
    helping processes becoming more efficient but also allow users to gain benefits.
    One can predict how much you are likely going to be earning based on your professional
    skills and experience. The output could simply be a number, but users typically
    want to know why that value is given!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习和人工智能越来越受欢迎，越来越多的组织正在采用这一新技术。预测建模帮助过程变得更加高效，同时也让用户获得利益。人们可以根据专业技能和经验预测你可能赚多少钱。输出可能只是一个数字，但用户通常想知道为什么给出这个值！
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article, I will demonstrate some methods for creating explainable predictions
    and guide you into opening these black-box models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将演示一些创建可解释预测的方法，并指导你打开这些黑箱模型。
- en: '![](../Images/313ed8b941464d1b36522ff8b99f30db.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/313ed8b941464d1b36522ff8b99f30db.png)'
- en: The data used in this article is the US Adult Income data set, which is typically
    used to predict whether somebody makes less than 50K or more than 50, a simple
    binary classification task. You can get the data [here](https://www.kaggle.com/johnolafenwa/us-census-data),
    or you can follow along with the notebook [here](https://github.com/MaartenGr/InterpretableML).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的数据集是美国成人收入数据集，通常用于预测某人是否赚取少于50K或多于50K，这是一个简单的二分类任务。你可以在[这里](https://www.kaggle.com/johnolafenwa/us-census-data)获取数据，或者可以跟随[这里](https://github.com/MaartenGr/InterpretableML)的笔记本进行操作。
- en: The data is relatively straightforward with information with respect to an individuals’
    Relationship, Occupation, Race, Gender, etc.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据相对简单，包含个人的关系、职业、种族、性别等信息。
- en: '![](../Images/683718f5d319cd68e46d7d1116649495.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/683718f5d319cd68e46d7d1116649495.png)'
- en: Modeling
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建模
- en: The categorical variables are one-hot encoded, and the target is set to either
    0 (≤50K) or 1 (>50K). Now let’s say that we would like to use a model that is
    known for its great performance on classification tasks, but is highly complex
    and the output difficult to interpret. This model would be LightGBM which, together
    with CatBoost and XGBoost, is often used in both classification and regression
    tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 类别变量被进行了一次性编码，目标设置为0（≤50K）或1（>50K）。现在，假设我们想使用一个在分类任务中表现优秀但非常复杂且输出难以解释的模型，这个模型是LightGBM，它与CatBoost和XGBoost一起，常用于分类和回归任务。
- en: 'We start by simply fitting the model:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从简单地拟合模型开始：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I should note that preferably you would have a train/test split with additional
    holdout data to prevent any overfitting you would do.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该注意到，最好有一个训练/测试分割，并且有额外的保留数据来防止任何过拟合。
- en: 'Next, I quickly check the performance of the model using 10-fold cross-validation:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我快速检查模型的性能，使用10折交叉验证：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Interestingly, scores_accuracy gives an average accuracy across 10-folds of
    87% while scores_balanced gives 80%. As it turns out, the target variable is imbalanced,
    with 25% of the target belonging to 1 and 75% to 0\. Thus, choosing the correct
    validation measure is highly important as it may falsely indicate a good model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，scores_accuracy在10折交叉验证中的平均准确率为87%，而scores_balanced为80%。事实证明，目标变量是不平衡的，25%的目标属于1，75%属于0。因此，选择正确的验证指标非常重要，因为它可能会虚假地表示一个好的模型。
- en: Now that we have created the model, next would be explaining what it exactly
    has done. Since LightGBM works with highly efficient gradient boosting decision
    trees, interpretation of the output can be difficult.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了模型，接下来就是解释它具体做了什么。由于LightGBM使用高效的梯度提升决策树，输出的解释可能会很困难。
- en: Partial Dependency Plots (PDP)
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部分依赖图（PDP）
- en: Partial Dependency Plots (DPD) show the effect a feature has on the outcome
    of a predictive based model. It marginalizes the model output over the distribution
    of features to extract the importance of the feature of interest. The package,
    PDPbox, that I used can be found [here](https://github.com/SauceCat/PDPbox).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 部分依赖图（PDP）显示了某个特征对预测模型结果的影响。它在特征分布上对模型输出进行边际化，以提取感兴趣特征的重要性。我使用的包，PDPbox，可以在[这里](https://github.com/SauceCat/PDPbox)找到。
- en: '**Assumptions**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**假设**'
- en: This importance calculation is based on an important assumption, namely that
    the feature of interest is not correlated with all other features (except for
    the target). The reason for this is that it will show data points that are likely
    to be impossible. For example, weight and height are correlated, but the PDP might
    show the effect of a large weight and very small height on the target while that
    combination is highly unlikely. This can be partially resolved by showing a rug
    at the bottom of your PDP.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个重要性计算基于一个重要的假设，即感兴趣的特征与所有其他特征（目标除外）不相关。原因在于，这样会显示出可能不现实的数据点。例如，体重和身高是相关的，但PDP可能会显示大体重和非常小的身高对目标的影响，而这种组合的可能性很小。通过在PDP底部显示一个小条，可以部分解决这个问题。
- en: '**Correlation**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关性**'
- en: 'Thus, we check the correlation between features to make sure that there are
    no problems there:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们检查特征之间的相关性，以确保没有问题：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/60bb33e90dd4bc99b3dae6fb4f12957b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60bb33e90dd4bc99b3dae6fb4f12957b.png)'
- en: We can see that there is no strong correlation present among the features. However,
    I will do some one-hot encoding, later on, to prepare the data for modeling, which
    could lead to the creation of correlated features.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到特征之间没有明显的相关性。然而，我稍后会进行一些独热编码，以准备数据进行建模，这可能会导致相关特征的产生。
- en: '**Continuous variables**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**连续变量**'
- en: 'PDP plots can be used to visualize the impact of a variable on the output across
    all data points. Let’s first start with an obvious one, the effect of a continuous
    variable, namely *capital_gain*, on the target:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: PDP图可以用来可视化一个变量在所有数据点上的输出影响。让我们从一个明显的例子开始，连续变量*capital_gain*对目标的影响：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/3a4b24499ee4089c1915fe3aad26d54a.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a4b24499ee4089c1915fe3aad26d54a.png)'
- en: The x-axis shows the values capital_gain can take, and the y-axis indicates
    the effect it can have on the probability of the binary classification. It is
    clear that as one’s *capital_gain *increases their chance of making <50K increases
    with it. Note that the rug of data points at the bottom helps identify data points
    that do not appear often.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: x轴显示了capital_gain可能的值，y轴则表示它对二分类概率的影响。显然，随着*capital_gain*的增加，其赚取<50K的机会也会增加。注意，底部的数据点条有助于识别不常出现的数据点。
- en: '**One-hot encoded variables**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码变量**'
- en: 'Now, what if you have categorical variables that you one-hot encoded? You would
    likely want to see the effect of the categories individually without having to
    plot them separately. With PDPbox, you can show the effect on multiple binary
    categorical variables at the same time:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你有一个已经进行独热编码的分类变量呢？你可能想查看各类别的单独影响，而不必单独绘制它们。使用PDPbox，你可以同时显示多个二分类变量的效果：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/1f2a8c0afee9ce8416afcc2c1c66e290.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f2a8c0afee9ce8416afcc2c1c66e290.png)'
- en: Here, you can clearly see that the likelihood of making more is positively affected
    by being either in a managerial position or that of technology. The chance decreases
    if you are working in the fishing industry.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以清楚地看到，无论是处于管理职位还是技术职位，都对获得更多机会有正面影响。如果你在渔业工作，机会会减少。
- en: '**Interaction between variables**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量之间的交互**'
- en: Finally, the interaction between variables might be problematic as PDP will
    create values for the combination, which are unlikely to be possible if the variables
    are highly correlated.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，变量之间的交互可能是有问题的，因为 PDP 会为组合创建值，如果变量高度相关，这些值可能不太可能存在。
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/5d5167ae19832b3753cbd36e65aa82d1.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d5167ae19832b3753cbd36e65aa82d1.png)'
- en: This matrix tells you that an individual is likely to make more if they are
    around 49 years old and work roughly 50 hours a week. I should note that it is
    important to keep in mind the actual distribution of all interactions in your
    data set. There is a chance that this plot will show you interesting interactions
    that will rarely or never happen.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 该矩阵告诉你，如果一个人约 49 岁并且每周工作大约 50 小时，他们可能赚得更多。我应该指出，重要的是要记住数据集中所有交互的实际分布。这个图可能会显示出一些有趣的交互，但这些交互很少或永远不会发生。
- en: Local Interpretable Model-agnostic Explanations (LIME)
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 局部可解释模型无关解释（LIME）
- en: LIME basically tries to step away from deriving the importance of global features
    and instead approximates the importance of features for local predictions. It
    does so by taking the row (or set of data points) from which to predict and generate
    fake data based on that row. It then calculates the similarity between the fake
    data and the real data and approximates the effect of the changes based on the
    similarity between the fake and real data. The package that I used can be found [here](https://github.com/marcotcr/lime).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LIME 基本上试图远离推导全局特征的重要性，而是近似局部预测中特征的重要性。它通过从中预测的行（或数据点集）生成假数据，然后计算假数据与真实数据之间的相似性，并根据假数据和真实数据之间的相似性来近似变化的影响。我使用的包可以在[这里](https://github.com/marcotcr/lime)找到。
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/e929e6ebcb6cbdb81d8ddeadfb30f189.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e929e6ebcb6cbdb81d8ddeadfb30f189.png)'
- en: '*The output of LIME for a single row.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*LIME 对单行数据的输出。*'
- en: The output shows the effect of the top 5 variables on the prediction probability.
    This helps in identifying why your model makes a certain prediction but also allows
    for explanations to users.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了前 5 个变量对预测概率的影响。这有助于确定模型为何做出特定预测，同时也为用户提供了解释。
- en: '**Disadvantage**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点**'
- en: Note that the neighborhood (kernel width) around which LIME tries to find different
    values for the initial row is, to an extent, a hyperparameter that can be optimized.
    At times you want a larger neighborhood depending on the data. It is a bit of
    trial and error to find the right kernel width as it might hurt the interpretability
    of explanations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 LIME 尝试为初始行寻找不同值的邻域（核宽度）在一定程度上是一个可以优化的超参数。有时你需要根据数据选择更大的邻域。找到合适的核宽度有点像试错过程，因为它可能会影响解释的可解释性。
- en: SHapley Additive exPlanations (SHAP)
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Shapley 加法解释（SHAP）
- en: A (fairly) recent development has been the implementation of Shapley values
    into machine learning applications. In its essence, SHAP uses game theory to track
    the *marginal contributions *of each variable. For each variable, it randomly
    samples other values from the data set and calculates the change in your model
    score. These changes are then averaged for each variable to create a summary score,
    but also gives information on how important certain variables are for a specific
    data point.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一个（相当）新的发展是将 Shapley 值应用于机器学习。其本质上，SHAP 使用博弈论来跟踪每个变量的*边际贡献*。对于每个变量，它随机从数据集中抽样其他值并计算模型评分的变化。这些变化然后被平均以创建总结评分，同时也提供了有关特定数据点的某些变量的重要性的信息。
- en: Click [here](https://github.com/slundberg/shap) for the package that I used
    in the analyses. For a more in-depth explanation of the theoretical background
    of SHAP, click [here](https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 点击[这里](https://github.com/slundberg/shap)查看我在分析中使用的包。有关 SHAP 理论背景的更深入解释，请点击[这里](https://towardsdatascience.com/one-feature-attribution-method-to-supposedly-rule-them-all-shapley-values-f3e04534983d)。
- en: '**Three axioms of interpretability**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释性的三个公理**'
- en: 'SHAP has been well-received due to its ability to satisfy the three axioms
    of interpretability:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 因其满足可解释性的三个公理而受到好评：
- en: Any feature that has no effect on the predicted value should have a Shapley
    value of 0 (Dummy)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何对预测值没有影响的特征，其 Shapley 值应为 0（虚拟特征）
- en: If two features add the same value to the prediction, then their Shapley values
    should be the same (Substitutability)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果两个特征对预测增加相同的值，则它们的Shapley值应相同（可替代性）
- en: If you have two or more predictions that you would want to merge you should
    be able to simply add the Shapley values that were calculated on the individual
    predictions (Additivity)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有两个或更多预测需要合并，你应该能够简单地将对个别预测计算的Shapley值相加（加性原理）
- en: '**Binary Classification**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**二分类**'
- en: 'Let’s see what the result would be if we were to calculate the Shapley values
    for a single row:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果计算单行的Shapley值结果会如何：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/f20722d81563bf308ce241839154c08c.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f20722d81563bf308ce241839154c08c.png)'
- en: '*Shapley values for a single data point.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*单个数据点的Shapley值。*'
- en: This plot shows a base value that is used to indicate the direction of the prediction.
    Seeing as most of the targets are 0, it isn’t strange to see that the base value
    is negative.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了一个基准值，用于指示预测的方向。由于大多数目标是0，因此基准值为负数并不奇怪。
- en: The red bar shows how much the probability that the target is 1 (>50K) is increased
    if its *Education_num* is 13\. Higher education typically leads to making more.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 红色条形图显示当*教育年数*为13时，目标为1（>50K）的概率增加了多少。更高的教育通常会带来更多的收入。
- en: The blue bars show that these variables decrease the probability, with *Age*having
    the biggest effect. This makes sense as younger people typically make less.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝色条形图显示这些变量降低了概率，其中*年龄*的影响最大。这是合理的，因为年轻人通常赚得更少。
- en: '**Regression**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**'
- en: 'Shapley works intuitively a bit better when it concerns regression (continuous
    variable) rather than binary classification. Just to show an example, let’s train
    a model to predict age from the same data set:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley在处理回归（连续变量）时直观上表现得更好，而不是二分类。为了展示一个例子，让我们训练一个模型，从同一个数据集中预测年龄：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/284c3c397552aa096e96fe0e57c541e3.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/284c3c397552aa096e96fe0e57c541e3.png)'
- en: '*Shapley values for a single data point.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*单个数据点的Shapley值。*'
- en: Here, you can quickly observe that if you are never married, the predicted Age
    is lowered by roughly 8 years. This helps a bit more with explaining the prediction
    compared to a classification task since you are directly talking about the value
    of the target instead of its probability.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以快速观察到，如果你从未结婚，预测的年龄大约降低8岁。这比分类任务更有助于解释预测，因为你直接谈论的是目标的值，而不是其概率。
- en: '**One-hot encoded features**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**一热编码特征**'
- en: 'The Additivity axiom allows for summing Shapley values for each feature over
    all data points to create the mean absolute Shapley value. In other words, it
    gives global feature importances:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 加性公理允许对所有数据点的每个特征的Shapley值进行求和，以创建均值绝对Shapley值。换句话说，它提供了全局特征重要性：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/e9b93c3774dbe2de1b9d998f466553da.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9b93c3774dbe2de1b9d998f466553da.png)'
- en: However, you can immediately see the problem using Shapley values for one-hot
    encoded features, they are shown for each one-hot encoded feature instead of what
    they originally represented.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可以立即看到使用Shapley值处理一热编码特征的问题，它们是针对每个一热编码特征显示的，而不是它们最初所代表的。
- en: Fortunately, the Additivity axiom allows the Shapley values for each one-hot
    encoded generated feature to be summed as a representation of the Shapley value
    for the entire feature.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，加性公理允许将每个一热编码生成特征的Shapley值进行求和，以表示整个特征的Shapley值。
- en: 'First, we need to sum up all the Shapley values for the one-hot encoded features:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要对所有一热编码特征的Shapley值进行求和：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now that all the Shapley values are average across all features and summed
    for the one-hot encoded features we can plot the resulting feature importance:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有Shapley值已在所有特征中取平均并对一热编码特征进行求和，我们可以绘制结果特征重要性：
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/381d21c7fd64b721b0e565944e50af1e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/381d21c7fd64b721b0e565944e50af1e.png)'
- en: We can now see that *Occupation *is way more important than the original Shapley
    summary plot showed. Thus, make sure to use the Additivity to your advantage when
    explaining the importance of features to your users. They are likely to be more
    interested in how important *Occupation *is rather than a specific *Occupation*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到，*职业*比最初的Shapley总结图表所显示的要重要得多。因此，在向用户解释特征的重要性时，确保利用加性原理。用户可能更感兴趣于*职业*的重要性，而不是具体的*职业*。
- en: Conclusion
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: Although this is not the first article to talk about Interpretable and Explainable
    ML, I hope this helped you understand how these technologies can be used when
    developing your model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这不是第一篇讨论可解释和解释性机器学习的文章，但我希望这能帮助你了解在开发模型时如何使用这些技术。
- en: There has been a significant buzz around SHAP, and I hope that demonstrating
    the Additivity axiom using one-hot encoded features gives more intuition on how
    to use such a method.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对SHAP的关注日益增加，我希望通过使用独热编码特征展示加法公理，能够深入理解如何使用这种方法。
- en: Notebook with code can be found [here](https://github.com/MaartenGr/InterpretableML).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 带有代码的笔记本可以在[此处](https://github.com/MaartenGr/InterpretableML)找到。
- en: '**Bio:** [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/)
    is a Data Scientist | I/O Psychologist | Clinical Psychologist | Co-Founder at
    Emset.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [Maarten Grootendorst](https://www.linkedin.com/in/mgrootendorst/)
    是数据科学家 | I/O心理学家 | 临床心理学家 | Emset的联合创始人。'
- en: '[Original](https://towardsdatascience.com/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e).
    Reposted with permission.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e)。经许可转载。'
- en: '**Related:**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[A Data Science Playbook for explainable ML/xAI](https://www.kdnuggets.com/2019/07/domino-xai-data-science-explainable.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解释性机器学习/xAI的数据科学指南](https://www.kdnuggets.com/2019/07/domino-xai-data-science-explainable.html)'
- en: '[“Please, explain.” Interpretability of machine learning models](https://www.kdnuggets.com/2019/05/interpretability-machine-learning-models.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“请解释。” 机器学习模型的可解释性](https://www.kdnuggets.com/2019/05/interpretability-machine-learning-models.html)'
- en: '[An introduction to explainable AI, and why we need it](https://www.kdnuggets.com/2019/04/introduction-explainable-ai.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释AI介绍及其必要性](https://www.kdnuggets.com/2019/04/introduction-explainable-ai.html)'
- en: More On This Topic
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Black Friday Deal - Master Machine Learning for Less with DataCamp](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑色星期五优惠 - 使用DataCamp以更低价格掌握机器学习](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
- en: '[How to Better Leverage Data Science for Business Growth](https://www.kdnuggets.com/2022/08/better-leverage-data-science-business-growth.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何更好地利用数据科学推动业务增长](https://www.kdnuggets.com/2022/08/better-leverage-data-science-business-growth.html)'
- en: '[Using RAPIDS cuDF to Leverage GPU in Feature Engineering](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用RAPIDS cuDF在特征工程中发挥GPU作用](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
- en: '[How To Leverage Docker Cache for Optimizing Build Speeds](https://www.kdnuggets.com/how-to-leverage-docker-cache-for-optimizing-build-speeds)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何利用Docker缓存优化构建速度](https://www.kdnuggets.com/how-to-leverage-docker-cache-for-optimizing-build-speeds)'
- en: '[The Quest for Model Confidence: Can You Trust a Black Box?](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对模型信心的探索：你能信任一个黑箱吗？](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[缩小人类理解与机器学习之间的差距：…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
