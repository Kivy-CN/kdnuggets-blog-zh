# 实用的超参数优化

> 原文：[https://www.kdnuggets.com/2020/02/practical-hyperparameter-optimization.html](https://www.kdnuggets.com/2020/02/practical-hyperparameter-optimization.html)

[评论](#comments)

**作者 [Pier Paolo Ippolito](https://www.linkedin.com/in/pierpaolo28/)，南安普顿大学**

![](../Images/e7d267de83d374a4b81eacc48c82c3dc.png)

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织 IT

* * *

### 介绍

机器学习模型由两种不同类型的参数组成：

+   **超参数** = 是所有可以由用户在开始训练之前任意设置的参数（例如随机森林中的估计器数量）。

+   **模型参数 =** 在模型训练过程中学习得出（例如神经网络中的权重，线性回归中的系数）。

模型参数定义了如何使用输入数据得到期望的输出，并在训练时学习。而超参数则决定了我们模型的基本结构。

机器学习模型调优是一种优化问题。我们有一组超参数，并且目标是找到它们的最佳组合，从而帮助我们找到函数的最小值（例如损失）或最大值（例如准确率）（见图 1）。

当比较不同的机器学习模型在数据集上的表现时，这一点尤其重要。事实上，将一个具有最佳超参数的 SVM 模型与一个未经过优化的随机森林模型进行比较是不公平的。

在这篇文章中，将解释以下超参数优化的方法：

1.  **手动搜索**

1.  **随机搜索**

1.  **网格搜索**

1.  **自动化超参数调优（贝叶斯优化，遗传算法）**

1.  **人工神经网络（ANNs）调优**

![图示](../Images/a925c643693adacdb575d44ea48f69bb.png)

图 1：ML 优化工作流程 [1]

为了演示如何在 Python 中进行超参数优化，我决定对 [信用卡欺诈检测 Kaggle 数据集](https://www.kaggle.com/mlg-ulb/creditcardfraud) 进行完整的数据分析。我们在这篇文章中的目标是正确分类哪些信用卡交易应标记为欺诈或真实（即二分类）。该数据集在分发前已被匿名化，因此，大多数特征的含义未被公开。

在这种情况下，我决定只使用数据集的一个子集，以加快训练速度，并确保在两个不同类别之间实现完美的平衡。此外，仅使用有限数量的特征以使优化任务更加具有挑战性。最终的数据集如下面的图（图 2）所示。

![图](../Images/ac4eeb1e5f700fc844f3fead905f2a0d.png)

图 2：信用卡欺诈检测数据集

本文中使用的所有代码（及更多！）可以在我的 [GitHub 仓库](https://github.com/pierpaolo28/Kaggle-Challenges/blob/master/credit-card-fraud-model-tuning.ipynb) 和 [Kaggle 个人主页](https://www.kaggle.com/pierpaolo28/credit-card-fraud-model-tuning) 找到。

### 机器学习

首先，我们需要将数据集分为训练集和测试集。

在本文中，我们将使用随机森林分类器作为优化模型。

随机森林模型由大量不相关的决策树构成，这些决策树共同组成一个集成模型。在随机森林中，每棵决策树做出自己的预测，最终模型输出的是出现频率最高的预测。

现在我们可以开始计算我们的基本模型准确率。

```py
[[110   6]
 [  6 118]]
              precision    recall  f1-score   support

           0       0.95      0.95      0.95       116
           1       0.95      0.95      0.95       124

    accuracy                           0.95       240
   macro avg       0.95      0.95      0.95       240
weighted avg       0.95      0.95      0.95       240
```

使用默认 scikit-learn 参数的随机森林分类器可以达到 95% 的总体准确率。现在让我们看看通过应用一些优化技术是否能实现更好的准确率。

### 手动搜索

使用手动搜索时，我们根据判断/经验选择一些模型超参数。然后训练模型，评估其准确率，并重新开始这一过程。这个循环会重复，直到达到令人满意的准确率。

随机森林分类器使用的主要参数包括：

+   **criterion** = 用于评估切分质量的函数。

+   **max_depth** = 每棵树允许的最大层数。

+   **max_features** = 切分节点时考虑的最大特征数量。

+   **min_samples_leaf** = 可以存储在树叶中的最小样本数量。

+   **min_samples_split** = 节点中进行节点分裂所需的最小样本数量。

+   **n_estimators** = 集成中的树木数量。

关于随机森林参数的更多信息可以在 scikit-learn 的[文档](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)中找到。

作为手动搜索的一个例子，我尝试指定模型中的估计器数量。不幸的是，这并没有带来准确率的提升。

```py
[[110   6]
 [  6 118]]
              precision    recall  f1-score   support

           0       0.95      0.95      0.95       116
           1       0.95      0.95      0.95       124

    accuracy                           0.95       240
   macro avg       0.95      0.95      0.95       240
weighted avg       0.95      0.95      0.95       240
```

### 随机搜索

在随机搜索中，我们创建一个超参数网格，并在这些超参数的随机组合上训练/测试模型。在这个例子中，我还决定对训练集进行交叉验证。

在执行机器学习任务时，我们通常将数据集分为训练集和测试集。这是为了在训练模型后测试它（这样我们可以检查它在处理未见数据时的表现）。使用交叉验证时，我们将训练集划分为N个其他分区，以确保模型没有过拟合数据。

最常用的交叉验证方法之一是K折验证。在K折验证中，我们将训练集划分为N个分区，然后迭代地使用N-1个分区训练模型，并用剩余的分区进行测试（在每次迭代中，我们会更换剩余的分区）。训练N次模型后，我们将每次迭代中获得的训练结果进行平均，以获得整体训练性能结果（见图3）。

![图](../Images/ef469d0bf742072bd0a720a564e8c996.png)

图3：K折交叉验证 [2]

在实现超参数优化时使用交叉验证可能非常重要。这样，我们可能会避免使用在训练数据上效果很好但在测试数据上效果不佳的超参数。

我们现在可以通过首先定义一个超参数网格来开始实现随机搜索，这些超参数将在调用***RandomizedSearchCV()***时随机采样。以这个例子为例，我决定将训练集分为4个折（***cv = 4***）并选择80作为采样组合的数量（***n_iter = 80***）。使用scikit-learn的***best_estimator_***属性，我们可以检索在训练过程中表现最佳的超参数集合来测试我们的模型。

一旦训练了我们的模型，我们就可以可视化一些超参数的变化如何影响整体模型准确性（见图4）。在这种情况下，我决定观察估算器数量和准则的变化如何影响我们的随机森林准确性。

![图](../Images/f655111ff344502011d6b50d2e15d0ba.png)

图4：准则与N个估算器准确性热图

我们可以进一步通过使可视化更具互动性来提升效果。在下图中，我们可以通过滑块检查模型中估算器数量的变化如何影响整体准确性，考虑选定的min_split和min_leaf参数。

随意调整下面的图表，改变n_estimators参数，放大和缩小图表，改变其方向，并悬停在单个数据点上以获取额外信息！

如果你有兴趣了解更多关于如何使用[Plotly](https://towardsdatascience.com/interactive-data-visualization-167ae26016e8)创建这些动画的信息，我的代码可以在[这里](https://www.kaggle.com/kernels/scriptcontent/20590929/download)找到。此外，这也被[Xoel López Barata](https://towardsdatascience.com/using-3d-visualizations-to-tune-hyperparameters-of-ml-models-with-python-ba2885eab2e9)在一篇文章中介绍过。

我们现在可以评估我们的模型使用随机搜索的表现。在这种情况下，使用随机搜索会导致比我们的基线模型更稳定的准确率提升。

```py
[[115   1]
 [  6 118]]
              precision    recall  f1-score   support

           0       0.95      0.99      0.97       116
           1       0.99      0.95      0.97       124

    accuracy                           0.97       240
   macro avg       0.97      0.97      0.97       240
weighted avg       0.97      0.97      0.97       240
```

### 网格搜索

在网格搜索中，我们设置超参数的网格，并在每个可能的组合上训练/测试我们的模型。

为了选择在网格搜索中使用的参数，我们可以查看哪些参数在随机搜索中表现最好，并基于这些参数形成网格，以便寻找更好的组合。

网格搜索可以使用 Python 的 scikit-learn 中的 ***GridSearchCV()*** 函数实现。此次，我决定将我们的训练集分为 4 折（***cv = 4***）。

使用网格搜索时，尝试所有网格中的参数组合。在这种情况下，训练期间将使用 128000 种组合（2 × 10 × 4 × 4 × 4 × 10）。而在之前的网格搜索示例中，仅使用了 80 种组合。

```py
[[115   1]
 [  7 117]]
              precision    recall  f1-score   support

           0       0.94      0.99      0.97       116
           1       0.99      0.94      0.97       124

    accuracy                           0.97       240
   macro avg       0.97      0.97      0.97       240
weighted avg       0.97      0.97      0.97       240
```

网格搜索（Grid Search）相比随机搜索（Random Search）速度较慢，但它可以更有效，因为它能够遍历整个搜索空间。相对而言，随机搜索可能更快，但可能会错过搜索空间中的一些重要点。

### 自动化超参数调整

使用自动化超参数调整时，通过贝叶斯优化、梯度下降和进化算法等技术来确定要使用的模型超参数。

### 贝叶斯优化

贝叶斯优化（Bayesian Optimization）可以使用 Hyperopt 库在 Python 中执行。贝叶斯优化利用概率来寻找函数的最小值。最终目标是找到一个输入值，使函数输出最小值。

贝叶斯优化已被证明比随机、网格或手动搜索更高效。因此，贝叶斯优化可以在测试阶段带来更好的性能并减少优化时间。

在 Hyperopt 中，贝叶斯优化可以通过向 **fmin()** 函数提供 3 个主要参数来实现。

+   **目标函数** = 定义要最小化的损失函数。

+   **领域空间** = 定义要测试的输入值范围（在贝叶斯优化中，这个空间为每个使用的超参数创建概率分布）。

+   **优化算法** = 定义用于选择每次新迭代中最佳输入值的搜索算法。

此外，还可以在 ***fmin()*** 中定义要执行的最大评估次数。

贝叶斯优化可以通过考虑过去的结果来减少搜索迭代次数。这样，我们可以从一开始就将搜索集中在更接近我们期望输出的值上。

我们现在可以使用 **fmin()** 函数运行贝叶斯优化器。首先创建一个 **Trials()** 对象，以便后来可视化 **fmin()** 函数运行时发生了什么（例如，损失函数的变化情况以及使用的超参数的变化情况）。

```py
100%|██████████| 80/80 [03:07<00:00,  2.02s/it, best loss: -0.9339285714285713]{'criterion': 1,
 'max_depth': 120.0,
 'max_features': 2,
 'min_samples_leaf': 0.0006380325074247448,
 'min_samples_split': 0.06603114636418073,
 'n_estimators': 1}
```

现在我们可以检索到识别出的最佳参数集合，并使用在训练过程中创建的***最佳***字典测试我们的模型。一些参数已经通过索引以数字形式存储在***最佳***字典中，因此我们需要首先将它们转换回字符串形式，然后再输入到我们的随机森林中。

使用贝叶斯优化的分类报告如下所示。

```py
[[114   2]
 [ 11 113]]
              precision    recall  f1-score   support

           0       0.91      0.98      0.95       116
           1       0.98      0.91      0.95       124

    accuracy                           0.95       240
   macro avg       0.95      0.95      0.95       240
weighted avg       0.95      0.95      0.95       240
```

### 遗传算法

遗传算法尝试将自然选择机制应用于机器学习背景。它们受到达尔文自然选择过程的启发，因此通常也称为进化算法。

假设我们创建一个包含N个机器学习模型的种群，并设定一些预定义的超参数。然后，我们可以计算每个模型的准确性，并决定只保留表现最好的模型的一半。接下来，我们可以生成一些与最佳模型超参数相似的后代，从而再次获得N个模型的种群。此时，我们可以再次计算每个模型的准确性，并重复这个过程若干代。这样，最终只有表现最好的模型会存活下来。

为了在Python中实现遗传算法，我们可以使用[TPOT自动机器学习库](https://epistasislab.github.io/tpot/)。TPOT基于scikit-learn库构建，可以用于回归或分类任务。

训练报告和使用遗传算法识别出的最佳参数在下面的代码片段中显示。

```py
Generation 1 - Current best internal CV score: 0.9392857142857143
Generation 2 - Current best internal CV score: 0.9392857142857143
Generation 3 - Current best internal CV score: 0.9392857142857143
Generation 4 - Current best internal CV score: 0.9392857142857143
Generation 5 - Current best internal CV score: 0.9392857142857143

Best pipeline: RandomForestClassifier(CombineDFs(input_matrix, input_matrix), criterion=entropy, max_depth=406, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=617)
```

我们的随机森林遗传算法优化模型的整体准确性如下所示。

```py
0.9708333333333333
```

### 人工神经网络（ANNs）调优

使用KerasClassifier封装器，可以像使用scikit-learn机器学习模型时一样，应用网格搜索和随机搜索来优化深度学习模型。在以下示例中，我们将尝试优化一些ANN参数，例如：每层使用多少个神经元以及使用哪种激活函数和优化器。更多深度学习超参数优化的示例请见[这里](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)。

```py
Max Accuracy Registred: 0.932 using {'activation': 'relu', 'neurons': 35, 'optimizer': 'Adam'}
```

使用我们的人工神经网络（ANN）得到的整体准确性如下所示。

```py
[[115   1]
 [  8 116]]
              precision    recall  f1-score   support

           0       0.93      0.99      0.96       116
           1       0.99      0.94      0.96       124

    accuracy                           0.96       240
   macro avg       0.96      0.96      0.96       240
weighted avg       0.96      0.96      0.96       240
```

### 评估

现在我们可以比较所有不同优化技术在这个给定练习中的表现。总体而言，随机搜索和进化算法表现最好。

```py
Base Accuracy vs Manual Search 0.0000%.
Base Accuracy vs Random Search 2.1930%.
Base Accuracy vs Grid Search 1.7544%.
Base Accuracy vs Bayesian Optimization Accuracy -0.4386%.
Base Accuracy vs Evolutionary Algorithms 2.1930%.
Base Accuracy vs Optimized ANN 1.3158%.
```

获得的结果高度依赖于所选择的网格空间和数据集。因此，在不同的情况下，不同的优化技术表现可能会有所不同。

*希望你喜欢这篇文章，谢谢阅读！*

### 联系方式

如果你想跟进我的最新文章和项目，[在Medium关注我](https://medium.com/@pierpaoloippolito28?source=post_page---------------------------)并订阅我的[邮件列表](http://eepurl.com/gwO-Dr?source=post_page---------------------------)。以下是我的一些联系方式：

+   [LinkedIn](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------)

+   [个人博客](https://pierpaolo28.github.io/blog/?source=post_page---------------------------)

+   [个人网站](https://pierpaolo28.github.io/?source=post_page---------------------------)

+   [Medium 个人主页](https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------)

+   [GitHub](https://github.com/pierpaolo28?source=post_page---------------------------)

+   [Kaggle](https://www.kaggle.com/pierpaolo28?source=post_page---------------------------)

### 参考文献

[超参数优化：自动化算法的解释](https://dkopczyk.quantee.co.uk/hyperparameter-optimization/)

[模型选择](http://ethen8181.github.io/machine-learning/model_selection/model_selection.html)

**简介： [Pier Paolo Ippolito](https://www.linkedin.com/in/pierpaolo28/)** 是南安普顿大学的最后一年硕士人工智能学生。他是一个AI爱好者、数据科学家和RPA开发者。

[原文](https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d)。经授权转载。

**相关：**

+   [自动化机器学习项目实施复杂性](/2019/11/automl-implementation-complexities.html)

+   [自动化机器学习：团队如何在AutoML项目中协作？](/2020/01/teams-work-together-automl-project.html)

+   [如何自动化超参数优化](/2019/06/automate-hyperparameter-optimization.html)

### 更多相关主题

+   [超参数优化：10大Python库](https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html)

+   [使用网格搜索和随机搜索进行超参数调整](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)

+   [超参数调整：GridSearchCV和RandomizedSearchCV的解释](https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained)

+   [使用TPOT进行机器学习管道优化](https://www.kdnuggets.com/2021/05/machine-learning-pipeline-optimization-tpot.html)

+   [SQL查询优化技巧](https://www.kdnuggets.com/2023/03/sql-query-optimization-techniques.html)

+   [数据库优化：探索SQL中的索引](https://www.kdnuggets.com/2023/07/database-optimization-exploring-indexes-sql.html)
