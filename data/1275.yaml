- en: Model Experiments, Tracking and Registration using MLflow on Databricks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 在 Databricks 上进行模型实验、跟踪和注册
- en: 原文：[https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html](https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html](https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Dash Desai](https://www.linkedin.com/in/dash-desai/), Director of Platform
    and Technical Evangelism at StreamSets**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Dash Desai](https://www.linkedin.com/in/dash-desai/)，StreamSets 的平台及技术推广总监**'
- en: Learn how StreamSets, [a modern data integration platform for DataOps](https://streamsets.com/),
    can help expedite operations at some of the most crucial stages of Machine Learning
    Lifecycle and MLOps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 了解 StreamSets，[一个现代的数据集成平台用于 DataOps](https://streamsets.com/)，它如何在机器学习生命周期和
    MLOps 的一些关键阶段加速操作。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Data Acquisition And Preparation
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据获取与准备
- en: Machine learning models are only as good as the quality of data and the size
    of datasets used to train the models. [Data has shown](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#282426e76f63) that
    data scientists spend around 80% of their time on preparing and managing data
    for analysis and 57% of the data scientists regard cleaning and organizing data
    as the least enjoyable part of their work. This further validates the idea of 
    MLOps and the need for collaboration between data scientists and data engineers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的质量取决于用于训练模型的数据质量和数据集的大小。[数据表明](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#282426e76f63)，数据科学家将约
    80% 的时间花在数据准备和管理上，57% 的数据科学家认为清理和组织数据是他们工作中最不愉快的部分。这进一步验证了 MLOps 的理念以及数据科学家和数据工程师之间需要协作的必要性。
- en: During this crucial phase of data acquisition and preparation, data scientists
    identify what types of (trusted) datasets are needed to train models and work
    closely with data engineers to acquire data from viable data sources.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据获取和准备的关键阶段，数据科学家确定需要哪些类型的（可信）数据集来训练模型，并与数据工程师紧密合作，从可行的数据源中获取数据。
- en: How Can StreamSets Help
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StreamSets 如何提供帮助
- en: 'Some of the common data sources for acquiring datasets for data science projects
    include: Amazon S3, Microsoft Azure Blob Storage, Google Cloud Storage, Kafka,
    Hadoop, on-prem and cloud data warehouses. StreamSets DataOps Platform provides
    easy-to-use GUI for building smart data pipelines for streaming and batch dataflows
    for fast data ingestion of large amounts of data from distributed systems–including
    all of the common sources mentioned above.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的数据科学项目数据来源包括：Amazon S3、Microsoft Azure Blob Storage、Google Cloud Storage、Kafka、Hadoop、本地和云数据仓库。StreamSets
    DataOps Platform 提供了易于使用的 GUI，用于构建智能数据管道，实现流数据和批量数据流的快速数据摄取，支持从分布式系统中提取大量数据，包括上述所有常见来源。
- en: Another aspect of the data ingestion process is the storage–in some cases, companies
    may already have a data lake or a data warehouse and in some cases they may need
    to build one. StreamSets DataOps Platform is capable of connecting to existing
    data lakes and data warehouses (on-prem or in the cloud) and also has built-in
    capabilities of creating new ones.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄取过程的另一个方面是存储——在某些情况下，公司可能已经拥有数据湖或数据仓库，而在其他情况下，可能需要构建一个。StreamSets DataOps
    Platform 能够连接到现有的数据湖和数据仓库（本地或云端），并且还具备创建新数据湖和数据仓库的内置能力。
- en: '![Modern Data Integration for DataOps](../Images/12bff326545c71bc6f41afffdea07c7f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![现代数据集成用于 DataOps](../Images/12bff326545c71bc6f41afffdea07c7f.png)'
- en: 'As part of building these data pipelines, data engineers can also perform some
    of the key transformations needed by data scientists. Some of the common transformations
    required during data preparation include: data type conversion for fields/columns/features,
    renaming fields/columns/features, joining datasets, merging datasets, repartitioning,
    dataset data format conversion (for example, JSON to Parquet for efficient downstream
    analysis in Apache Spark), etc. All of these transformations and many more are
    readily supported by StreamSets DataOps Platform.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建这些数据管道的过程中，数据工程师还可以执行数据科学家所需的一些关键转换。数据准备过程中常见的一些转换包括：字段/列/特征的数据类型转换、字段/列/特征的重命名、数据集的连接、数据集的合并、重分区、数据集数据格式转换（例如，为了在
    Apache Spark 中进行高效的下游分析，将 JSON 转换为 Parquet）等。所有这些转换以及更多的操作都可以通过 StreamSets DataOps
    平台轻松完成。
- en: '*Imp Note: Extensive and thorough feature engineering tasks and in depth analysis
    of features, their correlation with the target variable, feature importances,
    etc. is best suited for and better performed on interactive tools, such as, Databricks
    Notebook, Jupyter, RStudio, and ML platforms.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*重要提示：广泛而彻底的特征工程任务以及对特征、特征与目标变量之间的相关性、特征重要性等的深入分析，最适合在交互式工具上进行，如 Databricks
    Notebook、Jupyter、RStudio 和 ML 平台。*'
- en: Model Experiments, Tracking, And Registration
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型实验、跟踪和注册
- en: Experimentation is a big precursor to model development where data scientists
    take sufficient subsets of trusted datasets and create several models in a rapid,
    iterative manner.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实验是模型开发的重要前置环节，在这一过程中，数据科学家从可信的数据集中取出足够的子集，并以快速、迭代的方式创建多个模型。
- en: Without proper industry standards, data scientists have to rely on manual tracking
    of models, inputs, hyperparameters, outputs and any other such artifacts throughout
    the model experimentation and development process. This results in very long model
    deployment/release cycles, which effectively prevents organizations from adapting
    to dynamic changes, gaining competitive advantage, and in some cases staying in
    compliance with changing governance and regulations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有适当的行业标准的情况下，数据科学家必须依赖手动跟踪模型、输入、超参数、输出和任何其他相关工件的过程。这导致了非常长的模型部署/发布周期，实际上阻碍了组织适应动态变化、获得竞争优势，并且在某些情况下难以保持对不断变化的治理和法规的合规性。
- en: How Can StreamSets Help
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StreamSets 如何提供帮助
- en: Using StreamSets Transformer, [a Spark ETL engine](https://streamsets.com/products/dataops-platform/transformer-etl/),
    it’s easy to integrate with [MLflow](https://mlflow.org/) using its PySpark or
    Scala APIs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 StreamSets Transformer，[一个 Spark ETL 引擎](https://streamsets.com/products/dataops-platform/transformer-etl/)，可以轻松地通过其
    PySpark 或 Scala API 与 [MLflow](https://mlflow.org/) 集成。
- en: This MLflow integration allows for tracking and versioning of model training
    code, data, config, hyperparameters as well as register and manage models in a
    central repository in MLflow from Transformer. This is critical for retraining
    models and/or for reproducing experiments.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这项 MLflow 集成允许跟踪和版本控制模型训练代码、数据、配置、超参数，并且可以在 MLflow 中的中央存储库中注册和管理模型，从 Transformer
    中进行。这对重新训练模型和/或重现实验至关重要。
- en: When using [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html),
    this creates a powerful and seamless solution because [Transformer can run on
    Databricks](https://streamsets.com/solutions/streamsets-for-databricks/) clusters
    and Databricks comes bundled with MLflow server.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用 [Databricks 上的 MLflow](https://docs.databricks.com/applications/mlflow/index.html)
    时，这会创建一个强大而无缝的解决方案，因为 [Transformer 可以在 Databricks](https://streamsets.com/solutions/streamsets-for-databricks/)
    集群上运行，并且 Databricks 已捆绑 MLflow 服务器。
- en: End-to-end Use Case
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端用例
- en: Let’s walk through an end-to-end scenario where we’ll ingest data from a cloud
    object storage (for example, Amazon S3), perform necessary transformations, and
    train a regression model. The dataset consists of a set of houses with features
    like number of bedrooms, bathrooms, square footage, etc. and the price it was
    sold at.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个端到端的场景来演示，我们将从云对象存储（例如，Amazon S3）中获取数据，执行必要的转换，并训练一个回归模型。数据集由一组房屋组成，包含卧室数量、浴室数量、建筑面积等特征，以及房屋出售时的价格。
- en: Apart from tracking, versioning, and registering models in MLflow with every
    run we’d also like the pipeline to automatically promote models from “*staging*”
    to “*production*” provided they meet a certain set of conditions. For example,
    if *r2 >= ${r2Threshold} or rmse <= ${rmseThreshold},* then the model needs to
    be promoted to “Production” on MLflow server on Databricks. This can be one of
    the requirements and part of the specification given by the data scientists to
    the data engineering team responsible for deploying the models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在每次运行时跟踪、版本化和注册模型外，我们还希望管道能够自动将模型从“*staging*”提升到“*production*”，前提是它们满足一定的条件。例如，如果*r2
    >= ${r2Threshold} 或 rmse <= ${rmseThreshold},* 则模型需要在 Databricks 的 MLflow 服务器上提升为“Production”。这可以是数据科学家向负责部署模型的数据工程团队提供的要求之一和规范的一部分。
- en: Pipeline Overview
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道概述
- en: The StreamSets Transformer pipeline shown below is designed to load training
    data from [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Origins/AmazonS3.html#concept_gww_1kw_shb),
    perform transformations like [remove](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/FieldRemover.html#concept_svw_dxf_fhb) row
    id, rename target column “*mdev*” to “*label*” (which is required by SparkMLlib),
    train **Gradient Boosted Regression** model using [PySpark](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) processor
    and archive the training data in [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Destinations/AmazonS3-D.html#concept_ymh_534_d3b).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下图所示的 StreamSets Transformer 管道旨在从[Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Origins/AmazonS3.html#concept_gww_1kw_shb)加载训练数据，执行如[移除](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/FieldRemover.html#concept_svw_dxf_fhb)行
    ID、将目标列“*mdev*”重命名为“*label*”（这是 SparkMLlib 所要求的）、使用[PySpark](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb)处理器训练**梯度提升回归**模型，并将训练数据存档在[Amazon
    S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Destinations/AmazonS3-D.html#concept_ymh_534_d3b)。
- en: More importantly, the pipeline also integrates with [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html) to
    track and version model training code including hyperparameters, model evaluation
    metrics, and register models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，该管道还集成了[MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html)，用于跟踪和版本化模型训练代码，包括超参数、模型评估指标，并注册模型。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/b18bd6ccd1ef4da94c8ad40ce57f779c.png)**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/b18bd6ccd1ef4da94c8ad40ce57f779c.png)**'
- en: '**Model Training And Experimentation**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型训练和实验**'
- en: Here’s the code snippet of interest in [PySpark Processor](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) —
    this is part of the pipeline that trains the Gradient Boosted Regression model
    and tracks everything in MLflow including promoting models from “*staging*” to
    “*production*” based on certain conditions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[PySpark Processor](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb)中的感兴趣代码片段——这是管道的一部分，训练梯度提升回归模型，并在
    MLflow 中跟踪所有内容，包括根据特定条件将模型从“*staging*”提升到“*production*”。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Show All ▼
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 显示全部 ▼
- en: '**Model Tracking in MLflow On Databricks**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLflow On Databricks 中的模型跟踪**'
- en: Here are the model training runs from the Transformer pipeline tracked in MLflow.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 MLflow 中跟踪的 Transformer 管道的模型训练运行记录。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/621550444f5f5e9f78ea27f94aeda536.png)**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/621550444f5f5e9f78ea27f94aeda536.png)**'
- en: '**Model Versioning in MLflow On Databricks**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLflow On Databricks 中的模型版本控制**'
- en: Here are the model versions registered from the Transformer pipeline.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从 Transformer 管道注册的模型版本。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/71af7b1d9949d7e5d7bde0d90f25de9f.png)**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/71af7b1d9949d7e5d7bde0d90f25de9f.png)**'
- en: '**Model Comparison in MLflow On Databricks**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLflow On Databricks 中的模型比较**'
- en: Here’s a side-by-side comparison of two selected models created from the Transformer
    pipeline.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从 Transformer 管道创建的两个选定模型的并排比较。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/a9f6c3ab266eb42837024a2c6d8e62c6.png)**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/a9f6c3ab266eb42837024a2c6d8e62c6.png)**'
- en: Model Retraining
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型重新训练
- en: Now, a very common requirement is to automate the process of retraining the
    model as and when more data becomes available–especially if the model hasn’t yet
    met the evaluation criteria. For example, accuracy can be one of the metrics on
    how a particular model is evaluated. This type of automation can be implemented
    by setting up an [orchestrator pipeline](https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title) as
    shown below.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一个非常常见的需求是自动化模型重新训练的过程，当更多数据可用时，特别是当模型尚未满足评估标准时。例如，准确率可以是评估特定模型的一个指标。这种类型的自动化可以通过设置如下所示的
    [编排器管道](https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title)
    来实现。
- en: The orchestrator pipeline is designed to continuously run and “wait” for training
    dataset  files to be uploaded on Amazon S3\. As soon as a training dataset is
    uploaded, this pipeline triggers/starts the model (re)training job described earlier.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 编排器管道设计为持续运行并“等待”训练数据集文件上传到 Amazon S3。当训练数据集上传后，这个管道会触发/启动前面描述的模型（重新）训练作业。
- en: '![Model Experiments, Tracking and Registration using MLflow on StreamSets and
    Databricks](../Images/303066fe0a00df998d4f07c69006e900.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/303066fe0a00df998d4f07c69006e900.png)'
- en: Also note that there are two hyperparameters ***maxIter*** and ***numberOfCVFolds*** passed
    in the pipeline so there’s no need to hard code them, and can be dynamically passed
    into the pipeline during model retraining and experimentation. The StreamSets
    DataOps Platform also provides ways to check the status of jobs that are currently
    running so that actions can be taken based on the status as shown above in the
    pipeline.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意的是，管道中传递了两个超参数 ***maxIter*** 和 ***numberOfCVFolds***，因此无需硬编码这些参数，可以在模型重新训练和实验过程中动态传递到管道中。StreamSets
    DataOps 平台还提供了检查当前运行作业状态的方法，以便根据状态采取行动，如上所示的管道。
- en: Sample Pipelines
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例管道
- en: 'If you’re interested in additional technical details and sample pipelines,
    please reach out to me: dash at streamsets dot com or [@iamontheinet](https://twitter.com/iamontheinet).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对更多技术细节和示例管道感兴趣，请与我联系：dash at streamsets dot com 或 [@iamontheinet](https://twitter.com/iamontheinet)。
- en: Get Started With Your Own Model Experiments
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始进行您自己的模型实验
- en: StreamSets DataOps Platform is not a machine learning platform, but it does
    provide important capabilities and extensibility that can help and expedite operations
    at some of the most crucial stages of the ML Lifecycle and MLOps.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: StreamSets DataOps 平台不是一个机器学习平台，但它确实提供了重要的功能和扩展性，可以帮助和加快机器学习生命周期和 MLOps 的一些关键阶段的操作。
- en: Learn more about [StreamSets For Databricks](https://streamsets.com/products/cloud/streamsets-for-databricks-marketplace/) available
    on AWS Marketplace and Microsoft Azure Marketplace.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多关于在 AWS Marketplace 和 Microsoft Azure Marketplace 上提供的 [StreamSets For Databricks](https://streamsets.com/products/cloud/streamsets-for-databricks-marketplace/)
    的信息。
- en: '**Bio: [Dash Desai](https://www.linkedin.com/in/dash-desai/)** is Director
    of Platform and Technical Evangelism at StreamSets, and has 18+ years of hands-on
    software and data engineering background. With recent experience in Big Data,
    Data Science, and Machine Learning, Dash applies his technical skills to help
    build solutions that solve business problems and surface trends that shape markets
    in new ways. Dash has worked for global enterprises and tech startups in agile
    environments as an engineer and a solutions architect. As a Platform and Technical
    Evangelist, he is passionate about evaluating new ideas to help articulate how
    technology can address a given business problem. He also enjoys writing technical
    blog posts, hands-on tutorials, and conducting technical workshops.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Dash Desai](https://www.linkedin.com/in/dash-desai/)** 是 StreamSets 平台和技术推广总监，拥有超过
    18 年的实际软件和数据工程背景。凭借在大数据、数据科学和机器学习方面的最新经验，Dash 运用他的技术技能帮助构建解决方案，以解决业务问题并揭示以新方式塑造市场的趋势。Dash
    曾在全球企业和技术初创公司中担任工程师和解决方案架构师。在担任平台和技术推广人员的过程中，他热衷于评估新想法，以帮助阐明技术如何解决特定的业务问题。他还喜欢撰写技术博客、动手教程和举办技术研讨会。'
- en: '[Original](https://streamsets.com/blog/model-experiments-tracking-and-registration-using-mlflow-on-databricks/).
    Reposted with permission.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://streamsets.com/blog/model-experiments-tracking-and-registration-using-mlflow-on-databricks/)。已获授权转载。'
- en: '**Related:**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[MLOps Is Changing How Machine Learning Models Are Developed](/2020/12/mlops-changing-machine-learning-developed.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps正在改变机器学习模型的开发方式](https://www.kdnuggets.com/2020/12/mlops-changing-machine-learning-developed.html)'
- en: '[Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical
    Performance](/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生产机器学习监控：异常值、漂移、解释器和统计性能](https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)'
- en: '[Managing Machine Learning Cycles: Five Learnings from comparing Data Science
    Experimentation/ Collaboration Tools](/2020/01/managing-machine-learning-cycles.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理机器学习周期：从比较数据科学实验/协作工具中获得的五个经验](https://www.kdnuggets.com/2020/01/managing-machine-learning-cycles.html)'
- en: More On This Topic
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多关于此话题
- en: '[Versioning Machine Learning Experiments vs Tracking Them](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[版本控制机器学习实验与跟踪](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
- en: '[How to Package and Distribute Machine Learning Models with MLFlow](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用MLFlow打包和分发机器学习模型](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
- en: '[Developing an Open Standard for Analytics Tracking](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开发分析跟踪的开放标准](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
- en: '[7 Best Tools for Machine Learning Experiment Tracking](https://www.kdnuggets.com/2023/02/7-best-tools-machine-learning-experiment-tracking.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7个最佳机器学习实验跟踪工具](https://www.kdnuggets.com/2023/02/7-best-tools-machine-learning-experiment-tracking.html)'
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据分析：在Databricks中集成GitHub Copilot](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
- en: '[How to Design Experiments for Data Collection](https://www.kdnuggets.com/2022/04/design-experiments-data-collection.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何设计数据收集实验](https://www.kdnuggets.com/2022/04/design-experiments-data-collection.html)'
