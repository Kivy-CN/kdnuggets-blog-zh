- en: Activation maps for deep learning models in a few lines of code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 几行代码中的深度学习模型激活图
- en: 原文：[https://www.kdnuggets.com/2019/10/activation-maps-deep-learning-models-lines-code.html](https://www.kdnuggets.com/2019/10/activation-maps-deep-learning-models-lines-code.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/activation-maps-deep-learning-models-lines-code.html](https://www.kdnuggets.com/2019/10/activation-maps-deep-learning-models-lines-code.html)
- en: '[comments](#comments)![Figure](../Images/172d14ff552ce3f79ca30349d8fb3b5d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图示](../Images/172d14ff552ce3f79ca30349d8fb3b5d.png)'
- en: 'Deep learning has a bad rep: ‘black-box’'
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习有个不好的名声：‘黑箱’
- en: '**D**eep **L**earning (DL) models are [revolutionizing the business and technology
    world with jaw-dropping performances](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/) in
    one application area after another — image classification, object detection, object
    tracking, pose recognition, video analytics, synthetic picture generation — just
    to name a few.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度** **学习** (DL) 模型正在[以令人惊叹的表现](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)在一个接一个的应用领域——图像分类、目标检测、目标跟踪、姿态识别、视频分析、合成图片生成——彻底革新商业和技术世界。'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: However, they are like anything but classical **M**achine **L**earning (ML)
    algorithms/techniques. DL models use millions of parameters and create extremely
    complex and highly nonlinear internal representations of the images or datasets
    that are fed to these models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们与经典的**机器** **学习** (ML) 算法/技术截然不同。DL 模型使用数百万个参数，创建图像或数据集的极其复杂且高度非线性的内部表示。
- en: They are, therefore, often called the [**perfect black-box ML techniques**](https://www.wired.com/story/inside-black-box-of-neural-network/).
    We can get highly accurate predictions from them after we train them with large
    datasets, but [**we have little hope of understanding the internal features and
    representations**](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)of
    the data that a model uses to classify a particular image into a category.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，它们常被称为[**完美的黑箱 ML 技术**](https://www.wired.com/story/inside-black-box-of-neural-network/)。我们在用大数据集训练它们后可以获得高度准确的预测，但[**我们几乎无法理解模型用来将特定图像分类到某一类别的内部特征和表示**](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)。
- en: '![Figure](../Images/228630f7ce878a88a50a6d3e86d74745.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/228630f7ce878a88a50a6d3e86d74745.png)'
- en: '**Source**: [CMU ML blog](https://blog.ml.cmu.edu/2019/05/17/explaining-a-black-box-using-deep-variational-information-bottleneck-approach/)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源**：[CMU ML 博客](https://blog.ml.cmu.edu/2019/05/17/explaining-a-black-box-using-deep-variational-information-bottleneck-approach/)'
- en: Black-box problem of deep learning — predictive power without an intuitive and
    easy-to-follow explanation.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 深度学习的黑箱问题——预测能力强但缺乏直观易懂的解释。
- en: This does not bode well because [we, humans, are visual creatures](https://www.seyens.com/humans-are-visual-creatures/).
    Millions of years of evolution have gifted us an [amazingly complex pair of eyes](https://www.relativelyinteresting.com/irreducible-complexity-intelligent-design-evolution-and-the-eye/) and
    an even more complex [visual cortex](https://www.neuroscientificallychallenged.com/blog/know-your-brain-primary-visual-cortex),
    and we use those organs for making sense of the world.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不吉利，因为[我们，人类，是视觉生物](https://www.seyens.com/humans-are-visual-creatures/)。数百万年的进化赋予了我们一对[极其复杂的眼睛](https://www.relativelyinteresting.com/irreducible-complexity-intelligent-design-evolution-and-the-eye/)和更复杂的[视觉皮层](https://www.neuroscientificallychallenged.com/blog/know-your-brain-primary-visual-cortex)，我们用这些器官来理解世界。
- en: '![Figure](../Images/2dd409def7456c9d29aee92c4297bb0a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2dd409def7456c9d29aee92c4297bb0a.png)'
- en: '**Source**: Wikimedia'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源**：Wikimedia'
- en: The scientific process starts with observation, and that is almost always synonymous
    with vision. In business, only what we can observe and measure, we can control
    and manage effectively.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 科学过程从观察开始，这几乎总是与视觉同义。在商业中，只有我们能够观察和测量的东西，我们才能有效地控制和管理。
- en: Seeing/observing is how we start to [make mental models of worldly phenomena](https://medium.com/personal-growth/mental-models-898f70438075),
    classify objects around us, separate a friend from a foe, love, work, and play.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 看到/观察是我们开始[构建世界现象的心理模型](https://medium.com/personal-growth/mental-models-898f70438075)、分类周围的物体、区分朋友和敌人、爱、工作和玩耍的方式。
- en: Visualization helps a lot. Especially, for deep learning.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 可视化非常有帮助，尤其是对于深度学习。
- en: Therefore, a ‘black box’ DL model, where we cannot visualize the inner workings,
    often draws some criticism.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，那些我们无法可视化内部工作原理的‘黑箱’深度学习模型，常常受到一些批评。
- en: Activation maps
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 激活图
- en: Among various deep learning architectures, perhaps the most prominent one is
    the so-called **C**onvolutional **N**eural **N**etwork (CNN). [It has emerged
    as the workhorse for analyzing high-dimensional, unstructured data](https://www.flatworldsolutions.com/data-science/articles/7-applications-of-convolutional-neural-networks.php) —
    image, text, or audio — which has traditionally posed severe challenges for classical
    ML (non-deep-learning) or hand-crafted (non-ML) algorithms.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种深度学习架构中，也许最突出的就是所谓的**卷积神经网络**（CNN）。[它已经成为分析高维、非结构化数据的主力军](https://www.flatworldsolutions.com/data-science/articles/7-applications-of-convolutional-neural-networks.php)——图像、文本或音频——这些数据传统上对经典的机器学习（非深度学习）或手工制作（非机器学习）算法构成了严峻的挑战。
- en: Several approaches for understanding and visualizing CNN have been developed
    in the[ literature](https://arxiv.org/pdf/1806.00069.pdf), partly as a response
    to the common criticism that the learned internal features in a CNN are not interpretable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 了解和可视化 CNN 的几种方法已在[文献](https://arxiv.org/pdf/1806.00069.pdf)中提出，部分是为了回应对 CNN
    中学习到的内部特征不可解释的普遍批评。
- en: '**The most straight-forward visualization technique is to show the activations** of
    the network during the forward pass.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**最直接的可视化技术是展示网络在前向传播过程中的激活**。'
- en: So, what are activation anyway?
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么，激活究竟是什么呢？
- en: At a simple level, activation functions help decide whether a neuron should
    be activated. This helps determine whether the information that the neuron is
    receiving is relevant for the input. The activation function is a non-linear transformation
    that happens over an input signal, and the transformed output is sent to the next
    neuron.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单层面上，激活函数帮助决定一个神经元是否应该被激活。这有助于判断神经元接收到的信息是否对输入相关。激活函数是对输入信号进行的非线性变换，变换后的输出被发送到下一个神经元。
- en: If you want to understand what precisely, these activations mean, and why are
    they placed in the neural net architecture in the first place, check out this
    article,
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想准确理解这些激活的含义，以及它们为何最初被放置在神经网络架构中，请查看这篇文章，
- en: '**[Fundamentals of Deep Learning - Activation Functions and When to Use Them?](https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/?source=post_page-----ed9ced1e8d21----------------------)**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**[深度学习基础 - 激活函数及其使用时机？](https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/?source=post_page-----ed9ced1e8d21----------------------)**'
- en: Introduction Internet provides access to a plethora of information today. Whatever
    we need is just a Google (search)…
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍 互联网如今提供了大量的信息。我们所需的一切仅需通过 Google（搜索）即可获得…
- en: Below is a fantastic video by the renowned data scientist [Brandon Rohrer](https://brohrer.github.io/blog.html) about
    the basic mechanism of a CNN i.e. how a given input (say a two-dimensional image)
    is processed layer by layer. At each layer, the output is generated by passing
    the transformed input through an activation function.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是著名数据科学家[布兰登·罗赫](https://brohrer.github.io/blog.html)关于 CNN 基本机制的精彩视频，即给定输入（例如二维图像）如何逐层处理。在每一层，输出是通过激活函数传递变换后的输入生成的。
- en: Activation maps are just a visual representation of these activation numbers
    at various layers of the network as a given image progresses through as a result
    of various linear algebraic operations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 激活图只是这些激活数字在网络不同层中的可视化表示，作为图像通过各种线性代数操作处理的结果。
- en: For ReLU activation based networks, the activations usually start out looking
    relatively blobby and dense, but as the training progresses the activations usually
    become more sparse and localized. One design pitfall that can be easily caught
    with this visualization is that some activation maps may be all zero for many
    different inputs, which can indicate *dead* filters and can be a symptom of high
    learning rates.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于ReLU激活的网络，激活通常开始时看起来相对模糊且密集，但随着训练的进行，激活通常变得更稀疏和局部化。一个可以通过这种可视化轻松发现的设计陷阱是，一些激活图对于许多不同的输入可能全部为零，这可能表明*死亡*的滤波器，并可能是高学习率的症状。
- en: Activation maps are just a visual representation of these activation numbers
    at various layers of the network.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 激活图只是这些激活数在网络各层上的视觉表示。
- en: Sounds good. **But visualizing these activation maps is a non-trivial task**,
    even after you have trained your neural net well and are making predictions out
    of it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来不错。**但可视化这些激活图是一个复杂的任务**，即使在你已经很好地训练了神经网络并进行预测之后。
- en: How do you easily visualize and show these activation maps for a reasonably
    complicated CNN with just a few lines of code?
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如何通过几行代码轻松可视化和展示这些激活图，适用于一个相当复杂的CNN？
- en: Activation maps with a few lines of code
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过几行代码生成激活图
- en: The whole [**Jupyter notebook is here**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keract-activation.ipynb).
    Feel free to fork and expand (and leave a star for the repository if you like
    it).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 整个[**Jupyter笔记本在这里**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keract-activation.ipynb)。随意克隆和扩展（如果你喜欢，给仓库留个星）。
- en: A compact function and a nice little library
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个紧凑的函数和一个好用的小库
- en: I showed previously in an article, how to write a single compact function for
    obtaining a fully trained CNN model by reading image files one by one automatically
    from your disk, by utilizing some amazing utility methods and classes offered
    by Keras library.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我在之前的文章中展示了如何编写一个紧凑的函数，通过利用Keras库提供的一些神奇的实用方法和类，自动从磁盘逐个读取图像文件来获得一个完全训练的CNN模型。
- en: '**Do check out this article, because, without it, you cannot train arbitrary
    models with arbitrary image datasets in a compact manner, as described in this
    article**.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**请查看这篇文章，因为没有它，你不能以紧凑的方式训练任意模型与任意图像数据集，如本文所述**。'
- en: '**[A single function to streamline image classification with Keras](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df?source=post_page-----ed9ced1e8d21----------------------)**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**[一个简化Keras图像分类的函数](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df?source=post_page-----ed9ced1e8d21----------------------)**'
- en: We show, how to construct a single, generalized, utility function to pull images
    automatically from a directory and…
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了如何构建一个通用的实用函数，从目录中自动提取图像，并…
- en: Next, we use this function along with a [nice little library called **Keract**](https://github.com/philipperemy/keract),
    which makes the visualization of activation maps super easy. It is a high-level
    accessory library to Keras library to show useful heatmaps and activation maps
    on various layers of a neural network.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用这个函数和一个叫做**Keract**的小库，它使得激活图的可视化变得非常简单。它是Keras库的一个高级附加库，用于在神经网络的各种层上展示有用的热图和激活图。
- en: '![](../Images/7f9b95d5762d427bbc693c00547d8031.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f9b95d5762d427bbc693c00547d8031.png)'
- en: Therefore, for this code, we need to use a couple of utility functions from
    my `utils.DL_utils` module - `train_CNN_keras` and `preprocess_image` to make
    a random RGB image compatible for generating the activation maps (these were described
    in the article mentioned above).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于这段代码，我们需要使用我`utils.DL_utils`模块中的几个实用函数——`train_CNN_keras`和`preprocess_image`，使随机RGB图像适合生成激活图（这些函数在上文提到的文章中进行了描述）。
- en: '[**Here is the Python module — **](https://raw.githubusercontent.com/tirthajyoti/Deep-learning-with-Python/master/Notebooks/utils/DL_utils.py)`[**DL_utils.py**](https://raw.githubusercontent.com/tirthajyoti/Deep-learning-with-Python/master/Notebooks/utils/DL_utils.py)`.
    You can store in your local drive and import the functions as usual.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这是Python模块 —**](https://raw.githubusercontent.com/tirthajyoti/Deep-learning-with-Python/master/Notebooks/utils/DL_utils.py)`[**DL_utils.py**](https://raw.githubusercontent.com/tirthajyoti/Deep-learning-with-Python/master/Notebooks/utils/DL_utils.py)`。你可以将其存储在本地驱动器中，并像往常一样导入这些函数。'
- en: The dataset
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集
- en: For training, we are using the famous **Caltech-101 dataset** from [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).
    This dataset was somewhat a **precursor to the **[**ImageNet database**](http://image-net.org/),
    which is the current gold standard for image classification data repository.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练，我们使用了著名的 **Caltech-101 数据集**，来自 [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)。该数据集在某种程度上是
    **[ImageNet 数据库](http://image-net.org/)** 的前身，后者是当前图像分类数据存储库的金标准。
- en: '![](../Images/8359b9ee76f7e1baadf3f4b32d961dbe.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8359b9ee76f7e1baadf3f4b32d961dbe.png)'
- en: It is an image dataset of diverse types of objects belonging to 101 categories.
    There are about 40 to 800 images per category. Most categories have about 50 images.
    The size of each image is roughly 300 x 200 pixels.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个包含 101 类对象的多样化图像数据集。每个类别大约有 40 到 800 张图像。大多数类别有大约 50 张图像。每张图像的大小大约为 300
    x 200 像素。
- en: However, we are training only with 5 categories of images — *crab, cup, brain,
    camera*, and *chair*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们只训练了 5 种类别的图像——*螃蟹、杯子、大脑、相机* 和 *椅子*。
- en: This is just a random choice for this demo, feel free to choose your own categories.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是为了演示而随机选择的，欢迎自由选择你自己的类别。
- en: Training the model
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: Training is done in a few lines of code only.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 训练仅需几行代码。
- en: A random image of a human brain downloaded from the internet
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从互联网下载的人脑随机图像
- en: For generating the activations, we download a random image of a human brain
    from the internet.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成激活图，我们从互联网上下载了一张人脑的随机图像。
- en: '![](../Images/e1cc6c7c6432e84e966a75c041976532.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1cc6c7c6432e84e966a75c041976532.png)'
- en: Generate the activations (a dictionary)
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成激活（一个字典）
- en: Then, another couple of lines of code to generate the activation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，再写几行代码来生成激活。
- en: We get back a dictionary with layer names as the keys and Numpy arrays as the
    values corresponding to the activations. Below an illustration is shown where
    the activation arrays are shown to have varying lengths corresponding to the size
    of the filter maps of that particular convolutional layer.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会得到一个字典，字典的键是层名称，值是对应于激活的 Numpy 数组。下面的插图展示了激活数组的长度因特定卷积层的滤波器图的大小而有所不同。
- en: '![](../Images/e1e45d99f81c3869ca6b14a5a8bd9187.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1e45d99f81c3869ca6b14a5a8bd9187.png)'
- en: Display the activations
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 展示激活
- en: Again, a single line of code,
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，一行代码，
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We get to see activation maps layer by layer. Here is the first convolutional
    layer (**16 images corresponding to the 16 filters**)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以逐层查看激活图。这里是第一层卷积层（**16 张图像对应 16 个滤波器**）
- en: '![](../Images/5f4f3379ba06ffb4a3200e1007ea1782.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f4f3379ba06ffb4a3200e1007ea1782.png)'
- en: And, here is layer number 2 (**32 images corresponding to the 32filters**)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第 2 层（**32 张图像对应 32 个滤波器**）
- en: '![](../Images/ba89486af99001bec03612730c27143a.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba89486af99001bec03612730c27143a.png)'
- en: We have 5 convolutional layers (followed by Max pooling layers) in this model,
    and therefore, we get back 10 sets of images. For brevity, I am not showing the
    rest but you can see them all in my Github repo here.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个模型中有 5 层卷积层（后跟最大池化层），因此，我们会得到 10 组图像。为简洁起见，我没有展示其余的图像，但你可以在我的 GitHub 仓库中查看所有图像。
- en: Heatmaps
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 热力图
- en: You can also show the activations as heatmaps.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将激活图展示为热力图。
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/184d2017bb4c94276a95a1bbf687f1dc.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/184d2017bb4c94276a95a1bbf687f1dc.png)'
- en: 'Update: Quiver'
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更新：Quiver
- en: After writing this article last week, I found out about another beautiful library
    for activation visualization called [**Quiver**](https://github.com/keplr-io/quiver).
    However, this one is built on the Python microserver framework Flask and displays
    the activation maps on a browser port rather than inside your Jupyter Notebook.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上周写完这篇文章后，我发现了另一个漂亮的激活可视化库，名为 [**Quiver**](https://github.com/keplr-io/quiver)。不过，这个库是基于
    Python 微服务器框架 Flask 构建的，它会在浏览器端口上显示激活图，而不是在 Jupyter Notebook 内部。
- en: They also need a trained Keras model as input. So, you can easily use the compact
    function described in this article (from my [DL_uitls module](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/utils/DL_utils.py))
    and try this library for interactive visualization of activation maps.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 它们还需要一个经过训练的 Keras 模型作为输入。所以，你可以轻松使用本文描述的紧凑函数（来自我的 [DL_uitls 模块](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/utils/DL_utils.py)），并尝试这个库以进行激活图的交互式可视化。
- en: '![](../Images/20f533df1b28d1fd7fd6d9a0b9c266fa.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20f533df1b28d1fd7fd6d9a0b9c266fa.png)'
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: That’s it, for now.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，目前为止。
- en: The whole [**Jupyter notebook is here**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keract-activation.ipynb).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的[**Jupyter笔记本在这里**](https://github.com/tirthajyoti/Deep-learning-with-Python/blob/master/Notebooks/Keract-activation.ipynb)。
- en: We showed, how using only a few lines of code (utilizing compact functions from
    a special module and a nice little accessory library to Keras) we can train a
    CNN, generate activation maps, and display them layer by layer — from scratch.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了如何仅用几行代码（利用来自特殊模块的紧凑函数和Keras的小配件库）来训练CNN，生成激活图，并逐层显示——从头开始。
- en: This gives you the ability to train CNN models (simple to complex) from any
    image dataset (as long as you can arrange it in a simple format) and look inside
    their guts for any test image you want.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这使你能够从任何图像数据集中训练CNN模型（从简单到复杂，只要你可以将其整理成简单的格式），并查看你想要的任何测试图像的内部。
- en: For more of such hands-on tutorials, [**check my Deep-Learning-with-Python Github
    repo**](https://github.com/tirthajyoti/Deep-learning-with-Python).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 欲获取更多此类动手教程，请[**查看我的深度学习与Python GitHub仓库**](https://github.com/tirthajyoti/Deep-learning-with-Python)。
- en: If you have any questions or ideas to share, please contact the author at [**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com).
    Also, you can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    other fun code snippets in Python, R, and machine learning resources. If you are,
    like me, passionate about machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter.](https://twitter.com/tirthajyotiS)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或想法，请通过[**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com)与作者联系。你还可以查看作者的[**GitHub**](https://github.com/tirthajyoti?tab=repositories)** 仓库**，获取其他有趣的Python、R代码片段和机器学习资源。如果你像我一样，对机器学习/数据科学充满热情，请随时[在LinkedIn上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)或[在Twitter上关注我](https://twitter.com/tirthajyotiS)。
- en: '[Original](https://towardsdatascience.com/activation-maps-for-deep-learning-models-in-a-few-lines-of-code-ed9ced1e8d21).
    Reposted with permission.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/activation-maps-for-deep-learning-models-in-a-few-lines-of-code-ed9ced1e8d21)。转载许可。'
- en: '**Related:**'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Overcoming Deep Learning Stumbling Blocks](/2019/10/overcoming-deep-learning-stumbling-blocks.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克服深度学习中的障碍](/2019/10/overcoming-deep-learning-stumbling-blocks.html)'
- en: '[Evolving Deep Neural Networks](/2019/06/evolving-deep-neural-networks.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[演变的深度神经网络](/2019/06/evolving-deep-neural-networks.html)'
- en: '[Research Guide for Neural Architecture Search](/2019/10/research-guide-neural-architecture-search.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络架构搜索研究指南](/2019/10/research-guide-neural-architecture-search.html)'
- en: More On This Topic
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，然后寻找目标……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学学习统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90亿美元的AI失败，详解](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使Python成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
