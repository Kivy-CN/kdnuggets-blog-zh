# Pandas的增强版：使用Dask进行端到端的数据科学

> 原文：[https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html](https://www.kdnuggets.com/2020/11/pandas-steroids-dask-python-data-science.html)

[评论](#comments)

**作者 [Ravi Shankar](https://www.linkedin.com/in/ravi-shankar-83863441/)，数据科学家**

![图示](../Images/2dba06d5b5ef5894865533eb15a7b35a.png)Dask - 功能增强的Pandas

* * *

## 我们的前3个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT需求

* * *

俗话说，数据科学家花90%的时间清理数据，10%的时间抱怨数据。他们的抱怨可能涉及数据规模、数据分布错误、空值、数据随机性、数据捕获中的系统性错误、训练集和测试集之间的差异，等等。

一个常见的瓶颈问题是数据规模庞大，这导致数据无法完全加载到内存中，或者处理时间非常长（以分钟计），使得固有的模式分析变得无效。数据科学家本质上是好奇的人，他们希望识别和解读那些通常被粗略的拖放视图隐藏的模式。他们需要扮演多重角色，通过反复的“折磨”（即多次迭代）让数据吐露真相。

在探索性数据分析过程中，他们扮演了多个角色，并且从包含6列的纽约出租车费用数据集（[https://www.kaggle.com/c/new-york-city-taxi-fare-prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction)）中，他们可能会提出以下问题：

> 1.  费用年年变化如何？
> 1.  
> 1.  近年来旅行次数是否增加？
> 1.  
> 1.  人们更喜欢独自旅行还是有伴同行？
> 1.  
> 1.  随着人们变得更加懒散，短途旅行是否增加了？
> 1.  
> 1.  人们一天中的哪个时间和一周中的哪一天想要旅行？
> 1.  
> 1.  最近除了常规的机场接送外，城市中是否出现了新的热点？
> 1.  
> 1.  人们是否进行更多的城市间旅行？
> 1.  
> 1.  交通量是否增加导致相同距离的费用/时间增加？
> 1.  
> 1.  是否存在高流量的接送点或区域？
> 1.  
> 1.  数据中是否存在离群值，例如0距离和超过$100的费用等？
> 1.  
> 1.  节假日季节和机场旅行的需求是否发生变化？
> 1.  
> 1.  天气（如雨雪）与出租车需求之间是否存在相关性？

即使回答了这些问题，仍然可能会出现多个子线程，例如我们是否能预测受 Covid 影响的跨年会怎样，年度纽约马拉松如何影响出租车需求，特定路线是否更容易出现多名乘客（派对中心）与单一乘客（机场到郊区）。

为了满足这些好奇心，时间至关重要，让数据科学家等待超过 5 分钟来读取一个包含 5500 万行的 CSV 文件或进行列添加及聚合是犯罪行为。此外，由于大多数数据科学家都是自学成才的，他们已经非常习惯 Pandas 数据框 API，不愿意从头开始学习不同的 API，比如 numba、Spark 或 datatable。我尝试过在 DPLYR（R）、Pandas（Python）和 pyspark（Spark）之间切换，但考虑到对统一流程和代码语法的需求，这有些不尽如人意。不过，对于好奇的人，我在这里写了一个 pyspark 入门指南：[https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)

在接下来的部分中，我尝试提供一个 Dask 的实践指南，并尽可能少地改变我们钟爱的 Pandas 架构：

### **1\. 数据读取与分析**

Dask 与 Pandas 的速度对比

Dask 如何能使数据处理速度提高约 90 倍，即从 Pandas 的 1 秒以下到 91 秒。

![图示](../Images/76f6d452602d9621a742e24474e658c1.png)*来源: *[*https://dask.org/*](https://dask.org/)

Dask 之所以如此受欢迎，是因为它使 Python 中的分析可扩展，而不需要在 SQL、Scala 和 Python 之间来回切换。这个神奇的特性是，这个工具需要的代码更改最小。它将计算分解为 Pandas 数据框，从而并行操作以实现快速计算。

![图示](../Images/643af4e780c97b3377bbe76e9f67246e.png)*来源:* [*https://docs.dask.org/en/latest/*](https://docs.dask.org/en/latest/)

### **2\. 数据聚合**

在完全不改变 Pandas API 的情况下，它能够在毫秒级别进行聚合和排序。请注意，**compute()** 函数用于延迟计算的最后阶段，将大数据的结果载入 Pandas 数据框内存。

### **3\. 机器学习**

以下代码片段提供了一个在 Dask 中使用 XGBoost 进行特征工程和 ML 模型构建的工作示例

使用 Dask 进行特征工程和机器学习模型

### **结论：**

Dask 是一个强大的工具，提供并行计算、大数据处理和创建端到端数据科学管道的功能。它的学习曲线较陡，因为 API 几乎与 Pandas 相似，并且能够像风一样处理超出内存的计算（约 10 倍 RAM）。

由于这是一个活跃的博客，我将会继续编写Dask系列的后续部分，我们将利用并行处理来争夺Kaggle排行榜。如果你在设置Dask时遇到任何问题，或者无法执行任何Dask操作，甚至只是想聊聊天，请在评论中告诉我。祝学习愉快！

来源：

1.  [https://ml.dask.org/](https://ml.dask.org/)

1.  [https://dask.org/](https://dask.org/)

1.  [https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2](https://medium.com/@ravishankar_22148/billions-of-rows-milliseconds-of-time-pyspark-starter-guide-c1f984023bf2)

1.  [https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138](https://towardsdatascience.com/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138)

1.  [https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask](https://www.kaggle.com/yuliagm/how-to-work-with-big-datasets-on-16g-ram-dask)

1.  [https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57](https://medium.com/better-programming/what-is-dask-and-how-can-it-help-you-as-a-data-scientist-72adec7cec57)

**简历： [拉维·香卡](https://www.linkedin.com/in/ravi-shankar-83863441/)** 是亚马逊定价部门的数据科学家-II。

[原文](https://medium.com/analytics-vidhya/pandas-on-steroids-dask-end-to-end-data-science-with-python-code-1845d3722c8a)。经许可转载。

**相关：**

+   [Dask中的机器学习](/2020/06/machine-learning-dask.html)

+   [云中的数据科学与Dask](/2020/10/data-science-cloud-dask.html)

+   [为什么以及如何在大数据中使用Dask](/2020/04/dask-big-data.html)

### 更多相关话题

+   [成为伟大的数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [停止学习数据科学，寻找目的，然后为了…寻找目的](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)
