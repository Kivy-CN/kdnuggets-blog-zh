# 在TensorFlow中剪枝机器学习模型

> 原文：[https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html](https://www.kdnuggets.com/2020/12/pruning-machine-learning-models-tensorflow.html)

[评论](#comments)

[在上一篇文章中](https://heartbeat.fritz.ai/research-guide-pruning-techniques-for-neural-networks-d9b8440ab10d)，我们回顾了一些关于神经网络剪枝的权威文献。我们了解到，剪枝是一种模型优化技术，涉及消除权重张量中不必要的值。这导致模型更小，但准确性非常接近基线模型。

在这篇文章中，我们将通过一个示例来应用剪枝，并查看对最终模型大小和预测误差的影响。

### 导入常见模块

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT

* * *

我们的第一步是处理几个导入：

+   `Os`和`Zipfile`将帮助我们评估模型的大小。

+   `tensorflow_model_optimization` 用于模型剪枝。

+   `load_model` 用于加载已保存的模型。

+   当然，还需要`tensorflow`和`keras`。

最后，我们初始化TensorBoard，以便可视化模型：

```py
import os
import zipfile
import tensorflow as tf
import tensorflow_model_optimization as tfmot
from tensorflow.keras.models import load_model
from tensorflow import keras
%load_ext tensorboard
```

### 数据集生成

对于这个实验，我们将使用scikit-learn生成一个回归数据集。之后，我们将数据集分成训练集和测试集：

```py
from sklearn.datasets import make_friedman1
X, y = make_friedman1(n_samples=10000, n_features=10, random_state=0)from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

### 剪枝前的模型

我们将创建一个简单的神经网络来预测目标变量`y`。然后我们将检查均方误差。之后，我们将与整个模型剪枝后的结果进行比较，然后再与仅剪枝`Dense`层的结果进行比较。

接下来，我们设置一个回调函数，在训练停止改进后（30个epoch后）停止训练模型。

```py
early_stop = keras.callbacks.EarlyStopping(monitor=’val_loss’, patience=30)
```

让我们打印出模型的摘要，以便与剪枝后的模型摘要进行比较。

```py
model = setup_model()model.summary()
```

![文章图片](../Images/2557a1d142f91122421703dfb64bc1dd.png)

让我们编译模型并进行训练。

```py
model.compile(optimizer=’adam’,
 loss=tf.keras.losses.mean_squared_error,
 metrics=[‘mae’, ‘mse’])model.fit(X_train,y_train,epochs=300,validation_split=0.2,callbacks=early_stop,verbose=0)
```

由于这是一个回归问题，我们正在监控平均绝对误差和均方误差。

这是绘制到图像上的模型。输入是10，因为我们生成的数据集有10个特征。

```py
tf.keras.utils.plot_model(
 model,
 to_file=”model.png”,
 show_shapes=True,
 show_layer_names=True,
 rankdir=”TB”,
 expand_nested=True,
 dpi=96,
)
```

![文章图片](../Images/17359d8f180680b7254944b99f740797.png)

现在让我们检查均方误差。我们可以继续下一部分，看看在剪枝整个模型时误差如何变化。

```py
from sklearn.metrics import mean_squared_errorpredictions = model.predict(X_test)print(‘Without Pruning MSE %.4f’ % mean_squared_error(y_test,predictions.reshape(3300,)))Without Pruning MSE 0.0201
```

### 使用ConstantSparsity剪枝计划剪枝整个模型

让我们将上面的均方误差与剪枝整个模型后获得的均方误差进行比较。第一步是定义剪枝参数。权重剪枝是基于幅度的。这意味着在训练过程中，一些权重会被转换为零。模型变得稀疏，因此更容易压缩。稀疏模型还使推理速度更快，因为可以跳过零值。

预期的参数包括剪枝计划、块大小和块池化类型。

+   在这种情况下，我们设置了50% [剪枝稀疏度](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/ConstantSparsity)，这意味着50%的权重将被置为零。

+   `block_size` — 块的尺寸（高度，宽度）

    矩阵权重张量中的稀疏模式。

+   `block_pooling_type` — 用于在中池化权重的函数

    block。必须是 `AVG` 或 `MAX`。

我们现在可以通过应用剪枝参数来剪枝整个模型。

让我们检查模型摘要。将其与未剪枝模型的摘要进行比较。从下图中我们可以看到整个模型已被剪枝——稍后我们会看到剪枝一个密集层后的摘要差异。

```py
model_to_prune.summary()
```

![图像](../Images/600a83cad46033ad4505372e7850a817.png)

我们必须在将模型拟合到训练集和测试集之前编译模型。

```py
model_to_prune.compile(optimizer=’adam’,
 loss=tf.keras.losses.mean_squared_error,
 metrics=[‘mae’, ‘mse’])
```

由于我们正在应用剪枝，我们必须定义几个剪枝回调函数，除了早期停止回调函数。我们定义日志模型的文件夹，然后创建一个包含回调函数的列表。

`tfmot.sparsity.keras.UpdatePruningStep()` 通过优化器步骤更新剪枝包装器。不指定它会导致错误。

`tfmot.sparsity.keras.PruningSummaries()` 将剪枝摘要添加到 Tensorboard。

```py
log_dir = ‘.models’
callbacks = [
 tfmot.sparsity.keras.UpdatePruningStep(),
 # Log sparsity and other metrics in Tensorboard.
 tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir),
 keras.callbacks.EarlyStopping(monitor=’val_loss’, patience=10)
]
```

处理完这些后，我们现在可以将模型拟合到训练集。

```py
model_to_prune.fit(X_train,y_train,epochs=100,validation_split=0.2,callbacks=callbacks,verbose=0)
```

检查此模型的均方误差时，我们注意到它略高于未剪枝模型的均方误差。

```py
prune_predictions = model_to_prune.predict(X_test)print(‘Whole Model Pruned MSE %.4f’ % mean_squared_error(y_test,prune_predictions.reshape(3300,)))Whole Model Pruned MSE  0.1830
```

### 仅使用多项式衰减剪枝计划剪枝密集层

现在让我们实现相同的模型——但这次我们只剪枝密集层。请注意在剪枝计划中使用了 `[PolynomialDecay](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay)`[ 函数](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay)。

从摘要中，我们可以看到只有第一个密集层会被剪枝。

```py
model_layer_prunning.summary()
```

![图像](../Images/cb575b67fcf38555ae54a9132353e9bc.png)

然后我们编译并拟合模型。

```py
model_layer_prunning.compile(optimizer=’adam’,
 loss=tf.keras.losses.mean_squared_error,
 metrics=[‘mae’, ‘mse’])model_layer_prunning.fit(X_train,y_train,epochs=300,validation_split=0.1,callbacks=callbacks,verbose=0)
```

现在，让我们检查均方误差。

```py
layer_prune_predictions = model_layer_prunning.predict(X_test)print(‘Layer Prunned MSE %.4f’ % mean_squared_error(y_test,layer_prune_predictions.reshape(3300,)))Layer Prunned MSE 0.1388
```

我们不能将这里获得的 MSE 与之前的结果进行比较，因为我们使用了不同的修剪参数。如果你想进行比较，请确保修剪参数相似。在测试中，`layer_pruning_params` 在这个特定案例中给出的错误比 `pruning_params` 更低。比较不同修剪参数得到的 MSE 是有用的，以便你选择不会使模型性能变差的参数。

### 比较模型大小

现在让我们比较修剪前后模型的大小。我们从训练和保存模型权重开始，以备后用。

我们将设置我们的基础模型并加载已保存的权重。然后对整个模型进行修剪。我们编译、拟合模型，并在 TensorBoard 上可视化结果。

这里是来自 TensorBoard 的修剪总结的单个快照。

![文章图片](../Images/869fe54127f831eb2c443bd69ffb8251.png)

其他修剪总结也可以在 TensorBoard 上查看。

![文章图片](../Images/1df0795bf97341e8e19402d6820ba186.png)

现在让我们定义一个函数来计算模型的大小。

现在我们定义模型以进行导出，然后计算模型的大小。

对于修剪后的模型，`tfmot.sparsity.keras.strip_pruning()` 用于恢复具有稀疏权重的原始模型。请注意修剪和未修剪模型之间的大小差异。

```py
model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)
```

```py
Size of gzipped pruned model without stripping: 6101.00 bytes
Size of gzipped pruned model with stripping: 5140.00 bytes
```

对两个模型进行预测，我们发现它们具有相同的均方误差。

```py
Model for Prunning Error 0.0264
Model for Export Error  0.0264
```

### 最终想法

你可以继续测试不同修剪计划如何影响模型的大小。显然，这里的观察结果并非普遍适用。你需要尝试不同的修剪参数，了解它们如何影响你的模型大小、预测误差和/或准确性，具体取决于你的问题。

为了进一步优化模型，**你可以对其进行量化**。如果你想进一步探索这一点，请查看以下仓库和资源。

### 资源

[**Keras 中的修剪示例 | TensorFlow 模型优化**](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras)

欢迎来到一个基于幅度的权重修剪的端到端示例。有关修剪是什么以及如何…

[**全面修剪指南 | TensorFlow 模型优化**](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide)

TensorFlow Lite 用于移动和嵌入式设备

[**mwitiderrick/Pruning-in-TensorFlow**](https://github.com/mwitiderrick/Pruning-in-TensorFlow)

在本文中，我们逐步应用修剪，并查看其对最终模型大小的影响…

[**8 位量化与 TensorFlow Lite：通过低精度加速移动推断**](https://heartbeat.fritz.ai/8-bit-quantization-and-tensorflow-lite-speeding-up-mobile-inference-with-low-precision-a882dfcafbbd)

heartbeat.fritz.ai

**简历：德里克·穆伊提** 是一位数据科学家，热衷于分享知识。他是数据科学社区的积极贡献者，通过 Heartbeat、Towards Data Science、Datacamp、Neptune AI、KDnuggets 等博客分享内容。他的内容在互联网上的浏览量已超过一百万次。德里克还是一位作者和在线讲师。他还与各种机构合作，实施数据科学解决方案以及提升员工技能。德里克曾在多媒体大学学习数学和计算机科学，也曾是 Meltwater 创业技术学校的校友。如果你对数据科学、机器学习和深度学习的世界感兴趣，或许可以查看他的[完整数据科学与机器学习 Python 课程](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)。

[原文](https://heartbeat.fritz.ai/model-pruning-in-tensorflow-e4e8f5646f6f)。转载许可。

**相关内容：**

+   [使用 TensorFlow Serving 部署训练好的模型](/2020/11/serving-tensorflow-models.html)

+   [处理机器学习中的数据不平衡](/2020/10/imbalanced-data-machine-learning.html)

+   [如何将 PyTorch Lightning 模型部署到生产环境](/2020/11/deploy-pytorch-lightning-models-production.html)

### 更多相关主题

+   [决策树剪枝：为什么和如何](https://www.kdnuggets.com/2022/09/decision-tree-pruning-hows-whys.html)

+   [PyTorch 还是 TensorFlow？比较流行的机器学习框架](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)

+   [TensorFlow 在计算机视觉中的应用 - 迁移学习简化](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)

+   [Tensorflow 的“Hello World”](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)

+   [使用 Tensorflow 训练图像分类模型的指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)

+   [使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)
