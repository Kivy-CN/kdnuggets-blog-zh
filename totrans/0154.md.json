["```py\nmkdir GPT4ALL_Fabio\ncd GPT4ALL_Fabio\n```", "```py\npython3 -m venv .venv\n```", "```py\nsource .venv/bin/activate\n```", "```py\npip install pygpt4all==1.0.1\npip install pyllamacpp==1.0.6\npip install langchain==0.0.149\npip install unstructured==0.6.5\npip install pdf2image==1.16.3\npip install pytesseract==0.3.10\npip install pypdf==3.8.1\npip install faiss-cpu==1.7.4\n```", "```py\npip install -r requirements.txt\n```", "```py\npip install llama-cpp-python\n```", "```py\nfrom pygpt4all.models.gpt4all import GPT4All\n```", "```py\ndef new_text_callback(text):\n    print(text, end=\"\")\n\nmodel = GPT4All('./models/gpt4all-converted.bin')\nmodel.generate(\"Once upon a time, \", n_predict=55, new_text_callback=new_text_callback)\n```", "```py\npython3 pygpt4all_test.py\n```", "```py\n# Import of langchain Prompt Template and Chain\nfrom langchain import PromptTemplate, LLMChain\n\n# Import llm to be able to interact with GPT4All directly from langchain\nfrom langchain.llms import GPT4All\n\n# Callbacks manager is required for the response handling \nfrom langchain.callbacks.base import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nlocal_path = './models/gpt4all-converted.bin' \ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n```", "```py\ntemplate = \"\"\"Question: {question}\n\nAnswer: Let's think step by step on it.\n\n\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n```", "```py\n# Hardcoded question\nquestion = \"What Formula 1 pilot won the championship in the year Leonardo di Caprio was born?\"\n\n# User input question...\nquestion = input(\"Enter your question: \")\n```", "```py\ntemplate = \"\"\"Question: {question}\nAnswer: Let's think step by step on it.\n\"\"\"\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\"])\n\n# initialize the GPT4All instance\nllm = GPT4All(model=local_path, callback_manager=callback_manager, verbose=True)\n\n# link the language model with our prompt template\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\n# Hardcoded question\nquestion = \"What Formula 1 pilot won the championship in the year Leonardo di Caprio was born?\"\n\n# User imput question...\n# question = input(\"Enter your question: \")\n\n#Run the query and get the results\nllm_chain.run(question)\n```", "```py\npython3 my_langchain.py\n```", "```py\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import GPT4All\nfrom langchain.callbacks.base import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\n# function for loading only TXT files\nfrom langchain.document_loaders import TextLoader\n\n# text splitter for create chunks\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# to be able to load the pdf files\nfrom langchain.document_loaders import UnstructuredPDFLoader\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import DirectoryLoader\n\n# Vector Store Index to create our database about our knowledge\nfrom langchain.indexes import VectorstoreIndexCreator\n\n# LLamaCpp embeddings from the Alpaca model\nfrom langchain.embeddings import LlamaCppEmbeddings\n\n# FAISS  library for similaarity search\nfrom langchain.vectorstores.faiss import FAISS\n\nimport os  #for interaaction with the files\nimport datetime\n```", "```py\n# assign the path for the 2 models GPT4All and Alpaca for the embeddings \ngpt4all_path = './models/gpt4all-converted.bin' \nllama_path = './models/ggml-model-q4_0.bin' \n# Calback manager for handling the calls with  the model\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\n# create the embedding object\nembeddings = LlamaCppEmbeddings(model_path=llama_path)\n# create the GPT4All llm object\nllm = GPT4All(model=gpt4all_path, callback_manager=callback_manager, verbose=True)\n```", "```py\n# Split text \ndef split_chunks(sources):\n    chunks = []\n    splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=32)\n    for chunk in splitter.split_documents(sources):\n        chunks.append(chunk)\n    return chunks\n\ndef create_index(chunks):\n    texts = [doc.page_content for doc in chunks]\n    metadatas = [doc.metadata for doc in chunks]\n\n    search_index = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n\n    return search_index\n\ndef similarity_search(query, index):\n    # k is the number of similarity searched that matches the query\n    # default is 4\n    matched_docs = index.similarity_search(query, k=3) \n    sources = []\n    for doc in matched_docs:\n        sources.append(\n            {\n                \"page_content\": doc.page_content,\n                \"metadata\": doc.metadata,\n            }\n        )\n\n    return matched_docs, sources\n```", "```py\n# get the list of pdf files from the docs directory into a list  format\npdf_folder_path = './docs'\ndoc_list = [s for s in os.listdir(pdf_folder_path) if s.endswith('.pdf')]\nnum_of_docs = len(doc_list)\n# create a loader for the PDFs from the path\nloader = PyPDFLoader(os.path.join(pdf_folder_path, doc_list[0]))\n# load the documents with Langchain\ndocs = loader.load()\n# Split in chunks\nchunks = split_chunks(docs)\n# create the db vector index\ndb0 = create_index(chunks)\n```", "```py\npython3 my_knowledge_qna.py\n```", "```py\n# merge dbi with the existing db0\ndb0.merge_from(dbi)\n```", "```py\n# Save the databasae locally\ndb0.save_local(\"my_faiss_index\")\n```", "```py\n# get the list of pdf files from the docs directory into a list  format\npdf_folder_path = './docs'\ndoc_list = [s for s in os.listdir(pdf_folder_path) if s.endswith('.pdf')]\nnum_of_docs = len(doc_list)\n# create a loader for the PDFs from the path\ngeneral_start = datetime.datetime.now() #not used now but useful\nprint(\"starting the loop...\")\nloop_start = datetime.datetime.now() #not used now but useful\nprint(\"generating fist vector database and then iterate with .merge_from\")\nloader = PyPDFLoader(os.path.join(pdf_folder_path, doc_list[0]))\ndocs = loader.load()\nchunks = split_chunks(docs)\ndb0 = create_index(chunks)\nprint(\"Main Vector database created. Start iteration and merging...\")\nfor i in range(1,num_of_docs):\n    print(doc_list[i])\n    print(f\"loop position {i}\")\n    loader = PyPDFLoader(os.path.join(pdf_folder_path, doc_list[i]))\n    start = datetime.datetime.now() #not used now but useful\n    docs = loader.load()\n    chunks = split_chunks(docs)\n    dbi = create_index(chunks)\n    print(\"start merging with db0...\")\n    db0.merge_from(dbi)\n    end = datetime.datetime.now() #not used now but useful\n    elapsed = end - start #not used now but useful\n    #total time\n    print(f\"completed in {elapsed}\")\n    print(\"-----------------------------------\")\nloop_end = datetime.datetime.now() #not used now but useful\nloop_elapsed = loop_end - loop_start #not used now but useful\nprint(f\"All documents processed in {loop_elapsed}\")\nprint(f\"the daatabase is done with {num_of_docs} subset of db index\")\nprint(\"-----------------------------------\")\nprint(f\"Merging completed\")\nprint(\"-----------------------------------\")\nprint(\"Saving Merged Database Locally\")\n# Save the databasae locally\ndb0.save_local(\"my_faiss_index\")\nprint(\"-----------------------------------\")\nprint(\"merged database saved as my_faiss_index\")\ngeneral_end = datetime.datetime.now() #not used now but useful\ngeneral_elapsed = general_end - general_start #not used now but useful\nprint(f\"All indexing completed in {general_elapsed}\")\nprint(\"-----------------------------------\")\n```", "```py\nfrom langchain import PromptTemplate, LLMChain\nfrom langchain.llms import GPT4All\nfrom langchain.callbacks.base import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n# function for loading only TXT files\nfrom langchain.document_loaders import TextLoader\n# text splitter for create chunks\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n# to be able to load the pdf files\nfrom langchain.document_loaders import UnstructuredPDFLoader\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.document_loaders import DirectoryLoader\n# Vector Store Index to create our database about our knowledge\nfrom langchain.indexes import VectorstoreIndexCreator\n# LLamaCpp embeddings from the Alpaca model\nfrom langchain.embeddings import LlamaCppEmbeddings\n# FAISS  library for similaarity search\nfrom langchain.vectorstores.faiss import FAISS\nimport os  #for interaaction with the files\nimport datetime\n\n# TEST FOR SIMILARITY SEARCH\n\n# assign the path for the 2 models GPT4All and Alpaca for the embeddings \ngpt4all_path = './models/gpt4all-converted.bin' \nllama_path = './models/ggml-model-q4_0.bin' \n# Calback manager for handling the calls with  the model\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\n# create the embedding object\nembeddings = LlamaCppEmbeddings(model_path=llama_path)\n# create the GPT4All llm object\nllm = GPT4All(model=gpt4all_path, callback_manager=callback_manager, verbose=True)\n\n# Split text \ndef split_chunks(sources):\n    chunks = []\n    splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=32)\n    for chunk in splitter.split_documents(sources):\n        chunks.append(chunk)\n    return chunks\n\ndef create_index(chunks):\n    texts = [doc.page_content for doc in chunks]\n    metadatas = [doc.metadata for doc in chunks]\n\n    search_index = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n\n    return search_index\n\ndef similarity_search(query, index):\n    # k is the number of similarity searched that matches the query\n    # default is 4\n    matched_docs = index.similarity_search(query, k=3) \n    sources = []\n    for doc in matched_docs:\n        sources.append(\n            {\n                \"page_content\": doc.page_content,\n                \"metadata\": doc.metadata,\n            }\n        )\n\n    return matched_docs, sources\n\n# Load our local index vector db\nindex = FAISS.load_local(\"my_faiss_index\", embeddings)\n# Hardcoded question\nquery = \"What is a PLC and what is the difference with a PC\"\ndocs = index.similarity_search(query)\n# Get the matches best 3 results - defined in the function k=3\nprint(f\"The question is: {query}\")\nprint(\"Here the result of the semantic search on the index, without GPT4All..\")\nprint(docs[0])\n```", "```py\n# Load our local index vector db\nindex = FAISS.load_local(\"my_faiss_index\", embeddings)\n\n# create the prompt template\ntemplate = \"\"\"\nPlease use the following context to answer questions.\nContext: {context}\n---\nQuestion: {question}\nAnswer: Let's think step by step.\"\"\"\n\n# Hardcoded question\nquestion = \"What is a PLC and what is the difference with a PC\"\nmatched_docs, sources = similarity_search(question, index)\n# Creating the context\ncontext = \"\\n\".join([doc.page_content for doc in matched_docs])\n# instantiating the prompt template and the GPT4All chain\nprompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"]).partial(context=context)\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n# Print the result\nprint(llm_chain.run(question))\n```", "```py\nPlease use the following context to answer questions.\nContext: 1.What is a PLC\n2.Where and Why it is used\n3.How a PLC is different from a PC\nPLC is especially important in industries where safety and reliability are\ncritical, such as manufacturing plants, chemical plants, and power plants.\nHow a PLC is different from a PC\nBecause a PLC is a specialized computer used in industrial and\nmanufacturing applications to control machinery and processes.,the\nhardware components of a typical PLC must be able to interact with\nindustrial device. So a typical PLC hardware include:\n---\nQuestion: What is a PLC and what is the difference with a PC\nAnswer: Let's think step by step. 1) A Programmable Logic Controller (PLC), \nalso called Industrial Control System or ICS, refers to an industrial computer \nthat controls various automated processes such as manufacturing \nmachines/assembly lines etcetera through sensors and actuators connected \nwith it via inputs & outputs. It is a form of digital computers which has \nthe ability for multiple instruction execution (MIE), built-in memory \nregisters used by software routines, Input Output interface cards(IOC) \nto communicate with other devices electronically/digitally over networks \nor buses etcetera\n2). A Programmable Logic Controller is widely utilized in industrial \nautomation as it has the ability for more than one instruction execution. \nIt can perform tasks automatically and programmed instructions, which allows \nit to carry out complex operations that are beyond a \nPersonal Computer (PC) capacity. So an ICS/PLC contains built-in memory \nregisters used by software routines or firmware codes etcetera but \nPC doesn't contain them so they need external interfaces such as \nhard disks drives(HDD), USB ports, serial and parallel \ncommunication protocols to store data for further analysis or \nreport generation.\n```", "```py\nquestion = \"What is a PLC and what is the difference with a PC\"\n```", "```py\nquestion = input(\"Your question: \")\n```"]