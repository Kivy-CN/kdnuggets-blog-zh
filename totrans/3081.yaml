- en: Why Automated Feature Engineering Will Change the Way You Do Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么自动化特征工程将改变你进行机器学习的方式
- en: 原文：[https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html](https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html](https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [William Koehrsen](https://twitter.com/koehrsen_will), Feature Labs**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [William Koehrsen](https://twitter.com/koehrsen_will), Feature Labs**'
- en: '![Image](../Images/1aaf5ba4e7a7004049c3debb7a5c0f6c.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/1aaf5ba4e7a7004049c3debb7a5c0f6c.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There are few certainties in data science — libraries, tools, and algorithms
    constantly change as better methods are developed. However, one trend that is
    not going away is the move towards *increased levels of automation.*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中有很少的确定性——库、工具和算法随着更好方法的开发而不断变化。然而，一个不会消失的趋势是*自动化水平的提高*。
- en: Recent years have seen progress in [automating model selection](https://epistasislab.github.io/tpot/api/) and [hyperparameter
    tuning](https://github.com/automl), but the [most important aspect](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) of
    the machine learning pipeline, [feature engineering](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html),
    has largely been neglected. The most capable entry in this critical field is [Featuretools](https://docs.featuretools.com/#minute-quick-start),
    an open-source Python library. In this article, we’ll use this library to see
    how automated feature engineering will change the way you do machine learning
    for the better.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，[自动化模型选择](https://epistasislab.github.io/tpot/api/)和[超参数调整](https://github.com/automl)取得了进展，但机器学习管道的[最重要方面](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)，即[特征工程](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html)，却在很大程度上被忽视了。这个关键领域中最有能力的工具是[Featuretools](https://docs.featuretools.com/#minute-quick-start)，一个开源
    Python 库。在本文中，我们将使用这个库来看看自动化特征工程将如何改善你进行机器学习的方式。
- en: '![](../Images/10c12c4dcee741fb89cad8717eb726dc.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10c12c4dcee741fb89cad8717eb726dc.png)'
- en: Featuretools is an open-source Python library for automated feature engineering.Automated
    feature engineering is a relatively new technique, but, after using it to solve
    a number of data science problems using real-world data sets, I’m convinced it
    should be a *standard *part of any machine learning workflow. Here we’ll take
    a look at the results and conclusions from two of these projects with the full [code
    available as Jupyter Notebooks on GitHub](https://github.com/Featuretools/Automated-Manual-Comparison).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Featuretools 是一个用于自动化特征工程的开源 Python 库。自动化特征工程是一种相对较新的技术，但在使用它解决了多个实际数据集中的数据科学问题后，我相信它应该成为任何机器学习工作流程的*标准*部分。在这里，我们将查看这两个项目的结果和结论，完整的[代码可以在
    GitHub 上的 Jupyter Notebooks 中找到](https://github.com/Featuretools/Automated-Manual-Comparison)。
- en: 'Each project highlights some of the benefits of automated feature engineering:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目都突出了自动特征工程的一些好处：
- en: '**Loan Repayment Prediction:** automated feature engineering can reduce machine
    learning development time by 10x compared to manual feature engineering while
    delivering better modeling performance. ([Notebooks](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Loan%20Repayment))'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贷款偿还预测：** 自动化特征工程可以将机器学习开发时间缩短 10 倍，同时提供更好的建模性能。 ([Notebooks](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Loan%20Repayment))'
- en: '**Retail Spending Prediction:** automated feature engineering creates meaningful
    features and prevents data leakage by internally handling time-series filters,
    enabling successful model deployment. ([Notebooks](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Retail%20Spending))'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零售支出预测：** 自动化特征工程通过内部处理时间序列过滤器，创建有意义的特征并防止数据泄露，从而实现成功的模型部署。 ([笔记本](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Retail%20Spending))'
- en: 'Feel free to dig into the code and try out Featuretools! (Full disclosure:
    I work for [Feature Labs](https://www.featurelabs.com/), the company developing
    the library. These projects were completed with the free, open-source version
    of Featuretools).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随意深入了解代码并尝试使用 Featuretools！(完全披露：我在[Feature Labs](https://www.featurelabs.com/)工作，这家公司开发了这个库。这些项目使用的是免费、开源的
    Featuretools 版本完成的。)
- en: '**Feature Engineering: Manual vs. Automated**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**特征工程：手动与自动**'
- en: '[Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is
    the process of taking a dataset and constructing explanatory variables — features — that
    can be used to train a machine learning model for a prediction problem. Often,
    data is spread across multiple tables and must be gathered into a single table
    with rows containing the observations and features in the columns.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[特征工程](https://en.wikipedia.org/wiki/Feature_engineering)是将数据集转化为解释变量——特征——的过程，这些特征可以用于训练机器学习模型以解决预测问题。通常，数据分布在多个表格中，必须将其收集到一个包含观察结果的行和特征的列的单独表格中。'
- en: The traditional approach to feature engineering is to build features one at
    a time using domain knowledge, a tedious, time-consuming, and error-prone process
    known as manual feature engineering. The code for manual feature engineering is *problem-dependent* and *must
    be re-written for each new dataset.*
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的特征工程方法是使用领域知识一次构建一个特征，这是一种繁琐、耗时且容易出错的过程，被称为手动特征工程。手动特征工程的代码是*问题依赖的*，并且*必须为每个新的数据集重新编写*。
- en: Automated feature engineering improves upon this standard workflow by automatically
    extracting *useful and meaningful* features from a set of related data tables
    with a framework that can be applied *to any problem.* It not only cuts down on
    the time spent feature engineering, but creates interpretable features and prevents
    data leakage by filtering time-dependent data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化特征工程通过自动从一组相关数据表中提取*有用且有意义*的特征，并使用可以应用*于任何问题*的框架，改进了这一标准工作流程。它不仅减少了特征工程所花费的时间，还通过过滤时间相关的数据来创建可解释的特征并防止数据泄露。
- en: Automated feature engineering is more efficient and repeatable than manual feature
    engineering allowing you to build better predictive models faster.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化特征工程比手动特征工程更高效、更可重复，使你能够更快地构建更好的预测模型。
- en: 'Loan Repayment: Build Better Models Faster'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贷款偿还：更快地构建更好的模型
- en: The primary difficulty facing a data scientist approaching the Home Credit Loan
    problem (a [machine learning competition currently running on Kaggle](https://www.kaggle.com/c/home-credit-default-risk)where
    the objective is to predict if a loan will be repaid by a client) is the size
    and spread of the data. Take a look at the complete dataset and you are confronted
    with *58 million* rows of data spread across seven tables. Machine learning requires
    a single table for training, so feature engineering means consolidating all the
    information about each client in one table.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 面对 Home Credit 贷款问题（一个在 [Kaggle 上进行的机器学习竞赛](https://www.kaggle.com/c/home-credit-default-risk)，其目标是预测贷款是否会被客户偿还）时，数据科学家面临的主要困难是数据的规模和分布。查看完整的数据集，你会看到*5800万*行数据分布在七个表格中。机器学习需要一个单独的表格进行训练，因此特征工程意味着将每个客户的所有信息整合到一个表中。
- en: '![](../Images/5b75cf347c83b5be9c654ee9726f78c8.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b75cf347c83b5be9c654ee9726f78c8.png)'
- en: 'Feature engineering requires capturing all information from a set of related
    tables into one table.My first attempt at the problem used traditional manual
    feature engineering: I spent a total of **10 hours **creating a set of features
    by hand. First I read [other data scientist’s work](https://www.kaggle.com/c/home-credit-default-risk/kernels),
    explored the data, and researched the problem area in order to acquire the necessary
    domain knowledge. Then I translated the knowledge into code, building one feature
    at a time. As an example of a single manual feature, I found the total number
    of late payments a client had on previous loans, an operation that required using
    3 different tables.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程需要将一组相关表中的所有信息整合到一个表中。我第一次尝试这个问题时使用了传统的手动特征工程：我花了**10小时**手动创建一组特征。首先，我阅读了[其他数据科学家的工作](https://www.kaggle.com/c/home-credit-default-risk/kernels)，探索数据，并研究了问题领域，以获得必要的领域知识。然后，我将知识转化为代码，一次构建一个特征。作为单个手动特征的例子，我找出了客户在之前贷款中的逾期付款总数，这个操作需要使用3个不同的表。
- en: The final manual engineered features performed quite well, achieving a 65% improvement
    over the baseline features (relative to the top leaderboard score), indicating
    the [importance of proper feature engineering](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的手动工程特征表现相当好，比基准特征提高了65%（相对于顶级排行榜分数），这表明了[正确特征工程的重要性](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)。
- en: However, inefficient does not even begin to describe this process. For manual
    feature engineering, I ended up spending over 15 minutes per feature because I
    used the traditional approach of making a single feature at a time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，低效甚至无法描述这个过程。对于手动特征工程，我每个特征花费了超过15分钟，因为我采用了逐个制作单一特征的传统方法。
- en: '![](../Images/b5a4fa499842a9d508e2bbf236732acf.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5a4fa499842a9d508e2bbf236732acf.png)'
- en: 'The Manual Feature Engineering process.Besides being tedious and time-consuming,
    manual feature engineering is:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 手动特征工程过程。除了繁琐和耗时之外，手动特征工程还：
- en: '**Problem-specific:** all of the code I wrote over many hours cannot be applied
    to *any other problem*'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题特定的：** 我花费数小时编写的所有代码无法应用于*任何其他问题*'
- en: '**Error-prone:** each line of code is another opportunity to make a mistake'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易出错：** 每一行代码都是一个犯错的机会'
- en: 'Furthermore, the final manual engineered features are limited both by **human
    creativity **and **patience**: there are only so many features we can think to
    build and only so much time we have to make them.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最终的手动工程特征受限于**人类创造力**和**耐心**：我们能想到的特征有限，制作它们的时间也有限。
- en: The promise of automated feature engineering is to surpass these limitations
    by taking a set of related tables and automatically building hundreds of useful
    features using code that can be applied across all problems.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动特征工程的承诺是通过处理一组相关表，自动构建数百个有用特征，从而超越这些限制，这些代码可以应用于所有问题。
- en: '**From Manual to Automated Feature Engineering**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**从手动到自动特征工程**'
- en: As implemented in Featuretools, automated feature engineering allows even a
    domain novice such as myself to create thousands of relevant features from a set
    of related data tables. All we need to know is the basic structure of our tables
    and the relationships between them which we track in a single data structure called
    an [entity set](https://docs.featuretools.com/generated/featuretools.EntitySet.html).
    Once we have an entity set, using a method called [Deep Feature Synthesis](https://www.featurelabs.com/blog/deep-feature-synthesis/) (DFS),
    we’re able to build thousands of features in *one function call*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在Featuretools中实现的自动特征工程允许即使是像我这样的领域新手，也能从一组相关的数据表中创建数千个相关特征。我们需要知道的只是表的基本结构和它们之间的关系，我们将其跟踪在一个叫做[实体集](https://docs.featuretools.com/generated/featuretools.EntitySet.html)的数据结构中。一旦我们拥有了实体集，使用一种叫做[深度特征合成](https://www.featurelabs.com/blog/deep-feature-synthesis/)（DFS）的方法，我们就能够在*一次函数调用*中构建数千个特征。
- en: '![](../Images/8233ab01f8616439d3a2fc6b064fc404.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8233ab01f8616439d3a2fc6b064fc404.png)'
- en: The Automated Feature Engineering process using Featuretools.DFS works using
    functions called [“primitives”](https://docs.featuretools.com/automated_feature_engineering/primitives.html) to
    aggregate and transform our data. These primitives can be as simple as taking
    a mean or a max of a column, or they can be complex and based on subject expertise
    because [Featuretools allows us to define our own custom primitives](https://docs.featuretools.com/guides/advanced_custom_primitives.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Featuretools.DFS的自动特征工程过程通过称为[“原语”](https://docs.featuretools.com/automated_feature_engineering/primitives.html)的函数来聚合和转换数据。这些原语可以是计算列的均值或最大值等简单操作，也可以是基于主题知识的复杂操作，因为[Featuretools允许我们定义自己的自定义原语](https://docs.featuretools.com/guides/advanced_custom_primitives.html)。
- en: Feature primitives include many operations we already would do manually by hand,
    but with Featuretools, instead of re-writing the code to apply these operations
    on different datasets, we can use the *same exact *syntax across any relational
    database. Moreover, the power of DFS comes when we stack primitives on each other
    to create deep features. (For more on DFS, take a look at [this blog post](https://www.featurelabs.com/blog/deep-feature-synthesis/) by
    one of the inventors of the technique.)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 特征原语包括许多我们手动执行的操作，但通过Featuretools，我们可以在任何关系数据库中使用*相同的*语法，而无需重新编写代码来应用这些操作。此外，DFS的强大之处在于我们将原语堆叠在一起以创建深度特征。（有关DFS的更多信息，请查看[这篇博客文章](https://www.featurelabs.com/blog/deep-feature-synthesis/)由该技术的一位发明者撰写。）
- en: Deep Feature Synthesis is flexible — allowing it to be applied to any data science
    problem — and powerful — revealing insights in our data by creating deep features.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 深度特征合成是灵活的——允许应用于任何数据科学问题——也是强大的——通过创建深度特征揭示数据中的洞察。
- en: 'I’ll spare you the few lines of code needed for the set-up, but the action
    of DFS happens in a single line. Here we make *thousands of features* for each
    client using all 7 tables in our dataset (`ft` is the imported featuretools library):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我将省略设置所需的几行代码，但DFS的操作发生在一行代码中。我们使用数据集中所有7个表为每个客户生成*数千个特征*（`ft`是导入的featuretools库）：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Below are some of the **1820 features** we automatically get from Featuretools:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们从Featuretools自动获得的一些**1820个特征**：
- en: The maximum total amount paid on previous loans by a client. This is created
    using a `MAX` and a `SUM` primitive across 3 tables.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在以前贷款中支付的最大总金额。这是通过在3个表上使用`MAX`和`SUM`原语创建的。
- en: The percentile ranking of a client in terms of average previous credit card
    debt. This uses a `PERCENTILE` and `MEAN` primitive across 2 tables.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在平均以前信用卡债务方面的百分位排名。这使用了`PERCENTILE`和`MEAN`原语，跨2个表。
- en: Whether or not a client turned in two documents during the application process.
    This uses a `AND` transform primitive and 1 table.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在申请过程中是否提交了两份文件。这使用了`AND`变换原语和1个表。
- en: Each of these features is built using simple aggregations and hence is human-interpretable.
    Featuretools created many of the same features I did manually, but also thousands
    I never would have conceived — or had the time to implement. Not every single
    feature will be relevant to the problem, and some of the features are highly correlated,
    nonetheless, having *too many features is a better problem than having too few*!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征中的每一个都是通过简单的聚合构建的，因此是人类可解释的。Featuretools创建了许多我手动完成的特征，但也有数千个我从未想到过——或者没有时间实现的特征。并非每个特征都与问题相关，有些特征高度相关，但*特征过多总比特征过少要好*！
- en: After a little feature selection and model optimization, these features did
    slightly better in a predictive model compared to the manual features with an
    overall development time of **1 hour**, a 10x reduction compared to the manual
    process. Featuretools is much faster both because it requires less domain knowledge
    and because there are considerably fewer lines of code to write.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些特征选择和模型优化，这些特征在预测模型中的表现略优于手动特征，总开发时间为**1小时**，相比于手动过程减少了10倍。Featuretools之所以更快，是因为它需要的领域知识更少，且需要编写的代码行数大幅减少。
- en: I’ll admit that there is a slight time cost to learning Featuretools but it’s
    an investment that will pay off. After taking an hour or so to learn Featuretools,
    you can apply it *to any machine learning *problem.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我承认学习Featuretools确实有轻微的时间成本，但这是值得的投资。花费一个小时左右学习Featuretools后，你可以将其应用*于任何机器学习*问题。
- en: 'The following graphs sum up my experience for the loan repayment problem:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了我在贷款还款问题上的经验：
- en: '![Image](../Images/d1ad6837257f31146ded86b94dda4e60.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/d1ad6837257f31146ded86b94dda4e60.png)'
- en: Comparison between automated and manual feature engineering on time, number
    of features, and performance.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化与手动特征工程在时间、特征数量和性能上的比较。
- en: 'Development time: accounts for everything required to make the final feature
    engineering code: **10 hours manual vs 1 hour automated**'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发时间：完成最终特征工程代码所需的时间：**10小时手动 vs 1小时自动化**
- en: Number of features produced by the method: **30 features manual vs 1820 automated**
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法产生的特征数量：**30个手动特征 vs 1820个自动化特征**
- en: Improvement relative to baseline is the % gain over the baseline compared to
    the top public leaderboard score using a model trained on the features: **65%
    manual vs 66% automated**
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对于基线的改进是相对于使用特征训练的模型在公开排行榜中的最高分数的百分比增益：**65% 手动 vs 66% 自动化**
- en: My takeaway is that automated feature engineering will not replace the data
    scientist, but rather by significantly increasing efficiency, it will free her
    to spend more time on other aspects of the machine learning pipeline.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的收获是自动化特征工程不会取代数据科学家，而是通过显著提高效率，使她能花更多时间在机器学习管道的其他方面。
- en: Furthermore, the Featuretools code I wrote for this first project could be applied
    to any dataset while the manual engineering code would have to be thrown away
    and entirely rewritten for the next dataset!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我为这个第一个项目编写的Featuretools代码可以应用于任何数据集，而手动工程代码必须被丢弃并完全重写以适应下一个数据集！
- en: 'Retail Spending: Build Meaningful Features and Prevent Data Leakage'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零售支出：构建有意义的特征并防止数据泄漏
- en: For the second dataset, a [record of online time-stamped customer transactions](https://archive.ics.uci.edu/ml/datasets/online+retail#),
    the prediction problem is to classify customers into two segments, those who will
    spend more than $500 in the next month and those who won’t. However, instead of
    using a single month for all the labels, each customer is a label *multiple times*.
    We can use their spending in May as a label, then in June, and so on.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个数据集，[在线时间戳顾客交易记录](https://archive.ics.uci.edu/ml/datasets/online+retail#)，预测问题是将顾客分为两个类别：那些下个月将花费超过$500的顾客和那些不会的顾客。然而，除了使用单个月的数据为所有标签外，每个顾客的标签是*多次*出现的。我们可以使用他们在五月的消费作为一个标签，然后是六月，以此类推。
- en: '![](../Images/40c4b456b5b3b1fc2729f740921fb539.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40c4b456b5b3b1fc2729f740921fb539.png)'
- en: 'Each customer is used as a training example multiple timesUsing each customer
    multiple times as an observation brings up difficulties for creating training
    data: when making features for a customer for a given month, we can’t use any
    information from months in the future, *even though we have access to this data*.
    In a deployment, we’ll *never have future data* and therefore can’t use it for
    training a model. Companies routinely struggle with this issue and often deploy
    a model that does much worse in the real world than in development because it
    was trained using invalid data.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 每个顾客作为训练示例使用了多次。使用每个顾客作为观察多次会带来创建训练数据的困难：在为特定月份的顾客创建特征时，我们不能使用未来月份的信息，*即使我们有这些数据*。在部署中，我们*永远不会有未来数据*，因此不能用它来训练模型。公司经常面临这个问题，并且通常会部署在现实世界中表现远差于开发阶段的模型，因为它是使用无效数据训练的。
- en: Fortunately, ensuring that our data is valid in a time-series problem is [straightforward
    in Featuretools. ](https://docs.featuretools.com/automated_feature_engineering/handling_time.html)In
    the Deep Feature Synthesis function we pass in a dataframe like that shown above,
    where the cutoff time represents the point past which we can’t use any data for
    the label, and Featuretools *automatically* takes the time into account when building
    features.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，确保我们数据在时间序列问题中的有效性在[Featuretools中是直接的](https://docs.featuretools.com/automated_feature_engineering/handling_time.html)。在深度特征合成功能中，我们传入一个如上所示的数据框，其中截止时间表示我们不能使用任何数据进行标签的时间点，Featuretools在构建特征时*自动*考虑了时间。
- en: The features for a customer in a given month are built using data filtered to
    before the month. Notice that the call to create our set of features is the same
    as that for the loan repayment problem with the addition of `cutoff_time.`
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个月的顾客，特征是使用过滤到该月份之前的数据构建的。注意，创建我们特征集的调用与贷款还款问题中的调用相同，只是添加了`cutoff_time`。
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The result of running Deep Feature Synthesis is a table of features, one for
    each customer *for each month*. We can use these features to train a model with
    our labels and then make predictions for any month. Moreover, we can rest assured
    that the features in our model do not use future information, which would result
    in an unfair advantage and yield misleading training scores.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 运行深度特征合成的结果是一个特征表，每个客户的每个月都有一个特征。我们可以使用这些特征来训练一个带有标签的模型，然后对任何月份进行预测。此外，我们可以放心的是，我们模型中的特征不使用未来的信息，这样可以避免不公平的优势并防止产生误导性的训练分数。
- en: With the automated features, I was able to build a machine learning model that
    achieved 0.90 ROC AUC compared to an informed baseline (guessing the same level
    of spending as the previous month) of 0.69 when predicting customer spending categories
    for one month.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 利用自动化功能，我能够构建一个机器学习模型，该模型在预测一个月的客户支出类别时，取得了0.90的ROC AUC，相比之下，基于先验（猜测与上个月相同的支出水平）的基线为0.69。
- en: 'In addition to delivering impressive predictive performance, the Featuretools
    implementation gave me something equally valuable: interpretable features. Take
    a look at the 15 most important features from a random forest model:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供令人印象深刻的预测性能外，Featuretools的实现还给了我同样宝贵的东西：可解释的特征。看看随机森林模型中最重要的15个特征：
- en: '![](../Images/ff083e61483b98ff52a2818ffa34a613.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff083e61483b98ff52a2818ffa34a613.png)'
- en: 15 most important Featuretools features from a random forest model.The feature
    importances tell us that the most important predictors of how much the customer
    will spend in the next month is how much they have spent previously `SUM(purchases.total)`,
    and the number of purchases, `SUM(purchases.quantity).` These are features that
    we could have built by hand, but then we would have to worry about leaking data
    and creating a model that does much better in development than in deployment.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从随机森林模型中提取的15个最重要的Featuretools特征。特征重要性告诉我们，预测客户下个月支出多少的最重要因素是他们之前的支出`SUM(purchases.total)`以及购买次数`SUM(purchases.quantity)`。这些是我们本可以手动构建的特征，但那样我们就需要担心数据泄露，并且创建的模型在开发阶段表现优于实际部署阶段。
- en: If the tool already exists for creating meaningful features without any need
    to worry about the validity of our features, then why do the implementation by
    hand? Furthermore, the automated features are completely clear in the context
    of the problem and can inform our real-world reasoning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工具已经存在，可以创建有意义的特征而无需担心特征的有效性，那为什么要手动实现呢？此外，自动化特征在问题背景中完全清晰，可以指导我们的实际推理。
- en: 'Automated feature engineering identified the most important signals, achieving
    the primary goal of data science: reveal insights hidden in mountains of data.'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化特征工程识别出了最重要的信号，实现了数据科学的主要目标：揭示隐藏在大量数据中的见解。
- en: 'Even after spending significantly more time on manual feature engineering than
    I did with Featuretools, I was not able to develop a set of features with close
    to the same performance. The graph below shows the ROC curves for classifying
    one month of future customer sales using a model trained on the two datasets.
    A curve to the left and top indicates better predictions:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在手动特征工程上花费了比Featuretools更多的时间，我也无法开发出接近相同性能的特征集。下图显示了使用两种数据集训练的模型对未来一个月客户销售的分类ROC曲线。向左和向上的曲线表示更好的预测：
- en: '![](../Images/b4281a47906f49d0918ad72243c61fc4.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4281a47906f49d0918ad72243c61fc4.png)'
- en: ROC curves comparing automated and manual feature engineering results. A curve
    to the left and top indicates better performance.I’m not even completely sure
    if the manual features were made using valid data, but with the Featuretools implementation,
    I didn’t have to worry about data leakage in time-dependent problems. Maybe this
    inability to manually engineer a useful set of valid features speaks to my failings
    as a data scientist, but if the tool exists to safely do this for us, why not
    use it?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化和手动特征工程结果的ROC曲线比较。向左和向上的曲线表示更好的性能。我甚至不完全确定手动特征是否使用了有效的数据，但使用Featuretools的实现，我不必担心时间相关问题中的数据泄露。也许这种无法手动工程化有效特征的能力反映了我作为数据科学家的不足，但如果工具可以安全地为我们做到这一点，为什么不使用呢？
- en: We use automatic safety systems in our day-to-day life and automated feature
    engineering in Featuretools is the secure method to build meaningful machine learning
    features in a time-series problem while delivering superior predictive performance.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在日常生活中使用自动安全系统，而 Featuretools 中的自动特征工程是构建具有实际意义的机器学习特征的安全方法，同时提供卓越的预测性能。
- en: Conclusions
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: I came away from these projects convinced that automated feature engineering
    should be an *integral part of the machine learning workflow*. The technology
    is not perfect yet still delivers significant gains in efficiency.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我从这些项目中得出的结论是，自动特征工程应该是 *机器学习工作流程的一个重要组成部分*。这项技术虽然不完美，但仍能显著提高效率。
- en: 'The main conclusions are that automated feature engineering:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 主要结论是自动特征工程：
- en: '**Reduced implementation time** by up to 10x'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少实施时间** 高达 10 倍'
- en: Achieved modeling **performance at the same level** **or better**
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现了 **相同水平的建模性能** 或更好
- en: Delivered **interpretable features** with real-world significance
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了 **具有现实世界意义的可解释特征**
- en: '**Prevented improper data usage** that would invalidate a model'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**防止不当数据使用** 以避免模型失效'
- en: '**Fit into existing workflows** and machine learning models'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**融入现有工作流程** 和机器学习模型'
- en: '“Work smarter, not harder” may be a cliche, but sometimes there is truth to
    platitudes: if there is a way to do the same job with the same performance for
    a smaller time investment, then clearly it’s a method worth learning.'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “聪明地工作，而不是努力地工作”可能是陈词滥调，但有时这些老生常谈确实有其道理：如果有一种方法可以在投入更少时间的情况下实现相同的性能，那么显然这是一种值得学习的方法。
- en: '[Featuretools](https://www.featuretools.com/) will always be free to use and
    open-source (contributions are welcome), and there are several examples — [here’s
    an article I’ve written](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219) — to
    get you started in 10 minutes. Your job as a data scientist is safe, but it can
    be made significantly easier with automated feature engineering.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[Featuretools](https://www.featuretools.com/) 将始终免费使用和开源（欢迎贡献），还有几个示例——[这是我写的一篇文章](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219)——帮助你在
    10 分钟内入门。作为数据科学家的你是安全的，但使用自动特征工程可以显著简化你的工作。'
- en: If building meaningful, high-performance predictive models is something you
    care about, then get in touch with us at [Feature Labs](https://www.featurelabs.com/contact/).
    While this project was completed with the open-source Featuretools, the [commercial
    product](https://www.featurelabs.com/product) offers additional tools and support
    for creating machine learning solutions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你关心构建有意义、高性能的预测模型，那么请联系我们的 [Feature Labs](https://www.featurelabs.com/contact/)。虽然这个项目是使用开源的
    Featuretools 完成的，但 [商业产品](https://www.featurelabs.com/product) 提供了额外的工具和支持来创建机器学习解决方案。
- en: '**Bio: [Will Koehrsen](https://twitter.com/koehrsen_will)** is a Data Scientist
    at Feature Labs, and a Data Science Communicator and Advocate.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Will Koehrsen](https://twitter.com/koehrsen_will)** 是 Feature Labs
    的数据科学家，同时也是数据科学传播者和倡导者。'
- en: '[Original](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96).
    Reposted with permission.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96)。经许可转载。'
- en: '**Related:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容:**'
- en: '[Deep Feature Synthesis: How Automated Feature Engineering Works](/2018/02/deep-feature-synthesis-automated-feature-engineering.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度特征合成：自动特征工程如何工作](/2018/02/deep-feature-synthesis-automated-feature-engineering.html)'
- en: '[Quick Feature Engineering with Dates Using fast.ai](/2018/03/feature-engineering-dates-fastai.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 fast.ai 快速进行特征工程](/2018/03/feature-engineering-dates-fastai.html)'
- en: '[Basic Concepts of Feature Selection](/2017/11/rapidminer-basic-concepts-feature-selection.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征选择的基本概念](/2017/11/rapidminer-basic-concepts-feature-selection.html)'
- en: More On This Topic
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Forget ChatGPT, This New AI Assistant Is Leagues Ahead and Will…](https://www.kdnuggets.com/2023/08/forget-chatgpt-new-ai-assistant-leagues-ahead-change-way-work-forever.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[忘记 ChatGPT，这个新的 AI 助手远超 ChatGPT，将……](https://www.kdnuggets.com/2023/08/forget-chatgpt-new-ai-assistant-leagues-ahead-change-way-work-forever.html)'
- en: '[Feature Store Summit 2022: A free conference on Feature Engineering](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征存储峰会 2022：关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
- en: '[A Practical Approach To Feature Engineering In Machine Learning](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中特征工程的实用方法](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
- en: '[Building a Tractable, Feature Engineering Pipeline for Multivariate…](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建可处理的多变量时间序列特征工程管道](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
- en: '[Using RAPIDS cuDF to Leverage GPU in Feature Engineering](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 RAPIDS cuDF 利用 GPU 进行特征工程](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
- en: '[Feature Engineering for Beginners](https://www.kdnuggets.com/feature-engineering-for-beginners)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征工程入门](https://www.kdnuggets.com/feature-engineering-for-beginners)'
