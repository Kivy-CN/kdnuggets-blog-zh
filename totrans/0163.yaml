- en: 'Web LLM: Bring LLM Chatbots to the Browser'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html](https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Web LLM: Bring LLM Chatbots to the Browser](../Images/1d53a0269ef099c94062bdcebf457895.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: LLM-based chatbots are accessible through a front end, and they involve a large
    number of expensive API calls to the server side. But what if we could get LLMs
    to run entirely in the browser—using the computing power of the underlying system.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: This way, the full functionality of the LLM is available at the client side—without
    having to worry about server availability, infrastructure, and the like. Web LLM
    is a project that aims to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Let's learn more about what drives Web LLM and the challenges of building such
    a project. We'll also look at the advantages and limitations of Web LLM.
  prefs: []
  type: TYPE_NORMAL
- en: What is Web LLM?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Web LLM is a project that uses WebGPU and WebAssembly and much more to enable
    the running of LLMs and LLM apps completely in the browser. With Web LLM, you
    can run LLM chatbots in the browser by leveraging the underlying system’s GPU
    through WebGPU.
  prefs: []
  type: TYPE_NORMAL
- en: It uses the compiler stack of the Apache TVM project and uses [WebGPU](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API)
    that was recently released. In addition to 3D graphics rendering and the like,
    the WebGPU API also supports general purpose GPU computations (GPGPU computations).
  prefs: []
  type: TYPE_NORMAL
- en: Challenges of Building Web LLM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since Web LLM runs entirely on the client side without any inference server,
    the following challenges are associated with the project:'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models use Python frameworks for deep learning that also natively
    support leveraging the GPU for operations on tensors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When building Web LLM to run completely in the browser, we will not be able
    to use the same Python frameworks. And alternative tech stacks that enable running
    LLMs on the web while still using Python for development had to be explored.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running LLM apps typically requires large inference servers, but when everything
    runs on the client side—in the browser—we cannot have large inference servers
    any longer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires a smart compression of the model’s weights to make it fit in the available
    memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How Does Web LLM Work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Web LLM project uses the underlying system’s GPU and hardware capabilities
    to run large language models in the browser. The process of **machine learning
    compilation** helps bake the functionality of LLMs into the browser side by leveraging
    [TVM Unity](https://discuss.tvm.apache.org/t/establish-tvm-unity-connection-a-technical-strategy/13344)
    and a set of optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Web LLM: Bring LLM Chatbots to the Browser](../Images/359f43c767f9eda2517ba92138545f41.png)'
  prefs: []
  type: TYPE_IMG
- en: How Web LLM Works | [Image Source](https://github.com/mlc-ai/web-llm)
  prefs: []
  type: TYPE_NORMAL
- en: The system is developed in Python and runs on the web using the TVM runtime.
    This porting to the web browser is achieved by running a series of optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: The LLM’s functionality is first baked into an IRModule in TVM. Several transformations
    are run on the functions in the IRModule to get an optimized and runnable code.
    [TensorIR](https://arxiv.org/abs/2207.04296) is a compiler abstraction for optimizing
    programs with tensor computations. Further, INT-4 quantization is used to compress
    the model’s weights. And a TVM runtime is made possible using TypeScript and [emscripten](https://emscripten.org/),
    an LLVM compiler that transforms C and C++ code to WebAssembly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Web LLM: Bring LLM Chatbots to the Browser](../Images/e6653174ffee8e836c1f39f4fc734339.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: You need to have the latest version of Chrome or [Chrome Canary](https://www.google.com/intl/en_in/chrome/canary/)
    to try out Web LLM. As of writing this article, Web LLM supports the Vicuna and
    LLaMa LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the model takes a while the first time you run the model. Because the
    caching is complete after the first run, subsequent runs are considerably faster
    and have minimum overhead.
  prefs: []
  type: TYPE_NORMAL
- en: '![Web LLM: Bring LLM Chatbots to the Browser](../Images/584e9cfbfff3498667913a97fe4a1a14.png)'
  prefs: []
  type: TYPE_IMG
- en: Advantages and Limitations of Web LLM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s wrap up our discussion by enumerating the advantages and limitations of
    Web LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to exploring the synergy of Python, WebAssembly and other tech
    stacks, Web LLM has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: The main advantage of running LLMs in the browser is **privacy**. Because the
    server side is completely eliminated in this privacy-first design, we no longer
    have to worry about the use of our data. Because Web LLM harnesses the computing
    power of the underlying system’s GPU, we don't have to worry about data reaching
    malicious entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can build personal AI assistants for day-to-day activities. Therefore, the
    Web LLM project offers a high degree of **personalization**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another advantage of Web LLM is the **reduced cost**. We no longer need expensive
    API calls and inference servers, and Web LLM uses the underlying system’s GPU
    and processing capabilities. So running Web LLM is possible at a fraction of the
    cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some of the limitations of Web LLM:'
  prefs: []
  type: TYPE_NORMAL
- en: Though Web LLM alleviates the concerns around inputting sensitive information,
    it is still susceptible to attack on the browser.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is further scope for improvement by adding support for multiple language
    models and choice of browsers. Currently, this feature is available only in Chrome
    Canary and the latest version of Chrome. Expanding this to a bigger set of supported
    browsers will be helpful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of robustness checks run by the browser, Web LLM using WebGPU does not
    have the native performance of a GPU runtime. You can optionally disable the flag
    that runs robustness checks in order to improve performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve tried to understand how Web LLM works. You can try running it in your
    browser or even [deploy it locally](https://github.com/mlc-ai/web-llm#instructions-for-local-deployment).
    Consider playing around with the model in your browser and check how effective
    it is when integrated into your day-to-day workflow. If you are interested you
    can also check out the [MLC-LLM project](https://mlc.ai/mlc-llm/), which allows
    you to run LLMs—natively on any device of your choice—including laptops and iPhones.
  prefs: []
  type: TYPE_NORMAL
- en: References and Further Reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] [WebGPU API](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API),
    MDN Web Docs'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [TensorIR: An Abstraction for Automatic Tensorized Program Optimization](https://arxiv.org/abs/2207.04296)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [MLC-LLM](https://mlc.ai/mlc-llm/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a developer
    and technical writer from India. She likes working at the intersection of math,
    programming, data science, and content creation. Her areas of interest and expertise
    include DevOps, data science, and natural language processing. She enjoys reading,
    writing, coding, and coffee! Currently, she''s working on learning and sharing
    her knowledge with the developer community by authoring tutorials, how-to guides,
    opinion pieces, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[AgentGPT: Autonomous AI Agents in your Browser](https://www.kdnuggets.com/2023/06/agentgpt-autonomous-ai-agents-browser.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing OpenChat: The Free & Simple Platform for Building…](https://www.kdnuggets.com/2023/06/introducing-openchat-free-simple-platform-building-custom-chatbots-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build a Machine Learning Web App in 5 Minutes](https://www.kdnuggets.com/2022/03/build-machine-learning-web-app-5-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Creating a Web Application to Extract Topics from Audio with Python](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build a Web Scraper with Python in 5 Minutes](https://www.kdnuggets.com/2022/02/build-web-scraper-python-5-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Step-by-Step Guide to Web Scraping with Python and Beautiful Soup](https://www.kdnuggets.com/2023/04/stepbystep-guide-web-scraping-python-beautiful-soup.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
