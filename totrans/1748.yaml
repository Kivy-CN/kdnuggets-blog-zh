- en: How to Build a Data Science Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建数据科学管道
- en: 原文：[https://www.kdnuggets.com/2017/07/build-data-science-pipeline.html](https://www.kdnuggets.com/2017/07/build-data-science-pipeline.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文](https://www.kdnuggets.com/2017/07/build-data-science-pipeline.html)'
- en: '**By Balázs Kégl, Data scientist, co-creator of [RAMP](http://www.ramp.studio/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 Balázs Kégl 撰写，数据科学家，[RAMP](http://www.ramp.studio/) 的共同创建者。**'
- en: There is no debate on how a well-functioning predictive workflow works when
    it is finally put into production. Data sources are transformed into a set of
    features or indicators *X*, describing each instance (client, piece of equipment,
    asset) on which the prediction will act on. A predictor then turns *X* into an
    actionable piece of information *y_pred* (will the client churn?, will the equipment
    fail?, will the asset price go up?). In certain fluid markets (e.g., ad targeting)
    the prediction is then monetized through a fully automated process, in other cases
    it is used as decision support with a human in the loop.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个良好运作的预测工作流最终投入生产时，如何运作没有争议。数据源被转化为一组特征或指标 *X*，描述每个实例（客户、设备、资产）在预测中将会受到的影响。预测器然后将
    *X* 转化为一个可操作的信息 *y_pred*（客户会流失吗？设备会故障吗？资产价格会上涨吗？）。在某些流动性市场（例如广告定向）中，预测通过完全自动化的过程变现，而在其他情况下，则作为决策支持，涉及人为干预。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](../Images/ad14dee5b05eafb0757e03274901b08a.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad14dee5b05eafb0757e03274901b08a.png)'
- en: The data flow in a data science pipeline in production.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学管道中的数据流在生产环境中。
- en: 'This sounds simple, yet examples of working and well-monetized predictive workflows
    are rare. Companies struggle with the building process. The questions they need
    to ask are:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来简单，但成功和盈利的预测工作流的例子却很少。公司在构建过程中面临困难。他们需要问的问题是：
- en: Who builds this workflow? What are the roles and expertises I need to cover?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁负责构建这个工作流？我需要覆盖哪些角色和专业知识？
- en: What is the building process? What are the steps, and what expertise I need
    at each step?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建造过程是什么？每一步需要什么样的专业知识？
- en: What are the costs and risks at any of those steps, and how do I control them?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这些步骤中有哪些费用和风险，我该如何控制它们？
- en: Hype around data challenges gave the false impression that the data scientist
    and the predictive score are the main drivers of the process. Even industrial
    processes (e.g., [CRISP-DM](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)
    and [Dataiku](https://blog.dataiku.com/2016/03/30/automation-scenarios-another-step-towars-a-successful-model-deployment))
    that have been around since the nineties usually put the data scientist in the
    center and deployment at the end of the process. While they are not wrong, they
    are mostly irrelevant. Building and optimizing the predictor is easy. What is
    hard is finding the business problem and the KPI that it will improve, hunting
    and transforming the data into digestible instances, defining the steps of the
    workflow, putting it into production, and organizing the model maintenance and
    regular update.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据挑战的炒作给人一种错误的印象，即数据科学家和预测评分是过程的主要驱动因素。即使是自九十年代以来就存在的工业流程（例如，[CRISP-DM](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)
    和 [Dataiku](https://blog.dataiku.com/2016/03/30/automation-scenarios-another-step-towars-a-successful-model-deployment)）通常将数据科学家置于中心，将部署放在过程的最后。虽然它们并非完全错误，但大多无关紧要。构建和优化预测器很容易。困难的是找到业务问题和它将改善的
    KPI，搜寻并将数据转化为可消化的实例，定义工作流的步骤，将其投入生产，并组织模型维护和定期更新。
- en: 'Companies usually start by what seems to be a no brainer: asking their IT departments
    to put in place the big data infrastructure and build a data lake. They then hire
    their first data scientists. These experts, fresh off school and a handful of
    Kaggle challenges, armed with the data science toolkit, are eager to put their
    hands on the data. They can predict anything, and they do! They talk the business
    unit, they find reasonable prediction targets for which labels exist already,
    they try a dozen models, hyperopt them, and choose the best. They build POCs and
    send reports to the business unit. And then start again.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 公司通常从看似简单的任务开始：要求 IT 部门建立大数据基础设施并构建数据湖。随后，他们会雇佣首批数据科学家。这些专家刚从学校毕业，经过一些 Kaggle
    挑战，装备了数据科学工具包，渴望动手处理数据。他们可以预测任何东西，而且他们确实这样做了！他们与业务部门沟通，找到已有标签的合理预测目标，尝试多种模型，进行超参数优化，并选择最佳模型。他们构建
    POC 并将报告发送给业务部门，然后重新开始。
- en: The usual way to construct a data science workflow.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 构建数据科学工作流的常见方式。
- en: '**Most of those POCs never go into production.** The business unit doesn’t
    know what to do with them. They can’t interpret the scores. The prediction target
    seems reasonable, yet they have no clue how they will make a money with their
    *y_pred*. If they do, putting the POC into production seems insurmountable. Code
    has to be rewritten. Real time data has to be channeled into the workflow. Operational
    constraints need to be satisfied. The decision support system needs to be integrated
    with the existing work tools of the users. Model maintenance, user feedback, rollback
    needs to be put in place. These operations usually cost more and create more risk
    than the safe POCs the data scientist worked on, and the POC simply cannot drive
    the process.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**这些 POC 中大多数从未投入生产。** 业务部门不知道如何处理它们。他们无法解读分数。预测目标似乎合理，但他们不知道如何利用他们的 *y_pred*
    赚钱。如果他们知道，将 POC 投入生产似乎不可逾越。代码必须重写。实时数据必须纳入工作流。需要满足操作约束。决策支持系统需要与用户现有工作工具集成。需要进行模型维护、用户反馈和回滚。这些操作通常比数据科学家工作中的安全
    POC 成本更高、风险更大，而 POC 仅仅无法推动过程。'
- en: The process I describe below will not solve these problems, but it gives you
    an ordering in which you can at least address and control costs and risks. First,
    **find a chief data officer** (or rather a *data value architect*) at any cost
    who has already put in production a predictive workflow. Your CDO doesn’t need
    to know the latest deep learning architecture, but she should have a broad understanding
    of both the business of the company and the data science process. She should play
    a central role and drive the process.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我在下面描述的过程不会解决这些问题，但它为你提供了一个顺序，使你至少可以处理和控制成本和风险。首先，**无论如何找到一位首席数据官**（或者说是*数据价值架构师*），他/她已经将预测工作流投入生产。你的
    CDO 不需要了解最新的深度学习架构，但她应该对公司的业务和数据科学过程有广泛的理解。她应该发挥核心作用，推动过程。
- en: Getting IT on board early is important. You need your data lake, but more importantly,
    **you need data engineers to think in terms of production from day one**. But
    this is not the first step. The first step is to figure out **whether you need
    a prediction at all**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 早期将 IT 纳入是重要的。你需要数据湖，但更重要的是，**你需要数据工程师从第一天起就以生产的角度思考**。但这并不是第一步。第一步是弄清楚**你是否真的需要预测**。
- en: So, start with ***y***, the prediction target.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以，从 ***y*** 开始，即预测目标。
- en: Your CDO should work closely and longly with the business unit to figure out
    what they want to know. What *y* drives their decisions? How would a better prediction
    of *y* will improve the bottom line (cost down, profit up, productivity up)? Once
    you have your *y*, try to **monetize prediction error as much as possible**. There
    is nothing that makes your (future) data scientists happier than a well monetized
    metrics. They will know that improving their score by 2% make you a million dollars;
    more importantly ***you* will know how much you can spend on your data science
    team**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 CDO 应与业务部门密切且长期合作，弄清楚他们想了解什么。是什么* y* 驱动他们的决策？* y* 的更好预测如何改善底线（降低成本、提高利润、提高生产力）？一旦确定了
    *y*，尽量**最大化预测误差的货币化**。没有什么比一个良好的货币化指标更能让（未来的）数据科学家感到高兴了。他们会知道提高 2% 的分数能为你带来一百万美元；更重要的是，***你*
    会知道你可以在数据科学团队上花多少钱**。
- en: Once you cemented *y* and the metrics,
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你巩固了 *y* 和指标，
- en: go for a data hunt,
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进行数据探索，
- en: find **indicators** in your data lake and elsewhere which are **likely to correlate
    with your prediction target**. In principle, you still don’t need a data scientist
    for this, the process should be driven by the CDO and the BU (after all, *they*
    know what information they use for their decisions, which is usually a great baseline).
    But it may help to have someone who knows what’s out there in terms of open and
    buyable data. Here you absolutely need to **talk to IT to have an idea about what
    the operational costs will be** when these indicators need to be collected real
    time. The data scientist needs this information. If storing a new feature on each
    client costs you 4TB a day, that single fact decides how the predictor will look
    like.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 找到你数据湖及其他地方的**指标**，这些指标**可能与预测目标相关**。原则上，你仍然不需要数据科学家来完成这项工作，这个过程应该由首席数据官和业务单位推动（毕竟，*他们*
    知道他们在决策中使用了哪些信息，这通常是一个很好的基准）。但是，有一个了解开放和可购买数据的人可能会有所帮助。在这里，你绝对需要**与 IT 沟通，以了解在实时收集这些指标时运营成本会是多少**。数据科学家需要这些信息。如果在每个客户上存储一个新特征的成本是每天
    4TB，那么这个单一事实决定了预测器的样子。
- en: '*Now* hire a data scientist, preferably one that can also develop production
    quality software. Make him'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*现在* 雇佣一个数据科学家，最好是一个能够开发生产质量软件的人。让他'
- en: build the experimental setup and the baseline workflow
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 建立实验设置和基线工作流
- en: with a simple prediction and check whether it can be put into production. At
    this point you are ready for the full scale experimental data science loop which
    data scientists know how to handle. You may need a deep learning specialist, but
    it is likely that you can out- and crowdsource your first model, e.g., by doing
    a [RAMP](http://www.ramp.studio/) with us.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 进行简单的预测，并检查其是否可以投入生产。此时你已经准备好进行全规模的实验数据科学循环，这个循环数据科学家知道如何处理。你可能需要一个深度学习专家，但很可能你可以外包并众包你的第一个模型，例如，通过与我们一起进行一个[RAMP](http://www.ramp.studio/)。
- en: '**If you like what you read, follow me on [Medium](https://medium.com/@balazskegl),
    [LinkedIn](https://www.linkedin.com/in/balazskegl/), & [Twitter](https://twitter.com/balazskegl).**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你喜欢你所读的内容，可以在 [Medium](https://medium.com/@balazskegl)、[LinkedIn](https://www.linkedin.com/in/balazskegl/)
    和 [Twitter](https://twitter.com/balazskegl) 上关注我。**'
- en: '**Bio: [Balázs Kégl](https://twitter.com/balazskegl)** is a senior research
    scientist at CNRS and head of the Center for Data Science of the Université Paris-Saclay.
    He is co-creator of RAMP ([www.ramp.studio](http://www.ramp.studio)).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Balázs Kégl](https://twitter.com/balazskegl)** 是 CNRS 的高级研究科学家，并且是巴黎-萨克雷大学数据科学中心的负责人。他是
    RAMP 的共同创始人 ([www.ramp.studio](http://www.ramp.studio))。'
- en: '[Original](https://medium.com/towards-data-science/how-to-build-a-data-science-pipeline-f24341848045).
    Reposted with permission.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/towards-data-science/how-to-build-a-data-science-pipeline-f24341848045)。经许可转载。'
- en: '**Related:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Teaching the Data Science Process](/2017/05/teaching-data-science-process.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[教授数据科学流程](/2017/05/teaching-data-science-process.html)'
- en: '[Will Data Science Eliminate Data Science?](/2017/05/data-science-eliminate-data-science.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学会消除数据科学吗？](/2017/05/data-science-eliminate-data-science.html)'
- en: '[Embrace the Random: A Case for Randomizing Acceptance of Borderline Papers](/2016/05/embrace-random-acceptance-borderline-papers.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[接受随机：随机化边界论文接受的案例](/2016/05/embrace-random-acceptance-borderline-papers.html)'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并寻找目的来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学统计学习的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家都应该掌握的 6 种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
