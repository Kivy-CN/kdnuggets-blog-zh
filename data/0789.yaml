- en: 7 Essential Data Quality Checks with Pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 个重要的数据质量检查与 Pandas
- en: 原文：[https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)
- en: '![7 Essential Data Quality Checks with Pandas](../Images/c9dfcc4434fa36f099ef3af225d45b7b.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![7 个重要的数据质量检查与 Pandas](../Images/c9dfcc4434fa36f099ef3af225d45b7b.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: As a data professional, you’re probably familiar with the cost of poor data
    quality. For all data projects—big or small—you should perform essential data
    quality checks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据专业人士，你可能熟悉数据质量差的成本。对于所有数据项目——无论大小——你都应该执行必要的数据质量检查。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的信息技术'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There are dedicated libraries and frameworks for data quality assessment. But
    if you are a beginner, you can run simple yet important data quality checks with
    pandas. And this tutorial will teach you how.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量评估有专门的库和框架。但是，如果你是初学者，你可以使用 pandas 运行简单但重要的数据质量检查。本教程将教你如何做。
- en: We’ll use the [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)
    from scikit-learn for this tutorial.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 [加州住房数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)
    作为本教程的示例。
- en: An Overview of the California Housing Dataset
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加州住房数据集概述
- en: We’ll use the California housing dataset from Scikit-learn’s [datasets module](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets).
    The data set contains over 20,000 records of eight numeric features and a target
    median house value.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自 Scikit-learn 的 [数据集模块](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets)
    的加州住房数据集。该数据集包含超过 20,000 条记录，涵盖八个数值特征和一个目标中位数房价。
- en: 'Let’s read the dataset into a pandas dataframe `df`:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将数据集读取到 pandas 数据框 `df` 中：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For a detailed description of the dataset, run `data.DESCR` as shown:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据集的详细描述，请运行 `data.DESCR`，如下所示：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![7 Essential Data Quality Checks with Pandas](../Images/f75bc0f8c1f2fd389c4abd2454c2c71d.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![7 个重要的数据质量检查与 Pandas](../Images/f75bc0f8c1f2fd389c4abd2454c2c71d.png)'
- en: Output of data.DESCR
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: data.DESCR 的输出
- en: 'Let''s get some basic information on the dataset:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们获取数据集的一些基本信息：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here’s the output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Because we have numeric features, let us also get the summary starts using
    the `describe()` method:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有数值特征，让我们还使用 `describe()` 方法获取摘要统计：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![7 Essential Data Quality Checks with Pandas](../Images/116989112eb8a816cb5b4b701c5f246c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![7 个重要的数据质量检查与 Pandas](../Images/116989112eb8a816cb5b4b701c5f246c.png)'
- en: Output of df.describe()
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: df.describe() 的输出
- en: 1\. Check for Missing Values
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 检查缺失值
- en: Real-world datasets often have missing values. To analyze the data and build
    models, you need to handle these missing values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的数据集通常会有缺失值。为了分析数据和建立模型，你需要处理这些缺失值。
- en: To ensure data quality, you should check if the fraction of missing values is
    within a specific tolerance limit. You can then impute the missing values using
    suitable imputation strategies.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保数据质量，你应该检查缺失值的比例是否在特定的容忍范围内。然后，你可以使用适当的插补策略来填补缺失值。
- en: The first step, therefore, is to check for missing values across all features
    in the dataset.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，第一步是检查数据集中所有特征的缺失值。
- en: 'This code checks for missing values in each column of the dataframe `df`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码检查数据框 `df` 中每一列的缺失值：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result is a pandas series that shows the count of missing values for each
    column:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个 pandas 系列，显示了每一列的缺失值计数：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As seen, there are no missing values in this dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如所见，此数据集中没有缺失值。
- en: 2\. Identify Duplicate Records
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 识别重复记录
- en: Duplicate records in the dataset can skew analysis. So you should check for
    and drop the duplicate records as needed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的重复记录可能会扭曲分析结果。因此，你应该根据需要检查并删除重复记录。
- en: 'Here’s the code to identify and return duplicate rows in `df`. If there are
    any duplicate rows, they will be included in the result:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用于识别和返回 `df` 中重复行的代码。如果存在任何重复行，它们将包含在结果中：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result is an empty dataframe. Meaning there are no duplicate records in
    the dataset:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个空的 DataFrame。这意味着数据集中没有重复记录：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 3\. Check Data Types
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 检查数据类型
- en: When analyzing a dataset, you’ll often have to transform or scale one or more
    features. To avoid unexpected errors when performing such operations, it is important
    to check if the columns are all of the expected data type.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析数据集时，你通常需要转换或缩放一个或多个特征。为了避免在执行这些操作时出现意外错误，重要的是检查所有列是否都是预期的数据类型。
- en: 'This code checks the data types of each column in the dataframe `df`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码检查 DataFrame `df` 中每一列的数据类型：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, all numeric features are of `float` data type as expected:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，所有数值特征都是 `float` 数据类型，如预期：
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 4\. Check for Outliers
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 检查异常值
- en: Outliers are data points that are significantly different from other points
    in the dataset. If you remember, we ran the `describe()` method on the dataframe.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是数据集中与其他点显著不同的数据点。如果你还记得，我们在 DataFrame 上运行了 `describe()` 方法。
- en: 'Based on the quartile values and the maximum value, you could’ve identified
    that a subset of features contain outliers. Specifically, these features:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据四分位数值和最大值，你可以识别出某些特征包含异常值。具体来说，这些特征：
- en: MedInc
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MedInc
- en: AveRooms
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AveRooms
- en: AveBedrms
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AveBedrms
- en: Population
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口
- en: 'One approach to handling outliers is to use the [interquartile range](https://www.khanacademy.org/math/cc-sixth-grade-math/cc-6th-data-statistics/cc-6th/a/interquartile-range-review),
    the difference between the 75th and 25th quartiles. If Q1 is the 25th quartile
    and Q3 is the 75th quartile, then the interquartile range is given by: Q3 - Q1.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常值的一种方法是使用 [四分位距](https://www.khanacademy.org/math/cc-sixth-grade-math/cc-6th-data-statistics/cc-6th/a/interquartile-range-review)，即第75百分位数与第25百分位数之间的差异。如果
    Q1 是第25百分位数，Q3 是第75百分位数，则四分位距为：Q3 - Q1。
- en: We then use the quartiles and the IQR to define the interval `[Q1 - 1.5 * IQR,
    Q3 + 1.5 * IQR]`. And all points outside this range are outliers.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用四分位数和 IQR 来定义区间 `[Q1 - 1.5 * IQR, Q3 + 1.5 * IQR]`。所有超出此范围的点都是异常值。
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![7 Essential Data Quality Checks with Pandas](../Images/2c799aaf132686d2ac77a2b57ab6cb4a.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![7 个使用 Pandas 进行的基本数据质量检查](../Images/2c799aaf132686d2ac77a2b57ab6cb4a.png)'
- en: Outliers in 'AveRooms' Column | Truncated Output for Outliers Check
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '''AveRooms'' 列中的异常值 | 异常值检查的截断输出'
- en: 5\. Validate Numeric Ranges
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 验证数值范围
- en: An important check for numeric features is to validate the range. This ensures
    that all observations of a feature take on values in an expected range.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数值特征，一个重要的检查是验证范围。这确保了特征的所有观测值都在预期范围内。
- en: 'This code validates that the ''MedInc'' value falls within an expected range
    and identifies data points that do not meet this criteria:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码验证了 'MedInc' 值是否在预期范围内，并识别出不符合此标准的数据点：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can try for other numeric features of your choice. But we see that all
    values in the ''MedInc'' column lie in the expected range:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试其他你选择的数值特征。但我们看到 'MedInc' 列中的所有值都在预期范围内：
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 6\. Check Cross-Column Dependency
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 检查跨列依赖性
- en: Most data sets contain related features. So it's important to include checks
    based on logically relevant relationships between columns (or features).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据集包含相关特征。因此，基于列（或特征）之间逻辑相关关系的检查很重要。
- en: While features—individually—may take on values in the expected range, the relationship
    between them may be inconsistent.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管特征——单独来看——可能在预期范围内，但它们之间的关系可能不一致。
- en: Here is an example for our dataset. In a valid record, the ‘AveRooms’ should
    typically be greater than or equal to the ‘AveBedRms’.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们数据集的一个示例。在有效记录中，‘AveRooms’ 应通常大于或等于 ‘AveBedRms’。
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In the California housing dataset we’re working with, we see that there are
    no such invalid records:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们处理的加州住房数据集中，我们看到没有这些无效记录：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 7\. Check for Inconsistent Data Entry
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 检查不一致的数据输入
- en: 'Inconsistent data entry is a common data quality issue in most datasets. Examples
    include:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 不一致的数据输入是大多数数据集中常见的数据质量问题。示例包括：
- en: Inconsistent formatting in datetime columns
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: datetime 列中的格式不一致
- en: Inconsistent logging of categorical variable values
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类变量值的不一致记录
- en: Recording of reading in different units
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以不同单位记录的读数
- en: In our dataset, we’ve verified the data types of columns and have identified
    outliers. But you can also run checks for inconsistent data entry.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，我们已经验证了列的数据类型并识别出了异常值。但你也可以进行不一致数据录入的检查。
- en: Let’s whip up a simple example to check if all the date entries have a consistent
    formatting.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来一个简单的例子，检查所有日期条目是否具有一致的格式。
- en: 'Here we use regular expressions in conjunction with pandas `apply()` function
    to check if all date entries are in the `YYYY-MM-DD` format:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用正则表达式与 pandas 的 `apply()` 函数结合，以检查所有日期条目是否符合 `YYYY-MM-DD` 格式：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This returns the entries that do not follow the expected format:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回不符合预期格式的条目：
- en: '[PRE17]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Wrapping up
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this tutorial, we went over common data quality checks with pandas.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们讨论了 pandas 的常见数据质量检查。
- en: When you are working on smaller data analysis projects, these data quality checks
    with pandas are a good starting point. Depending on the problem and the dataset,
    you can include additional checks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在进行较小的数据分析项目时，这些使用 pandas 的数据质量检查是一个很好的起点。根据问题和数据集，你可以加入额外的检查。
- en: If you’re interested in learning data analysis, check out the guide [7 Steps
    to Mastering Data Wrangling with Pandas and Python](/7-steps-to-mastering-data-wrangling-with-pandas-and-python).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣学习数据分析，查看指南 [7 步掌握 Pandas 和 Python 数据整理](/7-steps-to-mastering-data-wrangling-with-pandas-and-python)。
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)**
    是来自印度的开发者和技术作者。她喜欢在数学、编程、数据科学和内容创作的交汇点上工作。她的兴趣和专长包括 DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和喝咖啡！目前，她正在通过撰写教程、操作指南、观点文章等与开发者社区分享她的知识。Bala
    还创建了引人入胜的资源概述和编码教程。'
- en: More On This Topic
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Data Quality Dimensions: Assuring Your Data Quality with Great Expectations](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据质量维度：用伟大期望保证你的数据质量](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)'
- en: '[Deep Learning For Compliance Checks: What''s New?](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于合规检查的深度学习：有什么新变化？](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测数据漂移以确保生产 ML 模型质量（使用 Eurybia）](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[Free 4 Week Data Science Course on AI Quality Management](https://www.kdnuggets.com/2022/02/truera-free-4-week-data-science-course-ai-quality-management.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费 4 周数据科学课程：AI 质量管理](https://www.kdnuggets.com/2022/02/truera-free-4-week-data-science-course-ai-quality-management.html)'
- en: '[The Significance of Data Quality in Making a Successful Machine…](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据质量在成功的机器学习模型中的重要性…](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
- en: '[Data Quality: The Good, The Bad, and The Ugly](https://www.kdnuggets.com/2022/01/data-quality-good-bad-ugly.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据质量：好、坏、丑](https://www.kdnuggets.com/2022/01/data-quality-good-bad-ugly.html)'
