- en: Why Automated Feature Engineering Will Change the Way You Do Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么自动化特征工程将改变你的机器学习方式
- en: 原文：[https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html](https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html](https://www.kdnuggets.com/2018/08/automated-feature-engineering-will-change-machine-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [William Koehrsen](https://twitter.com/koehrsen_will), Feature Labs**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [William Koehrsen](https://twitter.com/koehrsen_will)，Feature Labs**'
- en: '![Image](../Images/1aaf5ba4e7a7004049c3debb7a5c0f6c.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1aaf5ba4e7a7004049c3debb7a5c0f6c.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There are few certainties in data science — libraries, tools, and algorithms
    constantly change as better methods are developed. However, one trend that is
    not going away is the move towards *increased levels of automation.*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中少有确定性——库、工具和算法随着更好方法的发展不断变化。然而，有一个趋势不会消失，那就是向*更高水平的自动化*的转变。
- en: Recent years have seen progress in [automating model selection](https://epistasislab.github.io/tpot/api/) and [hyperparameter
    tuning](https://github.com/automl), but the [most important aspect](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) of
    the machine learning pipeline, [feature engineering](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html),
    has largely been neglected. The most capable entry in this critical field is [Featuretools](https://docs.featuretools.com/#minute-quick-start),
    an open-source Python library. In this article, we’ll use this library to see
    how automated feature engineering will change the way you do machine learning
    for the better.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，[模型选择的自动化](https://epistasislab.github.io/tpot/api/)和[超参数调整](https://github.com/automl)取得了进展，但机器学习流程中[最重要的方面](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)，[特征工程](https://www.kdnuggets.com/2018/12/feature-engineering-explained.html)，却在很大程度上被忽视了。这个关键领域中最有能力的条目是[Featuretools](https://docs.featuretools.com/#minute-quick-start)，一个开源Python库。本文将使用这个库，探讨自动化特征工程如何改善你的机器学习方式。
- en: '![](../Images/10c12c4dcee741fb89cad8717eb726dc.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10c12c4dcee741fb89cad8717eb726dc.png)'
- en: Featuretools is an open-source Python library for automated feature engineering.Automated
    feature engineering is a relatively new technique, but, after using it to solve
    a number of data science problems using real-world data sets, I’m convinced it
    should be a *standard *part of any machine learning workflow. Here we’ll take
    a look at the results and conclusions from two of these projects with the full [code
    available as Jupyter Notebooks on GitHub](https://github.com/Featuretools/Automated-Manual-Comparison).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Featuretools是一个用于自动化特征工程的开源Python库。自动化特征工程是一种相对较新的技术，但在用它解决了多个数据科学问题后，我相信它应该成为任何机器学习工作流的*标准*部分。这里我们将查看这些项目中的两个结果和结论，完整的[代码可在GitHub上作为Jupyter笔记本获取](https://github.com/Featuretools/Automated-Manual-Comparison)。
- en: 'Each project highlights some of the benefits of automated feature engineering:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目都突显了自动化特征工程的一些好处：
- en: '**Loan Repayment Prediction:** automated feature engineering can reduce machine
    learning development time by 10x compared to manual feature engineering while
    delivering better modeling performance. ([Notebooks](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Loan%20Repayment))'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贷款偿还预测：** 自动化特征工程相比于手动特征工程可以将机器学习开发时间缩短10倍，同时提供更好的建模性能。 ([笔记本](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Loan%20Repayment))'
- en: '**Retail Spending Prediction:** automated feature engineering creates meaningful
    features and prevents data leakage by internally handling time-series filters,
    enabling successful model deployment. ([Notebooks](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Retail%20Spending))'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零售支出预测：** 自动化特征工程创建有意义的特征，并通过内部处理时间序列过滤器来防止数据泄露，从而实现成功的模型部署。 ([笔记本](https://github.com/Featuretools/Automated-Manual-Comparison/tree/master/Retail%20Spending))'
- en: 'Feel free to dig into the code and try out Featuretools! (Full disclosure:
    I work for [Feature Labs](https://www.featurelabs.com/), the company developing
    the library. These projects were completed with the free, open-source version
    of Featuretools).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随意深入代码并尝试Featuretools！ (完全透明：我为[Feature Labs](https://www.featurelabs.com/)工作，该公司开发了这个库。这些项目是使用Featuretools的免费开源版本完成的。)
- en: '**Feature Engineering: Manual vs. Automated**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**特征工程：手动与自动化**'
- en: '[Feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) is
    the process of taking a dataset and constructing explanatory variables — features — that
    can be used to train a machine learning model for a prediction problem. Often,
    data is spread across multiple tables and must be gathered into a single table
    with rows containing the observations and features in the columns.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[特征工程](https://en.wikipedia.org/wiki/Feature_engineering)是将数据集转换为可用于训练机器学习模型的解释性变量——特征——的过程。通常，数据分布在多个表格中，需要将这些数据汇集到一个包含观察结果的行和特征的列的单一表格中。'
- en: The traditional approach to feature engineering is to build features one at
    a time using domain knowledge, a tedious, time-consuming, and error-prone process
    known as manual feature engineering. The code for manual feature engineering is *problem-dependent* and *must
    be re-written for each new dataset.*
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的特征工程方法是使用领域知识逐一构建特征，这是一种繁琐、耗时且容易出错的过程，称为手动特征工程。手动特征工程的代码是*问题依赖性的*，*必须为每个新的数据集重新编写。*
- en: Automated feature engineering improves upon this standard workflow by automatically
    extracting *useful and meaningful* features from a set of related data tables
    with a framework that can be applied *to any problem.* It not only cuts down on
    the time spent feature engineering, but creates interpretable features and prevents
    data leakage by filtering time-dependent data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化特征工程通过从一组相关数据表中自动提取*有用且有意义*的特征，并使用一个可以*应用于任何问题*的框架来改进这一标准工作流程。它不仅减少了特征工程所花费的时间，而且创建了可解释的特征，并通过过滤时间相关的数据来防止数据泄露。
- en: Automated feature engineering is more efficient and repeatable than manual feature
    engineering allowing you to build better predictive models faster.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化特征工程比手动特征工程更高效且可重复，使你能够更快地构建更好的预测模型。
- en: 'Loan Repayment: Build Better Models Faster'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贷款偿还：更快地构建更好的模型
- en: The primary difficulty facing a data scientist approaching the Home Credit Loan
    problem (a [machine learning competition currently running on Kaggle](https://www.kaggle.com/c/home-credit-default-risk)where
    the objective is to predict if a loan will be repaid by a client) is the size
    and spread of the data. Take a look at the complete dataset and you are confronted
    with *58 million* rows of data spread across seven tables. Machine learning requires
    a single table for training, so feature engineering means consolidating all the
    information about each client in one table.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 面对家庭信贷贷款问题（一个正在[Kaggle上进行的机器学习竞赛](https://www.kaggle.com/c/home-credit-default-risk)，目标是预测贷款是否会被客户偿还），数据科学家主要面临的难题是数据的规模和分布。查看完整数据集，你会发现*5800万*行数据分布在七个表格中。机器学习需要一个单一的表格用于训练，因此特征工程意味着将每个客户的所有信息整合到一个表格中。
- en: '![](../Images/5b75cf347c83b5be9c654ee9726f78c8.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b75cf347c83b5be9c654ee9726f78c8.png)'
- en: 'Feature engineering requires capturing all information from a set of related
    tables into one table.My first attempt at the problem used traditional manual
    feature engineering: I spent a total of **10 hours **creating a set of features
    by hand. First I read [other data scientist’s work](https://www.kaggle.com/c/home-credit-default-risk/kernels),
    explored the data, and researched the problem area in order to acquire the necessary
    domain knowledge. Then I translated the knowledge into code, building one feature
    at a time. As an example of a single manual feature, I found the total number
    of late payments a client had on previous loans, an operation that required using
    3 different tables.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程需要将一组相关表中的所有信息捕捉到一个表中。我第一次尝试这个问题时使用了传统的手动特征工程：我花了总共**10小时**手动创建了一组特征。首先，我阅读了[其他数据科学家的工作](https://www.kaggle.com/c/home-credit-default-risk/kernels)，探索数据，并研究了问题领域以获得必要的领域知识。然后我将知识转化为代码，一次构建一个特征。作为一个手动特征的示例，我找到了客户在以前贷款上的逾期总数，这一操作需要使用3个不同的表。
- en: The final manual engineered features performed quite well, achieving a 65% improvement
    over the baseline features (relative to the top leaderboard score), indicating
    the [importance of proper feature engineering](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最终手动工程的特征表现相当不错，相对于基准特征（相对于最高排行榜分数），实现了65%的改进，表明了[适当特征工程的重要性](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)。
- en: However, inefficient does not even begin to describe this process. For manual
    feature engineering, I ended up spending over 15 minutes per feature because I
    used the traditional approach of making a single feature at a time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，低效甚至无法描述这个过程。对于手动特征工程，我最终每个特征花费了超过15分钟，因为我使用了逐个特征制作的传统方法。
- en: '![](../Images/b5a4fa499842a9d508e2bbf236732acf.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5a4fa499842a9d508e2bbf236732acf.png)'
- en: 'The Manual Feature Engineering process.Besides being tedious and time-consuming,
    manual feature engineering is:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 手动特征工程过程。除了繁琐和耗时，手动特征工程还包括：
- en: '**Problem-specific:** all of the code I wrote over many hours cannot be applied
    to *any other problem*'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题特定：**我花了很多小时编写的所有代码都不能应用于*任何其他问题*'
- en: '**Error-prone:** each line of code is another opportunity to make a mistake'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易出错：**每行代码都是犯错的机会'
- en: 'Furthermore, the final manual engineered features are limited both by **human
    creativity **and **patience**: there are only so many features we can think to
    build and only so much time we have to make them.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，最终的手动工程特征受限于**人类创造力**和**耐心**：我们能构思的特征数量有限，我们有的时间也有限。
- en: The promise of automated feature engineering is to surpass these limitations
    by taking a set of related tables and automatically building hundreds of useful
    features using code that can be applied across all problems.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动特征工程的承诺在于通过利用一组相关表格并自动构建数百个有用的特征，来超越这些限制，这些代码可以应用于所有问题。
- en: '**From Manual to Automated Feature Engineering**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**从手动到自动特征工程**'
- en: As implemented in Featuretools, automated feature engineering allows even a
    domain novice such as myself to create thousands of relevant features from a set
    of related data tables. All we need to know is the basic structure of our tables
    and the relationships between them which we track in a single data structure called
    an [entity set](https://docs.featuretools.com/generated/featuretools.EntitySet.html).
    Once we have an entity set, using a method called [Deep Feature Synthesis](https://www.featurelabs.com/blog/deep-feature-synthesis/) (DFS),
    we’re able to build thousands of features in *one function call*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如Featuretools中所实现的，自动特征工程使得像我这样的领域新手也能从一组相关的数据表中创建数千个相关特征。我们需要知道的只是表的基本结构和它们之间的关系，我们在一个名为[实体集](https://docs.featuretools.com/generated/featuretools.EntitySet.html)的数据结构中跟踪这些关系。一旦我们有了实体集，使用一种名为[深度特征合成](https://www.featurelabs.com/blog/deep-feature-synthesis/)（DFS）的方法，我们能够在*一次函数调用*中构建数千个特征。
- en: '![](../Images/8233ab01f8616439d3a2fc6b064fc404.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8233ab01f8616439d3a2fc6b064fc404.png)'
- en: The Automated Feature Engineering process using Featuretools.DFS works using
    functions called [“primitives”](https://docs.featuretools.com/automated_feature_engineering/primitives.html) to
    aggregate and transform our data. These primitives can be as simple as taking
    a mean or a max of a column, or they can be complex and based on subject expertise
    because [Featuretools allows us to define our own custom primitives](https://docs.featuretools.com/guides/advanced_custom_primitives.html).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Featuretools.DFS 的自动化特征工程过程通过称为 [“primitives”](https://docs.featuretools.com/automated_feature_engineering/primitives.html)的函数来聚合和转换我们的数据。这些原语可以简单到对列取均值或最大值，也可以复杂到基于主题专业知识，因为 [Featuretools
    允许我们定义自己的自定义原语](https://docs.featuretools.com/guides/advanced_custom_primitives.html)。
- en: Feature primitives include many operations we already would do manually by hand,
    but with Featuretools, instead of re-writing the code to apply these operations
    on different datasets, we can use the *same exact *syntax across any relational
    database. Moreover, the power of DFS comes when we stack primitives on each other
    to create deep features. (For more on DFS, take a look at [this blog post](https://www.featurelabs.com/blog/deep-feature-synthesis/) by
    one of the inventors of the technique.)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 特征原语包括我们通常会手动执行的许多操作，但使用 Featuretools 时，我们可以在任何关系数据库中使用*完全相同*的语法，而不是重新编写代码以应用这些操作。此外，当我们将原语堆叠在一起以创建深层特征时，DFS
    的强大功能才会显现。（有关 DFS 的更多信息，请查看 [this blog post](https://www.featurelabs.com/blog/deep-feature-synthesis/) ，由该技术的发明者之一撰写。）
- en: Deep Feature Synthesis is flexible — allowing it to be applied to any data science
    problem — and powerful — revealing insights in our data by creating deep features.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 深度特征合成是灵活的——允许它应用于任何数据科学问题——也是强大的——通过创建深层特征揭示我们数据中的洞察。
- en: 'I’ll spare you the few lines of code needed for the set-up, but the action
    of DFS happens in a single line. Here we make *thousands of features* for each
    client using all 7 tables in our dataset (`ft` is the imported featuretools library):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我将省略设置所需的几行代码，但 DFS 的操作在一行代码中完成。在这里，我们使用数据集中所有 7 个表为每个客户生成*数千个特征*（`ft` 是导入的
    featuretools 库）：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Below are some of the **1820 features** we automatically get from Featuretools:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们从 Featuretools 自动获得的一些**1820 个特征**：
- en: The maximum total amount paid on previous loans by a client. This is created
    using a `MAX` and a `SUM` primitive across 3 tables.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在以往贷款上的最大总支付额。这是使用 `MAX` 和 `SUM` 原语跨越 3 个表创建的。
- en: The percentile ranking of a client in terms of average previous credit card
    debt. This uses a `PERCENTILE` and `MEAN` primitive across 2 tables.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在以往信用卡债务的百分位排名。这使用了一个 `PERCENTILE` 和一个 `MEAN` 原语跨越 2 个表。
- en: Whether or not a client turned in two documents during the application process.
    This uses a `AND` transform primitive and 1 table.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户在申请过程中是否提交了两份文件。这使用了一个 `AND` 转换原语和 1 个表。
- en: Each of these features is built using simple aggregations and hence is human-interpretable.
    Featuretools created many of the same features I did manually, but also thousands
    I never would have conceived — or had the time to implement. Not every single
    feature will be relevant to the problem, and some of the features are highly correlated,
    nonetheless, having *too many features is a better problem than having too few*!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征中的每一个都是通过简单的聚合构建的，因此是可以被人理解的。Featuretools 创建了许多我手动实现的相同特征，但也创造了数千个我从未想到过的特征——或没有时间实现的特征。并非每个特征对问题都相关，有些特征高度相关，不过，*特征过多总比特征过少是一个更好的问题*！
- en: After a little feature selection and model optimization, these features did
    slightly better in a predictive model compared to the manual features with an
    overall development time of **1 hour**, a 10x reduction compared to the manual
    process. Featuretools is much faster both because it requires less domain knowledge
    and because there are considerably fewer lines of code to write.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行了一些特征选择和模型优化后，这些特征在预测模型中的表现略优于手动特征，整体开发时间为**1小时**，相比手动过程减少了 10 倍。Featuretools
    更快，因为它需要的领域知识更少，并且需要编写的代码行数也大大减少。
- en: I’ll admit that there is a slight time cost to learning Featuretools but it’s
    an investment that will pay off. After taking an hour or so to learn Featuretools,
    you can apply it *to any machine learning *problem.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我承认，学习 Featuretools 有一点时间成本，但这是一个值得的投资。学习 Featuretools 大约需要一个小时，你可以将其应用于*任何机器学习*问题。
- en: 'The following graphs sum up my experience for the loan repayment problem:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了我在贷款还款问题上的经验：
- en: '![Image](../Images/d1ad6837257f31146ded86b94dda4e60.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/d1ad6837257f31146ded86b94dda4e60.png)'
- en: Comparison between automated and manual feature engineering on time, number
    of features, and performance.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化与手动特征工程在时间、特征数量和性能方面的比较。
- en: 'Development time: accounts for everything required to make the final feature
    engineering code: **10 hours manual vs 1 hour automated**'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发时间：完成最终特征工程代码所需的一切：**10 小时手动 vs 1 小时自动**
- en: Number of features produced by the method: **30 features manual vs 1820 automated**
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法生成的特征数量：**30 个特征手动 vs 1820 个自动**
- en: Improvement relative to baseline is the % gain over the baseline compared to
    the top public leaderboard score using a model trained on the features: **65%
    manual vs 66% automated**
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对基线的改进是相对于基线的百分比增益，与使用特征训练的模型在公开排行榜上的最佳分数相比：**65% 手动 vs 66% 自动**
- en: My takeaway is that automated feature engineering will not replace the data
    scientist, but rather by significantly increasing efficiency, it will free her
    to spend more time on other aspects of the machine learning pipeline.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的收获是，自动化特征工程不会取代数据科学家，而是通过显著提高效率，使她能够将更多时间用于机器学习流程的其他方面。
- en: Furthermore, the Featuretools code I wrote for this first project could be applied
    to any dataset while the manual engineering code would have to be thrown away
    and entirely rewritten for the next dataset!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我为第一个项目编写的 Featuretools 代码可以应用于任何数据集，而手动工程代码则必须丢弃并为下一个数据集完全重写！
- en: 'Retail Spending: Build Meaningful Features and Prevent Data Leakage'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零售支出：构建有意义的特征并防止数据泄漏
- en: For the second dataset, a [record of online time-stamped customer transactions](https://archive.ics.uci.edu/ml/datasets/online+retail#),
    the prediction problem is to classify customers into two segments, those who will
    spend more than $500 in the next month and those who won’t. However, instead of
    using a single month for all the labels, each customer is a label *multiple times*.
    We can use their spending in May as a label, then in June, and so on.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个数据集，[在线时间戳客户交易记录](https://archive.ics.uci.edu/ml/datasets/online+retail#)，预测问题是将客户分类为两个群体：那些在下个月花费超过
    $500 的客户和那些不会花费的客户。然而，与其为所有标签使用单个月份，每个客户的标签*会出现多次*。我们可以使用他们在五月的支出作为标签，然后是六月，以此类推。
- en: '![](../Images/40c4b456b5b3b1fc2729f740921fb539.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40c4b456b5b3b1fc2729f740921fb539.png)'
- en: 'Each customer is used as a training example multiple timesUsing each customer
    multiple times as an observation brings up difficulties for creating training
    data: when making features for a customer for a given month, we can’t use any
    information from months in the future, *even though we have access to this data*.
    In a deployment, we’ll *never have future data* and therefore can’t use it for
    training a model. Companies routinely struggle with this issue and often deploy
    a model that does much worse in the real world than in development because it
    was trained using invalid data.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 每个客户作为训练样本被多次使用。使用每个客户作为观察对象多次会带来创建训练数据的困难：在为某个月的客户制作特征时，我们不能使用未来月份的信息，*即使我们可以访问这些数据*。在部署中，我们*永远无法获得未来数据*，因此不能用于训练模型。公司通常会面临这个问题，并经常部署在现实世界中表现远逊于开发阶段的模型，因为它是使用无效数据训练的。
- en: Fortunately, ensuring that our data is valid in a time-series problem is [straightforward
    in Featuretools. ](https://docs.featuretools.com/automated_feature_engineering/handling_time.html)In
    the Deep Feature Synthesis function we pass in a dataframe like that shown above,
    where the cutoff time represents the point past which we can’t use any data for
    the label, and Featuretools *automatically* takes the time into account when building
    features.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，确保我们在时间序列问题中的数据有效性是[在 Featuretools 中很简单的](https://docs.featuretools.com/automated_feature_engineering/handling_time.html)。在
    Deep Feature Synthesis 函数中，我们传入如上所示的数据框，其中截止时间表示我们不能用于标签的数据点，Featuretools 在构建特征时会*自动*考虑时间。
- en: The features for a customer in a given month are built using data filtered to
    before the month. Notice that the call to create our set of features is the same
    as that for the loan repayment problem with the addition of `cutoff_time.`
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 某个月的客户特征是使用过滤到该月之前的数据构建的。请注意，创建我们特征集合的调用与贷款还款问题中的调用相同，只是多了`cutoff_time`。
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The result of running Deep Feature Synthesis is a table of features, one for
    each customer *for each month*. We can use these features to train a model with
    our labels and then make predictions for any month. Moreover, we can rest assured
    that the features in our model do not use future information, which would result
    in an unfair advantage and yield misleading training scores.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 运行深度特征合成的结果是一个特征表，每个客户*每个月*都有一个。我们可以利用这些特征训练一个带有标签的模型，然后对任何月份进行预测。此外，我们可以放心，模型中的特征不会使用未来的信息，这会导致不公平的优势和误导性的训练得分。
- en: With the automated features, I was able to build a machine learning model that
    achieved 0.90 ROC AUC compared to an informed baseline (guessing the same level
    of spending as the previous month) of 0.69 when predicting customer spending categories
    for one month.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自动特征，我能够构建一个机器学习模型，其ROC AUC达到了0.90，相比之下，基线模型（预测与前一个月相同的花费水平）的ROC AUC为0.69，用于预测一个月的客户花费类别。
- en: 'In addition to delivering impressive predictive performance, the Featuretools
    implementation gave me something equally valuable: interpretable features. Take
    a look at the 15 most important features from a random forest model:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供令人印象深刻的预测性能外，Featuretools的实现还给了我同样宝贵的东西：可解释的特征。请查看随机森林模型中最重要的15个特征：
- en: '![](../Images/ff083e61483b98ff52a2818ffa34a613.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff083e61483b98ff52a2818ffa34a613.png)'
- en: 15 most important Featuretools features from a random forest model.The feature
    importances tell us that the most important predictors of how much the customer
    will spend in the next month is how much they have spent previously `SUM(purchases.total)`,
    and the number of purchases, `SUM(purchases.quantity).` These are features that
    we could have built by hand, but then we would have to worry about leaking data
    and creating a model that does much better in development than in deployment.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从随机森林模型中提取的15个最重要的Featuretools特征。特征重要性告诉我们，预测客户下个月花费多少的最重要指标是他们之前的花费`SUM(purchases.total)`以及购买次数`SUM(purchases.quantity)`。这些特征本可以手动构建，但那样我们就得担心数据泄漏，并且可能在开发时表现良好，但在实际应用中效果却差。
- en: If the tool already exists for creating meaningful features without any need
    to worry about the validity of our features, then why do the implementation by
    hand? Furthermore, the automated features are completely clear in the context
    of the problem and can inform our real-world reasoning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已经存在工具来创建有意义的特征，而无需担心特征的有效性，那么为什么还要手动实现呢？此外，自动特征在问题背景中完全清晰，可以指导我们的现实世界推理。
- en: 'Automated feature engineering identified the most important signals, achieving
    the primary goal of data science: reveal insights hidden in mountains of data.'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动特征工程识别了最重要的信号，实现了数据科学的主要目标：揭示隐藏在大量数据中的洞察。
- en: 'Even after spending significantly more time on manual feature engineering than
    I did with Featuretools, I was not able to develop a set of features with close
    to the same performance. The graph below shows the ROC curves for classifying
    one month of future customer sales using a model trained on the two datasets.
    A curve to the left and top indicates better predictions:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 即便在手动特征工程上花费了比使用Featuretools更多的时间，我也未能开发出接近同等性能的特征集。下面的图表显示了在使用两个数据集训练的模型上对未来一个月客户销售进行分类的ROC曲线。曲线越向左上方表示预测越好：
- en: '![](../Images/b4281a47906f49d0918ad72243c61fc4.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4281a47906f49d0918ad72243c61fc4.png)'
- en: ROC curves comparing automated and manual feature engineering results. A curve
    to the left and top indicates better performance.I’m not even completely sure
    if the manual features were made using valid data, but with the Featuretools implementation,
    I didn’t have to worry about data leakage in time-dependent problems. Maybe this
    inability to manually engineer a useful set of valid features speaks to my failings
    as a data scientist, but if the tool exists to safely do this for us, why not
    use it?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 比较自动特征工程和手动特征工程结果的ROC曲线。曲线越向左上方表示性能越好。我甚至不完全确定手动特征是否使用了有效的数据，但使用Featuretools的实现，我不必担心时间相关问题中的数据泄漏。也许无法手动工程出有用的有效特征反映了我作为数据科学家的不足，但如果工具可以安全地为我们完成这项工作，为什么不使用呢？
- en: We use automatic safety systems in our day-to-day life and automated feature
    engineering in Featuretools is the secure method to build meaningful machine learning
    features in a time-series problem while delivering superior predictive performance.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们在日常生活中使用自动安全系统，而 Featuretools 中的自动特征工程是构建有意义的时间序列机器学习特征的安全方法，同时提供优越的预测性能。
- en: Conclusions
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: I came away from these projects convinced that automated feature engineering
    should be an *integral part of the machine learning workflow*. The technology
    is not perfect yet still delivers significant gains in efficiency.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我从这些项目中深信，自动特征工程应该成为*机器学习工作流程的一个不可或缺的部分*。尽管技术尚不完美，但仍能显著提升效率。
- en: 'The main conclusions are that automated feature engineering:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 主要结论是自动特征工程：
- en: '**Reduced implementation time** by up to 10x'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将实施时间减少**多达 10 倍'
- en: Achieved modeling **performance at the same level** **or better**
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现了与**同等水平**或**更佳**的建模**性能**
- en: Delivered **interpretable features** with real-world significance
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了**具有现实世界意义的可解释特征**
- en: '**Prevented improper data usage** that would invalidate a model'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**防止不当的数据使用**，以免使模型失效'
- en: '**Fit into existing workflows** and machine learning models'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**融入现有工作流程**和机器学习模型'
- en: '“Work smarter, not harder” may be a cliche, but sometimes there is truth to
    platitudes: if there is a way to do the same job with the same performance for
    a smaller time investment, then clearly it’s a method worth learning.'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “聪明地工作，而不是更努力”可能是个陈词滥调，但有时候这些空话中确实包含真理：如果有一种方法可以用更少的时间投入获得相同的结果，那么显然这是值得学习的方法。
- en: '[Featuretools](https://www.featuretools.com/) will always be free to use and
    open-source (contributions are welcome), and there are several examples — [here’s
    an article I’ve written](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219) — to
    get you started in 10 minutes. Your job as a data scientist is safe, but it can
    be made significantly easier with automated feature engineering.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[Featuretools](https://www.featuretools.com/) 将始终免费使用并且开源（欢迎贡献），还有几个例子 — [这是我写的一篇文章](https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219) — 可以在
    10 分钟内让你入门。你的数据科学工作是安全的，但通过自动特征工程可以显著简化工作。'
- en: If building meaningful, high-performance predictive models is something you
    care about, then get in touch with us at [Feature Labs](https://www.featurelabs.com/contact/).
    While this project was completed with the open-source Featuretools, the [commercial
    product](https://www.featurelabs.com/product) offers additional tools and support
    for creating machine learning solutions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你关心构建有意义的高性能预测模型，那么可以通过 [Feature Labs](https://www.featurelabs.com/contact/)
    联系我们。尽管这个项目是使用开源的 Featuretools 完成的，但[商业产品](https://www.featurelabs.com/product)提供了额外的工具和支持来创建机器学习解决方案。
- en: '**Bio: [Will Koehrsen](https://twitter.com/koehrsen_will)** is a Data Scientist
    at Feature Labs, and a Data Science Communicator and Advocate.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Will Koehrsen](https://twitter.com/koehrsen_will)** 是 Feature Labs 的数据科学家，同时也是数据科学的传播者和倡导者。'
- en: '[Original](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96).
    Reposted with permission.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/why-automated-feature-engineering-will-change-the-way-you-do-machine-learning-5c15bf188b96)。已获许可转载。'
- en: '**Related:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Feature Synthesis: How Automated Feature Engineering Works](/2018/02/deep-feature-synthesis-automated-feature-engineering.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度特征合成：自动特征工程如何运作](/2018/02/deep-feature-synthesis-automated-feature-engineering.html)'
- en: '[Quick Feature Engineering with Dates Using fast.ai](/2018/03/feature-engineering-dates-fastai.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 fast.ai 快速特征工程](/2018/03/feature-engineering-dates-fastai.html)'
- en: '[Basic Concepts of Feature Selection](/2017/11/rapidminer-basic-concepts-feature-selection.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征选择的基本概念](/2017/11/rapidminer-basic-concepts-feature-selection.html)'
- en: More On This Topic
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Forget ChatGPT, This New AI Assistant Is Leagues Ahead and Will…](https://www.kdnuggets.com/2023/08/forget-chatgpt-new-ai-assistant-leagues-ahead-change-way-work-forever.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[忘记 ChatGPT，这款新的 AI 助手遥遥领先，将…](https://www.kdnuggets.com/2023/08/forget-chatgpt-new-ai-assistant-leagues-ahead-change-way-work-forever.html)'
- en: '[Feature Store Summit 2022: A free conference on Feature Engineering](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Feature Store Summit 2022：一个关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
- en: '[A Practical Approach To Feature Engineering In Machine Learning](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的特征工程实用方法](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
- en: '[Building a Tractable, Feature Engineering Pipeline for Multivariate…](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建可处理的特征工程管道用于多变量…](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
- en: '[Using RAPIDS cuDF to Leverage GPU in Feature Engineering](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 RAPIDS cuDF 利用 GPU 进行特征工程](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
- en: '[Feature Engineering for Beginners](https://www.kdnuggets.com/feature-engineering-for-beginners)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征工程入门](https://www.kdnuggets.com/feature-engineering-for-beginners)'
