- en: YOLOv5 PyTorch Tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/677a6a1db1a597d6d66c9f2dce9867b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Using YOLOv5 in PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: YOLO, an acronym for 'You only look once,’ is an open-source software tool utilized
    for its efficient capability of detecting objects in a given image in real time.
    The YOLO algorithm uses convolutional neural network (CNN) models to detect objects
    in an image.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm requires only one forward propagation through a given neural network
    to detect all objects in the image. This gives the YOLO algorithm an edge in speed
    over others, making it one of the most well-known detection algorithms to date.
  prefs: []
  type: TYPE_NORMAL
- en: What is YOLO Object Detection?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An object detection algorithm is an algorithm that is capable of detecting certain
    objects or shapes in a given frame. For example, simple detection algorithms may
    be capable of detecting and identifying shapes in an image such as circles or
    squares, while more advanced detection algorithms can detect more complex objects
    such as humans, bicycles, cars, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Not only does the YOLO algorithm offer high detection speed and performance
    through its one-forward propagation capability, but it also detects them with
    great accuracy and precision.
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we will focus on [YOLOv5](https://github.com/ultralytics/yolov5),
    which is the fifth and latest version of the YOLO software. It was originally
    released on the 18th of May 2020\. The YOLO open-source code can be found on [GitHub](https://github.com/ultralytics/yolov5).
    We will be using YOLO with the well-known PyTorch library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PyTorch](https://pytorch.org/) is a deep learning open-source package that
    is based on the well-known Torch library. It''s also a Python-based library that
    is more commonly used for natural language processing and computer vision.'
  prefs: []
  type: TYPE_NORMAL
- en: How does the YOLO Algorithm Work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Step 1: Residual Blocks (Dividing the Image Into Smaller, Grid-Like Boxes)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this step, the complete (whole) frame is divided into smaller boxes or grids.
  prefs: []
  type: TYPE_NORMAL
- en: All the grids are drawn over the original image sharing the exact shape and
    size. The idea behind these divisions is that each grid box will detect the different
    objects inside it.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/b697b57190ca3e06f2f0b3b6d35ee00f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 2: Bounding Box Regression (Identifying the Object Inside a Bounding Box)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After detecting a given object in an image, a bounding box is drawn surrounding
    it. The bounding box has parameters such as the **center point, height, width,
    and class (object type detected)**.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/e8b6c4eab9ee049ccef69744a4194440.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 3: Intersection Over Union (IOU)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/30111de8b4f85a72d7daa1d9005134ca.png)'
  prefs: []
  type: TYPE_IMG
- en: The **IOU**, short for **intersection over union**, is used to calculate our
    model's accuracy. This is achieved by quantifying the degree of intersection of
    two boxes which are the real value box (red box in image) and the box returned
    from our result (blue box in image).
  prefs: []
  type: TYPE_NORMAL
- en: In the tutorial portion of this article, we identified our IOU value as 40 percent,
    meaning that if the intersection of the two boxes is below 40 percent then this
    prediction should not be taken into consideration. This is done to help us calculate
    the accuracy of our predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Below is an image showing the complete process of the YOLO detection algorithm
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/1c627f3285b1a1621a7bf28cb7243337.png)'
  prefs: []
  type: TYPE_IMG
- en: For additional information on how the YOLO algorithm works, view the [Introduction
    to YOLO algorithm](https://www.section.io/engineering-education/introduction-to-yolo-algorithm-for-object-detection/#:~:text=YOLO%20is%20an%20algorithm%20that,%2C%20parking%20meters%2C%20and%20animals.).
  prefs: []
  type: TYPE_NORMAL
- en: What are we Trying to Achieve with our Model?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main goal of the example in this tutorial is to use the YOLO algorithm to
    detect a list of chest diseases in a given image. As with any machine learning
    model, we will run ours using thousands of chest-scanned images. The goal is for
    the YOLO algorithm to successfully detect all lesions in the given image.
  prefs: []
  type: TYPE_NORMAL
- en: Data Set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [VinBigData 512 image Dataset](https://www.kaggle.com/datasets/awsaf49/vinbigdata-512-image-dataset) used
    in this tutorial can be found on Kaggle. The data set is divided into two parts,
    the training, and the testing data sets. The training data set contains 15,000
    images, while the testing data set contains 3,000\. This division of data between
    the training and the testing is somehow optimal as the training data set is usually
    4 to 5 times the size of the testing data set.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/495e553306a0277e683d55dfe65641c1.png)'
  prefs: []
  type: TYPE_IMG
- en: The other part of the data set contains the label for all the images. Inside
    this data set each image is labeled with a class name (chest disease found), along
    with the class ID, width and height of the image, etc. Check the below image to
    view all the columns available.
  prefs: []
  type: TYPE_NORMAL
- en: '![YOLOv5 PyTorch Tutorial](../Images/ab2b60451cc644a880b98d46a39186da.png)'
  prefs: []
  type: TYPE_IMG
- en: YOLOv5 Tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Note:** You can view the [original code](https://www.kaggle.com/code/mostafaibrahim17/yolov5/notebook) used
    in this example on Kaggle.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 1: Importing the Necessary Libraries'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start with, we will import the required libraries and packages at the very
    beginning of our code. First, let's explain some of the more common libraries
    that we just imported. NumPy is an open-source numerical Python library that allows
    users to create matrices and perform a number of mathematical operations on them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Defining Our Paths'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make our life easier, we will start by defining the direct paths to the labels
    and the images of the training and testing data sets.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Importing and Reading the Textual Dataset'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we will import and read the textual data set. This data is stored as rows
    and columns in a CSV file format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Note:** the df.head() function prints the first 5 rows of the given data
    set.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Step 4: Filtering and Cleaning the Data Set'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As no data set is perfect, most of the time a filtering process is necessary
    to optimize a data set, thus optimizing our model’s performance. In this step,
    we would drop any row with a class id that is equal to 14.
  prefs: []
  type: TYPE_NORMAL
- en: This class id stands for a no finding in the disease class. The reason we dropped
    this class is that it may confuse our model. Moreover, it will slow it down because
    our data set will be slightly bigger.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 5: Calculating the Coordinates of the Bounding Box for YOLO'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously in the **'How does the YOLO algorithm work section'** (particularly
    steps 1 and 2), the YOLO algorithm expects the dataset to be in a certain format.
    Here we will be going through the dataframe and applying a few transformations.
  prefs: []
  type: TYPE_NORMAL
- en: The end goal of the below code is to calculate the new x-mid, y-mid, width,
    and height dimensions for each data point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 6: Changing the Provided Data Format'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this part of the code, we will change the given data format of all rows in
    the dataset into the following columns; <class> <x_center> <y_center> <width>
    <height>.This is necessary since the YOLOv5 algorithm can only read the data in
    this specific format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We will then run the preproccess_data function two times, once with the training
    data set and its images, and the second with the testing data set and its images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Using the line below, we will clone the YOLOv5 algorithm into our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 7: Defining our Model’s Classes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we will define the available 14 chest diseases in our models as classes.
    These are the actual diseases that can be identified in the data set’s images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 8: Training the Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start, we will open the YOLOv5 directory. Then we will use pip in order to
    install all the libraries written inside the requirements file.
  prefs: []
  type: TYPE_NORMAL
- en: The requirements file contains all the required libraries that the code base
    needs to work. We will also install other libraries such as pycocotools, seaborn,
    and pandas.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Wandb, short for weights and biases, allows us to monitor a given neural network
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now we will train the YOLOv5 on the vinbigdata set provided for 100 epochs.
    We’ll also pass some other flags such as --img 512 which tells the model that
    our image size is 512 pixels, --batch 16 will allow our model to take 16images
    per batch. Using the --data ./vinbigdata.yaml flag we will pass our dataset which
    is the vinbigdata.yaml data set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 9: Evaluating the Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we will identify the testing data set directory along with the weights
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this part, we will use the detect.py as our inference to check the accuracy
    of our predictions. We will also pass some flags such as --conf 0.15\ which is
    the model's confidence threshold. If the confidence rate of a detected object
    is under 15 percent then remove it from our output. The --iou 0.4\ flag informs
    our model that if the intersection over the union of two boxes is below 40 percent
    then it should be removed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we explained what YOLOv5 is and how the basic YOLO algorithm
    works. Next, we went on to briefly explain PyTorch. Then we covered a couple of
    reasons why you should use YOLO over other, similar detection algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we walked you through a machine-learning model that is capable of detecting
    chest diseases in x-ray images. In this example, we used YOLO as our main detection
    algorithm to find and locate chest lesions. We then classified each lesion into
    a given class or disease.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in machine learning and building your own models, especially
    models that require the detection of multiple objects in a given image or video
    representation, then YOLOv5 is definitely worth a try.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact Corp
    blog and works with many of its talented authors who write about different aspects
    of Deep Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://exxactcorp.com/blog/Deep-Learning/YOLOv5-PyTorch-Tutorial).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tuning Adam Optimizer Parameters in PyTorch](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Practical Guide to Transfer Learning using PyTorch](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch Tips to Boost Your Productivity](https://www.kdnuggets.com/2023/08/pytorch-tips-boost-productivity.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
