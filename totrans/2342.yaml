- en: The Gap Between Deep Learning and Human Cognitive Abilities
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习与人类认知能力之间的差距
- en: 原文：[https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html](https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html](https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html)
- en: '![The Gap Between Deep Learning and Human Cognitive Abilities](../Images/43a8377c5f6fc2d5c4ac39328d20d5bc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![深度学习与人类认知能力之间的差距](../Images/43a8377c5f6fc2d5c4ac39328d20d5bc.png)'
- en: Photo by [David Cassolato](https://www.pexels.com/photo/person-holding-string-lights-photo-818563/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [David Cassolato](https://www.pexels.com/photo/person-holding-string-lights-photo-818563/)
    提供
- en: Hi! I am Bohdan Ponomar, CEO at the [AI HOUSE](https://aihouse.org.ua/) community.
    We are part of the ecosystem being built up by [Roosh](https://jobs.dou.ua/companies/roosh/)
    technology company. Roosh creates ML/AI projects and invests in innovative ideas
    in the industry. Our ecosystem also includes Pawa venture studio, Roosh Ventures
    venture fund, SET University technological university, Reface and ZibraAI startups,
    and Neurons Lab company.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 嗨！我是 [AI HOUSE](https://aihouse.org.ua/) 社区的首席执行官**博赫丹·波诺马尔**。我们是由 [Roosh](https://jobs.dou.ua/companies/roosh/)
    技术公司构建的生态系统的一部分。Roosh 创建 ML/AI 项目并投资于行业中的创新想法。我们的生态系统还包括 Pawa 风投工作室、Roosh Ventures
    风投基金、SET University 科技大学、Reface 和 ZibraAI 初创公司，以及 Neurons Lab 公司。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In August 2022, we launched a new educational project 'AI for Ukraine' — a series
    of workshops and lectures held by international artificial intelligence experts
    to support the development of Ukraine’s tech community.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年8月，我们启动了一个新的教育项目“AI for Ukraine”——一系列由国际人工智能专家主讲的研讨会和讲座，旨在支持乌克兰科技社区的发展。
- en: The first lecture of the series was delivered by Yoshua Bengio, professor at
    the University of Montreal, founder and scientific director of the Quebec Artificial
    Intelligence Institute, head of the CIFAR Learning in Machines & Brains program,
    and one of the leading experts in the AI industry. In 2022, he became the computer
    scientist with the highest h-index in the world.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 系列的第一讲由蒙特利尔大学的教授**约书亚·本吉奥**主讲，他是魁北克人工智能研究所的创始人和科学主任，CIFAR 机器与大脑学习计划的负责人，以及 AI
    行业的领先专家之一。2022年，他成为全球 h-index 最高的计算机科学家。
- en: During the lecture, the professor covers his research project, which aimed to
    bridge the gap between modern AI based on Deep Learning, and human intelligence
    featuring creativity. The full recording is available [here](https://aiforukraine.aihouse.club/#agenda)
    for a donation, and in this article, we cover the main points of the lecture.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在讲座中，教授介绍了他的研究项目，旨在弥合基于深度学习的现代 AI 与具有创造力的人类智能之间的差距。完整录音可以在 [这里](https://aiforukraine.aihouse.club/#agenda)
    通过捐款获取，本文中我们涵盖了讲座的主要内容。
- en: Systematic Generalization
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统性泛化
- en: Current Machine Learning has issues with reliability due to the poor performance
    of OOD (Out-Of-Distribution) sample representation. We are used to relying on
    the IID (Independent & Identically Distributed) hypothesis that the test distribution
    and the training distribution are the same. But without this assumption, we need
    some alternative hypothesis to perform the generalization.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的机器学习在可靠性方面存在问题，因为 OOD（分布外样本）表示的表现不佳。我们习惯依赖 IID（独立同分布）假设，即测试分布和训练分布是相同的。但没有这个假设，我们需要一些替代假设来进行泛化。
- en: 'This results in a research question: how exactly can distributions change?
    Let''s consider how humans usually cope with such tasks, as this can inspire AI
    learning methods development.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了一个研究问题：分布如何具体变化？让我们考虑一下人类通常如何应对这些任务，因为这可以激发AI学习方法的发展。
- en: For many years linguists have been studying systematic generalization, which
    is easily observed in natural language. A human can take familiar concepts and
    arrange them in a new order, while the meaning of the statement remains fully
    clear.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，语言学家一直在研究系统性概括，这在自然语言中很容易观察到。一个人可以将熟悉的概念重新排列，而声明的意思仍然完全明确。
- en: We can even create such configurations that would have zero probability according
    to the training distribution. For example, a driver generalizes his knowledge
    of driving laws in his home country to other countries where road rules may be
    slightly different. However, Deep Learning hasn’t yet achieved similar results.
    This shows the nature of the gap between state-of-the-art AI systems and human
    intelligence.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以创建那些在训练分布中概率为零的配置。例如，一名司机将自己在本国的驾驶法律知识概括到其他国家，而这些国家的道路规则可能略有不同。然而，深度学习尚未实现类似的结果。这显示了最先进的AI系统与人类智能之间的差距本质。
- en: Compositional Knowledge Representation
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组合知识表示
- en: We have large language models, but they require a huge amount of data, which
    makes their use senseless. This is a problem of sample complexity — the number
    of samples needed for training.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有大型语言模型，但它们需要大量数据，这使得它们的使用变得毫无意义。这是样本复杂性的问题——训练所需的样本数量。
- en: 'Therefore, we shouldn’t consider quantitative scaling, but the qualitative
    development of Deep Learning. And the questions are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不应该考虑定量扩展，而是应该关注深度学习的定性发展。问题是：
- en: How can these systems be generalized to new out-of-distribution settings?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统如何能够泛化到新的分布外设置？
- en: How quickly can they adapt to these settings (transfer learning)?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们能多快适应这些设置（迁移学习）？
- en: These questions are directly related to human’s ability to establish and identify
    causal relationships. Humans can make new conclusions by combining and recombining
    pieces of their previous knowledge. This compositional ability to represent knowledge
    in natural language also allows us to consider the course of future AI generations
    development.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题与人类建立和识别因果关系的能力直接相关。人类可以通过结合和重组之前的知识来得出新的结论。这种在自然语言中表示知识的组合能力也让我们能够考虑未来AI一代的发展方向。
- en: Conscious Processing of Information
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有意识的信息处理
- en: Everything we covered above was related to one key ability of humans that is
    currently beyond the AI’s reach. This is the conscious information processing
    performed by our brain.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上述内容涉及到一个人类当前超越AI的关键能力。这就是我们大脑进行的有意识的信息处理。
- en: For instance, what happens when a driver starts driving in a foreign country?
    Let's assume the driver is used to left-hand traffic, but now he has to adapt
    to driving on right. He cannot fully apply his previous experience here, because
    that would bring the car to the oncoming lane. But he can focus on the task, constantly
    reminding himself of the difference in road rules. And this is where his previous
    driving experience helps.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，当一名司机开始在外国开车时会发生什么？假设司机习惯于左侧交通，但现在他必须适应右侧行驶。他不能完全依赖之前的经验，因为这样会使汽车驶入对向车道。但他可以专注于任务，不断提醒自己道路规则的不同。这就是他之前驾驶经验的帮助之处。
- en: Thus, when humans face a new situation, they call to conscious attention in
    order to combine relevant pieces of knowledge on-the-fly, analyze them, and in
    the end successfully complete the task. Such conscious information processing
    differs by its nature from the one we are guided by in our routine (see "Thinking,
    Fast and Slow" by D. Kahneman).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当人们面对新的情况时，他们会在意识上注意，以便即兴结合相关的知识点，分析它们，并最终成功完成任务。这种有意识的信息处理本质上不同于我们在日常生活中依赖的处理方式（参见D.
    Kahneman的《思考，快与慢》）。
- en: Current Deep Learning systems successfully reproduce fast thinking with a simple
    sequence of actions, when there is no need to solve a non-trivial issue. But the
    reproduction of more complex and algorithmic slow thinking is a challenge for
    future industry development.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的深度学习系统在没有需要解决复杂问题的情况下，可以通过简单的动作序列成功模拟快速思维。但再现更复杂和算法性的慢思维对未来的行业发展来说是一项挑战。
- en: For this, we need to organize knowledge in a way to make it easy to select the
    relevant pieces of knowledge out of the training distribution to reuse when solving
    a new problem. The analogy can be a program code consisting of independent modules
    and functions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要以一种方式组织知识，使其易于从训练分布中选择相关知识片段，以便在解决新问题时重新使用。类似的比喻可以是由独立模块和函数组成的程序代码。
- en: Causal Relationship
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果关系
- en: 'A human is able to distinguish two perspectives of their knowledge about the
    world:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 人类能够区分他们对世界的知识的两个视角：
- en: those depending on immutable physical laws; and
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些依赖于不变的物理法则；以及
- en: those associated with dynamically changing conditions.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些与动态变化条件相关。
- en: This differs from the usual IID assumption, for things that are preserved in
    distributions and related to physical laws in fact remain unchanged. And things
    related to variable conditions change.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这与常见的IID假设不同，因为那些在分布中保持不变并与物理法则相关的事物实际上是不变的。而与变量条件相关的事物则会发生变化。
- en: Therefore, the goal of Deep Learning is to discover such a knowledge representation
    that reflects the cause-and-effect relationship of variable factors. In other
    words, the outcome depends on the actions taken.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，深度学习的目标是发现能够反映变量因素因果关系的知识表示。换句话说，结果取决于所采取的行动。
- en: Inductive Biases
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 归纳偏差
- en: A human can receive and share a lot of information using a language. The most
    suitable for verbalization is the knowledge that relies on inductive biases, such
    as the use of abstract named objects.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 人类可以通过语言接收和分享大量信息。最适合口头表达的是依赖于归纳偏差的知识，比如使用抽象命名对象。
- en: 'For instance, I hold a ball in my hand. This sentence contains named objects:
    me, the hand, and the ball. Each of them has its own features, like coordinates
    in space. If I suddenly drop the ball, they can be used to predict the coordinates
    of the ball each next moment while it falls. This prediction is accurate, though
    it is based on a few variables only.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我手里拿着一个球。这句话包含了命名对象：我、手和球。每个对象都有自己的特征，如空间中的坐标。如果我突然掉下球，它们可以用来预测球在每一个下落时刻的坐标。这个预测是准确的，尽管它只基于几个变量。
- en: But this approach will not work if applied at the pixel level. It is impossible
    to accurately predict the state of a pixel itself. But you can predict the state
    of the pixel, related to an abstract named object, like a ball. Because the statistical
    structure of such named objects differs from ordinary pixels.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果在像素级别应用这种方法，它将不起作用。无法准确预测一个像素本身的状态。但可以预测与抽象命名对象相关的像素状态，比如球。因为这种命名对象的统计结构与普通像素不同。
- en: Besides, causal relationships between abstract objects are reusable. No matter
    what object falls as a result of dropping — a ball, a phone, or else — the mechanism
    remains the same.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，抽象对象之间的因果关系是可重复使用的。无论是什么物体由于掉落而发生——球、电话或其他——机制保持不变。
- en: GFlowNets
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GFlowNets
- en: 'In neuroscience, there is a random factor: in a certain situation, a human
    can have this or that thought. So there is some discrete stochastic aspect of
    thinking that cannot be accounted for in advance. Then, from a Machine Learning
    point of view, we need a probabilistic neural network that can generate thoughts
    from a selected distribution, such as Bayesian posterior probability.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经科学中，有一个随机因素：在某种情况下，人类可能会有某种思维。因此，思维中存在某种离散随机的方面，无法事先预测。从机器学习的角度来看，我们需要一个能够从选择的分布中生成思想的概率神经网络，例如贝叶斯后验概率。
- en: GFlowNets is a versatile probabilistic modeling tool. Such networks make it
    possible to model distributions by composite objects and to estimate such quantities
    as normalizing constants or conditional probabilities. The easiest way to imagine
    this structure is the hypograph.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GFlowNets 是一个多功能的概率建模工具。这些网络使得通过复合对象建模分布以及估计如归一化常数或条件概率等量成为可能。最容易想象这种结构的是假图。
- en: How do GFlowNets generate such structured objects as graphs? For several years
    now, we have known networks that take not a set of fixed-size vectors, but a graph
    as an input. Now we consider getting a graph as an output. This process is similar
    to how the brain generates thoughts. To create a composite structure, we add one
    element at a time. I.e., we take a partially constructed thought as the input
    and derive a distribution as the output, that determines all possible potential
    further actions. Thus, we get the desired outcome step by step.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: GFlowNets如何生成像图这样的结构化对象？我们已经知道几年来，网络接受的不是固定大小向量的集合，而是图作为输入。现在我们考虑将图作为输出。这一过程类似于大脑生成思维的方式。为了创建复合结构，我们一次添加一个元素。即，我们将一个部分构建的思维作为输入，并推导出一个分布作为输出，确定所有可能的进一步行动。这样，我们一步步获得所需的结果。
- en: GFlowNets can be organized as different modules specializing in different types
    of knowledge. Competing with each other, they provide the normalized estimations
    as the output. Moreover, each module shares information with others — this is
    how short-term working memory is formed. Finally, one of the estimates is stochastically
    chosen, such as the process of initiating conscious processing in the human brain.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: GFlowNets可以组织为专注于不同类型知识的不同模块。通过相互竞争，它们提供标准化的估计作为输出。此外，每个模块与其他模块共享信息——这就是短期工作记忆形成的方式。最后，某个估计会被随机选择，类似于人脑中启动意识处理的过程。
- en: Causal Relationships Model
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果关系模型
- en: When working with such a neural network the main challenge is to correctly identify
    and model the causal structure. Because if you simply take two A and B variables
    with a correlation between them, then there’s no knowing which one of them triggers
    another one. But we can assume that this connection will change due to external
    factors. For example, if we change the state of A, which also changes B, then
    it is likely that A has an effect on B and not vice versa.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用这样的神经网络时，主要挑战是正确识别和建模因果结构。因为如果你仅仅拿两个有相关性的A和B变量，那么无法确定哪个变量触发了另一个。然而，我们可以假设这种连接会由于外部因素而改变。例如，如果我们改变A的状态，这也改变了B，那么A对B的影响更可能，而不是反过来。
- en: Causal relationships are asymmetric. If you don’t understand it perfectly, you
    can make big mistakes. For instance, it can cause ambiguity, like has a patient
    been cured by the new medicine, or due to some other reason?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因果关系是非对称的。如果你没有完全理解它，你可能会犯很大的错误。例如，这可能导致歧义，比如病人是因为新药治愈的，还是由于其他原因？
- en: Therefore, it is necessary to build such models that can cover the entire set
    of possible causal explanations. In their thinking humans are able to make similar
    hypotheses. For AI, this task is solved by Bayesian posterior causal models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要构建能够涵盖所有可能因果解释的模型。在思考中，人类能够提出类似的假设。对于人工智能，这一任务通过贝叶斯后验因果模型来解决。
- en: Conclusions
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: So far, the gap between Deep Learning and human cognitive abilities is significant.
    After all, people can generalize their knowledge, apply slow thinking and use
    it to solve non-trivial issues, consciously process information, and understand
    the cause-and-effect relationship between phenomena.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，深度学习与人类认知能力之间的差距仍然很大。毕竟，人类可以概括他们的知识，应用慢思维并用来解决非平凡问题，意识处理信息，并理解现象之间的因果关系。
- en: However, world-leading AI experts work on bridging this gap and improving AI
    capabilities, inspired by studying the principles of the human brain function.
    Joshua Bengio's team in Montreal researches probabilistic neural networks to make
    a step toward the next generation of Deep Learning.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，世界领先的人工智能专家正在努力弥合这一差距，提升人工智能能力，灵感来自于对人脑功能原理的研究。蒙特利尔的**Joshua Bengio**团队研究概率神经网络，以迈向下一代深度学习。
- en: '**[Bohdan Ponomar](https://www.linkedin.com/in/bogdan-ponomar-41866328/)**
    is CEO at the [AI HOUSE](https://aihouse.org.ua/) community. He is creating a
    leading AI ecosystem for students and experts to build world-class AI ventures
    in Ukraine.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**[博赫丹·波诺马尔](https://www.linkedin.com/in/bogdan-ponomar-41866328/)** 是[AI HOUSE](https://aihouse.org.ua/)社区的首席执行官。他正在为学生和专家创建一个领先的人工智能生态系统，以在乌克兰建立世界一流的人工智能企业。'
- en: More On This Topic
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弥合人类理解与机器学习之间的差距：…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
- en: '[The AI Education Gap and How to Close It](https://www.kdnuggets.com/2022/11/ai-education-gap-close.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能教育差距及其解决方案](https://www.kdnuggets.com/2022/11/ai-education-gap-close.html)'
- en: '[Is There a Way to Bridge the MLOps Tools Gap?](https://www.kdnuggets.com/2022/08/way-bridge-mlops-tools-gap.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是否有方法弥合MLOps工具差距？](https://www.kdnuggets.com/2022/08/way-bridge-mlops-tools-gap.html)'
- en: '[Data Scientist''s Guide to Cognitive Biases: A Free eBook](https://www.kdnuggets.com/2023/05/data-scientist-guide-cognitive-biases-free-ebook.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家认知偏差指南：免费电子书](https://www.kdnuggets.com/2023/05/data-scientist-guide-cognitive-biases-free-ebook.html)'
- en: '[Between Dreams and Reality: Generative Text and Hallucinations](https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梦想与现实之间：生成文本与幻觉](https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations)'
- en: '[The Difference Between Training and Testing Data in Machine Learning](https://www.kdnuggets.com/2022/08/difference-training-testing-data-machine-learning.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中训练数据与测试数据的区别](https://www.kdnuggets.com/2022/08/difference-training-testing-data-machine-learning.html)'
