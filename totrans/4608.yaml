- en: Introduction to Image Segmentation with K-Means clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html](https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![Figure](../Images/9b0a0b8be42317acaed68988ff8a24df.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pic Credit: [datastuff.tech](http://www.datastuff.tech/machine-learning/k-means-clustering-unsupervised-learning-for-recommender-systems/)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Image segmentation is an important step in image processing, and it seems everywhere
    if we want to analyze what’s inside the image. For example, if we seek to find
    if there is a chair or person inside an indoor image, we may need image segmentation
    to separate objects and analyze each object individually to check what it is.
    Image segmentation usually serves as the pre-processing before pattern recognition,
    feature extraction, and compression of the image.
  prefs: []
  type: TYPE_NORMAL
- en: Image segmentation is the classification of an image into different groups.
    Many kinds of research have been done in the area of image segmentation using
    clustering. There are different methods and one of the most popular methods is **K-Means
    clustering algorithm**.
  prefs: []
  type: TYPE_NORMAL
- en: 'So here in this article, we will explore a method to read an image and cluster
    different regions of the image. But before doing lets first talk about:'
  prefs: []
  type: TYPE_NORMAL
- en: Image Segmentation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How Image segmentation works
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: K-Means clustering ML Algorithm
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge K-Means clustering Algorithm with Image Segmentation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Canny Edge detection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Image Segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Figure](../Images/f0e25c04eae3b9a998f05ddd691d3292.png)'
  prefs: []
  type: TYPE_IMG
- en: Pic Credit: [omicsonline.org](https://www.omicsonline.org/open-access/image-segmentation-by-using-linear-spectral-clustering-2167-0919-1000143.php?aid=81482&view=mobile)
  prefs: []
  type: TYPE_NORMAL
- en: Image segmentation is the process of partitioning a digital image into multiple
    distinct regions containing each pixel(sets of pixels, also known as superpixels)
    with similar attributes.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of Image segmentation is to change the representation of an image into
    something that is more meaningful and easier to analyze.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Image segmentation is typically used to locate objects and [boundaries](https://en.wikipedia.org/wiki/Boundary_tracing)(lines,
    curves, etc.) in images. More precisely, Image Segmentation is the process of
    assigning a label to every pixel in an image such that pixels with the same label
    share certain characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, a common question arises:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Why does Image Segmentation even matter?**'
  prefs: []
  type: TYPE_NORMAL
- en: If we take an example of Autonomous Vehicles, they need sensory input devices
    like cameras, radar, and lasers to allow the car to perceive the world around
    it, creating a digital map. Autonomous driving is not even possible without object
    detection which itself involves image classification/segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c5478641b8db1523e1c1f3f781d15fee.png)'
  prefs: []
  type: TYPE_IMG
- en: Object detection and Image Classification by an Autonomous Vehicle
  prefs: []
  type: TYPE_NORMAL
- en: Other examples involve Healthcare Industry where if we talk about Cancer, even
    in today’s age of technological advancements, cancer can be fatal if we don’t
    identify it at an early stage. Detecting cancerous cell(s) as quickly as possible
    can potentially save millions of lives. The shape of the cancerous cells plays
    a vital role in determining the severity of cancer which can be identified using
    image classification algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/5cd5d39b1ed64885b7c3c1032d66b827.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Breast cancer cells](https://imgur.com/gallery/QYbhkFH)'
  prefs: []
  type: TYPE_NORMAL
- en: Like this, there were several algorithms and techniques for image segmentation
    have been developed over the years using domain-specific knowledge to effectively
    solve segmentation problems in that specific application area which includes [medical
    imaging](https://en.wikipedia.org/wiki/Medical_imaging), [object detection](https://en.wikipedia.org/wiki/Object_detection), [Iris
    recognition](https://en.wikipedia.org/wiki/Iris_recognition), [video surveillance](https://en.wikipedia.org/wiki/Closed-circuit_television), [machine
    vision](https://en.wikipedia.org/wiki/Machine_vision) and many more….
  prefs: []
  type: TYPE_NORMAL
- en: Let us plot an image in 3D space using python matplotlib library.
  prefs: []
  type: TYPE_NORMAL
- en: Below is the image that we’ll gonna plot in 3D space and we can clearly see
    3 different colors which means 3 clusters/groups should be generated.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/99b2323f5239141a914e6ec9ab099c33.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [lightstalking.com](https://www.lightstalking.com/composing-with-color/)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/4465821b34acf5a136a0c9dc831c1381.png)'
  prefs: []
  type: TYPE_IMG
- en: Image plotting in 3D space
  prefs: []
  type: TYPE_NORMAL
- en: From the plot one can easily see that the data points are forming groups — some
    places in a graph are more dense, which we can think as different colors’ dominance
    on the image.
  prefs: []
  type: TYPE_NORMAL
- en: How Image Segmentation works
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Image Segmentation involves converting an image into a collection of regions
    of pixels that are represented by a mask or a labeled image. By dividing an image
    into segments, you can process only the important segments of the image instead
    of processing the entire image.
  prefs: []
  type: TYPE_NORMAL
- en: A common technique is to look for abrupt discontinuities in pixel values, which
    typically indicate edges that define a region.
  prefs: []
  type: TYPE_NORMAL
- en: Another common approach is to detect similarities in the regions of an image.
    Some techniques that follow this approach are region growing, clustering, and
    thresholding.
  prefs: []
  type: TYPE_NORMAL
- en: A variety of other approaches to perform image segmentation have been developed
    over the years using domain-specific knowledge to effectively solve segmentation
    problems in specific application areas.
  prefs: []
  type: TYPE_NORMAL
- en: So let us start with one of the clustering-based approaches in Image Segmentation
    which is K-Means clustering.
  prefs: []
  type: TYPE_NORMAL
- en: K-Means clustering algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ok first What are Clustering algorithms in Machine Learning?
  prefs: []
  type: TYPE_NORMAL
- en: Clustering algorithms are unsupervised algorithms but are similar to Classification
    algorithms but the basis is different.
  prefs: []
  type: TYPE_NORMAL
- en: In Clustering, you don't know what you are looking for, and you are trying to
    identify some segments or clusters in your data. When you use clustering algorithms
    in your dataset, unexpected things can suddenly pop-up like structures, clusters,
    and groupings you would have never thought otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '***K*-Means clustering** algorithm is an unsupervised algorithm and it is used
    to segment the interest area from the background. It clusters, or partitions the
    given data into K-clusters or parts based on the K-centroids.'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm is used when you have unlabeled data(i.e. data without defined
    categories or groups). The goal is to find certain groups based on some kind of
    similarity in the data with the number of groups represented by K.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/37c4f348f6a69fed5102b46d3eda1705.png)'
  prefs: []
  type: TYPE_IMG
- en: K-Means clustering example
  prefs: []
  type: TYPE_NORMAL
- en: In the above figure, Customers of a shopping mall have been grouped into 5 clusters
    based on their income and spending score. Yellow dots represent the Centroid of
    each cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of K-Means clustering is to minimize the sum of squared distances
    between all points and the cluster center.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/2266d8cbedb64ea634a1afe60a04cfaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Pic Credit: [saedsayad.com](https://www.saedsayad.com/clustering_kmeans.htm)
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps in K-Means algorithm:**'
  prefs: []
  type: TYPE_NORMAL
- en: Choose the number of clusters K.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select at random K points, the centroids(not necessarily from your dataset).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign each data point to the closest centroid → that forms K clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute and place the new centroid of each cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reassign each data point to the new closest centroid. If any reassignment .
    took place, go to step 4, otherwise, the model is ready.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**How to choose the optimal value of K?**'
  prefs: []
  type: TYPE_NORMAL
- en: For a certain class of clustering algorithms (in particular K-Means, K[-medoids](https://en.wikipedia.org/wiki/K-medoid),
    and [expectation-maximization](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) algorithm),
    there is a parameter commonly referred to as K that specifies the number of clusters
    to detect. Other algorithms such as [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN) and [OPTICS
    algorithm](https://en.wikipedia.org/wiki/OPTICS_algorithm) do not require the
    specification of this parameter; [Hierarchical Clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering) avoids
    the problem altogether but that's beyond the scope of this article.
  prefs: []
  type: TYPE_NORMAL
- en: If we talk about K-Means then the correct choice of K is often ambiguous, with
    interpretations depending on the shape and scale of the distribution of points
    in a data set and the desired clustering resolution of the user. In addition,
    increasing K without penalty will always reduce the amount of error in the resulting
    clustering, to the extreme case of zero error if each data point is considered
    its own cluster (i.e., when K equals the number of data points, *n*). Intuitively
    then, *the optimal choice of K will strike a balance between maximum compression
    of the data using a single cluster, and maximum accuracy by assigning each data
    point to its own cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: If an appropriate value of K is not apparent from prior knowledge of the properties
    of the data set, it must be chosen somehow. There are several categories of methods
    for making this decision and **Elbow method** is one such method.
  prefs: []
  type: TYPE_NORMAL
- en: Elbow method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic idea behind partitioning methods, such as K-Means clustering, is to
    define clusters such that the total intra-cluster variation or in other words,
    total within-cluster sum of square (WCSS) is minimized. ***The total WCSS measures
    the compactness of the clustering and we want it to be as small as possible.***
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c15401f28d280f1a8b9b62571528e9ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The Elbow method looks at the total WCSS as a function of the number of clusters:
    One should choose a number of clusters so that adding another cluster doesn’t
    improve much better the total WCSS.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Steps to choose the optimal number of clusters K:(Elbow Method)**'
  prefs: []
  type: TYPE_NORMAL
- en: Compute K-Means clustering for different values of K by varying K from 1 to
    10 clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each K, calculate the total within-cluster sum of square (WCSS).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the curve of WCSS vs the number of clusters K.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The location of a bend (knee) in the plot is generally considered as an indicator
    of the appropriate number of clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is a catch!!!
  prefs: []
  type: TYPE_NORMAL
- en: In spite of all the advantages K-Means have got but it fails sometimes due to
    the random choice of centroids which is called **The** **Random Initialization
    Trap.**
  prefs: []
  type: TYPE_NORMAL
- en: To solve this issue we have an initialization procedure for K-Means which is
    called [**K-Means++**](https://en.wikipedia.org/wiki/K-means%2B%2B)(Algorithm
    for choosing the initial values for K-Means clustering).
  prefs: []
  type: TYPE_NORMAL
- en: In K-Means++, We pick a point randomly and that's your first centroid, then
    we pick the next point based on the probability that depends upon the distance
    of the first point, the further apart the point is the more probable it is.
  prefs: []
  type: TYPE_NORMAL
- en: Then we have two centroids, repeat the process, the probability of each point
    is based on its distance to the closest centroid to that point. Now, ***this introduces
    an overhead in the initialization of the algorithm, but it reduces the probability
    of a bad initialization leading to bad clustering result.***
  prefs: []
  type: TYPE_NORMAL
- en: '**Visual Representation of K-Means Clustering:** Starting with 4 leftmost points.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/73a6666e8af6262bc8673e734728b100.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Source](http://shabal.in/visuals/kmeans/5.html): K-Means Clustering in action'
  prefs: []
  type: TYPE_NORMAL
- en: Enough of theory lets implement what we have discussed in a real-world scenario.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will explore a method to read an image and cluster different
    regions of the image using the **K-Means clustering algorithm** and **OpenCV**.
  prefs: []
  type: TYPE_NORMAL
- en: So basically we will perform Color clustering and Canny Edge detection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Color Clustering:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load all the required libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Next step is to load the image in RGB color space
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Original Image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/bbc112394504e9508aec30c6c069201d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'source: unsplash'
  prefs: []
  type: TYPE_NORMAL
- en: We need to convert our image from RGB Colours Space to HSV to work ahead.
  prefs: []
  type: TYPE_NORMAL
- en: '**But the question is why ??**'
  prefs: []
  type: TYPE_NORMAL
- en: According to [wikipedia](https://en.wikipedia.org/wiki/HSL_and_HSV#Use_in_image_analysis) the
    R, G, and B components of an object’s color in a digital image are all correlated
    with the amount of light hitting the object, and therefore with each other, image
    descriptions in terms of those components make object discrimination difficult.
    Descriptions in terms of hue/lightness/chroma or hue/lightness/saturation are
    often more relevant.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you don''t convert your image to HSV, your image will look something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/be1a19424260442f8af5f305c7793fb3.png)'
  prefs: []
  type: TYPE_IMG
- en: Our original image in RGB color space
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, converts the MxNx3 image into a Kx3 matrix where K=MxN and each row is
    now a vector in the 3-D space of RGB.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We convert the unit8 values to float as it is a requirement of the k-means method
    of OpenCV.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We are going to cluster with k = 3 because if you look at the image above it
    has 3 colors, green-colored grass and forest, blue sea and the greenish-blue seashore.
  prefs: []
  type: TYPE_NORMAL
- en: Define criteria, number of clusters(K) and apply k-means()
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: OpenCV provides [**cv2.kmeans(**](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88)**samples,
    nclusters(K), criteria, attempts, flags**[**)**](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88)function
    for color clustering.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. samples:** It should be of **np.float32** data type, and each feature
    should be put in a single column.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. nclusters(K)**: Number of clusters required at the end'
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. criteria:** It is the iteration termination criteria. When this criterion
    is satisfied, the algorithm iteration stops. Actually, it should be a tuple of
    3 parameters. They are `( type, max_iter, epsilon )`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Type of termination criteria. It has 3 flags as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**cv.TERM_CRITERIA_EPS** — stop the algorithm iteration if specified accuracy, *epsilon*,
    is reached.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cv.TERM_CRITERIA_MAX_ITER** — stop the algorithm after the specified number
    of iterations, *max_iter*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER** — stop the iteration when
    any of the above condition is met.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4\. attempts:** Flag to specify the number of times the algorithm is executed
    using different initial labelings. The algorithm returns the labels that yield
    the best compactness. This compactness is returned as output.'
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. flags:** This flag is used to specify how initial centers are taken.
    Normally two flags are used for this: [**cv.KMEANS_PP_CENTERS**](https://docs.opencv.org/master/d0/de1/group__core.html#gga276000efe55ee2756e0c471c7b270949a78ddd00a99cd51db10ed63c024eb1e62) and [**cv.KMEANS_RANDOM_CENTERS**](https://docs.opencv.org/master/d0/de1/group__core.html#gga276000efe55ee2756e0c471c7b270949adfa80a38dfc0aef0de888c3164f33faf).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Now convert back into uint8.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Next, we have to access the labels to regenerate the clustered image
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`result_image` is the result of the frame which has undergone k-means clustering.'
  prefs: []
  type: TYPE_NORMAL
- en: Now let us visualize the output result with K=3
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/e122ed9b791e75f09b42e30fe5d57809.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Segmentation when K=3
  prefs: []
  type: TYPE_NORMAL
- en: So the algorithm has categorized our original image into three dominant colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what happens when we change the value of K=5:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/757897619f800fa4107a94cf459ecd1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Segmentation when K=5
  prefs: []
  type: TYPE_NORMAL
- en: 'Change the value of K=7:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/987b393caef9ae0a152d28540c87dafd.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Segmentation when K=7
  prefs: []
  type: TYPE_NORMAL
- en: As you can see with an increase in the value of K, the image becomes clearer
    because the K-means algorithm can classify more classes/cluster of colors.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can try our code for different images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/95680db4234dcd426ab5cdb840dc8a90.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Segmentation when K=6![Figure](../Images/047b4c6eba9cfd996a2acb2024317bd0.png)
  prefs: []
  type: TYPE_NORMAL
- en: Image Segmentation when K=6
  prefs: []
  type: TYPE_NORMAL
- en: Let's move to our next part which is Canny Edge detection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Canny Edge detection: **It is an image processing method used to detect edges
    in an image while suppressing noise.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Canny Edge detection algorithm is composed of 5 steps:**'
  prefs: []
  type: TYPE_NORMAL
- en: <noise reduction="">Gradient calculation</noise>
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-maximum suppression
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double threshold
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Edge Tracking by Hysteresis
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: OpenCV provides **cv2.Canny(image, threshold1,threshold2)** function for edge
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: The first argument is our input image. Second and third arguments are our min
    and max threshold respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The function finds edges in the input image(8-bit input image) and marks them
    in the output map edges using the Canny algorithm. The smallest value between
    threshold1 and threshold2 is used for edge linking. The largest value is used
    to find initial segments of strong edges.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/343ca587398f6095595d469d8176a580.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Result-1: Edge detection using the Canny algorithm![Figure](../Images/0a649a64791babd29ae0bf62fb3e9807.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Result-2: Edge detection using the Canny algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion: What the future holds'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Figure](../Images/40d187193d833bf9f63d02536b0efe73.png)'
  prefs: []
  type: TYPE_IMG
- en: Pic credit: [gehealthcare](http://newsroom.gehealthcare.com/is-the-ai-trend-why-doctors-of-the-future-may-know-code/)
  prefs: []
  type: TYPE_NORMAL
- en: Due to advancements in Image processing, Machine learning, AI and related technologies,
    there will be millions of robots in the world in a few decades time, transforming
    the way we live our daily lives. These advancements will involve spoken commands,
    anticipating the information requirements of governments, translating languages,
    recognizing and tracking people and things, diagnosing medical conditions, performing
    surgery, reprogramming defects in human DNA, driverless cars and many more applications,
    the count of real-life applications is endless.
  prefs: []
  type: TYPE_NORMAL
- en: Well, this comes to the end of this article. I hope you guys have enjoyed reading
    this article. Share your thoughts/comments/doubts in the comment section.
  prefs: []
  type: TYPE_NORMAL
- en: You can reach me out over [LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/?source=post_page---------------------------) for
    any query.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading !!!
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Data Science enthusiast. Interested in Big Data, Python, Machine Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Predict Age and Gender Using Convolutional Neural Network and OpenCV](/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Beginner’s Guide to Linear Regression in Python with Scikit-Learn](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Data Pre-processing to Optimizing a Regression Model Performance](/2019/07/data-pre-processing-optimizing-regression-model-performance.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hands-On with Unsupervised Learning: K-Means Clustering](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Clustering in Python with PyCaret](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
