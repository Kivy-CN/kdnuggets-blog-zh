- en: How Not To Program the TensorFlow Graph
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/05/how-not-program-tensorflow-graph.html](https://www.kdnuggets.com/2017/05/how-not-program-tensorflow-graph.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Aaron Schumacher, Deep Learning Analytics.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Using TensorFlow from Python is like using Python to program [another computer](http://planspace.org/20170328-tensorflow_as_a_distributed_virtual_machine/).
    Some Python statements build your TensorFlow program, some Python statements execute
    that program, and of course some Python statements aren’t involved with TensorFlow
    at all. Being thoughtful about the graphs you construct can help you avoid confusion
    and performance pitfalls. Here are a few considerations.![](../Images/e09c1745abd025c932b954fd964eedfb.png)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Avoid having many identical ops
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lots of methods in TensorFlow create ops in the computation graph, but do not
    execute them. You may want to execute multiple times, but that doesn’t mean you
    should create lots of copies of the same ops.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: A clear example is `tf.global_variables_initializer()`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If the call to `tf.global_variables_initializer()` is repeated, for example
    directly as the argument to `session.run()`, there are downsides.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: A new initializer op is created every time the argument to `session.run()` here
    is evaluated. This creates multiple initializer ops in the graph. Having multiple
    copies isn’t a big deal for small ops in an interactive session, and you might
    even want to do it in the case of the initializer if you’ve created more variables
    that need to be included in initialization. But think about whether you need lots
    of duplicate ops.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Creating ops inside `session.run()`, you also don’t have a Python variable referring
    to those ops, so you can’t easily reuse them.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: In Python, if you create an object that nothing refers to, it can be garbage
    collected. The abandoned object will be deleted and and memory it used will be
    freed. That doesn’t happen to things in the TensorFlow graph; everything you put
    in the graph stays there.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: It’s pretty clear that `tf.global_variables_initializer()` returns an op. But
    ops are also created in less obvious ways.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Let’s compare to how NumPy works.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: At this point there are two arrays in memory, `x` and `y`. The `y` has the value
    2.0, but there’s no record of *how* it came to have that value. The addition has
    left no record of itself.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is different.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now only `x` is a TensorFlow variable; `y` is an `add` op, which can return
    the result of that addition if we ever run it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: One more comparison.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here `y` is assigned to refer to one result array `x + 1.0`, and then reassigned
    to point to a different one. The first one will be garbage collected and disappear.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this case, `y` refers to one `add` op in the TensorFlow graph, and then `y`
    is reassigned to point to a different `add` op in the graph. Since `y` only points
    to the second `add` now, we don’t have a convenient way to work with the first
    one. But both the `add` ops are still around, in the graph, and will stay there.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: (As an aside, Python’s mechanism for defining class-specific addition [and so
    on](http://www.python-course.eu/python3_magic_methods.php), which is how `+` is
    made to create TensorFlow ops, is pretty neat.)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Especially if you’re just working with the default graph and running interactively
    in a regular REPL or a notebook, you can end up with a lot of abandoned ops in
    your graph. Every time you re-run a notebook cell that defines any graph ops,
    you aren’t just redefining ops—you’re creating new ones.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Often it’s okay to have a few extra ops floating around when you’re experimenting.
    But things can get out of hand.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If `x` is a NumPy array, or just a regular Python number, this will run in constant
    memory and finish with one value for x.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: But if `x` is a TensorFlow variable, there will be over a million ops in your
    TensorFlow graph, just defining a computation and not even *doing* it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: One immediate fix for TensorFlow is to use a `tf.assign` op, which gives behavior
    more like what you might expect.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This revised version does not create any ops inside the loop, which is generally
    good advice. TensorFlow does have [control flow constructs](https://www.tensorflow.org/api_guides/python/control_flow_ops)
    including [while loops](https://www.tensorflow.org/api_docs/python/tf/while_loop).
    But only use these when really needed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Be conscious of when you’re creating ops, and only create the ones you need.
    Try to keep op creation distinct from op execution. And after interactive experimentation,
    eventually get to a state, probably in a script, where you’re only creating the
    ops that you need.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Avoid constants in the graph
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A particularly unfortunate op to needlessly add to a graph is accidental constant
    ops, especially large ones.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: There are a million ones in the NumPy array `many_ones`. We can add them up.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: What if we add them up with TensorFlow?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The result is the same, but the mechanism is quite different. This not only
    added some ops to the graph—it put a copy of the entire million-element array
    into the graph as a constant.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Variations on this pattern can result in accidentally loading an entire data
    set into the graph as constants. A program might still run, for small data sets.
    Or your system might fail.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: One simple way to avoid storing data in the graph is to use the `feed_dict`
    mechanism.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As before, be clear about what you’re adding to the graph and when. Concrete
    data usually only enters the graph at moments of evaluation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow as Functional Programming
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: TensorFlow ops are like functions. This is especially clear when an op has one
    or more placeholder inputs; evaluating the op in a session is like calling a function
    with those arguments. So Python functions that return TensorFlow ops are like
    [higher-order functions](https://en.wikipedia.org/wiki/Higher-order_function).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: You might decide that it’s worth putting a constant into the graph. For example,
    if you have to reshape a lot of tensors to 28×28, you might make an op that does
    that.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is like [currying](https://en.wikipedia.org/wiki/Currying) in that the
    `shape` argument has now been set. The `[28, 28]` has become a constant in the
    graph and specified that argument. Now to evaluate `reshape_to_28` we only have
    to provide `input_tensor`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Broader connections have been suggested between [neural networks, types, and
    functional programming](http://colah.github.io/posts/2015-09-NN-Types-FP/). It’s
    interesting to think of TensorFlow as a system that supports this kind of construction.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: I’m working on [Building TensorFlow systems from components](http://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/57823),
    a workshop at [OSCON 2017](https://conferences.oreilly.com/oscon/oscon-tx).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Find [Aaron](http://planspace.org/aaron/) on [Twitter](https://twitter.com/planarrowspace)
    | [LinkedIn](https://www.linkedin.com/in/ajschumacher) | [Google+](https://plus.google.com/112658546306232777448/)
    | [GitHub](https://github.com/ajschumacher) | [email](mailto:ajschumacher@gmail.com)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://planspace.org/20170404-how_not_to_program_the_tensorflow_graph/).
    Reposted with permission.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Aaron Schumacher](https://www.linkedin.com/in/ajschumacher/)** is a
    Senior Data Scientist and Software Engineer at Deep Learning Analytics. He tweets
    at [@planarrowspace](https://twitter.com/planarrowspace).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[How to Build a Recurrent Neural Network in TensorFlow](/2017/04/build-recurrent-neural-network-tensorflow.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Gentlest Introduction to Tensorflow – Part 1](/2016/08/gentlest-introduction-tensorflow-part-1.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An Overview of Python Deep Learning Frameworks](/2017/02/python-deep-learning-frameworks-overview.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[AWS AI & ML Scholarship Program Overview](https://www.kdnuggets.com/2022/09/aws-ai-ml-scholarship-program-overview.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Enroll in a 4-year Computer Science Degree Program For Free](https://www.kdnuggets.com/enroll-in-a-4-year-computer-science-degree-program-for-free)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Join UC''s Information Session for the Master''s in Business…](https://www.kdnuggets.com/2022/10/ucincinnati-join-ucs-information-session-masters-business-analytics-program.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Maximize Your Value With The 3rd Best Online Master’s In Data…](https://www.kdnuggets.com/2023/05/bay-path-maximize-value-online-masters-data-science.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Advance your Career with the 3rd Best Online Master''s in Data…](https://www.kdnuggets.com/2023/07/bay-path-advance-career-3rd-best-online-masters-data-science-program.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过第3名的在线数据科学硕士项目来提升你的职业生涯…](https://www.kdnuggets.com/2023/07/bay-path-advance-career-3rd-best-online-masters-data-science-program.html)'
- en: '[Pursue A Master’s In Data Science With The 3rd Best Online Program](https://www.kdnuggets.com/2023/09/bay-path-pursue-masters-data-science-3rd-best-online-program)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过第3名的在线数据科学硕士项目来追求硕士学位](https://www.kdnuggets.com/2023/09/bay-path-pursue-masters-data-science-3rd-best-online-program)'
