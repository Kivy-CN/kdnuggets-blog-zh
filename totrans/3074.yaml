- en: Free resources to learn Natural Language Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习自然语言处理的免费资源
- en: 原文：[https://www.kdnuggets.com/2018/09/free-resources-natural-language-processing.html](https://www.kdnuggets.com/2018/09/free-resources-natural-language-processing.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/09/free-resources-natural-language-processing.html](https://www.kdnuggets.com/2018/09/free-resources-natural-language-processing.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Muktabh Mayank](https://twitter.com/muktabh), [ParallelDots](https://www.paralleldots.com/)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Muktabh Mayank](https://twitter.com/muktabh), [ParallelDots](https://www.paralleldots.com/)**
    提供。'
- en: '![](../Images/fb0dc19ad05061fdc63ed485a5b17f2a.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb0dc19ad05061fdc63ed485a5b17f2a.png)'
- en: Natural Language Processing (NLP) is the ability of a computer system to understand
    human language. Natural Langauge Processing is a subset of Artificial Intelligence
    (AI). There are multiple resources available online which can help you develop
    expertise in Natural Language Processing.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）是计算机系统理解人类语言的能力。自然语言处理是人工智能（AI）的一个子集。在线有许多资源可以帮助你在自然语言处理方面发展专长。
- en: In this blog post, we list resources for the beginners and intermediate level
    learners.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们列出了供初学者和中级学习者使用的资源。
- en: '**Natural Language Resources for Beginners**'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**初学者的自然语言资源**'
- en: '![](../Images/d873ca29f1691333fbfa3d861d733b30.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d873ca29f1691333fbfa3d861d733b30.png)'
- en: A beginner can follow two methods i.e. Traditional Machine Learning and Deep
    Learning to get started with Natural language processing. These two methods are
    very different from each other. For the inquisitive, [here’s](https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063) the
    difference between these two.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 初学者可以选择两种方法，即传统机器学习和深度学习，以开始自然语言处理。这两种方法有很大的不同。对于好奇者，[这里](https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063)是这两者之间的差异。
- en: '**Traditional Machine Learning**'
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**传统机器学习**'
- en: 'Traditional machine learning algorithms are complex and often not easy to understand.
    Here are a few resources which will help you get started in learning NLP using
    machine learning:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 传统机器学习算法复杂，且常常不易理解。以下是一些资源，将帮助你开始学习使用机器学习进行自然语言处理：
- en: Speech and Language Processing by Jurafsky and Martin is the popularly acclaimed
    bible for traditional Natural Language Processing. You can access it [here](https://web.stanford.edu/~jurafsky/slp3/).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 Jurafsky 和 Martin 编写的《语音与语言处理》是传统自然语言处理的经典之作。你可以通过[这里](https://web.stanford.edu/~jurafsky/slp3/)访问它。
- en: For a more practical approach, you can try out [Natural Language Toolkit.](http://www.nltk.org/book/)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于更实际的方法，你可以尝试[Natural Language Toolkit](http://www.nltk.org/book/)。
- en: '**Deep Learning**'
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**深度学习**'
- en: 'Deep learning is a subfield of machine learning and is far better than traditional
    machine learning due to the introduction of Artificial Neural Networks. Beginners
    can start with the following resources:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，由于引入了人工神经网络，它比传统的机器学习方法要好得多。初学者可以从以下资源开始：
- en: CS 224n: This is the best course to get started with using Deep Learning for
    Natural Language Processing. This course is hosted by Stanford and can be accessed [here](http://web.stanford.edu/class/cs224n/).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CS 224n：这是使用深度学习进行自然语言处理的最佳课程。该课程由斯坦福大学提供，访问[这里](http://web.stanford.edu/class/cs224n/)。
- en: Yoav Golberg’s free and paid books are great resources to get started with Deep
    Learning in Natural Language Processing. The free version can be accessed [here](https://u.cs.biu.ac.il/~yogo/nnlp.pdf)and
    the full version is available [here](https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yoav Golberg 的免费和付费书籍是开始进行自然语言处理深度学习的优秀资源。免费版本可以通过[这里](https://u.cs.biu.ac.il/~yogo/nnlp.pdf)访问，完整版可通过[这里](https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984)获取。
- en: A very thorough coverage of all algorithms can be found in Jacob Einsenstein’s
    notes from GATECH’s NLP class which deals in almost all NLP methods. You can access
    the notes on GitHub [here](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacob Einsenstein 在 GATECH 的 NLP 课程中的笔记对所有算法进行了非常全面的覆盖，涉及几乎所有的 NLP 方法。你可以在 GitHub
    上通过[这里](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)访问这些笔记。
- en: '**Natural Language Resources for Practitioners**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**自然语言资源供从业者使用**'
- en: '![](../Images/0509064d98e73366d835bb6b6c84c51e.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0509064d98e73366d835bb6b6c84c51e.png)'
- en: 'If you are a practicing Data Scientist, you will need three types of resources:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名数据科学家，你将需要三种类型的资源：
- en: Quick Getting Started guides / Knowing about what is hot and new
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 快速入门指南 / 了解最新热点
- en: Problem-Specific Surveys of Methods
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 针对特定问题的方法综述
- en: Blogs to follow regularly
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定期关注的博客
- en: Quick Getting Started guides / Knowing about what is hot and new
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 快速入门指南 / 了解最新热点
- en: One can start with Otter et al.’s Deep Learning for Natural Language Processing
    survey. You can access it [here](https://arxiv.org/abs/1807.10854).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以从Otter等人的《自然语言处理的深度学习》综述开始。你可以在 [这里](https://arxiv.org/abs/1807.10854) 访问这篇综述。
- en: A survey paper by Young et al tries to summarize everything hip in Deep Learning
    based Natural Language Processing, and is recommended to get started with Natural
    Language Processing for practitioners. You can access the paper [here](https://arxiv.org/abs/1708.02709).
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Young等人的综述论文尝试总结深度学习自然语言处理中的所有前沿技术，推荐给实践者作为自然语言处理的入门读物。你可以在 [这里](https://arxiv.org/abs/1708.02709)
    访问这篇论文。
- en: 'You can refer to [this](https://arxiv.org/abs/1808.03314)article to understand
    the basics of LSTMs and RNNs, which are used in Natural Language Processing a
    lot. Another much more cited (and highly reputed) survey of LSTMs is [here](https://arxiv.org/abs/1503.04069).
    This is an interesting paper to understand how the hidden states of RNNs work.
    It is an enjoyable read and can be accessed [here](https://github.com/locuslab/TCN).
    I always recommend the following two blog posts anyone who hasn’t read them:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以参考 [这篇](https://arxiv.org/abs/1808.03314)文章，以理解LSTM和RNN的基础知识，这些技术在自然语言处理（NLP）中被广泛使用。另一篇更常被引用（且声誉极高）的LSTM综述可以在 [这里](https://arxiv.org/abs/1503.04069)找到。这是一篇有趣的论文，可以帮助理解RNN的隐藏状态如何工作。阅读起来很愉快，可以在 [这里](https://github.com/locuslab/TCN)
    访问。我总是推荐以下两个博客文章给任何还没有读过的人：
- en: http://colah.github.io/posts/2015-08-Understanding-LSTMs
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: http://colah.github.io/posts/2015-08-Understanding-LSTMs
- en: https://distill.pub/2016/augmented-rnns/
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: https://distill.pub/2016/augmented-rnns/
- en: Convolutional Neural Networks (Convnets) can be used to make sense of Natural
    Language. You can visualize how Convnets work in NLP by reading this paper [here](https://arxiv.org/abs/1801.06287).
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（Convnets）可以用于理解自然语言。你可以通过阅读这篇论文 [这里](https://arxiv.org/abs/1801.06287)
    来可视化Convnets在NLP中的工作原理。
- en: How Convnets and RNNs compare with each other has been highlighted in [this](https://arxiv.org/abs/1803.01271)paper
    by Bai et al.. All its pytorch (I have stopped or reduced, to a large extent,
    reading deep learning code not written in pytorch  ) code is open sourced [here](https://github.com/locuslab/TCN) and
    gives you a feel of Godzilla v/s King Kong or Ford Mustang vs Chevy Camaro(if
    you enjoy(ed) that type of thing). Who will win! .
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Convnets和RNN的比较在 [这篇](https://arxiv.org/abs/1803.01271) 由Bai等人撰写的论文中得到了强调。所有的pytorch代码（我已经停止或大幅减少阅读非pytorch编写的深度学习代码）在 [这里](https://github.com/locuslab/TCN)
    开源，并且让你感受到哥斯拉对战金刚或福特野马对比雪佛兰Camaro（如果你喜欢那种东西）。谁将赢得胜利！
- en: Problem-specific Surveys of Methods
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 针对特定问题的方法综述
- en: 'Another type of resources practitioners need is answers to questions of the
    type: “I have to train an algorithm to do X, what is the coolest (and easily accessible)
    thing I can apply?”.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实践者需要的另一类资源是对以下类型问题的解答：“我需要训练一个算法来做X，我可以应用什么最酷（且易于访问）的东西？”。
- en: 'Here’s what you will need for this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要以下内容：
- en: '**TEXT CLASSIFICATION**'
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**文本分类**'
- en: What’s the first problem people solve? Text Classification, mostly. Text Classification
    can be in the form of categorizing text into different categories or detecting
    sentiment/emotion within the text.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 人们首先解决的问题是什么？主要是文本分类。文本分类可以是将文本分类到不同的类别中，或检测文本中的情感/情绪。
- en: I would like to highlight an easy read about different surveys of Sentiment
    Analysis described in this ParallelDots [blog](https://blog.paralleldots.com/data-science/breakthrough-research-papers-and-models-for-sentiment-analysis/).
    Though the survey is for sentiment analysis technologies, it can be extended to
    most text classification problems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我想强调一个关于不同情感分析综述的简单阅读，描述在这个ParallelDots [博客](https://blog.paralleldots.com/data-science/breakthrough-research-papers-and-models-for-sentiment-analysis/)
    中。尽管这篇综述是关于情感分析技术的，但它可以扩展到大多数文本分类问题。
- en: Our (ParallelDots) surveys are slightly less technical and aim to direct you
    to cool resources to understand a concept. The Arxiv survey papers I point you
    to will be very technical and will need you to read other important papers to
    deeply understand a topic. Our suggested way is to use our links to get familiar
    and have fun with a topic but then to be sure to read the thorough guides we point
    to. (Dr. Oakley’s [course](https://www.coursera.org/learn/learning-how-to-learn) talks
    about chunking, where you first try to get small bits here and there before you
    jump deep). Remember, it is great to have fun but unless you understand the techniques
    in detail, it will be hard to apply concepts in a new situation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们（ParallelDots）的调查问卷技术性稍弱，旨在引导您到有趣的资源以理解一个概念。我推荐给您的 Arxiv 调查论文将非常技术性，需要您阅读其他重要论文以深入理解一个主题。我们建议的方式是通过我们的链接来熟悉并乐在其中，但要确保阅读我们推荐的详细指南。（奥克利博士的[课程](https://www.coursera.org/learn/learning-how-to-learn)讲解了块化学习，即您首先尝试从各处获取小块信息，然后再深入学习）。记住，虽然有趣很重要，但除非详细理解技术，否则在新情况中应用概念将会很困难。
- en: Another survey of Sentiment Analysis algorithms (by people at Linked University
    and UIUC) is [here](https://arxiv.org/abs/1801.07883).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个情感分析算法的调查（由 Linked University 和 UIUC 的人员编写）请见[这里](https://arxiv.org/abs/1801.07883)。
- en: The Transfer Learning revolution has already hit Deep Learning. Just like in
    images where a model trained on ImageNet classification can be fine-tuned for
    any classification task, NLP models trained for language modeling on Wikipedia
    can now transfer learn text classification on a relatively lesser amount of data.
    Here are two papers from OpenAI and Ruder, and Howard which deal with these techniques.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习革命已经影响了深度学习。就像在图像中，一个在 ImageNet 分类上训练的模型可以针对任何分类任务进行微调一样，针对维基百科的语言建模训练的
    NLP 模型现在可以在相对较少的数据上进行文本分类。这里有两篇来自 OpenAI 和 Ruder 及 Howard 的论文，处理了这些技术。
- en: '[https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)'
- en: '[https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf).'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)'
- en: Fast.ai has a more friendly documentation to apply these methods [here](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Fast.ai 提供了更友好的文档来应用这些方法，详见[这里](http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html)。
- en: If you are transfer learning two different tasks (not transferring from Wikipedia
    language modeling task), tricks to use Convnets are mentioned [here](https://arxiv.org/abs/1801.06480).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在进行两个不同任务的迁移学习（不是从维基百科语言建模任务迁移），有关使用 Convnets 的技巧请参见[这里](https://arxiv.org/abs/1801.06480)。
- en: IMHO, such approaches will slowly take up on all other classification methods
    (simple extrapolation from what has happened in vision). We also released our
    work on [Zero Shot Text classification](https://arxiv.org/abs/1712.05972) which
    gets good accuracy without any training on a dataset and are working on its next
    generation. We have built our custom text classification API commonly called the
    Custom Classifier in which you can define your own categories. You can check out
    the free [here](https://www.paralleldots.com/custom-classifier).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 恕我直言，这种方法将会慢慢取代所有其他分类方法（这是从视觉领域发生的情况进行的简单推测）。我们还发布了关于[零样本文本分类](https://arxiv.org/abs/1712.05972)的研究，能够在没有数据集训练的情况下获得良好的准确性，并且正在开发其下一代。我们建立了一个自定义文本分类
    API，通常称为 Custom Classifier，您可以定义自己的类别。您可以在[这里](https://www.paralleldots.com/custom-classifier)查看免费版。
- en: SEQUENCE LABELING
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SEQUENCE LABELING
- en: Sequence Labeling is a task which labels words with different attributes. These
    include part-of-speech tagging, Named Entity Recognition, Keyword Tagging etc.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 序列标注是一个为单词标注不同属性的任务。这些属性包括词性标注、命名实体识别、关键词标注等。
- en: We wrote a fun review of methods to tasks like these [here](https://blog.paralleldots.com/data-science/named-entity-recognition-milestone-models-papers-and-technologies/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对类似任务的方法进行了有趣的回顾，详见[这里](https://blog.paralleldots.com/data-science/named-entity-recognition-milestone-models-papers-and-technologies/)。
- en: An excellent resource for such problems is the research paper from this year’s
    COLING which gives optimal guidelines to train Sequence labeling algorithms. You
    can access it [here](https://arxiv.org/abs/1806.04470).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这些问题的一个优秀资源是今年COLING的研究论文，它提供了训练序列标注算法的最佳指南。你可以在[这里](https://arxiv.org/abs/1806.04470)获取。
- en: MACHINE TRANSLATION
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器翻译
- en: One of the biggest advances in NLP in recent days has been the discovery of
    algorithms that can translate text from one language to another. Google’s system
    is an insane 16 layered LSTM (which requires no dropout because they have tons
    of data to train on) and gives state-of-the-art translation results.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近自然语言处理领域最大的进展之一是发现了能够将文本从一种语言翻译到另一种语言的算法。Google的系统是一个令人惊叹的16层LSTM（因为他们有大量的数据进行训练，所以不需要丢弃）并且提供了最先进的翻译结果。
- en: Media experts blew the hype out of proportion with hyperbole reports claiming
    “Facebook had to shut down AI which invented its own language”. Here are some
    of these.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体专家夸大了这一炒作，发布了虚假报道声称“Facebook不得不关闭发明了自己语言的AI”。以下是一些相关报道。
- en: '[https://gadgets.ndtv.com/social-networking/news/facebook-shuts-ai-system-after-bots-create-own-language-1731309](https://gadgets.ndtv.com/social-networking/news/facebook-shuts-ai-system-after-bots-create-own-language-1731309)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://gadgets.ndtv.com/social-networking/news/facebook-shuts-ai-system-after-bots-create-own-language-1731309](https://gadgets.ndtv.com/social-networking/news/facebook-shuts-ai-system-after-bots-create-own-language-1731309)'
- en: '[https://www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/#1d1ca041292c](https://www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/#1d1ca041292c)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/#1d1ca041292c](https://www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/#1d1ca041292c)'
- en: For an extensive tutorial on Machine Translation, refer to Philip Koehn’s research
    paper [here](https://arxiv.org/abs/1709.07809). A specific review to use Deep
    Learning for Machine Translation (which we call NMT or Neural Machine Translation)
    is [here](https://arxiv.org/abs/1707.07631).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于机器翻译的详细教程，请参考Philip Koehn的研究论文[在这里](https://arxiv.org/abs/1709.07809)。使用深度学习进行机器翻译（我们称之为NMT或神经机器翻译）的具体综述在[这里](https://arxiv.org/abs/1707.07631)。
- en: A couple of my favorite papers are here –
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我的一些最喜欢的论文在这里—
- en: This [paper by Google](https://arxiv.org/abs/1609.08144) tells you how to solve
    a problem end-to-end when you have a lot of money and data.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这篇[Google的论文](https://arxiv.org/abs/1609.08144)告诉你当你有大量的钱和数据时，如何解决一个问题。
- en: Facebook’s [Convolutional NMT system](https://arxiv.org/abs/1705.03122)(just
    because of its cool convolutional approach) and its code is released as a library [here](https://github.com/facebookresearch/fairseq).
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Facebook的[卷积神经机器翻译系统](https://arxiv.org/abs/1705.03122)（仅仅因为其酷炫的卷积方法）及其代码作为库被发布[在这里](https://github.com/facebookresearch/fairseq)。
- en: '[https://marian-nmt.github.io/](https://marian-nmt.github.io/)is a framework
    for fast translation in C++[http://www.aclweb.org/anthology/P18-4020](http://www.aclweb.org/anthology/P18-4020)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://marian-nmt.github.io/](https://marian-nmt.github.io/)是一个用于快速翻译的C++框架[http://www.aclweb.org/anthology/P18-4020](http://www.aclweb.org/anthology/P18-4020)'
- en: '[http://opennmt.net/](http://opennmt.net/)enables everyone to train their NMT
    systems.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://opennmt.net/](http://opennmt.net/)使每个人都能训练他们的NMT系统。'
- en: QUESTION ANSWERING
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问答系统
- en: IMHO this is going to be the next “Machine Translation”. There are many different
    types of Question Answering tasks. Choosing from options, selecting answers from
    a paragraph or a knowledge graph and answering questions based on an image (also
    known as Visual Question Answering) and there are different datasets to get to
    know the state of the art method.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这将是下一个“机器翻译”。问答任务有很多不同的类型。从选项中选择，基于段落或知识图谱选择答案，或基于图像回答问题（也称为视觉问答），有不同的数据集可以了解最前沿的方法。
- en: '[SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/)is a question answering
    datasets which tests an algorithm’s ability to read comprehensions and answer
    questions. Microsoft published a paper earlier this year claiming they have reached
    human-level accuracy for the [task](https://blogs.microsoft.com/ai/microsoft-creates-ai-can-read-document-answer-questions-well-person/).
    The paper can be found [here](https://www.ailab.microsoft.com/experiments/ef90706b-e822-4686-bbc4-94fd0bca5fc5).
    Another important algorithm (which I feel is the coolest) is Allen AI’s [BIDAF](https://allenai.github.io/bi-att-flow/) and
    its improvements.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQuAD数据集](https://rajpurkar.github.io/SQuAD-explorer/)是一个测试算法阅读理解和回答问题能力的问答数据集。微软今年早些时候发布了一篇论文，声称他们已达到该[任务](https://blogs.microsoft.com/ai/microsoft-creates-ai-can-read-document-answer-questions-well-person/)的人类水平准确性。论文可以在[这里](https://www.ailab.microsoft.com/experiments/ef90706b-e822-4686-bbc4-94fd0bca5fc5)找到。另一个重要的算法（我觉得非常酷）是Allen
    AI的[BIDAF](https://allenai.github.io/bi-att-flow/)及其改进。'
- en: Another important set of algorithms is Visual Question Answering which answers
    questions about images. Teney et al.’s [paper](https://allenai.github.io/bi-att-flow/)from
    VQA 2017 challenge is an excellent resource to get started. You can also find
    its implementations on Github [here](https://github.com/markdtw/vqa-winner-cvprw-2017).
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个重要的算法集是视觉问答，它回答关于图像的问题。Teney等人的[论文](https://allenai.github.io/bi-att-flow/)来自VQA
    2017挑战赛，是一个很好的入门资源。你还可以在Github上找到它的实现[这里](https://github.com/markdtw/vqa-winner-cvprw-2017)。
- en: Extractive Question Answering on large documents (like how Google Highlights
    answer to your queries in first few results) in real life can be done using Transfer
    Learning (thus with few annotations) as shown in this ETH paper [here](https://arxiv.org/abs/1804.07097). A
    very good paper criticizing the “understanding” of Question Answering algorithms
    is [here](https://arxiv.org/abs/1808.04926). Must read if you are working in this
    field.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对大文档进行抽取式问答（类似于谷歌如何在前几条结果中突出显示对查询的回答）在现实生活中可以使用迁移学习（因此只需少量标注），如这篇ETH论文中所示[这里](https://arxiv.org/abs/1804.07097)。一篇非常好的论文批评了问答算法的“理解”，请参阅[这里](https://arxiv.org/abs/1808.04926)。如果你在这个领域工作，必须阅读。
- en: PARAPHRASE, SENTENCE SIMILARITY OR INFERENCE
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 同义句生成、句子相似性或推理
- en: 'The task of comparing sentences. NLP has three different tasks: Sentence Similarity,
    Paraphrase detection and Natural Language Inference (NLI) for this, each requiring
    more semantic understanding than the last. [MultiNLI](https://www.nyu.edu/projects/bowman/multinli/) and
    its subset Stanford NLI are the most well-known benchmarks datasets for NLI and
    have become the focus of research lately. There are also MS Paraphrase Corpus
    and Quora Corpus for paraphrase detection, and a SemEval Dataset for STS (Semantic
    Text Similarity). A good survey for advanced models in this domain can be found [here](https://arxiv.org/abs/1806.04330).
    Applied NLI in the clinical domain is very important. (Finding out about right
    medical procedures, side effects and cross effects of drugs etc. ). [This tutorial](https://arxiv.org/abs/1808.06752) from
    applied NLI in the medical domain is a good read if you are looking to apply the
    tech in a specific domain.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 句子比较任务。NLP有三个不同的任务：句子相似性、同义句检测和自然语言推理（NLI），每个任务对语义理解的要求逐渐提高。[MultiNLI](https://www.nyu.edu/projects/bowman/multinli/)及其子集斯坦福NLI是最知名的NLI基准数据集，最近成为了研究的重点。还有MS同义句语料库和Quora语料库用于同义句检测，以及SemEval数据集用于STS（语义文本相似性）。有关该领域高级模型的良好调查可以在[这里](https://arxiv.org/abs/1806.04330)找到。在临床领域应用NLI非常重要。（查找正确的医疗程序、药物的副作用及交叉效应等）。如果你希望将技术应用于特定领域，[这篇教程](https://arxiv.org/abs/1808.06752)是一个不错的阅读选择。
- en: Here is a list of my favorite papers in this domain
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我在这个领域中最喜欢的论文列表
- en: Natural Language Inference over Interaction Space – It highlights a very clever
    approach for putting a DenseNet (Convolutional Neural Network on Sentence representations).
    The fact that this was the outcome of an internship project makes it even cooler!
    You can read the paper [here](https://arxiv.org/pdf/1709.04348.pdf).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言推理在交互空间中的应用 – 它展示了一种非常巧妙的方法，将DenseNet（用于句子表示的卷积神经网络）应用于此。这个成果还是一个实习项目的结果，这让它更加酷炫！你可以在[这里](https://arxiv.org/pdf/1709.04348.pdf)阅读这篇论文。
- en: This research [paper](https://homes.cs.washington.edu/~roysch/papers/artifacts/artifacts_poster.pdf)from
    Omar Levy’s group shows that even simple algorithms can perform the task. This
    is because algorithms are still not learning “inference”.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Omar Levy 小组的这篇研究[论文](https://homes.cs.washington.edu/~roysch/papers/artifacts/artifacts_poster.pdf)表明，即使是简单的算法也能完成任务。这是因为算法仍然没有学习“推理”。
- en: BiMPM is a cool model to predict paraphrases and can be accessed [here](https://arxiv.org/abs/1702.03814).
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BiMPM 是一个很酷的模型，用于预测同义句，可以在[这里](https://arxiv.org/abs/1702.03814)访问。
- en: We have a new work for Paraphrase detection too which applies Relation Networks
    on top of sentence representations and has been accepted at this year’s AINL conference.
    You can read it [here](https://peerj.com/preprints/26847).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们也有一项关于同义句检测的新工作，它将关系网络应用于句子表示，并且已被今年的 AINL 会议接受。你可以在[这里](https://peerj.com/preprints/26847)阅读。
- en: OTHER FIELDS
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他领域
- en: Here are some of the more detailed survey papers to get information about research
    for other tasks you might encounter making an NLP system.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些更详细的调查论文，可以获取有关你可能在构建 NLP 系统时遇到的其他任务的研究信息。
- en: '**Language Modelling(LM) – **Language Modelling is the task of learning an
    unsupervised representation of a language. This is done by predicting the (n+1)th
    word of a sentence given the first N words. These models have two important real-world
    uses, autocomplete and acting as a base model for transfer learning for text classification
    as mentioned above. A detailed survey is [here](https://arxiv.org/abs/1708.07252).
    If you are interested in learning how to autocomplete LSTMs in cellphones/search
    engines work based on search history, [here](https://arxiv.org/abs/1804.09661)is
    a cool paper you should read.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言建模（LM） –** 语言建模的任务是学习语言的无监督表示。通过预测给定前 N 个单词后第 (n+1) 个单词来完成。这些模型有两个重要的实际应用，自动补全和作为文本分类转移学习的基础模型，如前所述。详细调查可以在[这里](https://arxiv.org/abs/1708.07252)找到。如果你有兴趣了解基于搜索历史的
    LSTM 如何在手机/搜索引擎中进行自动补全，[这里](https://arxiv.org/abs/1804.09661)有一篇很酷的论文值得阅读。'
- en: '**Relation Extraction – **Relation extraction is the task of extracting relations
    between entities present in a sentence. A given sentence “A is related as r to
    B”, gives the triplet (A,r, B). A survey of the research work in the field is [here](https://arxiv.org/abs/1712.05191). [Here](https://arxiv.org/abs/1706.04115)is
    a research paper that I found to be really interesting. It uses BIDAFs for Zero
    Shot Relation extraction (that is, it can recognize relations it was not even
    trained to recognize).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关系抽取 –** 关系抽取的任务是提取句子中存在的实体之间的关系。给定句子“A 与 B 的关系为 r”，给出三元组 (A, r, B)。该领域的研究工作调查可以在[这里](https://arxiv.org/abs/1712.05191)找到。[这里](https://arxiv.org/abs/1706.04115)是我发现非常有趣的一篇研究论文。它使用
    BIDAFs 进行零样本关系抽取（即，它可以识别它未曾接受训练的关系）。'
- en: '**Dialog Systems – **With the onset of the chatbot revolution, Dialog systems
    are now the rage. Many people (including us) make dialog systems as a combination
    of models such as intent detection, keyword detection, question answering etc,
    while others try to model it end-to-end. A detailed survey of dialog system models
    by the team at JD.com is [here](https://arxiv.org/abs/1711.01731). I would also
    like to mention Parl.ai, a framework by Facebook AI for the purpose.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话系统 –** 随着聊天机器人革命的兴起，对话系统现在非常流行。许多人（包括我们）将对话系统构建为意图检测、关键词检测、问答等模型的组合，而其他人则尝试端到端建模。JD.com
    团队对对话系统模型的详细调查可以在[这里](https://arxiv.org/abs/1711.01731)找到。我还想提到 Facebook AI 提供的框架
    Parl.ai。'
- en: '**Text Summarization – **Text Summarization is used to get a condensed text
    from a document (paragraph/news article etc.). There are two ways to do this:
    extractive and abstractive summarization. While extractive summarization gives
    out sentences from the article with the highest information content (and what
    has been available for decades), abstractive summarization aims to write a summary
    just like a human would. This [demo](https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/)from
    Eintein AI brought abstractive summarization into mainstream research. There is
    an extensive survey of techniques [here](https://arxiv.org/abs/1804.04589).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本摘要 –** 文本摘要用于从文档（段落/新闻文章等）中获取简洁的文本。有两种方法：提取式摘要和抽象式摘要。提取式摘要提供了信息含量最高的句子（这种方法已经存在几十年），而抽象式摘要则旨在像人类一样撰写摘要。这款[演示](https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/)来自
    Einstein AI，将抽象式摘要引入主流研究。有关技术的详细调查报告[这里](https://arxiv.org/abs/1804.04589)。'
- en: '**Natural Language Generation (NLG) – **Natural Language Generation is the
    research where the computer aims to write like a human would. This could be stories,
    poetries, image captions etc. Out of these, current research has been able to
    do very well on image captions where LSTMs and attention mechanism combined has
    given outputs usable in real life. A survey of techniques is available [here](https://arxiv.org/abs/1703.09902).'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言生成 (NLG) –** 自然语言生成是计算机旨在像人类一样写作的研究。这可能包括故事、诗歌、图像描述等。在这些方面，当前研究在图像描述上表现很好，LSTM
    和注意力机制的结合已经提供了可以实际使用的输出。有关技术的调查报告[这里](https://arxiv.org/abs/1703.09902)。'
- en: Blogs to follow
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐关注的博客
- en: Here’s a list of blogs which we highly recommend for anyone interested in keeping
    track of what’s new in NLP research.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一份博客推荐列表，适合任何对跟踪 NLP 研究新动态感兴趣的人。
- en: Einstein AI – [ https://einstein.ai/research](https://einstein.ai/research)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Einstein AI – [ https://einstein.ai/research](https://einstein.ai/research)
- en: Google AI blog – [https://ai.googleblog.com/](https://ai.googleblog.com/)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Google AI 博客 – [https://ai.googleblog.com/](https://ai.googleblog.com/)
- en: WildML – [http://www.wildml.com/](http://www.wildml.com/)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: WildML – [http://www.wildml.com/](http://www.wildml.com/)
- en: DistillPub – [https://distill.pub/](https://distill.pub/) (distillpub is unique,
    blog and publication both)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: DistillPub – [https://distill.pub/](https://distill.pub/) (distillpub 是独特的，既是博客也是出版物)
- en: Sebastian Ruder – [http://ruder.io/](http://ruder.io/)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Sebastian Ruder – [http://ruder.io/](http://ruder.io/)
- en: If you liked this article, you must follow our blog. We come up with resource
    lists quite frequently here.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，必须关注我们的博客。我们经常在这里提供资源列表。
- en: That’s all folks! Enjoy making neural nets understand language. You can also
    try on text analysis APIs based on Natural Language Processing [here](https://www.paralleldots.com/text-analysis-apis).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！享受让神经网络理解语言的乐趣。你还可以尝试基于自然语言处理的文本分析 API，[这里](https://www.paralleldots.com/text-analysis-apis)。
- en: You can also read about Machine Learning algorithms you should know to become
    a Data Scientist [here](https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以阅读有关机器学习算法的文章，了解成为数据科学家应掌握的算法[这里](https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/)。
- en: You can also check out free demos of ParallelDots AI APIs [here](https://www.paralleldots.com/text-analysis-apis).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以[这里](https://www.paralleldots.com/text-analysis-apis)查看 ParallelDots AI
    API 的免费演示。
- en: '[Original](https://blog.paralleldots.com/data-science/nlp/free-natural-language-processing-resources/).
    Reposted with permission.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[原创](https://blog.paralleldots.com/data-science/nlp/free-natural-language-processing-resources/)。已获授权转载。'
- en: '**Bio**: [Muktabh Mayank](https://twitter.com/muktabh) is cofounder at [ParallelDots](https://www.paralleldots.com/),
    a company that is "Simplifying Machine Learning For Everyone". Muktabh is a Data
    Scientist, entrepreneur , sociologist, not the classic nerd.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**: [Muktabh Mayank](https://twitter.com/muktabh) 是 [ParallelDots](https://www.paralleldots.com/)
    的联合创始人，该公司致力于“简化每个人的机器学习”。Muktabh 是数据科学家、企业家、社会学家，不是传统的书呆子。'
- en: '**Related:**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关链接：**'
- en: '[The Data Science of “Someone Like You” or Sentiment Analysis of Adele’s Songs](https://www.kdnuggets.com/2018/09/sentiment-analysis-adele-songs.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“Someone Like You” 的数据科学或阿黛尔歌曲的情感分析](https://www.kdnuggets.com/2018/09/sentiment-analysis-adele-songs.html)'
- en: '[Machine Learning for Text Classification Using SpaCy in Python](https://www.kdnuggets.com/2018/09/machine-learning-text-classification-using-spacy-python.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 中的 SpaCy 进行文本分类的机器学习](https://www.kdnuggets.com/2018/09/machine-learning-text-classification-using-spacy-python.html)'
- en: '[Deep Learning for NLP: An Overview of Recent Trends](https://www.kdnuggets.com/2018/09/deep-learning-nlp-overview-recent-trends.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的深度学习：近期趋势概述](https://www.kdnuggets.com/2018/09/deep-learning-nlp-overview-recent-trends.html)'
- en: '* * *'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[N-gram Language Modeling in Natural Language Processing](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理中的N-gram语言建模](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
- en: '[5 Free Books on Natural Language Processing to Read in 2023](https://www.kdnuggets.com/2023/06/5-free-books-natural-language-processing-read-2023.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年值得阅读的5本自然语言处理免费书籍](https://www.kdnuggets.com/2023/06/5-free-books-natural-language-processing-read-2023.html)'
- en: '[25 Free Books to Master SQL, Python, Data Science, Machine…](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握SQL、Python、数据科学、机器学习和自然语言处理的25本免费书籍](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
- en: '[5 Free Courses to Master Natural Language Processing](https://www.kdnuggets.com/5-free-courses-to-master-natural-language-processing)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握自然语言处理的5门免费课程](https://www.kdnuggets.com/5-free-courses-to-master-natural-language-processing)'
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像识别和自然语言处理的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
- en: '[How to Start Using Natural Language Processing With PyTorch](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用PyTorch开始自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
