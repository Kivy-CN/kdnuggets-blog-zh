- en: A Gentle Introduction to PyTorch 1.2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 1.2 简介
- en: 原文：[https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html](https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html](https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Elvis Saravia](https://twitter.com/omarsar0), Affective Computing & NLP
    Researcher**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Elvis Saravia](https://twitter.com/omarsar0)，情感计算与 NLP 研究员**'
- en: '![Figure](../Images/b4722fc331c461340adab4a229dc2d80.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/b4722fc331c461340adab4a229dc2d80.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In our previous PyTorch [notebook](https://medium.com/dair-ai/pytorch-1-2-quickstart-with-google-colab-6690a30c38d),
    we learned about how to get started quickly with PyTorch 1.2 using Google Colab.
    In this tutorial, we are going to take a step back and review some of the basic
    components of building a neural network model using PyTorch. As an example, we
    will build an image classifier using a few stacked layers and then evaluate the
    model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的 PyTorch [笔记本](https://medium.com/dair-ai/pytorch-1-2-quickstart-with-google-colab-6690a30c38d)中，我们学习了如何快速开始使用
    PyTorch 1.2 和 Google Colab。在本教程中，我们将退一步，回顾使用 PyTorch 构建神经网络模型的一些基本组件。作为示例，我们将构建一个图像分类器，使用几个堆叠层，然后评估模型。
- en: This will be a brief tutorial and will avoid using jargon and over-complicated
    code. That said, this is perhaps the most basic of neural network models you can
    build with PyTorch.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个简短的教程，避免使用行话和过于复杂的代码。也就是说，这可能是你可以用 PyTorch 构建的最基本的神经网络模型。
- en: If fact, it is so basic that it’s ideal for those starting to learn about PyTorch
    and machine learning. So if you have a friend or colleague that wants to jump
    in, I highly encourage you to refer them to this tutorial as a starting point.
    Let’s get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这么基础的内容对于那些刚开始学习 PyTorch 和机器学习的人来说是理想的。所以如果你有朋友或同事想要入门，我强烈建议你把他们推荐到这个教程作为起点。让我们开始吧！
- en: Getting Started
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始使用
- en: Before you get started with code, you need to install the latest version of
    PyTorch. We are using Google Colab for our tutorial, so we will use the following
    command to install PyTorch. *You can also find a Colab notebook towards the end
    of this blog post.*
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始代码之前，你需要安装最新版本的 PyTorch。我们使用 Google Colab 进行教程，因此我们将使用以下命令安装 PyTorch。*你也可以在本博客文章的末尾找到一个
    Colab 笔记本。*
- en: Now we need to import a few modules which will be useful to obtain the necessary
    functions that will help us to build our neural network model. The main ones are `torch` and `torchvision`.
    They contain the majority of the functions that you need to get started with PyTorch.
    However, as this is a machine learning tutorial we will need `torch.nn`, `torch.nn.functional`
    and `torchvision.transforms` which all contain utility functions to build our
    model. We probably won't use all the modules listed below but they are the typical
    modules you will need to import before starting your machine learning projects.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要导入一些模块，这些模块将帮助我们获取构建神经网络模型所需的功能。主要的是`torch`和`torchvision`。它们包含了你开始使用 PyTorch
    所需的大部分功能。然而，由于这是一个机器学习教程，我们还需要`torch.nn`、`torch.nn.functional`和`torchvision.transforms`，它们都包含了构建模型的实用函数。我们可能不会使用下面列出的所有模块，但这些是你在开始机器学习项目之前需要导入的典型模块。
- en: Below we check for the PyTorch version just to make sure that you are using
    the proper version that was used for this tutorial. At the time of this tutorial,
    we are working with PyTorch 1.2.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，我们检查 PyTorch 版本，以确保你使用的是本教程所用的正确版本。到本教程时，我们使用的是 PyTorch 1.2。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading the Data
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: Let’s get right into it! As with any machine learning project, you need to load
    your dataset. We are using the [MNIST dataset](http://yann.lecun.com/exdb/mnist/),
    which is the “Hello World” of datasets in the machine learning world.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接进入正题！与任何机器学习项目一样，你需要加载你的数据集。我们使用的是[MNIST数据集](http://yann.lecun.com/exdb/mnist/)，它是机器学习领域中的“Hello
    World”数据集。
- en: 'The data consists of a series of images (containing hand-written numbers) that
    are of the size `28 X 28`. We will discuss the images shortly, but our plan is
    to load the data into batches of `32`, similar to the figure below:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据由一系列`28 X 28`大小的图像（包含手写数字）组成。我们将很快讨论这些图像，但我们的计划是将数据加载成`32`的批次，类似于下面的图示：
- en: '![](../Images/9fe8202824dcd4afffb50905030f2530.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9fe8202824dcd4afffb50905030f2530.png)'
- en: 'Here are the complete steps we are performing when importing our data:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们在导入数据时执行的完整步骤：
- en: We will import and transform the data into tensors using the `transforms` module.
    In the context of machine learning, tensors are just efficient data structures
    used to store data.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用`transforms`模块将数据导入并转换为张量。在机器学习的背景下，张量只是用于存储数据的高效数据结构。
- en: We will use `DataLoader` to build convenient data loaders, which makes it easy
    to efficiently feed data in batches to neural network models. We will get to the
    topic of batches in a bit but for now, just think of them as subsets of your data.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用`DataLoader`来构建便捷的数据加载器，这使得将数据高效地批量输入神经网络模型变得容易。稍后我们将讨论批次的问题，但现在，先把它们当作数据的子集。
- en: As hinted above, we will also create batches of the data by setting the `batch` parameter
    inside the data loader. Notice we use batches of `32` in this tutorial but you
    can change it to `64` if you like.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如上所述，我们还将通过在数据加载器中设置`batch`参数来创建数据批次。注意，在本教程中我们使用了`32`的批次，但如果你愿意，可以将其更改为`64`。
- en: Let’s inspect what the `trainset` and `testset` objects contain.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下`trainset`和`testset`对象包含的内容。
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is a beginner’s tutorial so I will break down things a bit here:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个初学者教程，所以我会稍微拆解一下：
- en: '`BATCH_SIZE` is a parameter that denotes the batch size we will use for our
    model'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BATCH_SIZE`是一个参数，表示我们将用于模型的批次大小。'
- en: '`transform` holds code for whatever transformations you will apply to your
    data. I will show you an example below to demonstrate exactly what it does to
    shed more light into its use'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transform`包含你将应用于数据的所有转换代码。下面我会展示一个示例，演示它的作用，以便更好地理解它的使用。'
- en: '`trainset` and `testset` contain the actual dataset object. Notice I use `train=True` to
    specify that this corresponds to the training dataset, and I use `train=False` to
    specify that this is the remainder of the dataset which we call the test set.
    From the block I printed above you can see that the split of the data was 85%
    (60000) / 15% (10000), corresponding to the portions of samples for the training
    set and testing set, respectively'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainset`和`testset`包含实际的数据集对象。注意我使用`train=True`来指定这对应于训练数据集，我使用`train=False`来指定这是其余的数据集，我们称之为测试集。从上面打印的块中你可以看到，数据的划分是85%（60000）/15%（10000），分别对应于训练集和测试集的样本部分。'
- en: '`trainloader` is what holds the data loader object which takes care of *shuffling* the
    data and constructing the batches'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainloader`是持有数据加载器对象的地方，它负责*打乱*数据并构建批次。'
- en: 'Now let’s take a closer look at that `transforms.Compose(...)` function and
    see what it does. We will use a randomly generated image to demonstrate its use.
    Let''s generate an image:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们仔细看看`transforms.Compose(...)`函数，看看它的作用。我们将使用一个随机生成的图像来演示它的使用。让我们生成一张图像：
- en: 'And let’s render it:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们渲染它：
- en: 'The output:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](../Images/19604cc32294528da514e4c3ac6d90eb.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19604cc32294528da514e4c3ac6d90eb.png)'
- en: 'Okay, we have our image sample, so now let’s apply some dummy transformation
    to it. We are going to rotate the image by `45` degrees. The transformation below
    takes care of that:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们有了我们的图像样本，现在让我们对它应用一些虚拟转换。我们将把图像旋转`45`度。下面的转换处理了这一点：
- en: 'The output:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](../Images/79b8103af10513e590b0c2942f378530.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79b8103af10513e590b0c2942f378530.png)'
- en: Notice you can put any transformations within `transforms.Compose(...)`. You
    can use the built-in transformations offered by PyTorch or you can build your
    own and compose transformations as you wish. In fact, you can place as many transformations
    in the function as you wish. Let's try another composition of transformations: *rotate* + *vertical
    flip*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你可以将任何转换放在 `transforms.Compose(...)` 中。你可以使用 PyTorch 提供的内置转换，也可以构建自己的转换并按需组合。事实上，你可以在函数中放入任意多的转换。让我们尝试另一种转换组合：*rotate*
    + *vertical flip*。
- en: 'The output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](../Images/b43d65f8130b742734c15f34c5998d3a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b43d65f8130b742734c15f34c5998d3a.png)'
- en: That’s pretty cool right! Keep trying other transform methods. On the topic
    of exploring our data further, let’s take a closer look at our images dataset.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这很酷，对吧！继续尝试其他转换方法。在进一步探索我们的数据话题上，让我们更仔细地看看我们的图像数据集。
- en: Exploring the Data
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据
- en: As a practitioner and researcher, I always spend a bit of time and effort exploring
    and understanding my datasets. It’s fun and this is a good practice to ensure
    that everything is in order before training the model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个从业者和研究人员，我总是花一点时间和精力探索和理解我的数据集。这很有趣，并且这是一个很好的做法，以确保在训练模型之前一切都井井有条。
- en: 'Let’s check what the train and test dataset contains. I will use the `matplotlib` library
    to print out some of the images from our dataset. With a bit of `numpy` code,
    I can convert images into a proper format to print them out. Below I print out
    an entire batch of 32 images:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下训练和测试数据集包含了什么。我将使用 `matplotlib` 库来打印出数据集中的一些图像。通过一点 `numpy` 代码，我可以将图像转换为合适的格式以打印出来。下面我打印出了一整批
    32 张图像：
- en: 'The output:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](../Images/8974f9884052ce437df9813fbdb8fdcc.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8974f9884052ce437df9813fbdb8fdcc.png)'
- en: 'The dimensions of our batches are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的批次维度如下：
- en: 'The output:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Model
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型
- en: Now it’s time to build the neural network model that will be used to perform
    the image classification task. We will keep things simple and stack a *dense *layer,
    a *dropout* layer, and an *output* layer to train our model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建用于执行图像分类任务的神经网络模型了。我们将保持简单，堆叠一个 *dense* 层、一个 *dropout* 层和一个 *output*
    层来训练我们的模型。
- en: 'Let’s discuss a bit about the model:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下模型：
- en: 'First of all, the following structure, involving a `class` called `MyModel` ,
    is standard code that''s used to build a neural network model in PyTorch:'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，以下结构，涉及一个名为 `MyModel` 的 `class`，是用于在 PyTorch 中构建神经网络模型的标准代码：
- en: The layers are defined inside the `def __init__()` function. `super(...).__init__()` is
    just there to stick things together. For our model, we stack a hidden layer (`self.d1`)
    followed by a dropout layer (`self.dropout`), which is then followed by an output
    layer (`self.d2`).
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层在 `def __init__()` 函数内定义。`super(...).__init__()` 只是用来将各部分粘合在一起。对于我们的模型，我们堆叠了一个隐藏层（`self.d1`），接着是一个
    dropout 层（`self.dropout`），然后是一个输出层（`self.d2`）。
- en: '`nn.Linear(...)` defines the dense layer and it requires the `in` and `out` dimensions,
    which corresponds to the size of the input feature and output feature of that
    layer, respectively.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.Linear(...)` 定义了密集层，它需要 `in` 和 `out` 维度，这些维度分别对应于该层输入特征和输出特征的大小。'
- en: '`nn.Dropout(...)` is used to define a dropout layer. Dropout is an approach
    in deep learning that helps a model to avoid *overfitting*. This means that dropout
    acts as a regularization technique that helps the model to not overfit on the
    images it has seen while training. We want this because we need a model that generalizes
    well to unseen examples — in our case, the testing dataset. Dropout randomly zeroes
    some of the units of the neural network layer with the probability of `p=0.2`.
    Read more about the dropout layer [here](https://pytorch.org/docs/stable/nn.html#dropout).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.Dropout(...)` 用于定义一个 dropout 层。Dropout 是深度学习中的一种方法，帮助模型避免 *overfitting*。这意味着
    dropout 作为一种正则化技术，帮助模型不在训练时看到的图像上过拟合。我们需要这样做，因为我们需要一个对未见示例——在我们这个案例中是测试数据集——有很好的泛化能力的模型。Dropout
    随机将神经网络层的一些单元置为零，概率为 `p=0.2`。更多关于 dropout 层的信息请参考 [这里](https://pytorch.org/docs/stable/nn.html#dropout)。'
- en: The entry point of the model, i.e. where the data is fed into the neural network
    model, is placed under the `forward(...)` function. Typically, we also place other
    transformations we perform on the data while training inside this function.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的入口点，即数据输入到神经网络模型的位置，放在 `forward(...)` 函数下。通常，我们还会将训练过程中对数据进行的其他转换放在此函数内。
- en: In the `forward()` function, we are performing a series of computations on the
    input data: **1)** we flatten the images first, converting it from 2D (`28 X 28`)
    to 1D (`1 X 784`); **2)** then we feed the batches of those 1D images into the
    first hidden layer; **3)** the output of that hidden layer is then applied a [non-linear
    activate function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) called `ReLU`.
    It's not so important to know what `F.relu()` does at the moment, but the effect
    that it achieves is that it allows faster and more effective training of neural
    architectures on large datasets; **4)** as explained above, the dropout also helps
    the model to train more efficiently by avoiding overfitting on the training data; **5)** we
    then feed the output of that dropout layer into the output layer (`d2`); **6)** the
    result of that is then fed to the [softmax function](https://en.wikipedia.org/wiki/Softmax_function),
    which converts or normalizes the output into a probability distribution which
    helps with outputting proper prediction values that are used to calculate the
    accuracy of the model; **7)** this will be the final output of the model.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`forward()` 函数中，我们对输入数据执行一系列计算：**1)** 我们首先将图像展平，将其从2D (`28 X 28`) 转换为1D (`1
    X 784`); **2)** 然后将这些1D图像的批次输入到第一个隐藏层; **3)** 该隐藏层的输出应用了[非线性激活函数](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) 叫做`ReLU`。此时了解`F.relu()`的具体作用并不重要，但它的效果是允许神经网络架构在大数据集上更快、更有效地训练；**4)** 如上所述，dropout还通过避免对训练数据过拟合来帮助模型更有效地训练；**5)** 然后我们将dropout层的输出输入到输出层（`d2`）；**6)** 其结果接着传递到[softmax函数](https://en.wikipedia.org/wiki/Softmax_function)，它将输出转换或规范化为概率分布，有助于输出正确的预测值，这些值用于计算模型的准确率；**7)** 这将是模型的最终输出。
- en: Visually speaking, the following is a diagram of the model that we have just
    built. Just keep in mind that the hidden layer is much bigger than shown in the
    diagram but due to space constraint, the diagram should be viewed as an approximation
    of the actual model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上讲，以下是我们刚刚构建的模型的图示。请记住，隐藏层比图示中显示的要大，但由于空间限制，图示应视为实际模型的近似。
- en: '![](../Images/8ef5afdfb7ea69c95543514a412424cb.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ef5afdfb7ea69c95543514a412424cb.png)'
- en: As I have done in my previous tutorials, I always encourage to test the model
    with one batch to ensure that the dimensions of the output are what we expect.
    Notice how we are iterating over the dataloader which conveniently stores the `images` and `labels` pairs. `out` contains
    the output of the model, which are the logits applied a `softmax` layer which
    helps with prediction.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在之前的教程中所做的，我总是建议用一个批次测试模型，以确保输出的维度符合我们的期望。注意我们如何迭代数据加载器，它方便地存储了`images`和`labels`对。`out`包含模型的输出，这些输出是应用了`softmax`层的logits，有助于预测。
- en: 'The output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can clearly see that we get back the batches with 10 output values associated
    with each image in the batch; these values are used to check the performance of
    the model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到，我们得到的每个批次有10个输出值与批次中的每个图像相关联；这些值用于检查模型的性能。
- en: Training the Model
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'Now we are ready to train the model but before that, we are going to set up
    a *loss *function, an *optimizer*, and a utility function to calculate the accuracy
    of the model:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好训练模型了，但在此之前，我们将设置一个*损失*函数，一个*优化器*，以及一个计算模型准确率的实用函数：
- en: The `learning_rate` is the rate at which the model will try to optimize its
    weights, so it can be seen as just another parameter of the model.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate` 是模型尝试优化其权重的速率，因此可以看作是模型的另一个参数。'
- en: '`num_epochs` is the number of training steps… we don’t need to train this model
    for long so we just use 5 epochs.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_epochs` 是训练步骤的数量……我们不需要训练这个模型太长时间，所以只用5个epoch。'
- en: '`device` determines what hardware we will use to train the model. If a `gpu` is
    present, then that will be used, otherwise, it defaults to the `cpu`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device` 确定我们将使用什么硬件来训练模型。如果存在`gpu`，则会使用它，否则默认为`cpu`。'
- en: '`model` is just the model instance.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` 只是模型实例。'
- en: '`model.to(device)` is in charge of setting the actual device that will be used
    for training the model.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model.to(device)` 负责设置将用于训练模型的实际设备。'
- en: '`criterion` is just the metric that''s used to compute the loss of the model
    while it forward and backward trains to optimize its weights.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`criterion` 只是用于计算模型在前向和反向训练过程中损失的度量标准。'
- en: '`optimizer` is the optimization technique used to modify the weights in the
    backward propagation step. Notice that it requires the `learning_rate` and the
    model parameters which are part of the optimization. More on this in a bit!'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer` 是在反向传播步骤中用于修改权重的优化技术。注意，它需要`learning_rate`和模型参数，这些都是优化的一部分。稍后会详细介绍！'
- en: The utility function below helps to calculate the accuracy of the model. For
    now, it’s not important to understand how it’s calculated but basically it compares
    the outputs of the model (predictions) with the actual target values (i.e., the
    labels of the dataset), and tries to compute the average of correct predictions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的实用函数有助于计算模型的准确性。目前，理解它是如何计算的并不重要，但基本上它比较了模型的输出（预测）与实际目标值（即数据集的标签），并试图计算正确预测的平均值。
- en: Training the Model
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'Now it’s time to train the model. The code portion that follows can be described
    in the following steps:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是训练模型的时候了。以下代码部分可以按以下步骤描述：
- en: 'The first thing when training a neural network model is defining the training
    loop, which is achieved by:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练神经网络模型时的第一件事是定义训练循环，这通过以下方式实现：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We define two variables, `training_running_loss` and `train_acc` , that will
    help us to monitor the running accuracy and loss of the model while it trains
    over the different batches.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了两个变量，`training_running_loss`和`train_acc`，它们将帮助我们在模型训练不同批次时监控运行的准确性和损失。
- en: '`model.train()` explicitly indicates that we are ready to start training.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model.train()` 明确表示我们准备好开始训练了。'
- en: Notice that we are iterating over the *dataloader*, which conveniently gives
    us the batches in image-label pairs.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意，我们正在迭代*dataloader*，它方便地以图像-标签对的形式提供批次。
- en: That second `for` loop means that for every training step we will iterate over
    all the batches and train the model over them.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个`for`循环意味着在每个训练步骤中，我们将迭代所有批次并在这些批次上训练模型。
- en: We feed the model the images via `model(images)` and the output represents the
    predictions of the model.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过`model(images)`将图像输入模型，输出表示模型的预测。
- en: The predictions together with the target labels are used to compute the loss
    using the loss function we defined earlier.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测结果与目标标签一起用于使用我们之前定义的损失函数计算损失。
- en: Before we update our weights for the next round of training, we perform the
    following steps: **1)** we use the optimizer object to reset all the gradients
    for the variables it will update (`optimizer.zero_grad()` );** 2)** This is a
    safe step and it doesn’t overwrite the gradients the model accumulates while training
    (those are [stored in a buffer](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-optim) via
    the `loss.backward()` call); **3)**`loss.backward()` simply computes the gradient
    of the loss with respect to the model parameters; **4)** `optimizer.step()` then
    ensures that the model parameters are properly updated; 5) and finally we gather
    and accumulate the loss and accuracy, which is what we will use to tell us if
    the model is learning effectively.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们更新权重以进行下一轮训练之前，我们执行以下步骤：**1)** 我们使用优化器对象重置所有变量的梯度（`optimizer.zero_grad()`）；**2)**
    这是一个安全的步骤，它不会覆盖模型在训练过程中累积的梯度（这些梯度通过[`loss.backward()`调用](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-optim)存储在缓冲区中）；**3)**
    `loss.backward()` 只是计算损失相对于模型参数的梯度；**4)** `optimizer.step()` 然后确保模型参数得到适当更新；**5)**
    最后，我们收集并累积损失和准确性，这将帮助我们判断模型是否有效地学习。
- en: 'The output of the training:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的输出：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After all the training steps are over, we can clearly see that the loss keeps
    decreasing while the training accuracy of the model keeps rising, which is a good
    sign that the model is effectively learning to classify images.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有训练步骤完成后，我们可以清楚地看到损失不断减少，而模型的训练准确性不断提高，这表明模型有效地学习了图像分类。
- en: We can verify this by computing the accuracy on the testing dataset to see how
    well the model performs on the image classification task. As you can see below,
    our basic neural network model is performing very well on the MNIST classification
    task.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在测试数据集上计算准确性来验证这一点，以查看模型在图像分类任务上的表现如何。如下面所示，我们的基本神经网络模型在MNIST分类任务上表现非常好。
- en: 'The output:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Final Words
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后总结
- en: Congratulations ????! You have made it to the end of this tutorial. This is
    a comprehensive tutorial that aims to give a very basic introduction to the fundamentals
    of image classification using neural networks and PyTorch.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜 ????！你已完成本教程。这是一个全面的教程，旨在提供神经网络和 PyTorch 的图像分类基础介绍。
- en: '*This tutorial was heavily inspired by this *[*TensorFlow tutorial.*](https://www.tensorflow.org/beta/tutorials/quickstart/beginner)* We
    thank the authors of the corresponding reference for their valuable work.*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*本教程深受这篇*[*TensorFlow 教程*](https://www.tensorflow.org/beta/tutorials/quickstart/beginner)*的启发。我们感谢相关参考的作者们的宝贵工作。*'
- en: References
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[PyTorch 1.2 Quickstart with Google Colab](https://medium.com/dair-ai/pytorch-1-2-quickstart-with-google-colab-6690a30c38d)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 1.2 使用 Google Colab 的快速入门](https://medium.com/dair-ai/pytorch-1-2-quickstart-with-google-colab-6690a30c38d)'
- en: '[Get started with TensorFlow 2.0 for beginners](https://www.tensorflow.org/beta/tutorials/quickstart/beginner)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者入门 TensorFlow 2.0](https://www.tensorflow.org/beta/tutorials/quickstart/beginner)'
- en: '[PyTorch Data Loading Tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 数据加载教程](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)'
- en: '[Neural Networks with PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的神经网络](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)'
- en: ???? [Colab Notebook](https://colab.research.google.com/drive/1kl3--YxUIOoCcthoP47YLoSOoTxhNl0V)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ???? [Colab 笔记本](https://colab.research.google.com/drive/1kl3--YxUIOoCcthoP47YLoSOoTxhNl0V)
- en: ???? [ GitHub Repo](https://github.com/omarsar/pytorch_notebooks)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ???? [ GitHub 仓库](https://github.com/omarsar/pytorch_notebooks)
- en: '**Bio: [Elvis Saravia](https://twitter.com/omarsar0)** is a researcher and
    science communicator in Affective Computing and NLP.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Elvis Saravia](https://twitter.com/omarsar0)** 是情感计算和自然语言处理领域的研究员和科学传播者。'
- en: '[Original](https://medium.com/dair-ai/pytorch-1-2-introduction-guide-f6fa9bb7597c).
    Reposted with permission.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始文章](https://medium.com/dair-ai/pytorch-1-2-introduction-guide-f6fa9bb7597c)。已获授权转载。'
- en: '**Related:**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[XLNet Outperforms BERT on Several NLP Tasks](/2019/07/xlnet-outperforms-bert-several-nlp-tasks.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNet 在多个 NLP 任务上超越 BERT](/2019/07/xlnet-outperforms-bert-several-nlp-tasks.html)'
- en: '[Adapters: A Compact and Extensible Transfer Learning Method for NLP](/2019/07/adapters-compact-extensible-transfer-learning-method-nlp.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适配器：一种紧凑且可扩展的 NLP 迁移学习方法](/2019/07/adapters-compact-extensible-transfer-learning-method-nlp.html)'
- en: '[NLP Overview: Modern Deep Learning Techniques Applied to Natural Language
    Processing](/2019/01/nlp-overview-modern-deep-learning-techniques.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NLP 概述：现代深度学习技术在自然语言处理中的应用](/2019/01/nlp-overview-modern-deep-learning-techniques.html)'
- en: More On This Topic
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[A Gentle Introduction to Natural Language Processing](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的温和介绍](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机的温和介绍](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库介绍：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的可解释神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整免费的 PyTorch 深度学习课程](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用 PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
