- en: AI and Deep Learning, Explained Simply
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 和深度学习，简明解析
- en: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png)[comments](2017/07/ai-deep-learning-explained-simply.html/3#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png)[评论](2017/07/ai-deep-learning-explained-simply.html/3#comments)'
- en: '![AI and Deep Learning](../Images/c7647d29fcffe28c724b24f417ff1a6c.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![AI 和深度学习](../Images/c7647d29fcffe28c724b24f417ff1a6c.png)'
- en: 'Sci-fi level **Artificial Intelligence (AI)** like HAL 9000 was promised since
    1960s, but PCs and robots were dumb until recently. Now, tech giants and startups
    are announcing the AI revolution: self-driving cars, robo doctors, robo investors,
    etc. PwC just said that AI will contribute **$15.7 trillion** to the world economy
    by 2030\. “AI” it’s the 2017 buzzword, like “dot com” was in 1999, and everyone
    claims to be into AI. Don’t be confused by the AI hype. Is this a bubble or for
    real? What’s new from older AI flops?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 自 1960 年代以来，科幻级**人工智能 (AI)** 如 HAL 9000 一直被承诺，但直到最近，个人计算机和机器人仍然很笨。现在，科技巨头和初创公司正在宣布
    AI 革命：自动驾驶汽车、机器人医生、机器人投资者等。PwC 刚刚表示，AI 将在 2030 年为世界经济贡献**15.7 万亿美元**。 “AI” 是 2017
    年的流行词，就像 1999 年的“互联网”一样，每个人都声称自己在做 AI。不要被 AI 炒作迷惑。这是泡沫还是实情？与旧的 AI 失败相比，有什么新变化？
- en: '**AI is not easy or fast to apply**. The most exciting AI examples come from
    universities or the tech giants. Self-appointed AI experts who promise to revolutionize
    any company with the latest AI in short time are doing **AI misinformation**,
    some just rebranding old tech as AI. Everyone is already using the latest AI through
    Google, Microsoft, Amazon etc. services. But “deep learning” will not soon be
    mastered by the majority of businesses for custom in-house projects. Most have
    insufficient relevant digital data, not enough to train an AI reliably. As a result,
    AI will not kill all jobs, especially because it will require humans to train
    and test each AI.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI 的应用并不容易或快速**。最令人兴奋的 AI 示例来自大学或科技巨头。那些自称 AI 专家并承诺在短时间内用最新 AI 彻底改变任何公司的，实际上是在进行**AI
    误导**，有些只是将旧技术重新包装为 AI。每个人已经通过 Google、Microsoft、Amazon 等服务使用了最新的 AI。但“深度学习”不会很快被大多数企业掌握用于定制内部项目。大多数企业没有足够相关的数字数据来可靠地训练
    AI。因此，AI 不会消灭所有工作，尤其是因为它需要人类来训练和测试每个 AI。'
- en: '**AI now can “see”**, and master vision jobs, for ex. **identify cancer** or
    other diseases from medical images, statistically better than human radiologists,
    ophthalmologists, dermatologists, etc. AI can drive cars, read lips, etc. AI can **paint **in
    any style learned from samples (for ex., Picasso or yours), and apply the style
    to photos. And the inverse: guess a realistic photo from a painting, hallucinating
    the missing details. AIs looking at screenshots of web pages or apps, can write
    code producing similar pages or apps.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI 现在可以“看见”**，并掌握视觉任务，例如**识别癌症**或其他疾病，统计上比人类放射科医生、眼科医生、皮肤科医生等更为准确。AI 可以驾驶汽车、读唇等。AI
    可以**以任何从样本中学习到的风格绘画**（例如，毕加索风格或你自己的风格），并将风格应用到照片中。反过来：从画作中猜测出逼真的照片，想象缺失的细节。AI
    观看网页或应用程序的截图后，可以编写代码生成类似的页面或应用程序。'
- en: '![AI and Deep Learning](../Images/c649b75b63b727a4073ef28d679bb39b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![AI 和深度学习](../Images/c649b75b63b727a4073ef28d679bb39b.png)'
- en: '***Fig. (Style transfer: learn from a photo, apply to another. Credits: Andrej
    Karpathy)***'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '***图（风格迁移：从一张照片中学习，应用到另一张。来源：Andrej Karpathy）***'
- en: '**AI now can “hear”**, not only to understand your voice: it can compose music
    in style of the Beatles or yours, imitate the voice of any person it hears for
    a while, and so on. The average person can’t say what painting or music is composed
    by humans or machines, or what voices are spoken by the human or AI impersonator.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI 现在可以“听”**，不仅仅是理解你的声音：它可以以披头士或你的风格创作音乐，模仿它听到的任何人的声音等等。普通人无法区分哪种绘画或音乐是由人类还是机器创作的，或哪个声音是由人还是
    AI 模仿者发出的。'
- en: AI trained to win at poker games **learned to bluff**, handling missing and
    potentially fake, misleading information. Bots trained to negotiate and find compromises,
    learned to **deceive **too, guessing when you’re not telling them the truth, and
    lying as needed. A Google translate AI trained on Japanese-English and Korean-English
    examples only, translated Korean-Japanese too, a language pair **it was not trained
    on**. It seems it built an intermediate language on its own, representing any
    sentence regardless of language.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 训练以赢得扑克游戏的 AI **学会了虚张声势**，处理丢失和潜在的虚假、误导信息。被训练以进行谈判和寻找妥协的机器人，也学会了**欺骗**，猜测你是否没有告诉它们真相，并在需要时撒谎。一个仅在日英和韩英示例上训练的
    Google 翻译 AI，也翻译了韩日语言对，这是**它没有被训练的**语言对。它似乎建立了一个中间语言，代表任何句子，无论语言如何。
- en: '**Machine learning (ML)**, a subset of AI, make machines **learn** from experience,
    from examples of the real world: the more the data, the more it learns. A machine
    is said to learn from experience with respect to a task, if its performance at
    doing the task improves with experience. Most AIs are still made of fixed rules,
    and do not learn. I will use “ML” to refer “AI that learns from data” from now
    on, to underline the difference.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）**，是 AI 的一个子集，让机器通过经验从真实世界的示例中**学习**：数据越多，学习得越多。如果一个机器在某项任务上的表现随着经验的增加而提高，那么就说它从经验中学习了。大多数
    AI 仍然由固定规则组成，并不学习。我将从现在开始使用“ML”来指代“从数据中学习的 AI”，以突出区别。'
- en: '**Artificial Neural Networks (ANN) **is only one approach to ML, others (not
    ANN) include decision trees, support vector machines, etc. **Deep learning** is
    an ANN with many levels of abstraction. Despite the “deep” hype, many ML methods
    are “shallow”. Winning MLs are often a mix – a **ensemble** of methods, for example
    trees + deep learning + other, independently trained and then combined together.
    Each method might make different errors, so averaging their results can win, at
    times, over single methods.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANN）**只是 ML 的一种方法，其他（非 ANN）包括决策树、支持向量机等。**深度学习**是具有多个抽象层次的 ANN。尽管有“深度”炒作，但许多
    ML 方法仍然是“浅层”的。成功的 ML 通常是多种方法的结合——例如树 + 深度学习 + 其他方法，分别训练后再结合在一起。每种方法可能会犯不同的错误，因此平均它们的结果有时会胜过单一的方法。'
- en: '**The old AI was not learning**. It was rule-based, several “if this then that”
    written by humans: this can be AI since it solves problems, but not ML since it
    does not learn from data. Most of current AI and automation systems still are
    rule-based code. ML is known since the 1960s, but like the human brain, it needs
    billions of computations over lots of data. To train an ML in 1980s PCs it required
    months, and digital data was rare. Handcrafted rule-based code was solving most
    problems fast, so ML was forgotten. But with today’s hardware (NVIDIA GPUs, Google
    TPUs etc.) you can train an ML in minutes, optimal parameters are known, and more
    digital data is available. Then, after 2010 one AI field after another (vision,
    speech, language translation, game playing etc.) it was mastered by MLs, winning
    over rules-based AIs, and often over humans too.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**旧的 AI 不会学习**。它是基于规则的，由几个“如果这样，那么那样”的人类编写的规则组成：这可以是 AI，因为它解决问题，但不是 ML，因为它不从数据中学习。当前的大多数
    AI 和自动化系统仍然是基于规则的代码。ML 从 1960 年代就被认识到，但像人脑一样，它需要对大量数据进行数十亿次计算。在 1980 年代的个人电脑上训练一个
    ML 需要几个月时间，并且数字数据很稀少。手工编写的基于规则的代码快速解决了大多数问题，所以 ML 被遗忘了。但凭借今天的硬件（如 NVIDIA GPUs、Google
    TPUs 等），你可以在几分钟内训练一个 ML，最优参数已经知道，更多的数字数据也可用。因此，自 2010 年以来，一个又一个的 AI 领域（如视觉、语音、语言翻译、游戏等）都被
    ML 掌握，击败了基于规则的 AI，甚至经常超越了人类。'
- en: '**Why AI beat humans in Chess in 1997, but only in 2016 in Go**: for problems
    that can be mastered by humans as a limited, well defined rule-set, for ex. beat
    Kasparov (then world champion) at chess, it’s enough (and best) to write a rule-based
    code the old way. The possible next dozen moves in Chess (8 x 8 grid with limits)
    are just billions: in 1997, computers simply became fast enough to try all the
    moves. But in Go (19 x 19 grid, free) there are more moves than atoms in the universe:
    no machine can try them all in billion years. It’s like trying all random letter
    combinations to get this article as result, or trying random paint strokes until
    getting a Picasso: it will never happen. The only known hope is to train an ML
    on the task. But ML is approximate, not exact, to be used only for intuitive tasks
    you can’t reduce to “if this then that” deterministic logic in reasonably few
    loops. ML is “stochastic”: for patterns you can analyse statistically, but you
    can’t predict precisely.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么 AI 在 1997 年击败人类国际象棋选手，而在 2016 年才在围棋中获胜**：对于可以由人类掌握的有限且明确定义的规则集的问题，例如在国际象棋中击败当时的世界冠军卡斯帕罗夫，编写基于规则的旧式代码就足够了（也是最好的方法）。国际象棋中可能的下一个十几步（8
    x 8 的格子限制）只是数十亿步：到 1997 年，计算机速度足够快，可以尝试所有的走法。但在围棋中（19 x 19 的格子，自由）存在的走法比宇宙中的原子还要多：没有机器可以在十亿年内尝试所有走法。这就像尝试所有随机字母组合来生成这篇文章，或是随机涂抹直到得到毕加索作品：这种事情永远不会发生。唯一已知的希望是对任务进行机器学习（ML）训练。但
    ML 是近似的，而非精确的，只能用于无法归结为“如果这样，那么那样”的确定性逻辑的直观任务。ML 是“随机的”：对于可以统计分析的模式，但无法精确预测。'
- en: '**ML automates automation**, as long as you prepared correctly the data to
    train from. That’s unlike manual automation where humans come up with rules to
    automate a task, a lot of “if this then that” describing for ex. what e-mail is
    likely to be spam or not, or if a medical photo represents a cancer or not. In
    ML instead we only feed data samples of the problem to solve: lots (thousands
    or more) of spam and no spam emails, cancer and no cancer photos etc., all first
    sorted, polished, and labeled by humans. The ML then figures out (learns) the
    rules by itself, magically, but it does not explains these rules. You show a photo
    of a cat, the ML says this is a cat, but no indication why.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**ML 自动化自动化**，只要你正确准备了训练数据。这不同于人工自动化，人类制定规则来自动化任务，比如描述哪些电子邮件可能是垃圾邮件，或一张医学照片是否显示癌症。相反，在
    ML 中，我们只需提供待解决问题的数据样本：大量（数千或更多）垃圾邮件和非垃圾邮件，癌症和非癌症的照片等，所有这些首先由人类进行排序、润色和标记。ML 然后神奇地自行找出（学习）规则，但它不会解释这些规则。你展示一张猫的照片，ML
    说这是猫，但没有说明理由。'
- en: '![Bi-Directional Image Transformations with Deep Learning](../Images/c5f267a4fa4de9aff08af53db2b1e49c.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![双向图像转换与深度学习](../Images/c5f267a4fa4de9aff08af53db2b1e49c.png)'
- en: '*(bidirectional AI transforms: Horse to Zebra, Zebra to Horse, Summer from/to
    Winter, Photo from/to Monet etc. credits: Jun-Yan Zhu, Taesung Park et all.)*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*(双向 AI 转换：马到斑马，斑马到马，夏季到冬季，照片到莫奈等，致谢：Jun-Yan Zhu、Taesung Park 等人)*'
- en: Most ML is **Supervised Learning**, where the examples for training are given
    to ML along with labels, a description or transcription of each example. You first
    need a human to divide the photos of cats from those of dogs, or spam from legitimate
    emails, etc. If you label the data incorrectly, the ML results will be incorrect,
    this is very important as will be discussed later. Throwing unlabeled data to
    ML it’s **Unsupervised Learning**, where the ML discovers patterns and clusters
    on data, useful for exploration, but unlikely enough alone to solve your problems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 ML 是 **监督学习**，其中训练的示例与标签一同提供给 ML，即每个示例的描述或转录。你首先需要一个人来将猫的照片与狗的照片、垃圾邮件与合法邮件等区分开来。如果你标记数据不准确，ML
    的结果也会不准确，这一点非常重要，如后文所述。将未标记的数据丢给 ML 就是 **无监督学习**，ML 会在数据上发现模式和簇，这对于探索很有用，但单独使用不太可能解决你的问题。
- en: In **Anomaly Detection** you identify unusual things that differ from the norm,
    for ex. frauds or cyber intrusions. An ML trained only on old frauds it would
    miss the always new fraud ideas. Then, you can teach the normal activity, asking
    the ML to warn on any suspicious difference. Governments already rely on ML to
    detect tax evasion.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **异常检测** 中，你识别出与常规不同的异常情况，例如欺诈或网络入侵。一个只在旧的欺诈案例上训练的 ML 会错过不断出现的新型欺诈想法。然后，你可以教会
    ML 正常活动，要求其对任何可疑差异发出警报。政府已经依赖 ML 来检测税收逃漏。
- en: '**Reinforcement Learning** is shown in the 1983 movie War Games, where a computer
    decides not to start World War III by playing out every scenario at light speed,
    finding out that all would cause world destruction. The AI discovers through millions
    of trial and error, within rules of a game or an environment, which actions yield
    the greatest rewards. AlphaGo was trained this way: it played against itself millions
    of times, reaching super-human skills. It made surprising moves, never seen before,
    that humans would consider as mistakes. But later, these was proven as brilliantly
    innovative tactics. The ML became more **creative** than humans at the Go game.
    At Poker or other games with hidden cards, the MLs learns to bluff and deceive
    too: it does what’s best to win.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**在1983年的电影《战争游戏》中有所展示，电脑通过以光速模拟每种可能的情境来决定不启动第三次世界大战，发现所有情境都会导致世界毁灭。人工智能通过数百万次的试错，在游戏或环境的规则下，发现哪些动作能够获得最大的奖励。AlphaGo就是这样训练的：它与自己对弈了数百万次，达到了超人的技能。它做出了令人惊讶的举动，人类认为这些举动是错误的。但后来，这些被证明是极具创新性的战术。机器学习在围棋游戏中变得比人类更**有创造力**。在扑克或其他有隐藏牌的游戏中，机器学习也学会了虚张声势和欺骗：它会做出最有利于获胜的行为。'
- en: '**The “AI effect” is when people argue that an AI it is not real intelligence**.
    Humans subconsciously need to believe to have a magical spirit and unique role
    in the universe. Every time a machine outperforms humans on a new piece of intelligence,
    such as play chess, recognize images, translate etc., always people say: “That’s
    just brute force computation, not intelligence”. Lots of AI is included in many
    apps, but once widely used, it’s not labeled “intelligence” anymore. If “intelligence”
    it is only what’s not done yet by AI (what’s still unique to the brain), then
    dictionaries should be updated every year, like: “math it was considered intelligence
    until 1950s, but now no more, since computers can do it”, it’s quite strange.
    About “brute force”, a human brain got 100 trillion of neuronal connections, lots
    more than any computer on earth. ML can’t do “brute force”: trying all the combinations
    it would take billion years. ML do “educated guesses” using less computations
    than a brain. So it should be the “smaller” AI to claim that the human brain as
    not real intelligence, but only brute force computation.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**“人工智能效应”指的是人们争论人工智能是否真正具备智慧**。人类下意识地需要相信自己在宇宙中拥有神奇的精神和独特的角色。每当机器在新的智能任务上超越人类，比如下棋、识别图像、翻译等，人们总是会说：“这只是蛮力计算，不是智慧”。许多人工智能被包含在各种应用中，但一旦广泛使用，就不再被标记为“智慧”了。如果“智慧”仅仅是指人工智能尚未做到的（大脑独有的部分），那么词典应该每年更新，比如：“数学曾被认为是智慧，直到1950年代，但现在不再是，因为计算机可以做它”，这实在有些奇怪。关于“蛮力计算”，人脑有100万亿个神经连接，比地球上任何计算机都多。机器学习无法进行“蛮力计算”：尝试所有组合需要亿万年。机器学习使用比大脑更少的计算来进行“有根据的猜测”。因此，应该是“较小的”人工智能来声称人脑不是智慧，只是蛮力计算。'
- en: '**ML is not a human brain simulator**: real neurons are very different. ML
    it’s an alternative way to reach brain-like results, similar to a brain like a
    horse is similar to a car. It matters that both car and horse can transport you
    from point A to point B: the car do it faster, consuming more energy and lacking
    most horse features. Both the brain and ML run statistics (probability) to approximate
    complex functions: they give result only a bit wrong, but usable. MLs and brains
    give different results on same task, as they approximate in different way. Everyone
    knows that while the brain forgets things and is limited in doing explicit math,
    the machines are perfect for memory and math. But the old idea that machines either
    give exact results or are broken is wrong, outdated. Humans do many mistakes,
    but instead of: “this brain is broken!”, you hear: “study more!”. MLs doing mistakes
    are not “broken” either, they must study more data, or different data. MLs trained
    with biased (human generated) data will end up racist, sexist, unfair: human in
    the worst way. AI should not be compared only with our brain, AI it is different,
    and that’s an opportunity. We train MLs with our data, to imitate the human jobs,
    activity and brain only. But the same MLs, if trained in other galaxies, could
    imitate different (perhaps better) alien brains. Let’s try to think in alien ways
    too.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习不是人脑的模拟器**：真实的神经元非常不同。机器学习是一种达到类脑结果的替代方法，类似于大脑就像马类似于汽车。重要的是汽车和马都能将你从A点运输到B点：汽车做得更快，消耗更多的能量，并且缺乏大多数马的特性。大脑和机器学习都运行统计（概率）来近似复杂函数：它们的结果有一点点错误，但可以使用。机器学习和大脑在同一任务上的结果不同，因为它们的近似方式不同。每个人都知道，虽然大脑会忘记事物且在做显式数学方面有限，但机器在记忆和数学方面表现得很完美。但旧有的观点认为机器要么提供精确结果，要么就是坏掉了，这是错误的、过时的。人类会犯许多错误，但不是：“这个大脑坏掉了！”，而是：“多学习一点！”机器学习犯错误也不是“坏掉了”，它们需要更多的数据，或者不同的数据。用有偏见（人类生成的）数据训练的机器学习将变得种族歧视、性别歧视、不公平：在最糟糕的情况下的人类。人工智能不应仅与我们的大脑进行比较，人工智能是不同的，这正是一个机会。我们用我们的数据训练机器学习，以模仿人类的工作、活动和大脑。但相同的机器学习，如果在其他星系中训练，可能会模仿不同（也许更好）的外星大脑。让我们也试着用外星人的方式思考。'
- en: '**AI is getting as mysterious as humans**. The idea that computers can’t be
    creative, liars, wrong or human-like comes from old rule-based AI, indeed predictable,
    but that seems changed with ML. The arguments to reduce each new capability mastered
    by AI as “not real intelligence” are ending. The real issue left is: general versus
    narrow AI.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能正变得像人类一样神秘**。认为计算机不能具备创造力、撒谎、犯错或像人类一样的想法来自于旧的基于规则的人工智能，这些人工智能确实是可预测的，但这似乎在机器学习中发生了变化。将人工智能掌握的每一种新能力归结为“不是一种真正的智能”的论点正在减少。剩下的真正问题是：通用人工智能与狭义人工智能。'
- en: '![AI in the movies](../Images/09bfcaf72ce6441fb4bf4944111f0099.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![电影中的人工智能](../Images/09bfcaf72ce6441fb4bf4944111f0099.png)'
- en: '*(Please forget the general AI seen in movies. But the “narrow AI” is smart
    too!)*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*(请忽略电影中看到的通用人工智能。但“狭义人工智能”也很聪明！)*'
- en: '**Unlike some other sciences, you can’t verify if an ML is correct using a
    logical theory**. To judge if an ML it is correct or not, you can only test its
    results (errors) on unseen new data. The ML is not a black box: you can see the
    “if this then that” list it produces and runs, but it’s often too big and complex
    for any human to follow. ML it’s a practical science trying to reproduce the real
    world’s chaos and human intuition, without giving a simple or theoretical explanation.
    It gives the too big to understand linear algebra producing the results. It’s
    like when you have an idea which works, but **you can’t explain exactly how you
    came up with the idea**: for the brain that’s called inspiration, intuition, subconscious,
    while in computers it’s called ML. If you could get the complete list of neuron
    signals that caused a decision in a human brain, could you understand why and
    how really the brain took that decision? Maybe, but it’s complex.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**与一些其他科学不同，你不能通过逻辑理论来验证机器学习（ML）的正确性**。要判断一个ML是否正确，你只能在未见过的新数据上测试其结果（错误）。ML
    不是黑箱：你可以看到它生成并运行的“如果这样，那么那样”列表，但它通常太大、太复杂，任何人都难以跟随。ML 是一种实践科学，试图重现现实世界的混乱和人类直觉，而不提供简单或理论性的解释。它产生了无法理解的大规模线性代数结果。这就像你有一个有效的想法，但**你不能确切解释你是如何想到这个想法的**：对大脑来说，这被称为灵感、直觉或潜意识，而在计算机中则称为ML。如果你能获得一份完整的神经信号列表，说明人脑是如何做出某个决定的，你能理解大脑为什么以及如何做出这个决定吗？也许能，但这很复杂。'
- en: '**Everyone can intuitively imagine** (some even draw) the face of a person,
    in original and in Picasso style. Or imagine (some even play) sounds or music
    styles. But no one can describe, with a complete and working formula, the face,
    sound or style change. **Humans can visualize only up to 3 dimensions**: even
    Einstein it could not conceive, consciously, ML-like math with let’s say 500 dimensions.
    Such 500D math is solved by our brains all the time, intuitively, like magic.
    Why it is not solved consciously? Imagine if for each idea, the brain also gave
    us the formulas used, with thousands of variables. That extra info would confuse
    and slow us down a lot, and for what? No human could use pages-long math, we’re
    not evolved with an USB cable on the head.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**每个人都可以直观地想象**（有些人甚至可以绘画）一个人的面孔，无论是原始的还是毕加索风格的。或者想象（有些人甚至可以演奏）声音或音乐风格。但没有人能够用完整而有效的公式描述面孔、声音或风格的变化。**人类只能可视化最多3个维度**：即使是爱因斯坦也无法有意识地理解例如500维的机器学习数学。这种500维的数学一直在我们的大脑中以直观的方式解决，就像魔法一样。为什么它无法有意识地解决呢？试想一下，如果每一个想法，大脑也同时给我们所用的公式，包含成千上万的变量。那额外的信息会极大地混淆和拖慢我们的速度，且为了什么？没有人能够使用几页长的数学公式，我们也没有在头上进化出一个USB接口。'
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加入网络安全职业的快速通道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT需求'
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并寻找目的来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学统计学习的顶尖资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析一个90亿美元的人工智能失败](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
