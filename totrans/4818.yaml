- en: Text Classification & Embeddings Visualization Using LSTMs, CNNs, and Pre-trained
    Word Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/07/text-classification-lstm-cnn-pre-trained-word-vectors.html](https://www.kdnuggets.com/2018/07/text-classification-lstm-cnn-pre-trained-word-vectors.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/), Computational
    Geophysicist and Machine Learning Enthusiast**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Editor''s note:** This post summarizes the 3 currently-published posts in
    this series, while a fourth and final installment is soon on the way.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In this tutorial, I classify [Yelp round-10 review datasets](https://www.yelp.com/dataset/).
    The reviews contain a lot of metadata that can be mined and used to infer meaning,
    business attributes, and sentiment. For simplicity, I classify the review comments
    into two class: either as positive or negative. Reviews that have star higher
    than three are regarded as positive while the reviews with star less than or equal
    to 3 are negative. Therefore, the problem is a supervised learning. To build and
    train the model, I first clean the text and convert them to sequences. Each review
    comment is limited to 50 words. As a result, short texts less than 50 words are
    padded with zeros, and long ones are truncated. After processing the review comments,
    I trained three model in three different ways and obtained three word embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/3e8934012ca13e02934441669b872907.png)'
  prefs: []
  type: TYPE_IMG
- en: '[**Part 1: Text Classification Using LSTM and visualize Word Embeddings**](https://medium.com/@sabber/classifying-yelp-review-comments-using-lstm-and-word-embeddings-part-1-eb2275e4066b)'
  prefs: []
  type: TYPE_NORMAL
- en: In this part, I build a neural network with LSTM and word embeddings were leaned
    while fitting the neural network on the classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: The network starts with an embedding layer. The layer lets the system expand
    each token to a more massive vector, allowing the network to represent a word
    in a meaningful way. The layer takes 20000 as the first argument, which is the
    size of our vocabulary, and 100 as the second input parameter, which is the dimension
    of the embeddings. The third parameter is the input_length of 50, which is the
    length of each comment sequence.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2: Text Classification Using CNN, LSTM and visualize Word Embeddings](https://medium.com/@sabber/classifying-yelp-review-comments-using-cnn-lstm-and-visualize-word-embeddings-part-2-ca137a42a97d)**'
  prefs: []
  type: TYPE_NORMAL
- en: In in this part, I add an extra 1D convolutional layer on top of LSTM layer
    to reduce the training time.
  prefs: []
  type: TYPE_NORMAL
- en: The LSTM model worked well. However, it takes forever to train three epochs.
    One way to speed up the training time is to improve the network adding “Convolutional”
    layer. Convolutional Neural Networks (CNN) come from image processing. They pass
    a “filter” over the data and calculate a higher-level representation. They have
    been shown to work surprisingly well for text, even though they have none of the
    sequence processing ability of LSTMs.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 3: Text Classification Using CNN, LSTM and Pre-trained Glove Word Embeddings](https://medium.com/@sabber/classifying-yelp-review-comments-using-cnn-lstm-and-pre-trained-glove-word-embeddings-part-3-53fcea9a17fa)**'
  prefs: []
  type: TYPE_NORMAL
- en: In this part-3, I use the same network architecture as part-2, but use the pre-trained
    glove 100 dimension word embeddings as initial input.
  prefs: []
  type: TYPE_NORMAL
- en: In this subsection, I want to use word embeddings from pre-trained Glove. It
    was trained on a dataset of one billion tokens (words) with a vocabulary of 400
    thousand words. The glove has embedding vector sizes, including 50, 100, 200 and
    300 dimensions. I chose the 100-dimensional version. I also want to see the model
    behavior in case the learned word weights do not get updated. I, therefore, set
    the trainable attribute for the model to be False.
  prefs: []
  type: TYPE_NORMAL
- en: '**Part 4: (Not yet published)**'
  prefs: []
  type: TYPE_NORMAL
- en: In part-4, I use word2vec to learn word embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)** is the
    Founder of [xoolooloo.com](https://www.xoolooloo.com/). Computational Geophysicist
    and Machine Learning Enthusiast.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Natural Language Processing Nuggets: Getting Started with NLP](/2018/06/getting-started-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[On the contribution of neural networks and word embeddings in Natural Language
    Processing](/2018/05/contribution-neural-networks-word-embeddings-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Detecting Sarcasm with Deep Convolutional Neural Networks](/2018/06/detecting-sarcasm-deep-convolutional-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LSTMs Rise Again: Extended-LSTM Models Challenge the Transformer…](https://www.kdnuggets.com/lstms-rise-again-extended-lstm-models-challenge-the-transformer-superiority)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automate Microsoft Excel and Word Using Python](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is Text Classification?](https://www.kdnuggets.com/2022/07/text-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Architecture for Your Text Classification Task: Benchmarking…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
