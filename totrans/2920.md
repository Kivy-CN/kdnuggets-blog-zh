# 使用K最近邻算法对心脏病进行分类

> 原文：[https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html](https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html?page=2#comments)

对象分类是各种领域研究和应用的重要领域。在完全了解潜在概率的情况下，贝叶斯决策理论提供了最佳的错误率。在没有这些信息的情况下，许多算法利用样本之间的距离或相似性作为分类的方法。

这篇文章分为两部分。第一部分，我们将讨论K-NN机器学习算法，第二部分，我们将实现K-NN并对心脏病患者进行分类。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您组织的IT工作

* * *

**目录**

1.  什么是K-NN算法？

1.  K-NN算法是如何工作的？

1.  什么时候选择K-NN？

1.  如何选择K的最佳值？

1.  什么是维度诅咒？

1.  使用Python的scikit-learn构建K-NN分类器。

1.  如何提高分类器的性能？

### 什么是K-NN算法？

![](../Images/fe225aa90f1f3ec39506d32db01afc17.png)

[K-NN算法表示](https://acadgild.com/blog/k-nearest-neighbor-algorithm)

K-NN或K-最近邻算法是目前行业中最著名的分类算法之一，主要因为它的简单性和准确性。

K-NN是一种简单的算法，它存储所有可用的案例，并基于相似性度量（例如，距离函数）对新案例进行分类。KNN自1970年代初期以来作为一种非参数技术已经用于统计估计和模式识别。

该算法假设相似的事物存在于彼此接近的地方。换句话说，相似的实体是聚集在一起的。

### K-NN算法是如何工作的？

在K-NN中，K是最近邻的数量。邻居的数量是核心决定因素。**当类别数为2时，K通常是一个奇数**。当K=1时，算法被称为最近邻算法。这是最简单的情况。

在下图中，假设黄色的“**?**”点为P，这是需要预测标签的点。首先，找到离P最近的点，然后将最近点的标签分配给P。

![](../Images/861a2f7b786e09051bbd0d37b8db1857.png)

其次，找到离P最近的k个点，然后通过这K个邻居的多数投票对点进行分类。每个对象为其类别投票，票数最多的类别作为预测结果。为了找到最相似的点，我们使用距离度量如欧几里得距离、汉明距离、曼哈顿距离和闵可夫斯基距离来计算点之间的距离。算法的基本步骤如下：

1.  计算距离

1.  查找最近邻居

1.  投票标签

![](../Images/be2fc1f9343745ff2ec1e5a9747b2f7a.png)

三种最常用的距离度量用于计算点P与其最近邻居之间的距离：

![](../Images/82d48a4486aae9019ed734c5115b1878.png)

在本文中，我们将采用欧几里得距离，因此首先了解它。

**欧几里得距离：** 它是最常用的距离度量，也简称为距离。当数据是密集或连续时，强烈建议使用欧几里得距离度量。欧几里得距离是最佳的接近度量。两点之间的欧几里得距离是连接它们的路径长度。毕达哥拉斯定理给出了两点之间的距离。

下图展示了如何计算二维平面上两点之间的欧几里得距离。

![图](../Images/181a263e28b55514150e7ae38d495336.png)

[二维平面上两点之间的欧几里得距离](https://mccormickml.com/2013/08/15/the-gaussian-kernel/)

### 何时使用K-NN算法？

KNN可用于分类和回归预测问题。然而，在行业中，它在分类问题中使用更广泛。评估任何技术时，我们通常考虑3个重要方面：

1.  易于解释输出

1.  算法的计算时间

1.  预测能力

让我们将KNN与不同模型进行比较：

![图](../Images/d52f21040e5ef16e8e24e34609aa2528.png)

来源：Analytics Vidhya

如你所见，K-NN在我们考虑的各个方面超越了逻辑回归、CART和随机森林。

### 如何选择最优的K值？

K-NN中的邻居数量（K）是一个超参数，你需要在构建模型时选择。你可以将K视为预测模型的控制变量。

现在，选择K的最优值最好先检查数据。通常，大K值更精确，因为它减少了整体噪声，但没有保证。交叉验证是通过使用独立数据集来验证K值， retrospectively 确定一个好的K值的另一种方法。历史上，大多数数据集的最优K值在3到10之间。与1NN（K=1）相比，结果要好得多。

通常，如果类别数量为偶数，则选择一个奇数。你还可以通过生成不同K值的模型并检查它们的性能来进行验证。

### 维度诅咒

K-NN在特征较少时表现更好，而不是特征较多。可以说，当特征数量增加时，需要更多的数据。维度的增加也会导致过拟合问题。为了避免过拟合，随着维度数量的增加，所需的数据将需要呈指数增长。这种高维问题被称为维度诅咒。

![](../Images/40e1bba71a6b963a2370165dc5a23d79.png)

从上述图形表示中，可以清楚地看出，随着特征（维度）数量的增加，模型的性能会下降。

为了应对维度诅咒的问题，你需要在应用任何机器学习算法之前执行主成分分析（PCA），或者你也可以使用特征选择方法。研究表明，在大维度下，欧几里得距离不再有用。因此，你可以选择其他度量方法，如余弦相似度，它对高维度的影响较小。

> **KNN算法能够与最准确的模型竞争，因为它能够做出非常准确的预测。因此，你可以在需要高准确率但不需要人类可读模型的应用中使用KNN算法。 — **来源：[IBM](https://www.ibm.com/support/knowledgecenter/en/SS6NHC/com.ibm.swg.im.dashdb.analytics.doc/doc/r_knn_usage.html)

计算K-NN算法的步骤：

1.  确定参数K = 最近邻居的数量。

1.  计算查询实例与所有训练样本之间的距离。

1.  排序距离，并根据第K小的距离确定最近邻居。

1.  收集最近邻居的类别

1.  使用最近邻居的类别的简单多数作为查询的预测值。

在下一部分，我们将使用K-NN算法解决一个实际场景。

### 更多相关内容

+   [从理论到实践：构建k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [用于分类的最近邻居](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn中的K-最近邻](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [使用BERT对长文本进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)

+   [使用Python自动化Microsoft Excel和Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)

+   [使用Python确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)
