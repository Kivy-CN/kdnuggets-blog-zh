- en: Frameworks for Approaching the Machine Learning Process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is it worth comparing approaches to the machine learning process? Are there
    any fundamental differences between such frameworks?
  prefs: []
  type: TYPE_NORMAL
- en: 'Though [classical approaches](/2016/03/data-science-process-rediscovered.html)
    to such tasks exist, and have existed for some time, it is worth taking consult
    from new and different perspectives for a variety of reasons: Have I missed something?
    Are there new approaches which had not previously been considered? Should I change
    my perspective on how I approach machine learning?'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The 2 most recent resources I've come across outlining frameworks for approaching
    the process of machine learning are Yufeng Guo's [The 7 Steps of Machine Learning](https://towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e)
    and section 4.5 of Francois Chollet's [Deep Learning with Python](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438).
    Are either of these anything different than how you already process just such
    a task?
  prefs: []
  type: TYPE_NORMAL
- en: What follows are outlines of these 2 supervised machine learning approaches,
    a brief comparison, and an attempt to reconcile the two into a third framework
    highlighting the most important areas of the (supervised) machine learning process.
  prefs: []
  type: TYPE_NORMAL
- en: The 7 Steps of Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I actually came across Guo's article by way of first watching [a video of his](https://youtu.be/nKW8Ndu7Mjw?list=PLIivdWyY5sqJxnwJhe3etaK7utrBiPBQ2)
    on YouTube. The post is the same content as the video, and so if interested one
    of the two resources will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/bb2013560dcb54a0a997f3e3533b3671.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Image source](https://towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Guo laid out the steps as follows (with a little ad-libbing on my part):'
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → The quantity & quality of your data dictate how accurate our model is
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → The outcome of this step is generally a representation of data (Guo simplifies
    to specifying a table) which we will use for training
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Using pre-collected data, by way of datasets from Kaggle, UCI, etc., still
    fits into this step
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Data Preparation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Wrangle data and prepare it for training
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Clean that which may require it (remove duplicates, correct errors, deal with
    missing values, normalization, data type conversions, etc.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Randomize data, which erases the effects of the particular order in which
    we collected and/or otherwise prepared our data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Visualize data to help detect relevant relationships between variables or
    class imbalances (bias alert!), or perform other exploratory analysis
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Split into training and evaluation sets
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Choose a Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Different algorithms are for different tasks; choose the right one
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Train the Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → The goal of training is to answer a question or make a prediction correctly
    as often as possible
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '→ Linear regression example: algorithm would need to learn values for *m* (or
    *W*) and *b* (*x* is input, *y* is output)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Each iteration of process is a training step
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Evaluate the Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Uses some metric or combination of metrics to "measure" objective performance
    of model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Test the model against previously unseen data
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → This unseen data is meant to be somewhat representative of model performance
    in the real world, but still helps tune the model (as opposed to test data, which
    does not)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Good train/eval split? 80/20, 70/30, or similar, depending on domain, data
    availability, dataset particulars, etc.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Parameter Tuning
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → This step refers to *hyperparameter* tuning, which is an "artform" as opposed
    to a science
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Tune model parameters for improved performance
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '→ Simple model hyperparameters may include: number of training steps, learning
    rate, initialization values and distribution, etc.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make Predictions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Using further (test set) data which have, until this point, been withheld
    from the model (and for which class labels are known), are used to test the model;
    a better approximation of how the model will perform in the real world
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Universal Workflow of Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In section 4.5 of [his book](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438),
    Chollet outlines a universal workflow of machine learning, which he describes
    as a blueprint for solving machine learning problems:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The blueprint ties together the concepts we''ve learned about in this chapter:
    problem definition, evaluation, feature engineering, and fighting overfitting.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'How does this compare with Guo''s above framework? Let''s have a look at the
    7 steps of Chollet''s treatment (keeping in mind that, while not explicitly stated
    as being specifically tailored for them, his blueprint is written for a book on
    *neural networks*):'
  prefs: []
  type: TYPE_NORMAL
- en: Defining the problem and assembling a dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choosing a measure of success
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deciding on an evaluation protocol
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preparing your data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Developing a model that does better than a baseline
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scaling up: developing a model that overfits'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Regularizing your model and tuning your parameters
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Machine learning](../Images/628c051fa81b348e055c44294678c8d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: Andrew Ng''s Machine Learning class at Stanford'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chollet''s workflow is higher level, and focuses more on getting your model
    from good to great, as opposed to Guo''s, which seems more concerned with going
    from zero to good. While it does not necessarily jettison any other important
    steps in order to do so, the blueprint places more emphasis on hyperparameter
    tuning and [regularization](http://neuralnetworksanddeeplearning.com/chap3.html#overfitting_and_regularization)
    in its pursuit of greatness. A simplification here seems to be:'
  prefs: []
  type: TYPE_NORMAL
- en: good model → "too good" model → scaled back, "generalizable" model
  prefs: []
  type: TYPE_NORMAL
- en: Drafting A Simplified Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can reasonably conclude that Guo's framework outlines a "beginner" approach
    to the machine learning process, more explicitly defining early steps, while Chollet's
    is a more advanced approach, emphasizing both the explicit decisions regarding
    model evaluation and the tweaking of machine learning models. Both approaches
    are equally valid, and do not prescribe anything fundamentally different from
    one another; you could superimpose Chollet's on top of Guo's and find that, while
    the 7 steps of the 2 models would not line up, they would end up covering the
    same tasks in sum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mapping Chollet''s to Guo''s, here is where I see the steps lining up (Guo''s
    are numbered, while Chollet''s are listed underneath the corresponding Guo step
    with their Chollet workflow step number in parenthesis):'
  prefs: []
  type: TYPE_NORMAL
- en: Data collection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Defining the problem and assembling a dataset (1)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Preparing your data (4)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Choose model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Developing a model that does better than a baseline (5)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Evaluate model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → Choosing a measure of success (2)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Deciding on an evaluation protocol (3)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Parameter tuning
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '→ Scaling up: developing a model that overfits (6)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: → Regularizing your model and tuning your parameters (7)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Predict
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It's not perfect, but I stand by it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In my view, this presents something important: both frameworks agree, and together
    place emphasis, on particular points of the framework. It should be clear that
    model evaluation and parameter tuning are important aspects of machine learning.
    Addition agreed-upon areas of importance are the assembly/preparation of data
    and original model selection/training.'
  prefs: []
  type: TYPE_NORMAL
- en: A Simplified Machine Learning Process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use the above to put together a simplified framework to machine learning,
    the **5 main areas of the machine learning process**:'
  prefs: []
  type: TYPE_NORMAL
- en: Data collection and preparation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → everything from choosing where to get the data, up to the point it is clean
    and ready for feature selection/engineering
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Feature selection and feature engineering
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → this includes all changes to the data from once it has been cleaned up to
    when it is ingested into the machine learning model
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Choosing the machine learning algorithm and training our first model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → getting a "better than baseline" result upon which we can (hopefully) improve
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Evaluating our model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → this includes the selection of the measure as well as the actual evaluation;
    seemingly a smaller step than others, but important to our end result
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Model tweaking, regularization, and hyperparameter tuning
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: → this is where we iteratively go from a "good enough" model to our best effort
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So, which framework should you use? Are there really any important differences?
    Do those presented by Guo and Chollet offer anything that was previously lacking?
    Does this simplified framework provide any real benefit? As long as the bases
    are covered, and the tasks which explicitly exist in the overlap of the frameworks
    are tended to, the outcome of following either of the two models would equal that
    of the other. Your vantage point or level of experience may exhibit a preference
    for one.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have guessed, this has really been less about deciding on or contrasting
    specific frameworks than it has been an investigation of what a reasonable machine
    learning process **should** look like.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Matthew Mayo](https://www.linkedin.com/in/mattmayo13/)** ([**@mattmayo13**](https://twitter.com/mattmayo13))
    is a Data Scientist and the Editor-in-Chief of KDnuggets, the seminal online Data
    Science and Machine Learning resource. His interests lie in natural language processing,
    algorithm design and optimization, unsupervised learning, neural networks, and
    automated approaches to machine learning. Matthew holds a Master''s degree in
    computer science and a graduate diploma in data mining. He can be reached at editor1
    at kdnuggets[dot]com.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Expert Insights on Developing Safe, Secure, and Trustworthy AI Frameworks](https://www.kdnuggets.com/expert-insights-on-developing-safe-secure-and-trustworthy-ai-frameworks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Types of Visualization Frameworks](https://www.kdnuggets.com/types-of-visualization-frameworks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chip Huyen shares frameworks and case studies for implementing ML systems](https://www.kdnuggets.com/2023/02/sphere-chip-huyen-shares-frameworks-case-studies-implementing-ml-systems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Top AutoML Frameworks You Should Consider in 2023](https://www.kdnuggets.com/2023/05/best-automl-frameworks-2023.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Process a DataFrame with Millions of Rows in Seconds](https://www.kdnuggets.com/2022/01/process-dataframe-millions-rows-seconds.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
