- en: Python for data analysis… is it really that simple?!?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析的 Python……真的那么简单吗？！？！
- en: 原文：[https://www.kdnuggets.com/2020/04/python-data-analysis-really-that-simple.html](https://www.kdnuggets.com/2020/04/python-data-analysis-really-that-simple.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/04/python-data-analysis-really-that-simple.html](https://www.kdnuggets.com/2020/04/python-data-analysis-really-that-simple.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Ferenc Bodon Ph.D.](https://www.linkedin.com/in/ferencbodon/), Data Engineer,
    Cloud Solutions Architect at Kx**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Ferenc Bodon 博士](https://www.linkedin.com/in/ferencbodon/)，Kx 的数据工程师和云解决方案架构师**'
- en: '![Figure](../Images/b8a0052d9e1d377c6bae71923bcd8ad5.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/b8a0052d9e1d377c6bae71923bcd8ad5.png)'
- en: Graphic designed and made by CineArt
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由 CineArt 设计并制作
- en: '[Python](https://www.python.org/) is a popular programming language that is
    easy to learn, efficient and enjoys the support of a large and active community.
    It is a general-purpose language with libraries specialized for various areas,
    including web development, scripting, data science, and DevOps.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[Python](https://www.python.org/) 是一种易于学习、高效且拥有大量活跃社区支持的流行编程语言。它是一种通用语言，拥有针对各种领域的专用库，包括
    Web 开发、脚本编写、数据科学和 DevOps。'
- en: Its primary data analysis library, [Pandas](https://pandas.pydata.org/), gained
    popularity among data scientists and data engineers. It follows Python’s principles,
    so it seems to be easy to learn, read and allows rapid development… at least based
    on the textbook examples. But, what happens if we leave the safe and convenient
    world of the textbook examples? Is Pandas still an easy-to-use data analysis tool
    to query **tabular data**? How does it perform compared to other professional
    tools like [R](https://www.r-project.org/) and [kdb+](https://code.kx.com/q/learn/)?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 其主要的数据分析库 [Pandas](https://pandas.pydata.org/) 在数据科学家和数据工程师中获得了广泛的欢迎。它遵循 Python
    的原则，因此似乎容易学习、阅读，并允许快速开发……至少基于教科书的例子。但如果我们离开教科书例子的安全和方便的世界，会发生什么？Pandas 仍然是一个易于使用的工具来查询
    **表格数据** 吗？与其他专业工具如 [R](https://www.r-project.org/) 和 [kdb+](https://code.kx.com/q/learn/)
    相比，它的表现如何？
- en: In this article, I will take an example that goes just one step beyond the simplest
    use cases by performing some **aggregation based on multiple columns**. The complexity
    of my use case is around level 2 out of 5 levels. Anybody who analyzes data tables
    will bump into the problem, probably in the second week. For comparison, I will
    also cover other popular tools that aim for data analysis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将以一个超越最简单用例的例子为例，通过对 **多个列的聚合** 来演示。我的用例复杂性大约是 5 级中的第 2 级。任何分析数据表的人都会遇到这个问题，可能在第二周就会遇到。为了对比，我还将涵盖其他旨在进行数据分析的流行工具。
- en: First of all, the problem can be solved by [ANSI SQL](https://en.wikipedia.org/wiki/SQL) so
    all traditional RDBM systems like [PostegreSQL](https://www.postgresql.org/), [MySQL](https://www.linkedin.com/redir/general-malware-page?url=https%3A%2F%2Fwww%2emysql%2ecom%2F),
    etc can enter the game. In the experiments, I will use [BigQuery](https://cloud.google.com/bigquery/),
    a serverless, highly-scalable data warehouse solution by Google.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，问题可以通过 [ANSI SQL](https://en.wikipedia.org/wiki/SQL) 解决，因此所有传统的 RDBM 系统如
    [PostgreSQL](https://www.postgresql.org/)、[MySQL](https://www.linkedin.com/redir/general-malware-page?url=https%3A%2F%2Fwww%2emysql%2ecom%2F)
    等都可以参与游戏。在实验中，我将使用 [BigQuery](https://cloud.google.com/bigquery/)，这是 Google 提供的无服务器、高度可扩展的数据仓库解决方案。
- en: The [R](https://www.r-project.org/) programming language is designed for statistical
    analysis. It natively supports tables via its class [data.frame](https://www.google.com/search?q=r+data.frame&oq=r+data.fr&aqs=chrome.0.0j69i57j0l4j69i60j69i61.6225j1j7&sourceid=chrome&ie=UTF-8).
    Using multiple aggregations is quite inconvenient due to the limitation of the
    core function [aggregate](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aggregate).
    The R community developed the library [plyr](https://cran.r-project.org/web/packages/plyr/index.html) to
    simplify the usage of data.frame. Package [plyr](https://cran.r-project.org/web/packages/plyr/index.html) was
    retired and package [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) was
    introduced with the promise of improved API and faster execution. Package [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) is
    part of the [tidyverse](https://www.tidyverse.org/) collection that is designed
    for professional data science work. It provides an abstract query layer and decouples
    the query from the data storage let it be data.frame or in an external database
    that supports ANSI SQL. Package [data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) is
    an alternative of [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) and
    it is famous for its speed and concise syntax. A data.table can also be queried
    by the dplyr syntax.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R](https://www.r-project.org/)编程语言是为统计分析设计的。它通过其类[data.frame](https://www.google.com/search?q=r+data.frame&oq=r+data.fr&aqs=chrome.0.0j69i57j0l4j69i60j69i61.6225j1j7&sourceid=chrome&ie=UTF-8)本地支持表格。由于核心函数[aggregate](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aggregate)的限制，使用多个聚合功能相当不便。R社区开发了库[plyr](https://cran.r-project.org/web/packages/plyr/index.html)以简化data.frame的使用。包[plyr](https://cran.r-project.org/web/packages/plyr/index.html)已被淘汰，包[dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8)被引入，承诺提供改进的API和更快的执行速度。包[dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8)是[tidyverse](https://www.tidyverse.org/)集合的一部分，专为专业数据科学工作设计。它提供了一个抽象的查询层，并将查询与数据存储解耦，无论是data.frame还是支持ANSI
    SQL的外部数据库。包[data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html)是[dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8)的替代方案，以其速度和简洁的语法而著名。data.table也可以使用dplyr语法进行查询。'
- en: In the [Q/Kdb+](https://code.kx.com/v2/learn/q-for-all/) programming language,
    tables are also first-class citizens and the speed was a primary design concept
    of the language. Kdb+ made use of multicore processors and [employs map-reduce](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1437-map-reduce) from
    its birth in 2004 if data was [partitioned](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#143-partitioned-tables) on
    the disk. From version 4.0 (released in March 2020) most primitives (such as sum,
    avg, dev) use slave threads and are executed in parallel even if the table is
    in memory. Productivity was the other design consideration - any redundant programming
    element that does not contribute to the understanding (even a parenthesis) is
    regarded as visual noise. Kdb+ is a good contender for any data analysis tool.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[Q/Kdb+](https://code.kx.com/v2/learn/q-for-all/)编程语言中，表格也是一等公民，速度是该语言的主要设计理念。Kdb+自2004年诞生以来就利用多核处理器，并[使用Map-Reduce](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1437-map-reduce)处理数据，如果数据在磁盘上是[分区的](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#143-partitioned-tables)。从4.0版本（2020年3月发布）开始，大多数原语（如sum、avg、dev）使用从属线程并行执行，即使表格在内存中。生产力是另一个设计考虑因素——任何不有助于理解的冗余编程元素（甚至一个括号）都被视为视觉噪声。Kdb+是任何数据分析工具的有力竞争者。
- en: I will consider the elegance, simplicity and the speed of the various solutions.
    Also, I investigate how to **tune the performance** and leverage multicore processors
    or cluster of computers by employing **parallel computation**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我将考虑各种解决方案的优雅性、简洁性和速度。同时，我会研究如何**调整性能**以及通过采用**并行计算**来利用多核处理器或计算机集群。
- en: The Problem
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: '![An example input table](../Images/90809ed59bbfbe9914c3071e0b9e2e8d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![示例输入表](../Images/90809ed59bbfbe9914c3071e0b9e2e8d.png)'
- en: We are given a simple table with four columns, one nominal, called **bucket **and
    three numerical, **qty**, **risk**, and **weight**. For simplicity let us assume
    that the numerical columns contain integers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到一个简单的表格，包含四列，一列名为**bucket**，另外三列为**qty**、**risk**和**weight**。为简便起见，假设数值列包含整数。
- en: We would like to see for each **bucket**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望查看每个**bucket**的情况。
- en: the number of elements, as column NR
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素的数量，作为列NR
- en: the sum and the average of **qty**and **risk**, as columns TOTAL_QTY/TOTAL_RISK and AVG_QTY/AVG_RISK
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**qty**和 **risk**的总和和平均值，作为列 TOTAL_QTY/TOTAL_RISK 和 AVG_QTY/AVG_RISK'
- en: the weighted average of **qty**and **risk**, as columnsW_AVG_QTY and W_AVG_RISK.
    Weights are provided in column **weight**.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**qty**和 **risk**的加权平均值，作为列 W_AVG_QTY 和 W_AVG_RISK。权重在列 **weight**中提供。'
- en: To get the solution, I will not use any deprecated approach e.g [renaming aggregation
    by a nested dictionary](https://github.com/pandas-dev/pandas/issues/18366). Let
    us solve each task separately.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到解决方案，我不会使用任何已废弃的方法，例如 [通过嵌套字典重命名聚合](https://github.com/pandas-dev/pandas/issues/18366)。让我们分别解决每个任务。
- en: Number of elements in each bucket
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个桶中的元素数量
- en: Getting the number of elements in each bucket does not look enticing and requires
    intense typing
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 计算每个桶中的元素数量看起来不太吸引人，需要大量打字。
- en: '![No alt text provided for this image](../Images/09dbc34b1ce0a1f854605837fbbecd46.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/09dbc34b1ce0a1f854605837fbbecd46.png)'
- en: The literal **bucket **is required three times and you need to use 5 brackets/parentheses [????](https://en.wikipedia.org/wiki/%F0%9F%98%90).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 字面量 **bucket** 需要三次，并且你需要使用 5 个括号/圆括号 [????](https://en.wikipedia.org/wiki/%F0%9F%98%90)。
- en: The solutions in R look more tempting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: R 的解决方案看起来更有吸引力。
- en: '![No alt text provided for this image](../Images/d8dd9c42ea18835850c82d7ec1698196.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/d8dd9c42ea18835850c82d7ec1698196.png)'
- en: Developers of libraries dplyr and data.table also have aversion to word repetition.
    They introduced special built-in variables **n()** and **.N** respectively that
    hold the number of observations in the current group. This simplifies the expressions
    and we can get rid of a pair of parentheses.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: dplyr 和 data.table 的库开发者也对词汇重复感到厌恶。他们分别引入了内置变量 **n()** 和 **.N**，它们保存当前组中的观察数量。这简化了表达式，我们可以省去一对圆括号。
- en: '![No alt text provided for this image](../Images/d0a435e726edac8b2dfa565a41abb199.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/d0a435e726edac8b2dfa565a41abb199.png)'
- en: The ANSI SQL expression is simple and easy to understand.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ANSI SQL 表达式简单易懂。
- en: '![No alt text provided for this image](../Images/cf1334e8735319fcab68085a13ebf857.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/cf1334e8735319fcab68085a13ebf857.png)'
- en: You can avoid the repetition of the literal bucket by employing column indices
    in the GROUP BY clause. IMHO this is not a recommended design because the expression
    is not self-documenting and less robust. In fact, [Apache deprecated usage of
    numbers](https://issues.apache.org/jira/browse/DRILL-942) in GROUP BY clauses.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 GROUP BY 子句中使用列索引可以避免字面量 bucket 的重复。个人认为这不是推荐的设计，因为表达式不具自我文档性且不够健壮。事实上， [Apache
    已废弃使用数字](https://issues.apache.org/jira/browse/DRILL-942) 在 GROUP BY 子句中。
- en: The kdb+ expression is more elegant. It requires no brackets, quote marks or
    any word repetition.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: kdb+ 表达式更优雅。它不需要括号、引号或任何词汇重复。
- en: '![No alt text provided for this image](../Images/18dd6a40ac5e9e05bc79f239bb8bdf60.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/18dd6a40ac5e9e05bc79f239bb8bdf60.png)'
- en: SQL forms the basis of data analysis so probably everybody understands the ANSI
    SQL and kdb+ solutions. R and kdb+ developers agree that "GROUP BY" is too verbose,
    a simple "by" literal is expressive enough.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: SQL 形成了数据分析的基础，因此可能每个人都理解 ANSI SQL 和 kdb+ 解决方案。R 和 kdb+ 的开发者一致认为“GROUP BY”太冗长，一个简单的“by”字面量已经足够表达。
- en: Note that apart from Pandas, no languages use any quotation marks in this simple
    expression. The query in Pandas requires four pairs of them [????](https://en.wikipedia.org/wiki/%F0%9F%98%90) to
    wrap column names. In R, SQL, and kdb+ you can refer to columns as if they were
    variables. The notation .() in R - which is an alias for list() - allows this
    convenience feature.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了 Pandas 外，没有其他语言在这个简单表达式中使用任何引号。Pandas 中的查询需要四对引号 [????](https://en.wikipedia.org/wiki/%F0%9F%98%90) 来包裹列名。在
    R、SQL 和 kdb+ 中，你可以像引用变量一样引用列。R 中的 .() 符号 - 它是 list() 的别名 - 提供了这种便利特性。
- en: Aggregation of multiple columns
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多列的聚合
- en: Calculating sum and average of a single column and calculating the sums of multiple
    columns are quite simple with Pandas
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Pandas 计算单列的总和和平均值，以及计算多列的总和都非常简单。
- en: '![No alt text provided for this image](../Images/6ec1c299d8ec3781122391df1160c25f.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/6ec1c299d8ec3781122391df1160c25f.png)'
- en: '![No alt text provided for this image](../Images/bdb598a90547d3cec86cc0947080d21e.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/bdb598a90547d3cec86cc0947080d21e.png)'
- en: '![No alt text provided for this image](../Images/a236c220eb5a01618c1178fc6015d892.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/a236c220eb5a01618c1178fc6015d892.png)'
- en: '![No alt text provided for this image](../Images/abc52c2336cdd49ae81ecc4a7f89f146.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/abc52c2336cdd49ae81ecc4a7f89f146.png)'
- en: Code gets nasty if you try to combine the two approaches as it results in a
    column name conflict. [Multi-level columns](https://pandas.pydata.org/pandas-docs/stable/advanced.html) and
    function [map](https://docs.python.org/3/library/functions.html#map) need to be
    introduced.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试将两种方法结合在一起，代码会变得复杂，因为这会导致列名冲突。需要引入[多级列](https://pandas.pydata.org/pandas-docs/stable/advanced.html)和函数[map](https://docs.python.org/3/library/functions.html#map)。
- en: '![No alt text provided for this image](../Images/1152478e711c7acec5ae6ff74ebb8b27.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/1152478e711c7acec5ae6ff74ebb8b27.png)'
- en: '![No alt text provided for this image](../Images/b579576cf182169ab5bfa0e1bd7b5bf3.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/b579576cf182169ab5bfa0e1bd7b5bf3.png)'
- en: The SQL, R, and kdb+ equivalents do not require introducing any new concept.
    The new aggregations are simply separated by commas. You can use keyword [sum](https://code.kx.com/q/ref/arith-integer/#sum)and [avg](https://code.kx.com/v2/ref/stats-aggregates/#avg-average)/[mean](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/mean)to
    get sum and average respectively.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: SQL、R和kdb+的等价物不需要引入任何新概念。新的聚合操作仅通过逗号分隔。你可以使用关键字[sum](https://code.kx.com/q/ref/arith-integer/#sum)和[avg](https://code.kx.com/v2/ref/stats-aggregates/#avg-average)/[mean](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/mean)来分别获取和平均值。
- en: '![No alt text provided for this image](../Images/2f244c5f53b988918700736159dfec04.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/2f244c5f53b988918700736159dfec04.png)'
- en: Observe the lightness of the kdb+ expression; it does not require parentheses
    or brackets.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 观察kdb+表达式的简洁性；它不需要括号或方括号。
- en: '![No alt text provided for this image](../Images/a229bab4db85c16e330ea10bcdd452b3.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/a229bab4db85c16e330ea10bcdd452b3.png)'
- en: Weighted average
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加权平均
- en: The weighted average is supported by [Numpy](http://www.numpy.org/) library
    that Pandas relies on. Unfortunately, it cannot be used in the same way such as
    np.sum. You need to wrap it in a [lambda expression](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions),
    introduce a local variable, use [apply ](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html)instead
    of [agg](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.agg.html) and
    create a data frame from a series.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 加权平均由[Pandas](http://www.numpy.org/)依赖的[Numpy](http://www.numpy.org/)库支持。不幸的是，它不能像`np.sum`那样直接使用。你需要将其包裹在一个[lambda
    表达式](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions)中，引入一个局部变量，使用[apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html)代替[agg](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.agg.html)，并从系列创建一个数据框。
- en: '![No alt text provided for this image](../Images/ddb0578e6a3329675ac8fec347b94763.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/ddb0578e6a3329675ac8fec347b94763.png)'
- en: '![No alt text provided for this image](../Images/31ddf49336f61983417332e95ee3c09a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/31ddf49336f61983417332e95ee3c09a.png)'
- en: Neither standard SQL nor its Google extension, BigQuery, provides a built-in
    function to get a weighted average. You need to recall the definition and implement
    it by hand.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 标准SQL及其Google扩展BigQuery都没有提供获取加权平均的内置函数。你需要回忆定义并手动实现它。
- en: '![No alt text provided for this image](../Images/9451c257a36f1647822fc087988a3722.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/9451c257a36f1647822fc087988a3722.png)'
- en: Again the R and Q/Kdb+ solutions do not require introducing any new concept.
    The function weighted average is supported natively and accepts two column names
    as parameters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，R和Q/Kdb+的解决方案不需要引入任何新概念。加权平均函数在本地得到支持，并接受两个列名作为参数。
- en: '![No alt text provided for this image](../Images/4d22bb3a4180e3b8d37f45f5225f8945.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/4d22bb3a4180e3b8d37f45f5225f8945.png)'
- en: In kdb+ you can use infix notation to get a more natural syntax - just pronounce
    this "**w** weighted average **x**".
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在kdb+中，你可以使用中缀表示法来获得更自然的语法——只需将其读作"**w** 加权平均 **x**"。
- en: '![No alt text provided for this image](../Images/44af1a3b6d157860e89282b6d5e55796.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/44af1a3b6d157860e89282b6d5e55796.png)'
- en: All in one statement
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一条语句搞定
- en: Let us put all the parts together. We created multiple data frames, so we need
    to join them
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有部分结合在一起。我们创建了多个数据框，因此需要将它们合并
- en: '![No alt text provided for this image](../Images/385ca65b6d18111fbafd145f8b680d10.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/385ca65b6d18111fbafd145f8b680d10.png)'
- en: '![No alt text provided for this image](../Images/adb4ef52dba992faf73efce55d01ae7f.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/adb4ef52dba992faf73efce55d01ae7f.png)'
- en: Note that the first [join](https://docs.python.org/3/library/stdtypes.html#str.join) expression
    has nothing to do with the others. It creates a string from a list of strings
    as opposed to the others which perform [left joins](https://en.wikipedia.org/wiki/Join_(SQL)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第一个 [join](https://docs.python.org/3/library/stdtypes.html#str.join) 表达式与其他表达式无关。它从字符串列表中创建一个字符串，而其他表达式执行 [left
    joins](https://en.wikipedia.org/wiki/Join_(SQL))。
- en: To get the final result, we need three expressions and a temporary variable **res**.
    If we spend more time searching forums then we can find out that this complexity
    is partially attributed to deprecating nested dictionaries in function [agg](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.agg.html).
    Also, we might discover an alternative, less documented approach using just the
    function [apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html),
    with no join. Unfortunately, this solution returns all numeric columns of type
    float so you need to explicitly cast integer columns.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得最终结果，我们需要三个表达式和一个临时变量**res**。如果我们花更多时间搜索论坛，可以发现这种复杂性部分归因于函数 [agg](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.agg.html)
    中的嵌套字典的弃用。此外，我们可能会发现使用仅有的函数 [apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html)
    的一种替代方法，没有连接。不幸的是，这种解决方案返回所有浮点型的数值列，因此需要显式地转换整数列。
- en: '![No alt text provided for this image](../Images/43c61ad539c87048ef81ac96b602cc49.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/43c61ad539c87048ef81ac96b602cc49.png)'
- en: This solution requires creating a temporary function that will probably never
    be used again in your source code. We can squeeze all the statements into a single,
    stateless solution but that results in a hard-to-read and hard-to-maintain, nested
    code. Also, this second approach is slower on mid-size tables.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案需要创建一个临时函数，这个函数可能在你的源代码中不会再次使用。我们可以将所有语句压缩成一个单一的无状态解决方案，但这会导致难以阅读和维护的嵌套代码。此外，这种第二种方法在中等大小的表格上速度较慢。
- en: The Pandas [release of the 18th of July, 2019](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.25.0.html) supported
    group-by aggregation by [named aggregator](http://pandas-docs.github.io/pandas-docs-travis/user_guide/groupby.html#aggregation).
    It provides a more elegant syntax than the aforementioned apply-based solution
    and does not require typecasting. Also, the developers probably recognized the
    pain caused by the overwhelming usage of the quotation marks. Unfortunately, the
    weighted average is not supported because only a single column can be used in
    the aggregation. For completeness, we provide the new proper syntax, ignoring
    the weighted average calculation. It is great to see that the output column names
    no longer require quotation marks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas [2019 年 7 月 18 日的发布](https://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.25.0.html) 支持通过 [named
    aggregator](http://pandas-docs.github.io/pandas-docs-travis/user_guide/groupby.html#aggregation)
    进行分组聚合。它提供了比前述基于 apply 的解决方案更优雅的语法，并且不需要类型转换。此外，开发人员可能已经认识到使用引号造成的麻烦。不幸的是，权重平均数不被支持，因为聚合中只能使用单列。为了完整性，我们提供了新的适当语法，忽略了加权平均计算。很高兴看到输出列名不再需要引号。
- en: '![No alt text provided for this image](../Images/629c97d73d3196e3a291e0f8889848d6.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/629c97d73d3196e3a291e0f8889848d6.png)'
- en: In contrast, SQL could already provide an elegant solution 30 years ago.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，SQL 早在 30 年前就已经提供了优雅的解决方案。
- en: '![No alt text provided for this image](../Images/9b1f4d0545f1bb90da296f0b3f167ab9.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/9b1f4d0545f1bb90da296f0b3f167ab9.png)'
- en: Let us see how R solves the task with a data.table
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 R 如何使用 data.table 解决这个任务
- en: '![No alt text provided for this image](../Images/97325ee6d91274a11ecbbea83638169c.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/97325ee6d91274a11ecbbea83638169c.png)'
- en: and how the solution in kdb+ appears
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 kdb+ 中的解决方案的表现
- en: '![No alt text provided for this image](../Images/50880fb4fe953406cda883a5245f61e9.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![未提供该图像的替代文本](../Images/50880fb4fe953406cda883a5245f61e9.png)'
- en: It seems that kdb+ has the **most intuitive, simplest and most readable** solution.
    It is stateless, requires no parenthesis/bracket and creation of temporary variables
    (or functions).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 kdb+ 提供了**最直观、最简单且最易读**的解决方案。它是无状态的，不需要括号/方括号和临时变量（或函数）的创建。
- en: What about the performance?
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那性能怎么样呢？
- en: The experiments were conducted on both Windows and Linux using the stable latest
    binaries and libraries. Queries were executed a hundred times, test Jupyter notebooks
    are available on [Github.](https://github.com/BodonFerenc/PythonIsThisReallySimple) The
    data were randomly generated. The bucket fields were strings of size two and fields **qty** and **risk** are
    represented by 64-bit integers. Library [bit64](https://cran.r-project.org/web/packages/bit64/index.html) was
    used in R to get 64-bit integers. The table below summarises execution times in
    milliseconds. The axes are log scaled. The two Python solutions of version 3.6.8
    with Pandas 0.25.3 are compared to the three R libraries (version 3.6.0) and to
    the two kdb+ versions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 实验在 Windows 和 Linux 上进行，使用的是稳定的最新二进制文件和库。查询执行了百次，测试 Jupyter notebooks 可在 [Github](https://github.com/BodonFerenc/PythonIsThisReallySimple)
    上获取。数据是随机生成的。桶字段是大小为二的字符串，字段 **qty** 和 **risk** 由 64 位整数表示。在 R 中使用库 [bit64](https://cran.r-project.org/web/packages/bit64/index.html)
    获取 64 位整数。下表总结了以毫秒为单位的执行时间。坐标轴采用对数刻度。将两个 Python 解决方案（版本 3.6.8，Pandas 0.25.3）与三个
    R 库（版本 3.6.0）以及两个 kdb+ 版本进行比较。
- en: '![No alt text provided for this image](../Images/50507e7d70a7e844b6ebc76ee774bdac.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/50507e7d70a7e844b6ebc76ee774bdac.png)'
- en: The kdb+ solution is not only more elegant than Pandas but it is also faster
    by more than an order of magnitude. R's data.table of version 1.12.6 is three
    times slower than kdb+ 3.6 for this particular query. Kdb+ 4.0 is five times faster
    than kdb+ 3.6 for tables of billion rows. Package dplyr of version 0.8.3 was two
    orders of magnitude slower than plyr of version 1.8.5 ????.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: kdb+ 解决方案不仅比 Pandas 更优雅，而且速度也快了一个数量级。对于这个特定的查询，R 的 data.table 1.12.6 版本比 kdb+
    3.6 慢三倍。kdb+ 4.0 对于十亿行的表格比 kdb+ 3.6 快五倍。dplyr 0.8.3 版本的包比 plyr 1.8.5 版本慢两个数量级
    ????。
- en: Pandas hit memory limit with an input table of 1 billion rows. All other solutions
    could handle that volume without running out of memory.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 在处理 10 亿行的输入表时达到了内存限制。所有其他解决方案都能够处理这种规模的数据而不会耗尽内存。
- en: Let see how can we decrease execution times.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何减少执行时间。
- en: Performance optimizations
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能优化
- en: The column bucket contains strings. If the domain size is small and there are
    many repetitions then it is suggested to use **categorical** values instead of
    strings. Categories are like enums and represented by integers, hence they consume
    less memory and comparison is faster. You can convert string to categorical in
    Pandas by
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列桶包含字符串。如果领域大小较小且有很多重复项，则建议使用**类别**值而不是字符串。类别类似于枚举，由整数表示，因此它们消耗的内存更少，比较速度更快。你可以通过以下方法在
    Pandas 中将字符串转换为类别
- en: '![No alt text provided for this image](../Images/73accb51f6d0fb3b5bc5ef29919a4f3a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/73accb51f6d0fb3b5bc5ef29919a4f3a.png)'
- en: but it is more memory efficient to create the category column during the table
    construct. We use function [product](https://docs.python.org/2/library/itertools.html#itertools.product) to
    generate the universe of strings of length two by employing the [cartesian product](https://en.wikipedia.org/wiki/Cartesian_product).
    In the code snippet below we omit the syntax for creating other columns. *N* stores
    the number of rows to be inserted.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 但在构建表时创建类别列会更节省内存。我们使用函数 [product](https://docs.python.org/2/library/itertools.html#itertools.product)
    通过采用 [笛卡尔积](https://en.wikipedia.org/wiki/Cartesian_product) 来生成长度为二的字符串全集。在下面的代码片段中，我们省略了创建其他列的语法。*N*
    存储要插入的行数。
- en: '![No alt text provided for this image](../Images/c5b89afd5ab91b225ef844c1d90ffb9b.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/c5b89afd5ab91b225ef844c1d90ffb9b.png)'
- en: Categories are called **factors** in R. Class data.frame converts strings to
    factors automatically (use "stringAsFactors = FALSE" to avoid this) but in data.table
    strings are left intact for good reasons.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中，类别被称为**因素**。类 data.frame 会自动将字符串转换为因素（使用 "stringAsFactors = FALSE" 可以避免这种情况），但在
    data.table 中，字符串会被保留，原因正当。
- en: '![No alt text provided for this image](../Images/5b272ddf500676bc805aa50daf5d8217.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/5b272ddf500676bc805aa50daf5d8217.png)'
- en: BigQuery has no concept of category or factor. Instead, it applies various [encoding
    and compression techniques](http://db.csail.mit.edu/projects/cstore/abadisigmod06.pdf) to
    achieve the best performance. To generate random strings you can use Unicode [code
    points](https://en.wikipedia.org/wiki/Code_point), functions RAND and [CODE_POINTS_TO_STRING](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#code_points_to_string) and
    some casting. Lowercase letter "a" has code points 97 - you can figure this out
    by using function [TO_CODE_POINTS](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#to_code_points).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 没有类别或因素的概念。相反，它应用各种 [编码和压缩技术](http://db.csail.mit.edu/projects/cstore/abadisigmod06.pdf)
    来实现最佳性能。要生成随机字符串，你可以使用 Unicode [代码点](https://en.wikipedia.org/wiki/Code_point)、函数
    RAND 和 [CODE_POINTS_TO_STRING](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#code_points_to_string)
    以及一些转换。小写字母 "a" 的代码点是 97——你可以使用函数 [TO_CODE_POINTS](https://cloud.google.com/bigquery/docs/reference/standard-sql/string_functions#to_code_points)
    找出这一点。
- en: '![No alt text provided for this image](../Images/ea82a723615b346ff150438ac487e9e7.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/ea82a723615b346ff150438ac487e9e7.png)'
- en: You can employ a [user-defined function](https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions) to
    avoid code duplication.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用一个 [用户定义的函数](https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions)
    来避免代码重复。
- en: '![No alt text provided for this image](../Images/871bafeb6392a6867c6ebdd44de59c04.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/871bafeb6392a6867c6ebdd44de59c04.png)'
- en: For comparison, the same operation in kdb+ looks like this
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对比，在 kdb+ 中，相同的操作看起来是这样的。
- en: '![No alt text provided for this image](../Images/59f019d6bf657f2bec2628a52651a4ab.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![未提供此图像的替代文本](../Images/59f019d6bf657f2bec2628a52651a4ab.png)'
- en: The construct [N?M](https://code.kx.com/q/ref/deal/) generates N random values
    depending on the type of M. If M is an integer, float, date or boolean then a
    random integer, float, date or boolean vector is returned. If M is a list then
    random list elements are picked. If N is a negative integer then the result will
    not contain any duplicates. In kdb+ many operators are overloaded in a similar
    way.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 构造 [N?M](https://code.kx.com/q/ref/deal/) 会根据 M 的类型生成 N 个随机值。如果 M 是整数、浮点数、日期或布尔值，则返回一个随机整数、浮点数、日期或布尔值向量。如果
    M 是列表，则随机选择列表元素。如果 N 是负整数，则结果不会包含任何重复项。在 kdb+ 中，许多操作符以类似方式被重载。
- en: Enums are called **symbols** in kdb+ parlance and are heavily used by developers.
    The language strongly supports symbols. You can use them without defining possible
    values upfront, kdb+ maintains the mapping for you.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在 kdb+ 中，枚举被称为**符号**，并被开发人员广泛使用。该语言强烈支持符号。你可以使用它们而无需事先定义可能的值，kdb+ 会为你维护映射。
- en: Based on my measurement, optimization by categories/symbols reduces run times
    by a **factor of two** in Pandas and kdb+. R's data.table shows different characteristics.
    Using factors instead of strings has no impact on the performance. This is due
    to the built-in string optimization via the **global string pool**. Although,
    factors are stored as 32-bit integers and strings require 64-bit pointers to the
    pool elements, the difference has a marginal impact on the execution times.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的测量，通过类别/符号的优化在 Pandas 和 kdb+ 中可以将运行时间减少**两倍**。R 的 data.table 显示出不同的特性。使用因素而不是字符串对性能没有影响。这是由于**全局字符串池**的内置字符串优化。虽然，因素被存储为
    32 位整数，而字符串需要 64 位指向池元素的指针，但这种差异对执行时间的影响很小。
- en: We can further improve performance if we use types that require less space.
    For example, if column **qty** fits into 2 bytes then we can use [int16](https://numpy.org/devdocs/user/basics.types.html) in
    Pandas and [short](https://code.kx.com/q4m3/2_Basic_Data_Types_Atoms/#212-short-and-int) in
    kdb+. This results in less memory operation which is often the bottleneck in data
    analysis. R does not support 2-bytes integers so we used its default integer type
    which occupies 4 bytes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用占用空间更少的类型，可以进一步提高性能。例如，如果列 **qty** 可以适配到 2 字节，那么我们可以在 Pandas 中使用 [int16](https://numpy.org/devdocs/user/basics.types.html)，在
    kdb+ 中使用 [short](https://code.kx.com/q4m3/2_Basic_Data_Types_Atoms/#212-short-and-int)。这会减少内存操作，而内存操作通常是数据分析的瓶颈。R
    不支持 2 字节整数，因此我们使用了其默认的 4 字节整数类型。
- en: Integers of size 32, which is the default in R, results in a 5-6 fold execution
    time improvements. Use 64-bit integers only if you really need the large cardinality.
    This is especially true for package dplyr.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 32 位整数（R 中的默认值）可以带来 5-6 倍的执行时间改进。只有在你真正需要大基数时才使用 64 位整数。这对 dplyr 包尤其适用。
- en: When calculating the aggregation we need to keep track of the bucket due to
    the grouping. If the table is sorted by the group column then aggregation is faster
    as groups are already gathered contiguously in RAM. The execution times drop to
    circa one third in Pandas, half in R and fifth in kdb+. The execution times with
    the type optimizations on a sorted table of size 1 billion is shown below.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/f76b3f1c536fe46463888ba67835d7b9.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
- en: Parallelization
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All modern computers have multiple CPU cores. Pandas by default operate on a
    single core. What do we need to do to make the computation parallel and exploit
    multiple cores?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Python libraries [Dask](https://dask.org/) and [Ray](https://github.com/ray-project/ray) are
    the two most famous libraries for running parallel computations. Library [Modin](https://modin.readthedocs.io/en/latest/) is
    a wrapper above these engines for Pandas data frames. The "media" is loud from
    the claim that you gain significant query performance improvements, even on an
    average laptop, by replacing a single line from
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/cbd9819fe215b1dfa1a2eebe966e7882.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
- en: to
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/3ca36daed1406cf034705e2564d9f129.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: This is probably true for a small number of textbook examples but does not apply
    in real life. With my simple exercise, I run into several issues both with Ray
    and with Dask. Let me describe the problem one-by-one starting with Ray.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: First, the category type is not supported. Second, function [apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply) and [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg) behaves
    differently than the corresponding Pandas functions. Using multiple aggregates
    with a group-by in function [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html#pandas.DataFrame.agg) is
    not supported so the operation falls back to Pandas operation. The function [applies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply) only
    handles lambdas that return a scalar. This disables the second, more elegant Pandas
    solution. Furthermore, apply returns a Modin data frame instead of a series. You
    need to transpose the result and rename the column index (0) to a meaningful column
    name, e.g.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/2921d63f8270367cfdd8f64cebfde02c.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: Finally, the code ran significantly slower than the Pandas equivalent and broke
    with 100M rows. Pandas and the others handle 1B rows easily.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Moving to the library Dask also has some nuisances. First, it does not handle
    the weighted average if the bucket’s type is categorical. We lose an important
    performance improvement technique. Second, you need to provide type hinting to
    suppress warnings. This means yet another column name repetition. In the more
    elegant apply-based solution you type the output column names (like TOTAL_QTY)
    four times ☹️. So it seems moving to Dask is not as simple as extending the code
    with a simple [compute](https://docs.dask.org/en/latest/dataframe.html) statement
    to trigger the computation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/c43adaa24c846a34ec6614a449924c16.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: '**Parallelization in kdb+ is automatic** for on-disk, partitioned tables and
    for in-memory tables in version 4.0\. You won''t observe any type problem - everything
    works smoothly. All you need is to start kdb+ in multiprocess mode via [command
    line parameter -s](https://code.kx.com/q/basics/syscmds/#s-number-of-slaves).
    The [built-in map-reduce](https://code.kx.com/q4m3/14_Introduction_to_Kdb+/#1437-map-reduce) decomposition
    spreads the computation to several cores for the majority of operations including [sum](https://code.kx.com/q/ref/sum/), [avg](https://code.kx.com/q/ref/avg/), [count](https://code.kx.com/q/ref/count/), [wavg](https://code.kx.com/q/ref/avg/), [cor](https://code.kx.com/q/ref/cor/),
    etc. You can also get performance gain by partitioning the table manually and
    use function [peach](https://code.kx.com/v2/ref/each/) that executes functions
    in parallel. All we need is to change from'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/b008380e3dddeb72d3431f2b32531649.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: to
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/9644443ab45161925cc211f122377808.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: This simple code modification resulted in almost an order of magnitude faster
    execution on a 16-core box with kdb+ version 3.6\. Since version 4.0 already employs
    parallel computing, manual parallelization adds no value. If you are aiming for
    the best performance then code will be simpler with kdb+ 4.0 than with 3.6.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '**R data.table also uses multiple threads by default** and executes queries
    in parallel behind the scene. You can check and set the number of threads that
    the data.table uses via function [setDTthreads](https://www.rdocumentation.org/packages/data.table/versions/1.12.8/topics/setDTthreads).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Let us compare the execution times of the most performant versions of all languages.
    For SQL we evaluated BigQuery which is considered to be the fastest SQL implementation
    for huge datasets due to its massive parallelization.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![No alt text provided for this image](../Images/ae75206d32368a5a479ea33b41000b14.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: kdb+ is again the winner in this category, BigQuery being the runner-up. R data.table
    is two times faster than Pandas.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Above 1 billion rows
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The largest tables in our experience contained one billion rows. Above this
    number the table does not fit into the memory, hence Pandas is out of the league.
    Dask and Ray which is designed for parallel processing and cluster of computers
    performed poorly compared to the other contenders. **For BigQuery the size of
    the table almost does not matter.** The execution time will hardly increase if
    we move from 1 billion rows to 10 or 100 billion rows.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的经验中最大表格包含十亿行。超过这个数量，表格无法适配到内存中，因此Pandas无能为力。Dask和Ray设计用于并行处理和计算机集群，相比其他竞争者表现较差。**对于BigQuery，表格的大小几乎没有关系。**
    如果我们将行数从10亿增加到100亿或1000亿，执行时间几乎不会增加。
- en: In kdb+, the data can be persisted to disk so it can cope with terabytes of
    data. The query will be the same and kdb+ automatically applies map-reduce and
    leverage multicore processors. Furthermore, if the data is segmented and segments
    are located on different storages with separate IO channels then IO operation
    will be executed in parallel. These low-level optimizations allow the kdb+-based
    solution to scale gracefully.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在kdb+中，数据可以持久化到磁盘，因此可以处理TB级的数据。查询将保持不变，kdb+会自动应用map-reduce并利用多核处理器。此外，如果数据被分段且段位于具有独立IO通道的不同存储上，则IO操作将并行执行。这些低级优化使得基于kdb+的解决方案能够优雅地扩展。
- en: Distributed computing with kdb+
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用kdb+的分布式计算
- en: As a final simple exercise let us investigate how can we spread the computation
    across many kdb+ processes, leverage our cluster of machines and horizontally
    partition our sample table. How difficult it is to achieve a Ray/Dask/Spark-like
    distributed computation with kdb+?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最终的简单练习，让我们探讨如何将计算分散到多个kdb+进程中，利用我们的机器集群并水平分割样本表。实现类似Ray/Dask/Spark的分布式计算在kdb+中有多困难？
- en: Function peach uses external, slave kdb+ processes as opposed to slave threads
    if variable [.z.pd](https://code.kx.com/v2/ref/dotz/#zpd-peach-handles) stores
    connection handles to slave kdb+ processes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 函数peach使用外部的kdb+从属进程，而不是从属线程，如果变量[.z.pd](https://code.kx.com/v2/ref/dotz/#zpd-peach-handles)存储连接到从属kdb+进程的连接句柄。
- en: '![No alt text provided for this image](../Images/7076b41e633ca03c787d89834e9c2625.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/7076b41e633ca03c787d89834e9c2625.png)'
- en: We can split table **t** by bucket values
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按桶值分割表**t**
- en: '![No alt text provided for this image](../Images/9e2947cfcc84890d63991af6544b3986.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/9e2947cfcc84890d63991af6544b3986.png)'
- en: Finally, we can distribute the select statement and merge the result. Function [raze](https://code.kx.com/q/ref/raze/) is
    similar to Pandas' [concat](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) function.
    From a list of tables, it produces a large table via concatenation.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以分发选择语句并合并结果。函数[raze](https://code.kx.com/q/ref/raze/)类似于Pandas的[concat](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)函数。从一个表格列表中，它通过连接生成一个大表。
- en: '![No alt text provided for this image](../Images/db8042fb22f14074923e27a320a5be16.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/db8042fb22f14074923e27a320a5be16.png)'
- en: Well done! We implemented "kdb-spark" with four lines of code.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 做得好！我们用四行代码实现了“kdb-spark”。
- en: Code simplicity
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码简洁性
- en: I collected a few statistics about the code themselves. Although short code
    does not necessarily mean clean code, for this particular example these metrics
    well correlate with simplicity.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我收集了一些关于代码本身的统计数据。虽然简短的代码不一定意味着干净的代码，但对于这个特定的例子，这些指标与简洁性很好地相关。
- en: '![No alt text provided for this image](../Images/68d2942f4fa51ce053a89dab058e893c.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/68d2942f4fa51ce053a89dab058e893c.png)'
- en: Conclusion
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: My observations are collected in the table below. Emoji ????stands for excellent,
    ✔️for good and ☹️for a disappointing performance.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我的观察结果汇总在下面的表格中。表情符号????表示优秀，✔️表示良好，☹️表示表现令人失望。
- en: '![No alt text provided for this image](../Images/2b59ea9e74f33cc6be88ae78a1e435b8.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![没有提供此图像的替代文本](../Images/2b59ea9e74f33cc6be88ae78a1e435b8.png)'
- en: Python is often the first programming language a student learns. It is simple,
    performant and has a slight learning curve. Its library Pandas is a natural step
    to introduce new-joiners to the world of data analyses. Pandas is also often used
    in a professional environment and more complex data analysis. Pandas looks tempting
    in simple, textbook exercises but is inconvenient to use in our simple real-world
    use-case.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Python通常是学生学习的第一个编程语言。它简单、性能良好且学习曲线较小。它的库Pandas是引导新手进入数据分析世界的自然步骤。Pandas也常用于专业环境和更复杂的数据分析。Pandas在简单的教科书练习中看起来很诱人，但在我们的简单实际应用中却不方便使用。
- en: There is more focus on extending Pandas and support large tables via cluster
    computing. Ray, Dask and Modin are in an early phase with a bunch of limitations.
    In our use case, they simply added syntactical complexity and actually decreased
    performance.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的关注点在于通过集群计算扩展Pandas并支持大型表。Ray、Dask和Modin处于早期阶段，有很多限制。在我们的使用案例中，它们只是增加了语法复杂性，并实际上降低了性能。
- en: R outperformed Pandas in every sense, including simplicity, elegance and performance.
    There are several built-in optimizations, such as inherent multi-threading. Optimization
    of string representation works like a charm and allows developers to focus on
    the analyses as opposed to minor technical details. It comes as no surprise that
    R data.table is being [ported to Python](https://github.com/h2oai/datatable).
    Maybe package data.table will be the replacement of Pandas in the future?
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: R在每个方面都优于Pandas，包括简单性、优雅性和性能。它有几个内置的优化，比如固有的多线程。字符串表示的优化效果很好，使开发者可以专注于分析，而不是琐碎的技术细节。R数据表被[移植到Python](https://github.com/h2oai/datatable)也就不足为奇了。也许数据表包将来会取代Pandas？
- en: Kdb+ takes data analyses to the next level. It is designed for extreme productivity.
    In our use case, it was the clear winner of simplicity, elegance, and performance.
    No wonder that 20 out of the 20 top organizations in the capital market chose
    kdb+ as a primary tool for data analyses. In this industry, the data analysis
    drives the revenue and the tools are tested under extreme conditions.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: kdb+将数据分析提升到新的水平。它被设计为极致的生产力工具。在我们的使用案例中，它在简单性、优雅性和性能方面明显胜出。难怪资本市场前20名组织中有20个选择了kdb+作为主要的数据分析工具。在这个行业中，数据分析驱动收入，工具在极端条件下进行测试。
- en: BigQuery is a winner in performance above 100 Billion rows assuming that you
    don't have a cluster of computers at hand. If you need to analyze huge tables
    and you are sensitive to run-times then BigQuery does a great job for you.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery在处理超过100亿行的数据时表现出色，前提是你没有一群计算机。如果你需要分析巨大的表格，并且对运行时间非常敏感，那么BigQuery为你做得很好。
- en: Related works
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关工作
- en: '[DB ops benchmark](https://h2oai.github.io/db-benchmark/) was initially started
    by [Matt Dowle](https://twitter.com/MattDowle) the creator of R data.table. Besides
    Pandas, data.table, dask dplyr they also test [Apache Spark](https://spark.apache.org/), [ClickHouse](https://clickhouse.yandex/) and [Julia
    data frames](https://juliadata.github.io/DataFrames.jl/stable/) on a variety of
    queries with different parameters. Anyone can see the queries side-by-side and
    even download the test environment to conduct the experiments of his/her custom
    hardware.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[DB ops benchmark](https://h2oai.github.io/db-benchmark/) 最初由[R数据表](https://twitter.com/MattDowle)的创建者[Matt
    Dowle](https://twitter.com/MattDowle)发起。除了Pandas、data.table、dask dplyr，他们还在各种查询和不同参数下测试了[Apache
    Spark](https://spark.apache.org/)、[ClickHouse](https://clickhouse.yandex/)和[Julia数据框](https://juliadata.github.io/DataFrames.jl/stable/)。任何人都可以并排查看查询，甚至下载测试环境以进行自定义硬件的实验。'
- en: '[Mark Litwintschik](https://www.linkedin.com/in/marklitwintschik/) uses the
    NYC taxi drives database and four queries on [33 database-like systems](https://tech.marksblogg.com/benchmarks.html).
    He provides a detailed description of the test environments, the settings he used
    and some valuable personal remarks. It is a thorough work that demonstrates Mark''s
    outstanding knowledge in Big Data platforms. His observation is in line with our
    experiments, kdb+ turned out the be the fastest among the non-GPU-based database
    solutions.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mark Litwintschik](https://www.linkedin.com/in/marklitwintschik/) 使用了NYC出租车驾驶数据集和[33种数据库系统](https://tech.marksblogg.com/benchmarks.html)上的四个查询。他提供了测试环境的详细描述、所用设置以及一些有价值的个人备注。这是一项彻底的工作，展示了Mark在大数据平台上的杰出知识。他的观察与我们的实验一致，kdb+在非GPU数据库解决方案中表现最快。'
- en: The STAC-M3 benchmark was originally [developed in 2010](https://stacresearch.com/system/files/central/STAC-M3_Overview.pdf) by
    several of the world’s largest banks and trading firms. It is designed to measure
    exactly how much emerging hardware and software innovations improve the performance
    of time-series analytics. After STAC-M3 was developed, kdb+ quickly became the
    favorite database platform for hardware vendors running the tests because it set
    performance standards that other software providers simply couldn’t beat. Also,
    Google acknowledged STAC-M3 as an industry-standard benchmark for time-series
    analytics. They used kdb+ to [demonstrate](https://cloud.google.com/blog/products/compute/can-cloud-instances-perform-better-than-bare-metal-latest-stac-m3-benchmarks-say-yes) that
    migrating data and workload from on-premise to GCP does not mean compromising
    the performance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: STAC-M3基准测试最初由几家全球最大银行和交易公司于[2010年开发](https://stacresearch.com/system/files/central/STAC-M3_Overview.pdf)。它旨在精确测量新兴硬件和软件创新如何提高时间序列分析的性能。在STAC-M3开发之后，kdb+迅速成为运行测试的硬件供应商的首选数据库平台，因为它设定了其他软件供应商无法超越的性能标准。此外，Google也承认STAC-M3作为时间序列分析的行业标准基准。他们使用kdb+来[展示](https://cloud.google.com/blog/products/compute/can-cloud-instances-perform-better-than-bare-metal-latest-stac-m3-benchmarks-say-yes)将数据和工作负载从本地迁移到GCP不会妥协性能。
- en: Acknowledgments
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 致谢
- en: I would like to thank [Péter Györök](https://github.com/gyorokpeter), [Péter
    Simon Vargha](https://www.linkedin.com/in/varghaps/) and [Gergely Daróczi](https://www.linkedin.com/in/daroczig/) for
    their insightful bits of advice.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我想感谢[Péter Györök](https://github.com/gyorokpeter)、[Péter Simon Vargha](https://www.linkedin.com/in/varghaps/)和[Gergely
    Daróczi](https://www.linkedin.com/in/daroczig/)提供的富有洞见的建议。
- en: '**Bio: [Ferenc Bodon Ph.D.](https://www.linkedin.com/in/ferencbodon/)** is
    an experienced data engineer, software developer, multi language programmer, software
    architect with academic background in data mining and statistics. Reflects long-term
    thinking and always striving to find top quality, robust solutions that are scalable
    and allow rapid development. Believes in software quality and cannot relax until
    the "glory solution" is found.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Ferenc Bodon博士](https://www.linkedin.com/in/ferencbodon/)** 是一位经验丰富的数据工程师、软件开发者、多语言程序员、拥有数据挖掘和统计学学术背景的软件架构师。具有长期思维，始终致力于寻找高质量、稳健且可扩展的解决方案，并允许快速开发。相信软件质量，并且在找到“完美解决方案”之前无法放松。'
- en: '[Original](https://www.linkedin.com/pulse/python-data-analysis-really-simple-ferenc-bodon-ph-d-/).
    Reposted with permission.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.linkedin.com/pulse/python-data-analysis-really-simple-ferenc-bodon-ph-d-/)。经许可转载。'
- en: '**Related:**'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[10 Simple Hacks to Speed up Your Data Analysis in Python](/2019/07/10-simple-hacks-speed-data-analysis-python.html)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Python中加速数据分析的10个简单技巧](/2019/07/10-simple-hacks-speed-data-analysis-python.html)'
- en: '[The Last SQL Guide for Data Analysis You’ll Ever Need](/2019/10/last-sql-guide-data-analysis-ever-need.html)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你将永远需要的最后一份SQL数据分析指南](/2019/10/last-sql-guide-data-analysis-ever-need.html)'
- en: '[The Berlin Rent Freeze: How many illegal overpriced offers can I find online?](/2020/03/berlin-rent-freeze-illegal-overpriced-offers.html)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[柏林租金冻结：我能在网上找到多少非法的高价报价？](/2020/03/berlin-rent-freeze-illegal-overpriced-offers.html)'
- en: '* * *'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织在IT领域'
- en: '* * *'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并寻找目的来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个 90 亿美元的人工智能失败案例，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
