# 机器学习的学习曲线

> 原文：[https://www.kdnuggets.com/2018/01/learning-curves-machine-learning.html](https://www.kdnuggets.com/2018/01/learning-curves-machine-learning.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/01/learning-curves-machine-learning.html?page=2#comments)

**作者：[Alex Olteanu](https://www.dataquest.io/blog/author/alex-olteanu/)，Dataquest.io 学生成功专家**

在构建机器学习模型时，我们希望将误差保持在尽可能低的水平。误差的两个主要来源是偏差和方差。如果我们能够减少这两个因素，那么我们可以构建出更准确的模型。

但是，我们首先如何诊断偏差和方差？一旦检测到问题，我们应该采取什么措施？

在这篇文章中，我们将学习如何利用学习曲线回答这两个问题。我们将使用一个实际数据集，尝试预测电厂的电能输出。

![topimage](../Images/b33264e06b657964ebe236ca92cc602e.png)

我们将生成学习曲线，同时尝试预测电厂的电能输出。图片来源：[Pexels](https://www.pexels.com/photo/black-metal-current-posts-157827/)。

假设你对 scikit-learn 和机器学习理论有一定的了解。如果你在听到*交叉验证*或*监督学习*时没有皱眉，那么你可以继续。如果你是机器学习的新手，从[这篇博客文章](https://www.dataquest.io/blog/machine-learning-tutorial/)开始是个不错的选择。

我们首先简要介绍偏差和方差。

### 偏差-方差权衡

在监督学习中，我们*假设*特征和目标之间存在真实关系，并用模型估计这个未知的关系。如果假设是正确的，确实存在一个模型，我们称之为![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png)，它完美描述了特征和目标之间的关系。

在实际操作中，![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png)几乎总是完全未知的，我们尝试用模型来估计它！[Equation](../Images/a94d66a6a6aee949360df0defda68828.png)（注意![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png)和![Equation](../Images/a94d66a6a6aee949360df0defda68828.png)之间符号的细微差别）。我们使用某个训练集并得到某个![Equation](../Images/a94d66a6a6aee949360df0defda68828.png)。如果使用不同的训练集，我们很可能会得到不同的![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。随着训练集的不断变化，我们会得到不同的![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)的输出。![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)随着训练集的变化而变化的程度称为**方差**。

要估计真实的 ![方程式](../Images/0124e78268c96059dbff35809fb67ffe.png)，我们使用不同的方法，如线性回归或随机森林。例如，线性回归假设特征与目标之间的关系是线性的。然而，在大多数现实场景中，特征与目标之间的真实关系是复杂的，远非线性。简化的假设会给模型带来**偏差**。假设与真实关系的误差越大，偏差越高，反之亦然。

一般来说，模型 ![方程式](../Images/f882e047405752e27ee94c30f948ef78.png) 在测试一些测试数据时会有一些误差。可以通过 [数学方法](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff#Bias.E2.80.93variance_decomposition_of_squared_error) 证明，偏差和方差都会增加模型的误差。我们希望误差低，所以需要将偏差和方差保持在最低水平。然而，这并不完全可能。偏差和方差之间存在权衡。

低偏差的方法能很好地拟合训练数据。如果我们改变训练集，我们将获得显著不同的模型 ![方程式](../Images/f882e047405752e27ee94c30f948ef78.png)。

![低偏差](../Images/ab1470baaa9fe78506fbcac164556371.png)

你可以看到，低偏差的方法能够捕捉到不同训练集之间的大多数差异（即使是微小的差异）。 ![方程式](../Images/f882e047405752e27ee94c30f948ef78.png) *变化* 很大，随着训练集的改变，这表明方差很高。

方法的偏差越小，其对数据的拟合能力越强。拟合能力越强，方差也越高。因此，偏差越低，方差越大。

反之亦然：偏差越大，方差越低。高偏差的方法构建了通常不能很好拟合训练数据的简单模型。当我们改变训练集时，从高偏差算法得到的模型 ![方程式](../Images/f882e047405752e27ee94c30f948ef78.png) 通常不会彼此有很大的不同。

![高偏差](../Images/86c72c905bc8f130a0bba3d54a627202.png)

如果 ![方程式](../Images/f882e047405752e27ee94c30f948ef78.png) 在我们改变训练集时变化不大，则方差很低，这证明了我们的观点：偏差越大，方差越低。

从数学上讲，我们之所以希望偏差和方差都低是显而易见的。如上所述，偏差和方差只会增加模型的误差。然而，从更直观的角度来看，我们希望偏差低，以避免构建过于简单的模型。在大多数情况下，简单模型在训练数据上的表现较差，而且极有可能在测试数据上重复这种差劲的表现。

同样，我们希望低方差，以避免构建一个过于复杂的模型。这样的模型几乎完美地拟合了训练集中的所有数据点。然而，训练数据通常包含噪声，并且只是来自更大人群的一个样本。一个过于复杂的模型会捕捉到这些噪声。当在*out-of-sample*数据上进行测试时，性能通常较差。这是因为模型过于完美地学习了*样本*训练数据，对其他任何东西了解较少。

然而，在实践中，我们需要接受权衡。我们不能同时拥有低偏差和低方差，因此我们希望在两者之间找到一个平衡点。

![biasvariance](../Images/6938ccb23dc3c764c12b74135c1b9c98.png)

来源：[Scott Fortmann-Roe - 理解偏差-方差权衡](http://scott.fortmann-roe.com/docs/BiasVariance.html)

我们将在下文生成和解释学习曲线时，试图建立对这种权衡的实际直觉。

### 学习曲线 - 基本概念

假设我们有一些数据并将其拆分为训练集和[验证集](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set#19051)。我们从训练集中取出一个实例（没错，就一个！）来估计模型。然后我们测量模型在验证集和该单一训练实例上的错误。训练实例上的错误将为0，因为完美拟合一个数据点相当容易。然而，验证集上的错误将非常大。这是因为模型是围绕一个实例构建的，它几乎肯定无法准确泛化到未见过的数据上。

现在假设我们不是使用一个训练实例，而是使用十个，并重复错误测量。然后我们使用五十个、一百个、五百个，直到使用整个训练集。随着我们改变训练集，错误评分会有所变化。

因此，我们需要监控两个错误评分：一个用于验证集，另一个用于训练集。如果我们绘制两个错误评分在训练集变化时的演变图，就会得到两条曲线。这些曲线被称为*学习曲线*。

简而言之，学习曲线显示了随着训练集大小的增加，错误如何变化。下图应帮助你可视化到目前为止描述的过程。在训练集列中，你可以看到我们不断增加训练集的大小。这会导致我们的模型发生轻微变化 ![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。

在第一行中，当n = 1（*n*是训练实例的数量）时，模型完美地拟合了那个单一的训练数据点。然而，同样的模型在一个包含20个不同数据点的验证集上的拟合效果非常差。因此，模型在训练集上的错误为0，但在验证集上的错误则高得多。

随着训练集大小的增加，模型无法再完美地拟合训练集。因此，训练误差变大。然而，模型在更多数据上进行训练，因此它能更好地拟合验证集。因此，验证误差减少。请注意，验证集在所有三个情况中保持不变。

![models](../Images/266e92e6dd9cc26c3063532071441905.png)

如果我们绘制每个训练集大小的误差得分，我们会得到类似于这些的两个学习曲线：

![learning_curves](../Images/41b716750016cb9f85f40fba3a46795d.png)

学习曲线为我们提供了诊断监督学习模型偏差和方差的机会。我们将在接下来的内容中看到这是如何实现的。

### 引入数据

上述绘制的学习曲线是为了教学目的而理想化的。然而，在实践中，它们通常看起来有很大不同。因此，让我们使用一些真实世界的数据，将讨论转到实际环境中。

我们将尝试构建回归模型，预测电厂的每小时电能输出。我们使用的数据来自土耳其研究人员 Pınar Tüfekci 和 Heysem Kaya，可以从[这里](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)下载。由于数据存储在`.xlsx`文件中，我们使用 pandas 的 `read_excel()` [函数](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html?highlight=read_excel#pandas.read_excel)来读取数据：

```py
import pandas as pd

electricity = pd.read_excel('Folds5x2_pp.xlsx')

print(electricity.info())
electricity.head(3)
```

```py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 9568 entries, 0 to 9567
Data columns (total 5 columns):
AT    9568 non-null float64
V     9568 non-null float64
AP    9568 non-null float64
RH    9568 non-null float64
PE    9568 non-null float64
dtypes: float64(5)
memory usage: 373.8 KB
None
```

|  | AT | V | AP | RH | PE |
| --- | :-- | :-- | :-- | :-- | :-- |
| 0 | 14.96 | 41.76 | 1024.07 | 73.17 | 463.26 |
| 1 | 25.18 | 62.96 | 1020.04 | 59.08 | 444.37 |
| 2 | 5.11 | 39.40 | 1012.16 | 92.14 | 488.56 |

让我们快速解读每一列的名称：

| 缩写 | 全名 |
| :-- | :-- |
| AT | 环境温度 |
| V | 排气真空 |
| AP | 环境压力 |
| RH | 相对湿度 |
| PE | 电能输出 |

`PE`列是目标变量，描述了净每小时电能输出。其他所有变量都是潜在的特征，且每个变量的值实际上是每小时的平均值（不是像`PE`那样的净值）。

电力由燃气涡轮机、蒸汽涡轮机和热回收蒸汽发生器产生。根据数据集的文档，真空水平对蒸汽涡轮机有影响，而其他三个变量则影响燃气涡轮机。因此，我们将在回归模型中使用所有特征列。

在这个步骤中，我们通常会留出一个测试集，彻底探索训练数据，移除任何异常值，测量相关性等。然而，为了教学目的，我们将假设这些步骤已经完成，并直接生成一些学习曲线。在开始之前，值得注意的是没有缺失值。此外，数字是未缩放的，但我们将避免使用对未缩放数据有问题的模型。

### 确定训练集大小

首先决定我们想用什么训练集大小来生成学习曲线。

最小值是1。最大值由训练集中的实例数决定。我们的训练集有9568个实例，所以最大值是9568。

不过，我们还没有留出验证集。我们将使用80:20的比例，最终得到一个包含7654个实例（80%）的训练集和一个包含1914个实例（20%）的验证集。鉴于我们的训练集将有7654个实例，我们生成学习曲线时可以使用的最大值是7654。

对于我们的案例，我们使用这六种大小：

```py
train_sizes = [1, 100, 500, 2000, 5000, 7654]
```

一个重要的注意事项是，对于每个指定的大小都会训练一个新的模型。如果你使用交叉验证，我们将在本帖中进行的，*k*个模型会为每个训练大小进行训练（其中*k*由交叉验证使用的折数决定）。为了节省代码运行时间，最好将训练大小限制在5-10个之间。

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT工作

* * *

### 更多相关内容

+   [KDnuggets新闻，12月14日：3门免费的机器学习课程…](https://www.kdnuggets.com/2022/n48.html)

+   [每个机器学习工程师都应该具备的5项机器学习技能](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)

+   [学习数据科学、机器学习和深度学习的可靠计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)

+   [人工智能、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)

+   [打破数据壁垒：零样本、单样本和少样本学习…](https://www.kdnuggets.com/2023/08/breaking-data-barrier-zeroshot-oneshot-fewshot-learning-transforming-machine-learning.html)

+   [联邦学习：协作机器学习教程…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)
