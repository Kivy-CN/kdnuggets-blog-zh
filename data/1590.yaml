- en: My secret sauce to be in top 2% of a Kaggle competition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的秘密武器，帮助我在 Kaggle 比赛中进入前 2%
- en: 原文：[https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html](https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html](https://www.kdnuggets.com/2018/11/secret-sauce-top-kaggle-competition.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Abhay Pawar](https://www.linkedin.com/in/abhayspawar/), Instacart**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Abhay Pawar](https://www.linkedin.com/in/abhayspawar/), Instacart**。'
- en: Competing in kaggle competitions is fun and addictive! And over the last couple
    of years, I developed some standard ways to explore features and build better
    machine learning models. These simple, but powerful techniques helped me get a
    top 2% rank in [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis) competition
    and I use them outside of kaggle as well. So, let’s get right into it!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 参加 Kaggle 比赛很有趣且上瘾！在过去的几年里，我开发了一些标准方法来探索特征并构建更好的机器学习模型。这些简单但强大的技术帮助我在 [Instacart
    市场篮子分析](https://www.kaggle.com/c/instacart-market-basket-analysis) 比赛中获得了前 2%
    的排名，我在 Kaggle 之外也使用这些技术。让我们直接进入正题！
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One of the most important aspects of building any supervised learning model
    on numeric data is to understand the features well. Looking at partial dependence
    plots of a model helps you understand how the model’s output changes with any
    feature.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在数值数据上构建任何监督学习模型的最重要方面之一是充分理解特征。查看模型的部分依赖图有助于你了解模型输出如何随特征变化。
- en: '![](../Images/07c9b6de56eb09c892fd33c2bfcca060.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07c9b6de56eb09c892fd33c2bfcca060.png)'
- en: '**[source](http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html)**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**[来源](http://scikit-learn.org/stable/auto_examples/ensemble/plot_partial_dependence.html)**'
- en: 'But, the problem with these plots is that they are created using a trained
    model. If we could create these plots from train data directly, it could help
    us understand the underlying data better. In fact, it can help you with all the
    following things:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些图的问题在于它们是使用训练模型创建的。如果我们能够直接从训练数据创建这些图，它将有助于我们更好地理解基础数据。实际上，它可以帮助你完成以下所有任务：
- en: Feature understanding
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征理解
- en: Identifying noisy features (**the most interesting part!**)
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别噪声特征 (**最有趣的部分！**)
- en: Feature engineering
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征工程
- en: Feature importance
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征重要性
- en: Feature debugging
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征调试
- en: Leakage detection and understanding
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 泄漏检测和理解
- en: Model monitoring
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型监控
- en: In order to make it easily accessible, I decided to put these techniques into
    a python package [featexp](https://github.com/abhayspawar/featexp) and in this
    article, we’ll see how it can be used for feature exploration. We’ll use the application
    dataset from [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/) competition
    on Kaggle. The task of the competition is to predict defaulters using the data
    given about them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其易于访问，我决定将这些技术放入 Python 包 [featexp](https://github.com/abhayspawar/featexp)，在本文中，我们将看看如何使用它进行特征探索。我们将使用
    Kaggle 上的 [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/)
    竞赛的应用数据集。该竞赛的任务是使用提供的数据预测违约者。
- en: '**Feature Understanding**'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征理解**'
- en: '![](../Images/ea624a802c8f342df8575ad80e83098b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea624a802c8f342df8575ad80e83098b.png)'
- en: '**Scatter plot of feature vs. target doesn’t help**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征与目标的散点图无帮助**'
- en: If dependent variable (target) is binary, scatter plots don’t work because all
    points lie either at 0 or 1\. For continuous target, too many data points make
    it difficult to understand the target vs. feature trend. Featexp creates better
    plots which help with this problem. Let’s try it out!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果因变量（目标）是二值的，散点图就不起作用，因为所有点要么在 0，要么在 1。对于连续目标，数据点过多会使理解目标与特征的趋势变得困难。Featexp
    创建了更好的图表来帮助解决这个问题。我们来试试吧！
- en: '![](../Images/4f370ec9c6877ce1c858a553c8cd5f6a.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f370ec9c6877ce1c858a553c8cd5f6a.png)'
- en: '**Feature vs. target plot of DAYS_BIRTH (age)**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**DAYS_BIRTH（年龄）的特征与目标图**'
- en: Featexp creates equal population bins (X-axis) of a numeric feature. It then
    calculates target’s mean in each bin and plots it in the left-hand side plot above.
    In our case, target’s mean is nothing but default rate. The plot tells us that
    customers with high negative values for DAYS_BIRTH (higher age) have lower default
    rates. This makes sense since younger people are usually more likely to default.
    These plots help us understand what the feature is telling about customers and
    how it will affect the model. The plot on the right shows number of customers
    in each bin.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Featexp 创建了一个数值特征的等人口区间（X 轴）。然后计算每个区间的目标均值，并将其绘制在上面的左侧图中。在我们的例子中，目标均值就是违约率。图表告诉我们，高负值的
    DAYS_BIRTH（较大年龄）的客户违约率较低。这是合理的，因为年轻人通常更容易违约。这些图表帮助我们了解特征对客户的影响以及它如何影响模型。右侧的图表显示了每个区间的客户数量。
- en: '**Identifying noisy features**'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**识别噪声特征**'
- en: Noisy features lead to overfitting and identifying them isn’t easy. In featexp,
    you can pass a test set and compare feature trends in train/test to identify noisy
    ones. This test set is not the actual test set. Its your local test set/validation
    set for which you know target.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声特征会导致过拟合，识别这些特征并不容易。在 featexp 中，你可以传递一个测试集，并比较训练集/测试集中的特征趋势以识别噪声特征。这个测试集不是实际的测试集，而是你的本地测试集/验证集，你对其目标是知道的。
- en: '![](../Images/351dde6ae8bc3e0a98dacd8ce5f3f4e2.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/351dde6ae8bc3e0a98dacd8ce5f3f4e2.png)'
- en: '**Comparison of feature trends in train and test**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练集和测试集中的特征趋势比较**'
- en: 'Featexp calculates two metrics to display on these plots which help with gauging
    noisiness:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Featexp 计算两个指标以显示在这些图表上，这有助于评估噪声。
- en: '**Trend correlation**(seen in test plot): If a feature doesn’t hold same trend
    w.r.t. target across train and evaluation sets, it can lead to overfitting. This
    happens because the model is learning something which is not applicable in test
    data. Trend correlation helps understand how similar train/test trends are and
    mean target values for bins in train & test are used to calculate it. Feature
    above has 99% correlation. Doesn’t seem noisy!'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**趋势相关性**（在测试图中看到）：如果一个特征在训练集和评估集中的趋势不同，则可能导致过拟合。这是因为模型正在学习一些在测试数据中不适用的内容。趋势相关性有助于理解训练/测试趋势的相似程度，计算时使用训练集和测试集中区间的目标均值。上述特征的相关性为
    99%。看起来不噪声！'
- en: '**Trend changes**: Sudden and repeated changes in trend direction could imply
    noisiness. But, such trend change can also happen because that bin has a very
    different population in terms of other features and hence, its default rate can’t
    really be compared with other bins.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**趋势变化**：趋势方向的突然和重复变化可能暗示噪声。但这种趋势变化也可能发生，因为该区间在其他特征方面有很大不同，因此其默认率无法与其他区间进行比较。'
- en: Feature below is not holding the same trend and hence, has a low trend correlation
    of 85%. These two metrics can be used to drop noisy features.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下述特征没有保持相同的趋势，因此其趋势相关性较低，为 85%。这两个指标可以用来去掉噪声特征。
- en: '![](../Images/83ad33aa0de9f5870280829884569f80.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83ad33aa0de9f5870280829884569f80.png)'
- en: Example of noisy feature
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声特征示例
- en: Dropping low trend-correlation features works well when there are a lot of features
    and they are correlated with each other. It leads to less overfitting and other
    correlated features avoid information loss. It’s also important to not drop too
    many important features as it might lead to a drop in performance. **Also, you
    can’t identify these noisy features using feature importance because they could
    be fairly important and still be very noisy!**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征数量较多且它们彼此相关时，去掉低趋势相关性的特征效果很好。这样可以减少过拟合，其他相关特征可以避免信息丢失。同时，也要注意不要去掉过多重要特征，否则可能会导致性能下降。**此外，你不能仅通过特征重要性来识别这些噪声特征，因为它们可能非常重要，但仍然非常嘈杂！**
- en: Using test data from a different time period works better because then you would
    be making sure if feature trend holds over time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同时间段的测试数据效果更好，因为这样你可以确保特征趋势随时间保持一致。
- en: '***get_trend_stats()***function in featexp returns a dataframe with trend correlation
    and changes for each feature.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '***get_trend_stats()***函数在featexp中返回一个包含每个特征趋势相关性和变化的数据框。'
- en: '![](../Images/d3de62250fd43f434c6f248afa3dda3f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3de62250fd43f434c6f248afa3dda3f.png)'
- en: '**Dataframe returned by get_trend_stats()**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**get_trend_stats()返回的数据框**'
- en: Let’s actually try dropping features with low trend-correlation in our data
    and see how results improve.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实际尝试在数据中丢弃趋势相关性低的特征，看看结果是否有所改善。
- en: '![](../Images/2e5ecf19c6de1dc2da562afc954c2ea4.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e5ecf19c6de1dc2da562afc954c2ea4.png)'
- en: '**AUC for different feature selections using trend-correlation**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**不同特征选择下的AUC与趋势相关性**'
- en: '**We can see that higher the trend-correlation threshold to drop features,
    higher is the leaderboard (LB) AUC.** Not dropping important features further
    improves LB AUC to 0.74\. It’s also interesting and concerning that test AUC doesn’t
    change as much as LB AUC. Getting your validation strategy right such that local
    test AUC follows LB AUC is also important. Whole code can be found in [featexp_demo](https://github.com/abhayspawar/featexp/blob/master/featexp_demo.ipynb) notebook.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们可以看到，丢弃特征的趋势相关性阈值越高，排行榜（LB）AUC越高。** 不丢弃重要特征可以进一步提高LB AUC到0.74。值得注意且令人担忧的是测试AUC没有像LB
    AUC那样变化。确保验证策略正确，使得本地测试AUC跟随LB AUC也很重要。完整代码可以在[featexp_demo](https://github.com/abhayspawar/featexp/blob/master/featexp_demo.ipynb)笔记本中找到。'
- en: '**Feature Engineering**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征工程**'
- en: 'The insights that you get by looking at these plots help with creating better
    features. Just having a better understanding of data can lead to better feature
    engineering. But, in addition to this, it can also help you in improving the existing
    features. Let’s look at another feature EXT_SOURCE_1:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看这些图，你可以获得创建更好特征的洞见。对数据有更好的理解可以导致更好的特征工程。但除此之外，它还可以帮助你改进现有特征。让我们再看一个特征EXT_SOURCE_1：
- en: '![](../Images/92d9594de93911d7327e963c608c014d.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92d9594de93911d7327e963c608c014d.png)'
- en: '**Feature vs. target plot of EXT_SOURCE_1**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**EXT_SOURCE_1的特征与目标关系图**'
- en: Customers having a high value of EXT_SOURCE_1 have low default rates. But, the
    first bin (~8% default rate) isn’t following the feature trend (goes up and then
    down). It has only negative values around -99.985 and a large population. This
    probably implies that these are special values and hence, don’t follow the feature
    trend. Fortunately, non-linear models won’t have a problem learning this relationship.
    But, for linear models like logistic regression, such special values and nulls
    (which will be shown as a separate bin) should be imputed with a value from a
    bin with similar default rate instead of simply imputing with feature mean.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 具有高EXT_SOURCE_1值的客户违约率较低。但，第一个区间（~8%的违约率）并没有跟随特征趋势（先上升再下降）。这个区间只有-99.985左右的负值和一个大的人口基数。这可能意味着这些是特殊值，因此不符合特征趋势。幸运的是，非线性模型在学习这种关系时不会有问题。但是，对于像逻辑回归这样的线性模型，这些特殊值和空值（将作为单独的区间显示）应该用具有类似违约率的区间的值进行填补，而不是简单地用特征均值填补。
- en: '**Feature importance**'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征重要性**'
- en: Featexp also helps you with gauging feature importance. DAYS_BIRTH and EXT_SOURCE_1
    both have a good trend. But, population for EXT_SOURCE_1 is concentrated in special
    value bin implying that feature has the same information for most of the customers
    and hence, can’t differentiate them well. This tells that it might not be as important
    as DAYS_BIRTH. Based on XGBoost model’s feature importance, DAYS_BIRTH is actually
    more important than EXT_SOURCE_1.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Featexp还可以帮助你评估特征的重要性。DAYS_BIRTH和EXT_SOURCE_1都有较好的趋势。然而，EXT_SOURCE_1的人口集中在特殊值区间，意味着该特征对大多数客户的信息相同，因此不能很好地区分他们。这表明它可能没有DAYS_BIRTH重要。根据XGBoost模型的特征重要性，DAYS_BIRTH实际上比EXT_SOURCE_1更重要。
- en: '**Feature debugging**'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征调试**'
- en: 'Looking at Featexp’s plots helps you in capturing bugs in complex feature engineering
    codes by doing these two things:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Featexp的图可以帮助你通过以下两种方式捕捉复杂特征工程代码中的错误：
- en: '![](../Images/427300b93d98d42509f93614b0ea11f4.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/427300b93d98d42509f93614b0ea11f4.png)'
- en: '**Zero variation features show only a single bin**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**零变异特征只显示一个区间**'
- en: Checking if the feature’s population distribution looks right. I’ve personally
    encountered extreme cases like above numerous times due to minor bugs.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查特征的总体分布是否正常。我个人因为一些小错误多次遇到类似上图的极端情况。
- en: Always hypothesize what the feature trend will look like before looking at these
    plots. Feature trend not looking like what you expected might hint towards some
    problem. **And frankly, this process of hypothesizing trends makes building ML
    models much more fun!**
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查看这些图表之前，始终假设特征趋势会是什么样的。特征趋势看起来与预期不符可能暗示某些问题。**坦率地说，假设趋势的过程使得构建机器学习模型变得更加有趣！**
- en: '**Leakage Detection**'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**泄漏检测**'
- en: Data leakage from target to features leads to overfitting. Leaky features have
    high feature importance. But, understanding why leakage is happening in a feature
    is difficult. Looking at featexp plots can help you with that.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 目标到特征的数据泄漏会导致过拟合。泄漏特征具有较高的特征重要性。然而，理解特征泄漏的原因是困难的。查看 featexp 图表可以帮助你解决这个问题。
- en: The feature below has 0% default rate in ‘Nulls’ bin and 100% in all other bins.
    Clearly, this is an extreme case of leakage. This feature has a value only when
    the customer has defaulted. Based on what the feature is, this could be because
    of a bug or the feature is actually populated only for defaulters (in which case
    it should be dropped). **Knowing what the problem is with leaky feature leads
    to quicker debugging.**
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的特征在‘空值’分箱中的违约率为 0%，在所有其他分箱中的违约率为 100%。显然，这是泄漏的极端案例。该特征仅在客户违约时有值。根据特征的性质，这可能是由于错误，或者该特征仅为违约者填充（在这种情况下应删除）。**了解泄漏特征的问题有助于更快地进行调试。**
- en: '![](../Images/253799c3124bc342cdd142d4037a4b0d.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/253799c3124bc342cdd142d4037a4b0d.png)'
- en: '**Understanding why a feature is leaky**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**理解特征为何会泄漏**'
- en: '**Model Monitoring**'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型监控**'
- en: Since featexp calculates trend correlation between two data sets, it can be
    easily used for model monitoring. Every time the model is re-trained, the new
    train data can be compared with a well-tested train data (typically train data
    from the first time you built the model). Trend correlation can help you monitor
    if anything has changed in feature w.r.t. its relationship with target.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 featexp 计算了两个数据集之间的趋势相关性，因此可以轻松用于模型监控。每次模型重新训练时，可以将新的训练数据与经过充分测试的训练数据进行比较（通常是第一次构建模型时的训练数据）。趋势相关性可以帮助你监控特征与目标之间的关系是否发生了变化。
- en: Doing these simple things have always helped me in building better models in
    real life and on kaggle. With featexp it takes 15 minutes to look at these plots
    and it’s definitely worth it as you won’t be flying blind after that.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些简单的操作一直帮助我在实际生活中和在 Kaggle 上构建更好的模型。使用 featexp 只需 15 分钟就能查看这些图表，这绝对值得，因为你在此之后不会盲目操作。
- en: '**Bio**: [Abhay Pawar](https://www.linkedin.com/in/abhayspawar/) currently
    works as a Senior Machine Learning Engineer at Instacart, in their Search & Discovery
    team. He works on large scale machine learning problems which help Instacart in
    improving the quality of their service.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介**： [Abhay Pawar](https://www.linkedin.com/in/abhayspawar/) 目前在 Instacart
    担任高级机器学习工程师，隶属于搜索与发现团队。他处理大规模机器学习问题，帮助 Instacart 提升服务质量。'
- en: '[Original](https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c).
    Reposted with permission.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c)。经许可转载。'
- en: '**Resources:**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[How many data scientists are there and is there a shortage?](https://www.kdnuggets.com/2018/09/how-many-data-scientists-are-there.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家有多少？是否存在短缺？](https://www.kdnuggets.com/2018/09/how-many-data-scientists-are-there.html)'
- en: '[An Introduction to Deep Learning for Tabular Data](https://www.kdnuggets.com/2018/05/introduction-deep-learning-tabular-data.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[表格数据深度学习简介](https://www.kdnuggets.com/2018/05/introduction-deep-learning-tabular-data.html)'
- en: '[To Kaggle Or Not](https://www.kdnuggets.com/2018/05/to-kaggle-or-not.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[去 Kaggle 还是不去](https://www.kdnuggets.com/2018/05/to-kaggle-or-not.html)'
- en: More On This Topic
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用 LLMOps：无缝交互的秘诀](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)'
- en: '[GPT-4: 8 Models in One; The Secret is Out](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT-4：一体化的8种模型；秘密已揭晓](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
- en: '[HuggingGPT: The Secret Weapon to Solve Complex AI Tasks](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingGPT：解决复杂AI任务的秘密武器](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)'
- en: '[Top 4 tricks for competing on Kaggle and why you should start](https://www.kdnuggets.com/2022/05/packt-top-4-tricks-competing-kaggle-start.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Kaggle竞争的四大技巧及为何你应立即开始](https://www.kdnuggets.com/2022/05/packt-top-4-tricks-competing-kaggle-start.html)'
- en: '[Top 10 Kaggle Machine Learning Projects to Become Data Scientist in 2024](https://www.kdnuggets.com/top-10-kaggle-machine-learning-projects-to-become-data-scientist-in-2024)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2024年成为数据科学家的10个Kaggle机器学习项目](https://www.kdnuggets.com/top-10-kaggle-machine-learning-projects-to-become-data-scientist-in-2024)'
- en: '[The Most Comprehensive List of Kaggle Solutions and Ideas](https://www.kdnuggets.com/2022/11/comprehensive-list-kaggle-solutions-ideas.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最全面的Kaggle解决方案和创意列表](https://www.kdnuggets.com/2022/11/comprehensive-list-kaggle-solutions-ideas.html)'
