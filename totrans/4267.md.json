["```py\nimport pandas as pd\nimport regex\nfrom gensim.utils import simple_preprocess\nfrom nltk.corpus import stopwords\nEMAIL_REGEX_STR = '\\S*@\\S*'\nMENTION_REGEX_STR = '@\\S*'\nHASHTAG_REGEX_STR = '#\\S+'\nURL_REGEX_STR = r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*'\ndef denoise_docs(texts_df: pd.DataFrame, text_column: str):\n    texts = texts_df[text_column].values.tolist()\n    remove_regex = regex.compile(f'({EMAIL_REGEX_STR}|{MENTION_REGEX_STR}|{HASHTAG_REGEX_STR}|{URL_REGEX_STR})')\n    texts = [regex.sub(remove_regex, '', text) for text in texts]\n    docs = [[w for w in simple_preprocess(doc, deacc=True) if w not in stopwords.words('english')] for doc in texts]\n    return docs \n```", "```py\nimport pandas as pd\nimport spacy\ndef generate_docs(texts_df: pd.DataFrame, text_column: str, ngrams: str = None):\n    docs = denoise_docs(texts_df, text_column)\n\n    # bigram / trigam preprocessing ...\n\n    lemmantized_docs = []\n    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n    for doc in docs:\n        doc = nlp(' '.join(doc))\n        lemmantized_docs.append([token.lemma_ for token in doc])\n\n    return lemmantized_docs \n```", "```py\nimport gensim\nfrom gensim import corpora\ndef prepare_training_data(docs):\n    id2word = corpora.Dictionary(docs)\n    corpus = [id2word.doc2bow(doc) for doc in docs]\n    return id2word, corpus\ndef train_model(docs, num_topics: int = 10, per_word_topics: bool = True):\n    id2word, corpus = prepare_training_data(docs)\n    model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, per_word_topics=per_word_topics)\n    return model \n```", "```py\nfrom wordcloud import WordCloud\nWORDCLOUD_FONT_PATH = r'./data/Inkfree.ttf'\ndef generate_wordcloud(docs, collocations: bool = False):\n    wordcloud_text = (' '.join(' '.join(doc) for doc in docs))\n    wordcloud = WordCloud(font_path=WORDCLOUD_FONT_PATH, width=700, height=600, background_color='white', collocations=collocations).generate(wordcloud_text)\n    return wordcloud \n```", "```py\nst.subheader('Top N Topic Keywords Wordclouds')\ntopics = model.show_topics(formatted=False, num_topics=num_topics)\ncols = st.beta_columns(3)\ncolors = random.sample(COLORS, k=len(topics))\nfor index, topic in enumerate(topics):\n    wc = WordCloud(font_path=WORDCLOUD_FONT_PATH, width=700, height=600, background_color='white', collocations=collocations, prefer_horizontal=1.0, color_func=lambda *args, **kwargs: colors[index])\n    with cols[index % 3]:\n        wc.generate_from_frequencies(dict(topic[1]))\n        st.image(wc.to_image(), caption=f'Topic #{index}', use_column_width=True) \n```"]