- en: 'Neural Code Search: How Facebook Uses Neural Networks to Help Developers Search
    for Code Snippets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经代码搜索：Facebook 如何利用神经网络帮助开发者搜索代码片段
- en: 原文：[https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html](https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html](https://www.kdnuggets.com/2019/07/neural-code-facebook-uses-neural-networks.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![](../Images/080a800f2e408eaeed765a38fd92c8bb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/080a800f2e408eaeed765a38fd92c8bb.png)'
- en: Google and StackOverflow are every developer’s best friend these days. When
    working on a specific project, developers constantly resort to external sources
    of information to find solutions or code snippets to a given problem. However,
    the search resolution is mostly based on metadata and not in the information provided
    by the code itself. For instance, if a developer posts a code snippet to StackOverflow,
    it will typically include a description and tags that help to index it for future
    searches. This approach relies on the accuracy of that metadata in order to render
    accurate search results, but it also misses information that can be inferred directly
    from the code. To address this limitation, a team from Facebook AI Research (FAIR)
    has been working on an approach to use natural language processing (NLP) and information
    retrieval (IR) to infer search-relevant information directly from the source code
    text.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Google和StackOverflow是每个开发者的好帮手。在进行特定项目时，开发者经常借助外部信息源来寻找解决方案或代码片段。然而，搜索结果大多基于元数据，而不是代码本身提供的信息。例如，如果开发者在StackOverflow上发布了一个代码片段，它通常会包含描述和标签，以帮助对其进行索引以备将来搜索。这种方法依赖于这些元数据的准确性以呈现准确的搜索结果，但也遗漏了可以直接从代码中推断的信息。为了应对这一限制，Facebook
    AI Research（FAIR）团队一直在研究一种方法，利用自然语言处理（NLP）和信息检索（IR）直接从源代码文本中推断搜索相关信息。
- en: 'The first materialization of the FAIR team efforts is a tool called Neural
    Code Search (NCS) which accepts a natural language query and returns results inferred
    directly from the code corpus. The techniques behind NCS were summarized in two
    research papers recently published:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: FAIR团队努力的首次实现是一个名为神经代码搜索（NCS）的工具，它接受自然语言查询，并直接从代码语料库中推断结果。NCS背后的技术在最近发表的两篇研究论文中进行了总结：
- en: '[**NCS**](https://dl.acm.org/citation.cfm?id=3211353&fbclid=IwAR3qdp2vDXwBuZb7uw2vR1op7SPngnRr0R6l3pxHrvqWH_0Unj0UXtTYpKA)**: **This
    paper describes a technique that uses an unsupervised model that combines NLP
    and IR techniques.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**NCS**](https://dl.acm.org/citation.cfm?id=3211353&fbclid=IwAR3qdp2vDXwBuZb7uw2vR1op7SPngnRr0R6l3pxHrvqWH_0Unj0UXtTYpKA)**: **本文描述了一种使用无监督模型结合NLP和IR技术的技术。**'
- en: '[**UNIF**](https://arxiv.org/pdf/1905.03813.pdf?fbclid=IwAR3_9ejBpho2yNLfMKVCp5rZ58gAD63T_peTg3RQh8tIRLZkYwH9SquLQI8)**: **This
    paper proposes an extension of NCS that uses a supervised neural network model
    to improve performance when good supervision data is available for training.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**UNIF**](https://arxiv.org/pdf/1905.03813.pdf?fbclid=IwAR3_9ejBpho2yNLfMKVCp5rZ58gAD63T_peTg3RQh8tIRLZkYwH9SquLQI8)**: **本文提出了一种NCS的扩展，使用有监督神经网络模型来改善在训练中有良好监督数据时的性能。**'
- en: The principles behind both techniques, NCS and UNIF, is relatively similar.
    Both methods rely on vector representations of code snippets, which can be used
    to train a model such as semantically similar code snippets, and queries are close
    together in the vector space. This technique is able to answer natural language
    queries directly using the code snippets corpus without relying on external metadata.
    Although both techniques (NCS, UNIF) are relatively similar, UNIF extends NCS
    with a supervised model to create even more accurate answers to NLP queries.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: NCS和UNIF这两种技术背后的原理相对类似。这两种方法都依赖于代码片段的向量表示，这可以用于训练模型，比如语义相似的代码片段，并且在向量空间中查询是接近的。这项技术能够直接使用代码片段语料库回答自然语言查询，而无需依赖外部元数据。尽管这两种技术（NCS、UNIF）相对类似，UNIF通过有监督模型扩展NCS，以创建更准确的NLP查询答案。
- en: NCS
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NCS
- en: The core principle behind is to use embeddings to generate a vector representation
    from a code corpus in a way in which similar code snippets are close to each other
    in the vector space. In the example below, there are two distinct method bodies
    that both pertain to closing or hiding the Android soft keyboard (the first question
    above). Since they share similar semantic meanings, even if they do not share
    the exact same lines of code, they are represented by points in the vector space
    that are close to each other. NCS uses method-level granularity to embed every
    code snippet in the vector space.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其核心原则是使用嵌入从代码语料库生成向量表示，使得相似的代码片段在向量空间中彼此接近。在下面的示例中，有两个不同的方法体都涉及到关闭或隐藏 Android
    软键盘（上面的问题）。由于它们具有类似的语义，即使它们没有完全相同的代码行，它们在向量空间中的表示点也彼此接近。NCS 使用方法级粒度将每个代码片段嵌入到向量空间中。
- en: '![](../Images/697238c45896d8a3545d08028ae0dbf2.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/697238c45896d8a3545d08028ae0dbf2.png)'
- en: 'The process of creating the vector representation has three main steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 创建向量表示的过程有三个主要步骤：
- en: 1) Extracting Words
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 提取词汇
- en: 2) Build Word Embeddings
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 构建词嵌入
- en: 3) Build Document Embeddings
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 构建文档嵌入
- en: 4)Natural Language Search Retrieval
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 4) 自然语言搜索检索
- en: '![](../Images/89c413a0e256dc571ed6f13139d6fe9b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89c413a0e256dc571ed6f13139d6fe9b.png)'
- en: Give a specific code snippet, NCS extracts different syntactic sections such
    as method names, method invocations, enums, string literals, and comments. Those
    artifacts are then tokenized using standards English conventions. For each document
    in the input corpus, NCS tokenizes the source code in a manner that can learn
    an embedding for each word. After this step, the list of words we extracted for
    each method body resembles a natural language document.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个具体的代码片段，NCS 提取不同的语法部分，例如方法名称、方法调用、枚举、字符串字面量和注释。这些工件随后按照标准英语约定进行标记化。对于输入语料库中的每个文档，NCS
    以一种可以为每个单词学习嵌入的方式对源代码进行标记化。经过这一步后，我们为每个方法体提取的单词列表类似于自然语言文档。
- en: After the word extraction, NCS proceeds to build the word embeddings using the [FastText
    framework](https://fasttext.cc/). During this process, FastText computes vector
    representations using a two-layer dense neural network that can be trained unsupervised
    on a large corpus. More specifically, NCS uses the skip-gram model, where the
    embedding for a target token is used to predict embeddings of context tokens within
    a fixed window size.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在词汇提取之后，NCS 继续使用[FastText 框架](https://fasttext.cc/)构建词嵌入。在此过程中，FastText 使用一个两层的密集神经网络计算向量表示，该网络可以在大规模语料库上进行无监督训练。更具体地说，NCS
    使用 skip-gram 模型，其中目标标记的嵌入用于预测固定窗口大小内上下文标记的嵌入。
- en: The final step of this phase is to express the general intent of a method body
    using the extracted word embeddings. NCS achieves that by calculating a weighted
    average of the word embedding vectors for the set of words in the method body.
    The result of this formula is known as a document embedding and is used to create
    an index of each method in the body for effective search retrieval.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的最后一步是使用提取的词嵌入来表达方法体的一般意图。NCS 通过计算方法体中单词集合的词嵌入向量的加权平均值来实现这一点。该公式的结果被称为文档嵌入，并用于创建每个方法的索引，以便进行有效的搜索检索。
- en: Using a vector representation as a starting point, NCS can now try to answer
    natural language queries related to code snippets. Given a natural language query,
    NCS follows a similar tokenization process using the FastText framework. Using
    the same FastText embedding matrix, NCS averages the vector representations of
    words to create a document embedding for the query sentence; out-of-vocab words
    are dropped. NCS then uses a standard similarity search algorithm, [FAISS](https://github.com/facebookresearch/faiss),
    to find the document vectors with closest cosine distance to the query.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用向量表示作为起点，NCS 现在可以尝试回答与代码片段相关的自然语言查询。给定自然语言查询，NCS 使用 FastText 框架进行类似的标记化处理。使用相同的
    FastText 嵌入矩阵，NCS 平均化单词的向量表示，以创建查询句子的文档嵌入；超出词汇表的词被丢弃。然后，NCS 使用标准相似性搜索算法[FAISS](https://github.com/facebookresearch/faiss)找到与查询具有最接近余弦距离的文档向量。
- en: '![](../Images/4a1ffb905908fccc1f398da3fc34dc74.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a1ffb905908fccc1f398da3fc34dc74.png)'
- en: UNIF
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UNIF
- en: As an unsupervised technique, NCS has the advantage that it can build knowledge
    directly from the code corpus in a quick and easy manner. However, one of the
    main limitations of NCS is that the model implicitly assumes that the words in
    the query come from the same domain as the words extracted from source code, as
    the queries and the code snippets are both mapped to the same vector space. However,
    there are plenty of examples in which a code corpus does not convey any relevant
    semantic information. Take the example below of a code snippet that obtains available
    blocks in a memory space. Just by generating the word embeddings in an unsupervised
    way, NCS won’t be able to match relevant queries such as “Get free space on internal
    memory”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种无监督技术，NCS 的优势在于它可以通过快速简便的方式直接从代码语料库中构建知识。然而，NCS 的主要限制之一是模型隐含地假设查询中的单词来自与源代码提取的单词相同的领域，因为查询和代码片段都映射到相同的向量空间。然而，许多代码语料库并不传达任何相关的语义信息。以下是一个代码片段的例子，该片段获取内存空间中的可用块。仅通过无监督地生成词嵌入，NCS
    无法匹配诸如“获取内部内存上的空闲空间”这样的相关查询。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: UNIF is a supervised extension to NCS that attempts to bridge the gap between
    natural language words and source code words. Essentially, UNIF uses supervised
    learning to modify the initial token embedding matrix T and produce two embedding
    matrices, Tc and Tq, for code and query tokens, respectively. We also replace
    the TF-IDF weighing of code token embeddings with a learned attention-based weighing
    scheme. This twist essentially accounts for some of the semantic mismatches in
    code corpus.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: UNIF 是对 NCS 的监督扩展，试图弥合自然语言单词与源代码单词之间的差距。本质上，UNIF 使用监督学习来修改初始的 token 嵌入矩阵 T，并分别为代码和查询
    token 生成两个嵌入矩阵 Tc 和 Tq。我们还用基于学习的注意力加权方案替换了代码 token 嵌入的 TF-IDF 权重。这一变动基本上考虑了代码语料库中的一些语义不匹配。
- en: '![](../Images/700f1ec76d6696dfe81212b8b3b9ece1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/700f1ec76d6696dfe81212b8b3b9ece1.png)'
- en: NCS and UNIF in Action
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NCS 和 UNIF 的应用
- en: The FAIR team evaluates both NCS and UNIF against state-of-the-art information
    retrieval models. Using a starting dataset of StackOverflow questions, NCS was
    able to outperform the popular BM25 model across a diverse series of tasks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: FAIR 团队将 NCS 和 UNIF 与最先进的信息检索模型进行了评估。使用 StackOverflow 问题的数据集，NCS 能够在各种任务中超越流行的
    BM25 模型。
- en: '![](../Images/a8d58432722c936eff7184903b511cae.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8d58432722c936eff7184903b511cae.png)'
- en: Similarly, adding the UNIF extension showed incremental improvements in the
    NCS performance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，添加 UNIF 扩展显示了 NCS 性能的渐进改进。
- en: '![](../Images/5189a0560330e460c9f8d40e98251857.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5189a0560330e460c9f8d40e98251857.png)'
- en: Both NCS and UNIF present a clever and yet simple-to-implement approach for
    information retrieval. Starting with code search is a trivial way to deliver immediate
    value, but the ideas behind NCS and UNIF are applicable to many neural search
    and information retrieval scenarios.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: NCS 和 UNIF 都提供了一种巧妙且易于实现的信息检索方法。从代码搜索开始是提供即时价值的一种简单方式，但 NCS 和 UNIF 背后的理念适用于许多神经搜索和信息检索场景。
- en: '[Original](https://towardsdatascience.com/neural-code-search-how-facebook-uses-neural-networks-to-help-developers-search-for-code-snippets-9db9e0090780).
    Reposted with permission.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/neural-code-search-how-facebook-uses-neural-networks-to-help-developers-search-for-code-snippets-9db9e0090780)。已获转载许可。'
- en: '**Related:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Your Guide to Natural Language Processing (NLP)](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你的自然语言处理 (NLP) 指南](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
- en: '[Extracting Knowledge from Knowledge Graphs Using Facebook’s Pytorch-BigGraph](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从知识图谱中提取知识，使用 Facebook 的 Pytorch-BigGraph](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
- en: '[Natural Language Processing Key Terms, Explained](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理关键术语，解释](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT领域'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关话题
- en: '[Low Code: Are Developers Still Needed?](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[低代码：开发者仍然需要吗？](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)'
- en: '[How LinkedIn Uses Machine Learning To Rank Your Feed](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[领英如何使用机器学习来排序你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
- en: '[Top Programming Languages and Their Uses](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级编程语言及其用途](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
- en: '[KDnuggets™ News 22:n04, Jan 26: The High Paying Side Hustles…](https://www.kdnuggets.com/2022/n04.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™新闻22:n04，1月26日：高薪兼职…](https://www.kdnuggets.com/2022/n04.html)'
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，11月16日：领英如何使用机器学习 •…](https://www.kdnuggets.com/2022/n45.html)'
- en: '[3 Interesting Uses of Python''s Context Managers](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python上下文管理器的3个有趣用途](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
