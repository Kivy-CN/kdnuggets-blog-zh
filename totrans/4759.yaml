- en: Multi-Class Text Classification Model Comparison and Selection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类别文本分类模型比较与选择
- en: 原文：[https://www.kdnuggets.com/2018/11/multi-class-text-classification-model-comparison-selection.html](https://www.kdnuggets.com/2018/11/multi-class-text-classification-model-comparison-selection.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/multi-class-text-classification-model-comparison-selection.html](https://www.kdnuggets.com/2018/11/multi-class-text-classification-model-comparison-selection.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/11/multi-class-text-classification-model-comparison-selection.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/11/multi-class-text-classification-model-comparison-selection.html?page=2#comments)'
- en: '**By [Susan Li](https://www.linkedin.com/in/susanli/), Sr. Data Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Susan Li](https://www.linkedin.com/in/susanli/), 高级数据科学家**'
- en: '![Image](../Images/9b64f7c1a5f857cb61411ba48d204dbb.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9b64f7c1a5f857cb61411ba48d204dbb.png)'
- en: 'Photo credit: Pixabay'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 照片来源：Pixabay
- en: When working on a [supervised machine learning](https://en.wikipedia.org/wiki/Supervised_learning) problem
    with a given data set, we try different algorithms and techniques to search for
    models to produce general hypotheses, which then make the most accurate predictions
    possible about future instances. The same principles apply to text (or document)
    classification where there are many models can be used to train a text classifier. [The
    answer to the question “What machine learning model should I use?” is always “It
    depends.” Even the most experienced data scientists can’t tell which algorithm
    will perform best before experimenting them](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理一个给定数据集的[有监督机器学习](https://en.wikipedia.org/wiki/Supervised_learning)问题时，我们尝试不同的算法和技术，寻找能生成通用假设的模型，从而对未来实例做出最准确的预测。相同的原则适用于文本（或文档）分类，其中可以使用许多模型来训练文本分类器。[对于“我应该使用哪个机器学习模型？”这个问题的答案始终是“这要看情况。”即使是经验最丰富的数据科学家也无法在实验之前确定哪个算法表现最佳](https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-choice)。
- en: 'This is what we are going to do today: use everything that we have presented
    about text classification in the previous articles (and more) and comparing between
    the text classification models we trained in order to choose the most accurate
    one for our problem.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们要做的是：利用我们在之前文章中介绍的关于文本分类的所有内容（以及更多），并比较我们训练的文本分类模型，以选择最准确的一个来解决我们的问题。
- en: The Data
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'We are using a relatively large data set of Stack Overflow questions and tags.
    The data is available in [Google BigQuery](https://bigquery.cloud.google.com/dataset/bigquery-public-data:stackoverflow),
    it is also publicly available at this Cloud Storage URL: [https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv](https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的是一个相对较大的Stack Overflow问题和标签数据集。数据可以在[Google BigQuery](https://bigquery.cloud.google.com/dataset/bigquery-public-data:stackoverflow)中获取，也可以通过这个Cloud
    Storage URL公开获取：[https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv](https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv)。
- en: Exploring the Data
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索数据
- en: '![](../Images/a5cabad690901acd935be6fd74d840d2.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5cabad690901acd935be6fd74d840d2.png)'
- en: Figure 1
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: '***10276752***'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '***10276752***'
- en: We have over 10 million words in the data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据中有超过1000万字。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/452d3fe88135ada3e259b741efa43955.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/452d3fe88135ada3e259b741efa43955.png)'
- en: Figure 2
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: The classes are very well balanced.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 类别非常均衡。
- en: We want to have a look a few post and tag pairs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想看看几个帖子和标签对。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/9be95e3d1a25f01dd32295fac28865e9.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9be95e3d1a25f01dd32295fac28865e9.png)'
- en: Figure 3
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图3
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/00beb827a9a27fc750727df3b6562c61.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00beb827a9a27fc750727df3b6562c61.png)'
- en: Figure 4
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图4
- en: As you can see, the texts need to be cleaned up.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，文本需要清理。
- en: Text Pre-processing
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本预处理
- en: The text cleaning techniques we have seen so far work very well in practice.
    Depending on the kind of texts you may encounter, it may be relevant to include
    more complex text cleaning steps. But keep in mind that the more steps we add,
    the longer the text cleaning will take.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们看到的文本清理技术在实践中效果很好。根据你可能遇到的文本类型，可能需要包括更复杂的文本清理步骤。但请记住，步骤越多，文本清理所需的时间就越长。
- en: For this particular data set, our text cleaning step includes HTML decoding,
    remove stop words, change text to lower case, remove punctuation, remove bad characters,
    and so on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的数据集，我们的文本清理步骤包括HTML解码、去除停用词、将文本转换为小写、去除标点符号、删除坏字符等。
- en: 'Now we can have a look a cleaned post:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看看清理后的帖子：
- en: '![](../Images/dec6390974584bf90a0941482a627b0c.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dec6390974584bf90a0941482a627b0c.png)'
- en: Figure 5
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: Way better!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 好得多了！
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***3421180***'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '***3421180***'
- en: After text cleaning and removing stop words, we have only over 3 million words
    to work with!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本清理和去除停用词之后，我们只有超过300万个词汇可供使用！
- en: After splitting the data set, the next steps includes feature engineering. We
    will convert our text documents to a matrix of token counts (CountVectorizer),
    then transform a count matrix to a normalized tf-idf representation (tf-idf transformer).
    After that, we train several classifiers from [Scikit-Learn library](http://scikit-learn.org/stable/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在拆分数据集之后，下一步包括特征工程。我们将把文本文档转换为词频矩阵（CountVectorizer），然后将词频矩阵转换为标准化的tf-idf表示（tf-idf
    transformer）。之后，我们将从[Scikit-Learn库](http://scikit-learn.org/stable/)中训练几个分类器。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Naive Bayes Classifier for Multinomial Models**'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**多项式模型的朴素贝叶斯分类器**'
- en: After we have our features, we can train a classifier to try to predict the
    tag of a post. We will start with a [Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) classifier,
    which provides a nice baseline for this task. `scikit-learn` includes several
    variants of this classifier; the one most suitable for text is the multinomial
    variant.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得特征之后，我们可以训练一个分类器来尝试预测帖子标签。我们将从一个[朴素贝叶斯](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)分类器开始，这为这个任务提供了一个很好的基线。`scikit-learn`包括几种这种分类器的变体；最适合文本的变体是多项式变体。
- en: To make the vectorizer => transformer => classifier easier to work with, we
    will use `Pipeline` class in Scilkit-Learn that behaves like a compound classifier.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使向量化器 => 转换器 => 分类器更易于使用，我们将使用`Pipeline`类，该类在Scikit-Learn中表现得像一个复合分类器。
- en: '![](../Images/c3a81dd575687d97955c8bea7f4b2346.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3a81dd575687d97955c8bea7f4b2346.png)'
- en: Figure 6
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6
- en: We achieved 74% accuracy.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们达到了74%的准确率。
- en: '**Linear Support Vector Machine**'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**线性支持向量机**'
- en: '[Linear Support Vector Machine](http://scikit-learn.org/stable/modules/svm.html#svm) is
    widely regarded as one of the best text classification algorithms.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[线性支持向量机](http://scikit-learn.org/stable/modules/svm.html#svm)被广泛认为是最好的文本分类算法之一。'
- en: '![](../Images/8a17b5a7232e05f83bf4c7e26052b9d4.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a17b5a7232e05f83bf4c7e26052b9d4.png)'
- en: Figure 7
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7
- en: We achieve a higher accuracy score of 79% which is 5% improvement over Naive
    Bayes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了79%的更高准确率，比朴素贝叶斯提高了5%。
- en: Logistic Regression
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is a simple and easy to understand classification algorithm,
    and Logistic regression can be easily generalized to multiple classes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种简单且易于理解的分类算法，并且逻辑回归可以很容易地推广到多类分类问题。
- en: '![](../Images/d7389cf061c3db22f58eda8311724fd2.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7389cf061c3db22f58eda8311724fd2.png)'
- en: Figure 8
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8
- en: We achieve an accuracy score of 78% which is 4% higher than Naive Bayes and
    1% lower than SVM.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了78%的准确率，比朴素贝叶斯高4%，比SVM低1%。
- en: As you can see, following some very basic steps and using a simple linear model,
    we were able to reach as high as an 79% accuracy on this multi-class text classification
    data set.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，通过一些非常基本的步骤和使用简单的线性模型，我们能够在这个多类文本分类数据集上达到79%的准确率。
- en: Using the same data set, we are going to try some advanced techniques such as
    word embedding and neural networks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的数据集，我们将尝试一些高级技术，如词嵌入和神经网络。
- en: Now, let’s try some complex features than just simply counting words.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试一些比简单计数单词更复杂的特征。
- en: '* * *'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织IT'
- en: '* * *'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[A Comparison of Machine Learning Algorithms in Python and R](https://www.kdnuggets.com/2023/06/machine-learning-algorithms-python-r.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python和R中的机器学习算法比较](https://www.kdnuggets.com/2023/06/machine-learning-algorithms-python-r.html)'
- en: '[Linear Regression Model Selection: Balancing Simplicity and Complexity](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归模型选择：平衡简洁性与复杂性](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)'
- en: '[What is Text Classification?](https://www.kdnuggets.com/2022/07/text-classification.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是文本分类？](https://www.kdnuggets.com/2022/07/text-classification.html)'
- en: '[Best Architecture for Your Text Classification Task: Benchmarking…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适用于你的文本分类任务的最佳架构：基准测试…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
- en: '[ChatGPT vs Google Bard: A Comparison of the Technical Differences](https://www.kdnuggets.com/2023/03/chatgpt-google-bard-comparison-technical-differences.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 与 Google Bard：技术差异的比较](https://www.kdnuggets.com/2023/03/chatgpt-google-bard-comparison-technical-differences.html)'
- en: '[A Deep Dive into GPT Models: Evolution & Performance Comparison](https://www.kdnuggets.com/2023/05/deep-dive-gpt-models.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深入了解 GPT 模型：演变与性能比较](https://www.kdnuggets.com/2023/05/deep-dive-gpt-models.html)'
