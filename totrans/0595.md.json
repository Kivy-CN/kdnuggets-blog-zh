["```py\n!git clone https://github.com/IDEA-Research/GroundingDINO.git\n%cd GroundingDINO\n!git checkout -q 57535c5a79791cb76e36fdb64975271354f10251\n!pip install -q -e . \n```", "```py\n!pip uninstall -y supervision\n!pip install -q supervision==0.6.0\n\nimport supervision as svn\nprint(svn.__version__) \n```", "```py\nimport os\n\nGROUNDING_DINO_CONFIG_PATH = os.path.join(\"groundingdino/config/GroundingDINO_SwinT_OGC.py\")\nprint(GROUNDING_DINO_CONFIG_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CONFIG_PATH))\n!mkdir -p weights\n%cd weights\n\n!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\nimport os\n%cd /content/GroundingDINO\nGROUNDING_DINO_CHECKPOINT_PATH = os.path.join(\"weights/groundingdino_swint_ogc.pth\")\nprint(GROUNDING_DINO_CHECKPOINT_PATH, \"; exist:\", os.path.isfile(GROUNDING_DINO_CHECKPOINT_PATH)) \n```", "```py\nimport torch\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n```", "```py\nfrom groundingdino.util.inference import Model\n\ngrounding_dino_model = Model(model_config_path=GROUNDING_DINO_CONFIG_PATH, model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH)\n```", "```py\n!mkdir -p data \n```", "```py\nSOURCE_IMAGE_PATH = \"/content/GroundingDINO/data/example_image_3.png\"\nCLASSES = ['person','dog'] #add the class name to be labeled automatically\nBOX_TRESHOLD = 0.35\nTEXT_TRESHOLD = 0.15\n```", "```py\nfrom typing import List\n\ndef enhance_class_name(class_names: List[str]) -> List[str]:\n   return [\n       f\"all {class_name}s\"\n       for class_name\n       in class_names\n   ]\nimport cv2\nimport supervision as sv\n\n# load image\nimage = cv2.imread(SOURCE_IMAGE_PATH)\n\n# detect objects\ndetections = grounding_dino_model.predict_with_classes(\n   image=image,\n   classes=enhance_class_name(class_names=CLASSES),\n   box_threshold=BOX_TRESHOLD,\n   text_threshold=TEXT_TRESHOLD\n)\n\n# annotate image with detections\nbox_annotator = svn.BoxAnnotator()\nlabels = [\n   f\"{CLASSES[class_id]} {confidence:0.2f}\"\n   for _, _, confidence, class_id, _\n   in detections]\nannotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n\n%matplotlib inline\nsvn.plot_image(annotated_frame, (16, 16))\n```", "```py\nimport os\n\nIMAGES_DIRECTORY = \"./data\"\nIMAGES_EXTENSIONS = ['jpg', 'jpeg', 'png']\n\nCLASSES = ['person','dog]\nBOX_TRESHOLD = 0.35\nTEXT_TRESHOLD = 0.15\n```", "```py\nimport cv2\nfrom tqdm.notebook import tqdm\n\nimages = {}\nannotations = {}\n\nimage_paths = svn.list_files_with_extensions(\n   directory=IMAGES_DIRECTORY,\n   extensions=IMAGES_EXTENSIONS)\n\nfor image_path in tqdm(image_paths):\n   image_name = image_path.name\n   image_path = str(image_path)\n   image = cv2.imread(image_path)\n\n   detections = grounding_dino_model.predict_with_classes(\n       image=image,\n       classes=enhance_class_name(class_names=CLASSES),\n       box_threshold=BOX_TRESHOLD,\n       text_threshold=TEXT_TRESHOLD\n   )\n   detections = detections[detections.class_id != None]\n   images[image_name] = image\n   annotations[image_name] = detections\n```", "```py\nplot_images = []\nplot_titles = []\n\nbox_annotator = svn.BoxAnnotator()\nmask_annotator = svn.MaskAnnotator()\n\nfor image_name, detections in annotations.items():\n   image = images[image_name]\n   plot_images.append(image)\n   plot_titles.append(image_name)\n\n   labels = [\n       f\"{CLASSES[class_id]} {confidence:0.2f}\"\n       for _, _, confidence, class_id, _\n       in detections]\n   annotated_image = mask_annotator.annotate(scene=image.copy(), detections=detections)\n   annotated_image = box_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)\n   plot_images.append(annotated_image)\n   title = \" \".join(set([\n       CLASSES[class_id]\n       for class_id\n       in detections.class_id\n   ]))\n   plot_titles.append(title)\n\nsvn.plot_images_grid(\n   images=plot_images,\n   titles=plot_titles,\n   grid_size=(len(annotations), 2),\n   size=(2 * 4, len(annotations) * 4) \n```", "```py\n%cd /content/GroundingDINO\n!mkdir annotations\nANNOTATIONS_DIRECTORY = \"/content/GroundingDINO/annotations\"\n\nMIN_IMAGE_AREA_PERCENTAGE = 0.002\nMAX_IMAGE_AREA_PERCENTAGE = 0.80\nAPPROXIMATION_PERCENTAGE = 0.75\nsvn.Dataset(\n   classes=CLASSES,\n   images=images,\n   annotations=annotations\n).as_pascal_voc(\n   annotations_directory_path=ANNOTATIONS_DIRECTORY,\n   min_image_area_percentage=MIN_IMAGE_AREA_PERCENTAGE,\n   max_image_area_percentage=MAX_IMAGE_AREA_PERCENTAGE,\n   approximation_percentage=APPROXIMATION_PERCENTAGE\n) \n```"]