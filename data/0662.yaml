- en: 'Building a Computer Vision Model: Approaches and datasets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立计算机视觉模型：方法和数据集
- en: 原文：[https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Javier Couto](https://twitter.com/JCoutoNLP), Tryolabs**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Javier Couto](https://twitter.com/JCoutoNLP)，Tryolabs**。'
- en: 'Computer vision is one of the hottest subfields of machine learning, given
    its [wide variety of applications](https://tryolabs.com/resources/introductory-guide-computer-vision/#industry-applications)
    and tremendous potential. Its goal: to replicate the powerful capacities of human
    vision. But how is this achieved with algorithms?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是机器学习领域最热门的子领域之一，鉴于其[广泛的应用](https://tryolabs.com/resources/introductory-guide-computer-vision/#industry-applications)和巨大的潜力。其目标是复制人类视觉的强大能力。但是，这些算法是如何实现的呢？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Let's have a loot at the most important datasets and approaches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看最重要的数据集和方法。
- en: '**Existing datasets**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**现有数据集**'
- en: 'Computer vision algorithms are no magic. They need data to work, and they can
    only be as good as the data you feed in. These are different sources to collect
    the right data, depending on the task:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉算法并不是魔法。它们需要数据才能工作，它们的效果只能与输入的数据质量相匹配。根据任务的不同，这里有不同的来源来收集合适的数据：
- en: One of the most voluminous and well known dataset is **[ImageNet](http://www.image-net.org/)**,
    a readily-available dataset of 14 million images manually annotated using **[WordNet](https://wordnet.princeton.edu/)** concepts.
    Within the global dataset, 1 million images contain bounding box annotations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最庞大且知名的数据集是**[ImageNet](http://www.image-net.org/)**，这是一个包含 1400 万张图像的数据集，手动标注了**[WordNet](https://wordnet.princeton.edu/)**概念。在全球数据集中，100
    万张图像包含边界框注释。
- en: '![](../Images/47bdf49b1e7bdf044830642dc62105e9.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47bdf49b1e7bdf044830642dc62105e9.png)'
- en: '**ImageNet images with bounding boxes. [Image source](http://www.image-net.org/bbox_fig/kit_fox.JPG)**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**ImageNet 图像带有边界框。 [图片来源](http://www.image-net.org/bbox_fig/kit_fox.JPG)**'
- en: '![](../Images/1de2789c0f6f512afa807174edb804a3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1de2789c0f6f512afa807174edb804a3.png)'
- en: '**ImageNet images with object attributes annotations. [Image source](http://www.image-net.org/attribute_fig/pullfigure.jpg)**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**ImageNet 图像附带物体属性注释。 [图片来源](http://www.image-net.org/attribute_fig/pullfigure.jpg)**'
- en: Another well-known one is the **[Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home)**,
    dataset, loaded with 328,000 images including 91 object types that would be easily
    recognizable by a 4 year old, with a total of 2.5 million labeled instances.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个著名的数据集是**[Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home)**，包含
    328,000 张图片，涵盖 91 种物体类型，这些物体对于 4 岁儿童来说很容易辨认，总共有 250 万个标注实例。
- en: '![](../Images/e60ccd5b9feab0cca16b8b7d9ebd07f8.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e60ccd5b9feab0cca16b8b7d9ebd07f8.png)'
- en: '**Examples of annotated images from the COCO dataset. [Image source](https://arxiv.org/abs/1405.0312)**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**来自 COCO 数据集的标注图像示例。 [图片来源](https://arxiv.org/abs/1405.0312)**'
- en: While there isn’t a plethora of available datasets, there are several suitable
    for different tasks, such as the **[CelebFaces Attributes Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)** (CelebA,
    a face attributes dataset with more than 200K celebrity images); the **[Indoor
    Scene Recognition](http://web.mit.edu/torralba/www/indoor.html)** dataset (15,620
    images of indoor scenes); and the **[Plant Image Analysis](https://www.plant-image-analysis.org/dataset)** dataset
    (1 million images of plants from 11 different species).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可用的数据集不多，但仍有几个适合不同任务的数据集，如**[CelebFaces属性数据集](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)**（CelebA，一个包含超过20万张名人图像的面部属性数据集）；**[室内场景识别](http://web.mit.edu/torralba/www/indoor.html)**数据集（15620张室内场景图像）；以及**[植物图像分析](https://www.plant-image-analysis.org/dataset)**数据集（来自11种不同物种的100万张植物图像）。
- en: '**A general strategy**'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**一个通用策略**'
- en: '**[Deep learning methods and techniques](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)** have
    profoundly transformed computer vision, along with other areas of artificial intelligence,
    to such an extent that for many tasks its use is considered standard. In particular, **[Convolutional
    Neural Networks](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)** (CNN)
    have achieved beyond state-of-the-art results utilizing traditional computer vision
    techniques.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**[深度学习方法和技术](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)** 深刻地改变了计算机视觉以及人工智能的其他领域，以至于在许多任务中，其使用被视为标准。特别是，**[卷积神经网络](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)** （CNN）利用传统的计算机视觉技术取得了超越最先进的结果。'
- en: 'These four steps outline a general approach to building a computer vision model
    using CNNs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个步骤概述了使用CNN构建计算机视觉模型的一般方法：
- en: Create a dataset comprised of annotated images or use an existing one. Annotations
    can be the image category (for a classification problem); pairs of bounding boxes
    and classes (for an object detection problem); or a pixel-wise segmentation of
    each object of interest present in an image (for an instance segmentation problem).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含标注图像的数据集，或使用现有的数据集。标注可以是图像类别（针对分类问题）；边界框和类别对（针对目标检测问题）；或每个感兴趣的图像对象的逐像素分割（针对实例分割问题）。
- en: Extract, from each image, features pertinent to the task at hand. This is a
    key point in modeling the problem. For example, the features used to recognize
    faces, features based on facial criteria, are obviously not the same as those
    used to recognize tourist attractions or human organs.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每张图像中提取与当前任务相关的特征。这是建模问题的关键点。例如，用于识别人脸的特征，基于面部标准的特征，显然不同于用于识别旅游景点或人体器官的特征。
- en: Train a deep learning model based on the features isolated. Training means feeding
    the machine learning model many images and it will learn, based on those features,
    how to solve the task at hand.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于隔离的特征训练深度学习模型。训练意味着向机器学习模型输入许多图像，它将根据这些特征学习如何解决当前任务。
- en: Evaluate the model using images that weren’t used in the training phase. By
    doing so, the accuracy of the training model can be tested.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用未在训练阶段使用的图像来评估模型。通过这种方法，可以测试训练模型的准确性。
- en: This strategy is very basic but it serves the purpose well. Such an approach,
    known as **[supervised machine learning](https://www.kdnuggets.com/2017/11/3-different-types-machine-learning.html)**,
    requires a dataset that encompasses the phenomenon the model has to learn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个策略非常基本，但能够很好地实现目的。这样的做法被称为**[监督学习](https://www.kdnuggets.com/2017/11/3-different-types-machine-learning.html)**，需要一个包含模型必须学习的现象的数据集。
- en: '**Training an object detection model**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**训练目标检测模型**'
- en: '**Viola and Jones approach**'
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**维奥拉和琼斯的方法**'
- en: There are many ways to address object detection challenges. For years, the prevalent
    approach was one proposed by Paul Viola and Michael Jones in the paper, **[Robust
    Real-time Object Detection](http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-2001-1.pdf)**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 处理目标检测挑战有很多方法。多年来，流行的方法是保罗·维奥拉和迈克尔·琼斯在论文中提出的，**[鲁棒实时目标检测](http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-2001-1.pdf)**。
- en: Although it can be trained to detect a diverse range of object classes, the
    approach was first motivated by the objective of face detection. It is so fast
    and straightforward that it was the algorithm implemented in point-and-shoot cameras,
    which allows for real-time face detection with little processing power.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它可以被训练以检测各种物体类别，但这一方法最初的动机是面部检测。它如此快速且直接，以至于成为了点拍摄相机中实现实时面部检测的算法，这样可以在处理能力较低的情况下完成检测。
- en: The central feature of the approach is to train with a potentially large set
    of binary classifiers based on **[Haar features](https://en.wikipedia.org/wiki/Haar-like_feature)**.
    These features represent edges and lines, and are extremely simple to compute
    when scanning an image.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的核心特征是使用基于 **[Haar 特征](https://en.wikipedia.org/wiki/Haar-like_feature)**
    的潜在大型二分类器进行训练。这些特征表示边缘和线条，在扫描图像时非常简单计算。
- en: '![](../Images/bc6c26478e97521e0942d50b5f5a4dce.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc6c26478e97521e0942d50b5f5a4dce.png)'
- en: '**Haar features. [Image source](https://docs.opencv.org/3.4.3/haar_features.jpg)**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**Haar 特征。 [图片来源](https://docs.opencv.org/3.4.3/haar_features.jpg)**'
- en: Although quite basic, in the specific case of faces these features allow for
    the capturing of important elements such as the nose, mouth, or the distance between
    the eyebrows. It is a supervised method that requires many positive and negative
    examples of the type of object to be discerned.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然非常基础，但在面部的特定情况下，这些特征允许捕捉重要的元素，如鼻子、嘴巴或眉毛之间的距离。这是一种需要大量正负样本的监督方法，用于辨别目标类型。
- en: '**Detecting the face of the Mona Lisa**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**检测蒙娜丽莎的面部**'
- en: '**CNN-based approaches**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**基于 CNN 的方法**'
- en: Deep learning has been a real game changer in machine learning, especially in
    computer vision, where deep-learning-based approaches are now cutting edge for
    many of the usual tasks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在机器学习中确实带来了革命性变化，特别是在计算机视觉领域，基于深度学习的方法现在在许多常见任务中处于前沿。
- en: 'Among the different deep learning approaches proposed for accomplishing object
    detection, **[R-CNN](https://arxiv.org/abs/1311.2524)** (Regions with CNN features)
    is particularly simple to understand. The authors of this work propose a three
    stage process:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成物体检测的各种深度学习方法中，**[R-CNN](https://arxiv.org/abs/1311.2524)** （具有 CNN 特征的区域）特别容易理解。该工作的作者提出了一个三阶段过程：
- en: Extract possible objects using a region proposal method.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用区域提议方法提取可能的物体。
- en: Identify features in each region using a CNN.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 CNN 识别每个区域的特征。
- en: Classify each region utilizing **[SVMs](https://en.wikipedia.org/wiki/Support_vector_machine)**.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用 **[SVMs](https://en.wikipedia.org/wiki/Support_vector_machine)** 对每个区域进行分类。
- en: '![](../Images/2be7c020983b89d8c01e3077de68f762.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be7c020983b89d8c01e3077de68f762.png)'
- en: '**R-CNN Architecture. [Image source](https://arxiv.org/abs/1311.2524)**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**R-CNN 架构。 [图片来源](https://arxiv.org/abs/1311.2524)**'
- en: The region proposal method opted for in the original work was **[Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)**,
    although the R-CNN algorithm is agnostic regarding the particular region proposal
    method adopted. Step 3 is very important as it decreases the number of object
    candidates, which makes the method less computationally expensive.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 原始工作中选择的区域提议方法是 **[选择性搜索](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)**，尽管
    R-CNN 算法对具体采用的区域提议方法持中立态度。第 3 步非常重要，因为它减少了物体候选者的数量，从而使方法的计算开销较小。
- en: The features extracted here are less intuitive than the Haar features previously
    mentioned. To summarize, a CNN is used to extract a 4096-dimensional feature vector
    from each region proposal. Given the nature of the CNN, it is necessary that the
    input always have the same dimension. This is usually one of the CNN’s weak points
    and the various approaches address this in different ways. With respect to the
    R-CNN approach, the trained CNN architecture requires inputs of a fixed area of
    227 × 227 pixels. Since the proposed regions have sizes that differ from this,
    the authors’ approach simply warps the images so that they fit the required dimension.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提取的特征不如前述的 Haar 特征直观。总结来说，CNN 用于从每个区域提议中提取一个 4096 维的特征向量。由于 CNN 的性质，输入必须始终具有相同的维度。这通常是
    CNN 的一个弱点，不同的方法以不同的方式解决这个问题。关于 R-CNN 方法，训练好的 CNN 架构要求输入的固定区域为 227 × 227 像素。由于提议的区域尺寸不同，作者的方法简单地扭曲图像以使其适应所需的尺寸。
- en: '![](../Images/528b58be52eb7121ca6d994c8c7cbcd8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/528b58be52eb7121ca6d994c8c7cbcd8.png)'
- en: '**Examples of warped images matching the input dimension required by the CNN.
    [Image source](https://arxiv.org/abs/1311.2524)**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**扭曲图像示例，匹配CNN所需的输入维度。[图片来源](https://arxiv.org/abs/1311.2524)**'
- en: 'While it achieved great results, the training encountered several obstacles,
    and the approach was eventually outperformed by others. Some of those are reviewed
    in depth in the article, **[Object Detection with Deep Learning: The Definitive
    Guide](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)**.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管取得了良好的结果，但训练过程中遇到了几个障碍，最终这种方法被其他方法超越。这些在文章中有深入的探讨，**[深度学习的物体检测: 权威指南](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)**。'
- en: This article is an extract of the *Introductory Guide to Computer Vision* by
    Tryolabs, originally published [here](https://tryolabs.com/resources/introductory-guide-computer-vision/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本文摘录自Tryolabs的*计算机视觉入门指南*，最初发布于[这里](https://tryolabs.com/resources/introductory-guide-computer-vision/)。
- en: '**Bio**: [Javier Couto](https://twitter.com/JCoutoNLP) is a freelance machine
    learning consultant and data scientist at Tryolabs, specialized in applying machine
    learning to solve business problems.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**: [哈维尔·库托](https://twitter.com/JCoutoNLP)是Tryolabs的自由职业机器学习顾问和数据科学家，专注于应用机器学习解决商业问题。'
- en: '**Resources:**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源:**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络: 分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[Think Like an Amateur, Do As an Expert: Lessons from a Career in Computer
    Vision](https://www.kdnuggets.com/2019/05/kanade-lessons-career-computer-vision.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[像业余爱好者一样思考，像专家一样做事: 计算机视觉职业生涯的经验教训](https://www.kdnuggets.com/2019/05/kanade-lessons-career-computer-vision.html)'
- en: '[Predict Age and Gender Using Convolutional Neural Network and OpenCV](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络和OpenCV预测年龄和性别](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
- en: '[Pedestrian Detection in Aerial Images Using RetinaNet](https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用RetinaNet进行航空图像中的行人检测](https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关话题
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解数据管理的6件事及其重要性…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow在计算机视觉中的应用 - 简化迁移学习](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索计算机视觉的世界: 介绍MLM最新的…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的5个应用](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2: Meta AI的自监督计算机视觉模型](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 2022年3月9日: 在5分钟内构建机器学习网络应用](https://www.kdnuggets.com/2022/n10.html)'
