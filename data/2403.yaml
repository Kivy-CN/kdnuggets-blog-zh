- en: Why Use k-fold Cross Validation?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用 k 折交叉验证？
- en: 原文：[https://www.kdnuggets.com/2022/07/kfold-cross-validation.html](https://www.kdnuggets.com/2022/07/kfold-cross-validation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/kfold-cross-validation.html](https://www.kdnuggets.com/2022/07/kfold-cross-validation.html)
- en: '![Why Use k-fold Cross Validation?](../Images/aacfb45cb2f16b61d7002d768975c272.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![为什么使用 k 折交叉验证？](../Images/aacfb45cb2f16b61d7002d768975c272.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图片
- en: Generalization is a frequent term that is used in conversations about Machine
    Learning. It refers to how able the model can adapt to new, unseen data and how
    it works effectively using various inputs. It is understandable to say that if
    new unseen data is inputted into a model, if this unseen data has similar characteristics
    to the training data, it will perform well.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化是一个在机器学习讨论中经常出现的术语。它指的是模型适应新数据的能力以及如何有效地使用各种输入。可以理解的是，如果将新的未见数据输入模型中，只要这些未见数据与训练数据具有类似的特征，模型会表现良好。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT 部门'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Generalizing things is easy to us humans, however it can be challenging to Machine
    Learning models. This is where Cross-Validation comes into the picture.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们人类来说，泛化是容易的，但对机器学习模型来说可能具有挑战性。这就是交叉验证发挥作用的地方。
- en: Cross-Validation
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: You may see cross-validation also being referred to as rotation estimation and/or
    out-of-sample testing. The overall aim of Cross-Validation is to use it as a tool
    to evaluate machine learning models, by training a number of models on different
    subsets of the input data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会看到交叉验证也被称为轮换估计和/或样本外测试。交叉验证的总体目标是将其作为工具来评估机器学习模型，通过在不同的输入数据子集上训练多个模型。
- en: Cross-validation can be used to detect overfitting in a model which infers that
    the model is not effectively generalizing patterns and similarities in the new
    inputted data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证可以用来检测模型的过拟合，这意味着模型在新输入数据中无法有效地泛化模式和相似性。
- en: A typical Cross-Validation workflow
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个典型的交叉验证工作流程
- en: 'In order to perform cross-validation, the following steps are typically taken:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行交叉验证，通常采取以下步骤：
- en: Split the dataset into training data and test data
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集拆分为训练数据和测试数据
- en: The parameters will undergo a Cross-Validation test to see which are the best
    parameters to select.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数将经过交叉验证测试，以确定哪些参数是最佳选择。
- en: These parameters will then be implemented into the model for retraining
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些参数将被应用到模型中以进行重新训练
- en: Final evaluation will occur and this will depend if the cycle has to go again,
    depending on the accuracy and the level of generalization that the model performs.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终评估将会发生，这将取决于是否需要再次进行周期，这取决于模型的准确性和泛化水平。
- en: There are different types of Cross-Validation techniques
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的交叉验证技术
- en: Hold-out
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留法
- en: K-folds
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K 折
- en: Leave-one-out
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 留一法
- en: Leave-p-out
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 留出法
- en: However, we will be particularly focusing on K-folds.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们将特别关注 K 折。
- en: K-fold Cross-Validation
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K 折交叉验证
- en: K-fold Cross-Validation is when the dataset is split into a K number of folds
    and is used to evaluate the model's ability when given new data. K refers to the
    number of groups the data sample is split into. For example, if you see that the
    k-value is 5, we can call this a 5-fold cross-validation. Each fold is used as
    a testing set at one point in the process.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: K 折交叉验证是指将数据集拆分为 K 个折，并用来评估模型在面对新数据时的能力。K 表示数据样本被拆分成的组数。例如，如果看到 k 值为 5，我们可以称之为
    5 折交叉验证。在过程中，每个折在某一时刻被用作测试集。
- en: 'K-fold Cross-Validation Process:'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K 折交叉验证过程：
- en: Choose your k-value
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你的 k 值
- en: Split the dataset into the number of k folds.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集拆分为 k 折。
- en: Start off with using your k-1 fold as the test dataset and the remaining folds
    as the training dataset
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从使用你的k-1折作为测试数据集和其余折作为训练数据集开始
- en: Train the model on the training dataset and validate it on the test dataset
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据集上训练模型，并在测试数据集上验证模型
- en: Save the validation score
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存验证分数
- en: Repeat steps 3 – 5, but changing the value of your k test dataset. So we chose
    k-1 as our test dataset for the first round, we then move onto k-2 as the test
    dataset for the next round.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤3到5，但改变你的k测试数据集的值。比如我们在第一轮选择k-1作为测试数据集，接着在下一轮选择k-2作为测试数据集。
- en: By the end of it you would have validated the model on every fold that you have.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到最后，你将会在每一个折上验证模型。
- en: Average the results that were produced in step 5 to summarize the skill of the
    model.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对第5步中产生的结果进行平均，以总结模型的技能。
- en: You can easily implement this using sklearn.model_selection.KFold
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用sklearn.model_selection.KFold轻松实现这一点
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Why Should I Use K-fold Cross-Validation?
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我应该使用K折交叉验证？
- en: I am going to break down the reasons below as to why you should use K-fold Cross
    Validation
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我将分解为什么你应该使用K折交叉验证的原因
- en: Make use of your data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用你的数据
- en: We have a lot of readily available data that can explain a lot of things and
    help us identify hidden patterns. However, if we only have a small dataset, splitting
    it into a training and test dataset at a 80:20 ratio respectively doesn’t seem
    to do much for us.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很多现成的数据，可以解释很多事情并帮助我们识别隐藏的模式。然而，如果我们只有一个小数据集，将其分成80:20的训练和测试数据集似乎对我们帮助不大。
- en: However, when using K-fold cross validation, all parts of the data will be able
    to be used as part of the testing data. This way, all of our data from our small
    dataset can be used for both training and testing, allowing us to better evaluate
    the performance of our model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当使用K折交叉验证时，数据的所有部分都可以作为测试数据的一部分使用。这样，我们小数据集中的所有数据都可以用于训练和测试，从而更好地评估模型的性能。
- en: More available metrics to help evaluate
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多可用的指标来帮助评估
- en: Let’s refer back to the example of splitting your dataset into training and
    testing as a 80:20 ratio or a train-test split - this provides us with only one
    result to refer to in our evaluation of the model. We are not sure about the accuracy
    of this result, if it’s due to chance, the level of bias, or if it actually performed
    well.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到将数据集拆分为80:20比例的训练和测试的例子——这只提供一个结果用于评估模型。我们不能确定这个结果的准确性，是由于偶然、偏差程度，还是它确实表现良好。
- en: However, when using k-fold cross validation, we have more models that will be
    producing more results. For example, if we chose our k value at 10, we would have
    10 results to use in our evaluation of the model's performance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当使用k折交叉验证时，我们有更多的模型会产生更多的结果。例如，如果我们选择k值为10，我们将有10个结果用于评估模型的性能。
- en: If we were using accuracy as our measurement; having 10 different accuracy results
    where all of the data was used in the test phase is always going to be better
    and more reliable than using one accuracy result that was produced by a train-test
    split - where all the data wasn’t used in the test phase.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用准确率作为衡量标准；拥有10个不同的准确率结果，其中所有数据都用于测试阶段，总是比使用一个由训练-测试拆分产生的准确率结果更好，更可靠——因为不是所有数据都在测试阶段使用过。
- en: You would have more trust and confidence in your model's performance if the
    accuracy outputs were 94.0, 92.8, 93.0, 97.0, and 94.5 in a 5-fold cross validation
    than a 93.0 accuracy in a train-test split. This proves to us that our algorithm
    is generalizing and actively learning and is providing consistent reliable outputs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果准确率输出为94.0、92.8、93.0、97.0和94.5在5折交叉验证中，那么相比于训练-测试拆分中93.0的准确率，你会对模型的性能有更多的信任和信心。这向我们证明了我们的算法在泛化和积极学习，并提供了一致可靠的输出。
- en: Better performance using dependent data
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用相关数据获得更好的性能
- en: In a random train-test split, we assume that the data inputs are independent.
    Let’s further expand on this. Let’s say we are using a random train-test split
    on a speech recognition dataset for British English speakers who reside from London.
    There are 5 speakers, with 250 recording each. Once the model performs a random
    train-test split, both the training and testing dataset will learn from the same
    speaker, which will be saying the same dialogue.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在随机训练-测试划分中，我们假设数据输入是独立的。让我们进一步扩展这个问题。假设我们在一个语音识别数据集中使用随机训练-测试划分，这些讲者都是来自伦敦的英国英语讲者。共有5位讲者，每位讲者有250个录音。模型进行随机训练-测试划分后，训练集和测试集都会来自同一位讲者，并且这些录音会说相同的对话。
- en: Yes this does improve the accuracy and boost the performance of the algorithms,
    however, what about when a new speaker is introduced to the model? How does the
    model perform then?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这确实提高了准确性并增强了算法的性能，但是，当引入新讲者时，模型的表现如何？那时模型的表现怎么样？
- en: Using K-fold cross validation will allow you to train 5 different models, where
    in each model you are using one of the speakers for the testing dataset and the
    remaining for the training dataset. This way, not only can we evaluate the performance
    of our model, but our model will be able to perform better on new speakers and
    can be deployed in production to produce similar performance for other tasks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用K折交叉验证将允许你训练5个不同的模型，每个模型使用一个讲者作为测试数据集，其余的作为训练数据集。通过这种方式，我们不仅可以评估模型的性能，还可以使模型在新讲者上的表现更好，并且可以部署到生产中，为其他任务提供类似的性能。
- en: Why is 10 Such a Desirable k value?
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么10是一个如此理想的k值？
- en: Choosing the right k-value is important as it can affect your level of accuracy,
    variance, bias and cause you to misinterpreted the overall performance of your
    model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的k值很重要，因为它会影响你的准确性、方差、偏差，并可能导致对模型整体性能的误解。
- en: The simplest way to choose your k value is by equating it to your ‘n’ value,
    also known as leave-one-out cross-validation. n represents the size of the dataset
    which allows for each test sample the opportunity to be used in the test data
    or hold out data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 选择k值的最简单方法是将其等同于你的‘n’值，也称为留一法交叉验证。n代表数据集的大小，这样每个测试样本都有机会作为测试数据或保留数据使用。
- en: However, through various experimentations from Data Scientists, Machine Learning
    Engineers, and Researchers they have found that choosing a k-value of 10 has proven
    to provide a low bias and a modest variance.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过数据科学家、机器学习工程师和研究人员的各种实验，他们发现选择k值为10能够提供较低的偏差和适中的方差。
- en: Kuhn & Johnson spoke about their choice of k value in their book [Applied Predictive
    Modeling](https://link.springer.com/book/10.1007/978-1-4614-6849-3).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kuhn & Johnson 在他们的书籍 [应用预测建模](https://link.springer.com/book/10.1007/978-1-4614-6849-3)
    中讨论了他们选择k值的方法。
- en: '*“The choice of k is usually 5 or 10, but there is no formal rule. As k gets
    larger, the difference in size between the training set and the resampling subsets
    gets smaller. As this difference decreases, the bias of the technique becomes
    smaller (i.e., the bias is smaller for k=10 than k= 5). In this context, the bias
    is the difference between the estimated and true values of performance”*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*“k的选择通常是5或10，但没有正式的规则。随着k值的增大，训练集和重采样子集之间的大小差异会变小。随着这种差异的减少，该技术的偏差也会变小（即k=10时的偏差比k=5时小）。在这种情况下，偏差是估计值与实际性能值之间的差异”*'
- en: 'Let’s take this context and put it in an example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来说明这个背景：
- en: Let's say we have a data set where N = 100
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个数据集，其中N = 100
- en: If we chose our k value = 2, our subset size = 50 and the difference = 50
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择k值 = 2，我们的子集大小 = 50，差异 = 50
- en: If we chose our k value k = 4, our subset size = 75 and the difference = 25
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择k值 = 4，我们的子集大小 = 75，差异 = 25
- en: If we chose our k value = 10, our subset size = 90 and the difference = 10
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们选择k值 = 10，我们的子集大小 = 90，差异 = 10
- en: So therefore, as the value of k increases, the difference between the original
    data set and the cross-validation subsets becomes smaller.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，随着k值的增加，原始数据集与交叉验证子集之间的差异变得更小。
- en: It is also stated that choosing k= 10 is more computationally efficient, as
    the larger the values of k gets it becomes more computationally impractical. Small
    values will also be deemed as computationally efficient, however they pose the
    possibility of high bias.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 还指出，选择k=10在计算上更为高效，因为k值越大，计算上的可行性越差。小值也被认为在计算上高效，但它们可能会导致较高的偏差。
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Cross-Validation is an important tool that every Data Scientist should be using
    or very proficient in at least. It allows you to make better use of all your data
    as well as providing Data Scientists, Machine Learning Engineers and Researchers
    with a better understanding of the performance of the algorithm.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是每个数据科学家都应该使用或至少非常熟练的一个重要工具。它可以让你更好地利用所有数据，同时为数据科学家、机器学习工程师和研究人员提供对算法性能的更好理解。
- en: Having confidence in your model is important to future deployment and trust
    that the model will be effective and perform well.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对模型有信心对于未来的部署和信任模型的有效性和表现至关重要。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家和自由技术作家。她特别关注提供数据科学职业建议或教程以及围绕数据科学的理论知识。她还希望探索人工智能如何/可以促进人类寿命的延续。她是一个热衷学习的人，寻求拓宽她的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Data Validation for PySpark Applications using Pandera](https://www.kdnuggets.com/2023/08/data-validation-pyspark-applications-pandera.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Pandera进行PySpark应用程序的数据验证](https://www.kdnuggets.com/2023/08/data-validation-pyspark-applications-pandera.html)'
- en: '[Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pydantic教程：简化Python中的数据验证](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
- en: '[MarshMallow: The Sweetest Python Library for Data Serialization and…](https://www.kdnuggets.com/marshmallow-the-sweetest-python-library-for-data-serialization-and-validation)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarshMallow：最甜蜜的Python数据序列化库](https://www.kdnuggets.com/marshmallow-the-sweetest-python-library-for-data-serialization-and-validation)'
- en: '[Why the Newest LLMs use a MoE (Mixture of Experts) Architecture](https://www.kdnuggets.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么最新的LLMs使用MoE（专家混合）架构](https://www.kdnuggets.com/why-the-newest-llms-use-a-moe-mixture-of-experts-architecture)'
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该使用线性回归模型而不是…的3个原因](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[4 Reasons Why You Shouldn’t Use Machine Learning](https://www.kdnuggets.com/2021/12/4-reasons-shouldnt-machine-learning.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你不应该使用机器学习的4个理由](https://www.kdnuggets.com/2021/12/4-reasons-shouldnt-machine-learning.html)'
