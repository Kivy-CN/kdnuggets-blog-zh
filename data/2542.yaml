- en: Visualizing Bias-Variance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化偏差-方差
- en: 原文：[https://www.kdnuggets.com/2021/08/visualizing-bias-variance.html](https://www.kdnuggets.com/2021/08/visualizing-bias-variance.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/visualizing-bias-variance.html](https://www.kdnuggets.com/2021/08/visualizing-bias-variance.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Theodore Tsitsimis](https://www.linkedin.com/in/tsitsimis/), Machine
    Learning Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[西奥多·齐茨密斯](https://www.linkedin.com/in/tsitsimis/)，机器学习科学家**'
- en: Bias-Variance trade-off is a fundamental concept of Machine Learning. Here we'll
    explore some different perspectives of what this trade-off really means with the
    help of visualizations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差-方差权衡是机器学习的一个基本概念。这里我们将通过可视化的帮助来探讨这种权衡的不同视角。
- en: Bias-Variance in real life
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现实生活中的偏差-方差
- en: 'A lot of our decisions are influenced by others, when observing their actions
    and comparing ourselves with them (through some social similarity metric). At
    the same time, we maintain our own set of rules that we learn through experience
    and reasoning. In this context:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的很多决策都受到他人的影响，当我们观察他们的行为并通过某些社会相似度度量来比较自己时。同时，我们保持自己通过经验和推理学到的一套规则。在这种情况下：
- en: '**Bias** is when we have very simplistic rules that don''t really explain real-life
    situations. For example, thinking you can become a doctor by watching Youtube
    videos.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差**是当我们有非常简单的规则而无法真正解释现实情况时。例如，认为通过观看YouTube视频就能成为医生。'
- en: '**Variance** is when we always change our minds by listening to different groups
    of people and mimicking their actions. For example, when you see someone well-shaped
    in the gym, eating protein bars after workout and you think that protein bars
    is what you also need. And then you listen someone saying that they bought some
    fitness equipment which helped them grow their muscles and you go right ahead
    and buy the same machine.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差**是当我们通过倾听不同的群体并模仿他们的行为而不断改变自己的想法时。例如，当你看到某人在健身房里形体很好，运动后吃蛋白棒，你也认为蛋白棒是你需要的。然后你听到有人说他们买了一些健身器材，帮助他们增长了肌肉，你便去购买了同样的机器。'
- en: A trade-off perspective
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 权衡视角
- en: Bias-Variance is very often called a trade-off. When talking about trade-offs,
    we're usually referring to situations with 2 (or more) competing quantities where
    strengthening the one results in the reduction of the other and vice versa. A
    famous example is the exploration-exploitation trade-off in reinforcement learning,
    where increasing the exploration factor (e.g. ε-greedy) causes the agent to exploit
    less the already estimated high-value states.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差-方差通常被称为权衡。当谈到权衡时，我们通常指的是有两个（或更多）竞争量的情况，其中加强一个量会导致另一个量减少，反之亦然。一个著名的例子是强化学习中的探索-利用权衡，其中增加探索因素（如ε-贪婪）会使代理减少对已估计高价值状态的利用。
- en: 'On the other hand, bias-variance is rather a decomposition. It is shown that
    the expected test error (mean squared error) of a regression model can be decomposed
    to 3 terms: variance, bias and irreducible error (due to noise and intrinsic variability):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，偏差-方差是一种分解。研究表明，回归模型的期望测试误差（均方误差）可以分解为三个部分：方差、偏差和不可减少的误差（由于噪声和内在变异性）。
- en: '![Equation](../Images/4572eeedd5e20d6d489a5164c410e3f4.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![方程式](../Images/4572eeedd5e20d6d489a5164c410e3f4.png)'
- en: However, in contrast to the exploration-exploitation trade-off where you can
    directly control the 2 competing quantities, bias and variance are not levers
    that you can just pull to control the error. It's just another way of writing
    the test error and bias and variance emerge from this decomposition.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与探索-利用权衡直接控制两个竞争量不同，偏差和方差不是可以直接调整来控制误差的杠杆。它只是另一种表达测试误差的方式，偏差和方差由这种分解产生。
- en: But why is it called a trade-off then? Flexible models tend to have low bias
    and high variance, while more rigid models tend to have high bias and low variance.
    Model flexibility is something you can control (regularization, number of parameters,
    etc) and therefore indirectly control bias and variance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么它被称为权衡呢？灵活的模型往往具有低偏差和高方差，而更为刚性的模型则往往具有高偏差和低方差。模型的灵活性是你可以控制的（正则化、参数数量等），因此可以间接控制偏差和方差。
- en: Bias-Variance in simple terms
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差-方差的简单术语
- en: 'We read in Bishop''s Pattern Recognition and Machine Learning that the bias-variance
    decomposition is the result of attempting to model prediction uncertainty by running
    a learning algorithm to multiple datasets sampled from the same distribution.
    And concludes:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Bishop的《模式识别与机器学习》中读到，偏差-方差分解是通过对来自相同分布的多个数据集运行学习算法来尝试建模预测不确定性得到的结果。并得出结论：
- en: The bias term represents the extent to which the average prediction over all
    datasets differs from the desired regression function
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏差项表示在所有数据集上的平均预测值与期望回归函数之间的差异程度
- en: The variance term measures the extent to which the solutions for individual
    datasets vary around their average, and hence this measures the extent to which
    the learned function is sensitive to the particular choice of dataset.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方差项测量了各个数据集的解在其平均值周围变化的程度，因此，这测量了学习函数对特定数据集选择的敏感程度。
- en: Fit "by inspection"
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过“目测”拟合
- en: Let's put some context (and graphs) here. Consider the below 1D dataset that
    was generated by the function ### and was perturbed by some Gaussian noise.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里放一些背景（和图表）。考虑下面这个1D数据集，它是由函数###生成的，并且被一些高斯噪声扰动了。
- en: '![Image](../Images/801b588ed6d173a872b4ca7c41b18b50.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/801b588ed6d173a872b4ca7c41b18b50.png)'
- en: What if we wanted to fit a polynomial in these points?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要在这些点上拟合一个多项式怎么办？
- en: We can look at the graph and after taking a step back and squinting our eyes
    really well, we sketch a line that approximately passes through all points (like
    the red line in the graph). We then observe that the y values tend to increase
    towards +infinity (if you squint hard enough) for high and low x values, which
    gives us the hint that it should be an even-degree polynomial. We then see that
    the points cut the x-axis 4 times (4 real roots), which means that it should be
    an at least 4-degree polynomial. We finish by observing that the graph has 3 turning
    points (going from increasing to decreasing or vice versa), again indicating that
    we have a 4-degree polynomial.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看图形，稍微退后一步，眯起眼睛仔细观察，勾画出一条大致通过所有点的线（如图中的红线）。然后我们观察到，y值在高x值和低x值时趋向于增加到+∞（如果你眯眼看得够仔细），这给了我们一个提示：这应该是一个偶数次的多项式。我们进一步看到这些点在x轴上交叉了4次（4个实根），这意味着它应该至少是4次多项式。最后，我们观察到图形有3个转折点（从增加到减少或反之），这再次表明我们有一个4次多项式。
- en: By "squinting our eyes" we basically did some kind of noise smoothing to see
    the "bigger picture" instead of the small and irrelevant variations of the dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“眯眼看”，我们基本上进行了一种噪声平滑，以便看到“全局图景”，而不是数据集的微小和无关的变化。
- en: However, how can we be sure that this is indeed the right choice?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们如何能确定这确实是正确的选择？
- en: Just throw a 1000-degree polynomial and see what happens
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接抛出一个1000次多项式，看看会发生什么
- en: 'Since we can''t be sure about the degree of a polynomial that would best approximate
    the underlying process, or we are just too bored to estimate it, we could just
    use the most "complex" model we can imagine to fit the points. To validate this
    argument, we fit multiple polynomials of increasing degree to see how they behave:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不能确定哪个多项式的度数最能最佳近似潜在的过程，或者我们只是太无聊了而不愿估计它，我们可以使用我们能想象的最“复杂”的模型来拟合这些点。为了验证这个观点，我们拟合了多个逐渐增加度数的多项式，看看它们的表现：
- en: '![Image](../Images/1fef77965c6c9fa49553fcdd2457e7b5.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/1fef77965c6c9fa49553fcdd2457e7b5.png)'
- en: Half of the points (circled) were used for training in each case. It's obvious
    that the low-degree model (left) can't curve and bend enough to fit the data.
    The 7-degree polynomial seems to elegantly pass between the points, as if it can
    ignore (smooth out) the noise. What's more interesting is that the high-degree
    polynomial (right) tries to interpolate through the points and achieves it in
    some degree. But is this what we want? What would happen if were given a different
    set of training points? Would the predictions and shape of the regression curve
    change?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 每种情况下一半的点（圈出的）用于训练。显然，低次模型（左侧）不能弯曲到足以拟合数据。7次多项式似乎优雅地通过了这些点，好像它可以忽略（平滑掉）噪声。更有趣的是，高次多项式（右侧）试图通过这些点进行插值，并在某种程度上达到了这一点。但这就是我们想要的吗？如果给定一组不同的训练点会发生什么？预测和回归曲线的形状会改变吗？
- en: Below, the same fitting was repeated for different subsets of the data and the
    resulting curves are overlayed to check their variability. The results in the
    case of the 7-degree polynomial seem to be pretty consistent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，对不同数据子集重复了相同的拟合，并将结果曲线叠加以检查它们的变异性。在7阶多项式的情况下，结果似乎相当一致。
- en: The model is robust to changes in training set, as long as they are uniformly
    sampled from the input space.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型对训练集的变化具有鲁棒性，只要这些变化是从输入空间中均匀采样的。
- en: '![Image](../Images/1bbb9053b2da098d787263cc3ffd44d1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/1bbb9053b2da098d787263cc3ffd44d1.png)'
- en: 'Now the same diagram for the 30-degree polynomial:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是30阶多项式的相同图示：
- en: '![Image](../Images/c68d1ef9bdefe37c310f7a7a860e014f.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c68d1ef9bdefe37c310f7a7a860e014f.png)'
- en: Predictions seem to oscillate up and down for different training sets. The main
    impact of this is that we can't trust the prediction of such a model, because
    if by chance we had a slightly different set of data, the prediction of the same
    input sample would probably change.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 预测似乎在不同训练集上上下波动。其主要影响是我们不能信任这种模型的预测，因为如果偶然得到一个稍微不同的数据集，同样的输入样本的预测可能会改变。
- en: 'To better illustrate this argument, the below plot shows the distributions
    of predictions for the 3 models when evaluated on a single test point (in this
    case at x=7):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明这一点，下图展示了在单个测试点（在这种情况下为x=7）上评估的3个模型的预测分布：
- en: '![Image](../Images/b5967bf2c5555732100acefb12a0b07b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/b5967bf2c5555732100acefb12a0b07b.png)'
- en: The dashed line is the true value of the function at x=7.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虚线是x=7时函数的真实值。
- en: That's what Random Forests® do
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这就是随机森林®的作用
- en: The green distribution of the high-degree model in the above graph shows that
    the predictions vary a lot for different datasets. This is not a good property
    of the model since it is not robust to small dataset perturbations. But note that
    the average of the distribution is a very good prediction of the actual target,
    even better than the average value of the 7-degree model (red distribution). Averaging
    (bagging) over many realizations of the dataset is a beneficial procedure and
    can overcome overfitting and variance. This is actually what Random Forests® do
    and give pretty good results most of the times without much tuning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中高阶模型的绿色分布显示，预测在不同数据集上变化很大。这不是模型的一个好特性，因为它对小的数据集扰动不够鲁棒。但请注意，分布的平均值对实际目标的预测非常好，甚至比7阶模型（红色分布）的平均值更好。对数据集的多个实现进行平均（bagging）是一个有益的过程，可以克服过拟合和方差。这实际上就是随机森林®的工作方式，并且大多数时候能够在没有太多调优的情况下给出相当好的结果。
- en: Hopefully, this visualizations will help make more clear how bias-variance affect
    model performance and why averaging many models can lead to better predictions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这些可视化能帮助更清楚地了解偏差-方差如何影响模型性能，以及为什么平均多个模型可以得到更好的预测。
- en: '**Bio: [Theodore Tsitsimis](https://www.linkedin.com/in/tsitsimis/)** is a
    machine learning scientist. He is currently working in a consulting firm solving
    business problems using data and machine learning for diverse industries. He holds
    a B.Sc. and M.Sc. from the school of Electrical and Computer Engineering in National
    Technical University of Athens, where he conducted research on robotics.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [西奥多·齐茨米斯](https://www.linkedin.com/in/tsitsimis/)** 是一名机器学习科学家。他目前在一家咨询公司工作，利用数据和机器学习解决各种行业的业务问题。他拥有来自雅典国立技术大学电气与计算机工程学院的学士和硕士学位，在那里他进行了机器人研究。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[How to Create Unbiased Machine Learning Models](/2021/07/create-unbiased-machine-learning-models.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何创建无偏机器学习模型](/2021/07/create-unbiased-machine-learning-models.html)'
- en: '[The Three Edge Case Culprits: Bias, Variance, and Unpredictability](/2021/04/imerit2-bias-variance-unpredictability.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[三个边缘情况罪魁祸首：偏差、方差和不可预测性](/2021/04/imerit2-bias-variance-unpredictability.html)'
- en: '[20 Core Data Science Concepts for Beginners](/2020/12/20-core-data-science-concepts-beginners.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者的数据科学核心概念20条](/2020/12/20-core-data-science-concepts-beginners.html)'
- en: '* * *'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 方面'
- en: '* * *'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Visualizing Your Confusion Matrix in Scikit-learn](https://www.kdnuggets.com/2022/09/visualizing-confusion-matrix-scikitlearn.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Scikit-learn 中可视化你的混淆矩阵](https://www.kdnuggets.com/2022/09/visualizing-confusion-matrix-scikitlearn.html)'
- en: '[Visualizing Data: A Statology Primer](https://www.kdnuggets.com/visualizing-data-statology-primer)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据可视化：Statology 入门指南](https://www.kdnuggets.com/visualizing-data-statology-primer)'
