- en: Open Source Toolkits for Speech Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/03/open-source-toolkits-speech-recognition.html](https://www.kdnuggets.com/2017/03/open-source-toolkits-speech-recognition.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Cindi Thompson, [Silicon Valley Data Science](https://www.svds.com/).**'
  prefs: []
  type: TYPE_NORMAL
- en: As members of the [deep learning](http://svds.com/getting-started-deep-learning/)
    R&D team at SVDS, we are interested in comparing [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network)
    (RNN) and other approaches to speech recognition. Until a few years ago, the state-of-the-art
    for speech recognition was a [phonetic](https://en.wikipedia.org/wiki/Phonetics)-based
    approach including separate components for pronunciation, [acoustic](https://en.wikipedia.org/wiki/Acoustic_model),
    and [language](https://en.wikipedia.org/wiki/Language_model) models. Typically,
    this consists of n-gram language models combined with [Hidden Markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model)
    (HMM). We wanted to start with this as a baseline model, and then explore ways
    to combine it with newer approaches such as Baidu’s [Deep Speech](https://arxiv.org/abs/1412.5567).
    While summaries exist explaining these baseline phonetic models, there do not
    appear to be any easily-digestible blog posts or papers that compare the tradeoffs
    of the different freely available tools.
  prefs: []
  type: TYPE_NORMAL
- en: This article reviews the main options for free speech recognition toolkits that
    use traditional HMM and n-gram language models. For operational, general, and
    customer-facing speech recognition it may be preferable to purchase a product
    such as [Dragon](http://www.nuance.com/dragon/index.htm) or [Cortana](https://www.microsoft.com/en-us/mobile/experiences/cortana/).
    But in an R&D context, a more flexible and focused solution is often required,
    and that is why we decided to develop our own speech recognition pipeline. Below
    we list the top contenders in the free or open source world, and rate them on
    several characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparison matrix](../Images/98e57bf6c7f584277f8b9c2b4f5ec19b.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of open source and free speech recognition toolkits.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis is based on our subjective experience and the information available
    from the repositories and toolkit websites. This is also not an exhaustive list
    of speech recognition software, most of which are listed [here](https://en.wikipedia.org/wiki/List_of_speech_recognition_software)
    (which goes beyond open source). A 2014 paper by Gaida et.al. evaluates the performance
    of [CMU Sphinx](http://cmusphinx.sourceforge.net/), [Kaldi](http://kaldi-asr.org/),
    and [HTK](http://htk.eng.cam.ac.uk/#). Note that HTK is not strictly open source
    in its usual interpretation, as the code cannot be redistributed or re-purposed
    for commercial use.
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming Languages:** Depending on your familiarity with different languages,
    you may naturally prefer one toolkit over another. All of the listed options except
    for [ISIP](https://www.isip.piconepress.com/projects/speech/) have Python wrappers
    available either on the main site or found quickly with a web search. Of course,
    the Python wrappers may not expose the full functionality of the core code available
    in the toolkit. CMU Sphinx also has wrappers in several other programming languages.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Development activity:** All of the projects listed have their origins in
    academic research. CMU Sphinx, as may be obvious from its name, is a product of
    Carnegie Mellon University. It’s existed in some form for about 20 years, and
    is now available on both GitHub (with [C](https://github.com/cmusphinx/pocketsphinx)
    and [Java](https://github.com/cmusphinx/sphinx4) versions there) and [SourceForge](https://sourceforge.net/projects/cmusphinx/),
    with recent activity on both. Both the Java and C versions appear to have only
    one contributor on GitHub, but this doesn’t reflect the historical reality of
    the project (there are 9 administrator and more than a dozen developers on the
    SourceForge repo). Kaldi has its academic roots from a 2009 workshop, with its
    code now hosted on [GitHub](https://github.com/kaldi-asr/kaldi) with 121 contributors.
    HTK started its life at Cambridge University in 1989, was commercial for some
    time, but is now licenced back to Cambridge and is not available as open source
    software. While its latest version was updated in December of 2015, the prior
    release was in 2009\. [Julius](http://julius.osdn.jp/en_index.php) has been in
    development since 1997 and had its last major release in September of 2016 with
    a somewhat active [GitHub](https://github.com/julius-speech/julius) repo consisting
    of three contributors, which again is unlikely to reflect reality. ISIP was the
    first state-of-the-art open source speech recognition system, and originated from
    Mississippi State. It was developed mostly from 1996 to 1999, with its last release
    in 2011, but the project was mostly defunct before the emergence of GitHub.^([1](https://www.svds.com/open-source-toolkits-speech-recognition/#fn1))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Github comparison](../Images/a863a2c6bcca436b4d4d6acc0f627238.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Community:** Here we looked at both mailing and discussion lists and the
    community of developers involved. CMU Sphinx has online discussion forums and
    active interest in its repos. However, we wonder if the duplication of repos in
    both SourceForge and GitHub are blocking more widespread contribution. In comparison,
    Kaldi has both forums and mailing lists as well as an active GitHub repo. HTK
    has mailing lists but no open repository. The user forum link on the Julius web
    site is broken but there may be more information on the Japanese site. ISIP is
    primarily targeted for educational purposes and the mailing list archives are
    no longer functional.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tutorials and Examples:** CMU Sphinx has very readable, thorough, and easy
    to follow documentation; Kaldi’s documentation is also comprehensive but a bit
    harder to follow in my opinion. However, Kaldi does cover both the phonetic and
    deep learning approaches to speech recognition. If you are not familiar with speech
    recognition, HTK’s tutorial documentation (available to registered users) gives
    a good overview to the field, in addition to documentation on actual design and
    use of the system. The Julius project is focused on Japanese, and the most current
    documentation is in Japanese^([2](https://www.svds.com/open-source-toolkits-speech-recognition/#fn2)),
    but they also are actively translating to English and provide that documentation
    as well; there are some examples of running speech recognition [here](https://github.com/julius-speech/dictation-kit).
    Finally, the ISIP project has some documentation, but is a little more difficult
    to navigate.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trained models:** Even though a main reason to use these open or free tools
    is because you want to train specialized recognition models, it is a big advantage
    when you can speak to the system out of the box. CMU Sphinx includes English and
    many [other models](https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/)
    ready to use, with the documentation for connecting to them with Python included
    right in the [GitHub readme](https://github.com/cmusphinx/pocketsphinx-python/blob/master/readme.md).
    Kaldi’s instructions for decoding with existing models is hidden deep in the documentation,
    but we eventually discovered a model trained on some part of an English VoxForge dataset
    in the `egs/voxforge` subdirectory of the repo, and recognition can be done by
    running the script in the `online-data` subdirectory. We didn’t dig as deeply
    into the other three packages, but they all come with at least simple models or
    appear to be compatible with the format provided on the [VoxForge](http://www.voxforge.org/home) site,
    a fairly active crowdsourced repository of speech recognition data and trained
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: In the future, we will discuss how to get started using CMU Sphinx. We also
    plan to follow up on our earlier deep learning post with one that applies neural
    networks to speech, and will compare the neural net’s recognition performance
    to that of CMU Sphinx. In the meantime, we always love feedback and questions
    on our blog posts, so let us know if you have additional perspective on these
    toolkits or others.
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: '[blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits](http://blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaida, Christian, et al. “Comparing open-source speech recognition toolkits.”
    Tech. Rep., DHBW Stuttgart (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bio: [Cindi Thompson](https://www.linkedin.com/in/cindithompson/)** is a
    naturally collaborative problem-solver able to bridge technical and business concerns
    using strong communication and facilitation skills. With a PhD in artificial intelligence,
    she brings a unique blend of academic and industry experience in machine learning,
    natural language understanding, and R&D.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.svds.com/open-source-toolkits-speech-recognition/?utm_campaign=KDNuggets%20Blog&utm_source=KDNuggets).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Artificial Intelligence and Speech Recognition for Chatbots: A Primer](/2017/01/artificial-intelligence-speech-recognition-chatbots-primer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Achieving Human Parity in Conversational Speech Recognition](/2016/12/achieving-human-parity-conversational-speech-recognition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 20 Python Machine Learning Open Source Projects, updated](/2016/11/top-20-python-machine-learning-open-source-updated.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[The Evolution of Speech Recognition Metrics](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Closed Source VS Open Source Image Annotation](https://www.kdnuggets.com/closed-source-vs-open-source-image-annotation)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build a Text-to-Speech Converter with Python in 5 Minutes](https://www.kdnuggets.com/2022/09/build-texttospeech-converter-python-5-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 IT Jobs That Are High in Demand But Don’t Get Enough Recognition](https://www.kdnuggets.com/5-it-jobs-that-are-high-in-demand-but-dont-get-enough-recognition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
