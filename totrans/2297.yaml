- en: 'Linear Regression Model Selection: Balancing Simplicity and Complexity'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Linear Regression Model Selection: Balancing Simplicity and Complexity](../Images/4aec1c8a060a8e79a81d4fca50744cef.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [freepik ](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Simple linear regression is one of the oldest types of predictive modeling.
    In a simple linear regression, we have a single feature (![Equation](../Images/fcb1f8de5e7672d9fe0c9a7da57d2750.png))
    and a single continuous target variable (![Equation](../Images/92cee04f93ff75bc34f082e5efa945f5.png)).
    The goal is to find a mathematical function that describes the relationship between
    X and y. The simplest form is to try a linear (degree = 1) relationship in the
    form ![Equation](../Images/72a022503f9434f7a28bbadf6e04c726.png) where ![Equation](../Images/8967ecc5e80780e956772991143d706f.png)
    and *a**1* are coefficients to be determined. A quadratic model (degree = 2) takes
    the form ![Equation](../Images/0abbfbe3a8a7fe16b9cad81e5a656cb9.png), where ![Equation](../Images/a9b62396df36649ba189a47f11c3cf91.png),
    ![Equation](../Images/7e699bbbd6ec52fa38b17d03d4ea1b06.png) and ![Equation](../Images/dce1b24bf9f7a6b7e814e534f10ce7fa.png)
    are regression coefficients to be determined.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a dataset provided in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear Regression Model Selection: Balancing Simplicity and Complexity](../Images/fb30bd9f6870c76fac363b0e55678d15.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to perform regression analysis to quantify the relationship between
    *X* and *y*, that is *y = f(X)*. Once this is obtained, we can then predict a
    new value for *y* for any given value for *X*.
  prefs: []
  type: TYPE_NORMAL
- en: First, we generate a scatter plot to display the relationship between *X* and
    *y*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Linear Regression Model Selection: Balancing Simplicity and Complexity](../Images/787df4b5fc65fc3e2112aab792bb7e6b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To perform a polynomial fit of degree =1 for the data, we can use the code
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: By changing the degree value to degree = 2, and degree = 10, we can perform
    higher order polynomial fits to the data.
  prefs: []
  type: TYPE_NORMAL
- en: The figure below shows a plot of the original and predicted values obtained
    for different polynomial fits of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear Regression Model Selection: Balancing Simplicity and Complexity](../Images/12f5d8077dbe93188886ed35a4a195c2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'A summary of the goodness of fit score (R2 score) for the different models
    is given in the table below:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the figure above, we observe the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear Regression Model Selection: Balancing Simplicity and Complexity](../Images/d25b40416767d1b97c204f8aac6eb4ae.png)'
  prefs: []
  type: TYPE_IMG
- en: The linear model (degree = 1) is too simple, and hence underfits the data, leading
    to a high bias error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The higher polynomial model (degree = 10) is too complex, and hence overfits
    the data, leading to a high variance error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The quadratic model (degree = 2) seems to provide the right balance between
    simplicity and complexity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In summary, we’ve shown how to perform simple linear regression using python.
    Generally, a polynomial of any degree could be used to fit the data. However,
    when selecting the final model, it is important to find the right balance between
    simplicity and complexity. A model that is too simple underfits the data, leading
    to high bias error. Likewise, a model that is too complex overfits the data, leading
    to high variance error. The model with the right balance of simplicity and complexity
    should be chosen as this model will produce a lower error when applied to new
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Benjamin O. Tayo](https://www.linkedin.com/in/benjamin-o-tayo-ph-d-a2717511/)**
    is a Physicist, Data Science Educator, and Writer, as well as the Owner of DataScienceHub.
    Previously, Benjamin was teaching Engineering and Physics at U. of Central Oklahoma,
    Grand Canyon U., and Pittsburgh State U.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Memory Complexity with Transformers](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Making Predictions: A Beginner''s Guide to Linear Regression in Python](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear Regression from Scratch with NumPy](https://www.kdnuggets.com/linear-regression-from-scratch-with-numpy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
