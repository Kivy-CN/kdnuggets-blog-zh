- en: 'Overcoming Barriers in Multi-lingual Voice Technology: Top 5 Challenges and
    Innovative Solutions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克服多语言语音技术中的障碍：前5大挑战及创新解决方案
- en: 原文：[https://www.kdnuggets.com/2023/08/overcoming-barriers-multilingual-voice-technology-top-5-challenges-innovative-solutions.html](https://www.kdnuggets.com/2023/08/overcoming-barriers-multilingual-voice-technology-top-5-challenges-innovative-solutions.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/overcoming-barriers-multilingual-voice-technology-top-5-challenges-innovative-solutions.html](https://www.kdnuggets.com/2023/08/overcoming-barriers-multilingual-voice-technology-top-5-challenges-innovative-solutions.html)
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力。'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求。'
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: How often have you had to pause after asking your voice assistant about something
    in Spanish, your preferred language, and then restate your ask in the language
    that the voice assistant understands, likely English, because the voice assistant
    did not understand your request in Spanish? Or how often have you had to deliberately
    mis-pronounce your favorite artist A. R. Rahman’s name when asking your voice
    assistant to play their music because you know that if you say their name the
    right way, the voice assistant will simply not understand, but if you say A. R.
    *Ramen* the voice assistant will get it? Further, how often have you cringed when
    the voice assistant, in their soothing, all-knowing voice, butcher the name of
    your favorite musical Les Misérables and distinctly pronounce it as "Les Miz-er-ables"?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你多久会在用西班牙语（你的首选语言）向语音助手提问后不得不暂停一下，然后重新用语音助手能理解的语言（可能是英语）重复你的请求，因为语音助手没有理解你的西班牙语请求？或者你多久会在要求语音助手播放你最喜欢的艺术家A.
    R. Rahman的音乐时故意发错音，因为你知道如果你正确地说出他们的名字，语音助手根本听不懂，但如果你说A. R. *Ramen*，语音助手就能明白？此外，你多久会在语音助手用它那安抚的、全知的声音把你最喜欢的音乐剧《悲惨世界》叫成“Les
    Miz-er-ables”时感到尴尬？
- en: Despite voice assistants having become mainstream about a decade ago, they continue
    to remain simplistic, specifically in their understanding of user requests in
    multilingual contexts. In a world where multi-lingual households are on the rise
    and the existing and potential user base is becoming increasingly global and diverse,
    it is critical for voice assistants to become seamless when it comes to understanding
    user requests, irrespective of their language, dialect, accent, tone, modulation,
    and other speech characteristics. However, voice assistants continue to lag woefully
    when it comes to being able to smoothly converse with users in a way that humans
    do with each other. In this article, we will dive into what the top challenges
    in making voice assistants operate multi-lingually are, and what some strategies
    to mitigate these challenges might be. We will use a hypothetical voice assistant,
    *Nova*, throughout this article, for illustration purposes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语音助手在大约十年前已经成为主流，但它们在多语言环境中的用户请求理解方面仍然显得很简单。在多语言家庭日益增多、现有和潜在用户群体变得越来越全球化和多样化的世界中，语音助手在理解用户请求时必须做到无缝对接，无论是语言、方言、口音、语调、调制还是其他语音特征。然而，语音助手在与用户进行流畅对话方面依然大大滞后于人类之间的自然交流。本文将探讨使语音助手能够进行多语言操作的主要挑战，并讨论一些可能的解决策略。我们将在整篇文章中使用假设的语音助手*Nova*作为示例。
- en: How Voice Assistants Work
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语音助手的工作原理
- en: Before diving into the challenges and opportunities with respect to making voice
    assistant user experiences multilingual, let’s get an overview of how voice assistants
    work. Using Nova as the hypothetical voice assistant, we look at how the end-to-end
    flow for asking for a music track looks like ([reference](https://iaeme.com/Home/article_id/IJAIML_02_01_007)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨使语音助手用户体验多语言化的挑战和机遇之前，让我们先了解一下语音助手是如何工作的。以 Nova 为假设的语音助手，我们看看请求音乐曲目的端到端流程是什么样的（[参考](https://iaeme.com/Home/article_id/IJAIML_02_01_007)）。
- en: '![Overcoming Barriers in Multi-lingual Voice Technology: Top 5 Challenges and
    Innovative Solutions](../Images/4039e506555c12eb8193e31100115bb4.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![克服多语言语音技术的障碍：前五大挑战和创新解决方案](../Images/4039e506555c12eb8193e31100115bb4.png)'
- en: Fig. 1\. End-to-end overview of hypothetical voice assistant *Nova *
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1. 假设语音助手 *Nova* 的端到端概览
- en: As seen in Fig. 1., when a user asks Nova to play acoustic music by the popular
    band Coldplay, this sound signal of the user is first converted to a string of
    text tokens, as a first step in the human – voice assistant interaction. This
    stage is called Automatic Speech Recognition (ASR) or Speech to Text (STT). Once
    the string of tokens is available, it is passed on to the Natural Language Understanding
    step where the voice assistant tries to understand the semantic and syntactic
    meaning of the user’s intent. In this case, the voice assistant’s NLU interprets
    that the user is looking for songs by the band Coldplay (i.e. interprets that
    Coldplay is a band) that are acoustic in nature (i.e. look for meta data of songs
    in the discography of this band and only select the songs with version = acoustic).
    This user intent understanding is then used to query the back-end to find the
    content that the user is looking for. Finally, the actual content that the user
    is looking for and any other additional information needed to present this output
    to the user is carried forward to the next step. In this step, the response and
    any other information available is used to decorate the experience for the user
    and satisfactorily respond to the user query. In this case, it would be a Text
    To Speech (TTS) output (“*here’s some acoustic music by Coldplay*”) followed by
    a playback of the actual songs that were selected for this user query.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 1 所示，当用户请求 Nova 播放流行乐队 Coldplay 的原声音乐时，用户的声音信号首先被转换为一串文本令牌，这一步是人类与语音助手互动的第一步。这一阶段称为自动语音识别（ASR）或语音转文本（STT）。一旦文本令牌串生成，它将被传递到自然语言理解步骤，在这里语音助手尝试理解用户意图的语义和句法含义。在这种情况下，语音助手的
    NLU 解释用户在寻找由乐队 Coldplay 演唱的歌曲（即解释 Coldplay 是一个乐队），这些歌曲的性质是原声的（即在该乐队的专辑中查找歌曲的元数据，只选择版本为原声的歌曲）。然后，这种用户意图理解被用来查询后端以找到用户所寻找的内容。最后，实际的用户查询内容以及任何其他需要呈现给用户的附加信息被转移到下一步骤。在这一步中，响应和任何其他可用信息被用来装饰用户体验，并令人满意地响应用户查询。在这种情况下，输出将是一个文本到语音（TTS）输出（“*这是一些
    Coldplay 的原声音乐*”），接着播放为此用户查询所选择的实际歌曲。
- en: Challenges in Building Multi-lingual Voice Assistants
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建多语言语音助手的挑战
- en: Multi-lingual voice assistants (VAs) imply VAs that are able to understand and
    respond to multiple languages, whether they are spoken by the same person or persons
    or if they are spoken by the same person in the same sentence mixed with another
    language (e.g. “*Nova, arrêt! Play something else*”). Below are the top challenges
    in voice assistants when it comes to being able to operate seamlessly in a multi-modal
    setting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 多语言语音助手（VAs）意味着能够理解和回应多种语言的语音助手，无论这些语言是否由同一个人或不同的人说，或者如果它们在同一句话中混合着另一种语言（例如“*Nova,
    arrêt! Play something else*”）。以下是语音助手在多模态环境中无缝操作时面临的主要挑战。
- en: Inadequate Quantity and Quantity of Language Resources
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言资源的数量和质量不足
- en: In order for a voice assistant to be able to parse and understand a query well,
    it needs to be trained on a significant amount of training data in that language.
    This data includes speech data from humans, annotations for ground truth, vast
    amounts of text corpora, resources for improved pronunciation of TTS (e.g. pronunciation
    dictionaries) and language models. While these resources are easily available
    for popular languages like English, Spanish and German, their availability is
    limited or even non-existent for languages like Swahili, Pashto or Czech. Even
    though these languages are spoken by enough people, there aren’t structured resources
    available for these. Creating these resources for multiple languages can be expensive,
    complex and manually intensive, creating headwinds to progress.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使语音助手能够很好地解析和理解查询，它需要在该语言的大量训练数据上进行训练。这些数据包括人类的语音数据、地面真实情况的注释、大量的文本语料库、用于改进TTS（例如发音词典）的资源和语言模型。虽然这些资源在英语、西班牙语和德语等热门语言中很容易获得，但对于斯瓦希里语、普什图语或捷克语等语言，它们的可用性有限甚至不存在。尽管这些语言有足够多的使用者，但仍没有结构化的资源。为多种语言创建这些资源可能成本高昂、复杂且劳动密集，从而成为进步的障碍。
- en: Variations in Language
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言变化
- en: Languages have different dialects, accents, variations and regional adaptations.
    Dealing with these variations is challenging for voice assistants. Unless a voice
    assistant adapts to these linguistic nuances, it would be hard to understand user
    requests correctly or be able to respond in the same linguistic tone in order
    to deliver natural sounding and more human-like experience. For example, the UK
    alone has more than 40 English accents. Another example is how the Spanish spoken
    in Mexico is different from the one spoken in Spain.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 语言有不同的方言、口音、变体和地区适应。处理这些变体对语音助手来说是一个挑战。除非语音助手适应这些语言细微差别，否则很难正确理解用户请求或以相同的语言语调作出回应，以提供自然且更像人类的体验。例如，仅英国就有超过40种英语口音。另一个例子是墨西哥讲的西班牙语与西班牙讲的西班牙语的区别。
- en: Language Identification and Adaptation
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言识别和适应
- en: It is common for multi-lingual users to switch between languages during their
    interactions with other humans, and they might expect the same natural interactions
    with voice assistants. For example, “Hinglish” is a commonly used term to describe
    the language of a person who uses words from both Hindi and English while talking.
    Being able to identify the language(s) the user is interacting with the voice
    assistant in and adapting responses accordingly is a difficult challenge that
    no mainstream voice assistant can do today.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 多语言用户在与其他人互动时通常会切换语言，他们可能希望与语音助手的互动也能自然地进行。例如，“Hinglish”是一个常用术语，用于描述一个人在讲话时使用印地语和英语的单词。能够识别用户与语音助手互动时使用的语言并相应调整回应是一个困难的挑战，目前没有主流的语音助手能够做到这一点。
- en: Language Translation
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言翻译
- en: One way to scale the voice assistant to multiple languages could be translating
    the ASR output from a not-so-mainstream language like Luxembourgish into a language
    that can be interpreted by the NLU layer more accurately, like English. Commonly
    used translation technologies include using one or more techniques like Neural
    Machine Translation (NMT), Statistical Machine Translation (SMT), Rule-based Machine
    Translation (RBMT), and others. However, these algorithms might not scale well
    for diverse language sets and might also require extensive training data. Further,
    language-specific nuances are often lost, and the translated versions often seem
    awkward and unnatural. The quality of translations continues to be a persistent
    challenge in terms of being able to scale multi-lingual voice assistants. Another
    challenge in the translation step is the latency it introduces, degrading the
    experience of the human – voice assistant interaction.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展语音助手到多种语言的一种方法可能是将来自像卢森堡语这样的非主流语言的ASR输出翻译成可以被NLU层更准确解释的语言，如英语。常用的翻译技术包括使用一种或多种技术，如神经机器翻译（NMT）、统计机器翻译（SMT）、基于规则的机器翻译（RBMT）等。然而，这些算法可能无法很好地扩展到多样化的语言集，并且可能还需要大量的训练数据。此外，语言特定的细微差别往往会丧失，翻译版本常常显得生硬和不自然。翻译的质量在扩展多语言语音助手方面仍然是一个持续的挑战。翻译步骤中的另一个挑战是它引入的延迟，降低了人类与语音助手互动的体验。
- en: True Language Understanding
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 真实语言理解
- en: Languages often have unique grammatical structures. For example, while English
    has the concept of *singular* and *plural*, Sanskrit has 3 (*singular, dual, plural*).
    There might also be different idioms that don’t translate well to other languages.
    Finally, there might also be cultural nuances and cultural references that might
    be poorly translated, unless the translating technique has a high quality of semantic
    understanding. Developing language specific NLU models is expensive.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 语言通常具有独特的语法结构。例如，虽然英语有*单数*和*复数*的概念，但梵语有3种（*单数、双数、复数*）。还可能存在一些难以翻译的成语。最后，文化细微差别和文化参考可能会被翻译得不好，除非翻译技术具有高质量的语义理解。开发语言特定的NLU模型是昂贵的。
- en: Overcoming Challenges in Building Multi-lingual Voice Assistants
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 克服构建多语言语音助手的挑战
- en: The challenges mentioned above are hard problems to solve. However, there are
    ways in which these challenges can be mitigated partially, if not fully, right
    away. Below are some techniques that can solve one or more of the challenges mentioned
    above.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述挑战是难以解决的问题。然而，有一些方法可以部分地（即使不能完全）缓解这些挑战。以下是一些可以解决上述一个或多个挑战的技术。
- en: Leverage Deep Learning to Detect Language
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用深度学习检测语言
- en: The first step in interpreting the meaning of a sentence is to know what language
    the sentence belongs to. This is where deep learning comes into the picture. Deep
    learning uses artificial neural networks and high volumes of data to create output
    that seems human-like. Transformer-based architecture (e.g. BERT) have demonstrated
    success in language detection, even in the cases of low resource languages. An
    alternative to transformer-based language detection model is a recurrent neural
    network (RNN). An example of the application of these models is that if a user
    who usually speaks in English suddenly talks to the voice assistant in Spanish
    one day, the voice assistant can detect and ID Spanish correctly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 解释句子意义的第一步是知道句子属于哪种语言。这时深度学习发挥作用。深度学习使用人工神经网络和大量数据来生成似乎人类般的输出。基于Transformer的架构（如BERT）在语言检测中表现成功，即使在资源匮乏的语言中也不例外。一个替代的基于RNN的语言检测模型是递归神经网络（RNN）。这些模型的一个应用示例是，如果一个通常讲英语的用户某天突然用西班牙语与语音助手对话，语音助手可以正确检测并识别西班牙语。
- en: Use Contextual Machine Translation to ‘Understand’ the Request
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用上下文机器翻译来“理解”请求
- en: Once the language has been detected, the next step towards interpreting the
    sentence is to take the output of the ASR stage, i.e., the string of tokens, and
    translate this string, not just literally but also semantically, into a language
    that can be processed in order to generate a response. Instead of using translation
    APIs that might not always be aware of the context and peculiarities of the voice
    interface and also introduce suboptimal delays in responses because of high latency,
    degrading the user experience. However, if context-aware machine translation models
    are integrated into voice assistants, the translations can be of higher quality
    and accuracy because of being specific to a domain or the context of the session.
    For example, if a voice assistant is being used mainly for entertainment, it can
    leverage contextual machine translation to correctly understand and respond to
    questions about genres and sub-genres of music, musical instruments and notes,
    cultural relevance of certain tracks, and more.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦检测到语言，解释句子的下一步是将ASR阶段的输出，即一串标记，翻译成可以处理的语言，以生成回应。与可能无法始终了解语境和语音界面特性的翻译API不同，这些API还会因高延迟而引入次优的响应延迟，从而降低用户体验。然而，如果将上下文感知的机器翻译模型集成到语音助手中，翻译的质量和准确性会更高，因为这些模型是针对特定领域或会话上下文的。例如，如果语音助手主要用于娱乐，它可以利用上下文机器翻译来正确理解和回应关于音乐类型和子类型、乐器和音符、某些曲目的文化相关性等问题。
- en: Capitalize on Multi-lingual Pre-trained Models
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用多语言预训练模型
- en: Since every language has a unique structure and grammar, cultural references,
    phrases, idioms and expressions and other nuances, it is challenging to process
    diverse languages. Given language specific models are expensive, pre-trained multi-lingual
    models can help capture language specific nuances. Models like BERT and XLM-R
    are good examples of pre-trained models that can capture language specific nuances.
    Lastly, these models can be fine-tuned to a domain to further increase their accuracy.
    For example, for a model trained on the music domain might be able to not just
    understand the query but also return a rich response via a voice assistant. If
    this voice assistant is asked what the meaning behind the lyrics of a song are,
    the voice assistant will be able to answer the question in a much richer way than
    a simple interpretation of the words.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每种语言都有独特的结构和语法、文化参考、短语、习语和表达方式等细微差别，因此处理多样的语言是具有挑战性的。考虑到特定语言的模型费用高昂，预训练的多语言模型可以帮助捕捉语言特有的细微差别。像BERT和XLM-R这样的模型是捕捉语言特有细微差别的预训练模型的良好示例。最后，这些模型可以进一步微调以适应特定领域，从而提高准确性。例如，训练于音乐领域的模型可能不仅能够理解查询，还可以通过语音助手返回丰富的响应。如果这个语音助手被问到一首歌歌词背后的意义，它将能够比简单的词汇解释提供更丰富的答案。
- en: Use Code Switching Models
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用代码切换模型
- en: Implementing code switching models for being able to handle language input that
    is a mix of different languages can help in the cases where a user uses more than
    one language in their interactions with the voice assistant. For example, if a
    voice assistant is designed specifically for a region in Canada where users often
    mix up French and English, a code-switching model can be used to understand sentences
    directed to the voice assistant that are a mix of the two languages and the voice
    assistant will be able to handle it.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实施代码切换模型以处理混合多种语言的语言输入可以帮助应对用户在与语音助手互动时使用多种语言的情况。例如，如果一个语音助手专门为加拿大的一个地区设计，而用户在该地区经常混合使用法语和英语，那么可以使用代码切换模型来理解对语音助手发出的混合语言句子，语音助手将能够处理这些情况。
- en: Leverage Transfer Learning and Zero Shot Learning for Low Resource Languages
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用迁移学习和零样本学习处理低资源语言
- en: Transfer learning is a technique in ML where a model is trained on one task
    but is used as a starting point for a model on a second task. It uses the learning
    from the first task to improve the performance of the second task, thus overcoming
    the cold-start problem to an extent. Zero shot learning is when a pre-trained
    model is used to process data it has never seen before. Both Transfer Learning
    and Zero Shot learning can be leveraged to transfer knowledge from high-resource
    languages into low-resource languages. For example, if a voice assistant is already
    trained on the top 10 languages spoken most commonly in the world, it could be
    leveraged to understand queries in low resource languages like Swahili.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种机器学习技术，其中一个模型在一个任务上进行训练，但作为第二个任务模型的起点。它利用第一个任务中的学习来提高第二个任务的性能，从而在一定程度上克服了冷启动问题。零样本学习是指使用预训练模型处理之前从未见过的数据。迁移学习和零样本学习都可以用来将知识从高资源语言转移到低资源语言。例如，如果一个语音助手已经在世界上最常用的前十种语言上进行了训练，那么它可以用于理解像斯瓦希里语这样的低资源语言中的查询。
- en: Conclusion
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In summary, building and implementing multilingual experiences on voice assistants
    is challenging, but there are also ways to mitigate some of these challenges.
    By addressing the challenges called out above, voice assistants will be able to
    provide a seamless experience to their users, irrespective of their language.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 总结而言，在语音助手上构建和实施多语言体验是具有挑战性的，但也有办法减轻这些挑战。通过解决上述提到的挑战，语音助手将能够为用户提供无缝的体验，不论他们使用什么语言。
- en: '**Note:** All content and opinions presented in this article belong to the
    individual writing the article alone and are not representative in any shape or
    form of their employer'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 本文中所呈现的所有内容和观点仅代表撰写文章的个人，不代表其雇主的任何形式或形态。'
- en: '**[Ashlesha Kadam](https://www.linkedin.com/in/ashleshakadam/)** leads a global
    product team at Amazon Music that builds music experiences on Alexa and Amazon
    Music apps (web, iOS, Android) for millions of customers across 45+ countries.
    She is also a passionate advocate for women in tech, serving as co-chair for the
    Human Computer Interaction (HCI) track for Grace Hopper Celebration (biggest tech
    conference for women in tech with 30K+ participants across 115 countries). In
    her free time, Ashlesha loves reading fiction, listening to biz-tech podcasts
    (current favorite - Acquired), hiking in the beautiful Pacific Northwest and spending
    time with her husband, son and 5yo Golden Retriever.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Ashlesha Kadam](https://www.linkedin.com/in/ashleshakadam/)** 领导着Amazon
    Music的全球产品团队，负责为45多个国家的数百万客户构建Alexa和Amazon Music应用（网页、iOS、Android）上的音乐体验。她还是女性技术倡导者，担任Grace
    Hopper Celebration（全球最大女性技术会议，参会者超过3万人，来自115个国家）的计算机人机交互（HCI）分会的共同主席。在闲暇时，Ashlesha喜欢阅读小说，听商业技术播客（当前最爱
    - Acquired），在美丽的太平洋西北地区徒步旅行，并与丈夫、儿子及5岁的金毛寻回犬共度时光。'
- en: More On This Topic
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Overcoming Imbalanced Data Challenges in Real-World Scenarios](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克服现实世界场景中的数据不平衡挑战](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
- en: '[5 Data Management Challenges with Solutions](https://www.kdnuggets.com/2023/04/5-data-management-challenges-solutions.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个数据管理挑战及其解决方案](https://www.kdnuggets.com/2023/04/5-data-management-challenges-solutions.html)'
- en: '[8 Innovative BERT Knowledge Distillation Papers That Have Changed…](https://www.kdnuggets.com/2022/09/eight-innovative-bert-knowledge-distillation-papers-changed-nlp-landscape.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8篇创新的BERT知识蒸馏论文，这些论文改变了…](https://www.kdnuggets.com/2022/09/eight-innovative-bert-knowledge-distillation-papers-changed-nlp-landscape.html)'
- en: '[Main 2021 Developments and Key 2022 Trends in AI, Data Science,…](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年的主要发展和2022年的关键趋势在人工智能、数据科学等领域](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)'
- en: '[The Top 8 Cloud Container Management Solutions of 2024](https://www.kdnuggets.com/the-top-8-cloud-container-management-solutions-of-2024)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2024年顶级的8大云容器管理解决方案](https://www.kdnuggets.com/the-top-8-cloud-container-management-solutions-of-2024)'
- en: '[How AI/ML Technology Integration Will Help Business in Achieving…](https://www.kdnuggets.com/2021/12/aiml-technology-integration-help-business-achieving-goals-2022.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI/ML技术整合如何帮助企业实现…](https://www.kdnuggets.com/2021/12/aiml-technology-integration-help-business-achieving-goals-2022.html)'
