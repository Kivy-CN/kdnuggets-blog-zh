- en: Best Practices for Building ETLs for ML
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习 ETL 的最佳实践
- en: 原文：[https://www.kdnuggets.com/best-practices-for-building-etls-for-ml](https://www.kdnuggets.com/best-practices-for-building-etls-for-ml)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/best-practices-for-building-etls-for-ml](https://www.kdnuggets.com/best-practices-for-building-etls-for-ml)
- en: An integral part of ML Engineering is building reliable and scalable procedures
    for extracting data, transforming it, enriching it and loading it in a specific
    file store or database. This is one of the components in which the data scientist
    and the ML engineer collaborate the most. Typically, the data scientist comes
    up with a rough version of what the data set should look like. Ideally, not on
    a Jupyter notebook. Then, the ML engineer joins this task to support making the
    code more readable, efficient and reliable.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工程的一个关键部分是构建可靠且可扩展的数据提取、转换、丰富和加载的过程。这是数据科学家与机器学习工程师最密切合作的组成部分之一。通常，数据科学家会提出一个粗略的数据集设计方案。理想情况下，不是在
    Jupyter notebook 上。然后，机器学习工程师加入这个任务，以帮助使代码更具可读性、效率和可靠性。
- en: 'ML ETLs can be composed of several sub-ETLs or tasks. And they can be materialized
    in very different forms. Some common examples:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习 ETLs 可以由多个子 ETL 或任务组成，并且可以以非常不同的形式体现。一些常见的例子：
- en: Scala-based Spark job reading and processing event log data stored in S3 as
    Parquet files and scheduled through Airflow on a weekly basis.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 Scala 的 Spark 任务读取和处理存储在 S3 中的 Parquet 文件格式的事件日志数据，并通过 Airflow 每周计划。
- en: Python process executing a Redshift SQL query through a scheduled AWS Lambda
    function.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 进程通过计划的 AWS Lambda 函数执行 Redshift SQL 查询。
- en: Complex pandas-heavy processing executed through a Sagemaker Processing Job
    using [EventBridge triggers](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-notebook-jobs/studio-scheduling/scheduled-example.html#Scale-interactive-experimentation-to-scheduled-jobs-on-SageMaker-Studio-Notebooks-without-changing-code.).
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的 pandas 重处理通过 Sagemaker 处理作业执行，使用 [EventBridge 触发器](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-notebook-jobs/studio-scheduling/scheduled-example.html#Scale-interactive-experimentation-to-scheduled-jobs-on-SageMaker-Studio-Notebooks-without-changing-code.)。
- en: '* * *'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT 工作'
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Entities in ETLs
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ETL 中的实体
- en: We can identify different entities in these types of ETLs, we have ***Sources***
    (where the raw data lives), ***Destinations*** (where the final data artifact
    gets stored), ***Data*** ***Processes*** (how the data gets read, processed and
    loaded) and ***Triggers*** (how the ETLs get initiated).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这些类型的 ETL 中识别不同的实体，我们有***源***（原始数据存储的位置）、***目标***（最终数据制品存储的位置）、***数据***
    ***处理***（数据如何被读取、处理和加载）和***触发器***（ETL 如何被启动）。
- en: '![Best Practices for Building ETLs for ML](../Images/d415303a783e9bd7c4dc794639ad097d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习 ETL 的最佳实践](../Images/d415303a783e9bd7c4dc794639ad097d.png)'
- en: Under the *Sources*, we can have stores such as AWS Redshift, AWS S3, Cassandra,
    Redis or external APIs. *Destinations* are the same.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*源*部分，我们可以有如 AWS Redshift、AWS S3、Cassandra、Redis 或外部 API 等存储位置。*目标*也是如此。
- en: The *Data Processes* are typically run under ephemeral Docker containers. We
    could add another level of abstraction using Kubernetes or any other AWS managed
    service such as AWS ECS or AWS Fargate. Or even SageMaker Pipelines or Processing
    Jobs.You can run these processes in a cluster by leveraging specific data processing
    engines such as Spark, Dask, Hive, Redshift SQL engine. Also, you can use simple
    single-instance processes using Python processes and Pandas for data processing.
    Apart from that, there are some other interesting frameworks such as Polars, Vaex,
    Ray or Modin which can be useful to tackle intermediate solutions.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据处理* 通常在临时的 Docker 容器中运行。我们可以通过使用 Kubernetes 或其他 AWS 管理服务，如 AWS ECS 或 AWS
    Fargate，再增加一层抽象。甚至可以使用 SageMaker Pipelines 或 Processing Jobs。通过利用特定的数据处理引擎，如 Spark、Dask、Hive、Redshift
    SQL 引擎，你可以在集群中运行这些过程。同时，你还可以使用 Python 进程和 Pandas 进行简单的单实例数据处理。除此之外，还有一些其他有趣的框架，如
    Polars、Vaex、Ray 或 Modin，它们可以用于处理中间解决方案。'
- en: The most popular *Trigger* tool is Airflow. Others that can be used are Prefect,
    Dagster, Argo Workflows or Mage.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最受欢迎的 *触发器* 工具是 Airflow。其他可用的工具有 Prefect、Dagster、Argo Workflows 或 Mage。
- en: '![Best Practices for Building ETLs for ML](../Images/c3c1282ef8593296b444398dfdb22dce.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![构建机器学习 ETLs 的最佳实践](../Images/c3c1282ef8593296b444398dfdb22dce.png)'
- en: Should I use a Framework?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我是否应该使用框架？
- en: A framework is a set of abstractions, conventions and out-of-the-box utilities
    that can be used to create a more uniform codebase when applied to concrete problems.
    Frameworks are very convenient for ETLs. As we’ve previously described, there
    are very generic entities that could potentially be abstracted or encapsulated
    to generate comprehensive workflows.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 框架是一组抽象、约定和开箱即用的工具，可以用于创建更统一的代码库，当应用于具体问题时。框架对于 ETLs 非常方便。正如我们之前描述的那样，有很多非常通用的实体可以被抽象或封装，以生成全面的工作流。
- en: 'The progression that I would take to build an internal data processing framework
    is the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我构建内部数据处理框架的进展步骤如下：
- en: Start by building a library of connectors to the different *Sources* and *Destinations*.
    Implement them as you need them throughout the different projects you work on.
    That’s the best way to avoid *YAGNI*.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先建立一个连接不同 *源* 和 *目标* 的库。在你进行的不同项目中，根据需要实现这些连接器。这是避免 *YAGNI* 的最佳方式。
- en: Create simple and automated development workflow that allows you to iterate
    quickly the codebase. For example, configure CI/CD workflows to automatically
    test, lint and publish your package.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建简单且自动化的开发工作流，使你能够快速迭代代码库。例如，配置 CI/CD 工作流以自动测试、代码检查和发布你的包。
- en: Create utilities such as reading SQL scripts, spinning up Spark sessions, dates
    formatting functions, metadata generators, logging utilities, functions for fetching
    credentials and connection parameters and alerting utilities among others.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建实用工具，如读取 SQL 脚本、启动 Spark 会话、日期格式化函数、元数据生成器、日志记录工具、获取凭据和连接参数的函数，以及警报工具等。
- en: Choose between building an internal framework for writing workflows or use an
    existing one. The complexity scope is wide when considering this in-house development.
    You can start with some simple conventions when building workflows and end up
    building some DAG-based library with generic classes such as [Luigi](https://luigi.readthedocs.io/en/stable/)
    or [Metaflow](https://metaflow.org/). These are popular frameworks that you can
    use.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建工作流的内部框架与使用现有框架之间进行选择。在考虑内部开发时，复杂性范围非常广泛。你可以从一些简单的约定开始构建工作流，最终可能会构建一些基于 DAG
    的库，如 [Luigi](https://luigi.readthedocs.io/en/stable/) 或 [Metaflow](https://metaflow.org/)。这些是你可以使用的流行框架。
- en: Building a *“Utils”* Libraries
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 *“Utils”* 库
- en: This is a critical and central part of your data codebase. All your processes
    will use this library to move data around from one source into another destination.
    A solid and well-though initial software design is key.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你的数据代码库的一个关键和核心部分。所有的处理过程将使用这个库来将数据从一个源移动到另一个目标。一个扎实且经过深思熟虑的初始软件设计是关键。
- en: '![Best Practices for Building ETLs for ML](../Images/e851b582d0e7d9c4024ed7b35dde3019.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![构建机器学习 ETLs 的最佳实践](../Images/e851b582d0e7d9c4024ed7b35dde3019.png)'
- en: 'But why would we want to do this? Well, the main reasons are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们为什么要这样做呢？主要原因是：
- en: '**Reusability**: Using the same software components in different software projects
    allows for higher productivity. The piece of software has to be developed only
    once. Then, it can be integrated into other software projects. But this idea is
    not new. We can find references back in [1968 on a conference](https://www.cs.dartmouth.edu/~doug/components.txt)
    whose aim was to solve the so-called [software crisis.](https://en.wikipedia.org/wiki/Software_crisis)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重用性**：在不同的软件项目中使用相同的软件组件可以提高生产力。这个软件组件只需开发一次。然后，它可以集成到其他软件项目中。但这个想法并不新鲜。我们可以追溯到[1968年的一次会议](https://www.cs.dartmouth.edu/~doug/components.txt)，其目标是解决所谓的[软件危机](https://en.wikipedia.org/wiki/Software_crisis)。'
- en: '**Encapsulation**: Not all the internals of the different connectors used through
    the library need to be shown to end-users. Hence, by providing an understandable
    interface, that’s enough. For example, if we had a connector to a database, we
    wouldn’t like that the connection string got exposed as a public attribute of
    the connector class. By using a library we can ensure that secure access to data
    sources is guaranteed. ***Review this bit***'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**封装**：库中不同连接器的所有内部细节不需要展示给最终用户。因此，提供一个可理解的接口就足够了。例如，如果我们有一个数据库连接器，我们不希望连接字符串暴露为连接器类的公共属性。通过使用库，我们可以确保对数据源的安全访问得到保障。***审查此部分***'
- en: '**Higher-quality** codebase: We have to develop tests only once. Hence, developers
    can rely on the library because it contains a test suite (Ideally, with a very
    high test coverage). When debugging for errors or issues we can ignore, at least
    at first pass, that the issue is within the library if we’re confident on our
    test suite.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更高质量**的代码库：我们只需开发一次测试。因此，开发者可以依赖于这个库，因为它包含了一个测试套件（理想情况下，测试覆盖率非常高）。在调试错误或问题时，我们可以忽略，至少在初次检查时，问题是否出在库中，只要我们对测试套件有信心。'
- en: '**Standardisation** / “*Opinionation”*: Having a library of connectors determines,
    in certain way, the way you develop ETLs. That is good, because ETLs in the organization
    will have the same ways of extracting or writing data into the different data
    sources. Standardisation leads to better communication, more productivity and
    better forecasting and planning.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化** / “*观点*”：拥有一个连接器库在某种程度上决定了你开发ETL的方式。这是好的，因为组织中的ETL将具有相同的数据提取或写入方式。标准化有助于更好的沟通、更高的生产力以及更好的预测和规划。'
- en: 'When building this type of library, teams commit to maintain it over time and
    assume the risk of having to implement complex refactors when needed. Some causes
    of having to do these refactors might be:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建这种类型的库时，团队承诺在一段时间内维护它，并承担在需要时实施复杂重构的风险。需要进行这些重构的原因可能包括：
- en: The organisation migrates to a different public cloud.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织迁移到不同的公共云。
- en: The data warehouse engine changes.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据仓库引擎发生变化。
- en: New dependency version breaks interfaces.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的依赖版本破坏了接口。
- en: More security permission checks need to be put in place.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要进行更多的安全权限检查。
- en: A new team comes in with different opinions about the library design.a
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新团队进来，对库的设计有不同的意见。
- en: Interface classes
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接口类
- en: If you want to make your ETLs agnostic of the *Sources* or *Destinations*, it
    is a good decision to create interface classes for base entities. Interfaces serve
    as template definitions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想让你的ETL与*来源*或*目的地*无关，创建基类的接口类是一个好的决定。接口作为模板定义。
- en: 'For example, you can have abstract classes for defining required methods and
    attributes of a *DatabaseConnector.* Let’s show a simplified example of how this
    class could look like:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以有抽象类来定义*DatabaseConnector*所需的方法和属性。让我们展示一个简化的示例，说明这个类可能的样子：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Other developers would subclass from the *DatabaseConnector* and create new
    concrete implementations. For instance, a **MySqlConnector** or **CassandraDbConnector**
    could be implemented in this fashion.  This would help end-users to quickly understand
    how to use any connector subclassed from the *DatabaseConnector* as all of them
    will have the same interface (same methods).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 其他开发者可以从*DatabaseConnector*子类化并创建新的具体实现。例如，可以以这种方式实现**MySqlConnector**或**CassandraDbConnector**。这将帮助最终用户快速理解如何使用任何从*DatabaseConnector*子类化的连接器，因为它们都将具有相同的接口（相同的方法）。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Simples interfaces with well-named methods are very powerful and allow for better
    productivity. So my advice is to spend quality time thinking about it.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的接口与命名良好的方法非常强大，有助于提高生产力。因此，我建议花时间仔细思考这一点。
- en: The right documentation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正确的文档
- en: Documentation not only refers to *docstrings* and inline comments in the code.
    It also refers to the surrounding explanations you give about the library. Writing
    a bold statement about what’s the end goal of the package and a sharp explanation
    of the requirements and guidelines to contribute is essential.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 文档不仅仅指代码中的*docstrings*和内联注释。它还指你关于库的周边解释。对包的最终目标进行明确的陈述，以及对贡献的要求和指南进行清晰的解释是至关重要的。
- en: 'For example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Or
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Having a clear mission of the library paves the way for a correct interpretation
    from contributors. This is why open source libraries (E.g: pandas, scikit-learn,
    etc) have gained such a great popularity these last years. Contributors have embraced
    the goal of the library and they are committed to follow the outlined standards.
    We should be doing something pretty similar at organizations.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对库有一个清晰的使命有助于贡献者的正确理解。这就是为什么开源库（例如：pandas、scikit-learn 等）在这些年中获得了如此大的受欢迎程度。贡献者接受了库的目标，并承诺遵循规定的标准。我们在组织中也应该做得类似。
- en: 'Right after the mission is stated, we should develop the foundational software
    architecture. How do we want our interfaces to look like? Should we cover functionality
    through more flexibility in the interface methods (e.g: more arguments that lead
    to different behaviours) or more granular methods (e.g: each method has a very
    specific function)?'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务陈述之后，我们应该开发基础的软件架构。我们希望接口的样子是什么？我们应该通过接口方法中的更多灵活性（例如：更多的参数导致不同的行为）还是通过更细粒度的方法（例如：每个方法都有非常具体的功能）来覆盖功能？
- en: After having that, the styleguide. Outline the preferred modules hierarchy,
    the documentation depth required, how to publish PRs, coverage requirements, etc.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，制定风格指南。概述首选的模块层次结构、所需的文档深度、如何发布 PR、覆盖要求等。
- en: 'With respect to documentation in the code, docstrings need to be sufficiently
    descriptive of the function behaviour but we shouldn’t fall into just copying
    the function name. Sometimes, the function name is sufficiently expressive that
    a docstring explaining its behaviour is just redundant. Be concise and accurate.
    Let’s provide a dumb example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 关于代码中的文档，docstrings 需要充分描述函数的行为，但我们不应仅仅复制函数名称。有时，函数名称已经足够表达其功能，此时 docstring
    解释其行为就显得多余。保持简洁准确。举个简单的例子：
- en: ❌No!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❌不行！
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ✅Yes!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ✅是的！
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Coming to the topic of inline comments, I always like to use them to explain
    certain things that might seem weird or irregular. Also, if I have to use a complex
    logic or fancy syntax, it is always better if you write a clear explanation on
    top of that snippet.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 说到内联注释，我总是喜欢用它们来解释一些可能看起来奇怪或不规则的事情。此外，如果我必须使用复杂的逻辑或花哨的语法，最好在该片段上方写一个清晰的解释。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Apart from that, you can also include links to Github issues or Stackoverflow
    answers. This is really useful, specially if you had to code a weird logic just
    to overcome a known dependency issue. It is also really convenient when you had
    to implement an optimisation trick that you got from Stackoverflow.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以包含指向 Github 问题或 Stackoverflow 回答的链接。这非常有用，特别是当你需要编写一些奇怪的逻辑来解决已知的依赖问题时。当你实施了从
    Stackoverflow 获得的优化技巧时，这也是非常方便的。
- en: These two, interface classes and clear documentation are, in my opinion, the
    best ways to keep a shared library alive for a long time. It will resist lazy
    and conservative new developers and also fully-energized, radical and highly opinionated
    ones. Changes, improvements or revolutionary refactors will be smooth.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这两者——接口类和清晰的文档——是让共享库长时间保持活力的最佳方法。它将抵御懒散和保守的新开发者，同时也能适应充满活力、激进且意见明确的开发者。更改、改进或革命性的重构将会顺利进行。
- en: Applying Software Design Patterns to ETLs
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将软件设计模式应用于 ETL
- en: 'From a code perspective, ETLs should have 3 clearly differentiated high-level
    functions. Each one related to one of the following steps: *Extract, Transform,
    Load*. This is one of the simplest requirements for ETL code.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码的角度来看，ETL 应该有 3 个明显区分的高级功能。每个功能与以下步骤之一相关：*提取、转换、加载*。这是 ETL 代码最简单的要求之一。
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Obviously, it is not mandatory to name these functions like this, but it will
    give you a plus on readability as they are widely accepted terms.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，将这些函数命名为这样并不是强制的，但它会提高可读性，因为这些术语是广泛接受的。
- en: DRY (Don’t Repeat Yourself)
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DRY（不要重复自己）
- en: This is one of the great design patterns which justifies a connectors library.
    You write it once and reuse it across diferent steps or projects.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个伟大的设计模式之一，为连接器库提供了正当理由。你写一次，并在不同的步骤或项目中重用它。
- en: Functional Programming
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数式编程
- en: This is a programming style that aims at making functions “pure” or without
    side-effects. Inputs must be immutable and outputs are always the same given those
    inputs. These functions are easier to test and debug in isolation. Therefore,
    provides a better degree of reproducibility to data pipelines.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种编程风格，旨在使函数“纯”或无副作用。输入必须是不可变的，给定这些输入，输出总是相同的。这些函数更容易在隔离环境下进行测试和调试。因此，为数据管道提供了更好的可重复性。
- en: With functional programming applied to ETLs, we should be able to provide *idempotency*.
    This means that every time we run (or re-run) the pipeline, it should return the
    same outputs. With this characteristic, we are able to confidently operate ETLs
    and be sure that double runs won’t generate duplicate data. How many times you
    had to create a weird SQL query to remove inserted rows from a wrong ETL run?
    Ensuring *idempotency* helps avoiding those situations. Maxime Beauchemin, creator
    of Apache Airflow and Superset, is one known advocate for [*Functional Data Engineering*](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)*.*
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 应用函数式编程到ETL时，我们应该能够提供*幂等性*。这意味着每次运行（或重新运行）管道时，应该返回相同的输出。具有这种特性，我们可以自信地操作ETL，确保重复运行不会生成重复数据。你曾经多少次需要创建一个奇怪的SQL查询来删除错误ETL运行中插入的行？确保*幂等性*有助于避免这些情况。Maxime
    Beauchemin，Apache Airflow和Superset的创始人，是[*函数式数据工程*](https://maximebeauchemin.medium.com/functional-data-engineering-a-modern-paradigm-for-batch-data-processing-2327ec32c42a)*的知名倡导者。
- en: SOLID
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SOLID
- en: We will use references to classes definitions, but this section can also be
    applied to first-class functions. We will be using heavy object-oriented programming
    to explain these concepts, but it doesn’t mean this is the best way of developing
    an ETL. There’s not a specific consensus and each company does it on its own way.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用类定义的引用，但这一部分也可以应用于一等函数。我们将使用重度面向对象编程来解释这些概念，但这并不意味着这是开发ETL的最佳方式。没有具体的共识，每家公司都有自己的方法。
- en: Regarding the *Single Responsibility Principle*, you must create entities that
    have only one reason to change. For example, segregating responsibilities among
    two objects such as a *SalesAggregator* and a *SalesDataCleaner* class. The latter
    is susceptible to contain specific business rules to “clean” data from sales,
    and the former is focused on extracting sales from disparate systems. Both classes
    code can change because of different reasons.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 关于*单一职责原则*，你必须创建只有一个变化原因的实体。例如，将职责分隔到两个对象中，例如*SalesAggregator*和*SalesDataCleaner*类。后者可能包含特定的业务规则来“清理”销售数据，而前者则专注于从不同系统中提取销售数据。这两个类的代码可能会因为不同的原因而变化。
- en: For the *Open-Close Principle,* entities should be expandable to add new features
    but not opened to be modified. Imagine that the *SalesAggregator* received as
    components a *StoresSalesCollector* which is used to extract sales from physical
    stores. If the company started selling online and we wanted to get that data,
    we would state that *SalesCollector* is open for extension if it can receive also
    another *OnlineSalesCollector* with a compatible interface.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*开放-封闭原则*，实体应该可以扩展以添加新功能，但不应开放以进行修改。想象一下，*SalesAggregator*接收了一个*StoresSalesCollector*作为组件，用于从实体店提取销售数据。如果公司开始在线销售并且我们想获取这些数据，我们会声明*SalesCollector*对于扩展是开放的，只要它也能接收另一个具有兼容接口的*OnlineSalesCollector*。
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The Liskov substitution principle, or [*behavioural subtyping*](https://www.youtube.com/watch?v=-Z-17h3jG0A)
    is not so straightforward to apply to ETL design, but it is for the utilities
    library we mentioned before. This principle tries to set a rule for subtypes.
    In a given program that uses the supertype, one could potential substitute it
    with one subtype without altering the behaviour of the program.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 里氏替换原则，或[*行为子类型*](https://www.youtube.com/watch?v=-Z-17h3jG0A)并不容易直接应用于ETL设计，但对于我们之前提到的实用程序库却适用。这个原则试图为子类型设定规则。在使用超类型的程序中，理论上可以用一个子类型来替代它，而不会改变程序的行为。
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We see in the example below that any of the *DatabaseConnector* subtypes conform
    to the Liskov substitution principle as any of its subtypes could be used within
    the *ETLManager* class.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，我们看到任何*DatabaseConnector*的子类型都符合 Liskov 替换原则，因为其任何子类型都可以在*ETLManager*类中使用。
- en: Now, let’s talk about the *Interface Segregation Principle*. It states that
    clients shouldn’t depend on interfaces they don’t use. This one comes very handy
    for the *DatabaseConnector* design. If you’re implementing a *DatabaseConnector*,
    don’t overload the interface class with methods that won’t be used in the context
    of an ETL. For example, you won’t need methods such as *grant_permissions*, or
    *check_log_errors*. Those are related to an administrative usage of the database,
    which is not the case.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈*接口隔离原则*。它指出，客户端不应依赖于它们不使用的接口。这对于*DatabaseConnector*设计非常有用。如果你在实现*DatabaseConnector*，不要用在
    ETL 上下文中不会使用的方法来过载接口类。例如，你不需要*grant_permissions*或*check_log_errors*等方法。这些方法与数据库的管理使用有关，而这并不是我们关注的内容。
- en: The one but not least, the *Dependency Inversion* principle. This one says that
    high-level modules shouldn’t depend on lower-level modules, but instead on abstractions.
    This behaviour is clearly exemplified with the *SalesAggregator* above. Notice
    that its *__init__* method doesn’t depend on concrete implementations of either
    *StoreSalesCollector or OnlineSalesCollector.* It basically depends on a *BaseCollector*
    interface.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的原则是*依赖倒置*原则。这个原则指出，高层模块不应该依赖于低层模块，而应该依赖于抽象。这个行为在上面的*SalesAggregator*中得到了明确的体现。注意，它的*__init__*方法不依赖于*StoreSalesCollector*或*OnlineSalesCollector*的具体实现。它基本上依赖于一个*BaseCollector*接口。
- en: How does a great ML ETL look like?
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个优秀的 ML ETL 应该是什么样的？
- en: We’ve heavily rely on object-oriented classes in the examples above to show
    ways in which we can apply SOLID principles to ETL jobs. Nevertheless, there is
    no general consensus of what’s the best code format and standard to follow when
    building an ETL. It can take very different forms and it tends to be more a problem
    of having an internal well-documented opinionated framework, as discussed previously,
    rather than trying to come up with a global standard across the industry.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上面的例子中重度依赖面向对象的类，以展示如何将 SOLID 原则应用于 ETL 作业。然而，关于构建 ETL 时最好的代码格式和标准，没有普遍的共识。它可以有非常不同的形式，更多的是一个拥有内部良好文档化的观点框架的问题，而不是试图制定一个行业范围内的全球标准。
- en: '![Best Practices for Building ETLs for ML](../Images/0b94f2f9bd0e78878fcfbaf31a3dd7bc.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![构建 ML 用 ETL 的最佳实践](../Images/0b94f2f9bd0e78878fcfbaf31a3dd7bc.png)'
- en: Hence, in this section, I will try to focus on explaining some characteristics
    that make ETL code more legible, secure and reliable.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这一部分，我将尝试专注于解释一些使 ETL 代码更易读、更安全、更可靠的特征。
- en: Command Line Applications
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令行应用程序
- en: All *Data Processes* that you can think of are basically command line applications.
    When developing your ETL in Python, always provide a parametrized CLI interface
    so that you can execute it from any place (E.g, a Docker container that can run
    under a Kubernetes cluster). There are a variety of tools for building command-line
    arguments parsing such as  argparse, [click](https://github.com/pallets/click),
    [typer](https://github.com/tiangolo/typer), yaspin or docopt. Typer is possibly
    the most flexible, easy to use an non-invasive to your existing codebase. It was
    built by the creator of the famous Python web services library FastApi, and its
    Github starts keep growing. The documentation is great and is becoming more and
    more industry-standard.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 所有*数据处理*本质上都是命令行应用程序。在用 Python 开发 ETL 时，总是提供一个参数化的 CLI 接口，以便可以从任何地方执行它（例如，可以在
    Kubernetes 集群下运行的 Docker 容器）。有许多工具可以构建命令行参数解析，如 argparse、[click](https://github.com/pallets/click)、[typer](https://github.com/tiangolo/typer)、yaspin
    或 docopt。Typer 可能是最灵活、易用且对现有代码库侵入性最小的。它由著名的 Python 网络服务库 FastApi 的创作者开发，其 Github
    星标数不断增长。文档很出色，并且正变得越来越符合行业标准。
- en: '[PRE10]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To run the above command, you’d only have to do:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行上述命令，你只需要做：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Process vs Database Engine Compute Trade Off
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理与数据库引擎计算的权衡
- en: The typical recommendation when building ETLs on top of a Data Warehouse is
    to push as much compute processing to the Data Warehouse as possible. That’s all
    right if you have a data warehouse engine that autoscales based on demand. But
    that’s not the case for every company, situation or team. Some ML queries can
    be very long and overload the cluster easily. It’s typical to aggregate data from
    very disparate tables, lookback for years of data, perform point-in-time clauses,
    etc. Hence, pushing everything to the cluster is not always the best option. Isolating
    the compute into the memory of the process instance can be safer in some cases.
    It is risk-free as you won’t hit the cluster and potentially break or delay business-critical
    queries. This is an obvious situation for Spark users, as all the compute & data
    gets distributed across the executors because of the massive scale they need.
    But if you’re working over Redshift or BigQuery clusters always keep an eye into
    how much compute you can delegate to them.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 构建基于数据仓库的 ETL 时，通常建议将尽可能多的计算处理推送到数据仓库。如果你拥有一个根据需求自动扩展的数据仓库引擎，这完全没问题。但并非每个公司、情况或团队都具备这种条件。一些机器学习查询可能非常长，并容易超载集群。通常需要从非常不同的表中汇总数据，回溯多年的数据，执行时间点子句等。因此，将所有计算都推送到集群并不是最好的选择。在某些情况下，将计算隔离到进程实例的内存中可能更安全。这是没有风险的，因为你不会影响集群，从而可能会破坏或延迟业务关键查询。这对于
    Spark 用户来说是显而易见的，因为所有计算和数据都分布在执行器上，因为他们需要的大规模。但如果你在使用 Redshift 或 BigQuery 集群时，总是要注意可以将多少计算委托给它们。
- en: Track Outputs
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪输出
- en: ML ETLs generate different types of output artifacts. Some are Parquet files
    in HDFS, CSV files in S3, tables in the data warehouse, mapping files, reports,
    etc. Those files can later be used to train models, enrich data in production,
    fetch features online and many more options.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习 ETL 生成不同类型的输出工件。一些是 HDFS 中的 Parquet 文件，S3 中的 CSV 文件，数据仓库中的表，映射文件，报告等。这些文件可以用于训练模型、丰富生产数据、在线获取特征等多个选项。
- en: This is quite helpful as you can link dataset building jobs with training jobs
    using the identifier of the artifacts. For example, when using [Neptune track_files()](https://docs.neptune.ai/logging/datasets/)
    method, you can track these kind of files. There’s a very clear example [here](https://docs.neptune.ai/tutorials/data_versioning/#add-tracking-of-dataset-version)
    that you can use.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有帮助，因为你可以使用工件的标识符将数据集构建作业与训练作业链接。例如，当使用 [Neptune track_files()](https://docs.neptune.ai/logging/datasets/)
    方法时，你可以跟踪这些类型的文件。这里有一个非常清晰的例子 [here](https://docs.neptune.ai/tutorials/data_versioning/#add-tracking-of-dataset-version)
    你可以使用。
- en: Implement Automatic Backfilling
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现自动回填
- en: Imagine you have a daily ETL that gets last day’s data to compute a feature
    used to train a model If for any reason your ETL fails to run for a day, the next
    day it runs you would have lost the previous day data computed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一个每日 ETL，它获取前一天的数据以计算用于训练模型的特征。如果由于任何原因你的 ETL 一天未能运行，第二天它运行时，你将丢失前一天计算的数据。
- en: To resolve this, it’s a good practice to look at what’s the last registered
    timestamp in the destination table or file. Then, the ETL can be executed for
    those lagging two days.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，最好查看目标表或文件中最后注册的时间戳。然后，ETL 可以对那些滞后的两天执行。
- en: Develop Loosely Coupled Components
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发松散耦合的组件
- en: 'Code is very susceptible to change, and processes that depend on data even
    more. Events that build up tables can evolve, columns can change, sizes can increase,
    etc. When you have ETLs that depend on different sources of information is always
    good to isolate them in the code. This is because if at any time you have to separate
    both components as two different tasks (E.g: One needs a bigger instance type
    to run the processing because the data has grown), it is much easier to do if
    the code is not spaghetti!'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 代码非常容易改变，而依赖数据的过程更是如此。构建表的事件可能会演变，列可能会改变，大小可能会增加等。当你的 ETL 依赖于不同的数据源时，将它们在代码中隔离总是好的。这是因为如果你需要将两个组件分开作为两个不同的任务（例如：一个需要更大的实例类型来处理，因为数据增加了），如果代码不是混乱的，将更容易做到。
- en: Make Your ETLs Idempotent
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使你的 ETL 幂等
- en: It’s typical to run the same process more than once in case there was an issue
    on the source tables or within the process itself. To avoid generating duplicate
    data outputs or half-filled tables, ETLs should be idempotent. That is, if you
    accidentally run the same ETL twice with the same conditions that the first time,
    the output or side-effects from the first run shouldn’t be affected ([ref](https://www.startdataengineering.com/post/why-how-idempotent-data-pipeline/)).
    You can ensure this is imposed in your ETL by applying the **delete-write** pattern,
    the pipeline will first delete the existing data before writing new data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在源表或过程本身出现问题的情况下，通常会多次运行相同的过程。为了避免生成重复的数据输出或半填充的表格，ETL 应该是幂等的。也就是说，如果你不小心用相同的条件运行相同的
    ETL 两次，第一次运行的输出或副作用不应受到影响（[ref](https://www.startdataengineering.com/post/why-how-idempotent-data-pipeline/)）。你可以通过应用**删除-写入**模式来确保这一点，管道会先删除现有数据，然后再写入新数据。
- en: Keep Your ETLs Code Succinct
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使你的 ETL 代码简洁
- en: I always like to have a clear separation between the actual implementation code
    from the business/logical layer. When I’m building an ETL, the first layer should
    be read as a sequence of steps (functions or methods) that clearly state what
    is happening to the data. Having several layers of abstraction is not bad. It’s
    very helpful if you have have to maintain the ETL for years.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我总是喜欢将实际实现代码与业务/逻辑层进行明确的分离。当我构建 ETL 时，第一层应被视为一系列步骤（函数或方法），明确说明数据发生了什么。拥有多个抽象层并不坏。如果你需要维护
    ETL 多年，这将非常有帮助。
- en: 'Always isolate high-level and low-level functions from each other. It is very
    weird to find something like:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 总是将高层次和低层次的函数彼此隔离。发现类似的情况非常奇怪：
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the example above we are using high-level functions such as the “remove_duplicates”
    and “encode_categorical_columns” but at the same time we’re explicitly showing
    an implementation operation to convert the price with a conversion factor. Wouldn’t
    it be nicer to remove those 2 lines of code and replace them with a “convert_prices”
    function?
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们使用了高层次的函数，如“remove_duplicates”和“encode_categorical_columns”，但同时我们明确展示了一个实现操作，用于通过转换因子转换价格。将这两行代码移除并用一个“convert_prices”函数替换，会不会更好？
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, readability wasn’t a problem, but imagine that instead, you
    embed a 5 lines long groupby operation in the “transform_data” along with the
    “remove_duplicates” and “encode_categorical_columns”. In both cases, you’re mixing
    high-level and low-level functions. It is highly recommended to keep a cohesive
    layered code. Sometimes is inevitable and over-engineered to keep a function or
    module 100% cohesively layered, but it’s a very beneficial goal to pursue.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，可读性不是问题，但假设你将一个长达 5 行的 groupby 操作嵌入到“transform_data”中，与“remove_duplicates”和“encode_categorical_columns”一起。在这两种情况下，你都混合了高层次和低层次的函数。强烈建议保持一致的分层代码。有时候，为了保持函数或模块
    100% 一致性分层，是不可避免且过度工程的，但这是一个非常有益的目标。
- en: Use Pure Functions
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用纯函数
- en: Don’t let side-effects or global states complicate your ETLs. Pure functions
    return the same results if the same arguments are passed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让副作用或全局状态使你的 ETL 变得复杂。纯函数如果传入相同的参数，会返回相同的结果。
- en: ❌The function below is not **pure**. You’re passing a dataframe that is joined
    with another functions that is read from an outside source. This means that the
    table can change, hence, returning a different dataframe, potentially, each time
    the function is called with the same arguments.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❌下面的函数不是**纯函数**。你正在传递一个与另一个从外部源读取的函数连接的 dataframe。这意味着表格可能会发生变化，因此，每次函数被调用时，返回的
    dataframe 可能会不同，即使使用相同的参数。
- en: '[PRE14]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To make this function pure, you would have to do the following:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要使这个函数成为纯函数，你需要执行以下操作：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, when passing the same “data” and “reference_data” arguments, the function
    will yield the same results.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当传递相同的“data”和“reference_data”参数时，函数将产生相同的结果。
- en: This is a simple example, but we all have witnessed worse situations. Functions
    that rely on global state variables, methods that change the state of class attributes
    based on certain conditions, potentially changing the behaviour of other upcoming
    methods in the ETL, etc.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的例子，但我们都见过更糟的情况。依赖全局状态变量的函数、根据某些条件更改类属性状态的方法，可能会改变 ETL 中其他即将出现的方法的行为，等等。
- en: Maximising the use of pure functions leads to more functional ETLs. As we have
    already discussed in points above, it comes with great benefits.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最大限度地使用纯函数可以实现更具功能性的 ETL。正如我们在前面的几点中已经讨论的，它带来了巨大的好处。
- en: Paremetrize As Much As You Can
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尽可能多地参数化
- en: ETLs change. That’s something that we have to assume. Source table definitions
    change, business rules change, desired outcomes evolve, experiments are refined,
    ML models require more sophisticated features, etc.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ETL会发生变化。这是我们必须接受的事实。源表定义、业务规则、期望结果、实验的精细化、ML模型对更复杂特征的需求等都会发生变化。
- en: In order to have some degree of flexibility in our ETLs, we need to thoroughly
    assess where to put most of the effort to provide parametrised executions of the
    ETLs. Parametrisation is a characteristic in which, just by changing *parameters*
    through a simple interface, we can alter the behaviour of the process. The interface
    can be a YAML file, a class initialisation method, function arguments or even
    CLI arguments.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的ETL中拥有一定的灵活性，我们需要深入评估在哪里投入大部分精力来提供参数化执行。参数化是一种特性，通过简单的接口只需更改*参数*即可改变过程的行为。该接口可以是YAML文件、类初始化方法、函数参数甚至CLI参数。
- en: A simple straightforward parametrisation is to define the “environment”, or
    “stage” of the ETL. Before running the ETL into production, where it can affect
    downstream processes and systems, it’s good to have a “test”, “integration” or
    “dev” isolated environments so that we can test our ETLs. That environment might
    involve different levels of isolation. It can go from the execution infrastructure
    (dev instances isolated from production instances), object storage, data warehouse,
    data sources, etc.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单直接的参数化方式是定义ETL的“环境”或“阶段”。在将ETL投入生产之前，最好拥有一个“测试”、“集成”或“开发”隔离环境，以便我们可以测试我们的ETL。该环境可能涉及不同的隔离级别，可以从执行基础设施（开发实例与生产实例隔离）、对象存储、数据仓库、数据源等开始。
- en: That’s an obvious parameter and probably the most important. But we can expand
    the parametrisation also to business-related arguments. We can parametrise window
    dates to run the ETL, columns names that can change or be refined, data types,
    filtering values, etc.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个明显的参数，可能是最重要的。但我们还可以将参数化扩展到与业务相关的参数。我们可以参数化运行ETL的窗口日期、可能更改或细化的列名、数据类型、过滤值等。
- en: Just The Right Amount Of Logging
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 适量记录日志
- en: 'This is one of the most underestimated properties of an ETL. Logs are useful
    to detect production executions anomalies or implicit bugs or explain data sets.
    It’s always useful to log properties about extracted data. Apart from in-code
    validations to ensure the different ETL steps run successfully, we can also log:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ETL中最被低估的属性之一。日志对于检测生产执行异常或隐性错误、解释数据集非常有用。记录提取数据的属性总是很有用。除了代码中的验证以确保不同的ETL步骤成功运行，我们还可以记录：
- en: 'References to source tables, APIs or destination paths (E.g: “Getting data
    from `item_clicks` table”)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来源表、API或目标路径的引用（例如：“从`item_clicks`表中获取数据”）
- en: 'Changes in expected schemas (E.g: “There is a new column in `promotion` table”)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期模式的变化（例如：“`promotion` 表中有一个新列”）
- en: 'The number of rows fetched (E.g: “Fetched 145234093 rows from `item_clicks`
    table”)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取的行数（例如：“从`item_clicks`表中获取145234093行”）
- en: 'The number of null values in critical columns (E.g: “Found 125 null values
    in Source column”)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键列中的空值数量（例如：“在Source列中发现125个空值”）
- en: 'Simple statistics of data (e.g: mean, standard deviation, etc). (E.g: “CTR
    mean: 0.13, CTR std: 0.40)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的简单统计（例如：均值、标准差等）（例如：“CTR均值：0.13，CTR标准差：0.40”）
- en: 'Unique values for categorical columns (E.g: “Country column includes: ‘Spain’,
    ‘France’ and ‘Italy’”)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别列的唯一值（例如：“Country列包含：‘Spain’，‘France’和‘Italy’”）
- en: 'Number of rows deduplicated (E.g: “Removed 1400 duplicated rows”)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去重的行数（例如：“移除1400行重复数据”）
- en: 'Execution times for compute-intensive operations (E.g: “Aggregation took 560s”)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算密集型操作的执行时间（例如：“聚合耗时560秒”）
- en: 'Completion checkpoints for different stages of the ETL (e.g: “Enrichment process
    finished successfully”)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETL不同阶段的完成检查点（例如：“丰富过程成功完成”）
- en: '**[](https://www.linkedin.com/in/manuelmart%C3%ADn11/)**[Manuel Martín](https://www.linkedin.com/in/manuelmart%C3%ADn11/)****
    is an Engineering Manager with more than 6 years of expertise in data science.
    He have previously worked as a data scientist and a machine learning engineer
    and now I lead the ML/AI practice at Busuu.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/manuelmart%C3%ADn11/)**[Manuel Martín](https://www.linkedin.com/in/manuelmart%C3%ADn11/)****
    是一位拥有超过6年数据科学经验的工程经理。他曾担任数据科学家和机器学习工程师，现在负责Busuu的ML/AI实践。'
- en: More On This Topic
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Schedule & Run ETLs with Jupysql and GitHub Actions](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Jupysql 和 GitHub Actions 调度和运行 ETL](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
- en: '[MLOps: The Best Practices and How To Apply Them](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：最佳实践及其应用](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
- en: '[Best Practices for Creating Domain-Specific AI Models](https://www.kdnuggets.com/2022/07/best-practices-creating-domainspecific-ai-models.html)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[创建特定领域 AI 模型的最佳实践](https://www.kdnuggets.com/2022/07/best-practices-creating-domainspecific-ai-models.html)'
- en: '[Integrating ChatGPT Into Data Science Workflows: Tips and Best Practices](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 ChatGPT 集成到数据科学工作流中：技巧和最佳实践](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
- en: '[Data Warehousing and ETL Best Practices](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据仓库和 ETL 的最佳实践](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
- en: '[11 Best Practices of Cloud and Data Migration to AWS Cloud](https://www.kdnuggets.com/2023/04/11-best-practices-cloud-data-migration-aws-cloud.html)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS 云及数据迁移的 11 个最佳实践](https://www.kdnuggets.com/2023/04/11-best-practices-cloud-data-migration-aws-cloud.html)'
