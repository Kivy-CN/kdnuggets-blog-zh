- en: Picking Examples to Understand Machine Learning Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/9ac344170867fbb2fefa67b5f52b56fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Skylar Zilka](https://unsplash.com/@skylarjaybird?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/picking?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluating model relevance does not stop at measuring its performance. For
    many reasons it is important to know how it ended up making such predictions.
    It notably favors: a better understanding of models, explaining how it works to
    non-data specialists, checking bias and model consistency, and debugging,…'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: A machine learning model can be explained using local explainability or global
    explainability.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will use a **complementary approach** by combining **explainability** and **sample
    picking**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Sample picking** is a process with great added value to better understand
    models, their strengths and weaknesses. To explain this approach we will answer
    3 questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Why select samples? What kind of samples would you like to analyze? What
    to analyze in these samples?***'
  prefs: []
  type: TYPE_NORMAL
- en: Local and global explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before that, let us briefly recall local and global explainability notions.
  prefs: []
  type: TYPE_NORMAL
- en: The classical forms of local explainability are weight-based methods.
  prefs: []
  type: TYPE_NORMAL
- en: The prediction of a given sample is explained by decomposing the weight of each
    feature used in the machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/7ac71f008c044c21aa6ab35f4bbd0753.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Global explainability consists of measuring how features are important for
    model prediction. This explainability is often shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/5c013b36f38266d22ce85b211f6b7172.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have quickly introduced the notions of explainability, let’s get
    back to the questions about picking.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, we use [**Shapash**](https://github.com/MAIF/shapash), an
    open-source Python library about explainability. You will find the general presentation
    of Shapash in this [**article**](https://pub.towardsai.net/shapash-making-ml-models-understandable-by-everyone-8f96ad469eb3).
  prefs: []
  type: TYPE_NORMAL
- en: The illustrations below are based on the famous Kaggle datasets: **“**[**Titanic**](https://www.kaggle.com/competitions/titanic/overview)**”** (for
    classification) and **“**[**House Prices**](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)**”** (for
    regression).
  prefs: []
  type: TYPE_NORMAL
- en: Why Select Samples?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To explain how the model works and what are the characteristics of a single
    example or of a sub-population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Let’s take for example the regression model of the price of a house based
    on these characteristics.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*You will be able to explain to a buyer why the house is valued at this price.
    Or how the model estimates houses with bigger surfaces, located in a specific
    neighborhood, and built with wood.*'
  prefs: []
  type: TYPE_NORMAL
- en: To better understand wrong predictions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This can lead to the following questions: Is the problem coming from the data
    quality?'
  prefs: []
  type: TYPE_NORMAL
- en: If we have a very low real price and we estimate that it will be higher because
    the square footage of the house is high, it can question the quality of the “Surface”
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: Could an extra feature improve the prediction?
  prefs: []
  type: TYPE_NORMAL
- en: If a real estate agent provides a textual description of what the buyer likes
    best. Even if this textual variable is not available at the time of prediction,
    we can use it to cross-reference the prediction error on samples with the buyer’s
    feedback.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate correct predictions of the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can take examples to explain the prediction of a machine learning model.
    This process is easier when the most relevant examples are highlighted.
  prefs: []
  type: TYPE_NORMAL
- en: To select samples on which to perform data quality validation or to validate
    the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a data scientist, you can have an idea of the price for some sales that the
    model is supposed to estimate. Exploring its local explainability would also provide
    you with potential reasons for rationalizing the estimation. Then you can observe
    the difference between your thoughts and the local explainability. Based on this
    you might validate or not the data quality, the prediction of the model, and the
    explainability.
  prefs: []
  type: TYPE_NORMAL
- en: To study examples with experts who are familiar with the use case.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By selecting sales, you will be able to see with the real estate agent what
    he thinks about the price prediction and the importance of the features on the
    price.
  prefs: []
  type: TYPE_NORMAL
- en: What Kind of Samples Would you like to Analyze?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is possible to analyze :'
  prefs: []
  type: TYPE_NORMAL
- en: raw model predictions
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: correct predictions/errors (through the association of predictions with the
    known target status)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a subset according to output probabilities of the model prediction, target to
    predict, values of explanatory features
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why not select random samples?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To **save time** and have an **exhaustive vision** of the different cases. Since
    we usually do not evaluate hundreds of samples, selecting them randomly may end
    up randomly picking similar samples. It would thus be possible to miss potentially
    interesting cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Picking: How to Easily and Reliably Pick Meaningful Examples?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since [**Shapash Version 2.2.0**](https://github.com/MAIF/shapash/), You can
    identify these samples by plotting the model probabilities for each sample provided
    as a function of their true label such as :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/6bad0c3b5a805b2bee57ceb3fcfa7164.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 by Author
  prefs: []
  type: TYPE_NORMAL
- en: For binary classification with model output probabilities between 0 and 1, we
    could select a well-predicted class 1 sample. In this case, this class 1 displays,
    as expected a high probability of being in class 1 (as seen in figure 1 example
    A).
  prefs: []
  type: TYPE_NORMAL
- en: Oppositely, we could also select a wrongly predicted class 1 sample. Here this
    sample should be predicted as 0 but has a high probability of being in class 1
    (as seen in figure 1 example B).
  prefs: []
  type: TYPE_NORMAL
- en: For regression, plotting the predicted values against the true values favors
    the direct identification and study of the best or worse predictions returned
    by the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/9ace29b46e7b3b6efaa221f743587202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2 by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'The selection of a subset could ease the understanding of a population’s behavior:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For binary classification, the subset could focus on all points predicted as
    class 1 which are in fact class 0 (i.e. the “False negative” subpopulation).
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/6ec013c78c1d5a280ed2f2c4238e04e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: For regression, it can be interesting to focus on a set of well-estimated, over
    or under-estimated values.
  prefs: []
  type: TYPE_NORMAL
- en: You can also select a subset according to the characteristics of the explanatory
    features.
  prefs: []
  type: TYPE_NORMAL
- en: '*For example, on house price, you can select houses that have a construction
    date higher than 2000\. Or according to the location of the house.*'
  prefs: []
  type: TYPE_NORMAL
- en: What to Analyze in these Samples?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you want to explain a single sample, it is interesting to look at its local
    explicability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, using shapash webapp, you can select a single sample you want
    to analyze in the local plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/a109acd243e86a69d219afca0a89acaa.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The sample with the index “206” has a survival probability of 0.99, but its
    real label is “Death”. For this individual, the local interpretability indicates
    that the probability is mainly determined by the age (2 years) and by the sex
    (female).
  prefs: []
  type: TYPE_NORMAL
- en: Oppositely, the sample with the index “571” has a survival probability of 0.005,
    but its real label is “Survival”. Here again, the local interpretability indicates
    that the probability is mainly determined by the age (62 years) and by the sex
    (male).
  prefs: []
  type: TYPE_NORMAL
- en: In these 2 cases, in relation to the global functioning of the model, we understand
    that it is normal for the model to be wrong. For example, check that the “age”
    data is collected correctly, or ask whether any other data can explain that older
    men have survived. We can also wonder if these types of individuals are often
    shown in the dataset. Indeed, if only a few examples exist, the model is unable
    to properly learn reliable rules.
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, it may help to question the data choice, data quality, or the
    need to collect other features.
  prefs: []
  type: TYPE_NORMAL
- en: When you want to understand a sub-population, you can look at the global explainability
    of that sub-population and compare it to the global population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, if you want to zoom in on the “False negative” in this app:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Picking examples to understand your machine learning model](../Images/463edd404a548534d9b97e7ef3d8cf4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can see if the importance of features for the subset is similar to the overall
    population.
  prefs: []
  type: TYPE_NORMAL
- en: For the “False negative” subpopulation, there is a decrease in the weight of
    the “Sex” feature on the prediction (grey vs yellow bar). This could rely on the
    fact that women are underrepresented in this subset. As the “Sex” feature has
    less impact, the other features take over. We can see that many wrong predictions
    rely on the variable “age”, for individuals between 20 and 30 years old.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of selecting a subset rather than a single sample is that we can **generalize** wrong
    or correct predictions, and specifically look at their global explainability in
    regard to the whole population.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, an extra feature might help to better classify men in their
    twenties.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Picking** **single samples** or a **subset** is a complementary approach
    that helps data scientists to understand their models.'
  prefs: []
  type: TYPE_NORMAL
- en: These approaches can be used as powerful tools to **explain the models to non-data
    technicians**. It provides reliable explanations of predictions on samples to **illustrate** how
    the model works.
  prefs: []
  type: TYPE_NORMAL
- en: Sub-populations could also be described and qualified using clustering approaches.
  prefs: []
  type: TYPE_NORMAL
- en: If you use picking techniques to help understand a model, feel free to explain
    it in the comments!
  prefs: []
  type: TYPE_NORMAL
- en: '**[Thomas Bouche](https://medium.com/@thomas.bouche_2245)** is a Data Scientist
    at MAIF.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[24 Best (and Free) Books To Understand Machine Learning](https://www.kdnuggets.com/2020/03/24-best-free-books-understand-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ensemble Learning with Examples](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SQL LIKE Operator Examples](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Graphs: The natural way to understand data](https://www.kdnuggets.com/2022/10/manning-graphs-natural-way-understand-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using SQL to Understand Data Science Career Trends](https://www.kdnuggets.com/using-sql-to-understand-data-science-career-trends)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Segment Anything Model: Foundation Model for Image Segmentation](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
