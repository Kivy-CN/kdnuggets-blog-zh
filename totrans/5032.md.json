["```py\n#include \"tiny_cnn/tiny_cnn.h\"\nusing namespace tiny_cnn;\nusing namespace tiny_cnn::activation;\n\nvoid construct_mlp() {\n    auto mynet = make_mlp<tan_h>({ 32 * 32, 300, 10 });\n\n    assert(mynet.in_data_size() == 32 * 32);\n    assert(mynet.out_data_size() == 10);\n}\n\n```", "```py\nfrom layered.network import Network\nfrom layered.activation import Identity, Relu, Softmax\n\nnum_inputs = 784\nnum_outputs = 10\n\nnetwork = Network([\n    Layer(num_inputs, Identity),\n    Layer(700, Relu),\n    Layer(500, Relu),\n    Layer(300, Relu),\n    Layer(num_outputs, Softmax),\n])\n\n```", "```py\nvar net = new brain.NeuralNetwork();\n\nnet.train([{input: [0, 0], output: [0]},\n{input: [0, 1], output: [1]},\n{input: [1, 0], output: [1]},\n{input: [1, 1], output: [0]}]);\n\nvar output = net.run([1, 0]); // [0.987]\n\n```", "```py\nnet.train(data, {\n  errorThresh: 0.005,  // error threshold to reach\n  iterations: 20000,   // maximum training iterations\n  log: true,           // console.log() progress periodically\n  logPeriod: 10,       // number of iterations between logging\n  learningRate: 0.3    // learning rate\n})\n\n```"]