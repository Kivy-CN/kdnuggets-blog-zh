- en: '30 Years of Data Science: A Review From a Data Science Practitioner'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 30年数据科学：数据科学从业者的回顾
- en: 原文：[https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner](https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner](https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner)
- en: '![30 Years of Data Science: A Review From a Data Science Practitioner](../Images/ab1465c448144225caa94e4f1cf5ccaf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![30年数据科学：数据科学从业者的回顾](../Images/ab1465c448144225caa94e4f1cf5ccaf.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图片
- en: 30 years of KDnuggets and 30 years of data science. More or less 30 years of
    my professional life. One of the privileges that comes with working in the same
    field for a long time - aka experience - is the chance to write about its evolution,
    as a direct eye witness.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 30年的KDnuggets和30年的数据科学。差不多是我职业生涯的30年。长期从事同一领域工作所带来的特权之一——即经验——就是有机会作为直接目击者撰写其演变过程。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The Algorithms
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法
- en: 'I started working at the beginning of the 90s on what was then called Artificial
    Intelligence, referring to a new paradigm that was self-learning, mimicking organizations
    of nervous cells, and that did not require any statistical hypothesis to be verified:
    yes, neural networks! An efficient usage of the Back-Propagation algorithm had
    been published just a few years earlier [1], solving the problem of training hidden
    layers in multilayer neural networks, enabling armies of enthusiastic students
    to tackle new solutions to a number of old use cases. Nothing could have stopped
    us … just the machine power.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我在90年代初开始从事当时称为人工智能的工作，指的是一种自我学习的新范式，模仿神经细胞的组织，并且不需要验证任何统计假设：没错，就是神经网络！几年前刚刚发布了有效使用回传算法的研究成果[1]，解决了多层神经网络隐藏层训练的问题，使得一大批热情的学生能够探索多种老用例的新解决方案。没有什么能阻止我们……只有机器性能。
- en: Training a multilayer neural network requires quite some computational power,
    especially if the number of network parameters is high and the dataset is large.
    Computational power, that the machines at the time did not have. Theoretical frameworks
    were developed, like Back-Propagation Through Time (BPTT) in 1988 [2] for time
    series or Long Short Term Memories (LSTM) [3] in 1997 for selective memory learning.
    However, computational power remained an issue and neural networks were parked
    by most data analytics practitioners, waiting for better times.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个多层神经网络需要相当大的计算能力，特别是当网络参数数量多且数据集庞大时。计算能力是当时机器所缺乏的。理论框架已经发展出来，如1988年的时间序列回传算法（BPTT）[2]或1997年的长短期记忆网络（LSTM）[3]用于选择性记忆学习。然而，计算能力仍然是个问题，大多数数据分析从业者将神经网络搁置，等待更好的时机。
- en: In the meantime, leaner and often equally performing algorithms appeared. Decision
    trees in the form of C4.5 [4] became popular in 1993, even though in the CART
    [5] form had already been around since 1984\. Decision trees were lighter to train,
    more intuitive to understand, and often performed well enough on the datasets
    of the time. Soon, we also learned to combine many decision trees together as
    a forest [6], in the random forest algorithm, or as a cascade [7] [8], in the
    gradient boosted trees algorithm. Even though those models are quite large, that
    is with a large number of parameters to train, they were still manageable in a
    reasonable time. Especially the gradient boosted trees, with its cascade of trees
    trained in sequence, diluted the required computational power over time, making
    it a very affordable and very successful algorithm for data science.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，出现了更精简且通常表现相当的算法。决策树形式的 C4.5 [4] 在 1993 年变得流行，尽管以 CART [5] 形式的决策树早在 1984
    年就已存在。决策树训练起来更轻便，更易于理解，并且在当时的数据集上表现良好。很快，我们还学会了将多个决策树组合成一个森林 [6]，在随机森林算法中，或组合成一个级联
    [7] [8]，在梯度提升树算法中。尽管这些模型相当庞大，即有大量的参数需要训练，但在合理的时间内仍然可管理。尤其是梯度提升树，利用级联的树按序列训练，将所需的计算能力分散到时间上，使其成为数据科学中非常实惠且成功的算法。
- en: 'Till the end of the 90s, all datasets were classic datasets of reasonable size:
    customer data, patient data, transactions, chemistry data, and so on. Basically,
    classic business operations data. With the expansion of social media, ecommerce,
    and streaming platforms, data started to grow at a much faster pace, posing completely
    new challenges. First of all, the challenge of storage and fast access for such
    large amounts of structured and unstructured data. Secondly, the need for faster
    algorithms for their analysis. Big data platforms took care of storage and fast
    access. Traditional relational databases hosting structured data left space to
    new data lakes hosting all kinds of data. In addition, the expansion of ecommerce
    businesses propelled the popularity of recommendation engines. Either used for
    market basket analysis or for video streaming recommendations, two of such algorithms
    became commonly used: the apriori algorithm [9] and the collaborative filtering
    algorithm [10].'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 直到 90 年代末，所有数据集都是经典的、合理大小的数据集：客户数据、患者数据、交易数据、化学数据等等。基本上，都是经典的业务操作数据。随着社交媒体、电子商务和流媒体平台的扩展，数据开始以更快的速度增长，带来了全新的挑战。首先是存储和快速访问如此大量结构化和非结构化数据的挑战。其次是对更快算法的需求来进行分析。大数据平台负责存储和快速访问。传统的关系型数据库承载结构化数据，逐渐让位于新的数据湖，这些数据湖承载各种类型的数据。此外，电子商务业务的扩展推动了推荐引擎的普及。无论是用于市场篮子分析还是视频流推荐，这两种算法变得常用：apriori
    算法 [9] 和协同过滤算法 [10]。
- en: In the meantime, performance of computer hardware improved reaching unimaginable
    speed and … we are back to the neural networks. GPUs started being used as accelerators
    for the execution of specific operations in neural network training, allowing
    for more and more complex neural algorithms and neural architectures to be created,
    trained, and deployed. This second youth of neural networks took on the name of
    deep learning [11] [12]. The term Artificial Intelligence (AI) started resurfacing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，计算机硬件的性能得到了提升，达到了难以想象的速度……我们又回到了神经网络。GPU 开始被用作神经网络训练中特定操作的加速器，使得越来越复杂的神经算法和神经架构得以创建、训练和部署。这一神经网络的第二次青春被称为深度学习
    [11] [12]。人工智能（AI）这一术语开始重新浮现。
- en: 'A side branch of deep learning, generative AI [13], focused on generating new
    data: numbers, texts, images, and even music. Models and datasets kept growing
    in size and complexity to attain the generation of more realistic images, texts,
    and human-machine interactions.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的一个分支，生成式 AI [13]，专注于生成新数据：数字、文本、图像，甚至音乐。模型和数据集的规模和复杂性不断增长，以实现更现实的图像、文本和人机互动的生成。
- en: New models and new data were quickly substituted by new models and new data
    in a continuous cycle. It became more and more an engineering problem rather than
    a data science problem. Recently, due to an admirable effort in data and machine
    learning engineering, automatic frameworks have been developed for continuous
    data collection, model training, testing, human in the loop actions, and finally
    deployment of very large machine learning models. All this engineering infrastructure
    is at the basis of the current Large Language Models (LLMs), trained to provide
    answers to a variety of problems while simulating a human to human interaction.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 新模型和新数据在一个持续循环中迅速被新的模型和数据所替代。它越来越成为一个工程问题，而不是数据科学问题。最近，由于数据和机器学习工程方面的卓越努力，已经开发出了用于持续数据收集、模型训练、测试、人机交互动作，以及最终部署大型机器学习模型的自动化框架。所有这些工程基础设施是当前大型语言模型（LLMs）的基础，这些模型经过训练，旨在提供各种问题的答案，同时模拟人际互动。
- en: The Life Cycle
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生命周期
- en: 'More than around the algorithms, the biggest change in data science in the
    last years, in my opinion, has taken place in the underlying infrastructure: from
    frequent data acquisition to continuous smooth retraining and redeployment of
    models. That is, there has been a shift in data science from a research discipline
    into an engineering effort.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，过去几年数据科学最大的变化不在于算法，而在于基础设施的变革：从频繁的数据获取到模型的持续平滑再训练和重新部署。也就是说，数据科学已经从一个研究学科转变为一个工程努力。
- en: The life cycle of a machine learning model has changed from a single cycle of
    pure creation, training, testing, and deployment, like CRISP-DM [14] and other
    similar paradigms, to a double cycle covering creation on one side and productionisation
    - deployment, validation, consumption, and maintenance - on the other side [15].
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的生命周期已经从类似CRISP-DM [14]的纯创建、训练、测试和部署的单一周期，变成了一个双周期，其中一边是创建，而另一边是生产化——部署、验证、消费和维护
    [15]。
- en: '![30 Years of Data Science: A Review From a Data Science Practitioner](../Images/e6990b731d915adcf0f483a65b378a04.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![30年的数据科学：来自数据科学从业者的回顾](../Images/e6990b731d915adcf0f483a65b378a04.png)'
- en: Fig. 1 The life cycle of a machine learning model
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 机器学习模型的生命周期
- en: The Tools
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具
- en: 'Consequently, data science tools had to adapt. They had to start supporting
    not only the creation phase but also the productionization phase of a machine
    learning model. There had to be two products or two separate parts within the
    same product: one to support the user in the creation and training of a data science
    model and one to allow for a smooth and error-free productionisation of the final
    result. While the creation part is still an exercise of the intellect, the productionisation
    part is a structured repetitive task.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据科学工具不得不适应变化。它们不仅要支持创建阶段，还要支持机器学习模型的生产化阶段。必须有两个产品或一个产品的两个独立部分：一个支持用户创建和训练数据科学模型，另一个则使最终结果的生产化过程顺畅且无误。虽然创建部分仍然是智力的练习，但生产化部分则是结构化的重复任务。
- en: Obviously for the creation phase, data scientists need a platform with extensive
    coverage of machine learning algorithms, from the basic ones to the most advanced
    and sophisticated ones. You never know which algorithm you will need to solve
    which problem. Of course, the most powerful models have a higher chance of success,
    that comes at the price of a higher risk of overfitting and slower execution.
    Data scientists in the end are like artisans who need a box full of different
    tools for the many challenges of their work.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在创建阶段，数据科学家需要一个涵盖广泛机器学习算法的平台，从基本算法到最先进、最复杂的算法应有尽有。你永远不知道你需要哪个算法来解决哪个问题。当然，最强大的模型成功的机会更高，但代价是更高的过拟合风险和较慢的执行速度。数据科学家最终就像工匠一样，需要一个装满各种工具的工具箱，以应对他们工作中的各种挑战。
- en: Low code based platforms have also gained popularity, since low code enables
    programmers and even non-programmers to create and quickly update all sorts of
    data science applications.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 低代码平台也获得了人气，因为低代码使程序员甚至非程序员能够创建和快速更新各种数据科学应用程序。
- en: As an exercise of the intellect, the creation of machine learning models should
    be accessible to everybody. This is why, though not strictly necessary, an open
    source platform for data science would be desirable. Open-source allows free access
    to data operations and machine learning algorithms to all aspiring data scientists
    and at the same time allows the community to investigate and contribute to the
    source code.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作为智力的练习，机器学习模型的创建应该对每个人都可及。这就是为什么，尽管不是绝对必要的，但一个开源的数据科学平台将是理想的。开源允许所有有志于数据科学的人员自由访问数据操作和机器学习算法，同时允许社区调查和贡献源代码。
- en: On the other side of the cycle, productionization requires a platform that provides
    a reliable IT framework for deployment, execution, and monitoring of the ready-to-go
    data science application.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在生命周期的另一端，生产化需要一个提供可靠IT框架的平台，用于部署、执行和监控准备好的数据科学应用程序。
- en: Conclusion
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Summarizing 30 years of data science evolution in less than 2000 words is of
    course impossible. In addition, I quoted the most popular publications at the
    time, even though they might not have been the absolute first ones on the topic.
    I apologize already for the many algorithms that played an important role in this
    process and that I did not mention here.  Nevertheless, I hope that this short
    summary gives you a deeper understanding of where and why we are now in the space
    of data science 30 years later!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在不到2000字的篇幅中总结30年的数据科学发展当然是不可能的。此外，我引用了当时最受欢迎的出版物，尽管它们可能不是该主题上的绝对首篇。我对那些在这一过程中扮演了重要角色但未在这里提及的许多算法表示歉意。尽管如此，我希望这段简短的总结能让你对数据科学在30年后的现状有更深入的理解！
- en: Bibliography
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Rumelhart, D.E.; Hinton, G.E.; Williams, R.J. (1986). “Learning representations
    by back-propagating errors”. *Nature*, 323, p. 533-536.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Rumelhart, D.E.; Hinton, G.E.; Williams, R.J. (1986). “通过误差反向传播学习表示”。*自然*，323，页码
    533-536。'
- en: '[2] Werbos, P.J.  (1988). ["Generalization of backpropagation with application
    to a recurrent gas market model"](https://zenodo.org/record/1258627). *Neural
    Networks*. 1 (4): 339–356. [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1016/0893-6080(88)90007](https://doi.org/10.1016%2F0893-6080%2888%2990007-x)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Werbos, P.J. (1988). ["反向传播的泛化及其在递归气体市场模型中的应用"](https://zenodo.org/record/1258627)。*神经网络*。1
    (4): 339–356。 [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1016/0893-6080(88)90007](https://doi.org/10.1016%2F0893-6080%2888%2990007-x)'
- en: '[3] [Hochreiter](https://en.wikipedia.org/wiki/Sepp_Hochreiter), S.; Schmidhuber,
    J.  (1997). "Long Short-Term Memory". *Neural Computation*. **9** (8): 1735–1780.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [Hochreiter](https://en.wikipedia.org/wiki/Sepp_Hochreiter), S.; Schmidhuber,
    J. (1997). "长短期记忆". *神经计算*。**9** (8): 1735–1780。'
- en: '[4] Quinlan, J. R. (1993). “C4.5: Programs for Machine Learning” *Morgan Kaufmann
    Publishers*.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Quinlan, J. R. (1993). “C4.5：机器学习程序” *摩根·考夫曼出版社*。'
- en: '[5] Breiman, L. ; Friedman, J.; Stone, C.J.; Olshen, R.A. (1984) “Classification
    and Regression Trees”, Routledge. [https://doi.org/10.1201/9781315139470](https://doi.org/10.1201/9781315139470)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Breiman, L.; Friedman, J.; Stone, C.J.; Olshen, R.A. (1984) “分类与回归树”，Routledge。
    [https://doi.org/10.1201/9781315139470](https://doi.org/10.1201/9781315139470)'
- en: '[6] Ho, T.K.  (1995). [*Random Decision Forests*](https://web.archive.org/web/20160417030218/http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf).
    *Proceedings of the 3rd International Conference on Document Analysis and Recognition*,
    Montreal, QC, 14–16 August 1995\. pp. 278–282'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Ho, T.K. (1995). [*随机决策森林*](https://web.archive.org/web/20160417030218/http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf).
    *第三届国际文档分析与识别会议论文集*，蒙特利尔，QC，1995年8月14-16日，页码 278-282。'
- en: '[7] Friedman, J. H. (1999). ["Greedy Function Approximation: A Gradient Boosting
    Machine](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf), Reitz Lecture'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Friedman, J. H. (1999). ["贪婪函数近似：一种梯度提升机器](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)，Reitz讲座'
- en: '[8] Mason, L.; Baxter, J.; Bartlett, P. L.; Frean, Marcus (1999). ["Boosting
    Algorithms as Gradient Descent"](http://papers.nips.cc/paper/1766-boosting-algorithms-as-gradient-descent.pdf).
    In [S.A. Solla](https://en.wikipedia.org/wiki/Sara_Solla) and T.K. Leen and K.
    Müller (ed.). *Advances in Neural Information Processing Systems 12*. MIT Press.
    pp. 512–518'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Mason, L.; Baxter, J.; Bartlett, P. L.; Frean, Marcus (1999). ["将提升算法视为梯度下降"](http://papers.nips.cc/paper/1766-boosting-algorithms-as-gradient-descent.pdf)。见
    [S.A. Solla](https://en.wikipedia.org/wiki/Sara_Solla) 和 T.K. Leen 和 K. Müller
    (编辑)。*神经信息处理系统进展 12*。MIT出版社。页码 512-518'
- en: '[9] Agrawal, R.; Srikant, R (1994) [Fast algorithms for mining association
    rules](http://www.vldb.org/conf/1994/P487.PDF). *Proceedings of the 20th International
    Conference on Very Large Data Bases*, VLDB, pages 487-499, Santiago, Chile, September
    1994.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Agrawal, R.; Srikant, R (1994) [“挖掘关联规则的快速算法”](http://www.vldb.org/conf/1994/P487.PDF)。
    *第20届国际大型数据库会议论文集*，VLDB，第487-499页，智利圣地亚哥，1994年9月。'
- en: '[10] Breese, J.S.; Heckerman, D,; Kadie C. (1998) “Empirical Analysis of Predictive
    Algorithms for Collaborative Filtering”, *Proceedings of the Fourteenth Conference
    on Uncertainty in Artificial Intelligence* (UAI1998)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Breese, J.S.; Heckerman, D.; Kadie C. (1998) “协同过滤预测算法的实证分析”， *第十四届人工智能不确定性会议论文集*
    (UAI1998)'
- en: '[11] Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). "Multi-column deep neural
    networks for image classification". *2012 IEEE Conference on Computer Vision and
    Pattern Recognition*. pp. 3642–3649. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier)):[1202.2745](https://arxiv.org/abs/1202.2745).
    [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1109/cvpr.2012.6248110](https://doi.org/10.1109%2Fcvpr.2012.6248110).
    [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier)) [978-1-4673-1228-8](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4673-1228-8).
    [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier)) [2161592](https://api.semanticscholar.org/CorpusID:2161592).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). “用于图像分类的多列深度神经网络”。*2012
    IEEE计算机视觉与模式识别会议*，第3642–3649页。 [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier)):[1202.2745](https://arxiv.org/abs/1202.2745)。
    [doi](https://en.wikipedia.org/wiki/Doi_(identifier)):[10.1109/cvpr.2012.6248110](https://doi.org/10.1109%2Fcvpr.2012.6248110)。
    [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier)) [978-1-4673-1228-8](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4673-1228-8)。
    [S2CID](https://en.wikipedia.org/wiki/S2CID_(identifier)) [2161592](https://api.semanticscholar.org/CorpusID:2161592)。'
- en: '[12] Krizhevsky, A.; Sutskever, I.; Hinton, G. (2012). ["ImageNet Classification
    with Deep Convolutional Neural Networks"](https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf).
    *NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada*.[ ](https://web.archive.org/web/20170110123024/http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] Krizhevsky, A.; Sutskever, I.; Hinton, G. (2012). [“使用深度卷积神经网络进行ImageNet分类”](https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf)。
    *NIPS 2012: 神经信息处理系统，内华达州湖塔霍*。[ ](https://web.archive.org/web/20170110123024/http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf)'
- en: '[13] Hinton, G.E.; Osindero, S.; Teh, Y.W. (2006) ”A Fast Learning Algorithm
    for Deep Belief Nets”. *Neural Comput* 2006; 18 (7): 1527–1554\. doi: [https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Hinton, G.E.; Osindero, S.; Teh, Y.W. (2006) “一种快速的深度信念网络学习算法”。 *Neural
    Comput* 2006; 18 (7): 1527–1554\. doi: [https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527)'
- en: '[14] Wirth, R.; Jochen, H.. (2000) “CRISP-DM: Towards a Standard Process Model
    for Data Mining.” *Proceedings of the 4th international conference on the practical
    applications of knowledge discovery and data mining* (4), pp. 29–39.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] Wirth, R.; Jochen, H. (2000) “CRISP-DM: 面向数据挖掘的标准过程模型。” *第四届国际知识发现与数据挖掘应用会议论文集*
    (4)，第29–39页。'
- en: '[15] Berthold, R.M. (2021) “[How to move data science into production](https://www.knime.com/blog/how-to-move-data-science-into-production)”,
    KNIME Blog'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[15] Berthold, R.M. (2021) [“如何将数据科学转移到生产环境”](https://www.knime.com/blog/how-to-move-data-science-into-production)，KNIME博客'
- en: '**[Rosaria Silipo](https://www.linkedin.com/in/rosaria/?originalSubdomain=ch)**
    is not only an expert in data mining, machine learning, reporting, and data warehousing,
    she has become a recognized expert on the KNIME data mining engine, about which
    she has published three books: KNIME Beginner’s Luck, The KNIME Cookbook, and
    The KNIME Booklet for SAS Users. Previously Rosaria worked as a freelance data
    analyst for many companies throughout Europe. She has also led the SAS development
    group at Viseca (Zürich), implemented the speech-to-text and text-to-speech interfaces
    in C# at Spoken Translation (Berkeley, California), and developed a number of
    speech recognition engines in different languages at Nuance Communications (Menlo
    Park, California). Rosaria gained her doctorate in biomedical engineering in 1996
    from the University of Florence, Italy.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Rosaria Silipo](https://www.linkedin.com/in/rosaria/?originalSubdomain=ch)**
    不仅是数据挖掘、机器学习、报告和数据仓库的专家，她还成为了KNIME数据挖掘引擎的公认专家，关于这个领域她已经出版了三本书：《KNIME初学者的好运》、《KNIME食谱》和《KNIME
    SAS用户手册》。此前，Rosaria曾在欧洲多家公司担任自由数据分析师。她还曾领导Viseca（苏黎世）的SAS开发小组，在Spoken Translation（加州伯克利）用C#实现了语音转文本和文本转语音接口，并在Nuance
    Communications（加州门洛帕克）开发了多个不同语言的语音识别引擎。Rosaria于1996年在意大利佛罗伦萨大学获得生物医学工程博士学位。'
- en: More On This Topic
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Ten Years of AI in Review](https://www.kdnuggets.com/2023/06/ten-years-ai-review.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI十年回顾](https://www.kdnuggets.com/2023/06/ten-years-ai-review.html)'
- en: '[Hidden Technical Debts Every AI Practitioner Should be Aware of](https://www.kdnuggets.com/2022/07/hidden-technical-debts-every-ai-practitioner-aware.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个AI从业者应当了解的隐藏技术债务](https://www.kdnuggets.com/2022/07/hidden-technical-debts-every-ai-practitioner-aware.html)'
- en: '[How I 14Xed my salary in 14 years as a data analytics/science professional](https://www.kdnuggets.com/2021/12/14x-salary-in-14-years-data-professional.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在14年内将我的薪资提高14倍作为数据分析/科学专业人士](https://www.kdnuggets.com/2021/12/14x-salary-in-14-years-data-professional.html)'
- en: '[40% of Labour Force Will be Affected by AI in 3 Years](https://www.kdnuggets.com/40-of-labour-force-will-be-affected-by-ai-in-3-years)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40%的劳动力将在3年内受到AI的影响](https://www.kdnuggets.com/40-of-labour-force-will-be-affected-by-ai-in-3-years)'
- en: '[Google Data Analytics Certification Review for 2023](https://www.kdnuggets.com/2023/01/google-data-analytics-certification-review-2023.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年Google数据分析认证评论](https://www.kdnuggets.com/2023/01/google-data-analytics-certification-review-2023.html)'
- en: '[Python For Machine Learning: eBook Review](https://www.kdnuggets.com/2022/06/python-machine-learning-ebook-review.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的Python：电子书评论](https://www.kdnuggets.com/2022/06/python-machine-learning-ebook-review.html)'
