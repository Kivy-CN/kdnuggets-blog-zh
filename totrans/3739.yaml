- en: Explain NLP Models with LIME
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/01/explain-nlp-models-lime.html](https://www.kdnuggets.com/2022/01/explain-nlp-models-lime.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is very important to know how LIME reaches to its final outputs for explaining
    a prediction done for text data. In this article, I have shared that concept by
    enlightening the components of LIME.
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/83111f6cff2c0031977b71b290ff7b61.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ethan Medrano](https://unsplash.com/@itsethan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/magnifying-glass-text?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Few weeks back I wrote a [blog](https://towardsdatascience.com/explainable-ai-an-illuminator-in-the-field-of-black-box-machine-learning-62d805d54a7a) on
    how different interpretability tools can be used to interpret certain predictions
    done by the black-box models. In that article I shared the mathematics behind
    LIME, SHAP and other interpretability tools, but I did not go much into details
    of implementing those concepts on original data. In this article, I thought of
    sharing how LIME works on text data in a step-by-step manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data that is used for the whole analysis is taken from [here](https://www.kaggle.com/c/nlp-getting-started/overview) .
    This data is for predicting whether a given tweet is about a real disaster(1)
    or not(0). It has the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/ea3fdda6795fee3f3428ce351623f7f3.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Source](https://www.kaggle.com/c/nlp-getting-started/data)'
  prefs: []
  type: TYPE_NORMAL
- en: As the main focus of this blog is to interpret [LIME](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_text) and
    its different components so we will quickly build a binary text classification
    model using Random Forest and will focus mainly on LIME interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: First, we start with importing the necessary packages. Then we read the data
    and start preprocessing like stop words removal, Lowercase, lemmatization, punctuation
    removal, whitespace removal etc. All the cleaned preprocessed text are stored
    in a new ‘cleaned_text’ column which will be further used for analysis and the
    data is split into train and validation set in a ratio of 80:20.
  prefs: []
  type: TYPE_NORMAL
- en: Then we quickly move to converting the text data into vectors using [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) vectoriser
    and fitting a [Random Forest](https://en.wikipedia.org/wiki/Random_forest) classification
    model on that.
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/0409de5351ef5d8565b1c417b090747f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s begin the main interest of this blog which is how to interpret different
    components of LIME.
  prefs: []
  type: TYPE_NORMAL
- en: First let’s see what is the final output of the LIME interpretation for a particular
    data instance. Then we will go deep dive into the different components of LIME
    in a step by step manner which will finally result the desired output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/9df02ffbb8a78e583d15659474c59d36.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Here labels=(1,) is passed as an argument that means we want the explanation
    for the class 1\. The features (words in this case) highlighted with orange are
    the top features that cause a prediction of class 0 (not disaster) with probability
    0.75 and class 1(disaster) with probability 0.25.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: char_level is one of the arguments for LimeTextExplainer which is
    a boolean identifying that we treat each character as an independent occurrence
    in the string. Default is False so we don’t consider each character independently
    and IndexedString function is used for tokenization and indexing the words in
    the text instance, otherwise IndexedCharacters function is used.'
  prefs: []
  type: TYPE_NORMAL
- en: '*So, you must be interested to know how these are calculated. Right?*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see that.
  prefs: []
  type: TYPE_NORMAL
- en: LIME starts with creating some perturbed samples around the neighbourhood of
    data point of interest. For text data, perturbed samples are created by randomly
    removing some of the words from the instance and cosine distance is used to calculate
    the distance between the original and perturbed samples as default metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'This returns the array of 5000 perturbed samples(each perturbed sample is of
    length of the original instance and 1 means the word in that position of the original
    instance is present in the perturbed sample), their corresponding prediction probabilities
    and the cosine distances between the original and perturbed samples.A snippet
    of that is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/6584e38ed39751bc52ad19db4fc33c4d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Now after creating the perturbed samples in the neighbourhood it’s time to give
    weights to those samples. Samples that are near from the original instance are
    given higher weightage than the samples far from the original instance. [Exponential
    kernel](https://www.cs.toronto.edu/~duvenaud/cookbook/) with kernel width 25 is
    used as default to give those weightage.
  prefs: []
  type: TYPE_NORMAL
- en: 'After that important features(as per num_features: max number of features to
    be explained) are selected by learning a locally linear sparse model from perturbed
    data. There are several methods for choosing the important features using the
    local linear sparse model like ‘auto’(default), ‘forward_selection’, ‘lasso_path’,
    ‘highest_weights’. If we choose ‘auto’ then ‘forward_selection’ is used if num_features≤6,
    else ‘highest_weights’ is used.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/4033a8b5526b06a2c468d61c92943a80.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Here we can see that the features selected are [1,5,0,2,3] which are the indices
    of the important words(or features) in the original instance. As here num_features=5
    and method=‘auto’, ‘forward_selection’ method is used for selecting the important
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s see what will happen if we choose method as ‘lasso_path’.
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/4d26df070bc192e4d766b93318ea777e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Same. Right?
  prefs: []
  type: TYPE_NORMAL
- en: '*But you might be interested to go deep dive into this process of selection.
    Don’t worry, I will make that easy.*'
  prefs: []
  type: TYPE_NORMAL
- en: It uses the concept of [Least angle regression](http://www.cse.iitm.ac.in/~vplab/courses/SLT/PDF/LAR_hastie_2018.pdf) for
    selecting the top features.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see what will happen if we select method as ‘highest_weights’.
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/f2fcf30afefa146658be6bb2a92c131d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: '*Hang on. We are going deeper in the selection process.*'
  prefs: []
  type: TYPE_NORMAL
- en: So now the important features we have selected by using any one of the methods.
    But finally we will have to fit a local linear model to explain the prediction
    done by the black-box model. For that [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression) is
    used as default.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s check how the outputs will look like finally.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we select method as auto, highest_weights and lasso_path respectively the
    output will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/2323333d776ba785702665162b0a461a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: These return a tuple (intercept of the local linear model, important features
    indices and its coefficients, R² value of the local linear model, local prediction
    by the explanation model on the original instance).
  prefs: []
  type: TYPE_NORMAL
- en: If we compare the above image with
  prefs: []
  type: TYPE_NORMAL
- en: '![Explain NLP models with LIME](../Images/4aa6bf2aae1fb4991e125047a4a56f75.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: then we can say that the prediction probabilities given in the left most panel
    is the local prediction done by the explanation model. The features and the values
    given in the middle panel are the important features and their coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**: As for this particular data instance the number of words(or features)
    is only 6 and we are selecting the top 5 important features , all the methods
    are giving the same set of top 5 important features. But it may not happen for
    longer sentences.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you like this article please hit recommend. That would be amazing.**'
  prefs: []
  type: TYPE_NORMAL
- en: To get the full code please visit my [GitHub](https://github.com/kunduayan/LIME_text_data) repository.
    For my future blogs please follow me on [LinkedIn](https://www.linkedin.com/in/ayan-kundu-a86293149/) and [Medium](https://medium.com/@ayan.kundu09).
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I tried to explain the final outcome of LIME for text data
    and how the whole explanation process happens for text in a step by step manner.
    Similar explanations can be done for tabular and image data. For that I will highly
    recommend to go through [this](https://github.com/marcotcr/lime).
  prefs: []
  type: TYPE_NORMAL
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub repository for LIME : [https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Documentation on LARS: [http://www.cse.iitm.ac.in/~vplab/courses/SLT/PDF/LAR_hastie_2018.pdf](http://www.cse.iitm.ac.in/~vplab/courses/SLT/PDF/LAR_hastie_2018.pdf)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[https://towardsdatascience.com/python-libraries-for-interpretable-machine-learning-c476a08ed2c7](https://towardsdatascience.com/python-libraries-for-interpretable-machine-learning-c476a08ed2c7)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[Ayan Kundu](https://www.linkedin.com/in/ayan-kundu-a86293149/)** is a data
    scientist with 2+ years of experience in the field of banking and finance and
    also a passionate learner to help the community as much as possible. Follow Ayan
    on [LinkedIn](https://www.linkedin.com/in/ayan-kundu-a86293149/) and [Medium](https://medium.com/@ayan.kundu09).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[SHAP: Explain Any Machine Learning Model in Python](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[oBERT: Compound Sparsification Delivers Faster Accurate Models for NLP](https://www.kdnuggets.com/2022/05/obert-compound-sparsification-delivers-faster-accurate-models-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Must Read NLP Papers from the Last 12 Months](https://www.kdnuggets.com/2023/03/must-read-nlp-papers-last-12-months.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ultimate Guide To Different Word Embedding Techniques In NLP](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Range of NLP Applications in the Real World: A Different…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning’s Sweet Spot: Pure Approaches in NLP and Document Analysis](https://www.kdnuggets.com/2022/05/machine-learning-sweet-spot-pure-approaches-nlp-document-analysis.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
