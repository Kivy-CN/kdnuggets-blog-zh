- en: Data Validation in Machine Learning is Imperative, Not Optional
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html](https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Aditya Aggarwal](https://www.linkedin.com/in/aditya-agarwal-2395076/),
    Data Science Practice Lead & [Arnab Bose](https://www.linkedin.com/in/arnab-bose-phd-6369531/),
    Chief Scientific Officer, Abzooba**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Operationalizing a Machine Learning (ML) model in production needs a lot more
    than just creating and validating models like in academia or research. The ML
    application in production can be a pipeline with multiple components running consecutively
    as shown in Fig 1. Before we reach model training in the pipeline, there are various
    components like Data Ingestion, Data versioning, Data validation, and Data pre-processing
    that need to be executed. Here, we will discuss the Data Validation and have arranged
    this article as below:'
  prefs: []
  type: TYPE_NORMAL
- en: What is data validation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is data validation required?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the challenges with data validation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the data validation component work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Examples of data validation components available in the market.​​​​​​​​​​​​​​
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure](../Images/606003bb28e7628e01050c103bd49341.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1: Components in machine learning pipelines**'
  prefs: []
  type: TYPE_NORMAL
- en: '**1) What is data validation?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ​​​​​​​Data validation means **checking the accuracy and quality of source data**
    before training a new model version. It ensures that **anomalies** that are infrequent
    or manifested in incremental data **are not silently ignored.** It focuses on
    checking that the statistics of the new data are as expected (e.g. feature distribution,
    number of categories, etc). Different types of validation can be performed depending
    on objectives and constraints. Examples of such objectives in the machine learning
    pipeline are below - ​​​​​​​
  prefs: []
  type: TYPE_NORMAL
- en: Are there any **anomalies or data errors** in the incremental data? If yes,
    raise an alert to the team for investigation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there any **assumptions on data** that are taken **during model training** and
    are getting violated during serving? If yes, raise an alert to the team for investigation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there **significant differences** between **training** and **serving** data?
    Or, Are there differences between successive data that are getting added into
    training data? If yes, raise an alert to investigate differences in training and
    serving code stack.​​​​​​​​​​​​​​
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Output from the data validation step should be **informative** enough that a
    data engineer can take **action** on it. Also, it needs to have **high precision**
    as too many false alarms will easily be lost credibility.
  prefs: []
  type: TYPE_NORMAL
- en: '**2) Why is data validation required?**​​​​​​​'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning models are vulnerable to poor data quality as per the old adage
    "garbage in garbage out".
  prefs: []
  type: TYPE_NORMAL
- en: In production, the model gets re-trained with a fresh set of incremental data
    added on a periodic basis (as frequent as daily) and the updated model is pushed
    to the serving layer. The model makes predictions with new incoming data while
    serving and the same data is added with actual labels and used for retraining.
    This ensures that the newly generated model adapts to the changes in data characteristics.  ​​​​​​​
  prefs: []
  type: TYPE_NORMAL
- en: However, the new incoming **data in the serving layer can change **due to various
    reasons like changes in code that introduces errors in the serving data ingestion
    component or the difference between training and serving stacks. With time, the
    **erroneous ingested data​​​​​​​** will become part of the training data and this
    will start **degrading the model accuracy.** Since In each iteration, newly added
    data is generally a small fraction of overall training data, hence, the changes
    in model accuracy will be easily missed and the **errors will keep adding with
    time**. ​​​​​​​ ​​​​​​​​​​​​​​
  prefs: []
  type: TYPE_NORMAL
- en: Thus, **catching the data errors at an early stage** is very important because it
    will reduce the cost of data error which is bound to increase as the error propagates
    further in the pipeline (as shown in fig 2). ​​​​​​​​​​​​​​​​​​​​​
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/daef50f86df768b4248dfe974eeda2e0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2: Cost of data error in machine learning pipelines**'
  prefs: []
  type: TYPE_NORMAL
- en: '**3) What are the challenges with the data validation?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are various challenges that a data scientist faces while developing a
    data validation component, such as
  prefs: []
  type: TYPE_NORMAL
- en: Creating data validation rules for a dataset with few columns does sound simple.
    However, **when the number of columns in datasets increases, it becomes a humongous
    task**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tracking and comparing metrics from the historical datasets to find **anomalies
    in historical trends for each column** needs a good amount of recurring time from
    a data scientist.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Today applications are expected to run 24-by-7 and in such scenarios, **data
    validation needs to be automated.** The data validation component should be smart
    enough to refresh validation rules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**4) How does the data validation component work?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Think of the data validation component as a guard post of the ML application
    that does not let bad quality data in. It keeps a check on each and every new
    data entry that is going to add to the training data. As shown in Fig 3, the data
    validation framework can be summarised in 5 steps:'
  prefs: []
  type: TYPE_NORMAL
- en: ​​​​Calculate the statistics from the training data against a set of rules
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the statistics of the ingested data that has to be validated
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the statistics of the validation data with the statistics from the training
    data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store the validation results and takes automated actions like removing the row,
    capping, or flooring the values
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sending the notification and alerts for approval​​​​​​​
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[![Figure](../Images/9f0b435b38e84720969fc559e80184bd.png)](https://i.ibb.co/16Cc8G9/data-validation-imperative-3-large.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 3: Data validation workflow (click to enlarge)**'
  prefs: []
  type: TYPE_NORMAL
- en: '**5) Examples of data validation components available in the market **'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ​​
  prefs: []
  type: TYPE_NORMAL
- en: ​​​​​​​​​​​​Amazon Research [1] and Google Research [2] proposed a very similar
    approach to building a data validation component. Overall, both approaches follow
    the same workflow as given in Fig 2. We will discuss both approaches here.
  prefs: []
  type: TYPE_NORMAL
- en: '**5.1) Unit-test approach for data validation by Amazon Research (Deequ)**'
  prefs: []
  type: TYPE_NORMAL
- en: In software engineering, engineers write unit tests to test their code. Similarly,
    unit tests should also be defined to test the incoming data. Authors have defined
    a framework to define this component that follows the below principles -
  prefs: []
  type: TYPE_NORMAL
- en: 'a) **Declare constraints**: User defines how their data should look like. It
    works by declaring checks on their data by composing constraints on various columns.
    A list of constraints is shown in Table 1 below.'
  prefs: []
  type: TYPE_NORMAL
- en: 'b) **Compute metrics**: Based on the declared constraint, translate them to
    measurable metrics as shown in Table 2 below. These metrics can be computed and
    compared between the data in hand and the incremental data.'
  prefs: []
  type: TYPE_NORMAL
- en: c) **Analyze and report: **Based on the collected metrics over time, predict
    if the metric on the incremental data is an anomaly or not. As a rule, the user
    can have the system issue "a warning" if the new metric is more than three standard
    deviations away from the previous mean or throw "an error" if it is more than
    four standard deviations away. Basis the analysis, report the constraints that
    fail including the value(s) that made the constraint fail. ​​​​​​
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 1: Constraints available for composing user-defined data quality checks**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/de29fd8f0b908476f45a8ade91a6e6d9.png)**Table 2: Computable
    metrics to based constraints on**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/6d22df7c707eb74a7c4ac679e76ca189.png)'
  prefs: []
  type: TYPE_IMG
- en: '**5.2) Data schema approach for data validation by Google Research (Tensorflow
    data validation)**'
  prefs: []
  type: TYPE_NORMAL
- en: ​​​​​​Google Research has come up with a very similar technique but adopted
    "battle-tested" principles from the data management system and customized it for
    ML. This technique first codifies the expectation from correct data and then using
    these expected statistics along with user-defined validation schema performs data
    validation.​​​​​​​ This data validation framework consists of **3 sub-component**
    as also shown in Fig 4.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Analyzer** - computes a predefined set of data statistics required to
    define the data'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Data Validator** - checks for properties of data as specified through a schema.
    This schema is a precursor for a data validator to perform. This schema list out
    all the constraints on the features for basic checks and ML-related checks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model Unit Tester** - checks for errors in training code using synthetic
    data generated through the schema'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This framework gives the user the **ability to**
  prefs: []
  type: TYPE_NORMAL
- en: '**validate a single batch of incremental data by detecting anomalies in it**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Detect significant changes between successive batches of incremental training
    data**. Few anomalies are not visible when checking only a single batch but manifest when
    we look at successive batches.​​​​​​​'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Find assumptions in the training code that are not reflected in the data**
    (e.g. if a feature is expected to have log() in the training code should not have
    -ve value or string values). The goal here is to cover those constraints that
    are missed to add into the schema. It happens in 2 steps'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ​​​​​Synthetic training examples that adhere to the schema constraints are generated
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This generated data is iterated through the training code for checking errors
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure](../Images/2c4aaa37376bbd4ad55113aab845ccd7.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 4: Data validation for machine learning by Google Research**'
  prefs: []
  type: TYPE_NORMAL
- en: Both Amazon Research and Google Research approaches provide users with suggestions
    such as constraints in the Amazon framework and recommendations to update schema
    in the google framework. Both approaches treat data as a first-class citizen in
    ML pipelines and do data validation before putting data into the system. However,
    there are few differences worth noting.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 3: Differences between data validation libraries**'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Deequ (Amazon)** | **Tensorflow data validation (Google)** |'
  prefs: []
  type: TYPE_TB
- en: '| **1** | No visualization available | Provides visualization using Google
    Facets. It summarises statistics for each feature and compares the training and
    validation data. |'
  prefs: []
  type: TYPE_TB
- en: '| **2** | Recalculates training statistics by aggregating prior saved training
    statistics and new data statistics.   | Calculates statistics on whole training
    data in every run unless specified. This may become computationally expensive.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **3** | Provides capability to do anomaly detection based on running average
    and standard deviation in addition to the threshold or absolute/relative difference
    from training data. | Provides capability to do anomaly detection based on the
    threshold or absolute/relative difference from training data. |'
  prefs: []
  type: TYPE_TB
- en: '| **4** | Supports data only in SparkDataFrame. | Supports pandas dataframe,
    csv, and best works with TFRecord. |'
  prefs: []
  type: TYPE_TB
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: 'S. Schelter, D. Lange, P. Schmidt, M. Celikel, F. Biessmann and A. Grafberger,
    "Automating Large-Scale Data Quality Verification" in Proceedings of the VLDB
    endowment, volume 11, Issue 12: 1781-1794, 2018\. Available: [http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf](http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf)​​​​​​​'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: E. Breck, M. Zinkevich, N. Polyzotis, S. Whang and S. Roy, "Data validation
    for machine learning", in Proceedings of the 2nd SysML Conference, Palo Alto,
    CA, USA, 2019\. Available: [https://mlsys.org/Conferences/2019/doc/2019/167.pdf](https://mlsys.org/Conferences/2019/doc/2019/167.pdf)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Aditya Aggarwal**](https://www.linkedin.com/in/aditya-agarwal-2395076/) serves
    as Data Science – Practice Lead at Abzooba Inc. With more than 12+ years’ experience
    in driving business goals through data-driven solutions, Aditya specializes in
    predictive analytics, machine learning, business intelligence & business strategy
    across a range of industries. As the Advanced Analytics Practice Lead at Abzooba,
    Aditya leads a team of 50+ energetic data science professionals at Abzooba that
    are solving interesting business problems using machine learning, deep learning,
    Natural Language Processing and computer vision. He provides thought leadership
    in AI to clients to translate their business objectives into analytical problems
    and data-driven solutions. Under his leadership, several organizations have automated
    routine tasks, reduced operational cost, boosted team productivity, and improved
    top-line and bottom-line revenues. He has built solutions such as subrogation
    engine, price recommendation engine, IoT sensor predictive maintenance, and more.
    Aditya holds a Bachelor of Technology and Minor Degree in Business Management
    from Indian Institute of Technology (IIT), Delhi.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Dr. Arnab Bose**](https://www.linkedin.com/in/arnab-bose-phd-6369531/) is
    Chief Scientific Officer at Abzooba, a data analytics company, and an adjunct
    faculty at the University of Chicago where he teaches Machine Learning and Predictive
    Analytics, Machine Learning Operations, Time Series Analysis and Forecasting,
    and Health Analytics in the Master of Science in Analytics program. He is a 20-year
    predictive analytics industry veteran who enjoys using unstructured and structured
    data to forecast and influence behavioral outcomes in healthcare, retail, finance,
    and transportation. His current focus areas include health risk stratification
    and chronic disease management using machine learning, and production deployment
    and monitoring of machine learning models. Arnab has published book chapters and
    refereed papers in numerous Institute of Electrical and Electronics Engineers
    (IEEE) conferences & journals. He has received Best Presentation at American Control
    Conference and has given talks on data analytics at universities and companies
    in US, Australia, and India. Arnab holds MS and Ph.D. degrees in electrical engineering
    from the University of Southern California, and a B.Tech. in electrical engineering
    from the Indian Institute of Technology at Kharagpur, India.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[MLOps – “Why is it required?” and “What it is”?](/2020/12/mlops-why-required-what-is.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Validation and Data Verification – From Dictionary to Machine Learning](/2021/03/data-validation-data-verification-dictionary-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to get started managing data quality with SQL and scale](/2021/05/soda-io-managing-data-quality-sql-scale.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Validation for PySpark Applications using Pandera](https://www.kdnuggets.com/2023/08/data-validation-pyspark-applications-pandera.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MarshMallow: The Sweetest Python Library for Data Serialization and…](https://www.kdnuggets.com/marshmallow-the-sweetest-python-library-for-data-serialization-and-validation)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Use k-fold Cross Validation?](https://www.kdnuggets.com/2022/07/kfold-cross-validation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine learning does not produce value for my business. Why?](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
