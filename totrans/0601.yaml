- en: Multimodal Grounded Learning with Vision and Language
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态基础学习与视觉和语言
- en: 原文：[https://www.kdnuggets.com/2022/11/multimodal-grounded-learning-vision-language.html](https://www.kdnuggets.com/2022/11/multimodal-grounded-learning-vision-language.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/11/multimodal-grounded-learning-vision-language.html](https://www.kdnuggets.com/2022/11/multimodal-grounded-learning-vision-language.html)
- en: '![Multimodal Grounded Learning with Vision and Language](../Images/68641d86fe3e5850bdca92677a85e49b.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![具有视觉和语言的多模态基础学习](../Images/68641d86fe3e5850bdca92677a85e49b.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑提供
- en: Hi everyone! My name is Bogdan Ponomar, and I’m CEO at AI HOUSE – AI – community
    in Ukraine that brings together talents under dozens of initiatives, primarily
    educational. We are part of the [Roosh](http://roosh.tech) tech ecosystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 大家好！我叫博格丹·波诺马尔，我是AI HOUSE的首席执行官——一个将人才聚集在一起的乌克兰AI社区，涵盖了几十个以教育为主的计划。我们是 [Roosh](http://roosh.tech)
    技术生态系统的一部分。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In August 2022, we launched a new educational project [“AI for Ukraine”](https://aiforukraine.aihouse.club/)
    – a series of workshops and lectures held by international artificial intelligence
    experts to support the development of Ukraine’s tech community. The leading international
    AI/ML experts participated in this charity project and we decided to share some
    abstracts from the most insightful and engaging AI for Ukraine sessions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在2022年8月，我们推出了一个新的教育项目 [“AI for Ukraine”](https://aiforukraine.aihouse.club/)——由国际人工智能专家举办的一系列研讨会和讲座，以支持乌克兰科技社区的发展。领先的国际AI/ML专家参与了这个慈善项目，我们决定分享一些最具洞察力和引人入胜的AI
    for Ukraine会议的摘要。
- en: The first synopsis in the series was devoted to the lecture by Joshua Bengio
    covering the topic of "Bridging the gap between current deep learning and human
    higher-level cognitive abilities". You can read it  [here](/2022/10/gap-deep-learning-human-cognitive-abilities.html).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 系列中的第一个摘要是关于乔书亚·本吉奥的讲座，主题是“弥合当前深度学习与人类高级认知能力之间的差距”。你可以在 [这里](/2022/10/gap-deep-learning-human-cognitive-abilities.html)
    阅读。
- en: The next topic I’m inviting you to delve into is "Multimodal Grounded Learning
    with Vision and Language" delivered by Anna Rohrbach, Research Scientist at UC
    Berkeley.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的主题是“具有视觉和语言的多模态基础学习”，由UC伯克利的研究科学家安娜·罗尔巴赫（Anna Rohrbach）讲授。
- en: Let's start by acknowledging that humans use a variety of modalities, most notably
    vision and language, to perceive their environment and interact with one another.
    It is a fundamental human ability to describe what we observe to one another.
    We have a shared reality, which is essential for understanding one another since
    we ground the concepts to the world around us.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先承认，人类使用各种感知方式，最显著的是视觉和语言，来感知他们的环境和相互交流。描述我们观察到的事物是人类的一项基本能力。我们有一个共享的现实，这对于理解彼此至关重要，因为我们将概念与我们周围的世界相结合。
- en: In most cases, language is also used by humans to transfer knowledge about new
    things.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，人类也使用语言来传递关于新事物的知识。
- en: Thus, we can learn just via language. In her lecture, a Research Scientist at
    UC Berkeley Anna Rohrbach discussed how to provide AI models with similar capabilities,
    such as communication, grounding, and learning from language. Although there has
    been a significant advancement in the classical vision and language tasks, notably
    visual captioning, the AI models sometimes still have difficulties. One of the
    most challenging aspects in multimodal learning is exactly grounding, that is
    – accurately mapping language concepts on visual observations. Lack of proper
    grounding may negatively affect the models by producing bias or hallucinations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以仅通过语言进行学习。在她的讲座中，加州大学伯克利分校的研究科学家安娜·罗赫巴赫讨论了如何为人工智能模型提供类似的能力，如沟通、基础建立和从语言中学习。尽管在经典的视觉和语言任务中取得了显著进展，尤其是在视觉标注方面，人工智能模型有时仍然面临困难。多模态学习中最具挑战性的方面之一正是基础建立，即——准确地将语言概念映射到视觉观察上。缺乏适当的基础建立可能会通过产生偏见或幻觉对模型产生负面影响。
- en: Furthermore, even models that are able to communicate and ground may still require
    human "advice," or learn how to act more like humans. Language is increasingly
    being used to improve visual models by allowing zero-shot capabilities, improving
    generalization, minimizing bias and so forth. Anna Rohrbach is particularly interested
    in developing models that may use language advice to improve their behavior. In
    the talk, Anna covered how she and other researchers in the field try to achieve
    the aforementioned capabilities and the challenges as well as exciting opportunities
    that lie ahead.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，即使是能够进行交流和基础建立的模型，仍可能需要人类的“建议”，或者学习如何更像人类。语言越来越多地被用来通过实现零-shot 能力、改善泛化、最小化偏见等方式来提升视觉模型。安娜·罗赫巴赫特别感兴趣于开发可能使用语言建议来改善其行为的模型。在讲座中，安娜介绍了她和其他领域研究人员如何实现上述能力以及面临的挑战和即将到来的令人兴奋的机遇。
- en: AI is already everywhere, impacting all aspects of our lives from healthcare
    and assistive technology to self-driving and smart homes. Further, more human-like
    interactions with AI are going to be established. We are going to communicate
    with AI more and build trust.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能已经无处不在，影响着我们生活的各个方面，从医疗保健和辅助技术到自动驾驶和智能家居。此外，更类似人类的人工智能互动将会建立。我们将与人工智能进行更多的交流并建立信任。
- en: 'In our multimodal world, the primary two ways of interaction are through vision
    and language. Human-to-human interaction has such forms:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的多模态世界中，主要的互动方式有视觉和语言。人与人之间的互动形式包括：
- en: Communication about what you see (e.g., *Look, a blue jay is sitting on a branch*)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于你看到的内容的沟通（例如，*看，一个蓝松鸦正坐在树枝上*）
- en: Grounding concepts to the common reality
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将概念基础建立到共同现实中
- en: Learning from language (e.g., *Did you know, blue jays like eating acorns?*)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从语言中学习（例如，*你知道吗，蓝松鸦喜欢吃橡果？*）
- en: These three points are the key priorities for human-AI interaction. The researchers
    try to achieve it with visual captioning, including assisting visually impaired
    users and generating explanations (for example, bluejay — is a bird that is blue
    above and white below, with a large crest and black necklace). The explanations
    should be faithful and introspective.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这三点是人类与人工智能互动的关键优先事项。研究人员通过视觉标注来实现这一目标，包括协助视力受限用户和生成解释（例如，蓝松鸦——是一种上部蓝色、下部白色、带有大冠和黑色项链的鸟）。这些解释应该是忠实和自省的。
- en: Grounding
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础建立
- en: The task of visual grounding includes the localization of nouns or short phrases
    (e.g., a black beak, a blue wing). Recently, there’s been much interest in scaling
    it up.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉基础建立的任务包括名词或短语的定位（例如，一个黑色的喙，一个蓝色的翅膀）。最近，对将其规模化的兴趣增加了。
- en: The problem of alignment between modalities that we expect from AI-trained models
    often occurs. We expect that they relate the right words to the image. However,
    in practice, this is not always the case. For example, the system may say “A bird
    is sitting on a branch,” but we see no branch in the picture. This is an example
    of the failure of grounding. Lack of grounding may sometimes even hurt the user.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望AI训练模型在模态之间的对齐问题经常出现。我们希望它们将正确的词汇与图像相关联。然而，实际上情况并非总是如此。例如，系统可能会说“鸟儿正坐在树枝上”，但我们在图像中看不到树枝。这是基础建立失败的一个例子。缺乏基础建立有时甚至可能伤害用户。
- en: Anna suggests using language as a source of knowledge for AI models as we humans
    do. We could leverage language for zero-shot learning. This approach has already
    been used before. For instance, when you are asked to name the attributes to learn
    about the new species. Recently, this approach has been pushed forward with the
    arrival of large models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 安娜建议将语言作为人工智能模型的知识来源，就像我们人类一样。我们可以利用语言进行零样本学习。这种方法已经被使用过。例如，当你被要求列出需要了解的新物种的属性时。最近，随着大型模型的出现，这种方法得到了进一步的发展。
- en: Another way to achieve grounding is by using advisable learning. We learn not
    just from experience or doing things, we can learn by reading and listening to
    other humans too. Similarly, AIs can be trained to correct undesired model behavior.
    For example, if there’s a picture of a bird flying over water, the machine might
    be confused about the type of bird, so we can tell it to look at the bird, not
    the water. Therefore, the machine will not confuse it with a duck, for example.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 实现基础的另一种方法是使用建议性学习。我们不仅仅通过经验或做事来学习，我们还可以通过阅读和听其他人来学习。同样，人工智能也可以通过纠正不良模型行为来进行训练。例如，如果有一张鸟在水面上飞翔的照片，机器可能会对鸟的类型感到困惑，因此我们可以告诉它关注鸟而不是水面。因此，机器不会将其与鸭子混淆。
- en: Therefore, we need to build AI models that can communicate, are grounded, and
    learn from language.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要构建能够交流、具有基础并从语言中学习的人工智能模型。
- en: 'Anna Rohrbach outlined the lecture with these aspects:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 安娜·罗尔巴赫将讲座概述为以下几个方面：
- en: Communication needs grounding
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交流需要有基础。
- en: Grounded communication with Advisability
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有建议性的基础交流。
- en: Learning from language for improving visual robustness and transfer.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从语言中学习以提高视觉鲁棒性和迁移能力。
- en: Communication Needs Grounding
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交流需要有基础。
- en: If there’s a picture of a person riding a snowboard. Most likely the machine
    will identify it as “he”. Captioning models talk about gender even when humans
    would not. Models not only capture inequality (there is more data about men),
    they exaggerate this imbalance. For example, in a picture with the woman sitting
    at the desk with a laptop computer, the machine still identifies the person as
    a “man”. The model doesn’t even see the person, it sees a monitor and based on
    some correlations assumes this is a man. In the example of a man holding a tennis
    racket, the model identifies that gender correctly but not by looking at the person
    but at the racket. Therefore, the model does not attend to the person when discussing
    their gender.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一张人骑滑雪板的照片。机器很可能将其识别为“他”。描述模型即使在人类不会提及性别的情况下也会谈论性别。模型不仅捕捉到不平等（男性的数据更多），还夸大了这种不平衡。例如，在一张女人坐在桌前使用笔记本电脑的照片中，机器仍然将此人识别为“男人”。模型甚至没有看到这个人，它看到的是一个显示器，并基于一些相关性假设这是一个男人。在一个男人拿着网球拍的例子中，模型正确地识别了性别，但不是通过看人，而是通过看网球拍。因此，在讨论性别时，模型并没有关注到这个人。
- en: 'Anna and other researchers work on overcoming this problem by shifting the
    attention to the right person. To do this, they apply caption correctness loss
    to the gender. They have introduced confidence loss and appearance confusion loss.
    It provided a more fair model behavior: similar low error for both men and women.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 安娜和其他研究人员正在通过将注意力转移到正确的对象上来克服这个问题。为此，他们将描述正确性损失应用于性别。他们引入了置信度损失和外观混淆损失。这提供了更加公平的模型行为：对男性和女性的错误率相似。
- en: In the Baseline-FT and UpWeight, the model identified “A man and a dog are in
    the snow”
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Baseline-FT 和 UpWeight 中，模型识别了“一个男人和一只狗在雪地里”。
- en: The equalizer is more concerned about the gender mistake and identified it as
    “A person walking a dog on a leash” if the model couldn’t clearly recognize the
    gender in the picture.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型无法清晰识别图片中的性别时，均衡器更关心性别错误，并将其识别为“一个人牵着狗散步”。
- en: 'The issues that lack of grounding may cause include: inappropriate, harmful,
    and offensive items.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏基础可能会导致的问题包括：不适当、有害和冒犯性的内容。
- en: Grounded Communication with Advisability
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有建议性的基础交流。
- en: When you are self-driving, the car can communicate to you when it slows down
    since it’s about to turn left. There is a description (the car slows down) and
    an explanation of the action (since it is about to turn left). Anna and her colleagues
    have conducted a DeepDrive eXplanation (BDD-X) dataset experiment at Berkley University.
    The model was trying to predict the vehicle’s future ego motion.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当你自驾时，汽车在减速时可以与你沟通，因为它即将左转。有一个描述（汽车减速）和一个行动解释（因为它即将左转）。安娜和她的同事们在伯克利大学进行了DeepDrive
    eXplanation (BDD-X) 数据集实验。模型试图预测车辆的未来自我运动。
- en: They have introduced an explanation generator that generates the natural language
    explanation of the rationales behind the driving model. In the process of attention
    alignment, the key idea is to align the vehicle controller and the textual justifier
    such that they look at the same input regions. The key results they got were the
    most weakly aligned attention, “explanation-as-additional-loss” explainable without
    performance loss. The problem lay in that the system does not attend to pedestrians
    nor reacted to their presence.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 他们引入了一种解释生成器，用于生成驾驶模型背后的合理性解释的自然语言。在注意力对齐过程中，关键思想是将车辆控制器和文本解释器对齐，使它们关注相同的输入区域。他们得到的关键结果是最弱对齐的注意力，“作为额外损失的解释”可解释且不影响性能。问题在于系统没有关注行人，也没有对其存在作出反应。
- en: Advisable Driving Model
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可建议的驾驶模型
- en: How to make the model recognize the pedestrians by advice? Observation to action,
    not vice versa. This way the model learns to summarize its visual observations
    in natural language and predicts an appropriate action response. In the CARLA
    stimulator, the researchers studied the behavior of a non-explainable model, an
    explainable model, and an advisable model. Humans trust the advisable model the
    most.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如何通过建议让模型识别行人？观察到的行动，而不是相反。这样，模型学习将其视觉观察总结成自然语言，并预测适当的行动响应。在CARLA模拟器中，研究人员研究了一个不可解释的模型、一个可解释的模型和一个建议的模型。人们对建议模型的信任度最高。
- en: Therefore, incorporating language advice in deep models leads to better-performing,
    more interpretable models that gain higher human trust.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将语言建议纳入深度模型可以导致性能更好、更具可解释性的模型，从而获得更高的人类信任。
- en: Learning from language for Improving Visual Robustness
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从语言中学习以提高视觉鲁棒性
- en: Large Vision Language Models
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大规模视觉语言模型
- en: CLIP — a pre-trained model that learns to match images to captions. It can recognize
    and ground many high-level concepts, but not the fine-grained classes, such as
    dog species.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: CLIP——一个预训练模型，学习将图像与说明匹配。它可以识别和定位许多高层次的概念，但不能识别细粒度的类别，如犬种。
- en: 'The researchers find a lot of contextual bias that lies in separating the concept
    from context. They introduced GALS: Guiding visual attention with the language
    specification. It improves model learning with prompts (photo of a bird). They
    established turning high-level language task specification into spatial attention,
    which guides a CNN away from bias.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员发现了许多存在于将概念与上下文分离的情境偏差。他们引入了GALS：通过语言规范引导视觉注意力。这通过提示（如鸟的照片）改善了模型学习。他们将高层次语言任务规范转化为空间注意力，从而引导CNN远离偏差。
- en: Learning from Language for Improving Visual Transfer
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从语言中学习以提高视觉迁移能力
- en: Large-scale V+L models work well for high-level concepts, but not so for fine-grained
    ones. The idea is that a lot of general knowledge is captured in external resources.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模的视觉+语言模型在高层次概念上表现良好，但在细粒度概念上效果不佳。其理念是大量的通用知识被捕捉在外部资源中。
- en: Zero-Shot Learning
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Zero-Shot Learning
- en: Traditional Class level transfer has a goal to generalize to unseen object classes.
    The new task-level transfer has the goal of generalizing to unseen datasets or
    tasks. However, modeling external knowledge has not been explored. Whereas in
    traditional class-level transfer modeling external knowledge explored how to associate
    seen and unseen classes via some auxiliary info, such as embeddings or attributes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的类别级迁移旨在将知识泛化到未见过的对象类别。新的任务级迁移旨在将知识泛化到未见过的数据集或任务。然而，建模外部知识尚未被探索。相比之下，传统的类别级迁移建模外部知识探讨了如何通过一些辅助信息，如嵌入或属性，将已见类别与未见类别关联起来。
- en: 'In external knowledge, we could use explanation. Humans leverage prior (structured)
    knowledge. Can the same be done for AI? The researchers used K-Lite: Knowledge-augmented
    Language Image Training and Evaluation. Knowledge helps to improve performance
    in fine-grained concepts, such as sashimi — a Japanese specialty that consists
    of fresh, raw fish or meat that has been thinly sliced and is frequently consumed
    with soy sauce. However, it hurts performance when knowledge coverage is low and
    spurious works are contained. The researcher found that we can further enhance
    learning from the language by learning from the external language.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部知识中，我们可以使用解释。人类利用先前（结构化的）知识。AI能否做到这一点？研究人员使用了K-Lite：知识增强语言图像训练和评估。知识有助于提升对细粒度概念的表现，比如sashimi——一种日本特色菜，由新鲜的生鱼或肉切成薄片，通常配以酱油食用。然而，当知识覆盖范围低且包含虚假信息时，性能会受到影响。研究人员发现，我们可以通过从外部语言中学习进一步提升语言学习。
- en: What is Next?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步是什么？
- en: AI models that can learn from language. However, the possible limitation is
    human supervision that is hard to scale. Anna predicts that large-scale pre-trained
    models with open-ended scenarios with arbitrary concepts, complex relationships,
    and world knowledge will be introduced. Her long-term vision is that foundational
    grounded models will be compositional and structured, so AIs will communicate,
    be more grounded, and will be able to learn from language. They will also be sample-efficient
    with less human supervision.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型可以从语言中学习。然而，可能的限制是难以扩展的人类监督。安娜预测，将会引入具有开放式场景、任意概念、复杂关系和世界知识的大规模预训练模型。她的长期愿景是基础的、有根有据的模型将是可组合的和结构化的，这样AI将能够进行沟通，更加扎实，并能够从语言中学习。它们还将具有更高的样本效率，减少对人类监督的依赖。
- en: '**[Bohdan Ponomar](https://www.linkedin.com/in/bogdan-ponomar-41866328/)**
    is CEO at the AI HOUSE community. He is creating a leading AI ecosystem for students
    and experts to build world-class AI ventures in Ukraine.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Bohdan Ponomar](https://www.linkedin.com/in/bogdan-ponomar-41866328/)**
    是AI HOUSE社区的首席执行官。他正在为乌克兰的学生和专家创建一个领先的AI生态系统，以便建立世界级的AI企业。'
- en: More On This Topic
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NExT-GPT简介：任何对任何的多模态大语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
- en: '[Multimodal Models Explained](https://www.kdnuggets.com/2023/03/multimodal-models-explained.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多模态模型解析](https://www.kdnuggets.com/2023/03/multimodal-models-explained.html)'
- en: '[MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced…](https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MiniGPT-4：GPT-4的轻量级替代方案，增强视觉语言理解](https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html)'
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据管理你需要了解的6件事及其重要性](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow在计算机视觉中的应用——简化迁移学习](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻2022年3月9日：在5天内构建机器学习Web应用](https://www.kdnuggets.com/2022/n10.html)'
