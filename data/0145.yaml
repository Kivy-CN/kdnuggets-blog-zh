- en: What Can We Expect From GPT-5?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们可以期待GPT-5带来什么？
- en: 原文：[https://www.kdnuggets.com/2023/06/expect-gpt5.html](https://www.kdnuggets.com/2023/06/expect-gpt5.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/expect-gpt5.html](https://www.kdnuggets.com/2023/06/expect-gpt5.html)
- en: '![What Can We Expect From GPT-5?](../Images/6068774983714942e1d98cd6dfd25fc5.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![我们可以期待GPT-5带来什么？](../Images/6068774983714942e1d98cd6dfd25fc5.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图片
- en: It may seem very difficult to keep up with the fast movement in AI and technology.
    Every week or month, something new drops and now you’re here learning something
    new, again!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 跟上AI和技术的快速发展可能看起来非常困难。每周或每月，总会有新的东西出现，现在你又在这里学习新的内容！
- en: This time it is GPT-5.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这次是GPT-5。
- en: GPT-4 was released in March 2023, and since then everybody has been waiting
    for the release of GPT-5\. Siqi Chen [tweeted](https://twitter.com/blader/status/1640217165822578688)
    on March 27th saying that “gpt5 is scheduled to complete training this December.”
    However, this statement has been clarified by OpenAI CEO Sam Altman at an [MIT
    event](https://www.imaginationinaction.co/the-future-of-business-with-ai) in April
    when asked about GPT-5 stating “We are not and won’t for some time,”.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4于2023年3月发布，自那时以来，大家一直在等待GPT-5的发布。Siqi Chen在3月27日[发推](https://twitter.com/blader/status/1640217165822578688)称“GPT-5计划在今年12月完成训练。”然而，OpenAI首席执行官Sam
    Altman在4月的[MIT活动](https://www.imaginationinaction.co/the-future-of-business-with-ai)上被问及GPT-5时澄清道，“我们不会，也不会在一段时间内发布”。
- en: So that clarifies that. However, some experts have suggested that OpenAI release
    a GPT-4.5, an intermediate release between GPT-4 and GPT-5 by Q3/Q4 of 2023\.
    Improvements are always being made to current models and this could be a potential
    release of GPT-4.5\. Many are saying that GPT-4.5 has multimodal capability potential,
    which has already been demonstrated in GPT-4 developer livestream in March 2023.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这就澄清了这一点。然而，一些专家建议OpenAI在2023年第三季度或第四季度发布GPT-4.5，作为GPT-4和GPT-5之间的一个中间版本。当前模型总是在不断改进，这可能成为GPT-4.5的一个潜在发布。许多人认为GPT-4.5具备多模态能力，这在2023年3月的GPT-4开发者直播中已有展示。
- en: Although there are high expectations for GPT-5, GPT-4 still needs to iron out
    some of its creases. For example, GPT-4’s inference time is very high along with
    it being computationally expensive to run. There are other challenges such as
    accessing the GPT-4 APIs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对GPT-5有很高的期望，GPT-4仍然需要解决一些问题。例如，GPT-4的推理时间非常长，同时运行成本也很高。还有其他挑战，比如访问GPT-4的API。
- en: Although there is work to do, what we can say is that each of the GPT releases
    has pushed the boundaries of AI technology and what it is capable of. AI enthusiasts
    are excited to explore GPT-5's groundbreaking features.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管还有很多工作要做，但我们可以说的是，每一次GPT的发布都推动了AI技术及其能力的边界。AI爱好者们对探索GPT-5的突破性特性感到兴奋。
- en: So what features can we expect from GPT-5? Let’s find out.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们可以期待GPT-5带来哪些功能呢？让我们来了解一下。
- en: Reduced Hallucination
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少幻觉
- en: This is all about trust, the main reason why most users do not believe in AI
    models. For example, GPT-4 scored 40% higher than GPT-3.5 in internal factual
    evaluations under all nine categories, as shown in the image below. This means
    that GPT-4 is less likely to respond to disallowed content, and 40% more likely
    to produce factual reponses, in comparison to GPT-3.5.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这全关乎信任，这是大多数用户不相信AI模型的主要原因。例如，GPT-4在内部事实评估中的得分比GPT-3.5高40%，如下面的图片所示。这意味着GPT-4在回应不允许的内容方面的可能性更小，产生事实性回应的可能性比GPT-3.5高40%。
- en: As new releases will continue to improve on current challenges, it is said that
    GPT-5 will reduce hallucination to less than 10%, making LLMs more trustworthy.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着新版本不断改进当前挑战，据说GPT-5将把幻觉减少到10%以下，使大型语言模型（LLM）更值得信赖。
- en: '![What Can We Expect From GPT-5?](../Images/6dbc33e2d097d20a1a2e0b6d1bb2eecb.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![我们可以期待GPT-5带来什么？](../Images/6dbc33e2d097d20a1a2e0b6d1bb2eecb.png)'
- en: Image by [OpenAI](https://openai.com/research/gpt-4)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于[OpenAI](https://openai.com/research/gpt-4)
- en: Compute Efficiency
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算效率
- en: As stated earlier on, GPT-4 is very computationally expensive, at $0.03 per
    token. This is in comparison to GPT-3.5’s cost of $0.002\. That is a big difference.
    GPT-4 being trained on a one trillion parameter dataset and infrastructure reflects
    the cost.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GPT-4的计算成本非常高，每个token $0.03。这与GPT-3.5的$0.002成本相比差距巨大。GPT-4在一万亿参数数据集和基础设施上训练，反映了其成本。
- en: Whereas Google’s PaLM 2 model is only trained on 340 billion parameters and
    has efficient performance. If OpenAI plans to compete with Google's PaLM 2, they
    will need to look into ways of reducing the cost, and the size of GPT-4 parameters
    - all whilst being able to maintain performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 而谷歌的PaLM 2模型仅在3400亿参数上进行训练，并且性能高效。如果OpenAI计划与谷歌的PaLM 2竞争，他们需要寻找降低成本和缩小GPT-4参数规模的方法，同时保持性能。
- en: Another aspect to look into is a better inference time, for the time it takes
    a deep learning model to predict new data. The more features and plugins within
    GPT-4, the more compute efficiency becomes. Developers are already complaining
    to OpenAI that GPT-4 APIs frequently stop responding, which forces them to use
    GPT-3.5.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要关注的方面是更好的推理时间，即深度学习模型预测新数据所需的时间。GPT-4的功能和插件越多，计算效率也就越高。开发者们已经向OpenAI抱怨GPT-4的API经常停止响应，这迫使他们使用GPT-3.5。
- en: Taking all of that into consideration, we can expect OpenAI to overcome these
    challenges with a GPT-5 release that is smaller, cheaper and more efficient.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，我们可以期待OpenAI通过推出更小、更便宜、更高效的GPT-5来克服这些挑战。
- en: Multi-Sensory
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多感官
- en: In the come-up to GPT-4’s release, a lot of people were going crazy over its
    multimodal capabilities. Although it has not been added to GPT-4 yet, this is
    where GPT-5 may come and be the star of the show and truly make it multimodal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT-4发布之前，很多人对其多模态能力感到疯狂。尽管这尚未添加到GPT-4中，但这可能是GPT-5出现并真正成为明星的地方，使其真正实现多模态。
- en: Not only can we expect it to deal with images and text, but also audio, videos,
    temperature, and more. Sam Altman stated in an interview *“I’m very excited to
    see what happens when we can do video, there’s a lot of video content in the world.
    There are a lot of things that are much easier to learn with a video than text.”*
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅可以期待它处理图像和文本，还可以处理音频、视频、温度等更多内容。萨姆·奥特曼在一次采访中表示*“我非常期待看到当我们能够处理视频时会发生什么，世界上有很多视频内容。很多事情用视频学习比用文本更容易。”*
- en: Increasing the type of data that can be used to make conversations more dynamic
    and interactive. Multimodal capabilities will be the fastest link to Artificial
    general intelligence (AGI).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 增加可以用来使对话更具动态性和互动性的数据类型。多模态能力将是通向人工通用智能（AGI）的最快途径。
- en: Long-Term Memory
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长期记忆
- en: GPT-4’s maximum token length is 32 thousand tokens, which was impressive. But
    with the world releasing model after model, we have models such as Story Writer
    that can output 65 thousand tokens.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的最大令牌长度为32千个令牌，这在当时令人印象深刻。但随着世界上不断推出新模型，我们已经有如Story Writer这样的模型能够输出65千个令牌。
- en: To keep up with the current competition, we can expect GPT-5 to introduce a
    longer context length, allowing users to have AI friends that can remember their
    persona and history for years.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟上当前的竞争，我们可以期待GPT-5引入更长的上下文长度，使用户能够拥有能够记住他们的个性和历史多年之久的AI朋友。
- en: Improved Contextual Understanding
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进的上下文理解
- en: Being a large language model (LLM), the first thing we can expect is an improvement
    and enhanced ability in understanding context. If we merge this with the point
    above about long-term memory, GPT-5 could have the potential to maintain context
    over long conversations. As a user, you will have more catered and meaningful
    responses that are consistent with your requirements.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个大型语言模型（LLM），我们可以期待的第一件事是对上下文理解能力的提升。如果我们将其与上面提到的长期记忆结合起来，GPT-5可能具有在长时间对话中保持上下文的潜力。作为用户，你将获得更多量身定制且符合要求的有意义的回应。
- en: With this comes a more advanced understanding of language, with the main component
    of natural language being emotion. Potential capabilities of contextual understanding
    in GPT-5 can allow it to be more empathetic and produce appropriate replies to
    continue to engage in the conversation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 随之而来的是对语言的更高级理解，其中自然语言的主要组成部分是情感。GPT-5在上下文理解方面的潜在能力可以使其更具同理心，并生成适当的回复以继续参与对话。
- en: Wrapping it up
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: There is more to find out about the potential capabilities of GPT-5, and we
    won't be able to find out any more information till closer to the release. This
    article is based on the current challenges that GPT-4 and GPT-3.5 face, and how
    OpenAI can use these hurdles to overcome and produce a high performant release
    of GPT-5.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GPT-5潜在能力还有很多未知，我们要等到发布时才能了解更多信息。本文基于GPT-4和GPT-3.5目前面临的挑战，以及OpenAI如何利用这些障碍克服困难，推出高性能的GPT-5。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist,
    Freelance Technical Writer and Community Manager at KDnuggets. She is particularly
    interested in providing Data Science career advice or tutorials and theory based
    knowledge around Data Science. She also wishes to explore the different ways Artificial
    Intelligence is/can benefit the longevity of human life. A keen learner, seeking
    to broaden her tech knowledge and writing skills, whilst helping guide others.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**[尼莎·阿利亚](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一位数据科学家、自由技术写作人以及KDnuggets的社区经理。她特别关注提供数据科学职业建议或教程，以及围绕数据科学的理论知识。她还希望探索人工智能在延长人类寿命方面的不同应用方式。作为一个热衷学习的人，她寻求扩展自己的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[2023 AI Index Report: AI Trends We Can Expect in the Future](https://www.kdnuggets.com/2023/06/2023-ai-index-report-ai-trends-expect-future.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年AI指数报告：未来我们可以预期的AI趋势](https://www.kdnuggets.com/2023/06/2023-ai-index-report-ai-trends-expect-future.html)'
- en: '[What to Expect From Your Career Path as a Data Scientist](https://www.kdnuggets.com/2022/01/expect-career-path-data-scientist.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[作为数据科学家的职业发展预期](https://www.kdnuggets.com/2022/01/expect-career-path-data-scientist.html)'
- en: '[What To Expect for AI Quality Trends In 2023](https://www.kdnuggets.com/2022/11/expect-ai-quality-trends-2023.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年人工智能质量趋势的预期](https://www.kdnuggets.com/2022/11/expect-ai-quality-trends-2023.html)'
- en: '[Why Data Scientists Expect Flawed Advice From Google Bard](https://www.kdnuggets.com/2023/02/data-scientists-expect-flawed-advice-google-bard.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家为何期望从Google Bard得到有缺陷的建议](https://www.kdnuggets.com/2023/02/data-scientists-expect-flawed-advice-google-bard.html)'
- en: '[15 Trending MLOps Talks You can Access for Free at ODSC East 2022](https://www.kdnuggets.com/2022/04/odsc-15-trending-mlops-talks-access-free-odsc-east-2022.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ODSC East 2022 免费访问的15个热门MLOps讲座](https://www.kdnuggets.com/2022/04/odsc-15-trending-mlops-talks-access-free-odsc-east-2022.html)'
- en: '[How Artificial Intelligence Can Transform Data Integration](https://www.kdnuggets.com/2022/04/artificial-intelligence-transform-data-integration.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能如何改变数据集成](https://www.kdnuggets.com/2022/04/artificial-intelligence-transform-data-integration.html)'
