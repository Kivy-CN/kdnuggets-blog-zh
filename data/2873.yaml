- en: Choosing a Machine Learning Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择机器学习模型
- en: 原文：[https://www.kdnuggets.com/2019/10/choosing-machine-learning-model.html](https://www.kdnuggets.com/2019/10/choosing-machine-learning-model.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/choosing-machine-learning-model.html](https://www.kdnuggets.com/2019/10/choosing-machine-learning-model.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Lavanya Shukla](https://twitter.com/lavanyaai), Weights and Biases**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Lavanya Shukla](https://twitter.com/lavanyaai)，Weights and Biases**。'
- en: '![](../Images/2f34b86fccda019425f10c4b239275d8.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f34b86fccda019425f10c4b239275d8.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The number of shiny models out there can be overwhelming, which means a lot
    of times people fall back on a few they trust the most and use them on all new
    problems. This can lead to sub-optimal results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 众多闪亮的模型可能让人不知所措，这意味着很多时候，人们会回到几个他们最信任的模型，并在所有新问题上使用这些模型。这可能导致次优结果。
- en: Today we’re going to learn how to quickly and efficiently narrow down the space
    of available models to find those that are most likely to perform best on your
    problem type. We’ll also see how we can keep track of our models’ performances
    using Weights and Biases and compare them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们将学习如何快速高效地缩小可用模型的范围，以找到最有可能在你的问题类型上表现最佳的模型。我们还将了解如何使用 Weights and Biases
    跟踪我们的模型表现并进行比较。
- en: You can find the accompanying code [here](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model)找到配套代码。
- en: '**What We’ll Cover**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们将涵盖的内容**'
- en: Model selection in competitive data science vs. real world
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 竞争数据科学与现实世界中的模型选择
- en: A Royal Rumble of Models
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的皇家大战
- en: Comparing Models
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较模型
- en: Let’s get started!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: 'Unlike Lord of the Rings, in machine learning, there is no one ring (model)
    to rule them all. Different classes of models are good at modeling the underlying
    patterns of different types of datasets. For instance, decision trees work well
    in cases where your data has a complex shape:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与《魔戒》不同，在机器学习中，没有一个模型能够统治所有其他模型。不同类别的模型擅长于建模不同类型数据集的底层模式。例如，决策树在数据具有复杂形状的情况下表现良好。
- en: '![](../Images/0a6cea4d3d6d1b8f01090976bd1277c3.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a6cea4d3d6d1b8f01090976bd1277c3.png)'
- en: 'Whereas linear models work best where the dataset is linearly separable:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型在数据集线性可分的情况下效果最佳：
- en: '![](../Images/fd11384d1bd101b95d1394b1c5dd5469.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd11384d1bd101b95d1394b1c5dd5469.png)'
- en: Before we begin, let’s dive a little deeper into the disparity between model
    selection in the real world vs for competitive data science.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们更深入地探讨现实世界中的模型选择与竞争数据科学中的模型选择之间的差异。
- en: Model selection in competitive data science vs. real world
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争数据科学与现实世界中的模型选择
- en: As William Vorhies said in his [blog post](https://www.datasciencecentral.com/profiles/blogs/want-to-win-at-kaggle-pay-attention-to-your-ensembles),
    “the Kaggle competitions are like formula racing for data science. Winners edge
    out competitors at the fourth decimal place, and like Formula 1 race cars, not
    many of us would mistake them for daily drivers. The amount of time devoted and
    the sometimes extreme techniques wouldn’t be appropriate in a data science production
    environment.”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 William Vorhies 在他的[博客文章](https://www.datasciencecentral.com/profiles/blogs/want-to-win-at-kaggle-pay-attention-to-your-ensembles)中所说，“Kaggle
    竞赛就像数据科学的方程式赛车。获胜者在第四位小数点上超越对手，就像方程式1赛车一样，我们中的大多数人不会把它们误认为是日常驾驶的汽车。投入的时间和有时极端的技术在数据科学生产环境中并不合适。”
- en: Kaggle models are indeed like racing cars, as they’re not built for everyday
    use. Real-world production models are more like a Lexus — reliable but not flashy.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle模型确实像赛车一样，因为它们并不是为日常使用而构建的。现实世界的生产模型更像是雷克萨斯——可靠但不炫目。
- en: 'Kaggle competitions and the real world optimize for very different things,
    with some key differences being:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle 竞赛和现实世界优化的内容截然不同，其中一些关键区别包括：
- en: '**Problem Definition**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题定义**'
- en: The real world allows you to define your problem and choose the metric that
    encapsulates the success of your model. This allows you to optimize for a more
    complex utility function than just a singular metric, where Kaggle competitions
    come with a single pre-defined metric and don’t let you define the problem efficiently.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界允许你定义问题并选择一个能够 encapsulate 成功的度量标准。这使你能够优化一个比单一指标更复杂的效用函数，而 Kaggle 竞赛则提供一个预定义的单一指标，并且不允许你高效地定义问题。
- en: '**Metrics**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**指标**'
- en: In the real world, we care about inference and training speeds, resource and
    deployment constraints and other performance metrics, whereas in Kaggle competitions
    the only thing we care about is the one evaluation metric. Imagine we have a model
    with 0.98 accuracy that is very resource and time-intensive, and another with
    0.95 accuracy that is much faster and less compute-intensive. In the real world,
    for a lot of domains, we might prefer the 0.95 accuracy model because maybe we
    care more about the time to inference. In Kaggle competitions, it doesn’t matter
    how long it takes to train the model or how many GPUs it requires, higher accuracy
    is always better.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，我们关注推断和训练速度、资源和部署限制以及其他性能指标，而在 Kaggle 竞赛中，我们只关心一个评估指标。假设我们有一个准确率为 0.98
    的模型，它非常消耗资源和时间，而另一个准确率为 0.95 的模型则更快且计算量更小。在现实世界中，对于许多领域，我们可能更倾向于选择 0.95 准确率的模型，因为我们可能更关注推断时间。在
    Kaggle 竞赛中，训练模型所需的时间或所需的 GPU 数量并不重要，更高的准确率总是更好。
- en: '**Interpretability**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释性**'
- en: Similarly, in the real world, we prefer simpler models that are easier to explain
    to stakeholders, whereas in Kaggle we pay no heed to model complexity. Model interpretability
    is important because it allows us to take concrete actions to solve the underlying
    problem. For example, in the real world looking at our model and being able to
    see a correlation between a feature (e.g., potholes on a street), and the problem
    (e.g. likelihood of car accident on the street), is more helpful than increasing
    the prediction accuracy by 0.005%.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在现实世界中，我们更喜欢那些易于向利益相关者解释的简单模型，而在 Kaggle 中我们对模型复杂性毫不在意。模型可解释性很重要，因为它使我们能够采取具体行动来解决潜在问题。例如，在现实世界中，查看我们的模型并能够看到一个特征（例如，街道上的坑洼）与问题（例如，街道上的汽车事故发生概率）之间的关联，比将预测准确度提高
    0.005% 更有帮助。
- en: '**Data Quality**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据质量**'
- en: Finally, in Kaggle competitions, our dataset is collected and wrangled for us.
    Anyone who’s done data science knows that is almost never the case in real life.
    But being able to collect and structure our data also gives us more control over
    the data science process.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 Kaggle 竞赛中，我们的数据集是由他人收集和整理的。任何做过数据科学的人都知道，现实生活中几乎不会这样。但能够收集和构建我们的数据也让我们对数据科学过程有了更多控制权。
- en: '**Incentives**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**激励**'
- en: All this incentivizes a massive amount of time spent tuning our hyperparameters
    to extract the last drops of performance from our model and, at times, convoluted
    feature engineer methodologies. While Kaggle competitions are an excellent way
    to learn data science and feature engineering, they don’t address real-world concerns
    like model explainability, problem definition, or deployment constraints.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素促使我们花费大量时间来调整超参数，以从模型中提取最后一滴性能，有时还需要复杂的特征工程方法。虽然 Kaggle 竞赛是学习数据科学和特征工程的绝佳途径，但它们并没有涉及诸如模型可解释性、问题定义或部署限制等现实世界的问题。
- en: A Royal Rumble of Models
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型的皇家大战
- en: It’s time to start selecting models!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候开始选择模型了！
- en: 'When picking our initial set of models to test, we want to be mindful of a
    few things:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择我们要测试的初始模型时，我们需要考虑几个方面：
- en: '**Pick a diverse set of initial models**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择一组多样的初始模型**'
- en: Different classes of models are good at modeling different kinds of underlying
    patterns in data. So a good first step is to quickly test out a few different
    classes of models to know which ones capture the underlying structure of your
    dataset most efficiently! Within the realm of our problem type (regression, classification,
    clustering) we want to try a mixture of tree-based, instance-based, and kernel-based
    models. Pick a model from each class to test out. We’ll talk more about the different
    model types in the ‘models to try’ section below.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类别的模型擅长建模数据中不同类型的潜在模式。因此，一个好的第一步是快速测试几种不同类别的模型，以了解哪些模型最有效地捕捉了数据集的潜在结构！在我们的问题类型（回归、分类、聚类）的范围内，我们希望尝试混合树模型、实例模型和核模型。从每个类别中选择一个模型进行测试。我们将在下面的“待试模型”部分详细讨论不同的模型类型。
- en: '**Try a few different parameters for each model**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**为每个模型尝试几种不同的参数**'
- en: While we don’t want to spend too much time finding the optimal set of hyper-parameters,
    we do want to try a few different combinations of hyper-parameters to allow each
    model class to have the chance to perform well.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不希望花太多时间找到最佳的超参数组合，但我们确实希望尝试几种不同的超参数组合，以使每个模型类别都有机会表现良好。
- en: '**Pick the strongest contenders**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**挑选最强的竞争者**'
- en: We can use the best performing models from this stage to give us intuition around
    which class of models we want to further dive into. Your Weights and Biases dashboard
    will guide you to the class of models that performed best for your problem.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这一阶段表现最佳的模型来帮助我们直观了解我们想深入研究的模型类别。你的 Weights and Biases 仪表板将指导你找到最适合你问题的模型类别。
- en: '**Dive deeper into models in the best performing model classes.**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**深入研究表现最佳的模型类别中的模型。**'
- en: Next, we select more models belonging to the best performing classes of models
    we shortlisted above! For example, if linear regression seemed to work best, it
    might be a good idea to try lasso or ridge regression as well.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们选择更多属于上述表现最佳的模型类别的模型！例如，如果线性回归似乎效果最好，那么尝试 lasso 或 ridge 回归也是一个好主意。
- en: '**Explore the hyper-parameter space in more detail.**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**更详细地探索超参数空间。**'
- en: At this stage, I’d encourage you to spend some time tuning the hyper-parameters
    for your candidate models. (The next post in this series will dive deeper into
    the intuition around selecting the best hyper-parameters for your models.) At
    the end of this stage, you should have the best performing versions of all your
    strongest models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我建议你花时间调整候选模型的超参数。（本系列的下一篇文章将深入探讨选择最佳超参数的直觉。）在这一阶段结束时，你应该拥有所有最强模型的最佳版本。
- en: Making the final selection — Kaggle
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终选择 — Kaggle
- en: '**Pick final submissions from diverse models. **Ideally, we want to select
    the best models from more than one class of models. This is because if you make
    your selections from just one class of models and it happens to be the wrong one,
    all your submissions will perform poorly. Kaggle competitions usually allow you
    to pick more than one entry for your final submission. I’d recommend choosing
    predictions made by your strongest models from different classes to build some
    redundancy into your submissions.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**从多样化的模型中挑选最终提交。** 理想情况下，我们希望从多个类别的模型中选择最佳模型。这是因为如果你只从一个类别的模型中做选择，并且这个类别恰好是错误的，那么你的所有提交都会表现不佳。Kaggle
    比赛通常允许你为最终提交选择多个条目。我建议选择来自不同类别的最强模型的预测，以在提交中增加一些冗余。'
- en: '**The leaderboard is not your friend, but your cross-validation scores are. **The
    most important thing to remember is that the public leaderboard is not your friend.
    Picking your models solely based on your public leaderboard scores will lead to
    overfitting the training dataset. And when the private leaderboard is revealed
    after the competition ends, sometimes you might see your rank dropping a lot.
    You can avoid this little pitfall by using cross-validation when training your
    models. Then pick the models with the best cross-validation scores, instead of
    the best leaderboard scores. By doing this you counter overfitting by measuring
    your model’s performance against multiple validation sets instead of just the
    one subset of test data used by the public leaderboard.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**排行榜不是你的朋友，但交叉验证分数是。** 最重要的是要记住，公共排行榜不是你的朋友。仅仅根据公共排行榜分数来选择模型会导致过拟合训练数据集。当比赛结束后，私有排行榜揭晓时，有时你可能会看到排名大幅下跌。通过在训练模型时使用交叉验证，你可以避免这个小陷阱。然后选择交叉验证分数最佳的模型，而不是排行榜分数最佳的模型。这样，你可以通过对比模型在多个验证集上的表现来抵消过拟合，而不是仅仅依赖于公共排行榜使用的那一部分测试数据。'
- en: Making the final selection — Real-world
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终选择 — 现实世界
- en: '**Resource constraints. **Different models hog different types of resources,
    and knowing whether you’re deploying the models on an IoT/mobile device with a
    small hard drive and processor or an in cloud can be crucial in picking the right
    model.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源限制。** 不同的模型会消耗不同类型的资源，了解你是否将模型部署在具有小硬盘和处理器的IoT/移动设备上，还是在云中，对选择合适的模型至关重要。'
- en: '**Training time vs. Prediction time vs. Accuracy. **Knowing what metric(s)
    you’re optimizing for is also crucial for picking the right model. For instance,
    self-driving cars need blazing fast prediction times, whereas fraud detection
    systems need to quickly update their models to stay up to date with the latest
    phishing attacks. For other cases like medical diagnosis, we care about the accuracy
    (or area under the ROC curve) much more than the training times.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练时间 vs. 预测时间 vs. 准确率。** 了解你优化的指标是选择正确模型的关键。例如，自动驾驶汽车需要极快的预测时间，而欺诈检测系统需要快速更新模型，以应对最新的钓鱼攻击。对于像医疗诊断这样的情况，我们更关心准确率（或ROC曲线下面积），而不是训练时间。'
- en: '**Complexity vs. Explainability Tradeoff. **More complex models can use orders
    of magnitude more features to train and make predictions require more compute
    but if trained correctly can capture really interesting patterns in the dataset.
    This also makes them convoluted and harder to explain though. Knowing how important
    it is to easily explain the model to stakeholders vs capturing some really interesting
    trends while giving up explainability is key to picking a model.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**复杂性 vs. 可解释性的权衡。** 更复杂的模型可以使用数量级更多的特征进行训练和预测，但如果训练得当，可以捕捉数据集中非常有趣的模式。然而，这也使得模型变得复杂，更难以解释。了解向利益相关者清晰解释模型的重要性与捕捉一些有趣趋势而放弃可解释性之间的平衡是选择模型的关键。'
- en: '**Scalability. **Knowing how fast and how big your model needs to scale can
    help you narrow down your choices appropriately.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**可扩展性。** 了解你的模型需要多快、多大地扩展可以帮助你适当地缩小选择范围。'
- en: '**Size of training data. **For really large datasets or those with many features,
    neural networks or boosted trees might be an excellent choice whereas smaller
    datasets might be better served by logistic regression, Naive Bayes, or KNNs.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练数据的大小。** 对于非常大的数据集或具有许多特征的数据集，神经网络或提升树可能是一个很好的选择，而较小的数据集可能更适合使用逻辑回归、朴素贝叶斯或KNN。'
- en: '**Number of parameters. **Models with a lot of parameters give you lots of
    flexibility to extract really great performance. However, there may be cases where
    you don’t have the time required to, for instance, train a neural network’s parameters
    from scratch. A model that works well out of the box would be the way to go in
    this case!'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**参数数量。** 拥有大量参数的模型可以提供很大的灵活性，从而获得非常好的性能。然而，可能有些情况下你没有时间从头开始训练神经网络的参数。在这种情况下，一个开箱即用的模型会是更好的选择！'
- en: Comparing Models
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较模型
- en: '[Weights and Biases](http://wandb.com/) lets you track and compare the performance
    of your models with one line of code.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[Weights and Biases](http://wandb.com/) 让你只需一行代码就能跟踪和比较模型的性能。'
- en: 'Once you have selected the models you’d like to try, train them, and simply
    add *wandb.log({‘score’: cv_score})* to log your model state. Once you’re done
    training, you can compare your model performances in one easy dashboard!'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '一旦你选择了想尝试的模型，训练它们，并简单地添加*wandb.log({‘score’: cv_score})*来记录你的模型状态。训练完成后，你可以在一个简单的仪表板中比较你的模型性能！'
- en: You can find the code to do this efficiently [here](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model).
    I encourage you to fork [this kernel](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model) and
    play with the code!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model)找到高效完成此任务的代码。我鼓励你分叉[这个kernel](https://www.kaggle.com/lavanyashukla01/picking-the-best-model-a-whirlwind-tour-of-model)并尝试代码！
- en: That’s it now you have all the tools you need to pick the right models for your
    problem!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，现在你拥有了选择适合你问题的模型所需的所有工具！
- en: Model selection and can be very complicated, but I hope this guide sheds some
    light and gives you a good framework for picking models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择可能非常复杂，但我希望本指南能为你提供一些启示，并为选择模型提供一个良好的框架。
- en: '[Original](https://towardsdatascience.com/part-i-choosing-a-machine-learning-model-9821eecdc4ce).
    Reposted with permission.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://towardsdatascience.com/part-i-choosing-a-machine-learning-model-9821eecdc4ce)。已获许可转载。'
- en: '**Bio:** [Lavanya](https://twitter.com/lavanyaai) is a machine learning engineer
    @ Weights and Biases. She began working on AI 10 years ago when she founded ACM
    SIGAI at Purdue University as a sophomore. In a past life, she taught herself
    to code at age 10, and built her first startup at 14\. She''s driven by a deep
    desire to understand the universe around us better by using machine learning.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [Lavanya](https://twitter.com/lavanyaai) 是 Weights and Biases 的机器学习工程师。她在
    10 年前创立了普渡大学的 ACM SIGAI，并开始从事人工智能工作。在过去的生活中，她在 10 岁时自学编程，并在 14 岁时创建了她的第一个创业公司。她驱动于通过使用机器学习更好地理解我们周围的宇宙。'
- en: '**Related:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Show off your Data Science skills with Kaggle Kernels](https://www.kdnuggets.com/2019/06/data-science-kaggle-kernels.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过Kaggle Kernels展示你的数据科学技能](https://www.kdnuggets.com/2019/06/data-science-kaggle-kernels.html)'
- en: '[Good Feature Building Techniques and Tricks for Kaggle](https://www.kdnuggets.com/2018/12/feature-building-techniques-tricks-kaggle.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适用于Kaggle的优秀特征构建技巧和窍门](https://www.kdnuggets.com/2018/12/feature-building-techniques-tricks-kaggle.html)'
- en: '[Lessons Learned From Benchmarking Fast Machine Learning Algorithms](https://www.kdnuggets.com/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从基准测试快速机器学习算法中学到的经验教训](https://www.kdnuggets.com/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
- en: More On This Topic
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题更多内容
- en: '[Unlock the Secrets to Choosing the Perfect Machine Learning Algorithm!](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开选择完美机器学习算法的秘密！](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)'
- en: '[Choosing the Right Clustering Algorithm for Your Dataset](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为你的数据集选择正确的聚类算法](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
- en: '[Segment Anything Model: Foundation Model for Image Segmentation](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Segment Anything Model：图像分割的基础模型](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
- en: '[How To Use Synthetic Data To Overcome Data Shortages For Machine…](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何利用合成数据克服机器学习模型训练中的数据短缺](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
- en: '[SHAP: Explain Any Machine Learning Model in Python](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP：用Python解释任何机器学习模型](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
- en: '[The Significance of Data Quality in Making a Successful Machine…](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据质量在成功机器学习模型中的重要性](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
