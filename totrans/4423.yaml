- en: Working with Spark, Python or SQL on Azure Databricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/08/spark-python-sql-azure-databricks.html](https://www.kdnuggets.com/2020/08/spark-python-sql-azure-databricks.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Ajay Ohri](http://linkedin.com/in/ajayohri), Data Science Manager**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Databricks** is an Apache Spark-based big data analytics service designed
    for data science and data engineering offered by Microsoft. It allows collaborative
    working as well as working in multiple languages like Python, Spark, R and SQL.
    Working on Databricks offers the advantages of cloud computing - scalable, lower
    cost, on demand data processing and data storage.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Here we look at some ways to interchangeably work with Python, PySpark and SQL.
    We learn how to import in data from a CSV file by uploading it first and then
    choosing to  create it in a notebook. We learn how to convert an SQL table to
    a Spark Dataframe and convert a Spark Dataframe to a Python Pandas Dataframe.
    We also learn how to convert a Spark Dataframe to a Permanent or Temporary SQL
    Table.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need to learn how to interchange code between SQL, Spark and Python
    Panda Dataframe? SQL is great for easy writing and readable code for data manipulation,
    Spark is great for speed for big data as well as Machine Learning, while Python
    Pandas can be used for everything from data manipulation, machine learning as
    well as plotting in seaborn or matplotlib libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/10e3236941f0b760eb80a0b99e6a2abe.png)'
  prefs: []
  type: TYPE_IMG
- en: We choose a SQL notebook for ease and then we choose appropriate cluster with
    appropriate RAM, Cores, Spark version etc. Even though it is a SQL notebook we
    can write python code by typing %python in front of code in that cell.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/f90682a67b15f98366a13a8280832397.png)'
  prefs: []
  type: TYPE_IMG
- en: Now let's begin the basics of data input, data inspection and data interchange
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1** Reading in Uploaded Data'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 2** Create a temporary view or table from SPARK Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3** Creating Permanent SQL Table from SPARK Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 4** Inspecting SQL Table'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 5** Converting SQL Table to SPARK Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 6** Inspecting SPARK Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 7** Converting Spark Dataframe to Python Pandas Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 8** Inspecting Python Dataframe'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**References**'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Azure Databricks - [https://www.slideshare.net/jamserra/introduction-to-azure-databricks-83448539](https://www.slideshare.net/jamserra/introduction-to-azure-databricks-83448539)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dataframes and Datasets - [https://docs.databricks.com/spark/latest/dataframes-datasets/index.html](https://docs.databricks.com/spark/latest/dataframes-datasets/index.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Optimize conversion between PySpark and pandas DataFrames - [https://docs.databricks.com/spark/latest/spark-sql/spark-pandas.html](https://docs.databricks.com/spark/latest/spark-sql/spark-pandas.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: pyspark package - [https://spark.apache.org/docs/latest/api/python/pyspark.html](https://spark.apache.org/docs/latest/api/python/pyspark.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bio: [Ajay Ohri](http://linkedin.com/in/ajayohri)** is Data Science Manager
    (Publicis Sapient) and author of 4 books on data science including R for Cloud
    Computing and Python for R Users.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Apache Spark on Dataproc vs. Google BigQuery](/2020/07/apache-spark-dataproc-vs-google-bigquery.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Containerization of PySpark Using Kubernetes](/2020/08/containerization-pyspark-kubernetes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Apache Spark Best Practices For Data Science](/2020/08/5-spark-best-practices-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Working with SQLite Databases in Python](https://www.kdnuggets.com/a-guide-to-working-with-sqlite-databases-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Working With Sparse Features In Machine Learning Models](https://www.kdnuggets.com/2021/01/sparse-features-machine-learning-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Working with Big Data: Tools and Techniques](https://www.kdnuggets.com/working-with-big-data-tools-and-techniques)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Deep Learning working in the wild: A Data-Centric Course](https://www.kdnuggets.com/2022/04/corise-deep-learning-wild-data-centric-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Soft Skills for Data Scientists Working Remotely](https://www.kdnuggets.com/2022/05/6-soft-skills-data-scientists-working-remotely.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
