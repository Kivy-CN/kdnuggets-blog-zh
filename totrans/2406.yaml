- en: 'Linear Machine Learning Algorithms: An Overview'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html](https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Linear Machine Learning Algorithms: An Overview](../Images/cb7968557a2d010de52004b42d71d535.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear machine learning algorithms assume a linear relationship between the
    features and the target variable. In this article, we’ll discuss several linear
    algorithms and their concepts. Here’s a glimpse into what you can expect to learn:'
  prefs: []
  type: TYPE_NORMAL
- en: Types of linear ML algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assumptions of linear algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The difference between various linear machine learning algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to interpret the results of linear algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to use different linear algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive right in.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Linear Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can use linear algorithms for classification and regression problems. Let’s
    start by looking at different algorithms and what problems they solve.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear regression is arguably one of the oldest and most popular algorithms.
    With roots in the statistics world, the algorithm is used for solving regression
    problems. This means that the final output of the model is a numeric value. The
    algorithm maps a linear relationship between the input features(X) and the output
    (y).
  prefs: []
  type: TYPE_NORMAL
- en: The [Ordinary least squares Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
    is one the most widely used implementations of linear regression. It fits a linear
    model with coefficients `w = (w1, …, wp) to minimize the residual sum of squares
    between the observed targets in the dataset and the targets predicted by the linear
    approximation`. [Source](https://scikit-
  prefs: []
  type: TYPE_NORMAL
- en: learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).
  prefs: []
  type: TYPE_NORMAL
- en: In this approach, multiple lines are fitted, and the one that returns the least
    error is taken as the **best fit**. The error is the difference between the estimated
    value and the actual value.
  prefs: []
  type: TYPE_NORMAL
- en: Since linear regression fits a line, it can extrapolate to future data, unlike
    other algorithms such as random forests. Tree-based algorithms can not predict
    values outside the given data because their predictions are based on the mean
    of the predictions of different decision trees.
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](../Images/e7715eb95f29003470d7588229bcecb1.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Residuals for Linear Regression Fit](https://commons.wikimedia.org/wiki/File:Residuals_for_Linear_Regression_Fit.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, when predicting the price of a commodity, a line is fitted between
    the independent and dependent variables. The general equation of a linear regression
    line looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: c is the intercept, that is, the value of y when x is zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: m is the slope of the line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: x is the independent variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: y is the dependent variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other linear regression algorithms include:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Lasso regression**](https://scikit-learn.org/stable/modules/linear_model.html#lasso)
    a linear model that introduces the ***L1 regularization*** whose objective is
    to minimize the absolute sum of the coefficients. In this algorithm, the weights
    of insignificant features are driven to zero. Hence insignificant features are
    dropped from the linear equation making the final equation simpler.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Ridge regression**](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)
    whose coefficients minimize a penalized residual sum of squares. This regularization
    is referred to as ***L2 regularization***. In this algorithm, the weights of insignificant
    features are reduced to small numbers close to zero but not zero. This is handy
    for trimming coefficients while keeping all features while adjusting the weights
    accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assumptions of linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linear regression is sensitive to outliers in the data. Other items to look
    out for include:'
  prefs: []
  type: TYPE_NORMAL
- en: The data has a normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That the relationship between the input variables and the output is linear.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The variables are not highly correlated. In the event of this occurrence, remove
    highly correlated variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standardizing or normalizing the data also doesn’t hurt the algorithm!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logistic regression is a linear model for classification problems. It generates
    a probability between 0 and 1\. This happens by fitting a [logistic function,
    also known as the sigmoid function.](https://en.wikipedia.org/wiki/Logistic_function)
    The function is responsible for mapping the predicted values to numbers between
    0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](../Images/b2a09333fc8a8e506d0da6a66f57387f.png)'
  prefs: []
  type: TYPE_IMG
- en: The Logistic Function | [Image source](https://christophm.github.io/interpretable-ml-book/images/logistic-function-1.png)
  prefs: []
  type: TYPE_NORMAL
- en: When used for multi-class classification, it is referred to as multinomial regression.
    This is done by adjusting the logistic regression algorithm to predict a multinormal
    distribution. It is achieved by changing the loss function used to train the model
    from log-loss to cross-entropy loss. The algorithm is also altered to output a
    probability for each class instead of a single probability.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most popular implementations of Logistic Regression is done in [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).
    This implementation handles imbalanced datasets by setting the `class_weight`
    parameter to `balanced.` In this case, the algorithm will adjust the weights to
    give more importance to the class with fewer samples, enabling the algorithm to
    learn more from that class.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic regression assumptions**'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression algorithm assumptions are similar to those of linear regression. 
    The unique addition here is that the algorithm expects the target variable to
    be categorical.
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Support Vector Machines(SVM) is a supervised machine learning algorithm that
    can be used for regression and classification problems. It is mostly used for
    classification.
  prefs: []
  type: TYPE_NORMAL
- en: Linear SVM is used when data is linearly separable. In this case, the data is
    easily separated using a single line.
  prefs: []
  type: TYPE_NORMAL
- en: Classification is done by finding the hyperplane that best separates the two
    categories. SVM uses extreme data points in creating decision boundaries. These
    extreme data points are referred to as ***support vectors***, hence the name Support
    Vector Machines.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines](../Images/a568d50869df8b516cb48fa4688edb92.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Support Vector Machine model. Support vectors are created to maximize the
    separation between two groups](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/800px-Svm_separating_hyperplanes_%28SVG%29.svg.png).'
  prefs: []
  type: TYPE_NORMAL
- en: The distance between the vectors is known as a ***margin***. The algorithm works
    by maximizing the gap between the two categories––the margin.  The ***optimal
    hyperplane*** is the hyperplane with the maximum margin.
  prefs: []
  type: TYPE_NORMAL
- en: '![Maximum-margin hyperplane and margin for an SVM trained on two classes.](../Images/4dc921330b99b4983a2477f5d7cc3058.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Maximum-margin hyperplane and margin for an SVM trained on two classes.](https://commons.wikimedia.org/wiki/File:SVM_margin.png)'
  prefs: []
  type: TYPE_NORMAL
- en: SVM can also compute boundaries for non-linear classification through a technique
    known as the ***kernel trick***. It works by adding a third dimension and separating
    the data points in a 3D space.
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustration of kernel trick in SVM](../Images/5a6183e7b8cbdeed889cd6c6e15b3bd3.png)'
  prefs: []
  type: TYPE_IMG
- en: '[An illustration of kernel trick in SVM](https://commons.wikimedia.org/wiki/File:Kernel_trick_idea.svg)'
  prefs: []
  type: TYPE_NORMAL
- en: Difference Between SVM, Linear, and Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A linear regression algorithm is different from logistic regression in that
    the logistic regression outputs probabilities. Hence, the logistic regression
    algorithm can be used for classification while the linear regression algorithm
    can’t. While the logistic regression algorithm output values between 0 and 1,
    the linear regression algorithm will extrapolate and output values above and below
    zero.
  prefs: []
  type: TYPE_NORMAL
- en: SVM is more memory efficient because it uses a subset of the training data in
    the decision function. Unlike the logistic regression algorithm, SVM doesn’t provide
    probability estimates. SVM is also not prone to outliers like logistic regression
    because it is mainly concerned with the data points closest to the hyperplanes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Interpreting Linear Algorithm Results: Summary Statistics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A linear regression outputs a coefficient for each independent variable. Let’s
    take an example of an independent variable X1 used to predict the price of a commodity.
    If the coefficient of X1 is 6.2, it can be interpreted as follows; when all factors
    are held constant, a one-unit increase in F1 will lead to a  6.2 increase in the
    commodity's price.
  prefs: []
  type: TYPE_NORMAL
- en: A logistic regression algorithm outputs the probability of an item belonging
    to a certain class. Therefore, interpreting the results is done by setting a threshold
    of 0.5 to separate the two classes.
  prefs: []
  type: TYPE_NORMAL
- en: Given a certain dataset with two classes, the SVM algorithm will predict the
    class an item belongs to by computing the best hyperplane. It does not compute
    any probabilities but uses the distance of the data points from the optimal hyperplane
    to separate the categories.
  prefs: []
  type: TYPE_NORMAL
- en: When to Use Logistic Regression vs. Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression and Support Vector Machines are two popular algorithms in
    classification. However, in certain situations, you might prefer one over the
    other. For instance, it’s better to use SVM when there are outliers because they
    don’t affect how the algorithm separates the two classes. SVM is also a better
    choice when the data is of high dimension.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression is a better choice when classes are not well separated.
    Otherwise, use SVM. However, it’s common to start with a logistic regression model
    to create a baseline model.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear algorithms are quite popular in machine learning. In this article, we
    have looked at a couple of linear models and their inner workings. We have also
    talked about when you would prefer one over the other. Generally, the choice of
    algorithm will depend on the problem and the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Regularization for sparsity](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** is experienced
    in data science, machine learning, and deep learning with a keen eye for building
    machine learning communities.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Machine Learning Algorithms: An In-Depth Overview](https://www.kdnuggets.com/understanding-machine-learning-algorithms-an-indepth-overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Labeling for Machine Learning: Market Overview, Approaches, and Tools](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 3 Free Resources to Learn Linear Algebra for Machine Learning](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
