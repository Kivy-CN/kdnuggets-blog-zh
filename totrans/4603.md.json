["```py\n$ /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```", "```py\n$ brew analytics off\n```", "```py\nexport SPARK_PATH=(path found above by running brew info apache-spark)\nexport PYSPARK_DRIVER_PYTHON=\"jupyter\"\nexport PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\n#For python 3, You have to add the line below or you will get an error#\nexport PYSPARK_PYTHON=python3\nalias snotebook='$SPARK_PATH/bin/pyspark --master local[2]'\n\n```", "```py\n$ pip install findspark\n```", "```py\n# useful to have this code snippet to avoid getting an error in case forgeting\n# to close spark\n\ntry:\n    spark.stop()\nexcept:\n    pass\n\n# Using findspark to find automatically the spark folder\nimport findspark\nfindspark.init()\n\n# import python libraries\nimport random\n\n# initialize\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()\nnum_samples = 100000000\n\ndef inside(p):\n    x, y = random.random(), random.random()\n    return x*x + y*y < 1\n\ncount = spark.sparkContext.parallelize(range(0, num_samples)).filter(inside).count()\npi = 4 * count / num_samples\nprint(pi)\n```", "```py\nfrom pyspark.sql import SparkSession\nspark = SparkSession\\\n        .builder\n        .master(\"local[*]\")\n        .config(\"spark.driver.cores\", 1)\n        .appName(\"understanding_sparksession\")\n        .getOrCreate()\n```"]