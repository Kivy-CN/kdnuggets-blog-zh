# 37个原因说明你的神经网络无法正常工作

> 原文：[https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html](https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html)

[评论](/2017/08/37-reasons-neural-network-not-working.html/2#comments)

**由 [Slav Ivanov](https://twitter.com/slavivanov)，企业家和 ML 从业者**。

网络已经训练了12小时。所有一切看起来都很好：梯度在流动，损失在减少。但随后出现了预测：全是零，全是背景，什么也没检测到。“我做错了什么？”——我问我的计算机，它没有回答。

你从哪里开始检查你的模型是否输出垃圾（例如，预测所有输出的均值，或者准确率非常差）？

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT

* * *

网络可能由于多种原因无法训练。在许多调试过程中，我经常发现自己进行相同的检查。我将我的经验与最佳想法汇总在这个实用的列表中。希望对你也有帮助。

### 目录

+   0. 如何使用本指南？

+   I. 数据集问题

+   II. 数据标准化/增强问题

+   III. 实现问题

+   IV. 训练问题

### 0. 如何使用本指南？

许多事情可能会出错。但其中一些比其他的更容易出现问题。我通常从这个简短的列表开始作为紧急应对：

1.  从已知对这种类型的数据有效的简单模型开始（例如，VGG用于图像）。如果可能，使用标准损失函数。

1.  关闭所有附加功能，例如正则化和数据增强。

1.  如果是微调模型，请再次检查预处理，因为它应该与原始模型的训练相同。

1.  验证输入数据是否正确。

1.  从非常小的数据集（2-20 个样本）开始。对其进行过拟合，并逐步增加更多数据。

1.  逐步添加回所有被遗漏的部分：增强/正则化、自定义损失函数，尝试更复杂的模型。

如果以上步骤不起作用，开始检查以下的大列表，并逐一验证。

### I. 数据集问题

![](../Images/63268de4720c5d16ff843c53129d4356.png)

#### 1. 检查你的输入数据

检查你传递给网络的输入数据是否合理。例如，我曾多次混淆图像的宽度和高度。有时我会错误地输入全零数据，或者重复使用相同的批次。所以打印/显示几批输入和目标输出，确保它们是正确的。

#### 2. 尝试随机输入

尝试传递随机数字而不是实际数据，看看错误是否表现相同。如果是，这肯定是网络在某个点将数据变成垃圾的迹象。尝试逐层/逐操作调试，看看问题出在哪里。

#### 3. 检查数据加载器

你的数据可能没问题，但将输入传递给网络的代码可能有问题。在任何操作之前打印第一层的输入并进行检查。

#### 4. 确保输入与输出连接

检查几个输入样本是否有正确的标签。同时确保洗牌输入样本时，输出标签的洗牌方式也相同。

#### 5. 输入和输出之间的关系是否过于随机？

也许输入与输出之间的非随机关系相较于随机部分过小（有人认为股票价格就是这样）。即输入与输出之间的关系不够紧密。没有一种普遍的方法来检测这一点，因为这取决于数据的性质。

#### 6. 数据集中是否有过多的噪声？

我曾经在从一个食品网站抓取图像数据集时遇到过这种情况。标签太差，以至于网络无法学习。手动检查一些输入样本，看看标签是否正确。

截止点尚在讨论中，因为[这篇论文](https://arxiv.org/pdf/1412.6596.pdf)在使用50%损坏标签的情况下在MNIST上达到了超过50%的准确率。

#### 7. 洗牌数据集

如果你的数据集没有被洗牌，并且有特定的顺序（按标签排序），这可能会对学习产生负面影响。洗牌你的数据集以避免这种情况。确保你在洗牌输入和标签时同时进行。

#### 8. 减少类别不平衡

是否每个类别B的图像都有1000张类别A的图像？那么你可能需要平衡你的损失函数或[尝试其他类别不平衡的方法](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)。

#### 9. 你有足够的训练样本吗？

如果你是从头开始训练一个网络（即不是微调），你可能需要大量的数据。对于图像分类，[有人说](https://stats.stackexchange.com/a/226693/30773)每个类别需要1000张图片或更多。

#### 10. 确保你的批次中没有单一标签

这可能发生在排序的数据集中（即前10k样本包含相同的类别）。通过洗牌数据集可以轻松解决。

#### 11. 减小批次大小

[这篇论文](https://arxiv.org/abs/1609.04836)指出，使用非常大的批次可能会降低模型的泛化能力。

#### 附加 1. 使用标准数据集（例如mnist、cifar10）

感谢@[hengcherkeng](https://medium.com/@hengcherkeng)提供的这些内容：

> 在测试新的网络架构或编写新的代码时，首先使用标准数据集，而不是你自己的数据。这是因为这些数据集有很多参考结果，并且已经证明是“可解”的。这样就不会出现标签噪声、训练/测试分布差异、数据集难度过大等问题。

### II. 数据标准化/增强

![](../Images/56f24da5948f3ae4863dff3e9c3d02f6.png)

#### **12\. 标准化**特征

你是否将输入标准化为零均值和单位方差？

#### 13\. 你是否进行了过多的数据增强？

增强具有正则化效果。过多的增强结合其他正则化形式（权重L2、丢弃法等）可能导致网络欠拟合。

#### 14\. 检查你预训练模型的预处理

如果你使用的是预训练模型，请确保使用与模型训练时相同的归一化和预处理。例如，图像像素应在[0, 1]、[-1, 1]还是[0, 255]范围内？

#### 15\. 检查训练/验证/测试集的预处理

CS231n指出了一个[常见陷阱](http://cs231n.github.io/neural-networks-2/#datapre)：

> “…任何预处理统计（例如数据均值）只能在训练数据上计算，然后应用于验证/测试数据。例如，在整个数据集上计算均值并从每张图像中减去，然后将数据拆分为训练/验证/测试集，将是一个错误。”

另外，检查每个样本或批次的不同预处理。

### 了解更多信息

+   [为什么你应该使用线性回归模型而不是…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [停止学习数据科学以寻找目的，并找到目的…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [成为优秀数据科学家需要的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [一项90亿美元的AI失败，详解](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)
