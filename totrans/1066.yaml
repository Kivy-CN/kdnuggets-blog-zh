- en: How to Generate Synthetic Tabular Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何生成合成表格数据集
- en: 原文：[https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)
- en: '![How to Generate Synthetic Tabular Dataset](../Images/a1d5f83ff8498849deb3ba47907a9ccc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/a1d5f83ff8498849deb3ba47907a9ccc.png)'
- en: Image by author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Companies often come across the problem where they don't have enough real-life
    data or they cannot use actual data due to privacy concerns. This is where synthetic
    data generation comes to the rescue. Researchers and data scientists are using
    synthetic data to build new products, improve the performance of machine learning
    models, replace sensitive data, and save costs in acquiring the data. Read more
    at [The Ultimate Guide to Synthetic Data](https://research.aimultiple.com/synthetic-data/).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 企业经常遇到这样的问题：他们没有足够的真实数据，或者由于隐私问题不能使用实际数据。这时，合成数据生成技术就派上用场了。研究人员和数据科学家利用合成数据来开发新产品、提升机器学习模型的性能、替代敏感数据，并节省数据获取成本。更多内容请阅读
    [终极合成数据指南](https://research.aimultiple.com/synthetic-data/)。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The synthetic data is used in the healthcare sector, self-driving cars, financial
    sectors, maintaining a high level of privacy, and for research purposes - [Towards
    Data Science](https://towardsdatascience.com/synthetic-data-key-benefits-types-generation-methods-and-challenges-11b0ad304b55).
    Last year the entire Kaggle’s [Tabular Playground Series](https://www.kaggle.com/c/tabular-playground-series-apr-2021)
    dataset was developed using CTGANs. The Kaggle team has used the old datasets
    from various competitions to generate artificial datasets. It was a genius move
    by Kaggle as it made cheating hard. In this blog, we are going to learn about
    various methods to generate tabular data using [SDV’s](https://sdv.dev/SDV/#)
    Python library.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据被应用于医疗保健、自驾车、金融行业、维持高水平隐私以及研究目的 - [数据科学探索](https://towardsdatascience.com/synthetic-data-key-benefits-types-generation-methods-and-challenges-11b0ad304b55)。去年，整个Kaggle的
    [表格玩法系列](https://www.kaggle.com/c/tabular-playground-series-apr-2021) 数据集是使用CTGANs开发的。Kaggle团队利用来自各种比赛的旧数据集生成了人工数据集。这是Kaggle的一个聪明举动，因为它使作弊变得困难。在这篇博客中，我们将学习使用
    [SDV](https://sdv.dev/SDV/#) 的Python库生成表格数据的各种方法。
- en: CTGANs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CTGANs
- en: '[CTGAN](https://arxiv.org/abs/1907.00503) uses several [GAN-based](https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/)
    methods to learn from original data and generate highly realistic tabular data.
    To produce synthetic tabular data, we will use conditional generative adversarial
    networks from open-source Python libraries called [CTGAN](https://pypi.org/project/ctgan/)
    and Synthetic Data Vault ([SDV](https://sdv.dev/)). The SDV allows data scientists
    to learn and generate data sets from single tables, relational data, and time
    series. It is the one-stop solution for all kinds of tabular data.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[CTGAN](https://arxiv.org/abs/1907.00503) 使用几种 [基于GAN](https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/)
    的方法从原始数据中学习，并生成高度真实的表格数据。为了生成合成表格数据，我们将使用开源Python库中的条件生成对抗网络，如 [CTGAN](https://pypi.org/project/ctgan/)
    和合成数据库 ([SDV](https://sdv.dev/))。SDV允许数据科学家从单表、关系数据和时间序列中学习和生成数据集。它是各种表格数据的一站式解决方案。'
- en: With a few lines of code, our deep learning model can learn and generate sample
    tabular data. In the example below, we have initialized the model, trained it
    on real data, saved the model, and then generated 200 samples. This is just a
    start, we will also learn various ways to generate artificial data and then evaluate
    the results.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过几行代码，我们的深度学习模型可以学习并生成样本表格数据。在下面的示例中，我们初始化了模型，在真实数据上训练了它，保存了模型，然后生成了 200 个样本。这只是开始，我们还将学习生成人工数据的各种方法，然后评估结果。
- en: '![How to Generate Synthetic Tabular Dataset](../Images/7d9b8b958865d9e407e605cacfe3e8ff.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/7d9b8b958865d9e407e605cacfe3e8ff.png)'
- en: Image by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Tutorial
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教程
- en: In this tutorial, we are going to use the [Food Demand Forecasting | Kaggle](https://www.kaggle.com/kannanaikkal/food-demand-forecasting)
    (under [DbCL](https://opendatacommons.org/licenses/dbcl/1-0/) license) dataset
    to create a synthetic dataset. We will experiment with a vanilla model, custom
    model and finally evaluate results. The results will help us determine the quality
    of generated data. We will be using a [Deepnote](https://deepnote.com/) cloud
    notebook for generating the results.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用 [Food Demand Forecasting | Kaggle](https://www.kaggle.com/kannanaikkal/food-demand-forecasting)（根据
    [DbCL](https://opendatacommons.org/licenses/dbcl/1-0/) 许可）数据集来创建合成数据集。我们将尝试一个基础模型、自定义模型，最后评估结果。这些结果将帮助我们确定生成数据的质量。我们将使用
    [Deepnote](https://deepnote.com/) 云笔记本生成结果。
- en: CTGANSynthesizer
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CTGANSynthesizer
- en: First, we need to install the CTGAN library by using ` pip install ctgan` and
    then load our dataset using Pandas. We are shuffling the dataset to get truly
    randomized two thousand samples. We are using a lower number of samples to reduce
    training duration.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要通过使用 `pip install ctgan` 安装 CTGAN 库，然后使用 Pandas 加载我们的数据集。我们正在打乱数据集，以获得真正随机的两千个样本。我们使用较少的样本量来减少训练时间。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Before we start model training let's observe our actual dataset so that we can
    see the difference between real and artificial.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始模型训练之前，让我们观察一下我们的实际数据集，以便我们可以看到真实数据和人工数据之间的差异。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![How to Generate Synthetic Tabular Dataset](../Images/3c690c93a910e65edacf933f3f52d126.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/3c690c93a910e65edacf933f3f52d126.png)'
- en: In order to train our CTGAN model, we need to provide a list of discrete columns,
    batch size, and the number of epochs. The API is similar to [Scikit-learn](https://scikit-learn.org/)
    where we initialize the model with hyperparameters and then train the model using
    `.fit()`. After successfully training the model, we are going to save our model
    to reproduce similar results. With `ctgan.sample(2000)` we are going to generate
    2k samples.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的 CTGAN 模型，我们需要提供离散列的列表、批量大小和训练轮数。API 类似于 [Scikit-learn](https://scikit-learn.org/)，我们用超参数初始化模型，然后使用
    `.fit()` 训练模型。在成功训练模型后，我们将保存模型以重现类似的结果。通过 `ctgan.sample(2000)` 我们将生成 2k 个样本。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As we can observe, the output is quite similar to the original data. The results
    are acceptable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所观察到的，输出与原始数据非常相似。结果是可以接受的。
- en: '![How to Generate Synthetic Tabular Dataset](../Images/1a26cf80589b30adf5411e35c8776e27.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/1a26cf80589b30adf5411e35c8776e27.png)'
- en: SDV
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SDV
- en: In this part, we are going to use the [SDV](https://sdv.dev/SDV/) library to
    generate data. SDV provides us with multiple single table models and also provides
    more features to run data generation experiments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用 [SDV](https://sdv.dev/SDV/) 库生成数据。SDV 提供了多个单表模型，并且还提供了更多功能来进行数据生成实验。
- en: First, we are going to initialize the model by providing a primary key and decimal
    places for floating features. Then, we are going to train our model and generate
    200 samples.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将通过提供主键和浮动特征的小数位数来初始化模型。然后，我们将训练模型并生成 200 个样本。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As we can see, the id column started with 0 and the overall data looks clean.
    To fully understand our synthetic data, we need to evaluate the dataset using
    similarity metrics and comparing the data distribution.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，id 列以 0 开始，整体数据看起来很干净。为了完全理解我们的合成数据，我们需要使用相似度度量来评估数据集，并比较数据分布。
- en: '![How to Generate Synthetic Tabular Dataset](../Images/3c192f11c664fe8dc1686b606d09ee60.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/3c192f11c664fe8dc1686b606d09ee60.png)'
- en: Evaluation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: We will be using the SDV evaluate function to analyze the similarity between
    real and fake datasets. This function displays aggregated results of all of the
    similarity metrics from 0 to 1, where 0 begins worst and 1 is ideal. In our case,
    the similarity metric is **(0.34)** which is bad and we need to work more on hyperparameter
    optimization to get better results.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 SDV evaluate 函数来分析真实数据集与虚假数据集之间的相似度。此函数显示了所有相似度指标的汇总结果，范围从 0 到 1，其中 0
    最差，1 最理想。在我们的情况下，相似度指标为**（0.34）**，这表示较差，我们需要在超参数优化上投入更多工作，以获得更好的结果。
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[TableEvaluator](https://pypi.org/project/table-evaluator/) is used to evaluate
    the similarity between a synthesized and a real dataset. It was exclusively built
    for analyzing the performance of GAN-based tabular models. By writing a few lines
    of code, we can compare both datasets on the absolute log mean, distribution of
    all features, correlation matrix, and first two components of [PCA](https://www.keboola.com/blog/pca-machine-learning).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[TableEvaluator](https://pypi.org/project/table-evaluator/) 用于评估合成数据集与真实数据集之间的相似度。它专门用于分析基于
    GAN 的表格模型的性能。通过编写几行代码，我们可以比较两个数据集在绝对对数均值、所有特征的分布、相关矩阵和前两个 [PCA](https://www.keboola.com/blog/pca-machine-learning)
    组件上的表现。'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By observing all the visualizing, we can conclude that the data features distribution
    is somehow similar but principal component analysis distribution is completely
    different from real data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察所有可视化结果，我们可以得出结论：数据特征的分布在某种程度上是相似的，但主成分分析的分布与真实数据完全不同。
- en: '![How to Generate Synthetic Tabular Dataset](../Images/e37e1772e4003f50070cb3afa1fb5c5f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/e37e1772e4003f50070cb3afa1fb5c5f.png)'
- en: '![How to Generate Synthetic Tabular Dataset](../Images/264bb0bb3ad5633d3e2be96acd065cb4.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/264bb0bb3ad5633d3e2be96acd065cb4.png)'
- en: '![How to Generate Synthetic Tabular Dataset](../Images/540039a27ab33660f9a3b8781baf32f3.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/540039a27ab33660f9a3b8781baf32f3.png)'
- en: Custom Model
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义模型
- en: Let’s create a customized model to improve the similarity metric by changing,
    number of epochs, bach_size, generator dimensions, and discriminator dimensions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来创建一个自定义模型，通过改变训练轮数、批量大小、生成器维度和判别器维度来改善相似度指标。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can also customize the generated dataset by creating constants. Let's say
    we want to generate data for *center_id 161\.* We will first create a dictionary
    of "conditions" and pass it to a sample function as shown below.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过创建常量来定制生成的数据集。假设我们想为*center_id 161\.* 生成数据。我们将首先创建一个“条件”字典，并将其传递给下述样本函数。
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![How to Generate Synthetic Tabular Dataset](../Images/889ae70d040607bc4d50ba13fcff4852.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![如何生成合成表格数据集](../Images/889ae70d040607bc4d50ba13fcff4852.png)'
- en: With light hyper-parameter optimization we have achieved a better similarity
    score **(0.53)** as shown below. If your generated dataset is soaring between
    0.6 to 0.7 then your dataset is ready for production.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过轻量级超参数优化，我们已实现了更好的相似度评分**（0.53）**，如下所示。如果您的生成数据集的评分在 0.6 到 0.7 之间，那么您的数据集已准备好用于生产。
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: SDV for Relational and Time Series
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SDV 用于关系数据和时间序列
- en: We can also use the SDV library to generate relational dataset using `sdv.relational.HMA1`
    and time series data using `sdv.timeseries.PAR`. The API works similar CTGAN model,
    we just need to train the model and then generate **N** numbers of samples.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 SDV 库生成关系数据集，使用 `sdv.relational.HMA1` 和时间序列数据，使用 `sdv.timeseries.PAR`。API
    的工作原理类似于 CTGAN 模型，我们只需训练模型，然后生成**N**个样本。
- en: Relational Data
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关系数据
- en: '[Hierarchical Modeling Algorithm](https://sdv.dev/SDV/user_guides/relational/hma1.html)
    is an algorithm that allows one to recursively walk through a relational dataset
    and apply tabular models across all the tables. In this way, models learn how
    all the fields from all the tables are related.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[层次建模算法](https://sdv.dev/SDV/user_guides/relational/hma1.html) 是一种允许递归遍历关系数据集并在所有表格上应用表格模型的算法。通过这种方式，模型学习所有表格中的字段如何相关。'
- en: Time Series
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列
- en: '[Probabilistic AutoRegressive](https://sdv.dev/SDV/user_guides/timeseries/par.html#what-is-par)
    allows learning multi-type, multivariate time series data and later on generates
    new synthetic data that has the same format and properties as the learned one.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[概率自回归模型](https://sdv.dev/SDV/user_guides/timeseries/par.html#what-is-par)
    允许学习多类型、多变量的时间序列数据，然后生成具有与学习数据相同格式和属性的新合成数据。'
- en: Conclusion
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: I use CTGANs to improve my machine learning model performance and assess model
    accuracy on the unseen dataset. It has also helped me with an unbalanced class
    dataset. If you have limited training data and you want to develop an AI product
    without investing a lot of money in occurring data then you should consider generating
    synthetic datasets. The synthetic dataset is not limited to tabular as we can
    now use GANs to generate images, audio, and text dataset. Creating artificial
    data is an ever-growing field. In the future, it will surpass the real dataset.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 CTGAN 来提升我的机器学习模型性能，并评估模型在未见数据集上的准确性。这也帮助我处理不平衡的类数据集。如果你有有限的训练数据，并且希望在不投入大量资金的情况下开发人工智能产品，那么你应该考虑生成合成数据集。合成数据集不仅限于表格数据，我们现在可以使用
    GAN 生成图像、音频和文本数据集。创建人工数据是一个不断发展的领域，未来它将超过真实数据集。
- en: In this blog, we have learned about CTGANs and how to use the SDV library to
    generate the tabular dataset. We have also learned that we can generate relation
    and times series data with a similar API. I hope you enjoyed the short tutorial
    and if you have any questions about debugging the code, comment below.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们了解了 CTGAN 以及如何使用 SDV 库生成表格数据集。我们还了解到，我们可以使用类似的 API 生成关系数据和时间序列数据。希望你喜欢这个简短的教程，如果你对调试代码有任何问题，请在下方评论。
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一名认证的数据科学专业人士，热爱构建机器学习模型。目前，他专注于内容创作，并撰写关于机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是使用图神经网络为患有心理疾病的学生构建人工智能产品。'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Generate Synthetic Time-series Data with Open-source Tools](https://www.kdnuggets.com/2022/06/generate-synthetic-timeseries-data-opensource-tools.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用开源工具生成合成时间序列数据](https://www.kdnuggets.com/2022/06/generate-synthetic-timeseries-data-opensource-tools.html)'
- en: '[Data-centric AI and Tabular Data](https://www.kdnuggets.com/2022/09/datacentric-ai-tabular-data.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据驱动的人工智能与表格数据](https://www.kdnuggets.com/2022/09/datacentric-ai-tabular-data.html)'
- en: '[4 Ways to Generate Passive Income Using ChatGPT](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 ChatGPT 生成被动收入的 4 种方法](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
- en: '[Generate Music From Text Using Google MusicLM](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Google MusicLM 从文本生成音乐](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
- en: '[3 Ways to Generate Hyper-Realistic Faces Using Stable Diffusion](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3 种使用稳定扩散生成超真实面孔的方法](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
- en: '[Combining Data Management and Data Storytelling to Generate Value](https://www.kdnuggets.com/combining-data-management-and-data-storytelling-to-generate-value)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将数据管理与数据讲述结合生成价值](https://www.kdnuggets.com/combining-data-management-and-data-storytelling-to-generate-value)'
