- en: A Tour of End-to-End Machine Learning Platforms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全面了解端到端机器学习平台
- en: 原文：[https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html](https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html](https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Ian Hellström](https://databaseline.tech/), Machine Learning Engineer**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[伊恩·赫尔斯特](https://databaseline.tech/)，机器学习工程师**'
- en: Machine Learning (ML) is known as [the high-interest credit card of technical
    debt](https://research.google/pubs/pub43146/). It is relatively easy to get started
    with a model that is good enough for a particular business problem, but to make
    that model work in a production environment that scales and can deal with messy,
    changing data semantics and relationships, and evolving schemas in an automated
    and reliable fashion, that is another matter altogether. If you’re interested
    in learning more about a few well-known ML platforms, you’ve come to the right
    place!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）被称为[技术债务的高利息信用卡](https://research.google/pubs/pub43146/)。启动一个对特定业务问题足够好的模型相对容易，但要让该模型在生产环境中高效运行，并能够处理混乱、变化的数据语义和关系以及不断发展的模式，那是完全不同的事。如果你有兴趣了解一些知名的机器学习平台，你来对地方了！
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: As little as 5% of the actual code for machine learning production systems is
    the model itself. What turns a collection of machine learning solutions into an
    end-to-end machine learning platform is an architecture that embraces technologies
    designed to speed up modelling, automate the deployment, and ensure scalability
    and reliability in production. I talked about [lean D/MLOps](https://databaseline.tech/lean-dml-operations/),
    data and machine learning operations, before, because machine learning operations
    without data is pointless, so an end-to-end machine learning platform needs a
    holistic approach.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 实际机器学习生产系统中只有 5% 的代码是模型本身。将一系列机器学习解决方案转变为端到端机器学习平台的关键在于一种架构，这种架构拥抱旨在加速建模、自动化部署并确保生产中的可扩展性和可靠性的技术。我之前讨论过[精益
    D/MLOps](https://databaseline.tech/lean-dml-operations/)，数据和机器学习操作，因为没有数据的机器学习操作是毫无意义的，因此端到端机器学习平台需要一种全面的方法。
- en: 'The CI/CD Foundation launched an [MLOps Special Interest Group (SIG)](https://cd.foundation/blog/2020/02/11/announcing-the-cd-foundation-mlops-sig/).
    The steps they have identified for an end-to-end machine learning platform are
    shown in the next image:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD 基础推出了一个[MLOps 特别兴趣小组（SIG）](https://cd.foundation/blog/2020/02/11/announcing-the-cd-foundation-mlops-sig/)。他们为端到端机器学习平台确定的步骤在下一张图片中展示：
- en: '[![CI/CD Foundation MLOps](../Images/7aa2ad97dc6bb2a1e398566a2c13e7b1.png)](https://databaseline.tech/images/2020-02-21-ml-cicd-mlops-sig.png)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[![CI/CD 基础 MLOps](../Images/7aa2ad97dc6bb2a1e398566a2c13e7b1.png)](https://databaseline.tech/images/2020-02-21-ml-cicd-mlops-sig.png)'
- en: 'It camouflages a few not-quite-insignificant details, though. For instance,
    serving may require different technologies depending on whether it’s done in real-time
    or not. Scalable solutions typically have the model inside a container that runs
    on many machines in a serving cluster that’s behind a load balancer. So, a single
    box in the aforementioned diagram does not imply a single step, container, or
    component of an actual platform. That’s not a critique of the picture, but a warning:
    what looks simple may not be quite as easy in practice yet.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 它掩盖了一些不那么微不足道的细节。例如，服务可能需要不同的技术，取决于是否实时进行。可扩展的解决方案通常将模型放在一个容器内，该容器在许多机器上运行，并且处于一个负载均衡器后的服务集群中。因此，前面提到的单个框并不意味着实际平台的单个步骤、容器或组件。这不是对图片的批评，而是警告：看起来简单的事情在实践中可能并非如此。
- en: Model (configuration) management is absent from the chart. You can think of
    things such as versioning, experiment management, run-time statistics, data lineage
    tracking for training, test, and validation data sets, the capability to retrain
    a model, either from scratch or incrementally from, say, a snapshot of the model,
    hyperparameter values, accuracy metrics, and so on.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中缺少模型（配置）管理。你可以考虑版本控制、实验管理、运行时统计信息、训练、测试和验证数据集的数据追踪、重新训练模型的能力（无论是从头开始还是从模型的快照增量更新）、超参数值、准确度指标等。
- en: A crucial aspect that is not listed either is the ability to check the model
    for bias by, for example, slicing the model’s key performance metrics by different
    dimensions. Many companies need the ability to hot-swap a model or run multiple
    in parallel, too. The former is important lest a user’s request go into the void
    as it hits the server while the model is updated in the background. And the latter
    is crucial for A/B testing or model validation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个未列出的关键方面是能够检查模型的偏差，例如，通过不同维度切分模型的关键性能指标。许多公司还需要能够热交换模型或并行运行多个模型。前者很重要，以免在模型在后台更新时用户的请求消失在服务器上。而后者对于A/B测试或模型验证至关重要。
- en: Another perspective from CI/CD is available [here](https://martinfowler.com/articles/cd4ml.html).
    It mentions the need for versioning data as well as code, which is often overlooked.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 从CI/CD的另一个视角可以[这里](https://martinfowler.com/articles/cd4ml.html)获取。它提到了对数据和代码进行版本控制的必要性，但这常常被忽视。
- en: 'Google: TFX'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Google: TFX'
- en: The main motivation behind Google’s development of [TensorFlow eXtended (TFX)](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/(https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform)) was
    to reduce the time to productionize a machine learning model from months to weeks.
    Their engineers and scientists struggled because ‘the actual workflow becomes
    more complex when machine learning needs to be deployed in production.’
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌开发**[TensorFlow eXtended (TFX)](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/(https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform))**的主要动机是将机器学习模型的生产化时间从几个月缩短到几周。他们的工程师和科学家们面临挑战，因为“当机器学习需要在生产环境中部署时，实际工作流程变得更加复杂。”
- en: '[![TensorFlow eXtended (TFX)](../Images/384435a75222fc795560a084c10898e8.png)](https://databaseline.tech/images/2020-02-21-ml-tfx.png)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[![TensorFlow eXtended (TFX)](../Images/384435a75222fc795560a084c10898e8.png)](https://databaseline.tech/images/2020-02-21-ml-tfx.png)'
- en: TensorFlow and [TFX](https://www.tensorflow.org/tfx/) are available freely,
    although the latter is not as mature as the former, having been released only
    in 2019, two years after Google presented their ML infrastructure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 和 [TFX](https://www.tensorflow.org/tfx/) 免费提供，尽管后者不如前者成熟，因为它于2019年发布，比谷歌展示其机器学习基础设施晚了两年。
- en: Model performance metrics are used to deploy safe-to-serve models. So, if a
    newer model does not perform as well as an existing one, it is not pushed to production.
    In TFX parlance, the model does not receive a ‘blessing’. With TFX that whole
    process is automatic.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能指标用于部署安全可服务的模型。因此，如果较新的模型表现不如现有模型，它不会被推送到生产中。在TFX术语中，模型不会获得“祝福”。在TFX中，这整个过程是自动化的。
- en: 'Here is a quick overview of open-source TFX components:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是开源TFX组件的快速概览：
- en: '[ExampleGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/examplegen.md) ingests
    and splits the input dataset.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ExampleGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/examplegen.md)
    处理并拆分输入数据集。'
- en: '[StatisticsGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/statsgen.md) calculates
    statistics for the dataset.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[StatisticsGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/statsgen.md)
    计算数据集的统计信息。'
- en: '[SchemaGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/schemagen.md) examines
    the statistics and creates a data schema.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SchemaGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/schemagen.md)
    检查统计数据并创建数据模式。'
- en: '[ExampleValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/exampleval.md) looks
    for anomalies and missing values in the dataset.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ExampleValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/exampleval.md)
    查找数据集中的异常和缺失值。'
- en: '[Transform](https://github.com/tensorflow/tfx/blob/master/docs/guide/transform.md) performs
    feature engineering on the dataset.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Transform](https://github.com/tensorflow/tfx/blob/master/docs/guide/transform.md)
    对数据集执行特征工程。'
- en: '[Trainer](https://github.com/tensorflow/tfx/blob/master/docs/guide/trainer.md) trains
    the model using TensorFlow.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Trainer](https://github.com/tensorflow/tfx/blob/master/docs/guide/trainer.md)
    使用 TensorFlow 训练模型。'
- en: '[Evaluator](https://github.com/tensorflow/tfx/blob/master/docs/guide/evaluator.md) analyses
    the training results.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Evaluator](https://github.com/tensorflow/tfx/blob/master/docs/guide/evaluator.md)
    分析训练结果。'
- en: '[ModelValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/modelval.md) ensures
    that the model is safe to serve.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ModelValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/modelval.md)
    确保模型可以安全提供服务。'
- en: '[Pusher](https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md) deploys
    the model to a serving infrastructure.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pusher](https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md)
    将模型部署到服务基础设施。'
- en: '[TensorFlow Serving](https://www.tensorflow.org/serving) is a C++ backend that
    serves a TensorFlow [SavedModel](https://www.tensorflow.org/guide/saved_model#save_and_restore_models) file.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow Serving](https://www.tensorflow.org/serving) 是一个 C++ 后端，用于提供 TensorFlow
    [SavedModel](https://www.tensorflow.org/guide/saved_model#save_and_restore_models)
    文件。'
- en: To minimize training/serving skew, TensorFlow Transform ‘freezes’ values in
    the computation graph, so that the same values found during training are used
    when serving. What may be several operations in the DAG when training will be
    a single fixed value at serving time.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化训练/服务偏差，TensorFlow Transform 在计算图中“冻结”值，以便在服务时使用训练期间找到的相同值。在训练时可能是 DAG
    中的多个操作，在服务时将是单一的固定值。
- en: 'Uber: Michelangelo'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Uber: Michelangelo'
- en: Around 2015, Uber’s ML engineers noticed the [hidden technical debt in machine
    learning systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems),
    or the ML equivalent of ‘But it works on my machine…’ Uber had built custom, one-off
    systems that integrated with ML models, which was not very scalable in a large
    engineering organization. [In their own words](https://eng.uber.com/michelangelo/),
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在 2015 年，Uber 的 ML 工程师注意到 [机器学习系统中的隐性技术债务](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems)，即“但它在我的机器上能工作……”的
    ML 等效。Uber 曾构建了自定义的单次系统，这在大型工程组织中并不是很具扩展性。[用他们自己的话说](https://eng.uber.com/michelangelo/)，
- en: there were no systems in place to build reliable, uniform, and reproducible
    pipelines for creating and managing training and prediction data at scale.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当时没有系统来构建可靠、一致和可重复的管道，以大规模创建和管理训练及预测数据。
- en: That’s why they built Michelangelo. It relies on Uber’s data lake of transactional
    and logged data, and it supports both offline (batch) and online (streaming) predictions.
    For offline predictions containerized Spark jobs generate batch predictions, whereas
    for online deployments the model is served in a prediction service cluster, which
    typically consists of hundreds of machines behind a load balancer, to which clients
    send individual or batched prediction requests as RPCs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么他们构建了 Michelangelo。它依赖于 Uber 的事务和日志数据湖，并支持离线（批处理）和在线（流式）预测。对于离线预测，容器化的
    Spark 作业生成批处理预测，而对于在线部署，模型在一个预测服务集群中提供，该集群通常由负载均衡器后面的数百台机器组成，客户端将单个或批量预测请求作为 RPC
    发送。
- en: Metadata relevant to model management (e.g. run-time statistics of the trainer,
    model configuration, lineage, distribution and relative importance of features,
    model evaluation metrics, standard evaluation charts, learned parameter values,
    and summary statistics) are stored for each experiment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与模型管理相关的元数据（例如，训练器的运行时统计数据、模型配置、血统、特征的分布和相对重要性、模型评估指标、标准评估图表、学习的参数值以及总结统计数据）会为每个实验存储。
- en: Michelangelo can deploy multiple models in the same serving container, which
    allows for safe transitions from old to new model versions and side-by-side A/B
    testing of models.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Michelangelo 可以在同一个服务容器中部署多个模型，这允许在旧模型版本到新模型版本之间安全过渡，并进行模型的并行 A/B 测试。
- en: '[![Uber''s Michelangelo: online vs offline](../Images/dc66920d446d06b5a08ba07f79c78628.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Uber的 Michelangelo: 在线与离线](../Images/dc66920d446d06b5a08ba07f79c78628.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v1.png)'
- en: The original incarnation of Michelangelo did not support deep learning’s need
    to train on GPUs, but that the team addressed that omission in the meantime. The [current
    platform](https://eng.uber.com/michelangelo-model-representation/) uses Spark’s
    ML pipeline serialization but with an additional interface for online serving
    that adds a single-example (online) scoring method that is both lightweight and
    capable of handling tight SLAs, for instance, for fraud detection and prevention.
    It does so by bypassing the overhead of Spark SQL’s Catalyst optimizer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Michelangelo 的最初版本不支持深度学习在 GPU 上的训练需求，但团队在此期间解决了这个遗漏。当前平台([current platform](https://eng.uber.com/michelangelo-model-representation/))
    使用了 Spark 的 ML 管道序列化，但增加了一个用于在线服务的额外接口，添加了一个单例（在线）评分方法，该方法既轻量级又能够处理紧密的服务水平协议，例如，用于欺诈检测和预防。它通过绕过
    Spark SQL 的 Catalyst 优化器的开销来实现。
- en: '[![Uber''s Michelangelo: training vs serving](../Images/f5d95859749ca800973a084799abdbaf.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v2.png)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Uber的 Michelangelo: 训练与服务](../Images/f5d95859749ca800973a084799abdbaf.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v2.png)'
- en: Noteworthy is that both Google and Uber built in-house protocol buffer parsers
    and representations for serving, avoiding bottlenecks present in the default implementation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Google 和 Uber 都为服务构建了内部的协议缓冲解析器和表示，从而避免了默认实现中的瓶颈。
- en: 'Airbnb: Bighead'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Airbnb: Bighead'
- en: 'Airbnb established their own ML infrastructure team in 2016/2017 for similar
    reasons. First, they only had a few models in production, but building each model
    could take up to three months. Second, there was no consistency among models.
    And third, there were large differences between online and offline predictions. [Bighead](https://www.slideshare.net/databricks/bighead-airbnbs-endtoend-machine-learning-platform-with-krishna-puttaswamy-and-andrew-hoh) is
    the culmination of their efforts:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Airbnb 在2016/2017年成立了自己的机器学习基础设施团队，原因类似。首先，他们当时生产中的模型很少，但每个模型的构建可能需要长达三个月。其次，各模型之间没有一致性。第三，在线预测和离线预测之间存在较大差异。[Bighead](https://www.slideshare.net/databricks/bighead-airbnbs-endtoend-machine-learning-platform-with-krishna-puttaswamy-and-andrew-hoh)是他们努力的结晶：
- en: '[![Airbnb''s Bighead](../Images/7ab8003ae8a7ebcfe1ca27697597d3ae.png)](https://databaseline.tech/images/2020-02-21-ml-bighead.png)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Airbnb的 Bighead](../Images/7ab8003ae8a7ebcfe1ca27697597d3ae.png)](https://databaseline.tech/images/2020-02-21-ml-bighead.png)'
- en: Data management is handled by the in-house tool Zipline. Redspot is a hosted,
    containerized, multi-tenant Jupyter notebook service. The Bighead library is for
    data transformations and pipeline abstractions, and it holds wrappers for common
    model frameworks. It preserves metadata through transformations, so it is used
    to track lineage.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管理由内部工具 Zipline 处理。Redspot 是一个托管的、容器化的、多租户 Jupyter notebook 服务。Bighead 库用于数据转换和管道抽象，并持有常见模型框架的封装器。它通过转换保留元数据，因此用于跟踪数据血统。
- en: Deep Thought is a REST API for online predictions. Kubernetes orchestrates the
    services. For offline predictions, Airbnb use their own Automator.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Deep Thought 是一个用于在线预测的 REST API。Kubernetes 协调这些服务。对于离线预测，Airbnb 使用他们自己的 Automator。
- en: 'Netflix: Metaflow'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Netflix: Metaflow'
- en: Netflix faced, rather unsurprisingly, similar issues as the aforementioned companies.
    Their solution was [Metaflow](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9),
    a Python library for data scientists that deals with [data management and model
    training, and not so much prediction serving](https://blog.valohai.com/three-ways-to-categorize-machine-learning-platforms).
    As such it is *not* an end-to-end platform for machine learning, and perhaps more
    geared towards company-internal instead of user-facing use cases. It can of course
    be turned into a fully-fledged solution with [Seldon](https://www.seldon.io/),
    which is backed by Kubernetes, or [AWS SageMaker](https://aws.amazon.com/sagemaker/).
    A list of further serving tools is available [here](https://github.com/EthicalML/awesome-production-machine-learning#model-deployment-and-orchestration-frameworks).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix遇到了与上述公司类似的问题，这并不令人惊讶。他们的解决方案是[Metaflow](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9)，这是一个针对数据科学家的Python库，处理[数据管理和模型训练，而不是预测服务](https://blog.valohai.com/three-ways-to-categorize-machine-learning-platforms)。因此，它*不是*一个端到端的机器学习平台，也许更适合公司内部使用，而不是面向用户的使用场景。当然，它可以通过[Seldon](https://www.seldon.io/)（由Kubernetes支持）或[AWS
    SageMaker](https://aws.amazon.com/sagemaker/)转变为一个成熟的解决方案。进一步的服务工具列表可以在[这里](https://github.com/EthicalML/awesome-production-machine-learning#model-deployment-and-orchestration-frameworks)找到。
- en: '[![Netflix'' Metaflow](../Images/596f35c7ad288860e2252c986a5fa308.png)](https://databaseline.tech/images/2020-02-21-ml-metaflow.png)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Netflix的Metaflow](../Images/596f35c7ad288860e2252c986a5fa308.png)](https://databaseline.tech/images/2020-02-21-ml-metaflow.png)'
- en: Data scientists write their workflow as DAG steps, much like data engineers
    when they use Airflow. And like Airflow, you can use any data science library
    because to Metaflow it’s only Python code that’s executed. Metaflow distributes
    processing and training in the background. All code and data is automatically
    snapshotted to S3 to ensure there is a version history of each model and experiment.
    Pickle is the default model serialization format.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家将他们的工作流程编写为DAG步骤，这与数据工程师在使用Airflow时的做法类似。像Airflow一样，你可以使用任何数据科学库，因为对Metaflow来说，只有执行的Python代码。Metaflow在后台分发处理和训练。所有代码和数据都会自动快照到S3，以确保每个模型和实验都有版本历史。Pickle是默认的模型序列化格式。
- en: The [open-source edition](https://docs.metaflow.org/) does not yet have a built-in [scheduler](https://docs.metaflow.org/introduction/what-is-metaflow).
    It also encourages users to ‘primarily rely on vertical scalability’, although
    they can use AWS SageMaker for horizontal scalability. It is tightly coupled to
    AWS.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[开源版本](https://docs.metaflow.org/)尚未内置[scheduler](https://docs.metaflow.org/introduction/what-is-metaflow)。它还鼓励用户“主要依赖垂直扩展”，尽管他们可以使用AWS
    SageMaker进行水平扩展。它与AWS紧密耦合。'
- en: 'Lyft: Flyte'
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Lyft: Flyte'
- en: 'Lyft have open-sourced their cloud-native platform called [Flyte](https://flyte.org/),
    where data and machine learning operations [converge](https://static.sched.com/hosted_files/kccncna19/7f/Flyte%20Kubecon.pdf).
    This is in line with my [D/MLOps philosophy](https://databaseline.tech/lean-dml-operations/)—Data(Ops)
    is to MLOps as fuel is to a rocket: without it, ain’t nothin’ happenin’.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Lyft开源了他们的云原生平台[Flyte](https://flyte.org/)，在这里数据和机器学习操作[融合](https://static.sched.com/hosted_files/kccncna19/7f/Flyte%20Kubecon.pdf)。这与我的[D/MLOps理念](https://databaseline.tech/lean-dml-operations/)一致——数据(Ops)对MLOps就像燃料对火箭一样：没有它，什么也不会发生。
- en: It is built on top of Kubernetes. Since it is used internally by Lyft, it scales
    to at least 7,000 unique workflows with over 100,000 executions every month, 1
    million tasks, and 10 million containers.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 它建立在Kubernetes之上。由于内部由Lyft使用，它能够扩展到至少7000个独特的工作流程，每月超过10万次执行，100万个任务和1000万个容器。
- en: All entities in Flyte are immutable, so it is possible to track data lineage,
    reproduce of experiments, and roll back deployments. Repeated tasks can leverage
    the task cache to save time and money. Currently supported tasks include [Python,
    Hive, Presto, and Spark](https://lyft.github.io/flyte/user/tasktypes/index.html) as
    well as [sidecars](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/).
    From looking at the source code it seems EKS is
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Flyte中的所有实体都是不可变的，因此可以跟踪数据血缘、重现实验和回滚部署。重复任务可以利用任务缓存来节省时间和金钱。目前支持的任务包括[Python、Hive、Presto和Spark](https://lyft.github.io/flyte/user/tasktypes/index.html)以及[sidecars](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)。从源代码来看，似乎EKS是
- en: '[![Lyft''s Flyte](../Images/1c7dd71ceb912bc09c0e0ef0565b8d13.png)](https://databaseline.tech/images/2020-02-21-ml-flyte.png)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Lyft的Flyte](../Images/1c7dd71ceb912bc09c0e0ef0565b8d13.png)](https://databaseline.tech/images/2020-02-21-ml-flyte.png)'
- en: Theirs is also [Amundsen](https://github.com/lyft/amundsen), a data catalogue
    that is not unlike Spotify’s [Lexikon](https://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还有一个[Amundsen](https://github.com/lyft/amundsen)，这是一个类似于Spotify的[Lexikon](https://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/)的数据目录。
- en: AWS, Azure, GCP, and Co.
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS、Azure、GCP等。
- en: All major players in the [public cloud](https://cloud.google.com/gartner-cloud-infrastructure-as-a-service/) space
    have their own offerings for machine learning platforms, save for Oracle who only
    offer [canned ML-based models](https://www.oracle.com/artificial-intelligence/products.html) for
    certain use cases and industries.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Oracle仅为某些用例和行业提供[预制的基于ML的模型](https://www.oracle.com/artificial-intelligence/products.html)外，所有主要的[公共云](https://cloud.google.com/gartner-cloud-infrastructure-as-a-service/)提供商都有自己的机器学习平台解决方案。
- en: '**AWS [SageMaker](https://aws.amazon.com/sagemaker/)** is a full-stack solution
    for machine learning that supports TensorFlow, Keras, PyTorch, and MXNet. With [SageMaker
    Neo](https://aws.amazon.com/sagemaker/neo/) it’s possible to deploy models both
    in the cloud and on the edge. It has a built-in feature for labelling through
    Amazon Mechanical Turk for data stored in S3.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS [SageMaker](https://aws.amazon.com/sagemaker/)** 是一个支持TensorFlow、Keras、PyTorch和MXNet的完整机器学习解决方案。通过[SageMaker
    Neo](https://aws.amazon.com/sagemaker/neo/)可以将模型同时部署到云端和边缘。它内置了通过Amazon Mechanical
    Turk进行标注的功能，适用于存储在S3中的数据。'
- en: '[![AWS SageMaker](../Images/b1311ad9d1502bf934a5199251ab3728.png)](https://databaseline.tech/images/2020-02-21-ml-sagemaker.png)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[![AWS SageMaker](../Images/b1311ad9d1502bf934a5199251ab3728.png)](https://databaseline.tech/images/2020-02-21-ml-sagemaker.png)'
- en: Google does not have a managed platform, but with [TFX, Kubeflow, and **AI Platform**](https://cloud.google.com/ai-platform/) it’s
    possible to stitch together all the components needed to run models on CPUs, GPUs
    and TPUs, tune hyperparameters, and automatically deploy to production. [Spotify](https://labs.spotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/) has
    even opted for the TFX/Kubeflow-on-GCP option.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Google没有托管平台，但通过[TFX、Kubeflow和**AI Platform**](https://cloud.google.com/ai-platform/)可以将运行模型所需的所有组件整合在一起，支持在CPU、GPU和TPU上运行，调优超参数，并自动部署到生产环境。[Spotify](https://labs.spotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/)甚至选择了TFX/Kubeflow-on-GCP选项。
- en: Beyond TensorFlow, there is support for [scikit-learn and XGBoost](https://cloud.google.com/ai-platform/training/docs?hl=en).
    Custom containers allow you to use any framework, such as [PyTorch](https://cloud.google.com/ai-platform/training/docs/custom-containers-training?hl=en).
    A [labelling service](https://cloud.google.com/ai-platform/data-labeling/docs/) à
    la SageMaker Ground Truth is at the moment in beta.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了TensorFlow，支持的还有[scikit-learn和XGBoost](https://cloud.google.com/ai-platform/training/docs?hl=en)。自定义容器允许你使用任何框架，如[PyTorch](https://cloud.google.com/ai-platform/training/docs/custom-containers-training?hl=en)。目前还有一个类似SageMaker
    Ground Truth的[标注服务](https://cloud.google.com/ai-platform/data-labeling/docs/)在测试阶段。
- en: '[![GCP AI Platform](../Images/93293af80aba9458cd660633ed54da87.png)](https://databaseline.tech/images/2020-02-21-ml-gcp.svg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![GCP AI Platform](../Images/93293af80aba9458cd660633ed54da87.png)](https://databaseline.tech/images/2020-02-21-ml-gcp.svg)'
- en: '**[Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/)** supports
    a fair number of [frameworks](https://azure.microsoft.com/en-us/services/machine-learning/#product-overview),
    such as scikit-learn, Keras, PyTorch, XGBoost, TensorFlow, and MXNet. It has its
    own [D/MLOps](https://azure.microsoft.com/en-us/services/machine-learning/mlops/#key-phases) suite
    with plenty of graphs. A drag-and-drop interface for model development is available
    to those who prefer it, but that comes with various [caveats](https://databaseline.tech/the-problems-with-visual-programming-languages-in-data-engineering/).
    Model and experiment management is done, as expected from Microsoft, with a registry.
    For production deployments, the [Azure Kubernetes Service](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-and-where#deploy-to-target) is
    used. Controlled roll-outs are [possible](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-azure-kubernetes-service#deploy-models-to-aks-using-controlled-rollout-preview) too.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Azure 机器学习](https://azure.microsoft.com/en-us/services/machine-learning/)**支持相当多的[框架](https://azure.microsoft.com/en-us/services/machine-learning/#product-overview)，例如
    scikit-learn、Keras、PyTorch、XGBoost、TensorFlow 和 MXNet。它拥有自己的[D/MLOps](https://azure.microsoft.com/en-us/services/machine-learning/mlops/#key-phases)套件，包含大量图表。对于那些喜欢拖放界面的模型开发者，该平台也提供了这样的功能，但这带有各种[caveats](https://databaseline.tech/the-problems-with-visual-programming-languages-in-data-engineering/)。模型和实验管理，如微软所期望的那样，是通过注册表来完成的。对于生产部署，使用了[Azure
    Kubernetes Service](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-and-where#deploy-to-target)。受控推出也是[possible](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-azure-kubernetes-service#deploy-models-to-aks-using-controlled-rollout-preview)的。'
- en: '**[IBM Watson ML](https://www.ibm.com/cloud/machine-learning)** comes with
    both point-and-click machine learning options (SPSS) and support for a bunch of
    common [frameworks](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html).
    As the other major players, models are trained on either CPUs or GPUs. [Hyperparameter
    tuning](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml_dlaas_hpo.html?linkInPage=true) is
    included in the box too. The platform does not have many details on data and model
    validation, as these are available in other IBM products.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**[IBM Watson ML](https://www.ibm.com/cloud/machine-learning)** 提供了点击式机器学习选项（SPSS）以及对一系列常见[框架](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html)的支持。与其他主要玩家一样，模型可以在
    CPU 或 GPU 上训练。[超参数调整](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml_dlaas_hpo.html?linkInPage=true)也包含在内。该平台在数据和模型验证方面没有很多细节，因为这些在其他
    IBM 产品中可以找到。'
- en: Although **Alibaba’s [ML Platform for AI](https://www.alibabacloud.com/product/machine-learning)** flaunts
    two buzzwords in one name, it does not improve the documentation; the section
    on [best practices](https://www.alibabacloud.com/help/doc-detail/67395.htm?spm=a2c63.p38356.b99.39.62bb4809Vl31Cw) has
    use cases rather than recommendations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管**Alibaba 的 [ML Platform for AI](https://www.alibabacloud.com/product/machine-learning)**
    名字中有两个流行词，但并没有改进文档；[最佳实践](https://www.alibabacloud.com/help/doc-detail/67395.htm?spm=a2c63.p38356.b99.39.62bb4809Vl31Cw)部分更多是用例而非推荐。
- en: Anyway, it is heavy on [dragging and dropping](https://www.alibabacloud.com/help/doc-detail/126312.htm),
    especially in data management and modelling, which may not be very conducive to
    an automated end-to-end ML platform. The platform supports frameworks such as [TensorFlow,
    MXNet, and Caffe](https://www.alibabacloud.com/help/doc-detail/75093.htm), but
    it also sports a plethora of [traditional algorithms](https://www.alibabacloud.com/help/doc-detail/69688.htm).
    It includes a hyperparameter tuner, as can be expected.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，它对[拖放操作](https://www.alibabacloud.com/help/doc-detail/126312.htm)要求较高，尤其是在数据管理和建模方面，这可能不利于一个自动化的端到端机器学习平台。该平台支持诸如[TensorFlow,
    MXNet 和 Caffe](https://www.alibabacloud.com/help/doc-detail/75093.htm)等框架，同时也拥有大量[传统算法](https://www.alibabacloud.com/help/doc-detail/69688.htm)。它包括一个超参数调整器，这是可以预期的。
- en: Model serialization is done with [PMML, TensorFlow’s SavedModel format, or Caffe’s
    format](https://www.alibabacloud.com/help/doc-detail/126313.htm). Please note
    that a scoring engine that takes a [PMML, ONNX](https://medium.com/analytics-and-data/overview-of-the-different-approaches-to-putting-machinelearning-ml-models-in-production-c699b34abf86),
    or [PFA file](http://dmg.org/pfa/) may enable quick deployments, but it risks
    introducing training/serving skew, since the served model is loaded from a different
    format.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 模型序列化使用 [PMML、TensorFlow 的 SavedModel 格式或 Caffe 格式](https://www.alibabacloud.com/help/doc-detail/126313.htm)。请注意，使用接受 [PMML、ONNX](https://medium.com/analytics-and-data/overview-of-the-different-approaches-to-putting-machinelearning-ml-models-in-production-c699b34abf86)
    或 [PFA 文件](http://dmg.org/pfa/)的评分引擎可能会实现快速部署，但这有可能引入训练/服务偏差，因为服务的模型是从不同的格式加载的。
- en: Honourable Mention
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 荣誉提名
- en: '**[H2O](https://www.h2o.ai/products/h2o/#overview)** offers a platform with
    data manipulation, various algorithms, cross-validation, grid search for hyperparameter
    tuning, feature ranking, and model serialization with [POJO or MOJO](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html#about-pojo-mojo).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**[H2O](https://www.h2o.ai/products/h2o/#overview)** 提供了一个包含数据操作、各种算法、交叉验证、超参数调优网格搜索、特征排名和模型序列化（使用 [POJO
    或 MOJO](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html#about-pojo-mojo)）的平台。'
- en: '[![H2O.ai](../Images/e40354fba75e394968b47280930201b3.png)](https://databaseline.tech/images/2020-02-21-ml-h2o.png)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[![H2O.ai](../Images/e40354fba75e394968b47280930201b3.png)](https://databaseline.tech/images/2020-02-21-ml-h2o.png)'
- en: '**[Valohai](https://valohai.com/product/)**—Finnish for light shark. Really!—
    is a managed machine learning platform. It can run on private, public, hybrid,
    or multi-cloud setups.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Valohai](https://valohai.com/product/)**—芬兰语中的“光明的鲨鱼”，真的！—是一个托管的机器学习平台。它可以运行在私有、公有、混合或多云设置中。'
- en: '[![Valohai](../Images/1a813d3633a3373e19b7e920386b3a65.png)](https://databaseline.tech/images/2020-02-21-ml-valohai.png)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Valohai](../Images/1a813d3633a3373e19b7e920386b3a65.png)](https://databaseline.tech/images/2020-02-21-ml-valohai.png)'
- en: Each operation (or [execution](https://docs.valohai.com/core-concepts/executions/))
    runs a command against a Docker image, so it’s very similar to [Kubeflow](https://www.kubeflow.org/).
    The main difference is that Valohai manages the Kubernetes deployment cluster
    for you, whereas Kubeflow requires you to do that. However, Kubeflow and TFX are
    opinionated in that they provide some TensorFlow-related tools out of the box.
    With Valohai you’re expected to re-use existing Docker images or roll your own,
    which means you can use any machine learning framework, but that freedom has to
    be weighed against maintainability concerns.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 每个操作（或 [执行](https://docs.valohai.com/core-concepts/executions/)）运行一个命令来处理 Docker
    镜像，因此它与 [Kubeflow](https://www.kubeflow.org/) 非常相似。主要的区别是 Valohai 为你管理 Kubernetes
    部署集群，而 Kubeflow 需要你自己管理。然而，Kubeflow 和 TFX 具有一定的偏好，它们提供了一些开箱即用的 TensorFlow 相关工具。使用
    Valohai，你需要重用现有的 Docker 镜像或自己创建，这意味着你可以使用任何机器学习框架，但这种自由必须与可维护性问题进行权衡。
- en: It is therefore possible to distribute training by relying on [Spark](https://spark.apache.org/docs/latest/ml-guide.html), [Horovod](https://eng.uber.com/horovod/), [TensorFlow](https://www.tensorflow.org/guide/distributed_training),
    or whatever suits your needs and infrastructure best, but it’s in your hands to
    fill in the blanks. It also means you’re responsible for ensuring compatibility
    in data transformations to avoid training/serving skew. Note that it currently
    only supports [object storages](https://docs.valohai.com/core-concepts/data-stores/).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过依赖 [Spark](https://spark.apache.org/docs/latest/ml-guide.html)、 [Horovod](https://eng.uber.com/horovod/)、 [TensorFlow](https://www.tensorflow.org/guide/distributed_training)
    或任何适合你需求和基础设施的工具，进行训练分布是可能的，但你需要填补空白。这也意味着你负责确保数据转换的兼容性，以避免训练/服务偏差。请注意，它目前只支持 [对象存储](https://docs.valohai.com/core-concepts/data-stores/)。
- en: '**[Iguazio](https://www.iguazio.com/platform/)** mentions the capability to [deploy
    in seconds from a notebook or IDE](https://www.iguazio.com/platform/), although
    that seems to miss the most common scenario: a CI/CD pipeline or even the platform
    itself as with TFX’s [Pusher](https://www.tensorflow.org/tfx/guide/pusher) component.
    It uses Kubeflow for workflow orchestration.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Iguazio](https://www.iguazio.com/platform/)** 提到能够 [从笔记本或 IDE 中秒级部署](https://www.iguazio.com/platform/)，但这似乎忽略了最常见的场景：CI/CD
    管道，甚至是平台本身，例如 TFX 的 [Pusher](https://www.tensorflow.org/tfx/guide/pusher) 组件。它使用
    Kubeflow 进行工作流编排。'
- en: '[![Iguazio](../Images/77a3e52aa3681a5ce0a14d3a1ac05315.png)](https://databaseline.tech/images/2020-02-21-ml-iguazio.png)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Iguazio](../Images/77a3e52aa3681a5ce0a14d3a1ac05315.png)](https://databaseline.tech/images/2020-02-21-ml-iguazio.png)'
- en: 'Iguazio does offer a feature store with unified APIs for key-value pairs and
    time series. Many available products do not come with their own features stores,
    although most large tech companies have these. A feature store is a central place
    with ready-to-reuse features that can be shared across models to accelerate model
    development. It can automate feature engineering on an enterprise scale. From
    a timestamp, for instance, you can extract many features: year, season, month,
    day of week, time of day, whether it’s a local holiday, elapsed time since last
    relevant event (recency), how often a certain event happened in a fixed window
    (frequency), and so on.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Iguazio确实提供了一个具有统一API的特征存储，用于键值对和时间序列。许多现有产品没有自己的特征存储，尽管大多数大型科技公司都有这样的存储。特征存储是一个集中式的地方，具有可重用的特征，可以在模型之间共享，以加速模型开发。它可以在企业规模上自动化特征工程。例如，从时间戳中，你可以提取许多特征：年份、季节、月份、星期几、一天中的时间、是否是当地假日、上一个相关事件后的经过时间（最近性）、在固定窗口内某事件发生的频率等等。
- en: '**[SwiftStack AI](https://www.swiftstack.com/solutions/ai)** is geared towards
    high-throughput deep learning on NVIDIA GPUs with the [RAPIDS](https://www.developer.nvidia.com/rapids) suite.
    RAPIDS offers libraries, such as [cuML](https://github.com/rapidsai/cuml), which
    allows people to use the familiar scikit-learn API but benefit from GPU acceleration
    for supported algorithms, and [cuGraph](https://github.com/rapidsai/cugraph) for
    GPU-powered graph analytics.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**[SwiftStack AI](https://www.swiftstack.com/solutions/ai)**旨在支持在NVIDIA GPUs上进行高吞吐量深度学习，使用[RAPIDS](https://www.developer.nvidia.com/rapids)套件。RAPIDS提供了库，如[cuML](https://github.com/rapidsai/cuml)，允许用户使用熟悉的scikit-learn
    API，但利用GPU加速支持的算法，以及[cuGraph](https://github.com/rapidsai/cugraph)用于GPU驱动的图分析。'
- en: '[![SwiftStack AI](../Images/d1e2f10cef9d510fbd15830b0cef3f06.png)](https://databaseline.tech/images/2020-02-21-ml-swiftstack.png)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[![SwiftStack AI](../Images/d1e2f10cef9d510fbd15830b0cef3f06.png)](https://databaseline.tech/images/2020-02-21-ml-swiftstack.png)'
- en: '**[AI Layer](https://algorithmia.com/serverless-ai-layer)** is an [API for
    D/MLOps](https://www.linkedin.com/pulse/ai-layer-diego-oppenheimer/). It has built-in
    support for multiple data sources, programming languages, and machine learning
    frameworks.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**[AI Layer](https://algorithmia.com/serverless-ai-layer)**是一个[D/MLOps的API](https://www.linkedin.com/pulse/ai-layer-diego-oppenheimer/)。它内置支持多种数据源、编程语言和机器学习框架。'
- en: '[![Algorithmia''s AI Layer](../Images/d043542d81bd1ef6ee760721a157c0ee.png)](https://databaseline.tech/images/2020-02-21-ml-ai-layer.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Algorithmia''s AI Layer](../Images/d043542d81bd1ef6ee760721a157c0ee.png)](https://databaseline.tech/images/2020-02-21-ml-ai-layer.jpg)'
- en: '**[MLflow](https://mlflow.org/)** is backed by Databricks, which explains the
    tight integration with Spark. It offers a [limited set of options for deployments](https://mlflow.org/docs/latest/models.html#built-in-deployment-tools).
    For example, the ability to export a model as a [vectorized UDF](https://spark.apache.org/docs/2.4.0/sql-pyspark-pandas-with-arrow.html) in
    PySpark is not the most sensible for real-time systems, since Python UDFs come
    with the communication overhead between the Python runtime environment and the
    JVM. The overhead is not as large as with standard PySpark UDFs because Apache
    Arrow, an in-memory columnar format, is used in the transfer between Python and
    the JVM, but it’s [not insignificant](https://medium.com/@QuantumBlack/spark-udf-deep-insights-in-performance-f0a95a4d8c62).
    With Spark Streaming as the default data ingestion solution, sub-second latency
    with Spark’s micro-batch model may be tricky to achieve anyway.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**[MLflow](https://mlflow.org/)**由Databricks支持，这解释了它与Spark的紧密集成。它提供了[有限的部署选项](https://mlflow.org/docs/latest/models.html#built-in-deployment-tools)。例如，将模型导出为[向量化UDF](https://spark.apache.org/docs/2.4.0/sql-pyspark-pandas-with-arrow.html)在PySpark中并不是最合适的实时系统选择，因为Python
    UDFs涉及Python运行时环境与JVM之间的通信开销。虽然这种开销比标准PySpark UDFs要小，因为在Python和JVM之间的传输中使用了Apache
    Arrow这一内存列式格式，但[开销仍然不小](https://medium.com/@QuantumBlack/spark-udf-deep-insights-in-performance-f0a95a4d8c62)。由于Spark
    Streaming作为默认的数据摄取解决方案，在Spark的微批处理模型下实现亚秒延迟可能仍然具有挑战性。'
- en: Support for logging, which is essential for D/MLOps, [is still experimental](https://mlflow.org/docs/latest/tracking.html#automatic-logging).
    From the documentation it follows that MLflow is not focused on data and model
    validation, at least not as a standard part of the platform itself. There is a
    managed version of MLflow available (on AWS and Azure) that offers [more features](https://databricks.com/product/managed-mlflow).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于日志记录的支持，这对D/MLOps至关重要，[仍在实验阶段](https://mlflow.org/docs/latest/tracking.html#automatic-logging)。根据文档，MLflow并不专注于数据和模型验证，至少不是平台自身的标准部分。MLflow有一个托管版本（在AWS和Azure上），提供[更多功能](https://databricks.com/product/managed-mlflow)。
- en: '**D2iQ’s [KUDO for Kubeflow](https://d2iq.com/solutions/ksphere/kudo-kubeflow)** is
    a Kubeflow-based platform geared towards enterprise customers. Unlike the open-source
    Kubeflow, it comes with Spark and [Horovod](https://github.com/horovod/horovod) as
    well as pre-built and fully tested CPU/GPU images for the major frameworks: TensorFlow,
    PyTorch, and MXNet. Data scientists can deploy form within notebooks without the
    need to switch contexts. By default it supports multi-tenancy. [Istio](https://istio.io/) and [Dex](https://github.com/dexidp/dex) are
    integrated for additional security and authentication. KUDO for Kubeflow sits
    atop Konvoy, D2iQ’s managed Kubernetes platform. It can run in the cloud, on-prem,
    a hybrid, or on the edge. Support for air-gapped clusters is also available.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**D2iQ的[KUDO for Kubeflow](https://d2iq.com/solutions/ksphere/kudo-kubeflow)**是一个面向企业客户的基于Kubeflow的平台。与开源的Kubeflow不同，它包含Spark和[Horovod](https://github.com/horovod/horovod)，以及针对主要框架（TensorFlow、PyTorch和MXNet）预构建和全面测试的CPU/GPU镜像。数据科学家可以在笔记本中进行部署，无需切换上下文。默认支持多租户。[Istio](https://istio.io/)和[Dex](https://github.com/dexidp/dex)集成以提供额外的安全性和认证。KUDO
    for Kubeflow建立在D2iQ的托管Kubernetes平台Konvoy之上。它可以在云中、本地、混合环境或边缘运行。还支持气隔集群。'
- en: In Kubernetes-speak, KUDO for Kubeflow is a collection of operators defined
    with [KUDO](https://kudo.dev/), a declarative toolkit to create Kubernetes operators
    using YAML instead of Go. Kubernetes Unified Declarative Operators (KUDOs) for
    Cassandra, Elastic, Flink, Kafka, Redis, and so on are all [open source](https://github.com/kudobuilder/operators) and
    can be integrated with the platform. More details are described in an [introductory
    article by yours truly](https://d2iq.com/blog/kudo-for-kubeflow-the-enterprise-machine-learning-platform).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes的术语中，Kubeflow的KUDO是一个由[KUDO](https://kudo.dev/)定义的操作符集合，KUDO是一个声明式工具包，用于使用YAML而非Go语言创建Kubernetes操作符。Kubernetes统一声明式操作符（KUDOs）对于Cassandra、Elastic、Flink、Kafka、Redis等都是[开源的](https://github.com/kudobuilder/operators)，并且可以与平台集成。更多细节请参阅[我个人的介绍文章](https://d2iq.com/blog/kudo-for-kubeflow-the-enterprise-machine-learning-platform)。
- en: If you want to see yet more options, including visual workbenches, have a look [here](https://heartbeat.fritz.ai/ai-and-machine-learning-landscape-part-4-end-to-end-ml-platforms-5adeac675d13) or
    check out [Gartner’s magic quadrant for data science and machine learning platforms](https://www.analyticsvidhya.com/blog/2020/02/gartners-2020-magic-quadrant-for-data-science-and-machine-learning-tools-check-out-the-new-leaders/).
    Facebook have also published details of their platform [FBLearner Flow](https://engineering.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/) (2016),
    as well as [LinkedIn](https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin) (2018)
    and [eBay](https://tech.ebayinc.com/engineering/ebays-transformation-to-a-modern-ai-platform/) (2019).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看更多选项，包括可视化工作台，请[点击这里](https://heartbeat.fritz.ai/ai-and-machine-learning-landscape-part-4-end-to-end-ml-platforms-5adeac675d13)或查看[Gartner的数据科学和机器学习平台魔力象限](https://www.analyticsvidhya.com/blog/2020/02/gartners-2020-magic-quadrant-for-data-science-and-machine-learning-tools-check-out-the-new-leaders/)。Facebook还发布了他们的平台[FBLearner
    Flow](https://engineering.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/)（2016年），以及[LinkedIn](https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin)（2018年）和[eBay](https://tech.ebayinc.com/engineering/ebays-transformation-to-a-modern-ai-platform/)（2019年）的相关细节。
- en: '**Bio: [Ian Hellström](https://databaseline.tech/)** has been a data and machine
    learning engineer at various companies, including D2iQ, Spotify, Bosch and Sievo.
    He is the product manager for D2iQ’s enterprise machine learning platform KUDO
    for Kubeflow. He currently resides in Hamburg, Germany.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Ian Hellström](https://databaseline.tech/)**曾在包括D2iQ、Spotify、Bosch和Sievo在内的多家公司担任数据和机器学习工程师。他是D2iQ企业机器学习平台KUDO
    for Kubeflow的产品经理。他目前居住在德国汉堡。'
- en: '[Original](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/). Reposted
    with permission.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/)。经允许转载。'
- en: '**Related:**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关信息：**'
- en: '[How to Extend Scikit-learn and Bring Sanity to Your Machine Learning Workflow](/2019/10/extend-scikit-learn-bring-sanity-machine-learning-workflow.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何扩展Scikit-learn并为你的机器学习工作流带来理智](/2019/10/extend-scikit-learn-bring-sanity-machine-learning-workflow.html)'
- en: '[A Layman’s Guide to Data Science. Part 3: Data Science Workflow](/2020/07/laymans-guide-data-science-workflow.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[外行人的数据科学指南。第3部分：数据科学工作流](/2020/07/laymans-guide-data-science-workflow.html)'
- en: '[Deploy a Machine Learning Pipeline to the Cloud Using a Docker Container](/2020/06/deploy-machine-learning-pipeline-cloud-docker.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Docker容器将机器学习管道部署到云端](/2020/06/deploy-machine-learning-pipeline-cloud-docker.html)'
- en: More On This Topic
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[7 End-to-End MLOps Platforms You Must Try in 2024](https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2024年你必须尝试的7个平台，支持端到端的MLOps](https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024)'
- en: '[A Beginner''s Guide to End to End Machine Learning](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[端到端机器学习的初学者指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
- en: '[A Full End-to-End Deployment of a Machine Learning Algorithm into a…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习算法的完整端到端部署到…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
- en: '[A Tour of Python NLP Libraries](https://www.kdnuggets.com/a-tour-of-python-nlp-libraries)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python NLP 库概览](https://www.kdnuggets.com/a-tour-of-python-nlp-libraries)'
- en: '[5 Best End-to-End Open Source MLOps Tools](https://www.kdnuggets.com/5-best-end-to-end-open-source-mlops-tools)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5款最佳的端到端开源MLOps工具](https://www.kdnuggets.com/5-best-end-to-end-open-source-mlops-tools)'
- en: '[A Simple to Implement End-to-End Project with HuggingFace](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用HuggingFace实现一个简单的端到端项目](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
