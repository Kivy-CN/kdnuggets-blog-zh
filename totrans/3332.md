# 电子邮件垃圾邮件过滤：使用 Python 和 Scikit-learn 的实现

> 原文：[https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html](https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html)

**由 [Machine Learning in Action](https://appliedmachinelearning.wordpress.com/).**

![垃圾邮件过滤器](../Images/b8a1b609f29a3b8d8f5000f853ad551f.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织 IT

* * *

文本挖掘（从文本中提取信息）是一个广泛的领域，随着生成的大量文本数据而变得流行。许多应用程序的自动化，如情感分析、文档分类、主题分类、文本摘要、机器翻译等，已经通过机器学习模型完成。

垃圾邮件过滤是文档分类任务的一个初学者示例，它涉及将电子邮件分类为垃圾邮件或非垃圾邮件（即正常邮件）。Gmail 账户中的垃圾邮件箱就是最好的例子。现在开始构建一个基于公开邮件语料库的垃圾邮件过滤器。我已经从 [Ling-spam 语料库](http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz) 中提取了相等数量的垃圾邮件和非垃圾邮件。我们将使用的提取子集可以从 [这里](https://www.dropbox.com/s/yjiplngoa430rid/) 下载。

我们将按照以下步骤构建这个应用程序：

1.  准备文本数据。

1.  创建词典。

1.  特征提取过程

1.  训练分类器

此外，我们将检查创建的子集上的测试集结果。

### 1\. 准备文本数据。

这里使用的数据集分为训练集和测试集，分别包含 702 封邮件和 260 封邮件，两者之间的垃圾邮件和正常邮件各占一半。您可以轻松识别垃圾邮件，因为其文件名中包含 *spmsg*。

在任何文本挖掘问题中，文本清洗是第一步，我们需要从文档中移除那些可能对我们提取的信息无帮助的词汇。电子邮件可能包含很多不必要的字符，如标点符号、停用词、数字等，这些都可能不利于检测垃圾邮件。Ling-spam 语料库中的电子邮件已经通过以下方式进行了预处理：

a) 停用词去除 – “and”、“the”、“of”等停用词在所有英语句子中非常常见，在决定垃圾邮件或合法状态时并不具有很大的意义，因此这些词已从邮件中删除。

b) 词形还原 – 这是将一个词的不同变形形式归并在一起的过程，以便将它们作为单个项目进行分析。例如，“include”、“includes”和“included”都将表示为“include”。与词干提取（文本挖掘中的另一个流行词，它不考虑句子的意义）相比，词形还原在保留句子上下文方面表现更好。

我们仍然需要从邮件文档中去除非单词，例如标点符号或特殊字符。有几种方法可以做到这一点。在这里，我们将在创建词典后去除这些单词，这是一种非常方便的方法，因为当你有了词典时，你只需要去除每个这样的单词一次。所以干杯！！目前你不需要做任何事情。

### 2\. 创建词典。

数据集中的一封示例邮件如下所示：

```py
Subject: posting

hi , ' m work phonetics project modern irish ' m hard source . anyone recommend book article english ? ' , specifically interest palatal ( slender ) consonant , work helpful too . thank ! laurel sutton ( sutton @ garnet . berkeley . edu
```

可以看出，邮件的第一行是主题，第3行包含邮件的正文。我们将仅对内容进行文本分析以检测垃圾邮件。第一步，我们需要创建一个单词及其频率的词典。为此任务，使用了700封邮件的训练集。这个python函数为你创建词典。

```py
def make_Dictionary(train_dir):
    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]    
    all_words = []       
    for mail in emails:    
        with open(mail) as m:
            for i,line in enumerate(m):
                if i == 2:  #Body of email is only 3rd line of text file
                    words = line.split()
                    all_words += words

    dictionary = Counter(all_words)
    # Paste code for non-word removal here(code snippet is given below) 
    return dictionary
```

一旦词典创建完成，我们可以在上面的函数中添加几行下面的代码，以去除我们在第1步中提到的非单词。我还删除了词典中与此无关的荒谬单字符。不要忘记将下面的代码插入到函数`def make_Dictionary(train_dir)`中。

```py
list_to_remove = dictionary.keys()
for item in list_to_remove:
    if item.isalpha() == False: 
        del dictionary[item]
    elif len(item) == 1:
        del dictionary[item]
dictionary = dictionary.most_common(3000)
```

可以通过命令`print dictionary`查看词典。你可能会发现一些荒谬的词频较高，但不用担心，这只是一个词典，你总是可以在之后对其进行改进。如果你正在跟随这个博客和提供的数据集，请确保你的词典中包含以下一些作为最常用单词的条目。这里我选择了词典中3000个最常用的单词。

```py
[('order', 1414), ('address', 1293), ('report', 1216), ('mail', 1127), ('send', 1079), ('language', 1072), ('email', 1051), ('program', 1001), ('our', 987), ('list', 935), ('one', 917), ('name', 878), ('receive', 826), ('money', 788), ('free', 762)
```

### 3\. 特征提取过程。

一旦词典准备好，我们可以为训练集中的每封邮件提取3000维的词频向量（我们这里的特征）。每个**词频向量**包含训练文件中3000个单词的频率。当然，你现在可能已经猜到它们中的大多数将是零。我们来看一个例子。假设我们在词典中有500个单词。每个词频向量包含训练文件中500个词典单词的频率。假设训练文件中的文本是“Get the work done, work done”，那么它将被编码为[0,0,0,0,0,…….0,0,2,0,0,0,……,0,0,1,0,0,…0,0,1,0,0,……2,0,0,0,0,0]。在这里，所有的词频分别位于500维词频向量的第296、第359、第415、第495个索引位置，其余的为零。

以下 Python 代码将生成一个特征向量矩阵，其中行表示 700 个训练集文件，列表示 3000 个词典中的单词。索引 ‘*ij*’ 的值将是第 i 个文件中第 j 个词典单词的出现次数。

```py
def extract_features(mail_dir): 
    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]
    features_matrix = np.zeros((len(files),3000))
    docID = 0;
    for fil in files:
      with open(fil) as fi:
        for i,line in enumerate(fi):
          if i == 2:
            words = line.split()
            for word in words:
              wordID = 0
              for i,d in enumerate(dictionary):
                if d[0] == word:
                  wordID = i
                  features_matrix[docID,wordID] = words.count(word)
        docID = docID + 1     
    return features_matrix
```

### 4\. 训练分类器。

在这里，我将使用 [scikit-learn ML 库](http://scikit-learn.org/stable/) 来训练分类器。它是一个开源的 Python 机器学习库，可以通过第三方发行版 [anaconda](https://www.continuum.io/downloads) 获得，或者可以按照 [这个](http://scikit-learn.org/stable/install.html) 方法单独安装。安装完成后，我们只需在程序中导入它即可。

我在这里训练了两个模型，即朴素贝叶斯分类器和支持向量机 (SVM)。朴素贝叶斯分类器是一种传统且非常流行的文档分类方法。它是基于贝叶斯定理的有监督概率分类器，假设特征之间是独立的。SVM 是有监督的二分类器，当特征数量较多时非常有效。SVM 的目标是将训练数据的某些子集与其余数据分开，这些子集被称为支持向量（分离超平面的边界）。SVM 模型的决策函数基于支持向量，并利用核技巧。

一旦训练了分类器，我们可以检查模型在测试集上的表现。我们提取测试集每封邮件的词频向量，并使用训练好的朴素贝叶斯分类器和 SVM 模型预测其类别（ham 或 spam）。以下是用于垃圾邮件过滤的完整代码。你需要在第 2 步和第 3 步中包含我们之前定义的两个函数。

```py
import os
import numpy as np
from collections import Counter
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn.svm import SVC, NuSVC, LinearSVC

# Create a dictionary of words with its frequency

train_dir = 'train-mails'
dictionary = make_Dictionary(train_dir)

# Prepare feature vectors per training mail and its labels

train_labels = np.zeros(702)
train_labels[351:701] = 1
train_matrix = extract_features(train_dir)

# Training SVM and Naive bayes classifier

model1 = MultinomialNB()
model2 = LinearSVC()
model1.fit(train_matrix,train_labels)
model2.fit(train_matrix,train_labels)

# Test the unseen mails for Spam
test_dir = 'test-mails'
test_matrix = extract_features(test_dir)
test_labels = np.zeros(260)
test_labels[130:260] = 1
result1 = model1.predict(test_matrix)
result2 = model2.predict(test_matrix)
print confusion_matrix(test_labels,result1)
print confusion_matrix(test_labels,result2)
```

### 检查性能

测试集包含 130 封垃圾邮件和 130 封非垃圾邮件。如果你已经读到这里，你会看到以下结果。我展示了两个模型在测试集上的混淆矩阵。对角线元素表示正确识别的邮件（即真实识别），而非对角线元素表示邮件的错误分类（虚假识别）。

| 多项式朴素贝叶斯 | Ham | Spam |
| --- | --- | --- |
| Ham | 129 | 1 |
| Spam | 9 | 121 |
| SVM（线性） | Ham | Spam |
| Ham | 126 | 4 |
| Spam | 6 | 124 |

两个模型在测试集上的表现相似，唯一不同的是 SVM 稍微平衡了错误识别。我必须提醒你，测试数据既没有用于创建词典，也没有用于训练集。

### 你的任务

下载预处理后的 [Euron-spam](http://www.aueb.gr/users/ion/data/enron-spam/) 语料库。该语料库包含 33716 封电子邮件，分布在 6 个目录中。每个目录包含 ‘ham’ 和 ‘spam’ 文件夹。非垃圾邮件和垃圾邮件的总数分别为 16545 和 17171。

按照本博客文章中描述的步骤操作，并检查它在支持向量机和多项式朴素贝叶斯模型中的表现。由于此语料库的目录结构与博客文章中使用的 ling-spam 子集的目录结构不同，你可能需要重新组织目录或修改 `def make_Dictionary(dir)` 和 `def extract_features(dir)` 函数。

我将 Euron-spam 语料库分为 60:40 的训练集和测试集。经过执行本博客的相同步骤后，我在 13487 个测试集邮件上获得了以下结果。我们可以看到，SVM 在正确检测垃圾邮件方面表现略优于朴素贝叶斯分类器。

| 多项式 NB | Ham | Spam |
| --- | --- | --- |
| Ham | 6445 | 225 |
| Spam | 137 | 6680 |
| SVM(线性) | Ham | Spam |
| Ham | 6490 | 180 |
| Spam | 109 | 6708 |

### 最终想法

希望这个教程简单易懂，因为我尽量保持简短。对文本分析感兴趣的初学者可以从这个应用程序开始。

你可能会考虑使用的模型背后的数学技术，如朴素贝叶斯和 SVM。SVM 是一个数学复杂的模型，而朴素贝叶斯相对容易理解。鼓励你从在线资源中研究这些模型。此外，还可以进行大量实验，以发现各种参数的效果，如

a) 训练数据量

b) 字典大小

c) 使用的 ML 技术变体（GaussianNB，BernoulliNB，SVC）

d) SVM 模型参数的微调

e) 通过消除不重要的词汇来改进字典（可能需要手动）

f) 其他特征（查看 td-idf）

我会在其他博客文章中写这些模型的数学解释。

你可以从 GitHub 链接 [这里](https://github.com/abhijeet3922/Mail-Spam-Filtering) 获取完整的 Python 实现。

如果你喜欢这篇文章，请关注这个博客，以获取即将发布的文章更新。同时，分享这篇文章，以便让真正受益的读者看到。请随时讨论任何关于这篇文章的内容。我非常乐意听取你的反馈。

祝机器学习愉快！

**[实践中的机器学习](https://appliedmachinelearning.wordpress.com/)** 是初学者提高机器学习技能的完美实践。

[原文](https://appliedmachinelearning.wordpress.com/2017/01/23/email-spam-filter-python-scikit-learn/)。经许可转载。

**相关：**

+   [使用 Numpy 矩阵：实用的第一参考](/2017/03/working-numpy-matrices.html)

+   [使用 Iris 数据集的简单 XGBoost 教程](/2017/03/simple-xgboost-tutorial-iris-dataset.html)

+   [K-Means 和其他聚类算法：Python 快速入门](/2017/03/k-means-clustering-algorithms-intro-python.html)

### 更多关于此主题

+   [通过集成 Jupyter 和 KNIME 缩短实现时间](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)

+   [DeepMind 的 AlphaTensor 首次开源实现](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)

+   [过滤 Python 列表的 5 种方法](https://www.kdnuggets.com/2022/11/5-ways-filtering-python-lists.html)

+   [协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)

+   [在 Pandas 中进行条件过滤的五种方法](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)

+   [理解 Python 的迭代和成员关系：__contains__ 和 __iter__ 魔法方法指南](https://www.kdnuggets.com/understanding-pythons-iteration-and-membership-a-guide-to-__contains__-and-__iter__-magic-methods)
