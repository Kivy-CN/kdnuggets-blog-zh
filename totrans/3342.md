# Apache Arrow 和 Apache Parquet：为何我们需要不同的列式数据项目，分别用于磁盘和内存

> 原文：[https://www.kdnuggets.com/2017/02/apache-arrow-parquet-columnar-data.html](https://www.kdnuggets.com/2017/02/apache-arrow-parquet-columnar-data.html)

**由架构师Julien LeDem撰写，来自 [Dremio](http://www.dremio.com/)。**

列式数据结构在分析方面提供了许多性能优势。包括磁盘上数据的好处——减少磁盘寻址次数，更有效的压缩，更快的扫描速度——以及内存中数据的CPU使用效率。今天，列式数据非常普遍，并且被大多数分析数据库实现，包括Teradata、Vertica、Oracle等。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT

* * *

在2012年和2013年，我们Twitter和Cloudera的一些人创建了Apache Parquet（最初叫做Red Elm，是Google的Dremel的一个字母重排），旨在将这些理念引入Hadoop生态系统。四年后，Parquet成为了磁盘上列式数据的标准，而一个名为Apache Arrow的新项目也出现了，成为了内存中表示列式数据的标准。在这篇文章中，我们将深入探讨为什么我们需要两个项目，一个用于磁盘上的数据存储，另一个用于内存中的数据处理，以及它们如何协同工作。

### 行有什么问题，列又有什么优点？

回到2007年，Vertica作为早期的商业列式数据库之一，有一个巧妙的营销口号“桌子已经翻转。”这并不是一个不好的方式来形象化列式数据库的工作方式——将桌子旋转90度，现在曾经读取的行变成了读取单一列。这种方法在处理分析性负载时有很多优势。

![](../Images/ed551a87e16d9473437bf40dfeb79e19.png)

大多数系统都被设计为最小化磁盘寻址次数和扫描的数据量，因为这些操作可能会带来巨大的延迟。在事务性负载中，当数据被写入到行导向数据库中的表时，给定行的列会连续地写入磁盘，这对于写操作非常高效。分析性负载则不同，因为大多数查询一次读取大量行中的一小部分列。在传统的行导向数据库中，系统可能会对每一行执行一次寻址，而大多数列则会被不必要地从磁盘读入内存。

列式数据库将给定列的值连续地组织在磁盘上。这具有显著减少多行读取时寻址次数的优势。此外，压缩算法在单一数据类型上往往比在典型行中的混合类型上更有效。权衡之处在于写入速度较慢，但对于分析来说，这是一种良好的优化，因为读取通常远多于写入。

### 列式，遇见 Hadoop

在 Twitter，我们是 Hadoop 的大量用户，Hadoop 非常可扩展，能够存储广泛的数据，并能在数百或数千台服务器之间并行化工作负载。一般来说，Hadoop 的延迟较高，因此我们也大量使用 Vertica，它为我们提供了很好的性能，但仅适用于数据的一个小子集。

我们认为通过在 HDFS 中以列式模型更好地组织数据，可以显著提高 Hadoop 在分析作业中的性能，主要是 Hive 查询，但也包括其他项目。当时我们有大约 4 亿用户，每天生成超过 100TB 的压缩数据，因此对这个项目有很大的兴趣。

我们在早期测试中看到了很多好处：我们减少了 28% 的存储开销，单列读取时间减少了 90%。我们继续优化，增加了列特定的压缩选项、字典压缩、位打包和游程编码，最终将存储减少了 52%，读取时间减少了 48%。

![列式数据](../Images/db84f998e32079445312e5e853a9089d.png)

Parquet 也被设计用来处理像 JSON 这样丰富结构的数据。这对我们在 Twitter 和许多其他早期采用者非常有利，如今大多数 Hadoop 用户将他们的数据存储在 Parquet 中。Hadoop 生态系统中广泛支持 Parquet，包括 Spark、Presto、Hive、Impala、Drill、Kite 等。即使在 Hadoop 之外，它也被一些科学社区采用，如 CERN 的 ROOT 项目。

### 基于 Parquet 的内存处理思想

自原始 Google 论文启发 Hadoop 以来，硬件在过去 15 年里发生了很大变化。最重要的变化是 RAM 价格的大幅下降。

![](../Images/ad2bc32d89913243206f9bbc9fe58f27.png)

现在的服务器拥有比我在 Twitter 时期更多的 RAM，由于从内存中读取数据的速度比从磁盘中读取数据快上千倍，因此在数据领域中，如何为分析任务优化使用 RAM 引起了巨大的兴趣。

列式数据的权衡与内存中的数据不同。对于磁盘上的数据，通常 IO 主导延迟，这可以通过积极的压缩来解决，但会以 CPU 为代价。在内存中，访问速度要快得多，我们希望通过关注缓存局部性、流水线和 SIMD 指令来优化 CPU 吞吐量。

### 简化系统间的接口

计算机科学中一个有趣的现象是，尽管有一套通用资源——RAM、CPU、存储、网络——但每种语言与这些资源的交互方式完全不同。当不同程序需要交互时——无论是在语言内部还是跨语言——这些数据传递中的低效性可能会占据整体成本的一部分。这有点像在欧元出现之前在欧洲旅行，你需要每个国家不同的货币，到旅程结束时，你可以肯定你在所有的货币兑换中损失了很多钱！

![](../Images/16e8a5fea28863305881f3286da70634.png)

![](../Images/016ddeda494124b5d26a1629156392b8.png)

我们将这些数据传递视为内存处理中的下一个明显瓶颈，并开始在广泛的项目中工作，以开发一套通用接口，消除在数据传输过程中不必要的序列化和反序列化。Apache Arrow 标准化了一种高效的内存列式表示，这种表示与网络传输表示相同。如今，它在超过13个项目中包括了一级绑定，包括 Spark、Hadoop、R、Python/Pandas 以及我的公司 Dremio。

![](../Images/c80acb3b2f2ee35321befe15be4dccee.png)

Python 尤其在 Pandas 库中得到了非常强的支持，并且支持直接处理 Arrow 记录批次并将其持久化为 Parquet。

对于 Apache Arrow 来说，这些仍然是早期阶段，但结果非常有希望。用户在各种工作负载中看到性能提高 10 倍到 100 倍并不少见。

### Parquet 和 Arrow 的协同工作

Parquet 和 Arrow 之间的互操作性从一开始就是一个目标。虽然每个项目可以独立使用，但两者都提供了在格式之间读取和写入的 API。 ![](../Images/3fe6329df67b98a388942afb32a69f2d.png)

由于两者都是列式的，我们可以实现高效的矢量化转换器，将数据从一个格式转换到另一个格式，并且从 Parquet 读取到 Arrow 的速度比行式表示要快得多。我们仍在寻找使这种集成更加无缝的方法，包括一个矢量化的 Java 阅读器和完全的类型等价。

Pandas 是一个很好的例子，展示了如何使用这两个项目。用户可以将 Pandas 数据框保存为 Parquet，并将 Parquet 文件读取到内存中的 Arrow。Pandas 可以直接在 Arrow 列上进行操作，为更快的 Spark 集成铺平道路。

在我目前的公司 Dremio，我们正在全力推进一个新项目，该项目广泛使用 Apache Arrow 和 Apache Parquet。你可以在 [www.dremio.com](http://www.dremio.com) 了解更多信息。

**简介：** Julien LeDem，架构师，[Dremio](http://www.dremio.com) 的联合创始人，Apache Parquet 的共同作者及项目 PMC 主席。他还是 Apache Pig 的 committer 和 PMC 成员。Julien 是 Dremio 的架构师，之前曾担任 Twitter 数据处理工具的技术负责人，并获得了一个两个字符的 Twitter 账号（[@J_](https://twitter.com/j_)）。在 Twitter 之前，Julien 是 Yahoo! 内容平台的首席工程师和技术负责人，并在那里获得了 Hadoop 方面的经验。

**相关：**

+   [闪耀的 Tungsten：Spark 的光芒更亮](/2016/05/spark-tungsten-burns-brighter.html)

+   [规模化的 Spark：大数据的机器学习](/2016/09/spark-scale-machine-learning-big-data.html)

+   [大内存正在吞噬大数据——用于分析的数据集大小](/2015/11/big-ram-big-data-size-datasets.html)

### 更多相关话题

+   [成为一名优秀数据科学家需要的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [生成式 AI 时代数据科学家还需要吗？](https://www.kdnuggets.com/2023/06/data-scientists-still-needed-age-generative-ai.html)

+   [低代码：开发者还需要吗？](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)

+   [Python 中加载数据的 5 种不同方式](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)

+   [数据挖掘与机器学习有何不同？](https://www.kdnuggets.com/2022/06/data-mining-different-machine-learning.html)

+   [如何从不同背景过渡到数据科学？](https://www.kdnuggets.com/2023/05/transition-data-science-different-background.html)
