- en: Inside the Mind of a Neural Network with Interactive Code in Tensorflow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络内部与 Tensorflow 中的交互式代码
- en: 原文：[https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html/2](https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html/2](https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html?page=2#comments)'
- en: '**Interior Gradients / Positive and Negative Attributes**'
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**内部梯度 / 正面和负面属性**'
- en: '![](../Images/df9c2757200f1a14d3619735f68800dd.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df9c2757200f1a14d3619735f68800dd.png)'
- en: alpha value of 1.0
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: alpha 值为 1.0
- en: Now lets use [interior gradient](https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2),
    with the alpha values of ….
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用 [内部梯度](https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2)，alpha
    值为 ….
- en: 0.01, 0.01, 0.03, 0.04, 0.1, 0.5, 0.6, 0.7, 0.8 and 1.0 (same as original input),
    to visualize the the inner workings of the network.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 0.01, 0.01, 0.03, 0.04, 0.1, 0.5, 0.6, 0.7, 0.8 和 1.0（与原始输入相同），以可视化网络的内部工作。
- en: '[![Image](../Images/6500908cf499dd7e147d14afb520fefa.png)](https://image.ibb.co/dqbES8/jaedukseo_alphas.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图像](../Images/6500908cf499dd7e147d14afb520fefa.png)](https://image.ibb.co/dqbES8/jaedukseo_alphas.jpg)'
- en: All of the images above represents the gradient respect to the input with different
    alpha values. We can observe as alpha value increases the gradients becomes closer
    to 0 (black) due to the saturation within the network. We can clearly see the
    difference of how gradients change when we view all of the images in a gif format.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 上述所有图像表示了不同 alpha 值下相对于输入的梯度。我们可以观察到，随着 alpha 值的增加，梯度变得越来越接近 0（黑色），这是由于网络的饱和。我们可以清楚地看到，当我们将所有图像以
    gif 格式查看时，梯度变化的差异。
- en: '![](../Images/44353a386f8ae7f410ac356c27d2284a.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44353a386f8ae7f410ac356c27d2284a.png)'
- en: However, I was able to make an interesting observation, as alpha value becomes
    smaller my network wasn’t able to make the correct predictions. As seen below
    when the alpha value is small (0.01) the network predict mostly 3 or 4\. (Cat/Deer)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我能够做出一个有趣的观察，随着 alpha 值变小，我的网络无法做出正确的预测。如下面所示，当 alpha 值较小时（0.01），网络预测大多为
    3 或 4（猫/鹿）
- en: '![](../Images/0c15fd789ec51ae1af897a4e170413c3.png)![](../Images/657845dc01154e828bb72e7179fbb9f1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c15fd789ec51ae1af897a4e170413c3.png)![](../Images/657845dc01154e828bb72e7179fbb9f1.png)'
- en: '**Red Box** → Models Prediction'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**红色框** → 模型预测'
- en: But as alpha value increased, eventually ending up at 1.0, we can observe that
    the accuracy of the model increases. Finally, lets take a look at positive and
    negative attributes from the gradient at each alpha values.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但随着 alpha 值的增加，最终达到 1.0，我们可以观察到模型的准确性增加。最后，让我们查看每个 alpha 值下梯度的正面和负面属性。
- en: '![](../Images/a222dcb85cc7e2d296fc24e584a4bbf3.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a222dcb85cc7e2d296fc24e584a4bbf3.png)'
- en: '**Blue Pixel →** Positive Attributes Overlay-ed with Original Image'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**蓝色像素 →** 与原始图像叠加的正面属性'
- en: '**Red Pixel → **Negative Attributes Overlay-ed with the Original Image'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**红色像素 →** 与原始图像叠加的负面属性'
- en: '[![Image](../Images/e3cd81af95d297f575f502e36aeb2f91.png)](https://image.ibb.co/moeeuo/jaedukseo_alphas_2.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图像](../Images/e3cd81af95d297f575f502e36aeb2f91.png)](https://image.ibb.co/moeeuo/jaedukseo_alphas_2.jpg)'
- en: Again, it is easier to view the change if we create a gif out of the images.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，如果我们将这些图像制作成 gif，就更容易查看变化。
- en: '![](../Images/a05f316ca73552e1fbc6ab99fe5174b7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a05f316ca73552e1fbc6ab99fe5174b7.png)'
- en: '**Integral Gradient / Positive and Negative Attributes**'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**积分梯度 / 正面和负面属性**'
- en: '![](../Images/63c5b2df3e30865ad02c2302b1328bd2.png)![](../Images/f8b236395a2e8acd0b5130c7f2ddd299.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63c5b2df3e30865ad02c2302b1328bd2.png)![](../Images/f8b236395a2e8acd0b5130c7f2ddd299.png)'
- en: '**Left Image** → Integral Gradient with Step Size 3000 for [riemann approximation](https://en.wikipedia.org/wiki/Riemann_sum)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**左侧图像** → 积分梯度，步长为 3000，用于 [黎曼近似](https://en.wikipedia.org/wiki/Riemann_sum)'
- en: '**Right Image **→ Blue Color for Positive Attributes and Red Color for Negative
    Attributes'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**右侧图像** → 正面属性用蓝色标记，负面属性用红色标记'
- en: Finally when we use Integral Gradient to visualize the gradients we can observe
    something like above. One very interesting fact I was able to find was how the
    network predicted horse (7), dog (5) and deer (4).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们使用积分梯度来可视化梯度时，我们可以观察到如上所示的结果。我发现的一个非常有趣的事实是网络如何预测马（7）、狗（5）和鹿（4）。
- en: '![](../Images/0dcba269087e7bbac3dde2ddce079742.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dcba269087e7bbac3dde2ddce079742.png)'
- en: Lets first take a look at the original images, as seen above the left, middle
    images are horses and right image is a sheep.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下原始图像，如上所示，左侧和中间的图像是马，右侧的图像是绵羊。
- en: '![](../Images/f1d3f810a13fc6e93ecfc7705c22a87b.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1d3f810a13fc6e93ecfc7705c22a87b.png)'
- en: When we visualize the Integral Gradient we can see something interesting. As
    seen in the middle image the network thought the head portion of a horse was most
    important. However, when only taking the head, the network thought it was an image
    of a dog. (And it kinda looks like a dog). Similar story for the right image,
    when the network only taken into account of only the head of a sheep, it predicts
    as seeing a dog.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们可视化积分梯度时，可以看到一些有趣的现象。正如中间图像所示，网络认为马的头部最重要。然而，当仅仅考虑头部时，网络认为这是一张狗的图片。（而且它确实有点像狗）。右侧图像也有类似的故事，当网络仅考虑绵羊的头部时，它预测为狗。
- en: '**However**, as seen on the most left image, when the network takes in the
    overall shape of a horse (including some portion of a human) it correctly identifies
    the image as a horse. AMAZING!'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而**，正如最左侧的图像所示，当网络接收马的整体形状（包括一些人类的部分）时，它正确地识别了这张图像为马。真是**惊人**！'
- en: '**Interactive Code**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**交互式代码**'
- en: '![](../Images/932b6906c5b23eaa53a6499266270145.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/932b6906c5b23eaa53a6499266270145.png)'
- en: '*For Google Colab, you would need a google account to view the codes, also
    you can’t run read only scripts in Google Colab so make a copy on your play ground.
    Finally, I will never ask for permission to access your files on Google Drive,
    just FYI. Happy Coding! Also for transparency I uploaded all of the training logs
    on my github.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于 Google Colab，你需要一个谷歌账户来查看代码，另外你不能在 Google Colab 中运行只读脚本，所以请在你的沙盒中复制一份。最后，我永远不会请求访问你
    Google Drive 上的文件，仅供参考。祝编程愉快！为了透明度，我已将所有训练日志上传到我的 GitHub。*'
- en: To access the code for this post please [click here](https://colab.research.google.com/drive/1ld8_40udZbnWALV1pU582JphXUZD-npn),
    for training [logs click here.](https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Understanding_Concepts/COUNTERFACTUALS/viz/z_viz.txt)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此帖子的代码，请 [点击这里](https://colab.research.google.com/drive/1ld8_40udZbnWALV1pU582JphXUZD-npn)，要查看训练 [日志请点击这里。](https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Understanding_Concepts/COUNTERFACTUALS/viz/z_viz.txt)
- en: '**Final Words**'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**最后的话**'
- en: As this area is still growing and being developed there will be new methods
    and findings. (I hope I can contribute to those findings as well.). Finally, if
    you want to access the code from the original authors of the paper “[*Axiomatic
    Attribution for Deep Networks*](https://arxiv.org/abs/1703.01365)” [please click
    here](https://github.com/ankurtaly/Integrated-Gradients/blob/master/attributions.ipynb).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这一领域仍在发展中，将会有新的方法和发现。（我希望我也能为这些发现做出贡献。）最后，如果你想访问原始论文“[*Axiomatic Attribution
    for Deep Networks*](https://arxiv.org/abs/1703.01365)”的代码， [请点击这里](https://github.com/ankurtaly/Integrated-Gradients/blob/master/attributions.ipynb)。
- en: If any errors are found, please email me at jae.duk.seo@gmail.com, if you wish
    to see the list of all of my writing please [view my website here](https://jaedukseo.me/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发现任何错误，请发邮件到 jae.duk.seo@gmail.com。如果你希望查看我所有写作的列表，请 [点击这里查看我的网站](https://jaedukseo.me/)。
- en: Meanwhile follow me on my twitter [here](https://twitter.com/JaeDukSeo), and
    visit [my website](https://jaedukseo.me/), or my [Youtube channel](https://www.youtube.com/c/JaeDukSeo) for
    more content. I also implemented [Wide Residual Networks, please click here to
    view the blog post](https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同时在我的 Twitter [关注我](https://twitter.com/JaeDukSeo)，访问 [我的网站](https://jaedukseo.me/)，或者我的 [YouTube
    频道](https://www.youtube.com/c/JaeDukSeo) 以获取更多内容。我还实现了 [Wide Residual Networks，请点击这里查看博客文章](https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec)。
- en: '**Reference**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考资料**'
- en: '[http://Axiom/definition/theorem/proof](http://axiom/definition/theorem/proof).
    (2018). YouTube. Retrieved 14 June 2018, from [https://www.youtube.com/watch?v=OeC5WuZbNMI](https://www.youtube.com/watch?v=OeC5WuZbNMI)'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[http://Axiom/definition/theorem/proof](http://axiom/definition/theorem/proof)。
    （2018）。YouTube。检索于 2018 年 6 月 14 日，来自 [https://www.youtube.com/watch?v=OeC5WuZbNMI](https://www.youtube.com/watch?v=OeC5WuZbNMI)'
- en: axiom — Dictionary Definition. (2018). Vocabulary.com. Retrieved 14 June 2018,
    from [https://www.vocabulary.com/dictionary/axiom](https://www.vocabulary.com/dictionary/axiom)
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: axiom — 词典定义。（2018）。Vocabulary.com。检索于 2018 年 6 月 14 日，来自 [https://www.vocabulary.com/dictionary/axiom](https://www.vocabulary.com/dictionary/axiom)
- en: Axiomatic Attribution for Deep Networks — — Mukund Sundararajan, Ankur Taly,
    Qiqi Yan. (2017). Vimeo. Retrieved 14 June 2018, from [https://vimeo.com/238242575](https://vimeo.com/238242575)
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Axiomatic Attribution for Deep Networks — — Mukund Sundararajan, Ankur Taly,
    Qiqi Yan. (2017). Vimeo. 取自 [https://vimeo.com/238242575](https://vimeo.com/238242575)
- en: STL-10 dataset. (2018). Cs.stanford.edu. Retrieved 15 June 2018, from [https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: STL-10 数据集。 (2018). Cs.stanford.edu. 取自 [https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)
- en: Benenson, R. (2018). Classification datasets results. Rodrigob.github.io. Retrieved
    15 June 2018, from [http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130)
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Benenson, R. (2018). 分类数据集结果。 Rodrigob.github.io. 取自 [http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130)
- en: '[duplicate], H. (2018). How to hide axes and gridlines in Matplotlib (python).
    Stack Overflow. Retrieved 16 June 2018, from [https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python](https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[duplicate], H. (2018). 如何在 Matplotlib (python) 中隐藏坐标轴和网格线。 Stack Overflow.
    取自 [https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python](https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python)'
- en: VanderPlas, J. (2018). Multiple Subplots | Python Data Science Handbook. Jakevdp.github.io.
    Retrieved 16 June 2018, from [https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html)
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: VanderPlas, J. (2018). 多个子图 | Python 数据科学手册。 Jakevdp.github.io. 取自 [https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html)
- en: matplotlib.pyplot.subplot — Matplotlib 2.2.2 documentation. (2018). Matplotlib.org.
    Retrieved 16 June 2018, from [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: matplotlib.pyplot.subplot — Matplotlib 2.2.2 文档。 (2018). Matplotlib.org. 取自
    [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html)
- en: matplotlib, m. (2018). more than 9 subplots in matplotlib. Stack Overflow. Retrieved
    16 June 2018, from [https://stackoverflow.com/questions/4158367/more-than-9-subplots-in-matplotlib](https://stackoverflow.com/questions/4158367/more-than-9-subplots-in-matplotlib)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: matplotlib, m. (2018). matplotlib 中超过 9 个子图。 Stack Overflow. 取自 [https://stackoverflow.com/questions/4158367/more-than-9-subplots-in-matplotlib](https://stackoverflow.com/questions/4158367/more-than-9-subplots-in-matplotlib)
- en: 'pylab_examples example code: subplots_demo.py — Matplotlib 2.0.0 documentation.
    (2018). Matplotlib.org. Retrieved 16 June 2018, from [https://matplotlib.org/2.0.0/examples/pylab_examples/subplots_demo.html](https://matplotlib.org/2.0.0/examples/pylab_examples/subplots_demo.html)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: pylab_examples 示例代码：subplots_demo.py — Matplotlib 2.0.0 文档。 (2018). Matplotlib.org.
    取自 [https://matplotlib.org/2.0.0/examples/pylab_examples/subplots_demo.html](https://matplotlib.org/2.0.0/examples/pylab_examples/subplots_demo.html)
- en: matplotlib.pyplot.hist — Matplotlib 2.2.2 documentation. (2018). Matplotlib.org.
    Retrieved 16 June 2018, from [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html)
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: matplotlib.pyplot.hist — Matplotlib 2.2.2 文档。 (2018). Matplotlib.org. 取自 [https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html)
- en: Python?, I. (2018). Is there a clean way to generate a line histogram chart
    in Python?. Stack Overflow. Retrieved 16 June 2018, from [https://stackoverflow.com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python](https://stackoverflow.com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python?, I. (2018). 是否有一种干净的方法在 Python 中生成折线直方图？ Stack Overflow. 取自 [https://stackoverflow.com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python](https://stackoverflow.com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python)
- en: Pyplot Text — Matplotlib 2.2.2 documentation. (2018). Matplotlib.org. Retrieved
    16 June 2018, from [https://matplotlib.org/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py](https://matplotlib.org/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py)
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pyplot Text — Matplotlib 2.2.2 文档。 (2018). Matplotlib.org. 取自 [https://matplotlib.org/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py](https://matplotlib.org/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py)
- en: '[ Google / ICLR 2017 / Paper Summary ] Gradients of Counterfactuals. (2018).
    Towards Data Science. Retrieved 16 June 2018, from [https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2](https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2)'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ Google / ICLR 2017 / 论文总结 ] 反事实的梯度。 (2018). Towards Data Science. 于2018年6月16日访问，来自 [https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2](https://towardsdatascience.com/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2)'
- en: numpy.transpose — NumPy v1.14 Manual. (2018). Docs.scipy.org. Retrieved 16 June
    2018, from [https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.transpose.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.transpose.html)
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: numpy.transpose — NumPy v1.14 手册。 (2018). Docs.scipy.org. 于2018年6月16日访问，来自 [https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.transpose.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.transpose.html)
- en: command, G. (2018). Git add and commit in one command. Stack Overflow. Retrieved
    16 June 2018, from [https://stackoverflow.com/questions/4298960/git-add-and-commit-in-one-command](https://stackoverflow.com/questions/4298960/git-add-and-commit-in-one-command)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 命令，G。 (2018). 在一个命令中执行 git add 和 commit。 Stack Overflow. 于2018年6月16日访问，来自 [https://stackoverflow.com/questions/4298960/git-add-and-commit-in-one-command](https://stackoverflow.com/questions/4298960/git-add-and-commit-in-one-command)
- en: How to slice an image into red, g. (2018). How to slice an image into red, green
    and blue channels with misc.imread. Stack Overflow. Retrieved 16 June 2018, from [https://stackoverflow.com/questions/37431599/how-to-slice-an-image-into-red-green-and-blue-channels-with-misc-imread](https://stackoverflow.com/questions/37431599/how-to-slice-an-image-into-red-green-and-blue-channels-with-misc-imread)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将图像切分为红色、绿色和蓝色通道。 (2018). 如何使用 misc.imread 将图像切分为红色、绿色和蓝色通道。 Stack Overflow.
    于2018年6月16日访问，来自 [https://stackoverflow.com/questions/37431599/how-to-slice-an-image-into-red-green-and-blue-channels-with-misc-imread](https://stackoverflow.com/questions/37431599/how-to-slice-an-image-into-red-green-and-blue-channels-with-misc-imread)
- en: How to install Bash shell command-line tool on Windows 10\. (2016). Windows
    Central. Retrieved 16 June 2018, from [https://www.windowscentral.com/how-install-bash-shell-command-line-windows-10](https://www.windowscentral.com/how-install-bash-shell-command-line-windows-10)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在 Windows 10 上安装 Bash shell 命令行工具。 (2016). Windows Central. 于2018年6月16日访问，来自 [https://www.windowscentral.com/how-install-bash-shell-command-line-windows-10](https://www.windowscentral.com/how-install-bash-shell-command-line-windows-10)
- en: Google Colab Free GPU Tutorial — Deep Learning Turkey — Medium. (2018). Medium.
    Retrieved 16 June 2018, from [https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google Colab 免费 GPU 教程 — Deep Learning Turkey — Medium. (2018). Medium. 于2018年6月16日访问，来自 [https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)
- en: Installation — imgaug 0.2.5 documentation. (2018). Imgaug.readthedocs.io. Retrieved
    16 June 2018, from [http://imgaug.readthedocs.io/en/latest/source/installation.html](http://imgaug.readthedocs.io/en/latest/source/installation.html)
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 — imgaug 0.2.5 文档。 (2018). Imgaug.readthedocs.io. 于2018年6月16日访问，来自 [http://imgaug.readthedocs.io/en/latest/source/installation.html](http://imgaug.readthedocs.io/en/latest/source/installation.html)
- en: numpy.absolute — NumPy v1.14 Manual. (2018). Docs.scipy.org. Retrieved 16 June
    2018, from [https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.absolute.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.absolute.html)
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: numpy.absolute — NumPy v1.14 手册。 (2018). Docs.scipy.org. 于2018年6月16日访问，来自 [https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.absolute.html](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.absolute.html)
- en: numpy.clip — NumPy v1.10 Manual. (2018). Docs.scipy.org. Retrieved 16 June 2018,
    from [https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.clip.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.clip.html)
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: numpy.clip — NumPy v1.10 手册。 (2018). Docs.scipy.org. 于2018年6月16日访问，来自 [https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.clip.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.clip.html)
- en: numpy.percentile — NumPy v1.14 Manual. (2018). Docs.scipy.org. Retrieved 16
    June 2018, from [https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html)
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: numpy.percentile — NumPy v1.14 手册。 (2018). Docs.scipy.org. 于2018年6月16日访问，来自 [https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html)
- en: CIFAR-10 and CIFAR-100 datasets. (2018). Cs.toronto.edu. Retrieved 16 June 2018,
    from [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CIFAR-10 和 CIFAR-100 数据集。 (2018). Cs.toronto.edu. 于2018年6月16日访问，来自 [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)
- en: '[ ICLR 2015 ] Striving for Simplicity: The All Convolutional Net with Interactive
    Code [ Manual…. (2018). Towards Data Science. Retrieved 16 June 2018, from [https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760](https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760)'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ICLR 2015] 追求简单性：具有交互式代码的全卷积网络 [手册…. (2018). Towards Data Science. 取自 [https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760](https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760)
    于 2018 年 6 月 16 日'
- en: EN10/CIFAR. (2018). GitHub. Retrieved 16 June 2018, from [https://github.com/EN10/CIFAR](https://github.com/EN10/CIFAR)
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: EN10/CIFAR. (2018). GitHub. 取自 [https://github.com/EN10/CIFAR](https://github.com/EN10/CIFAR)
    于 2018 年 6 月 16 日
- en: Axiomatic Attribution for Deep Networks — — Mukund Sundararajan, Ankur Taly,
    Qiqi Yan. (2017). Vimeo. Retrieved 16 June 2018, from [https://vimeo.com/238242575](https://vimeo.com/238242575)
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度网络的公理归因 — — Mukund Sundararajan, Ankur Taly, Qiqi Yan. (2017). Vimeo. 取自 [https://vimeo.com/238242575](https://vimeo.com/238242575)
    于 2018 年 6 月 16 日
- en: (2018). Arxiv.org. Retrieved 16 June 2018, from [https://arxiv.org/pdf/1506.06579.pdf](https://arxiv.org/pdf/1506.06579.pdf)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2018). Arxiv.org. 取自 [https://arxiv.org/pdf/1506.06579.pdf](https://arxiv.org/pdf/1506.06579.pdf)
    于 2018 年 6 月 16 日
- en: Riemann sum. (2018). En.wikipedia.org. Retrieved 16 June 2018, from [https://en.wikipedia.org/wiki/Riemann_sum](https://en.wikipedia.org/wiki/Riemann_sum)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Riemann 和. (2018). En.wikipedia.org. 取自 [https://en.wikipedia.org/wiki/Riemann_sum](https://en.wikipedia.org/wiki/Riemann_sum)
    于 2018 年 6 月 16 日
- en: '**Bio: [Jae Duk Seo](https://jaedukseo.me/)** is a fourth year computer scientist
    at Ryerson University.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Jae Duk Seo](https://jaedukseo.me/)** 是瑞尔森大学的四年级计算机科学学生。'
- en: '[Original](https://towardsdatascience.com/inside-the-mind-of-a-neural-network-with-interactive-code-in-tensorflow-histogram-activation-a4dff0963103).
    Reposted with permission.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/inside-the-mind-of-a-neural-network-with-interactive-code-in-tensorflow-histogram-activation-a4dff0963103)。经授权转载。'
- en: '**Related:**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Building Convolutional Neural Network using NumPy from Scratch](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 NumPy 从头开始构建卷积神经网络](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
- en: '[How I Used CNNs and Tensorflow and Lost a Silver Medal in Kaggle Challenge](/2018/05/lost-silver-medal-kaggle-mercari-price-suggestion-challenge-cnns-tensorflow.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我如何使用 CNN 和 TensorFlow 并在 Kaggle 挑战中失去了银牌](/2018/05/lost-silver-medal-kaggle-mercari-price-suggestion-challenge-cnns-tensorflow.html)'
- en: '[Using Tensorflow Object Detection to do Pixel Wise Classification](/2018/03/tensorflow-object-detection-pixel-wise-classification.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 对象检测进行像素级分类](/2018/03/tensorflow-object-detection-pixel-wise-classification.html)'
- en: '* * *'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 领域'
- en: '* * *'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[6 ChatGPT mind-blowing extensions to use anywhere](https://www.kdnuggets.com/2023/04/6-chatgpt-mindblowing-extensions-anywhere.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6 个让人惊叹的 ChatGPT 扩展插件](https://www.kdnuggets.com/2023/04/6-chatgpt-mindblowing-extensions-anywhere.html)'
- en: '[5 Things to Keep in Mind Before Selecting Your Next Data Science Job](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择下一个数据科学工作时需要牢记的5件事](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)'
- en: '[Data Management: How to Stay on Top of Your Customer''s Mind?](https://www.kdnuggets.com/2022/04/data-management-stay-top-customer-mind.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据管理：如何保持对客户的关注？](https://www.kdnuggets.com/2022/04/data-management-stay-top-customer-mind.html)'
- en: '[Inside DeepMind’s New Efforts to Use Deep Learning to Advance Mathematics](https://www.kdnuggets.com/2021/12/inside-deepmind-new-efforts-deep-learning-advance-mathematics.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepMind在使用深度学习推动数学发展的新努力](https://www.kdnuggets.com/2021/12/inside-deepmind-new-efforts-deep-learning-advance-mathematics.html)'
- en: '[Neural Network Optimization with AIMET](https://www.kdnuggets.com/2022/04/qualcomm-neural-network-optimization-aimet.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用AIMET进行神经网络优化](https://www.kdnuggets.com/2022/04/qualcomm-neural-network-optimization-aimet.html)'
