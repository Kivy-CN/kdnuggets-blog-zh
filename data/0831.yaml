- en: Harnessing ChatGPT for Automated Data Cleaning and Preprocessing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用ChatGPT进行自动化数据清理和预处理
- en: 原文：[https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/253506759c944a8380bc213fa5f4eaa5.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![利用ChatGPT进行自动化数据清理和预处理](../Images/253506759c944a8380bc213fa5f4eaa5.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: ChatGPT has become a swiss-army knife that can be used for multitude of applications,
    and there’s abundant scope to integrate ChatGPT into data science workflows.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT已经成为一个可以用于多种应用的瑞士军刀，而且有广阔的空间将ChatGPT集成到数据科学工作流中。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you’ve ever trained a machine learning model on a real-world dataset, you
    know that the steps of data cleaning and preprocessing are important for building
    robust machine learning models. In this guide, we’ll see how we can use ChatGPT
    to perform these tasks on an example dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经在真实世界的数据集上训练过机器学习模型，你知道数据清理和预处理的步骤对于构建稳健的机器学习模型至关重要。在本指南中，我们将看到如何利用ChatGPT在示例数据集上执行这些任务。
- en: 'We’ll use the [bank marketing dataset from the UCI machine learning repository](https://archive.ics.uci.edu/dataset/222/bank+marketing)
    and prompt ChatGPT to do the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[UCI机器学习库中的银行营销数据集](https://archive.ics.uci.edu/dataset/222/bank+marketing)，并提示ChatGPT完成以下任务：
- en: Fetch and load the dataset
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取并加载数据集
- en: Check for missing values
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查缺失值
- en: Encode categorical variables
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码分类变量
- en: You can follow along by signing in to your [OpenAI account](https://platform.openai.com/login)
    and starting a new ChatGPT session. If you prefer, you can also code along in
    [Google Colab](https://colab.research.google.com/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过登录[OpenAI账户](https://platform.openai.com/login)并启动一个新的ChatGPT会话来跟随学习。如果你愿意，也可以在[Google
    Colab](https://colab.research.google.com/)中编写代码。
- en: Fetching and Loading the Dataset
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取并加载数据集
- en: There are a [few different versions of the dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing).
    We’ll use bank-full.csv.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有[几种不同版本](https://archive.ics.uci.edu/dataset/222/bank+marketing)。我们将使用bank-full.csv。
- en: '**Prompt**: Today we’ll perform data cleaning and preprocessing on a real-world
    dataset. Write the code to do the following: 1\. Fetch the bank marketing dataset
    from the UCI machine learning repository. Use libraries like requests or urllib.
    2\. Download the zip file, unzip the contents, and read in the bank-full.csv file
    into a pandas dataframe (call it data).'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：今天我们将对一个真实世界的数据集进行数据清理和预处理。编写代码完成以下任务：1\. 从UCI机器学习库中获取银行营销数据集。使用requests或urllib等库。2\.
    下载zip文件，解压内容，并将bank-full.csv文件读取到pandas数据框中（称之为data）。'
- en: 'The code to fetch and read in the dataset is as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 获取和读取数据集的代码如下：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Getting Basic Info on the Dataset
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据集的基本信息
- en: Let's understand the dataset better.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更好地理解数据集。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This outputs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出：
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/c943e5830c9d9e43f5e1034a1e06e925.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![利用ChatGPT进行自动化数据清理和预处理](../Images/c943e5830c9d9e43f5e1034a1e06e925.png)'
- en: Truncated output of data.head()
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据.head()的截断输出
- en: '**Prompt**: Use pandas to get the dimension of the dataframe, descriptive statistics
    on the columns, and data types of various columns.'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：使用pandas获取数据框的维度、列的描述性统计信息以及各列的数据类型。'
- en: This step doesn’t really require prompting ChatGPT as the pandas methods are
    pretty simple.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步骤实际上不需要提示ChatGPT，因为pandas方法相对简单。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We have over 45000 records and 16 features (as 17 is inclusive of the output
    label as well).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有超过 45000 条记录和 16 个特征（17 包括了输出标签）。
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/cb09912fbc4731c724029ebaedb9c3dd.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![利用 ChatGPT 进行自动化数据清理和预处理](../Images/cb09912fbc4731c724029ebaedb9c3dd.png)'
- en: Truncated output of data.describe()
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据 `data.describe()` 的截断输出
- en: It’s also helpful to get an overview of the data types of the various columns.
    We’ll take a closer look at them when we encode categorical variables.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 了解各种列的数据类型也很有帮助。我们在对分类变量进行编码时会更详细地查看它们。
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So far we’ve gained an understanding of the bank marketing dataset. The output
    label denotes whether or not a customer will subscribe to a term deposit. The
    dataset contains several features such as the age, month, education, marital status,
    outcome of previous campaigns, and more.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了银行营销数据集。输出标签表示客户是否会订阅定期存款。数据集包含几个特征，如年龄、月份、教育、婚姻状况、之前活动的结果等。
- en: Checking for Missing Values
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查缺失值
- en: '**Prompt**: I want to know the number of missing values in each column. Please
    give me the code to do it. Use pandas.'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我想知道每列中的缺失值数量。请给我代码来实现。使用 pandas。'
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here’s the output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This version of the bank marketing dataset—with over 45000 records—does not
    have any missing values. In practice, though, most real-world datasets have missing
    values. You should handle missing values using suitable imputation techniques.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本的银行营销数据集——拥有超过 45000 条记录——没有任何缺失值。然而，在实践中，大多数现实世界的数据集都有缺失值。你应该使用合适的插补技术来处理缺失值。
- en: As an optional exercise , you can add a step here prompting ChatGPT to drop
    a small fraction of values from a subset of columns so you can practice how to
    handle missing values.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个可选练习，你可以在这里添加一个步骤，让 ChatGPT 从一部分列中删除一小部分值，以便你可以练习如何处理缺失值。
- en: Encoding Categorical Variables
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码分类变量
- en: The next step is to encode categorical variables in the dataset. We’ll start
    by getting the list of all categorical columns.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是对数据集中的分类变量进行编码。我们将从获取所有分类列的列表开始。
- en: '**Prompt**: Give the code to get the list of all categorical columns in this
    dataset.'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：给出代码以获取数据集中所有分类列的列表。'
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The categorical columns list also includes the output label **y**. But let's
    focus on the other categorical variables first.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 分类列列表还包括输出标签 **y**。但我们先关注其他分类变量。
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: A Closer Look at the Values of Categorical Variables
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更深入了解分类变量的值
- en: Next, let’s see the values that each categorical variable takes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看每个分类变量的值。
- en: '**Prompt**: I want to understand the various values that each categorical variable
    takes. Give the pandas code to do it.'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我想了解每个分类变量的各种值。请给出 pandas 代码来实现。'
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is hard to parse:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 输出难以解析：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Visualizing the Values of Categorical Variables
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化分类变量的值
- en: Let’s prompt ChatGPT to create a visualization so it’s easier to understand
    what values the categorical variables take.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们让 ChatGPT 创建一个可视化图表，以便更容易理解分类变量的值。
- en: '**Prompt**: I want a plot that shows the values that each categorical variable
    takes. Exclude the output label y. Include all other categorical variables.'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我想要一个图表，展示每个分类变量的值。排除输出标签 y。包括所有其他分类变量。'
- en: And here we go!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那我们开始吧！
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/e27c7a292f8f5588afd63b06a0a27503.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![利用 ChatGPT 进行自动化数据清理和预处理](../Images/e27c7a292f8f5588afd63b06a0a27503.png)'
- en: Values of Categorical Variables
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量的值
- en: One-Hot Encoding
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 独热编码
- en: For a subset of categorical columns, we can use one-hot encoding.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部分分类列，我们可以使用独热编码。
- en: '**Prompt**: Give the pandas code to perform one-hot encoding for a list of
    columns.'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：给出 pandas 代码以对一组列进行独热编码。'
- en: 'We use `get_dummies` from pandas to one-hot encode the following columns:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 pandas 中的 `get_dummies` 对以下列进行独热编码：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Prompt**: I want to print out the first few rows for the newly added columns.
    Write the code to do the same.'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我想打印出新添加列的前几行。编写代码来实现这一点。'
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/9bc20dfbab384edf86a1e63b3a860186.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![利用 ChatGPT 进行自动化数据清理和预处理](../Images/9bc20dfbab384edf86a1e63b3a860186.png)'
- en: Truncated output of encoded_data['new_colums'].head()
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 编码后的数据 `encoded_data['new_colums'].head()` 的截断输出
- en: Defining a Custom Mapping
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义自定义映射
- en: For columns for variables like ‘education’ and ‘poutcome’ (previous outcome),
    rather than one-hot encoding, it would be better to use custom mapping to have
    a degree of comparison between the values.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像‘education’和‘poutcome’（先前结果）这样的变量列，使用自定义映射比独热编码更好，这样可以在值之间进行比较。
- en: Also, when we use one-hot encoding to encode a categorical variable that takes
    k distinct values k new columns. For a categorical column like ‘month’ this will
    be excessive without adding much information.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当我们使用独热编码来编码一个取 k 个不同值的分类变量时，会创建 k 个新列。对于像‘month’这样的分类列，这样做会显得过于冗余而没有增加太多信息。
- en: So for both of these cases, we will define a custom mapping and then transform
    the values. We can prompt ChatGPT to get a generic code snippet which we can then
    modify to define the mapping for the specific columns.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于这两种情况，我们将定义一个自定义映射，然后转换值。我们可以提示 ChatGPT 来获取一个通用代码片段，然后对其进行修改以定义特定列的映射。
- en: '**Prompt**: I want to do a custom mapping for encoding some categorical variables.
    First give me a generic code snippet that defines a custom mapping from unique
    values in a categorical column to a different set of output values. We should
    then use this mapping to transform the values in the columns.'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我想对一些分类变量进行自定义映射。首先，给我一个通用代码片段，用于定义从分类列中的唯一值到不同输出值的自定义映射。然后我们应该使用此映射来转换列中的值。'
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'For the ‘month’ column, let us transform the month strings like so:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于‘month’列，让我们将月份字符串转换如下：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s map the ‘poutcome’ and ‘education’ columns to numerical values as shown:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将‘poutcome’和‘education’列映射到数值，如下所示：
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Encoding the Output Label
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码输出标签
- en: Let's also map the output labels 'yes' and 'no' to 1 and 0, respectively.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也将输出标签‘yes’和‘no’分别映射为 1 和 0。
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Recall that we used one-hot encoding for ‘housing’, ‘default’, and ‘loan’ columns.
    Because these columns also take ‘yes’ and ‘no’ values, you can also map ‘yes’
    and ‘no’ to 1 and 0, respectively.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 记住我们对‘housing’，‘default’和‘loan’列使用了独热编码。由于这些列也取‘yes’和‘no’值，你还可以将‘yes’和‘no’分别映射为
    1 和 0。
- en: Visualizing the Distribution of Class Labels
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化类别标签的分布
- en: It’s also helpful to check the distribution of class labels so that we can account
    for class imbalance when building models if needed.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 检查类别标签的分布也是有帮助的，这样我们在构建模型时可以根据需要考虑类别不平衡。
- en: '**Prompt**: I would like to understand the distribution of class labels. Please
    give me the code to generate a suitable plot for the same.'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：我希望了解类别标签的分布。请给我生成适当图表的代码。'
- en: 'Here’s the code to generate a countplot in Seaborn:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是生成 Seaborn 中的计数图的代码：
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/3124a915de369d6eac9b0510c9911766.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![利用 ChatGPT 实现自动化数据清洗和预处理](../Images/3124a915de369d6eac9b0510c9911766.png)'
- en: Distribution of Class Labels
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 类别标签的分布
- en: We see that there is class imbalance. So if you are building a model, you should
    be sure to address class imbalance using appropriate resampling methods.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到存在类别不平衡。因此，如果你正在构建模型，应该确保使用适当的重采样方法来解决类别不平衡问题。
- en: Generic Data Cleaning and Preprocessing Pipeline
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用数据清洗和预处理管道
- en: Though data cleaning and preprocessing require efforts from the developer, let’s
    try to get a generic sequence of steps that works reasonably well for a simple
    dataset.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据清洗和预处理需要开发者的努力，但让我们尝试得到一个适用于简单数据集的通用步骤序列。
- en: '**Prompt**: Can you give me a generic data cleaning and preprocessing pipeline
    based on what we’ve done so far. Get basic info on the dataset, check for and
    handle missing values, identify categorical columns, and encode categorical columns.
    Use only pandas.'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**：你能否给我一个基于我们目前所做的通用数据清洗和预处理管道。获取数据集的基本信息，检查并处理缺失值，识别分类列，并对分类列进行编码。仅使用
    pandas。'
- en: 'And here it is:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Wrapping Up
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: As seen, data science expertise in synergy with ChatGPT can help make data cleaning
    and preprocessing simpler and faster. Now that you have the preprocessed dataset
    ready, you can take this further by building a simple predictive model on this
    bank marketing dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所见，数据科学专业知识与 ChatGPT 的协同作用可以帮助简化和加速数据清洗和预处理。现在你已经准备好预处理的数据集，可以通过在这个银行营销数据集上构建一个简单的预测模型来进一步处理。
- en: If interested, you can also explore how to leverage [ChatGPT for data exploration](/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果感兴趣，你还可以探索如何利用 [ChatGPT 进行数据探索](/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)。
- en: Dataset Credits
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集致谢
- en: The bank marketing dataset is licensed under a [Creative Commons Attribution
    4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/legalcode)
    license.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 银行营销数据集根据 [知识共享署名 4.0 国际 (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/legalcode)
    许可证进行许可。
- en: Moro,S., Rita,P., and Cortez,P.. (2012). Bank Marketing. UCI Machine Learning
    Repository. [https://doi.org/10.24432/C5K306](https://doi.org/10.24432/C5K306).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Moro, S., Rita, P., 和 Cortez, P.. (2012). 银行营销. UCI 机器学习资料库. [https://doi.org/10.24432/C5K306](https://doi.org/10.24432/C5K306).
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a developer
    and technical writer from India. She likes working at the intersection of math,
    programming, data science, and content creation. Her areas of interest and expertise
    include DevOps, data science, and natural language processing. She enjoys reading,
    writing, coding, and coffee! Currently, she''s working on learning and sharing
    her knowledge with the developer community by authoring tutorials, how-to guides,
    opinion pieces, and more.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** 是来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇处工作。她的兴趣和专长领域包括
    DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和咖啡！目前，她正在通过撰写教程、操作指南、观点文章等，学习并与开发者社区分享她的知识。'
- en: More On This Topic
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题更多信息
- en: '[3 Steps for Harnessing the Power of Data](https://www.kdnuggets.com/2022/05/3-steps-harnessing-power-data.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用数据的力量的 3 个步骤](https://www.kdnuggets.com/2022/05/3-steps-harnessing-power-data.html)'
- en: '[Unveiling the Potential of CTGAN: Harnessing Generative AI for…](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 CTGAN 的潜力：利用生成性 AI 生成合成数据…](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费电子书学习数据清理和预处理](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清理和预处理文本数据以进行 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[Easy Guide To Data Preprocessing In Python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 数据预处理的简易指南](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
