# 如何在第一次Kaggle比赛中排名前10%

> 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/4](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/4)

### Home Depot 搜索相关性

在这一部分，我将分享我在[Home Depot搜索相关性比赛](https://www.kaggle.com/c/home-depot-product-search-relevance)中的解决方案以及我从顶尖团队中学到的东西。

本次比赛的任务是预测在Home Depot网站上搜索词的结果相关性。相关性是由三位人工评估者给出的平均分数，范围为1~3。因此，这是一个回归任务。数据集包含搜索词、产品标题/描述以及一些属性，如品牌、尺寸和颜色。评价指标是[RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的IT工作

* * *

这很像 [Crowdflower搜索结果相关性](https://www.kaggle.com/c/crowdflower-search-relevance)。区别在于 [Quadratic Weighted Kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa#Weighted_kappa) 在Crowdflower比赛中被使用，因此使最终回归分数的截止值更加复杂。而且Crowdflower中没有提供属性。

**EDA**

在我加入比赛时，已经有几个相当不错的EDA，特别是 [这个](https://www.kaggle.com/briantc/home-depot-product-search-relevance/homedepot-first-dataexploreation-k)。我了解到：

+   许多搜索词/产品出现了多次。

+   文本相似度是很好的特征。

+   许多产品没有属性特征。这会成为问题吗？

+   产品ID似乎具有很强的预测能力。然而，训练集和测试集之间的产品ID重叠度不是很高。这是否会导致过拟合？

**数据预处理**

你可以在[GitHub](https://github.com/dnc1994/Kaggle-Playground/blob/master/home-depot/Preprocess.ipynb)上找到我进行数据预处理和特征工程的方式。我这里只做简要总结：

1.  使用 [错别字词典](https://www.kaggle.com/steubk/home-depot-product-search-relevance/fixing-typos) 来纠正搜索词中的错别字。

1.  计算属性特征。找出那些频繁出现且容易利用的特征。

1.  将训练集与测试集合并。这很重要，否则你需要进行两次特征变换。

1.  对所有文本字段进行**[词干提取](https://en.wikipedia.org/wiki/Stemming)**和**[分词](https://en.wikipedia.org/wiki/Text_segmentation#Word_segmentation)**。一些**标准化**（涉及数字和单位）和**同义词替换**是手动进行的。

**特征**

+   *属性特征*

    +   产品是否包含某个特定属性（品牌、尺寸、颜色、重量、室内/室外、能源之星认证等）

    +   某个属性是否与搜索词匹配

+   元特征

    +   每个文本字段的长度

    +   产品是否包含属性字段

    +   品牌（以整数编码）

    +   产品 ID

+   匹配

    +   搜索词是否出现在产品标题/描述/属性中

    +   搜索词在产品标题/描述/属性中的出现次数和比例

    +   *搜索词的第 i 个词是否出现在产品标题/描述/属性中*

+   搜索词与产品标题/描述/属性之间的文本相似度

    +   [BOW](https://en.wikipedia.org/wiki/Bag-of-words_model) [余弦相似度](https://en.wikipedia.org/wiki/Cosine_similarity)

    +   [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 余弦相似度

    +   [Jaccard 相似度](https://en.wikipedia.org/wiki/Jaccard_index)

    +   *[编辑距离](https://en.wikipedia.org/wiki/Edit_distance)*

    +   [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) 距离（我没有包含这个，因为它的表现不佳且计算速度慢。然而，似乎是我使用不当。）

+   **[潜在语义索引](https://en.wikipedia.org/wiki/Latent_semantic_indexing)：通过对从 BOW/TF-IDF 向量化获得的矩阵进行[SVD 分解](https://en.wikipedia.org/wiki/Singular_value_decomposition)，我们得到不同搜索词/产品组的潜在表示。这使我们的模型能够区分不同组，并对特征分配不同的权重，从而解决了数据依赖和产品缺少某些特征的问题（在一定程度上）。**

请注意，上述以`*`标记的特征是我最后添加的一批特征。问题是，包含这些特征的数据训练的模型表现比之前的模型更差。起初我认为特征数量的增加需要重新调整模型参数。然而，在花费了大量 CPU 时间进行网格搜索后，我仍然无法超越旧模型。我认为这可能是上述**特征相关性**的问题。实际上，我知道一个可能有效的解决方案，即通过堆叠**结合不同特征版本训练的模型**。不幸的是，我没有足够的时间去尝试。**实际上，大多数顶级团队认为，结合不同预处理和特征工程管道训练的模型是成功的关键**。

**模型**

起初，我使用`RandomForestRegressor`来构建模型。然后我尝试了**Xgboost**，结果发现它比Sklearn快了两倍多。从那时起，我每天的工作基本上是进行网格搜索，同时在笔记本电脑上进行特征工程。

本次竞赛中的数据集并不容易验证。数据不是独立同分布的，许多记录是相关的。我多次使用更好的特征/参数，结果却得到了更差的LB分数。正如许多成功的Kaggler反复提到的那样，在这种情况下，你必须相信自己的交叉验证分数。因此，我决定在交叉验证中使用10折而不是5折，并在后续尝试中忽略LB分数。

**集成**

我的最终模型是由4个基础模型组成的集成模型：

+   `RandomForestRegressor`

+   `ExtraTreesRegressor`

+   `GradientBoostingRegressor`

+   `XGBRegressor`

堆叠器也是一个`XGBRegressor`。

问题是，我所有的基础模型都高度相关（最低相关性为0.9）。我考虑将线性回归、SVM回归和带有线性增强器的`XGBRegressor`包含在集成中，但这些模型的RMSE分数比我最终使用的4个模型高出0.02（这在排行榜上相当于数百名的差距）。因此，我决定不使用更多模型，尽管它们会带来更多的多样性。

好消息是，尽管基础模型高度相关，堆叠仍然大幅提高了我的分数。**更重要的是，自从我开始堆叠后，我的交叉验证分数和LB分数完全同步。**

在竞赛的最后两天，我做了一件事：**使用20个不同的随机种子生成集成模型，并将它们的加权平均作为最终提交**。这实际上是一种**袋装法**。理论上是有意义的，因为在堆叠中，我使用80%的数据训练每次迭代的基础模型，而100%的数据用于训练堆叠器。因此，它不够干净。使用不同种子的多次运行确保了**每次使用不同的80%数据**，从而降低了信息泄露的风险。然而，通过这种方式，我只实现了`0.0004`的提高，这可能只是随机性所致。

竞赛结束后，我发现我的最佳单模型在私人排行榜上的分数为`0.46378`，而我的最佳堆叠集成模型的分数为`0.45849`。这差距使我从第174名提升到了第98名。换句话说，特征工程和模型调优让我进入了前10%，而堆叠让我进入了前5%。

**经验教训**

从顶级团队分享的解决方案中可以学到很多：

+   产品标题中有一个模式。例如，标题末尾的`With/Without XXX`会指示产品是否附带某个配件。

+   使用外部数据。例如，使用[WordNet](https://wordnet.princeton.edu/)或[Reddit Comments Dataset](https://www.kaggle.com/reddit/reddit-comments-may-2015)来训练同义词和[上位词](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy)。

+   一些特征基于**字母**而不是**词语**。一开始我对此感到困惑，但仔细考虑后，这完全有意义。例如，获得第3名的团队在计算文本相似性时考虑了匹配字母的数量。他们认为**较长的词语更具体，因此更可能被人类分配较高的相关性评分**。他们还使用逐字符序列比较（`difflib.SequenceMatcher`）来测量**视觉相似性**，他们认为这对人类来说很重要。

+   对词汇进行词性标注并找出**[主语](https://en.wikipedia.org/wiki/Head_(linguistics))**在短语中，并在计算各种距离度量时使用它们。

+   从产品标题/描述字段的TF-IDF中提取排名靠前的三元组，并计算这些三元组中出现的搜索词的比例。反之亦然。这就像从另一个角度计算潜在索引。

+   一些新颖的距离度量，如[Word Movers Distance](http://jmlr.org/proceedings/papers/v37/kusnerb15.pdf)。

+   除了SVD，一些使用了[NMF](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)。

+   生成**成对的多项式交互**在排名前列的特征之间。

+   **对于交叉验证，构建产品ID在训练集和测试集之间不重叠的拆分，以及ID重叠的拆分。然后我们可以使用这些拆分及其对应的比例来近似公共/私有LB拆分在本地交叉验证中的影响。**

### 总结

**收获**

1.  早早开始进行集成学习是个不错的决定。事实证明，我在最后几天仍在玩弄特征。

1.  高优先级是构建一个能够自动训练模型和记录最佳参数的流程。

1.  **特征最为重要！** 我在这次竞赛中没有花足够的时间在特征上。

1.  如果可能，花些时间手动检查原始数据中的模式。

**提出的问题**

在这些竞赛中遇到的几个问题具有很高的研究价值。

1.  如何使用依赖数据进行可靠的交叉验证。

1.  如何量化**多样性与准确性之间的权衡**在集成学习中的影响。

1.  如何处理特征交互对模型性能的损害，以及**如何确定在这种情况下新特征是否有效**。

**初学者提示**

1.  选择一个你感兴趣的竞赛。**如果你对问题领域已有一些见解，那就更好了。**

1.  遵循我的方法或其他人的方法，开始探索、理解和建模数据。

1.  从论坛和脚本中学习。看看其他人如何解释数据和构建特征。

1.  **找到之前比赛的获胜者访谈/博客文章。它们非常有帮助，特别是那些与你正在做的比赛有一些相似之处的比赛。**

1.  当你取得了相当不错的分数（例如 10% ~ 20%）或你觉得新特征的空间不大时（这通常是错误的），开始做集成方法。

1.  如果你认为你可能有机会赢得奖品，尝试组队！

1.  **不要在比赛结束前放弃。至少每天尝试一些新的东西。**

1.  从比赛结束后的顶级团队分享中学习。反思你的方法。**如果可能，花些时间验证你所学到的东西。**

1.  休息一下吧！

### 参考

1.  [以简单的方式击败 Kaggle - 董颖](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiPxZHewLbMAhVKv5QKHb3PCGwQFggcMAA&url=http%3A%2F%2Fwww.ke.tu-darmstadt.de%2Flehre%2Farbeiten%2Fstudien%2F2015%2FDong_Ying.pdf&usg=AFQjCNE9o2BcEkqdnu_-lQ3EFD3eRAFWiw&sig2=oiU8TCEH57EYF9v9l6Scrw&bvm=bv.121070826,d.dGo)

1.  [搜索结果相关性获胜者访谈：第一名，陈成龙](https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md)

1.  [(中文) 预测人寿保险评估的解决方案 - Nutastray](http://rstudio-pubs-static.s3.amazonaws.com/158725_5d2f977f4004490e9b095c0ef9357c6b.html)

![Linghao Zhang](../Images/47effce75b02d75ca99360d2793970ea.png)**简介： [Linghao Zhang](https://www.linkedin.com/in/linghaozh)** 是复旦大学计算机科学的高年级学生和 Strikingly 的数据挖掘工程师。他的兴趣包括机器学习、数据挖掘、自然语言处理、知识图谱和大数据分析。

[原文](https://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)。经授权转载。

**相关：**

+   [解决（几乎）任何机器学习问题](/2016/08/approaching-almost-any-machine-learning-problem.html)

+   [自动化数据科学与机器学习：与 Auto-sklearn 团队的采访](/2016/10/interview-auto-sklearn-automated-data-science-machine-learning-team.html)

+   [数据科学基础：集成学习者简介](/2016/11/data-science-basics-intro-ensemble-learners.html)

### 更多相关内容

+   [LinkedIn 如何使用机器学习来排名你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)

+   [如何在没有工作经验的情况下获得你的第一份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [它活了！用 Python 和一些便宜的基础组件构建你的第一个机器人](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)

+   [从零到英雄：使用 PyTorch 创建你的第一个 ML 模型](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)

+   [部署你的第一个机器学习模型](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)
