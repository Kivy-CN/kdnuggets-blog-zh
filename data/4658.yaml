- en: Analyzing Tweets with NLP in Minutes with Spark, Optimus and Twint
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用Spark、Optimus和Twint在几分钟内分析推文
- en: 原文：[https://www.kdnuggets.com/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html](https://www.kdnuggets.com/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html](https://www.kdnuggets.com/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html?page=2#comments)![figure-name](../Images/158845770b9097a4963776d6c8df466e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html?page=2#comments)![figure-name](../Images/158845770b9097a4963776d6c8df466e.png)'
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: If you are here it’s likely that you are interested in analyzing tweets (or
    something similar) and you have a lot of them, or can get them. One of the most
    annoying things for that is getting a Twitter application, get the authentication
    and all of that. And then if you are using Pandas, there’s no way to scale that.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你来这里，很可能是因为你对分析推文（或类似内容）感兴趣，并且你有很多推文，或者可以获取它们。为此，最烦人的事情之一就是获取Twitter应用程序，获取身份验证等等。如果你使用Pandas，那根本无法扩展。
- en: So what about a system that doesn’t have to authenticate with the Twitter API,
    that can get an unlimited (well almost) amount of tweets and the power to analyze
    them, with NLP and more. Well you’re in for a treat because that’s exactly what
    I’m going to show you right now.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，怎样的系统无需通过Twitter API进行身份验证，能够获取几乎无限量的推文，并且具备分析它们的能力，包括NLP等功能。好吧，你将会很高兴，因为这正是我现在要展示给你的。
- en: Getting the project and repo
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取项目和代码库
- en: '![figure-name](../Images/0afff08895ea09d9967d745fe9c90c7f.png)[https://matrixds.com/](https://matrixds.com/)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/0afff08895ea09d9967d745fe9c90c7f.png)[https://matrixds.com/](https://matrixds.com/)'
- en: 'You can follow everything I’m going to show you very easily. Just forklift
    this MatrixDS project:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以很容易地跟随我将要展示的一切。只需获取这个MatrixDS项目：
- en: '[**MatrixDS | The Data Project Workbench**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[**MatrixDS | 数据项目工作台**](https://www.kdnuggets.com/2019/05/analyzing-tweets-nlp-spark-optimus-twint.html)'
- en: '*MatrixDS is a place to build, share and manage data projects at any scale.*community.platform.matrixds.com](https://community.platform.matrixds.com/community/project/5ccc9c4b3175e0603c394444/files)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*MatrixDS是一个用于构建、共享和管理各种规模的数据项目的地方。* [community.platform.matrixds.com](https://community.platform.matrixds.com/community/project/5ccc9c4b3175e0603c394444/files)'
- en: '![figure-name](../Images/49dc0eb58479ce87d4d33757b68ce13e.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/49dc0eb58479ce87d4d33757b68ce13e.png)'
- en: 'Also there’s a GitHub repo with everything:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个GitHub代码库，其中包含所有内容：
- en: '[**FavioVazquez/twitter_optimus_twint**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[**FavioVazquez/twitter_optimus_twint**](https://github.com/FavioVazquez/twitter_optimus_twint)'
- en: '*Analyzing tweets with Twint, Optimus and Apache Spark. - FavioVazquez/twitter_optimus_twint*github.com](https://github.com/FavioVazquez/twitter_optimus_twint)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用Twint、Optimus和Apache Spark分析推文。 - FavioVazquez/twitter_optimus_twint* [github.com](https://github.com/FavioVazquez/twitter_optimus_twint)'
- en: With MatrixDS you can actually run the notebooks, get the data and run the analysis
    for free, so if you want to learn more please do it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MatrixDS，你实际上可以免费运行笔记本，获取数据并进行分析，如果你想了解更多，请去尝试。
- en: Getting Twint and Optimus
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取Twint和Optimus
- en: '![figure-name](../Images/d49ee9761db3018624e8da2a75534fdd.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/d49ee9761db3018624e8da2a75534fdd.png)'
- en: Twint utilizes Twitter’s search operators to let you scrape Tweets from specific
    users, scrape Tweets relating to certain topics, hashtags & trends, or sort out
    *sensitive* information from Tweets like e-mail and phone numbers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Twint利用Twitter的搜索操作符，让你可以从特定用户那里抓取推文，抓取与某些主题、标签和趋势相关的推文，或者筛选推文中的*敏感*信息，如电子邮件和电话号码。
- en: With Optimus, a library I co-created, you can clean your data, prepare it, analyze
    it, create profilers and plots, and perform machine learning and deep learning,
    all in a distributed fashion, because on the back-end we have Spark, TensorFlow,
    Sparkling Water and Keras.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我共同创建的库Optimus，你可以清理数据、准备数据、分析数据、创建分析器和图表，并进行机器学习和深度学习，所有这些操作都是分布式的，因为我们在后台使用了Spark、TensorFlow、Sparkling
    Water和Keras。
- en: 'So let’s first install everything you need, for that when you are in the Matrix
    project, go to the Analyze Tweets notebook and run (you can also do this from
    the JupyterLab terminal):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所以首先安装你需要的一切，当你在Matrix项目中时，转到“分析推文”笔记本并运行（你也可以从JupyterLab终端执行此操作）：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After that, we need to install Twint, for that run:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要安装Twint，为此运行：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will download a scr/ folder so we need to do some config:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这将下载一个scr/文件夹，因此我们需要进行一些配置：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then to import Twint that we need to run:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后要导入Twint，我们需要运行：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'and finally:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Optimus was installed in the first step, so let’s just start it (this will
    start a Spark cluster for you):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Optimus 在第一步中已安装，所以让我们启动它（这将为你启动一个 Spark 集群）：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Setup Twint for scrapping tweets
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置 Twint 以抓取推文
- en: '![figure-name](../Images/c6d42439029e2f5090ec93963e5d389c.png)[https://www.theverge.com/2015/11/3/9661180/twitter-vine-favorite-fav-likes-hearts](https://www.theverge.com/2015/11/3/9661180/twitter-vine-favorite-fav-likes-hearts)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/c6d42439029e2f5090ec93963e5d389c.png)[https://www.theverge.com/2015/11/3/9661180/twitter-vine-favorite-fav-likes-hearts](https://www.theverge.com/2015/11/3/9661180/twitter-vine-favorite-fav-likes-hearts)'
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you are running this on notebooks you’ll need also to run:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在笔记本上运行这个，你还需要运行：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Search for data science tweets
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索数据科学的推文
- en: '![figure-name](../Images/15d7cd1e1b1b0ee760bfebf1484940b4.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/15d7cd1e1b1b0ee760bfebf1484940b4.png)'
- en: I’ll start our analysis scrapping tweets about data science, you can change
    this to whatever you want.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我将开始我们的分析，抓取关于数据科学的推文，你可以将其更改为任何你想要的内容。
- en: 'For doing that we just need to run this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们只需运行以下代码：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let me explain this code to you. In the last section when we ran the code:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我解释一下这段代码。在上一个部分，当我们运行代码时：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'we started a new Twint configuration. After that we need to pass different
    options we want to scrape tweets. Here’s the full list of configuring options:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始了新的 Twint 配置。之后，我们需要传递不同的选项来抓取推文。以下是完整的配置选项列表：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So in this code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中：
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We are setting the search term, them formatting the response (just to check),
    getting only 20 tweets with the Limit =1 (they are in increments of 20) and finally
    making the result compatible with Pandas.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在设置搜索词，然后格式化响应（仅供检查），仅获取 20 条推文，限制 = 1（推文以 20 为增量），最后使结果与 Pandas 兼容。
- en: 'Then when we run:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后当我们运行：
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We are launching the search. The result is:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在启动搜索。结果是：
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Doesn’t look that good but we got what we wanted. TWEETS!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不是很好，但我们得到了我们想要的。推文！
- en: Saving results into Pandas
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将结果保存到 Pandas
- en: '![figure-name](../Images/4b2054e82dc2febdc44394a2b860dfc3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/4b2054e82dc2febdc44394a2b860dfc3.png)'
- en: Sadly there’s no direct connection between Twint and Spark, but we can do it
    with Pandas and then pass the result to Optimus.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Twint 和 Spark 之间没有直接连接，但我们可以使用 Pandas，然后将结果传递给 Optimus。
- en: 'I created to simple functions that you can see in the actual project that helps
    you with Pandas and the weird Twint API for this part. So when we run this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了两个简单的函数，你可以在实际项目中看到，它们可以帮助你处理 Pandas 和这个奇怪的 Twint API。所以当我们运行这个：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You’ll see:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到：
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'These are the columns we have from the query we just did. There’s a lot of
    different things to do with this data, but for this article I’ll only use some
    of them. So to transform the result from Twint to Pandas we run:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们刚刚从查询中得到的列。这个数据有很多不同的处理方式，但在这篇文章中，我只会使用其中的一些。因此，为了将结果从 Twint 转换为 Pandas，我们运行：
- en: '[PRE18]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'and you’ll see this Pandas DF:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到这个 Pandas DF：
- en: '![figure-name](../Images/16619ee77856d1eb13a972582d73bc74.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/16619ee77856d1eb13a972582d73bc74.png)'
- en: Much better isn’t it?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要好得多，不是吗？
- en: Sentiment Analysis (the simple way)
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情感分析（简单方法）
- en: '![figure-name](../Images/67b470446e10c47f12b1b93ad24a8739.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/67b470446e10c47f12b1b93ad24a8739.png)'
- en: We will run a sentiment analysis on some tweets, using Optimus and TextBlob
    a library for NLP. The first thing we need to do is clean this tweets, for that
    Optimus is the best choice.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对一些推文进行情感分析，使用 Optimus 和 TextBlob 这个 NLP 库。我们需要做的第一件事是清理这些推文，对于这个任务，Optimus
    是最佳选择。
- en: 'For saving the data as an Optimus (Spark) DF we need to run:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据保存为 Optimus（Spark）DF，我们需要运行：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We’ll just remove accents and special characters with Optimus (for a real work
    scenario you need to do much more than this like removing links, images, and stopwords),
    for that:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用 Optimus 删除重音和特殊字符（对于实际工作场景，你需要做更多的工作，比如删除链接、图片和停用词），为此：
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then we need to collect this tweets from Spark to get them in a Python list,
    for that:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要从 Spark 收集这些推文，以便将它们放入 Python 列表中，为此：
- en: '[PRE21]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then to analyze the sentiment of these tweets we will use TextBlob *sentiment*
    function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了分析这些推文的情感，我们将使用 TextBlob 的*情感*函数：
- en: '[PRE22]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'That will give us:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们：
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Neutral
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 中立
- en: '[PRE25]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Neutral
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 中立
- en: '[PRE26]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Positive
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 正面
- en: '[PRE27]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Neutral
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 中立
- en: '[PRE28]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Negative
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 负面
- en: '[PRE29]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Positive
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正面
- en: '[PRE30]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Neutral
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 中立
- en: '[PRE31]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Positive
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正面
- en: '[PRE32]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Negative
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 负面
- en: '[PRE33]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Positive
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正面
- en: '[PRE34]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Neutral
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 中立
- en: '[PRE35]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Neutral.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 中立。
- en: And so on.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如此等等。
- en: Well that was extremely easy, but it won’t scale, because in the end we are
    collecting the data from Spark so the driver’s RAM is the limit. Let’s do it a
    little better.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这非常简单，但它不会扩展，因为最终我们从 Spark 收集数据，所以驱动程序的 RAM 是限制。让我们做得更好一点。
- en: '* * *'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Analyzing Scientific Articles with fine-tuned SciBERT NER Model and Neo4j](https://www.kdnuggets.com/2021/12/analyzing-scientific-articles-finetuned-scibert-ner-model-neo4j.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用微调的 SciBERT NER 模型和 Neo4j 分析科学文章](https://www.kdnuggets.com/2021/12/analyzing-scientific-articles-finetuned-scibert-ner-model-neo4j.html)'
- en: '[Data Analytics: The Four Approaches to Analyzing Data and How To…](https://www.kdnuggets.com/2023/04/data-analytics-four-approaches-analyzing-data-effectively.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据分析：四种数据分析方法及其如何…](https://www.kdnuggets.com/2023/04/data-analytics-four-approaches-analyzing-data-effectively.html)'
- en: '[Analyzing the Probability of Future Success with Intelligence…](https://www.kdnuggets.com/2022/02/analyzing-probability-future-success-intelligence-node-attributes-evolution-model.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用智能分析未来成功的概率…](https://www.kdnuggets.com/2022/02/analyzing-probability-future-success-intelligence-node-attributes-evolution-model.html)'
- en: '[Analyzing Diversity & Inclusion with SQL](https://www.kdnuggets.com/2022/11/analyzing-diversity-inclusion-sql.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 SQL 分析多样性和包容性](https://www.kdnuggets.com/2022/11/analyzing-diversity-inclusion-sql.html)'
- en: '[Master the Power of Data Analytics: The Four Approaches to Analyzing Data](https://www.kdnuggets.com/2023/03/master-power-data-analytics-four-approaches-analyzing-data.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据分析的力量：四种数据分析方法](https://www.kdnuggets.com/2023/03/master-power-data-analytics-four-approaches-analyzing-data.html)'
- en: '[Build AI Chatbot in 5 Minutes with Hugging Face and Gradio](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 5 分钟内使用 Hugging Face 和 Gradio 构建 AI 聊天机器人](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
