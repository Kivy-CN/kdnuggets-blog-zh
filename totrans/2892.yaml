- en: Scikit-Learn vs mlr for Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/09/scikit-learn-mlr-machine-learning.html](https://www.kdnuggets.com/2019/09/scikit-learn-mlr-machine-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4b0bc0e253bafaade27861da7aedba31.png)'
  prefs: []
  type: TYPE_IMG
- en: Scikit-Learn is known for its easily understandable API for Python users, and
    MLR became an alternative to the popular Caret package with a larger suite of
    available algorithms and an easy way of tuning hyperparameters. These two packages
    are somewhat in competition due to the debate where many people involved in analytics
    turn to Python for machine learning and R for statistical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: One of the reasons for a preference in using Python could be that current R
    packages for machine learning are provided via other packages that contain the
    algorithm. The packages are called through MLR but still require extra installation.
    Even external feature selection libraries are needed, and they will have other
    external dependencies that need to be satisfied as well.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn is dubbed as a unified API to a number of machine learning algorithms
    that do not require the user to call any more libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '**This by no means discredits R.** R is still a major component in the data
    science world regardless of what an online poll would say. Anyone with a background
    in Statistics and or Mathematics will know why you should use R (regardless of
    whether they use it themselves they recognize the appeal).'
  prefs: []
  type: TYPE_NORMAL
- en: Now we will take a look at how a user would go through a typical machine learning
    workflow. We will proceed with Logistic Regression in Scikit-Learn and Decision
    Tree in MLR.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating Your Training and Test Data**'
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x_train, x_test, y_train, y_test = train_test_split(x,y,test_size)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the simplest way to partition datasets in sci-kit learn. The test_size
    is to determine what percentage of the data goes into the test set. train_test_split
    will create a train and test set automatically in one line of code. x is the set
    of features and y is the target variable.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train <- sample(1:nrow(data), 0.8 * nrow(data))`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test <- setdiff(1:nrow(train), train)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR does not have an in-built function to subset datasets, so users need to
    rely on other R functions for this. This is an example of creating an 80/20 train
    test set.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Choosing an Algorithm**'
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LogisticRegression()`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The classifier is simply chosen and initialized by calling an obviously named
    function that makes it easy to identify.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`makeLearner(''classif.rpart'')` The algorithm is called a learner, and this
    function is called to initialize it.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`makeClassifTask(data=, target=)` If we are doing classification, we need to
    make a call to initialize a classification task. This function will take two arguments:
    your training data and the name of the target variable.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hyperparameter Tuning**'
  prefs: []
  type: TYPE_NORMAL
- en: In either package, there is a process to follow when tuning hyperparameters.
    You first need to specify which parameters you want to change and the space of
    those parameters. Then conduct either a grid search or random search to find the
    best combination of parameter estimates that give you the best outcome (i.e.,
    either minimize error or maximize accuracy).
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`penalty = [''l2'']`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C = np.logspace(0, 4, 10)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dual= [False]`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_iter= [100,110,120,130,140]`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hyperparameters = dict(C=C, penalty=penalty, dual=dual, max_iter=max_iter)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GridSearchCV(logreg, hyperparameters, cv=5, verbose=0)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`clf.fit(x_train, y_train)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`makeParamSet( makeDiscreteParam("minsplit", values=seq(5,10,1)), makeDiscreteParam("minbucket",
    values=seq(round(5/3,0), round(10/3,0), 1)), makeNumericParam("cp", lower = 0.01,
    upper = 0.05), makeDiscreteParam("maxcompete", values=6), makeDiscreteParam("usesurrogate",
    values=0), makeDiscreteParam("maxdepth", values=10) )`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctrl = makeTuneControlGrid()`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rdesc = makeResampleDesc("CV", iters = 3L, stratify=TRUE)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tuneParams(learner=dt_prob, resampling=rdesc, measures=list(tpr,auc, fnr,
    mmce, tnr, setAggregation(tpr, test.sd)), par.set=dt_param, control=ctrl, task=dt_task,
    show.info = TRUE) )`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setHyperPars(learner, par.vals = tuneParams$x)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training**'
  prefs: []
  type: TYPE_NORMAL
- en: Both packages provide one line codes for trainig a model.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LogisticRegression().fit(x_train50, y_train50)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train(learner, task)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is arguably one of the simpler steps in the process. The most arduous step
    would be tuning hyperparameters and feature selection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prediction**'
  prefs: []
  type: TYPE_NORMAL
- en: Just like training the model, prediction can be done with one line of code.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`LogisticRegression().predict(x_test)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict(trained model, newdata)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scikit-learn will return an array of predicted labels while MLR will return
    a data frame of predicted labels.
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Evaluation**'
  prefs: []
  type: TYPE_NORMAL
- en: The most popular method for evaluating a supervised classifier will be a confusion
    matrix from which you can obtain accuracy, error, precision, recall etc.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`confusion_matrix(y_test, prediction)` OR'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`classification_report(y_test,prediction)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`performance(prediction, measures = list(tpr,auc,mmce, acc,tnr))` OR'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`calculateROCMeasures(prediction)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Both packages offer more than one method of obtaining a confusion matrix. **However,
    for an informative view in the easiest possible fashion, Python is not as informative
    as R. The first python code will only return a matrix with no labels. The user
    has to go back to the documentation to decipher which columns and rows correspond
    to which category.** The second method has a better and more informative output,
    but it will only generate precision, recall, F1 score, and support. This is also
    the more important performance measures in an imbalanced classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision Thresholding (i.e., Changing the Classification threshold)**'
  prefs: []
  type: TYPE_NORMAL
- en: A threshold in a classification problem is a given probability that classifies
    each instance into a predicted category. The default threshold would always be
    0.5 (i.e., 50%). This is a major point of difference when conducting machine learning
    in Python and R. R offers one-line-of-code solution to manipulating the threshold
    to account for class imbalances. Python does not have a built-in function for
    this and is up to the user to programmatically manipulate the threshold by defining
    their custom scripts/functions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/48225c67de6b8769d9300f4c0ff33966.png)'
  prefs: []
  type: TYPE_IMG
- en: A pair of graphs showing decision thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-Learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no one standard way of thresholding in Scikitlearn. Check out this
    article for one way that you can implement it yourself: **Fine-tuning a Classifier
    in Scikit-Learn**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: MLR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setThreshold(prediction, threshold)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This one line of code in mlr will automatically change your threshold and can
    be passed as an argument to calculate your new performance metrics (i.e., confusion
    matrix)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the end, both MLR and Scikit-Learn have their pros and cons when dealing
    with machine learning. Our comparison focused on using either one for machine
    learning and does not serve as a reason to use one instead of the other. Knowing
    both is what can give a true competitive advantage to someone in the field. The
    conceptual understanding of the process will make it easier to use either tool.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://blog.exxactcorp.com/scikitlearn-vs-mlr-for-machine-learning/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[A Beginner’s Guide to Linear Regression in Python with Scikit-Learn](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Linear Regression for Predictive Modeling in R](https://www.kdnuggets.com/2018/06/linear-regression-predictive-modeling-r.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What you need to know: The Modern Open-Source Data Science/Machine Learning
    Ecosystem](https://www.kdnuggets.com/2019/06/top-data-science-machine-learning-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, December 14: 3 Free Machine Learning Courses for…](https://www.kdnuggets.com/2022/n48.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Machine Learning Skills Every Machine Learning Engineer Should…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Breaking the Data Barrier: How Zero-Shot, One-Shot, and Few-Shot…](https://www.kdnuggets.com/2023/08/breaking-data-barrier-zeroshot-oneshot-fewshot-learning-transforming-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Federated Learning: Collaborative Machine Learning with a Tutorial…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
