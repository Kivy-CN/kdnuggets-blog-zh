- en: 'Enhancing LLM Reasoning: Unveiling Chain of Code Prompting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/enhancing-llm-reasoning-unveiling-chain-of-code-prompting](https://www.kdnuggets.com/enhancing-llm-reasoning-unveiling-chain-of-code-prompting)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Enhancing LLM Reasoning: Unveiling Chain of Code Prompting](../Images/d823c899c7e1971459756d0f14197abe.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Image created by Author with DALL•E 3
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chain of Code (CoC) is a novel approach to interacting with language models,
    enhancing reasoning abilities through a blend of code writing and selective code
    emulation.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoC extends the capabilities of language models in logic, arithmetic, and linguistic
    tasks, especially those requiring a combination of these skills.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With CoC, language models write code and also emulate parts of it that cannot
    be compiled, offering a unique approach to solving complex problems.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoC shows effectiveness for both large and small LMs.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: The key idea is to encourage LMs to format linguistic sub-tasks in a program
    as flexible pseudocode that the compiler can explicitly catch undefined behaviors
    and hand off to simulate with an LM (as an 'LMulator').
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New language model (LM) prompting, communication, and training techniques keep
    emerging to enhance the LM reasoning and performance capabilities. One such emergence
    is the development of the [Chain of Code (CoC)](https://arxiv.org/abs/2312.04474),
    a method intended to advance code-driven reasoning in LMs. This technique is a
    fusion of traditional coding and the innovative emulation of LM code execution,
    which creates a powerful tool for tackling complex linguistic and arithmetic reasoning
    tasks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: CoC is differentiated by its ability to handle intricate problems that blend
    logic, arithmetic, and language processing, which, as has been known to LM users
    for quite some time, has long been a challenging feat for standard LMs. CoC's
    effectiveness is not limited to large models but extends across various sizes,
    demonstrating versatility and broad applicability in AI reasoning.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![Enhancing LLM Reasoning: Unveiling Chain of Code Prompting](../Images/32bcfb05aca53e28692305b6b6e913b8.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1**: Chain of Code approach and process comparison (Image from paper)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Chain of Code
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: CoC is a paradigm shift in LM functionality; this is not a simple prompting
    tactic to increase the chance of eliciting the desired response from an LM. Instead,
    CoC redefines the the LM's approach to the aforementioned reasoning tasks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: At its core, CoC enables LMs to not only write code but also to emulate parts
    of it, especially those aspects that are not directly executable. This duality
    allows LMs to handle a broader range of tasks, combining linguistic nuances with
    logical and arithmetic problem-solving. CoC is able to format linguistic tasks
    as pseudocode, and effectively bridge the gap between traditional coding and AI
    reasoning. This bridging allows for a flexible and more capable system for complex
    problem-solving. The LMulator, a main component of CoC's increased capabilities,
    enables the simulation and interpretation of code execution output that would
    otherwise not be directly available to the LM.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: CoC has shown remarkable success across different benchmarks, significantly
    outperforming existing approaches like Chain of Thought, particularly in scenarios
    that require a mix of linguistic and computational reasoning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Experiments demonstrate that Chain of Code outperforms Chain of Thought and
    other baselines across a variety of benchmarks; on BIG-Bench Hard, Chain of Code
    achieves 84%, a gain of 12% over Chain of Thought.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Enhancing LLM Reasoning: Unveiling Chain of Code Prompting](../Images/882f6a27df262eaef84a64624292c6e3.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2**: Chain of Code performance comparison (Image from paper)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Chain of Code
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The implementation of CoC involves a distinctive approach to reasoning tasks,
    integrating coding and emulation processes. CoC encourages LMs to format complex
    reasoning tasks as pseudocode, which is then interpreted and solved. This process
    comprises multiple steps:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Identifying Reasoning Tasks: Determine the linguistic or arithmetic task that
    requires reasoning'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Code Writing: The LM writes pseudocode or flexible code snippets to outline
    a solution'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Emulation of Code: For parts of the code that are not directly executable,
    the LM emulates the expected outcome, effectively simulating the code execution'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Combining Outputs: The LM combines the results from both actual code execution
    and its emulation to form a comprehensive solution to the problem'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These steps allow LMs to tackle a broader range of reasoning questions by "thinking
    in code," thereby enhancing their problem-solving capabilities.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'The LMulator, as part of the CoC framework, can significantly aid in refining
    both code and reasoning in a few specific ways:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Error Identification and Simulation: When a language model writes code that
    contains errors or non-executable parts, the LMulator can simulate how this code
    might behave if it were to run, revaling logical errors, infinite loops, or edge
    cases, and guiding the LM to rethink and adjust the code logic.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Handling Undefined Behaviors: In cases where the code involves undefined or
    ambiguous behavior that a standard interpreter cannot execute, the LMulator uses
    the language model''s understanding of context and intent to infer what the output
    or behavior should be, providing a reasoned, simulated output where traditional
    execution would fail.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理未定义行为：在代码涉及标准解释器无法执行的未定义或模糊行为的情况下，LMulator 利用语言模型对上下文和意图的理解来推断输出或行为应该是什么，在传统执行失败的地方提供有理由的模拟输出。
- en: 'Improving Reasoning in Code: When a mix of linguistic and computational reasoning
    is required, the LMulator allows the language model to iterate over its own code
    generation, simulating the results of various approaches, effectively ''reasoning''
    through code, leading to more accurate and efficient solutions.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高代码推理能力：当需要语言和计算推理的混合时，LMulator 允许语言模型迭代其自身的代码生成，模拟各种方法的结果，实际上是在代码中进行‘推理’，从而得出更准确和高效的解决方案。
- en: 'Edge Case Exploration: The LMulator can explore and test how code handles edge
    cases by simulating different inputs, which is particularly useful in ensuring
    that the code is robust and can handle a variety of scenarios.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘案例探索：LMulator 可以通过模拟不同的输入来探索和测试代码如何处理边缘案例，这在确保代码的健壮性和能够处理各种场景方面特别有用。
- en: 'Feedback Loop for Learning: As the LMulator simulates and identifies issues
    or potential improvements in the code, this feedback can be used by the language
    model to learn and refine its approach to coding and problem-solving, which is
    an ongoing learning process that improves the model''s coding and reasoning capabilities
    over time.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习反馈循环：当 LMulator 模拟和识别代码中的问题或潜在改进时，这些反馈可以被语言模型用来学习和完善其编码和解决问题的方法，这是一个持续的学习过程，随着时间的推移提高模型的编码和推理能力。
- en: The LMulator enhances the language model's ability to write, test, and refine
    code by providing a platform for simulation and iterative improvement.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LMulator 通过提供一个模拟和迭代改进的平台，增强了语言模型编写、测试和完善代码的能力。
- en: Conclusion
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The CoC technique is an advancement in enhancing the reasoning abilities of
    LMs. CoC broadens the scope of problems LMs can tackle by integrating code writing
    with selective code emulation. This approach demonstrates the potential for AI
    to handle more complex, real-world tasks that require nuanced thinking. Importantly,
    CoC has proven to excel in both small and large LMs, enabling a pathway for the
    increasing array of smaller models to potentially improve their reasoning capabilities
    and bring their effectiveness closer to that of larger models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CoC 技术是提升语言模型推理能力的进步。CoC 通过将代码编写与选择性代码仿真相结合，拓宽了语言模型可以解决的问题范围。这一方法展示了 AI 处理需要细致思考的更复杂、现实世界任务的潜力。值得注意的是，CoC
    在小型和大型语言模型中均表现优异，为越来越多的小型模型提供了可能提升其推理能力并将其效果接近大型模型的途径。
- en: For a more in-depth understanding, [refer to the full paper here](https://arxiv.org/abs/2312.04474).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解，请[参考完整论文](https://arxiv.org/abs/2312.04474)。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[马修·梅奥](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为[KDnuggets](https://www.kdnuggets.com/)和[Statology](https://www.statology.org/)的主编，以及[Machine
    Learning Mastery](https://machinelearningmastery.com/)的特约编辑，Matthew 旨在使复杂的数据科学概念变得易于理解。他的职业兴趣包括自然语言处理、语言模型、机器学习算法以及探索新兴的人工智能。他的使命是普及数据科学领域的知识。Matthew
    从6岁开始编程。'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Unraveling the Power of Chain-of-Thought Prompting in Large Language Models](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlocking GPT-4 Summarization with Chain of Density Prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Orca LLM: Simulating the Reasoning Processes of ChatGPT](https://www.kdnuggets.com/2023/06/orca-llm-reasoning-processes-chatgpt.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Research-Driven Advanced Prompting Techniques for LLM Efficiency…](https://www.kdnuggets.com/3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unveiling the Potential of CTGAN: Harnessing Generative AI for…](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unveiling Unsupervised Learning](https://www.kdnuggets.com/unveiling-unsupervised-learning)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
