- en: Data Cleaning and Preprocessing for Beginners
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗与预处理入门
- en: 原文：[https://www.kdnuggets.com/2019/11/data-cleaning-preprocessing-beginners.html](https://www.kdnuggets.com/2019/11/data-cleaning-preprocessing-beginners.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/11/data-cleaning-preprocessing-beginners.html](https://www.kdnuggets.com/2019/11/data-cleaning-preprocessing-beginners.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Sciforce](https://sciforce.solutions).**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Sciforce](https://sciforce.solutions) 提供。**'
- en: When our team’s [project](https://arxiv.org/abs/1908.02505) scored first in
    the text subtask of this year’s CALL Shared Task challenge, one of the key components
    of our success was careful preparation and cleaning of data. Data cleaning and
    preparation is the most critical first step in any AI project. As evidence shows, [most
    data scientists spend most of their time — up to **70%** — on cleaning data](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#77d304176f63).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们团队的[项目](https://arxiv.org/abs/1908.02505)在今年的CALL共享任务挑战的文本子任务中获得第一名时，我们成功的关键因素之一是对数据的仔细准备和清理。数据清理和准备是任何AI项目中最关键的第一步。证据表明，[大多数数据科学家将大部分时间
    — 多达**70%** — 用于清理数据](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#77d304176f63)。
- en: In this blog post, we’ll guide you through these initial steps of data cleaning
    and preprocessing in Python, starting from importing the most popular libraries
    to actual encoding of features.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将引导你完成数据清理和预处理的初始步骤，从导入最流行的库到实际编码特征。
- en: '* * *'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT 管理'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Data cleansing**** or **data cleaning** is the process of detecting and
    correcting (or removing) corrupt or inaccurate records from a record set, table,
    or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant
    parts of the data and then replacing, modifying, or deleting the dirty or coarse
    data. //[**Wikipedia**](https://en.wikipedia.org/wiki/Data_cleansing)*'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***数据清洗***或**数据清理**是检测和纠正（或删除）记录集、表格或数据库中的损坏或不准确记录的过程，并指的是识别数据中不完整、不正确、不准确或不相关的部分，然后替换、修改或删除脏数据或粗糙数据。
    //[**维基百科**](https://en.wikipedia.org/wiki/Data_cleansing)*'
- en: Step 1\. Loading the data set
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：加载数据集
- en: '![](../Images/ad30e2684164aac3dcbd2a80f07f2552.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad30e2684164aac3dcbd2a80f07f2552.png)'
- en: '**Importing libraries**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**导入库**'
- en: The absolutely first thing you need to do is to import libraries for data preprocessing.
    There are lots of libraries available, but the most popular and important Python
    libraries for working on data are Numpy, Matplotlib, and Pandas. **Numpy** is
    the library used for all mathematical things. **Pandas** is the best tool available
    for importing and managing datasets. **Matplotlib** (Matplotlib.pyplot) is the
    library to make charts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要导入用于数据预处理的库。虽然有很多可用的库，但用于数据处理的最流行和重要的 Python 库是 Numpy、Matplotlib 和 Pandas。**Numpy**
    是用于所有数学操作的库。**Pandas** 是导入和管理数据集的最佳工具。**Matplotlib**（Matplotlib.pyplot）是用于制作图表的库。
- en: 'To make it easier for future use, you can import these libraries with a shortcut
    alias:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便将来使用，你可以使用快捷别名导入这些库：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Loading data into pandas**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**将数据加载到 pandas 中**'
- en: Once you downloaded your data set and named it as a .csv file, you need to load
    it into a pandas DataFrame to explore it and perform some basic cleaning tasks
    removing information you don’t need that will make data processing slower.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你下载了数据集并将其命名为 .csv 文件，你需要将其加载到 pandas DataFrame 中，以便探索数据并执行一些基本的清理任务，去除那些会使数据处理变慢的信息。
- en: 'Usually, such tasks include:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些任务包括：
- en: 'Removing the first line: it contains extraneous text instead of the column
    titles. This text prevents the data set from being parsed properly by the pandas
    library:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除第一行：它包含了额外的文本而不是列标题。这些文本会阻碍 pandas 库正确解析数据集：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Removing columns with text explanations that we won’t need, url columns and
    other unnecessary columns:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除我们不需要的文本解释列、网址列和其他不必要的列：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Removing all columns with only one value, or have more than 50% missing values
    to work faster (if your data set is large enough that it will still be meaningful):'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除所有只有一个值或缺失值超过50%的列，以便提高处理速度（如果你的数据集足够大，这样做仍然有意义）：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It’s also a good practice to name the filtered data set differently to keep
    it separate from the raw data. This makes sure you still have the original data
    in case you need to go back to it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，一个好的做法是将筛选后的数据集命名为不同的名称，以便与原始数据分开。这确保了你仍然保留了原始数据，以备需要时可以返回。
- en: Step 2\. Exploring the data set
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步。探索数据集
- en: '![](../Images/a236f09b6fbe813c2f84daf5c39f23b4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a236f09b6fbe813c2f84daf5c39f23b4.png)'
- en: '**Understanding the data**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**理解数据**'
- en: Now you have got your data set up, but you still should spend some time exploring
    it and understanding what feature each column represents. Such a manual review
    of the data set is important, to avoid mistakes in the data analysis and the modeling
    process.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经设置好了数据集，但你仍然应该花些时间来探索它并理解每一列代表的特征。对数据集进行手动检查是很重要的，以避免在数据分析和建模过程中出现错误。
- en: To make the process easier, you can create a DataFrame with the names of the
    columns, data types, the first row’s values, and description from the data dictionary.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化过程，你可以创建一个包含列名、数据类型、第一行的值和数据字典描述的 DataFrame。
- en: 'As you explore the features, you can pay attention to any column that:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在你探索特征时，可以注意任何列：
- en: is formatted poorly,
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格式不佳，
- en: requires more data or a lot of pre-processing to turn into useful a feature,
    or
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要更多数据或大量预处理才能转化为有用特征，或者
- en: contains redundant information,
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含冗余信息，
- en: since these things can hurt your analysis if handled incorrectly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这些问题处理不当会影响你的分析。
- en: '***You should also pay attention to data leakage***, which can cause the model
    to overfit. This is because the model will be also learning from features that
    won’t be available when we’re using it to make predictions. We need to be sure
    our model is trained using only the data it would have at the point of a loan
    application.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '***你还应该注意数据泄漏***，这可能导致模型过拟合。这是因为模型还会从在使用时无法获得的特征中学习。我们需要确保我们的模型只使用在贷款申请时能够获得的数据进行训练。'
- en: '**Deciding on a target column**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**确定目标列**'
- en: With a filtered data set explored, you need to create a matrix of dependent
    variables and a vector of independent variables. At first, you should decide on
    the appropriate column to use as a target column for modeling based on the question
    you want to answer. For example, if you're going to predict the development of
    cancer, or the chance the credit will be approved, you need to find a column with
    the status of the disease or loan granting ad use it as the target column.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索过筛选后的数据集后，你需要创建一个因变量矩阵和一个自变量向量。首先，你应该根据你想要回答的问题决定使用哪个列作为建模的目标列。例如，如果你想预测癌症的发展情况，或信用是否会被批准，你需要找到一个包含疾病状态或贷款批准状态的列，并将其用作目标列。
- en: 'For example, if the target column is the last one, you can create the matrix
    of dependent variables by typing:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果目标列是最后一列，你可以通过输入以下内容来创建因变量矩阵：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'That first colon (**:**) means that we want to take all the lines in our dataset. **:
    -1** means that we want to take all of the columns of data except the last one.
    The .**values** on the end means that we want all of the values.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '第一个冒号（**:**）表示我们想要获取数据集中的所有行。**: -1** 表示我们想要获取除最后一列外的所有数据列。**.values** 表示我们想要所有的值。'
- en: To have a vector of independent variables with only the data from the last column,
    you can type
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要拥有一个仅包含最后一列数据的自变量向量，你可以输入
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Step 3\. Preparing the Features for Machine Learning
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步。为机器学习准备特征
- en: '![](../Images/0ffa2ab48587877da91d164b39e5af97.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ffa2ab48587877da91d164b39e5af97.png)'
- en: Finally, it’s time to do the preparatory work to feed the features for ML algorithms.
    To clean the data set, you need to **handle missing values and categorical features**,
    because the mathematics underlying most machine learning models assumes that the
    data is numerical and contains no missing values. Moreover, the **scikit-learn** library
    returns an error if you try to train a model like linear regression and logistic
    regression using data that contain missing or non-numeric values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，到了为机器学习算法准备特征的数据清理工作。为了清理数据集，你需要**处理缺失值和类别特征**，因为大多数机器学习模型的数学基础假设数据是数值型的且没有缺失值。此外，`scikit-learn`库会在你尝试使用包含缺失值或非数值值的数据训练线性回归和逻辑回归模型时返回错误。
- en: '**Dealing with Missing Values**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理缺失值**'
- en: Missing data is perhaps the most common trait of unclean data. These values
    usually take the form of NaN or None.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据可能是数据不洁的最常见特征。这些值通常以NaN或None的形式存在。
- en: 'Here are several causes of missing values: sometimes values are missing because
    they do not exist, or because of improper collection of data or poor data entry.
    For example, if someone is underage, and the question applies to people over 18,
    then the question will contain a missing value. In such cases, it would be wrong
    to fill in a value for that question.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是缺失值的几种原因：有时值缺失是因为它们不存在，或由于数据收集不当或数据录入错误。例如，如果某人未成年，而问题适用于18岁以上的人群，那么问题将包含缺失值。在这种情况下，为该问题填补一个值是不正确的。
- en: 'There are several ways to fill up missing values:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 填补缺失值的方法有几种：
- en: you can remove the lines with the data if you have your data set is big enough
    and the percentage of missing values is high (over 50%, for example);
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据集足够大且缺失值的比例很高（例如超过50%），你可以删除包含数据的行；
- en: you can fill all null variables with 0 is dealing with numerical values;
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果处理的是数值型数据，你可以用0填补所有空变量；
- en: you can use the Imputerclass from the scikit-learn library to fill in missing
    values with the data’s (mean, median, most_frequent)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用来自`scikit-learn`库的Imputer类用数据的（均值、中位数、最频繁值）填补缺失值。
- en: you can also decide to fill up missing values with whatever value comes directly
    after it in the same column.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你还可以决定用同一列中紧接着的值填补缺失值。
- en: These decisions depend on the type of data, what you want to do with the data,
    and the cause of values missing. In reality, just because something is popular
    doesn’t necessarily make it the right choice. The most common strategy is to use
    the mean value, but depending on your data, you may come up with a totally different
    approach.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些决定取决于数据类型、你对数据的需求以及缺失值的原因。实际上，虽然某种方法很流行，但并不一定是正确的选择。最常见的策略是使用均值，但根据你的数据，你可能会找到完全不同的方法。
- en: '**Handling categorical data**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理类别数据**'
- en: 'Machine learning uses only numeric values (float or int data type). However,
    data sets often contain the object data type than needs to be transformed into
    numeric. In most cases, categorical values are discrete and can be encoded as
    dummy variables, assigning a number for each category. The simplest way is to
    use One Hot Encoder, specifying the index of the column you want to work on:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习仅使用数值型数据（浮点型或整数型）。然而，数据集通常包含需要转换为数值的对象数据类型。在大多数情况下，类别值是离散的，可以编码为虚拟变量，为每个类别分配一个数字。最简单的方法是使用One
    Hot Encoder，指定你要处理的列的索引：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Dealing with inconsistent data entry**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理不一致的数据录入**'
- en: Inconsistency occurs, for example, when there are different unique values in
    a column that are meant to be the same. You can think of different approaches
    to capitalization, simple misprints and inconsistent formats to form an idea.
    One of the ways to remove data inconsistencies is by to remove whitespaces before
    or after entry names and by converting all cases to lower cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 不一致性发生在例如，当列中存在不同的唯一值但这些值本应相同时。你可以考虑不同的大小写处理方法、简单的打印错误和不一致的格式，以形成一个概念。移除数据不一致性的方法之一是去除条目名称前后的空格，并将所有字符转换为小写。
- en: If there is a large number of inconsistent unique entries, however, it is impossible
    to manually check for the closest matches. You can use the [Fuzzy Wuzzy ](https://github.com/seatgeek/fuzzywuzzy)package
    to identify which strings are most likely to be the same. It takes in two strings
    and returns a ratio. The closer the ratio is to 100, the more likely you will
    unify the strings.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有大量不一致的唯一条目，手动检查最接近的匹配项是不可能的。你可以使用 [Fuzzy Wuzzy](https://github.com/seatgeek/fuzzywuzzy)
    包来识别最可能相同的字符串。它接收两个字符串并返回一个比率。比率越接近 100，字符串统一的可能性就越大。
- en: '**Handling Dates and Times**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**处理日期和时间**'
- en: A specific type of data inconsistency is the inconsistent format of dates, such
    as dd/mm/yy and mm/dd/yy in the same columns. Your date values might not be in
    the right data type, and this will not allow you effectively perform manipulations
    and get insight from it. This time you can use the [datetime](https://docs.python.org/2/library/datetime.html) package
    to fix the type of the date.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特定类型的数据不一致是日期格式的不一致，例如同一列中的 dd/mm/yy 和 mm/dd/yy。你的日期值可能不是正确的数据类型，这将使你无法有效地进行操作并从中获得洞察。这时你可以使用
    [datetime](https://docs.python.org/2/library/datetime.html) 包来修复日期的类型。
- en: '**Scaling and Normalization**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**缩放和归一化**'
- en: Scaling is important if you need to specify that a change in one quantity is
    not equal to another change in another. With the help of scaling you ensure that
    just because some features are big they won’t be used as the main predictor. For
    example, if you use the age and the salary of a person in prediction, some algorithms
    will pay attention to the salary more because it is bigger, which does not make
    any sense.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要指定一个量的变化不等于另一个量的变化，缩放是很重要的。借助缩放，你可以确保某些特征虽然很大，但不会被用作主要预测因子。例如，如果你在预测中使用一个人的年龄和薪水，一些算法会更关注薪水，因为它更大，这并没有意义。
- en: Normalization involves transforming or converting your dataset into a normal
    distribution. Some algorithms like SVM converge far faster on normalized data,
    so it makes sense to normalize your data to get better results.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化涉及将数据集转换为正态分布。一些算法如 SVM 在归一化数据上收敛得更快，因此归一化数据以获得更好的结果是有意义的。
- en: 'There are many ways to perform feature scaling. In a nutshell, we put all of
    our features into the same scale so that none are dominated by another. For example,
    you can use the [StandardScaler](https://scikit-learn.org/stable/modules/preprocessing.html) class
    from the sklearn.preprocessing package to fit and transform your data set:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以执行特征缩放。简而言之，我们将所有特征放在相同的尺度上，以便没有特征会被其他特征所主导。例如，你可以使用 [StandardScaler](https://scikit-learn.org/stable/modules/preprocessing.html)
    类来拟合和转换你的数据集：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Save to CSV**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**保存为 CSV**'
- en: To be sure that you still have the raw data, it is a good practice to store
    the final output of each section or stage of your workflow in a separate CSV file.
    In this way, you’ll be able to make changes in your data processing flow without
    having to recalculate everything.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保你仍然保留原始数据，将每个阶段或部分的最终输出存储在单独的 CSV 文件中是一个好习惯。这样，你可以在不重新计算所有内容的情况下对数据处理流程进行更改。
- en: As we did previously, you can store your DataFrame as a .csv using the pandas *to_csv()* function.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前做的，你可以使用 pandas *to_csv()* 函数将 DataFrame 存储为 .csv 文件。
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Conclusion
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: These are the very basic steps required to work through a large data set, cleaning
    and preparing the data for any Data Science project. There are other forms of
    data cleaning that you might find useful. But for now we want you to understand
    that you need to properly arrange and tidy up your data before the formulation
    of any model. Better and cleaner data outperforms the best algorithms. If you
    use a very simple algorithm on the cleanest data, you will get very impressive
    results. And, what is more, it is not that difficult to perform basic preprocessing!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是处理大型数据集、清洗和准备数据以用于任何数据科学项目所需的基本步骤。你可能会发现其他形式的数据清洗也很有用。但现在我们希望你理解，在任何模型的构建之前，你需要正确地整理和清理数据。更好、更干净的数据能超越最好的算法。如果你在最干净的数据上使用一个非常简单的算法，你会得到非常令人印象深刻的结果。而且，更重要的是，执行基本预处理并不难！
- en: '[Original](https://medium.com/sciforce/data-cleaning-and-preprocessing-for-beginners-25748ee00743).
    Reposted with permission.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/sciforce/data-cleaning-and-preprocessing-for-beginners-25748ee00743)。转载授权。'
- en: '**Bio: **[SciForce ](https://sciforce.solutions)is a Ukraine-based IT company
    specialized in development of software solutions based on science-driven information
    technologies. We have wide-ranging expertise in many key AI technologies, including
    Data Mining, Digital Signal Processing, Natural Language Processing, Machine Learning,
    Image Processing and Computer Vision.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：**[SciForce](https://sciforce.solutions)是一家总部位于乌克兰的 IT 公司，专注于基于科学驱动的信息技术的软件解决方案开发。我们在许多关键的人工智能技术领域拥有广泛的专业知识，包括数据挖掘、数字信号处理、自然语言处理、机器学习、图像处理和计算机视觉。'
- en: '**Related:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[7 Steps to Mastering Data Preparation for Machine Learning with Python — 2019
    Edition](https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握机器学习数据准备的 7 个步骤 — 2019 年版](https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html)'
- en: '[Simple Yet Practical Data Cleaning Codes](https://www.kdnuggets.com/2019/02/simple-yet-practical-data-cleaning-codes.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[简单但实用的数据清理代码](https://www.kdnuggets.com/2019/02/simple-yet-practical-data-cleaning-codes.html)'
- en: '[Notes on Feature Preprocessing: The What, the Why, and the How](https://www.kdnuggets.com/2018/10/notes-feature-preprocessing-what-why-how.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征预处理笔记：什么，为什么，如何](https://www.kdnuggets.com/2018/10/notes-feature-preprocessing-what-why-how.html)'
- en: More On This Topic
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费电子书学习数据清理和预处理数据科学](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 ChatGPT 进行自动化数据清理和预处理](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)'
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清理和预处理文本数据以进行 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[Easy Guide To Data Preprocessing In Python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 数据预处理的简单指南](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
- en: '[KDnuggets News, June 29: 20 Basic Linux Commands for Data Science…](https://www.kdnuggets.com/2022/n26.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，6 月 29 日：数据科学的 20 个基本 Linux 命令…](https://www.kdnuggets.com/2022/n26.html)'
