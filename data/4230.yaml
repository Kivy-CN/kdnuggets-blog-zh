- en: Linear Algebra for Natural Language Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理的线性代数
- en: 原文：[https://www.kdnuggets.com/2021/08/linear-algebra-natural-language-processing.html](https://www.kdnuggets.com/2021/08/linear-algebra-natural-language-processing.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/linear-algebra-natural-language-processing.html](https://www.kdnuggets.com/2021/08/linear-algebra-natural-language-processing.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Taaniya Arora](https://medium.com/@TaaniyaArora), Data Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Taaniya Arora](https://medium.com/@TaaniyaArora)，数据科学家**'
- en: '![](../Images/0865fd73b4005b8f794326168d6b677f.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0865fd73b4005b8f794326168d6b677f.png)'
- en: Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The field of Natural Language Processing involves building techniques to process
    text in natural language by people like you and me, and extract insights from
    it for performing a variety of tasks from interpreting user queries on search
    engines and returning web pages, to solving customer queries as chatbot assistant.
    The importance of representing every word into a form that captures the meaning
    of the word and the overall context becomes crucial especially when major decisions
    are based upon the insights extracted from text on a large scale — like forecasting
    stock price change with social media.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理领域涉及构建技术，以处理自然语言中的文本，并从中提取见解，以执行各种任务，从解释搜索引擎上的用户查询并返回网页，到作为聊天机器人助手解决客户查询。当依赖于从大规模文本中提取的见解做出重要决策时，例如通过社交媒体预测股票价格变化，
    将每个单词表示为捕捉单词意义和整体上下文的形式变得至关重要。
- en: In this article, we’ll begin with the basics of linear algebra to get an intuition
    of sof vectors and their significance for representing specific types of information,
    the different ways of representing text in vector space, and how the concept has
    evolved to the state of the art models we have now.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将从线性代数的基础开始，以了解向量及其在表示特定类型信息中的重要性、在向量空间中表示文本的不同方式，以及这一概念如何发展到我们现在拥有的最先进模型。
- en: We’ll step through the following areas -
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步介绍以下内容 -
- en: Unit vectors in our coordinate system
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们坐标系统中的单位向量
- en: Linear combination of vectors
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量的线性组合
- en: Span in vector coordinate system
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量坐标系统中的跨度
- en: Collinearity & multicollinearity
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共线性与多重共线性
- en: Linear dependence and independence of vectors
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量的线性依赖性和独立性
- en: Basis vectors
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础向量
- en: Vector Space Model for NLP
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自然语言处理的向量空间模型
- en: Dense Vectors
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密集向量
- en: Unit vectors in our coordinate system
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们坐标系统中的单位向量
- en: '***i***-> Denotes a unit vector (vector of length 1 unit) pointing in the x-direction'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '***i***-> 表示一个单位向量（长度为1单位），指向x方向'
- en: '***j***-> Denotes a unit vector in the y-direction'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '***j***-> 表示y方向上的单位向量'
- en: Together, they are called the basis of our coordinate vector space.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 它们共同构成了我们坐标向量空间的基础。
- en: We’ll come to the term **basis** more in the subsequent parts below.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下面的后续部分中进一步讨论**基础**这一术语。
- en: '![](../Images/099b26537ff5a6f1dda889bf00ce567d.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/099b26537ff5a6f1dda889bf00ce567d.png)'
- en: Standard Unit vectors — Image by Author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 标准单位向量 — 作者图片
- en: Suppose we have a vector 3***i***+ 5***j***
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设我们有一个向量 3***i***+ 5***j***
- en: 'This vector has x,y coordinates : 3 & 5 respectively'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个向量的x，y坐标分别是：3和5
- en: These coordinates are the scalars that flip and scale the unit vectors by 3
    & 5 units in the x & y directions respectively
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些坐标是将单位向量在x和y方向上分别缩放3和5单位的标量
- en: '![](../Images/ab03155c8441be62dbcb33f9a9f5a7d6.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab03155c8441be62dbcb33f9a9f5a7d6.png)'
- en: A vector in 2D X-Y space — Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 二维X-Y空间中的一个向量 — 作者图片
- en: Linear Combination of 2 vectors
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 两个向量的线性组合
- en: If ***u*** & ***v*** are two vectors in a 2 dimensional space,then their linear
    combination resulting into a vector ***l*** is represented by -
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果***u***和***v***是二维空间中的两个向量，则它们的线性组合生成一个向量***l***，表示为 -
- en: '***l*** = *x1.* ***u*** + *x2.* ***v***'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '***l*** = *x1.* ***u*** + *x2.* ***v***'
- en: The numbers *x1*, *x2* are the components of a vector x
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字*x1*，*x2*是向量x的分量
- en: This is essentially a scaling and addition operation by x on the given vectors.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这本质上是在给定向量上进行的缩放和加法操作。
- en: The above expression of linear combination is equivalent to the following linear
    system -
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上述线性组合的表达式等同于以下线性系统 -
- en: '**B*x*** = ***l***'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**B*x*** = ***l***'
- en: Where ***B*** denotes a matrix whose columns are ***u*** and ***v***.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其中***B***表示一个矩阵，其列为***u***和***v***。
- en: Let’s understand this by an example below with vectors ***u*** & ***v*** in
    a 2 dimensional space -
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过下面的示例来理解，在二维空间中的向量***u***和***v*** —
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/cb3e7ee2e66b9f581e0804970e01ac37.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb3e7ee2e66b9f581e0804970e01ac37.png)'
- en: Linear Combination of vectors — Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的线性组合 — 作者提供的图像
- en: We can also understand it from this explanation for a similar example with 3
    dimensions given by a Professor in his notes here -
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以从教授在他的笔记中给出的类似3维示例中理解这一点 -
- en: '![](../Images/209915af4612495ea4b870beb5a0f8e7.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/209915af4612495ea4b870beb5a0f8e7.png)'
- en: Linear Algebra, Chapter 1- Introduction to Vectors, MIT
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数，第1章- 向量简介，MIT
- en: Taking the 3 vectors from the example in the image and plotting them in 3D space
    (The units of axes are different than the vectors in the plot)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从示例中的3个向量绘制它们在3D空间中的图像（轴的单位与图中的向量不同）
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/bf63a365b492826b88939fcb5bc0d4e6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf63a365b492826b88939fcb5bc0d4e6.png)'
- en: Vectors in 3D space — Image by Author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 3D空间中的向量 — 作者提供的图像
- en: Span
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨度
- en: A span is a set of all possible combinations of vectors that we can reach with
    a linear combination of a given pair of vectors
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨度是通过给定一对向量的线性组合可以达到的所有可能的向量组合的集合。
- en: The span of most pairs of 2-D vectors is all vectors in the 2-D space. Except,
    when they line up in the same direction (i.e if they are collinear) , in which
    case, their span is a line.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数二维向量对的跨度是二维空间中的所有向量。除非它们沿相同方向排列（即共线），在这种情况下，它们的跨度是一条直线。
- en: i.e span( ***a***, ***b***) = **R² **(all vectors in 2D space) , provided they
    are not collinear.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 即 span(***a***, ***b***) = **R²**（二维空间中的所有向量），前提是它们不是共线的。
- en: Collinearity
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共线性
- en: Collinearity is the case when we have p different predictor variables but some
    of them are linear combinations of others, so they don’t add any other information.
    2 collinear vectors / variables will have correlation close to +/- 1 and can be
    detected by their correlation matrix.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 共线性是指当我们有p个不同的预测变量，但其中一些是其他变量的线性组合，因此它们不提供额外的信息时。两个共线向量/变量将具有接近+/-1的相关性，并且可以通过它们的相关矩阵检测到。
- en: '**Multicollinearity** exists when more than 2 vectors are collinear and any
    pair of vectors may not necessarily have high correlation.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当超过两个向量共线且任何一对向量可能没有高相关性时，就存在**多重共线性**。
- en: '**Linear Independence**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性独立性**'
- en: We say that *v1* , *v2*, . . . , *vn* are linearly independent, if none of them
    is
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说*v1*、*v2*、...、*vn*是线性独立的，如果它们之间没有
- en: a linear combination of the others. This is equivalent to saying
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 其他向量的线性组合。这等同于说
- en: that *x1.v1* + *x2.v2* + . . . + *xn.vn* = 0 implies *x1 = x2 = . . . = xn =
    0*
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 公式 *x1.v1* + *x2.v2* + ... + *xn.vn* = 0 表示 *x1 = x2 = ... = xn = 0*
- en: Since collinear vectors can be expressed as linear combinations of each other,
    they are **linearly dependent.**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于共线向量可以表示为彼此的线性组合，因此它们是**线性相关的**。
- en: '**Basis**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**基础**'
- en: A basis is that set of linearly independent vectors that span that space.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 基础是能够表示该空间的线性独立向量集合。
- en: We call these vectors as basis vectors
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称这些向量为基向量
- en: Vector space Models in NLP
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自然语言处理中的向量空间模型
- en: A **Vector space** is a set V of vectors, where two operations — vector addition
    and scalar multiplication are defined. For E.g. IF two vectors ***u*** & ***v*** are
    in space ***V***, then their sum, ***w = u + v*** will also lie in the vector
    space ***V***.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量空间**是一个向量集合V，其中定义了两个操作——向量加法和标量乘法。例如，如果两个向量***u***和***v***在空间***V***中，则它们的和***w
    = u + v***也将位于向量空间***V***中。'
- en: A 2D vector space is a set of linearly independent vasis vectors with 2 axes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个二维向量空间是一组具有2个轴的线性独立的基向量。
- en: Each axis represents a dimension in the vector space.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 每个轴表示向量空间中的一个维度。
- en: Recalling the previous plot of vector ***a*** = (3,5) = 3 ***i*** + 5 ***j*** again.
    This vector is represented on a 2D space with 2 linearly independent basis vectors
    — X & Y, who also represent the 2 axes as well as the 2 dimenions of the space.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 再次回顾之前的向量***a*** = (3,5) = 3 ***i*** + 5 ***j***。这个向量在二维空间中用两个线性独立的基向量 — X和Y表示，它们不仅代表2个轴，也代表空间的2个维度。
- en: 3 & 5 here are the x,y components of this vector for representation on the X-Y
    2D space.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的3和5是表示在X-Y二维空间中的该向量的x，y分量。
- en: '![](../Images/ab03155c8441be62dbcb33f9a9f5a7d6.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab03155c8441be62dbcb33f9a9f5a7d6.png)'
- en: Vector in 2D X-Y plane — Image by Author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 二维X-Y平面中的向量 — 作者提供的图像
- en: '**Vector space model in NLP**'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**自然语言处理中的向量空间模型**'
- en: A vector space model is a representation of text in vector space.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 向量空间模型是文本在向量空间中的表示。
- en: Here, each word in a corpus is a linearly independent basis vector and each
    basis vector represents an axis in the vector space.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，语料库中的每个词是线性独立的基向量，每个基向量表示向量空间中的一个轴。
- en: This means, each word is orthogonal to other words/axes.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这意味着每个词与其他词/轴是正交的。
- en: For a corpus of vocabulary ***|V|***, **R **will contain ***|V|*** axes.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个词汇语料库***|V|***，**R** 将包含***|V|*** 轴。
- en: Combination of terms represent documents as points or vectors in this space
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语的组合将文档表示为该空间中的点或向量。
- en: For 3 words, we’ll have a 3D vector model represented like this -
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 对于3个词，我们将有一个3D向量模型，如下所示 -
- en: '![](../Images/46eb924f89cb4d6ba86b226ab4c30f0a.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46eb924f89cb4d6ba86b226ab4c30f0a.png)'
- en: Vector Space Model for 3 words — Image by Author
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 3个词的向量空间模型——作者提供的图像
- en: The table above the graph represents the TF-IDF incident matrix.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的表格表示TF-IDF事件矩阵。
- en: '***D1*** = (0.91, 0, 0.0011) represents a document vector in the 3 axes — good,
    house, car. Similarly, we have ***D2*** & ***D3*** document vectors.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '***D1*** = (0.91, 0, 0.0011) 表示在三个轴——好、房子、车子——上的文档向量。同样，我们还有***D2***和***D3***文档向量。'
- en: How does representation in vector space help us, though?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，在向量空间中的表示如何帮助我们呢？
- en: One of the common application using this representation is information retrieval
    for search engines, question answering systems and much more.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用这种表示的一个常见应用是信息检索，用于搜索引擎、问答系统等。
- en: By representing the text into vectors, we aim to use vector algebra to extract
    semantics from the text and use it for different applications like searching documents
    containing the similar sementics as those contained in a given search query.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将文本表示为向量，我们旨在利用向量代数从文本中提取语义，并将其用于不同的应用，如搜索包含与给定搜索查询中包含的相似语义的文档。
- en: For eg. For a search token ‘buy’ , we would want to get all the documents containing
    different forms of this word — buying, bought and even synonyms of the word ‘buy’.
    Such documents can not be captured from other rudimentary methods representing
    documents as Binary [incident matrix](https://en.wikipedia.org/wiki/Incidence_matrix).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于搜索令牌‘buy’，我们希望获取包含该词不同形式——buying、bought，甚至‘buy’的同义词的所有文档。其他初级方法，如将文档表示为二进制[事件矩阵](https://en.wikipedia.org/wiki/Incidence_matrix)，无法捕捉到这些文档。
- en: This is achieved through distance metrics like cosine similarity between vectors
    of document & query, where the documents closer to the query are ranked the highest.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过如余弦相似度这样的距离度量实现的，通过文档和查询的向量之间的距离，距离查询更近的文档被排在更高的位置。
- en: The number of words / vocabulary size can be as huge as in millions eg. Google
    news corpus is 3 Million, which means as many independent axes/dimensions to represent
    the vectors. Hence, we want to use the operations in vector space to reduce the
    number of dimensions and bring words with similar to each other in the same axis.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词汇量/词汇大小可以大到几百万，例如，Google新闻语料库有300万条，这意味着有那么多独立的轴/维度来表示向量。因此，我们希望在向量空间中使用操作来减少维度数量，并将相似的词放在同一个轴上。
- en: Dense vectors
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密集向量
- en: The above operations are possible on document vectors which are represented
    by extending the above vector representation of documents to documents represented
    as distributed or dense vectors. These representations capture the semantics of
    the text and also captures the linear combinations of word vectors
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上述操作可以在文档向量上进行，这些向量通过将文档的上述向量表示扩展到分布式或密集向量表示的文档来表示。这些表示捕捉了文本的语义，并且也捕捉了词向量的线性组合。
- en: The previous vector space model with each word representing a separate dimension
    results in sparse vectors.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以前的向量空间模型中，每个词表示一个单独的维度，导致了稀疏向量。
- en: Dense vectors captures the context in the vector representation. The dense vector
    of words are such that words appearing in similar contexts will have similar representations.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密集向量捕捉了向量表示中的上下文。密集词向量的特点是，在类似上下文中出现的词将具有类似的表示。
- en: These dense vectors are also called as word embeddings or distributed representations.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些密集向量也称为词嵌入或分布式表示。
- en: word2vec is one such framework to **learn** dense vectors of words from large
    corpus. It has 2 variants — skip-gram and CBOW(continuous bag of words)
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: word2vec 是一个用于**学习** 从大规模语料库中获得词密集向量的框架。它有两个变体——skip-gram 和 CBOW（连续词袋模型）。
- en: Some of the other frameworks and techniques to obtain dense vectors are Global
    Vectors(GloVe), fastText, ELMo(Embeddings from Language Model) and most recent
    state of the art Bert based approached to obtain contextualized word embeddings
    during inference.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他获取稠密向量的框架和技术包括全球向量（GloVe）、fastText、ELMo（语言模型中的嵌入）和最近的最先进Bert基于方法，用于在推理过程中获取上下文化的词嵌入。
- en: Conclusion
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This article introduced the concept of vector space based on linear algebra
    and highlighted the related concepts as part of their application in Natural Language
    Processing for representing text documents in semantics representation and extraction
    tasks.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了基于线性代数的向量空间概念，并强调了相关概念在自然语言处理中的应用，如文本语义表示和抽取任务。
- en: The applications of word embeddings have been extended to more advanced and
    wide applications with much improved performance than earlier.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入的应用已经扩展到更多先进的广泛应用，其性能比以前有了显著提升。
- en: You can also refer to the source code and run on colab by accessing my [Git
    repository here](https://github.com/Taaniya/linear-algebra-for-ml).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过访问我的 [Git 仓库](https://github.com/Taaniya/linear-algebra-for-ml) 来参考源代码并在
    colab 上运行。
- en: Hope you enjoyed reading it. :)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢阅读这篇文章。 :)
- en: References
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[Linear Independence, Basis & Dimension, MIT](https://www.youtube.com/watch?v=eeMJg4uI7o0)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性独立性、基与维度，MIT](https://www.youtube.com/watch?v=eeMJg4uI7o0)'
- en: '[Matrices-Introduction to Vectors, MIT](https://math.mit.edu/~gs/linearalgebra/linearalgebra5_1-3.pdf)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[矩阵-向量介绍，MIT](https://math.mit.edu/~gs/linearalgebra/linearalgebra5_1-3.pdf)'
- en: '[Vector space models for NLP, NPTEL](https://www.youtube.com/watch?v=6Nz88LHOIdo)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NLP的向量空间模型，NPTEL](https://www.youtube.com/watch?v=6Nz88LHOIdo)'
- en: An introduction to statistical learning, E-Book by Gareth James, Daniela Witten,
    Trevor Hastie and Robert Tibshirani
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gareth James, Daniela Witten, Trevor Hastie 和 Robert Tibshirani 的统计学习介绍，电子书
- en: '**Bio: [Taaniya Arora](https://medium.com/@TaaniyaArora)** is a Data Scientist
    and problem solver, especially interested in NLP and reinforcement learning.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Taaniya Arora](https://medium.com/@TaaniyaArora)** 是一位数据科学家和问题解决者，尤其对NLP和强化学习感兴趣。'
- en: '[Original](https://towardsdatascience.com/from-linear-algebra-to-text-representation-for-natural-language-processing-239cd3ccb12f).
    Reposted with permission.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/from-linear-algebra-to-text-representation-for-natural-language-processing-239cd3ccb12f)。转载授权。'
- en: '**Related:**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The Best SOTA NLP Course is Free!](/2021/07/best-sota-nlp-course-free.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最佳SOTA NLP课程是免费的!](/2021/07/best-sota-nlp-course-free.html)'
- en: '[Essential Linear Algebra for Data Science and Machine Learning](/2021/05/essential-linear-algebra-data-science-machine-learning.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学与机器学习中的基本线性代数](/2021/05/essential-linear-algebra-data-science-machine-learning.html)'
- en: '[How To Overcome The Fear of Math and Learn Math For Data Science](/2021/03/overcome-fear-learn-math-data-science.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何克服数学恐惧并学习数据科学中的数学](/2021/03/overcome-fear-learn-math-data-science.html)'
- en: '* * *'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT工作'
- en: '* * *'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[N-gram Language Modeling in Natural Language Processing](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理中的N-gram语言建模](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
- en: '[Natural Language Processing Key Terms, Explained](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理关键术语解释](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
- en: '[Data Representation for Natural Language Processing Tasks](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理任务的数据表示](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像识别和自然语言处理的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
- en: '[How to Start Using Natural Language Processing With PyTorch](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何开始使用 PyTorch 进行自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
- en: '[A Gentle Introduction to Natural Language Processing](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的温和入门](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)'
