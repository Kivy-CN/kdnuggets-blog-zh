# 数据可观察性，第二部分：如何使用SQL构建自己的数据质量监控工具

> 原文：[https://www.kdnuggets.com/2021/02/data-observability-part-2-build-data-quality-monitors-sql.html](https://www.kdnuggets.com/2021/02/data-observability-part-2-build-data-quality-monitors-sql.html)

[评论](#comments)

**由[巴尔·摩西](https://www.linkedin.com/in/barrmoses/)，Monte Carlo首席执行官兼联合创始人及[瑞安·基恩斯](https://www.linkedin.com/in/ryan-kearns-203686a9)，Monte Carlo机器学习工程师**

*在这篇文章系列中，我们将逐步介绍如何从头开始创建自己的数据可观察性监控工具，映射到*[***数据健康的五大关键支柱***](https://towardsdatascience.com/introducing-the-five-pillars-of-data-observability-e73734b263d5)*。第一部分可以在*[*这里*](https://www.montecarlodata.com/data-observability-in-practice-using-sql-1/)*找到。*

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织进行IT

* * *

*这一系列的第二部分改编自巴尔·摩西和瑞安·基恩斯的O'Reilly培训，*[***管理数据停机：将可观察性应用于您的数据管道***](https://www.oreilly.com/live-training/courses/managing-data-downtime/0636920508717/)*，这是业内首个关于数据可观察性的课程。相关的练习可以在*[*这里*](https://github.com/monte-carlo-data/data-downtime-challenge)*找到，本文中展示的改编代码可以在*[*这里*](https://github.com/monte-carlo-data/data-observability-in-practice)*找到。*

随着全球对数据需求的增加，稳健的数据管道显得尤为重要。当数据出现故障——无论是由于模式变化、空值、重复还是其他原因——数据工程师需要了解。

最重要的是，我们需要快速评估故障的根本原因——在它影响下游系统和用户之前。我们使用“*[**数据停机**](https://towardsdatascience.com/the-rise-of-data-downtime-841650cedfd5)*”来指代数据丢失、错误或其他不准确的时间段。如果你是一名数据专业人士，你可能会熟悉以下问题：

+   数据是否最新？

+   数据是否完整？

+   字段是否在预期范围内？

+   空值率是否高于或低于应有水平？

+   模式是否发生了变化？

为了有效地回答这些问题，我们可以借鉴软件工程师的做法：[**监控和可观测性**](https://observability.workshop.aws/en/anomalydetection.html)**。**

为了刷新你的记忆，我们将**数据可观测性**定义为一个组织回答这些问题并评估其数据生态系统健康的能力。反映数据健康的关键变量，数据可观测性的五个支柱包括：

+   **新鲜度**：我的数据是否是最新的？是否存在数据未更新的时间间隔？

+   **分布**：我的数据在字段级别的健康状况如何？我的数据是否在预期范围内？

+   **数据量**：我的数据摄取是否达到了预期的阈值？

+   **模式**：我的数据管理系统的正式结构是否发生了变化？

+   **数据血缘**：如果我的一些数据出现了问题，上游和下游会受到什么影响？我的数据来源是如何相互依赖的？

在这一系列文章中，我们的兴趣在于揭开面纱，调查数据可观测性在**代码中**的表现。

在[Part I](https://medium.com/swlh/data-observability-building-your-own-data-quality-monitors-using-sql-a4c848b6882d)中，我们探讨了前两个支柱——新鲜度和分布，并展示了如何通过一些 SQL 代码将这些概念转化为实际操作。这些是我们称之为更“经典”的[**异常检测问题**](https://en.wikipedia.org/wiki/Anomaly_detection)——给定一个稳定的数据流，有什么东西看起来不对劲？良好的异常检测无疑是数据可观测性拼图的一部分，但并不是全部。

> 同样重要的是[***上下文***](https://www.montecarlodata.com/data-teams-your-metadata-is-useless/)。如果发生了异常，太好了。但发生在哪里？哪些上游管道可能是原因？哪些下游仪表盘会受到影响？以及我的数据的正式结构是否发生了变化？良好的数据可观测性依赖于我们正确利用元数据来回答这些问题——以及许多其他问题——以便我们能识别根本原因，并在问题变得更严重之前解决它。

在这篇文章中，我们将探讨旨在提供这些关键背景的两个数据可观测性支柱——**模式**和**数据血缘**。我们将再次使用轻量级工具如 Jupyter 和 SQLite，这样你可以轻松地启动我们的环境并亲自尝试这些练习。让我们开始吧。

### 我们的数据环境

*本教程基于*[*练习 2 和 3*](https://github.com/monte-carlo-data/data-downtime-challenge/blob/master/exercise_text/ex2.md)*，出自我们 O’Reilly 课程的*[*管理数据停机*](https://www.oreilly.com/live-training/courses/managing-data-downtime/0636920508717/)*。欢迎使用 Jupyter Notebook 和 SQL 自行尝试这些练习。我们将在未来的文章中深入探讨，包括练习*[*4*](https://github.com/monte-carlo-data/data-downtime-challenge/blob/master/exercise_text/ex4.md)*。

如果你阅读了[第一部分](https://medium.com/swlh/data-observability-building-your-own-data-quality-monitors-using-sql-a4c848b6882d)，你应该对我们的数据有所了解。和以前一样，我们将使用[模拟天文数据](https://github.com/monte-carlo-data/data-observability-in-practice/blob/main/EXOPLANETS.db)，关于适宜居住的系外行星。我们使用 Python 生成了数据集，数据和异常基于我在生产环境中遇到的实际事件。这个数据集完全免费使用，且[utils 文件夹](https://github.com/monte-carlo-data/data-downtime-challenge/tree/master/data/utils)中包含了生成数据的代码，如果你感兴趣的话。

我使用的是 SQLite 3.32.3，这使得数据库可以通过命令提示符或 SQL 文件以最小的设置访问。这些概念可以扩展到几乎任何查询语言，且[这些实现](https://github.com/monte-carlo-data/data-observability-in-practice/tree/main/queries)可以很少的改动扩展到 MySQL、Snowflake 和其他数据库环境。

再次，我们有我们的 EXOPLANETS 表：

```py
$ sqlite3 EXOPLANETS.db
sqlite> PRAGMA TABLE_INFO(EXOPLANETS);
0 | _id            | TEXT | 0 | | 0
1 | distance       | REAL | 0 | | 0
2 | g              | REAL | 0 | | 0
3 | orbital_period | REAL | 0 | | 0
4 | avg_temp       | REAL | 0 | | 0
5 | date_added     | TEXT | 0 | | 0
```

EXOPLANETS 中的数据库条目包含以下信息：

0. `_id`：对应于行星的 UUID。

1. `distance`：与地球的距离，单位为光年。

2. `g`：以 g 作为重力常数倍数的表面重力。

3. `orbital_period`：一个轨道周期的天数长度。

4. `avg_temp`：以开尔文度为单位的平均表面温度。

5. `date_added`：我们的系统发现该行星并自动将其添加到数据库中的日期。

请注意，由于数据缺失或错误，`distance`、`g`、`orbital_period` 和 `avg_temp` 中一个或多个可能为 `NULL`。

`sqlite> SELECT * FROM EXOPLANETS LIMIT 5;`

请注意，本练习是追溯性的——我们正在查看历史数据。在生产数据环境中，数据可观察性是实时的，并应用于数据生命周期的每个阶段，因此实现方式将与这里所做的有所不同。

看起来我们最旧的数据日期为 2020-01-01（*注意*：大多数数据库不会为单个记录存储时间戳，所以我们的 `DATE_ADDED` 列为我们跟踪）。我们的最新数据……

```py
sqlite> SELECT DATE_ADDED FROM EXOPLANETS ORDER BY DATE_ADDED DESC LIMIT 1;
2020–07–18
```

… 看起来是从2020年7月18日开始的。当然，这与我们在过去的文章中使用的表相同。如果我们想要探索更具上下文的模式和血统，我们需要扩展我们的环境。

现在，除了`EXOPLANETS`之外，我们还有一个名为`EXOPLANETS_EXTENDED`的表，它是我们过去表的超集。将这些视为在*不同时间点*的相同表是有用的。实际上，`EXOPLANETS_EXTENDED`的数据追溯到2020年1月1日……

```py
sqlite> SELECT DATE_ADDED FROM EXOPLANETS_EXTENDED ORDER BY DATE_ADDED ASC LIMIT 1;
2020–01–01
```

… 但也包含截至2020年9月6日的数据，比`EXOPLANETS`的数据还要多：

```py
sqlite> SELECT DATE_ADDED FROM EXOPLANETS_EXTENDED ORDER BY DATE_ADDED DESC LIMIT 1;
2020–09–06
```

### 可视化模式变化

这些表之间还有其他不同之处：

```py
sqlite> PRAGMA TABLE_INFO(EXOPLANETS_EXTENDED);
0 | _ID            | VARCHAR(16777216) | 1 | | 0
1 | DISTANCE       | FLOAT             | 0 | | 0
2 | G              | FLOAT             | 0 | | 0
3 | ORBITAL_PERIOD | FLOAT             | 0 | | 0
4 | AVG_TEMP       | FLOAT             | 0 | | 0
5 | DATE_ADDED     | TIMESTAMP_NTZ(6)  | 1 | | 0
6 | ECCENTRICITY   | FLOAT             | 0 | | 0
7 | ATMOSPHERE     | VARCHAR(16777216) | 0 | | 0
```

除了`EXOPLANETS`中的6个字段，`EXOPLANETS_EXTENDED`表还包含两个额外的字段：

`eccentricity`：行星绕其宿主恒星的[轨道偏心率](https://en.wikipedia.org/wiki/Orbital_eccentricity)。

`atmosphere`：行星大气层的主要化学成分。

请注意，与`distance`、`g`、`orbital_period`和`avg_temp`一样，对于某些行星，`eccentricity`和`atmosphere`也可能因为数据缺失或错误而为`NULL`。例如，[流浪行星](https://en.wikipedia.org/wiki/Rogue_planet)的轨道偏心率未定义，而且许多行星根本没有大气层。

还要注意的是，数据没有回填，这意味着表开始部分的数据（也包含在`EXOPLANETS`表中的数据）将没有偏心率和大气层信息。

```py
sqlite> SELECT
   ...>     DATE_ADDED,
   ...>     ECCENTRICITY,
   ...>     ATMOSPHERE
   ...> FROM
   ...>     EXOPLANETS_EXTENDED
   ...> ORDER BY
   ...>     DATE_ADDED ASC
   ...> LIMIT 10;
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
2020–01–01 | |
```

增加两个字段是一个[**模式** **变化**](https://www.educative.io/blog/what-are-database-schemas-examples)的例子——我们数据的正式蓝图已被修改。模式变化发生在对数据结构进行更改时，并且可能很难手动调试。模式变化可能指示数据的任何数量问题，包括：

+   新的API端点的增加

+   被认为是过时的字段，但尚未… 过时

+   列、行或整个表的增加或减少

在理想的情况下，我们希望有这个变化的记录，因为它代表了我们管道可能出现问题的一个向量。不幸的是，我们的数据库没有自然配置来跟踪这些变化。它没有版本历史记录。

我们在[Part I](https://medium.com/swlh/data-observability-building-your-own-data-quality-monitors-using-sql-a4c848b6882d)中查询单个记录的年龄时遇到过这个问题，并增加了`DATE_ADDED`列来应对。在这种情况下，我们会做类似的事情，只是这次会增加整个表：

```py
sqlite> PRAGMA TABLE_INFO(EXOPLANETS_COLUMNS);
0 | DATE    | TEXT | 0 | | 0
1 | COLUMNS | TEXT | 0 | | 0
```

`EXOPLANETS_COLUMNS`表通过记录`EXOPLANETS_EXTENDED`中任何给定日期的列来“版本化”我们的模式。查看第一个和最后一个条目，我们可以看到列确实在某个时刻发生了变化：

```py
sqlite> SELECT * FROM EXOPLANETS_COLUMNS ORDER BY DATE ASC LIMIT 1;
2020–01–01 | [
              (0, ‘_id’, ‘TEXT’, 0, None, 0),
              (1, ‘distance’, ‘REAL’, 0, None, 0),
              (2, ‘g’, ‘REAL’, 0, None, 0),
              (3, ‘orbital_period’, ‘REAL’, 0, None, 0),
              (4, ‘avg_temp’, ‘REAL’, 0, None, 0),
              (5, ‘date_added’, ‘TEXT’, 0, None, 0)
             ]sqlite> SELECT * FROM EXOPLANETS_COLUMNS ORDER BY DATE DESC LIMIT 1;
2020–09–06 | 
[
              (0, ‘_id’, ‘TEXT’, 0, None, 0),
              (1, ‘distance’, ‘REAL’, 0, None, 0),
              (2, ‘g’, ‘REAL’, 0, None, 0),
              (3, ‘orbital_period’, ‘REAL’, 0, None, 0),
              (4, ‘avg_temp’, ‘REAL’, 0, None, 0),
              (5, ‘date_added’, ‘TEXT’, 0, None, 0),
              (6, ‘eccentricity’, ‘REAL’, 0, None, 0),
              (7, ‘atmosphere’, ‘TEXT’, 0, None, 0)
             ]
```

现在，回到我们最初的问题：究竟什么时候发生了模式变化？由于我们的列列表是按日期索引的，我们可以通过一个简单的SQL脚本找到变化的日期。

这是返回的数据，我已经重新格式化以便于阅读：

```py
DATE:         2020–07–19
NEW_COLUMNS:  [
               (0, ‘_id’, ‘TEXT’, 0, None, 0),
               (1, ‘distance’, ‘REAL’, 0, None, 0),
               (2, ‘g’, ‘REAL’, 0, None, 0),
               (3, ‘orbital_period’, ‘REAL’, 0, None, 0),
               (4, ‘avg_temp’, ‘REAL’, 0, None, 0),
               (5, ‘date_added’, ‘TEXT’, 0, None, 0),
               (6, ‘eccentricity’, ‘REAL’, 0, None, 0),
               (7, ‘atmosphere’, ‘TEXT’, 0, None, 0)
              ]
PAST_COLUMNS: [
               (0, ‘_id’, ‘TEXT’, 0, None, 0),
               (1, ‘distance’, ‘REAL’, 0, None, 0),
               (2, ‘g’, ‘REAL’, 0, None, 0),
               (3, ‘orbital_period’, ‘REAL’, 0, None, 0),
               (4, ‘avg_temp’, ‘REAL’, 0, None, 0),
               (5, ‘date_added’, ‘TEXT’, 0, None, 0)
              ]
```

使用此查询，我们返回了问题日期：2020–07–19。像新鲜度和分布可观察性一样，实现模式可观察性遵循一个模式：我们识别出信号管道健康的[有用元数据](https://towardsdatascience.com/metadata-is-useless-535e43311cd8)，进行跟踪，并建立探测器以提醒我们潜在的问题。提供像`EXOPLANETS_COLUMNS`这样的附加表是跟踪模式的一种方法，但还有许多其他方法。我们鼓励你思考如何为自己的数据管道实现模式变化探测器！

### 可视化血统

我们将血统描述为[数据可观察性的五大支柱中最全面的](https://towardsdatascience.com/introducing-the-five-pillars-of-data-observability-e73734b263d5)，这也是有充分理由的。

> 血统通过告诉我们（1）哪些下游来源可能受到影响，以及（2）哪些上游来源可能是根本原因，来为事件提供背景。虽然用SQL代码“可视化”血统并不直观，但一个简单的例子可以说明它的实用性。

为此，我们需要再次扩展我们的数据环境。

### 介绍：HABITABLES

让我们向数据库中添加另一个表。到目前为止，我们一直在记录系外行星的数据。这里有一个有趣的问题要问：这些行星中有多少可能支持生命？

`HABITABLES`表从`EXOPLANETS`中获取数据，帮助我们回答这个问题：

```py
sqlite> PRAGMA TABLE_INFO(HABITABLES);
0 | _id          | TEXT | 0 | | 0
1 | perihelion   | REAL | 0 | | 0
2 | aphelion     | REAL | 0 | | 0
3 | atmosphere   | TEXT | 0 | | 0
4 | habitability | REAL | 0 | | 0
5 | min_temp     | REAL | 0 | | 0
6 | max_temp     | REAL | 0 | | 0
7 | date_added   | TEXT | 0 | | 0
```

`HABITABLES`中的一条记录包含以下内容：

`_id`：一个对应于行星的UUID。

`perihelion`：[轨道周期中离天体的最近距离](https://en.wikipedia.org/wiki/Apsis#Perihelion_and_aphelion)。

`aphelion`：[轨道周期中离天体的最远距离](https://en.wikipedia.org/wiki/Apsis#Perihelion_and_aphelion)。

`atmosphere`：行星大气层的主要化学成分。

`habitability`：一个介于0和1之间的实数，表示行星支持生命的可能性。

`min_temp`：行星表面的最低温度。

`max_temp`：行星表面的最高温度。

`date_added`：我们的系统发现行星并自动将其添加到我们的数据库中的日期。

像`EXOPLANETS`中的列一样，`perihelion`、`aphelion`、`atmosphere`、`min_temp`和`max_temp`的值也允许为`NULL`。实际上，对于`EXOPLANETS`中`eccentricity`为`NULL`的任何`_id`，`perihelion`和`aphelion`也会是`NULL`，因为你使用轨道离心率来计算这些指标。这解释了为什么这两个字段在我们旧的数据条目中总是`NULL`：

```py
sqlite> SELECT * FROM HABITABLES LIMIT 5;
```

所以，我们知道`HABITABLES`依赖于`EXOPLANETS`（或同样，`EXOPLANETS_EXTENDED`）中的值，`EXOPLANETS_COLUMNS`也是如此。我们数据库的依赖图如下：

![Figure](../Images/d71210e8268ae60c9ab0032bc91921ee.png)

图片由[Monte Carlo](http://www.montecarlodata.com/)提供。

非常简单的谱系信息，但已经很有用。让我们在这个图表的背景下查看`HABITABLES`中的异常，并看看我们能学到什么。

### 调查异常

当我们有一个关键指标，比如`HABITABLES`中的habitability时，我们可以通过几种方式来评估该指标的健康状况。首先，给定日期的新数据的`habitability`的平均值是多少？

从这些数据来看，我们发现了一些问题。`habitability`的平均值通常在0.5左右，但在记录数据后期下降到0.25左右。

![图](../Images/cbc0ab591e234f730b65dc895ab2426a.png)

一个分布异常……但是什么导致了它？

这是一个明显的分布异常，但究竟发生了什么？换句话说，这个异常的*根本原因*是什么？

为什么我们不看看`HABITABLES`中的`NULL`率，就像我们在[第一部分](https://ryanothnielkearns.medium.com/data-observability-building-your-own-data-quality-monitors-using-sql-a4c848b6882d)中做的那样？

幸运的是，这里没有发现异常：

但这看起来不像是我们问题的原因。如果我们查看另一个分布健康指标，即**零值率**呢？

这里明显出现了一些异常：

历史上，`habitability`几乎从未为零，但在后来的日期中，平均值会急剧上升到接近40%。这导致了该领域平均值的降低。

![图](../Images/ca0aa0e21a7d21ac69d342c325b39a5d.png)

一个分布异常……但是什么导致了它？

我们可以使用在第一部分中构建的分布检测器之一来获取`habitability`字段中显著零率的第一个日期：

我通过命令行运行了这个查询：

```py
$ sqlite3 EXOPLANETS.db < queries/lineage/habitability-zero-rate-detector.sql
DATE_ADDED | HABITABILITY_ZERO_RATE | PREV_HABITABILITY_ZERO_RATE
2020–07–19 | 0.369047619047619      | 0.0
```

2020年7月19日是零值率开始出现异常结果的第一天。请注意，这一天也是`EXOPLANETS_EXTENDED`中方案变更检测的同一天。`EXOPLANETS_EXTENDED`位于`HABITABLES`的上游，因此这两个事件很可能有关联。

就这样，谱系信息可以帮助我们识别**根本原因**，并更快地解决问题。比较`HABITABLES`中对此事件的以下两个解释：

1.  在2020年7月19日，`HABITABLES`表中habitability列的零值率从0%跃升到37%。

1.  在2020年7月19日，我们开始跟踪`EXOPLANETS`表中的两个额外字段，`eccentricity`和`atmosphere`。这对下游表`HABITABLES`产生了不利影响，通常在`eccentricity`不是`NULL`时，将字段`min_temp`和`max_temp`设置为极端值。反过来，这导致了`habitability`字段的零值率激增，我们检测到这是平均值异常降低。

解释（1）仅使用异常发生的事实。解释（2）使用血缘关系，即表和字段之间的依赖关系，将事件置于背景中并确定根本原因。顺便提一下，（2）中的一切实际上都是正确的，我鼓励你自己动手操作环境以了解实际情况。虽然这些只是简单的例子，但配备了（2）的工程师会更快地*理解*和*解决*根本问题，这都归功于适当的可观察性。

### 接下来是什么？

跟踪模式变化和血缘关系可以让你对数据的健康和使用模式有前所未有的可视性，提供关于数据被使用的谁、什么、在哪里、为什么和如何的关键背景信息。实际上，在理解数据停机的下游（以及通常是现实世界的）影响时，模式和血缘关系是两个最重要的数据可观察性支柱。

总结：

+   观察我们数据的**模式**意味着了解我们数据的正式结构，以及何时和如何发生变化。

+   观察我们数据的**血缘关系**意味着了解我们管道中的上游和下游依赖关系，并将孤立事件置于更大的背景中。

+   这两个**数据可观察性**支柱都涉及到跟踪适当的元数据，并以使异常情况可理解的方式转换我们的数据。

+   更好的可观察性意味着**更好地理解数据为什么以及如何破坏**，从而减少检测时间和解决时间。

我们希望这第二部分的“数据可观察性在背景中的应用”对你有帮助。

在第三部分之前，祝你没有数据停机！

***有兴趣了解更多关于Monte Carlo数据可观察性的内容吗？请联系*** [***Ryan***](https://www.linkedin.com/in/ryan-kearns-203686a9)***、***[***Barr***](https://www.linkedin.com/in/barrmoses/)***和***[***Monte Carlo团队***](http://www.montecarlodata.com/)***。***

**[Barr Moses](https://www.linkedin.com/in/barrmoses/)** 是Monte Carlo的数据可观察性公司的首席执行官兼联合创始人。在此之前，她曾担任Gainsight的运营副总裁。

**[Ryan Kearns](https://www.linkedin.com/in/ryan-kearns-203686a9)** 是Monte Carlo的数据和机器学习工程师，同时也是斯坦福大学的高级学生。

[原文](https://towardsdatascience.com/data-observability-in-practice-using-sql-part-ii-schema-lineage-5ca6c8f4f56a)。经许可转载。

**相关内容：**

+   [数据可观察性：使用SQL构建数据质量监控器](/2021/02/data-observability-building-data-quality-monitors-using-sql.html)

+   [数据目录已死；数据发现万岁](/2020/12/data-catalogs-dead-long-live-data-discovery.html)

+   [SQL中的数据清洗和整理](/2021/01/data-cleaning-wrangling-sql.html)

### 更多相关主题

+   [数据质量维度：使用Great Expectations确保数据质量](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)

+   [数据治理与可观测性解释](https://www.kdnuggets.com/2022/08/data-governance-observability-explained.html)

+   [IMPACT 2022：数据可观测性峰会，10月25-26日](https://www.kdnuggets.com/2022/09/monte-carlo-impact-2022-data-observability-summit.html)

+   [IMPACT：数据可观测性峰会回归，11月8日及后续…](https://www.kdnuggets.com/2023/10/monte-carlo-impact-the-data-observability-summit-is-back)

+   [LangChain 101：构建你自己的GPT驱动应用程序](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)

+   [使用LlamaIndex构建你自己的PandasAI](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)
