- en: 'A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness,
    Fairness, and Explainability'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于可信赖的图神经网络的综合调查：隐私、鲁棒性、公平性和可解释性
- en: 原文：[https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)
- en: '*By [Enyan Dai](https://enyandai.github.io/), [Tianxiang Zhao](https://tianxiangzhao.github.io/),
    and [Suhang Wang](https://suhangwang.ist.psu.edu/)*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*作者：[戴恩艳](https://enyandai.github.io/)，[赵天翔](https://tianxiangzhao.github.io/)，和[王苏杭](https://suhangwang.ist.psu.edu/)*'
- en: '**Link of the survey:** [https://arxiv.org/pdf/2204.08570.pdf](https://arxiv.org/pdf/2204.08570.pdf)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**调查链接：** [https://arxiv.org/pdf/2204.08570.pdf](https://arxiv.org/pdf/2204.08570.pdf)'
- en: 'Graphs-structured data are pervasive in real-world such as social networks,
    traffic networks, knowledge graph and protein-protein interaction networks. Graph
    Neural Networks (GNNs) extend neural networks for graph-structured by aggregating
    the neighborhood information to update the representations. The message-passing
    mechanism of GNNs has lead to great success in modeling graphs. For instance,
    Pinterest has applied GNNs for their image recommendation systems. There are also
    efforts in deploying GNNs for credit risk estimation. However, similar to other
    deep learning models, there are several issues of trustworthiness of GNNs, which
    have raised tremendous concerns:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图结构数据在现实世界中广泛存在，如社交网络、交通网络、知识图谱和蛋白质互作网络。图神经网络（GNNs）通过汇聚邻域信息来更新表示，从而扩展了神经网络以处理图结构数据。GNNs的消息传递机制在图建模中取得了巨大成功。例如，Pinterest
    已经将GNNs应用于他们的图像推荐系统中。也有努力将GNNs应用于信用风险估计。然而，与其他深度学习模型类似，GNNs也存在一些信任问题，引发了极大的关注：
- en: '**Privacy** and **Robustness** are not guaranteed in GNNs. GNNs are vulnerable
    to privacy attacks that steal the private data information or adversarial attacks
    that can fool the model. For example, hackers can utilize outputs or node embeddings
    of GNNs to infer node attribute information and friendship information in a social
    network. They may also fool the deployed GNNs in credit risk estimation for fraud
    by injecting malicious links or nodes, causing significant financial loss to individuals,
    institute and the society.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私**和**鲁棒性**在图神经网络（GNNs）中并不保证。GNNs易受到隐私攻击，这些攻击窃取私人数据或对抗性攻击，这些攻击可以欺骗模型。例如，黑客可以利用GNNs的输出或节点嵌入来推断社交网络中的节点属性信息和好友信息。他们还可能通过注入恶意链接或节点来欺骗用于信用风险估计的GNNs，从而导致个人、机构和社会的重大财务损失。'
- en: GNN models themselves have problems in **fairness** and **explainability**.
    More specifically, GNNs is proven that can magnify the bias in the data, resulting
    discrimination towards genders, races, and other protected sensitive attributes.
    Due to the high nonlinearity of the model, predictions from the GNNs are difficult
    to understand, which largely limits the applications of GNNs.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GNN模型自身在**公平性**和**可解释性**方面存在问题。更具体地说，GNNs被证明会放大数据中的偏差，从而导致对性别、种族和其他受保护敏感属性的歧视。由于模型的高度非线性，GNNs的预测结果难以理解，这在很大程度上限制了GNNs的应用。
- en: Those weaknesses significantly hinder the adoption of GNNs in real-world applications,
    especially those high-stake scenarios such as finance and healthcare. Therefore,
    how to build trustworthy GNN models has become a focal topic. In our recent survey
    paper [6], we give a comprehensive review of existing trustworthy GNNs in the
    computational perspectives of privacy, robustness, fairness and Explainability
    and discuss promising future works. In this blog, we briefly introduce the structure
    and covered topics of each aspect in the survey.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这些弱点严重阻碍了GNNs在现实世界应用中的采纳，特别是在金融和医疗等高风险场景中。因此，如何构建可信赖的GNN模型已成为一个重点话题。在我们最近的调查论文[6]中，我们从隐私、鲁棒性、公平性和可解释性等计算视角对现有可信赖的GNNs进行了全面回顾，并讨论了有前景的未来工作。在这篇博客中，我们简要介绍了调查中每个方面的结构和涵盖的主题。
- en: '![The structure of the privacy section (Sec.3) in the survey](../Images/6e5a7c63dfed0d3e96a85b86297bdfd7.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![调查中隐私部分（第3节）的结构](../Images/6e5a7c63dfed0d3e96a85b86297bdfd7.png)'
- en: Figure 1\. The structure of the privacy section (Sec.3) in the survey.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 调查中隐私部分（第3节）的结构。
- en: Privacy
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐私
- en: As it is mentioned, private information of users can be leaked from model release
    or the provided services due to privacy attacks. However, existing surveys are
    overwhelmingly dedicated to the privacy issue on models for independent and identically
    distributed (i.i.d) data such as images and text and the introduced methods cannot
    handle the graph structure and message-passing mechanism of GNNs. Thus, we give
    the overview of the privacy attacks on GNNs and privacy-preserving GNNs. The covered
    topics are shown in the Figure 1\. We firstly formulate a unified framework of
    existing methods of the privacy attacks on graphs. Then, four types of the privacy
    attacks, i.e., membership inference attack, reconstruction attack, property inference
    attack, and model extraction attack, are introduced with details of corresponding
    methods. As for the privacy-preserving methods, we split them into three categories,
    i.e., differential privacy, federated learning, and adversarial privacy-preserving.
    We list part of the methods we discuss in the figure. For more methods and details
    please refer to the Section 3 in the survey paper. We also include related datasets
    in various domains and the applications of privacy-preserving GNNs. We find that
    defense methods against many privacy attacks on graphs such as property information
    attack and model extraction attack are less studied. Therefore, defense against
    various privacy attacks is one of the promising research directions. Some other
    directions are also discussed. The details can be found in our survey.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，由于隐私攻击，用户的私人信息可能会从模型发布或提供的服务中泄露。然而，现有的调查主要关注于独立同分布（i.i.d）数据（如图像和文本）的隐私问题，而这些方法无法处理GNNs的图结构和信息传递机制。因此，我们概述了针对GNNs的隐私攻击以及隐私保护GNNs的方法。所涉及的主题如图1所示。我们首先制定了一个统一的框架来描述现有的图隐私攻击方法。然后，详细介绍了四种类型的隐私攻击，即成员推断攻击、重建攻击、属性推断攻击和模型提取攻击。至于隐私保护方法，我们将其分为三类，即差分隐私、联邦学习和对抗隐私保护。我们在图中列出了部分讨论的方法。有关更多方法和详细信息，请参阅调查论文中的第3节。我们还包括了各个领域相关的数据集以及隐私保护GNNs的应用。我们发现，对图上的许多隐私攻击（如属性信息攻击和模型提取攻击）的防御方法研究较少。因此，防御各种隐私攻击是一个有前景的研究方向。还讨论了其他一些方向。详细信息请参见我们的调查。
- en: '![The organization of the robustness section (Sec.4) in the survey](../Images/4dd77662617fd09e224b2099fe0a1ea6.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![调查中鲁棒性部分（第4节）的组织结构](../Images/4dd77662617fd09e224b2099fe0a1ea6.png)'
- en: Figure 2\. The organization of the robustness section (Sec.4) in the survey.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 调查中鲁棒性部分（第4节）的组织结构。
- en: Robustness
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**鲁棒性**'
- en: Robustness is another important aspect of trustworthiness. Due to the message-passing
    mechanism and graph structure, GNNs can be negatively affected by adversarial
    perturbations on both graph structures and node attributes. For example, fraudsters
    can create several transactions with deliberately chosen high credit users to
    escape GNN-based fraud detectors. This implies the necessity of investigating
    robust GNNs in safety-critical domains such as healthcare and financial system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**鲁棒性**是可信度的另一个重要方面。由于信息传递机制和图结构，GNNs可能会受到图结构和节点属性上的对抗扰动的负面影响。例如，欺诈者可以创建多个有意选择高信用用户的交易，以逃避基于GNN的欺诈检测器。这表明有必要在安全关键领域（如医疗保健和金融系统）研究鲁棒的GNNs。'
- en: There are already several surveys about the robustness on graph-structured data.
    Therefore, in our survey, we focus more on the methods in emerging directions
    such as scalable attacks, graph backdoor attacks and recent defense methods. More
    specifically, perturbation sampling and perturbation candidate reduction are two
    directions that have been explored to improve the scalability of existing attack
    methods. In addition, node injection attacks whose time complexity of injecting
    one node is linear to the graph size is another promising direction. As for the
    graph backdoor attacks, we present few existing works in detail. We categorize
    existing robust GNNs against graph adversarial attacks as the *Figure 2* shows. 
    The defense with self-supervision is a new direction that is rarely discussed
    before. Therefore, we present methods in this direction such as SimP-GNN [1] in
    details. For other categories, we add most recent approaches such as RS-GNN [2],
    which simultaneously deal with the label sparsity and the adversarial perturbations.
    Some future research directions of robust GNNs are also discussed. More details
    can be found in Section 4 of the survey.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关于图结构数据的鲁棒性已经有几个调查。因此，在我们的调查中，我们更多地关注于新兴方向中的方法，例如可扩展攻击、图后门攻击和最近的防御方法。具体而言，扰动采样和扰动候选减少是两个已被探索以提高现有攻击方法可扩展性的方向。此外，节点注入攻击，其注入一个节点的时间复杂度与图大小线性相关，是另一个有前景的方向。至于图后门攻击，我们详细介绍了少数现有工作。我们将现有的针对图对抗攻击的鲁棒GNNs进行分类，如*图2*所示。带有自监督的防御是一个新方向，之前很少讨论。因此，我们详细介绍了这一方向的方法，如SimP-GNN
    [1]。对于其他类别，我们添加了最新的方法，如RS-GNN [2]，该方法同时处理标签稀疏性和对抗扰动。我们还讨论了鲁棒GNNs的一些未来研究方向。更多细节可以在调查的第4节中找到。
- en: '![The organization of fairness section (Sec.5) in our survey.](../Images/d2407e8af07aeacf756322bb75b66976.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![我们调查中公平性部分（第5节）的组织结构。](../Images/d2407e8af07aeacf756322bb75b66976.png)'
- en: Figure 3\. The organization of fairness section (Sec.5) in our survey.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图3. 我们调查中公平性部分（第5节）的组织结构。
- en: Fairness
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 公平性
- en: Our recent research [3] has shown that the message passing mechanism of GNNs
    can magnify the biases compared with MLP, which verifies the necessity to investigate
    fair algorithms that particularly designed for graph-structured data. Recently,
    many works have emerged to develop fairness-aware GNNs to achieve various types
    of fairness on different tasks. Hence, we comprehensively review the fairness
    of graph neural network from various aspects, which are shown in the Figure 3.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最近的研究[3]表明，与MLP相比，GNNs的消息传递机制可能会放大偏差，这验证了研究专门针对图结构数据的公平算法的必要性。近年来，许多研究工作已经出现，旨在开发公平感知的GNNs，以在不同任务中实现各种类型的公平性。因此，我们从多个方面全面回顾了图神经网络的公平性，这些方面在图3中展示。
- en: Firstly, we discuss the potential biases in the graph-structued data, which
    contain biases generally existing on all formats of data and the unique biases
    caused by the graph topology. For the research in fairness, one of the most important
    questions is how to define the fairness in a mathematical way. We list the widely
    used fairness definitions in the literature about fair GNNs. Most of them are
    applicable for both i.i.d data and graph-structured data except the dyadic fairness
    which is designed for link prediction.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们讨论了图结构数据中的潜在偏差，包括所有数据格式中普遍存在的偏差和由图拓扑造成的独特偏差。在公平性研究中，最重要的问题之一是如何以数学方式定义公平性。我们列出了文献中关于公平GNNs的广泛使用的公平性定义。除二分公平性外，大多数定义适用于i.i.d数据和图结构数据，二分公平性是专门为链路预测设计的。
- en: We categorize the fair GNNs into adversarial debiasing, fairness constraints,
    and other categories. Part of the representative methods are shown in the Figure
    3\. For both adversarial debiasing and fairness constraints,  the unified framework
    and objective function are formulated. Then the detailed implementation and the
    target fairness of the existing methods are presented. The dataset for training
    and evaluating fair GNNs needs to contain users’ sensitive attributes, which can
    be difficult to obtain. Hence, we list the used graph datasets in various application
    domains for fairness-aware GNNs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将公平GNNs分为对抗性去偏差、公平性约束和其他类别。部分代表性的方法在图3中展示。对于对抗性去偏差和公平性约束，统一的框架和目标函数已经制定。接着，介绍了现有方法的详细实现和目标公平性。用于训练和评估公平GNNs的数据集需要包含用户的敏感属性，这可能很难获得。因此，我们列出了各种应用领域中用于公平感知GNNs的图数据集。
- en: '![The organization of the explainability section (Sec.6) in our survey.](../Images/a52ddbe632331c4be3f8f6d37a4bef01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![我们调查中解释性部分（第6节）的组织结构。](../Images/a52ddbe632331c4be3f8f6d37a4bef01.png)'
- en: Figure 4\. The organization of the explainability section (Sec.6) in our survey.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图4。我们调查中解释性部分（第6节）的组织结构。
- en: Explainability
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释性
- en: Due to the discreteness of complex graph structures and high non-linearity and
    the deployment of message-passing mechanism in GNNs, GNN models generally lacks
    interpretability. It is very important to develop explainable GNNs. The explanation
    can enhance practitioners’ trust in GNN. In addition, explanations can expose
    the knowledge captured, helping us to evaluate the existence of possible biases
    and adversarial attacks. Therefore, many efforts have been taken in explainable
    GNNs and we give a comprehensive review about the explainable GNNs. The overall
    organization of the explainability section is presented as the Figure 4 shows.
    We firstly discuss the categorization of the explanations in GNNs. Then, we categorize
    the explainable GNNs to instance-level post-hoc, model-level pos-hoc, and self-explainable
    methods. It’s worth mentioning that self-explainable GNNs is a new direction that
    have not been reviewed by the previous survey. We give adequate details of the
    self-explainable GNN methods such as SE-GNN [4] and ProtGNN [5]. For other groups
    of methods, we further give a lower-level categorization based on the implemented
    techniques. Since the ground-truth explanations are very hard to obtain in the
    real-world graphs, the datasets and evaluation metrics are also big challenges
    in verifying the correctness of the learned explanations. And benchmark datasets
    for explainability can be promising future research direction in the research
    about the explainability of GNNs. More details can be found in our survey paper.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于复杂图结构的离散性和高度非线性，以及图神经网络（GNNs）中消息传递机制的使用，GNN模型通常缺乏可解释性。开发可解释的GNNs是非常重要的。解释可以增强从业者对GNN的信任。此外，解释可以揭示捕获的知识，帮助我们评估潜在的偏差和对抗攻击。因此，许多工作已投入到可解释的GNNs中，我们提供了关于可解释GNNs的综合综述。解释性部分的总体组织结构如图4所示。我们首先讨论GNNs中的解释分类。然后，我们将可解释GNNs分为实例级后处理、模型级后处理和自解释方法。值得一提的是，自解释GNNs是一个新的方向，之前的综述未曾涉及。我们详细介绍了自解释GNN方法，如SE-GNN
    [4] 和 ProtGNN [5]。对于其他方法组，我们进一步基于实现技术提供了更低级的分类。由于在实际图中获得真实解释非常困难，数据集和评估指标也是验证学习到的解释正确性的重大挑战。而解释性基准数据集可以成为未来研究GNN解释性的有前景的研究方向。更多细节可以在我们的调查论文中找到。
- en: References
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Jin, Wei, Tyler Derr, Yiqi Wang, Yao Ma, Zitao Liu, and Jiliang Tang. "Node
    similarity preserving graph convolutional networks." In Proceedings of the 14th
    ACM International Conference on Web Search and Data Mining, pp. 148-156\. 2021.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Jin, Wei, Tyler Derr, Yiqi Wang, Yao Ma, Zitao Liu, and Jiliang Tang. "节点相似性保留图卷积网络。"
    见第14届ACM国际网页搜索与数据挖掘会议论文集，第148-156页。2021年。'
- en: '[2] Dai, Enyan, Wei Jin, Hui Liu, and Suhang Wang. "Towards Robust Graph Neural
    Networks for Noisy Graphs with Sparse Labels." Proceedings of the 15th ACM International
    Conference on Web Search and Data Mining. 2022.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Dai, Enyan, Wei Jin, Hui Liu, and Suhang Wang. "面向噪声图和稀疏标签的鲁棒图神经网络。" 第15届ACM国际网页搜索与数据挖掘会议论文集。2022年。'
- en: '[3] Dai, Enyan, and Suhang Wang. "Say no to the discrimination: Learning fair
    graph neural networks with limited sensitive attribute information." Proceedings
    of the 14th ACM International Conference on Web Search and Data Mining. 2021.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Dai, Enyan, and Suhang Wang. "说不对歧视：利用有限的敏感属性信息学习公平的图神经网络。" 第14届ACM国际网页搜索与数据挖掘会议论文集。2021年。'
- en: '[4] Dai, Enyan, and Suhang Wang. "Towards Self-Explainable Graph Neural Network."
    Proceedings of the 30th ACM International Conference on Information & Knowledge
    Management. 2021.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Dai, Enyan, and Suhang Wang. "面向自解释图神经网络。" 第30届ACM国际信息与知识管理会议论文集。2021年。'
- en: '[5] Zhang, Zaixi, Qi Liu, Hao Wang, Chengqiang Lu, and Cheekong Lee. "ProtGNN:
    Towards Self-Explaining Graph Neural Networks." arXiv preprint arXiv:2112.00911
    (2021).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Zhang, Zaixi, Qi Liu, Hao Wang, Chengqiang Lu, and Cheekong Lee. "ProtGNN：面向自解释图神经网络。"
    arXiv预印本arXiv:2112.00911 (2021)。'
- en: '[6] Dai, Enyan, Tianxiang Zhao, Huaisheng Zhu, Junjie Xu, Zhimeng Guo, Hui
    Liu, Jiliang Tang, and Suhang Wang. "A Comprehensive Survey on Trustworthy Graph
    Neural Networks: Privacy, Robustness, Fairness, and Explainability." arXiv preprint
    arXiv:2204.08570 (2022).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] 戴恩言，赵天翔，朱怀生，徐俊杰，郭志萌，刘辉，唐继良，王苏航。 "关于可信赖图神经网络的全面调查：隐私、鲁棒性、公平性和可解释性。" arXiv
    预印本 arXiv:2204.08570 (2022)。'
- en: '* * *'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 工作'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[With Data Privacy learn to implement technical privacy solutions…](https://www.kdnuggets.com/2022/04/manning-data-privacy-learn-implement-technical-privacy-solutions-tools-scale.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过数据隐私学习如何实施技术隐私解决方案…](https://www.kdnuggets.com/2022/04/manning-data-privacy-learn-implement-technical-privacy-solutions-tools-scale.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络全面指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[How ML Model Explainability Accelerates the AI Adoption Journey for…](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ML 模型可解释性如何加速 AI 采用过程…](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
- en: '[Expert Insights on Developing Safe, Secure, and Trustworthy AI Frameworks](https://www.kdnuggets.com/expert-insights-on-developing-safe-secure-and-trustworthy-ai-frameworks)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[专家见解：开发安全、可靠和可信的 AI 框架](https://www.kdnuggets.com/expert-insights-on-developing-safe-secure-and-trustworthy-ai-frameworks)'
- en: '[Learn how to design, measure and implement trustworthy A/B tests…](https://www.kdnuggets.com/2023/01/sphere-design-measure-implement-trustworthy-ab-tests-ronny-kohavi.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习如何设计、测量和实施可信的 A/B 测试…](https://www.kdnuggets.com/2023/01/sphere-design-measure-implement-trustworthy-ab-tests-ronny-kohavi.html)'
- en: '[The Fast and Effective Way to Audit ML for Fairness](https://www.kdnuggets.com/2023/01/fast-effective-way-audit-ml-fairness.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[审计 ML 公平性的快速有效方法](https://www.kdnuggets.com/2023/01/fast-effective-way-audit-ml-fairness.html)'
