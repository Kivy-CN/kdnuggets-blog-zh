- en: 10 Machine Learning Model Training Mistakes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10个机器学习模型训练中的错误
- en: 原文：[https://www.kdnuggets.com/2021/07/10-machine-learning-model-training-mistakes.html](https://www.kdnuggets.com/2021/07/10-machine-learning-model-training-mistakes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/07/10-machine-learning-model-training-mistakes.html](https://www.kdnuggets.com/2021/07/10-machine-learning-model-training-mistakes.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Sandeep Uttamchandani, Ph.D.](https://www.linkedin.com/in/sandeepuc/),
    Both a Product/Software Builder (VP of Engg) & Leader in operating enterprise-wide
    Data/AI initiatives (CDO)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Sandeep Uttamchandani, Ph.D.](https://www.linkedin.com/in/sandeepuc/)，既是产品/软件开发者（工程副总裁），也是企业范围内数据/AI项目的领导者（首席数据官）**'
- en: '![Mistakes header](../Images/70a570ad807374cd4dd6269c8abf20d0.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Mistakes header](../Images/70a570ad807374cd4dd6269c8abf20d0.png)'
- en: Image by [Tumisu](https://pixabay.com/users/tumisu-148124/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1966448)
    from [Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1966448)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Tumisu](https://pixabay.com/users/tumisu-148124/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1966448)的[Pixabay](https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1966448)
- en: ML model training is the most time-consuming and resource-expensive part of
    the overall model-building journey. Training by definition is iterative, but somewhere
    during the iterations, mistakes seep into the mix. In this article, I share the
    ten deadly sins during ML model training — these are the most common as well as
    the easiest to overlook.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型训练是整个模型构建过程中最耗时和资源的部分。训练本质上是迭代的，但在某些迭代过程中，错误可能会渗入。在这篇文章中，我分享了机器学习模型训练中的十个致命错误——这些错误是最常见的，也是最容易被忽视的。
- en: Ten Deadly Sins of ML Model Training
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习模型训练的十个致命错误
- en: '**1\. Blindly increasing the number of epochs when the model is not converging**'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1\. 在模型未收敛时盲目增加轮次**'
- en: During model training, there are scenarios when the loss-epoch graph keeps bouncing
    around and does not seem to converge irrespective of the number of epochs. There
    is no silver bullet as there are multiple root causes to investigate — bad training
    examples, missing truths, changing data distributions, too high a learning rate.
    The most common one I have seen is bad training examples related to a combination
    of anomalous data and incorrect labels.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练过程中，有时损失-轮次图表会反复波动，不论轮次多少都似乎无法收敛。没有万能的解决方案，因为需要调查多个根本原因——不良训练样本、缺失的真值、变化的数据分布、过高的学习率。我见过的最常见原因是不良训练样本，涉及异常数据与不正确标签的组合。
- en: 2. **Not shuffling the training dataset**
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2. **未对训练数据集进行随机打乱**
- en: Sometimes there are scenarios where the model seems to be converging, but suddenly
    the loss value increases significantly, i.e., loss value reduces and then increases
    significantly with epochs. There are multiple reasons for this kind of exploding
    loss. The most common one I have seen is outliers in the data that are not evenly
    distributed/shuffled in the data. Shuffling, in general, is an important step
    including for patterns where the loss is showing a repeating step function behavior.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，模型似乎正在收敛，但突然损失值显著增加，即损失值在减少后突然显著增加。这种损失爆炸有多种原因。我见过的最常见原因是数据中的离群值没有均匀分布/打乱。打乱一般来说是一个重要步骤，包括在损失表现出重复步进函数行为的模式中。
- en: 3. **In multiclass classification, not prioritizing specific per-class metrics
    accuracy**
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3. **在多类别分类中，不优先考虑特定类别的度量准确性**
- en: For multiclass prediction problems, instead of tracking just the overall classification
    accuracy, it is often useful to prioritize the accuracy of specific classes and
    iteratively work on improving the model class by class. For instance, in classifying
    different forms of fraudulent transactions, focus on increasing the recall of
    specific classes (such as foreign transactions) based on business needs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多类别预测问题，除了跟踪总体分类准确性外，通常还需优先考虑特定类别的准确性，并逐步改进模型。例如，在对不同类型的欺诈交易进行分类时，根据业务需求，专注于提高特定类别（如外国交易）的召回率。
- en: 4. **Assuming specificity will lead to lower model accuracy**
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4. **假设特异性会导致模型准确性降低**
- en: Instead of building a generic model, imagine building a model for a specific
    geographic region or specific user persona. Specificity will make the data more
    sparse but can lead to better accuracy for those specific problems. It is important
    to explore the specificity and sparsity trade-off during tuning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与其构建一个通用模型，不如想象为特定地理区域或特定用户画像构建模型。特定性会使数据更加稀疏，但可能会提高对这些特定问题的准确性。在调优过程中，探索特定性和稀疏性的权衡是很重要的。
- en: 5. **Ignoring prediction bias**
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5. **忽视预测偏差**
- en: Prediction bias is the difference between the average of predictions and the
    average of labels in the dataset. Prediction bias serves as an early indicator
    of model issues. A big nonzero prediction bias is indicative of a bug somewhere
    in the model. There’s an interesting [Facebook paper](https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf) in
    the context of ad CTR. Typically, the bias is useful to measure across prediction
    buckets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 预测偏差是预测平均值和数据集中标签平均值之间的差异。预测偏差是模型问题的早期指标。较大的非零预测偏差表明模型中存在某个地方的错误。关于广告点击率的一个有趣的
    [Facebook 论文](https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf)。通常，偏差在预测桶之间的测量是有用的。
- en: 6. **Calling it a success just on model accuracy numbers**
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6. **仅仅依靠模型准确率就称之为成功**
- en: Accuracy of 95% means 95 of 100 predictions were correct. Accuracy is a flawed
    metric with a class imbalance in the dataset. Instead investigate deeply into
    metrics, such as precision/recall and how it correlates to overall user metrics
    such as spam detection, tumor classification, etc.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 95% 的准确率意味着 100 次预测中有 95 次是正确的。在数据集中存在类别不平衡的情况下，准确率是一个有缺陷的指标。应该深入调查诸如精准度/召回率等指标，以及它们如何与整体用户指标（如垃圾邮件检测、肿瘤分类等）相关联。
- en: 7. **Not understanding the impact of regularization lambda**
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7. **不了解正则化 λ 的影响**
- en: 'Lambda is a key parameter in striking the balance between simplicity and training-data
    fit. High lambda → simple model → possibly underfitting. Low lambda → complex
    model → potential overfitting your data (won’t be able to generalize to new data).
    The ideal value of lambda is one that generalizes well to previously unseen data:
    data-dependent and requires analysis.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: λ 是在简单性和训练数据拟合之间取得平衡的关键参数。高 λ → 简单模型 → 可能欠拟合。低 λ → 复杂模型 → 可能对数据过拟合（无法推广到新数据）。理想的
    λ 值是能够很好地推广到以前未见过的数据的值：依赖数据并需要分析。
- en: 8\. Using the same test set over and over
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8. 重复使用相同的测试集
- en: The more the same data is used for parameter and hyperparameter settings, the
    lesser confidence that the results will actually generalize. It is important to
    collect more data and keep adding to the test and validation sets.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同数据进行参数和超参数设置的次数越多，对结果实际推广能力的信心就越小。重要的是收集更多的数据，并不断增加测试和验证集。
- en: '**9\. Not paying attention to initiation value in neural networks**'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**9. 未关注神经网络中的初始化值**'
- en: Given non-convex optimization in NN, [initialization matters](https://www.deeplearning.ai/ai-notes/initialization/).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于神经网络中的非凸优化，[初始化很重要](https://www.deeplearning.ai/ai-notes/initialization/)。
- en: 10\. Assuming wrong labels always need to be fixed
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10. 假设错误标签总是需要修复
- en: When wrong labels are detected, it is tempting to jump in and get them fixed.
    It is important to first analyze misclassified examples for the root cause. Oftentimes,
    errors due to incorrect labels may be a very small percentage. There might be
    a bigger opportunity to better train for specific data slices that might be the
    predominant root cause.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当发现错误标签时，可能会很想立即修复它们。首先分析误分类示例的根本原因是很重要的。通常，由于标签错误引起的错误可能只占很小的比例。可能存在更大的机会来更好地训练针对特定数据片段的模型，这些数据片段可能是主要的根本原因。
- en: To summarize, avoiding these mistakes puts you significantly ahead of most other
    teams. Incorporate these as a checklist in your process.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，避免这些错误可以让你在大多数其他团队中脱颖而出。将这些作为你的流程检查清单。
- en: '**Bio: [Sandeep Uttamchandani, Ph.D.](https://www.linkedin.com/in/sandeepuc/)**:
    Data + AI/ML -- Both a Product/Software Builder (VP of Engg) & Leader in operating
    enterprise-wide Data/AI initiatives (CDO) | O''Reilly Book Author | Founder -
    DataForHumanity (non-profit)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Sandeep Uttamchandani, Ph.D.](https://www.linkedin.com/in/sandeepuc/)**:
    数据 + 人工智能/机器学习 -- 既是产品/软件构建者（工程副总裁）也是企业范围内数据/人工智能项目的领导者（首席数据官） | O''Reilly 图书作者
    | DataForHumanity 创始人（非营利组织）'
- en: '[Original](https://betterprogramming.pub/10-deadly-sins-of-ml-model-training-a5046c1f5094).
    Reposted with permission.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://betterprogramming.pub/10-deadly-sins-of-ml-model-training-a5046c1f5094)。经授权转载。'
- en: '**Related:**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to Determine if Your Machine Learning Model is Overtrained](/2021/05/how-determine-machine-learning-model-overtrained.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何判断你的机器学习模型是否过拟合](/2021/05/how-determine-machine-learning-model-overtrained.html)'
- en: '[Write and train your own custom machine learning models using PyCaret](/2021/05/pycaret-write-train-custom-machine-learning-models.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyCaret编写和训练你自己的自定义机器学习模型](/2021/05/pycaret-write-train-custom-machine-learning-models.html)'
- en: '[How to break a model in 20 days — a tutorial on production model analytics](/2021/03/break-model-20-days-tutorial-production-model-analytics.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在20天内破坏一个模型——关于生产模型分析的教程](/2021/03/break-model-20-days-tutorial-production-model-analytics.html)'
- en: '* * *'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How To Use Synthetic Data To Overcome Data Shortages For Machine…](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用合成数据克服机器学习中的数据短缺问题](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
- en: '[How to Speed Up XGBoost Model Training](https://www.kdnuggets.com/2021/12/speed-xgboost-model-training.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何加快XGBoost模型训练速度](https://www.kdnuggets.com/2021/12/speed-xgboost-model-training.html)'
- en: '[Software Mistakes and Tradeoffs: New book by Tomasz Lelek and…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件错误与权衡：Tomasz Lelek的新书及…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Mistakes That Could Be Affecting the Accuracy of Your Data Analytics](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可能影响数据分析准确性的3个错误](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免这5个每位AI新手都会犯的常见错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
