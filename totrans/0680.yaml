- en: Basic Image Data Analysis Using Python – Part 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本图像数据分析使用 Python – 第三部分
- en: 原文：[https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html](https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html](https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![Python image analysis fig 1](../Images/83d60005fe08b263cf8c69bbe8998971.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Python 图像分析图 1](../Images/83d60005fe08b263cf8c69bbe8998971.png)'
- en: Previously we’ve seen some of the very basic image analysis operations in Python.
    In this last part of basic image analysis, we’ll go through some of the following
    contents.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们已经在 Python 中看到了一些非常基本的图像分析操作。在本基本图像分析的最后一部分，我们将学习以下内容。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Following contents is the reflection of my completed academic image processing
    course in the previous term. So, I am not planning on putting anything into production
    sphere. Instead, the aim of this article is to try and realize the fundamentals
    of a few basic image processing techniques. For this reason, I am going to stick
    to using [**SciKit-Image**](https://scikit-image.org/) - [**numpy**](http://www.numpy.org/) mainly
    to perform most of the manipulations, although I will use other libraries now
    and then rather than using most wanted tools like [**OpenCV**](https://opencv.org/) :'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容是我在上个学期完成的学术图像处理课程的反映。因此，我不打算将其投入生产领域。相反，本文的目的是尝试理解一些基本图像处理技术的基础知识。为此，我将主要使用
    [**SciKit-Image**](https://scikit-image.org/) 和 [**numpy**](http://www.numpy.org/)
    来执行大多数操作，尽管我也会偶尔使用其他库，而不是使用 [**OpenCV**](https://opencv.org/) 这类最受欢迎的工具。
- en: I wanted to complete this series into two section but due to fascinating contents
    and its various outcome, I have to split it into too many part. However, one may
    find whole series into two section only on my homepage, included below.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我本打算将这个系列分为两个部分，但由于内容引人入胜及其多样的结果，我不得不将其拆分成多个部分。然而，可以在我的主页上找到整个系列的两个部分，如下所示。
- en: '**Find the whole series:** [**Part 1**](https://www.kdnuggets.com/2018/07/basic-image-data-analysis-numpy-opencv-p1.html)**,**
    [**Part 2**](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)
    **All source code:** [**GitHub-Image-Processing-Python**](https://github.com/iphton/Image-Processing-in-Python)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**找到整个系列：** [**第 1 部分**](https://www.kdnuggets.com/2018/07/basic-image-data-analysis-numpy-opencv-p1.html)**,**
    [**第 2 部分**](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)
    **所有源代码：** [**GitHub-图像处理-Python**](https://github.com/iphton/Image-Processing-in-Python)'
- en: But if you’re not interested to redirect, stick with me here . In the previous
    article, we’ve gone through some of the following basic operations. To keep pace
    with today’s content, continuous reading is highly appreciated.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你不打算重定向，就跟着我继续阅读。在上一篇文章中，我们已经介绍了一些基本操作。为了跟上今天的内容，非常感谢你继续阅读。
- en: '[Importing images and observe it’s properties](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#1-bullet)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[导入图像并观察其属性](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#1-bullet)'
- en: '[Splitting the layers](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#2-bullet)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分离图层](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#2-bullet)'
- en: '[Greyscale](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#3-bullet)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[灰度图](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#3-bullet)'
- en: '[Using Logical Operator on pixel values](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#4-bullet)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对像素值使用逻辑运算符](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#4-bullet)'
- en: '[Masking using Logical Operator](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#5-bullet)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’m so excited, let’s begin!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Intensity Transformation
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s begin with importing an image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Python image analysis fig 2](../Images/f53b2232b2f9c48c4f39496b7094396b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: Image Negative
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The intensity transformation function mathematically defined as:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: where r is the pixels of the input image and s is the pixels of the output image.
    T is a transformation function that maps each value of r to each value of s.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Negative transformation, which is the invert of identity transformation. In
    negative transformation, each value of the input image is subtracted from the
    L−1 and mapped onto the output image.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the following transition has been done:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So, each value is subtracted by **255**. So what happens is that the lighter
    pixels become dark and the darker picture becomes light. And it results in image
    negative.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Python image analysis fig 3](../Images/5a34fa6e0801651033e3ff1d87292f9b.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Log transformation
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The log transformations can be defined by this formula:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Where s and r are the pixel values of the output and the input image and c is
    a constant. The value 1 is added to each of the pixel value of the input image
    because if there is a pixel intensity of 0 in the image, then **log(0)** is equal
    to infinity. So, 1 is added, to make the minimum value at least 1.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: During log transformation, the dark pixels in an image are expanded as compared
    to the higher pixel values. The higher pixel values are kind of compressed in
    log transformation. This result in the following image enhancement.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: The value of c in the log transform adjust the kind of enhancement we are looking
    for.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Python image analysis fig 4](../Images/dd918a573ffe99b82543baa0d954bd8d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: Gamma Correction
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gamma correction, or often simply gamma, is a nonlinear operation used to encode
    and decode luminance or tristimulus values in video or still image systems. Gamma
    correction is also known as the **Power Law Transform**. First, our image pixel
    intensities must be scaled from the range **0, 255** to **0, 1.0**. From there,
    we obtain our output gamma corrected image by applying the following equation:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Where **Vi** is our input image and **G** is our gamma value. The output image,
    **Vo** is then scaled back to the range **0-255**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: A gamma value, **G < 1** is sometimes called an **encoding gamma**, and the
    process of encoding with this compressive power-law nonlinearity is called **gamma
    compression**; Gamma values < 1 will shift the image towards the darker end of
    the spectrum.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversely, a gamma value **G > 1** is called a **decoding gamma** and the
    application of the expansive power-law nonlinearity is called **gamma expansion**.
    Gamma values > 1 will make the image appear lighter. A gamma value of **G = 1**
    will have no effect on the input image:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Python image analysis fig 5](../Images/866cd402d5d49c45b3d747564db2fca5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: '**The Reason for Gamma Correction**'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The reason we apply gamma correction is that our eyes perceive color and luminance
    differently than the sensors in a digital camera. When a sensor on a digital camera
    picks up twice the amount of photons, the signal is doubled. However, our eyes
    do not work like this. Instead, our eyes perceive double the amount of light as
    only a fraction brighter. Thus, while a digital camera has a linear relationship
    between brightness our eyes have a non-linear relationship. In order to account
    for this relationship, we apply gamma correction.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用伽玛校正的原因是我们眼睛对颜色和亮度的感知与数字相机的传感器不同。当数字相机上的传感器接收到两倍的光子量时，信号会加倍。然而，我们的眼睛并不是这样工作的。相反，我们的眼睛将双倍的光线仅感知为略微亮一点。因此，尽管数字相机的亮度与光线之间有线性关系，但我们的眼睛有非线性关系。为了考虑这种关系，我们应用伽玛校正。
- en: 'There is some other linear transformation function. Listed below:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他线性变换函数，列举如下：
- en: Contrast Stretching
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对比度拉伸
- en: Intensity-Level Slicing
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强度级切片
- en: Bit-Plane Slicing
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位平面切片
- en: Convolution
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积
- en: We’ve discussed briefly in our previous [article](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html) is
    that, when a computer sees an image, it sees an array of pixel values. Now, depending
    on the resolution and size of the image, it will see a 32 x 32 x 3 array of numbers
    where the 3 refers to RGB values or channels. Just to drive home the point, let’s
    say we have a color image in PNG form and its size is 480 x 480\. The representative
    array will be 480 x 480 x 3\. Each of these numbers is given a value from 0 to
    255 which describes the pixel intensity at that point.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的[文章](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)中简要讨论过，当计算机看到图像时，它看到的是一个像素值数组。现在，根据图像的分辨率和大小，它会看到一个32
    x 32 x 3的数字数组，其中3指的是RGB值或通道。为了更明确地说明这一点，假设我们有一个PNG格式的彩色图像，大小为480 x 480。代表性的数组将是480
    x 480 x 3。每个数字的值从0到255，这描述了该点的像素强度。
- en: Like we mentioned before, the input is a 32 x 32 x 3 array of pixel values.
    Now, the best way to explain a convolution is to imagine a flashlight that is
    shining over the top left of the image. Let’s say that the flashlight shines cover
    a 3 x 3 area. And now, let’s imagine this flashlight sliding across all the areas
    of the input image. In machine learning terms, this flashlight is called a **filter** or [**kernel**](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details) or
    sometimes referred to as **weights** or **mask** and the region that it is shining
    over is called the [**receptive field**](https://en.wikipedia.org/wiki/Receptive_field).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，输入是一个32 x 32 x 3的像素值数组。现在，解释卷积的最佳方式是想象一个手电筒在图像的左上角照射。假设手电筒照射一个3 x 3的区域。现在，想象这个手电筒在输入图像的所有区域滑动。在机器学习术语中，这个手电筒被称为**滤波器**或[**内核**](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details)或者有时被称为**权重**或**掩码**，它照射的区域称为[**感受野**](https://en.wikipedia.org/wiki/Receptive_field)。
- en: Now, this filter is also an array of numbers where the numbers are called weights
    or parameters. A very important note is that the depth of this filter has to be
    the same as the depth of the input, so the dimensions of this filter are 3 x 3
    x 3.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个滤波器也是一个数字数组，其中的数字称为权重或参数。一个非常重要的说明是，这个滤波器的深度必须与输入的深度相同，因此这个滤波器的尺寸是3 x 3
    x 3。
- en: An image **kernel** or **filter** is a small matrix used to apply effects like
    the ones we might find in Photoshop or Gimp, such as blurring, sharpening, outlining
    or embossing. They’re also used in machine learning for **feature extraction**,
    a technique for determining the most important portions of an image. For more,
    have a look at Gimp’s excellent documentation on using [Image kernel’s](https://docs.gimp.org/en/plug-in-convmatrix.html).
    We can find a list of most common kernels [here](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图像**内核**或**滤波器**是一个小矩阵，用于应用诸如在Photoshop或Gimp中找到的效果，比如模糊、锐化、轮廓或浮雕。它们还用于机器学习中的**特征提取**，这是一种确定图像最重要部分的技术。更多内容，请查看Gimp关于使用[图像内核](https://docs.gimp.org/en/plug-in-convmatrix.html)的出色文档。我们可以在[这里](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details)找到最常见内核的列表。
- en: Now, let’s take the filter to the top left corner. As the filter is sliding,
    or **convolving**, around the input image, it is multiplying the values in the
    filter with the original pixel values of the image (aka computing element-wise
    multiplications). These multiplications are all summed up. So now we have a single
    number. Remember, this number is just representative of when the filter is at
    the top left of the image. Now, we repeat this process for every location on the
    input volume. Next step would be moving the filter to the right by a **stride** or **step** 1
    unit, then right again by **stride** 1, and so on. Every unique location on the
    input volume produces a number. We can also choose stride or the step size 2 or
    more, but we have to care whether it will fit or not on the input image.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将滤波器移到左上角。当滤波器在输入图像上滑动或**卷积**时，它将滤波器中的值与图像的原始像素值相乘（即进行逐元素乘法）。这些乘法的结果都被求和。因此，我们现在得到一个单一的数字。请记住，这个数字只是表示滤波器在图像左上角时的值。现在，我们对输入体积上的每个位置重复这个过程。下一步是将滤波器向右移动一个**步幅**或**步长**单位，再次向右移动一个**步幅**，以此类推。输入体积上的每个唯一位置都会产生一个数字。我们也可以选择步幅或步长为
    2 或更多，但我们必须注意它是否适合输入图像。
- en: '![Python image analysis fig 6](../Images/888bb82ac03be1227141c2fba72b3c81.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![Python 图像分析 图 6](../Images/888bb82ac03be1227141c2fba72b3c81.png)'
- en: 'After sliding the filter over all the locations, we will find out that, what
    we’re left with is a 30 x 30 x 1 array of numbers, which we call an **activation
    map** or **feature map**. The reason we get a 30 x 30 array is that there are
    900 different locations that a 3 x 3 filter can fit on a 32 x 32 input image.
    These 900 numbers are mapped to a 30 x 30 array. We can calculate the convolved
    image by following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在将滤波器滑动到所有位置后，我们会发现，剩下的是一个 30 x 30 x 1 的数字数组，我们称之为**激活图**或**特征图**。我们得到 30 x
    30 数组的原因是，3 x 3 的滤波器可以在 32 x 32 的输入图像上适配 900 个不同的位置。这 900 个数字被映射到一个 30 x 30 的数组中。我们可以通过以下方式计算卷积后的图像：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: where N and F represent Input image size and kernel size respectively and S represent
    stride or step size. So, in this case, the output would be
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，N 和 F 分别代表输入图像大小和卷积核大小，S 代表步幅或步长。因此，在这种情况下，输出将是
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Let’s say we’ve got a following 3x3 filter, convolving on a 5x5 matrix and according
    to the equation we should get a 3x3 matrix, technically called **activation map** or **feature
    map**.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个 3x3 的滤波器，对 5x5 的矩阵进行卷积，根据公式，我们应该得到一个 3x3 的矩阵，技术上称为**激活图**或**特征图**。
- en: Let’s take a look somewhat visually,
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看一些视觉效果，
- en: '![Python image analysis fig 7](../Images/3bc29603afbe93b6c007a8621ee94991.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![Python 图像分析 图 7](../Images/3bc29603afbe93b6c007a8621ee94991.png)'
- en: Moreover, we practically use more filters instead of one. Then our output volume
    would be 28x28xn (where n is the number of **activation map**).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们实际上使用更多的滤波器而不是一个。然后，我们的输出体积将是 28x28xn（其中 n 是**激活图**的数量）。
- en: By using more filters, we are able to preserve the spatial dimensions better.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用更多的滤波器，我们能够更好地保留空间维度。
- en: However, For the pixels on the border of the image matrix, some elements of
    the kernel might stand out of the image matrix and therefore does not have any
    corresponding element from the image matrix. In this case, we can eliminate the
    convolution operation for these positions which end up an output matrix smaller
    than the input or we can apply [**padding**](https://www.quora.com/What-are-the-roles-of-stride-and-padding-in-a-convolutional-neural-network) to
    the input matrix.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于图像矩阵边界上的像素，某些滤波器元素可能会超出图像矩阵，因此没有来自图像矩阵的对应元素。在这种情况下，我们可以取消这些位置的卷积操作，从而得到一个比输入矩阵小的输出矩阵，或者我们可以对输入矩阵应用[**填充**](https://www.quora.com/What-are-the-roles-of-stride-and-padding-in-a-convolutional-neural-network)。
- en: Now, I do realize that some of these topics are quite complex and could be made
    in whole posts by themselves. In an effort to remain concise yet retain comprehensiveness,
    I will provide links to resources where the topic is explained in more detail.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我确实意识到这些话题有些复杂，可能需要单独写整篇文章。为了保持简洁而又全面，我将提供一些资源的链接，其中对这些话题进行了更详细的解释。
- en: 'Let’s first apply some custom uniform window to the image. This has the effect
    of burning the image, by averaging each pixel with those nearby:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先对图像应用一些自定义的均匀窗口。这会将图像“烧录”，通过对每个像素与其附近的像素进行平均来实现：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Python image analysis fig 8](../Images/694f2bde257965d4b73bb74db3b180aa.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![Python 图像分析 图 8](../Images/694f2bde257965d4b73bb74db3b180aa.png)'
- en: Please, check this more [here.](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-2/#4-bullet)
    I’ve discussed more in depth and played with various types of kernel and showed
    the differences.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio:** [Mohammed Innat](https://twitter.com/innat_2k14) is currently a fourth
    year undergraduate student majoring in electronics and communication. He is passionate
    about applying his knowledge of machine learning and data science to areas in
    healthcare and crime forecast where better solutions can be engineered in the
    medical sector and security department.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[Basic Image Data Analysis Using Numpy and OpenCV – Part 1]("https://www.kdnuggets.com/2018/07/basic-image-data-analysis-numpy-opencv-p1.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Basic Image Processing in Python, Part 2](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Only Numpy: Implementing GANs and Adam Optimizer using Numpy](https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 29: 20 Basic Linux Commands for Data Science…](https://www.kdnuggets.com/2022/n26.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[It''s alive! Build your first robots with Python and some cheap,…](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How I Did Automatic Image Labeling Using Grounding DINO](https://www.kdnuggets.com/2023/05/automatic-image-labeling-grounding-dino.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Implement Agentic RAG Using LangChain: Part 1](https://www.kdnuggets.com/how-to-implement-agentic-rag-using-langchain-part-1)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 8 Basic Statistics Concepts for Data Science](https://www.kdnuggets.com/2020/06/8-basic-statistics-concepts.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
