- en: Ten Years of AI in Review
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过去十年的人工智能回顾
- en: 原文：[https://www.kdnuggets.com/2023/06/ten-years-ai-review.html](https://www.kdnuggets.com/2023/06/ten-years-ai-review.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/ten-years-ai-review.html](https://www.kdnuggets.com/2023/06/ten-years-ai-review.html)
- en: '![Ten Years of AI in Review](../Images/46e981674cb1b8fd706811a9402111f9.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![过去十年的人工智能回顾](../Images/46e981674cb1b8fd706811a9402111f9.png)'
- en: Image by the Author.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: The last decade has been a thrilling and eventful ride for the field of artificial
    intelligence (AI). Modest explorations of the potential of deep learning turned
    into an explosive proliferation of a field that now includes everything from recommender
    systems in e-commerce to object detection for autonomous vehicles and generative
    models that can create everything from realistic images to coherent text.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年对于人工智能（AI）领域来说是一段激动人心且充满事件的旅程。对深度学习潜力的初步探索转变为一个爆炸性增长的领域，现在包括从电子商务中的推荐系统到自动驾驶车辆的目标检测以及能够生成从逼真图像到连贯文本的生成模型。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article, we’ll take a walk down memory lane and revisit some of the
    key breakthroughs that got us to where we are today. Whether you are a seasoned
    AI practitioner or simply interested in the latest developments in the field,
    this article will provide you with a comprehensive overview of the remarkable
    progress that led AI to become a household name.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将回顾一些关键的突破，带您走一趟记忆之旅，了解我们如何走到今天。不论您是经验丰富的人工智能从业者还是对领域最新发展感兴趣的读者，本文将为您提供对人工智能取得显著进展的全面概述。
- en: '2013: AlexNet and Variational Autoencoders'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2013年：AlexNet和变分自编码器
- en: The year 2013 is widely regarded as the “coming-of-age” of deep learning, initiated
    by major advances in computer vision. According to a recent [interview](https://venturebeat.com/ai/10-years-on-ai-pioneers-hinton-lecun-li-say-deep-learning-revolution-will-continue/) of
    Geoffrey Hinton, by 2013 *“pretty much all the computer vision research had switched
    to neural nets”*. This boom was primarily fueled by a rather surprising breakthrough
    in image recognition one year earlier.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年被广泛认为是深度学习的“成长期”，这一变化由计算机视觉的重大进展引发。根据对Geoffrey Hinton的最新[采访](https://venturebeat.com/ai/10-years-on-ai-pioneers-hinton-lecun-li-say-deep-learning-revolution-will-continue/)，到2013年*“几乎所有的计算机视觉研究都转向了神经网络”*。这一繁荣主要是由于一年前图像识别领域的一个相当意外的突破。
- en: In September 2012, [AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf),
    a deep convolutional neural network (CNN), pulled off a record-breaking performance
    in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), demonstrating
    the potential of deep learning for image recognition tasks. It achieved a [top-5
    error](https://machinelearning.wtf/terms/top-5-error-rate/) of 15.3%, which was
    10.9% lower than that of its nearest competitor.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 2012年9月，[AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)，一个深度卷积神经网络（CNN），在ImageNet大规模视觉识别挑战赛（ILSVRC）中创下了破纪录的成绩，展示了深度学习在图像识别任务中的潜力。它达到了15.3%的[top-5
    error](https://machinelearning.wtf/terms/top-5-error-rate/)，比其最近的竞争对手低10.9%。
- en: '![Ten Years of AI in Review](../Images/708c174a6c86aca682f971273584b125.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![过去十年的人工智能回顾](../Images/708c174a6c86aca682f971273584b125.png)'
- en: Image by the Author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: The technical improvements behind this success were instrumental for the future
    trajectory of AI and dramatically changed the way *deep* learning was perceived.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种成功背后的技术改进对AI的未来轨迹至关重要，并且极大地改变了对*深度*学习的看法。
- en: First, the authors applied a deep CNN consisting of five convolutional layers
    and three fully-connected linear layers — an architectural design dismissed by
    many as impractical at the time. Moreover, due to the large number of parameters
    produced by the network’s depth, training was done in parallel on two graphics
    processing units (GPUs), demonstrating the ability to significantly accelerate
    training on large datasets. Training time was further reduced by swapping traditional
    activation functions, such as sigmoid and tanh, for the more efficient rectified
    linear unit ([ReLU](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，作者们应用了一个由五层卷积层和三层全连接线性层组成的深度 CNN —— 这种架构设计在当时被许多人视为不切实际。此外，由于网络深度产生的大量参数，训练是在两块图形处理单元（GPU）上并行进行的，展示了在大数据集上显著加速训练的能力。通过将传统的激活函数，如
    sigmoid 和 tanh，替换为更高效的整流线性单元（[ReLU](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)），训练时间进一步缩短。
- en: '![Ten Years of AI in Review](../Images/48cbe96a63beacfaa66e113a440806f1.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能十年回顾](../Images/48cbe96a63beacfaa66e113a440806f1.png)'
- en: Image by the Author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。
- en: These advances that collectively led to the success of AlexNet marked a turning
    point in the history of AI and sparked a surge of interest in deep learning among
    both academics and the tech community. As a result, 2013 is considered by many
    as the inflection point after which deep learning truly began to take off.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些进展共同促成了 AlexNet 的成功，标志着人工智能历史的一个转折点，并激发了学术界和科技界对深度学习的强烈兴趣。因此，许多人认为 2013 年是深度学习真正起飞的拐点。
- en: Also happening in 2013, albeit a little drowned out by the noise of AlexNet,
    was the development of variational autoencoders, or [VAEs](https://arxiv.org/abs/1312.6114) —
    generative models that can learn to represent and generate data such as images
    and sounds. They work by learning a compressed representation of the input data
    in a lower-dimensional space, known as *latent space*. This allows them to generate
    new data by sampling from this learned latent space. VAEs, later on, turned out
    to open up new avenues for generative modeling and data generation, with applications
    in fields like art, design, and gaming.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 2013 年的变化在 AlexNet 的喧嚣中稍显被淹没，但变分自编码器（[VAEs](https://arxiv.org/abs/1312.6114)）的发展也同样值得关注
    —— 这些生成模型可以学习表示和生成数据，如图像和声音。它们通过学习输入数据在低维空间中的压缩表示，即 *潜在空间*，来工作。这使得它们能够通过从学习到的潜在空间中采样来生成新数据。后来，VAEs
    证明开辟了生成建模和数据生成的新途径，应用于艺术、设计和游戏等领域。
- en: '2014: Generative Adversarial Networks'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '2014: 生成对抗网络'
- en: The following year, in June 2014, the field of deep learning witnessed another
    serious advance with the introduction of generative adversarial networks, or [GANs](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf),
    by Ian Goodfellow and colleagues.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的一年，即 2014 年 6 月，深度学习领域见证了另一个重大进展，Ian Goodfellow 和同事们引入了生成对抗网络，即 [GANs](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)。
- en: 'GANs are a type of neural network capable of generating new data samples that
    are similar to a training set. Essentially, two networks are trained simultaneously:
    (1) a generator network generates fake, or synthetic, samples, and (2) a discriminator
    network evaluates their authenticity. This training is performed in a game-like
    setup, with the generator trying to create samples that fool the discriminator,
    and the discriminator trying to correctly call out the fake samples.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 是一种能够生成与训练集相似的新数据样本的神经网络类型。基本上，两个网络同时训练：（1）生成器网络生成虚假的或合成的样本，（2）判别器网络评估这些样本的真实性。这种训练在类似游戏的设置中进行，生成器试图创建欺骗判别器的样本，而判别器则试图正确识别虚假样本。
- en: At that time, GANs represented a powerful and novel tool for data generation,
    being used not only for generating images and videos, but also music and art.
    They also contributed to the advance of unsupervised learning, a domain largely
    regarded as underdeveloped and challenging, by demonstrating the possibility to
    generate high-quality data samples without relying on explicit labels.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当时，GANs 代表了一个强大而新颖的数据生成工具，不仅用于生成图像和视频，还用于音乐和艺术。它们还推动了无监督学习的发展，这是一个被普遍认为发展不充分且具有挑战性的领域，展示了在不依赖显式标签的情况下生成高质量数据样本的可能性。
- en: '2015: ResNets and NLP Breakthroughs'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '2015: ResNets 和自然语言处理突破'
- en: In 2015, the field of AI made considerable advances in both computer vision
    and natural language processing, or NLP.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年，人工智能领域在计算机视觉和自然语言处理（NLP）方面取得了显著进展。
- en: Kaiming He and colleagues published a [paper](https://arxiv.org/abs/1512.03385) titled
    “Deep Residual Learning for Image Recognition”, in which they introduced the concept
    of residual neural networks, or ResNets — architectures that allow information
    to flow more easily through the network by adding shortcuts. Unlike in a regular
    neural network, where each layer takes the output of the previous layer as input,
    in a ResNet, additional *residual* connections are added that skip one or more
    layers and directly connect to deeper layers in the network.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 何凯明及其同事发表了一篇题为《深度残差学习用于图像识别》的[论文](https://arxiv.org/abs/1512.03385)，在其中他们引入了残差神经网络（ResNets）的概念——这种架构通过添加捷径，使信息在网络中流动更加顺畅。与普通神经网络不同的是，ResNet在每一层的输入中增加了*残差*连接，这些连接跳过一层或多层，直接连接到网络中的更深层次。
- en: As a result, ResNets were able to solve the problem of [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem),
    which enabled the training of much deeper neural networks beyond what was thought
    to be possible at the time. This, in turn, led to significant improvements in
    image classification and object recognition tasks.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，ResNets能够解决[梯度消失](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)问题，这使得训练比当时认为可能的更深层次的神经网络成为可能。这反过来在图像分类和物体识别任务中带来了显著的改进。
- en: At around the same time, researchers made considerable progress with the development
    of recurrent neural networks ([RNNs](https://en.wikipedia.org/wiki/Recurrent_neural_network))
    and long short-term memory ([LSTM](https://pubmed.ncbi.nlm.nih.gov/9377276/))
    models. Despite having been around since the 1990s, these models only started
    to generate some buzz around 2015, mainly due to factors such as (1) the availability
    of larger and more diverse datasets for training, (2) improvements in computational
    power and hardware, which enabled the training of deeper and more complex models,
    and (3) modifications made along the way, such as more sophisticated gating mechanisms.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一时期，研究人员在递归神经网络（[RNNs](https://en.wikipedia.org/wiki/Recurrent_neural_network)）和长短期记忆（[LSTM](https://pubmed.ncbi.nlm.nih.gov/9377276/)）模型的发展上取得了显著进展。尽管这些模型自1990年代以来已经存在，但它们直到2015年才开始引起关注，这主要由于以下因素：（1）可用于训练的更大且更多样化的数据集，（2）计算能力和硬件的改进，使得训练更深层次和更复杂的模型成为可能，以及（3）在此过程中进行的改进，如更复杂的门控机制。
- en: As a result, these architectures made it possible for language models to better
    understand the context and meaning of text, leading to vast improvements in tasks
    such as language translation, text generation, and sentiment analysis. The success
    of RNNs and LSTMs around that time paved the way for the development of large
    language models (LLMs) we see today.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构使得语言模型能够更好地理解文本的上下文和意义，从而在语言翻译、文本生成和情感分析等任务中取得了巨大的进步。那时RNNs和LSTMs的成功为我们今天看到的大型语言模型（LLMs）的发展铺平了道路。
- en: '2016: AlphaGo'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2016年：AlphaGo
- en: 'After Garry Kasparov’s defeat by IBM’s Deep Blue in 1997, another *human vs.
    machine* battle sent shockwaves through the gaming world in 2016: Google’s AlphaGo
    defeated the world champion of Go, Lee Sedol.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在1997年加里·卡斯帕罗夫被IBM的Deep Blue击败之后，2016年另一场*人类与机器*的对决震撼了游戏界：谷歌的AlphaGo战胜了围棋世界冠军李世石。
- en: '![Ten Years of AI in Review](../Images/3d6c0701f6afd1cb07addecc205925a0.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![十年的人工智能回顾](../Images/3d6c0701f6afd1cb07addecc205925a0.png)'
- en: Photo by [Elena Popova](https://unsplash.com/@elenapopova) on [Unsplash](https://unsplash.com/photos/xdXxY5C9PUo).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Elena Popova](https://unsplash.com/@elenapopova)提供，来源于[Unsplash](https://unsplash.com/photos/xdXxY5C9PUo)。
- en: 'Sedol’s [defeat](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol) marked
    another major milestone in the trajectory of AI advancement: it demonstrated that
    machines could outsmart even the most skilled human players in a game that was
    once considered too complex for computers to handle. Using a combination of [deep
    reinforcement learning](https://en.wikipedia.org/wiki/Deep_reinforcement_learning) and [Monte
    Carlo tree search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search), AlphaGo
    analyzes millions of positions from previous games and evaluates the best possible
    moves — a strategy that far surpasses human decision making in this context.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Sedol的[失败](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol)标志着人工智能发展轨迹上的另一个重大里程碑：它展示了机器可以超越即使是最熟练的人类玩家，在一个曾经被认为过于复杂以至于计算机无法处理的游戏中。AlphaGo使用了[深度强化学习](https://en.wikipedia.org/wiki/Deep_reinforcement_learning)和[蒙特卡罗树搜索](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search)的组合，分析了数百万个先前游戏中的位置，并评估最佳的可能走法——这一策略远远超越了人类在这一背景下的决策能力。
- en: '2017: Transformer Architecture and Language Models'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2017年：变压器架构和语言模型
- en: Arguably, 2017 was the most pivotal year that laid the foundation for the breakthroughs
    in generative AI that we are witnessing today.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，2017年是奠定了我们今天所见生成式AI突破基础的最关键的一年。
- en: In December 2017, Vaswani and colleagues released the foundational [paper](https://arxiv.org/abs/1706.03762) “Attention
    is all you need”, which introduced the transformer architecture that leverages
    the concept of [self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)) to
    process sequential input data. This allowed for more efficient processing of long-range
    dependencies, which had previously been a challenge for traditional RNN architectures.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年12月，Vaswani及其同事发布了基础性的[论文](https://arxiv.org/abs/1706.03762)《Attention
    is all you need》，介绍了利用[self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))概念处理序列输入数据的变压器架构。这使得处理长距离依赖变得更加高效，这曾经是传统RNN架构面临的挑战。
- en: '![Ten Years of AI in Review](../Images/96d0ee6743039a500f77d660e4dcc02a.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能十年回顾](../Images/96d0ee6743039a500f77d660e4dcc02a.png)'
- en: Photo by [Jeffery Ho](https://unsplash.com/@jefferyho) on [Unsplash](https://unsplash.com/photos/x22UAIdif_k).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jeffery Ho](https://unsplash.com/@jefferyho)拍摄，发布于[Unsplash](https://unsplash.com/photos/x22UAIdif_k)。
- en: 'Transformers are comprised of two essential components: encoders and decoders.
    The encoder is responsible for encoding the input data, which, for example, can
    be a sequence of words. It then takes the input sequence and applies multiple
    layers of self-attention and feed-forward neural nets to capture the relationships
    and features within the sentence and learn meaningful representations.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器由两个基本组件组成：编码器和解码器。编码器负责对输入数据进行编码，例如，这可以是一个单词序列。它然后对输入序列应用多个自注意力层和前馈神经网络，以捕捉句子中的关系和特征，并学习有意义的表示。
- en: Essentially, self-attention allows the model to understand relationships between
    different words in a sentence. Unlike traditional models, which would process
    words in a fixed order, transformers actually examine all the words at once. They
    assign something called *attention* scores to each word based on its relevance
    to other words in the sentence.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '本质上，自注意力使模型能够理解句子中不同单词之间的关系。与传统模型按固定顺序处理单词不同，变压器实际上同时检查所有单词。它们为每个单词分配一种称为*注意力*的分数，基于其与句子中其他单词的相关性。 '
- en: The decoder, on the other hand, takes the encoded representation from the encoder
    and produces an output sequence. In tasks such as machine translation or text
    generation, the decoder generates the translated sequence based on the input received
    from the encoder. Similar to the encoder, the decoder also consists of multiple
    layers of self-attention and feed-forward neural nets. However, it includes an
    additional attention mechanism that enables it to focus on the encoder’s output.
    This then allows the decoder to take into account relevant information from the
    input sequence while generating the output.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器则从编码器那里获取编码表示并生成输出序列。在机器翻译或文本生成等任务中，解码器根据从编码器接收到的输入生成翻译序列。与编码器类似，解码器也由多个自注意力层和前馈神经网络组成。然而，它包含一个额外的注意力机制，使其能够关注编码器的输出。这使得解码器在生成输出时可以考虑输入序列中的相关信息。
- en: The transformer architecture has since become a key component in the development
    of LLMs and has led to significant improvements across the domain of NLP, such
    as machine translation, language modeling, and question answering.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: transformer架构从此成为LLMs开发中的关键组件，并在自然语言处理领域如机器翻译、语言建模和问答等方面取得了显著改进。
- en: '2018: GPT-1, BERT and Graph Neural Networks'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2018年：GPT-1、BERT和图神经网络
- en: A few months after Vaswani et al. published their foundational paper, the **G**enerative **P**retrained **T**ransformer,
    or [GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf),
    was introduced by OpenAI in June 2018, which utilized the transformer architecture
    to effectively capture long-range dependencies in text. GPT-1 was one of the first
    models to demonstrate the effectiveness of unsupervised pre-training followed
    by fine-tuning on specific NLP tasks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月后，Vaswani等人发布了他们的基础论文，**G**enerative **P**retrained **T**ransformer，或 [GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)，在2018年6月由OpenAI推出，利用transformer架构有效地捕捉文本中的长程依赖关系。GPT-1是最早展示无监督预训练然后在特定NLP任务上进行微调的有效性的模型之一。
- en: 'Also taking advantage of the still quite novel transformer architecture was
    Google, who, in late 2018, released and open-sourced their own pre-training method
    called **B**idirectional **E**ncoder **R**epresentations from **T**ransformers,
    or [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html).
    Unlike previous models that process text in a unidirectional manner (including
    GPT-1), BERT considers the context of each word in both directions simultaneously.
    To illustrate this, the authors provide a very intuitive example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Google也利用了仍然相当新颖的transformer架构，在2018年底发布并开源了他们自己的预训练方法，称为**B**idirectional **E**ncoder
    **R**epresentations from **T**ransformers，或 [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)。与以前以单向方式处理文本的模型（包括GPT-1）不同，BERT同时考虑每个词的前后文。为了说明这一点，作者提供了一个非常直观的例子：
- en: '*… in the sentence *“I accessed the bank account”*, a unidirectional contextual
    model would represent *“bank”* based on *“I accessed the”* but not *“account”*.
    However, BERT represents *“bank”* using both its previous and next context — *“I
    accessed the … account”* — starting from the very bottom of a deep neural network,
    making it deeply bidirectional.*'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*…在句子*“I accessed the bank account”*中，单向上下文模型会根据*“I accessed the”*来表示*“bank”*，而不是*“account”*。然而，BERT使用其前后的上下文来表示*“bank”*——*“I
    accessed the … account”*——从深层神经网络的最底层开始，使其深度双向。*'
- en: The concept of bidirectionality was so powerful that it led BERT to outperform
    state-of-the-art NLP systems on a variety of benchmark tasks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 双向性的概念如此强大，以至于使BERT在各种基准任务上超越了最先进的NLP系统。
- en: Apart from GPT-1 and BERT, graph neural networks, or [GNNs](https://en.wikipedia.org/wiki/Graph_neural_network),
    also made some noise that year. They belong to a category of neural networks that
    are specifically designed to work with graph data. GNNs utilize a message passing
    algorithm to propagate information across the nodes and edges of a graph. This
    enables the network to learn the structure and relationships of the data in a
    much more intuitive way.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 除了GPT-1和BERT之外，图神经网络，或 [GNNs](https://en.wikipedia.org/wiki/Graph_neural_network)，在那一年也引起了一些关注。它们属于一种专门设计用于处理图数据的神经网络类别。GNNs利用消息传递算法在图的节点和边之间传播信息。这使得网络能够以一种更直观的方式学习数据的结构和关系。
- en: This work allowed for the extraction of much deeper insights from data and,
    consequently, broadened the range of problems that deep learning could be applied
    to. With GNNs, major advances were made possible in areas like social network
    analysis, recommendation systems, and drug discovery.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作使得从数据中提取更深层次的洞察成为可能，并因此拓宽了深度学习可以应用的领域。通过GNNs，社会网络分析、推荐系统和药物发现等领域取得了重大进展。
- en: '2019: GPT-2 and Improved Generative Models'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2019年：GPT-2和改进的生成模型
- en: The year 2019 marked several notable advancements in generative models, particularly
    the introduction of [GPT-2](https://openai.com/research/gpt-2-1-5b-release). This
    model really left its peers in the dust by achieving state-of-the-art performance
    in many NLP tasks and, in addition, was capable to generate highly realistic text,
    which, in hindsight, gave us a teaser of what was about to come in this arena.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 2019年标志着生成模型的几项显著进展，特别是[GPT-2](https://openai.com/research/gpt-2-1-5b-release)的推出。该模型在许多自然语言处理任务中实现了最先进的性能，并且能够生成高度真实的文本，这在回顾中给我们预示了这一领域即将到来的进展。
- en: Other improvements in this domain included DeepMind’s [BigGAN](https://www.deepmind.com/open-source/big-gan),
    which generated high-quality images that were almost indistinguishable from real
    images, and NVIDIA’s [StyleGAN](https://github.com/NVlabs/stylegan), which allowed
    for better control over the appearance of those generated images.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域的其他改进包括DeepMind的[BigGAN](https://www.deepmind.com/open-source/big-gan)，该模型生成的高质量图像几乎无法与真实图像区分开来，以及NVIDIA的[StyleGAN](https://github.com/NVlabs/stylegan)，该模型允许对生成图像的外观进行更好的控制。
- en: Collectively, these advancements in what’s now known as generative AI pushed
    the boundaries of this domain even further, and…
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来看，这些现在被称为生成式人工智能的进展进一步推动了这一领域的边界，而且…
- en: '2020: GPT-3 and Self-Supervised Learning'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2020年：GPT-3 和 自监督学习
- en: … not soon thereafter, another model was born, which has become a household
    name even outside of the tech community: [GPT-3](https://arxiv.org/abs/2005.14165).
    This model represented a major leap forward in the scale and capabilities of LLMs.
    To put things into context, GPT-1 sported a measly 117 million parameters. That
    number went up to 1.5 billion for GPT-2, and 175 billion for GPT-3.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: …不久之后，另一种模型诞生了，即使在技术圈外也已成为家喻户晓的名字：[GPT-3](https://arxiv.org/abs/2005.14165)。该模型代表了LLM规模和能力的重大飞跃。为了说明情况，GPT-1仅拥有117百万个参数，而GPT-2增加到了15亿个参数，而GPT-3则达到了1750亿个参数。
- en: This vast amount of parameter space enables GPT-3 to generate remarkably coherent
    text across a wide range of prompts and tasks. It also demonstrated impressive
    performance in a variety of NLP tasks, such as text completion, question answering,
    and even creative writing.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种庞大的参数空间使得GPT-3能够在各种提示和任务中生成异常连贯的文本。它还在文本完成、问答甚至创意写作等多种自然语言处理任务中展示了令人印象深刻的表现。
- en: Moreover, GPT-3 highlighted again the potential of using self-supervised learning,
    which allows models to be trained on large amounts of unlabeled data. This has
    the advantage that these models can acquire a broad understanding of language
    without the need for extensive task-specific training, which makes it far more
    economical.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GPT-3再次突显了使用自监督学习的潜力，这使得模型能够在大量未标注的数据上进行训练。这种方法的优势在于，这些模型能够在没有广泛任务特定训练的情况下获得对语言的广泛理解，从而使其成本更为经济。
- en: Yann LeCun tweets about an NYT article on self-supervised learning.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Yann LeCun 在推特上讨论了关于自监督学习的纽约时报文章。
- en: '2021: AlphaFold 2, DALL·E and GitHub Copilot'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2021年：AlphaFold 2、DALL·E 和 GitHub Copilot
- en: From protein folding to image generation and automated coding assistance, the
    year of 2021 was an eventful one thanks to the releases of AlphaFold 2, DALL·E,
    and GitHub Copilot.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从蛋白质折叠到图像生成和自动编码辅助，2021年因AlphaFold 2、DALL·E和GitHub Copilot的发布而变得尤为重要。
- en: '[AlphaFold 2](https://www.nature.com/articles/s41586-021-03819-2) was hailed
    as a long-awaited solution to the decades-old protein folding problem. DeepMind’s
    researchers extended the transformer architecture to create *evoformer blocks* —
    architectures that leverage evolutionary strategies for model optimization — to
    build a model capable of predicting a protein’s 3D structure based on its 1D amino
    acid sequence. This breakthrough has enormous potential to revolutionize areas
    like drug discovery, bioengineering, as well as our understanding of biological
    systems.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[AlphaFold 2](https://www.nature.com/articles/s41586-021-03819-2) 被誉为解决了困扰了几十年的蛋白质折叠问题的长期期待的解决方案。DeepMind的研究人员扩展了变压器架构，创建了*evoformer
    blocks* —— 利用进化策略进行模型优化的架构 —— 以构建一个能够根据蛋白质的1D氨基酸序列预测其3D结构的模型。这一突破有着巨大的潜力，能够革新药物发现、生物工程以及我们对生物系统的理解等领域。'
- en: OpenAI also made it in the news again this year with their release of [DALL·E](https://openai.com/product/dall-e-2).
    Essentially, this model combines the concepts of GPT-style language models and
    image generation to enable the creation of high-quality images from textual descriptions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI今年再次登上新闻头条，推出了[DALL·E](https://openai.com/product/dall-e-2)。本质上，这个模型结合了GPT风格语言模型和图像生成的概念，使得从文本描述中生成高质量图像成为可能。
- en: To illustrate how powerful this model is, consider the image below, which was
    generated with the prompt “Oil painting of a futuristic world with flying cars”.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这个模型的强大，请看下面的图像，这幅图像是根据“未来世界的油画，飞行汽车”这一提示生成的。
- en: '![Ten Years of AI in Review](../Images/0670b0f6173da8211da081333ad5812b.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![十年人工智能回顾](../Images/0670b0f6173da8211da081333ad5812b.png)'
- en: Image produced by DALL·E.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: DALL·E生成的图像。
- en: Lastly, GitHub released what would later become every developers best friend: [Copilot](https://github.com/features/copilot).
    This was achieved in collaboration with OpenAI, which provided the underlying
    language model, Codex, that was trained on a large corpus of publicly available
    code and, in turn, learned to understand and generate code in various programming
    languages. Developers can use Copilot by simply providing a code comment stating
    the problem they are trying to solve, and the model would then suggest code to
    implement the solution. Other features include the ability to describe input code
    in natural language and translate code between programming languages.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，GitHub发布了后来成为每个开发者最佳朋友的[Copilot](https://github.com/features/copilot)。这项成就与OpenAI合作实现，OpenAI提供了基础语言模型Codex，该模型经过大量公开代码的训练，从而学会理解和生成各种编程语言的代码。开发者只需提供一个代码注释说明他们试图解决的问题，模型就会建议实现解决方案的代码。其他功能包括用自然语言描述输入代码以及在编程语言之间转换代码。
- en: '2022: ChatGPT and Stable Diffusion'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2022年：ChatGPT与Stable Diffusion
- en: 'The rapid development of AI over the past decade has culminated in a groundbreaking
    advancement: OpenAI’s [ChatGPT](https://openai.com/blog/chatgpt), a chatbot that
    was released into the wild in November 2022\. The tool represents a cutting-edge
    achievement in NLP, capable of generating coherent and contextually relevant responses
    to a wide range of queries and prompts. Furthermore, it can engage in conversations,
    provide explanations, offer creative suggestions, assist with problem-solving,
    write and explain code, and even simulate different personalities or writing styles.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年里，人工智能的迅速发展 culminated in 一项突破性的进展：OpenAI的[ChatGPT](https://openai.com/blog/chatgpt)，这款聊天机器人于2022年11月正式发布。该工具代表了自然语言处理领域的尖端成就，能够对各种查询和提示生成连贯且具有上下文相关的回答。此外，它还可以进行对话、提供解释、提出创意建议、协助解决问题、编写和解释代码，甚至模拟不同的个性或写作风格。
- en: '![Ten Years of AI in Review](../Images/dd5a0fa103746ac3271b75f172347f08.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![十年人工智能回顾](../Images/dd5a0fa103746ac3271b75f172347f08.png)'
- en: Image by the Author.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: The simple and intuitive interface through which one can interact with the bot
    also stimulated a sharp rise in usability. Previously, it was mostly the tech
    community that would play around with the latest AI-based inventions. However,
    these days, AI tools have penetrated almost every professional domain, from software
    engineers to writers, musicians, and advertisers. Many companies are also using
    the model to automate services such as customer support, language translation,
    or answering FAQs. In fact, the wave of automation we’re seeing has rekindled
    some worries and stimulated discussions on which jobs might be at risk of being
    automated.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过与机器人互动的简单直观界面也刺激了可用性的急剧提升。以前，主要是科技界在尝试最新的人工智能发明。然而，现在，人工智能工具已渗透到几乎每个专业领域，从软件工程师到作家、音乐家和广告商。许多公司也在使用这一模型来自动化服务，例如客户支持、语言翻译或回答常见问题。实际上，我们看到的自动化浪潮重新点燃了一些担忧，并激发了关于哪些工作可能面临自动化风险的讨论。
- en: Even though ChatGPT was taking up much of the limelight in 2022, there was also
    a significant advancement made in image generation. [Stable diffusion](https://stability.ai/blog/stable-diffusion-public-release),
    a latent text-to-image diffusion model capable of generating photo-realistic images
    from text descriptions, was released by Stability AI.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ChatGPT在2022年占据了许多焦点，但图像生成领域也取得了重要进展。[Stable diffusion](https://stability.ai/blog/stable-diffusion-public-release)，一种能够从文本描述生成逼真图像的潜在文本到图像扩散模型，由Stability
    AI发布。
- en: Stable diffusion is an extension of the traditional diffusion models, which
    work by iteratively adding noise to images and then reversing the process to recover
    the data. It was designed to speed up this process by operating not directly on
    the input images, but instead on a lower-dimensional representation, or latent
    space, of them. In addition, the diffusion process is modified by adding the transformer-embedded
    text prompt from the user to the network, allowing it to guide the image generation
    process throughout each iteration.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散是传统扩散模型的扩展，这些模型通过反复向图像添加噪声，然后逆转过程以恢复数据。它的设计旨在通过不直接处理输入图像，而是处理其低维表示或潜在空间，从而加速这一过程。此外，通过将用户提供的嵌入变换器的文本提示添加到网络中，扩散过程也得到了修改，使其能够在每次迭代过程中引导图像生成过程。
- en: Overall, the release of both ChatGPT and Stable Diffusion in 2022 highlighted
    the potential of multimodal, generative AI and sparked a massive boost of further
    development and investment in this area.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，2022 年 ChatGPT 和稳定扩散的发布突显了多模态生成 AI 的潜力，并激发了这一领域进一步发展的巨大推动力和投资。
- en: '2023: LLMs and Bots'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2023：LLMs 和聊天机器人
- en: The current year has undoubtedly emerged as the year of LLMs and chatbots. More
    and more models are being developed and released at a rapidly increasing pace.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 今年无疑成为了LLMs和聊天机器人的一年。越来越多的模型正在快速开发和发布。
- en: '![Ten Years of AI in Review](../Images/538a846ed6c221116b068741cbd43f5f.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能十年回顾](../Images/538a846ed6c221116b068741cbd43f5f.png)'
- en: Image by the Author.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: For instance, on February 24th, Meta AI released [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) —
    an LLM that outperforms GPT-3 on most benchmarks, despite having a considerably
    smaller number of parameters. Less than a month later, on March 14th, OpenAI released [GPT-4](https://openai.com/product/gpt-4) —
    a bigger, more capable, and multimodal version of GPT-3\. While the exact number
    of parameters of GPT-4 is unknown, it is speculated to be in the trillions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，2月24日，Meta AI 发布了 [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)——一个在大多数基准测试中优于
    GPT-3 的 LLM，尽管其参数数量要少得多。不到一个月后，3月14日，OpenAI 发布了 [GPT-4](https://openai.com/product/gpt-4)——一个比
    GPT-3 更大、更强大且多模态的版本。虽然 GPT-4 的确切参数数量尚不清楚，但推测在万亿级别。
- en: On March 15, researchers at Stanford University released [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html),
    a light-weight language model that was fine-tuned from LLaMA on instruction-following
    demonstrations. A couple days later, on March 21st, Google launched its ChatGPT
    rival: [Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/).
    Google also just released its latest LLM, [PaLM-2](https://ai.google/discover/palm2),
    earlier this month on May 10th. With the relentless pace of development in this
    area, it is highly likely that yet another model will have emerged by the time
    you’re reading this.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 3月15日，斯坦福大学的研究人员发布了 [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)，这是一个从
    LLaMA 上经过微调的轻量级语言模型，专注于跟随指令的演示。几天后，3月21日，Google 推出了其 ChatGPT 竞争对手：[Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/)。Google
    还在本月 5月10日 发布了其最新的 LLM，[PaLM-2](https://ai.google/discover/palm2)。鉴于这一领域发展的迅猛，阅读本文时很可能又会出现另一个模型。
- en: We are also seeing more and more companies incorporating these models into their
    products. For example, Duolingo announced its GPT-4-powered [Duolingo Max](https://blog.duolingo.com/duolingo-max/),
    a new subscription tier with the aim of providing tailored language lessons to
    each individual. Slack has also rolled out an AI-powered assistant called [Slack
    GPT](https://slack.com/blog/news/introducing-slack-gpt), which can do things like
    draft replies or summarize threads. Furthermore, Shopify introduced a ChatGPT-powered
    assistant to the company’s Shop app, which can help customers identify desired
    products using a variety of prompts.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到越来越多的公司将这些模型融入到他们的产品中。例如，Duolingo 宣布了其 GPT-4 驱动的 [Duolingo Max](https://blog.duolingo.com/duolingo-max/)，这是一个新的订阅层，旨在为每个人提供量身定制的语言课程。Slack
    也推出了一个名为 [Slack GPT](https://slack.com/blog/news/introducing-slack-gpt) 的 AI 驱动的助手，可以进行草拟回复或总结线程。此外，Shopify
    向公司的 Shop 应用程序引入了一个 ChatGPT 驱动的助手，能够通过各种提示帮助客户识别所需的产品。
- en: Shopify announcing its ChatGPT-powered assistant on Twitter.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Shopify 在 Twitter 上宣布了其 ChatGPT 驱动的助手。
- en: Interestingly, AI chatbots are nowadays even considered as an alternative to
    human therapists. For example, [Replika](https://replika.com/), a US chatbot app,
    is offering users an “*AI companion who cares, always here to listen and talk,
    always on your side*”. Its founder, Eugenia Kuyda, says that the app has a wide
    variety of customers, ranging from autistic children, who turn to it as a way
    to “*warm up before human interactions*”, to lonely adults who simply are in the
    need of a friend.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，如今人工智能聊天机器人甚至被视为人类治疗师的替代品。例如，[Replika](https://replika.com/)是一款美国的聊天机器人应用，它为用户提供了一个“*关心你的AI伴侣，总是愿意倾听和交谈，总是站在你这边*”。其创始人尤金妮亚·库伊达表示，该应用拥有各种各样的用户，从将其作为“*在与人互动之前热身*”的自闭症儿童，到只是需要一个朋友的孤独成年人。
- en: 'Before we conclude, I’d like to highlight what may well be the climax of the
    last decade of AI development: people are actually using Bing! Earlier this year,
    Microsoft [introduced](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/) its
    GPT-4-powered “*copilot for the web*” that has been customized for search and,
    for the first time in… forever (?), has emerged as a serious contender to Google’s
    long-standing dominance in the search business.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们总结之前，我想强调一下过去十年人工智能发展的高潮：人们实际上在使用 Bing！今年早些时候，微软[推出了](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)其基于
    GPT-4 的“*网络副驾驶*”，该工具经过定制用于搜索，并且在……永远（？）中第一次成为了谷歌在搜索业务中长期主导地位的严肃竞争者。
- en: Looking back and looking forward
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回顾与展望
- en: As we reflect on the last ten years of AI development, it becomes evident that
    we have been witnessing a transformation that has had profound impact on how we
    work, do business, and interact with one another. Most of the considerable progress
    that has lately been achieved with generative models, particularly LLMs, seems
    to be adhering to the common belief that “bigger is better”, referring to the
    parameter space of the models. This has been especially noticeable with the GPT
    series, which started out with 117 million parameters (GPT-1) and, after each
    successive model increasing by approximately an order of magnitude, culminated
    in GPT-4 with potentially trillions of parameters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们回顾过去十年的人工智能发展时，显而易见的是，我们见证了一场对工作、商业和相互互动产生深远影响的变革。最近在生成模型，特别是 LLMs（大型语言模型）方面取得的大量进展，似乎遵循了“更大更好”的普遍信念，指的是模型的参数空间。这一点在
    GPT 系列中尤为明显，该系列从 117 百万参数的 GPT-1 起步，每个后续模型的参数数量增加了约一个数量级，最终在 GPT-4 中达到可能的万亿级参数。
- en: However, based on a recent [interview](https://techcrunch.com/2023/04/14/sam-altman-size-of-llms-wont-matter-as-much-moving-forward/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAANxF1G0qEgpUn-9mD7CxuZrc77IDr8t-QvyX3Do6Koa10eGy5DYiq3lzXDAJRakptl0Jy49OkuxXU8zD-3-8l-h3YJxFgKRwk5HqIHdhG2BIXavq5Tfn1HHz6IKk8-y86xZbyHXZJwE_Q_OFXr4nrHygrl48-WxX7vdgTft_lhw),
    OpenAI CEO Sam Altman believes that we have reached the end of the “bigger is
    better” era. Going forward, he still thinks that the parameter count will trend
    up, but the main focus of future model improvements will be on increasing the
    model’s capability, utility, and safety.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，根据最近的[采访](https://techcrunch.com/2023/04/14/sam-altman-size-of-llms-wont-matter-as-much-moving-forward/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAANxF1G0qEgpUn-9mD7CxuZrc77IDr8t-QvyX3Do6Koa10eGy5DYiq3lzXDAJRakptl0Jy49OkuxXU8zD-3-8l-h3YJxFgKRwk5HqIHdhG2BIXavq5Tfn1HHz6IKk8-y86xZbyHXZJwE_Q_OFXr4nrHygrl48-WxX7vdgTft_lhw)，OpenAI
    CEO Sam Altman 认为我们已经迎来了“更大更好”时代的终结。他认为，尽管未来模型的参数数量仍会增长，但未来模型改进的主要焦点将是提升模型的能力、实用性和安全性。
- en: The latter is of particular importance. Considering that these powerful AI tools
    are now in the hands of the general public and no longer confined to the controlled
    environment of research labs, it is now more critical than ever that we tread
    with caution and ensure that these tools are safe and align with humanity’s best
    interests. Hopefully we’ll see as much development and investment in AI safety
    as we’ve seen in other areas.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 后者尤为重要。考虑到这些强大的人工智能工具现在已经进入了公众手中，不再仅限于受控的研究实验室环境，我们现在比以往任何时候都更需要谨慎行事，确保这些工具是安全的，并符合人类的最佳利益。希望我们在人工智能安全方面能够看到与其他领域相同的开发和投资。
- en: '**PS:** In case I’ve missed a core AI concept or breakthrough that you think
    should have been included in this article, please let me know in the comments
    below!'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**附注：** 如果我遗漏了你认为应该包含在本文中的核心AI概念或突破，请在下方评论中告知我！'
- en: '**[Thomas A Dorfer](https://www.linkedin.com/in/thomasdorfer/)** is a Data
    & Applied Scientist at Microsoft. Prior to his current role, he worked as a data
    scientist in the biotech industry and as a researcher in the domain of neurofeedback.
    He holds a Master''s degree in Integrative Neuroscience and, in his spare time,
    also writes technical blog posts on Medium on the subjects of data science, machine
    learning, and AI.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**[托马斯·A·多弗](https://www.linkedin.com/in/thomasdorfer/)** 是微软的数据与应用科学家。在担任现职之前，他曾在生物技术行业担任数据科学家，并在神经反馈领域从事研究工作。他拥有整合神经科学硕士学位，并在业余时间在Medium上撰写有关数据科学、机器学习和AI的技术博客。'
- en: '[Original](https://medium.com/towards-data-science/ten-years-of-ai-in-review-85decdb2a540).
    Reposted with permission.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/towards-data-science/ten-years-of-ai-in-review-85decdb2a540)。经授权转载。'
- en: More On This Topic
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[30 Years of Data Science: A Review From a Data Science Practitioner](https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学30年：一位数据科学从业者的回顾](https://www.kdnuggets.com/30-years-of-data-science-a-review-from-a-data-science-practitioner)'
- en: '[Ten Key Lessons of Implementing Recommendation Systems in Business](https://www.kdnuggets.com/2022/07/ten-key-lessons-implementing-recommendation-systems-business.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实施推荐系统在业务中的十大关键教训](https://www.kdnuggets.com/2022/07/ten-key-lessons-implementing-recommendation-systems-business.html)'
- en: '[How I 14Xed my salary in 14 years as a data analytics/science professional](https://www.kdnuggets.com/2021/12/14x-salary-in-14-years-data-professional.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我如何在14年内将薪水提高14倍，作为数据分析/科学专业人士](https://www.kdnuggets.com/2021/12/14x-salary-in-14-years-data-professional.html)'
- en: '[40% of Labour Force Will be Affected by AI in 3 Years](https://www.kdnuggets.com/40-of-labour-force-will-be-affected-by-ai-in-3-years)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3年内40%的劳动力将受到AI的影响](https://www.kdnuggets.com/40-of-labour-force-will-be-affected-by-ai-in-3-years)'
- en: '[Python For Machine Learning: eBook Review](https://www.kdnuggets.com/2022/06/python-machine-learning-ebook-review.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习的Python：电子书评测](https://www.kdnuggets.com/2022/06/python-machine-learning-ebook-review.html)'
- en: '[Google Data Analytics Certification Review for 2023](https://www.kdnuggets.com/2023/01/google-data-analytics-certification-review-2023.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年Google数据分析认证评测](https://www.kdnuggets.com/2023/01/google-data-analytics-certification-review-2023.html)'
