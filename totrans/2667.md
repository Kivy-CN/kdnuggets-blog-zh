# 如何将表格数据与HuggingFace Transformers结合

> 原文：[https://www.kdnuggets.com/2020/11/tabular-data-huggingface-transformers.html](https://www.kdnuggets.com/2020/11/tabular-data-huggingface-transformers.html)

[评论](#comments)

**由[Ken Gu](https://www.linkedin.com/in/ken-gu/)，Georgian的应用研究科学实习生**。

基于变换器的模型在使用非结构化文本数据方面是一个游戏规则的改变者。截至2020年9月，通用语言理解评估（GLUE）基准测试中的顶级模型都是BERT变换器模型。在[Georgian](http://georgian.io/)中，我们发现自己在处理支持的表格特征信息以及非结构化文本数据。我们发现，通过在[我们的模型](http://georgian.io/platform/research-at-georgian/)中使用表格数据，可以进一步提高性能，因此我们着手构建一个工具包，使其他人也能更容易做到这一点。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT需求

* * *

![](../Images/f61083950afa7309c6727bd485c6062b.png)

*GLUE基准测试中的9项任务。*

### 基于变换器的模型

使用变换器的主要好处是它们可以学习文本之间的长期依赖关系，并且可以并行训练（与序列到序列模型不同），这意味着它们可以在大量数据上进行预训练。

鉴于这些优势，BERT 现在是许多现实世界应用中的基础模型。同样，借助像[HuggingFace Transformers](https://huggingface.co/transformers/)这样的库，可以轻松构建在常见NLP问题上表现出色的变换器模型。

使用非结构化文本数据的变换器模型已经得到很好的理解。然而，在现实世界中，文本数据通常会得到丰富的结构化数据或其他非结构化数据（如音频或视觉信息）的支持。这些每一种可能提供的信息信号是单独一种数据无法提供的。我们称这些不同的数据体验方式——音频、视觉或文本——为模态。

以电子商务评论为例。除了评论文本本身外，我们还拥有关于卖家、买家和产品的数值和分类特征信息。

我们开始探索如何将文本和表格数据结合起来，以在我们的项目中提供更强的信号。我们开始探索被称为多模态学习的领域，该领域专注于如何在机器学习中处理不同的模态。

### 多模态文献综述

当前的多模态学习模型主要集中于从感官模态（如音频、视觉和文本）中学习。

在多模态学习中，有几个研究分支。卡内基梅隆大学的MultiComp实验室提供了一个出色的[taxonomy](http://multicomp.cs.cmu.edu/research/taxonomy/)。我们的问题属于被称为**多模态融合**——将来自两种或更多模态的信息结合起来以进行预测。

由于文本数据是我们的主要模态，我们的综述集中在将文本视为主要模态并介绍利用变压器架构的模型的文献上。

**结构化数据的微不足道的解决方案**

在我们深入文献之前，值得一提的是，有一种简单的解决方案可以将结构化数据作为常规文本处理，并附加到标准文本输入中。以电子商务评论为例，输入可以结构化为：评论。买家信息。卖家信息。数字/标签。等等。然而，这种方法的一个警告是，它受限于变压器能够处理的最大标记长度。

### 图像和文本中的变压器

在过去的几年中，图像和文本的变压器扩展已经取得了真正的进展。[用于分类图像和文本的监督多模态双变换器](https://arxiv.org/pdf/1909.02950.pdf)（Kiela等，2019年）使用在单模态图像和文本上的预训练ResNet和预训练BERT特征，并将其输入到双向变压器中。关键创新是将图像特征适配为变压器模型的额外标记。

![](../Images/ef286dead61facdee4957f8ef1ec5b29.png)

*多模态变压器的示意图。该模型将ResNet在图像子区域上的输出作为输入图像标记。*

此外，还有一些模型——[ViLBERT](https://arxiv.org/abs/1908.02265)（Lu等，2019年）和[VLBert](https://arxiv.org/pdf/1908.08530.pdf)（Su等，2020年）——定义了图像和文本的预训练任务。这些模型都在[Conceptual Captions数据集](https://ai.google.com/research/ConceptualCaptions)上进行预训练，该数据集包含约330万对图像-标题对（来自alt文本的网页图像及其标题）。在这两种情况下，对于任何给定的图像，像Faster R-CNN这样的预训练对象检测模型会获取图像区域的向量表示，这些表示作为输入标记嵌入到变压器模型中。

![](../Images/90d0dd095ad4a5abb47417f9c112168a.png)

*VLBert模型图。它将Faster R-CNN输出的图像区域作为输入图像标记。*

例如，ViLBert在以下训练目标上进行预训练：

1.  **遮蔽多模态建模：** 遮蔽输入图像和词汇标记。对于图像，模型试图预测捕捉图像区域特征的向量，而对于文本，它基于文本和视觉线索预测被遮蔽的文本。

1.  **多模态对齐：** 图像和文本对是否确实来自同一图像和标题对。

![](../Images/1be6a703b698972f151b8964c46bfb09.png)

*ViLBERT 的两个预训练任务。*

![](../Images/f4fa4d30f67670e2cb7bc7237297819d.png)

![](../Images/e64e06ac18027d7ebda7c21140686ce2.png)

*一个遮蔽多模态学习的示例。给定图像和文本，如果我们遮蔽掉*dog*，则模型应能够利用未遮蔽的视觉信息正确预测被遮蔽的词为*dog*。*

所有这些模型使用双向变压器模型，这是 BERT 的核心。区别在于模型训练的预训练任务以及对变压器的轻微添加。在 ViLBERT 的情况下，作者还引入了一个共注意力变压器层（见下图），以显式定义模态之间的注意力机制。

![](../Images/3c2cee8e6ff7f49649f4b2b8f2627a38.png)

*标准变压器块与共注意力变压器块。共注意力块将另一种模态（例如语言）的注意力加权向量注入当前模态（视觉）的隐藏表示中。*

最后，还有[LXMERT](https://arxiv.org/abs/1908.07490)（Tan 和 Mohit 2019），另一种预训练的变压器模型，截至[Transformers 版本 3.1.0](https://pypi.org/project/transformers/3.1.0/)，作为库的一部分实现。LXMERT 的输入与 ViLBERT 和 VLBERT 相同。然而，LXMERT 在聚合的数据集上进行预训练，这些数据集还包括视觉问答数据集。总的来说，LXMERT 在 918 万对图像文本上进行预训练。

### 对齐音频、视觉和文本的变压器

除了用于结合图像和文本的变压器，还有用于音频、视频和文本模态的多模态模型，其中存在自然的真实时间对齐。相关论文包括 MulT，[Multimodal Transformer for Unaligned Multimodal Language Sequences](https://arxiv.org/pdf/1906.00295.pdf)（Tsai 等 2019），以及来自[Integrating Multimodal Information in Large Pretrained Transformers](https://www.aclweb.org/anthology/2020.acl-main.214.pdf)（Rahman 等 2020）的多模态适应门（MAG）。

MuIT 与 ViLBERT 类似，在模态对之间使用共注意力。而 MAG 则通过门控机制在某些变压器层中注入其他模态信息。

### 带有文本和知识图谱嵌入的变压器

一些研究还识别了知识图谱作为除文本数据之外的重要信息。[用知识图谱嵌入增强BERT进行文档分类](https://arxiv.org/pdf/1909.08402.pdf)（Ostendorff et al. 2019）除了书籍类别分类的元数据特征外，还使用了Wikidata知识图谱中的作者实体特征。在这种情况下，该模型是这些特征和BERT输出的书名和描述的文本特征的简单连接，然后是一些最终分类层。

![](../Images/36a31b4dd50e91186d80c891e7bdb9d6.png)

*简单的模型架构以融入知识图谱嵌入和表格元数据。*

另一方面，[ERNIE](https://arxiv.org/abs/1905.07129)（Zhang et al. 2019）将输入文本中的令牌与知识图谱中的实体进行匹配。他们融合这些嵌入，以产生具有实体意识的文本嵌入和具有文本意识的实体嵌入。

### 关键要点

适应变换器以处理多模态数据的主要要点是确保在不同模态之间存在注意力或加权机制。这些注意力机制可以在变换器架构的不同点出现，如编码的输入嵌入、在中间注入，或在变换器编码文本数据后合并。

### 多模态变换器工具包

使用我们从文献回顾和全面的[HuggingFace](https://huggingface.co/)最先进的变换器库中学到的知识，我们开发了一个工具包。**multimodal-transformers**包扩展了任何HuggingFace变换器以适应表格数据。要查看代码、文档和工作示例，请查看[项目仓库](https://github.com/georgianpartners/Multimodal-Toolkit)。

从高层次来看，变换器模型在文本数据和包含分类和数值数据的表格特征上的输出在结合模块中进行合并。由于数据中没有对齐，我们选择在变换器输出后合并文本特征。结合模块实现了几种集成模态的方法，包括受到文献调查启发的注意力和门控方法。这些方法的更多细节请见[这里](https://multimodal-toolkit.readthedocs.io/en/latest/notes/combine_methods.html)。

![](../Images/eb26b789b45570eadbc807594df6838c.png)

*多模态变换器的高级图示。变换器适应以融合数据的所有内容都包含在结合模块中。*

### 演练

让我们通过一个示例来进行分类衣物评论推荐。我们将使用Colab笔记本中包含的示例的简化版本。我们将使用Kaggle上的[女性电子商务服装评论](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews)，该数据集包含23,000条客户评论。

![](../Images/8b90adc7515e33fdd0d1fe2814d20360.png)

*衣物评论数据集的一个示例。*

在这个数据集中，我们在标题和评论文本列中有文本数据。我们还从*Clothing ID, Division Name, Department Name, 和 Class Name*列中获得类别特征，从*Rating 和 Positive Feedback Count*列中获得数值特征。

### 加载数据集

我们首先将数据加载到**TorchTabularTextDataset**中，该数据集与 PyTorch 的数据加载器兼容，包括 HuggingFace Transformers 的文本输入，以及我们指定的类别特征列和数值特征列。为此，我们还需要加载 HuggingFace 的分词器。

### 使用表格模型加载变换器

现在我们使用表格模型加载变换器。首先，我们在**TabularConfig**对象中指定我们的表格配置。然后将此配置设置为 HuggingFace 变换器配置对象的**tabular_config**成员变量。在这里，我们还指定如何将表格特征与文本特征结合起来。在此示例中，我们将使用加权求和方法。

一旦我们设置了**tabular_config**，我们可以使用与 HuggingFace 相同的 API 加载模型。请参阅[文档](https://multimodal-toolkit.readthedocs.io/en/latest/modules/model.html#module-multimodal_transformers.model.tabular_transformers)，以查看目前支持的包含表格组合模块的变换器模型列表。

### 训练

对于训练，我们可以使用 HuggingFace 的[trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#transformers.Trainer)类。我们还需要指定训练参数，在这种情况下，我们将使用默认值。

让我们来看看我们正在训练的模型吧！

![](../Images/36968204ded1b162b45de0c17de61647.png)

*以上实验的 Tensorboard 日志。您也可以在 [这里](https://tensorboard.dev/experiment/pzG4qrcJTyGhjENIKzE9Dw/#scalars) 查看这个 Tensorboard。*

### 结果

使用这个工具包，我们还在[女性电子商务服装评论](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews)数据集上进行推荐预测实验，以及在[墨尔本 Airbnb 开放数据](https://www.kaggle.com/tylerx/melbourne-airbnb-open-data)数据集上进行价格预测实验。前者是分类任务，而后者是回归任务。我们的结果见下表。**text_only**组合方法是一个基线，它仅使用变换器，本质上与 HuggingFace 的**forSequenceClassification**模型相同。

![](../Images/82486e33dc986cc9db2ee2043bc85266.png)

我们可以看到，结合表格特征可以提升**text_only**方法的性能。性能提升依赖于表格数据中训练信号的强度。例如，在评论推荐的情况下，**text_only**模型已经是一个强基线。

### 下一步

我们已经在我们的项目中成功地使用了这个工具包。欢迎在您的下一个机器学习项目中尝试！

查看 [文档](https://multimodal-toolkit.readthedocs.io/en/latest/) 和包含的 [主](https://github.com/georgianpartners/Multimodal-Toolkit/blob/master/main.py) 脚本以了解如何进行评估和推理。如果你希望支持你最喜欢的 Transformer，欢迎在 [这里](https://github.com/georgianpartners/Multimodal-Toolkit/blob/master/multimodal_transformers/model/tabular_transformers.py) 添加对 Transformer 的支持。

### 附录

读者应查看 [图解 Transformer](http://jalammar.github.io/illustrated-transformer/) 和 [图解 BERT](http://jalammar.github.io/illustrated-bert/) 以获得 Transformer 和 BERT 的概述。

以下是我们审阅的论文的快速分类。

**Transformer 在图像和文本上的应用**

+   用于分类图像和文本的监督多模态双向 Transformer（Kiela 等，2019）

+   ViLBERT: 预训练任务无关的视觉语言表示用于视觉和语言任务（Lu 等，2019）

+   VL-BERT: 预训练的通用视觉语言表示（Su 等，ICLR 2020）

+   LXMERT: 从 Transformer 学习跨模态编码表示（Tan 等，EMNLP 2019）

**Transformer 在音频、视觉和文本对齐方面的应用**

+   用于非对齐多模态语言序列的多模态 Transformer（Tsai 等，ACL 2019）

+   在大型预训练 Transformer 中集成多模态信息（Rahman 等，ACL 2020）

**Transformer 与知识图谱嵌入**

+   通过知识图谱嵌入丰富 BERT 以进行文档分类（Ostendorff 等，2019）

+   ERNIE: 增强的语言表示与信息实体（张等，2019）

[原文](https://medium.com/georgian-impact-blog/how-to-incorporate-tabular-data-with-huggingface-transformers-b70ac45fcfb4)。经许可转载。

**简介：** [Ken Gu](https://www.linkedin.com/in/ken-gu/) 是 Georgian 的应用研究实习生，他正在从事各种应用机器学习项目。他在加州大学洛杉矶分校获得计算机科学学士学位，并辅修数学。在 UCLA，Ken 曾参与图形深度学习的研究项目，重点关注生物医学交互网络。

**相关：**

+   [深入探讨 Transformer 架构 – Transformer 模型的发展](https://www.kdnuggets.com/2020/08/transformer-architecture-development-transformer-models.html)

+   [每一种复杂的数据框操作，解释与直观展示](https://www.kdnuggets.com/2020/11/dataframe-manipulation-explained-visualized.html)

+   [Transformer 研究指南](https://www.kdnuggets.com/2019/10/research-guide-transformers.html)

### 更多相关主题

+   [使用 HuggingFace Transformers 的简单 NLP 管道](https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html)

+   [以数据为中心的 AI 和表格数据](https://www.kdnuggets.com/2022/09/datacentric-ai-tabular-data.html)

+   [如何生成合成的表格数据集](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)

+   [使用 HuggingFace Pipelines 和 Streamlit 回答问题](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)

+   [使用 HuggingFace 对 BERT 进行推特分类微调](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)

+   [使用 HuggingFace 实现的简单端到端项目](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)
