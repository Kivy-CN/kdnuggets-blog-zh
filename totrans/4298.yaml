- en: The Best Machine Learning Frameworks & Extensions for Scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/03/best-machine-learning-frameworks-extensions-scikit-learn.html](https://www.kdnuggets.com/2021/03/best-machine-learning-frameworks-extensions-scikit-learn.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: Plenty of packages implement the [Scikit-learn](https://scikit-learn.org/) estimator
    API.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re already familiar with Scikit-learn, you’ll find the integration of
    these libraries pretty straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: With these packages, we can extend the functionality of Scikit-learn estimators,
    and I’ll show you how to use some of them in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Data formats
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we’ll explore libraries that can be used to process and transform
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '[Sklearn-pandas](https://github.com/scikit-learn-contrib/sklearn-pandas)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can use this package to map ‘DataFrame’ columns to Scikit-learn transformations.
    Then you can combine these columns into features.
  prefs: []
  type: TYPE_NORMAL
- en: To start using the package, install ‘sklearn-pandas’ via pip. The ‘DataFrameMapper’
    can be used to map pandas data frame columns into Scikit-learn transformations.
    Let’s see how it’s done.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a dummy DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `DataFrameMapper’ accepts a list of tuples – the first item’s name is the
    column name in [Pandas](https://pandas.pydata.org/) DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: The second passed item is the kind of transformation that will be applied to
    the column.
  prefs: []
  type: TYPE_NORMAL
- en: For example, ‘[LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html)’
    can be applied to the ‘Uni’ column, whereas the ‘Age’ column is scaled using a
    ‘[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After defining the mapper, next we use it to fit and transform the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `transformed_names_` attribute of the mapper can be used to show resulting
    names after the transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![scikit-learn extensions](../Images/e20ec6b1d2a971d30cf79b13060e9d58.png)'
  prefs: []
  type: TYPE_IMG
- en: Passing `df_out=True` to the mapper will return your results as a Pandas DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![scikit-learn extensions ](../Images/3af27754b889c66f1b59217310b36c41.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Sklearn-xarray](https://phausamann.github.io/sklearn-xarray/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This package combines n-dimensional labeled arrays from [xarray](http://xarray.pydata.org/en/stable/) with [Scikit-learn](http://scikit-learn.org/stable/) tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can apply Scikit-learn estimators to ‘xarrays’ without losing their labels.
    You can also:'
  prefs: []
  type: TYPE_NORMAL
- en: ensure compatibility between Sklearn estimators with xarray DataArrays and Datasets,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: enable estimators to change the number of samples,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: have pre-processing transformers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sklearn-xarray is basically a bridge between xarray and Scikit-learn. In order
    to use its functionalities, install ‘sklearn-xarray’ via pip or ‘conda’.
  prefs: []
  type: TYPE_NORMAL
- en: The package has wrappers, which let you use sklearn estimators on xarray DataArrays
    and Datasets. To illustrate this, let’s first create a ‘DataArray’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![scikit-learn extensions ](../Images/72abea9b124f6c109fed33700306eb55.png)'
  prefs: []
  type: TYPE_IMG
- en: Select one transformation from Sklearn to apply to this ‘DataArray’. In this
    case, [let’s apply](https://phausamann.github.io/sklearn-xarray/content/wrappers.html) the
    ‘StandardScaler’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![scikit-learn extensions ](../Images/0608abb02873fc4fb3286eac01d25fda.png)'
  prefs: []
  type: TYPE_IMG
- en: Wrapped estimators can be used in Sklearn pipelines seamlessly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: When fitting this pipeline, you will just pass in the DataArray.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, DataArrays can be used in a cross-validated grid search.
  prefs: []
  type: TYPE_NORMAL
- en: For this, you need to create a ‘CrossValidatorWrapper’ instance from ‘sklearn-xarray’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: After that, you will fit the ‘gridsearch’ to X and y in the ‘DataArray’ data
    type.
  prefs: []
  type: TYPE_NORMAL
- en: Auto-ML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Are there tools and libraries that integrate Sklearn for better Auto-ML? Yes
    there are, and here are some examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[Auto-sklearn](https://automl.github.io/auto-sklearn/master/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With this, you can perform automated machine learning with Scikit-learn. For
    the setup you need to [install](https://automl.github.io/auto-sklearn/master/installation.html) some
    dependencies manually.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Next, install ‘auto-sklearn’ via pip.
  prefs: []
  type: TYPE_NORMAL
- en: When using this tool, you don’t need to worry about algorithm selection and
    hyper-parameter tuning. Auto-sklearn does all that for you.
  prefs: []
  type: TYPE_NORMAL
- en: It does this thanks to the [latest advances](https://proceedings.neurips.cc/paper/2015/file/11d0e6287202fced83f79975ec59a3a6-Paper.pdf) in
    Bayesian optimization, meta-learning, and ensemble construction.
  prefs: []
  type: TYPE_NORMAL
- en: To use it, you need to select a classifier or regressor, and fit it to the training
    set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[Auto_ViML](https://github.com/AutoViML) – Automatic Variant Interpretable
    Machine Learning” (pronounced “Auto_Vimal”)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given a certain dataset, Auto_ViML tries out different models with varying features.
    It eventually settles on the best performing model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The package also selects the least number of features possible in building
    the model. This gives you a less complex and interpretable model. This package
    also:'
  prefs: []
  type: TYPE_NORMAL
- en: helps you clean data by suggesting changes to missing values, formatting, and
    adding variables;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: classifies variables automatically, whether it’s text, data, or numerical;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: generates model performance graphs automatically when verbose is set to 1 or
    2;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: lets you use of ‘featuretools’ for feature engineering;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: handles imbalance data when ‘Imbalanced_Flag’ is set to ‘True’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To see it in action, install ‘autoviml’ via pip.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[TPOT –](http://proceedings.mlr.press/v64/olson_tpot_2016.pdf) Tree-based Pipeline
    Optimization Tool'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a Python-based auto-ml tool. It uses genetic programming to optimize
    machine learning pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: It explores multiple pipelines in order to settle on the best one for your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Install ‘tpot’ via pip to start tinkering with it. After running ‘tpot’, you
    can save the resulting pipeline in a file. The file will be exported once the
    exploration process is completed or when you terminate the process.
  prefs: []
  type: TYPE_NORMAL
- en: The snippet below shows how you can create a classification pipeline on the
    digits dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[Feature Tools](https://github.com/alteryx/featuretools)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a tool for automated feature engineering. It works by transforming temporal
    and relational datasets into feature matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Install ‘featuretools[complete]’ via pip to start using it.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Feature Synthesis (DFS) can be used for automated feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: First, you define a dictionary containing all entities in a dataset. In ‘featuretools’,
    an entity is a single table. After that, the relationship between the different
    entities is defined.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to pass the entities, list of relationships, and the target
    entity to DFS. This will get you the feature matrix and the corresponding list
    of feature definitions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[Neuraxle](https://www.neuraxle.org/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can use Neuraxle for hyperparameter tuning and AutoML. Install ‘neuraxle’
    via pip to start using it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from Scikit-learn, Neuraxle is also compatible with Keras, TensorFlow,
    and PyTorch. It also has:'
  prefs: []
  type: TYPE_NORMAL
- en: parallel computation and serialization,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: time series processing through the provision of abstractions key to such projects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To do auto-ml with Neuraxle, you need:'
  prefs: []
  type: TYPE_NORMAL
- en: a defined pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a validation splitter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: definition of a scoring metric via the ‘ScoringCallback’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a selected ‘hyperparams’ repository
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a selected ‘hyperparams’ optimizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: an ‘AutoML’ loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check out a complete [example here](https://www.neuraxle.org/stable/hyperparameter_tuning.html).
  prefs: []
  type: TYPE_NORMAL
- en: Experimentation frameworks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now it’s time for a couple of SciKit tools that you can use for machine learning
    experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: '[SciKit-Learn Laboratory](https://scikit-learn-laboratory.readthedocs.io/en/latest/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SciKit-Learn Laboratory is a command-line tool you can use to run machine learning
    experiments. To start using it, install `skll` via pip.
  prefs: []
  type: TYPE_NORMAL
- en: After that, you need to obtain a dataset in the `SKLL` format.
  prefs: []
  type: TYPE_NORMAL
- en: Next, create a [configuration file](https://skll.readthedocs.io/en/latest/run_experiment.html#create-config) for
    the experiment, and run the experiment in the terminal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When the experiment is complete, multiple files will be stored in the [results](https://skll.readthedocs.io/en/latest/run_experiment.html#results) folder.
    You can use these files to examine the experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Neptune
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [Scikit-learn integration of Neptune](https://docs.neptune.ai/integrations/sklearn.html) lets
    you log your experiments using Neptune. For instance, you can log the summary
    of your Scikit-learn regressor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Check out this [notebook](https://colab.research.google.com/github/neptune-ai/neptune-examples/blob/master/integrations/sklearn/docs/Neptune-Scikit-learn.ipynb#scrollTo=GvDSBSrOx-R4) for
    the complete example.
  prefs: []
  type: TYPE_NORMAL
- en: Model selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s now shift gears, and look at SciKit libraries that are focused on model
    selection and optimization.
  prefs: []
  type: TYPE_NORMAL
- en: '[Scikit-optimize](https://scikit-optimize.github.io/stable/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This library implements methods for sequential model-based optimization. Install
    ‘scikit-optimize’ via pip to start using these functions.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-optimize can be used to perform hyper-parameter tuning via Bayesian optimization
    based on the Bayes theorem.
  prefs: []
  type: TYPE_NORMAL
- en: You use ‘BayesSearchCV’ to obtain the best parameters using this theorem. A
    Scikit-learn model is passed to it as the first argument.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: After fitting, you can get the best parameters of the model via the ‘best_params_’
    attribute.
  prefs: []
  type: TYPE_NORMAL
- en: '[Sklearn-deap](https://github.com/rsteca/sklearn-deap)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sklearn-deap is a package used to implement [evolutionary algorithms](https://en.wikipedia.org/wiki/Evolutionary_algorithm).
    It reduces the time you need to find the best parameters for the model.
  prefs: []
  type: TYPE_NORMAL
- en: It doesn’t try out every possible combination, but only evolves the combination
    that results in the best performance. Install ‘sklearn-deap’ via pip.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Model export for production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Moving on, let’s now look at Scikit tools that you can use to export your models
    for production.
  prefs: []
  type: TYPE_NORMAL
- en: '[sklearn-onnx](https://github.com/onnx/sklearn-onnx/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: sklearn-onnx enables the conversion of Sklearn models to [ONNX](https://onnx.ai/).
  prefs: []
  type: TYPE_NORMAL
- en: To use it, you need to get ‘skl2onnx’ via pip. Once your pipeline is ready,
    you can use the ‘to_onnx’ function to [convert](http://onnx.ai/sklearn-onnx/auto_tutorial/plot_abegin_convert_pipeline.html) the
    model to ONNX.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[Treelite](https://treelite.readthedocs.io/en/latest/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a model compiler for decision tree ensembles.
  prefs: []
  type: TYPE_NORMAL
- en: It handles various tree-based models, such as random forests and gradient boosted
    trees.
  prefs: []
  type: TYPE_NORMAL
- en: You can use it to import Scikit-learn models. Here, ‘model’ is a scikit-learn
    model object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Model inspection and visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, let’s look at libraries that can be used for model visualization
    and inspection.
  prefs: []
  type: TYPE_NORMAL
- en: '[Dtreeviz](https://github.com/parrt/dtreeviz/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: dtreeviz is used for decision tree visualization and model interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d12bd6f8518cbf2053f0378db032cb43.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Eli5](https://github.com/TeamHG-Memex/eli5/)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: eli5 is a package that can be used for debugging and inspecting machine learning
    classifiers. You can also use it to explain their predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, an explanation of Scikit-learn estimator weights can be shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![scikit-learn extensions ](../Images/2f9114ee1b717a317a3ddf58fa13bfc1.png)'
  prefs: []
  type: TYPE_IMG
- en: Other SciKit tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[dabl ](https://github.com/amueller/dabl)– Data Analysis Baseline Library'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: dabl provides boilerplate code for common machine learning tasks. It’s still
    in active development, so it’s not recommended for production systems.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[skorch](https://github.com/skorch-dev/skorch)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Skorch is a Scikit-learn wrapper for PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: It lets you use PyTorch in Scikit-learn. It supports numerous data types, like
    PyTorch Tensors, NumPy arrays and Python dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Final thoughts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we explored some of the popular tools and libraries that extend
    the Scikit-learn ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you see, these tools can be used to:'
  prefs: []
  type: TYPE_NORMAL
- en: process and transform data,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: implement automated machine learning,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: perform automatic feature selection,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: run machine learning experimentation,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: select the best models and pipelines for your problem,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: export models for production…
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: …and much more!
  prefs: []
  type: TYPE_NORMAL
- en: Try out these packages in your Scikit-learn workflow, and you might be surprised
    how convenient they are.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: Derrick Mwiti** is a data scientist who has a great passion for sharing
    knowledge. He is an avid contributor to the data science community via blogs such
    as Heartbeat, Towards Data Science, Datacamp, Neptune AI, KDnuggets just to mention
    a few. His content has been viewed over a million times on the internet. Derrick
    is also an author and online instructor. He also trains and works with various
    institutions to implement data science solutions as well as to upskill their staff.
    You might want to check his [Complete Data Science & Machine Learning Bootcamp
    in Python course](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://neptune.ai/blog/the-best-ml-framework-extensions-for-scikit-learn).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Top Python Libraries for Data Science, Data Visualization & Machine Learning](/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Python Libraries for Deep Learning, Natural Language Processing & Computer
    Vision](/2020/11/top-python-libraries-deep-learning-natural-language-processing-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pruning Machine Learning Models in TensorFlow](/2020/12/pruning-machine-learning-models-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
