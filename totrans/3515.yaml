- en: Does Deep Learning Come from the Devil?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**深度学习**来自魔鬼吗？'
- en: 原文：[https://www.kdnuggets.com/2015/10/deep-learning-vapnik-einstein-devil-yandex-conference.html](https://www.kdnuggets.com/2015/10/deep-learning-vapnik-einstein-devil-yandex-conference.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2015/10/deep-learning-vapnik-einstein-devil-yandex-conference.html](https://www.kdnuggets.com/2015/10/deep-learning-vapnik-einstein-devil-yandex-conference.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)![yandex-berlin](../Images/60c6fdc4a4c6d8ec69055fe310a2372d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)![yandex-berlin](../Images/60c6fdc4a4c6d8ec69055fe310a2372d.png)'
- en: 'Over the past week in Berlin, I attended Machine Learning: Prospects and Applications,
    a conference of invited speakers from the academic machine learning community.
    Organized by Yandex, Russia''s largest search engine, the conference prominently
    featured the themes **Deep Learning** and **Intelligent Learning**, two concepts
    that were often taken to be in opposition. Although I attended as a speaker and
    participant on the deep learning panel, the highlight of the conference was witnessing
    the clash of philosophies between empiricism and mathematics expressed by many
    leading theorists and practitioners.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去一周的柏林，我参加了“机器学习：前景与应用”会议，这是一个来自学术机器学习社区的邀请讲者会议。由俄罗斯最大搜索引擎Yandex组织，会议显著地突出**深度学习**和**智能学习**这两个常常被认为对立的概念。尽管我以深度学习小组的讲者和参与者身份参加了会议，但会议的亮点是见证了许多领先理论家和从业者表达的经验主义与数学之间的哲学冲突。
- en: The first day, which featured deep learning, was capped by an evening panel
    discussion. Moderated by Dr. Li Deng, the discussion challenged speakers from
    the deep learning community, including myself, to explain machine learning's mathematical
    underpinnings and also to offer a vision of its future. Questions about model
    interpretability, [a topic which I addressed in a previous post](/2015/04/model-interpretability-neural-networks-deep-learning.html),
    specifically concerning applications to medicine were abundant. On Wednesday,
    a second evening of discussion was held. Here, Vladimir Vapnik, the co-inventor
    of the support vector machine and widely considered among the fathers of statistical
    learning theory, held forth on his theory of knowledge transfer from an intelligent
    teacher. Additionally, he offered a philosophical view spanning machine learning,
    mathematics, and the source of intelligence. Perhaps most controversially, he
    took on deep learning, challenging its ad hoc approach.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第一日的深度学习主题结束时，进行了一个晚间小组讨论。由李登博士主持，该讨论挑战了深度学习社区的讲者，包括我自己，解释机器学习的数学基础，并展望其未来。关于模型可解释性的问题，[这是我在之前的帖子中讨论的一个话题](/2015/04/model-interpretability-neural-networks-deep-learning.html)，尤其是针对医学应用的问题特别多。在周三，举行了第二晚的讨论。在这里，支持向量机的共同发明者、被广泛认为是统计学习理论奠基人的弗拉基米尔·瓦普尼克阐述了他的知识传递理论，并提供了涉及机器学习、数学和智能源的哲学视角。或许最具争议的是，他对深度学习提出了挑战，质疑其特设的方法。
- en: '![vapnik](../Images/fc4e59139032bdce160824bcab79ca96.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![vapnik](../Images/fc4e59139032bdce160824bcab79ca96.png)'
- en: This past summer, I posted [an article suggesting that deep learning's success
    more broadly reflected the triumph of empiricism in the setting of big data.](/2015/07/deep-learning-triumph-empiricism-over-theoretical-mathematical-guarantees.html)
    I argued that absent the risk of overfitting, the set of methods which could be
    validated on real data might be much larger than those which we can guarantee
    to work from first principles mathematically. Following the conference, I'd like
    to follow up on this topic by presenting an alternative perspective, specifically
    those challenges put forth by Vladimir Vapnik at the conference.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的夏天，我发布了[一篇文章，建议深度学习的成功更广泛地反映了经验主义在大数据环境中的胜利。](/2015/07/deep-learning-triumph-empiricism-over-theoretical-mathematical-guarantees.html)
    我认为，若没有过拟合的风险，可在真实数据上验证的方法集合可能远大于那些我们可以从数学第一原则保证有效的方法。会议结束后，我想继续探讨这个话题，特别是那些弗拉基米尔·瓦普尼克在会议上提出的挑战。
- en: To preempt any confusion, I am a deep learning researcher. I do not personally
    dismiss deep learning and respect both its pioneers and torchbearers. But I also
    believe that we should be open to the possibility that eventually some mathematical
    theory will either explain its success more fully or point the way forward to
    a new approach. Clearly, there is value in digesting both the arguments for the
    deep learning approach, and those critical of it, and in that spirit I present
    some highlights from the conference, particularly from Professor Vapnik's talk.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免任何混淆，我是一名深度学习研究员。我个人并不否定深度学习，并尊重它的开创者和继承者。但我也相信，我们应该对最终某些数学理论将更全面地解释其成功或指引新的方法持开放态度。显然，理解深度学习方法的论点及其批评观点都有其价值，因此我呈现了一些会议的亮点，特别是来自Vapnik教授的讲座。
- en: '**Big Data and Deep Learning as Brute Force**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**大数据与深度学习作为蛮力方法**'
- en: 'Although Professor Vapnik had several angles on deep learning, perhaps this
    is the most central: During the audience discussion on *Intelligent Learning*,
    Vapnik, invoked Einstein''s metaphorical notion of God. In short, Vapnik posited
    that ideas and intuitions come either from God or from the devil. The difference,
    he suggested is that **God is clever, while the devil is not**.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Vapnik教授对深度学习有多个角度的看法，但也许最核心的观点是：在关于*智能学习*的观众讨论中，Vapnik提到了爱因斯坦的隐喻神的观点。简而言之，Vapnik认为，想法和直觉要么来自上帝，要么来自魔鬼。他提出的区别是**上帝聪明，而魔鬼则不聪明**。
- en: '![devil-deep-learning](../Images/24ca34d2b1cb8e1b014b29b2811cb5be.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![devil-deep-learning](../Images/24ca34d2b1cb8e1b014b29b2811cb5be.png)'
- en: In his career as a mathematician and machine learning researcher, Vapnik suggested
    that the devil appeared always in the form of brute force. Further, while acknowledging
    the impressive performance of deep learning systems at solving practical problems,
    he suggested that **big data and deep learning both have the flavor of brute force**.
    One audience member asked if Professor Vapnik believed that evolution (which presumably
    resulted in human intelligence) was a brute force algorithm. In keeping with a
    stated distaste for speculation, Professor Vapnik declined to offer any guesses
    about evolution. It also seems appropriate to mention that Einstein's intuitions
    about how God might design the universe while remarkably fruitful, did not always
    pan out. Most notably Einstein's intuition that "God does not play dice" appears
    to conflict with our modern understanding of quantum mechanics [(see this great,
    readable post on the topic by Stephen Hawking)](http://www.hawking.org.uk/does-god-play-dice.html).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的数学家和机器学习研究员职业生涯中，Vapnik表示魔鬼总是以蛮力的形式出现。此外，虽然承认深度学习系统在解决实际问题上的出色表现，但他认为**大数据和深度学习都带有蛮力的色彩**。有一位观众问Vapnik教授是否认为进化（这可能导致了人类智能）是一个蛮力算法。由于明确表示不喜欢猜测，Vapnik教授拒绝对进化提出任何猜测。还值得一提的是，虽然爱因斯坦关于上帝如何设计宇宙的直觉非常有成效，但并不总是奏效。最著名的是爱因斯坦认为“上帝不掷骰子”的直觉似乎与我们对量子力学的现代理解相冲突[(见斯蒂芬·霍金关于这个话题的精彩易读文章)](http://www.hawking.org.uk/does-god-play-dice.html)。
- en: While I may not agree that deep learning necessarily equates to brute force,
    I see more clearly the argument against modern attitudes towards big data. As
    Dr. Vapnik and [Professor Nathan Intrator](www.math.tau.ac.il/~nin/) of Tel Aviv
    University both suggested, a baby doesn't need billions of labeled examples in
    order to learn. In other words, it may be easy to learn effectively with gigantic
    labeled datasets, but by relying upon them, one may miss something fundamental
    about the nature of learning. Perhaps, if our algorithms can learn only with gigantic
    datasets what should be intrinsically learnable with hundreds, we have succumbed
    to laziness.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我可能不同意深度学习必然等同于蛮力的观点，但我更清楚地看到了对现代大数据态度的反对论点。正如Vapnik博士和[纳撒尼尔·因特拉托尔教授](www.math.tau.ac.il/~nin/)在特拉维夫大学所建议的，一个婴儿在学习时并不需要数十亿个标注样本。换句话说，虽然使用巨大的标注数据集进行有效学习可能很容易，但依赖这些数据集可能会错过关于学习本质的一些根本问题。也许，如果我们的算法只能通过巨大的数据集进行学习，而这些本应通过数百个样本即可学习的内容，那我们可能已经陷入了懒惰。
- en: '**Deep Learning or Deep Engineering**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习还是深度工程**'
- en: Another perspective that Professor Vapnik offered concerning deep learning is
    that it is not science. Precisely, he said that it distracted from the core mission
    of machine learning, which he posited to be the understanding of mechanism. In
    more elaborate remarks, he suggested that the study of machine learning is like
    trying to build a Stradivarius, while engineering solutions for practical problems
    was more like being a violinist. In this sense, a violinist may produce beautiful
    music, and have an intuition for how to play, but not formally understand what
    they are doing. By extension, he suggested that many deep learning practitioners
    have a great feeling for data and for engineering, but similarly do not truly
    know what they are doing.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 瓦普尼克教授对深度学习的另一种看法是，它不是科学。具体来说，他表示深度学习偏离了机器学习的核心使命，他认为机器学习的核心在于理解机制。更详细的说，他认为研究机器学习就像是在试图制造一把斯特拉迪瓦里小提琴，而工程解决实际问题更像是成为一名小提琴手。从这个角度来看，小提琴手可以演奏出美妙的音乐，并对如何演奏有直觉，但未必正式理解自己在做什么。由此，他建议许多深度学习从业者对数据和工程有很好的感觉，但同样不真正理解自己在做什么。
- en: '**Do Humans Invent Anything?**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类是否发明了什么？**'
- en: A final sharp idea raised by Professor Vapnik was whether we discover or invent
    algorithms and models. In Vapnik's view, we do not really invent anything. Specifically,
    he addressed the audience saying that he is "not so smart as to invent anything".
    By extension, presumably no one else was so smart either. More diplomatically,
    he suggested things we invent (if any), are trivial next to those which are intrinsic
    in nature and that the only source of real knowledge derives from an understanding
    of mathematics. Deep learning, in which models are frequently invented, branded,
    and techniques patented, seems somewhat artificial compared to more mathematically
    motivated machine learning. Around this time, he challenged the audience to offer
    a definition of deep learning. Most audience members, it seemed, were reluctant
    to offer one. At other times, audience members challenged his view by invoking
    deep learning's biological inspiration. To this Dr. Vapnik asked, "do you know
    how the brain works?"
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 瓦普尼克教授提出的一个尖锐的观点是，我们是发现还是发明算法和模型。在瓦普尼克看来，我们实际上并没有发明任何东西。他具体对观众说，他“并不聪明到可以发明什么”。由此推测，可能没有其他人也如此聪明。更委婉地说，他认为我们发明的东西（如果有的话），与那些本质上固有的事物相比微不足道，真正的知识来源于对数学的理解。深度学习中模型经常被发明、命名和技术专利，这与更具数学动机的机器学习相比显得有些人为。在这段时间里，他挑战观众提供一个深度学习的定义。大多数观众似乎不愿意提供定义。在其他时候，观众通过引用深度学习的生物学启发来挑战他的观点。对此，瓦普尼克教授问道：“你知道大脑是如何工作的？”
- en: '![Zachary Chase Lipton](../Images/240b273c667af1a53a99fd93d1fd39ce.png) **[Zachary
    Chase Lipton](http://zacklipton.com)** is a PhD student in the Computer Science
    Engineering department at the University of California, San Diego. Funded by the
    [Division of Biomedical Informatics](http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx),
    he is interested in both theoretical foundations and applications of machine learning.
    In addition to his work at UCSD, he has interned at Microsoft Research Labs and
    as a Machine Learning Scientist at Amazon, is a Contributing Editor at KDnuggets,
    and has signed on as an author at Manning Publications.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![扎克瑞·蔡斯·利普顿](../Images/240b273c667af1a53a99fd93d1fd39ce.png) **[扎克瑞·蔡斯·利普顿](http://zacklipton.com)**
    是加州大学圣地亚哥分校计算机科学工程系的博士生。由[生物医学信息学部](http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx)资助，他对机器学习的理论基础和应用都感兴趣。除了在UCSD的工作外，他还曾在微软研究院实习，并担任亚马逊的机器学习科学家，是KDnuggets的特约编辑，并在Manning
    Publications签约成为作者。'
- en: '**Related:**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning and the Triumph of Empiricism](/2015/07/deep-learning-triumph-empiricism-over-theoretical-mathematical-guarantees.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习与经验主义的胜利](/2015/07/deep-learning-triumph-empiricism-over-theoretical-mathematical-guarantees.html)'
- en: '[The Myth of Model Interpretability](/2015/04/model-interpretability-neural-networks-deep-learning.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型可解释性的神话](/2015/04/model-interpretability-neural-networks-deep-learning.html)'
- en: '[(Deep Learning’s Deep Flaws)’s Deep Flaws](/2015/01/deep-learning-flaws-universal-machine-learning.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[(深度学习的深层缺陷)](/2015/01/deep-learning-flaws-universal-machine-learning.html)'
- en: '[Data Science’s Most Used, Confused, and Abused Jargon](/2015/02/data-science-confusing-jargon-abused.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中最常用、最困惑和被滥用的术语](/2015/02/data-science-confusing-jargon-abused.html)'
- en: '[Differential Privacy: How to make Privacy and Data Mining Compatible](/2015/01/differential-privacy-data-mining-compatible.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[差分隐私：如何使隐私与数据挖掘兼容](/2015/01/differential-privacy-data-mining-compatible.html)'
- en: '* * *'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT 需求'
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Where Does Data Come From?](https://www.kdnuggets.com/2022/08/data-come.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据来自哪里？](https://www.kdnuggets.com/2022/08/data-come.html)'
- en: '[Machine learning does not produce value for my business. Why?](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习为何无法为我的业务创造价值？](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)'
- en: '[What Does ETL Have to Do with Machine Learning?](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL 与机器学习有什么关系？](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
- en: '[What Does a Data Scientist Do?](https://www.kdnuggets.com/2021/12/what-does-a-data-scientist-do.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家做什么？](https://www.kdnuggets.com/2021/12/what-does-a-data-scientist-do.html)'
- en: '[Does the Random Forest Algorithm Need Normalization?](https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[随机森林算法是否需要归一化？](https://www.kdnuggets.com/2022/07/random-forest-algorithm-need-normalization.html)'
- en: '[KDnuggets News, November 30: What is Chebychev''s Theorem and How…](https://www.kdnuggets.com/2022/n46.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月30日：什么是切比雪夫定理及其应用…](https://www.kdnuggets.com/2022/n46.html)'
