- en: Machine Learning on the Edge
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘上的机器学习
- en: 原文：[https://www.kdnuggets.com/2022/10/machine-learning-edge.html](https://www.kdnuggets.com/2022/10/machine-learning-edge.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/10/machine-learning-edge.html](https://www.kdnuggets.com/2022/10/machine-learning-edge.html)
- en: '![Machine Learning on the Edge](../Images/8fde58b3266931e0bc1a79dd95c08ac2.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![边缘上的机器学习](../Images/8fde58b3266931e0bc1a79dd95c08ac2.png)'
- en: Photo by [Alessandro Oliverio](https://www.pexels.com/photo/silver-and-green-circuit-board-1472443/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Alessandro Oliverio](https://www.pexels.com/photo/silver-and-green-circuit-board-1472443/)
    提供
- en: Over the past decade, many companies have shifted to the cloud to store, manage,
    and process data. This seems an even more promising area for machine learning
    solutions. By deploying ML models on the cloud, you have access to a plethora
    of powerful servers that are maintained by third parties. You can generate predictions
    on the latest graphics processing units (GPUs), tensor processing units (TPUs),
    and vision processing units (VPUs), without worrying about the initial setup cost,
    scalability, or hardware maintenance. Moreover, cloud solutions offer access to
    powerful servers which can make inferences (the process of generating predictions)
    much faster than on-premises servers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的十年里，许多公司已经转向云端来存储、管理和处理数据。这似乎是一个更有前景的机器学习解决方案领域。通过在云端部署 ML 模型，你可以使用大量由第三方维护的强大服务器。你可以在最新的图形处理单元（GPUs）、张量处理单元（TPUs）和视觉处理单元（VPUs）上生成预测，而不必担心初始设置成本、可扩展性或硬件维护。此外，云解决方案提供了强大的服务器，这些服务器可以比本地服务器更快地进行推断（生成预测的过程）。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One may be tempted to believe that it’s cheaper to deploy ML models on the cloud.
    After all, you do not need to build an infrastructure or maintain everything in-house.
    You pay only for the time the server was utilized. This, however, couldn't be
    further from the truth. Cloud costs continue to surge year after year, and most
    organizations are having a hard time keeping these costs under control. A recent
    report by Gartner forecasts that end-user spending on public cloud services will
    reach nearly $500 Billion in 2022 [1].
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有人会认为在云端部署 ML 模型更便宜。毕竟，你不需要构建基础设施或维护所有内部系统。你只需为服务器使用的时间付费。然而，这种看法远非真实。云成本逐年上涨，大多数组织很难控制这些成本。Gartner
    最近的报告预测，到 2022 年，终端用户在公共云服务上的支出将接近 5000 亿美元 [1]。
- en: Big companies like Netflix, Snapchat, Tik Tok, and Pinterest are already spending
    hundreds of millions of dollars on cloud bills annually [2, 3]. Even for small
    and medium businesses (SMBs), this cost averages around one million. Machine learning
    workloads require heavy computation that is expensive on the cloud. Though cloud
    solutions provide an easy way to manage ML applications, the edge ML has taken
    off recently.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Netflix、Snapchat、Tik Tok 和 Pinterest 这样的巨大公司每年在云端账单上的支出已经达到数亿美元 [2, 3]。即便是小型和中型企业（SMBs），这笔费用也平均在一百万左右。机器学习工作负载需要大量计算，这在云端的成本很高。尽管云解决方案提供了管理
    ML 应用程序的简便方法，但边缘 ML 最近也开始迅速发展。
- en: '![Machine Learning on the Edge](../Images/9758d75a3d68bfaebba26bafa10d4991.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![边缘上的机器学习](../Images/9758d75a3d68bfaebba26bafa10d4991.png)'
- en: 'Source: [Flexera 2022 State of the Cloud Report](https://resources.flexera.com/web/pdf/Flexera-State-of-the-Cloud-Report-2022.pdf)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Flexera 2022 年云计算现状报告](https://resources.flexera.com/web/pdf/Flexera-State-of-the-Cloud-Report-2022.pdf)
- en: From Cloud ML to Edge ML
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从云端 ML 到边缘 ML
- en: To keep their running costs under control, companies have started looking for
    ways to push as much computation on end-user devices as possible. This means putting
    ML models on consumer devices where they can independently run inferences without
    an internet connection, in real-time, and at no cost. Take, for instance, the
    example of Amazon’s Alexa and Echo, a voice-controlled virtual assistant that
    uses ML to perform various tasks for you. In September 2020, Amazon released the
    AZ1 Neural Edge processor that would make Alexa run inferences on the device rather
    than interacting with the cloud. By moving computation to the edge device, Echo
    has been able to run twice as faster while also offering privacy benefits since
    the data is processed locally [4].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制运行成本，公司开始寻找将尽可能多的计算推送到终端用户设备上的方法。这意味着将机器学习模型放在消费者设备上，这些设备可以独立进行推断，无需互联网连接，实时进行，而且没有额外成本。例如，亚马逊的Alexa和Echo是一个语音控制的虚拟助手，使用机器学习为你执行各种任务。在2020年9月，亚马逊发布了AZ1
    Neural Edge处理器，使Alexa能够在设备上进行推断，而不是与云端交互。通过将计算移到边缘设备，Echo能够以两倍的速度运行，同时由于数据在本地处理，也提供了隐私保护[4]。
- en: Performance
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: You could build a state-of-the-art ML model with the highest accuracy, but if
    it takes even a few more milliseconds long to respond, users will go away. Even
    though deploying ML models to the cloud gives access to high performance hardware,
    it does not necessarily mean that your application’s latency decreases. Transferring
    data over the network is usually a bigger overhead than accelerating a model’s
    performance with special hardware. You could increase the performance of a deep
    learning model by a few milliseconds, but the data transfer over the network can
    go up to seconds.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以构建一个精确度最高的最先进的机器学习模型，但如果响应时间多了几毫秒，用户可能会离开。尽管将机器学习模型部署到云端可以访问高性能的硬件，但这并不一定意味着你的应用程序的延迟会减少。通过网络传输数据通常比用特殊硬件加速模型性能的开销要大。你可以将深度学习模型的性能提高几毫秒，但网络传输的数据可能需要几秒钟。
- en: Offline Inference
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离线推断
- en: Cloud computing requires that your application has a stable internet connection
    for constant data transfer. With edge computing, your application can run where
    there is no internet connection. This is especially beneficial in areas where
    the network connection is unreliable, but the application heavily relies on computation.
    For instance, a heart monitoring application may require real-time inference to
    predict the health of a patient’s heart. Even if the internet connection breaks
    down, the model should generate inferences on the edge device.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算要求你的应用程序有稳定的互联网连接，以进行持续的数据传输。而边缘计算允许你的应用程序在没有互联网连接的情况下运行。这在网络连接不可靠但应用程序严重依赖计算的区域尤为有益。例如，一款心脏监测应用可能需要实时推断以预测患者心脏的健康状况。即使互联网连接中断，模型也应在边缘设备上生成推断。
- en: Data Privacy
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据隐私
- en: Edge computing provides the benefit of data privacy. Users’ personal data is
    processed in close proximity to the user rather than accumulating in a corporate
    data center. This also makes it less susceptible to being intercepted over the
    network. In fact, for many use cases, edge computing is the only way to abide
    by privacy compliance. Smartphone manufacturers are increasingly incorporating
    face detection systems to unlock users’ phones. Users wouldn’t want their deeply
    personal data to be transferred or stored on the cloud.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算提供了数据隐私的好处。用户的个人数据在靠近用户的地方处理，而不是在公司数据中心积累。这也使得数据更不容易被网络拦截。事实上，对于许多使用场景来说，边缘计算是遵守隐私合规的唯一途径。智能手机制造商越来越多地将面部识别系统集成到用户的手机解锁功能中。用户不希望他们深度个人化的数据被转移或存储在云端。
- en: Cost
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本
- en: Probably the most appealing reason to move towards edge ML is that you do need
    to pay for the recurring cost of computation on the cloud. If your model stays
    on the user’s device, all computation is incurred by that device. The model makes
    use of the processing power of the consumer’s device rather than paying for computation
    of the cloud.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最吸引人转向边缘机器学习的理由是你不需要支付云端计算的重复成本。如果你的模型保留在用户的设备上，所有计算都由该设备承担。模型利用消费者设备的处理能力，而不是支付云端计算费用。
- en: The Current Limitations of Edge ML
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘机器学习的当前局限性
- en: By now you’ve seen how edge ML gives you the competitive edge. However, the
    current landscape of machine learning infrastructure hints that a lot of work
    is needed to effectively utilize this edge. State-of-the-art deep learning models
    are notoriously huge, and deploying these models at edge devices is a whole other
    challenge. Edge devices encompass all sorts of arbitrary hardware ranging from
    smartphones to embedded processors and IoT devices. The real challenge is how
    to compile ML models to run on heterogeneous hardware platforms in an optimized
    manner. This is a growing area of research where companies are pouring billions
    of dollars to lead the ML hardware race [5]. Big companies including NVIDIA, Apple,
    and Tesla are already making their own AI chips optimized to run specific ML models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到边缘机器学习如何让你获得竞争优势。然而，当前机器学习基础设施的现状表明，还需要大量的工作来有效利用这种优势。最先进的深度学习模型
    notoriously 大，而在边缘设备上部署这些模型是另一个挑战。边缘设备涵盖了从智能手机到嵌入式处理器和物联网设备等各种任意硬件。真正的挑战在于如何将机器学习模型编译以优化的方式在异构硬件平台上运行。这是一个不断增长的研究领域，公司正在投入数十亿美元以领先于机器学习硬件竞赛[5]。包括NVIDIA、苹果和特斯拉在内的大公司已经在开发自己的AI芯片，以优化运行特定的机器学习模型。
- en: Reference
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考资料
- en: “Gartner Forecasts Worldwide Public Cloud End-User Spending to Reach Nearly
    $500 Billion in 2022,”  April 19, 2022, Gartner, [https://www.gartner.com/en/newsroom/press-releases/2022-04-19-gartner-forecasts-wordwide-public-cloud-end-user-spending-to-reach-nearly-500-billion-in-2022](https://www.gartner.com/en/newsroom/press-releases/2022-04-19-gartner-forecasts-worldwide-public-cloud-end-user-spending-to-reach-nearly-500-billion-in-2022)
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “Gartner预测2022年全球公共云终端用户支出将接近5000亿美元，”2022年4月19日，Gartner，[https://www.gartner.com/en/newsroom/press-releases/2022-04-19-gartner-forecasts-wordwide-public-cloud-end-user-spending-to-reach-nearly-500-billion-in-2022](https://www.gartner.com/en/newsroom/press-releases/2022-04-19-gartner-forecasts-worldwide-public-cloud-end-user-spending-to-reach-nearly-500-billion-in-2022)
- en: Matthew Gooding, “A third of cloud computing spend goes to waste,” March 21,
    2022, Tech Monitor [https://techmonitor.ai/technology/cloud/cloud-spending-wasted-oracle-computing-aws-azure](https://techmonitor.ai/technology/cloud/cloud-spending-wasted-oracle-computing-aws-azure)
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 马修·古丁（Matthew Gooding），“三分之一的云计算支出浪费掉了，”2022年3月21日，Tech Monitor [https://techmonitor.ai/technology/cloud/cloud-spending-wasted-oracle-computing-aws-azure](https://techmonitor.ai/technology/cloud/cloud-spending-wasted-oracle-computing-aws-azure)
- en: Amir Efrati, Kevin McLaughlin, “As AWS Use Soars, Companies Surprised by Cloud
    Bills,” February 25, 2019, The Information [https://www.theinformation.com/articles/as-aws-use-soars-companies-surprised-by-cloud-bills](https://www.theinformation.com/articles/as-aws-use-soars-companies-surprised-by-cloud-bills)
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阿米尔·埃夫拉提（Amir Efrati），凯文·麦克劳克林（Kevin McLaughlin），“随着AWS使用量的激增，公司对云账单感到惊讶，”2019年2月25日，《信息报》（The
    Information）[https://www.theinformation.com/articles/as-aws-use-soars-companies-surprised-by-cloud-bills](https://www.theinformation.com/articles/as-aws-use-soars-companies-surprised-by-cloud-bills)
- en: Larry Dignan, “Amazon's Alexa gets a new brain on Echo, becomes smarter via
    AI and aims for ambience,” September 25, 2020,  ZDNet, [https://www.zdnet.com/article/amazons-alexa-gets-a-new-brain-on-echo-becomes-smarter-via-ai-and-aims-for-ambience/](https://www.zdnet.com/article/amazons-alexa-gets-a-new-brain-on-echo-becomes-smarter-via-ai-and-aims-for-ambience/)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拉里·迪根（Larry Dignan），“亚马逊的Alexa在Echo上获得了新大脑，通过人工智能变得更聪明并旨在营造氛围，”2020年9月25日，ZDNet，[https://www.zdnet.com/article/amazons-alexa-gets-a-new-brain-on-echo-becomes-smarter-via-ai-and-aims-for-ambience/](https://www.zdnet.com/article/amazons-alexa-gets-a-new-brain-on-echo-becomes-smarter-via-ai-and-aims-for-ambience/)
- en: Chip Huyen, “A friendly introduction to machine learning compilers and optimizers,”
    September 7, 2021, [https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html](https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html)
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 奇普·惠恩（Chip Huyen），“机器学习编译器和优化器的友好介绍，”2021年9月7日，[https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html](https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html)
- en: '**[Najia Gul](https://www.linkedin.com/in/najiagul/)** is a Data Scientist
    at IBM working on building, modelling, deploying, and maintaining ML models. She
    is also a developer advocate for Data and AI companies, helping them produce content
    that speaks to the technical audience. Find [her personal website here](https://najiagul.com/).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Najia Gul](https://www.linkedin.com/in/najiagul/)** 是IBM的数据科学家，专注于构建、建模、部署和维护机器学习模型。她还是数据和人工智能公司的开发者倡导者，帮助他们制作面向技术受众的内容。可以在[她的个人网站](https://najiagul.com/)找到她。'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Introducing TPU v4: Googles Cutting Edge Supercomputer for Large…](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[推出TPU v4：谷歌为大型语言模型打造的尖端超级计算机](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)'
- en: '[Maximize Performance in Edge AI Applications](https://www.kdnuggets.com/maximize-performance-in-edge-ai-applications)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最大化边缘AI应用中的性能](https://www.kdnuggets.com/maximize-performance-in-edge-ai-applications)'
- en: '[Windows on Snapdragon Brings Hybrid AI to Apps at the Edge](https://www.kdnuggets.com/qualcomm-windows-on-snapdragon-brings-hybrid-ai-to-apps-at-the-edge)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Snapdragon上的Windows将混合AI引入边缘应用](https://www.kdnuggets.com/qualcomm-windows-on-snapdragon-brings-hybrid-ai-to-apps-at-the-edge)'
- en: '[The Promise of Edge AI and Approaches for Effective Adoption](https://www.kdnuggets.com/the-promise-of-edge-ai-and-approaches-for-effective-adoption)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[边缘AI的承诺及有效采用的方法](https://www.kdnuggets.com/the-promise-of-edge-ai-and-approaches-for-effective-adoption)'
- en: '[5 Machine Learning Skills Every Machine Learning Engineer Should…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个机器学习工程师都应该掌握的5项机器学习技能](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
- en: '[KDnuggets News, December 14: 3 Free Machine Learning Courses for…](https://www.kdnuggets.com/2022/n48.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，12月14日：3门免费的机器学习课程](https://www.kdnuggets.com/2022/n48.html)'
