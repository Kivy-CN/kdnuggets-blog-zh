# 您的自然语言处理（NLP）指南

> 原文：[https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**由[Diego Lopez Yse](https://twitter.com/LopezYse)，穆迪拉丁美洲运营部**。

![](../Images/fbc813c836c8dc6c3bb83c0cc408e48a.png)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您组织的IT工作

* * *

我们表达的一切（无论是口头还是书面）都携带大量信息。我们选择的话题、语调、词汇选择，一切都添加了一些可以解释并从中提取价值的信息。从理论上讲，我们可以利用这些信息理解甚至预测人类行为。

但也存在一个问题：一个人可能在声明中生成数百或数千个词，每个句子都有其相应的复杂性。如果你想在某个地理区域内扩展并分析数百、数千或数百万人的声明，那么情况将变得无法管理。

从对话、声明甚至推文中生成的数据是非结构化数据的例子。**非结构化数据**无法整齐地适配关系数据库的传统行列结构，并且代表了现实世界中绝大多数的数据。这些数据混乱且难以操作。然而，感谢像机器学习这样的学科的进步，关于这一话题正在发生一场大革命。如今，不再是基于关键词（传统机械方式）来解释文本或语音，而是理解这些词背后的意义（认知方式）。这样就可以检测到比喻等修辞手法，甚至进行情感分析。

> ***自然语言处理***（NLP）是人工智能的一个领域，它赋予机器读取、理解和从人类语言中推导意义的能力。

这是一个关注数据科学与人类语言互动的学科，并且正在向许多行业扩展。今天，得益于数据访问的巨大改善和计算能力的提升，NLP正在蓬勃发展，这使得从业者在医疗保健、媒体、金融和人力资源等领域取得了有意义的成果。

### **NLP的应用场景**

简单来说，NLP 代表了自然人类语言（如语音或文本）的自动处理，尽管这一概念本身很吸引人，但真正的价值来自于实际应用。

NLP 可以帮助你处理大量任务，应用领域似乎每天都在增加。让我们举几个例子：

+   NLP 能够基于电子健康记录和患者自身的语言识别和**预测疾病**。这种能力正在用于从心血管疾病到抑郁症甚至精神分裂症的健康状况。例如，Amazon Comprehend Medical 是一项使用 NLP 的服务，用于[提取疾病状况](https://www.thenewsminute.com/article/tech-giants-india-join-ai-bandwagon-focus-healthcare-93833)、药物和治疗结果，从患者笔记、临床试验报告及其他电子健康记录中获取信息。

+   组织可以通过在社交媒体等来源中识别和提取信息，确定客户对某项服务或产品的评价。这种[**情感分析**](https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17)可以提供大量关于客户选择及其决策驱动因素的信息。

+   [IBM 的一位发明家开发了一个**认知助手**](https://www.theatlantic.com/technology/archive/2016/01/sorry-dave-afraid-i-cant-do-that/431559/)，它像个个性化的搜索引擎，通过学习关于你的所有信息，提醒你名字、歌曲或任何你在需要时无法记住的东西。

+   像 Yahoo 和 Google 这样的公司通过 NLP 对电子邮件进行过滤和分类，分析通过其服务器流动的邮件文本，并在邮件进入你的收件箱之前**阻止垃圾邮件**。

+   为了帮助**识别假新闻**，[麻省理工学院的 NLP 组](http://nlp.csail.mit.edu/)开发了一种新系统来判断一个来源是否准确或有政治偏见，检测新闻来源是否值得信赖。

+   亚马逊的 Alexa 和苹果的 Siri 是使用 NLP 的智能**语音驱动界面**的例子，它们响应语音提示，完成诸如寻找特定商店、告诉我们天气预报、建议最佳办公路线或打开家里的灯等任务。

+   了解正在发生的事情和人们在谈论什么对[**金融交易员**](https://news.efinancialcareers.com/nl-en/331386/charles-elkan-goldman-sachs-machine-learning)来说非常有价值。NLP 正在用于跟踪新闻、报告、关于公司之间可能合并的评论，一切都可以纳入交易算法以产生巨额利润。记住：买谣言，卖新闻。

+   NLP 也在 [**人才招聘**](https://www.forbes.com/sites/forbeshumanresourcescouncil/2018/09/27/how-ai-makes-recruiting-more-human/#7531fc116ba4) 的搜索和筛选阶段中得到了应用，识别潜在雇员的技能，并在他们还未进入就业市场时就能发现他们。

+   由IBM Watson NLP技术驱动的 [LegalMation](https://www.legalmation.com/) 开发了一个平台，以自动化常规**诉讼任务**，帮助法律团队节省时间、降低成本，并转移战略重点。

NLP 在 **医疗行业** 特别蓬勃发展。这项技术正在改善护理服务、疾病诊断，并降低成本，同时医疗组织也在逐步采用电子健康记录。临床文档的改进意味着患者可以通过更好的医疗服务得到更好的理解和照顾。目标应是优化患者体验，许多组织已经在致力于此。

![](../Images/d488f02f8a32cceea5f6df26d4df9ef6.png)

在1978-2018年期间，PubMed中包含“自然语言处理”这一句子的出版物数量。截至2018年，PubMed包含超过2900万条生物医学文献的引用。

像 [Winterlight Labs](https://winterlightlabs.com/) 这样的公司通过语音监测认知障碍在阿尔茨海默病治疗方面取得了巨大进展，它们还可以支持临床试验和针对各种中枢神经系统疾病的研究。斯坦福大学也采用了类似的方法，开发了 [Woebot](https://woebot.io/)，一个 **聊天机器人治疗师**，旨在帮助有焦虑症和其他疾病的患者。

但围绕这一主题存在严重的 [争议](https://www.bmj.com/content/358/bmj.j3159)。几年前，微软展示了通过分析大量搜索引擎查询，他们能够 [识别出那些患有胰腺癌的互联网用户](https://www.nytimes.com/2016/06/08/technology/online-searches-can-identify-cancer-victims-study-finds.html)，即使在他们还未收到疾病诊断之前。用户对这样的诊断会有何反应？如果你被测试为假阳性（即被诊断为患有该疾病，但实际上并未患病）会发生什么？这让人想起2009年Google Flu Trends的案例，虽然当时宣称能够预测流感，但由于准确性低和未能达到预期水平，后来消失了。

NLP 可能是未来有效临床支持的关键，但短期内仍面临许多挑战。

### **基础NLP以给你的非NLP朋友留下深刻印象**

当前我们在自然语言处理（NLP）中面临的主要缺点与语言本身的复杂性有关。理解和处理语言的过程极其复杂，因此通常使用不同的技术来应对不同的挑战，然后再将所有内容整合在一起。像Python或R这样的编程语言被广泛用于执行这些技术，但在深入代码行之前（那将是另一篇文章的主题），理解其背后的概念非常重要。让我们总结并解释一些在NLP中定义术语词汇时最常用的算法：

#### **词袋模型**

是一种常用的模型，允许你计算文本中的所有词汇。基本上，它为句子或文档创建一个出现矩阵，不考虑语法和词序。这些词频或出现次数随后被用作训练分类器的特征。

举一个简单的例子，我取了The Beatles歌曲“Across the Universe”的第一句：

> *Words are flowing out like endless rain into a paper cup,*
> 
> *They slither while they pass, they slip away across the universe*

现在让我们计算这些词：

![](../Images/cda94d22ba9f20d78ed2e98df51abcaa.png)

这种方法可能反映出几个缺点，例如缺乏语义意义和上下文，以及停用词（如“the”或“a”）给分析增加噪音，并且一些词的权重不符合实际（例如“universe”权重低于“they”）。

解决这个问题的一种方法是根据词在所有文本中出现的频率（而不仅仅是我们正在分析的文本）来重新缩放词频，以便像“the”这样的高频词在其他文本中也很常见，因此会受到惩罚。这种评分方法被称为**“词频——逆文档频率”** **(TFIDF)**，通过权重改进词袋模型。通过TFIDF，文本中的高频术语（如我们示例中的“they”）会受到“奖励”，但如果这些术语在我们包含在算法中的其他文本中也很频繁，它们也会受到“惩罚”。相反，这种方法突出了并“奖励”独特或稀有的术语，考虑到所有文本。然而，这种方法仍然没有上下文或语义。

#### **标记化**

是将连续文本划分为句子和单词的过程。本质上，它是将文本切割成称为*tokens*的片段，同时丢弃某些字符，如标点符号。以我们的示例为例，标记化的结果将是：

![](../Images/c229250b850f1aecf4712dcebddb9435.png)

很简单，对吧？虽然在这种情况下以及在像英语这样通过空格分隔单词的语言（称为分段语言）中这看起来很基本，但并非所有语言都表现相同。即使在英语中，仅靠空格也不足以进行正确的词元化。基于空格的分割可能会破坏应该被视为一个词的内容，例如某些名称（例如旧金山或纽约）或借用的外语短语（例如 laissez faire）。

**词元化也可以去除标点符号**，简化正确的词分割路径，但也可能引发一些问题。例如，在缩写（例如 dr.）之后的句点应视为同一个词的一部分，而不是被去除。

在处理包含大量连字符、括号和其他标点符号的生物医学文本领域时，词元化过程可能会特别棘手。

有关词元化的更详细信息，可以在 [这篇文章](https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en)中找到很好的解释。

#### **停用词移除**

包括去除诸如“and”，“the”或“to”这样的常见语言文章、代词和介词。在这个过程中，一些非常常见的词汇因提供的价值很小或没有价值而被过滤和排除，从而去除了那些不提供关于相应文本信息的广泛和频繁的术语。

通过在预定义的关键词列表中进行查找，可以安全地忽略停用词，从而释放数据库空间并提高处理速度。

**没有通用的停用词列表**。这些词可以是预先选定的，也可以从头开始建立。一种潜在的方法是首先采用预定义的停用词，然后在后续添加词汇。不过，过去一段时间的总体趋势似乎是从使用大型标准停用词列表转向完全不使用列表。

问题是，停用词的去除可能会抹去相关信息并修改给定句子的上下文。例如，如果我们正在进行情感分析，移除像“not”这样的停用词可能会使我们的算法偏离轨道。在这种情况下，你可能需要选择一个最小的停用词列表，并根据具体目标添加额外的词汇。

#### **词干提取**

指的是对单词的开头或结尾进行切割，以去除词缀（附加在词根上的词汇）。

*附加在单词开头的词缀称为前缀*（例如，“astrobi”中的“astro”），*而附加在单词结尾的词缀称为后缀*（例如，“helpful”中的“ful”）。

问题是词缀可以创建或扩展同一单词的新形式（称为*屈折*词缀），甚至可以创造新词（称为*派生*词缀）。在英语中，前缀总是派生的（词缀创造了一个新词，如“ecosystem”中的前缀“eco”），但后缀可以是派生的（词缀创造了一个新词，如“guitarist”中的后缀“ist”）或屈折的（词缀创建了一个新形式的词，如“faster”中的后缀“er”）。

好的，那我们如何分辨差异并切割正确的部分呢？

![](../Images/1608f7938632b5f6fc5c9937e9d17b4e.png)

一种可能的方法是考虑常见的词缀和规则列表（Python 和 R 语言有不同的库包含词缀和方法），并基于这些词缀进行词干提取，但这种方法当然存在局限性。由于词干提取器使用算法方法，词干提取的结果可能不是实际的单词，甚至可能改变单词（和句子）的含义。为了抵消这种影响，你可以通过添加或删除词缀和规则来编辑这些预定义的方法，但你必须考虑到，可能在一个领域提高了性能的同时会在另一个领域造成退化。始终关注整体情况，并测试你模型的性能。

那么，如果词干提取有严重的局限性，为什么我们还要使用它呢？首先，它可以用来纠正标记中的拼写错误。**词干提取器使用简单，运行非常快**（它们对字符串执行简单操作），如果速度和性能在自然语言处理模型中很重要，那么词干提取无疑是值得使用的。记住，我们使用它的目标是提高性能，而不是作为语法练习。

#### **词形还原**

其目标是将单词还原为基本形式，并将同一单词的不同形式进行归类。例如，将过去时态的动词转换为现在时态（例如，“went”变为“go”），并将同义词统一（例如，“best”变为“good”），从而将具有相似含义的词标准化为其根词。虽然这与词干提取过程密切相关，但词形还原采用了不同的方法来获取词的根形式。

> *词形还原将单词解析为其词典形式（称为**词根**），这需要详细的词典，以便算法可以查找并将单词链接到相应的词根。*

例如，单词“*running*”、“*runs*”和“*ran*”都是单词“*run*”的形式，因此“*run*”是所有这些单词的词根。

![](../Images/db52d4f3acf412f2fc2968068d3a82b8.png)

词形还原还考虑了单词的上下文，以**解决其他问题，如消歧义**，这意味着它可以区分在特定上下文中具有不同含义的相同单词。考虑像“bat”（可以指动物，也可以指棒球中的金属/木质棒）或“bank”（可以指金融机构，也可以指水体旁边的土地）这样的单词。通过为单词提供一个词性参数（例如，它是名词、动词等），可以为该单词在句子中定义一个角色，并消除歧义。

正如你可能已经想象的，词形还原（lemmatization）是一个比词干提取（stemming）过程更加资源密集的任务。与此同时，由于它比词干提取方法需要更多关于语言结构的知识，它**需要比设置或调整词干提取算法更多的计算能力**。

#### **主题建模**

作为一种揭示文本或文档集隐藏结构的方法，本质上，它将文本进行聚类，以发现基于其内容的潜在主题，处理单独的单词并根据其分布赋予其值。这项技术基于这样的假设：每个文档由一组主题混合组成，每个主题由一组单词组成，这意味着如果我们能发现这些隐藏的主题，就能解锁我们文本的含义。

在主题建模技术的宇宙中，**潜在狄利克雷分配（LDA）**可能是最常用的。这种相对较新的算法（发明不到20年前）作为一种无监督学习方法，发现一组文档中的不同主题。在像这样的**无监督学习**方法中，没有输出变量来指导学习过程，数据由算法探索以寻找模式。更具体地说，LDA通过以下方式找到相关单词的组：

1.  将每个单词分配给一个随机主题，用户定义其希望揭示的主题数量。你不定义主题本身（你只定义主题的数量），算法将以一种方式将所有文档映射到这些主题中，使得每个文档中的单词大多由这些虚拟主题捕获。

1.  该算法通过迭代地处理每个单词，并根据单词属于某个主题的概率以及文档由某个主题生成的概率来重新分配单词。这些概率会被计算多次，直到算法收敛为止。

与执行硬聚类（即主题是分离的）的其他聚类算法如[*K-means*](https://towardsdatascience.com/the-anatomy-of-k-means-c22340543397)不同，LDA将每个文档分配到多个主题的混合中，这意味着每个文档可以由一个或多个主题来描述（例如，文档1由70%的主题A、20%的主题B和10%的主题C来描述），并且能反映更现实的结果。

![](../Images/99eacccff44debcd7badd73879846b96.png)

主题建模对于分类文本、构建推荐系统（例如，根据你过去的阅读推荐书籍）甚至检测在线出版物中的趋势非常有用。

### **未来的前景如何？**

目前，NLP正面临检测语言意义细微差别的挑战，无论是由于缺乏上下文、拼写错误还是方言差异。

2016年3月，微软推出了*Tay*，这是一个在Twitter上发布的人工智能（AI）聊天机器人，作为自然语言处理（NLP）实验。其设想是随着更多用户与Tay对话，它会变得越来越聪明。然而，结果是16小时后Tay因其种族主义和侮辱性言论被迫下线：

![](../Images/47796f4589c4b9f14b3dffde8ac600fd.png)

![](../Images/bdf3e47587ee620ca505d589bd9e3a5c.png)

微软从自身经验中吸取了教训，几个月后推出了[*Zo*](https://www.zo.ai/)，这是其第二代英语聊天机器人，不会犯与前任相同的错误。Zo使用了一系列创新的方法来识别和生成对话，其他公司也在探索能够记住特定对话细节的聊天机器人。

尽管未来对NLP来说充满了极大的挑战和威胁，但该领域的发展速度非常快（可能像从未有过的那样），我们有望在未来几年达到一个让复杂应用变得可能的进展水平。

[原文](https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1)。经允许转载。

**简介**：[Diego Lopez Yse](https://twitter.com/LopezYse)是一位拥有丰富国际背景的经验丰富的专业人士，曾在生物技术、软件、咨询、政府、农业等不同领域工作。

**资源：**

+   [在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)

+   [用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)

**相关：**

+   [利用Facebook的Pytorch-BigGraph从知识图谱中提取知识](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)

+   [文本数据的完整探索性数据分析和可视化：结合可视化和NLP以生成洞察](https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html)

+   [使用 Python 和 NLTK 构建你的第一个聊天机器人](https://www.kdnuggets.com/2019/05/build-chatbot-python-nltk.html)

### 相关主题

+   [N-gram 语言建模在自然语言处理中的应用](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)

+   [顶级自然语言处理库指南](https://www.kdnuggets.com/2023/04/guide-top-natural-language-processing-libraries.html)

+   [自然语言处理的关键术语解释](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)

+   [自然语言处理任务的数据表示](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)

+   [图像识别和自然语言处理中的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)

+   [如何使用 PyTorch 开始自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)
