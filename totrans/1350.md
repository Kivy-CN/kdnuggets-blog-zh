# 数据科学与 DevOps 的融合：使用 Jupyter、Git 和 Kubernetes 的 MLOps

> 原文：[https://www.kdnuggets.com/2020/08/data-science-meets-devops-mlops-jupyter-git-kubernetes.html](https://www.kdnuggets.com/2020/08/data-science-meets-devops-mlops-jupyter-git-kubernetes.html)

[评论](#comments)

**由 [Jeremy Lewi](https://www.linkedin.com/in/jeremy-lewi-600aaa8/)（谷歌软件工程师）与 [Hamel Husain](https://hamel.dev/)（GitHub 高级机器学习工程师）**

### 问题

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 在 IT 支持您的组织

* * *

[Kubeflow](https://www.kubeflow.org/) 是一个快速增长的开源项目，使得在 Kubernetes 上部署和管理机器学习变得简单。

由于 Kubeflow 的爆炸性流行，我们收到大量需要分流和转交给相关领域专家的 GitHub 问题。下图展示了过去一年中新开问题的数量：

![图](../Images/ca21ec3fd9d9af4779955e596f179893.png)

**图 1：** Kubeflow 问题数量

为了应对这一涌入，我们开始投资一个名为 [Issue Label Bot](https://github.com/marketplace/issue-label-bot) 的 GitHub 应用，该应用使用机器学习自动标记问题。我们的 [第一个模型](https://github.com/marketplace/issue-label-bot) 是使用 GitHub 上流行的公共代码库进行训练的，只预测通用标签。随后，我们开始使用 [Google AutoML](https://cloud.google.com/automl/docs) 训练一个特定于 Kubeflow 的模型。新模型能够以 72% 的平均精度和 50% 的平均召回率预测 Kubeflow 特定标签。这大大减少了 Kubeflow 维护者在问题管理方面的工作量。下表包含了 Kubeflow 特定标签在保留集上的评估指标。下方的 [精度和召回率](https://en.wikipedia.org/wiki/Precision_and_recall) 与我们调整以满足需求的预测阈值一致。

| 标签 | 精度 | 召回率 |
| --- | --- | --- |
| area-backend | 0.6 | 0.4 |
| area-bootstrap | 0.3 | 0.1 |
| area-centraldashboard | 0.6 | 0.6 |
| area-components | 0.5 | 0.3 |
| area-docs | 0.8 | 0.7 |
| area-engprod | 0.8 | 0.5 |
| area-front-end | 0.7 | 0.5 |
| area-frontend | 0.7 | 0.4 |
| area-inference | 0.9 | 0.5 |
| area-jupyter | 0.9 | 0.7 |
| area-katib | 0.8 | 1.0 |
| area-kfctl | 0.8 | 0.7 |
| area-kustomize | 0.3 | 0.1 |
| area-operator | 0.8 | 0.7 |
| area-pipelines | 0.7 | 0.4 |
| area-samples | 0.5 | 0.5 |
| area-sdk | 0.7 | 0.4 |
| area-sdk-dsl | 0.6 | 0.4 |
| area-sdk-dsl-compiler | 0.6 | 0.4 |
| area-testing | 0.7 | 0.7 |
| area-tfjob | 0.4 | 0.4 |
| platform-aws | 0.8 | 0.5 |
| platform-gcp | 0.8 | 0.6 |

**表 1:** 各种 Kubeflow 标签的评估指标。

鉴于新问题出现的速度，定期重新训练我们的模型成为了优先事项。我们认为，持续重新训练和部署模型以利用这些新数据对于保持模型的有效性至关重要。

### 我们的解决方案

我们的 CI/CD 解决方案如 [图 2](https://blog.kubeflow.org/mlops/#fig2) 所示。我们没有明确创建一个有向无环图 (DAG) 来连接 ML 工作流中的步骤（如预处理、训练、验证、部署等）。相反，我们使用一组独立的控制器。每个控制器声明性地描述了世界的期望状态，并采取必要的行动使实际状态与之匹配。这种独立性使我们能够使用最适合每个步骤的工具。更具体地说，我们使用

+   Jupyter notebooks 用于开发模型。

+   GitOps 进行持续集成和部署。

+   Kubernetes 和托管云服务用于基础设施。

![图像](../Images/931ec07d5c7eb19b1e7c4ea2d126b568.png)

**图 2:** 说明了我们如何进行 CI/CD。我们现在的管道由两个独立运行的控制器组成。我们通过描述希望存在的模型来配置 Trainer（左侧）；即我们希望模型“新鲜”的含义。Trainer 定期检查已训练模型的集合是否足够新鲜，如果不够新鲜，则训练新模型。我们同样配置 Deployer（右侧）来定义已部署模型与训练模型集合保持同步的含义。如果未部署正确的模型，它将部署新模型。

有关模型训练和部署的更多细节，请参阅 [下面的执行部分](https://blog.kubeflow.org/mlops/#actuation)。

### 背景

### 使用协调器构建弹性系统

协调器是一种被证明对构建弹性系统非常有用的控制模式。协调模式 [在 Kubernetes 工作原理的核心](https://book.kubebuilder.io/cronjob-tutorial/controller-overview.html)。图 3 说明了协调器是如何工作的。协调器通过首先观察世界的状态来工作；例如，当前部署了哪个模型。然后，协调器将其与世界的期望状态进行比较，并计算差异；例如，应该部署标签为“version=20200724”的模型，但当前部署的模型标签为“version=20200700”。然后，协调器采取必要的行动来将世界驱动到期望状态；例如，打开一个拉取请求以更改已部署的模型。

![图像](../Images/d8e6c56c244863ca835a1cfa7e1ad079.png)

**图 3。** 我们部署者应用调解器模式的示意图。

调解器在构建弹性系统方面证明极为有用，因为一个实施良好的调解器可以提供高度的信心，无论系统如何扰动，它最终都会回到期望的状态。

### 没有 DAG

控制器的声明性特征意味着数据可以通过一系列控制器流动，而不需要明确创建 DAG。代替 DAG，一系列数据处理步骤可以表达为一组期望的状态，如下面的图 4 所示：

![图像](../Images/1c53e020082053494462bff18c544df7.png)

**图 4：** 展示了管道如何从独立的控制器中出现，而无需明确编码 DAG。这里我们有两个完全独立的控制器。第一个控制器确保每个元素 a[i] 都有一个元素 b[i]。第二个控制器确保每个元素 b[i] 都有一个元素 c[i]。

这种基于调解器的范式相比于许多传统的 DAG 基于工作流具有以下优点：

+   **对故障的弹性：** 系统持续寻求实现并维持期望状态。

+   **工程团队的自主性提升：** 每个团队可以自由选择适合他们需求的工具和基础设施。调解器框架仅要求控制器之间有最小的耦合，同时仍允许编写表达力丰富的工作流。

+   **经过战斗检验的模式和工具**：这个基于调解器的框架并没有发明什么新的东西。Kubernetes 拥有丰富的工具生态系统，旨在简化控制器的构建。Kubernetes 的流行意味着有一个庞大且不断增长的社区熟悉这种模式和支持工具。

### GitOps：通过拉取请求操作

GitOps，图 5，是管理基础设施的一种模式。GitOps 的核心思想是源代码控制（不一定是 git）应该是描述你的基础设施的配置文件的真实来源。控制器可以监控源代码控制，并在配置变化时自动更新你的基础设施。这意味着要进行更改（或撤销更改），你只需打开一个拉取请求。

![图像](../Images/adfb35bbfe035929d945819692faca86.png)

**图 5：** 为了推动 Label Bot 的新模型，我们创建了一个 PR 更新存储我们想使用的 Auto ML 模型 ID 的配置映射。当 PR 合并时， [Anthos 配置管理(ACM](https://cloud.google.com/anthos-config-management/docs)) 会自动将这些更改部署到我们的 GKE 集群。因此，随后的预测将使用新模型。（图像由 [Weaveworks](https://www.weave.works/blog/automate-kubernetes-with-gitops)提供）

### 综合起来：调解器 + GitOps = 机器学习的 CI/CD

在了解了这些背景后，让我们深入探讨一下我们如何通过结合调解器和 GitOps 模式来构建机器学习的 CI/CD。

我们需要解决三个问题：

1.  我们如何计算期望状态与实际状态之间的差异？

1.  我们如何影响所需的更改，以使实际状态与期望状态匹配？

1.  我们如何构建一个控制循环来持续运行 1 和 2？

### 计算差异

为了计算差异，我们只需编写确切符合我们需求的 lambdas。因此，在这种情况下，我们编写了两个 lambdas：

1.  [第一个 lambda](https://github.com/kubeflow/code-intelligence/blob/faeb65757214ac93259f417b81e9e2fedafaebda/Label_Microservice/go/cmd/automl/pkg/server/server.go#L109)根据最新模型的年龄来确定是否需要重新训练。

1.  [第二个 lambda](https://github.com/kubeflow/code-intelligence/blob/faeb65757214ac93259f417b81e9e2fedafaebda/Label_Microservice/go/cmd/automl/pkg/server/server.go#L49) 通过将最近训练的模型与配置映射中列出的模型进行比较，来确定模型是否需要更新。

我们将这些 lambdas 封装在一个简单的 web 服务器中，并部署在 Kubernetes 上。我们选择这种方法的原因之一是我们希望依赖 Kubernetes 的 [git-sync](https://github.com/kubernetes/git-sync) 将我们的仓库镜像到一个 pod 卷中。这使我们的 lambdas 非常简单，因为所有的 git 管理都由一个运行 [git-sync](https://github.com/kubernetes/git-sync) 的 side-car 处理。

### 执行

为了应用所需的更改，我们使用 Tekton 将各种 CLIs 连接在一起，以执行各个步骤。

### 模型训练

为了训练我们的模型，我们有一个 [Tekton 任务](https://github.com/kubeflow/code-intelligence/blob/faeb65757214ac93259f417b81e9e2fedafaebda/tekton/tasks/run-notebook-task.yaml#L34)，其功能是：

1.  使用 [papermill](https://github.com/nteract/papermill) 运行我们的笔记本。

1.  使用 [nbconvert](https://nbconvert.readthedocs.io/en/latest/) 将笔记本转换为 html。

1.  使用 [gsutil](https://cloud.google.com/storage/docs/gsutil) 将 `.ipynb` 和 `.html` 文件上传到 GCS。

该笔记本从 BigQuery 中获取 GitHub Issues 数据 [从 BigQuery](https://medium.com/google-cloud/analyzing-github-issues-and-comments-with-bigquery-c41410d3308)，并生成适合导入到 [Google AutoML](https://cloud.google.com/automl)的 CSV 文件。然后，笔记本启动一个 [AutoML](https://cloud.google.com/automl) 任务来训练模型。

我们选择了 AutoML，因为我们希望专注于构建一个完整的端到端解决方案，而不是在模型上进行迭代。AutoML 提供了一个竞争性的基准，我们可能在未来尝试进行改进。

为了方便查看执行过的笔记本，我们将其转换为 html 并上传到 [GCS，使其易于提供公共静态内容](https://cloud.google.com/storage/docs/hosting-static-website)。这使我们能够使用笔记本生成丰富的可视化图表，以评估我们的模型。

### 模型部署

为了部署我们的模型，我们有一个 [Tekton 任务](https://github.com/kubeflow/code-intelligence/blob/faeb65757214ac93259f417b81e9e2fedafaebda/tekton/tasks/update-model-pr-task.yaml#L68)，其功能如下：

1.  使用 kpt 更新我们的 configmap 以设置所需的值。

1.  运行 git 将我们的更改推送到一个分支。

1.  使用 [GitHub CLI](https://github.com/cli/cli)（gh）的封装器来创建 PR。

控制器确保同时只有一个 Tekton 管道在运行。我们将管道配置为始终推送到相同的分支。这确保我们只会打开一个 PR 来更新模型，因为 GitHub 不允许从相同分支创建多个 PR。

一旦 PR 被合并，[Anthos Config Mesh](https://cloud.google.com/anthos/config-management) 会自动将 Kubernetes 清单应用到我们的 Kubernetes 集群中。

### 为什么选择 Tekton

我们选择 Tekton 是因为我们面临的主要挑战是在各种容器中顺序运行一系列 CLI。Tekton 非常适合这个任务。重要的是，Tekton 任务中的所有步骤都在同一个 Pod 上运行，这允许通过 Pod 卷在步骤之间共享数据。

此外，由于 Tekton 资源是 Kubernetes 资源，我们可以采用相同的 GitOps 模式和工具来更新我们的管道定义。

### 控制循环

最后，我们需要构建一个控制循环，该循环会定期调用我们的 Lambda 函数并根据需要启动我们的 Tekton 管道。我们使用 kubebuilder 创建了一个 [简单自定义控制器](https://github.com/kubeflow/code-intelligence/tree/master/Label_Microservice/go)。我们控制器的同步循环将调用我们的 Lambda 函数来确定是否需要同步，如果需要，则确定同步的参数。如果需要同步，控制器会触发 Tekton 管道来执行实际的更新。我们的 [自定义资源](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) 的示例如下：

[PRE0]

自定义资源指定了计算是否需要同步的 Lambda 的端点 **needsSyncUrl** 和一个 Tekton PipelineRun **pipelineRunTemplate**，描述了当需要同步时创建的管道运行。控制器处理细节，例如确保每个资源只运行一个管道，垃圾收集旧的运行等。所有繁重的工作由 Kubernetes 和 kubebuilder 处理。

注意，由于历史原因，kind **ModelSync** 和 apiVersion **automl.cloudai.kubeflow.org** 并未反映控制器实际的功能。我们计划在未来修复这一点。

### 构建你自己的 CI/CD 管道

我们的代码库距离精炼和易于重用的工具还有很长的路要走。尽管如此，它是公开的，并且可能是尝试构建自己管道的有用起点。

这里有一些提示可以帮助你入门：

1.  使用 Dockerfile 构建你自己的 [ModelSync 控制器](https://github.com/kubeflow/code-intelligence/blob/master/Label_Microservice/go/Dockerfile)

1.  [修改 kustomize 包](https://github.com/kubeflow/code-intelligence/tree/master/Label_Microservice/go/config/default) 以使用你的镜像并部署控制器。

1.  根据你的用例定义一个或多个 lambda 函数。

    +   你可以使用我们的 [Lambda 服务器](https://github.com/kubeflow/code-intelligence/blob/master/Label_Microservice/go/cmd/automl/pkg/server/server.go) 作为示例。

    +   我们使用 Go 编写了我们的代码，但你可以使用任何你喜欢的语言和 Web 框架（例如 flask）。

1.  为你的用例定义适合的 Tekton 流水线；我们的流水线（如下所示）可能是一个有用的起点。

    +   [Notebook Tekton 任务](https://github.com/kubeflow/code-intelligence/blob/master/tekton/tasks/run-notebook-task.yaml) - 使用 papermill 运行 notebook 并上传到 GCS。

    +   [PR Tekton 任务](https://github.com/kubeflow/code-intelligence/blob/master/tekton/tasks/update-model-pr-task.yaml) - 用于打开 GitHub PR 的 Tekton 任务。

1.  为你的用例定义 ModelSync 资源；你可以参考我们的示例。

    +   [ModelSync 部署规范](https://github.com/kubeflow/code-intelligence/blob/master/Label_Microservice/auto-update/prod/modelsync.yaml) - 用于持续部署标签机器人 的 YAML。

    +   [ModelSync 训练规范](https://github.com/kubeflow/code-intelligence/blob/master/Label_Microservice/auto-update/prod/retrain-model.yaml) - 用于持续训练我们模型的 YAML。

如果你希望看到我们清理并将其包含在未来的 Kubeflow 版本中，请在问题 [kubeflow/kubeflow#5167](https://github.com/kubeflow/kubeflow/issues/5167) 上发表意见。

### 下一步

### 血缘追踪

由于我们没有明确的 DAG 表示 CI/CD 流水线中的步骤序列，理解我们模型的血缘关系可能具有挑战性。幸运的是，Kubeflow Metadata 通过简化每个步骤记录其产生的输出、使用的代码和输入的信息来解决这个问题。Kubeflow metadata 可以轻松恢复并绘制血缘图。下图显示了我们 [xgboost 示例](https://github.com/kubeflow/examples/blob/master/xgboost_synthetic/build-train-deploy.ipynb) 的血缘图示例。

![图示](../Images/f326e5bb68979f485160afc1ff4f5995.png)

**图 6：** 我们 [xgboost 示例](https://github.com/kubeflow/examples/blob/master/xgboost_synthetic/build-train-deploy.ipynb) 的血缘追踪 UI 截图。

我们的计划是让控制器自动将血缘追踪信息写入 metadata 服务器，以便我们可以轻松了解生产环境中的内容的血缘关系。

### 结论

![替代文本](../Images/5fbf922ac3998192a63305b57198a28c.png)

构建机器学习产品是一个团队合作的过程。为了将模型从概念验证阶段转变为实际产品，数据科学家和运维工程师需要协作。为了促进这种协作，我们认为允许数据科学家和运维工程师使用他们首选的工具非常重要。具体来说，我们希望支持以下工具供数据科学家、运维工程师和[SRE](https://en.wikipedia.org/wiki/Site_Reliability_Engineering)使用：

+   用于开发模型的 Jupyter notebooks。

+   GitOps用于持续集成和部署。

+   Kubernetes和托管云服务作为基础设施。

为了最大化每个团队的自主性并减少对工具的依赖，我们的CI/CD过程采用了去中心化的方法。我们的方法并不是明确地定义一个连接步骤的DAG，而是依赖一系列可以独立定义和管理的控制器。我们认为这自然适用于那些责任可能分散在多个团队中的企业；数据工程团队可能负责将网络日志转化为特性，建模团队可能负责从这些特性中生成模型，而部署团队可能负责将这些模型投入生产。

### 进一步阅读

如果你想了解更多关于GitOps的内容，我们建议你查看Weaveworks的[指南](https://www.weave.works/technologies/gitops/)。

要学习如何构建自己的Kubernetes控制器，[kubebuilder书籍](https://book.kubebuilder.io/)提供了一个端到端的示例。

**[Jeremy Lewi](https://www.linkedin.com/in/jeremy-lewi-600aaa8/)** 是 Google 的软件工程师。

**[Hamel Husain](https://hamel.dev/)** 是 GitHub 的高级机器学习工程师。

[原始内容](https://blog.kubeflow.org/mlops/)。经授权转载。

**相关：**

+   [从200种机器学习工具中学到的东西](/2020/07/200-machine-learning-tools.html)

+   [在边缘设备上实现MLOps](/2020/08/implementing-mlops-edge-device.html)

+   [端到端机器学习平台导览](/2020/07/tour-end-to-end-machine-learning-platforms.html)

### 更多相关话题

+   [Kubernetes In Action: 第二版](https://www.kdnuggets.com/2022/03/manning-kubernetes-action-second-edition.html)

+   [Kubernetes中的高可用SQL Server Docker容器](https://www.kdnuggets.com/2022/04/high-availability-sql-server-docker-containers-kubernetes.html)

+   [数据科学Git快速参考](https://www.kdnuggets.com/2022/11/git-data-science-cheatsheet.html)

+   [通过这个免费的DevOps速成课程释放你的潜力](https://www.kdnuggets.com/2023/03/corise-unlock-potential-with-this-free-devops-crash-course.html)

+   [每个初学者都应学习的10个必备DevOps工具](https://www.kdnuggets.com/10-essential-devops-tools-every-beginner-should-learn)

+   [数据科学家必备的14条Git命令](https://www.kdnuggets.com/2022/06/14-essential-git-commands-data-scientists.html)
