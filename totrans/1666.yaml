- en: Data Science Interview Guide
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/04/data-science-interview-guide.html](https://www.kdnuggets.com/2018/04/data-science-interview-guide.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/04/data-science-interview-guide.html?page=2#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/), Analytic Scientist**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Header image](../Images/39c39201e31200f508a749b504e4a234.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Data Science is quite a large and diverse field. As a result, it is really difficult
    to be a jack of all trades. Traditionally, Data Science would focus on mathematics,
    computer science and domain expertise. While I will briefly cover some computer
    science fundamentals, the bulk of this blog will mostly cover the mathematical
    basics one might either need to brush up on (or even take an entire course).
  prefs: []
  type: TYPE_NORMAL
- en: Software Tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most data science workplaces, software skills are a must. While I understand
    most of you reading this are more math heavy by nature, realize the bulk of data
    science (dare I say 80%+) is collecting, cleaning and processing data into a useful
    form.
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming Language**'
  prefs: []
  type: TYPE_NORMAL
- en: Python and R are the most popular ones in the Data Science space. However, I
    have also come across C/C++, Java and Scala. Although, I would personally recommend
    Python as it has all the math libraries as well as specialized libraries for querying
    various databases and maintaining interactive web UIs. Common Python libraries
    of choice are matplotlib, numpy, pandas and scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5d840f5acc4259dbba2bfed69d0983bb.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Database Management**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is common to see the majority of the data scientists being in one of two
    camps: Mathematicians and Database Architects. If you are the second one, the
    blog won’t help you much (YOU ARE ALREADY AWESOME!). If you are among the first
    group (like me), chances are you feel that writing a double nested SQL query is
    an utter nightmare. That being said, it is important to have some knowledge of
    query optimization (both for SQL and noSQL systems).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f542bde46db7d4176e35873dcfa2f80d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Map Reduce**'
  prefs: []
  type: TYPE_NORMAL
- en: Big Data technologies are a little hard to follow considering how the Apache
    project keeps on adding new tools all the time. However, I would recommend learning
    either Hadoop or Spark (though my personal recommendation is Spark). Both use
    similar Map Reduce algorithms (except Hadoop does it on disk while Spark does
    it in memory). Common Spark wrappers are Scala, Python and Java.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/817cf4fb39635e39346fcbcac92ff0d1.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Additional Information**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information on software development for data science applications,
    here are some of my other blogs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Python based Plotting with Matplotlib](https://towardsdatascience.com/python-based-plotting-with-matplotlib-8e1c301e2799)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Package Management with Conda](https://medium.com/@sadatnazrul/python-package-management-with-conda-9d3475f42122)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to make your Software Development experience… painless….](https://towardsdatascience.com/how-to-make-your-software-development-experience-painless-2591ebcc69b6)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software Development Design Principles](https://medium.com/@sadatnazrul/software-development-design-principles-79d15ef765f3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Collection And Cleaning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have covered the software needs, we will start making a smooth
    transition into the mathematics domain. Around this part of the process, you generally
    need to have some parsing background. This might either be collecting sensor data,
    parsing websites or carrying out surveys. After collecting the data, it needs
    to be transformed into a usable form (e.g. key-value store in JSON Lines files).
    Once the data is collected and put in a usable format, it is essential to perform
    some data quality checks. Some common quality checks are as described below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NaN Handling**'
  prefs: []
  type: TYPE_NORMAL
- en: NaN or “Not A Number” is a common place holder for missing data. If the number
    of NaNs for the specific feature is small, it usually suffice fill in the NaNs
    with the average value (of the entire dataset or a window), or with 0s (for a
    sparse dataset).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b05ae3669467e2e78e90ff725d95200.png)'
  prefs: []
  type: TYPE_IMG
- en: 'NaNs in a dataset usually indicates:'
  prefs: []
  type: TYPE_NORMAL
- en: the data doesn’t exist
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the data does exist but we don’t know what it is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the specific use case, the appropriate measures should be taken.
  prefs: []
  type: TYPE_NORMAL
- en: '**Class Imbalance**'
  prefs: []
  type: TYPE_NORMAL
- en: Specifically for supervised learning models, it is important for classes (or
    targets) to be balanced. However, in cases of fraud, it is very common to heave
    heavy class imbalance (e.g. only 2% of the dataset is actual fraud).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/85afa006588db47a21393ed684cd573a.png)'
  prefs: []
  type: TYPE_IMG
- en: Such information is important to decide on the appropriate choices for feature
    engineering, modelling and model evaluation. For more information, check my blog
    on [Fraud Detection Under Extreme Class Imbalance](https://towardsdatascience.com/fraud-detection-under-extreme-class-imbalance-c241854e60c).
  prefs: []
  type: TYPE_NORMAL
- en: '**Univariate Analysis**'
  prefs: []
  type: TYPE_NORMAL
- en: Univariate analysis of single features (ignoring co-variate effects) is important
    when trying to look for outliers and unusual spikes in the variance. Common univariate
    analysis of choice is the histogram.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/eca0ccfc0e925d1359b7ae35b49cde2d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Bivariate Analysis**'
  prefs: []
  type: TYPE_NORMAL
- en: In bivariate analysis, each feature is compared to other features in the dataset.
    This would include correlation matrix, co-variance matrix or my personal favorite,
    the scatter matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/860554281a0551049ade70ff62aa1a59.png)'
  prefs: []
  type: TYPE_IMG
- en: Scatter matrices allow us to find hidden patterns such as
  prefs: []
  type: TYPE_NORMAL
- en: features that should be engineered together
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: features that may need to be eliminated to avoid multicolinearity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multicollinearity is actually an issue for multiple models like linear regression
    and hence needs to be taken care of accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the data is collected, cleaned and analyzed, it’s time to start creating
    features to be used in the model. In this section, we will explore some common
    feature engineering tactics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transformation**'
  prefs: []
  type: TYPE_NORMAL
- en: 'At times, the feature by itself may not provide useful information. For example,
    imagine using internet usage data. You will have YouTube users going as high as
    Giga Bytes while Facebook Messenger users use a couple of Mega Bytes. The simplest
    solution here would be to take the LOG of the values. Another issue is the use
    of categorical values. While categorical values are common in the data science
    world, realize computers can only comprehend numbers. In order for the categorical
    values to make mathematical sense, it needs to be transformed into something numeric.
    Typically for categorical values, it is common to perform a One Hot Encoding.
    In One Hot Encoding, a new feature is created for each categorical value to state
    if it is present in the given record. Example of One Hot Encoding is given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7b3f6bf4edc16893aa1143dc9624cfbb.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Combination**'
  prefs: []
  type: TYPE_NORMAL
- en: Certain features are redundant by themselves but are useful when grouped together.
    For example, imagine you had a predictive model for traffic density and you had
    a column for each type of car. Naturally, you don’t care about the type of car
    but the frequency of the total number of cars. Hence, a row wise summation of
    all the car types can be done to create a new “all_cars” variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dimensionality Reduction**'
  prefs: []
  type: TYPE_NORMAL
- en: At times, having too many sparse dimensions will hamper the performance of the
    model. For such situations (as commonly done in image recognition), dimensionality
    reduction algorithms are used.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ae399931b04fea3397d049e5bd502b13.png)'
  prefs: []
  type: TYPE_IMG
- en: An algorithm commonly used for dimensionality reduction is Principal Components
    Analysis or PCA. Learn the mechanics of PCA as it is also one of those topics
    amongst **COMMON INTERVIEW QUESTIONS**!!! For more information, check our my blog
    on [The DOs and DON’Ts of Principal Component Analysis](https://medium.com/@sadatnazrul/the-dos-and-donts-of-principal-component-analysis-7c2e9dc8cc48).
  prefs: []
  type: TYPE_NORMAL
- en: Feature Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have engineered your list of features, it is now time to select
    the features that will help build the most optimum model for the use case. The
    common categories and their sub categories are explained in this section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Filter Methods**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/aae4199567ae5c73388a9f0c63eb3e25.png)'
  prefs: []
  type: TYPE_IMG
- en: Filter methods are generally used as a preprocessing step. The selection of
    features is independent of any machine learning algorithms. Instead, features
    are selected on the basis of their scores in various statistical tests for their
    correlation with the outcome variable. The correlation is a subjective term here.
    Common methods under this category are Pearson’s Correlation, Linear Discriminant
    Analysis, ANOVA and Chi-Square.
  prefs: []
  type: TYPE_NORMAL
- en: '**Wrapper Methods**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9033a3d8e865d7793fa46722a0608f6d.png)'
  prefs: []
  type: TYPE_IMG
- en: In wrapper methods, we try to use a subset of features and train a model using
    them. Based on the inferences that we draw from the previous model, we decide
    to add or remove features from your subset. The problem is essentially reduced
    to a search problem. These methods are usually computationally very expensive.
    Common methods under this category are Forward Selection, Backward Elimination
    and Recursive Feature Elimination.
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedded Methods**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b155ab68ef14bdbc45c8d4eec0dc1baa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Embedded methods combine the qualities’ of filter and wrapper methods. It’s
    implemented by algorithms that have their own built-in feature selection methods.
    LASSO and RIDGE are common ones. The regularizations are given in the equations
    below as reference:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lasso:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5cb22dbb083a6b892f4a1b6b9fb96370.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Ridge:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2764f32a7e8f12f4f5707e8dbe11cf72.png)'
  prefs: []
  type: TYPE_IMG
- en: That being said, it is **VERY IMPORTANT** to understand the mechanics behind
    LASSO and RIDGE for interviews.
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interview Kickstart Data Science Interview Course — What Makes It…](https://www.kdnuggets.com/2022/10/interview-kickstart-data-science-interview-course-makes-different.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 1: The Structure](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, May 4: 9 Free Harvard Courses to Learn Data…](https://www.kdnuggets.com/2022/n18.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Answer Data Science Coding Interview Questions](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15 Python Coding Interview Questions You Must Know For Data Science](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
