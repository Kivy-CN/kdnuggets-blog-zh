["```py\ndef CrossEntropy(yHat, y):\n    if y == 1:\n      return -log(yHat)\n    else:\n      return -log(1 - yHat)\n```", "```py\nfrom sklearn.metrics import log_loss:\n\nLogLoss = log_loss(y_true, y_pred, eps = 1e-15,\n    normalize = True, sample_weight = None, labels = None)\n```", "```py\ndef Hinge(y_pred, y_true):\n   return np.max([0., 1\\. - y_pred * y_true])\n```", "```py\ndef mean_square_error(y_true, y_pred):\n   return K.mean(K.square(y_true-y_pred), axis=-1)\n```", "```py\ndef mean_abc_error(y_true, y_pred):\n   return K.mean(K.abs(y_true-y_pred), axis=-1)\n```", "```py\ndef Huber(yHat, y, delta=1.):\n    return np.where(np.abs(y-yHat) < delta,.5*(y-yHat)**2 , delta*(np.abs(y-yHat)-0.5*delta))\n```"]