- en: Visualizing Your Confusion Matrix in Scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/09/visualizing-confusion-matrix-scikitlearn.html](https://www.kdnuggets.com/2022/09/visualizing-confusion-matrix-scikitlearn.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: There are many machine learning algorithms packaged in the form of standard
    software to train your data. So, training and building an algorithm is trivial.
    But what separates an experienced data scientist from a novice is how they evaluate
    the quality of their machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: During the model development stage, you train a set of algorithms on the given
    data, evaluate their performance and eventually select the best-performing model.
    But how we define a metric to choose the best model out of the candidate set of
    algorithms plays a crucial role in the success of your machine learning solution.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about a confusion matrix, it is always in the classification problem
    context. Let’s take an example of binary classification (two-class problem). Here
    we have binary or two states of a variable known as the target variable. The task
    is to predict the state given some attributes or independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: The four counts we get from the state interaction between the predicted states
    and the actual states are what form our confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/80496a6d5fd6005d32caf8dfcfb4c429.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://www.explorium.ai/wp-content/uploads/2019/07/Confusion-1024x733.png](https://www.explorium.ai/wp-content/uploads/2019/07/Confusion-1024x733.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Components of Confusion Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The four quadrants are defined as True Negative (TN), True Positive (TP), False
    Positive (FP), False Negative (FN). If you are not acquainted with these terms
    and they look confusing going by their name, then stay tuned and read along, these
    terms are demystified in the section below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Negative:** Whenever we say True, it means our predictions match the
    actuals. True Negative means both predictions and actuals are of a negative class.'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positive:** Similarly when predictions and actuals are of positive class,
    it’s called a True Positive.'
  prefs: []
  type: TYPE_NORMAL
- en: Akin to the True categories explained above where the actuals and predictions
    are conforming, False categories indicate that prediction is not matching the
    ground truth i.e. actuals. This is the area of concern for data scientists. Optimistically
    speaking, this false section is also the key driver that enables data scientists
    to identify the limitations and concerns attributed to either the algorithmic
    model or the data itself. This process is called error analysis which puts focus
    on deviations of predictions from the actuals.
  prefs: []
  type: TYPE_NORMAL
- en: '**False Positive:** When a prediction is positive and the actual is negative
    it’s called a False Positive.'
  prefs: []
  type: TYPE_NORMAL
- en: '**False Negative:** Similar to False Positive, False Negative is when the prediction
    is negative but the actual is positive.'
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix thus represents the count of all TP, TN, FP, and FN instances.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Derived Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The four numbers in a confusion matrix standalone give us an understanding
    of the model performance at a granular level but data scientists need one single
    measure that can help them evaluate the overall model performance. This helps
    them formulate an ML problem as a minimization problem. Hence, there are some
    key evaluation metrics derived from these four measures as explained below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy:** Accuracy is defined as all correctly predicted instances over
    all instances. Mathematically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/b3b37e0b4a935a4677e9bf3835bd2ba3.png)'
  prefs: []
  type: TYPE_IMG
- en: It is not a robust metric to go by especially when the data has a class imbalance.
    Class Imbalance is when one class dominates the other.
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision**: Precision measures the fraction of positive predictions matching
    the actuals. Mathematically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/aaad482096ac9eb4de9c34e78b702132.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Recall**: Recall measures the fraction of positive instances correctly identified.
    Mathematically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/517cac0b5a0e20b37dfbaff317840789.png)'
  prefs: []
  type: TYPE_IMG
- en: '**F1 or F-beta**: While Precision tries to minimize FPs and Recall tries to
    minimize FNs, the F-1 metric maintains a balance between precision and recall
    and is defined as a harmonic mean between the two.'
  prefs: []
  type: TYPE_NORMAL
- en: 'F-beta is a weighted harmonic mean of precision and recall. Mathematically
    it’s defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/d23cb064c20d67e74989481cc3966cfe.png)'
  prefs: []
  type: TYPE_IMG
- en: Where a β value less than 1 would lower the impact of Precision and vice-versa.
    At β=1, F-beta becomes F1.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the metrics of a classification problem are under our belt. Let’s pick
    a dataset, train a model and evaluate its performance using a confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Scikit-learn Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will consider the [heart-disease dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)
    from Kaggle for building a model to predict whether the patient is prone to heart
    disease or not. So, it is a case of binary classification where ‘heart disease’
    is class 1 and ‘no heart disease’ is class 0.
  prefs: []
  type: TYPE_NORMAL
- en: Import Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Read Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Split train and test dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Train Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Evaluate predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Visualizing Your Confusion Matrix in Scikit-learn](../Images/a8ffabe58e9b0e4c2cae94f72cd30675.png)'
  prefs: []
  type: TYPE_IMG
- en: Interpreting Confusion Matrix and Computing Derived Metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'From the above confusion matrix let’s get the four numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True Positives**: 149 (when both Predicted and True labels are 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**True Negatives**: 156 (when both Predicted and True labels are 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Positives**: 0 (when both Predicted and True labels are 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False Negatives**: 3 (when both Predicted and True labels are 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Derived Metrics are computed using the mathematical expressions explained in
    the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: (156+149)/(156+149+0+3) = 99.03%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Precision**: 149/(149+0) = 100%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall**: 149/(149+3) = 98.03%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1**: 2*149/(2*149+0+3) = 99%'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this post we understood the usage and importance of confusion matrix in a
    classification algorithm. We then learned the four measures of a confusion matrix
    and how can we compute the derived metrics along with their advantages and disadvantages.
    Further, the article illustrates how to display a confusion matrix with the help
    of an example of a binary classification problem. Hopefully, the post has helped
    you build an understanding of what are the various metrics to evaluate the model
    performance and which one to use when.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Vidhi Chugh](https://vidhi-chugh.medium.com/)** is an award-winning AI/ML
    innovation leader and an AI Ethicist. She works at the intersection of data science,
    product, and research to deliver business value and insights. She is an advocate
    for data-centric science and a leading expert in data governance with a vision
    to build trustworthy AI solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Idiot''s Guide to Precision, Recall, and Confusion Matrix](https://www.kdnuggets.com/2020/01/guide-precision-recall-confusion-matrix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Confusion Matrix, Precision, and Recall Explained](https://www.kdnuggets.com/2022/11/confusion-matrix-precision-recall-explained.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Visualizing Data: A Statology Primer](https://www.kdnuggets.com/visualizing-data-statology-primer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sparse Matrix Representation in Python](https://www.kdnuggets.com/2020/05/sparse-matrix-representation-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convert Text Documents to a TF-IDF Matrix with tfidfvectorizer](https://www.kdnuggets.com/2022/09/convert-text-documents-tfidf-matrix-tfidfvectorizer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
