- en: How to Select Support Vector Machine Kernels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/06/select-support-vector-machine-kernels.html](https://www.kdnuggets.com/2016/06/select-support-vector-machine-kernels.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given an arbitrary dataset, you typically don't know which kernel may work best.
    I recommend starting with the simplest hypothesis space first -- given that you
    don't know much about your data -- and work your way up towards the more complex
    hypothesis spaces. So, the linear kernel works fine if your dataset if linearly
    separable; however, if your dataset isn't linearly separable, a linear kernel
    isn't going to cut it (almost in a literal sense ;)).
  prefs: []
  type: TYPE_NORMAL
- en: 'For simplicity (and visualization purposes), let''s assume our dataset consists
    of 2 dimensions only. Below, I plotted the decision regions of a linear SVM on
    2 features of the iris dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Selecting SVM Kernels](../Images/de1b68ee23dbaeb7c0c14a146503b9ac.png)](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels/1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This works perfectly fine. And here comes the RBF kernel SVM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Selecting SVM Kernels](../Images/280238071d4d7b2a7fc0f4dc03f07fc5.png)](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels/2.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Now, it looks like both linear and RBF kernel SVM would work equally well on
    this dataset. So, why prefer the simpler, linear hypothesis? Think of Occam's
    Razor in this particular case. Linear SVM is a parametric model, an RBF kernel
    SVM isn't, and the complexity of the latter grows with the size of the training
    set. Not only is it more expensive to train an RBF kernel SVM, but you also have
    to keep the kernel matrix around, and the projection into this "infinite" higher
    dimensional space where the data becomes linearly separable is more expensive
    as well during prediction. Furthermore, you have more hyperparameters to tune,
    so model selection is more expensive as well! And finally, it's much easier to
    overfit a complex model!
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, what I''ve said above sounds all very negative regarding kernel methods,
    but it really depends on the dataset. E.g., if your data is not linearly separable,
    it doesn''t make sense to use a linear classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Selecting SVM Kernels](../Images/608cb886ec38dfe4372fc3f8fbcd5f8c.png)](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels/3.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, a RBF kernel would make so much more sense:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Selecting SVM Kernels](../Images/92340a2e611d807e5f8813582e2ad5a4.png)](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels/4.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, I wouldn''t bother too much about the polynomial kernel. In practice,
    it is less useful for efficiency (computational as well as predictive) performance
    reasons. So, the rule of thumb is: use linear SVMs (or logistic regression) for
    linear problems, and nonlinear kernels such as the Radial Basis Function kernel
    for non-linear problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The RBF kernel SVM decision region is actually also a linear decision region.
    What RBF kernel SVM actually does is to create non-linear combinations of your
    features to uplift your samples onto a higher-dimensional feature space where
    you can use a linear decision boundary to separate your classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Selecting SVM Kernels](../Images/472009ef232672ddbd1aad7f899eb0d9.png)](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels/5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, above, I walked you through an intuitive example where we can visualize
    our data in 2 dimensions ... but what do we do in a real-world problem, i.e.,
    a dataset with more than 2 dimensions? Here, we want to keep an eye on our objective
    function: minimizing the hinge-loss. We would setup a hyperparameter search (grid
    search, for example) and compare different kernels to each other. Based on the
    loss function (or a performance metric such as accuracy, F1, MCC, ROC auc, etc.)
    we could determine which kernel is "appropriate" for the given task.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Sebastian Raschka](https://twitter.com/rasbt)** is a ''Data Scientist''
    and Machine Learning enthusiast with a big passion for Python & open source. Author
    of ''[Python Machine Learning](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning)''.
    Michigan State University.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/select_svm_kernels.md).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[When Does Deep Learning Work Better Than SVMs or Random Forests?](/2016/04/deep-learning-vs-svm-random-forest.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Development of Classification as a Learning Machine](/2016/04/development-classification-learning-machine.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Implement Machine Learning Algorithms From Scratch?](/2016/05/implement-machine-learning-algorithms-scratch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Correctly Select a Sample From a Huge Dataset in Machine Learning](https://www.kdnuggets.com/2019/05/sample-huge-dataset-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Select Rows and Columns in Pandas Using [ ], .loc, iloc, .at…](https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
