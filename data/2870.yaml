- en: Intro to Adversarial Machine Learning and Generative Adversarial Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗性机器学习与生成对抗网络简介
- en: 原文：[https://www.kdnuggets.com/2019/10/adversarial-machine-learning-generative-adversarial-networks.html](https://www.kdnuggets.com/2019/10/adversarial-machine-learning-generative-adversarial-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/adversarial-machine-learning-generative-adversarial-networks.html](https://www.kdnuggets.com/2019/10/adversarial-machine-learning-generative-adversarial-networks.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Andrew Martin](https://www.linkedin.com/in/andrewbmart/), Head of Data
    at Looka (formerly Logojoy)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Andrew Martin](https://www.linkedin.com/in/andrewbmart/)，Looka（前身为Logojoy）的数据主管**。'
- en: Machine learning is an ever-evolving field, so it can be easy to feel like you're
    out of the loop on the latest developments changing the world this week. One of
    those emerging areas that have been getting a lot of buzz lately is GANs—or generative
    adversarial networks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个不断发展的领域，因此很容易觉得自己跟不上这个周世界变化的最新动态。最近获得大量关注的新兴领域之一是GANs——即生成对抗网络。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'So to keep you in the machine learning loop, we’ve put together a short crash
    course on GANs:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你保持在机器学习的循环中，我们准备了一个简短的GANs速成课程：
- en: Where they fit into the pantheon of generative models
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们在生成模型的神圣殿堂中的位置
- en: How they’ve changed over time
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们如何随着时间的变化而变化
- en: Where they’re being applied
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的应用场景
- en: Challenges that come with GANs
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs面临的挑战
- en: What the future has in store for this emerging area of machine learning
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个新兴的机器学习领域的未来发展
- en: Let’s get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Generative Models
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成模型
- en: With generative models, the aim is to model the distribution of a given dataset.
    For the generative models that we’re talking about today, that dataset is usually
    a set of images, but it could also be other kinds of data, like audio samples
    or time-series data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生成模型，目标是建模给定数据集的分布。对于我们今天讨论的生成模型，这个数据集通常是一组图像，但也可以是其他类型的数据，如音频样本或时间序列数据。
- en: 'There are two ways to go about getting a model of this distribution: implicitly
    or explicitly.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 获得这种分布模型有两种方法：隐式或显式。
- en: So what’s the difference between the two?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这两者之间有什么区别呢？
- en: Well, with an explicit generative model, you have the probability density at
    your disposal. We can model all the variables from that distribution directly.
    Whereas with an implicit generative model you have to sample in order to get a
    sense of our model distribution.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，显式生成模型使你可以使用概率密度。我们可以直接对该分布中的所有变量进行建模。而对于隐式生成模型，你必须进行采样才能了解我们的模型分布。
- en: When we’re evaluating generative models, one way to do that (which happens to
    look very good in papers) is using images. So we can sample from our model distribution
    and then visually inspect the samples to see how well they match up with our original
    data. The closer our sample images are to our training images, the better our
    model is.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们评估生成模型时，一种方法（在论文中看起来很不错）是使用图像。因此我们可以从我们的模型分布中进行采样，然后视觉检查样本，以查看它们与原始数据的匹配程度。我们的样本图像与训练图像越接近，我们的模型就越好。
- en: Types of Generative Models
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成模型的类型
- en: 'In the context of deep learning, when we talk about generative models, we’re
    usually talking about one of four kinds of models:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习的背景下，当我们谈论生成模型时，我们通常指的是四种模型中的一种：
- en: Autoregressive
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自回归
- en: Reversible
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可逆
- en: Variational Autoencoders
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 变分自编码器
- en: Generative Adversarial Networks
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '**Autoregressive models:** With autoregressive models, you generate an image
    by generating each pixel conditioned on the previous pixels that you’ve generated.
    That is to say, when you generate an image using an autoregressive model, you
    generate it pixel by pixel. Here’s an example of an [autoregressive model](https://arxiv.org/pdf/1812.01608.pdf).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**自回归模型：** 使用自回归模型，你通过生成每个像素，依据你已经生成的前一个像素来生成图像。也就是说，当你使用自回归模型生成图像时，你是逐像素生成图像的。这是一个[自回归模型](https://arxiv.org/pdf/1812.01608.pdf)的例子。'
- en: '**Reversible models:** The concept of a reversible model is to take a GAN,
    but make the generator process reversible. This means we can pass images and noise
    both ways through a reversible model—going from noise to image and image to noise.
    This is an example of a [reversible model](https://arxiv.org/pdf/1807.03039.pdf).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**可逆模型：** 可逆模型的概念是将GAN的生成器过程变为可逆的。这意味着我们可以通过可逆模型双向传递图像和噪声——从噪声到图像，再从图像到噪声。这是一个[可逆模型](https://arxiv.org/pdf/1807.03039.pdf)的例子。'
- en: '**Variational Autoencoders**:  Autoencoders consist of a pair of connected
    networks: the encoder and the decoder. Variational autoencoders are distinguished
    by having a continuous latent space. This allows for easy sampling and interpolation,
    which is particularly useful when VAEs are used to explore variations on pre-existing
    data in a specified direction. Here’s a look at a [variational autoencoder](https://arxiv.org/pdf/1906.00446.pdf).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分自编码器：** 自编码器由一对连接的网络组成：编码器和解码器。变分自编码器的特点是具有连续的潜在空间。这允许轻松的采样和插值，这在变分自编码器用于探索在指定方向上对现有数据的变化时特别有用。这是一个[变分自编码器](https://arxiv.org/pdf/1906.00446.pdf)的例子。'
- en: Generative Adversarial Networks
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: Now, after traversing through other generative models, we get to GANs—or generative
    adversarial networks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在经历了其他生成模型之后，我们来到了GAN——生成对抗网络。
- en: '![](../Images/26fdce201e9ccd7301fb456f900e7f77.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26fdce201e9ccd7301fb456f900e7f77.png)'
- en: (image from [Brock 2018](https://arxiv.org/pdf/1809.11096.pdf))
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: （图像来自[Brock 2018](https://arxiv.org/pdf/1809.11096.pdf)）
- en: To begin, let’s examine some images that have been generated from GANs, to get
    an idea of how much progress has been made in the last five years. These images
    above are unconditionally generated ImageNet samples taken from a model called
    BigGAN which was presented by Andrew Brock at ICLR (International Conference on
    Learning Representation) in 2019.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们查看一些由GAN生成的图像，以了解过去五年取得了多大进展。上述图像是无条件生成的ImageNet样本，来自2019年Andrew Brock在ICLR（国际学习表征会议）上展示的BigGAN模型。
- en: 'These image samples are remarkable for two main reasons: the level of clarity
    and the diversity of classes. You have an animal, a mushroom, food, a landscape—all
    generated together, all with clear resolution.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像样本的显著之处在于两个主要原因：清晰度和类别的多样性。你有动物、蘑菇、食物、风景——所有这些都一起生成，所有图像都有清晰的分辨率。
- en: But it wasn't always like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但情况并非一直如此。
- en: '![](../Images/da76a4baf5f130aa2df1f47a20837515.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da76a4baf5f130aa2df1f47a20837515.png)'
- en: (image examples from [Goodfellow et al 2014](https://arxiv.org/pdf/1406.2661.pdf))
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: （图像示例来自[Goodfellow et al 2014](https://arxiv.org/pdf/1406.2661.pdf)）
- en: This is an image from the original GAN paper, by Ian Goodfellow et al. in 2014\.
    When this paper came out, this was state of the art image generation. But compared
    to the samples coming out of BigGAN, they’re worlds apart. Just glancing at these
    samples generated from the Toronto face data set, you can see the images are very
    low resolution, with features that aren’t fully resolved.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是2014年Ian Goodfellow等人发表的原始GAN论文中的图像。当这篇论文发布时，这是当时最先进的图像生成技术。但与BigGAN生成的样本相比，它们相距甚远。仅从这些来自Toronto面部数据集的样本中，你可以看到这些图像的分辨率非常低，特征没有完全解析。
- en: '![](../Images/a808933bcdeca5851be72ac52f489fdc.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a808933bcdeca5851be72ac52f489fdc.png)'
- en: (image examples from [Karras et al. 2019](https://arxiv.org/pdf/1812.04948.pdf))
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: （图像示例来自[Karras et al. 2019](https://arxiv.org/pdf/1812.04948.pdf)）
- en: Now fast forward four years to the StyleGAN paper out of Nvidia, and these generated
    humans look like they could be real. From fuzzy beginnings in 2014, faces generated
    by GANs have become almost indistinguishable from real people in just 4 years.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在快进四年到Nvidia的StyleGAN论文，这些生成的人物看起来非常逼真。从2014年的模糊起点开始，GAN生成的面孔在短短4年内几乎无法与真实人物区分。
- en: '**Overview of GANs**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**GAN概述**'
- en: Like the other models we discussed, GANs are a form of a generative model. However,
    unlike the other models we discussed, GAN’s are an implicit generative model.
    To refresh, this means that if we want to see how good of a model we have of the
    distribution we have to sample it.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 和我们讨论的其他模型一样，GANs 是一种生成模型。然而，与我们讨论的其他模型不同，GAN 是一种隐式生成模型。为了刷新记忆，这意味着如果我们想查看模型对分布的好坏，我们必须对其进行采样。
- en: So how do GANs work?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，GANs 是如何工作的呢？
- en: 'With a GAN we have two networks: a generator (the generative component) and
    a discriminator (the adversarial component).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GAN 中，我们有两个网络：生成器（生成组件）和判别器（对抗组件）。
- en: The discriminator is trained to identify generated examples and distinguish
    them from real examples. We train discriminators by taking a set of real examples
    and a set of generated examples and having the discriminator attempt to classify
    which examples are real. Through training we want the discriminator to be able
    to identify whether a sample comes from the real distribution or the generated
    distribution.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的训练目标是识别生成的样本并将其与真实样本区分开来。我们通过将一组真实样本和一组生成样本输入判别器，来训练判别器，以尝试分类哪些样本是真实的。通过训练，我们希望判别器能够识别样本是否来自真实分布还是生成分布。
- en: The counterpart to the discriminator is the generator, which takes random noise
    and learns to transform that random noise into realistic-looking samples—realistic
    enough to eventually fool the discriminator.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的对手是生成器，它接收随机噪声并学习将这些随机噪声转化为看起来逼真的样本——足够逼真以最终欺骗判别器。
- en: This happens over time, as the generator gets better and better at producing
    samples that look like the real examples, and the discriminator gets to a point
    where it's making random guesses as to whether a sample was real or generated.
    We can think of this as a two-player minimax game, and this point where the discriminator
    is making random guesses is its Nash equilibrium.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这会随着时间的推移发生，因为生成器在生成看起来像真实样本的样本方面变得越来越好，而判别器则会达到一个点，在这个点上它对样本是现实还是生成的做出随机猜测。我们可以将其视为一个双人博弈，这个判别器进行随机猜测的点是其纳什均衡。
- en: '**Training the GAN Generator**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练 GAN 生成器**'
- en: Going into the training a bit more, how exactly does the generator learn to
    transform random noise into images that can get past the discriminator?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探讨训练，生成器是如何学习将随机噪声转化为能够通过判别器的图像的？
- en: The generator takes samples—typically from a Gaussian— and transforms it through
    a neural network to create a sample. Again, the goal is to make this sample look
    as real as possible.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器从样本中获取数据——通常来自高斯分布——并通过神经网络进行变换以创建样本。同样，目标是使这个样本看起来尽可能真实。
- en: Initially, those transformations really are totally meaningless. So you pass
    the random noise through the generator, and what you get on the other side looks
    a lot like random noise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，这些变换确实是完全无意义的。所以你将随机噪声传递给生成器，你得到的另一端看起来很像随机噪声。
- en: '![](../Images/7c36a081dc365fa11bcefb9430f1e553.png)![](../Images/4c0b3d316e493ad5d5d0a9475187d301.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c36a081dc365fa11bcefb9430f1e553.png)![](../Images/4c0b3d316e493ad5d5d0a9475187d301.png)'
- en: (illustration of noise to image transformation process. Noise from Adobe Stock,
    face from [Karras et al. 2018](https://arxiv.org/pdf/1710.10196.pdf))
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: （噪声到图像变换过程的插图。噪声来自 Adobe Stock，面孔来自 [Karras et al. 2018](https://arxiv.org/pdf/1710.10196.pdf)）
- en: Now, when you generate an image of grayscale dots, and you pass it to the discriminator,
    most of the time the discriminator is going to say this doesn't look like a real
    example. Using backpropagation, you get a signal sent through the generator that
    tells the layers in the generator to update their weights based on the poor performance
    of the sample it just sent to the discriminator.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当你生成一个灰度点的图像，并将其传递给判别器时，大多数情况下，判别器会说这看起来不像真实样本。通过反向传播，你会得到一个信号传递到生成器，指示生成器中的层根据刚刚发送给判别器的样本的糟糕表现更新其权重。
- en: After these adjustments, more random noise passes through the generator to create
    a new image to send to the discriminator. This time, the discriminator might be
    fooled by our sample, because—and this is mostly due to randomness early in the
    training—the image had some features in it that resembled the real dataset. The
    generator then gets a signal that says that the last sample performed well, and
    again it updates its weights accordingly.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些调整之后，更多的随机噪声通过生成器生成新的图像，发送给鉴别器。这次，鉴别器可能会被我们的样本欺骗，因为——这主要是由于训练早期的随机性——图像中有一些特征类似于真实数据集。生成器然后收到一个信号，表示最后的样本表现良好，随后会相应更新其权重。
- en: Through many, many iterations and with very large numbers of images the generator
    weights continue to update based on how well they do at tricking the discriminator.
    If training goes well, the generator can take random noise and turn that into
    a realistic-looking image.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过许多次迭代以及大量的图像，生成器的权重会根据它们在欺骗鉴别器方面的表现不断更新。如果训练顺利，生成器可以将随机噪声转化为现实感很强的图像。
- en: '**Both the generator and discriminator can train completely unsupervised using
    this process, and create great samples—due to the dynamics created by the loss
    functions.**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成器和鉴别器都可以完全无监督地使用这个过程进行训练，并生成优秀的样本——这要归功于损失函数所创造的动态。**'
- en: Loss Functions in GANs
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GANs 中的损失函数
- en: In GANs, both the generator and discriminator each have their own loss functions.
    While these two different loss functions allow for the unsupervised learning we
    see with GANs, they also create some challenges in training.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GANs 中，生成器和鉴别器各自拥有自己的损失函数。虽然这两个不同的损失函数允许我们看到 GANs 的无监督学习，但它们也在训练中带来了一些挑战。
- en: The discriminator’s cost is that it wants to correctly identify real samples
    as real, and it wants to correctly identify generated samples as generated (equation
    1).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器的成本在于它希望正确识别真实样本为真实，并希望正确识别生成的样本为生成（公式 1）。
- en: '![](../Images/60ab3d4045078f425e6f420a405c5f09.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60ab3d4045078f425e6f420a405c5f09.png)'
- en: (equation 1)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 1）
- en: You can see that on the left here, where the first term says to identify real
    samples as real, and the right term says to identify generated samples as generated.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到左边的第一个项表示识别真实样本为真实，右边的项表示识别生成的样本为生成。
- en: Now the cool thing here is that the generator cost is just the negative of that
    function (equation 2).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有趣的是，生成器的成本只是该函数的负值（公式 2）。
- en: '![](../Images/d63695d54e2a9407ef4498af65ea4c47.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d63695d54e2a9407ef4498af65ea4c47.png)'
- en: (equation 2)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 2）
- en: You'll see here we have a constant for where the equation is referring to the
    discriminator identifying real examples as real—because the generator is not directly
    concerned with that part of the process. But what people have found is if they
    use the loss function for the generator as it is in the top equation, the loss
    saturates. So what we do is we just change the formulation a bit (equation 3).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到，这里我们有一个常量，用于表示方程中鉴别器识别真实样本为真实的部分——因为生成器与这个过程的这一部分没有直接关系。但人们发现，如果使用顶部方程中的生成器损失函数，损失会饱和。所以我们所做的是稍微改变一下公式（公式
    3）。
- en: '![](../Images/636514eeefc972c114b82894efa79e1b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/636514eeefc972c114b82894efa79e1b.png)'
- en: (equation 3)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 3）
- en: With this version of the loss function, the generator gets very strong signals
    if it creates samples that the discriminator easily identifies as generated. By
    using this second equation, it isn't exactly a two-player minimax game formulation
    anymore, but the training performs as we hope it would—and the training is a lot
    more stable than it would otherwise be.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种版本的损失函数，生成器如果创建出鉴别器容易识别为生成的样本，就会收到很强的信号。通过使用这个第二方程，它不再完全是一个二人最小化博弈的公式，但训练效果如我们所希望的那样——并且训练比其他方法更稳定。
- en: Applications of GANs
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GANs 的应用
- en: Now that we’ve got a grasp of training GANs let’s dive into some of the applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了训练 GANs 的基本知识，让我们深入探讨一些应用。
- en: One of the earliest identified applications GANs comes from Goodfellow’s original
    paper, which shows interpolating between the numbers 1 & 5 of MNIST. This is a
    kind of representation learning because through training a generator and discriminator
    we can learn a latent representation of our original data set.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 最早被识别的应用之一来自 Goodfellow 的原始论文，其中展示了 MNIST 中数字 1 和 5 之间的插值。这是一种表示学习，因为通过训练生成器和鉴别器，我们可以学习到原始数据集的潜在表示。
- en: '![](../Images/97f60e0edde9f0d070be887394be2fb4.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97f60e0edde9f0d070be887394be2fb4.png)'
- en: (image from [Karras et al. 2019](https://arxiv.org/pdf/1812.04948.pdf))
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: （图像来自 [Karras et al. 2019](https://arxiv.org/pdf/1812.04948.pdf)）
- en: You can see the same kind of application in images from the StyleGAN paper (above),
    as well as many other GAN papers out there.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 StyleGAN 论文（上面）中的图像以及许多其他 GAN 论文中看到相同的应用。
- en: What we're seeing with this particular example is we're taking the style of
    source A and applying it to the structure of source B. On the top left we're getting
    glasses applied to different images or we're making the people on the left look
    like young children.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个特定示例中看到的是，我们将源 A 的风格应用到源 B 的结构上。在左上角，我们将眼镜应用到不同的图像上，或者让左侧的人看起来像年轻的孩子。
- en: '![](../Images/85ba0787f200f79cdd0234cf0b40d42b.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85ba0787f200f79cdd0234cf0b40d42b.png)'
- en: '![](../Images/dc487433cb81f5aa2e9218f6d59b3982.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc487433cb81f5aa2e9218f6d59b3982.png)'
- en: (image examples from [Zhu et al. 2017](https://arxiv.org/pdf/1703.10593.pdf)
    and [Isola et al. 2016](https://arxiv.org/pdf/1611.07004.pdf))
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: （图像示例来自 [Zhu et al. 2017](https://arxiv.org/pdf/1703.10593.pdf) 和 [Isola et
    al. 2016](https://arxiv.org/pdf/1611.07004.pdf)）
- en: Another application of GANs is image translation—which in some contexts is a
    more general approach to style transfer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 的另一个应用是图像转换——在某些情况下，这是一种更通用的风格迁移方法。
- en: On the left (Zhu), we see some image enhancement being done by the CycleGAN,
    and on the right, in the Pix2Pix paper (Isola), we are translating images from
    one style to another.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧（Zhu），我们看到 CycleGAN 对图像进行了一些增强，而在右侧的 Pix2Pix 论文（Isola）中，我们将图像从一种风格转换为另一种风格。
- en: So we have segmentation for the Street View on the left and real images on the
    right. Then for the aerial to map we have a satellite image and the sort of like
    map image
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所以左侧是街景的分割图，右侧是真实图像。然后从航空图到地图，我们有一张卫星图像和类似地图的图像。
- en: What happens when you train this kind of transfer with the Pix2Pix model is
    you can go satellite to map and map to satellite. So if you’re looking to do style
    transfer on sets of images, these are the models that work best.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当你用 Pix2Pix 模型训练这种类型的转换时，你可以从卫星图像转换到地图，反之亦然。因此，如果你希望在图像集合上进行风格迁移，这些模型效果最好。
- en: Challenges with GANs
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GAN 的挑战
- en: But all the progress with GANs hasn’t come without its challenges.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但 GAN 的所有进展并没有没有遇到挑战。
- en: In theory, GANs operate as this orderly two-player minimax game slowly reaching
    its Nash equilibrium. We pass noise through the generator, and the generator learns
    to trick the discriminator, then the discriminator stops being good at detecting
    the difference and starts randomly guessing, in theory.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，GAN 作为一个有序的双玩家最小化游戏，慢慢达到纳什均衡。我们将噪声传递给生成器，生成器学会欺骗判别器，然后判别器停止有效地检测差异，并开始随机猜测，理论上如此。
- en: 'There are three main challenges that get in the way of GANs operating as this
    minimax game:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个主要挑战阻碍 GAN 作为这种最小化游戏运行：
- en: Mode collapse
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式崩溃
- en: Finicky training
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挑剔的训练
- en: Evaluation of GANs
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN 的评估
- en: '**Mode Collapse**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**模式崩溃**'
- en: '![](../Images/03afcd99e6555db9b03209a2685316a8.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03afcd99e6555db9b03209a2685316a8.png)'
- en: (image of mode collapse from [Goodfellow 2016](https://arxiv.org/pdf/1701.00160.pdf))
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: （模式崩溃的图像来自 [Goodfellow 2016](https://arxiv.org/pdf/1701.00160.pdf)）
- en: With mode collapse, the model only learns one or a few of the modes of a multimodal
    dataset. The data we’re training GANs on typically has a very large number of
    modes, which makes mode collapse problematic.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在模式崩溃中，模型仅学习到多模态数据集中的一种或几种模式。我们训练 GAN 的数据通常具有非常多的模式，这使得模式崩溃成为一个问题。
- en: '**Finicky Training**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**挑剔的训练**'
- en: Then there's the issue of finicky training. Earlier, we mentioned the cost functions
    of the generator and discriminator. And because we have two different cost functions
    in this model, it creates more challenges in terms of balancing them than you
    might otherwise have.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后就是挑剔的训练问题。之前我们提到了生成器和判别器的成本函数。由于这个模型中有两个不同的成本函数，因此在平衡它们方面会比其他情况更具挑战性。
- en: '**Evaluating GANs**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估 GAN**'
- en: When evaluating GANs, several issues come into play.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 评估 GAN 时，有几个问题需要考虑。
- en: First, good samples from a generator don't necessarily mean you've learned the
    distribution well.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，生成器生成的好样本不一定意味着你已经很好地学习了分布。
- en: 'Next, it can be very hard to estimate the likelihood, which is a measure of
    how well you''ve learned the distribution. Which both lead to the third issue:
    it''s hard to really know how much of the distribution you actually learned.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，估计可能性（这是衡量你学习分布效果的指标）可能非常困难。这也导致了第三个问题：很难真正知道你学到了多少分布。
- en: Finally, evaluating GANs is an active area of research, with no universal method
    of evaluation. Many papers propose new evaluation metrics that don't receive any
    attention in future publications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，评估 GAN（生成对抗网络）是一个活跃的研究领域，目前尚无通用的评估方法。许多论文提出了新的评估指标，但这些指标在未来的出版物中并未受到关注。
- en: The Future of GANs
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GAN 的未来
- en: Where do GANs go from here?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 接下来会走向何方？
- en: We mostly covered GANs generating images in this overview, but that’s far from
    the only applications of GANs we’re seeing—today or tomorrow.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本概述中主要讨论了 GAN 生成图像，但这远非我们今天或明天看到的 GAN 应用的唯一方向。
- en: GANs are also making leaps in things like generating audio for voice impersonations,
    developing new pharmaceuticals, designing floor plans for buildings, generating
    components for structures, creating graphic design layouts, generating tabular
    data, and more.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 还在音频生成（如语音模仿）、新药研发、建筑平面设计、结构组件生成、图形设计布局、表格数据生成等方面取得了突破。
- en: As this class of machine learning models continues to grow and develop across
    different industries and applications, and people continue to get more comfortable
    with the concept of GANs, they’ll continue to find more areas to apply the learnings
    to. So from 2014 to today and beyond, GANs still have a long way to go before
    we’ve exhausted all the opportunities that come along with this elegant adversarial
    system.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这一类机器学习模型在不同产业和应用中不断发展壮大，且人们对 GAN 的概念越来越熟悉，他们将继续发现更多的应用领域。因此，从 2014 年到今天及未来，GAN
    仍有很长的路要走，才能充分挖掘这一优雅对抗系统所带来的所有机会。
- en: '**Bio:** [Andrew Martin](https://www.linkedin.com/in/andrewbmart/)is the Lead
    Data Scientist at Looka, an [AI-powered logo generator](https://looka.com/logo-maker/)
    that provides business owners with a quick and affordable way to create a beautiful
    brand. Andrew previously founded Eco Modelling, a consultancy delivering data
    solutions to clients in forestry and energy. He holds a MSc in Industrial Engineering
    from Dalhousie University and a BSc in Math from McGill University.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [安德鲁·马丁](https://www.linkedin.com/in/andrewbmart/)是 Looka 的首席数据科学家，Looka
    是一个[AI 驱动的 logo 生成器](https://looka.com/logo-maker/)，为企业主提供了快速且经济实惠的品牌创建方式。安德鲁曾创办
    Eco Modelling，这是一家向林业和能源领域的客户提供数据解决方案的咨询公司。他拥有达尔豪斯大学工业工程硕士学位和麦吉尔大学数学学士学位。'
- en: '**Related:**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Generative Adversarial Networks – Key Milestones and State of the Art](https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成对抗网络 – 关键里程碑与最前沿技术](https://www.kdnuggets.com/2019/04/future-generative-adversarial-networks.html)'
- en: '[The Rise of Generative Adversarial Networks](https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成对抗网络的崛起](https://www.kdnuggets.com/2019/04/rise-generative-adversarial-networks.html)'
- en: '[Why Machine Learning is vulnerable to adversarial attacks and how to fix it](https://www.kdnuggets.com/2019/06/machine-learning-adversarial-attacks.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么机器学习容易受到对抗攻击以及如何解决](https://www.kdnuggets.com/2019/06/machine-learning-adversarial-attacks.html)'
- en: More On This Topic
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[What is Adversarial Machine Learning?](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是对抗性机器学习？](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
- en: '[The Most Popular Intro to Programming Course From Harvard is Free!](https://www.kdnuggets.com/2022/03/popular-intro-programming-course-harvard-free.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[哈佛大学最受欢迎的编程入门课程免费！](https://www.kdnuggets.com/2022/03/popular-intro-programming-course-harvard-free.html)'
- en: '[KDnuggets News March 30: The Most Popular Intro to Programming…](https://www.kdnuggets.com/2022/n13.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 3 月 30 日：最受欢迎的编程入门课程…](https://www.kdnuggets.com/2022/n13.html)'
- en: '[25 Free Courses to Master Data Science, Data Engineering, Machine…](https://www.kdnuggets.com/25-free-courses-to-master-data-science-data-engineering-machine-learning-mlops-and-generative-ai)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25 门免费课程掌握数据科学、数据工程、机器学习…](https://www.kdnuggets.com/25-free-courses-to-master-data-science-data-engineering-machine-learning-mlops-and-generative-ai)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最先进的深度学习可解释预测和实时预测](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Neural Networks and Deep Learning: A Textbook (2nd Edition)](https://www.kdnuggets.com/2023/07/aggarwal-neural-networks-deep-learning-textbook-2nd-edition.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络与深度学习：教科书（第2版）](https://www.kdnuggets.com/2023/07/aggarwal-neural-networks-deep-learning-textbook-2nd-edition.html)'
