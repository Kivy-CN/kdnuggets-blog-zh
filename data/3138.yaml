- en: Top 20 Deep Learning Papers, 2018 Edition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2018年版前20篇深度学习论文
- en: 原文：[https://www.kdnuggets.com/2018/03/top-20-deep-learning-papers-2018.html](https://www.kdnuggets.com/2018/03/top-20-deep-learning-papers-2018.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/03/top-20-deep-learning-papers-2018.html](https://www.kdnuggets.com/2018/03/top-20-deep-learning-papers-2018.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![](../Images/8411d00b24f3d992603721a3c9ca28f4.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8411d00b24f3d992603721a3c9ca28f4.png)'
- en: Deep Learning, one of the subfields of Machine Learning and Statistical Learning
    has been advancing in impressive levels in the past years. Cloud computing, robust
    open source tools and vast amounts of available data have been some of the levers
    for these impressive breakthroughs. The criteria used to select the 20 top papers
    is by using citation counts from [**academic.microsoft.com**](http://academic.microsoft.com).
    It is important to mention that these metrics are changing rapidly so the citations
    valued must be considered as the numbers when this article was published.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，作为机器学习和统计学习的一个子领域，在过去几年取得了令人瞩目的进展。云计算、强大的开源工具以及大量可用的数据是这些突破的关键因素之一。选择前20篇论文的标准是使用来自[**academic.microsoft.com**](http://academic.microsoft.com)的引用次数。值得提及的是，这些指标变化迅速，因此引用量必须考虑为文章发布时的数字。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this list of papers more than 75% refer to deep learning and neural networks,
    specifically Convolutional Neural Networks (CNN). Almost 50% of them refer to
    pattern recognition applications in the field of computer vision. I believe tools
    like TensorFlow, Theano and advancements in the use of GPUs have paved the way
    for data scientists and machine learning engineers to extend the field.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这份论文列表中，超过75%的论文涉及深度学习和神经网络，特别是卷积神经网络（CNN）。其中近50%的论文涉及计算机视觉领域的模式识别应用。我相信像TensorFlow、Theano以及GPU使用方面的进展，为数据科学家和机器学习工程师拓展这一领域铺平了道路。
- en: '![](../Images/ec1330d2b2ce29bd60a365126cd2a82c.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec1330d2b2ce29bd60a365126cd2a82c.png)'
- en: '**1. [Deep Learning](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf),**
    by Yann L., Yoshua B. & Geoffrey H. (2015) (Cited: 5,716)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.** [深度学习](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)**，**
    作者：Yann L.、Yoshua B. 和 Geoffrey H.（2015年）（引用次数：5,716）'
- en: Deep learning allows computational models that are composed of multiple processing
    layers to learn representations of data with multiple levels of abstraction. These
    methods have dramatically improved the state-of-the-art in speech recognition,
    visual object recognition, object detection and many other domains such as drug
    discovery and genomics.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 深度学习允许由多个处理层组成的计算模型学习具有多个抽象层次的数据表示。这些方法显著提高了语音识别、视觉对象识别、对象检测以及药物发现和基因组学等多个领域的最先进水平。
- en: '**2. **[**TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed
    Systems**](http://download.tensorflow.org/paper/whitepaper2015.pdf)**,** by Martín
    A., Ashish A. B., Eugene B. C., et al. (2015) (Cited: 2,423)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.** [**TensorFlow: 大规模异构分布式系统上的机器学习**](http://download.tensorflow.org/paper/whitepaper2015.pdf)**，**
    作者：Martín A.、Ashish A. B.、Eugene B. C.等（2015年）（引用次数：2,423）'
- en: The system is flexible and can be used to express a wide variety of algorithms,
    including training and inference algorithms for deep neural network models, and
    it has been used for conducting research and for deploying machine learning systems
    into production across more than a dozen areas of computer science and other fields,
    including speech recognition, computer vision, robotics, information retrieval,
    natural language processing, geographic information extraction, and computational
    drug discovery.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该系统灵活且可以表达各种算法，包括深度神经网络模型的训练和推理算法，它已被用于研究和在计算机科学及其他领域（如语音识别、计算机视觉、机器人技术、信息检索、自然语言处理、地理信息提取和计算药物发现）中部署机器学习系统。
- en: '**3. [TensorFlow: a system for large-scale machine learning](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf
    rel=)****,** by Martín A., Paul B., Jianmin C., Zhifeng C., Andy D. et al. (2016)
    (Cited: 2,227)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. [TensorFlow: 大规模机器学习系统](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf
    rel=)**，作者：Martín A.、Paul B.、Jianmin C.、Zhifeng C.、Andy D. 等（2016年）（被引用：2,227）'
- en: TensorFlow supports a variety of applications, with a focus on training and
    inference on deep neural networks. Several Google services use TensorFlow in production,
    we have released it as an open-source project, and it has become widely used for
    machine learning research.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TensorFlow 支持各种应用，重点是深度神经网络的训练和推理。多个 Google 服务在生产中使用 TensorFlow，我们将其发布为开源项目，并且它已广泛用于机器学习研究。
- en: '**4. [Deep learning in neural networks](https://arxiv.org/pdf/1404.7828.pdf)**,
    by Juergen Schmidhuber (2015) (Cited: 2,196)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**4. [深度学习中的神经网络](https://arxiv.org/pdf/1404.7828.pdf)**，作者：Juergen Schmidhuber（2015年）（被引用：2,196）'
- en: This historical survey compactly summarises relevant work, much of it from the
    previous millennium. Shallow and deep learners are distinguished by the depth
    of their credit assignment paths, which are chains of possibly learnable, causal
    links between actions and effects. I review deep supervised learning (also recapitulating
    the history of backpropagation), unsupervised learning, reinforcement learning
    & evolutionary computation, and indirect search for short programs encoding deep
    and large networks.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本历史综述简要总结了相关工作，其中大部分来自上一个千年。浅层和深层学习者通过其信用分配路径的深度进行区分，这些路径是可能可学习的因果链。我们回顾了深度监督学习（也回顾了反向传播的历史）、无监督学习、强化学习与进化计算，以及对编码深度和大型网络的短程序的间接搜索。
- en: '**5. [Human-level control through deep reinforcement learning](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)**,
    by Volodymyr M., Koray K., David S., Andrei A. R., Joel V et al (2015) (Cited:
    2,086)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**5. [通过深度强化学习实现人类级控制](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)**，作者：Volodymyr
    M.、Koray K.、David S.、Andrei A. R.、Joel V 等（2015年）（被引用：2,086）'
- en: Here we use recent advances in training deep neural networks to develop a novel
    artificial agent, termed a deep Q-network, that can learn successful policies
    directly from high-dimensional sensory inputs using end-to-end reinforcement learning.
    We tested this agent on the challenging domain of classic Atari 2600 games.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这里，我们利用训练深度神经网络的最新进展，开发了一种新型人工智能代理，称为深度 Q 网络，该网络可以通过端到端强化学习直接从高维感官输入中学习成功的策略。我们在经典
    Atari 2600 游戏的挑战领域测试了该代理。
- en: '**6. [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal
    Networks](https://arxiv.org/pdf/1506.01497.pdf)****,** by Shaoqing R., Kaiming
    H., Ross B. G. & Jian S. (2015) (Cited: 1,421)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**6. [更快的 R-CNN: 朝着实时目标检测的区域提议网络](https://arxiv.org/pdf/1506.01497.pdf)**，作者：Shaoqing
    R.、Kaiming H.、Ross B. G. 和 Jian S.（2015年）（被引用：1,421）'
- en: In this work, we introduce a Region Proposal Network (RPN) that shares full-image
    convolutional features with the detection network, thus enabling nearly cost-free
    region proposals. An RPN is a fully convolutional network that simultaneously
    predicts object bounds and objectness scores at each position.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这项工作中，我们介绍了一种区域提议网络（RPN），它与检测网络共享全图像卷积特征，从而实现几乎零成本的区域提议。RPN 是一种全卷积网络，它同时在每个位置预测对象边界和对象性得分。
- en: '**7. [Long-term recurrent convolutional networks for visual recognition and
    description](https://arxiv.org/pdf/1411.4389.pdf)****,** by Jeff D., Lisa Anne
    H., Sergio G., Marcus R., Subhashini V. et al. (2015) (Cited: 1,285)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**7. [用于视觉识别和描述的长期递归卷积网络](https://arxiv.org/pdf/1411.4389.pdf)**，作者：Jeff D.、Lisa
    Anne H.、Sergio G.、Marcus R.、Subhashini V. 等（2015年）（被引用：1,285）'
- en: In contrast to current models which assume a fixed spatio-temporal receptive
    field or simple temporal averaging for sequential processing, recurrent convolutional
    models are “doubly deep” in that they can be compositional in spatial and temporal
    “layers”.
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与当前假设固定空间-时间感受野或简单时间平均的序列处理模型相比，递归卷积模型在空间和时间“层”上都可以是“加倍深度”的。
- en: '**8. [MatConvNet: Convolutional Neural Networks for MATLAB](https://arxiv.org/pdf/1412.4564.pdf),**
    byAndrea Vedaldi & Karel Lenc (2015) (Cited: 1,148)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**8. [MatConvNet：用于MATLAB的卷积神经网络](https://arxiv.org/pdf/1412.4564.pdf)**，作者
    Andrea Vedaldi 和 Karel Lenc（2015年）（引用次数：1,148）'
- en: It exposes the building blocks of CNNs as easy-to-use MATLAB functions, providing
    routines for computing linear convolutions with filter banks, feature pooling,
    and many more. This document provides an overview of CNNs and how they are implemented
    in MatConvNet and gives the technical details of each computational block in the
    toolbox.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它将CNN的构建模块暴露为易于使用的MATLAB函数，提供了计算线性卷积的滤波器组、特征池化等常用例程。本文档概述了CNN及其在MatConvNet中的实现，并提供了工具箱中每个计算块的技术细节。
- en: '**9. [Unsupervised Representation Learning with Deep Convolutional Generative
    Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)****,** by Alec R.,
    Luke M. & Soumith C. (2015) (Cited: 1,054)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**9. [使用深度卷积生成对抗网络的无监督表示学习](https://arxiv.org/pdf/1511.06434.pdf)**，作者 Alec
    R., Luke M. 和 Soumith C.（2015年）（引用次数：1,054）'
- en: In this work, we hope to help bridge the gap between the success of CNNs for
    supervised learning and unsupervised learning. We introduce a class of CNNs called
    deep convolutional generative adversarial networks (DCGANs), that have certain
    architectural constraints, and demonstrate that they are a strong candidate for
    unsupervised learning.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这项工作中，我们希望帮助弥合CNN在监督学习和无监督学习中的成功之间的差距。我们引入了一类称为深度卷积生成对抗网络（DCGANs）的CNN，这些网络具有某些架构约束，并证明它们是无监督学习的强有力候选者。
- en: '**10. [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)****,**
    by Olaf R., Philipp F. &Thomas B. (2015) (Cited: 975)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**10. [U-Net：用于生物医学图像分割的卷积网络](https://arxiv.org/pdf/1505.04597.pdf)**，作者 Olaf
    R., Philipp F. 和 Thomas B.（2015年）（引用次数：975）'
- en: There is large consent that successful training of deep networks requires many
    thousand annotated training samples. In this paper, we present a network and training
    strategy that relies on the strong use of data augmentation to use the available
    annotated samples more efficiently.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大多数人一致认为，成功训练深度网络需要成千上万的标注训练样本。本文提出了一种网络和训练策略，依赖于强大的数据增强，以更有效地利用现有的标注样本。
- en: '**11. [Conditional Random Fields as Recurrent Neural Networks](http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf)****,**
    by Shuai Z., Sadeep J., Bernardino R., Vibhav V. et al (2015) (Cited: 760)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**11. [条件随机场作为递归神经网络](http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf)**，作者
    Shuai Z., Sadeep J., Bernardino R., Vibhav V. 等（2015年）（引用次数：760）'
- en: We introduce a new form of convolutional neural network that combines the strengths
    of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based
    probabilistic graphical modelling. To this end, we formulate mean-field approximate
    inference for the Conditional Random Fields with Gaussian pairwise potentials
    as Recurrent Neural Networks.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们引入了一种新的卷积神经网络形式，结合了卷积神经网络（CNNs）和基于条件随机场（CRFs）的概率图模型的优点。为此，我们将具有高斯对偶势的条件随机场的均值场近似推断形式化为递归神经网络。
- en: '**12. [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/pdf/1501.00092.pdf)****,**
    by Chao D., Chen C., Kaiming H. & Xiaoou T. (2014) (Cited: 591)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**12. [使用深度卷积网络的图像超分辨率](https://arxiv.org/pdf/1501.00092.pdf)**，作者 Chao D.,
    Chen C., Kaiming H. 和 Xiaoou T.（2014年）（引用次数：591）'
- en: Our method directly learns an end-to-end mapping between the low/high-resolution
    images. The mapping is represented as a deep convolutional neural network (CNN)
    that takes the low-resolution image as the input and outputs the high-resolution
    one
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们的方法直接学习低分辨率图像与高分辨率图像之间的端到端映射。该映射表示为一个深度卷积神经网络（CNN），它以低分辨率图像为输入，输出高分辨率图像。
- en: '**13. [Beyond short snippets: Deep networks for video classification](https://arxiv.org/pdf/1503.08909.pdf)****,**
    by Joe Y. Ng, Matthew J. H., Sudheendra V., Oriol V., Rajat M. & George T. (2015)
    (Cited: 533)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**13. [超越短片段：用于视频分类的深度网络](https://arxiv.org/pdf/1503.08909.pdf)**，作者 Joe Y.
    Ng, Matthew J. H., Sudheendra V., Oriol V., Rajat M. 和 George T.（2015年）（引用次数：533）'
- en: In this work, we propose and evaluate several deep neural network architectures
    to combine image information across a video over longer time periods than previously
    attempted.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这项工作中，我们提出并评估了几种深度神经网络架构，以在比以往尝试的更长时间段内结合视频中的图像信息。
- en: '**14. [Inception-v4, Inception-ResNet and the Impact of Residual Connections
    on Learning](https://arxiv.org/pdf/1602.07261.pdf)****,** by Christian S., Sergey
    I., Vincent V. & Alexander A A. (2017) (Cited: 520)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**14. [Inception-v4、Inception-ResNet 及残差连接对学习的影响](https://arxiv.org/pdf/1602.07261.pdf)**，作者
    Christian S.、Sergey I.、Vincent V. 和 Alexander A A.（2017）（引用次数：520）'
- en: Very deep convolutional networks have been central to the largest advances in
    image recognition performance in recent years. With an ensemble of three residual
    and one Inception-v4, we achieve 3.08% top-5 error on the test set of the ImageNet
    classification (CLS) challenge.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 非常深的卷积网络在近年来图像识别性能的最大进展中发挥了核心作用。通过一个包含三个残差网络和一个 Inception-v4 的集合，我们在 ImageNet
    分类（CLS）挑战的测试集上实现了 3.08% 的 top-5 错误率。
- en: '**15. [Salient Object Detection: A Discriminative Regional Feature Integration
    Approach](https://arxiv.org/pdf/1410.5926.pdf)****,** by Huaizu J., Jingdong W.,
    Zejian Y., Yang W., Nanning Z. & Shipeng Li. (2013) (Cited: 518)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**15. [显著性对象检测：一种判别性区域特征融合方法](https://arxiv.org/pdf/1410.5926.pdf)**，作者 Huaizu
    J.、Jingdong W.、Zejian Y.、Yang W.、Nanning Z. 和 Shipeng Li.（2013）（引用次数：518）'
- en: In this paper, we formulate saliency map computation as a regression problem.
    Our method, which is based on multi-level image segmentation, utilizes the supervised
    learning approach to map the regional feature vector to a saliency score.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在本文中，我们将显著性图计算公式化为回归问题。我们的方法基于多级图像分割，利用监督学习方法将区域特征向量映射到显著性分数。
- en: '**16. [Visual Madlibs: Fill in the Blank Description Generation and Question
    Answering](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yu_Visual_Madlibs_Fill_ICCV_2015_paper.pdf)**,
    by Licheng Y., Eunbyung P., Alexander C. B. & Tamara L. B. (2015) (Cited: 510)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**16. [视觉 Madlibs: 填空描述生成和问答](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yu_Visual_Madlibs_Fill_ICCV_2015_paper.pdf)**，作者
    Licheng Y.、Eunbyung P.、Alexander C. B. 和 Tamara L. B.（2015）（引用次数：510）'
- en: 'In this paper, we introduce a new dataset consisting of 360,001 focused natural
    language descriptions for 10,738 images. This dataset, the Visual Madlibs dataset,
    is collected using automatically produced fill-in-the-blank templates designed
    to gather targeted descriptions about: people and objects, their appearances,
    activities, and interactions, as well as inferences about the general scene or
    its broader context.'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一个新的数据集，其中包含 360,001 个针对 10,738 张图像的集中自然语言描述。该数据集，Visual Madlibs 数据集，是通过自动生成的填空模板收集的，旨在收集关于：人物和物体、它们的外观、活动和互动，以及对一般场景或其更广泛背景的推断的目标描述。
- en: '**17. [Asynchronous methods for deep reinforcement learning](http://proceedings.mlr.press/v48/mniha16.pdf)****,**
    by Volodymyr M., Adrià P. B., Mehdi M., Alex G., Tim H. et al. (2016) (Cited:
    472)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**17. [深度强化学习的异步方法](http://proceedings.mlr.press/v48/mniha16.pdf)**，作者 Volodymyr
    M.、Adrià P. B.、Mehdi M.、Alex G.、Tim H. 等（2016）（引用次数：472）'
- en: The best performing method, an asynchronous variant of actor-critic, surpasses
    the current state-of-the-art on the Atari domain while training for half the time
    on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous
    actor-critic succeeds on a wide variety of continuous motor control problems as
    well as on a new task of navigating random 3D mazes using a visual input.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 性能最佳的方法是异步变体的演员-评论家方法，它在 Atari 领域超越了当前的最先进水平，同时在单个多核 CPU 上训练的时间仅为 GPU 的一半。此外，我们还展示了异步演员-评论家在各种连续运动控制问题以及在使用视觉输入的随机
    3D 迷宫导航新任务中的成功。
- en: '**18. [Theano: A Python framework for fast computation of mathematical expressions](https://arxiv.org/pdf/1605.02688.pdf).**,
    by by Rami A., Guillaume A., Amjad A., Christof A. et al (2016) (Cited: 451)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**18. [Theano: 一个用于快速计算数学表达式的 Python 框架](https://arxiv.org/pdf/1605.02688.pdf)**，作者
    Rami A.、Guillaume A.、Amjad A.、Christof A. 等（2016）（引用次数：451）'
- en: Theano is a Python library that allows to define, optimize, and evaluate mathematical
    expressions involving multi-dimensional arrays efficiently. Since its introduction,
    it has been one of the most used CPU and GPU mathematical compilers especially
    in the machine learning community and has shown steady performance improvements.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Theano 是一个 Python 库，允许高效地定义、优化和评估涉及多维数组的数学表达式。自推出以来，它已成为最常用的 CPU 和 GPU 数学编译器之一，特别是在机器学习社区中，并且显示出稳定的性能提升。
- en: '**19. [Deep Learning Face Attributes in the Wild](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Deep_Learning_Face_ICCV_2015_paper.pdf)****,**
    by Ziwei L., Ping L., Xiaogang W. & Xiaoou T. (2015) (Cited: 401)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**19. [深度学习在野外的面部属性](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Liu_Deep_Learning_Face_ICCV_2015_paper.pdf)**，由
    Ziwei L.、Ping L.、Xiaogang W. 和 Xiaoou T. (2015)（引用次数：401）'
- en: This framework not only outperforms the state-of-the-art with a large margin,
    but also reveals valuable facts on learning face representation. (1) It shows
    how the performances of face localization (LNet) and attribute prediction (ANet)
    can be improved by different pre-training strategies. (2) It reveals that although
    the filters of LNet are fine-tuned only with imagelevel attribute tags, their
    response maps over entire images have strong indication of face locations.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该框架不仅大幅超越了最先进的技术，而且揭示了有关学习面部表示的有价值的事实。（1）它展示了如何通过不同的预训练策略改善面部定位（LNet）和属性预测（ANet）的性能。（2）它揭示了尽管
    LNet 的滤波器仅通过图像级属性标签进行微调，但它们在整个图像上的响应图具有强烈的面部位置指示。
- en: '**20\.** [**Character-level convolutional networks for text classification**](http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf)**,**
    by Xiang Z., Junbo Jake Z. & Yann L. (2015) (Cited: 401)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**20.** [**用于文本分类的字符级卷积网络**](http://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf)**，**由
    Xiang Z.、Junbo Jake Z. 和 Yann L. (2015)（引用次数：401）'
- en: This article offers an empirical exploration on the use of character-level convolutional
    networks (ConvNets) for text classification. We constructed several largescale
    datasets to show that character-level convolutional networks could achieve state-of-the-art
    or competitive results.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这篇文章提供了对字符级卷积网络（ConvNets）在文本分类中应用的实证探索。我们构建了几个大规模数据集，展示了字符级卷积网络能够实现最先进或具有竞争力的结果。
- en: '**Related:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[7 Steps to Understanding Deep Learning](https://www.kdnuggets.com/2016/01/seven-steps-deep-learning.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解深度学习的 7 个步骤](https://www.kdnuggets.com/2016/01/seven-steps-deep-learning.html)'
- en: '[Deep Learning – Past, Present, and Future](https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习——过去、现在和未来](https://www.kdnuggets.com/2017/05/deep-learning-big-deal.html)'
- en: '[The 10 Deep Learning Methods AI Practitioners Need to Apply](https://www.kdnuggets.com/2017/12/10-deep-learning-methods-ai-practitioners-need-apply.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 从业者需要应用的 10 种深度学习方法](https://www.kdnuggets.com/2017/12/10-deep-learning-methods-ai-practitioners-need-apply.html)'
- en: More On This Topic
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应掌握的 6 种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021 年最佳 ETL 工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标以……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
