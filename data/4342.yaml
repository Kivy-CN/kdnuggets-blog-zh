- en: 10 Underappreciated Python Packages for Machine Learning Practitioners
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10个被低估的机器学习Python包
- en: 原文：[https://www.kdnuggets.com/2021/01/10-underappreciated-python-packages-machine-learning-practitioners.html](https://www.kdnuggets.com/2021/01/10-underappreciated-python-packages-machine-learning-practitioners.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/10-underappreciated-python-packages-machine-learning-practitioners.html](https://www.kdnuggets.com/2021/01/10-underappreciated-python-packages-machine-learning-practitioners.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[comments](#comments)'
- en: '**By [Vinay Uday Prabhu](https://vinayprabhu.github.io/), Chief Scientist at
    UnifyID Inc.**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Vinay Uday Prabhu](https://vinayprabhu.github.io/)，UnifyID Inc.首席科学家**'
- en: '![Figure](../Images/581c9aff740dcd71f1784a23ed38d159.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/581c9aff740dcd71f1784a23ed38d159.png)'
- en: Collage of all the PyPi packages listed here
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出的所有PyPi包的汇编
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'TL-DR: Resources curated:'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'TL-DR: 精心策划的资源：'
- en: ????????:[Github Repo](https://github.com/vinayprabhu/Favorite_PyPi_2020) with
    all the images, code and figures
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '????????: [Github Repo](https://github.com/vinayprabhu/Favorite_PyPi_2020)
    其中包含所有图像、代码和图表'
- en: ???????? : [Collage in pdf form with clickable links](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/PyPi_2020_collage.pdf)
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '???????? : [带有可点击链接的PDF汇编](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/PyPi_2020_collage.pdf)'
- en: ????????: [Colab notebook](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Colab_Pypi_Top10.ipynb)
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '????????: [Colab笔记本](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Colab_Pypi_Top10.ipynb)'
- en: ????????:[ HTML Document](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Top_Pypi_2020.html)
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '????????: [HTML文档](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Top_Pypi_2020.html)'
- en: ????????:[Notebook in PDF format](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Top_Pypi_2020.pdf)
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '????????: [PDF格式的笔记本](https://github.com/vinayprabhu/Favorite_PyPi_2020/blob/main/Top_Pypi_2020.pdf)'
- en: Introduction
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引言
- en: '*“The power of Open Source is the power of the people. The people rule”: ****Philippe
    Kahn***'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“开源的力量就是人民的力量。人民统治”：****Philippe Kahn***'
- en: Ever since my doctoral studies that mostly entailed performing statistical analysis
    in **R** ( and admittedly **Octave/MATLAB**), I have strongly embraced the emergence
    of Python as the lingua franca amongst machine learners / data scientists / *insert
    latest profession-buzzword here*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 自从我的博士研究主要涉及在**R**（以及坦白说**Octave/MATLAB**）中进行统计分析以来，我就坚定地拥抱了Python作为机器学习者/数据科学家/
    *插入最新职业热词*的通用语言。
- en: My daily workflow involves *quickly* *reacting* to the vagaries of messy real-world
    data, in all it’s naive-assumption-shattering glory. One major difference between
    graduate school and industry to me is the conquest of the inner-ego that goads
    you to implement algorithms from scratch. Once past the *white-boarding/hypothesis
    building phase *I quickly parse through the [PyPi repository](https://pypi.org/) to
    check if any of the constituent modules have already been authored. This is typically
    followed by a
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我的日常工作流程涉及*快速* *响应*混乱现实数据的变化，尽管这些数据常常打破了天真的假设。对我而言，研究生院与工业界之间的一个主要区别是征服内心那个驱使你从零开始实现算法的自我。
    一旦过了*白板/假设建立阶段*，我会迅速浏览[PyPi 仓库](https://pypi.org/)检查是否已经有相关模块。这通常接着是
- en: '**>>* pip install *PACKAGE_NAME****ritual and voila, I find myself standing
    on the shoulders of the open-source giants whose careful work I am now harnessing
    to scale the [DIKW pyramid](https://en.wikipedia.org/wiki/DIKW_pyramid).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**>>* pip install *PACKAGE_NAME****仪式，结果，我发现自己站在开源巨人的肩膀上，利用他们的精心工作来扩展[DIKW
    金字塔](https://en.wikipedia.org/wiki/DIKW_pyramid)。'
- en: I authored this blogpost to *acknowledge, celebrate and yes, publicize*, some
    amazing and *under-appreciated* PyPi packages that I used this past year; ones
    that I strongly feel deserve more recognition and love from our community. This
    is also my humble ode to the open-source scholars’ sweat equity that oft gets
    buried inside the *pip install *command.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我撰写了这篇博客文章，以*认可、庆祝并且是，宣传*，一些令人惊叹和*被低估的* PyPi 包，这些包是我过去一年使用的；我强烈认为它们值得我们社区更多的关注和喜爱。这也是我对开源学者的汗水贡献的一次谦逊致敬，这些贡献常常被埋没在*pip
    install*命令中。
- en: Caveat on sub-domain bias: *This particular post is focused on machine learning
    pipelines entailing**** neural networks/deep learning****. I plan to author similarly
    focused blogposts on specialized topics such as time-series analysis and human-kinematics
    analysis in the near future.*✌️
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 关于子领域偏差的警告：*这篇文章专注于涉及****神经网络/深度学习****的机器学习管道。我计划在不久的将来撰写类似专题的博客文章，如时间序列分析和人体运动学分析。*✌️
- en: 'What follows below are basic introductions into the 10 PyPi packages spanning:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是涵盖的10个PyPi包的基本介绍：
- en: a) **Neural network architecture specification and training**: *NSL-tf*, *Kymatio* and *LARQ*
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: a) **神经网络架构规范和训练**：*NSL-tf*、*Kymatio* 和 *LARQ*
- en: b) **Post training calibration and performance benchmarking**: *NetCal, PyEER *and* Baycomp.*
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: b) **训练后校准和性能基准测试**：*NetCal*、*PyEER* 和 *Baycomp*。
- en: c) **Pre real-world deployment stress-testing**:* PyOD, HyPPO* and *Gradio*
    d) **Documentation / dissemination**: *Jupyter_to_medium*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: c) **实际部署前的压力测试**：*PyOD*、*HyPPO* 和 *Gradio* d) **文档/传播**：*Jupyter_to_medium*
- en: '0: Pip install the above mentioned packages :)'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '0: 安装上述提到的包 :)'
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A) Neural network architecture specification and training: *NSL-tf*, *Kymatio* and *LARQ*
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A) 神经网络架构规范和训练：*NSL-tf*、*Kymatio* 和 *LARQ*
- en: '1: [Neural Structured Learning- Tensorflow](https://www.tensorflow.org/neural_structured_learning):'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '1: [神经结构学习 - Tensorflow](https://www.tensorflow.org/neural_structured_learning):'
- en: At the heart of most off-the-shelf classification algorithms in machine learning
    lies the ***i.i.d fallacy***. Simply put, the algorithm design rests on the assumption
    that the samples in the training set (as well as the test-set) are independent
    and identically distributed. In reality however, this rarely holds true and there
    exist correlations between the samples that can be harnessed to achieve better
    accuracy and explainability as well. In a wide array of application scenarios
    (See Fig-1), these correlations are captured by an underlying graph (G(V,E)) that
    can either be co-mined or statistically inferred. For example, if you are performing,
    say, sentiment detection of textual-tweets, the underlying follower-following
    social graph provides vital cues that models the *social* *context *in which the
    tweet was authored. This social neighborhood information can then be harnessed
    to perform network-aided classification that can be crucial in guarding against
    text-only shortcomings such as sarcasm mis-detection and hashtag-hijacking.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现成的机器学习分类算法的核心存在***i.i.d. 谬论***。简而言之，算法设计基于样本在训练集（以及测试集）中是独立且同分布的假设。然而，实际上这很少成立，样本之间存在可以利用的相关性，以实现更好的准确性和解释性。在广泛的应用场景中（见图-1），这些相关性通过一个底层图（G(V,E)）被捕获，该图可以是共同挖掘的或统计推断的。例如，如果你正在执行文本推文的情感检测，底层的关注者-被关注者社交图提供了建模*社交*
    *背景*的关键线索，这些背景是推文发布的背景信息。这种社交邻域信息可以被用来执行网络辅助分类，这对防范文本唯一的缺陷如讽刺误检和话题标签劫持至关重要。
- en: '![Figure](../Images/2944877f0d45bad5f74fd27be3bb672f.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2944877f0d45bad5f74fd27be3bb672f.png)'
- en: 'Fig-1: Examples of online information graphs'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图-1：在线信息图示例
- en: My [PhD thesis](https://kilthub.cmu.edu/articles/thesis/Network_Aided_Classification_and_Detection_of_Data/7430012/1) titled
    “Network Aided Classification and Detection of Data” literally explored the science
    and *algorithmics* of this graph-enhanced machine learning and it was so heartening
    to see Tensorflow release the [Neural structured learning](https://www.tensorflow.org/neural_structured_learning) framework
    along with a series of well crafted tutorials ( youtube [playlist](https://www.youtube.com/watch?v=N_IS3x5wFNI&list=PLS6Lwe0CFTqbS8WxxPmil0mCjAHZ0rD1x&ab_channel=TensorFlow) )
    along with an easy-to-follow [NSL Example colab-notebook](https://colab.research.google.com/drive/1yidXh-kM6fMi5c0yEXonvG4GFdcDO0-d#scrollTo=gRfU8T3BTYep&line=2&uniqifier=1).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我的[**博士论文**](https://kilthub.cmu.edu/articles/thesis/Network_Aided_Classification_and_Detection_of_Data/7430012/1)题为“网络辅助的数据分类与检测”字面上探讨了这种图增强机器学习的科学和*算法*，看到
    Tensorflow 发布了[**神经结构学习**](https://www.tensorflow.org/neural_structured_learning)框架，以及一系列精心制作的教程（YouTube
    [播放列表](https://www.youtube.com/watch?v=N_IS3x5wFNI&list=PLS6Lwe0CFTqbS8WxxPmil0mCjAHZ0rD1x&ab_channel=TensorFlow)），还有一个易于跟随的[**NSL
    示例 colab-notebook**](https://colab.research.google.com/drive/1yidXh-kM6fMi5c0yEXonvG4GFdcDO0-d#scrollTo=gRfU8T3BTYep&line=2&uniqifier=1)，让我感到非常振奋。
- en: 'In the example cell below, we train a NSL-enhanced neural network for the standard
    MNIST dataset in an adversarial setting:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元格中，我们在对抗性环境中训练一个 NSL 增强的神经网络用于标准 MNIST 数据集。
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '2: Kymatio: Wavelet scattering in Python'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '2: Kymatio: Python 中的小波散射'
- en: Here’s one of the best (or worst?) kept secrets in ML: ***A lot of the easy
    datasets (read the x-mnist family / cats-v-dogs / Hot-Dog classification) require
    NO backprop/SGD training histrionics***.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习中最好的（或最糟糕的？）秘密之一：***很多简单的数据集（如 x-mnist 家族 / cats-v-dogs / Hot-Dog 分类）不需要反向传播/SGD
    训练技巧***。
- en: The classes are separable enough and the architecture-induced discriminative
    capacity is high enough that careful initialization using [Grassmannian codebooks](https://arxiv.org/pdf/1911.07418.pdf) or
    wavelet filters followed by ‘last-layer’ hyper-plane learning (using standard
    regression techniques) should suffice to obtain a high-accuracy classifier.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类别足够可分，且架构引导的区分能力足够高，通过使用[**Grassmannian 码本**](https://arxiv.org/pdf/1911.07418.pdf)或小波滤波器进行仔细初始化，然后进行“最后一层”超平面学习（使用标准回归技术）应该足以获得一个高准确率的分类器。
- en: 'In this regard, [Kymatio](https://www.kymat.io/) has played a Caesar-esque
    role in the wavelet filters world uniting all the previous siloed projects such
    as `ScatNet`, `scattering.m`, `PyScatWave`, `WaveletScattering.jl`, and `PyScatHarm `into
    one easy to use monolithic portable framework that seamlessly works across six
    frontend–backend pairs: NumPy (CPU), scikit-learn (CPU), pure PyTorch (CPU and
    GPU), PyTorch+scikit-cuda (GPU), TensorFlow (CPU and GPU), and Keras (CPU and
    GPU).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，[**Kymatio**](https://www.kymat.io/)在小波滤波器领域发挥了类似凯撒的角色，将所有以前孤立的项目如 `ScatNet`、`scattering.m`、`PyScatWave`、`WaveletScattering.jl`
    和 `PyScatHarm` 整合成一个易于使用的整体便携框架，能够无缝地在六对前端-后端中工作：NumPy (CPU)、scikit-learn (CPU)、纯
    PyTorch (CPU 和 GPU)、PyTorch+scikit-cuda (GPU)、TensorFlow (CPU 和 GPU) 以及 Keras
    (CPU 和 GPU)。
- en: In the example cell below, we use the in-built Scattering2D class to train another
    MNIST-neural network that attains 92.84% accuracy in 15 epochs. This package is
    wonderfully well documented with a plethora of interesting examples such as [Classification
    of spoken digit recordings](https://www.kymat.io/gallery_1d/plot_classif_torch.html#sphx-glr-gallery-1d-plot-classif-torch-py) using
    1D scattering transforms and[ 3D scattering quantum chemistry regression](https://www.kymat.io/gallery_3d/scattering3d_qm7_torch.html#sphx-glr-gallery-3d-scattering3d-qm7-torch-py).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元格中，我们使用内建的 Scattering2D 类来训练另一个 MNIST 神经网络，该网络在 15 个训练周期中达到了 92.84%
    的准确率。这个软件包文档非常完善，包含了大量有趣的示例，如使用 1D 变换的[**口语数字录音分类**](https://www.kymat.io/gallery_1d/plot_classif_torch.html#sphx-glr-gallery-1d-plot-classif-torch-py)和[**3D
    变换量子化学回归**](https://www.kymat.io/gallery_3d/scattering3d_qm7_torch.html#sphx-glr-gallery-3d-scattering3d-qm7-torch-py)。
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[3: LARQ](https://docs.larq.dev/zoo/tutorials/)'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3: LARQ](https://docs.larq.dev/zoo/tutorials/)'
- en: 'I met the LARQ developers last December during NEURIPS-2019 in Vancouver where
    they unveiled their new open-source Python library for training Binarized Neural
    Networks (BNNs) alongside the poster of their paper titled [*Latent Weights Do
    Not Exist: Rethinking Binarized*](https://papers.nips.cc/paper/2019/file/9ca8c9b0996bbf05ae7753d34667a6fd-Paper.pdf)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 去年十二月，在温哥华的 NEURIPS-2019 上，我遇到了 LARQ 的开发者，他们展示了他们的新开源 Python 库，用于训练二值化神经网络 (BNNs)，同时展示了他们的论文海报，论文标题为[*潜在权重不存在：重新思考二值化*](https://papers.nips.cc/paper/2019/file/9ca8c9b0996bbf05ae7753d34667a6fd-Paper.pdf)。
- en: Neural Network Optimization. While there seems to be a lot of interest towards
    model compression for resource constrained on-device deployment ([Here’s 42 of
    ‘em](https://awesomeopensource.com/projects/model-compression)!), training fast-and-frugal
    Binary Neural Networks from scratch seems to be an option that many seem to discount
    at the outset.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络优化。虽然对于资源受限的设备部署模型压缩似乎有很多兴趣（[这里有42个](https://awesomeopensource.com/projects/model-compression)！），但从零开始训练快速且简约的二值神经网络似乎是一个许多人在一开始就忽略的选项。
- en: The LARQ package should help change things on that front given the ease of use,
    fast inference (Convolution operations turn into xor/bit-shifts with binarized
    weights), brilliant documentation and plentiful architecture examples that one
    can then hack away by means of a full-fledged model [zoo](https://docs.larq.dev/zoo/).
    This year, I have personally published work on [style-transfer](https://matthewmcateer.me/posts/bnn-nst/) and
    a [40 kB BiPedalNet model](https://pml4dc.github.io/iclr2020/papers/PML4DC2020_32.pdf) using
    LARQ and it’s always a breeze to work with this toolkit. Besides the [Zoo](https://docs.larq.dev/zoo/),
    the package is also accompanied by a highly optimized [Compute Engine](https://docs.larq.dev/compute-engine/) that* currently
    supports various mobile platforms, has been benchmarked on a Pixel 1 phone & Raspberry
    Pi and also provides a collection of hand-optimized TensorFlow Lite custom operators
    for supported instruction sets, developed in inline assembly or in C++ using compiler
    intrinsics.*
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LARQ包应有助于改变这一情况，考虑到其易用性、快速推断（卷积操作转变为使用二值权重的xor/位移）、出色的文档和大量的架构示例，用户可以通过完整的模型*[zoo](https://docs.larq.dev/zoo/)*进行修改。今年，我个人使用LARQ发布了关于*[风格迁移](https://matthewmcateer.me/posts/bnn-nst/)*和一个*[40
    kB BiPedalNet模型](https://pml4dc.github.io/iclr2020/papers/PML4DC2020_32.pdf)*的工作，使用这个工具包总是非常顺利。除了*[Zoo](https://docs.larq.dev/zoo/)*，该包还配备了一个高度优化的*[计算引擎](https://docs.larq.dev/compute-engine/)*，*目前支持各种移动平台，已在Pixel
    1手机和Raspberry Pi上进行基准测试，还提供了一个为支持的指令集开发的手工优化的TensorFlow Lite自定义操作集合，这些操作是用内联汇编或C++通过编译器内建函数开发的。*
- en: In the example code cell below, we train a 13.19 KB BNN that hits 98.31 % on
    the MNIST dataset in 6 epochs and also demonstrate how easy it is to pull one
    of the SOTA pre-trained *QuickNet* models from the LARQ-zoo and run inference.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例代码单元中，我们训练了一个13.19 KB的BNN，它在MNIST数据集上经过6个周期达到了98.31%，并演示了如何轻松地从LARQ-zoo中提取一个SOTA预训练的*QuickNet*模型并进行推断。
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![png](../Images/a6780fad5a800441cfe7fcb83d032f80.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/a6780fad5a800441cfe7fcb83d032f80.png)'
- en: 'B) Post training calibration and performance benchmarking: NetCal, PyEER and
    BayComp'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B) 训练后校准和性能基准测试：NetCal、PyEER和BayComp
- en: In this section, we’ll look at packages that are useful in the post-training
    pre-deployment scenario where the practitioner’s goals are to calibrate the outputs
    a of a pre-trained model and rigorously benchmark the performance of multiple
    models ripe for deployment.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将查看在训练后、部署前场景中有用的包，其中从业者的目标是校准预训练模型的输出，并严格基准测试多个适合部署的模型的性能。
- en: '[1: Netcal](https://pypi.org/project/netcal/):'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[1: Netcal](https://pypi.org/project/netcal/)：'
- en: '![Figure](../Images/32e6d40a03a71407982fa90300c831bc.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/32e6d40a03a71407982fa90300c831bc.png)'
- en: 'Fig-2: Scaling v/s Binning v/s Scaling-Binning. ‘B’ denotes the # of distinct
    probabilities the model'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图-2：缩放与分箱与缩放-分箱。‘B’表示模型的不同概率数
- en: outputs. Source: [https://arxiv.org/pdf/1909.10155.pdf](https://arxiv.org/pdf/1909.10155.pdf)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 输出。来源：[https://arxiv.org/pdf/1909.10155.pdf](https://arxiv.org/pdf/1909.10155.pdf)
- en: 'Often times, I have seen ML practitioners buy into this false equivalence between
    the output *softmax* values and probabilities. They are anything but that! Their
    co-inhabitance of the (0,1] space allows them to masquerade as probabilities but
    the ‘raw’ softmax values are, well, ‘[uncalibrated](https://arxiv.org/pdf/1706.04599.pdf)’
    put nicely. Hence, post-training calibration is a rapidly growing body of work
    in deep learning, and the techniques proposed herewith largely falls into 3 categories
    (See Fig-2):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我常常看到机器学习从业者误认为输出的*softmax*值和概率是等同的。它们远非如此！它们在（0,1]空间中的共存使它们伪装成概率，但‘原始’softmax值，嗯，可以说是‘[未校准](https://arxiv.org/pdf/1706.04599.pdf)’。因此，训练后校准是深度学习中快速增长的工作领域，这里提出的技术大致分为三类（见图-2）：
- en: 'Binning (Ex: Histogram Binning, Isotonic Regression, Bayesian Binning into
    Quantiles (BBQ), Ensemble of Near Isotonic Regression (ENIR))'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分箱（例如：直方图分箱、等距回归、贝叶斯分箱到分位数（BBQ）、近似等距回归集成（ENIR））
- en: 'Scaling (Ex: Logistic Calibration/Platt Scaling, Temperature Scaling , Beta
    Calibration)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '缩放（例如: Logistic 校准/Platt 缩放，温度缩放，Beta 校准）'
- en: '[Hybrid scaling-binning](https://arxiv.org/pdf/1909.10155.pdf) (Python library: [https://pypi.org/project/uncertainty-calibration](https://pypi.org/project/uncertainty-calibration))'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[混合缩放-分箱](https://arxiv.org/pdf/1909.10155.pdf) (Python 库: [https://pypi.org/project/uncertainty-calibration](https://pypi.org/project/uncertainty-calibration))'
- en: With regards to all the above stated Binning and Scaling techniques, the implementations
    with extremely well authored documentation is available in the NetCal. The package
    also included primitives for generating Reliability Diagrams and estimating calibration
    error metrics such as Expected /Max/Average Calibration Errors as well.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关于上述所有分箱和缩放技术，具有极好编写文档的实现可以在 NetCal 中找到。该包还包括生成可靠性图和估计校准误差指标（如期望/最大/平均校准误差）的原语。
- en: In the cell below, we see use the obtained softmax values on the MNIST test-set
    (from the NSL trained model above) to demonstrate the usage of the Temperature
    Scaling calibration and Reliability-Diagram generation routines.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的单元格中，我们使用从上述 NSL 训练模型获得的 MNIST 测试集上的 softmax 值来演示温度缩放校准和可靠性图生成例程的使用。
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![png](../Images/d5cc7402f1bff615fa0059bf41206c80.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/d5cc7402f1bff615fa0059bf41206c80.png)'
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![png](../Images/69889862580274b1cdc38edc66102162.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/69889862580274b1cdc38edc66102162.png)'
- en: '![png](../Images/daa5d781ae7379488957133f289260c2.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/daa5d781ae7379488957133f289260c2.png)'
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![png](../Images/af4846a01cfe622db1c26cb4d13f6a83.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/af4846a01cfe622db1c26cb4d13f6a83.png)'
- en: '[2: Baycomp](https://baycomp.readthedocs.io/): So you think you have a better
    classifier?'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[2: Baycomp](https://baycomp.readthedocs.io/): 你认为你有一个更好的分类器吗？'
- en: One of the under-rated conundrums that both ML practitioners and in some ways,
    research paper reviewers, grapple with, is rigorously ascertaining the predictive
    supremacy of one classifier model over the other(s). Model-Olympics platforms
    like [Papers with code](https://paperswithcode.com/) further promulgate this model-ranking
    fallacy by erroneously centering the top-1 accuracy metric (See Fig below) as
    the deciding measure.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个被低估的难题是，机器学习从业者以及在某些方面，研究论文审稿人，如何严格确定一个分类器模型相对于其他模型的预测优势。像 [Papers with code](https://paperswithcode.com/)
    这样的平台通过错误地将 top-1 准确度指标（见下图）作为决定性度量，进一步传播了这种模型排名的误区。
- en: '![Figure](../Images/1a89fad6cb754f68e51ad5bae2408900.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/1a89fad6cb754f68e51ad5bae2408900.png)'
- en: Source: [https://paperswithcode.com/sota/image-classification-on-inaturalist-2018](https://paperswithcode.com/sota/image-classification-on-inaturalist-2018)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://paperswithcode.com/sota/image-classification-on-inaturalist-2018](https://paperswithcode.com/sota/image-classification-on-inaturalist-2018)'
- en: So, given two classifications models with similar engineering overheads to deploy,
    how do you choose one over the other? Typically, we have a standard benchmarking
    dataset (or a set of datasets) that serve as the testing ground for classifier-wars.
    After obtaining the ‘*raw accuracy metrics over this dataset-space*’ a statistical
    minded machine learner might be inclined to use tools from the frequentist null
    hypothesis significance testing (NHST) framework to establish which classifier
    is ‘better’. However, as stated [here](https://www.jmlr.org/papers/volume18/16-305/16-305.pdf),
    “*Many scientific fields however realized the shortcomings of frequentist reasoning
    and in the most radical cases even banned its use in publications”.*
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，考虑到两个具有类似工程开销的分类模型，你如何选择其中一个而不是另一个？通常，我们有一个标准基准数据集（或一组数据集），作为分类器竞争的测试平台。在获得‘*该数据集空间的原始准确度指标*’后，统计思维的机器学习者可能会倾向于使用来自频率学派零假设显著性测试（NHST）框架的工具来确定哪个分类器‘更好’。然而，如
    [这里](https://www.jmlr.org/papers/volume18/16-305/16-305.pdf) 所述，“*许多科学领域意识到频率学推理的局限性，在最激进的情况下甚至禁止在出版物中使用它*”。
- en: 'Baycomp emerges in this contextproviding a ***Bayesian framework for comparison
    of classifiers***. The library helps compute three probabilities:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Baycomp 在这种背景下出现，提供了一个 ***用于比较分类器的贝叶斯框架***。该库帮助计算三个概率：
- en: 'P_left : The probability that the first classifier has higher accuracy scores
    than the second.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'P_left: 第一个分类器比第二个分类器具有更高准确度得分的概率。'
- en: 'P_rope: The probability that differences are within the region of practical
    equivalence (rope)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'P_rope: 差异在实际等效区域（rope）内的概率'
- en: 'P_right: The probability that the second classifier has higher scores.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'P_right: 第二个分类器具有更高得分的概率。'
- en: The **r**egion **o**f **p**ractical **e**quivalence (rope) is specified by the
    machine learner who is well versed with what could be safely assumed to be *equivalent* in
    the domain of deployment.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**实用等效区域**（rope）由机器学习者指定，该学习者对在部署领域中可以安全假设为*等效*的内容非常熟悉。'
- en: In the example cell below, we consider both, a synthetic example entailing two
    closely competitive classifiers as well as the two classifiers we just trained
    using the NSL-TF and LARQ-BNN frameworks on the MNIST dataset
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元中，我们考虑了一个合成示例，其中包括两个紧密竞争的分类器以及我们刚刚使用NSL-TF和LARQ-BNN框架在MNIST数据集上训练的两个分类器。
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![png](../Images/2d6d7dda04dc122e5edcebdba65f2f69.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/2d6d7dda04dc122e5edcebdba65f2f69.png)'
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![png](../Images/c2a73cc8cfd3d6f173d37301cacecd95.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/c2a73cc8cfd3d6f173d37301cacecd95.png)'
- en: '![Figure](../Images/91a01fb33e6680632e0490584b6e874d.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/91a01fb33e6680632e0490584b6e874d.png)'
- en: Using baycomp to compare classifiers +NSL v/s BNN classifier comparison on the
    MNIST dataset
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用baycomp比较分类器 +NSL与BNN分类器在MNIST数据集上的比较
- en: '***Important caveat***: *There is a related but distinct conversation surrounding
    the very culture of predictive accuracy veneration in ML. This*[* predicitivism
    v/s accommodation debate*](https://plato.stanford.edu/entries/prediction-accommodation/#:~:text=The%20view%20that%20predictions%20are,when%20predicted%20than%20when%20accommodated.)* in
    science has been evolving since the days of John Herschel and William Whewell
    in the 1800s.*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '***重要警告***：*有关机器学习中预测准确性崇拜的相关但不同的讨论。这*[*预测主义与适应辩论*](https://plato.stanford.edu/entries/prediction-accommodation/#:~:text=The%20view%20that%20predictions%20are,when%20predicted%20than%20when%20accommodated.)*在科学中自19世纪的约翰·赫歇尔和威廉·惠更斯时代以来一直在演变。*'
- en: '[3: PyEER](https://pypi.org/project/pyeer/)'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3: PyEER](https://pypi.org/project/pyeer/)'
- en: '![Figure](../Images/fe59eb7b9ce52d039f05b4232f0ce982.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/fe59eb7b9ce52d039f05b4232f0ce982.png)'
- en: The wide repertoire of methods available in PyEER
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: PyEER中可用的方法广泛
- en: Another way of comparing two classifiers, especially in the context of solving
    the binary authentication problem (Not *surveillance *but* Authentication*) is
    by plotting the comparative detection error tradeoff (DET) and Receiver operating
    characteristic (ROC) graphs. PyEER is an absolute tour-de-force in this regard
    as it serves as a one-stop-shop for not just plotting the relevant graphs but
    also auto-generating metrics-reports and estimating EER-optimal-thresholds. In
    the example cell below, we compare the Angle-Based Outlier Detector (ABOD)and
    the KNN inlier-outlier detector binary classifiers that’ll be introduced in the
    forthcoming section on pre-deployment Out-of-Distribution detection techniques.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 比较两个分类器的另一种方法，特别是在解决二元身份验证问题的背景下（而非*监控*而是*身份验证*），是通过绘制比较检测错误权衡（DET）和接收器操作特性（ROC）图。PyEER在这方面是绝对的杰作，因为它不仅可以绘制相关图形，还能自动生成指标报告和估算EER最佳阈值。在下面的示例单元中，我们比较了即将在下一节介绍的角度基础异常检测器（ABOD）和KNN内点-外点检测器二元分类器。
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![png](../Images/96d46c201082e58e04fc232d1fa08fb2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![png](../Images/96d46c201082e58e04fc232d1fa08fb2.png)'
- en: 'C: Pre real-world deployment stress-testing: PyOD, HyPPO and Gradio'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'C: 现实世界部署前的压力测试：PyOD、HyPPO和Gradio'
- en: '![Figure](../Images/17ec9df55fe6dd212daf2484e5a6f557.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/17ec9df55fe6dd212daf2484e5a6f557.png)'
- en: 'The landscape of OOD susceptibility: Access the SVG [here](https://matthew-mcateer.github.io/oodles-of-oods/)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: OOD易感性的全景：访问SVG [这里](https://matthew-mcateer.github.io/oodles-of-oods/)
- en: Vulnerability to Out-of-distribution (OOD) samples resulting in confident mispredictions
    is currently one of the most serious roadblocks that haunts the transition of
    ML ideas from pretty little papers to real-world deployment where the inputs have
    no guarantees to emanate from the proverbial *training manifold*. In a joint project
    with [Matthew McAteer](https://matthew-mcateer.github.io/oodles-of-oods/), I’ve
    created a landscape of susceptibility (See figure above) that should empower machine
    learners to cover the wide spectrum of specific vulnerability-vectors with regards
    to their models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于外部分布（OOD）样本造成的自信错误预测，目前是从理论论文过渡到现实世界部署中最严重的障碍之一，因为输入没有从所谓的*训练流形*中获得保证。在与[Matthew
    McAteer](https://matthew-mcateer.github.io/oodles-of-oods/)的联合项目中，我创建了一个易感性全景（见上图），这应该能够帮助机器学习者覆盖与他们的模型相关的广泛特定易感性向量。
- en: While there is no silver bullet (and there perhaps will never be — See [this](https://arxiv.org/pdf/1802.08686.pdf) & [this](https://arxiv.org/abs/1809.02104)),
    it’d be hard to argue against incorporating OOD-model regularization and OOD-detection
    modules into your pipelines.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有银弹（可能永远也不会有——见 [这篇](https://arxiv.org/pdf/1802.08686.pdf) 和 [这篇](https://arxiv.org/abs/1809.02104)），但很难反对在你的管道中加入OOD模型正则化和OOD检测模块。
- en: With regards to OOD-detection, I felt that there were 3 recent efforts that
    have gone under-adopted by the ML community.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 关于OOD检测，我认为ML社区有三项近期努力被低估了。
- en: The first two, *PyOD* and *HyPPO*, would be useful for pre-filtering inputs
    before performing inference and the third, Gradio, is an amazing tool for human-in-the-loop
    white-hat stress testing and complementary to efforts such as [Dynabench](https://dynabench.org/) by
    FAIR.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个， *PyOD* 和 *HyPPO*，在进行推理前有助于预筛选输入，而第三个，Gradio，是一个出色的人机交互白帽压力测试工具，补充了如 [Dynabench](https://dynabench.org/)
    这样的FAIR努力。
- en: '[1: PYOD](https://pyod.readthedocs.io/en/latest/)'
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[1: PYOD](https://pyod.readthedocs.io/en/latest/)'
- en: '![Figure](../Images/f1cb5578bfaf5d746d6dc6a33256602b.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/f1cb5578bfaf5d746d6dc6a33256602b.png)'
- en: Source: [https://www.jmlr.org/papers/volume20/19-011/19-011.pdf](https://www.jmlr.org/papers/volume20/19-011/19-011.pdf)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.jmlr.org/papers/volume20/19-011/19-011.pdf](https://www.jmlr.org/papers/volume20/19-011/19-011.pdf)
- en: PyOD is arguably the most comprehensive and scalable Outlier Detection Python
    toolkit out there that includes implementation of more than 30 detection algorithms!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: PyOD可以说是最全面和可扩展的异常检测Python工具包，包含了30多种检测算法的实现！
- en: It is somewhat rare for a student-maintained PyPi package to incorporate software
    engineering best practices that ensures that model classes implemented are covered
    by unit testing with cross platform continuous integration, code coverage and
    code maintainability checks. This combined with a a clean unified API, detailed
    documentation and just-in-time (JIT) compiled execution makes it an absolute breeze
    to both learn about the different techniques and use it in practice. The efforts
    invested by the authors towards careful parallelization has resulted in extremely
    fast and scalable outlier detection code that is also seamlessly compatible across *Python
    2 and 3 across major operating systems (Windows, Linux and MacOS)*.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 学生维护的PyPi包能够结合软件工程最佳实践，这确保了实现的模型类都经过了单元测试、跨平台持续集成、代码覆盖率和代码可维护性检查，这种情况比较少见。这与清晰统一的API、详细的文档以及即时（JIT）编译执行相结合，使得学习不同技术和实际使用变得异常轻松。作者在仔细并行化方面投入的努力，使得异常检测代码不仅非常快速且可扩展，而且在
    *Python 2 和 3 及主要操作系统（Windows、Linux 和 MacOS）* 上也无缝兼容。
- en: 'In the example cell below, we train and visualize the results of two inlier-outlier
    detector binary classifiers on a synthetic dataset: the Angle-Based Outlier Detector
    (ABOD)and the KNN outlier detector.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元格中，我们训练并可视化了两个内点-外点检测器二元分类器在一个合成数据集上的结果：角度基础异常检测器（ABOD）和KNN异常检测器。
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let’s visualize the results:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们可视化结果：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Figure](../Images/b1e03b0842cef601d3e1bd7dce0867b8.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/b1e03b0842cef601d3e1bd7dce0867b8.png)'
- en: ABOD v/s KNN for outlier detection
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ABOD与KNN在异常检测中的对比
- en: '[2: Hyppo](https://hyppo.neurodata.io/index.html):'
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[2: Hyppo](https://hyppo.neurodata.io/index.html):'
- en: It is somewhat bewildering to witness this collective amnesia on part of the
    Deep Learning community that keeps treating OOD susceptibility as a uniquely ‘deep
    neural networks’ shortcoming that somehow merits a deep-learning-solution whilst
    completing ignoring the cache of approaches and solutions already explored by
    the statistics community.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 目睹深度学习社区普遍存在这种集体遗忘现象，继续将OOD易感性视为一种独特的“深度神经网络”缺陷，似乎需要一个深度学习解决方案，而完全忽视了统计学社区已经探索过的一系列方法和解决方案，这有些令人困惑。
- en: One could argue that OOD-detection by it’s very definition falls under the ambit
    of the multivariate hypothesis testing framework, and hence it is frustrating
    to see deep learning OOD papers not even benchmark the results obtained by their
    shiny new deep-approaches with what could be possible legacy hypothesis testing
    algorithms. With this setting, we now introduce HYPPO.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会认为，按定义，OOD（异常检测）属于多变量假设检验框架的范畴，因此看到深度学习OOD论文没有将其炫目的新深度方法与可能存在的传统假设检验算法进行基准测试，实在令人沮丧。在这种背景下，我们现在介绍HYPPO。
- en: HYPPO (**HYP**othesis Testing in **P**yth**O**n, pronounced “Hippo”) is arguably
    the most comprehensive open-source software package for multivariate hypothesis
    testing produced by the [NEURODATA](https://neurodata.io/) community. In the figure
    below, we see the landscape of modules implemnetd in this package that spans synthetic
    data generation (with 20 dependency structures!), Independence Tests, K-sample
    Tests as well as Time-Series Tests.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: HYPPO（**HYP**othesis Testing in **P**yth**O**n，发音为“Hippo”）可以说是由[NEURODATA](https://neurodata.io/)社区生产的最全面的开源多变量假设检验软件包。在下图中，我们可以看到这个包中实现的模块的全景，涵盖了合成数据生成（具有20种依赖结构！）、独立性测试、K样本测试以及时间序列测试。
- en: '![Figure](../Images/a278d6ff3db81a5ad235291b15bde662.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/a278d6ff3db81a5ad235291b15bde662.png)'
- en: Landscape of algorithms implemented in Hyppo
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Hyppo中实现的算法全景
- en: In the example cell below, we see the K-Sample-Distance Correlation(Or “Dcorr”)
    test being used to hypothesis test between the in-and-out distributed data generated
    by the generate_data() module in PyOD above. In a deep-learning setting, we could
    deploy these tests both at the input layer level or in the feature-embedding space
    to guesstimate if the output softmax values are even worthy of being processed
    further down the inference pipeline.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元格中，我们看到使用K-Sample-Distance Correlation（或称“Dcorr”）测试来检验PyOD中generate_data()模块生成的内外分布数据。在深度学习环境中，我们可以在输入层级别或特征嵌入空间中部署这些测试，以估计输出的softmax值是否值得进一步在推理管道中处理。
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[3: Gradio](https://gradio.app/ml_examples):'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[3: Gradio](https://gradio.app/ml_examples)：'
- en: '![Figure](../Images/f63344218fef2c36bef52b79235e381e.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/f63344218fef2c36bef52b79235e381e.png)'
- en: Gradio’s saliency cropping algorithm: [http://saliency-model.gradiohub.com/](http://saliency-model.gradiohub.com/)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio的显著性裁剪算法：[http://saliency-model.gradiohub.com/](http://saliency-model.gradiohub.com/)
- en: Having a nice GUI to interact with the model you have just trained has thus
    far required a fair amount of JavaScript-front-end gimmickry or the Heroku-Flask
    route that can take focus away from the algorithmics.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，与刚刚训练的模型交互所需的良好GUI通常需要大量的JavaScript前端技巧或Heroku-Flask路线，这可能会使算法的重点分散。
- en: Thanks to Gradio, one can can quickly fire up a gui with <10 lines of Python
    with pre-built input modules that cover textual input, image-inputs with an awesome
    Toast-UI image-editor and a sketchpad to boot as well!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 借助Gradio，可以用不到10行Python代码快速启动一个GUI，包含文本输入、图像输入（配备了出色的Toast-UI图像编辑器）和一个素描板！
- en: This past year, I have heavily used Gradio in my workflow, using it to investigate
    why Twitter’s saliency cropping algorithm yields such racist results (See Figure
    to the left) to why Onions were triggering NSFW filters on [facebook](https://www.bbc.com/news/54467384) (See
    tweet below) .
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的一年里，我在工作流程中大量使用了Gradio，用它来调查Twitter的显著性裁剪算法为何会产生如此种族偏见的结果（见左图），以及为什么Onions会触发[facebook](https://www.bbc.com/news/54467384)上的NSFW过滤器（见下方推文）。
- en: 'The [NSFW-Onion](https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb) fiasco.
    Colab notebook: [https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb](https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[NSFW-Onion](https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb)的灾难。Colab笔记本：[https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb](https://github.com/vinayprabhu/Crimes_of_Vision_Datasets/blob/master/Notebooks/Notebook_5b_Onion_Gradio_NSFW.ipynb)'
- en: In the example cell below, we demonstrate two simple examples of using Gradio
    to fire-up UIs to stress-test the MNIST classification BNN model we just trained
    above with a sketchpad input and to demonstrate the ease of using the InceptionV3
    model to classify images. The Gradio team has also rapidly added explainaibility
    and embeddings-visualization tools, and implemented SOTA [blind super resolution](https://gradio.app/g/dawoodkhan82/dan) and [Real-Time
    High-Resolution Background Matting](https://gradio.app/g/BackgroundMattingV2) UIs
    as well!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例单元格中，我们展示了两个简单的示例，使用Gradio启动UI，以对我们刚刚训练的MNIST分类BNN模型进行压力测试，并演示了使用InceptionV3模型进行图像分类的简便性。Gradio团队还迅速添加了解释性和嵌入可视化工具，并实现了SOTA的[盲超分辨率](https://gradio.app/g/dawoodkhan82/dan)和[实时高分辨率背景抠图](https://gradio.app/g/BackgroundMattingV2)
    UI！
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Figure](../Images/9b5d730fae41a829217dfe3fbcc4ab6c.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/9b5d730fae41a829217dfe3fbcc4ab6c.png)'
- en: Gradio MNIST classification with a sketchpad input![Figure](../Images/ead2537d8637878a263a7c0101d030a7.png)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio MNIST 分类与草图输入![图示](../Images/ead2537d8637878a263a7c0101d030a7.png)
- en: Gradio Image classification (InceptionV3) with an image input
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio 图像分类（InceptionV3）与图像输入
- en: 'D) Documentation / dissemination:'
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D) 文档/传播：
- en: '1) Jupyter_to_medium:'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '1) Jupyter_to_medium:'
- en: '![Figure](../Images/45bb652f1b909dd4c89ef395ee1ae867.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/45bb652f1b909dd4c89ef395ee1ae867.png)'
- en: Example image. Source: [https://www.dexplo.org/jupyter_to_medium/](https://www.dexplo.org/jupyter_to_medium/)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 示例图像。来源：[https://www.dexplo.org/jupyter_to_medium/](https://www.dexplo.org/jupyter_to_medium/)
- en: Video tutorial of the *Jupyter_to_medium package*
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '*Jupyter_to_medium 包* 的视频教程'
- en: Last but not the least, I used the *Jupyter_to_medium* PyPi package to author
    this very blogpost from it’s [source notebook](https://github.com/vinayprabhu/Favorite_PyPi_2020)!
    As many of you might have experienced, converting your jupyter/colab notebook
    into a readable blogpost involves painful copy-pasting antics, code snapshotting
    and plug-in gimmicks. All of this is a thing of past after the release of this
    game-changing package.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我使用了*Jupyter_to_medium* PyPi 包来撰写本博客文章，来源于它的[source notebook](https://github.com/vinayprabhu/Favorite_PyPi_2020)!
    正如你们中的许多人可能经历过的，将你的 Jupyter/Colab 笔记本转换为可读的博客文章涉及到痛苦的复制粘贴、代码截图和插件花招。自从这个改变游戏规则的包发布以来，这些问题已经成为过去。
- en: 'The procedure is super-simple: pip install, finish the notebook, choose File
    →’Deploy as’, insert integration token from medium, and perform final edits/prettification
    if necessary.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程非常简单：pip 安装，完成笔记本，选择文件→‘部署为’，插入来自 medium 的集成令牌，然后进行最终编辑/美化（如有必要）。
- en: On the concluding note, I’d like to thank the incredible researchers and engineers
    who created these wonderful PyPi packages . In the forthcoming blogpost(s), I
    plan to cover packages pertaining to specific topics such as time-series analysis
    and dimensionality reduction. Here’s a recap picture that summarizes the packages
    explored above.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要感谢那些创造了这些精彩 PyPi 包的杰出研究人员和工程师。在即将到来的博客文章中，我计划涵盖与特定主题相关的包，如时间序列分析和降维。这里有一张回顾图片，总结了上述探索的包。
- en: '![Figure](../Images/b0ff25585442b78ff440f70a0a846a2b.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/b0ff25585442b78ff440f70a0a846a2b.png)'
- en: Recap of the PyPi landscape covered in this blogpost
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本博客文章中涵盖的 PyPi 生态系统回顾
- en: Hope some of you will find this blogpost useful in your ML adventures. Good
    luck and wish y’all a happy and productive 2021 ????!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你们中的一些人在机器学习冒险中能发现这篇博客文章有所帮助。祝好运，并祝大家2021年快乐高效 ????
- en: Feel free to leave feedback regarding the content /errata/ broken links. You
    may connect with me via [Linkedin](https://www.linkedin.com/in/vinay-prabhu-84619785/) or [Twitter](https://twitter.com/vinayprabhu) as
    well ????
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 随时欢迎对内容/错误/坏链进行反馈。你可以通过[Linkedin](https://www.linkedin.com/in/vinay-prabhu-84619785/)或[Twitter](https://twitter.com/vinayprabhu)与我联系
    ????
- en: '**Bio: [Vinay Uday Prabhu](https://vinayprabhu.github.io/)** is Chief Scientist
    at UnifyID Inc.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Vinay Uday Prabhu](https://vinayprabhu.github.io/)** 是 UnifyID Inc.
    的首席科学家。'
- en: '[Original](https://towardsdatascience.com/most-useful-machine-learning-pypi-packages-of-2020-a0ec6678ce22).
    Reposted with permission.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/most-useful-machine-learning-pypi-packages-of-2020-a0ec6678ce22)。已获许可转载。'
- en: '**Related:**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Data Science as a Product – Why Is It So Hard?](/2020/12/data-science-product-hard.html)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学作为产品 – 为什么这么难？](/2020/12/data-science-product-hard.html)'
- en: '[Generating Beautiful Neural Network Visualizations](/2020/12/generating-beautiful-neural-network-visualizations.html)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成美丽的神经网络可视化](/2020/12/generating-beautiful-neural-network-visualizations.html)'
- en: '[Fast and Intuitive Statistical Modeling with Pomegranate](/2020/12/fast-intuitive-statistical-modeling-pomegranate.html)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Pomegranate 进行快速直观的统计建模](/2020/12/fast-intuitive-statistical-modeling-pomegranate.html)'
- en: More On This Topic
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为出色数据科学家所需的 5 个关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学数据科学家都应该掌握的 6 种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021 年最佳 ETL 工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使得 Python 成为初创公司理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三大 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
