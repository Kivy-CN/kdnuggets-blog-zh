- en: 'XGBoost Algorithm: Long May She Reign'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: XGBoost算法：愿她长久统治
- en: 原文：[https://www.kdnuggets.com/2019/05/xgboost-algorithm.html](https://www.kdnuggets.com/2019/05/xgboost-algorithm.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/xgboost-algorithm.html](https://www.kdnuggets.com/2019/05/xgboost-algorithm.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Vishal Morde](https://www.linkedin.com/in/vishalmorde/) and [Anurag Setty](https://www.linkedin.com/in/venkatsetty/)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Vishal Morde](https://www.linkedin.com/in/vishalmorde/) 和 [Anurag Setty](https://www.linkedin.com/in/venkatsetty/)
    合著**'
- en: '![](../Images/761721cbfdec29c67b1b4fe8eb636e39.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/761721cbfdec29c67b1b4fe8eb636e39.png)'
- en: '**Photo by [Jared Subia](https://unsplash.com/photos/QczH4IiPNx0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/tiara?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**照片由 [Jared Subia](https://unsplash.com/photos/QczH4IiPNx0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/search/photos/tiara?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**'
- en: (This article was co-authored with [Venkat Anurag Setty](https://medium.com/@setgeti))
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: （本文与 [Venkat Anurag Setty](https://medium.com/@setgeti) 共同撰写）
- en: 'I still remember the day 1 of my very first job fifteen years ago. I had just
    finished my graduate studies and joined a global investment bank as an analyst.
    On my first day, I kept straightening my tie and trying to remember everything
    that I had studied. Meanwhile, deep down, I wondered if I was good enough for
    the corporate world. Sensing my anxiety, my boss smiled and said:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我仍然记得十五年前我第一份工作的第一天。我刚刚完成研究生学业，加入了一家全球投资银行担任分析师。在第一天，我不断整理领带，试图记住我学过的所有东西。与此同时，我深深地怀疑自己是否足够适合企业世界。感受到我的焦虑，我的老板微笑着说：
- en: '*“Don’t worry! The only thing that you need to know is the regression modeling!”*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*“别担心！你唯一需要知道的就是回归建模！”*'
- en: I remember thinking myself, “I got this!”. I knew regression modeling; both
    linear and logistic regression. My boss was right. In my tenure, I exclusively
    built regression-based statistical models. I wasn’t alone. In fact, at that time,
    regression modeling was the undisputed queen of predictive analytics. Fast forward
    fifteen years, the era of regression modeling is over. The old queen has passed.
    Long live the new queen with a funky name; XGBoost or Extreme Gradient Boosting!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得当时我在想，“我搞定了！”我了解回归建模，包括线性回归和逻辑回归。我的老板说得对。在我的任期内，我专注于构建基于回归的统计模型。我不是唯一的。事实上，那时回归建模是预测分析领域的无可争议的女王。快进十五年，回归建模的时代已经结束。老女王已逝，新女王以一个独特的名字登场；XGBoost或极端梯度提升！
- en: What is XGBoost?
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: XGBoost是什么？
- en: '[XGBoost](https://xgboost.ai/)is a decision-tree-based ensemble Machine Learning
    algorithm that uses a [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) framework.
    In prediction problems involving unstructured data (images, text, etc.) artificial
    neural networks tend to outperform all other algorithms or frameworks. However,
    when it comes to small-to-medium structured/tabular data, decision tree based
    algorithms are considered best-in-class right now. Please see the chart below
    for the evolution of tree-based algorithms over the years.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[XGBoost](https://xgboost.ai/) 是一种基于决策树的集成机器学习算法，使用了 [梯度提升](https://en.wikipedia.org/wiki/Gradient_boosting)
    框架。在涉及非结构化数据（如图像、文本等）的预测问题中，人工神经网络通常优于所有其他算法或框架。然而，当涉及到小到中型的结构化/表格数据时，基于决策树的算法目前被认为是最优的。请参见下面的图表，了解决策树算法的演变过程。'
- en: '![](../Images/51eaf3b11b2c984a8cb4f70a69c15825.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51eaf3b11b2c984a8cb4f70a69c15825.png)'
- en: '**Evolution of XGBoost Algorithm from Decision Trees**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost算法从决策树的演变**'
- en: 'XGBoost algorithm was developed as a research project at the University of
    Washington. [Tianqi Chen and Carlos Guestrin](https://arxiv.org/pdf/1603.02754.pdf) presented
    their paper at SIGKDD Conference in 2016 and caught the Machine Learning world
    by fire. Since its introduction, this algorithm has not only been credited with
    winning numerous Kaggle competitions but also for being the driving force under
    the hood for several cutting-edge industry applications. As a result, there is
    a strong community of data scientists contributing to the XGBoost open source
    projects with ~350 contributors and ~3,600 commits on [GitHub](https://github.com/dmlc/xgboost/).
    The algorithm differentiates itself in the following ways:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 算法是华盛顿大学的一个研究项目。**[Tianqi Chen and Carlos Guestrin](https://arxiv.org/pdf/1603.02754.pdf)**
    在 2016 年的 SIGKDD 会议上展示了他们的论文，引起了机器学习界的广泛关注。自引入以来，该算法不仅因赢得众多 Kaggle 比赛而受到赞誉，还因在多个前沿行业应用中作为核心驱动力而广泛使用。因此，XGBoost
    开源项目拥有一个强大的数据科学家社区，有约 350 位贡献者和约 3,600 次提交，分布在 **[GitHub](https://github.com/dmlc/xgboost/)**
    上。该算法在以下方面有所不同：
- en: 'A wide range of applications: Can be used to solve regression, classification,
    ranking, and user-defined prediction problems.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 广泛的应用范围：可用于解决回归、分类、排序和用户定义的预测问题。
- en: 'Portability: Runs smoothly on Windows, Linux, and OS X.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可移植性：在 Windows、Linux 和 OS X 上运行流畅。
- en: 'Languages: Supports all major programming languages including C++, Python,
    R, Java, Scala, and Julia.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语言：支持包括 C++、Python、R、Java、Scala 和 Julia 在内的所有主要编程语言。
- en: 'Cloud Integration: Supports AWS, Azure, and Yarn clusters and works well with
    Flink, Spark, and other ecosystems.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 云集成：支持 AWS、Azure 和 Yarn 集群，并与 Flink、Spark 和其他生态系统良好兼容。
- en: How to build an intuition for XGBoost?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何建立对 XGBoost 的直觉？
- en: Decision trees, in their simplest form, are easy-to-visualize and fairly interpretable
    algorithms but building intuition for the next-generation of tree-based algorithms
    can be a bit tricky. See below for a simple analogy to better understand the evolution
    of tree-based algorithms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树在最简单的形式下，易于可视化且相当可解释，但为下一代基于树的算法建立直觉可能有些棘手。请参见下面的简单类比，以更好地理解基于树的算法的演变。
- en: '![](../Images/ce8a0aa4b29d06c2eca8644d430fa0c4.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce8a0aa4b29d06c2eca8644d430fa0c4.png)'
- en: '**Photo by [rawpixel](https://unsplash.com/photos/cnseVhmbA7k?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/interview?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**照片由 [rawpixel](https://unsplash.com/photos/cnseVhmbA7k?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，出处 [Unsplash](https://unsplash.com/search/photos/interview?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**'
- en: Imagine that you are a hiring manager interviewing several candidates with excellent
    qualifications. Each step of the evolution of tree-based algorithms can be viewed
    as a version of the interview process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你是一个招聘经理，正在面试几位资格出色的候选人。基于树的算法的每一步演变都可以被视为面试过程的一个版本。
- en: '**Decision Tree**: Every hiring manager has a set of criteria such as education
    level, number of years of experience, interview performance. A decision tree is
    analogous to a hiring manager interviewing candidates based on his or her own
    criteria.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**决策树**：每个招聘经理都有一套标准，如教育水平、工作经验年限、面试表现。决策树类似于招聘经理根据他或她自己的标准面试候选人。'
- en: '**Bagging**: Now imagine instead of a single interviewer, now there is an interview
    panel where each interviewer has a vote. Bagging or bootstrap aggregating involves
    combining inputs from all interviewers for the final decision through a democratic
    voting process.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Bagging**：现在想象一下，不再是一个面试官，而是一个面试小组，其中每个面试官都有一票。Bagging 或自助聚合涉及通过民主投票过程结合所有面试官的输入来做出最终决策。'
- en: '**Random Forest**: It is a bagging-based algorithm with a key difference wherein
    only a subset of features is selected at random. In other words, every interviewer
    will only test the interviewee on certain randomly selected qualifications (e.g.
    a technical interview for testing programming skills and a behavioral interview
    for evaluating non-technical skills).'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机森林**：这是一种基于 bagging 的算法，其主要区别在于仅随机选择一部分特征。换句话说，每个面试官只会测试面试者某些随机选择的资格（例如，技术面试测试编程技能，行为面试评估非技术技能）。'
- en: '**Boosting**: This is an alternative approach where each interviewer alters
    the evaluation criteria based on feedback from the previous interviewer. This
    ‘boosts’ the efficiency of the interview process by deploying a more dynamic evaluation
    process.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提升**：这是一种替代方法，其中每个面试官根据前一位面试官的反馈调整评估标准。这种方法通过部署更具动态的评估过程来“提升”面试过程的效率。'
- en: '**Gradient Boosting**: A special case of boosting where errors are minimized
    by gradient descent algorithm e.g. the strategy consulting firms leverage by using
    case interviews to weed out less qualified candidates.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**梯度提升**：提升的一种特殊情况，其中通过梯度下降算法最小化错误，例如，战略咨询公司利用案例面试来筛选出不合格的候选人。'
- en: '**XGBoost**: Think of XGBoost as gradient boosting on ‘steroids’ (well it is
    called ‘Extreme Gradient Boosting’ for a reason!). It is a perfect combination
    of software and hardware optimization techniques to yield superior results using
    less computing resources in the shortest amount of time.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**XGBoost**：将XGBoost看作是“增强版”的梯度提升（它被称为‘极端梯度提升’，这是有原因的！）。它是软件和硬件优化技术的完美结合，能够在最短时间内使用较少的计算资源获得卓越的结果。'
- en: Why does XGBoost perform so well?
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么XGBoost表现如此出色？
- en: XGBoost and Gradient Boosting Machines (GBMs) are both ensemble tree methods
    that apply the principle of boosting weak learners ([CARTs](https://www.datasciencecentral.com/profiles/blogs/introduction-to-classification-regression-trees-cart) generally)
    using the gradient descent architecture. However, XGBoost improves upon the base
    GBM framework through systems optimization and algorithmic enhancements.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost和梯度提升机（GBMs）都是集成树方法，利用梯度下降架构应用提升弱学习者（通常是[CARTs](https://www.datasciencecentral.com/profiles/blogs/introduction-to-classification-regression-trees-cart)）。然而，XGBoost通过系统优化和算法增强改进了基础的GBM框架。
- en: '![](../Images/00b082518e586d3d8b79c7b113b1441a.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00b082518e586d3d8b79c7b113b1441a.png)'
- en: '**How XGBoost optimizes standard GBM algorithm**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost如何优化标准GBM算法**'
- en: '**System Optimization:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统优化：**'
- en: '**Parallelization**: XGBoost approaches the process of sequential tree building
    using [parallelized](http://zhanpengfang.github.io/418home.html) This is possible
    due to the interchangeable nature of loops used for building base learners; the
    outer loop that enumerates the leaf nodes of a tree, and the second inner loop
    that calculates the features. This nesting of loops limits parallelization because
    without completing the inner loop (more computationally demanding of the two),
    the outer loop cannot be started. Therefore, to improve run time, the order of
    loops is interchanged using initialization through a global scan of all instances
    and sorting using parallel threads. This switch improves algorithmic performance
    by offsetting any parallelization overheads in computation.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**并行化**：XGBoost在构建树的过程中采用了[并行化](http://zhanpengfang.github.io/418home.html)方法。这是因为用于构建基础学习者的循环具有可交换的性质；外部循环枚举树的叶节点，内部循环计算特征。这种循环嵌套限制了并行化，因为在完成内部循环（计算上更具挑战性）之前，外部循环无法开始。因此，为了提高运行时间，通过对所有实例进行全局扫描和使用并行线程进行排序，来交换循环顺序。这种切换通过抵消计算中的任何并行化开销来提高算法性能。'
- en: '**Tree Pruning:**The stopping criterion for tree splitting within GBM framework
    is greedy in nature and depends on the negative loss criterion at the point of
    split. XGBoost uses ‘max_depth’ parameter as specified instead of criterion first,
    and starts pruning trees backward. This ‘depth-first’ approach improves computational
    performance significantly.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**树剪枝**：GBM框架中的树分裂停止准则本质上是贪婪的，并依赖于分裂点的负损失准则。XGBoost使用指定的‘max_depth’参数，而不是首先使用准则，并开始从后向前剪枝树。这种“深度优先”的方法显著提高了计算性能。'
- en: '**Hardware Optimization**: This algorithm has been designed to make efficient
    use of hardware resources. This is accomplished by cache awareness by allocating
    internal buffers in each thread to store gradient statistics. Further enhancements
    such as ‘out-of-core’ computing optimize available disk space while handling big
    data-frames that do not fit into memory.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**硬件优化**：该算法旨在高效利用硬件资源。这通过缓存感知来实现，即在每个线程中分配内部缓冲区以存储梯度统计数据。进一步的增强措施，如“外部核心”计算，优化了可用的磁盘空间，同时处理那些无法完全载入内存的大数据帧。'
- en: '**Algorithmic Enhancements:**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法增强：**'
- en: '**Regularization**: It penalizes more complex models through both LASSO (L1)
    and Ridge (L2) [regularization](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c)to
    prevent overfitting.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**正则化**：它通过LASSO (L1) 和 Ridge (L2) [正则化](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c)
    来惩罚更复杂的模型，从而防止过拟合。'
- en: '**Sparsity Awareness**: XGBoost naturally admits sparse features for inputs
    by automatically ‘learning’ best missing value depending on training loss and
    handles different types of [sparsity patterns](https://www.kdnuggets.com/2017/10/xgboost-concise-technical-overview.html)in
    the data more efficiently.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**稀疏性意识**：XGBoost自然地接受输入的稀疏特征，通过自动‘学习’最佳的缺失值，依据训练损失，并更有效地处理数据中的不同类型的[sparsity
    patterns](https://www.kdnuggets.com/2017/10/xgboost-concise-technical-overview.html)。'
- en: '**Weighted Quantile Sketch:**XGBoost employs the distributed [weighted Quantile
    Sketch algorithm](https://arxiv.org/pdf/1603.02754.pdf) to effectively find the
    optimal split points among weighted datasets.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加权分位数草图**：XGBoost采用了分布式[加权分位数草图算法](https://arxiv.org/pdf/1603.02754.pdf)来有效地在加权数据集中找到最佳的分裂点。'
- en: '**Cross-validation**: The algorithm comes with built-in [cross-validation](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f)method
    at each iteration, taking away the need to explicitly program this search and
    to specify the exact number of boosting iterations required in a single run.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**交叉验证**：该算法在每次迭代中都内置了[cross-validation](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f)方法，这样就不需要显式地编程进行搜索，也不需要在单次运行中指定确切的提升迭代次数。'
- en: Where is the proof?
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 证据在哪里？
- en: We used Scikit-learn’s ‘[Make_Classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)’
    data package to create a random sample of 1 million data points with 20 features
    (2 informative and 2 redundant). We tested several algorithms such as Logistic
    Regression, Random Forest, standard Gradient Boosting, and XGBoost.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了Scikit-learn的‘[Make_Classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)’
    数据包，创建了一个包含100万数据点的随机样本，具有20个特征（2个信息性特征和2个冗余特征）。我们测试了几种算法，如逻辑回归、随机森林、标准梯度提升和XGBoost。
- en: '![](../Images/f25ea245834fda95344103c725cec06e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f25ea245834fda95344103c725cec06e.png)'
- en: '**XGBoost vs. Other ML Algorithms using SKLearn’s Make_Classification Dataset**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**XGBoost与其他机器学习算法在SKLearn的Make_Classification数据集上的比较**'
- en: As demonstrated in the chart above, XGBoost model has the best combination of
    prediction performance and processing time compared to other algorithms. Other
    rigorous [benchmarking](https://github.com/szilard/benchm-ml) studies have produced
    similar results. No wonder XGBoost is widely used in recent Data Science competitions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，XGBoost模型在预测性能和处理时间方面相比其他算法具有最佳的组合。其他严谨的[基准测试](https://github.com/szilard/benchm-ml)研究也产生了类似的结果。难怪XGBoost在最近的数据科学比赛中被广泛使用。
- en: '*“When in doubt, use XGBoost”**—**Owen Zhang, Winner of [Avito](https://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/) Context
    Ad Click Prediction competition on Kaggle*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*“当有疑问时，使用XGBoost”*—**欧文·张**，Kaggle [Avito](https://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/)
    上的广告点击预测比赛冠军'
- en: So should we use just XGBoost all the time?
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那么我们是否应该一直使用XGBoost？
- en: When it comes to Machine Learning (or even life for that matter), there is no
    free lunch. As Data Scientists, we must test all possible algorithms for data
    at hand to identify the champion algorithm. Besides, picking the right algorithm
    is not enough. We must also choose the right configuration of the algorithm for
    a dataset by tuning the [hyper-parameters](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/).
    Furthermore, there are several other considerations for choosing the winning algorithm
    such as computational complexity, explainability, and ease of implementation.
    This is exactly the point where Machine Learning starts drifting away from science
    towards art, but honestly, that’s where the magic happens!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（甚至生活中），没有免费的午餐。作为数据科学家，我们必须测试所有可能的算法，以找出最佳算法。此外，选择正确的算法还不够。我们还必须通过调整[超参数](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)来为数据集选择正确的算法配置。此外，还有其他因素，如计算复杂性、可解释性和实现的难易程度，这些也是选择获胜算法时需要考虑的。这正是机器学习从科学向艺术转变的地方，但说实话，这也是魔法发生的地方！
- en: What does the future hold?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来会怎样？
- en: Machine Learning is a very active research area and already there are several
    viable alternatives to XGBoost. Microsoft Research recently released [LightGBM](https://www.microsoft.com/en-us/research/project/lightgbm/) framework
    for gradient boosting that shows great potential. [CatBoost](https://catboost.ai/) developed
    by Yandex Technology has been delivering impressive bench-marking results. It
    is a matter of time when we have a better model framework that beats XGBoost in
    terms of prediction performance, flexibility, explanability, and pragmatism. However,
    until a time when a strong challenger comes along, XGBoost will continue to reign
    over the Machine Learning world!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个非常活跃的研究领域，目前已经有几个可行的替代方案来挑战 XGBoost。微软研究院最近发布了 [LightGBM](https://www.microsoft.com/en-us/research/project/lightgbm/)
    框架，用于梯度提升，显示出巨大潜力。 [CatBoost](https://catboost.ai/) 由 Yandex 技术开发，已经提供了令人印象深刻的基准结果。我们何时能够拥有一个更好的模型框架来超越
    XGBoost，取决于预测性能、灵活性、可解释性和实用性。然而，在强有力的挑战者出现之前，XGBoost 将继续在机器学习领域占据主导地位！
- en: '[Original](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d).
    Reposted with permission.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)。已获转载许可。'
- en: '**Bio**: [Vishal Morde](https://www.linkedin.com/in/vishalmorde/) is a seasoned
    executive and transformational leader with 15+ years of progressive experience
    in Data Science, Machine Learning, Artificial Intelligence, Big Data, and Strategic
    Analytics.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介**: [Vishal Morde](https://www.linkedin.com/in/vishalmorde/) 是一位经验丰富的高管和变革性领导者，在数据科学、机器学习、人工智能、大数据和战略分析方面拥有超过
    15 年的渐进经验。'
- en: '**Resources:**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网页的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[XGBoost on GPUs: Unlocking Machine Learning Performance and Productivity](https://www.kdnuggets.com/2018/12/nvidia-xgboost-gpu-machine-learning-performance-productivity.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost 在 GPU 上：释放机器学习性能和生产力](https://www.kdnuggets.com/2018/12/nvidia-xgboost-gpu-machine-learning-performance-productivity.html)'
- en: '[Unveiling Mathematics Behind XGBoost](https://www.kdnuggets.com/2018/08/unveiling-mathematics-behind-xgboost.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 XGBoost 背后的数学](https://www.kdnuggets.com/2018/08/unveiling-mathematics-behind-xgboost.html)'
- en: '[Data Scientist Interviews Demystified](https://www.kdnuggets.com/2018/08/data-scientist-interviews-demystified.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家面试揭秘](https://www.kdnuggets.com/2018/08/data-scientist-interviews-demystified.html)'
- en: '* * *'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How to Speed Up XGBoost Model Training](https://www.kdnuggets.com/2021/12/speed-xgboost-model-training.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何加速 XGBoost 模型训练](https://www.kdnuggets.com/2021/12/speed-xgboost-model-training.html)'
- en: '[What are the Assumptions of XGBoost?](https://www.kdnuggets.com/2022/08/assumptions-xgboost.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost 的假设是什么？](https://www.kdnuggets.com/2022/08/assumptions-xgboost.html)'
- en: '[Tuning XGBoost Hyperparameters](https://www.kdnuggets.com/2022/08/tuning-xgboost-hyperparameters.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调优 XGBoost 超参数](https://www.kdnuggets.com/2022/08/tuning-xgboost-hyperparameters.html)'
- en: '[Leveraging XGBoost for Time-Series Forecasting](https://www.kdnuggets.com/2023/08/leveraging-xgboost-timeseries-forecasting.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 XGBoost 进行时间序列预测](https://www.kdnuggets.com/2023/08/leveraging-xgboost-timeseries-forecasting.html)'
- en: '[WTF is the Difference Between GBM and XGBoost?](https://www.kdnuggets.com/wtf-is-the-difference-between-gbm-and-xgboost)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GBM 和 XGBoost 之间的区别是什么？](https://www.kdnuggets.com/wtf-is-the-difference-between-gbm-and-xgboost)'
- en: '[Classifying Long Text Documents Using BERT](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 BERT 对长文本进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
