- en: Micro, Macro & Weighted Averages of F1 Score, Clearly Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: F1分数的微观、宏观和加权平均值，清晰解释
- en: 原文：[https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html](https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html](https://www.kdnuggets.com/2023/01/micro-macro-weighted-averages-f1-score-clearly-explained.html)
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/429ec3fe3106393e90ce45f6d2ffc16a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![F1分数的微观、宏观和加权平均值，清晰解释](../Images/429ec3fe3106393e90ce45f6d2ffc16a.png)'
- en: Image by Author and [Freepik](https://www.freepik.com/vectors/people)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片和[Freepik](https://www.freepik.com/vectors/people)
- en: The F1 score (aka F-measure) is a popular metric for evaluating the performance
    of a classification model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数（也称F度量）是评估分类模型性能的常用指标。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In the case of multi-class classification, we adopt **averaging **methods for
    F1 score calculation, resulting in a **set of different average scores **(macro,
    weighted, micro) in the classification report.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在多类别分类的情况下，我们采用**平均**方法来计算F1分数，从而在分类报告中得到一**组不同的平均分数**（宏观、加权、微观）。
- en: This article looks at the meaning of these averages, **how **to calculate them,
    and **which **one to choose for reporting.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文讨论了这些平均值的含义，**如何**计算它们，以及**选择**哪个来进行报告。
- en: (1) Recap of the Basics (Optional)
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: （1）基础知识回顾（可选）
- en: '*Note: Skip this section if you are already familiar with the concepts of precision,
    recall, and F1 score.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：如果你已经对精确率、召回率和F1分数的概念很熟悉，可以跳过这一部分。*'
- en: Precision
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确率
- en: '**Layman definition**: Of all the positive predictions I made, how many of
    them are truly positive?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**通俗定义：** 在我做出的所有正例预测中，有多少是真正的正例？'
- en: '**Calculation**: Number of True Positives (TP) divided by the Total Number
    of True Positives (TP) **and **False Positives (FP).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算：** 真正例数（TP）除以真正例数（TP）**和**假阳性（FP）的总数。'
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/fbad1874c80df06600a6f5c9e98d8ad1.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![F1分数的微观、宏观和加权平均值，清晰解释](../Images/fbad1874c80df06600a6f5c9e98d8ad1.png)'
- en: The equation for precision | Image by author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 精确率的公式 | 作者图片
- en: Recall
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 召回率
- en: '**Layman definition:** Of all the actual positive examples out there, how many
    of them did I correctly predict to be positive?'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**通俗定义：** 在所有实际的正例中，我正确预测为正例的有多少？'
- en: '**Calculation: **Number of True Positives (TP) divided by the Total Number
    of True Positives (TP) **and **False Negatives (FN).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算：** 真正例数（TP）除以真正例数（TP）**和**假阴性（FN）的总数。'
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/72f898eb906c2538341b2e6949326d34.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![F1分数的微观、宏观和加权平均值，清晰解释](../Images/72f898eb906c2538341b2e6949326d34.png)'
- en: The equation for Recall | Image by author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率的公式 | 作者图片
- en: If you compare the formula for precision and recall, you will notice both look
    similar. The only difference is the second term of the denominator, where it is
    False Positive for **precision **but False Negative for **recall**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你比较精确率和召回率的公式，你会发现它们看起来很相似。唯一的不同是分母的第二项，对于**精确率**是假阳性，对于**召回率**是假阴性。
- en: F1 Score
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: F1分数
- en: To evaluate model performance comprehensively, we should examine **both** precision
    and recall. The F1 score serves as a helpful metric that considers both of them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估模型性能，我们应该检查**精确率**和召回率。F1分数作为一个有用的指标，考虑了这两者。
- en: '**Definition**: Harmonic mean of precision and recall for a more balanced summarization
    of model performance.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**：精确率和召回率的调和均值，用于更平衡地总结模型性能。'
- en: '**Calculation:**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算：**'
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/1fb705ac44e1cdcd4e3b59c4ad5efd8f.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/1fb705ac44e1cdcd4e3b59c4ad5efd8f.png)'
- en: The equation for F1 score | Image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数的方程 | 图片由作者提供
- en: 'If we express it in terms of True Positive (TP), False Positive (FP), and False
    Negative (FN), we get this equation:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用真正例（TP）、假正例（FP）和假负例（FN）来表示，我们会得到这个方程：
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/66f6333a5a25fca51e30b8e003655ea6.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/66f6333a5a25fca51e30b8e003655ea6.png)'
- en: The alternative equation for F1 score | Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数的另一种方程 | 图片由作者提供
- en: (2) Setting the Motivating Example
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (2) 设置动机示例
- en: To illustrate the concepts of averaging F1 scores, we will use the following
    example in the context of this tutorial.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 F1 分数的平均概念，我们将在本教程中使用以下示例。
- en: Imagine we have trained an **image classification model** on a **multi-class** dataset
    containing images of **three** classes: **A**irplane, **B**oat, and **C**ar.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们已经在一个包含**三**类图像的**多类**数据集上训练了一个**图像分类模型**：**飞机**、**船**和**汽车**。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/a39c452d77a57fd6c727198407488983.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/a39c452d77a57fd6c727198407488983.png)'
- en: Image by [macrovector](https://www.freepik.com/vectors/car) — [freepik.com](https://www.freepik.com/)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [macrovector](https://www.freepik.com/vectors/car) 提供 — [freepik.com](https://www.freepik.com/)
- en: 'We use this model to **predict **the classes of **ten **test set images. Here
    are the **raw predictions**:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个模型来**预测****十**个测试集图像的类别。以下是**原始预测**：
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/fd1fe5cfbe0c7580455c468d239ecd41.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/fd1fe5cfbe0c7580455c468d239ecd41.png)'
- en: Sample predictions of our demo classifier | Image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的演示分类器的样本预测 | 图片由作者提供
- en: 'Upon running `sklearn.metrics.classification_report`, we get the following
    classification report:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`sklearn.metrics.classification_report`后，我们得到以下分类报告：
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/c0219f91435f7f9618f852e1071256a5.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/c0219f91435f7f9618f852e1071256a5.png)'
- en: '[Classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) from
    scikit-learn package | Image by author'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[分类报告](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)来自
    scikit-learn 包 | 图片由作者提供'
- en: The columns (in orange) with the **per-class** scores (i.e., score for each
    class) and **average **scores are the focus of our discussion.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论的重点是带有**每类**分数（即每个类别的分数）和**平均**分数的列（橙色）。
- en: We can see from the above that the dataset is **imbalanced **(only one out of
    ten test set instances is ‘Boat’). Thus the **proportion of correct matches** (aka
    accuracy) would be ineffective in assessing model performance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面可以看出，数据集是**不平衡的**（十个测试集实例中只有一个是“船”）。因此，**正确匹配的比例**（即准确率）在评估模型性能时将无效。
- en: Instead, let us look at the **confusion matrix** for a holistic understanding
    of the model predictions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，让我们查看**混淆矩阵**以全面理解模型预测。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/959f27e63613d2f0af126e8b908c968b.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/959f27e63613d2f0af126e8b908c968b.png)'
- en: Confusion matrix | Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵 | 图片由作者提供
- en: The confusion matrix above allows us to compute the critical values of True
    Positive (**TP**), False Positive (**FP**), and False Negative (**FN**), as shown
    below.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的混淆矩阵使我们能够计算真正例（**TP**）、假正例（**FP**）和假负例（**FN**）的关键值，如下所示。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/21e7f5ec5267ad67577b9b0b7479a2fa.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均，清晰解释](../Images/21e7f5ec5267ad67577b9b0b7479a2fa.png)'
- en: Calculated TP, FP, and FN values from confusion matrix | Image by author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从混淆矩阵中计算的 TP、FP 和 FN 值 | 图片由作者提供
- en: The above table sets us up nicely to compute the **per-class** values of **precision**, **recall**,
    and F1 score for each of the three classes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 上表为我们计算每个三类中的**每类**的**精确度**、**召回率**和 F1 分数奠定了基础。
- en: It is important to remember that in **multi-class classification, we calculate
    the F1 score for each class in a One-vs-Rest (OvR) **approach instead of a single
    overall F1 score, as seen in binary classification.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，在**多类分类中，我们计算每个类别的 F1 分数，采用一对其余（OvR）**的方法，而不是像二分类那样计算一个整体的 F1 分数。
- en: 'In this **OvR** approach, we determine the metrics for each class separately,
    as if there is a different classifier for each class. Here are the per-class metrics
    (with the F1 score calculation displayed):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种**OvR**方法中，我们分别为每个类别确定指标，就好像每个类别都有一个不同的分类器。以下是每个类别的指标（显示了 F1 分数的计算）：
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/fefe4e9cd2fc0860c7ed3deda30a9fa0.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/fefe4e9cd2fc0860c7ed3deda30a9fa0.png)'
- en: However, instead of having multiple per-class F1 scores, it would be better
    to **average **them to obtain a **single number** to describe overall performance.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与其有多个每类 F1 分数，不如**平均**它们以获得一个**单一数字**来描述总体性能。
- en: Now, let’s discuss the **averaging **methods that led to the classification
    report’s **three different average F1 scores**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论**平均**方法，这些方法导致了分类报告中的**三种不同的平均 F1 分数**。
- en: (3) Macro Average
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (3) 宏观平均
- en: '**Macro averaging **is perhaps the most straightforward among the numerous
    averaging methods.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**宏观平均**可能是所有平均方法中最简单的。'
- en: The macro-averaged F1 score (or macro F1 score) is computed using the arithmetic
    mean (aka **unweighted **mean) of all the per-class F1 scores.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 宏观平均 F1 分数（或宏观 F1 分数）是通过所有每个类别 F1 分数的算术平均（即**未加权**平均）计算得出的。
- en: This method treats all classes equally regardless of their **support **values.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法对所有类别一视同仁，无论其**支持度**值如何。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/091a97df9f500a20cc42f3972ef5ebf1.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/091a97df9f500a20cc42f3972ef5ebf1.png)'
- en: Calculation of macro F1 score | Image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 宏观 F1 分数计算 | 图片来源于作者
- en: The value of **0.58** we calculated above matches the macro-averaged F1 score
    in our classification report.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算得到的**0.58**与我们的分类报告中的宏观平均 F1 分数相匹配。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/4354a5d171fd59135b7937ce8b39e5cf.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/4354a5d171fd59135b7937ce8b39e5cf.png)'
- en: (4) Weighted Average
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (4) 加权平均
- en: The **weighted-averaged **F1 score is calculated by taking the mean of all per-class
    F1 scores **while considering each class’s support**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权平均** F1 分数是通过计算所有类别的 F1 分数的平均值来得到的，**同时考虑每个类别的支持度**。'
- en: S**upport** refers to the number of actual occurrences of the class in the dataset.
    For example, the support value of 1 in **Boat **means that there is only one observation
    with an actual label of Boat.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**支持度**指的是数据集中该类别的实际出现次数。例如，**船**的支持度值为 1 意味着只有一个实际标签为船的观察。'
- en: The ‘weight’ essentially refers to the proportion of each class’s support relative
    to the sum of all support values.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: “权重”本质上是指每个类别的支持度相对于所有支持度值总和的比例。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/bb2a60a3bf772ffeeb36194a081d256a.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/bb2a60a3bf772ffeeb36194a081d256a.png)'
- en: Calculation of weighted F1 score | Image by author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 加权 F1 分数计算 | 图片来源于作者
- en: With weighted averaging, the output average would have accounted for the contribution
    of each class as weighted by the number of examples of that given class.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加权平均，输出的平均值将考虑到每个类别按该类别示例数加权的贡献。
- en: The calculated value of **0.64** tallies with the weighted-averaged F1 score
    in our classification report.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 计算得到的**0.64**与我们分类报告中的加权平均 F1 分数一致。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/9f64f540f8c00419559e2c3c88dec20c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/9f64f540f8c00419559e2c3c88dec20c.png)'
- en: (5) Micro Average
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (5) 微观平均
- en: Micro averaging computes a **global average **F1 score by counting the **sums** of
    the True Positives (**TP**), False Negatives (**FN**), and False Positives (**FP**).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 微观平均通过计算真实正例（**TP**）、假阴性（**FN**）和假正例（**FP**）的**总和**来计算**全局平均**F1 分数。
- en: We first sum the respective TP, FP, and FN values across all classes and then
    plug them into the F1 equation to get our micro F1 score.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将所有类别的 TP、FP 和 FN 值相加，然后将这些值代入 F1 方程，得到我们的微观 F1 分数。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/f3b285964495c2f053936aea18dc8cd1.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![F1 分数的微观、宏观和加权平均值，清晰解释](../Images/f3b285964495c2f053936aea18dc8cd1.png)'
- en: Calculation of micro F1 score | Image by author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 微观 F1 分数计算 | 图片来源于作者
- en: In the classification report, you might be wondering why our micro F1 score
    of **0.60** is displayed as ‘accuracy’ and why there is **NO row stating **‘**micro
    avg’**.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类报告中，你可能会想知道为什么我们的微观F1分数**0.60**显示为“准确率”，以及为什么没有**‘微观平均’**的行。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/95d3d34f2a58f129eaa75d2c68809b1b.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![F1分数的微观、宏观和加权平均，清晰解释](../Images/95d3d34f2a58f129eaa75d2c68809b1b.png)'
- en: This is because micro-averaging essentially computes the **proportion **of **correctly
    classified** observations out of all observations. If we think about this, this
    definition is what we use to calculate overall **accuracy**.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为微观平均本质上计算的是**正确分类**观察结果在所有观察结果中的**比例**。如果我们考虑这一点，这一定义就是我们用来计算整体**准确率**的标准。
- en: Furthermore, if we were to do micro-averaging for precision and recall, we would
    get the same value of **0.60**.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们对精确率和召回率进行微观平均，我们将得到相同的**0.60**值。
- en: '![Micro, Macro & Weighted Averages of F1 Score, Clearly Explained](../Images/b78fea2ad253da1945d2811318d06069.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![F1分数的微观、宏观和加权平均，清晰解释](../Images/b78fea2ad253da1945d2811318d06069.png)'
- en: Calculation of all micro-averaged metrics | Image by author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 所有微观平均指标的计算 | 作者提供的图像
- en: These results mean that in multi-class classification cases where each observation
    has a **single label**, the **micro-F1**, **micro-precision**, **micro-recall,** and **accuracy **share
    the **same **value (i.e.,** 0.60** in this example).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果意味着，在每个观察结果只有**单一标签**的多类别分类情况下，**微观-F1**、**微观精确率**、**微观召回率**和**准确率**共享**相同**的值（即，本示例中的**0.60**）。
- en: And this explains why the classification report **only needs to display a single
    accuracy value** since micro-F1, micro-precision, and micro-recall also have the
    same value.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这也解释了为什么分类报告**只需要显示一个准确率值**，因为微观-F1、微观精确率和微观召回率也有相同的值。
- en: '**micro-F1 **= accuracy = micro-precision = micro-recall'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**微观-F1** = 准确率 = 微观精确率 = 微观召回率'
- en: (6) Which Average should I choose?
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (6) 我应该选择哪种平均方式？
- en: In general, if you are working with an imbalanced dataset where all classes
    are equally important, using the **macro **average would be a good choice as it
    treats all classes equally.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，如果你在处理一个类别不平衡的数据集，其中所有类别同样重要，使用**宏观**平均将是一个不错的选择，因为它对所有类别一视同仁。
- en: It means that for our example involving the classification of airplanes, boats,
    and cars, we would use the macro-F1 score.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，对于我们涉及飞机、船只和汽车分类的示例，我们将使用宏观-F1分数。
- en: If you have an imbalanced dataset but want to assign greater contribution to
    classes with more examples in the dataset, then the **weighted **average is preferred.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个不平衡的数据集，但希望对数据集中样本更多的类别赋予更大的贡献，那么**加权**平均是首选。
- en: This is because, in weighted averaging, the contribution of each class to the
    F1 average is weighted by its size.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为，在加权平均中，每个类别对F1平均值的贡献是根据其大小加权的。
- en: Suppose you have a balanced dataset and want an easily understandable metric
    for overall performance regardless of the class. In that case, you can go with
    accuracy, which is essentially our **micro** F1 score.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个平衡的数据集，并且希望得到一个易于理解的整体性能指标，不论类别如何，那么你可以选择准确率，这本质上是我们的**微观**F1分数。
- en: Before You Go
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在你离开之前
- en: I welcome you to** join me on a data science learning journey!** Follow my [Medium](https://kennethleungty.medium.com/) page
    and check out my [GitHub](https://github.com/kennethleungty) to stay in the loop
    of more exciting data science content. Meanwhile, have fun interpreting F1 scores!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我欢迎你**加入我的数据科学学习之旅！** 关注我的[Medium](https://kennethleungty.medium.com/)页面，并查看我的[GitHub](https://github.com/kennethleungty)以获取更多令人兴奋的数据科学内容。同时，祝你在解释F1分数时玩得愉快！
- en: '**[Kenneth Leung](https://www.linkedin.com/in/kennethleungty/)** is data scientist
    at Boston Consulting Group (BCG), and technical writer, and pharmacist.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kenneth Leung](https://www.linkedin.com/in/kennethleungty/)** 是波士顿咨询集团（BCG）的数据科学家、技术作者和药剂师。'
- en: '[Original](https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f).
    Reposted with permission.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/micro-macro-weighted-averages-of-f1-score-clearly-explained-b603420b292f)。经允许转载。'
- en: More On This Topic
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[7 Free Kaggle Micro-Courses for Data Science Beginners](https://www.kdnuggets.com/7-free-kaggle-micro-courses-for-data-science-beginners)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7个免费的Kaggle微课程，适合数据科学初学者](https://www.kdnuggets.com/7-free-kaggle-micro-courses-for-data-science-beginners)'
- en: '[Database Key Terms, Explained](https://www.kdnuggets.com/2016/07/database-key-terms-explained.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据库关键术语解释](https://www.kdnuggets.com/2016/07/database-key-terms-explained.html)'
- en: '[Descriptive Statistics Key Terms, Explained](https://www.kdnuggets.com/2017/05/descriptive-statistics-key-terms-explained.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[描述性统计关键术语解析](https://www.kdnuggets.com/2017/05/descriptive-statistics-key-terms-explained.html)'
- en: '[Decision Tree Algorithm, Explained](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树算法解析](https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html)'
- en: '[Key-Value Databases, Explained](https://www.kdnuggets.com/2021/04/nosql-explained-understanding-key-value-databases.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[键值数据库解析](https://www.kdnuggets.com/2021/04/nosql-explained-understanding-key-value-databases.html)'
- en: '[Gaussian Naive Bayes, Explained](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯朴素贝叶斯解析](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
