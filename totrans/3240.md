# 机器学习翻译和谷歌翻译算法

> 原文：[https://www.kdnuggets.com/2017/09/machine-learning-translation-google-translate-algorithm.html](https://www.kdnuggets.com/2017/09/machine-learning-translation-google-translate-algorithm.html)

**作者：Daniil Korbut，[Statsbot](https://statsbot.co/)。**

![](../Images/ad62fc7c2ba75d845ae4835dea932f43.png)

[谷歌机器翻译](https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的 IT

* * *

每天我们使用不同的技术，却未必知道它们究竟是如何工作的。事实上，理解由机器学习驱动的引擎并不容易。* [Statsbot](http://statsbot.co/?utm_source=kdnuggets)团队希望通过在这个博客中讲述数据故事来让机器学习变得清晰。今天，我们决定深入探讨机器翻译器，并解释谷歌翻译算法是如何工作的。*

几年前，将文本从未知语言翻译过来是非常耗时的。使用简单的词汇逐字翻译很困难，有两个原因：1）读者必须了解语法规则；2）需要在翻译整句话时记住所有语言版本。

现在，我们不需要如此费劲地挣扎——我们可以通过将短语、句子甚至大型文本放入 Google 翻译中来完成翻译。但是大多数人实际上并不关心机器学习翻译的引擎如何工作。本文是为那些关心的人准备的。

### **深度学习翻译问题**

如果 Google 翻译引擎尝试保留甚至短句的翻译，它将无法工作，因为可能的变体数量巨大。最好的方法可能是教计算机一组语法规则，并根据这些规则翻译句子。只要这听起来如此简单就好了。

如果你曾经尝试学习外语，你知道总会有很多规则的例外。当我们尝试在程序中捕捉所有这些规则、例外以及例外的例外时，翻译质量会下降。

> *现代机器翻译系统使用不同的方法：通过分析大量文档来分配文本中的规则。*

创建你自己的简单机器翻译器将是[**任何数据科学简历上的一个很棒的项目**](https://blog.statsbot.co/data-scientist-resume-projects-806a74388ae6?utm_source=kdnuggets)。

让我们尝试调查一下我们称之为机器翻译器的“黑箱”里隐藏了什么。深度神经网络可以在非常复杂的任务（如语音/视觉对象识别）中取得出色的结果，但尽管它们具有灵活性，它们只能应用于输入和目标具有固定维度的任务。

### **递归神经网络**

这时，长短期记忆网络（LSTM）就派上用场了，帮助我们处理长度无法事先知道的序列。

LSTM是一种特殊类型的递归神经网络（RNN），能够学习长期依赖关系。所有RNN看起来像是一个重复模块的链条。

![](../Images/6de3d1247fc0c6dd19b6126f28c69ff1.png)

[展开的递归神经网络](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

因此，LSTM将数据从一个模块传输到另一个模块，例如，在生成Ht时，我们不仅使用Xt，还使用所有之前的输入值X。要了解有关LSTM结构和数学模型的更多信息，你可以阅读那篇精彩的文章“[理解LSTM网络](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)”。

### **双向RNN**

我们的下一步是双向递归神经网络（BRNNs）。BRNN的作用是将普通RNN的神经元分成两个方向。一个方向是正时间，或前向状态。另一个方向是负时间，或后向状态。这两个状态的输出不会连接到对面方向状态的输入。

![](../Images/c632cea579cb40f348be6066dbe1e821.png)

[双向递归神经网络](https://www.semanticscholar.org/paper/Hybrid-speech-recognition-with-Deep-Bidirectional-Graves-Jaitly/5807664af8e63d5207f59fb263c9e7bd3673be79)

要理解为什么BRNN可能比简单的RNN表现更好，可以想象我们有一个9个单词的句子，我们想预测第5个单词。我们可以让它只知道前4个单词，或者知道前4个单词和最后4个单词。当然，第二种情况下的质量会更好。

### **序列到序列**

现在我们准备转向序列到序列模型（也称为seq2seq）。基本的seq2seq模型由两个RNN组成：一个编码器网络处理输入，一个解码器网络生成输出。

![](../Images/4a829f9839b0211cdd633e5c69373cec.png)

[序列到序列模型](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

最终，我们可以制作出我们的第一个机器翻译器！

不过，让我们想一个技巧。谷歌翻译 [目前支持103种语言](https://www.newscientist.com/article/2114748-google-translate-ai-invents-its-own-language-to-translate-with/)，所以我们应该为每对语言有103x102个不同的模型。当然，这些模型的质量因语言的普及程度和训练该网络所需的文档量而异。我们能做的最好的就是制作一个神经网络，接受任何语言作为输入，并翻译成任何语言。

### **Google翻译**

这个想法在[2016年底被谷歌工程师实现](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)。NN的架构基于seq2seq模型，我们已经研究过这个模型。

唯一的例外是编码器和解码器之间有8层LSTM-RNN，这些层之间有残差连接，并且在准确性和速度上做了一些调整。如果你想深入了解，查看文章[Google的神经机器翻译系统](https://arxiv.org/abs/1609.08144)。

> 这种方法的主要特点是现在Google翻译算法只使用一个系统，而不是每对语言都使用一个庞大的集合。

系统在输入句子开头需要一个“令牌”，指定你想要翻译成的语言。

这提高了翻译质量，并使得即使在系统之前未见过的两种语言之间进行翻译成为可能，这种方法称为“零样本翻译”。

### **什么是更好的翻译？**

当我们谈论Google翻译算法的改进和更好结果时，我们如何正确评估第一个翻译候选是否优于第二个？

这不是一个简单的问题，因为对于一些常用的句子，我们有来自专业翻译人员的参考翻译集合，当然这些翻译之间有一些差异。

有很多方法部分解决了这个问题，但最受欢迎和有效的指标是[BLEU](https://en.wikipedia.org/wiki/BLEU)（双语评估了解）。想象一下，我们有两个来自机器翻译的候选：

> 候选 1: Statsbot 使公司可以通过自然语言轻松地密切监控来自各种分析平台的数据。
> 
> 候选 2: Statsbot 使用自然语言准确分析来自不同分析平台的业务指标。

![](../Images/a812122e97cb432b115267962b8ead35.png)

虽然它们有相同的意思，但它们在质量上有所不同，结构也不同。

我们来看看两个人工翻译：

> 参考翻译 1: Statsbot 通过自然语言帮助公司密切监控来自不同分析平台的数据。
> 
> 参考翻译 2: Statsbot 允许公司通过自然语言仔细监控来自各种分析平台的数据。

显然，候选 1 更好，包含比候选 2 更多的单词和短语。这是简单BLEU方法的关键思想。我们可以比较候选翻译的[n-grams](https://en.wikipedia.org/wiki/N-gram)与参考翻译的n-grams，并计算匹配次数（不论位置）。我们只使用n-gram准确率，因为在有多个参考翻译的情况下计算召回率较为困难，结果是n-gram分数的几何平均值。

现在你可以评估机器学习翻译的复杂引擎。下次当你使用 Google 翻译时，想象一下它分析了多少百万份文档才给出最好的语言版本。

**个人简介：[Daniil Korbut](https://medium.com/@daniilkorbut)** 是 [Statsbot](https://statsbot.co/) 的初级数据科学家。

[原文](https://blog.statsbot.co/machine-learning-translation-96f0ed8f19e4)。经授权转载。

**相关：**

+   [深度学习和 NLP 中的注意力与记忆](/2016/01/attention-memory-deep-learning-nlp.html)

+   [顶级 /r/MachineLearning 帖子，五月：深度图像类比；风格化面部动画；谷歌开源 Sketch-RNN](/2017/06/top-reddit-machine-learning-posts-may.html)

+   [5 个免费的资源，帮助你开始深度学习自然语言处理](/2017/07/5-free-resources-getting-started-deep-learning-nlp.html)

### 更多相关内容

+   [OpenAI 的 Whisper API 用于转录和翻译](https://www.kdnuggets.com/2023/06/openai-whisper-api-transcription-translation.html)

+   [如何使用 MarianMT 和 Hugging Face Transformers 进行语言翻译](https://www.kdnuggets.com/how-to-translate-languages-with-marianmt-and-hugging-face-transformers)

+   [用 AI 读取思维：研究人员将脑电波翻译成图像](https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html)

+   [将机器学习算法完全端到端地部署到…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)

+   [解锁选择完美机器学习算法的秘密！](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)

+   [机器学习中的 DBSCAN 聚类算法](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)
