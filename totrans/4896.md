# 入门TensorFlow：机器学习教程

> 原文：[https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html](https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2017/12/getting-started-tensorflow.html/2#comments)

**由[Dino Causevic](https://www.toptal.com/resume/dino-causevic)，Toptal**。

TensorFlow是Google创建的一个开源软件库，用于实现机器学习和深度学习系统。这两个名称包含一系列强大的算法，它们面临一个共同的挑战——使计算机能够自动发现复杂模式和/或做出最佳决策。

如果你对这些系统的细节感兴趣，可以通过Toptal博客文章了解更多关于[机器学习](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)和[深度学习](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)的信息。

![](../Images/6e3b08444cb7bdaecec1e430278822de.png)

TensorFlow的核心是一个数据流编程库。它利用各种优化技术来简化数学表达式的计算，并提高性能。

TensorFlow的一些关键特性包括：

+   高效处理涉及多维数组的数学表达式

+   良好的深度神经网络和机器学习概念支持

+   GPU/CPU计算，其中相同的代码可以在这两种架构上执行

+   高度可扩展的跨机器计算和巨大的数据集

这些特性使TensorFlow成为生产规模的机器智能的完美框架。

在本TensorFlow教程中，你将学习如何使用简单而强大的机器学习方法，并如何利用一些辅助库来调试、可视化和调整使用TensorFlow创建的模型。

**安装TensorFlow**

我们将使用TensorFlow Python API，它适用于Python 2.7和Python 3.3+。GPU版本（仅限Linux）需要Cuda Toolkit 7.0+和cuDNN v2+。

我们将使用Conda包依赖管理系统来安装TensorFlow。Conda允许我们在一台机器上分离多个环境。你可以从[这里](https://conda.io/docs/user-guide/install/index.html)学习如何安装Conda。

在安装了Conda后，我们可以创建一个用于TensorFlow安装和使用的环境。以下命令将创建我们的环境，并添加一些附加库，如[NumPy](https://www.numpy.org/)，在开始使用TensorFlow时非常有用。

在此环境中安装的Python版本为2.7，我们将在本文中使用该版本。

```py
conda create --name TensorflowEnv biopython
```

*为了简单起见，我们在这里安装 biopython，而不仅仅是 NumPy。这包括 NumPy 和我们需要的一些其他包。你可以在需要时使用 `conda install` 或 `pip install` 命令来安装这些包。*

以下命令将激活创建的 Conda 环境。我们将能够使用其中安装的包，而不与全局或其他环境中安装的包混合。

```py
source activate TensorFlowEnv
```

pip 安装工具是 Conda 环境的标准部分。我们将用它来安装 TensorFlow 库。在此之前，第一步是更新 pip 到最新版本，使用以下命令：

```py
pip install --upgrade pip
```

现在我们准备通过运行以下命令来安装 TensorFlow：

```py
pip install tensorflow
```

TensorFlow 的下载和构建可能需要几分钟。编写时，这将安装 TensorFlow 1.1.0。

**数据流图**

在 TensorFlow 中，计算是通过数据流图描述的。图的每个节点表示一个数学操作的实例（如加法、除法或乘法），每条边是一个多维数据集（张量），这些操作在其上执行。

![](../Images/1a9f8cab43009efda34fad441f236123.png)

由于 TensorFlow 使用计算图，它们在每个节点表示一个操作的实例，每个操作有零个或多个输入和零个或多个输出。

TensorFlow 中的边缘可以分为两类：普通边缘传输数据结构（张量），可能一个操作的输出成为另一个操作的输入，和特殊边缘，用于控制两个节点之间的依赖关系，设置操作的顺序，其中一个节点等待另一个完成。

**简单表达式**

在我们继续讨论 TensorFlow 的元素之前，我们将首先进行一个 TensorFlow 的会话，以了解 TensorFlow 程序的样子。

让我们从简单的表达式开始，假设出于某种原因，我们想要以 TensorFlow 的方式评估函数 `y = 5*x + 13`。

在简单的 Python 代码中，它会像这样：

```py
x = -2.0
y = 5*x + 13
print y
```

在这种情况下，这给我们带来了 3.0 的结果。

现在我们将把上述表达式转换为 TensorFlow 术语。

**常量**

在 TensorFlow 中，常量是通过 `constant` 函数创建的，其签名为 `constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`，其中 `value` 是将用于进一步计算的实际常量值，`dtype` 是数据类型参数（例如，float32/64、int8/16 等），`shape` 是可选维度，`name` 是张量的可选名称，最后一个参数是一个布尔值，指示是否验证值的形状。

如果你需要在训练模型中使用具有特定值的常量，可以使用 `constant` 对象，如下例所示：

```py
z = tf.constant(5.2, name="x", dtype=tf.float32)
```

**变量**

TensorFlow 中的变量是内存中的缓冲区，包含需要显式初始化并在图中使用的张量，以保持状态跨会话。通过简单地调用构造函数，变量被添加到计算图中。

变量在开始训练模型时特别有用，它们用于保存和更新参数。作为构造函数参数传递的初始值表示一个张量或对象，可以转换或返回为张量。这意味着如果我们希望用一些预定义或随机值填充一个变量，然后在训练过程中使用并在迭代中更新，我们可以按如下方式定义它：

```py
k = tf.Variable(tf.zeros([1]), name="k")
```

在 TensorFlow 中使用变量的另一种方式是在计算中，该变量不是可训练的，可以按如下方式定义：

```py
k = tf.Variable(tf.add(a, b), trainable=False)
```

**会话**

为了实际评估节点，我们必须在会话中运行计算图。

会话封装了 TensorFlow 运行时的控制和状态。没有参数的会话将使用当前会话中创建的默认图，否则会话类接受一个图参数，该参数在会话中用于执行。

以下是一个简要的代码片段，展示了如何在 TensorFlow 中使用上述定义的术语来计算一个简单的线性函数。

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init)
    print session.run(y)

```

**使用 TensorFlow：定义计算图**

使用数据流图的好处在于执行模型与其执行（在 CPU、GPU 或某种组合上）是分开的，一旦实现，TensorFlow 中的软件可以在 CPU 或 GPU 上使用，所有与代码执行相关的复杂性都被隐藏。

计算图可以在使用 TensorFlow 库的过程中构建，而无需显式实例化 [Graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph) 对象。

在 TensorFlow 中，可以通过像 `c = tf.add(a, b)` 这样的简单代码行来创建 Graph 对象。这将创建一个操作节点，该节点接受两个张量 `a` 和 `b`，并将它们的和 `c` 作为输出。

计算图是一个内置过程，利用库进行操作，而无需直接调用 [graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph) 对象。TensorFlow 中的图对象包含一组操作和张量作为数据单元，操作之间使用该对象，这允许相同的过程，并且包含多个图，每个图将分配给不同的会话。例如，简单的代码行 `c = tf.add(a, b)` 将创建一个操作节点，该节点接受两个张量 `a` 和 `b` 作为输入，并产生它们的和 `c` 作为输出。

TensorFlow 还提供了一个馈送机制，用于将张量补丁到图中的任何操作，其中馈送用张量值替换操作的输出。馈送数据作为参数传递给 `run()` 函数调用。

占位符是 TensorFlow 允许开发者通过占位符将数据注入计算图中的一种方式，占位符被绑定在某些表达式中。占位符的签名是：

```py
placeholder(dtype, shape=None, name=None)
```

其中 `dtype` 是张量中元素的类型，可以提供张量的形状和操作的名称。

如果未传递形状，该张量可以用任何形状的数据进行填充。一个重要的注意事项是，占位符张量必须被填充数据，否则，在执行会话时，如果该部分缺失，占位符会生成如下结构的错误：

```py
InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype float
```

占位符的优点在于，它们允许开发者创建操作和计算图，而无需提前提供数据，数据可以在运行时从外部来源添加。

让我们以 TensorFlow 的方式乘以两个整数 `x` 和 `y` 为简单问题，其中将使用占位符并通过会话 `run` 方法进行数据喂入。

```py
import tensorflow as tf

x = tf.placeholder(tf.float32, name="x")
y = tf.placeholder(tf.float32, name="y")

z = tf.multiply(x, y, name="z")

with tf.Session() as session:
    print session.run(z, feed_dict={x: 2.1, y: 3.0})

```

**使用 TensorBoard 可视化计算图**

TensorBoard 是一个用于分析数据流图的可视化工具。这对于更好地理解机器学习模型非常有用。

使用 TensorBoard，你可以深入了解关于参数的不同类型的统计信息以及计算图各部分的细节。深度神经网络中有大量节点并不罕见。TensorBoard 允许开发者洞察每个节点及其在 TensorFlow 运行时上的计算执行情况。

![](../Images/48d7c35fa2fff56b5635fa7bdf908e1c.png)

现在让我们回到 TensorFlow 教程开始时的示例，我们定义了一个线性函数，其格式为 `y = a*x + b`。

为了从会话中记录事件，后续可以在 TensorBoard 中使用，TensorFlow 提供了 `FileWriter` 类。它可以用来创建用于存储 [摘要](https://www.tensorflow.org/api_guides/python/summary) 和 [事件](https://www.tensorflow.org/api_docs/python/tf/Event) 的事件文件，其构造函数接受六个参数，如下所示：

```py
__init__(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None)
```

其中 `logdir` 参数是必需的，其他参数有默认值。图形参数将从在训练程序中创建的会话对象中传递。完整的示例代码如下：

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    merged = tf.summary.merge_all() // new
    writer = tf.summary.FileWriter("logs", session.graph) // new

    session.run(init)
    print session.run(y)
```

我们仅添加了两行新代码。我们合并了在默认图形中收集的所有摘要，`FileWriter` 用于将事件写入文件，如上所述。

运行程序后，我们在目录 logs 中会得到一个文件，最后一步是运行 `tensorboard`：

```py
tensorboard --logdir logs/
```

现在 TensorBoard 已启动并运行在默认端口 6006\. 打开 https://localhost:6006 并点击页面顶部的 Graphs 菜单项，你将能看到图形，如下图所示：

![](../Images/d7def7e0a9ba10e06df3f474264fe157.png)

TensorBoard 标记常量和摘要节点的特定符号，下面对此进行了描述。

![](../Images/f39a2398dc314d85d44d6734a1ae94b9.png)

**使用 TensorFlow 进行数学运算**

张量是 TensorFlow 中的基本数据结构，它们表示数据流图中的连接边。

张量只是标识一个多维数组或列表。张量结构可以通过三个参数来识别：秩、形状和类型。

+   秩：识别张量的维度数量。秩也称为张量的阶数或 n 维度，例如秩为 1 的张量是一个向量，秩为 2 的张量是一个矩阵。

+   形状：张量的形状是指它的行数和列数。

+   类型：分配给张量元素的数据类型。

要在 TensorFlow 中构建一个张量，我们可以构建一个 n 维数组。这可以通过使用 NumPy 库轻松完成，或者通过将 Python n 维数组转换为 TensorFlow 张量来实现。

![](../Images/54429bdf3b195d6b7305c5e32546eff4.png)

要构建一个 1 维张量，我们将使用 NumPy 数组，这将通过传递一个内置的 Python 列表来构造。

```py
import numpy as np
tensor_1d = np.array([1.45, -1, 0.2, 102.1])
```

使用这种数组与使用内置的 Python 列表类似。主要区别在于 NumPy 数组还包含一些额外的属性，如维度、形状和类型。

```py
>> print tensor_1d
[   1.45   -1\.      0.2   102.1 ]

>> print tensor_1d[0]
1.45

>> print tensor_1d[2]
0.2

>> print tensor_1d.ndim
1

>> print tensor_1d.shape
(4,)

>> print tensor_1d.dtype
float64

```

NumPy 数组可以通过辅助函数 [convert_to_tensor](https://www.tensorflow.org/versions/master/api_docs/python/tf/convert_to_tensor) 轻松转换为 TensorFlow 张量，该函数帮助开发人员将 Python 对象转换为张量对象。该函数接受张量对象、NumPy 数组、Python 列表和 Python 标量。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
```

现在如果我们将张量绑定到 TensorFlow 会话中，我们将能够看到转换的结果。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)

with tf.Session() as session:
    print session.run(tensor)
    print session.run(tensor[0])
    print session.run(tensor[1])

```

输出：

```py
[   1.45   -1\.      0.2   102.1 ]
1.45
-1.0

```

我们可以以类似的方式创建一个 2 维张量或矩阵：

```py
tensor_2d = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_1 = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_2 = np.array(np.random.rand(4, 4), dtype='float32')

m1 = tf.convert_to_tensor(tensor_2d)
m2 = tf.convert_to_tensor(tensor_2d_1)
m3 = tf.convert_to_tensor(tensor_2d_2)
mat_product = tf.matmul(m1, m2)
mat_sum = tf.add(m2, m3)
mat_det = tf.matrix_determinant(m3)

with tf.Session() as session:
    print session.run(mat_product)
    print session.run(mat_sum)
    print session.run(mat_det)

```

**张量操作**

在上面的示例中，我们介绍了对向量和矩阵进行的一些 TensorFlow 操作。这些操作对张量执行某些计算。具体是哪些计算在下表中显示。

上表中列出的 TensorFlow 操作作用于张量对象，并且是逐元素执行的。因此，如果你想计算向量 x 的余弦，TensorFlow 操作将对传递的张量中的每个元素进行计算。

```py
tensor_1d = np.array([0, 0, 0])
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
with tf.Session() as session:
    print session.run(tf.cos(tensor))

```

输出：

```py
[ 1\.  1\.  1.]

```

**矩阵运算**

矩阵操作对于机器学习模型非常重要，例如线性回归，因为它们在这些模型中经常使用。TensorFlow 支持所有最常见的矩阵操作，如 [矩阵乘法](https://www.tensorflow.org/versions/master/api_docs/python/tf/matmul)、[转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、[求逆](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_inverse)、计算 [行列式](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_determinant)、求解 [线性方程](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_solve) 以及 [更多](https://www.tensorflow.org/versions/master/api_guides/python/math_ops#Matrix_Math_Functions)。

接下来，我们将解释一些矩阵操作。当涉及到机器学习模型时，它们通常非常重要，例如在线性回归中。让我们编写一些代码，进行基本的矩阵操作，如乘法、获取 [转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、获取行列式、乘法、解线性方程等。

以下是调用这些操作的基本示例。

```py
import tensorflow as tf
import numpy as np

def convert(v, t=tf.float32):
    return tf.convert_to_tensor(v, dtype=t)

m1 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m2 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m3 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m4 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m5 = convert(np.array(np.random.rand(4, 4), dtype='float32'))

m_tranpose = tf.transpose(m1)
m_mul = tf.matmul(m1, m2)
m_det = tf.matrix_determinant(m3)
m_inv = tf.matrix_inverse(m4)
m_solve = tf.matrix_solve(m5, [[1], [1], [1], [1]])

with tf.Session() as session:
    print session.run(m_tranpose)
    print session.run(m_mul)
    print session.run(m_inv)
    print session.run(m_det)
    print session.run(m_solve)

```

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 需求

* * *

### 更多相关内容

+   [联邦学习：协作机器学习教程…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)

+   [入门 Scikit-learn 用于机器学习中的分类](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)

+   [入门自动化文本摘要](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)

+   [入门数据清理](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)

+   [入门 SQL 备忘单](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)

+   [入门 spaCy 用于自然语言处理](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
