- en: 'Email Spam Filtering: An Implementation with Python and Scikit-learn'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 电子邮件垃圾邮件过滤：使用 Python 和 Scikit-learn 的实现
- en: 原文：[https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html](https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html](https://www.kdnuggets.com/2017/03/email-spam-filtering-an-implementation-with-python-and-scikit-learn.html)
- en: '**By [Machine Learning in Action](https://appliedmachinelearning.wordpress.com/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Machine Learning in Action](https://appliedmachinelearning.wordpress.com/).**'
- en: '![Spam filter](../Images/b8a1b609f29a3b8d8f5000f853ad551f.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![垃圾邮件过滤器](../Images/b8a1b609f29a3b8d8f5000f853ad551f.png)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT 事务'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Text mining (deriving information from text) is a wide field which has gained
    popularity with the huge text data being generated. Automation of a number of
    applications like sentiment analysis, document classification, topic classification,
    text summarization, machine translation, etc has been done using machine learning
    models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 文本挖掘（从文本中提取信息）是一个广泛的领域，随着大量文本数据的生成而获得了普及。许多应用程序的自动化，如情感分析、文档分类、主题分类、文本摘要、机器翻译等，已经通过机器学习模型实现。
- en: Spam filtering is a beginner’s example of document classification task which
    involves classifying an email as spam or non-spam (a.k.a. ham) mail. Spam box
    in your Gmail account is the best example of this. So lets get started in building
    a spam filter on a publicly available mail corpus. I have extracted equal number
    of spam and non-spam emails from [Ling-spam corpus](http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz).
    The extracted subset on which we will be working can be downloaded from [here](https://www.dropbox.com/s/yjiplngoa430rid/).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件过滤是一个初学者的文档分类任务示例，它涉及将电子邮件分类为垃圾邮件或非垃圾邮件（也称为正常邮件）。你的 Gmail 帐户中的垃圾邮件箱是最好的例子。所以，让我们开始在公开的邮件语料库上构建垃圾邮件过滤器。我已经从
    [Ling-spam 语料库](http://www.aueb.gr/users/ion/data/lingspam_public.tar.gz) 中提取了相等数量的垃圾邮件和非垃圾邮件。我们将使用的提取子集可以从
    [这里](https://www.dropbox.com/s/yjiplngoa430rid/) 下载。
- en: 'We will walk through the following steps to build this application :'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤来构建这个应用程序：
- en: Preparing the text data.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备文本数据。
- en: Creating word dictionary.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建词典。
- en: Feature extraction process
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征提取过程
- en: Training the classifier
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练分类器
- en: Further, we will check the results on test set of the subset created.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将检查在创建的子集上的测试集结果。
- en: 1\. Preparing the text data.
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 准备文本数据。
- en: The data-set used here, is split into a training set and a test set containing
    702 mails and 260 mails respectively, divided equally between spam and ham mails.
    You will easily recognize spam mails as it contains *spmsg* in its filename.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的数据集被分成了一个包含 702 封邮件的训练集和一个包含 260 封邮件的测试集，两者在垃圾邮件和正常邮件之间均等分配。你可以很容易地识别垃圾邮件，因为它的文件名中包含
    *spmsg*。
- en: 'In any text mining problem, text cleaning is the first step where we remove
    those words from the document which may not contribute to the information we want
    to extract. Emails may contain a lot of undesirable characters like punctuation
    marks, stop words, digits, etc which may not be helpful in detecting the spam
    email. The emails in Ling-spam corpus have been already preprocessed in the following
    ways:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何文本挖掘问题中，文本清理是第一步，我们会从文档中移除那些可能对我们要提取的信息没有贡献的词汇。电子邮件可能包含许多不必要的字符，如标点符号、停用词、数字等，这些在检测垃圾邮件时可能没有帮助。Ling-spam
    语料库中的电子邮件已经通过以下方式进行了预处理：
- en: a) Removal of stop words – Stop words like “and”, “the”, “of”, etc are very
    common in all English sentences and are not very meaningful in deciding spam or
    legitimate status, so these words have been removed from the emails.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: a) 停用词的移除 – 停用词如“and”、“the”、“of”等在所有英语句子中都非常常见，在决定垃圾邮件或合法状态时并不太有意义，因此这些词已从邮件中移除。
- en: b) Lemmatization – It is the process of grouping together the different inflected
    forms of a word so they can be analysed as a single item. For example, “include”,
    “includes,” and “included” would all be represented as “include”. The context
    of the sentence is also preserved in lemmatization as opposed to stemming (another
    buzz word in text mining which does not consider meaning of the sentence).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: b) 词形还原 – 这是将一个词的不同变形形式归为一类，以便将其作为单个项进行分析的过程。例如，“include”、“includes”和“included”都会被表示为“include”。与词干提取（另一种文本挖掘中的流行词，未考虑句子意义）不同，词形还原也会保留句子的上下文。
- en: We still need to remove the non-words like punctuation marks or special characters
    from the mail documents. There are several ways to do it. Here, we will remove
    such words after creating a dictionary, which is a very convenient method to do
    so since when you have a dictionary, you need to remove every such word only once.
    So cheers !! As of now you don’t need to do anything.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然需要从邮件文档中删除诸如标点符号或特殊字符等非单词。有几种方法可以做到这一点。在这里，我们将在创建字典后删除这些单词，这是一种非常方便的方法，因为有了字典后，你只需要删除每个这样的单词一次。所以，干杯！！到目前为止，你无需做任何事情。
- en: 2\. Creating word dictionary.
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2. 创建词典。
- en: 'A sample email in the data-set looks like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中一个示例邮件如下所示：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It can be seen that the first line of the mail is subject and the 3rd line contains
    the body of the email. We will only perform text analytics on the content to detect
    the spam mails. As a first step, we need to create a dictionary of words and their
    frequency. For this task, training set of 700 mails is utilized. This python function
    creates the dictionary for you.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看到，邮件的第一行是主题，第`3`行包含邮件正文。我们将仅对内容进行文本分析，以检测垃圾邮件。作为第一步，我们需要创建一个单词及其频率的字典。为此任务，使用了`700`封邮件的训练集。这个Python函数会为你创建字典。
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once the dictionary is created we can add just a few lines of code written below
    to the above function to remove non-words about which we talked in step 1\. I
    have also removed absurd single characters in the dictionary which are irrelevant
    here. Do not forget to insert the below code in the function `def make_Dictionary(train_dir)`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦字典创建完成，我们可以在上述函数中添加几行代码，以删除我们在第1步中讨论的非单词。我还删除了字典中那些无关的荒谬单字符。不要忘记将下面的代码插入到`def
    make_Dictionary(train_dir)`函数中。
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Dictionary can be seen by the command `print dictionary`. You may find some
    absurd word counts to be high but don’t worry, it’s just a dictionary and you
    always have the scope of  improving it later. If you are following this blog with
    provided data-set, make sure your dictionary has some of the entries given below
    as most frequent words. Here I have chosen 3000 most frequently used words in
    the dictionary.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过命令`print dictionary`查看字典。你可能会发现一些荒谬的词频很高，但不用担心，这只是一个字典，你总有机会在之后改进它。如果你正在使用提供的数据集来跟随这个博客，请确保你的字典中包含下面列出的最常见词汇。我在字典中选择了`3000`个最常用的单词。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 3\. Feature extraction process.
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3. 特征提取过程。
- en: Once the dictionary is ready, we can extract word count vector (our feature
    here) of 3000 dimensions for each email of training set. Each **word count vector**
    contains the frequency of 3000 words in the training file. Of course you might
    have guessed by now that most of them will be zero. Let us take an example. Suppose
    we have 500 words in our dictionary. Each word count vector contains the frequency
    of 500 dictionary words in the training file. Suppose text in training file was
    “Get the work done, work done” then it will be encoded as [0,0,0,0,0,…….0,0,2,0,0,0,……,0,0,1,0,0,…0,0,1,0,0,……2,0,0,0,0,0].
    Here, all the word counts are placed at 296th, 359th, 415th, 495th index of 500
    length word count vector and the rest are zero.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦字典准备好，我们可以为训练集中的每封邮件提取`3000`维的词频向量（我们的特征）。每个**词频向量**包含训练文件中`3000`个单词的频率。当然你现在可能已经猜到，大多数词频会是零。让我们举个例子。假设我们的字典中有`500`个单词。每个词频向量包含训练文件中`500`个字典单词的频率。假设训练文件中的文本是“Get
    the work done, work done”，那么它将被编码为[0,0,0,0,0,…….0,0,2,0,0,0,……,0,0,1,0,0,…0,0,1,0,0,……2,0,0,0,0,0]。在这里，所有词频都放在`500`长度词频向量的第`296`、`359`、`415`、`495`个索引处，其余为零。
- en: The below python code will generate a feature vector matrix whose rows denote
    700 files of training set and columns denote 3000 words of dictionary. The value
    at index ‘*ij’* will be the number of occurrences of j^(th) word of dictionary
    in i^(th) file.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的python代码将生成一个特征向量矩阵，其中行表示700个训练集文件，列表示3000个词典中的单词。索引‘*ij*’的值将是词典中第j^(th)个单词在第i^(th)个文件中出现的次数。
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 4\. Training the classifiers.
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 训练分类器。
- en: Here, I will be using [scikit-learn ML library](http://scikit-learn.org/stable/)
    for training classifiers. It is an open source python ML library which comes bundled
    in 3rd party distribution [anaconda](https://www.continuum.io/downloads) or can
    be used by separate installation following [this](http://scikit-learn.org/stable/install.html).
    Once installed, we only need to import it in our program.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将使用[scikit-learn ML库](http://scikit-learn.org/stable/)来训练分类器。它是一个开源的python
    ML库，可以在第三方分发包[anaconda](https://www.continuum.io/downloads)中找到，也可以通过[这个](http://scikit-learn.org/stable/install.html)单独安装。安装完成后，我们只需在程序中导入即可。
- en: I have trained two models here namely Naive Bayes classifier and Support Vector
    Machines (SVM). Naive Bayes classifier is a conventional and very popular method
    for document classification problem. It is a supervised probabilistic classifier
    based on Bayes theorem assuming independence between every pair of features. SVMs
    are supervised binary classifiers which are very effective when you have higher
    number of features. The goal of SVM is to separate some subset of training data
    from rest called the support vectors (boundary of separating hyper-plane). The
    decision function of SVM model that predicts the class of the test data is based
    on support vectors and makes use of a kernel trick.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里训练了两个模型，即朴素贝叶斯分类器和支持向量机（SVM）。朴素贝叶斯分类器是一种传统且非常流行的文档分类方法。它是一种基于贝叶斯定理的有监督概率分类器，假设每对特征之间相互独立。SVM是一种有监督的二元分类器，当特征数量较多时非常有效。SVM的目标是将训练数据的某个子集与其他数据分开，这些数据被称为支持向量（分隔超平面的边界）。SVM模型的决策函数基于支持向量，并利用了核技巧来预测测试数据的类别。
- en: Once the classifiers are trained, we can check the performance of the models
    on test-set. We extract word count vector for each mail in test-set and predict
    its class(ham or spam) with the trained NB classifier and SVM model. Below is
    the full code for spam filtering application. You have to include the two functions
    we have defined before in step 2 and step 3.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦分类器训练完成，我们可以检查模型在测试集上的表现。我们提取测试集中每封邮件的词频向量，并用训练好的NB分类器和SVM模型预测其类别（ham或spam）。下面是完整的垃圾邮件过滤应用代码。你需要在第2步和第3步中包含我们定义的两个函数。
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Checking Performance
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能检查
- en: Test-set contains 130 spam emails and 130 non-spam emails. If you have come
    so far, you will find below results. I have shown the confusion matrix of the
    test-set for both the models. The diagonal elements represents the correctly identified(a.k.a.
    true identification) mails where as non-diagonal elements represents wrong classification
    (false identification) of mails.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集包含130封垃圾邮件和130封非垃圾邮件。如果你读到这里，你会看到下面的结果。我展示了两个模型的测试集混淆矩阵。对角线元素表示正确识别（即真实识别）的邮件，而非对角线元素表示错误分类（虚假识别）的邮件。
- en: '| Multinomial NB | Ham | Spam |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| Multinomial NB | Ham | Spam |'
- en: '| Ham | 129 | 1 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Ham | 129 | 1 |'
- en: '| Spam | 9 | 121 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Spam | 9 | 121 |'
- en: '| SVM(Linear) | Ham | Spam |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| SVM(Linear) | Ham | Spam |'
- en: '| Ham | 126 | 4 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| Ham | 126 | 4 |'
- en: '| Spam | 6 | 124 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Spam | 6 | 124 |'
- en: Both the models had similar performance on the test-set except that the SVM
    has slightly balanced false identifications. I must remind you that the test data
    was neither used in creating dictionary nor in the training set.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 两个模型在测试集上的表现类似，只是SVM在错误识别方面稍微平衡了一些。我必须提醒你，测试数据既没有用于创建词典，也没有用于训练集。
- en: Task for you
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务
- en: Download the pre-processed form of [Euron-spam](http://www.aueb.gr/users/ion/data/enron-spam/)
    corpus. The corpus contains 33716 emails in 6 directories. Each of 6 directories
    contains ‘ham’ and ‘spam’ folders. Total number of non-spam emails and spam emails
    are 16545 and 17171 respectively.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下载[Euron-spam](http://www.aueb.gr/users/ion/data/enron-spam/)语料库的预处理版本。该语料库包含33716封电子邮件，分布在6个目录中。每个目录包含‘ham’和‘spam’文件夹。非垃圾邮件和垃圾邮件的总数分别为16545封和17171封。
- en: Follow the same steps described in this blog post and check how is it performing
    with Support Vector Machines and Multinomial Naive Bayes models. As the directory
    structure of this corpus is different than the directory structure of ling-spam
    subset used in the blog post, you may have to either reorganize it or do modifications
    in `def make_Dictionary(dir)` and `def extract_features(dir)`functions.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 按照本博客文章中描述的步骤操作，检查使用支持向量机和多项式朴素贝叶斯模型的表现。由于这个语料库的目录结构与博客文章中使用的ling-spam子集的目录结构不同，你可能需要重新组织它或修改`def
    make_Dictionary(dir)`和`def extract_features(dir)`函数。
- en: I divided the Euron-spam corpus into training set and test set in 60:40 split.
    After performing the same steps of this blog, i got the following results on 13487 test
    set emails. We can see that SVM has performed slightly better than Naive Bayes
    classifier in detecting spam emails correctly.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我将Euron-spam语料库划分为60:40的训练集和测试集。在执行了本博客中的相同步骤后，我在13487个测试集邮件上得到了以下结果。我们可以看到，SVM在正确检测垃圾邮件方面的表现略优于朴素贝叶斯分类器。
- en: '| Multinomial NB | Ham | Spam |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 多项式NB | Ham | Spam |'
- en: '| Ham | 6445 | 225 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Ham | 6445 | 225 |'
- en: '| Spam | 137 | 6680 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| Spam | 137 | 6680 |'
- en: '| SVM(Linear) | Ham | Spam |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| SVM(线性) | Ham | Spam |'
- en: '| Ham | 6490 | 180 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Ham | 6490 | 180 |'
- en: '| Spam | 109 | 6708 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Spam | 109 | 6708 |'
- en: Final Thoughts
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终思考
- en: Hope it was easy to go through tutorial as I have tried to keep it short and
    simple. Beginners who are interested in text analytics can start with this application.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你觉得这个教程易于理解，因为我尽量保持简洁明了。对文本分析感兴趣的初学者可以从这个应用开始。
- en: You might be thinking about the mathematical techniques behind the used models
    like Naive Bayes and SVM. SVM is mathematically complex model where as Naive bayes
    is relatively easy to understand. You are encouraged to study about these models
    from online sources. Apart from that, there can be a lot of experiments that can
    be done in order to find the effect of various parameters like
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在考虑使用的模型（如朴素贝叶斯和SVM）背后的数学技术。SVM是一个数学上复杂的模型，而朴素贝叶斯相对容易理解。建议你从在线资源中学习这些模型。此外，还可以进行很多实验，以找出不同参数的效果，比如
- en: a) Amount of training data
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: a) 训练数据量
- en: b) Dictionary size
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: b) 字典大小
- en: c) Variants of the ML techniques used (GaussianNB, BernoulliNB, SVC)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用的机器学习技术的变体（GaussianNB, BernoulliNB, SVC）
- en: d) Fine tuning of parameters of SVM models
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: d) 对SVM模型参数的微调
- en: e) Improving the dictionary by eliminating insignificant words (may be manually)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: e) 通过去除无关词汇来改进字典（可能需要手动进行）
- en: f) Some other feature (look for td-idf)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: f) 其他特征（查找td-idf）
- en: I will be writing the mathematical explanation about these models in some another
    blog-posts some other time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我将会在一些其他的博客文章中撰写关于这些模型的数学解释。
- en: You can get the full python implementation for both the corpus from GitHub link
    [here](https://github.com/abhijeet3922/Mail-Spam-Filtering).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从GitHub链接[这里](https://github.com/abhijeet3922/Mail-Spam-Filtering)获取这两个语料库的完整Python实现。
- en: If you liked the post, follow this blog to get updates about upcoming articles.
    Also, share it so that it can reach out to the readers who can actually gain from
    this. Please feel free to discuss anything regarding the post. I would love to
    hear feedback from you.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，关注本博客以获取即将发布的文章更新。同时，分享它，让更多读者看到。请随时讨论任何与这篇文章相关的内容。我很乐意听取你的反馈。
- en: Happy machine learning!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你机器学习愉快！
- en: '**[Machine Learning in Action](https://appliedmachinelearning.wordpress.com/)**
    is a perfect hands-on practice for beginners to elevate their ML skills.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**[机器学习实践](https://appliedmachinelearning.wordpress.com/)** 是一个完美的入门实践，适合初学者提升其机器学习技能。'
- en: '[Original](https://appliedmachinelearning.wordpress.com/2017/01/23/email-spam-filter-python-scikit-learn/).
    Reposted with permission.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://appliedmachinelearning.wordpress.com/2017/01/23/email-spam-filter-python-scikit-learn/)。经许可转载。'
- en: '**Related:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Working With Numpy Matrices: A Handy First Reference](/2017/03/working-numpy-matrices.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[与Numpy矩阵的操作：一个实用的初步参考](/2017/03/working-numpy-matrices.html)'
- en: '[A Simple XGBoost Tutorial Using the Iris Dataset](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用鸢尾花数据集的简单XGBoost教程](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
- en: '[K-Means & Other Clustering Algorithms: A Quick Intro with Python](/2017/03/k-means-clustering-algorithms-intro-python.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[K-Means与其他聚类算法：Python快速入门](/2017/03/k-means-clustering-algorithms-intro-python.html)'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Cutting Down Implementation Time by Integrating Jupyter and KNIME](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过集成 Jupyter 和 KNIME 来缩短实现时间](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)'
- en: '[First Open Source Implementation of DeepMind’s AlphaTensor](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepMind 的 AlphaTensor 首个开源实现](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)'
- en: '[5 Ways of Filtering Python Lists](https://www.kdnuggets.com/2022/11/5-ways-filtering-python-lists.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[过滤 Python 列表的 5 种方法](https://www.kdnuggets.com/2022/11/5-ways-filtering-python-lists.html)'
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
- en: '[Five Ways to do Conditional Filtering in Pandas](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中进行条件过滤的五种方法](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
- en: '[Understanding Python''s Iteration and Membership: A Guide to…](https://www.kdnuggets.com/understanding-pythons-iteration-and-membership-a-guide-to-__contains__-and-__iter__-magic-methods)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解 Python 的迭代与成员关系：__contains__ 和 __iter__ 魔法方法指南](https://www.kdnuggets.com/understanding-pythons-iteration-and-membership-a-guide-to-__contains__-and-__iter__-magic-methods)'
