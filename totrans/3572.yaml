- en: Deploying Your Machine Learning Model to Production in the Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/deploying-your-ml-model-to-production-in-the-cloud](https://www.kdnuggets.com/deploying-your-ml-model-to-production-in-the-cloud)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/1e861fd70865beb9a9381204e5f7026a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: '[AWS](https://aws.amazon.com/), or Amazon Web Services, is a cloud computing
    service used in many businesses for storage, analytics, applications, deployment
    services, and many others. It’s a platform utilizes several services to support
    business in a serverless way with pay-as-you-go schemes.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning modeling activity is also one of the activities that AWS supports.
    With several services, modeling activities can be supported, such as developing
    the model to making it into production. AWS has shown versatility, which is essential
    for any business that needs scalability and speed.
  prefs: []
  type: TYPE_NORMAL
- en: This article will discuss deploying a machine learning model in the AWS cloud
    into production. How could we do that? Let’s explore further.
  prefs: []
  type: TYPE_NORMAL
- en: Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you start this tutorial, you need to create an [AWS account](https://aws.amazon.com/console/),
    as we would need them to access all the AWS services. I assume that the reader
    would use the free tier to follow this article.  Additionally, I assume the reader
    already knows how to use Python programming language and has basic knowledge of
    machine learning.  Also, we will focus on the model deployment part and will not
    concentrate on other aspects of data science activity, such as data preprocessing
    and model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, we will start our journey of deploying your machine learning
    model in the AWS Cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: Model Deployment on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we will develop a machine-learning model to predict churn
    from the given data. The training dataset is acquired from Kaggle, which you can
    download [here](https://www.kaggle.com/datasets/barun2104/telecom-churn).
  prefs: []
  type: TYPE_NORMAL
- en: After we have acquired the dataset, we would create an S3 bucket to store the
    dataset. Search the S3 in the AWS services and make the bucket.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/4affd00bab5b37b371e49957a8eb32a0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I named the bucket “telecom-churn-dataset” and located in Singapore.
    You can change them if you want, but let’s go with this one for now.
  prefs: []
  type: TYPE_NORMAL
- en: After you have finished creating the bucket and uploading the data into your
    bucket, we will go to the AWS SageMaker service. In this service, we will use
    the Studio as our working environment. If you have never used the Studio, let’s
    create a domain and user before proceeding further.
  prefs: []
  type: TYPE_NORMAL
- en: First, choose the Domains within the Amazon SageMaker Admin configurations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/e65adacfad77518b7230915749acd823.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: In the Domains, you would see a lot of buttons to select. In this screen, select
    the Create domain button.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/2a839fc8efc6a8cfdf3a7ae6923346e3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Choose the quick setup if you want to speed up the creation process. After it’s
    finished, you should see a new domain created in the dashboard. Select the new
    domain you just created and then click the Add user button.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/a2d6060267cadaa03283d6caf33c1e72.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Next, you should name the user profile according to your preferences. For the
    execution role, you can leave it on default for now, as it’s the one that was
    created during the Domain creation process.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/d0c99f07042ee8754192e490c95b1ea1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Just click next until the canvas setting. In this section, I turn off several
    settings that we don’t need, such as Time Series Forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: After everything is set, go to the studio selection and select the Open studio
    button with the user name you just created.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/635aed46417a557eef597bcd440e2088.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Inside the Studio, navigate to the sidebar that looks like a folder icon and
    create a new notebook there. We can let them by default, like the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/10195e96acbf8431c222d69699afa4c6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: With the new notebook, we would work to create a churn prediction model and
    deploy the model into API inferences that we can use in production.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s import the necessary package and read the churn data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/6073082e1c9837c4a283fb49aa7ac600.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would split the data above into training data and testing data with
    the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We set the test data to be 30% of the original data. With our data split, we
    would upload them back into the S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can see the data inside your S3 bucket, which currently consists of three
    different datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/4fb0d26593d2545b8fc6d4c8281e066a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: With our dataset ready, we would now develop a churn prediction model and deploy
    them. In the AWS, we often use a script training method for machine learning training.
    That’s why we would develop a script before starting the training.
  prefs: []
  type: TYPE_NORMAL
- en: For the next step, we need to create an additional Python file, which I called
    train.py, in the same folder.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/9a3a29ebfad3c876de8d737a3ae9ffaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Inside this file, we would set our model development process to create the churn
    model. For this tutorial, I would adopt some code from [Ram Vegiraju](https://github.com/RamVegiraju/SageMaker-Deployment/blob/master/RealTime/Script-Mode/Sklearn/Regression/train.py).
  prefs: []
  type: TYPE_NORMAL
- en: First, we would import all the necessary packages for developing the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next, we would use the parser method to control the variable that we can input
    into our training process. The overall code that we would put in our script to
    train our model is in the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly,  we need to put four different functions that SageMaker requires to
    make inferences: *model_fn, input_fn, output_fn, and predict_fn*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With our script ready, we would run the training process. In the next step,
    we would pass the script we created above into the SKLearn estimator. This estimator
    is a Sagemaker object that would handle the entire training process, and we would
    only need to pass all the parameters similar to the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If the training is successful, you will end up with the following report.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/51aed0b6446c9ca5ba4169af08b2d691.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: If you want to check the Docker image for the SKLearn training and your model
    artifact location, you can access them using the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: With the model in place, we would then deploy the model into an API endpoint
    that we can use for prediction. To do that, we can use the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If the deployment is successful, the model endpoint is created, and you can
    access it to create a prediction. You can also see the endpoint in the Sagemaker
    dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying Your ML Model to Production in the Cloud](../Images/18bdd21a081c4864693e74c607b01ce0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can now make predictions with this endpoint. To do that, you can test the
    endpoint with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Congratulation. You have now successfully deployed your model in the AWS Cloud.
    After you have finished the testing process, don’t forget to clean up the endpoint.
    You can use the following code to do that.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Don’t forget to shut down the instance you use and clean up the S3 storage if
    you don’t need it anymore.
  prefs: []
  type: TYPE_NORMAL
- en: For further reading, you can read more about the [SKLearn estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/index.html)
    and [Batch Transform inferences](https://sagemaker-examples.readthedocs.io/en/latest/sagemaker_batch_transform/introduction_to_batch_transform/batch_transform_pca_dbscan_movie_clusters.html)
    if you prefer to not have an endpoint model.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AWS Cloud platform is a multi-purpose platform that many companies use to support
    their business. One of the services often used is for data analytic purposes,
    especially model production. In this article, we learn to use AWS SageMaker and
    how to deploy the model into the endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Feature Store Summit 2023: Practical Strategies for Deploying ML…](https://www.kdnuggets.com/2023/09/hopsworks-feature-store-summit-2023-practical-strategies-deploying-ml-models-production-environments)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deploying Your First Machine Learning Model](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tips & Tricks of Deploying Deep Learning Webapp on Heroku Cloud](https://www.kdnuggets.com/2021/12/tips-tricks-deploying-dl-webapps-heroku.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Basics Bonus Week: Deploying to the Cloud](https://www.kdnuggets.com/back-to-basics-bonus-week-deploying-to-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Managing Model Drift in Production with MLOps](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
