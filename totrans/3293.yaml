- en: The Practical Importance of Feature Selection
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择的实际重要性
- en: 原文：[https://www.kdnuggets.com/2017/06/practical-importance-feature-selection.html](https://www.kdnuggets.com/2017/06/practical-importance-feature-selection.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/06/practical-importance-feature-selection.html](https://www.kdnuggets.com/2017/06/practical-importance-feature-selection.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: If you wanted to classify animals, for example, based on a plethora of relevant
    collected data, you would quickly find that all sorts of potential data attributes,
    or features, were relatively unhelpful for classification. For example, given
    that most living creatures have precisely 1 heart, this particular feature would
    not be beneficial, from a learning perspective. On the other hand, an attribute
    denoting whether or not a given animal is hoofed would likely be a powerful predictor.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你想根据大量收集到的相关数据来分类动物，你会迅速发现各种潜在的数据属性或特征对分类相对无用。例如，鉴于大多数生物都有一个心脏，从学习角度来看，这个特征不会有帮助。另一方面，表示某个动物是否有蹄的属性可能是一个强有力的预测因子。
- en: Further, using all of these irrelevant attributes, mixed in with the powerful
    predictors, may actually have a negative effect on the resulting model. This is
    to say nothing of the increased training times that may come along with the inclusion
    of useless attributes, or the overfitting which may occur on the training data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用所有这些与强预测因子混杂的无关属性，实际上可能对结果模型产生负面影响。更不用说包含无用属性可能带来的训练时间增加，或在训练数据上可能发生的过拟合。
- en: 'Feature selection is the process of narrowing down a subset of features, or
    attributes, to be used in the predictive modeling process. Feature selection is
    useful on a variety of fronts: it is the best weapon against the Curse of Dimensionality;
    it can reduce overall training times; and it is a powerful defense against overfitting,
    increasing model generalizability.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择是缩小用于预测建模过程中的特征或属性子集的过程。特征选择在多个方面都很有用：它是对抗维度灾难的最佳武器；它可以减少整体训练时间；同时也是对抗过拟合的强大防御，提高模型的泛化能力。
- en: 'Something I read recently -- [written so eloquently and concisely](https://www.linkedin.com/feed/update/urn:li:activity:6257288156043890688/)
    by data scientist [Rubens Zimbres](https://www.linkedin.com/in/rubens-zimbres/)
    -- alludes to the importance of feature selection from a practical standpoint:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近读到的一篇文章 -- [由数据科学家 [Rubens Zimbres](https://www.linkedin.com/in/rubens-zimbres/)
    以非常优雅和简洁的方式撰写](https://www.linkedin.com/feed/update/urn:li:activity:6257288156043890688/)
    -- 提到了从实际角度看特征选择的重要性：
- en: 'After some experiences, using stacked neural nets, parallel neural nets, asymmetric
    configs, simple neural nets, multiple layers, dropouts, activation functions etc
    there is one conclusion: There''s NOTHING like a good Feature Selection.'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 经过一些经验，使用堆叠神经网络、并行神经网络、不对称配置、简单神经网络、多层、丢弃、激活函数等，得出的一个结论是：没有什么比良好的特征选择更重要。
- en: 'Having had some previous professional contacts with Rubens Zimbres in the past,
    I reached out to him for some elaboration. He provided the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于之前与 Rubens Zimbres 有过一些专业联系，我向他寻求了一些详细说明。他提供了如下内容：
- en: Feature selection should be one of the main concerns for a Data Scientist. Accuracy
    and generalization power can be leveraged by a correct feature selection, based
    in correlation, skewness, t-test, ANOVA, entropy and information gain.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特征选择应该是数据科学家的主要关注点之一。通过正确的特征选择，可以利用相关性、偏度、t 检验、ANOVA、熵和信息增益来提高准确性和泛化能力。
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Many times a correct feature selection allows you to develop simpler and faster
    Machine Learning models. Consider the picture below (Support Vector Machine classification
    of the IRIS dataset): on the left side a wrong variable selection is presented.
    The linear kernel cannot handle the classification task properly, neither the
    radial basis function kernel. On the right side, petal width and petal length
    were selected as features and even the linear kernel is quite accurate. A correct
    variable selection, a good algorithm choice and hyperparameter tuning are the
    keys to success. Picture below made with Python.'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 多次正确的特征选择可以帮助你开发更简单、更快速的机器学习模型。请看下面的图片（IRIS 数据集的支持向量机分类）：左侧展示了错误的变量选择。线性核无法正确处理分类任务，径向基函数核也无法处理。在右侧，选择了花瓣宽度和花瓣长度作为特征，即使是线性核也表现得相当准确。正确的变量选择、好的算法选择和超参数调整是成功的关键。下图使用
    Python 制作。
- en: '![Variable selection](../Images/895154c762b80423be8ae02bc8dbe313.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![变量选择](../Images/895154c762b80423be8ae02bc8dbe313.png)'
- en: In a time when ample processing power can tempt us to think that feature selection
    may not be as relevant as it once was, it's important to remember that this only
    accounts for one of the numerous benefits of informed feature selection -- decreased
    training times. As Zimbres notes above, with a simple concrete example, feature
    selection can quite literally mean the difference between valid, generalizable
    models and a big waste of time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在充足的处理能力使我们可能认为特征选择可能不再像以前那样相关的时代里，重要的是要记住，这仅仅是知情特征选择的诸多好处之一——减少训练时间。正如 Zimbres
    上面所述，通过一个简单的具体例子，特征选择可以确实意味着有效且可泛化的模型与浪费时间之间的区别。
- en: '**Related**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**：'
- en: '[Must-Know: Why it may be better to have fewer predictors in Machine Learning
    models?](/2017/04/must-know-fewer-predictors-machine-learning-models.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[必须知道：为什么在机器学习模型中减少预测变量可能更好？](/2017/04/must-know-fewer-predictors-machine-learning-models.html)'
- en: '[Is Regression Analysis Really Machine Learning?](/2017/06/regression-analysis-really-machine-learning.html)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回归分析真的属于机器学习吗？](/2017/06/regression-analysis-really-machine-learning.html)'
- en: '[Identifying Variables That Might Be Better Predictors](/2017/02/schmarzo-variables-better-predictors.html)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[识别可能是更好预测变量的变量](/2017/02/schmarzo-variables-better-predictors.html)'
- en: '* * *'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT'
- en: '* * *'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家都应该掌握的 6 个预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90 亿美元的 AI 失败，剖析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
