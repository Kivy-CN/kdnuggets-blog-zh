- en: How to troubleshoot memory problems in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/06/troubleshoot-memory-problems-python.html](https://www.kdnuggets.com/2021/06/troubleshoot-memory-problems-python.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Freddy Boulton](https://innovation.alteryx.com/author/freddy/), Software
    Engineer at Alteryx**'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to troubleshoot memory problems in Python](../Images/30b767756e098c963065f0aa81571cb8.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Finding out that an application is running out of memory is one of the worst
    realizations a developer can have. Memory problems are hard to diagnose and fix
    in general, but I’d argue it’s even harder in Python. Python’s automatic garbage
    collection makes it easy to get up and going with the language, but it’s so good
    at being out of the way that when it doesn’t work as expected, developers can
    be at a loss for how to identify and fix the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog post, I will show how we diagnosed and fixed a memory problem in [EvalML](https://evalml.alteryx.com/en/stable/),
    the open-source AutoML library developed by Alteryx Innovation Labs. There is
    no magic recipe for solving memory problems, but my hope is that developers, specifically
    Python developers, can learn about tools and best practices they can leverage
    when they run into this kind of problem in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'After reading this blog post, you should walk away with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Why it’s important to find and fix memory problems in your programs,
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What circular references are and why they can cause memory leaks in Python,
    and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Knowledge of Python’s memory profiling tools and some steps you can take to
    identify the cause of memory problems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Setting the stage**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The EvalML team runs a suite of performance tests before releasing a new version
    of our package to catch any performance regressions. These performance tests involve
    running our AutoML algorithm on a variety of datasets, measuring the scores our
    algorithm achieves as well as the runtime, and comparing those metrics to our
    previously released version.
  prefs: []
  type: TYPE_NORMAL
- en: One day I was running the tests, and suddenly the application crashed. What
    happened?
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 0 - What is memory, and what is a leak?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the most important functions of any programming language is its ability
    to store information in the computer’s memory. Each time your program creates
    a new variable, it’ll allocate some memory to use to store the contents of that
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: The kernel defines an interface for programs to access the computer’s CPUs,
    memory, disk storage and more. Every programming language provides ways to ask
    the kernel to allocate and deallocate chunks of memory for use by a running program.
  prefs: []
  type: TYPE_NORMAL
- en: Memory leaks occur when a program asks the kernel to set aside a chunk of memory
    to use, but then due to a bug or a crash, the program never tells the kernel when
    it is finished using that memory. In that case, the kernel will continue to think
    the forgotten chunks of memory are still being used by the running program, and
    other programs won’t be able to access those chunks of memory.
  prefs: []
  type: TYPE_NORMAL
- en: If the same leak occurs repeatedly while running a program, the total size of
    forgotten memory can grow so large that it consumes a large portion of the computer’s
    memory! In that situation, if a program then tries to ask for more memory, the
    kernel will raise an “out of memory” error and the program will stop running,
    or in other words, “crash.”
  prefs: []
  type: TYPE_NORMAL
- en: So, it is important to find and fix memory leaks in programs you write, because
    if you don’t, your program could eventually run out of memory and crash, or it
    could cause other programs to crash.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1: Establish that it is a memory problem**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An application can crash for a number of reasons — maybe the server running
    the code crashed, maybe there’s a logical error in the code itself — so it’s important
    to establish that the problem at hand is a memory problem.
  prefs: []
  type: TYPE_NORMAL
- en: The EvalML performance tests crashed in an eerily quiet way. All of a sudden,
    the server stopped logging progress, and the job quietly finished. The server
    log would display any stack traces caused by coding errors, so I had a hunch this
    silent crash was caused by the job using all of the available memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'I reran the performance tests again, but this time with Python’s [memory-profiler](https://pypi.org/project/memory-profiler/) enabled
    to get a plot of the memory usage over time. The tests crashed again and when
    I looked at the memory plot, I saw this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, line chart'
  prefs: []
  type: TYPE_NORMAL
- en: Description automatically generated](../Images/b89d4018ae7029f0d96e81d268ee0d20.png)Memory
    profile of the performance tests
  prefs: []
  type: TYPE_NORMAL
- en: Our memory usage stays stable over time, but then it reaches 8 gigabytes! I
    know that our application server has 8 gigabytes of RAM, so this profile confirms
    we’re running out of memory. Moreover, when the memory is stable, we’re using
    about 4 GB of memory, but our previous version of EvalML used about 2 GB of memory.
    So, for some reason, this current version is using about twice as much memory
    as normal.
  prefs: []
  type: TYPE_NORMAL
- en: Now I needed to find out why.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2: Reproduce the memory problem locally with a minimal example**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pinpointing the cause of a memory problem involves a lot of experimentation
    and iteration because the answer is not usually obvious. If it was, you probably
    wouldn’t have written it into the code! For this reason, I think it is important
    to reproduce the problem with as few lines of code as possible. This minimal example
    makes it possible for you to quickly run it under a profiler while you modify
    the code to see if you are making progress.
  prefs: []
  type: TYPE_NORMAL
- en: In my case, I knew from experience that our application runs a taxi dataset
    with 1.5 million rows at about the time I saw the big spike. I stripped down our
    application to only the [part](https://gist.github.com/freddyaboulton/66159137063d01f3ee9cfb84b0ac2aaa) that
    runs this dataset. I saw a spike similar to what I described above, but this time,
    the memory usage reached 10 gigabytes!
  prefs: []
  type: TYPE_NORMAL
- en: After seeing this, I knew had a good enough minimal example to dive deeper.
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart, scatter chart Description automatically generated](../Images/57a022a7cf02687d0161d62b3f449ece.png)Memory
    footprint of local reproducer on taxi dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3: Find the lines of code that are allocating the most memory**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we’ve isolated the problem to as small a code chunk as possible, we can
    see where the program is allocating the most memory. This can be the smoking gun
    you need to be able to refactor the code and fix the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'I think the [filprofiler](https://pypi.org/project/filprofiler/) is a great
    Python tool to do this. It displays the memory allocation of each line of code
    in your application at the point of peak memory usage. This is the output on my
    local example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text Description automatically generated](../Images/8ce1abe4d64ab0a96176d21157d4da47.png)The
    output of fil-profile'
  prefs: []
  type: TYPE_NORMAL
- en: The filprofiler ranks the lines of code in your application (and your dependencies’
    code) by their memory allocation. The longer and redder the line is, the more
    memory is allocated.
  prefs: []
  type: TYPE_NORMAL
- en: The lines that allocate the most memory are creating pandas dataframes (pandas/core/algorithms.py
    and pandas/core/internal/managers.py) and amount to 4 gigabytes of data! I’ve
    truncated the output of filprofiler here but it’s able to track the pandas code
    to code in EvalML that creates pandas dataframes.
  prefs: []
  type: TYPE_NORMAL
- en: Seeing this was a bit perplexing. Yes, EvalML creates pandas dataframes, but
    these dataframes are short-lived throughout the AutoML algorithm and should be
    deallocated as soon as they are no longer used. Since this was not the case, and
    these dataframes were still in memory long enough EvalML was done with them, I
    thought the latest version had introduced a [memory leak](https://en.wikipedia.org/wiki/Memory_leak).
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 4: Identify Leaking objects**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the context of Python, a leaking object is an object that is not deallocated
    by Python’s garbage collector after it is done being used. Since Python uses [reference
    counting](https://en.wikipedia.org/wiki/Reference_counting) as one of its primary
    garbage collection algorithms, these leaking objects are usually caused by objects
    holding a reference to them longer than they should.
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of objects are tricky to find, but there are some Python tools you
    can leverage to make the search tractable. The first tool is the [gc.DEBUG_SAVEALL](https://docs.python.org/3/library/gc.html#gc.DEBUG_SAVEALL) flag
    of the garbage collector. By setting this flag, the garbage collector will store
    unreachable objects in the gc.garbage list. This will let you investigate those
    objects further.
  prefs: []
  type: TYPE_NORMAL
- en: The second tool is the [objgraph](https://pypi.org/project/objgraph/) library.
    Once the objects are in the gc.garbage list, we can filter this list to pandas
    dataframes, and use objgraph to see what other objects are referring to these
    dataframes and keeping them in memory. I got the idea for this approach by reading
    this O’Reilly [blog post](https://www.oreilly.com/library/view/python-cookbook/0596001673/ch14s10.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a subset of the object graph I saw when I visualized one of these dataframes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram Description automatically generated](../Images/20a8329f59226382469b80a7194f1839.png)'
  prefs: []
  type: TYPE_IMG
- en: A graph of the memory used by a pandas dataframe, showing a circular reference
    which results in a memory leak.
  prefs: []
  type: TYPE_NORMAL
- en: This is the smoking gun I was looking for! The dataframe makes a reference to
    itself via something called the PandasTableAccessor, which creates a [circular
    reference](https://en.wikipedia.org/wiki/Circular_reference), so this will keep
    the object in memory until Python’s garbage collector runs and is able to free
    it. (You can trace the cycle via dict, PandasTableAccessor, dict, _dataframe.)
     This was problematic for EvalML because the garbage collector was keeping these
    dataframes in memory so long that we ran out of memory!
  prefs: []
  type: TYPE_NORMAL
- en: I was able to trace the PandasTableAccessor to the [Woodwork](https://woodwork.alteryx.com/en/stable/) library
    and bring this [issue](https://github.com/alteryx/woodwork/issues/880) up to the
    maintainers. They were able to fix it in a new release and file a relevant [issue](https://github.com/pandas-dev/pandas/issues/41357) to
    the pandas repository — a great example of the collaboration that’s possible in
    the open source ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: After the Woodwork update was released, I visualized the object graph of the
    same dataframe, and the cycle disappeared!
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram Description automatically generated](../Images/5e263655619062aa7c19fc4758280201.png)Object
    graph of pandas dataframe after the woodwork upgrade. No more cycles!'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 5: Verify the fix works**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once I upgraded the Woodwork version in EvalML, I measured the memory footprint
    of our application. I’m happy to report that the memory usage is now less than
    half of what it used to be!
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart Description automatically generated](../Images/91321f74711571f99421d7a0e9e70fb7.png)Memory
    of performance tests after the fix'
  prefs: []
  type: TYPE_NORMAL
- en: '**Closing thoughts**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As I said at the beginning of this post, there is no magic recipe for fixing
    memory problems, but this case study offers a general framework and set of tools
    you can leverage if you run into this situation in the future. I found memory-profiler
    and filprofiler to be helpful tools for debugging memory leaks in Python.
  prefs: []
  type: TYPE_NORMAL
- en: I also want to emphasize that circular references in Python can increase the
    memory footprint of your applications. The garbage collector will eventually free
    the memory but, aswe saw in this case, maybe not until it’s too late!
  prefs: []
  type: TYPE_NORMAL
- en: Circular references are surprisingly easy to introduce unintentionally in Python.
    I was able to find an [unintentional one](https://github.com/alteryx/evalml/issues/2226) in
    EvalML, [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize/issues/1028),
    and [scipy](https://github.com/scipy/scipy/issues/13986). I encourage you to keep
    your eyes peeled, and if you see a circular reference in the wild, start a conversation
    to see if it is actually needed!
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Freddy Boulton](https://innovation.alteryx.com/author/freddy/)** is
    a software engineer at Alteryx. He enjoys working on open source projects and
    riding his bicycle all over Boston.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://innovation.alteryx.com/how-to-troubleshoot-memory-problems-in-python/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Top Programming Languages and Their Uses](/2021/05/top-programming-languages.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Scientists, You Need to Know How to Code](/2021/06/data-scientists-need-know-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Tasks To Automate With Python](/2021/06/5-tasks-automate-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introduction to Memory Profiling in Python](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Perform Memory-Efficient Operations on Large Datasets with Pandas](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Memory Complexity with Transformers](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[More Performance Evaluation Metrics for Classification Problems You…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Common Data Problems (and Solutions)](https://www.kdnuggets.com/2022/02/common-data-problems-solutions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4 Factors to Identify Machine Learning Solvable Problems](https://www.kdnuggets.com/2022/04/4-factors-identify-machine-learning-solvable-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
