- en: Change the Background of Any Video with 5 Lines of Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/12/change-background-video-5-lines-code.html](https://www.kdnuggets.com/2020/12/change-background-video-5-lines-code.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/),
    Independent AI Researcher**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c90ef44af509ee9620dd55a0fd935595.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Author
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib is a library created to enable easy implementation of object segmentation
    in real life applications. PixelLib supports image tuning, which is the ability
    to alter the background of any image. PixelLib now supports video tuning, which
    is the ability to alter the background of videos and camera’s feeds. PixelLib
    employs the technique of object segmentation to perform excellent foreground and
    background subtraction. PixelLib makes use of deeplabv3+ model trained on pascalvoc
    dataset and the dataset supports 20 object categories.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Background effects supported are as follows:*'
  prefs: []
  type: TYPE_NORMAL
- en: '**1** Changing the background of an image with a picture'
  prefs: []
  type: TYPE_NORMAL
- en: '**2** Assigning a distinct color to the background of an image and a video.'
  prefs: []
  type: TYPE_NORMAL
- en: '**3** Blurring the background of an image and a video.'
  prefs: []
  type: TYPE_NORMAL
- en: '**4** Grayscaling the background of an image of an image and a video.'
  prefs: []
  type: TYPE_NORMAL
- en: '**5** Creating a virtual background for a video.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install PixelLib and its dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Tensorflow with:(PixelLib supports tensorflow 2.0 and above)
  prefs: []
  type: TYPE_NORMAL
- en: '*pip3 install tensorflow*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Install PixelLib with
  prefs: []
  type: TYPE_NORMAL
- en: pip3 install pixellib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If installed, upgrade to the latest version using:'
  prefs: []
  type: TYPE_NORMAL
- en: pip3 install pixellib — upgrade
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detection of a target object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some applications, you may want to target the detection of a particular object
    in an image or a video. The deeplab model by default detects all the objects it
    supports in an image or video. It is now possible to filter out unused detections
    and target a particular object in an image or a video.
  prefs: []
  type: TYPE_NORMAL
- en: '*sample image*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/3844ccd3c79e2702e0710a8e6bb650ef.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Unsplash.com](https://unsplash.com/photos/D5mCL7Q_6Us) By Strvnge Films
  prefs: []
  type: TYPE_NORMAL
- en: We intend to blur the background of the image above.
  prefs: []
  type: TYPE_NORMAL
- en: Code to blur image’s background.
  prefs: []
  type: TYPE_NORMAL
- en: output image
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/dd2a391896609ec6e19d2b2ecc8882b8.png)'
  prefs: []
  type: TYPE_IMG
- en: Our goal is to completely blur the background of the person in this image, but
    we are not satisfied with the presence of other objects. Therefore, there is need
    to modify the code to detect a target object.
  prefs: []
  type: TYPE_NORMAL
- en: It is still the same code except we introduced an extra parameter ***detect ***in
    the *blur_bg* function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**detect: **This is the parameter that determines the target object to be detected.
    The value of detect is set to ***person***. This means that the model will detect
    only person in the image.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/af4678c17099777cc6af3f59ac414219.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the new image with only our target object shown.
  prefs: []
  type: TYPE_NORMAL
- en: If we intend to show only the cars present in this image, we just have to change
    the value of **detect** from ***person*** to ***car****.*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/c831882ee424554647b31976a41d2941.png)'
  prefs: []
  type: TYPE_IMG
- en: We set the target object to ***car ***and every other object present in the
    image was blurred with the background.
  prefs: []
  type: TYPE_NORMAL
- en: '***Color background of target object***'
  prefs: []
  type: TYPE_NORMAL
- en: Target detections can be done with color effect.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/b849e912cc6dfe47cfae912cb1d5cbd9.png)'
  prefs: []
  type: TYPE_IMG
- en: '***Change the background of a target object with a new picture***'
  prefs: []
  type: TYPE_NORMAL
- en: '***background image***'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/ccef7e7882379916a9c419cb6457e54e.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Unsplash.com by Dawid Zawila](https://unsplash.com/photos/9P2-bzjvIHk)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/1602d3c22c22d9579a983ef93eeb1d1f.png)'
  prefs: []
  type: TYPE_IMG
- en: '***Grayscale the background of a target object***'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/c08f9107b96b6938bb4eb9e9dfca052b.png)'
  prefs: []
  type: TYPE_IMG
- en: Read this article to have a comprehensive knowledge about background editing
    in images with PixelLib.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Change the Background of Any Image with 5 Lines of Code**](https://towardsdatascience.com/change-the-background-of-any-image-with-5-lines-of-code-23a0ef10ce9a)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Video tuning with PixelLib***'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Video tuning is the ability to alter the background of any video.
  prefs: []
  type: TYPE_NORMAL
- en: '**Blur Video background**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib makes it convenient to blur the background of any video using just
    five lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: '**sample_video**'
  prefs: []
  type: TYPE_NORMAL
- en: '*code to blur the background of a video file*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We imported pixellib, and from pixellib we imported in the class *alter_bg*.
    Instance of the class was created, and within the class, we added a parameter *model_type *and
    set it to***pb****. *We finally called the function to load the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** PixelLib supports two types of deeplabv3+ models, keras and tensorflow
    models. The keras model is extracted from the tensorflow model’s checkpoint. The
    tensorflow model performs better than the keras model extracted from its checkpoint.
    We will make use of tensorflow model. Download the tensorflow model from [here ](https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.1/xception_pascalvoc.pb).'
  prefs: []
  type: TYPE_NORMAL
- en: There are three parameters that determine the degree to which the background
    is blurred.
  prefs: []
  type: TYPE_NORMAL
- en: '*low:* When it is set to true, the background is blurred slightly.'
  prefs: []
  type: TYPE_NORMAL
- en: '*moderate:* When it is set to true, the background is moderately blurred.'
  prefs: []
  type: TYPE_NORMAL
- en: '*extreme:* When it is set to true, the background is deeply blurred.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the line of code that blurs the video’s background. This function takes
    in five parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**video_path:** This is the path to the video file we want to blur its background.'
  prefs: []
  type: TYPE_NORMAL
- en: '**extreme:** It is set to true and the background of the video would be extremely
    blurred.'
  prefs: []
  type: TYPE_NORMAL
- en: '**frames_per_second:** This is the parameter to set the number of frames per
    second for the output video file. In this case, it is set to 10 i.e the saved
    video file will have 10 frames per second.'
  prefs: []
  type: TYPE_NORMAL
- en: '**output_video_name:**Thisis the saved video. The output video will be saved
    in your current working directory.'
  prefs: []
  type: TYPE_NORMAL
- en: '**detect: **This is the parameter that chooses the target object in the video.
    It is set to ***person***.'
  prefs: []
  type: TYPE_NORMAL
- en: '**output video**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Blur the Background of Camera’s Feeds**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We imported cv2 and included the code to capture camera’s frames.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In the code for blurring camera’s frames, we replaced the video’s filepath
    to capture i.e we are going to process a stream of camera’s frames instead of
    a video file.We added extra parameters for the purpose of showing the camera’s
    frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '**show_frames:** This is the parameter that handles showing of blurred camera’s
    frames.'
  prefs: []
  type: TYPE_NORMAL
- en: '**frame_name:** This is the name given to the shown camera’s frame.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Output Video**'
  prefs: []
  type: TYPE_NORMAL
- en: Wow! PixelLib successfully blurred my background in the video.
  prefs: []
  type: TYPE_NORMAL
- en: '**Create a Virtual Background for a Video**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PixelLib makes it super easy to create a virtual background for any video, and
    you can make use of any image to create a virtual background for a video.
  prefs: []
  type: TYPE_NORMAL
- en: '**sample video**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image to serve as background for a video**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c5bdc32590fbb45357cd1a3591bdaa5f.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Unsplash.com](https://unsplash.com/photos/rCbdp8VCYhQ) [by Handy Holmes](https://unsplash.com/photos/rCbdp8VCYhQ)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It is still the same code except we called the function *change_video_bg* to
    create a virtual background for the video. The function takes in the path of the
    image we want to use as background for the video.
  prefs: []
  type: TYPE_NORMAL
- en: '**Output Video**'
  prefs: []
  type: TYPE_NORMAL
- en: Beautiful demo! We are able to successfully create a virtual space background
    for the video.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Create a Virtual Background for Camera’s Feeds**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It is similar to the code we used to blur camera’s frames. The only difference
    is that we called the function *change_camera_bg*. We performed the same routine,
    replaced the video’s filepath to capture, and added the same parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Output Video**'
  prefs: []
  type: TYPE_NORMAL
- en: Wow! PixelLib successfully created a virtual background for my video.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Color Video background**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib makes it possible to assign any color to the background of a video.
  prefs: []
  type: TYPE_NORMAL
- en: '*code to color the background of a video file*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It is still the same code, except we called the function *color_video* to give
    the video’s background a distinct color. The function *color_bg* takes the parameter *colors, *and
    colors’s RGB value is set to green. The RGB value of green color is (0, 128, 0).
  prefs: []
  type: TYPE_NORMAL
- en: output video
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The same video with a white background
  prefs: []
  type: TYPE_NORMAL
- en: '**Color the Background of Camera’s Feeds**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It is similar to the code we used to create a virtual background for camera’s
    frames. The only difference is that we called the function *color_camera*. We
    performed the same routine, replaced the video’s filepath to capture, and added
    the same parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Output Video**'
  prefs: []
  type: TYPE_NORMAL
- en: Beautiful demo! My background was successfully colored green with PixelLib.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Grayscale Video background**'
  prefs: []
  type: TYPE_NORMAL
- en: '*code to grayscale the background of a video file*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: output video
  prefs: []
  type: TYPE_NORMAL
- en: '**Note: **The background of the video would be altered and the objects present
    would maintain their original quality.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Grayscale the Background of Camera’s Feeds**'
  prefs: []
  type: TYPE_NORMAL
- en: It is similar to the code we used to color camera’s frames. The only difference
    is that we called the function *gray_camera*. We performed the same routine, replaced
    the video filepath to capture, and added the same parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[Visit PixelLib’s official github repository](https://github.com/ayoolaolafenwa/PixelLib)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Visit PixelLib’s offical documentation](https://pixellib.readthedocs.io/en/latest/)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Reach to me via:'
  prefs: []
  type: TYPE_NORMAL
- en: Email: [olafenwaayoola@gmail.com](https://mail.google.com/mail/u/0/#inbox)
  prefs: []
  type: TYPE_NORMAL
- en: Linkedin: [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/)
  prefs: []
  type: TYPE_NORMAL
- en: Twitter: [@AyoolaOlafenwa](https://twitter.com/AyoolaOlafenwa)
  prefs: []
  type: TYPE_NORMAL
- en: Facebook: [Ayoola Olafenwa](https://web.facebook.com/ayofen)
  prefs: []
  type: TYPE_NORMAL
- en: Check out these articles written on how to make use of PixelLib for semantic
    and instance segmentation of objects in images and videos.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Image Segmentation With 5 Lines 0f Code**](https://towardsdatascience.com/image-segmentation-with-six-lines-0f-code-acb870a462e8)'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic and Instance Segmentation with PixelLib.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Video Segmentation With 5 Lines of Code**](https://towardsdatascience.com/video-segmentation-with-5-lines-of-code-87f798afb93)'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic and instance segmentation of videos.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Semantic Segmentation of 150 classes of objects With 5 Lines of Code**](https://towardsdatascience.com/semantic-segmentation-of-150-classes-of-objects-with-5-lines-of-code-7f244fa96b6c)'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic segmentation of 150 classes of objects with PixelLib
  prefs: []
  type: TYPE_NORMAL
- en: '[**Custom Instance Segmentation Training With 7 Lines Of Code.**](https://towardsdatascience.com/custom-instance-segmentation-training-with-7-lines-of-code-ff340851e99b)'
  prefs: []
  type: TYPE_NORMAL
- en: Train your dataset with 7 Lines of Code to implement instance segmentation and
    object detection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/)**
    is an independent AI Researcher who specializes in the field of computer vision.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/change-the-background-of-any-video-with-5-lines-of-code-7cc847394f5d).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Change the Background of Any Image with 5 Lines of Code](/2020/11/change-background-image-5-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Roadmap to Computer Vision](/2020/10/roadmap-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Auto Rotate Images Using Deep Learning](/2020/07/auto-rotate-images-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Multi-modal deep learning in less than 15 lines of code](https://www.kdnuggets.com/2023/01/predibase-multi-modal-deep-learning-less-15-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Transition into Data Science from a Different Background?](https://www.kdnuggets.com/2023/05/transition-data-science-different-background.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SHAP: Explain Any Machine Learning Model in Python](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Read This Before You Take Any Free Data Science Course](https://www.kdnuggets.com/read-this-before-you-take-any-free-data-science-course)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
