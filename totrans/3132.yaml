- en: Ten Machine Learning Algorithms You Should Know to Become a Data Scientist
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成为数据科学家应该了解的十种机器学习算法
- en: 原文：[https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html](https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html](https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html)'
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](2018/04/10-machine-learning-algorithms-data-scientist.html/2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](2018/04/10-machine-learning-algorithms-data-scientist.html/2#comments)'
- en: '**By Muktabh Mayank, [ParallelDots](https://paralleldots.com/)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Muktabh Mayank，[ParallelDots](https://paralleldots.com/)**'
- en: '![machine learning algorithms](../Images/da0e3450c1e1433e14e7a1b2c34d159e.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/da0e3450c1e1433e14e7a1b2c34d159e.png)'
- en: Machine Learning Practitioners have different personalities. While some of them
    are “I am an expert in X and X can train on any type of data”, where X = some
    algorithm, some others are “Right tool for the right job people”. A lot of them
    also subscribe to “Jack of all trades. Master of one” strategy, where they have
    one area of deep expertise and know slightly about different fields of Machine
    Learning. That said, no one can deny the fact that as practicing Data Scientists,
    we will have to know basics of some common [machine learning algorithms](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html),
    which would help us engage with a new-domain problem we come across. This is a
    whirlwind tour of common machine learning algorithms and quick resources about
    them which can help you get started on them.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习从业者有不同的个性。有些人是“我是X领域的专家，X算法可以处理任何类型的数据”，其中X=某个算法；而有些人则是“适合的工具用于合适的工作”。许多人还遵循“全才，专才”策略，即他们在一个领域有深厚的专业知识，同时对机器学习的不同领域有略微的了解。尽管如此，作为实践中的数据科学家，我们必须了解一些常见的[机器学习算法](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html)的基础知识，这将帮助我们应对遇到的新领域问题。这是对常见机器学习算法的快速浏览及其相关资源，这些资源可以帮助你入门。
- en: 1\. Principal Component Analysis(PCA)/SVD
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1. 主成分分析（PCA）/奇异值分解（SVD）
- en: PCA is an unsupervised method to understand global properties of a dataset consisting
    of vectors. Covariance Matrix of data points is analyzed here to understand what
    dimensions(mostly)/ data points (sometimes) are more important (ie have high variance
    amongst themselves, but low covariance with others). One way to think of top PCs
    of a matrix is to think of its eigenvectors with highest eigenvalues. SVD is essentially
    a way to calculate ordered components too, but you don’t need to get the covariance
    matrix of points to get it.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 是一种无监督方法，用于理解由向量组成的数据集的全局属性。这里分析数据点的协方差矩阵，以了解哪些维度（通常是）/数据点（有时）更重要（即，在它们之间具有高方差，但与其他数据点的协方差低）。一种理解矩阵顶级主成分的方法是考虑其具有最高特征值的特征向量。SVD
    本质上也是一种计算有序组件的方法，但你无需获取点的协方差矩阵就能得到它。
- en: '![machine learning algorithms](../Images/d799bb2104583027c8fffea1197d84e1.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/d799bb2104583027c8fffea1197d84e1.png)'
- en: This Algorithm helps one fight curse of dimensionality by getting datapoints
    with reduced dimensions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法通过获取维度减少的数据点来帮助克服维度诅咒。
- en: '**Libraries:**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**库：**'
- en: '[https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html)'
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)'
- en: '**Introductory Tutorial:**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**入门教程：**'
- en: '[https://arxiv.org/pdf/1404.1100.pdf](https://arxiv.org/pdf/1404.1100.pdf)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/pdf/1404.1100.pdf](https://arxiv.org/pdf/1404.1100.pdf)'
- en: 2a. Least Squares and Polynomial Fitting
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2a. 最小二乘法和多项式拟合
- en: Remember your Numerical Analysis code in college, where you used to fit lines
    and curves to points to get an equation. You can use them to fit curves in Machine
    Learning for very small datasets with low dimensions. (For large data or datasets
    with many dimensions, you might just end up terribly overfitting, so don’t bother).
    OLS has a closed form solution, so you don’t need to use complex optimization
    techniques.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 记得你在大学时的数值分析代码吗？你用来拟合点上的直线和曲线以得到一个方程。你可以在机器学习中使用这些方法来拟合非常小的数据集中的曲线（对于大数据或高维数据集，你可能会严重过拟合，因此不要使用）。OLS有一个闭式解，因此你不需要使用复杂的优化技术。
- en: '![](../Images/4751b805d2c61703c32e03f0fbb1e165.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4751b805d2c61703c32e03f0fbb1e165.png)'
- en: As is obvious, use this algorithm to fit simple curves / regression
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见，使用此算法来拟合简单曲线/回归
- en: 'Libraries:'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 库：
- en: '[https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html)[https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html)[https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html)'
- en: 'Introductory Tutorial:'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 入门教程：
- en: '[https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf)'
- en: 2b. Constrained Linear Regression
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2b. 约束线性回归
- en: Least Squares can get confused with outliers, spurious fields and noise in data.
    We thus need constraints to decrease the variance of the line we fit on a dataset.
    The right method to do it is to fit a linear regression model which will ensure
    that the weights do not misbehave. Models can have L1 norm (LASSO) or L2 (Ridge
    Regression) or both (elastic regression). Mean Squared Loss is optimized.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法可能会受到异常值、虚假字段和数据噪声的干扰。因此，我们需要约束条件来减少拟合数据集的线的方差。正确的方法是拟合一个线性回归模型，以确保权重不会出现异常。模型可以具有L1范数（LASSO）或L2范数（岭回归）或两者都有（弹性回归）。均方损失被优化。
- en: '![](../Images/727b71525e3373fc2f7d83ce4e350469.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/727b71525e3373fc2f7d83ce4e350469.png)'
- en: Use these algorithms to fit regression lines with constraints, avoiding overfitting
    and masking noise dimensions from model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些算法来拟合带约束的回归线，避免过拟合，并掩盖模型中的噪声维度。
- en: '**Libraries:**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**库：**'
- en: '[http://scikit-learn.org/stable/modules/linear_model.html](http://scikit-learn.org/stable/modules/linear_model.html)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/linear_model.html](http://scikit-learn.org/stable/modules/linear_model.html)'
- en: '**Introductory Tutorial(s):**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**入门教程：**'
- en: '[https://www.youtube.com/watch?v=5asL5Eq2x0A](https://www.youtube.com/watch?v=5asL5Eq2x0A)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=5asL5Eq2x0A](https://www.youtube.com/watch?v=5asL5Eq2x0A)'
- en: '[https://www.youtube.com/watch?v=jbwSCwoT51M](https://www.youtube.com/watch?v=jbwSCwoT51M)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=jbwSCwoT51M](https://www.youtube.com/watch?v=jbwSCwoT51M)'
- en: 3\. K means Clustering
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3. K均值聚类
- en: Everyone’s favorite unsupervised clustering algorithm. Given a set of data points
    in form of vectors, we can make clusters of points based on distances between
    them. It’s an Expectation Maximization algorithm that iteratively moves the centers
    of clusters and then clubs points with each cluster centers. The input the algorithm
    has taken is the number of clusters which are to be generated and the number of
    iterations in which it will try to converge clusters.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人最喜欢的无监督聚类算法。给定一组以向量形式存在的数据点，我们可以根据它们之间的距离来创建点的聚类。这是一种期望最大化算法，它通过迭代移动聚类的中心，然后将点与每个聚类中心组合在一起。算法所需的输入是要生成的聚类数和尝试收敛聚类的迭代次数。
- en: '![machine learning algorithms](../Images/351e4ae23251bd092d8c3315e482ceb1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/351e4ae23251bd092d8c3315e482ceb1.png)'
- en: As is obvious from the name, you can use this algorithm to create K clusters
    in dataset
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从名称中显而易见，你可以使用这个算法在数据集中创建K个簇
- en: '**Library:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**库：**'
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)'
- en: '**Introductory Tutorial(s):**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**入门教程：**'
- en: '[https://www.youtube.com/watch?v=hDmNF9JG3lo](https://www.youtube.com/watch?v=hDmNF9JG3lo)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=hDmNF9JG3lo](https://www.youtube.com/watch?v=hDmNF9JG3lo)'
- en: '[https://www.datascience.com/blog/k-means-clustering](https://www.datascience.com/blog/k-means-clustering)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.datascience.com/blog/k-means-clustering](https://www.datascience.com/blog/k-means-clustering)'
- en: 4\. Logistic Regression
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 逻辑回归
- en: 'Logistic Regression is constrained Linear Regression with a nonlinearity (sigmoid
    function is used mostly or you can use tanh too) application after weights are
    applied, hence restricting the outputs close to +/- classes (which is 1 and 0
    in case of sigmoid). Cross-Entropy Loss functions are optimized using Gradient
    Descent. A note to beginners: Logistic Regression is used for classification,
    not regression. You can also think of Logistic regression as a one layered Neural
    Network. Logistic Regression is trained using optimization methods like Gradient
    Descent or L-BFGS. NLP people will often use it with the name of Maximum Entropy
    Classifier.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是受限的线性回归，在应用非线性（通常使用sigmoid函数或tanh函数）后，限制输出接近于+/-类别（在sigmoid的情况下为1和0）。交叉熵损失函数使用梯度下降法进行优化。给初学者的提示：逻辑回归用于分类，而不是回归。你也可以把逻辑回归看作是一个单层的神经网络。逻辑回归使用梯度下降法或L-BFGS等优化方法进行训练。NLP领域的人们经常用最大熵分类器的名称来表示它。
- en: 'This is what a Sigmoid looks like:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Sigmoid的样子：
- en: '![](../Images/0e1fce437687ecfe4d3fb5b72127f730.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e1fce437687ecfe4d3fb5b72127f730.png)'
- en: Use LR to train simple, but very robust classifiers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LR来训练简单但非常强大的分类器。
- en: '**Library:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**库：**'
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)'
- en: '**Introductory Tutorial(s):**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**入门教程：**'
- en: '[https://www.youtube.com/watch?v=-la3q9d7AKQ](https://www.youtube.com/watch?v=-la3q9d7AKQ)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=-la3q9d7AKQ](https://www.youtube.com/watch?v=-la3q9d7AKQ)'
- en: 5\. SVM (Support Vector Machines)
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. SVM（支持向量机）
- en: SVMs are linear models like Linear/ Logistic Regression, the difference is that
    they have different margin-based loss function (The derivation of Support Vectors
    is one of the most beautiful mathematical results I have seen along with eigenvalue
    calculation). You can optimize the loss function using optimization methods like
    L-BFGS or even SGD.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是类似于线性/逻辑回归的线性模型，不同之处在于它们具有不同的基于边界的损失函数（支持向量的推导是我见过的最美丽的数学结果之一，与特征值计算一起）。你可以使用优化方法，如L-BFGS或甚至SGD来优化损失函数。
- en: '![](../Images/076c7aab2765ed2bf0c959f351786eaf.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/076c7aab2765ed2bf0c959f351786eaf.png)'
- en: Another innovation in SVMs is the usage of kernels on data to feature engineer.
    If you have good domain insight, you can replace the good-old RBF kernel with
    smarter ones and profit.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的另一个创新是使用核函数对数据进行特征工程。如果你对领域有深入的了解，你可以用更聪明的核函数替代传统的RBF核，并从中获利。
- en: One unique thing that SVMs can do is learn one class classifiers.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: SVM的一个独特之处是它可以学习单类分类器。
- en: SVMs can used to Train a classifier (even regressors)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: SVM可用于训练分类器（甚至回归器）
- en: '**Library:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**库：**'
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)'
- en: '**Introductory Tutorial(s):**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**入门教程：**'
- en: '[https://www.youtube.com/watch?v=eHsErlPJWUU](https://www.youtube.com/watch?v=eHsErlPJWUU)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=eHsErlPJWUU](https://www.youtube.com/watch?v=eHsErlPJWUU)'
- en: '**Note:** SGD based training of both Logistic Regression and SVMs are found
    in SKLearn’s [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) ,
    which I often use as it lets me check both LR and SVM with a common interface.
    You can also train it on >RAM sized datasets using mini batches.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 逻辑回归和SVM的SGD基于训练可以在SKLearn的 [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)中找到，我常用它，因为它让我可以通过一个通用接口检查LR和SVM。你还可以在大于RAM大小的数据集上使用迷你批量进行训练。'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速通道进入网络安全领域的职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R语言库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学来寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学学习统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为一名出色数据科学家需要的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败案例，深度剖析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
