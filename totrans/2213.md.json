["```py\ncargo new new_burn_app\n```", "```py\ncd new_burn_app\n```", "```py\ncargo add burn --features wgpu\n```", "```py\ncargo build\n```", "```py\nuse burn::tensor::Tensor;\nuse burn::backend::WgpuBackend;\n\n// Type alias for the backend to use.\ntype Backend = WgpuBackend;\n\nfn main() {\n    // Creation of two tensors, the first with explicit values and the second one with ones, with the same shape as the first\n    let tensor_1 = Tensor::<backend>::from_data([[2., 3.], [4., 5.]]);\n    let tensor_2 = Tensor::<backend>::ones_like(&tensor_1);\n\n    // Print the element-wise addition (done with the WGPU backend) of the two tensors.\n    println!(\"{}\", tensor_1 + tensor_2);\n}</backend></backend>\n```", "```py\nTensor {\n  data: [[3.0, 4.0], [5.0, 6.0]],\n  shape:  [2, 2],\n  device:  BestAvailable,\n  backend:  \"wgpu\",\n  kind:  \"Float\",\n  dtype:  \"f32\",\n}\n```", "```py\nuse burn::nn;\nuse burn::module::Module;\nuse burn::tensor::backend::Backend;\n\n#[derive(Module, Debug)]\npub struct PositionWiseFeedForward<B: Backend> {\n    linear_inner: Linear<B>,\n    linear_outer: Linear<B>,\n    dropout: Dropout,\n    gelu: GELU,\n}\n\nimpl <b: backend=\"\">PositionWiseFeedForward<B> {\n    pub fn forward<const d:=\"\" usize=\"\">(&self, input: Tensor<B, D>) -> Tensor<B, D> {\n        let x = self.linear_inner.forward(input);\n        let x = self.gelu.forward(x);\n        let x = self.dropout.forward(x);\n\n        self.linear_outer.forward(x)\n    }\n}</const></b:>\n```"]