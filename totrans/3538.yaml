- en: 7 common mistakes when doing Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行机器学习时的7个常见错误
- en: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html)
- en: By Cheng-Tao Chu ([@chengtao_chu](https://twitter.com/chengtao_chu)) .
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：程涛（[@chengtao_chu](https://twitter.com/chengtao_chu)）。
- en: Statistical modeling is a lot like engineering.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 统计建模很像工程。
- en: '![statistics1](../Images/0e70aa3c1fdb3fb7f30b800354621863.png) In engineering,
    there are various ways to build a key-value storage, and each design makes a different
    set of assumptions about the usage pattern. In statistical modeling, there are
    various algorithms to build a classifier, and each algorithm makes a different
    set of assumptions about the data.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![statistics1](../Images/0e70aa3c1fdb3fb7f30b800354621863.png) 在工程学中，有多种方式构建键值存储，每种设计对使用模式做出不同的假设。在统计建模中，有多种算法用于构建分类器，每种算法对数据做出不同的假设。'
- en: When dealing with small amounts of data, it’s reasonable to try as many algorithms
    as possible and to pick the best one since the cost of experimentation is low.
    But as we hit “big data”, it pays off to analyze the data upfront and then design
    the modeling pipeline (pre-processing, modeling, optimization algorithm, evaluation,
    productionization) accordingly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 处理小量数据时，尝试尽可能多的算法并选择最佳算法是合理的，因为实验成本较低。但当面对“大数据”时，提前分析数据然后相应地设计建模管道（预处理、建模、优化算法、评估、生产化）是值得的。
- en: As pointed out in my previous [post](http://ml.posthaven.com/why-building-a-data-science-team-is-hard),
    there are dozens of ways to solve a given modeling problem. Each model assumes
    something different, and it’s not obvious how to navigate and identify which assumptions
    are reasonable. In industry, most practitioners pick the modeling algorithm they
    are most familiar with rather than pick the one which best suits the data. In
    this post, I would like to share some common mistakes (the don't-s). I’ll save
    some of the best practices (the do-s) in a future post.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前在[帖子](http://ml.posthaven.com/why-building-a-data-science-team-is-hard)中提到的，解决特定建模问题有很多方法。每种模型假设不同，如何导航和识别哪些假设合理并不明显。在工业界，大多数从业者选择他们最熟悉的建模算法，而不是选择最适合数据的算法。在这篇文章中，我想分享一些常见错误（不应该做的事情）。一些最佳实践（应该做的事情）我会在未来的帖子中保存。
- en: '**1\. Take default loss function for granted**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 不要把默认损失函数当作理所当然**'
- en: Many practitioners train and pick the best model using the default loss function
    (e.g., squared error). In practice, off-the-shelf loss function rarely aligns
    with the business objective. Take fraud detection as an example. When trying to
    detect fraudulent transactions, the business objective is to minimize the fraud
    loss. The off-the-shelf loss function of binary classifiers weighs false positives
    and false negatives equally. To align with the business objective, the loss function
    should not only penalize false negatives more than false positives, but also penalize
    each false negative in proportion to the dollar amount. Also, data sets in fraud
    detection usually contain highly imbalanced labels. In these cases, bias the loss
    function in favor of the rare case (e.g., through up/down sampling).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 许多从业者使用默认的损失函数（例如，平方误差）来训练和选择最佳模型。在实践中，现成的损失函数很少与业务目标对齐。以欺诈检测为例。当尝试检测欺诈交易时，业务目标是最小化欺诈损失。现成的二分类器损失函数对假阳性和假阴性给予相同的权重。为了与业务目标对齐，损失函数不仅应对假阴性给予比假阳性更多的惩罚，还应按金额对每个假阴性进行惩罚。此外，欺诈检测中的数据集通常包含高度不平衡的标签。在这些情况下，损失函数应倾斜以支持稀有情况（例如，通过上下采样）。
- en: '**2\. Use plain linear models for non-linear interaction**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 对于非线性交互使用简单的线性模型**'
- en: When building a binary classifier, many practitioners immediately jump to logistic
    regression because it’s simple. But, many also forget that logistic regression
    is a linear model and the non-linear interaction among predictors need to be encoded
    manually. Returning to fraud detection, high order interaction features like "billing
    address = shipping address and transaction amount < $50" are required for good
    model performance. So one should prefer non-linear models like SVM with kernel
    or tree based classifiers that bake in higher-order interaction features.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建二分类器时，许多从业者立即跳转到逻辑回归，因为它很简单。但许多人也忘记了逻辑回归是一个线性模型，预测变量之间的非线性交互需要手动编码。回到欺诈检测，高阶交互特征如“账单地址
    = 收货地址且交易金额 < $50”对于模型性能是必要的。因此，应优先考虑非线性模型，如具有核函数的SVM或内置高阶交互特征的树基分类器。
- en: '**3\. Forget about outliers**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 忘记异常值**'
- en: Outliers are interesting. Depending on the context, they either deserve special
    attention or should be completely ignored. Take the example of revenue forecasting.
    If unusual spikes of revenue are observed, it's probably a good idea to pay extra
    attention to them and figure out what caused the spike. But if the outliers are
    due to mechanical error, measurement error or anything else that’s not generalizable,
    it’s a good idea to filter out these outliers before feeding the data to the modeling
    algorithm.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值很有趣。根据上下文，它们可能需要特别关注，也可能应该完全忽视。例如在收入预测中，如果观察到收入的异常峰值，可能需要特别关注并找出峰值的原因。但如果异常值是由于机械故障、测量误差或其他不可普遍化的原因造成的，那么在将数据输入建模算法之前，最好将这些异常值筛除。
- en: '![statistics-bars](../Images/4397b851f09b620efd73fc1acd8d17e3.png) Some models
    are more sensitive to outliers than others. For instance, AdaBoost might treat
    those outliers as "hard" cases and put tremendous weights on outliers while decision
    tree might simply count each outlier as one false classification. If the data
    set contains a fair amount of outliers, it''s important to either use modeling
    algorithm robust against outliers or filter the outliers out.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![statistics-bars](../Images/4397b851f09b620efd73fc1acd8d17e3.png) 一些模型对异常值比其他模型更敏感。例如，AdaBoost
    可能将这些异常值视为“困难”案例，并对异常值施加巨大的权重，而决策树可能仅将每个异常值计为一个错误分类。如果数据集包含大量异常值，则重要的是使用对异常值具有鲁棒性的建模算法，或将异常值筛除。'
- en: '* * *'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT工作'
- en: '* * *'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免这5个每个AI新手常犯的错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个常见的数据科学错误及其避免方法](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
- en: '[How To Tackle 3 Common Machine Learning Challenges](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何应对3个常见的机器学习挑战](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Mistakes That Could Be Affecting the Accuracy of Your Data Analytics](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可能影响你数据分析准确性的3个错误](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
- en: '[Software Mistakes and Tradeoffs: New book by Tomasz Lelek and…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件错误与权衡：Tomasz Lelek 等新书](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
