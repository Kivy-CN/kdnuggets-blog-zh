- en: 5 Things You Need to Know about Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/03/5-things-reinforcement-learning.html](https://www.kdnuggets.com/2018/03/5-things-reinforcement-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement Learning is one of the hottest research topics currently and its
    popularity is only growing day by day. Let’s look at 5 useful things to know about
    RL.
  prefs: []
  type: TYPE_NORMAL
- en: '**What is reinforcement learning? How does it relate with other ML techniques?**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reinforcement Learning(RL) is a type of machine learning technique that enables
    an agent to learn in an interactive environment by trial and error using feedback
    from its own actions and experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Though both supervised and reinforcement learning use mapping between input
    and output, unlike supervised learning where feedback provided to the agent is
    correct set of actions for performing a task, reinforcement learning uses rewards
    and punishment as signals for positive and negative behavior.
  prefs: []
  type: TYPE_NORMAL
- en: As compared to unsupervised learning, reinforcement learning is different in
    terms of goals. While the goal in unsupervised learning is to find similarities
    and differences between data points, in reinforcement learning the goal is to
    find a suitable action model that would maximize the total cumulative reward of
    the agent. The figure below represents the basic idea and elements involved in
    a reinforcement learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Reinforcement Learning Fig. 1](../Images/33941f44debccc0218dc7911f6e19d20.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1
  prefs: []
  type: TYPE_NORMAL
- en: '**How to formulate a basic reinforcement Learning problem?**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Some key terms that describe the elements of a RL problem are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment**: Physical world in which the agent operates'
  prefs: []
  type: TYPE_NORMAL
- en: '**State**: Current situation of the agent'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reward**: Feedback from the environment'
  prefs: []
  type: TYPE_NORMAL
- en: '**Policy**: Method to map agent’s state to actions'
  prefs: []
  type: TYPE_NORMAL
- en: '**Value**: Future reward that an agent would receive by taking an action in
    a particular state'
  prefs: []
  type: TYPE_NORMAL
- en: A Reinforcement Learning problem can be best explained through games. Let’s
    take the game of PacMan where the goal of the agent (PacMan) is to eat the food
    in the grid while avoiding the ghosts on its way. The grid world is the interactive
    environment for the agent. PacMan receives a reward for eating food and punishment
    if it gets killed by the ghost (loses the game). The states are the location of
    PacMan in the grid world and the total cumulative reward is PacMan winning the
    game.
  prefs: []
  type: TYPE_NORMAL
- en: In order to build an optimal policy, the agent faces the dilemma of exploring
    new states while maximizing its reward at the same time. This is called **Exploration
    vs Exploitation trade-off**.
  prefs: []
  type: TYPE_NORMAL
- en: '[Markov Decision Processes (MDPs)](https://en.wikipedia.org/wiki/Markov_decision_process)
    are mathematical frameworks to describe an environment in reinforcement learning
    and almost all RL problems can be formalized using MDPs.  An MDP consists of a
    set of finite environment states S, a set of possible actions A(s) in each state,
    a real valued reward function R(s) and a transition model P(s’, s | a). However,
    real world environments are more likely to lack any prior knowledge of environment
    dynamics. Model-free RL methods come handy in such cases.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Q-learning**](https://en.wikipedia.org/wiki/Q-learning) is a commonly used
    model free approach which can be used for building a self-playing PacMan agent.
    It revolves around the notion of updating Q values which denotes value of doing
    action *a* in state *s*. The value update rule is the core of the Q-learning algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reinforcement Learning Fig2: Update Rule](../Images/336afa9839ae3120aa2557a4483a10a9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2: Reinforcement Learning Update Rule**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reinforcement Learning Fig3 Pacman](../Images/ff32fdfaa7b912f3d699337cd4a84367.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3: PacMan**'
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a [video](https://www.youtube.com/watch?v=QilHGSYbjDQ) of a Deep reinforcement
    learning PacMan agent
  prefs: []
  type: TYPE_NORMAL
- en: '**What are some most used Reinforcement Learning algorithms?**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Q-learning and SARSA (State-Action-Reward-State-Action) are two commonly used
    model-free RL algorithms. They differ in terms of their exploration strategies
    while their exploitation strategies are similar. While Q-learning is an off-policy
    method in which the agent learns the value based on action a* derived from the
    another policy, SARSA is an on-policy method where it learns the value based on
    its current action *a*derived from its current policy. These two methods are simple
    to implement but lack generality as they do not have the ability to estimate values
    for unseen states.
  prefs: []
  type: TYPE_NORMAL
- en: This can be overcome by more advanced algorithms such as [Deep Q-Networks](https://deepmind.com/research/dqn/)
    which use Neural Networks to estimate Q-values. But DQNs can only handle discrete,
    low-dimensional action spaces. [DDPG(Deep Deterministic Policy Gradient)](https://arxiv.org/abs/1509.02971)is
    a model-free, off-policy, actor-critic algorithm that tackles this problem by
    learning policies in high dimensional, continuous action spaces.
  prefs: []
  type: TYPE_NORMAL
- en: '![Reinforcement Learning Fig4: actor-critic architecture](../Images/1b01bb70433f08d65cd07caaf62ec8ed.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 4: actor-critic architecture for Reinforcement Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: '**What are the practical applications of Reinforcement Learning?**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since, RL requires a lot of data, therefore it is most applicable in domains
    where simulated data is readily available like gameplay, robotics.
  prefs: []
  type: TYPE_NORMAL
- en: RL is quite widely used in building AI for playing computer games. [AlphaGo
    Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/) is the first computer
    program to defeat a world champion in the ancient Chinese game of Go. Others include
    ATARI games, Backgammon, etc
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In robotics and industrial automation,RL is used to enable the robot to create
    an efficient adaptive control system for itself which learns from its own experience
    and behavior.[DeepMind’s work](https://deepmind.com/research/publications/deep-reinforcement-learning-robotic-manipulation/)
    on Deep Reinforcement Learning for Robotic Manipulation with Asynchronous Policy
    updates is a good example of the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watch this interesting demonstration [video](https://www.youtube.com/watch?v=ZhsEKTo7V04&t=48s).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other applications of RL include text summarization engines, dialog agents (text,
    speech) which can learn from user interactions and improve with time, learning
    optimal treatment policies in healthcare and RL based agents for online stock
    trading.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**How can I get started with Reinforcement Learning?**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For understanding the basic concepts of RL,
  prefs: []
  type: TYPE_NORMAL
- en: '**Reinforcement Learning-An Introduction**, a book by the father of Reinforcement
    Learning- [Richard Sutton](https://en.wikipedia.org/wiki/Richard_S._Sutton) and
    his doctoral advisor [Andrew Barto](https://en.wikipedia.org/wiki/Andrew_Barto).
    An online draft of the book is available here [http://incompleteideas.net/book/the-book-2nd.html](http://incompleteideas.net/book/the-book-2nd.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Teaching material**](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)from
    **David Silver** including video lectures is a great introductory course on RL'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here’s another [technical tutorial](http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf)
    on RL by **Pieter Abbeel** and **John Schulman** (Open AI/ Berkeley AI Research
    Lab).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For getting started with building and testing RL agents,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This blog](http://karpathy.github.io/2016/05/31/rl/) on how to train a Neural
    Network ATARI Pong agent with Policy Gradients from raw pixels by **Andrej Karpathy**
    will help you get your first Deep Reinforcement Learning agent up and running
    in just 130 lines of Python code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeepMind Lab](https://deepmind.com/blog/open-sourcing-deepmind-lab/) is an
    open source 3D game-like platform created for agent-based AI research with rich
    simulated environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Project Malmo](https://www.microsoft.com/en-us/research/project/project-malmo/)
    is another AI experimentation platform for supporting fundamental research in
    AI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAI gym](https://gym.openai.com/) is a toolkit for building and comparing
    reinforcement learning algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bio: [Shweta Bhatt](https://www.linkedin.com/in/shweta-bhatt-1a930b12/)**
    is AI researcher with experience in private and public sector, passionate about
    the impact and applications of deriving knowledge from data to solve challenging
    problems. She likes telling stories with data and is based in London.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Resurgence of AI During 1983-2010](https://www.kdnuggets.com/2018/02/resurgence-ai-1983-2010.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Exclusive: Interview with Rich Sutton, the Father of Reinforcement Learning**](https://www.kdnuggets.com/2017/12/interview-rich-sutton-reinforcement-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[When reinforcement learning should not be used?](https://www.kdnuggets.com/2017/12/when-reinforcement-learning-not-used.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Making Machine Learning Simple](https://www.kdnuggets.com/2018/03/databricks-ebook-making-machine-learning-simple.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Things You Need to Know When Building LLM Applications](https://www.kdnuggets.com/2023/08/5-things-need-know-building-llm-applications.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Things You Didn''t Know You Could do with a Low Code Tool](https://www.kdnuggets.com/2022/09/7-things-didnt-know-could-low-code-tool.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Things You Should Know When Scaling Your Web Data-Driven Product](https://www.kdnuggets.com/2023/08/things-know-scaling-web-datadriven-product.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 things you didn’t know about the SAS Academy for Data Science](https://www.kdnuggets.com/2022/07/sas-3-things-didnt-know-sas-academy-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
