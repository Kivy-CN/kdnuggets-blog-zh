# 你的机器学习代码消耗了多少内存？

> 原文：[https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html](https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html)

[评论](#comments)

![](../Images/e666b93a66f863d32faf7f17039496f7.png)

图片来源：[Pixabay](https://pixabay.com/photos/hourglass-clock-time-period-hours-2910951/)

### 为什么要分析内存使用情况？

假设你已经编写了一个很酷的机器学习（ML）应用程序或创建了一个炫目的神经网络模型。现在你想将这个模型部署到某个网络服务或REST API上。

或者，你可能是基于来自制造厂工业传感器的数据流开发了这个模型，现在你需要将模型部署到一个工业控制计算机上，以便根据持续输入的数据做出决策。

![](../Images/d3c66c70d3e3d5a01f9a613c092c6a39.png)

“兴奋地开发了一个炫目的ML模型”。 图片来源：[Pixabay](https://pixabay.com/photos/children-win-success-video-game-593313/)

作为数据科学家，你可能会经常遇到来自工程/平台团队的一个非常常见的问题：“***你的模型/代码的内存占用有多大？***” 或 “***当代码在某些数据负载下运行时，内存的峰值使用量是多少？***”

这是很自然的疑问，因为**硬件资源可能有限**，单个ML模块不应占用系统的全部内存。这在**边缘计算场景中尤为重要**，即ML应用程序可能在边缘运行，例如在工业PC上的虚拟化容器内。

此外，你的模型可能是运行在那块硬件上的数百个模型之一，你必须对**内存峰值使用量有一些了解**，因为如果多个模型在同一时间内存使用量达到峰值，可能会导致系统崩溃。

现在，这让你感到好奇了，不是吗？

![](../Images/60dfc75688808c42908777a9085c8b0e.png)

图片来源：[Pixabay](https://pixabay.com/photos/child-surprise-think-interactivity-2800835/)

> **… 硬件资源可能有限**，单个ML模块不应占用系统的全部内存。这在**边缘计算场景中尤为重要…**

### 不要犯这个基本错误

请注意，我们讨论的是你整个代码的运行时内存配置文件（一个动态量）。这与ML模型的大小或压缩（你可能将其保存为磁盘上的特殊对象，例如[Scikit-learn Joblib dump](https://scikit-learn.org/stable/modules/model_persistence.html)、一个简单的Python Pickle dump、[TensorFlow HFD5](https://www.tensorflow.org/tutorials/keras/save_and_load)等）无关。

### Scalene：一个整洁的小型内存/CPU/GPU分析器

这里有一篇关于一些旧的内存分析工具的文章，可以与Python一起使用。

[**如何管理Python中的内存**](https://www.pluralsight.com/guides/profiling-memory-usage-in-python)

在这篇文章中，我们将讨论 **Scalene** —— 这是你解答工程团队提出的这些问题的一站式工具。

根据其 [GitHub 页面](https://github.com/plasma-umass/scalene)，“*Scalene 是一个高性能的 CPU、GPU 和内存分析工具，用于 Python，它做了其他 Python 分析工具不能做的事情。它比其他分析工具运行速度快几个数量级，同时提供更详细的信息。*”

它在马萨诸塞大学开发。查看这个视频以获得全面的介绍。

### 安装

毕竟它是一个 Python 包。因此，通常需要进行安装，

```py
**pip install scalene**
```

目前仅适用于 Linux 操作系统。我没有在 Windows 10 上测试过。

### 在 CLI 或 Jupyter Notebook 内部使用

使用 Scalene 非常简单，

```py
**scalene <yourapp.py>**
```

或者，你可以通过使用这个魔法命令在 Jupyter notebook 内部使用它，

```py
**%load_ext scalene**
```

### 示例输出

这是一个示例输出。我们将很快深入探讨这个问题。

![](../Images/56327d172e1146bf408b00075cfc9130.png)

### 特性

以下是 Scalene 一些很酷的功能。大多数功能显而易见，可以从上面的截图中看出，

+   **行或函数**：报告整个函数和每一行独立代码的信息

+   **线程**：它支持 Python 线程。

+   **多进程**：支持使用 `multiprocessing` 库

+   **Python vs. C 时间**：Scalene 区分 Python 代码与本地代码（例如库）所花费的时间

+   **系统时间**：它区分系统时间（例如，休眠或执行 I/O 操作）

+   **GPU**：它也可以报告在 NVIDIA GPU 上（如果存在）的时间

+   **复制量**：报告每秒复制的数据量（以 MB 为单位）

+   **检测泄漏**：Scalene 可以自动定位可能导致内存泄漏的代码行！

### 一个具体的机器学习代码示例

让我们开始使用 Scalene 进行内存分析的标准机器学习代码。我们将查看两种不同类型的 ML 模型——原因将在不久后说明。我们将使用 Scikit-learn 库进行所有三个模型，并利用其合成数据生成函数来创建我们的数据集。

+   一个多元线性回归模型

+   使用相同数据集的深度神经网络模型

模型代码在所有三个模型中遵循完全相同的结构。外部 I/O 操作在下图中也有所指示，因为我们将看到这些操作可能会主导或不主导内存分析，具体取决于模型的类型。

![](../Images/bad072eafb90ed13e967f39d8e78549e.png)

图片来源：作者制作（拥有版权）

### 线性回归模型

代码文件在 [这里我的 GitHub 仓库](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)。

我们使用标准导入和两个变量 `NUM_FEATURES` 和 `NUM_SAMPLES` 进行一些后续实验。

![](../Images/13f542dad7e5f782d08833165ac26985.png)

我们没有展示数据生成和模型拟合的代码。这些代码相当标准，可以在[这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)看到。我们将拟合的模型保存为pickle格式，并与测试CSV文件一起加载进行推断。

![](../Images/58d405dfd5cbd73c8c812d6b95f98183.png)

我们在`main`循环中运行所有内容，以便于Scalene执行和报告（你很快会明白）。

![](../Images/ff5d40503e1cab93aaa148f919586e68.png)

当我们运行命令时，

```py
$ scalene linearmodel.py --html >> linearmodel-scalene.html
```

我们得到这些结果作为输出。**注意，这里我使用了`**--html**`标志，并将输出通过管道传送到HTML文件中以便于报告**。

![](../Images/b9a015457f196fb99f274789ee2c8455.png)

![](../Images/f47459e528414a38fd1903b9ed9792b7.png)

### **那么，这个结果中最引人注目的是什么？**

内存占用几乎完全由外部I/O（如Pandas和Scikit-learn估计器加载）主导，只有极少部分用于将测试数据写入磁盘上的CSV文件。

实际的机器学习建模、Numpy或Pandas操作以及推断完全不会影响内存！

### 随着模型和数据规模的扩大，会发生什么？

我们可以扩展数据集大小（行数）和模型复杂性（特征数量），并运行相同的内存分析，以记录各种操作在内存消耗方面的行为。结果如下所示。

在这里，**X轴表示特征数量/数据点数量的配对**。请注意，此图展示的是百分比而非绝对值，以突出各种操作的相对重要性。

![](../Images/bfadee308ec5d1872491b943029cc923.png)

图片来源：作者制作（拥有版权）

### 所以，对于线性回归模型……

从这些实验中，我们得出结论，Scikit-learn的线性回归估计器非常高效，并且**在实际模型拟合或推断时不会消耗太多内存**。

不过，它在代码方面有一个固定的内存占用，并在加载时消耗了这么多内存。然而，随着数据大小和模型复杂性的增加，这部分代码占用的百分比会下降。

因此，如果你正在使用这样的**小型线性模型，那么你可能需要专注于数据文件的I/O以优化你的代码**以获得更好的内存性能。

### 深度神经网络会发生什么？

如果我们用一个具有2个隐藏层（每个隐藏层50个神经元）的神经网络运行类似的实验，那么结果如下所示。 [代码文件在这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/mlp.py)。

![](../Images/bdc5ab77dc5b38015239b35d40d382bd.png)

图片来源：作者制作（拥有版权）

很明显，**神经网络模型在训练/拟合阶段消耗大量内存，这与线性回归模型不同**。然而，对于特征数量较少而数据量较大的情况，拟合所需的内存量较低。

你还可以尝试各种架构和超参数，并记录内存使用情况，以找到适合你情况的设置。

### 采取实验方法

如果你重复使用相同的[代码文件](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Memory-profiling/Scalene)进行实验，结果将根据你的硬件、磁盘/ CPU/ GPU/ 内存类型而有很大不同。本文的目的是不关注实际值或趋势。我希望你能够掌握为自己的代码进行内存性能分析实验的方法。

### 一些关键建议

+   尽可能编写**专注于单一任务的小函数**。

+   保持一些**自由变量**，如特征数量和数据点数量，以便在数据/模型扩展时可以对相同的代码文件进行最小更改并检查内存配置。

+   如果你在比较一个机器学习算法与另一个，尽量保持**整体代码的结构和流程尽可能相同**，以减少混淆。最好只更改估算器类并比较内存配置。

+   **数据和模型的输入/输出**（导入语句、模型在磁盘上的持久化）在内存占用方面可能会出乎意料地占据主导地位，具体取决于你的建模场景。在进行优化时，绝不要忽视它们。

+   出于上述原因，考虑比较**多个实现/包中相同算法的内存配置**（例如Keras与PyTorch与Scikit-learn）。如果内存优化是你的主要目标，你可能需要寻找内存占用最少但仍能令人满意地完成工作的实现，即使它在功能或性能方面不是绝对最佳的。

+   如果数据输入/输出成为瓶颈，可以探索**更快的选项或其他存储类型**，例如用parquet文件和Apache Arrow存储替换Pandas CSV。查看这篇文章，

[**读取Parquet文件（使用Arrow）与CSV文件（使用Pandas）的速度有多快？**](https://towardsdatascience.com/how-fast-is-reading-parquet-file-with-arrow-vs-csv-with-pandas-2f8095722e94)

### 使用Scalene可以做的其他事情

在这篇文章中，我们仅讨论了最基本的内存性能分析，重点是经典的机器学习建模代码。Scalene CLI还提供了其他选项，你可以加以利用，

+   仅对CPU时间进行性能分析，不分析内存。

+   仅减少有非零内存占用的性能分析

+   指定CPU和内存分配的最小阈值

+   设置CPU采样率

+   多线程并检查差异

### 最终验证有时是必要的。

对于资源有限的情况，建议托管一个验证环境/服务器，该服务器将接受给定的建模代码（开发完成后），并通过内存分析器运行该代码以生成运行时统计数据。如果它符合预定的内存占用标准，则该建模代码才会被接受以进行进一步部署。

![](../Images/834d9c2379f2cc82d9c48a779e04b4cc.png)

图片来源：作者制作（拥有版权）

> 如果内存优化是你的主要目标，你可能需要寻找一个内存占用最小但能令人满意地完成工作的实现。

### 摘要

在这篇文章中，我们讨论了内存分析对你的机器学习代码的重要性，以便与将代码部署到服务/机器上的平台/工程团队顺利对接。内存分析还可以展示优化代码的意外方式，基于你处理的数据和算法。

我们展示了一个典型的机器学习建模代码示例，并使用了强大而轻量的 Python 库 Scalene 进行分析。我们展示了一些线性回归和神经网络模型的代表性结果，并提供了一些通用建议。

希望你在使用这些工具和技术实现并部署你的机器学习代码时取得更多成功。

你可以查看作者的 [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** 仓库 **以获取机器学习和数据科学方面的代码、想法和资源。如果你像我一样，对 AI/机器学习/数据科学充满热情，请随时 [在 LinkedIn 上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) 或 [关注我的 Twitter](https://twitter.com/tirthajyotiS)。

[原文](https://towardsdatascience.com/how-much-memory-is-your-ml-code-consuming-98df64074c8f)。经许可转载。

**相关：**

+   [作为数据科学家的可重用 Python 代码管理](/2021/06/managing-reusable-python-code-data-scientist.html)

+   [5 个 Python 数据处理技巧及代码片段](/2021/07/python-tips-snippets-data-processing.html)

+   [GitHub Copilot：你的 AI 编程伙伴 – 这究竟有什么大惊小怪？](/2021/07/github-copilot-ai-pair-programmer.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 更多相关话题

+   [一种（更佳的）评估机器学习模型的方法](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)

+   [你在数据科学中需要多少数学知识？](https://www.kdnuggets.com/2020/06/math-data-science.html)

+   [数据科学家在2022年赚多少钱？](https://www.kdnuggets.com/2022/02/much-data-scientists-make-2022.html)

+   [如何使用Pandas在大数据集上执行内存高效的操作](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)

+   [变压器的内存复杂性](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)

+   [Python中的内存分析简介](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)
