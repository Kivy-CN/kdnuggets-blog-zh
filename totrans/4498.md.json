["```py\n # Import everything\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Create a DataFrame\ndf = pd.read_csv('KNN_Project_Data')\n\n# Print the head of the data.\ndf.head() \n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(df.drop('TARGET CLASS', axis=1))\nsc_transform = scaler.transform(df.drop('TARGET CLASS', axis=1))\nsc_df = pd.DataFrame(sc_transform)\n\n# Now you can safely use sc_df as your input features.\nsc_df.head() \n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX = sc_transform\ny = df['TARGET CLASS']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) \n```", "```py\n# Initialize an array that stores the error rates.\nfrom sklearn.neighbors import KNeighborsClassifier\n\nerror_rates = []\n\nfor a in range(1, 40):\n    k = a\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    preds = knn.predict(X_test)\n    error_rates.append(np.mean(y_test - preds))\n\nplt.figure(figsize=(10, 7))\nplt.plot(range(1,40),error_rates,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate') \n```", "```py\nk = 30\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train, y_train)\npreds = knn.predict(X_test) \n```", "```py\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nprint(confusion_matrix(y_test, preds))\nprint(classification_report(y_test, preds)) \n```"]