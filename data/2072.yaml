- en: 37 Reasons why your Neural Network is not working
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 37 个原因说明你的神经网络无法工作
- en: 原文：[https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html](https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html](https://www.kdnuggets.com/2017/08/37-reasons-neural-network-not-working.html)
- en: '[comments](/2017/08/37-reasons-neural-network-not-working.html/2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](/2017/08/37-reasons-neural-network-not-working.html/2#comments)'
- en: '**By [Slav Ivanov](https://twitter.com/slavivanov), Entrepreneur & ML Practitioner**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Slav Ivanov](https://twitter.com/slavivanov)，企业家与机器学习从业者**。'
- en: 'The network had been training for the last 12 hours. It all looked good: the
    gradients were flowing and the loss was decreasing. But then came the predictions:
    all zeroes, all background, nothing detected. “What did I do wrong?” — I asked
    my computer, who didn’t answer.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 网络已经训练了过去 12 个小时。一切看起来都很好：梯度在流动，损失在减少。但随后预测出来的结果是：全是零，全是背景，什么也没检测到。“我哪里做错了？”——我问我的电脑，但它没有回答。
- en: Where do you start checking if your model is outputting garbage (for example
    predicting the mean of all outputs, or it has really poor accuracy)?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的模型输出垃圾（例如预测所有输出的均值，或准确率非常差），你应该从哪里开始检查？
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A network might not be training for a number of reasons. Over the course of
    many debugging sessions, I would often find myself doing the same checks. I’ve
    compiled my experience along with the best ideas around in this handy list. I
    hope they would be of use to you, too.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可能因为多种原因而无法训练。在多次调试过程中，我经常发现自己进行相同的检查。我将我的经验以及周围的最佳建议编成了这份实用的清单。希望对你也有帮助。
- en: Table of Contents
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目录
- en: 0\. How to use this guide?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0\. 如何使用本指南？
- en: I. Dataset issues
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I. 数据集问题
- en: II. Data Normalization/Augmentation issues
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: II. 数据规范化/增强问题
- en: III. Implementation issues
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: III. 实施问题
- en: IV. Training issues
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IV. 训练问题
- en: 0\. How to use this guide?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 0\. 如何使用本指南？
- en: 'A lot of things can go wrong. But some of them are more likely to be broken
    than others. I usually start with this short list as an emergency first response:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 许多事情可能会出错。但其中一些比其他的更容易出问题。我通常会从这个紧急响应的短名单开始：
- en: Start with a simple model that is known to work for this type of data (for example,
    VGG for images). Use a standard loss if possible.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个已知对这种数据类型有效的简单模型开始（例如，VGG 用于图像）。如果可能，使用标准损失函数。
- en: Turn off all bells and whistles, e.g. regularization and data augmentation.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭所有的附加功能，例如正则化和数据增强。
- en: If fine-tuning a model, double check the preprocessing, for it should be the
    same as the original model’s training.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果对模型进行微调，务必再次检查预处理步骤，确保它与原始模型的训练一致。
- en: Verify that the input data is correct.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证输入数据是否正确。
- en: Start with a really small dataset (2–20 samples). Overfit on it and gradually
    add more data.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个非常小的数据集（2–20 个样本）开始。在其上进行过拟合，并逐渐增加更多的数据。
- en: 'Start gradually adding back all the pieces that were omitted: augmentation/regularization,
    custom loss functions, try more complex models.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逐渐添加所有被省略的部分：增强/正则化、自定义损失函数，尝试更复杂的模型。
- en: If the steps above don’t do it, start going down the following big list and
    verify things one by one.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述步骤不起作用，开始逐项检查以下大清单。
- en: I. Dataset issues
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I. 数据集问题
- en: '![](../Images/63268de4720c5d16ff843c53129d4356.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63268de4720c5d16ff843c53129d4356.png)'
- en: 1\. Check your input data
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1\. 检查你的输入数据
- en: Check if the input data you are feeding the network makes sense. For example,
    I’ve more than once mixed the width and the height of an image. Sometimes, I would
    feed all zeroes by mistake. Or I would use the same batch over and over. So print/display
    a couple of batches of input and target output and make sure they are OK.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 检查你提供给网络的输入数据是否合理。例如，我曾多次混淆图像的宽度和高度。有时，我会错误地输入全零的数据。或者我会一遍又一遍地使用同一批数据。因此，打印/显示几批输入和目标输出，确保它们是正确的。
- en: 2\. Try random input
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2\. 尝试随机输入
- en: Try passing random numbers instead of actual data and see if the error behaves
    the same way. If it does, it’s a sure sign that your net is turning data into
    garbage at some point. Try debugging layer by layer /op by op/ and see where things
    go wrong.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试传递随机数字而不是实际数据，看看错误是否表现得一样。如果是，那就说明你的网络在某个点上把数据变成了垃圾。尝试逐层/逐操作调试，看看问题出在哪里。
- en: 3\. Check the data loader
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3\. 检查数据加载器
- en: Your data might be fine but the code that passes the input to the net might
    be broken. Print the input of the first layer before any operations and check
    it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据可能没问题，但将输入传递给网络的代码可能有问题。在任何操作之前，打印第一层的输入并检查它。
- en: 4\. Make sure input is connected to output
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4\. 确保输入与输出相连
- en: Check if a few input samples have the correct labels. Also make sure shuffling
    input samples works the same way for output labels.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一些输入样本是否有正确的标签。还要确保打乱输入样本的方式对于输出标签也一样有效。
- en: 5\. Is the relationship between input and output too random?
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5\. 输入和输出之间的关系是否过于随机？
- en: Maybe the non-random part of the relationship between the input and output is
    too small compared to the random part (one could argue that stock prices are like
    this). I.e. the input are not sufficiently related to the output. There isn’t
    an universal way to detect this as it depends on the nature of the data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 也许输入和输出之间的非随机关系相比于随机部分太小（可以说股票价格就是这样）。即输入与输出之间的关系不够紧密。没有通用的方法来检测这个问题，因为这取决于数据的性质。
- en: 6\. Is there too much noise in the dataset?
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6\. 数据集中的噪声是否过多？
- en: This happened to me once when I scraped an image dataset off a food site. There
    were so many bad labels that the network couldn’t learn. Check a bunch of input
    samples manually and see if labels seem off.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经在从一个食品网站抓取图像数据集时遇到过这种情况。标签错误太多，以至于网络无法学习。手动检查一批输入样本，看看标签是否有问题。
- en: The cutoff point is up for debate, as [this paper](https://arxiv.org/pdf/1412.6596.pdf) got
    above 50% accuracy on MNIST using 50% corrupted labels.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点尚有争议，因为[这篇论文](https://arxiv.org/pdf/1412.6596.pdf)在使用50%标签被破坏的情况下在MNIST上达到了超过50%的准确率。
- en: 7\. Shuffle the dataset
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7\. 打乱数据集
- en: If your dataset hasn’t been shuffled and has a particular order to it (ordered
    by label) this could negatively impact the learning. Shuffle your dataset to avoid
    this. Make sure you are shuffling input and labels together.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据集没有被打乱，并且有特定的顺序（按标签排序），这可能会对学习产生负面影响。打乱你的数据集以避免这种情况。确保你同时打乱输入和标签。
- en: 8\. Reduce class imbalance
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8\. 减少类别不平衡
- en: Are there a 1000 class A images for every class B image? Then you might need
    to balance your loss function or [try other class imbalance approaches](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 是否每个类别B图像都有1000张类别A图像？那么你可能需要平衡你的损失函数或[尝试其他类别不平衡的方法](http://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)。
- en: 9\. Do you have enough training examples?
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9\. 你是否有足够的训练样本？
- en: If you are training a net from scratch (i.e. not finetuning), you probably need
    lots of data. For image classification, [people say](https://stats.stackexchange.com/a/226693/30773) you
    need a 1000 images per class or more.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从头开始训练一个网络（即不是微调），你可能需要大量数据。对于图像分类，[有人说](https://stats.stackexchange.com/a/226693/30773)你每个类别需要1000张图像或更多。
- en: 10\. Make sure your batches don’t contain a single label
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10\. 确保你的批次不包含单一标签
- en: This can happen in a sorted dataset (i.e. the first 10k samples contain the
    same class). Easily fixable by shuffling the dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在排序的数据集中（即前10k个样本包含相同的类别）可能会发生这种情况。通过打乱数据集可以轻松解决。
- en: 11\. Reduce batch size
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11\. 减少批量大小
- en: '[This paper](https://arxiv.org/abs/1609.04836) points out that having a very
    large batch can reduce the generalization ability of the model.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[这篇论文](https://arxiv.org/abs/1609.04836)指出，拥有非常大的批次可能会降低模型的泛化能力。'
- en: Addition 1\. Use standard dataset (e.g. mnist, cifar10)
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 附加 1\. 使用标准数据集（例如 mnist，cifar10）
- en: 'Thanks to @[hengcherkeng](https://medium.com/@hengcherkeng) for this one:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢@[hengcherkeng](https://medium.com/@hengcherkeng)的分享：
- en: When testing new network architecture or writing a new piece of code, use the
    standard datasets first, instead of your own data. This is because there are many
    reference results for these datasets and they are proved to be ‘solvable’. There
    will be no issues of label noise, train/test distribution difference , too much
    difficulty in dataset, etc.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在测试新的网络架构或编写新代码时，首先使用标准数据集，而不是你自己的数据。这是因为这些数据集有许多参考结果，并且被证明是“可解决的”。不会有标签噪声、训练/测试分布差异、数据集难度过大等问题。
- en: II. Data Normalization/Augmentation
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II. 数据标准化/增强
- en: '![](../Images/56f24da5948f3ae4863dff3e9c3d02f6.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56f24da5948f3ae4863dff3e9c3d02f6.png)'
- en: '**12\. Standardize** the features'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12\. 标准化** 特征'
- en: Did you standardize your input to have zero mean and unit variance?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否将输入标准化为零均值和单位方差？
- en: 13\. Do you have too much data augmentation?
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13\. 你是否进行过多的数据增强？
- en: Augmentation has a regularizing effect. Too much of this combined with other
    forms of regularization (weight L2, dropout, etc.) can cause the net to underfit.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强具有正则化效果。过多的增强与其他形式的正则化（如权重L2、dropout等）结合使用，可能导致模型欠拟合。
- en: 14\. Check the preprocessing of your pretrained model
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 14\. 检查你的预训练模型的预处理
- en: If you are using a pretrained model, make sure you are using the same normalization
    and preprocessing as the model was when training. For example, should an image
    pixel be in the range [0, 1], [-1, 1] or [0, 255]?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用了预训练模型，确保你使用的归一化和预处理与训练时的模型一致。例如，图像像素应该在[0, 1]、[-1, 1]还是[0, 255]范围内？
- en: 15\. Check the preprocessing for train/validation/test set
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15\. 检查训练/验证/测试集的预处理
- en: 'CS231n points out a [common pitfall](http://cs231n.github.io/neural-networks-2/#datapre):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 'CS231n 指出一个 [常见的陷阱](http://cs231n.github.io/neural-networks-2/#datapre):'
- en: “… any preprocessing statistics (e.g. the data mean) must only be computed on
    the training data, and then applied to the validation/test data. E.g. computing
    the mean and subtracting it from every image across the entire dataset and then
    splitting the data into train/val/test splits would be a mistake. “
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “… 任何预处理统计（例如数据均值）必须仅在训练数据上计算，然后应用于验证/测试数据。例如，计算均值并从整个数据集的每张图像中减去，然后将数据拆分为训练/验证/测试集将是一个错误。”
- en: Also, check for different preprocessing in each sample or batch.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，检查每个样本或批次中的不同预处理。
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么你应该使用线性回归模型而不是……](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以找到目标，并以找到目标来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为一名出色的数据科学家需要的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，解析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
