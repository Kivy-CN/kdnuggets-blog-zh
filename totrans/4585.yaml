- en: Train sklearn 100x Faster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练 sklearn 快速 100 倍
- en: 原文：[https://www.kdnuggets.com/2019/09/train-sklearn-100x-faster.html](https://www.kdnuggets.com/2019/09/train-sklearn-100x-faster.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/09/train-sklearn-100x-faster.html](https://www.kdnuggets.com/2019/09/train-sklearn-100x-faster.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Evan Harris](https://www.linkedin.com/in/evan-harris-387375b2/), Manager,
    Machine Learning and Data Science at Ibotta, Inc.**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Evan Harris](https://www.linkedin.com/in/evan-harris-387375b2/)，Ibotta,
    Inc. 机器学习与数据科学经理**'
- en: At Ibotta we train a lot of machine learning models. These models power our
    recommendation system, search engine, pricing optimization engine, data quality,
    and more. They make predictions for millions of users as they interact with our
    mobile app.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在Ibotta，我们训练了大量的机器学习模型。这些模型驱动了我们的推荐系统、搜索引擎、定价优化引擎、数据质量等。它们为数百万用户提供预测，用户在使用我们的移动应用时会与这些模型互动。
- en: While we do much of our data processing with [Spark](https://spark.apache.org/),
    our preferred machine learning framework is [scikit-learn](https://scikit-learn.org/stable/).
    As compute gets cheaper and time to market for machine learning solutions becomes
    more critical, we’ve explored options for speeding up model training. One of those
    solutions is to combine elements from Spark and scikit-learn into our own hybrid
    solution.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们用[Spark](https://spark.apache.org/)处理了很多数据，但我们首选的机器学习框架是[scikit-learn](https://scikit-learn.org/stable/)。随着计算成本的降低以及机器学习解决方案的市场时间变得越来越关键，我们探索了加速模型训练的选项。解决方案之一是将Spark和scikit-learn的元素结合成我们自己的混合解决方案。
- en: Introducing sk-dist
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍 sk-dist
- en: We are excited to announce the launch of our open source project [sk-dist](https://github.com/Ibotta/sk-dist).
    The goal of the project is to provide a general framework for distributing scikit-learn
    meta-estimators with Spark. Examples of meta-estimators are decision tree ensembles
    ([random forests](https://en.wikipedia.org/wiki/Random_forest) and [extra randomized
    trees](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)), [hyperparameter
    tuners](https://scikit-learn.org/stable/modules/grid_search.html) ([grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) and [randomized
    search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV))
    and multi-class techniques ([one vs rest](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier) and [one
    vs one](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很高兴地宣布我们的开源项目[sk-dist](https://github.com/Ibotta/sk-dist)的上线。该项目的目标是提供一个通用框架，以便在Spark中分发scikit-learn元估计器。元估计器的例子包括决策树集成（[随机森林](https://en.wikipedia.org/wiki/Random_forest)
    和 [额外随机树](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)）、[超参数调优器](https://scikit-learn.org/stable/modules/grid_search.html)（[网格搜索](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)
    和 [随机搜索](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)）以及多类技术（[一对其余](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier)
    和 [一对一](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsOneClassifier.html#sklearn.multiclass.OneVsOneClassifier)）。
- en: '![](../Images/4df608e27f8783fb241b1762eed6f489.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4df608e27f8783fb241b1762eed6f489.png)'
- en: Our primary motivation is to fill a void in the space of options for distributing
    traditional machine learning models. Outside of the space of neural networks and
    deep learning, we find that much of our compute time for training models is not
    spent on training a single model on a single dataset. The bulk of time is spent
    training multiple iterations of a model on multiple iterations of a dataset using
    meta-estimators like grid search or ensembles.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要动机是填补传统机器学习模型分发选项中的空白。在神经网络和深度学习的领域之外，我们发现，训练模型的大部分计算时间并不是用来在单一数据集上训练单一模型。大部分时间用于在多个数据集的多个迭代上训练多个模型，使用像网格搜索或集成这样的元估计器。
- en: Example
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例
- en: Consider the [hand written digits dataset](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html).
    Here we have encoded images of hand written digits to be classified appropriately.
    We can train a [support vector machine](https://en.wikipedia.org/wiki/Support-vector_machine) on
    this dataset of 1797 records very quickly on a single machine. It takes under
    a second. But hyperparameter tuning requires a number of training jobs on different
    subsets of the training data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下 [手写数字数据集](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)。在这里，我们已经对手写数字图像进行了编码，以便进行适当分类。我们可以在单台机器上非常快速地训练一个
    [支持向量机](https://en.wikipedia.org/wiki/Support-vector_machine) 处理 1797 条记录的数据集。这只需不到一秒钟。但超参数调整需要在不同的训练数据子集上进行多个训练作业。
- en: Shown below, we’ve built a parameter grid totaling 1050 required training jobs.
    It takes only 3.4 seconds with sk-dist on a Spark cluster with over a hundred
    cores. The total task time of this job is 7.2 minutes, meaning it would take this
    long to train on a single machine with no parallelization.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，我们构建了一个总共需要 1050 个训练作业的参数网格。在具有超过一百个核心的 Spark 集群上使用 sk-dist 只需 3.4 秒。此作业的总任务时间为
    7.2 分钟，这意味着在没有并行化的情况下，单台机器上训练将需要这么长时间。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This example illustrates the common scenario where fitting data into memory
    and training a single classifier is trivial but the number of required fits for
    hyperparameter tuning adds up quickly. Here is a look under the hood at running
    a grid search problem like the above example with sk-dist:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子说明了一个常见的场景，其中将数据适配到内存并训练单个分类器是微不足道的，但超参数调整所需的拟合次数很快就会增加。以下是使用 sk-dist 运行如上例的网格搜索问题的幕后分析：
- en: '![Figure](../Images/282b2a6db0d1e7459055893272e39ba7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/282b2a6db0d1e7459055893272e39ba7.png)'
- en: Grid Search with sk-dist
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 sk-dist 的网格搜索
- en: 'For real-world applications of traditional machine learning at Ibotta, we often
    find ourselves in a similar situation: small to medium sized data (100k to 1M
    records) with many iterations of simple classifiers to fit for hyperparameter
    tuning, ensembles and multi-class solutions.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Ibotta 的传统机器学习实际应用中，我们经常发现自己处于类似的情况：小到中等规模的数据（10 万到 100 万条记录），需要多次迭代简单的分类器以进行超参数调整、集成和多类解决方案。
- en: Existing Solutions
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现有解决方案
- en: 'There are existing solutions to distributing traditional machine learning meta-estimator
    training. The first is the simplest: scikit-learn’s built-in parallelization of
    meta-estimators using [joblib](https://joblib.readthedocs.io/en/latest/). This
    operates very similarly to sk-dist, except for one major constraint: performance
    is limited to the resources of any one machine. Even versus a theoretical single
    machine with hundreds of cores, Spark still has advantages like [fine tuned memory
    specification for executors](https://spark.apache.org/docs/latest/tuning.html), [fault
    tolerance](https://techvidvan.com/tutorials/fault-tolerance-in-spark/), as well
    as cost control options like using [spot instances](https://aws.amazon.com/ec2/spot/) for
    worker nodes.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有一些解决方案用于分布式传统机器学习元估计器训练。第一个是最简单的：scikit-learn 内置的使用 [joblib](https://joblib.readthedocs.io/en/latest/)
    的元估计器并行化。这与 sk-dist 的操作非常相似，除了一个主要限制：性能受限于任何一台机器的资源。即使与理论上拥有数百个核心的单台机器相比，Spark
    仍具有诸如 [针对执行器的精细调优内存规范](https://spark.apache.org/docs/latest/tuning.html)、[容错](https://techvidvan.com/tutorials/fault-tolerance-in-spark/)
    以及像使用 [抢占实例](https://aws.amazon.com/ec2/spot/) 作为工作节点的成本控制选项等优势。
- en: Another existing solution is [Spark ML](https://spark.apache.org/docs/latest/ml-guide.html).
    This is Spark’s native machine learning library, supporting many of the same algorithms
    as scikit-learn for classification and regression problems. It also has meta-estimators
    like tree ensembles and grid search, as well as support for multi-class problems.
    While this sounds like it may be a sufficient solution for distributing scikit-learn
    style machine learning workloads, it distributes training in a way that doesn’t
    solve the kind of parallelism of interest to us.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种现有解决方案是 [Spark ML](https://spark.apache.org/docs/latest/ml-guide.html)。这是
    Spark 的原生机器学习库，支持许多与 scikit-learn 相同的分类和回归算法。它还具有像树集成和网格搜索这样的元估计器，并支持多类问题。虽然这听起来可能是一个足以分布式处理
    scikit-learn 风格机器学习负载的解决方案，但它的分布式训练方式并未解决我们关心的并行性问题。
- en: '![Figure](../Images/3fcf7a970a8832f2998bd8ca037f6870.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3fcf7a970a8832f2998bd8ca037f6870.png)'
- en: Distributed on Different Dimensions
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同维度上的分布式
- en: As shown above, Spark ML will train a single model on data that is distributed
    on many executors. This works well when data is large and won’t fit into memory
    on a single machine. However, when data is small this can *underperform* scikit-learn
    on a single machine. Furthermore, when training a random forest for example, Spark
    ML trains each decision tree in sequence. Wall time for this job will scale linearly
    with the number of decision trees regardless of the resources allocated to the
    job.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，Spark ML 会在分布在多个执行器上的数据上训练一个单一模型。当数据量很大且无法适应单台机器的内存时，这种方法效果很好。然而，当数据量较小时，这可能会导致
    scikit-learn 在单台机器上表现*不如预期*。此外，例如，在训练随机森林时，Spark ML 会按顺序训练每棵决策树。无论为此任务分配了多少资源，其壁垒时间将随着决策树数量的增加而线性增长。
- en: For [grid search, Spark ML](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) does
    implement a [parallelism](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator.parallelism) parameter
    that will train [individual models in parallel](https://issues.apache.org/jira/browse/SPARK-19357).
    However each individual model is still training on data that is distributed across
    executors. The total parallelism of the job is a [fraction of what it could be](https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py) if
    distributed purely along the dimension of models rather than data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于[网格搜索，Spark ML](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator)确实实现了一个[并行](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator.parallelism)参数，该参数可以[并行训练单独模型](https://issues.apache.org/jira/browse/SPARK-19357)。然而，每个单独的模型仍然是在分布在执行器上的数据上进行训练的。如果纯粹沿模型维度而非数据维度进行分布，该任务的总并行度是[可以有的一个小数](https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py)。
- en: Ultimately, we want to distribute our training on a different dimension than
    that of Spark ML. When using small or medium data, fitting the data into memory
    is not a problem. For the random forest example, we want to broadcast the training
    data in full to each executor, fit an independent decision tree on each executor,
    and bring those fitted decision trees back to the driver to assemble a random
    forest. Distributing along this dimension can be [orders of magnitude faster](https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py) than
    distributing the data and training decision trees in serial. This behavior is
    similar for other meta-estimator techniques like grid search and multi-class.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们希望在不同于 Spark ML 的维度上分布我们的训练。当使用小型或中型数据时，将数据适配到内存中并不是问题。以随机森林为例，我们希望将完整的训练数据广播到每个执行器，分别在每个执行器上拟合一个独立的决策树，然后将这些拟合的决策树带回驱动程序以组装随机森林。沿此维度分布可以比将数据分布和串行训练决策树快[数量级](https://github.com/Ibotta/sk-dist/blob/master/examples/search/spark_ml.py)得多。其他元估计技术，如网格搜索和多类别，也有类似的行为。
- en: Features
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特性
- en: Given the limitations of these existing solutions in our problem space, we decided
    to develop sk-dist in-house. The bottom line is that we want to **distribute models,
    not data**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些现有解决方案在我们问题空间中的局限性，我们决定内部开发 sk-dist。底线是我们想要**分布模型，而不是数据**。
- en: While the primary focus is on distributed training of meta-estimators, sk-dist
    also includes modules for distributed prediction of scikit-learn models with Spark,
    several pre/post processing scikit-learn transformers for use without Spark, and
    a flexible feature encoder for use with or without Spark.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然主要关注的是元估计器的分布式训练，但 sk-dist 还包括用于与 Spark 进行 scikit-learn 模型分布式预测的模块、用于不使用 Spark
    的多个前处理/后处理 scikit-learn 转换器以及一个灵活的特征编码器，可在有或没有 Spark 的情况下使用。
- en: '**Distributed Training** — Distribute meta-estimator training with Spark. The
    following algorithms are supported: [Hyperparameter optimization](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/search.py) with
    grid search and randomized search, [tree ensembles](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/ensemble.py) with
    random forests, extra trees, and random trees embedding, and [multi-class strategies](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/multiclass.py) with
    one-vs-rest and one-vs-one. All of these meta-estimators mirror their scikit-learn
    counterparts after the fit.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式训练** — 使用 Spark 分发元估计器训练。支持以下算法：[超参数优化](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/search.py)（包括网格搜索和随机搜索）、[树集成](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/ensemble.py)（包括随机森林、额外树和随机树嵌入）以及[多类别策略](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/multiclass.py)（包括一对多和一对一）。所有这些元估计器在拟合后都与其
    scikit-learn 对应物一致。'
- en: '**Distributed Prediction** — [Distribute the prediction methods](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/predict.py) of
    fitted scikit-learn estimators with [Spark DataFrames](https://spark.apache.org/docs/latest/sql-programming-guide.html).
    This enables large scale distributed prediction with portable scikit-learn estimators
    that can be used with or without Spark.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式预测** — 使用[Spark DataFrames](https://spark.apache.org/docs/latest/sql-programming-guide.html)分发拟合的
    scikit-learn 估计器的预测方法。这样可以实现大规模的分布式预测，使用便携的 scikit-learn 估计器，可以选择是否使用 Spark。'
- en: '**Feature Encoding** — Distribute feature encoding with a flexible feature
    transformer called [Encoderizer](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/encoder.py).
    It functions with or without Spark parallelization. It will infer data types and
    shapes, automatically applying default feature transformers as a best guess implementation
    of standard feature encoding techniques. It can also be used as a fully customizable
    feature union-like encoder with the added advantage of distributed transformer
    fitting with Spark.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征编码** — 使用一个名为[Encoderizer](https://github.com/Ibotta/sk-dist/blob/master/skdist/distribute/encoder.py)的灵活特征变换器来分发特征编码。它可以在有无
    Spark 并行化的情况下运行。它会推断数据类型和形状，自动应用默认的特征变换器，以最佳猜测实现标准特征编码技术。它还可以作为一个完全可定制的特征联合编码器使用，具有
    Spark 分布式变换器拟合的附加优势。'
- en: Use Cases
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用例
- en: 'Here are some guidelines for deciding whether or not sk-dist is a good fit
    for your machine learning problem space:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些指导方针，用于决定 sk-dist 是否适合你的机器学习问题领域：
- en: '**Traditional Machine Learning** — Methods like [generalized linear models](https://scikit-learn.org/stable/modules/linear_model.html), [stochastic
    gradient descent](https://scikit-learn.org/stable/modules/sgd.html), [nearest
    neighbors](https://scikit-learn.org/stable/modules/neighbors.html), [decision
    trees](https://scikit-learn.org/stable/modules/tree.html), and [naive bayes](https://scikit-learn.org/stable/modules/naive_bayes.html) work
    well with sk-dist. These all have implementations in scikit-learn which are ready
    for direct implementation with sk-dist meta-estimators.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**传统机器学习** — 像[广义线性模型](https://scikit-learn.org/stable/modules/linear_model.html)、[随机梯度下降](https://scikit-learn.org/stable/modules/sgd.html)、[最近邻](https://scikit-learn.org/stable/modules/neighbors.html)、[决策树](https://scikit-learn.org/stable/modules/tree.html)和[朴素贝叶斯](https://scikit-learn.org/stable/modules/naive_bayes.html)等方法在
    sk-dist 中表现良好。这些方法在 scikit-learn 中都有实现，可以直接与 sk-dist 元估计器配合使用。'
- en: '**Small to Medium Sized Data** — Big data won’t work well with sk-dist. Keep
    in mind that the dimensionality of distribution of training is along the axis
    of the models, not the data. Data needs to not only fit in memory on each executor,
    but also be small enough to broadcast. Depending on Spark configuration, the maximum
    broadcast size can be limiting.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**小到中等规模数据** — 大数据与 sk-dist 不兼容。请记住，训练分布的维度沿着模型的轴，而不是数据。数据不仅需要能够适应每个执行器的内存，还需要足够小以便进行广播。根据
    Spark 配置，最大广播大小可能会成为限制因素。'
- en: '**Spark Orientation and Access** — The core functionality of sk-dist requires
    running Spark. This isn’t always feasible for individuals or small data science
    teams. Additionally, some Spark tuning and configuration will be necessary to
    get the most out of sk-dist in a cost effective way, which requires some training
    in Spark fundamentals.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Spark 定向和访问** — sk-dist 的核心功能需要运行 Spark。这对于个人或小型数据科学团队来说并不总是可行的。此外，还需要一些
    Spark 调优和配置，以成本效益的方式充分利用 sk-dist，这需要对 Spark 基础知识有一定的培训。'
- en: An important note here is that while neural networks and deep learning could
    technically be used with sk-dist, these techniques require large amounts of training
    data and sometimes specialized infrastructure to be effective. Deep learning is
    not an intended use case of sk-dist, as it violates (1) and (2) above. Alternatively,
    at Ibotta [we’ve been using](https://medium.com/building-ibotta/heating-up-word2vec-blazingtext-for-real-time-search-c2121bd1396) [Amazon
    SageMaker](https://aws.amazon.com/sagemaker/) for these techniques, which we’ve
    found to be a more efficient use of compute than Spark for these workloads.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，尽管神经网络和深度学习技术理论上可以与 sk-dist 一起使用，但这些技术需要大量的训练数据，有时还需要专门的基础设施才能有效。深度学习并不是
    sk-dist 的预期使用场景，因为它违背了上述 (1) 和 (2) 条。作为替代方案，我们在 Ibotta [使用了](https://medium.com/building-ibotta/heating-up-word2vec-blazingtext-for-real-time-search-c2121bd1396) [Amazon
    SageMaker](https://aws.amazon.com/sagemaker/) 进行这些技术，我们发现其在这些工作负载中的计算效率优于 Spark。
- en: Getting Started
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 入门指南
- en: To get started with sk-dist, check out the [installation guide](https://github.com/Ibotta/sk-dist#installation).
    The code repository also contains a library of [examples](https://github.com/Ibotta/sk-dist/tree/master/examples) to
    illustrate some of the use cases of sk-dist. [All are welcome](https://github.com/Ibotta/sk-dist/blob/master/CODE_OF_CONDUCT.md) to
    submit issues and contribute to the project.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 sk-dist，请查看 [安装指南](https://github.com/Ibotta/sk-dist#installation)。代码库还包含一个 [示例](https://github.com/Ibotta/sk-dist/tree/master/examples) 库，以展示
    sk-dist 的一些使用案例。 [欢迎所有人](https://github.com/Ibotta/sk-dist/blob/master/CODE_OF_CONDUCT.md) 提交问题并参与项目贡献。
- en: If these kinds of projects and challenges sound interesting to you, Ibotta is
    hiring! Check out our [jobs page](https://ibotta.com/careers) for more information.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些项目和挑战对您感兴趣，Ibotta 正在招聘！请查看我们的 [招聘页面](https://ibotta.com/careers) 了解更多信息。
- en: Thanks to charley frazier, Chad Foley, and Sam Weiss.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢 charley frazier、Chad Foley 和 Sam Weiss。
- en: '**Bio: [Evan Harris](https://www.linkedin.com/in/evan-harris-387375b2/)** is
    an experienced technologist specializing in data science and machine learning.
    He is currently leading a machine learning team which is building services for
    search relevancy, content recommendations, pricing optimization and fraud detection,
    powering a mobile application serving millions of users.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Evan Harris](https://www.linkedin.com/in/evan-harris-387375b2/)** 是一位经验丰富的技术专家，专注于数据科学和机器学习。他目前领导一个机器学习团队，致力于构建搜索相关性、内容推荐、定价优化和欺诈检测服务，支持一个服务于数百万用户的移动应用程序。'
- en: '[Original](https://medium.com/building-ibotta/train-sklearn-100x-faster-bec530fc1f45).
    Reposted with permission.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/building-ibotta/train-sklearn-100x-faster-bec530fc1f45)。经许可转载。'
- en: '**Related:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[Understanding Decision Trees for Classification in Python](/2019/08/understanding-decision-trees-classification-python.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解 Python 中的决策树分类](/2019/08/understanding-decision-trees-classification-python.html)'
- en: '[Advanced Keras — Accurately Resuming a Training Process](/2019/03/advanced-keras-accurately-resuming-training-process.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高级 Keras — 准确恢复训练过程](/2019/03/advanced-keras-accurately-resuming-training-process.html)'
- en: '[Distributed Artificial Intelligence: A primer on Multi-Agent Systems, Agent-Based
    Modeling, and Swarm Intelligence](/2019/04/distributed-artificial-intelligence-multi-agent-systems-agent-based-modeling-swarm-intelligence.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分布式人工智能：多智能体系统、基于代理的建模和群体智能简介](/2019/04/distributed-artificial-intelligence-multi-agent-systems-agent-based-modeling-swarm-intelligence.html)'
- en: '* * *'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT 服务'
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个 90 亿美元的人工智能失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学的统计学顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功的数据科学家的五个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个 R 语言库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
