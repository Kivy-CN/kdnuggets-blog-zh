- en: Urban Sound Classification with Neural Networks in Tensorflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/09/urban-sound-classification-neural-networks-tensorflow.html/2](https://www.kdnuggets.com/2016/09/urban-sound-classification-neural-networks-tensorflow.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Feature Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To extract the useful features from sound data, we will use *Librosa* library.
    It provides several methods to extract different features from the sound clips.
    We are going to use below mentioned methods to extract various features:'
  prefs: []
  type: TYPE_NORMAL
- en: '*melspectrogram*: Compute a Mel-scaled power spectrogram'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*mfcc*: Mel-frequency cepstral coefficients'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*chorma-stft*: Compute a chromagram from a waveform or power spectrogram'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*spectral_contrast*: Compute spectral contrast, using method defined in [[1](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1035731)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*tonnetz*: Computes the tonal centroid features (tonnetz), following the method
    of [[2](http://dl.acm.org/citation.cfm?id=1178727)]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To make the process of feature extraction from sound clips easy, two helper
    methods are defined. First *parse_audio_files* which takes parent directory name,
    subdirectories within parent directory and file extension (default is .wav) as
    input. It then iterates over all the files within subdirectories and call second
    helper function *extract_feature.* It takes file path as input, read the file
    by calling *librosa.load* method, extract and return features discussed above.
    These two methods are all we required to convert raw sound clips into informative
    features (along with a class label for each sound clip) that we can directly feed
    into our classifier. Remember, the class label of each sound clip is in the file
    name. For example, if the file name is *108041-9-0-4.wav* then the class label
    will be 9\. Doing string split by – and taking the second item of the array will
    give us the class label.
  prefs: []
  type: TYPE_NORMAL
- en: Classification using Multilayer Neural Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Note: If you want to use scikit-learn or any other library for training classifier,
    feel free to use that. The goal of this tutorial is to provide an implementation
    of the neural network in Tensorflow for classification tasks.*'
  prefs: []
  type: TYPE_NORMAL
- en: Now we have our dataset ready, let’s implement two layers neural network in
    Tensorflow to classify each sound clip into a different category. But before starting
    with that, let’s encode class labels into one hot vector using the method *one_hot_encode*
    and divide the dataset into a train and test sets by using following code.
  prefs: []
  type: TYPE_NORMAL
- en: The code provided below defines configuration parameters required by neural
    network model. Such as training epochs, a number of neurones in each hidden layer
    and learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: Now define placeholders for features and class labels, which tensor flow will
    fill with the data at runtime. Furthermore, define weights and biases for hidden
    and output layers of the network. For non-linearity, we use the sigmoid function
    in the first hidden layer and tanh in the second hidden layer. The output layer
    has softmax as non-linearity as we are dealing with multiclass classification
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: The cross-entropy cost function will be minimised using gradient descent optimizer,
    the code provided below initialize cost function and optimizer. Also, define and
    initialize variables for accuracy calculation of the prediction by model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have all the required pieces in place. Now let’s train neural network model,
    visualise whether cost is decreasing with each epoch and make prediction on the
    test set, using following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![NN Cost Per Epoch](../Images/2a6c1c3b2ea1bec3aa6b6405f1e01422.png)'
  prefs: []
  type: TYPE_IMG
- en: In this tutorial, we saw how to extract features from a sound dataset and train
    a two layer neural network model in Tensorflow to categories sounds, without much
    tuning the above NN architecture achieved around **82%** accuracy on fold1 of
    the Urban8K dataset. I would encourage you to check the documentation of Librosa
    and experiment with different neural network configurations i.e. by changing number
    of neurons, number of hidden layers and introducing dropout etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![Author](../Images/f9c21800dc7ef2fdf98de5b260d7c466.png)The python notebook
    is available at the following **[link](https://github.com/aqibsaeed/Urban-Sound-Classification)**.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Aaqib Saeed](http://aqibsaeed.github.io/)** is a graduate student of
    Computer Science (specializing in Data Science and Smart Services) at University
    of Twente (The Netherlands).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://aqibsaeed.github.io/2016-09-03-urban-sound-classification-part-1/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[The Gentlest Introduction to Tensorflow – Part 1](/2016/08/gentlest-introduction-tensorflow-part-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning Reading Group: Deep Networks with Stochastic Depth](/2016/09/deep-learning-reading-group-stochastic-depth-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Up to Speed on Deep Learning: July Update](/2016/08/deep-learning-july-update.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
