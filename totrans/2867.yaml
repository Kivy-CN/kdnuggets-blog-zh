- en: How Bayes’ Theorem is Applied in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《贝叶斯定理在机器学习中的应用》
- en: 原文：[https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html](https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html](https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Jaime Zornoza](https://www.linkedin.com/in/jaime-zornoza/), Universidad
    Politecnica de Madrid**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Jaime Zornoza](https://www.linkedin.com/in/jaime-zornoza/)提供，马德里理工大学**'
- en: '![Header image](../Images/417c5ca8ecb0d2fe52777d09b2a5dc99.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![头图](../Images/417c5ca8ecb0d2fe52777d09b2a5dc99.png)'
- en: In the previous post we saw **what Bayes’ Theorem is**, and went through an
    easy, intuitive example of how it works. You can find this post [**here**](https://towardsdatascience.com/probability-learning-i-bayes-theorem-708a4c02909a?source=friends_link&sk=29a5c9c9301a1204f16460781eaba113)**. **If
    you don’t know what Bayes’ Theorem is, and you have not had the pleasure to read
    it yet, I recommend you do, as it will make understanding this present article
    a lot easier.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一篇文章中，我们了解了**贝叶斯定理是什么**，并通过一个简单直观的例子讲解了它的工作原理。你可以在[**这里**](https://towardsdatascience.com/probability-learning-i-bayes-theorem-708a4c02909a?source=friends_link&sk=29a5c9c9301a1204f16460781eaba113)**找到这篇文章**。如果你还不知道贝叶斯定理是什么，且尚未阅读过，我建议你阅读它，这将使你更容易理解本文。
- en: In this post, we will see the **uses of this theorem in *Machine Learning.***
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨**该定理在*机器学习*中的用途**。
- en: '***Ready? Lets go then!***'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '***准备好了吗？那我们开始吧！***'
- en: Bayes’ Theorem in Machine Learning
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习中的贝叶斯定理
- en: As mentioned in the previous post, Bayes’ theorem tells use how to **gradually
    update our knowledge** on *something* as we get more evidence or that about that *something*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上一篇文章所提到的，贝叶斯定理告诉我们如何**逐渐更新我们的知识**，随着我们获得更多关于*某事*的证据。
- en: Generally, in **Supervised Machine Learning**, when we want to train a model
    the **main building blocks** are a set of data points that contain **features** (the
    attributes that define such data points),**the labels** of such data point (the
    numeric or categorical tag which we later want to predict on new data points),
    and a **hypothesis function** or model that links such features with their corresponding
    labels. We also have a **loss function**, which is the difference between the
    predictions of the model and the real labels which we want to reduce to achieve
    the best possible results.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，在**监督机器学习**中，当我们想要训练一个模型时，**主要构建块**是包含**特征**（定义数据点的属性）、**标签**（我们想要在新数据点上预测的数值或分类标签）和一个**假设函数**或模型（将这些特征与对应标签关联起来）。我们还需要一个**损失函数**，它是模型预测值与实际标签之间的差异，我们希望将其减少，以获得最佳结果。
- en: '![Figure](../Images/fbcde049a8bc3e5d2627e6f4686e7a2b.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/fbcde049a8bc3e5d2627e6f4686e7a2b.png)'
- en: Main elements of a supervised Learning Problem
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习问题的主要元素
- en: 'These supervised Machine Learning problems can be divided into **two main categories:
    regression**, where we want to calculate a number or **numeric** **value** associated
    with some data (like for example the price of a house), and **classification**,
    where we want to assign the data point to a **certain category** (for example
    saying if an image shows a dog or a cat).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些监督机器学习问题可以分为**两大类：回归**，其中我们希望计算一个与数据相关的**数值**（例如房价），和**分类**，其中我们希望将数据点分配到**某个类别**（例如判断图像中是狗还是猫）。
- en: '**Bayes’ theorem can be used in both regression, and classification.**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**贝叶斯定理可以用于回归和分类。**'
- en: Lets see how!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看吧！
- en: '**Bayes’ Theorem in Regression**'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**回归中的贝叶斯定理**'
- en: Imagine we have a very **simple set of data**, which represents the **temperature
    of each day** of the year in a certain area of a town (the** feature** of the
    data points), and the **number of water bottles **sold by a local shop in that
    area every single day (the **label** of the data points).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组**非常简单的数据**，表示某个小镇地区每一天的**气温**（数据点的**特征**），以及该地区每一天**售出的水瓶数量**（数据点的**标签**）。
- en: By making a **very simple model**, we could s**ee if these two are related**,
    and if they are, then use this model to **make predictions** in order to stock
    up on water bottles depending on the temperature and never run out of stock, or
    avoid having too much inventory.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过建立一个**非常简单的模型**，我们可以**查看这两者是否相关**，如果相关，就可以使用该模型**进行预测**，以便根据温度储备水瓶，避免库存短缺或过剩。
- en: We could try a very simple** linear regression model** to see how these variables
    are related. In the following formula, that describes this linear model, y is
    the target label (the number of water bottles in our example), **each of the θs
    is a parameter of the model **(the slope and the cut with the y-axis) and x would
    be our feature (the temperature in our example).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试一个非常简单的**线性回归模型**来查看这些变量之间的关系。在描述这个线性模型的以下公式中，y 是目标标签（在我们的例子中是水瓶的数量），**每个θs都是模型的参数**（斜率和与
    y 轴的截距），x 是我们的特征（在我们的例子中是温度）。
- en: '![Figure](../Images/dcd3d2aa38efa1fdbd9b71557db7fa51.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/dcd3d2aa38efa1fdbd9b71557db7fa51.png)'
- en: Equation describing a linear model
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 描述线性模型的方程
- en: The goal of this training would be to **reduce the mentioned loss function**,
    so that the predictions that the model makes for the known data points, are close
    to the actual values of the labels of such data points.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这次训练的目标是**减少提到的损失函数**，使模型对已知数据点的预测接近这些数据点的实际标签值。
- en: After having trained the model with the available data we would get a value
    for both of the **θs**. This training can be performed by using an **iterative
    process **like gradient descent or another **probabilistic method** like Maximum
    Likelihood. In any way, we would just **have ONE single value** for each one of
    the parameters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在用可用数据训练模型后，我们将得到两个**θs**的值。这种训练可以通过使用**迭代过程**（如梯度下降）或其他**概率方法**（如最大似然法）来完成。无论如何，我们只会为每个参数得到**一个单一的值**。
- en: In this manner, when we get **new data without a label** (new temperature forecasts)
    as we know the value of the **θs**, we could just use this simple equation to
    obtain the wanted ***Ys*** (number of water bottles needed for each day).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，当我们获得**没有标签的新数据**（新的温度预测）时，由于我们知道**θs 的值**，我们可以仅使用这个简单的方程来获得所需的 ***Ys***（每天所需的水瓶数量）。
- en: '![Figure](../Images/19d7c2937dca6f54c2fba3af72f67475.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/19d7c2937dca6f54c2fba3af72f67475.png)'
- en: Figure of an uni-variate linear regression. Using the initial blue data points,
    we calculate the line that best fits these points, and then when we get a new
    temperature we can easily calculate the Nº sold bottles for that day.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 单变量线性回归的图示。使用最初的蓝色数据点，我们计算出最佳拟合这些点的直线，然后当我们获得新的温度时，我们可以轻松计算出当天销售的瓶数。
- en: 'When we use Bayes’ theorem for regression, instead of **thinking of the parameters **(the
    θs) of the model as having a single, unique value, we represent them **as** parameters **having
    a certain distribution**: the prior distribution of the parameters. The following
    figures show the generic Bayes formula, and under it how it can be applied to
    a machine learning model.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用贝叶斯定理进行回归时，我们不是**将模型的参数**（θs）视为唯一的单一值，而是将其表示为**具有某种分布的参数**：参数的先验分布。以下图示展示了通用贝叶斯公式，以及如何将其应用于机器学习模型。
- en: '![Figure](../Images/80bad4a0f02bf45b7c24c44afee57cab.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/80bad4a0f02bf45b7c24c44afee57cab.png)'
- en: Bayes formula![Figure](../Images/2eec6c3f30b4ba354530210cb67ff621.png)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯公式 ![图示](../Images/2eec6c3f30b4ba354530210cb67ff621.png)
- en: Bayes formula applied to a machine learning model
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯公式应用于机器学习模型
- en: The idea behind this is that **we have some previous knowledge of the parameters
    of the model **before we have any actual data: ***P(model)* **is this prior probability.
    Then, **when we get some new data, we update the distribution of the parameters** of
    the model, making it the posterior probability ***P(model|data)***.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法的基础是，在我们拥有实际数据之前，**我们对模型参数有一些先验知识**：***P(model)*** 就是这个先验概率。然后，**当我们获得一些新数据时，我们会更新模型参数的分布**，使其成为后验概率
    ***P(model|data)***。
- en: What this means is that** our parameter set **(the θs of our model) is not constant,
    but instead **has its own distribution**. Based on previous knowledge (from experts
    for example, or from other works) **we make a first hypothesis** about the distribution
    of the parameters of our model. Then as we train our models with **more data**, **this
    distribution gets updated** and grows more exact (in practice the variance gets
    smaller).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着**我们的参数集**（模型的θs）不是恒定的，而是**有其自己的分布**。基于先前的知识（例如来自专家或其他研究）**我们对模型参数的分布做出初步假设**。然后随着我们用**更多的数据**训练模型，**这个分布会更新**并变得更加精确（实际上，方差变小）。
- en: '![Figure](../Images/dfd80faad7b3be9607c854a6b18befb8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/dfd80faad7b3be9607c854a6b18befb8.png)'
- en: Figure of the a priori and posteriori parameter distributions. θMap is the maximum
    posteior estimation, which we would then use in our models.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 关于先验和后验参数分布的图。θMap 是最大后验估计，我们将其用于我们的模型中。
- en: This figure shows the **initial distribution of the parameters of the model *p(θ)***,
    and how as we add more data this distribution **gets updated, **making it grow
    more exact to*** p(θ|x)***, where x denotes this new data. The θ here is equivalent
    to the *model* in the formula shown above, and the ***x*** here is equivalent
    to the *data* in such formula.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图展示了**模型参数的初始分布*p(θ)***，以及随着我们添加更多数据，这个分布如何**被更新**，使其变得更准确地接近***p(θ|x)***，其中x表示这些新数据。这里的θ相当于上述公式中的*模型*，而这里的***x***相当于该公式中的*数据*。
- en: Bayes’ formula, as always, tells us **how to go from the prior to the posterior
    probabilities**. We do this in an iterative process as we get more and more data,
    having the **posterior probabilities become the prior probabilities for the next
    iteration**. Once we have trained the model with enough data, to choose the set
    of final parameters we would search for the **Maximum posterior (MAP) estimation
    to use a concrete set of values for the parameters of the model.**
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯公式，如往常一样，告诉我们**如何从先验概率转换为后验概率**。我们在迭代过程中进行此操作，随着数据的不断增加，**后验概率成为下一次迭代的先验概率**。一旦我们用足够的数据训练了模型，为了选择最终的参数集，我们会寻找**最大后验（MAP）估计，以使用一组具体的模型参数值**。
- en: 'This kind of analysis **gets its strength from the initial prior distribution**:
    if we do not have any previous information, and can’t make any assumption about
    it, other probabilistic approaches like Maximum Likelihood are better suited.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分析的**优势来自于初始的先验分布**：如果我们没有任何先前的信息，且无法对其做出任何假设，其他概率方法如最大似然估计可能更合适。
- en: However, **if we have some prior information about the distribution of the parameters
    the Bayes’ approach proves to be very powerful**, specially in the case of having **unreliable
    training data**. In this case, as we are not building the model and calculating
    its parameters from scratch using this data, but rather using some kind of previous
    knowledge to infer an initial distribution for these parameters, **this previous
    distribution makes the parameters more robust and less affected by inaccurate
    data.**
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**如果我们对参数的分布有一些先验信息，贝叶斯方法证明非常强大**，特别是在面对**不可靠的训练数据**的情况下。在这种情况下，由于我们不是从头开始构建模型并计算其参数，而是使用某种先前的知识来推断这些参数的初始分布，**这种先验分布使得参数更为稳健，并且不容易受到不准确数据的影响**。
- en: I don’t want to get very technical in this part, but the maths behind all this
    reasoning is beautiful; if you want to know about it don’t hesitate and email
    me to jaimezorno@gmail.com or **contact me** on [LinkdIn](https://www.linkedin.com/in/jaime-zornoza/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想在这一部分过于技术化，但这一推理背后的数学是非常美妙的；如果你想了解更多，随时发邮件至 jaimezorno@gmail.com 或在 [LinkedIn](https://www.linkedin.com/in/jaime-zornoza/)
    上**联系我**。
- en: '**Bayes’ Theorem in Classification**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**贝叶斯定理在分类中的应用**'
- en: We have seen how Bayes’ theorem can be used for regression, by estimating the
    parameters of a linear model. The same reasoning could be applied to other kind
    of regression algorithms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到贝叶斯定理如何用于回归，通过估计线性模型的参数。相同的推理也可以应用于其他类型的回归算法。
- en: Now we will see how to use Bayes’ theorem for classification. This is known
    as **Bayes’ optimal classifier**. The reasoning now is very similar to the previous
    one.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将了解如何使用贝叶斯定理进行分类。这被称为**贝叶斯最优分类器**。现在的推理与之前的非常相似。
- en: Imagine we have a classification problem with** *i* different classes**. The
    thing we are after here is **the class probability** for each class** w*i***.
    Like in the previous regression case, we also differentiate between prior and
    posterior probabilities, but now we have **prior class probabilities** ***p(wi)*** and **posterior
    class probabilities**, after using data or observations ***p(wi|x)***.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下我们有一个分类问题，具有** *i* 个不同的类别**。我们关注的是**每个类别的概率** **w*i***。如同之前的回归情况，我们也区分先验概率和后验概率，但现在我们有**先验类别概率** ***p(wi)*** 以及在使用数据或观测后得到的**后验类别概率** ***p(wi|x)***。
- en: '![Figure](../Images/04e9559d24235af022e7804cf0039701.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/04e9559d24235af022e7804cf0039701.png)'
- en: Bayes formula used for Bayes’ optimal classifier
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯公式用于贝叶斯最优分类器
- en: Here ***P(x)*** is the **density function** common to** all the data points**,*** P(x|wi)*** is
    the **density function of the data points belonging to class *wi***, and*** P(wi)*** is
    the prior distribution of class ***wi***. ***P(x|wi)*** is calculated from the
    training data, assuming a certain distribution and calculating a **mean vector
    for each class** and the** covariance of the features** of the data points belonging
    to such class. The prior class distributions ***P(wi)* **are estimated based on **domain
    knowledge**, expert advice or previous works, like in the regression example.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，***P(x)*** 是与**所有数据点**共同的**密度函数**，***P(x|wi)*** 是属于类别*wi*的数据点的**密度函数**，而***P(wi)***
    是类别***wi***的先验分布。***P(x|wi)*** 是从训练数据中计算的，假设某种分布，并计算**每个类别的均值向量**以及属于该类别的数据点的**特征协方差**。先验类别分布***P(wi)***
    是基于**领域知识**、专家建议或以前的工作来估计的，如回归示例中所示。
- en: 'Lets see an example of how this works: Image we have measured the height of
    34 individuals: **25 males (blue)** and **9 females (red)**, and we get a **new** height **observation **of
    172 cm which we want to classify as male or female. The following figure represents
    the predictions obtained using a **Maximum likelihood classifier and a Bayes optimal
    classifier.**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子来说明这是如何工作的：假设我们测量了34个人的身高：**25名男性（蓝色）**和**9名女性（红色）**，然后我们得到一个**新的**身高**观测值**172厘米，我们想将其分类为男性或女性。下图表示了使用**最大似然分类器和贝叶斯最优分类器**获得的预测结果。
- en: '![Figure](../Images/ade69484436a30253dcaf9ba792fc0b7.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ade69484436a30253dcaf9ba792fc0b7.png)'
- en: On the left, the training data for both classes with their estimated normal
    distributions. On the right, Bayes optimal classifier, with prior class probabilities
    p(wA) of male being 25/34 and p(wB) of female being 9/34.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧是两个类别的训练数据及其估计的正态分布。右侧是贝叶斯最优分类器，其中男性的先验类别概率p(wA)为25/34，女性的p(wB)为9/34。
- en: In this case we have used the **number of samples** in the training data **as** the **prior
    knowledge** for our class distributions, but if for example we were doing this
    same differentiation between height and gender for a specific country, and we
    knew the woman there are specially tall, and also knew the mean height of the
    men, we could have used this** information to build our prior class distributions.**
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用了**训练数据中的样本数量**作为**类别分布的先验知识**，但例如，如果我们在特定国家对身高和性别进行相同的区分，并且知道那里女性特别高，同时也知道男性的平均身高，我们可以利用这些**信息来构建我们的先验类别分布**。
- en: As we can see from the example, using these** prior knowledge leads to different
    results **than not using them. Assuming this previous knowledge is of high quality
    (or otherwise we wouldn’t use it), these predictions should be **more accurate** than
    similar trials that don’t incorporate this information.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中可以看出，使用这些**先验知识会导致不同的结果**，而不是不使用它们。假设这些先验知识的质量很高（否则我们不会使用它），这些预测应该比不包含这些信息的类似试验**更准确**。
- en: After this, as always, as we get **more data** these** distributions would get
    updated** to reflect the knowledge obtained from this data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，随着我们获得**更多数据**，这些**分布会被更新**以反映从这些数据中获得的知识。
- en: As in the previous case, I don’t want to get too technical, or extend the article
    too much, so I won’t go into the mathematical details, but **feel free to contact
    me if you are curious about them**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 和之前的情况一样，我不想过于技术化，或过多延伸文章，所以我不会深入数学细节，但**如果你对这些细节感到好奇，欢迎随时联系我**。
- en: Conclusion
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: We have seen **how Bayes’ theorem is used in Machine learning**; both in **regression **and **classification**,
    to incorporate previous knowledge into our models and improve them.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到**贝叶斯定理在机器学习中的应用**；无论是在**回归**还是**分类**中，都是将先前的知识纳入我们的模型并加以改进。
- en: In the following post we will see how **simplifications of Bayes’ theorem **are
    one of the most used techniques for **Natural Language Processing** and how they
    are applied to many real world use cases like spam filters or sentiment analysis
    tools. To check it out [**follow me on Medium**](https://medium.com/@jaimezornoza),
    and stay tuned!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的文章中，我们将看到**贝叶斯定理的简化**是**自然语言处理**中最常用的技术之一，以及它们如何应用于许多实际用例，如垃圾邮件过滤器或情感分析工具。要了解更多，**请关注我的Medium**](https://medium.com/@jaimezornoza)，敬请期待！
- en: '![Figure](../Images/5dab590ad63e916f60390c57978bf78a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/5dab590ad63e916f60390c57978bf78a.png)'
- en: Another example of Bayesian classification
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯分类的另一个示例
- en: That is all, I hope you liked the post. Feel Free to connect with me on [LinkedIn](https://www.linkedin.com/in/jaime-zornoza/) or
    follow me on Twitter at **@jaimezorno**. Also, you can take a look at my other
    posts on Data Science and Machine Learning[**here**](https://medium.com/@jaimezornoza).
    Have a good read!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 以上就是所有内容，希望你喜欢这篇文章。随时可以在 [LinkedIn](https://www.linkedin.com/in/jaime-zornoza/)
    上联系我，或者在 Twitter 上关注我 **@jaimezorno**。你也可以查看我在数据科学和机器学习方面的其他文章 [**这里**](https://medium.com/@jaimezornoza)。阅读愉快！
- en: Additional Resources
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 额外资源
- en: 'In case you want to go more in depth into Bayes and Machine Learning, check
    out these other resources:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入了解贝叶斯和机器学习，请查看以下资源：
- en: '[How Bayesian Inference works](https://brohrer.github.io/how_bayesian_inference_works.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯推断如何工作](https://brohrer.github.io/how_bayesian_inference_works.html)'
- en: '[Bayesian statistics Youtube Series](https://www.youtube.com/watch?v=YsJ4W1k0hUg)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯统计 YouTube 系列](https://www.youtube.com/watch?v=YsJ4W1k0hUg)'
- en: '[Machine Learning Bayesian Learning slides](https://slideplayer.com/slide/4940573/)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习贝叶斯学习幻灯片](https://slideplayer.com/slide/4940573/)'
- en: '[Bayesian Inference](https://www.umass.edu/landeco/teaching/ecodata/schedule/bayesian.pdf)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯推断](https://www.umass.edu/landeco/teaching/ecodata/schedule/bayesian.pdf)'
- en: and as always, contact me with any questions. Have a fantastic day and keep
    learning.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，有任何问题请随时联系我。祝你有个美好的一天，继续学习。
- en: '**Bio: [Jaime Zornoza](https://www.linkedin.com/in/jaime-zornoza/)** is an
    Industrial Engineer with a bachelor specialized in Electronics and a Masters degree
    specialized in Computer Science.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Jaime Zornoza](https://www.linkedin.com/in/jaime-zornoza/)** 是一位工业工程师，拥有电子学学士学位和计算机科学硕士学位。'
- en: '[Original](https://towardsdatascience.com/probability-learning-ii-how-bayes-theorem-is-applied-in-machine-learning-bd747a960962).
    Reposted with permission.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/probability-learning-ii-how-bayes-theorem-is-applied-in-machine-learning-bd747a960962)。经许可转载。'
- en: '**Related:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Probability Learning I: Bayes’ Theorem](/2019/10/probability-learning-bayes-theorem.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[概率学习 I：贝叶斯定理](/2019/10/probability-learning-bayes-theorem.html)'
- en: '[How Bayesian Inference Works](/2016/11/how-bayesian-inference-works.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[贝叶斯推断如何工作](/2016/11/how-bayesian-inference-works.html)'
- en: '[Deep Learning for NLP: ANNs, RNNs and LSTMs explained!](/2019/08/deep-learning-nlp-explained.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习 NLP：ANNs、RNNs 和 LSTMs 解析！](/2019/08/deep-learning-nlp-explained.html)'
- en: '* * *'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[3 Ways Understanding Bayes Theorem Will Improve Your Data Science](https://www.kdnuggets.com/2022/06/3-ways-understanding-bayes-theorem-improve-data-science.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解贝叶斯定理的 3 种方法将提升你的数据科学技能](https://www.kdnuggets.com/2022/06/3-ways-understanding-bayes-theorem-improve-data-science.html)'
- en: '[What is Chebychev''s Theorem and How Does it Apply to Data Science?](https://www.kdnuggets.com/2022/11/chebychev-theorem-apply-data-science.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[切比雪夫定理是什么，它如何应用于数据科学？](https://www.kdnuggets.com/2022/11/chebychev-theorem-apply-data-science.html)'
- en: '[KDnuggets News, November 30: What is Chebychev''s Theorem and How…](https://www.kdnuggets.com/2022/n46.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月30日：切比雪夫定理是什么及其如何应用…](https://www.kdnuggets.com/2022/n46.html)'
- en: '[Gaussian Naive Bayes, Explained](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯朴素贝叶斯，解析](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
- en: '[Naïve Bayes Algorithm: Everything You Need to Know](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[朴素贝叶斯算法：你需要知道的一切](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月13日：数据科学家应该了解的 Python 库…](https://www.kdnuggets.com/2022/n15.html)'
