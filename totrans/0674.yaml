- en: Solve any Image Classification Problem Quickly and Easily
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速而轻松地解决任何图像分类问题
- en: 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)'
- en: 6\. Example
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6\. 示例
- en: In this example, we will see **how each of these classifiers can be implemented
    in a transfer learning solution for image classification**. According to Rawat
    and Wang (2017), ‘*comparing the performance of different classifiers on top of
    deep convolutional neural networks still requires further investigation and thus
    makes for an interesting research direction*’. So it will be interesting to see
    how each classifier performs in a standard image classification problem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将看到**如何在图像分类的迁移学习解决方案中实现这些分类器**。根据Rawat和Wang（2017）的说法，‘*在深度卷积神经网络基础上比较不同分类器的性能仍需要进一步研究，因此这是一个有趣的研究方向*’。因此，了解每个分类器在标准图像分类问题中的表现将很有趣。
- en: You can find the full code of this example on [my GitHub page](https://github.com/pmarcelino/blog/blob/master/dogs_cats/dogs_cats.ipynb).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[我的GitHub页面](https://github.com/pmarcelino/blog/blob/master/dogs_cats/dogs_cats.ipynb)找到这个示例的完整代码。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**6.1\. Prepare data**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.1\. 准备数据**'
- en: In this example, we will use a smaller version of the original dataset. This
    will allow us to run the models faster, which is great for people who have limited
    computational power (like me).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用原始数据集的较小版本。这将使我们能够更快地运行模型，这对计算能力有限的人（比如我）来说是很有帮助的。
- en: To build a smaller version of the dataset, we can adapt the code provided by
    Chollet (2017) as shown in Code 1.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建数据集的较小版本，我们可以根据代码1中显示的Chollet（2017）提供的代码进行调整。
- en: Code 1\. Create a smaller dataset for Dogs vs. Cats.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 代码1\. 创建一个较小的数据集用于狗与猫。
- en: '**6.2\. Extract features from the convolutional base**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.2\. 从卷积基础中提取特征**'
- en: The convolutional base will be used to extract features. These features will
    feed the classifiers that we want to train so that we can identify if images have
    dogs or cats.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积基础将用于提取特征。这些特征将供我们要训练的分类器使用，以便识别图像中是否有狗或猫。
- en: Once again, the code provided by Chollet (2017) is adapted. Code 2 shows the
    code used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 再次调整了Chollet（2017）提供的代码。代码2展示了使用的代码。
- en: Code 2\. Extract features from convolutional base.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 代码2\. 从卷积基础中提取特征。
- en: '**6.3\. Classifiers**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.3\. 分类器**'
- en: '**6.3.1\. Fully-connected layers**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.3.1\. 全连接层**'
- en: The first solution that we present is based on fully-connected layers. This
    classifier adds a stack of fully-connected layers that is fed by the features
    extracted from the convolutional base.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先展示的解决方案基于全连接层。这个分类器添加了一堆全连接层，这些层由从卷积基础中提取的特征提供输入。
- en: To keep it simple (and fast), we will use the solution proposed by Chollet (2018)
    with slight modifications. In particular, we will use the Adam optimizer instead
    of the RMSProp because [Stanford says so](http://cs231n.github.io/neural-networks-3/#adam) (what
    a beautiful *argumentum ad verecundiam*).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持简单（且快速），我们将使用Chollet（2018）提出的解决方案，并做少量修改。特别是，我们将使用Adam优化器而不是RMSProp，因为[斯坦福大学说如此](http://cs231n.github.io/neural-networks-3/#adam)（多么美妙的*argumentum
    ad verecundiam*）。
- en: Code 3 shows the code used, while Figures 5 and 6 present the learning curves.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 代码3展示了使用的代码，而图5和图6展示了学习曲线。
- en: Code 3\. Fully connected layers solution.![](../Images/37a3b1336eb12b75a2b53aea7edf9958.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 3\. 完全连接层解决方案。![](../Images/37a3b1336eb12b75a2b53aea7edf9958.png)
- en: Figure 5\. Accuracy of the fully connected layers solution.![](../Images/a624ba4e5278d22f95690936d9dab636.png)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 完全连接层解决方案的准确率。![](../Images/a624ba4e5278d22f95690936d9dab636.png)
- en: Figure 6\. Loss of the fully connected layers solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. 完全连接层解决方案的损失。
- en: '**Brief discussion of results:**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果简要讨论：**'
- en: Validation accuracy is around 0.85, which is encouraging given the size of the
    dataset.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证准确率约为 0.85，考虑到数据集的大小，这是令人鼓舞的。
- en: The model strongly overfits. There’s a big gap between the training and the
    validation curves.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型严重过拟合。训练曲线与验证曲线之间存在较大差距。
- en: Since we already used dropout, we should increase the size of the dataset to
    improve the results.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们已经使用了 dropout，我们应该增加数据集的大小以改善结果。
- en: '**6.3.2\. Global average pooling**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.3.2\. 全局平均池化**'
- en: The difference between this case and the previous one is that, instead of adding
    a stack of fully-connected layers, we will add a global average pooling layer
    and feed its output into a sigmoid activated layer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例与前一个案例的区别在于，我们将添加一个全局平均池化层，并将其输出送入一个 sigmoid 激活层，而不是添加一堆完全连接的层。
- en: Note that we are talking about a sigmoid activated layer instead of a softmax
    one, which is what is recommended by Lin et al. (2013). We are changing to the
    sigmoid activation because in Keras, to perform binary classification, you should
    use *sigmoid* activation and *binary_crossentropy* as the loss (Chollet 2017).
    Therefore, it was necessary to do this small modification to the original proposal
    of Lin et al. (2013).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们讨论的是一个 sigmoid 激活层，而不是 Lin 等人（2013）推荐的 softmax 层。我们更改为 sigmoid 激活，因为在 Keras
    中，要进行二分类，你应该使用 *sigmoid* 激活和 *binary_crossentropy* 作为损失（Chollet 2017）。因此，必须对 Lin
    等人（2013）的原始方案进行这一小修改。
- en: Code 4 shows the code to build the classifier. Figure 7 and 8 show the resulting
    learning curves.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 4 显示了构建分类器的代码。图 7 和图 8 显示了结果的学习曲线。
- en: Code 4\. Global average pooling solution.![](../Images/10de3d9dcec03af404861a8879c0accb.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 4\. 全局平均池化解决方案。![](../Images/10de3d9dcec03af404861a8879c0accb.png)
- en: Figure 7\. Accuracy of the global average pooling solution.![](../Images/a5d7d4e1dfd9f9804655064ae61f6cb7.png)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. 全局平均池化解决方案的准确率。![](../Images/a5d7d4e1dfd9f9804655064ae61f6cb7.png)
- en: Figure 8\. Loss of the global average pooling solution.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 全局平均池化解决方案的损失。
- en: '**Brief discussion of results:**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果简要讨论：**'
- en: Validation accuracy is similar to the one resulting from the fully-connected
    layers solution.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证准确率与完全连接层解决方案的结果相似。
- en: The model doesn’t overfit as much as in the previous case.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的过拟合情况没有前一个案例那么严重。
- en: The loss function is still decreasing when the model stops training. Probably,
    it is possible to improve the model by increasing the number of epochs.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当模型停止训练时，损失函数仍在下降。可能通过增加训练轮次可以改进模型。
- en: '**6.3.3 Linear support vector machines**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**6.3.3 线性支持向量机**'
- en: In this case, we will train a linear support vector machines (SVM) classifier
    on the features extracted by the convolutional base.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将训练一个线性支持向量机（SVM）分类器，使用卷积基提取的特征。
- en: To train this classifier, a traditional machine learning approach is preferable.
    Consequently, we will use k-fold cross-validation to estimate the error of the
    classifier. Since k-fold cross-validation will be used, we can concatenate the
    train and the validation sets to enlarge our training data (we keep the test set
    untouched, as we did in the previous cases). Code 5 shows how data was concatenated.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练这个分类器，传统的机器学习方法更为合适。因此，我们将使用 k 折交叉验证来估计分类器的误差。由于将使用 k 折交叉验证，我们可以将训练集和验证集合并以扩大训练数据（我们保持测试集不变，正如之前的案例中所做的）。代码
    5 显示了数据如何连接。
- en: Code 5\. Data concatenation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 5\. 数据连接。
- en: Finally, we must be aware that the SVM classifier has one hyperparameter. This
    hyperparameter is the penalty parameter C of the error term. To optimize the choice
    of this hyperparameter, we will use exhaustive grid search. Code 6 presents the
    code used to build this classifier, while Figure 9 illustrates the learning curves.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须注意，SVM 分类器有一个超参数。这个超参数是误差项的惩罚参数 C。为了优化这个超参数的选择，我们将使用穷举网格搜索。代码 6 展示了构建这个分类器的代码，而图
    9 说明了学习曲线。
- en: Code 6\. Linear SVM solution.![](../Images/1636b5411bb359e6864f8a0c3784e7b9.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 6\. 线性 SVM 解决方案。![](../Images/1636b5411bb359e6864f8a0c3784e7b9.png)
- en: Figure 9\. Accuracy of the linear SVM solution.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 线性 SVM 解决方案的准确率。
- en: '**Brief discussion of results:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果的简要讨论：**'
- en: Model’s accuracy is around 0.86, which is similar to the accuracy of the previous
    solutions.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的准确率约为0.86，这与之前的解决方案的准确率相似。
- en: Overfitting is around the corner. Moreover, the training accuracy is always
    1.0, which is not usual and can be interpreted as a sign of overfitting.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过拟合就在眼前。此外，训练准确率总是1.0，这不寻常，可以解释为过拟合的迹象。
- en: The accuracy of the model should increase with the number of training samples.
    However, that doesn’t seem to happen. This may be due to overfitting. It would
    be interesting to see how the model reacts when the dataset increases.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的准确率应该随着训练样本的增加而提高。然而，这似乎没有发生。这可能是由于过拟合。观察模型在数据集增加时的反应会很有趣。
- en: 7\. Summary
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7. 摘要
- en: 'In this article, we:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们：
- en: Presented the concepts of transfer learning, convolutional neural networks,
    and pre-trained models.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍了迁移学习、卷积神经网络和预训练模型的概念。
- en: Defined the basic fine-tuning strategies to repurpose a pre-trained model.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义了基本的微调策略，以重新利用预训练模型。
- en: Described a structured approach to decide which fine-tuning strategy should
    be used, based on the size and similarity of the dataset.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述了一种结构化的方法来决定应使用哪种微调策略，基于数据集的大小和相似性。
- en: Introduced three different classifiers that can be used on top of the features
    extracted from the convolutional base.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍了三种不同的分类器，这些分类器可以应用于从卷积基础提取的特征之上。
- en: Provided a end-to-end example on image classification for each of the three
    classifiers presented in this article.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了这篇文章中介绍的每个分类器的图像分类端到端示例。
- en: I hope that you feel motivated to start developing your deep learning projects
    on computer vision. This is a great field of study and new exciting findings are
    coming out everyday.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你能感到有动力开始在计算机视觉领域开发你的深度学习项目。这是一个很棒的研究领域，每天都有新的令人兴奋的发现。
- en: I’d be glad to help you, so let me know if you have any questions or improvement
    suggestions!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我很乐意帮助你，如果你有任何问题或改进建议，请告诉我！
- en: 8\. References
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8. 参考文献
- en: 1\. Bengio, Y., 2009\. Learning deep architectures for AI. Foundations and trends
    in Machine Learning, 2(1), pp.1–127.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 1. Bengio, Y., 2009\. Learning deep architectures for AI. Foundations and trends
    in Machine Learning, 2(1), pp.1–127.
- en: 2\. Canziani, A., Paszke, A. and Culurciello, E., 2016\. An analysis of deep
    neural network models for practical applications. arXiv preprint arXiv:1605.07678.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 2. Canziani, A., Paszke, A. and Culurciello, E., 2016\. An analysis of deep
    neural network models for practical applications. arXiv preprint arXiv:1605.07678.
- en: '[3\. Chollet, F., 2015\. Keras.](https://keras.io/)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[3. Chollet, F., 2015\. Keras.](https://keras.io/)'
- en: 4. [Chollet, F., 2017\. Deep learning with python. Manning Publications Co..](https://amzn.to/2CeEySF)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 4. [Chollet, F., 2017\. Deep learning with python. Manning Publications Co..](https://amzn.to/2CeEySF)
- en: '5\. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K. and Fei-Fei, L., 2009,
    June. Imagenet: A large-scale hierarchical image database. In Computer Vision
    and Pattern Recognition, 2009\. CVPR 2009\. IEEE Conference on (pp. 248–255).
    Ieee.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '5. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K. and Fei-Fei, L., 2009,
    June. Imagenet: A large-scale hierarchical image database. In Computer Vision
    and Pattern Recognition, 2009\. CVPR 2009\. IEEE Conference on (pp. 248–255).
    Ieee.'
- en: 6\. He, K., Zhang, X., Ren, S. and Sun, J., 2016\. Deep residual learning for
    image recognition. In Proceedings of the IEEE conference on computer vision and
    pattern recognition (pp. 770–778).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 6. He, K., Zhang, X., Ren, S. and Sun, J., 2016\. Deep residual learning for
    image recognition. In Proceedings of the IEEE conference on computer vision and
    pattern recognition (pp. 770–778).
- en: 7\. Krizhevsky, A., Sutskever, I. and Hinton, G.E., 2012\. Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems (pp. 1097–1105).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 7. Krizhevsky, A., Sutskever, I. and Hinton, G.E., 2012\. Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems (pp. 1097–1105).
- en: 8\. LeCun, Y., Bengio, Y. and Hinton, G., 2015\. Deep learning. nature, 521(7553),
    p.436.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 8. LeCun, Y., Bengio, Y. and Hinton, G., 2015\. Deep learning. nature, 521(7553),
    p.436.
- en: 9\. Lin, M., Chen, Q. and Yan, S., 2013\. Network in network. arXiv preprint
    arXiv:1312.4400.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 9. Lin, M., Chen, Q. and Yan, S., 2013\. Network in network. arXiv preprint
    arXiv:1312.4400.
- en: 10\. Pan, S.J. and Yang, Q., 2010\. A survey on transfer learning. IEEE Transactions
    on knowledge and data engineering, 22(10), pp.1345–1359.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 10. Pan, S.J. and Yang, Q., 2010\. A survey on transfer learning. IEEE Transactions
    on knowledge and data engineering, 22(10), pp.1345–1359.
- en: '11\. Rawat, W. and Wang, Z., 2017\. Deep convolutional neural networks for
    image classification: A comprehensive review. Neural computation, 29(9), pp.2352–2449.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '11. Rawat, W. and Wang, Z., 2017\. Deep convolutional neural networks for image
    classification: A comprehensive review. Neural computation, 29(9), pp.2352–2449.'
- en: 12\. Simonyan, K. and Zisserman, A., 2014\. Very deep convolutional networks
    for large-scale image recognition. arXiv preprint arXiv:1409.1556.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 12\. Simonyan, K. 和 Zisserman, A., 2014\. 用于大规模图像识别的非常深度卷积网络。arXiv预印本 arXiv:1409.1556。
- en: 13\. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. and Wojna, Z., 2016\.
    Rethinking the inception architecture for computer vision. In Proceedings of the
    IEEE conference on computer vision and pattern recognition (pp. 2818–2826).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 13\. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. 和 Wojna, Z., 2016\. 重新思考计算机视觉的Inception架构。IEEE计算机视觉与模式识别会议论文集
    (第2818–2826页)。
- en: 14\. Tang, Y., 2013\. Deep learning using linear support vector machines. arXiv
    preprint arXiv:1306.0239.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 14\. Tang, Y., 2013\. 使用线性支持向量机的深度学习。arXiv预印本 arXiv:1306.0239。
- en: '15\. Voulodimos, A., Doulamis, N., Doulamis, A. and Protopapadakis, E., 2018\.
    Deep learning for computer vision: A brief review. Computational intelligence
    and neuroscience, 2018.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 15\. Voulodimos, A., Doulamis, N., Doulamis, A. 和 Protopapadakis, E., 2018\.
    计算机视觉的深度学习：简要综述。计算智能与神经科学，2018。
- en: 16\. Yosinski, J., Clune, J., Bengio, Y. and Lipson, H., 2014\. How transferable
    are features in deep neural networks?. In Advances in neural information processing
    systems (pp. 3320–3328).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 16\. Yosinski, J., Clune, J., Bengio, Y. 和 Lipson, H., 2014\. 深度神经网络中的特征转移性如何？在神经信息处理系统进展
    (第3320–3328页)。
- en: 17\. Zeiler, M.D. and Fergus, R., 2014, September. Visualizing and understanding
    convolutional networks. In European conference on computer vision (pp. 818–833).
    Springer, Cham.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 17\. Zeiler, M.D. 和 Fergus, R., 2014年9月。可视化和理解卷积网络。在欧洲计算机视觉会议 (第818–833页)。Springer,
    Cham。
- en: Acknowledgments
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 致谢
- en: Thanks to [João Coelho](https://www.linkedin.com/in/joaopcoelho/) for reading
    drafts of this.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢[João Coelho](https://www.linkedin.com/in/joaopcoelho/)阅读这份草稿。
- en: '*You can find more about me and my projects at *[*pmarcelino.com*](http://www.pmarcelino.com/)*.
    Also, you can sign up for my *[*newsletter*](http://pmarcelino.com/subscribe)* to
    receive my latest updates on Humans, Machines, and Science.*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以在*[*pmarcelino.com*](http://www.pmarcelino.com/) *找到更多关于我和我的项目的信息。同时，你也可以注册我的*[*newsletter*](http://pmarcelino.com/subscribe)*，以接收我关于人类、机器和科学的最新更新。*'
- en: '**Bio: [Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)** is interested
    in all aspects of machine learning and data analysis. His focus is on data mining
    & quality, exploratory analysis & visualization, and predictive/prescriptive analytics,
    but includes testing and benchmarking of different machine learning approaches
    on real-life problems.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)** 对机器学习和数据分析的各个方面都感兴趣。他的重点是数据挖掘与质量、探索性分析与可视化，以及预测/处方分析，但也包括在实际问题上测试和基准不同的机器学习方法。'
- en: '[Original](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751).
    Reposted with permission.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)。已获授权转载。'
- en: '**Related:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Latest Trends in Computer Vision Technology and Applications](/2018/11/trends-computer-vision-technology-applications.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉技术与应用的最新趋势](/2018/11/trends-computer-vision-technology-applications.html)'
- en: '[Building an Image Classifier Running on Raspberry Pi](/2018/10/building-image-classifier-running-raspberry-pi.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个在Raspberry Pi上运行的图像分类器](/2018/10/building-image-classifier-running-raspberry-pi.html)'
- en: '[Analyze a Soccer (Football) Game Using Tensorflow Object Detection and OpenCV](/2018/07/analyze-soccer-game-using-tensorflow-object-detection-opencv.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Tensorflow目标检测和OpenCV分析足球比赛](/2018/07/analyze-soccer-game-using-tensorflow-object-detection-opencv.html)'
- en: More On This Topic
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NExT-GPT介绍：任何到任何的多模态大语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
- en: '[Machine Learning Is Not Like Your Brain Part 6: The Importance of…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第6部分：精确突触权重的重要性](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
- en: '[Scrape Images Easily from Websites in A No-Coding Way](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[以无代码方式轻松从网站抓取图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在你的笔记本电脑上轻松探索LLMs，使用openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
- en: '[Easily Integrate LLMs into Your Scikit-learn Workflow with Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Scikit-LLM 将 LLMs 轻松集成到您的 Scikit-learn 工作流中](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
