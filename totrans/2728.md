# 全面了解端到端机器学习平台

> 原文：[https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html](https://www.kdnuggets.com/2020/07/tour-end-to-end-machine-learning-platforms.html)

[评论](#comments)

**由[伊恩·赫尔斯特](https://databaseline.tech/)，机器学习工程师**

机器学习（ML）被称为[技术债务的高利息信用卡](https://research.google/pubs/pub43146/)。启动一个对特定业务问题足够好的模型相对容易，但要让该模型在生产环境中高效运行，并能够处理混乱、变化的数据语义和关系以及不断发展的模式，那是完全不同的事。如果你有兴趣了解一些知名的机器学习平台，你来对地方了！

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的 IT

* * *

实际机器学习生产系统中只有 5% 的代码是模型本身。将一系列机器学习解决方案转变为端到端机器学习平台的关键在于一种架构，这种架构拥抱旨在加速建模、自动化部署并确保生产中的可扩展性和可靠性的技术。我之前讨论过[精益 D/MLOps](https://databaseline.tech/lean-dml-operations/)，数据和机器学习操作，因为没有数据的机器学习操作是毫无意义的，因此端到端机器学习平台需要一种全面的方法。

CI/CD 基础推出了一个[MLOps 特别兴趣小组（SIG）](https://cd.foundation/blog/2020/02/11/announcing-the-cd-foundation-mlops-sig/)。他们为端到端机器学习平台确定的步骤在下一张图片中展示：

[![CI/CD 基础 MLOps](../Images/7aa2ad97dc6bb2a1e398566a2c13e7b1.png)](https://databaseline.tech/images/2020-02-21-ml-cicd-mlops-sig.png)

它掩盖了一些不那么微不足道的细节。例如，服务可能需要不同的技术，取决于是否实时进行。可扩展的解决方案通常将模型放在一个容器内，该容器在许多机器上运行，并且处于一个负载均衡器后的服务集群中。因此，前面提到的单个框并不意味着实际平台的单个步骤、容器或组件。这不是对图片的批评，而是警告：看起来简单的事情在实践中可能并非如此。

图表中缺少模型（配置）管理。你可以考虑版本控制、实验管理、运行时统计信息、训练、测试和验证数据集的数据追踪、重新训练模型的能力（无论是从头开始还是从模型的快照增量更新）、超参数值、准确度指标等。

另一个未列出的关键方面是能够检查模型的偏差，例如，通过不同维度切分模型的关键性能指标。许多公司还需要能够热交换模型或并行运行多个模型。前者很重要，以免在模型在后台更新时用户的请求消失在服务器上。而后者对于A/B测试或模型验证至关重要。

从CI/CD的另一个视角可以[这里](https://martinfowler.com/articles/cd4ml.html)获取。它提到了对数据和代码进行版本控制的必要性，但这常常被忽视。

### Google: TFX

谷歌开发**[TensorFlow eXtended (TFX)](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/(https://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform))**的主要动机是将机器学习模型的生产化时间从几个月缩短到几周。他们的工程师和科学家们面临挑战，因为“当机器学习需要在生产环境中部署时，实际工作流程变得更加复杂。”

[![TensorFlow eXtended (TFX)](../Images/384435a75222fc795560a084c10898e8.png)](https://databaseline.tech/images/2020-02-21-ml-tfx.png)

TensorFlow 和 [TFX](https://www.tensorflow.org/tfx/) 免费提供，尽管后者不如前者成熟，因为它于2019年发布，比谷歌展示其机器学习基础设施晚了两年。

模型性能指标用于部署安全可服务的模型。因此，如果较新的模型表现不如现有模型，它不会被推送到生产中。在TFX术语中，模型不会获得“祝福”。在TFX中，这整个过程是自动化的。

这是开源TFX组件的快速概览：

+   [ExampleGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/examplegen.md) 处理并拆分输入数据集。

+   [StatisticsGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/statsgen.md) 计算数据集的统计信息。

+   [SchemaGen](https://github.com/tensorflow/tfx/blob/master/docs/guide/schemagen.md) 检查统计数据并创建数据模式。

+   [ExampleValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/exampleval.md) 查找数据集中的异常和缺失值。

+   [Transform](https://github.com/tensorflow/tfx/blob/master/docs/guide/transform.md) 对数据集执行特征工程。

+   [Trainer](https://github.com/tensorflow/tfx/blob/master/docs/guide/trainer.md) 使用 TensorFlow 训练模型。

+   [Evaluator](https://github.com/tensorflow/tfx/blob/master/docs/guide/evaluator.md) 分析训练结果。

+   [ModelValidator](https://github.com/tensorflow/tfx/blob/master/docs/guide/modelval.md) 确保模型可以安全提供服务。

+   [Pusher](https://github.com/tensorflow/tfx/blob/master/docs/guide/pusher.md) 将模型部署到服务基础设施。

+   [TensorFlow Serving](https://www.tensorflow.org/serving) 是一个 C++ 后端，用于提供 TensorFlow [SavedModel](https://www.tensorflow.org/guide/saved_model#save_and_restore_models) 文件。

为了最小化训练/服务偏差，TensorFlow Transform 在计算图中“冻结”值，以便在服务时使用训练期间找到的相同值。在训练时可能是 DAG 中的多个操作，在服务时将是单一的固定值。

### Uber: Michelangelo

大约在 2015 年，Uber 的 ML 工程师注意到 [机器学习系统中的隐性技术债务](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems)，即“但它在我的机器上能工作……”的 ML 等效。Uber 曾构建了自定义的单次系统，这在大型工程组织中并不是很具扩展性。[用他们自己的话说](https://eng.uber.com/michelangelo/)，

> 当时没有系统来构建可靠、一致和可重复的管道，以大规模创建和管理训练及预测数据。

这就是为什么他们构建了 Michelangelo。它依赖于 Uber 的事务和日志数据湖，并支持离线（批处理）和在线（流式）预测。对于离线预测，容器化的 Spark 作业生成批处理预测，而对于在线部署，模型在一个预测服务集群中提供，该集群通常由负载均衡器后面的数百台机器组成，客户端将单个或批量预测请求作为 RPC 发送。

与模型管理相关的元数据（例如，训练器的运行时统计数据、模型配置、血统、特征的分布和相对重要性、模型评估指标、标准评估图表、学习的参数值以及总结统计数据）会为每个实验存储。

Michelangelo 可以在同一个服务容器中部署多个模型，这允许在旧模型版本到新模型版本之间安全过渡，并进行模型的并行 A/B 测试。

[![Uber的 Michelangelo: 在线与离线](../Images/dc66920d446d06b5a08ba07f79c78628.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v1.png)

Michelangelo 的最初版本不支持深度学习在 GPU 上的训练需求，但团队在此期间解决了这个遗漏。当前平台([current platform](https://eng.uber.com/michelangelo-model-representation/)) 使用了 Spark 的 ML 管道序列化，但增加了一个用于在线服务的额外接口，添加了一个单例（在线）评分方法，该方法既轻量级又能够处理紧密的服务水平协议，例如，用于欺诈检测和预防。它通过绕过 Spark SQL 的 Catalyst 优化器的开销来实现。

[![Uber的 Michelangelo: 训练与服务](../Images/f5d95859749ca800973a084799abdbaf.png)](https://databaseline.tech/images/2020-02-21-ml-michelangelo-v2.png)

值得注意的是，Google 和 Uber 都为服务构建了内部的协议缓冲解析器和表示，从而避免了默认实现中的瓶颈。

### Airbnb: Bighead

Airbnb 在2016/2017年成立了自己的机器学习基础设施团队，原因类似。首先，他们当时生产中的模型很少，但每个模型的构建可能需要长达三个月。其次，各模型之间没有一致性。第三，在线预测和离线预测之间存在较大差异。[Bighead](https://www.slideshare.net/databricks/bighead-airbnbs-endtoend-machine-learning-platform-with-krishna-puttaswamy-and-andrew-hoh)是他们努力的结晶：

[![Airbnb的 Bighead](../Images/7ab8003ae8a7ebcfe1ca27697597d3ae.png)](https://databaseline.tech/images/2020-02-21-ml-bighead.png)

数据管理由内部工具 Zipline 处理。Redspot 是一个托管的、容器化的、多租户 Jupyter notebook 服务。Bighead 库用于数据转换和管道抽象，并持有常见模型框架的封装器。它通过转换保留元数据，因此用于跟踪数据血统。

Deep Thought 是一个用于在线预测的 REST API。Kubernetes 协调这些服务。对于离线预测，Airbnb 使用他们自己的 Automator。

### Netflix: Metaflow

Netflix遇到了与上述公司类似的问题，这并不令人惊讶。他们的解决方案是[Metaflow](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9)，这是一个针对数据科学家的Python库，处理[数据管理和模型训练，而不是预测服务](https://blog.valohai.com/three-ways-to-categorize-machine-learning-platforms)。因此，它*不是*一个端到端的机器学习平台，也许更适合公司内部使用，而不是面向用户的使用场景。当然，它可以通过[Seldon](https://www.seldon.io/)（由Kubernetes支持）或[AWS SageMaker](https://aws.amazon.com/sagemaker/)转变为一个成熟的解决方案。进一步的服务工具列表可以在[这里](https://github.com/EthicalML/awesome-production-machine-learning#model-deployment-and-orchestration-frameworks)找到。

[![Netflix的Metaflow](../Images/596f35c7ad288860e2252c986a5fa308.png)](https://databaseline.tech/images/2020-02-21-ml-metaflow.png)

数据科学家将他们的工作流程编写为DAG步骤，这与数据工程师在使用Airflow时的做法类似。像Airflow一样，你可以使用任何数据科学库，因为对Metaflow来说，只有执行的Python代码。Metaflow在后台分发处理和训练。所有代码和数据都会自动快照到S3，以确保每个模型和实验都有版本历史。Pickle是默认的模型序列化格式。

[开源版本](https://docs.metaflow.org/)尚未内置[scheduler](https://docs.metaflow.org/introduction/what-is-metaflow)。它还鼓励用户“主要依赖垂直扩展”，尽管他们可以使用AWS SageMaker进行水平扩展。它与AWS紧密耦合。

### Lyft: Flyte

Lyft开源了他们的云原生平台[Flyte](https://flyte.org/)，在这里数据和机器学习操作[融合](https://static.sched.com/hosted_files/kccncna19/7f/Flyte%20Kubecon.pdf)。这与我的[D/MLOps理念](https://databaseline.tech/lean-dml-operations/)一致——数据(Ops)对MLOps就像燃料对火箭一样：没有它，什么也不会发生。

它建立在Kubernetes之上。由于内部由Lyft使用，它能够扩展到至少7000个独特的工作流程，每月超过10万次执行，100万个任务和1000万个容器。

Flyte中的所有实体都是不可变的，因此可以跟踪数据血缘、重现实验和回滚部署。重复任务可以利用任务缓存来节省时间和金钱。目前支持的任务包括[Python、Hive、Presto和Spark](https://lyft.github.io/flyte/user/tasktypes/index.html)以及[sidecars](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)。从源代码来看，似乎EKS是

[![Lyft的Flyte](../Images/1c7dd71ceb912bc09c0e0ef0565b8d13.png)](https://databaseline.tech/images/2020-02-21-ml-flyte.png)

他们还有一个[Amundsen](https://github.com/lyft/amundsen)，这是一个类似于Spotify的[Lexikon](https://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/)的数据目录。

### AWS、Azure、GCP等。

除了Oracle仅为某些用例和行业提供[预制的基于ML的模型](https://www.oracle.com/artificial-intelligence/products.html)外，所有主要的[公共云](https://cloud.google.com/gartner-cloud-infrastructure-as-a-service/)提供商都有自己的机器学习平台解决方案。

**AWS [SageMaker](https://aws.amazon.com/sagemaker/)** 是一个支持TensorFlow、Keras、PyTorch和MXNet的完整机器学习解决方案。通过[SageMaker Neo](https://aws.amazon.com/sagemaker/neo/)可以将模型同时部署到云端和边缘。它内置了通过Amazon Mechanical Turk进行标注的功能，适用于存储在S3中的数据。

[![AWS SageMaker](../Images/b1311ad9d1502bf934a5199251ab3728.png)](https://databaseline.tech/images/2020-02-21-ml-sagemaker.png)

Google没有托管平台，但通过[TFX、Kubeflow和**AI Platform**](https://cloud.google.com/ai-platform/)可以将运行模型所需的所有组件整合在一起，支持在CPU、GPU和TPU上运行，调优超参数，并自动部署到生产环境。[Spotify](https://labs.spotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/)甚至选择了TFX/Kubeflow-on-GCP选项。

除了TensorFlow，支持的还有[scikit-learn和XGBoost](https://cloud.google.com/ai-platform/training/docs?hl=en)。自定义容器允许你使用任何框架，如[PyTorch](https://cloud.google.com/ai-platform/training/docs/custom-containers-training?hl=en)。目前还有一个类似SageMaker Ground Truth的[标注服务](https://cloud.google.com/ai-platform/data-labeling/docs/)在测试阶段。

[![GCP AI Platform](../Images/93293af80aba9458cd660633ed54da87.png)](https://databaseline.tech/images/2020-02-21-ml-gcp.svg)

**[Azure 机器学习](https://azure.microsoft.com/en-us/services/machine-learning/)**支持相当多的[框架](https://azure.microsoft.com/en-us/services/machine-learning/#product-overview)，例如 scikit-learn、Keras、PyTorch、XGBoost、TensorFlow 和 MXNet。它拥有自己的[D/MLOps](https://azure.microsoft.com/en-us/services/machine-learning/mlops/#key-phases)套件，包含大量图表。对于那些喜欢拖放界面的模型开发者，该平台也提供了这样的功能，但这带有各种[caveats](https://databaseline.tech/the-problems-with-visual-programming-languages-in-data-engineering/)。模型和实验管理，如微软所期望的那样，是通过注册表来完成的。对于生产部署，使用了[Azure Kubernetes Service](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-and-where#deploy-to-target)。受控推出也是[possible](https://docs.microsoft.com/en-gb/azure/machine-learning/how-to-deploy-azure-kubernetes-service#deploy-models-to-aks-using-controlled-rollout-preview)的。

**[IBM Watson ML](https://www.ibm.com/cloud/machine-learning)** 提供了点击式机器学习选项（SPSS）以及对一系列常见[框架](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html)的支持。与其他主要玩家一样，模型可以在 CPU 或 GPU 上训练。[超参数调整](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml_dlaas_hpo.html?linkInPage=true)也包含在内。该平台在数据和模型验证方面没有很多细节，因为这些在其他 IBM 产品中可以找到。

尽管**Alibaba 的 [ML Platform for AI](https://www.alibabacloud.com/product/machine-learning)** 名字中有两个流行词，但并没有改进文档；[最佳实践](https://www.alibabacloud.com/help/doc-detail/67395.htm?spm=a2c63.p38356.b99.39.62bb4809Vl31Cw)部分更多是用例而非推荐。

不过，它对[拖放操作](https://www.alibabacloud.com/help/doc-detail/126312.htm)要求较高，尤其是在数据管理和建模方面，这可能不利于一个自动化的端到端机器学习平台。该平台支持诸如[TensorFlow, MXNet 和 Caffe](https://www.alibabacloud.com/help/doc-detail/75093.htm)等框架，同时也拥有大量[传统算法](https://www.alibabacloud.com/help/doc-detail/69688.htm)。它包括一个超参数调整器，这是可以预期的。

模型序列化使用 [PMML、TensorFlow 的 SavedModel 格式或 Caffe 格式](https://www.alibabacloud.com/help/doc-detail/126313.htm)。请注意，使用接受 [PMML、ONNX](https://medium.com/analytics-and-data/overview-of-the-different-approaches-to-putting-machinelearning-ml-models-in-production-c699b34abf86) 或 [PFA 文件](http://dmg.org/pfa/)的评分引擎可能会实现快速部署，但这有可能引入训练/服务偏差，因为服务的模型是从不同的格式加载的。

### 荣誉提名

**[H2O](https://www.h2o.ai/products/h2o/#overview)** 提供了一个包含数据操作、各种算法、交叉验证、超参数调优网格搜索、特征排名和模型序列化（使用 [POJO 或 MOJO](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/productionizing.html#about-pojo-mojo)）的平台。

[![H2O.ai](../Images/e40354fba75e394968b47280930201b3.png)](https://databaseline.tech/images/2020-02-21-ml-h2o.png)

**[Valohai](https://valohai.com/product/)**—芬兰语中的“光明的鲨鱼”，真的！—是一个托管的机器学习平台。它可以运行在私有、公有、混合或多云设置中。

[![Valohai](../Images/1a813d3633a3373e19b7e920386b3a65.png)](https://databaseline.tech/images/2020-02-21-ml-valohai.png)

每个操作（或 [执行](https://docs.valohai.com/core-concepts/executions/)）运行一个命令来处理 Docker 镜像，因此它与 [Kubeflow](https://www.kubeflow.org/) 非常相似。主要的区别是 Valohai 为你管理 Kubernetes 部署集群，而 Kubeflow 需要你自己管理。然而，Kubeflow 和 TFX 具有一定的偏好，它们提供了一些开箱即用的 TensorFlow 相关工具。使用 Valohai，你需要重用现有的 Docker 镜像或自己创建，这意味着你可以使用任何机器学习框架，但这种自由必须与可维护性问题进行权衡。

因此，通过依赖 [Spark](https://spark.apache.org/docs/latest/ml-guide.html)、 [Horovod](https://eng.uber.com/horovod/)、 [TensorFlow](https://www.tensorflow.org/guide/distributed_training) 或任何适合你需求和基础设施的工具，进行训练分布是可能的，但你需要填补空白。这也意味着你负责确保数据转换的兼容性，以避免训练/服务偏差。请注意，它目前只支持 [对象存储](https://docs.valohai.com/core-concepts/data-stores/)。

**[Iguazio](https://www.iguazio.com/platform/)** 提到能够 [从笔记本或 IDE 中秒级部署](https://www.iguazio.com/platform/)，但这似乎忽略了最常见的场景：CI/CD 管道，甚至是平台本身，例如 TFX 的 [Pusher](https://www.tensorflow.org/tfx/guide/pusher) 组件。它使用 Kubeflow 进行工作流编排。

[![Iguazio](../Images/77a3e52aa3681a5ce0a14d3a1ac05315.png)](https://databaseline.tech/images/2020-02-21-ml-iguazio.png)

Iguazio确实提供了一个具有统一API的特征存储，用于键值对和时间序列。许多现有产品没有自己的特征存储，尽管大多数大型科技公司都有这样的存储。特征存储是一个集中式的地方，具有可重用的特征，可以在模型之间共享，以加速模型开发。它可以在企业规模上自动化特征工程。例如，从时间戳中，你可以提取许多特征：年份、季节、月份、星期几、一天中的时间、是否是当地假日、上一个相关事件后的经过时间（最近性）、在固定窗口内某事件发生的频率等等。

**[SwiftStack AI](https://www.swiftstack.com/solutions/ai)**旨在支持在NVIDIA GPUs上进行高吞吐量深度学习，使用[RAPIDS](https://www.developer.nvidia.com/rapids)套件。RAPIDS提供了库，如[cuML](https://github.com/rapidsai/cuml)，允许用户使用熟悉的scikit-learn API，但利用GPU加速支持的算法，以及[cuGraph](https://github.com/rapidsai/cugraph)用于GPU驱动的图分析。

[![SwiftStack AI](../Images/d1e2f10cef9d510fbd15830b0cef3f06.png)](https://databaseline.tech/images/2020-02-21-ml-swiftstack.png)

**[AI Layer](https://algorithmia.com/serverless-ai-layer)**是一个[D/MLOps的API](https://www.linkedin.com/pulse/ai-layer-diego-oppenheimer/)。它内置支持多种数据源、编程语言和机器学习框架。

[![Algorithmia's AI Layer](../Images/d043542d81bd1ef6ee760721a157c0ee.png)](https://databaseline.tech/images/2020-02-21-ml-ai-layer.jpg)

**[MLflow](https://mlflow.org/)**由Databricks支持，这解释了它与Spark的紧密集成。它提供了[有限的部署选项](https://mlflow.org/docs/latest/models.html#built-in-deployment-tools)。例如，将模型导出为[向量化UDF](https://spark.apache.org/docs/2.4.0/sql-pyspark-pandas-with-arrow.html)在PySpark中并不是最合适的实时系统选择，因为Python UDFs涉及Python运行时环境与JVM之间的通信开销。虽然这种开销比标准PySpark UDFs要小，因为在Python和JVM之间的传输中使用了Apache Arrow这一内存列式格式，但[开销仍然不小](https://medium.com/@QuantumBlack/spark-udf-deep-insights-in-performance-f0a95a4d8c62)。由于Spark Streaming作为默认的数据摄取解决方案，在Spark的微批处理模型下实现亚秒延迟可能仍然具有挑战性。

对于日志记录的支持，这对D/MLOps至关重要，[仍在实验阶段](https://mlflow.org/docs/latest/tracking.html#automatic-logging)。根据文档，MLflow并不专注于数据和模型验证，至少不是平台自身的标准部分。MLflow有一个托管版本（在AWS和Azure上），提供[更多功能](https://databricks.com/product/managed-mlflow)。

**D2iQ的[KUDO for Kubeflow](https://d2iq.com/solutions/ksphere/kudo-kubeflow)**是一个面向企业客户的基于Kubeflow的平台。与开源的Kubeflow不同，它包含Spark和[Horovod](https://github.com/horovod/horovod)，以及针对主要框架（TensorFlow、PyTorch和MXNet）预构建和全面测试的CPU/GPU镜像。数据科学家可以在笔记本中进行部署，无需切换上下文。默认支持多租户。[Istio](https://istio.io/)和[Dex](https://github.com/dexidp/dex)集成以提供额外的安全性和认证。KUDO for Kubeflow建立在D2iQ的托管Kubernetes平台Konvoy之上。它可以在云中、本地、混合环境或边缘运行。还支持气隔集群。

在Kubernetes的术语中，Kubeflow的KUDO是一个由[KUDO](https://kudo.dev/)定义的操作符集合，KUDO是一个声明式工具包，用于使用YAML而非Go语言创建Kubernetes操作符。Kubernetes统一声明式操作符（KUDOs）对于Cassandra、Elastic、Flink、Kafka、Redis等都是[开源的](https://github.com/kudobuilder/operators)，并且可以与平台集成。更多细节请参阅[我个人的介绍文章](https://d2iq.com/blog/kudo-for-kubeflow-the-enterprise-machine-learning-platform)。

如果你想查看更多选项，包括可视化工作台，请[点击这里](https://heartbeat.fritz.ai/ai-and-machine-learning-landscape-part-4-end-to-end-ml-platforms-5adeac675d13)或查看[Gartner的数据科学和机器学习平台魔力象限](https://www.analyticsvidhya.com/blog/2020/02/gartners-2020-magic-quadrant-for-data-science-and-machine-learning-tools-check-out-the-new-leaders/)。Facebook还发布了他们的平台[FBLearner Flow](https://engineering.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/)（2016年），以及[LinkedIn](https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin)（2018年）和[eBay](https://tech.ebayinc.com/engineering/ebays-transformation-to-a-modern-ai-platform/)（2019年）的相关细节。

**个人简介：[Ian Hellström](https://databaseline.tech/)**曾在包括D2iQ、Spotify、Bosch和Sievo在内的多家公司担任数据和机器学习工程师。他是D2iQ企业机器学习平台KUDO for Kubeflow的产品经理。他目前居住在德国汉堡。

[原文](https://databaseline.tech/a-tour-of-end-to-end-ml-platforms/)。经允许转载。

**相关信息：**

+   [如何扩展Scikit-learn并为你的机器学习工作流带来理智](/2019/10/extend-scikit-learn-bring-sanity-machine-learning-workflow.html)

+   [外行人的数据科学指南。第3部分：数据科学工作流](/2020/07/laymans-guide-data-science-workflow.html)

+   [使用Docker容器将机器学习管道部署到云端](/2020/06/deploy-machine-learning-pipeline-cloud-docker.html)

### 更多相关话题

+   [2024年你必须尝试的7个平台，支持端到端的MLOps](https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024)

+   [端到端机器学习的初学者指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)

+   [机器学习算法的完整端到端部署到…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)

+   [Python NLP 库概览](https://www.kdnuggets.com/a-tour-of-python-nlp-libraries)

+   [5款最佳的端到端开源MLOps工具](https://www.kdnuggets.com/5-best-end-to-end-open-source-mlops-tools)

+   [使用HuggingFace实现一个简单的端到端项目](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)
