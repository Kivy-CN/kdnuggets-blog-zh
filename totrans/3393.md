# 如何在第一次Kaggle比赛中排名前10%

> 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3)

**模型训练**

我们可以通过调节模型参数来提高模型的性能。一个模型通常有很多参数，但其中只有少数对性能有显著影响。例如，随机森林中最重要的参数是森林中的树木数量和在每棵树中使用的最大特征数。**我们需要了解模型如何工作，以及每个参数对模型性能的影响，无论是准确性、鲁棒性还是速度。**

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的IT需求

* * *

通常我们会通过一个叫做**[网格搜索](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)**的过程来找到最佳参数集。实际上，它所做的只是遍历所有可能的组合并找到最佳的那个。

顺便提一下，当`max_features`设置为特征总数的平方根时，随机森林通常能达到最优。

在这里，我想强调一些关于调节XGB的要点。这些参数通常被认为对性能有实际影响：

+   `eta`：用于更新权重的步长。较低的`eta`意味着训练速度较慢，但收敛性更好。

+   `num_round`：总迭代次数。

+   `subsample`：每次迭代中使用的训练数据比例。这是为了防止过拟合。

+   `colsample_bytree`：每次迭代中使用的特征比例。这类似于`RandomForestClassifier`中的`max_features`。

+   `max_depth`：每棵树的最大深度。与随机森林不同，**梯度提升算法如果不限制其深度，最终会过拟合**。

+   `early_stopping_rounds`：如果在给定的迭代次数内验证分数没有提高，算法将提前停止。这也是为了防止过拟合。

常见的调优步骤：

1.  保留一部分训练集作为验证集。

1.  将`eta`设置为相对较高的值（例如0.05 ~ 0.1），将`num_round`设置为300 ~ 500。

1.  使用网格搜索来找到其他参数的最佳组合。

1.  逐渐降低`eta`直到达到最优。

1.  **使用验证集作为`watch_list`以最佳参数重新训练模型。观察每次迭代中验证集上的得分变化。找到`early_stopping_rounds`的最佳值。**

最后，请注意，所有具有随机性的模型都有一个类似于`seed`或`random_state`的参数来控制随机种子。**你必须记录这个**以及所有其他参数，以便在获得一个好的模型时能够重现它。否则你将无法复现它。

**交叉验证**

**[交叉验证](https://en.wikipedia.org/wiki/Cross-validation_(statistics))** 是模型训练中的一个关键步骤。它告诉我们我们的模型是否有较高的过拟合风险。在许多比赛中，公共LB分数并不非常可靠。经常地，当我们改进模型并获得更好的本地CV分数时，LB分数反而会变差。**在这种情况下，人们普遍认为我们应该信任我们的CV分数。** 理想情况下，我们希望**通过不同方法获得的CV分数与LB分数同步提高**，但这并非总是可能的。

通常**5折交叉验证（5-fold CV）**已经足够好。如果我们使用更多的折，CV分数将变得更可靠，但训练也需要更长时间完成。然而，如果我们的训练数据有限，我们不应使用太多的折。否则每个折中的样本太少，无法保证统计显著性。

如何正确进行CV不是一个简单的问题。它需要不断的实验和逐个案例讨论。许多Kaggler在比赛后分享他们的CV方法（例如[this one](https://www.kaggle.com/c/telstra-recruiting-network/forums/t/19277/what-is-your-cross-validation-method)），因为他们认为可靠的CV并不容易。

**集成生成（Ensemble Generation）**

[集成学习](https://en.wikipedia.org/wiki/Ensemble_learning)指的是结合不同模型的技术。它**减少了最终模型的偏差和方差**（你可以在[这里](http://link.springer.com/chapter/10.1007%2F3-540-33019-4_19)找到证明），从而**提高了得分并减少了过拟合的风险**。最近，没有使用集成方法几乎无法在Kaggle竞赛中获奖。

集成学习的常见方法包括：

+   **装袋（Bagging）**：使用训练数据的不同随机子集来训练每个基模型。然后，所有基模型投票生成最终预测。这就是随机森林的工作方式。

+   **提升（Boosting）**：迭代训练基模型，根据上一次迭代修改训练样本的权重。这就是梯度提升树的工作方式。（实际上这并不是全部。除了提升，GBT还试图学习早期迭代的残差。）它的表现优于装袋，但更容易过拟合。

+   **混合（Blending）**：使用不重叠的数据训练不同的基模型，并对它们的加权平均以获得最终预测。这种方法易于实现，但使用的数据较少。

+   **堆叠（Stacking）**：将在下一部分讨论。

理论上，要使集成模型表现良好，两个因素很重要：

+   **基础模型应该尽可能无关**。这就是为什么我们倾向于在集成中包含非树模型，即使它们的表现不如其他模型。数学上说，模型的多样性越大，最终集成中的偏差越小。

+   **基础模型的表现不应相差太大**。

实际上，我们在这里有一个**权衡**。在实践中，我们可能会得到表现相当的高度相关的模型。但我们仍然将它们集成在一起，因为这通常会提高整体性能。

**堆叠**

与混合方法相比，堆叠方法更好地利用了训练数据。以下是其工作原理的图示：

[![堆叠](../Images/fb2fd03a6a8cf5851969a1254b354966.png)](http://7xlo8f.com1.z0.glb.clouddn.com/blog-diagram-stacking.jpg)

*(摘自 [Faron](https://www.kaggle.com/mmueller)。非常感谢！)*

这很像交叉验证。以5折堆叠为例。首先，我们将训练数据分成5折。接下来，我们将进行5次迭代。在每次迭代中，在4折上训练每个基础模型，并在保留折上进行预测。**你还必须保留在测试数据上的预测。** 这样，在每次迭代中，每个基础模型将对训练数据中的1折和所有测试数据进行预测。经过5次迭代后，我们将得到一个形状为`#(训练数据样本数) X #(基础模型数)`的矩阵。这个矩阵随后会被送到第二层的堆叠器（它只是另一个模型）。在堆叠器训练完成后，使用基础模型在测试数据上的预测（**每个基础模型训练5次，因此我们需要取平均值以获得相同形状的矩阵**）作为堆叠器的输入，从而获得我们的最终预测。

也许直接展示代码会更好：

奖励获得者通常有更大且复杂得多的集成。对于初学者来说，实施一个正确的5折堆叠就足够了。

***管道***

我们可以看到，Kaggle比赛的工作流程相当复杂，尤其是在模型选择和集成方面。理想情况下，我们需要一个能够高度自动化的管道，具备以下功能：

+   **模块化特征转换**。我们只需写几行代码（或者更好的是，使用规则/领域特定语言），新的特征就会添加到训练集中。

+   **自动化网格搜索**。我们只需设置模型和参数网格，搜索将会运行，并记录最佳参数。

+   **自动化集成选择**。当我们将另一个基础模型添加到池中时，使用K个最佳模型进行集成训练。

对于初学者来说，第一个因素不太重要，因为特征数量相对可管理；第三个因素也不重要，因为通常我们在比赛结束时只做几次集成。但第二个因素是值得注意的，因为**手动记录每个模型的性能和参数既耗时又容易出错**。

[陈成龙](https://www.kaggle.com/chenglongchen)，曾获得 [Crowdflower 搜索结果相关性](https://www.kaggle.com/c/crowdflower-search-relevance) 的奖项，曾在 [GitHub](https://github.com/ChenglongChen/Kaggle_CrowdFlower) 上发布过他的工作流程。这个流程非常完整且高效，但理解和提取他的所有逻辑以构建一个通用框架是非常困难的。这是你在有充足时间时可能想做的事情。

### 更多相关主题

+   [LinkedIn 如何利用机器学习来排序你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)

+   [如何在没有任何工作经验的情况下获得你的第一份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [它活了！用 Python 和一些便宜的组件打造你的第一个机器人](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)

+   [从零到英雄：用 PyTorch 创建你的第一个 ML 模型](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)

+   [部署你的第一个机器学习模型](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)
