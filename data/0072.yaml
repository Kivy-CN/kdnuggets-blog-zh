- en: 'Greening AI: 7 Strategies to Make Applications More Sustainable'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Greening AI: 7 Strategies to Make Applications More Sustainable'
- en: 原文：[https://www.kdnuggets.com/greening-ai-7-strategies-to-make-applications-more-sustainable](https://www.kdnuggets.com/greening-ai-7-strategies-to-make-applications-more-sustainable)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/greening-ai-7-strategies-to-make-applications-more-sustainable](https://www.kdnuggets.com/greening-ai-7-strategies-to-make-applications-more-sustainable)
- en: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/313096bb3be8117d714e163bf4bbafb3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/313096bb3be8117d714e163bf4bbafb3.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图片
- en: AI applications possess unparalleled computational capabilities that can propel
    progress at an unprecedented pace. Nevertheless, these tools rely heavily on energy-intensive
    data centers for their operations, resulting in a concerning lack of energy sensitivity
    that contributes significantly to their carbon footprint. Surprisingly, these
    AI applications already account for a substantial [2.5 to 3.7](https://8billiontrees.com/carbon-offsets-credits/carbon-ecological-footprint-calculators/carbon-footprint-of-data-centers/#:~:text=Data%20centers%20account%20for%202.5,that%20fuel%20the%20global%20economy)
    percent of global greenhouse gas emissions, surpassing the emissions from the
    aviation industry.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: AI应用具有无与伦比的计算能力，可以以前所未有的速度推动进步。然而，这些工具高度依赖于耗能的数据中心，从而导致其碳足迹的显著增加。令人惊讶的是，这些AI应用已经占据了全球温室气体排放的[2.5到3.7](https://8billiontrees.com/carbon-offsets-credits/carbon-ecological-footprint-calculators/carbon-footprint-of-data-centers/#:~:text=Data%20centers%20account%20for%202.5,that%20fuel%20the%20global%20economy)百分比，超过了航空业的排放量。
- en: And unfortunately, this carbon footprint is increasing at a fast pace.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这一碳足迹正在快速增长。
- en: Presently, the pressing need is to measure the carbon footprint of machine learning
    applications, as emphasized by Peter Drucker's wisdom that "You can't manage what
    you can't measure." Currently, there exists a significant lack of clarity in quantifying
    the environmental impact of AI, with precise figures eluding us.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，迫切需要测量机器学习应用的碳足迹，正如彼得·德鲁克的智慧所强调的：“你无法管理你无法测量的东西。”目前，在量化AI的环境影响方面存在显著的模糊性，具体数字仍然难以确定。
- en: In addition to measuring the carbon footprint, the AI industry's leaders must
    actively focus on optimizing it. This dual approach is vital to addressing the
    environmental concerns surrounding AI applications and ensuring a more sustainable
    path forward.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 除了测量碳足迹外，AI行业的领导者还必须积极关注优化碳足迹。这一双重方法对于解决AI应用的环境问题以及确保更加可持续的发展路径至关重要。
- en: What factors contribute to the carbon footprint of AI applications
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 影响AI应用碳足迹的因素
- en: The increased use of machine learning requires increased data centers, many
    of which are power hungry and thus have a significant carbon footprint. The global
    electricity usage by data centers amounted to [0.9 to 1.3 percent](https://www.iea.org/reports/data-centres-and-data-transmission-networks)
    in 2021.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的使用增加了对数据中心的需求，其中许多数据中心电力消耗巨大，因此具有显著的碳足迹。2021年，数据中心的全球电力使用量达到了[0.9到1.3百分比](https://www.iea.org/reports/data-centres-and-data-transmission-networks)。
- en: A [2021 study](https://ris.utwente.nl/ws/portalfiles/portal/252516283/1_s2.0_S0306261921003019_main.pdf)
    estimated that this usage can increase to 1.86 percent by 2030\. This [figure](https://www.akcp.com/blog/the-real-amount-of-energy-a-data-center-use/)
    represents the increasing trend of energy demand due to data centers
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一项[2021年的研究](https://ris.utwente.nl/ws/portalfiles/portal/252516283/1_s2.0_S0306261921003019_main.pdf)估计，到2030年，这一使用比例可能会增加到1.86%。这个[数字](https://www.akcp.com/blog/the-real-amount-of-energy-a-data-center-use/)代表了由于数据中心导致的能源需求不断增加的趋势
- en: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/569ee8c6690d85fe7a8b9432a1cdf8b1.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/569ee8c6690d85fe7a8b9432a1cdf8b1.png)'
- en: © Energy consumption trend and share of use for data centers
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: © 数据中心的能源消耗趋势及使用份额
- en: Notably, the higher the energy consumption is, the higher the carbon footprint
    will be. Data centers heat up during processing and can become faulty and even
    stop functioning due to overheating. Hence, they need cooling, which requires
    additional energy. Around [40 percent](https://www.sciencedirect.com/science/article/pii/S1876610215009467)
    of the electricity consumed by data centers is for air conditioning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，能源消耗越高，碳足迹也越高。数据中心在处理过程中会发热，可能会因过热而发生故障甚至停止运作。因此，它们需要冷却，这需要额外的能源。大约[40％](https://www.sciencedirect.com/science/article/pii/S1876610215009467)的数据中心电力消耗用于空调。
- en: Computing Carbon Intensity for AI Applications
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算AI应用程序的碳强度
- en: Given the increasing footprint of AI usage, these tools’ carbon intensity needs
    to be accounted for. Currently, the research on this subject is limited to analyses
    of a few models and does not adequately address the diversity of the said models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于AI使用的足迹不断增加，这些工具的碳强度需要被考虑。目前，关于这一主题的研究仅限于对几个模型的分析，并没有充分涵盖这些模型的多样性。
- en: Here is an evolved methodology and a few effective tools to compute carbon intensity
    of AI systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个经过改进的方法论以及一些有效的工具，用于计算AI系统的碳强度。
- en: Methodology for estimating carbon intensity of AI
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算AI碳强度的方法论
- en: The Software Carbon Intensity (SCI) [standard](https://github.com/Green-Software-Foundation/sci)
    is an effective approach for estimating carbon intensity of AI systems. Unlike
    the conventional methodologies that employ attributional carbon accounting approach,
    it uses a consequential computing approach.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 软件碳强度（SCI）[标准](https://github.com/Green-Software-Foundation/sci) 是估算AI系统碳强度的有效方法。与传统的采用归因性碳会计方法的方式不同，它采用了后果性计算方法。
- en: Consequential approach attempts to calculate the marginal change in emissions
    arising from an intervention or decision, such as the decision to generate an
    extra unit. Whereas, attribution refers to accounting average intensity data or
    static inventories of emissions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 后果性方法尝试计算由于干预或决策（例如生成额外单位）所产生的排放边际变化。而归因则是指计算平均强度数据或排放的静态清单。
- en: 'A [paper](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533234) on “Measuring
    the Carbon Intensity of AI in Cloud Instances” by Jesse Doge et al. has employed
    this methodology to bring in more informed research. Since a significant amount
    of AI model training is conducted on cloud computing instances, it can be a valid
    framework to compute the carbon footprint of AI models. The paper refines SCI
    formula for such estimations as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇由Jesse Doge等人撰写的关于“测量云实例中AI的碳强度”的[论文](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533234)运用了这一方法论，以提供更为详尽的研究。由于大量的AI模型训练是在云计算实例上进行的，这可能成为计算AI模型碳足迹的有效框架。该论文对SCI公式进行了改进，用于此类估算：
- en: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/0d85e81153b9458cddbb4b35ae8ce2c0.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![绿色AI：使应用程序更可持续的7种策略](../Images/0d85e81153b9458cddbb4b35ae8ce2c0.png)'
- en: 'which is refined from:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法从以下公式中细化：
- en: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/391d8019836a589269228939d8330048.png)
    that derives from ![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/9d091f70ee7b67ae92bb65af3100b033.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![绿色AI：使应用程序更可持续的7种策略](../Images/391d8019836a589269228939d8330048.png) 来源于
    ![绿色AI：使应用程序更可持续的7种策略](../Images/9d091f70ee7b67ae92bb65af3100b033.png)'
- en: 'where:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '**E:** Energy consumed by a software system, primarily of graphical processing
    units-GPUs which is specialized ML hardware.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**E:** 软件系统消耗的能源，主要是图形处理单元（GPU），这是一种专用的机器学习硬件。'
- en: '**I:** Location-based marginal carbon emissions by the grid powering the datacenter.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**I:** 数据中心电网提供的基于位置的边际碳排放。'
- en: '**M:** Embedded or embodied carbon, which is the carbon emitted during usage,
    creation, and disposal of hardware.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**M:** 嵌入或体现的碳，即在硬件的使用、制造和处置过程中排放的碳。'
- en: '**R:** Functional unit, which in this case is one machine learning training
    task.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**R:** 功能单元，在本例中为一个机器学习训练任务。'
- en: '**C= O+M, where O equals E*I **'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**C= O+M，其中O等于E*I**'
- en: 'The paper uses the formula to estimate electricity usage of a single cloud
    instance. In ML systems based on deep learning, major electricity consumption
    owes it to the GPU, which is included in this formula. They trained a BERT-base
    model using a single NVIDIA TITAN X GPU (12 GB) in a commodity server with two
    Intel Xeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs) to experiment
    the application of this formula. The following figure shows the results of this
    experiment:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 论文使用公式来估算单个云实例的电力使用。在基于深度学习的ML系统中，主要的电力消耗归功于GPU，该公式中包括了GPU。他们使用一台配有两个Intel Xeon
    E5-2630 v3 CPU（2.4GHz）和256GB RAM（16x16GB DIMMs）的商品服务器上的单个NVIDIA TITAN X GPU（12
    GB）训练了一个BERT-base模型，以实验该公式的应用。下图显示了这个实验的结果：
- en: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/6af4c8d1704f436f450fd32b55e47464.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Greening AI: 7 Strategies to Make Applications More Sustainable](../Images/6af4c8d1704f436f450fd32b55e47464.png)'
- en: © Energy consumption and split between components of a server
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: © 能耗及服务器组件间的分配
- en: The GPU claims 74 percent of the energy consumption. Although it is still claimed
    as an underestimation by the paper’s authors, inclusion of GPU is the step in
    the right direction. It is not the focus of the conventional estimation techniques,
    which means that a major contributor of carbon footprint is being overlooked in
    the estimations. Evidently, SCI offers a more wholesome and reliable computation
    of carbon intensity.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: GPU占据了74%的能耗。尽管论文作者仍然认为这是一个低估，但纳入GPU是朝着正确方向迈出的步骤。传统的估算技术没有关注这一点，这意味着碳足迹的一个主要贡献者在估算中被忽视了。显然，SCI提供了更全面和可靠的碳强度计算。
- en: Approaches to measure real-time carbon footprint of cloud computing
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时测量云计算的碳足迹的方法
- en: AI model training is often conducted on cloud compute instances, as cloud makes
    it flexible, accessible, and cost-efficient. Cloud computing provides the infrastructure
    and resources to deploy and train AI models at scale. That’s why model training
    on cloud computing is increasing gradually.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型训练通常在云计算实例上进行，因为云计算使其灵活、可访问且成本高效。云计算提供了大规模部署和训练AI模型所需的基础设施和资源。这就是为什么模型训练在云计算上逐渐增加的原因。
- en: It’s important to measure the real-time carbon intensity of cloud compute instances
    to identify areas suitable for mitigation efforts. Accounting time-based and location-specific
    marginal emissions per unit of energy can help calculate operational carbon emissions,
    as done by a [2022 paper](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533234).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 测量云计算实例的实时碳强度很重要，以识别适合减排努力的领域。计算单位能源的时间和地点特定的边际排放量可以帮助计算操作碳排放，正如[2022年论文](https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533234)中所做的那样。
- en: An [opensource](https://www.cloudcarbonfootprint.org/) tool, Cloud Carbon Footprint
    (CCF) software is also available to compute the impact of cloud instances.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个[开源](https://www.cloudcarbonfootprint.org/)工具，Cloud Carbon Footprint (CCF)
    软件也可以用来计算云实例的影响。
- en: Improving the carbon efficiency of AI applications
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高AI应用的碳效率
- en: Here are 7 ways to optimize the carbon intensity of AI systems.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有7种方法来优化AI系统的碳强度。
- en: 1\. Write better, more efficient code
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 编写更好、更高效的代码
- en: Optimized codes can reduce energy consumption by [30 percent](https://www.zuehlke.com/en/insights/green-coding-innovation-for-more-sustainable-it)
    through decreased memory and processor usage. Writing a carbon-efficient code
    involves optimizing algorithms for faster execution, reducing unnecessary computations,
    and selecting energy-efficient hardware to perform tasks with less power.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 优化的代码可以通过减少内存和处理器使用来减少[30 percent](https://www.zuehlke.com/en/insights/green-coding-innovation-for-more-sustainable-it)的能耗。编写碳高效的代码涉及优化算法以加快执行速度，减少不必要的计算，以及选择能效高的硬件以用更少的电力完成任务。
- en: Developers can use profiling tools to identify performance bottlenecks and areas
    for optimization in their code. This process can lead to more energy-efficient
    software. Also, consider implementing energy-aware programming techniques, where
    code is designed to adapt to the available resources and prioritize energy-efficient
    execution paths.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员可以使用性能分析工具来识别代码中的性能瓶颈和优化领域。这个过程可以导致更节能的软件。此外，考虑实施节能编程技术，其中代码设计为适应可用资源并优先考虑节能执行路径。
- en: 2\. Select more efficient model
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 选择更高效的模型
- en: Choosing the right algorithms and data structures is crucial. Developers should
    opt for algorithms that minimize computational complexity and consequently, energy
    consumption. If the more complex model only yields 3-5% improvement but takes
    2-3x more time to train; then pick the simpler and faster model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的算法和数据结构至关重要。开发人员应选择能最小化计算复杂性的算法，从而减少能源消耗。如果更复杂的模型仅带来3-5%的提升，但训练时间却增加了2-3倍，那么选择简单且更快的模型。
- en: Model distillation is another technique for condensing large models into smaller
    versions to make them more efficient while retaining essential knowledge. It can
    be achieved by training a small model to mimic the large one or removing unnecessary
    connections from a neural network.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模型蒸馏是将大型模型压缩为小型版本的另一种技术，以提高效率，同时保留核心知识。可以通过训练一个小模型来模仿大型模型，或从神经网络中去除不必要的连接来实现。
- en: 3\. Tune model parameters
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 调整模型参数
- en: Tune hyperparameters for the model using dual-objective optimization that balance
    model performance (e.g., accuracy) and energy consumption. This dual-objective
    approach ensures that you are not sacrificing one for the other, making your models
    more efficient.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用双目标优化调整模型的超参数，以平衡模型性能（例如准确性）和能源消耗。这种双目标方法确保你不会为了一个目标而牺牲另一个目标，使你的模型更高效。
- en: Leverage techniques like [Parameter-Efficient Fine-Tuning](https://huggingface.co/blog/peft)
    (PEFT) whose goal is to attain performance similar to traditional fine-tuning
    but with a reduced number of trainable parameters. This approach involves fine-tuning
    a small subset of model parameters while keeping the majority of the pre-trained
    Large Language Models (LLMs) frozen, resulting in significant reductions in computational
    resources and energy consumption.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 利用像[参数高效微调](https://huggingface.co/blog/peft)（PEFT）这样的技术，其目标是实现与传统微调类似的性能，但所需的可训练参数数量更少。这种方法涉及对模型参数的小部分进行微调，同时保持大部分预训练的大型语言模型（LLMs）被冻结，从而显著减少计算资源和能源消耗。
- en: 4\. Compress data and use low-energy storage
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 压缩数据并使用低能耗存储
- en: Implement data compression techniques to reduce the amount of data transmitted.
    Compressed data requires less energy to transfer and occupies lower space on disk.
    During the model serving phase, using a cache can help reduce the calls made to
    the online storage layer thereby reducing
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实施数据压缩技术以减少传输的数据量。压缩数据需要更少的能源进行传输，并占用更少的磁盘空间。在模型服务阶段，使用缓存可以帮助减少对在线存储层的调用，从而减少
- en: Additionally, picking the right storage technology can result in significant
    gains. For eg. AWS Glacier is an efficient data archiving solution and can be
    a more sustainable approach than using S3 if the data does not need to be accessed
    frequently.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，选择合适的存储技术也能带来显著的收益。例如，AWS Glacier 是一个高效的数据归档解决方案，如果数据不需要频繁访问，使用 Glacier 可能比使用
    S3 更可持续。
- en: 5\. Train models on cleaner energy
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 在更清洁的能源上训练模型
- en: If you are using a cloud service for model training, you can choose the region
    to operate computations. Choose a region that employs renewable energy sources
    for this purpose, and you can reduce the emissions by up to [30 times](https://arxiv.org/pdf/2002.05651.pdf).
    AWS [blog post](https://aws.amazon.com/blogs/architecture/how-to-select-a-region-for-your-workload-based-on-sustainability-goals/)
    outlines the balance between optimizing for business and sustainability goals.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用云服务进行模型训练，可以选择计算操作的区域。选择一个使用可再生能源的区域，你可以将排放减少多达[30倍](https://arxiv.org/pdf/2002.05651.pdf)。AWS的[博客文章](https://aws.amazon.com/blogs/architecture/how-to-select-a-region-for-your-workload-based-on-sustainability-goals/)概述了优化业务和可持续性目标之间的平衡。
- en: Another option is to select the opportune time to run the model. At certain
    times of the day; the energy is cleaner and such data can be acquired through
    a paid service such as [Electricity Map](https://www.electricitymaps.com/), which
    offers access to real-time data and future predictions regarding the carbon intensity
    of electricity in different regions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是选择合适的时间运行模型。在一天中的某些时段，能源更清洁，这类数据可以通过[电力地图](https://www.electricitymaps.com/)等付费服务获取，该服务提供关于不同地区电力碳强度的实时数据和未来预测。
- en: 6\. Use specialized data centers and hardware for model training
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 使用专门的数据中心和硬件进行模型训练
- en: Choosing more efficient data centers and hardware can make a huge difference
    on carbon intensity. ML-specific data centers and hardware can be [1.4-2](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf)
    and 2-5 times more energy efficient than the general ones.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 选择更高效的数据中心和硬件可以显著降低碳强度。专门用于机器学习的数据中心和硬件比通用数据中心和硬件的能源效率高出[1.4-2](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf)倍和2-5倍。
- en: 7\. Use serverless deployments like AWS Lambda, Azure Functions
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 使用像AWS Lambda、Azure Functions这样的无服务器部署
- en: Traditional deployments require the server to be always on, which means 24x7
    energy consumption. Serverless deployments like AWS Lambda and Azure Functions
    work just fine with minimal carbon intensity.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 传统部署要求服务器始终开启，这意味着24x7的能源消耗。像AWS Lambda和Azure Functions这样的无服务器部署能以最低的碳强度正常工作。
- en: Final Notes
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终说明
- en: The AI sector is experiencing exponential growth, permeating every facet of
    business and daily existence. However, this expansion comes at a cost—a burgeoning
    carbon footprint that threatens to steer us further away from the goal of limiting
    global temperature increases to just 1°C.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域正经历指数级增长，渗透到商业和日常生活的各个方面。然而，这种扩张也带来了代价——一个不断增长的碳足迹，这可能使我们离限制全球温升至1°C的目标越来越远。
- en: This carbon footprint is not just a present concern; its repercussions may extend
    across generations, affecting those who bear no responsibility for its creation.
    Therefore, it becomes imperative to take decisive actions to mitigate AI-related
    carbon emissions and explore sustainable avenues for harnessing its potential.
    It is crucial to ensure that AI's benefits do not come at the expense of the environment
    and the well-being of future generations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这一碳足迹不仅仅是当前的担忧，其影响可能跨越几代人，影响那些与其创建无关的人。因此，采取决定性措施来减轻与人工智能相关的碳排放并探索可持续的利用途径变得尤为重要。确保人工智能的好处不会以环境和未来世代的福祉为代价是至关重要的。
- en: '**[](https://www.linkedin.com/in/ankurgupta101)**[Ankur Gupta](https://www.linkedin.com/in/ankurgupta101)****
    is an engineering leader with a decade of experience spanning sustainability,
    transportation, telecommunication and infrastructure domains; currently holds
    the position of Engineering Manager at Uber. In this role, he plays a pivotal
    role in driving the advancement of Uber''s Vehicles Platform, leading the charge
    towards a zero-emissions future through the integration of cutting-edge electric
    and connected vehicles.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/ankurgupta101)**[Ankur Gupta](https://www.linkedin.com/in/ankurgupta101)**是拥有十年经验的工程领导者，涉足可持续发展、交通运输、电信和基础设施领域；目前担任Uber的工程经理。在这个角色中，他在推动Uber车辆平台的发展方面发挥了关键作用，通过整合前沿电动和联网汽车，领导朝着零排放未来迈进。**'
- en: More On This Topic
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Using Data Science to Make Clean Energy More Equitable](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用数据科学使清洁能源更公平](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
- en: '[Data Masking: The Core of Ensuring GDPR and other Regulatory…](https://www.kdnuggets.com/2023/05/data-masking-core-ensuring-gdpr-regulatory-compliance-strategies.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据遮蔽：确保GDPR及其他监管合规性的核心](https://www.kdnuggets.com/2023/05/data-masking-core-ensuring-gdpr-regulatory-compliance-strategies.html)'
- en: '[Feature Store Summit 2023: Practical Strategies for Deploying ML…](https://www.kdnuggets.com/2023/09/hopsworks-feature-store-summit-2023-practical-strategies-deploying-ml-models-production-environments)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年特征商店峰会：部署机器学习模型的实用策略](https://www.kdnuggets.com/2023/09/hopsworks-feature-store-summit-2023-practical-strategies-deploying-ml-models-production-environments)'
- en: '[Mastering Python: 7 Strategies for Writing Clear, Organized, and…](https://www.kdnuggets.com/mastering-python-7-strategies-for-writing-clear-organized-and-efficient-code)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握Python：编写清晰、有组织和高效代码的7种策略](https://www.kdnuggets.com/mastering-python-7-strategies-for-writing-clear-organized-and-efficient-code)'
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在云中使用大型语言模型时优化性能和成本的策略](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
- en: '[The Best Strategies for Fine-Tuning Large Language Models](https://www.kdnuggets.com/the-best-strategies-for-fine-tuning-large-language-models)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化大型语言模型的最佳策略](https://www.kdnuggets.com/the-best-strategies-for-fine-tuning-large-language-models)'
