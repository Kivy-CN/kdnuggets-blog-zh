- en: 'Graduating in GANs: Going From Understanding Generative Adversarial Networks
    to Running Your Own'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2](https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2019/04/graduating-gans-understanding-generative-adversarial-networks.html?page=2#comments)'
  prefs: []
  type: TYPE_IMG
- en: Inception Score
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Invented in Salimans et al. 2016 in ‘[Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)’,
    the Inception Score is based on a heuristic that realistic samples should be able
    to be classified when passed through a pre-trained network, such as Inception
    on ImageNet. Technically, this means that the sample should have a low entropy
    softmax prediction vector.
  prefs: []
  type: TYPE_NORMAL
- en: Besides high predictability (low entropy), the Inception Score also evaluates
    a GAN based on how diverse the generated samples are (e.g. high variance or entropy
    over the distribution of generated samples). This means that there should not
    be any dominating classes.
  prefs: []
  type: TYPE_NORMAL
- en: If both these traits are satisfied, there should be a large Inception Score.
    The way that you combine the two criteria is by evaluating the Kullback-Leibler
    (KL) divergence between the conditional label distribution of samples and the
    marginal distribution from all the samples.
  prefs: []
  type: TYPE_NORMAL
- en: Fréchet Inception Distance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Introduced by [Heusel et al. 2017](https://arxiv.org/abs/1706.08500), FID estimates
    realism by measuring the distance between the generated distribution of images
    and the true distribution. FID embeds a set of generated samples into a feature
    space given by a specific layer of Inception Net. This embedding layer is viewed
    as as a continuous multivariate Gaussian, then the mean and covariance are estimated
    for both the generated data and the real data. The Fréchet distance between these
    two Gaussians (a.k.a Wasserstein-2 distance) is then used to quantify the quality
    of generated samples. A lower FID corresponds to more similar real and generated
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: An important note is that FID needs a decent sample size to give good results
    (suggested size = 50k samples ). If you use too few samples, you will end up over-estimating
    your actual FID and the estimates will have a large variance.
  prefs: []
  type: TYPE_NORMAL
- en: For a comparison of how Inception Scores and FID scores have differed across
    papers, see Neal Jean’s post [here](https://nealjean.com/ml/frechet-inception-distance/).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Want to see more?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Aji Borji’s paper, ‘[Pros and Cons of GAN Evaluation Measures](http://Pros%20and%20Cons%20of%20GAN%20Evaluation%20Measures)’
    includes an excellent table with more exhaustive coverage of GAN evaluation metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![gan-evaluation-metrics](../Images/9bed7abab406224cd9e80f00edf9ca18.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Interestingly, other researchers are taking different approaches by using
    domain-specific evaluation metrics.** For text GANs, Guy Tevet and his team proposed
    using traditional probability-based language model metrics to evaluate the distribution
    of text generated by a GAN in their paper ‘[Evaluating Text GANs as Language Models](https://arxiv.org/abs/1810.12686)’.'
  prefs: []
  type: TYPE_NORMAL
- en: In ‘[How good is my GAN?](https://arxiv.org/abs/1807.09499)’, Konstantin Shmelkov
    and his team use two measures based on image classification, GAN-train and GAN-test,
    which approximate the recall (diversity) and precision (quality of the image)
    of GANs respectively. You can see these evaluation metrics in action in the Google
    Brain research paper, ‘[Are GANS created equal](https://arxiv.org/abs/1711.10337)’,
    where they used a dataset of triangles to measure the precision and the recall
    of different GAN models.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/40d228fcf571b101b154fe25f0a2a047.png)'
  prefs: []
  type: TYPE_IMG
- en: Running your own GAN
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To illustrate GANs, we’ll be adapting [this excellent tutorial](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/)
    from Wouter Bulten that uses Keras and the MNIST dataset to generate written digits.
  prefs: []
  type: TYPE_NORMAL
- en: See the full tutorial notebook [here](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/8e6ad138242a7689b6244e6831462044.png)We’ll be tracking
    our GAN’s progress by visualizing our loss and accuracy curves but also by checking
    test outputs using [Comet.ml](http://bit.ly/2WGduCM)'
  prefs: []
  type: TYPE_IMG
- en: 'This GAN model takes in the MNIST training data and random noise as an input
    (specifically, random vectors of noise) to generate:'
  prefs: []
  type: TYPE_NORMAL
- en: images (in this case, image of handwritten digits). *Eventually, these generated
    images will resemble the data distribution of the MNIST dataset.*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the discriminator’s prediction on the generated images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Generator** and **Discriminator** models together form the adversarial
    model — for this example, the generator will perform well if the adversarial model
    serves an output classifying the generated images as real for all inputs.
  prefs: []
  type: TYPE_NORMAL
- en: See the full code [here](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6)
    and the full Comet Experiment with results [here](https://www.comet.ml/ceceshao1/mnist-gan)
  prefs: []
  type: TYPE_NORMAL
- en: Tracking your model’s progress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’re able to track the training progress for both our **Generator** and **Discriminator**
    models using [Comet.ml](http://bit.ly/2WGduCM).
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re plotting both the accuracy and loss for our discriminator and adversarial
    models — the most important metrics to track here are:'
  prefs: []
  type: TYPE_NORMAL
- en: the discriminator’s loss (see blue line on the right chart)— *dis_loss*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the adversarial model’s accuracy (see blue line on the left chart) — *acc_adv*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**See the training progression for this experiment** [**here**](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/chart)**.**'
  prefs: []
  type: TYPE_NORMAL
- en: '![comet.ml](../Images/5bec2780460c28d933adb6f423a0cdca.png)'
  prefs: []
  type: TYPE_IMG
- en: You also want to confirm that your training process is actually using GPUs,
    which you can check in [the Comet System Metrics tab](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/systemMetrics).
  prefs: []
  type: TYPE_NORMAL
- en: '![comet-ml-metrics](../Images/ae2c79999a6b58beabcd2ba493254f4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You notice that our training for-loop includes code to report images from the
    test vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Part of the reason why we want to report generated output every few steps is
    so that we can visually analyze how our generator and discriminator models are
    performing in terms of generating realistic handwritten digits and correctly classifying
    the generated digits as ‘real’ or ‘fake, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at these generated outputs!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: See the generated outputs on your own in [this Comet Experiment](https://www.comet.ml/ceceshao1/mnist-gan)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can see how the Generator models starts off with this fuzzy, grayish output
    (see 0.png below)that doesn’t really look like the handwritten digits we expect.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/bfd48dfdbc0df6119f3796a3aa78d990.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As training progresses and our models’ losses decline, the generated digits
    become clearer and clear. Check out the generated outputs at:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 500:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![/gan-generated-model-step500](../Images/a20a84c9f5cc70f38fa59c038f0416a4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 1000:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![gan-generated-model-step1000](../Images/c587d867da942c19e25c4bb42760a442.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Step 1500:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![gan-generated-model-step1500](../Images/c8926b4f60d178941d027fa1fb909afc.png)'
  prefs: []
  type: TYPE_IMG
- en: And finally at **Step 10,000 — **you can see some samples of the GAN-generated
    digits in the red outlined boxes below
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/8140571c3f508b590341ba0587a5fe66.png)'
  prefs: []
  type: TYPE_IMG
- en: Once our GAN model is done training, we can even review our reported outputs
    as a movie in [Comet’s Graphics tab](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/images)
    (just press the play button!).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/7e655afefb6f4bc95d4903258e70baf2.png)'
  prefs: []
  type: TYPE_IMG
- en: To complete the experiment, make you sure run `experiment.end()` to see some
    summary statistics around the model and GPU usage.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/76b77f6a519c53762080bd8fff0cdf72.png)'
  prefs: []
  type: TYPE_IMG
- en: Iterating with your model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We could train the model longer to see how that impacts performance, but let’s
    try iterating with a few different parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the parameters we play around with are:'
  prefs: []
  type: TYPE_NORMAL
- en: the discriminator’s optimizer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the learning rate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dropout probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: batch size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From Wouter’s [original blog post](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/),
    he mentions his own efforts with testing parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: I have tested both `SGD`, `RMSprop` and `Adam` for the optimizer of the discriminator
    but `RMSprop` performed best. `RMSprop` is used a low learning rate and I clip
    the values between -1 and 1\. A small decay in the learning rate can help with
    stabilizing
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll try increasing the discriminator’s dropout probability from 0.4 to 0.5
    and increasing both the discriminator’s learning rate (from 0.008 to 0.0009) and
    the generator’s learning rate (from 0.0004 to 0.0006). Easy to see how these changes
    can get out of hand and difficult to track…????
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a different experiment, simply run the experiment definition cell
    again and [Comet](http://www.comet.ml) will issue you a new url for your new experiment!
    It’s nice to keep track of your experiments, so you can compare the differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/4be1d8f6090453b6919dd766cacf90fb.png)[See the difference](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/e7cdcbf789674be6af8d9c7cfade1922/compare?experiment-tab=params)
    between the two experiments’ hyperparameters. Can you spot the differences in
    learning rate and dropout probability that we made?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, our adjustments did not improve the model’s performance! In
    fact, it generated some funky outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/d609c27ab35a28346a6de8f5e5a34525.png)'
  prefs: []
  type: TYPE_IMG
- en: That’s it for this tutorial! If you enjoyed this post, feel free to share with
    a friend who might find it useful ????
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Cecilia Shao](https://www.linkedin.com/in/ceceliashao/)** is heading
    Product Growth at [comet.ml](https://www.comet.ml/).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/graduating-in-gans-going-from-understanding-generative-adversarial-networks-to-running-your-own-39804c283399).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[MNIST Generative Adversarial Model in Keras](/2016/07/mnist-generative-adversarial-model-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GANs in TensorFlow from the Command Line: Creating Your First GitHub Project](/2018/05/zimbres-first-github-project-gans.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Basic Keras Neural Network Sequential Model](/2018/06/basic-keras-neural-network-sequential-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to Stay on Top of What''s Going on in the AI World](https://www.kdnuggets.com/2022/03/stay-top-going-ai-world.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sentiment Analysis in Python: Going Beyond Bag of Words](https://www.kdnuggets.com/sentiment-analysis-in-python-going-beyond-bag-of-words)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LangChain 101: Build Your Own GPT-Powered Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build Your Own PandasAI with LlamaIndex](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Make Your Own GPTs with ChatGPT''s GPTs!](https://www.kdnuggets.com/make-your-own-gpts-with-chatgpts-gpts)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is Adversarial Machine Learning?](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
