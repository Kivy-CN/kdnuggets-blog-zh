- en: Building Your First ETL Pipeline with Bash
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Bash构建您的第一个ETL管道
- en: 原文：[https://www.kdnuggets.com/building-your-first-etl-pipeline-with-bash](https://www.kdnuggets.com/building-your-first-etl-pipeline-with-bash)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/building-your-first-etl-pipeline-with-bash](https://www.kdnuggets.com/building-your-first-etl-pipeline-with-bash)
- en: '![Building Your First ETL Pipeline with Bash](../Images/25385ed4de8b6638a1ca5f30f762b1f7.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用Bash构建第一个ETL管道](../Images/25385ed4de8b6638a1ca5f30f762b1f7.png)'
- en: Image by Author | Midjourney & Canva
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供 | Midjourney & Canva
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ETL, or Extract, Transform, Load, is a necessary data engineering process, which
    involves extracting data from various sources, converting it into a workable form,
    and moving it to some destination, such as a database. ETL pipelines automate
    this process, making sure that data is processed in a consistent and efficient
    manner, which provides a framework for tasks like data analysis, reporting, and
    machine learning, and ensures data is clean, reliable, and ready to use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ETL，即提取、转换、加载，是一个必要的数据工程过程，涉及从各种来源提取数据，将其转换为可用的格式，并将其移至某个目的地，如数据库。ETL管道自动化了这一过程，确保数据以一致和高效的方式处理，为数据分析、报告和机器学习等任务提供框架，并确保数据干净、可靠且可用。
- en: Bash, short for short for Bourne-Again Shell — aka the Unix shell — is a powerful
    tool for building ETL pipelines, due to its simplicity, flexibility, and extremely
    wide applicability, and thus it is an excellent option for novices and seasoned
    pros alike. Bash scripts can do things like automate tasks, move files around,
    and talk to other tools on the command line, meaning that it is a good choice
    for ETL work. Moreover, bash is ubiquitous on Unix-like systems (Linux, BSD, macOS,
    etc.), so it is ready to use on most such systems with no extra work on your part.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Bash，缩写自Bourne-Again Shell — 又名Unix Shell — 是一个强大的工具，用于构建ETL管道，因其简洁性、灵活性和极广泛的适用性，因此是初学者和资深专家的绝佳选择。Bash脚本可以自动化任务、移动文件和与命令行上的其他工具进行交互，这使它成为ETL工作的良好选择。此外，bash在类Unix系统（如Linux、BSD、macOS等）中无处不在，因此在大多数这类系统上无需额外操作即可使用。
- en: This article is intended for beginner and practitioner data scientists and data
    engineers who are looking to build their first ETL pipeline. It assumes a basic
    understanding of the command line and aims to provide a practical guide to creating
    an ETL pipeline using bash. The goal of the article is to guide readers through
    the process of building a basic ETL pipeline using bash. By the end of the article,
    readers will have a working understanding of implementing an ETL pipeline that
    extracts data from a source, transforms it, and loads it into a destination database.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文针对的是希望构建第一个ETL管道的初学者和实践数据科学家、数据工程师。假设读者具备基本的命令行理解，并旨在提供一个使用bash创建ETL管道的实用指南。文章的最终目标是引导读者完成构建基础ETL管道的过程，通过这篇文章，读者将能够了解如何实现一个从源提取数据、转换数据并将其加载到目标数据库的ETL管道。
- en: Setting Up Your Environment
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置您的环境
- en: 'Before we begin, ensure you have the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保您具备以下内容：
- en: A Unix-based system (Linux or macOS)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基于Unix的系统（Linux或macOS）
- en: Bash shell (usually pre-installed on Unix systems)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bash shell（通常在Unix系统上预装）
- en: Basic understanding of command-line operations
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本的命令行操作理解
- en: 'For our ETL pipeline, we will need these specific command line tools:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的ETL管道，我们将需要这些特定的命令行工具：
- en: '`curl`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`curl`'
- en: '`jq`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jq`'
- en: '`awk`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`awk`'
- en: '`sed`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sed`'
- en: '`sqlite3`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sqlite3`'
- en: 'You can install them using your system''s package manager. On a Debian-based
    system, you can use `apt-get`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用系统的包管理器安装它们。在基于Debian的系统上，您可以使用`apt-get`：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'On macOS, you can use `brew`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS上，您可以使用`brew`：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s set up a dedicated directory for our ETL project. Open your terminal
    and run:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为 ETL 项目设置一个专用目录。打开终端并运行：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This creates a new directory called `etl_project` and navigates into it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建一个名为 `etl_project` 的新目录并进入该目录。
- en: Extracting Data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取数据
- en: Data can come from various sources such as APIs, CSV files, or databases. For
    this tutorial, we'll demonstrate extracting data from a public API and a CSV file.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以来自各种来源，如 API、CSV 文件或数据库。在本教程中，我们将演示如何从公共 API 和 CSV 文件中提取数据。
- en: Let's use `curl` to fetch data from a public API. For example, we'll extract
    data from a mock API that provides sample data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `curl` 从公共 API 中获取数据。例如，我们将从一个提供样本数据的模拟 API 中提取数据。
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This command will download the data and save it as `data.json`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将下载数据并保存为 `data.json`。
- en: We can also use `curl` to download a CSV file from a remote server.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用 `curl` 从远程服务器下载一个 CSV 文件。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will save the CSV file as `data.csv` in our working directory.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把 CSV 文件保存为我们工作目录中的 `data.csv`。
- en: Transforming Data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据转换
- en: Data transformation is necessary to convert raw data into a format suitable
    for analysis or storage. This may involve parsing JSON, filtering CSV files, or
    cleaning text data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换是将原始数据转换为适合分析或存储的格式的必要步骤。这可能涉及解析 JSON、过滤 CSV 文件或清理文本数据。
- en: '`jq` is a powerful tool for working with JSON data. Let''s use it to extract
    specific fields from our JSON file.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`jq` 是一个处理 JSON 数据的强大工具。我们将使用它从 JSON 文件中提取特定字段。'
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This command extracts the `id`, `name`, and `value` fields from each entry in
    the JSON data and saves the result in `transformed_data.json`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令从 JSON 数据中的每个条目中提取 `id`、`name` 和 `value` 字段，并将结果保存到 `transformed_data.json`
    中。
- en: '`awk` is a versatile tool for processing CSV files. We''ll use it to extract
    specific columns from our CSV file.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk` 是一个用于处理 CSV 文件的多功能工具。我们将使用它从我们的 CSV 文件中提取特定的列。'
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This command extracts the first and third columns from `data.csv` and saves
    them in `transformed_data.csv`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令从 `data.csv` 中提取第一列和第三列，并将它们保存到 `transformed_data.csv`。
- en: '`sed` is a stream editor for filtering and transforming text. We can use it
    to perform text replacements and clean up our data.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`sed` 是一个用于过滤和转换文本的流编辑器。我们可以用它来执行文本替换和清理数据。'
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This command replaces occurrences of `old_text` with `new_text` in `transformed_data.csv`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将 `transformed_data.csv` 中的 `old_text` 替换为 `new_text`。
- en: Loading Data
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: Common destinations for loading data include databases and files. For this tutorial,
    we'll use SQLite, a commonly used lightweight database.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的数据加载目的地包括数据库和文件。对于本教程，我们将使用 SQLite，一种常用的轻量级数据库。
- en: First, let's create a new SQLite database and a table to hold our data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个新的 SQLite 数据库和一个表来存储我们的数据。
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This command creates a database file named `etl_database.db` and a table named
    `data` with three columns.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令创建一个名为 `etl_database.db` 的数据库文件，并创建一个名为 `data` 的表，该表有三列。
- en: Next, we'll insert our transformed data into the SQLite database.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把转换后的数据插入到 SQLite 数据库中。
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This block of commands sets the mode to CSV and imports `transformed_data.csv`
    into the `data` table.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这段命令将模式设置为 CSV 并将 `transformed_data.csv` 导入到 `data` 表中。
- en: We can verify that the data has been inserted correctly by querying the database.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查询数据库来验证数据是否正确插入。
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This command retrieves all rows from the `data` table and displays them.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令检索 `data` 表中的所有行并显示它们。
- en: Final Thoughts
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终思考
- en: 'We have covered the following steps while building our ETL pipeline with bash,
    including:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在使用 bash 构建 ETL 管道时涵盖了以下步骤，包括：
- en: Environment setup and tool installation
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 环境设置和工具安装
- en: Data extraction from a public API and CSV file with `curl`
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `curl` 从公共 API 和 CSV 文件中提取数据
- en: Data transformation using `jq`, `awk`, and `sed`
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `jq`、`awk` 和 `sed` 进行数据转换
- en: Data loading in an SQLite database with `sqlite3`
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sqlite3` 在 SQLite 数据库中加载数据
- en: Bash is a good choice for ETL due to its simplicity, flexibility, automation
    capabilities, and interoperability with other CLI tools.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Bash 是 ETL 的一个不错选择，因为它简单、灵活、自动化能力强，并且与其他 CLI 工具兼容。
- en: For further investigation, think about incorporating error handling, scheduling
    the pipeline via cron, or learning more advanced bash concepts. You may also wish
    to investigate alternative transformation apps and methods to increase your pipeline
    skillset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步调查，可以考虑加入错误处理、通过 cron 调度管道，或学习更高级的 bash 概念。你也可以探索其他转换应用和方法，以提升你的管道技能。
- en: Try out your own ETL projects, putting what you have learned to the test, in
    more elaborate scenarios. With some luck, the basic concepts here will be a good
    jumping-off point to more complex data engineering tasks.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试自己的 ETL 项目，将所学应用于更复杂的场景。幸运的话，这里的一些基本概念将成为你进行更复杂数据工程任务的良好起点。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为 [KDnuggets](https://www.kdnuggets.com/)
    和 [Statology](https://www.statology.org/) 的主编，以及 [Machine Learning Mastery](https://machinelearningmastery.com/)
    的特邀编辑，Matthew 旨在使复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、语言模型、机器学习算法以及探索新兴的人工智能技术。他致力于在数据科学社区普及知识。Matthew
    从 6 岁起就开始编程。'
- en: More On This Topic
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[ETL vs ELT: Which One is Right for Your Data Pipeline?](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL 与 ELT：哪个更适合你的数据管道？](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
- en: '[Building a Scalable ETL with SQL + Python](https://www.kdnuggets.com/2022/04/building-scalable-etl-sql-python.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建可扩展的 ETL 系统与 SQL + Python](https://www.kdnuggets.com/2022/04/building-scalable-etl-sql-python.html)'
- en: '[Building a Tractable, Feature Engineering Pipeline for Multivariate…](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为多变量时间序列构建可处理的特征工程管道](https://www.kdnuggets.com/2022/03/building-tractable-feature-engineering-pipeline-multivariate-time-series.html)'
- en: '[Building a Formula 1 Streaming Data Pipeline With Kafka and Risingwave](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 Kafka 和 Risingwave 构建 Formula 1 实时数据管道](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)'
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[Step-by-Step Tutorial to Building Your First Machine Learning Model](https://www.kdnuggets.com/step-by-step-tutorial-to-building-your-first-machine-learning-model)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逐步教程：构建你的第一个机器学习模型](https://www.kdnuggets.com/step-by-step-tutorial-to-building-your-first-machine-learning-model)'
