- en: Getting Started with spaCy for NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Getting Started with spaCy for NLP](../Images/229bca305b47c63570cb9b57e3f926b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, NLP is one of the most emerging trends of AI as its applications are
    widespread across several industries such as Healthcare, Retail, and Banking to
    name a few. As there is an increasing need to develop fast and scalable solutions,
    spaCy is one of the go-to NLP libraries for developers. NLP products are developed
    to make sense of the existing text data. It mainly revolves around solving questions
    such as ‘What is the context of data?’, ‘Does it represent any bias?’, ‘Is there
    some similarity among words?’ etc. to build valuable solutions?
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, spaCy is a library that helps to deal with such questions and it
    provides a bunch of modules that are easy to plug and play. It is an open-source
    and production-friendly library that makes development and deployment smooth and
    efficient. Moreover, spaCy was not built with a research-oriented approach hence
    it provides a limited set of functionalities for the users to choose from instead
    of multiple options to develop quickly.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we will explore how to get started with spaCy right from the installation
    to explore the various functionalities it provides.
  prefs: []
  type: TYPE_NORMAL
- en: Installation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To install spaCy enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: spaCy generally requires trained pipelines to be loaded in order to access most
    of its functionalities. These pipelines contained pretrained models which perform
    prediction for some of the commonly used tasks. The pipelines are available in
    multiple languages and in multiple sizes. Here, we will install the small and
    medium size pipelines for English.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Voila! You are now all set to start using spaCy.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we will load the smaller pipeline version of English.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The pipeline is now loaded into the nlp object.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will be exploring the various functionalities of spaCy using an example.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tokenization is a process of splitting the text into smaller units called tokens.
    For example, in a sentence tokens would be words whereas in a paragraph tokens
    could be sentences. This step helps to understand the content by making it easy
    to read and process.
  prefs: []
  type: TYPE_NORMAL
- en: We first define a string.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now we call the ‘nlp’ object on ‘text’ and store it in a ‘doc’ object. The object
    ‘doc’ would be containing all the information about the text - the words, the
    whitespaces etc.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '‘doc’ can be used as an iterator to parse through the text. It contains a ‘.text’
    method which can give the text of every token like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In addition to splitting the words by white spaces, the tokenization algorithm
    also performs double-checks on the split text.
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting Started with spaCy for NLP](../Images/101b1489919b38d00512b294cff9b53b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [spaCy documentation](https://spacy.io/usage/spacy-101)'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the above image, after splitting the words by white spaces, the
    algorithm checks for exceptions. The word ‘Let’s’ is not in its root form hence
    it is again split into ‘Let’ and ‘’s’. The punctuation marks are also split. Moreover,
    the rule makes sure not to split words like ‘N.Y.’ and considers them like a single
    token.
  prefs: []
  type: TYPE_NORMAL
- en: Stop Words
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the important preprocessing steps in NLP is to remove stop words from
    text. Stop words are basically connector words such as ‘to’, ‘with’, ‘is’, etc.
    which provide minimal context. spaCy allows easy identification of stop words
    with an attribute of the ‘doc’ object called ‘is_stop’.
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘is_stop’ method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Lemmatization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lemmatization is another important preprocessing step for NLP pipelines. It
    helps to remove different versions of a single word to reduce redundancy of same-meaning
    words as it converts the words to their root lemmas. For example, it will convert
    ‘is’ -> ‘be’, ‘eating’ -> ‘eat’, and ‘N.Y.’ -> ‘n.y.’. With spaCy, the words can
    be easily converted to their lemmas using a ‘.lemma_’ attribute of the ‘doc’ object.
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.lemma_’ method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Part-of-Speech (POS) Tagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automated POS tagging enables us to get an idea of the sentence structure by
    knowing what category of words dominate the content and vice versa. This information
    forms an essential part in understanding the context. spaCy allows parsing the
    content and tagging the individual tokens with their respective parts of speech
    through the ‘.pos_’ attribute of the ‘doc’ object.
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.pos_’ method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Dependency Parsing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every sentence has an inherent structure in which the words have an interdependent
    relationship with each other. Dependency parsing can be thought of as a directed
    graph wherein the nodes are words and the edges are relationships between the
    words. It extracts the information on what one word means to another grammatically;
    whether it is a subject, an auxiliary verb, or a root, and so on. spaCy has a
    method ‘.dep_’ of the ‘doc’ object which describes the syntactic dependencies
    of the tokens.
  prefs: []
  type: TYPE_NORMAL
- en: We iterate over all the tokens and apply the ‘.dep_’ method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Named Entity Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the real-world objects have a name assigned to them for recognition and
    likewise, they are grouped into a category. For instance, the terms ‘India’, ‘U.K.’,
    and ‘U.S.’ fall under the category of countries whereas ‘Microsoft’, ‘Google’,
    and ‘Facebook’ belong to the category of organizations. spaCy already has trained
    models in the pipeline that can determine and predict the categories of such named
    entities.
  prefs: []
  type: TYPE_NORMAL
- en: We will access the named entities by using the ‘.ents’ method over the ‘doc’
    object. We will display the text, start character, end character, and label of
    the entity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Word Vectors and Similarity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often in NLP, we wish to analyze the similarity of words, sentences, or documents
    which can be used for applications such as recommender systems or plagiarism detection
    tools to name a few. The similarity score is calculated by finding the distance
    between the word embeddings, i.e., the vector representation of words. spaCy provides
    this functionality with medium and large pipelines. The larger pipeline is more
    accurate as it contains models trained on more and diverse data. However, we will
    use the medium pipeline here just for the sake of understanding.
  prefs: []
  type: TYPE_NORMAL
- en: We first define the sentences to be compared for similarity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Rule-based Matching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rule-based matching can be considered similar to regex wherein we can mention
    the specific pattern to be found in the text. spaCy’s matcher module not only
    does the mentioned task but also provides access to the document information such
    as tokens, POS tags, lemmas, dependency structures, etc. which makes extraction
    of words possible on multiple additional conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will first create a matcher object to contain all the vocabulary. Next,
    we will define the pattern of text to be looked for and add that as a rule to
    the matcher module. Finally, we will call the matcher module over the input sentence.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '**output: **'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In this blog, we looked at how to install and get started with spaCy. We also
    explored the various basic functionalities it provides such as tokenization, lemmatization,
    dependency parsing, parts-of-speech tagging, named entity recognition and so on.
    spaCy is a really convenient library when it comes to developing NLP pipelines
    for production purposes. Its detailed documentation, simplicity of use, and variety
    of functions make it one of the widely used libraries for NLP.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** is a passionate
    AI developer and writer pursuing Master’s in Machine Learning from Université
    de Montréal. Yesha is intrigued to explore responsible AI techniques to solve
    challenges that benefit society and share her learnings with the community.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Natural Language Processing with spaCy](https://www.kdnuggets.com/2023/01/natural-language-processing-spacy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started Cleaning Data](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyCaret](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Scikit-learn for Classification in Machine Learning](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
