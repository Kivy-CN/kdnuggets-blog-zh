- en: An Intuitive Explanation of Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的直观解释
- en: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/2)
- en: 'Another good way to understand the Convolution operation is by looking at the
    animation in **Figure 6** below:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种理解卷积操作的好方法是查看下面的**图 6**中的动画：
- en: '![giphy.gif](../Images/03afaa451f7141fd7a9b9a4ecb9d13c6.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![giphy.gif](../Images/03afaa451f7141fd7a9b9a4ecb9d13c6.png)'
- en: 'Figure 6: The Convolution Operation. Source [9]'
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6：卷积操作。来源 [9]
- en: A filter (with red outline) slides over the input image (convolution operation)
    to produce a feature map. The convolution of another filter (with the green outline),
    over the same image gives a different feature map as shown. It is important to
    note that the Convolution operation captures the local dependancies in the original
    image. Also notice how these two different filters generate different feature maps
    from the same original image. Remember that the image and the two filters above
    are just numeric matrices as we have discussed above.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一个带有红色轮廓的滤波器在输入图像上滑动（卷积操作），以生成特征图。另一个带有绿色轮廓的滤波器在相同图像上的卷积生成了不同的特征图，如所示。需要注意的是，卷积操作捕捉了原始图像中的局部依赖关系。还要注意这两个不同的滤波器如何从相同的原始图像生成不同的特征图。记住，上述图像和两个滤波器只是我们之前讨论过的数字矩阵。
- en: In practice, a CNN *learns* the values of these filters on its own during the
    training process (although we still need to specify parameters such as number
    of filters, filter size, architecture of the network etc. before the training
    process). The more number of filters we have, the more image features get extracted
    and the better our network becomes at recognizing patterns in unseen images.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，CNN 在训练过程中*学习*这些滤波器的值（虽然我们仍然需要在训练过程之前指定一些参数，如滤波器的数量、滤波器的大小、网络的结构等）。我们拥有的滤波器数量越多，提取的图像特征就越多，我们的网络在识别未见图像中的模式时也会更好。
- en: 'The size of the Feature Map (Convolved Feature) is controlled by three parameters
    [4] that we need to decide before the convolution step is performed:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 特征图（卷积特征）的大小由我们需要在卷积步骤之前决定的三个参数 [4] 控制：
- en: '**Depth:** Depth corresponds to the number of filters we use for the convolution
    operation. In the network shown in **Figure 7**, we are performing convolution
    of the original boat image using three distinct filters, thus producing three different
    feature maps as shown. You can think of these three feature maps as stacked 2d
    matrices, so, the ‘depth’ of the feature map would be three.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度：** 深度对应于我们用于卷积操作的滤波器数量。在**图 7**中所示的网络中，我们使用三个不同的滤波器对原始船只图像进行卷积，从而生成了三个不同的特征图。你可以将这三个特征图视为堆叠的二维矩阵，因此，特征图的“深度”将是三。'
- en: '![Screen Shot 2016-08-10 at 3.42.35 AM](../Images/04434b802022918265ef4d1b9a70996a.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-10 at 3.42.35 AM](../Images/04434b802022918265ef4d1b9a70996a.png)'
- en: Figure 7
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7
- en: '**Stride:** Stride isthe number of pixels by which we slide our filter matrix
    over the input matrix. When the stride is 1 then we move the filters one pixel
    at a time. When the stride is 2, then the filters jump 2 pixels at a time as we
    slide them around. Having a larger stride will produce smaller feature maps.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步幅：** 步幅是我们在输入矩阵上滑动滤波器矩阵的像素数量。当步幅为 1 时，我们一次移动一个像素。当步幅为 2 时，滤波器在滑动时每次跳过 2
    个像素。较大的步幅会生成较小的特征图。'
- en: '**Zero-padding:** Sometimes, it is convenient to pad the input matrix with
    zeros around the border, so that we can apply the filter to bordering elements
    of our input image matrix. A nice feature of zero padding is that it allows us
    to control the size of the feature maps. Adding zero-padding is also called *wide
    convolution***,** and not using zero-padding would be a *narrow convolution*. This
    has been explained clearly in [14].'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零填充：** 有时，将输入矩阵的边界填充零是方便的，以便我们可以将滤波器应用于输入图像矩阵的边界元素。零填充的一个好处是它允许我们控制特征图的大小。添加零填充也被称为*宽卷积*，而不使用零填充则是*窄卷积*。这在
    [14] 中已经清楚地解释了。'
- en: Introducing Non Linearity (ReLU)
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 引入非线性（ReLU）
- en: 'An additional operation called ReLU has been used after every Convolution operation
    in **Figure 3** above. ReLU stands for Rectified Linear Unit and is a non-linear
    operation. Its output is given by:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的**图 3**中，每次卷积操作后都使用了一个额外的操作叫做 ReLU。ReLU 代表修正线性单元，是一种非线性操作。它的输出由以下公式给出：
- en: '![Screen Shot 2016-08-10 at 2.23.48 AM.png](../Images/f884f902a6eaab07c2e0655b59f3c524.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-10 at 2.23.48 AM.png](../Images/f884f902a6eaab07c2e0655b59f3c524.png)'
- en: 'Figure 8: the ReLU operation'
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 8: ReLU 操作'
- en: ReLU is an element wise operation (applied per pixel) and replaces all negative
    pixel values in the feature map by zero. The purpose of ReLU is to introduce non-linearity
    in our ConvNet, since most of the real-world data we would want our ConvNet to
    learn would be non-linear (Convolution is a linear operation – element wise matrix
    multiplication and addition, so we account for non-linearity by introducing a
    non-linear function like ReLU).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU 是逐元素操作（逐像素应用），将特征图中的所有负像素值替换为零。ReLU 的目的是在我们的卷积网络中引入非线性，因为我们希望卷积网络学习的大多数现实世界数据都是非线性的（卷积是线性操作——逐元素的矩阵乘法和加法，因此我们通过引入像
    ReLU 这样的非线性函数来考虑非线性）。
- en: The ReLU operation can be understood clearly from **Figure 9** below. It shows
    the ReLU operation applied to one of the feature maps obtained in **Figure 6** above.
    The output feature map here is also referred to as the ‘Rectified’ feature map.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU 操作可以从下面的**图 9**中清楚地理解。它展示了对**图 6**中获得的一个特征图应用 ReLU 操作。这里的输出特征图也称为“校正”特征图。
- en: '![Screen Shot 2016-08-07 at 6.18.19 PM.png](../Images/b7752825316c6b5e7742808da7e2888b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 6.18.19 PM.png](../Images/b7752825316c6b5e7742808da7e2888b.png)'
- en: 'Figure 9: ReLU operation. Source [10]'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 9: ReLU 操作。来源 [10]'
- en: Other non linear functions such as **tanh** or **sigmoid** can also be used
    instead of ReLU, but ReLU has been found to perform better in most situations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 其他非线性函数，如**tanh**或**sigmoid**，也可以用来代替 ReLU，但在大多数情况下，ReLU 被发现表现更好。
- en: The Pooling Step
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 池化步骤
- en: 'Spatial Pooling (also called subsampling or downsampling) reduces the dimensionality
    of each feature map but retains the most important information. Spatial Pooling
    can be of different types: Max, Average, Sum etc.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 空间池化（也称为下采样或降采样）减少了每个特征图的维度，但保留了最重要的信息。空间池化可以有不同的类型：最大池化、平均池化、求和池化等。
- en: In case of Max Pooling, we define a spatial neighborhood (for example, a 2×2
    window) and take the largest element from the rectified feature map within that
    window. Instead of taking the largest element we could also take the average (Average
    Pooling) or sum of all elements in that window. In practice, Max Pooling has been
    shown to work better.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在最大池化的情况下，我们定义一个空间邻域（例如，一个 2×2 的窗口），并从该窗口中的校正特征图中取出最大的元素。除了取最大元素，我们也可以取该窗口中所有元素的平均值（平均池化）或总和。在实践中，最大池化显示出更好的效果。
- en: '**Figure 10** shows an example of Max Pooling operation on a Rectified Feature
    map (obtained after convolution + ReLU operation) by using a 2×2 window.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 10** 显示了使用 2×2 窗口在一个校正特征图（卷积 + ReLU 操作后得到）上进行最大池化操作的示例。'
- en: '![Screen Shot 2016-08-10 at 3.38.39 AM.png](../Images/4aecf0fe58685bdfc7e82e425977ebb3.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-10 at 3.38.39 AM.png](../Images/4aecf0fe58685bdfc7e82e425977ebb3.png)'
- en: 'Figure 10: Max Pooling. Source [4]'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 10: 最大池化。来源 [4]'
- en: We slide our 2 x 2 window by 2 cells (also called ‘stride’) and take the maximum
    value in each region. As shown in **Figure 10**, this reduces the dimensionality
    of our feature map.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 2 x 2 窗口滑动 2 个单元（也称为“步幅”），并在每个区域中取最大值。如**图 10**所示，这减少了我们特征图的维度。
- en: In the network shown in **Figure 11,** pooling operation is applied separately
    to each feature map (notice that, due to this, we get three output maps from three
    input maps).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在**图 11**中所示的网络中，池化操作分别应用于每个特征图（请注意，由于此原因，我们从三个输入图获得了三个输出图）。
- en: '![Screen Shot 2016-08-07 at 6.19.37 PM.png](../Images/0229193e9d8a3fc3c5c0a01f9c57ec3e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 6.19.37 PM.png](../Images/0229193e9d8a3fc3c5c0a01f9c57ec3e.png)'
- en: 'Figure 11: Pooling applied to Rectified Feature Maps'
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 11: 应用于校正特征图的池化'
- en: '**Figure 12** shows the effect of Pooling on the Rectified Feature Map we received
    after the ReLU operation in **Figure 9** above.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 12** 显示了池化对我们在**图 9**中获得的校正特征图的影响。'
- en: '![Screen Shot 2016-08-07 at 6.11.53 PM.png](../Images/dcb2453efd17a687f7790c3527cc1475.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 6.11.53 PM.png](../Images/dcb2453efd17a687f7790c3527cc1475.png)'
- en: 'Figure 12: Pooling. Source [10]'
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 12: 池化。来源 [10]'
- en: The function of Pooling is to progressively reduce the spatial size of the input
    representation [4]. In particular, pooling
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 池化的功能是逐步减少输入表示的空间大小[4]。特别地，池化
- en: makes the input representations (feature dimension) smaller and more manageable
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使输入表示（特征维度）变得更小、更易于管理
- en: reduces the number of parameters and computations in the network, therefore,
    controlling [overfitting](https://en.wikipedia.org/wiki/Overfitting) [4]
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少网络中的参数和计算数量，从而控制[过拟合](https://en.wikipedia.org/wiki/Overfitting)[4]
- en: makes the network invariant to small transformations, distortions and translations
    in the input image (a small distortion in input will not change the output of Pooling
    – since we take the maximum / average value in a local neighborhood).
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使网络对输入图像中的小变换、失真和转换具有不变性（输入中的小失真不会改变池化的输出——因为我们在局部邻域中取最大/平均值）。
- en: helps us arrive at an almost scale invariant representation of our image (the
    exact term is “equivariant”). This is very powerful since we can detect objects
    in an image no matter where they are located (read [18] and [19] for details).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助我们获得几乎尺度不变的图像表示（确切术语是“等变”）。这非常强大，因为我们可以检测图像中的物体，无论它们的位置在哪里（详细信息请阅读[18]和[19]）。
- en: Story so far
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 到目前为止的故事
- en: '![Screen Shot 2016-08-08 at 2.26.09 AM.png](../Images/7f6e70b60b1771cafb71566ed7d80ab1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-08 at 2.26.09 AM.png](../Images/7f6e70b60b1771cafb71566ed7d80ab1.png)'
- en: Figure 13
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图13
- en: So far we have seen how Convolution, ReLU and Pooling work. It is important
    to understand that these layers are the basic building blocks of any CNN. As shown
    in **Figure 13**, we have two sets of Convolution, ReLU & Pooling layers – the
    2nd Convolution layer performs convolution on the output of the first Pooling
    Layer using six filters to produce a total of six feature maps. ReLU is then applied
    individually on all of these six feature maps. We then perform Max Pooling operation
    separately on each of the six rectified feature maps.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到卷积、ReLU和池化如何工作。重要的是要理解这些层是任何CNN的基本构建块。如**图13**所示，我们有两组卷积、ReLU和池化层——第二个卷积层对第一个池化层的输出进行卷积，使用六个滤波器生成六个特征图。然后对这六个特征图逐个应用ReLU。接着，我们分别对每个经过修正的六个特征图执行最大池化操作。
- en: Together these layers extract the useful features from the images, introduce
    non-linearity in our network and reduce feature dimension while aiming to make
    the features somewhat equivariant to scale and translation [18].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些层共同提取图像中的有用特征，引入网络中的非线性，并在旨在使特征对尺度和转换具有一定的等变性[18]的同时减少特征维度。
- en: The output of the 2nd Pooling Layer acts as an input to the Fully Connected
    Layer, which we will discuss in the next section.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个池化层的输出作为全连接层的输入，我们将在下一节讨论。
- en: Fully Connected Layer
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 全连接层
- en: The Fully Connected layer is a traditional Multi Layer Perceptron that uses
    a softmax activation function in the output layer (other classifiers like SVM
    can also be used, but will stick to softmax in this post). The term “Fully Connected”
    implies that every neuron in the previous layer is connected to every neuron on
    the next layer. I recommend [reading this post](http://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/) if
    you are unfamiliar with Multi Layer Perceptrons.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层是一个传统的多层感知器，它在输出层使用了softmax激活函数（其他分类器如SVM也可以使用，但在此帖中将坚持使用softmax）。术语“全连接”意味着前一层的每个神经元都连接到下一层的每个神经元。如果你对多层感知器不熟悉，建议[阅读这篇文章](http://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)。
- en: The output from the convolutional and pooling layers represent high-level features
    of the input image. The purpose of the Fully Connected layer is to use these features
    for classifying the input image into various classes based on the training dataset.
    For example, the image classification task we set out to perform has four possible
    outputs as shown in **Figure 14** below (note that Figure 14 does not show connections
    between the nodes in the fully connected layer)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积和池化层的输出代表了输入图像的高级特征。全连接层的目的是利用这些特征将输入图像分类到基于训练数据集的各种类别中。例如，我们设定的图像分类任务有四个可能的输出，如下**图14**所示（请注意图14未显示全连接层中节点之间的连接）
- en: '![Screen Shot 2016-08-06 at 12.34.02 AM.png](../Images/493fc738b0366d0bca616f59fc9f3766.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-06 at 12.34.02 AM.png](../Images/493fc738b0366d0bca616f59fc9f3766.png)'
- en: 'Figure 14: Fully Connected Layer -each node is connected to every other node
    in the adjacent layer'
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14：全连接层 - 每个节点与相邻层中的所有其他节点相连接
- en: Apart from classification, adding a fully-connected layer is also a (usually)
    cheap way of learning non-linear combinations of these features. Most of the features
    from convolutional and pooling layers may be good for the classification task,
    but combinations of those features might be even better [11].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分类之外，添加一个完全连接层也是一种（通常）廉价的方法来学习这些特征的非线性组合。卷积层和池化层中的大多数特征可能适合分类任务，但这些特征的组合可能更好[11]。
- en: The sum of output probabilities from the Fully Connected Layer is 1\. This is
    ensured by using the [Softmax](http://cs231n.github.io/linear-classify/#softmax)
    as the activation function in the output layer of the Fully Connected Layer. The
    Softmax function takes a vector of arbitrary real-valued scores and squashes it
    to a vector of values between zero and one that sum to one.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 完全连接层的输出概率之和为1。这是通过在完全连接层的输出层使用[Softmax](http://cs231n.github.io/linear-classify/#softmax)作为激活函数来确保的。Softmax
    函数将一个任意实值分数向量压缩成一个介于零和一之间的值向量，其总和为一。
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 需求'
- en: '* * *'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关话题
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络（CNNs）图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络综合指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：直观的方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
