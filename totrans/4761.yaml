- en: Introduction to Deep Learning with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html](https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/10/introduction-deep-learning-keras.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: '![Image](../Images/c89d61f18b1ba7aa60ff9422437fb38d.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: In this article, we’ll build a simple neural network using [Keras](http://keras.io/).
    We’ll assume you have prior knowledge of machine learning packages such as [scikit-learn](http://scikit-learn.org/stable/)and
    other scientific packages such as [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '**Training an Artificial Neural Network**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training an artificial neural network involves the following steps:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Weights are randomly initialized to numbers that are near zero but not zero.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the observations of your dataset to the input layer.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Forward propagation (from left to right): neurons are activated and the predicted
    values are obtained.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare predicted results to actual values and measure the error.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Backward propagation (from right to left): weights are adjusted.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 1–5
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One epoch is achieved when the whole training set has gone through the neural
    network.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Business Problem**'
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let’s proceed to solve a real business problem. An insurance company has
    approached you with a dataset of previous claims of their clients. The insurance
    company wants you to develop a model to help them predict which claims look fraudulent.
    By doing so you hope to save the company millions of dollars annually. This is
    a classification problem. These are the columns in our dataset.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/67889150c551e63f6b6a280479b46b8a.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/63f722c7a0d93149d31786aa4c177a2b.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/b0148e763fd945baa2c9f0f7cbb1bc81.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: '****Data Preprocessing****'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As in many business problems, the data provided will not be processed for us.
    We therefore have to prepare it in a way that our algorithm will accept it. We
    see from the dataset that we have some categorical columns. We need to convert
    these to zeros and ones so that our deep learning model will be able to understand
    them. Another thing to note is that we have to feed our dataset to the model as
    numpy arrays. Below we import the necessary packages and then load in our dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We then to convert the categorical columns to dummy variables.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: In this case we use drop_first=True to avoid the dummy variable trap. For example,
    if you have a, b, c, d as categories then you can drop d as a dummy variable.
    This is because if something does not fall into either a, b, or c then it’s definitely
    in d. This is referred to as multicollinearity.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: We use [sklearn’s](http://scikit-learn.org/) train_test_split to split the data
    into a training set and a test set.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next we make sure to drop the column we’re predicting to prevent it from leaking
    into the training set and the test set. We must avoid using the same dataset to
    train and test the model. We set **.values** at the end of the dataset in order
    to get the numpy arrays. This is the way our deep learning model will accept the
    data. This step is important because our machine learning model expects the data
    in form of arrays.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: We then split the data into a training and test set. We use 0.7 of the data
    for training and 0.3 for testing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next we have to scale our dataset using Sklearn’s *StandardScaler. *Due to the
    massive amounts of computations taking place in deep learning, feature scaling
    is compulsory. Feature scaling standardizes the range of our independent variables.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '****Building the Artificial Neural Network(ANN)****'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first thing we need to do is import Keras. By default, Keras will use TensorFlow
    as its backend.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next we need to import a few modules from Keras. The Sequential module is required
    to initialize the ANN, and the Dense module is required to build the layers of
    our ANN.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next we need to initialize our ANN by creating an instance of Sequential. The
    Sequential function initializes a linear stack of layers. This allows us to add
    more layers later using the Dense module.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Adding input layer (First Hidden Layer)**'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use the add method to add different layers to our ANN. The first parameter
    is the number of nodes you want to add to this layer. There is no rule of thumb
    as to how many nodes you should add. However a common strategy is to choose the
    number of nodes as the average of nodes in the input layer and the number of nodes
    in the output layer.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Say for example you had five independent variables and one output. Then you
    would take the sum of that and divide by two, which is three. You can also decide
    to experiment with a technique called parameter tuning. The second parameter, *kernel_initializer*,is
    the function that will be used to initialize the weights. In this case, it will
    use a uniform distribution to make sure that the weights are small numbers close
    to zero. The next parameter is the activation function. We use the Rectifier function,
    shortened as relu. We mostly use this function for the hidden layer in ANN. The
    final parameter is input_dim, which is the number of nodes in the input layer.
    It represents the number of independent variables.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '****Adding Second Hidden Layer****'
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adding the second hidden layer is similar to adding the first hidden layer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We don’t need to specify the input_dim parameter because we have already specified
    it in the first hidden layer. In the first hidden layer we specified this in order
    to let the layer know how many input nodes to expect. In the second hidden layer
    the ANN already knows how many input nodes to expect so we don’t need to repeat
    ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '****Adding the output layer****'
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We change the first parameter because in our output node we expect one node.
    This is because we are only interested in knowing whether a claim was fraudulent
    or not. We change the activation function because we want to get the probabilities
    that a claim is fraudulent. We do this by using the Sigmoid activation function.
    In case you’re dealing with a classification problem that has more than two classes
    (i.e. classifying cats, dogs, and monkeys) we’d need to change two things. We
    ‘d change the first parameter to 3 and change the activation function to softmax.
    Softmax is a sigmoid function applied to an independent variable with more than
    two categories.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们更改第一个参数，因为在我们的输出节点中，我们期望只有一个节点。这是因为我们只关心知道一个声明是否是欺诈性的。我们更改激活函数是因为我们想要获得声明是欺诈性的概率。我们通过使用
    Sigmoid 激活函数来实现这一点。如果你处理的是一个有多个类别的分类问题（即对猫、狗和猴子进行分类），我们需要更改两件事。我们将第一个参数更改为 3，并将激活函数更改为
    softmax。Softmax 是一种应用于具有两个以上类别的独立变量的 sigmoid 函数。
- en: '* * *'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建和训练您的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[Keras 3.0: Everything You Need To Know](https://www.kdnuggets.com/2023/07/keras-30-everything-need-know.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras 3.0：你需要知道的一切](https://www.kdnuggets.com/2023/07/keras-30-everything-need-know.html)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库介绍：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学、机器学习和深度学习的可靠计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月27日：关于 Papers With Code 的简要介绍；…](https://www.kdnuggets.com/2022/n17.html)'
- en: '[Introduction to Statistical Learning, Python Edition: Free Book](https://www.kdnuggets.com/2023/07/introduction-statistical-learning-python-edition-free-book.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学习简介，Python 版：免费书籍](https://www.kdnuggets.com/2023/07/introduction-statistical-learning-python-edition-free-book.html)'
