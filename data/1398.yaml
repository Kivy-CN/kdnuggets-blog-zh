- en: 'The Augmented Scientist Part 1: Practical Application Machine Learning in Classification
    of SEM Images'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强科学家第1部分：机器学习在 SEM 图像分类中的实际应用
- en: 原文：[https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html](https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html](https://www.kdnuggets.com/2020/03/the-augmented-scientist-practical-application-machine-learning-classification-images.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47), [Skellig.ai](https://www.skellig.ai/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47), [Skellig.ai](https://www.skellig.ai/)**'
- en: '![Augmented Science Graphic](../Images/475e10bf83a0678190e37f8e537318e8.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Augmented Science Graphic](../Images/475e10bf83a0678190e37f8e537318e8.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Welcome to the first blog in our Augmented Scientist series, where we will be
    looking at how machine learning can be used to improve the way that Scientists
    work on a day-to-day basis. As this series grows we’ll be looking at more applications
    for ML to work as a research aid for scientists, removing a lot of repetitive
    analysis work and allowing them to explore their fields deeper. Both my wife and
    I come from science backgrounds, her chemistry and me physics. What struck me
    when I started working on machine learning is the enormous opportunity to speed
    up much of the tedious analysis that consumes so much time in research labs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到我们“增强科学家”系列的第一篇博客，我们将探讨如何利用机器学习改善科学家日常工作的方式。随着这一系列的展开，我们将深入探讨机器学习作为研究助手的更多应用，减少大量重复的分析工作，并使科学家能够更深入地探索他们的领域。我和我的妻子都拥有科学背景，她专攻化学，我则专注于物理。当我开始从事机器学习工作时，我被加速处理研究实验室中繁琐分析任务的巨大机会所打动。
- en: As our first exploration into the concept of the Augmented Scientist, our goal
    here is to see if we can build a classifier that can identify patterns in [Scanning
    Electron Microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope) (SEM)
    images, and compare the performance of our classifier to the current state-of-the-art.
    Later posts will investigate more focused applications of SEM image classification.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对增强科学家概念的首次探索，我们的目标是看看是否可以构建一个分类器，识别 [扫描电子显微镜](https://en.wikipedia.org/wiki/Scanning_electron_microscope) （SEM）图像中的模式，并将我们的分类器的表现与当前的最先进技术进行比较。后续文章将探讨
    SEM 图像分类的更专注应用。
- en: What is SEM?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是 SEM？
- en: The first area that we’re going to look at is SEM image analysis, a technique
    my wife, as an electrochemist, has worked with extensively throughout her career.
    SEM is used extensively in chemistry and biology to create images of surfaces
    at a nanometer scale. It works by scanning a surface with a focused electron beam.
    The reflection of electrons off the surface creates an image of the topography
    and composition of the surface.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要关注的第一个领域是 SEM 图像分析，这是我妻子作为电化学家在职业生涯中广泛使用的技术。SEM 在化学和生物学中被广泛应用，以纳米级别创建表面图像。它通过用聚焦的电子束扫描表面来工作。电子在表面上的反射形成了表面地形和组成的图像。
- en: '![Figure](../Images/e60e3debf9b711715a308547a15e58aa.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/e60e3debf9b711715a308547a15e58aa.png)'
- en: source: [https://en.wikipedia.org/wiki/Scanning_electron_microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://en.wikipedia.org/wiki/Scanning_electron_microscope](https://en.wikipedia.org/wiki/Scanning_electron_microscope)'
- en: This type of detailed imaging has a vast array of applications, each one having
    different analysis requirements, such as optimizing the surfaces of electrodes
    in biosensors, or for producing electricity in fuel cells. The structure of the
    surface can tell us a lot about the properties and characteristics of an object.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种详细的成像有广泛的应用，每种应用都有不同的分析要求，例如优化生物传感器中电极的表面，或用于燃料电池中的电力生产。表面的结构可以告诉我们很多关于物体的属性和特征。
- en: 'Previous Work:'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 以往的工作：
- en: In this blog post we’re going to see if we can make any advancements on the
    work of [Modarres et al 2017](https://www.nature.com/articles/s41598-017-13565-z#Sec2),
    who previously looked at classifying the patterns in 18,577 SEM images (you can
    find the dataset [here](https://b2share.eudat.eu/records/19cc2afd23e34b92b36a1dfd0113a89f)).
    These examples show you the type of patterns categorised in Modarres et al 2017’s
    dataset, who’s labels are Tips, Particles, Patterned Surfaces, MEMS devices and
    electrodes, Nanowires, Porous Sponge, Biological, Powder, Films Coated Surfaces
    and Fibres.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将探讨是否能在[Modarres 等人 2017](https://www.nature.com/articles/s41598-017-13565-z#Sec2)的工作基础上取得任何进展，他们之前研究了
    18,577 张 SEM 图像的模式分类（你可以在[这里](https://b2share.eudat.eu/records/19cc2afd23e34b92b36a1dfd0113a89f)找到数据集）。这些示例展示了
    Modarres 等人 2017 数据集中分类的模式类型，标签包括：Tips、Particles、Patterned Surfaces、MEMS 设备和电极、Nanowires、Porous
    Sponge、生物、Powder、Films Coated Surfaces 和 Fibres。
- en: '![Figure](../Images/285f799e82ab7ee3482f1e3cfab59984.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/285f799e82ab7ee3482f1e3cfab59984.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 'source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)'
- en: The blow tables shows the distribution of images in the categories.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了各类别中图像的分布。
- en: '![Figure](../Images/fba5b29ddf02cdb4cd1a3450f3698937.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/fba5b29ddf02cdb4cd1a3450f3698937.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)'
- en: 'Using the pretrained Inception-v3 model, implemented in Tensorflow, Modarres
    et al achieved an accuracy of ~90%, with a precision of ~80% and a recall@1 of
    ~90%. Modarres et al also reported that an imbalance in the dataset had no effect
    on the classifier’s performance in accurately predicting the under represented
    categories. Their confusion matrix, shown below, shows that the least populated
    categories, Porous Sponge, Films Coated Surface and Fibers, all performed quite
    well. Modarres et al credited this to the distinct patterns of these categories.
    (Note: the values presented in Modarres et al’s confusion matrix are percentages
    of the validation sample for each actual/true label)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在 Tensorflow 中实现的预训练 Inception-v3 模型，Modarres 等人实现了约 90% 的准确率，约 80% 的精确度和约
    90% 的 recall@1。Modarres 等人还报告说，数据集中的不平衡对分类器在准确预测被低估类别的表现没有影响。他们的混淆矩阵如下所示，显示了人口最少的类别
    Porous Sponge、Films Coated Surface 和 Fibers 都表现得相当好。Modarres 等人将此归因于这些类别的独特模式。（注：Modarres
    等人混淆矩阵中呈现的值是每个实际/真实标签的验证样本百分比）
- en: '![Figure](../Images/ada5a524eed11450706d76ea8152fb76.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ada5a524eed11450706d76ea8152fb76.png)'
- en: source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 'source: [https://www.nature.com/articles/s41598-017-13565-z#Sec2](https://www.nature.com/articles/s41598-017-13565-z#Sec2)'
- en: Two things that are worth bearing in mind at this point is that Modarres et
    al did not use any data augmentations, and the training process for the Inception-v3
    implementation took ~7 min on 2 GPUs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 目前值得记住的两件事是，Modarres 等人没有使用任何数据增强，并且 Inception-v3 实现的训练过程在 2 个 GPU 上花费了大约 7
    分钟。
- en: 'Our Approach:'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们的方法：
- en: 'Wanting to see if we could achieve a higher accuracy than Modarres et al, we
    recreated their study with some of our own changes. First off we used the Resnet
    50 implementation on the Fastai v1 framework and executed on a Colab GPU. To avoid
    overfitting, we adopted two approaches introduced by Fast.ai: Data augmentation
    and progressive resizing.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看看我们是否能达到比 Modarres 等人更高的准确率，我们重新创建了他们的研究，并进行了一些自己的修改。首先，我们在 Fastai v1 框架上使用了
    Resnet 50 实现，并在 Colab GPU 上执行。为了避免过拟合，我们采用了 Fast.ai 介绍的两种方法：数据增强和渐进式缩放。
- en: 'Data Augmentation:'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强：
- en: Data augmentation is essentially altering/distorting each image, effectively
    creating a new image. Fastai v1 has a great tool called get_transforms that handles
    this process for us. The [get_transforms](https://docs.fast.ai/vision.transform.html) function
    transforms the images in a number of different ways, such as flipping, rotating,
    changing its contrast and distorting it, meaning that small datasets effectively
    become much bigger.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强本质上是改变/扭曲每个图像，有效地创建出新图像。Fastai v1 提供了一个叫做 get_transforms 的优秀工具来处理这个过程。[get_transforms](https://docs.fast.ai/vision.transform.html)函数以多种不同方式转换图像，例如翻转、旋转、改变对比度和扭曲，这意味着小数据集有效地变得更大。
- en: '![Figure](../Images/2d2d112b9a2c478b16cd2b7efcbba602.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2d2d112b9a2c478b16cd2b7efcbba602.png)'
- en: sources: [https://docs.fast.ai/vision.transform.html](https://docs.fast.ai/vision.transform.html)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://docs.fast.ai/vision.transform.html](https://docs.fast.ai/vision.transform.html)
- en: 'Progressive Resizing:'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逐步调整图像尺寸：
- en: Progressive resizing is an approach that was introduced by [Jeremy Howard](https://twitter.com/jeremyphoward) at [Fast.ai](https://www.fast.ai/).
    The concept is to crop the images in the dataset to a much smaller size, then
    after we’ve trained the model on the cropped images we increase their size and
    train the model again. We repeat this process a number of times, each time increasing
    the size of the images in the dataset. In this case we started with images of
    size 64x64 pixels. We trained the Resnet 50 on this dataset for a total of 15
    epochs and then increased it iteratively to 128 and finally 224\. Progressive
    resizing has two advantages. First off a lot of the early training is carried
    out on smaller images, which means the computational cost is lower and training
    takes less time. Secondly, repeatedly changing the size of the images and retraining
    the model can make it very difficult for the model to overfit. This means that
    your final model is more stable on new data it’s never seen before.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步调整图像尺寸是一种由[Jeremy Howard](https://twitter.com/jeremyphoward)在[Fast.ai](https://www.fast.ai/)提出的方法。这个概念是将数据集中图像裁剪为更小的尺寸，然后在这些裁剪后的图像上训练模型，接着逐渐增大图像尺寸并再次训练模型。我们多次重复这一过程，每次都增加数据集中图像的尺寸。在这个案例中，我们从64x64像素的图像开始。我们在这个数据集上训练了Resnet
    50，总共进行了15个周期，然后逐步增加到128，最后到224。逐步调整图像尺寸有两个优点。首先，许多早期的训练是在较小图像上进行的，这意味着计算成本较低，训练时间更短。其次，反复改变图像尺寸并重新训练模型可以使模型不易过拟合。这意味着你的最终模型在以前从未见过的新数据上更稳定。
- en: 'Results:'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果：
- en: Our implementation can be found in our GitHub repository, [here](https://github.com/skellig-ai/ikeaney.github.io/blob/master/SEM_Classification_ResNet50.ipynb).
    We achieved an overall accuracy of 94.5%, more than 4.5% of an increase on the
    previous state-of-the-art by Modarres et al, although our training process did
    take nearly 400 mins. Given that there is an imbalance in the data set, it is
    useful to consider metrics other than accuracy, such as [precision and recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall).
    Precision is essentially what proportion of the positive identification is actually
    correct, while recall is the proportion of actual positives which were identified
    correctly. Our model, while slightly over-fitting, achieved a precision of 94.2%
    and a recall of 91.8%. Comparing these to the values that Modarres et al reported
    of ~80% and ~90% respectively indicates that our model also performs better on
    the underrepresented categories in the dataset.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现可以在我们的 GitHub 仓库中找到，[这里](https://github.com/skellig-ai/ikeaney.github.io/blob/master/SEM_Classification_ResNet50.ipynb)。我们达到了94.5%的总体准确率，比Modarres等人之前的最先进水平提高了4.5%以上，尽管我们的训练过程确实花费了近400分钟。考虑到数据集存在不平衡，除了准确率外，还应考虑其他指标，如[精准度和召回率](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)。精准度本质上是正向识别中实际正确的比例，而召回率是实际正样本中被正确识别的比例。我们的模型虽然略有过拟合，但实现了94.2%的精准度和91.8%的召回率。与Modarres等人报告的~80%和~90%相比，这表明我们的模型在数据集中代表性不足的类别上也表现更好。
- en: 'Concluding Remarks:'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论：
- en: I hope you enjoyed the first blog post in our Augmented Scientist series. This
    series will explore more avenues where machine learning can be used to assist
    the work of Scientists across many disciplines. If you’re interested in getting
    involved, or have examples of where you’ve used machine learning to augment your
    own work please let us know, we’d love to hear from you.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你喜欢我们“增强科学家”系列的第一篇博客文章。这个系列将探讨机器学习如何帮助多个学科的科学家们。如果你有兴趣参与，或者有使用机器学习增强自己工作的例子，请告诉我们，我们很乐意听取你的意见。
- en: '**Bio: [Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47)** ([**@Iain_Keaney**](https://twitter.com/Iain_Keaney))
    is a Machine Learning Engineer and Program Facilitator at [Skellig.ai](https://www.skellig.ai/).
    You can find the [Skellig.ai blog here](https://skellig-ai.github.io/).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Iain Keaney](https://www.linkedin.com/in/iain-keaney-9a668b47)** ([**@Iain_Keaney**](https://twitter.com/Iain_Keaney))
    是 [Skellig.ai](https://www.skellig.ai/) 的机器学习工程师和项目协调员。你可以在这里找到 [Skellig.ai 博客](https://skellig-ai.github.io/)。'
- en: '[Original](https://skellig-ai.github.io/2020/02/03/The-Augmented-Scientist-Part-1.html).
    Reposted with permission.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://skellig-ai.github.io/2020/02/03/The-Augmented-Scientist-Part-1.html)。经授权转载。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Deep Learning for Image Classification with Less Data](/2019/11/deep-learning-image-classification-less-data.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[少量数据的深度学习图像分类](/2019/11/deep-learning-image-classification-less-data.html)'
- en: '[What Does it Mean to Deploy a Machine Learning Model?](/2020/02/deploy-machine-learning-model.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[部署机器学习模型意味着什么？](/2020/02/deploy-machine-learning-model.html)'
- en: '[A Single Function to Streamline Image Classification with Keras](/2019/09/single-function-streamline-image-classification-keras.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[单一功能简化 Keras 图像分类](/2019/09/single-function-streamline-image-classification-keras.html)'
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[认识 Gorilla：加州大学伯克利分校和微软的 API 增强 LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与…的结合](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[Essential Math for Data Science: Eigenvectors and Application to PCA](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的基础数学：特征向量及其在 PCA 中的应用](https://www.kdnuggets.com/2022/06/essential-math-data-science-eigenvectors-application-pca.html)'
- en: '[Creating a Web Application to Extract Topics from Audio with Python](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[创建一个 Web 应用程序从音频中提取主题](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)'
- en: '[Building a Geospatial Application in Python with Google Earth…](https://www.kdnuggets.com/2022/03/building-geospatial-application-python-google-earth-engine-greppo.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 和 Google Earth Engine 构建地理空间应用程序…](https://www.kdnuggets.com/2022/03/building-geospatial-application-python-google-earth-engine-greppo.html)'
- en: '[8 Ways to Improve Your Search Application this Week](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本周提升搜索应用的 8 种方法](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
