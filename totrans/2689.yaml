- en: Fast Gradient Boosting with CatBoost
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CatBoost 进行快速梯度提升
- en: 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: In gradient boosting, predictions are made from an ensemble of weak learners.
    Unlike a random forest that creates a decision tree for each sample, in gradient
    boosting, trees are created one after the other. Previous trees in the model are
    not altered. Results from the previous tree are used to improve the next one.
    In this piece, we’ll take a closer look at a gradient boosting library called
    CatBoost.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度提升中，预测是通过一组弱学习器来完成的。与随机森林为每个样本创建一个决策树不同，在梯度提升中，树是一个接一个地创建的。模型中的前一棵树不会被更改。前一棵树的结果被用来改进下一棵树。在这篇文章中，我们将更深入地了解一个名为
    CatBoost 的梯度提升库。
- en: '![Figure](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)'
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的信息技术'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[CatBoost](https://github.com/catboost) is a depth-wise gradient boosting library
    developed by [Yandex](https://yandex.com/company/). It uses oblivious decision
    trees to grow a balanced tree. The same features are used to make left and right
    splits for each level of the tree.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[CatBoost](https://github.com/catboost) 是一个由 [Yandex](https://yandex.com/company/)
    开发的深度梯度提升库。它使用无意识决策树来生长平衡树。相同的特征用于每一层树的左右分裂。'
- en: '![Figure](../Images/22cec580000a5a651f8a7b907b81bca5.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/22cec580000a5a651f8a7b907b81bca5.png)'
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
- en: As compared to classic trees, the oblivious trees are more efficient to implement
    on CPU and are simple to fit.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与经典树相比，无意识树在 CPU 上实现更高效，且更易于拟合。
- en: Dealing with Categorical Features
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理分类特征
- en: The common ways of handling categorical in machine learning are one-hot encoding
    and label encoding. CatBoost allows you to use categorical features without the
    need to pre-process them.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 处理分类特征的常见方法是独热编码和标签编码。CatBoost 允许您在不需要预处理分类特征的情况下使用它们。
- en: When using CatBoost, we shouldn’t use one-hot encoding, as this will affect
    the training speed, as well as the quality of predictions. Instead, we simply
    specify the categorical features using the `cat_features` parameter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CatBoost 时，我们不应使用独热编码，因为这会影响训练速度和预测质量。相反，我们只需使用 `cat_features` 参数指定分类特征。
- en: Advantages of using CatBoost
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 CatBoost 的优点
- en: 'Here are a few reasons to consider using CatBoost:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个考虑使用 CatBoost 的理由：
- en: CatBoost allows for training of data on several GPUs.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CatBoost 允许在多个 GPU 上训练数据。
- en: It provides great results with default parameters, hence reducing the time needed
    for parameter tuning.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了使用默认参数的良好结果，从而减少了参数调整所需的时间。
- en: Offers improved accuracy due to reduced overfitting.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于减少了过拟合，提供了更高的准确性。
- en: Use of CatBoost’s model applier for fast prediction.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CatBoost 的模型应用程序进行快速预测。
- en: Trained CatBoost models can be exported to Core ML for on-device inference (iOS).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练后的 CatBoost 模型可以导出到 Core ML 进行设备端推理（iOS）。
- en: Can handle missing values internally.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以内部处理缺失值。
- en: Can be used for regression and classification problems.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以用于回归和分类问题。
- en: Training Parameters
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练参数
- en: 'Let’s look at the common parameters in CatBoost:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 CatBoost 中的一些常见参数：
- en: '`loss_function` alias as `objective` — Metric used for training. These are
    regression metrics such as root mean squared error for regression and logloss
    for classification.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_function` 别名 `objective` — 用于训练的度量指标。这些是回归度量指标，例如回归的均方根误差和分类的logloss。'
- en: '`eval_metric` — Metric used for detecting overfitting.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_metric` — 用于检测过拟合的度量指标。'
- en: '`iterations` — The maximum number of trees to be built, defaults to 1000\.
    It aliases are `num_boost_round`, `n_estimators`, and `num_trees`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterations` — 最大树数量，默认为1000。它的别名有`num_boost_round`、`n_estimators`和`num_trees`。'
- en: '`learning_rate` alias `eta` — The learning rate that determines how fast or
    slow the model will learn. The default is usually 0.03.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate` 别名 `eta` — 决定模型学习速度的学习率。默认值通常为0.03。'
- en: '`random_seed` alias `random_state` — The random seed used for training.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_seed` 别名 `random_state` — 用于训练的随机种子。'
- en: '`l2_leaf_reg` alias `reg_lambda` — Coefficient at the L2 regularization term
    of the cost function. The default is 3.0.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l2_leaf_reg` 别名 `reg_lambda` — 成本函数L2正则化项的系数。默认值为3.0。'
- en: '`bootstrap_type` — Determines the sampling method for the weights of the objects,
    e.g Bayesian, Bernoulli, MVS, and Poisson.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap_type` — 确定对象权重的采样方法，例如Bayesian、Bernoulli、MVS和Poisson。'
- en: '`depth` —The depth of the tree.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth` — 树的深度。'
- en: '`grow_policy` — Determines how the greedy search algorithm will be applied.
    It can be either `SymmetricTree`, `Depthwise`, or `Lossguide`. `SymmetricTree` is
    the default. In `SymmetricTree`, the tree is built level-by-level until the depth
    is attained. In every step, leaves from the previous tree are split with the same
    condition. When `Depthwise` is chosen, a tree is built step-by-step until the
    specified depth is achieved. On each step, all non-terminal leaves from the last
    tree level are split. The leaves are split using the condition that leads to the
    best loss improvement. In `Lossguide`, the tree is built leaf-by-leaf until the
    specified number of leaves is attained. On each step, the non-terminal leaf with
    the best loss improvement is split'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grow_policy` — 确定贪婪搜索算法的应用方式。可以是`SymmetricTree`、`Depthwise`或`Lossguide`。`SymmetricTree`为默认选项。在`SymmetricTree`中，树按层构建，直到达到指定深度。在每一步中，前一棵树的叶子都用相同的条件进行分裂。当选择`Depthwise`时，树逐步构建，直到达到指定深度。在每一步中，上一层所有非终端叶子都会被分裂，叶子的分裂条件是导致最佳损失改善的条件。在`Lossguide`中，树逐叶构建，直到达到指定的叶子数。在每一步中，具有最佳损失改善的非终端叶子会被分裂。'
- en: '`min_data_in_leaf` alias `min_child_samples` — This is the minimum number of
    training samples in a leaf. This parameter is only used with the `Lossguide` and `Depthwise` growing
    policies.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_data_in_leaf` 别名 `min_child_samples` — 这是叶子中训练样本的最小数量。该参数仅在使用`Lossguide`和`Depthwise`生长策略时有效。'
- en: '`max_leaves` alias `num_leaves` — This parameter is used only with the `Lossguide` policy
    and determines the number of leaves in the tree.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_leaves` 别名 `num_leaves` — 该参数仅在使用`Lossguide`策略时有效，用于确定树中的叶子数。'
- en: '`ignored_features` — Indicates the features that should be ignored in the training
    process.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignored_features` — 指示在训练过程中应忽略的特征。'
- en: '`nan_mode` — The method for dealing with missing values. The options are `Forbidden`, `Min`,
    and `Max`. The default is `Min`. When `Forbidden` is used, the presence of missing
    values leads to errors. With `Min`, the missing values are taken as the minimum
    values for that feature. In `Max`, the missing values are treated as the maximum
    value for the feature.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nan_mode` — 处理缺失值的方法。选项包括`Forbidden`、`Min`和`Max`。默认值是`Min`。使用`Forbidden`时，缺失值会导致错误。使用`Min`时，缺失值被视为该特征的最小值。在`Max`中，缺失值被视为该特征的最大值。'
- en: '`leaf_estimation_method` — The method used to calculate values in leaves. In
    classification, 10 `Newton` iterations are used. Regression problems using quantile
    or MAE loss use one `Exact` iteration. Multi classification uses one `Netwon` iteration.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaf_estimation_method` — 用于计算叶子中的值的方法。在分类问题中，使用10次`Newton`迭代。回归问题中使用分位数或MAE损失时使用一次`Exact`迭代。多分类使用一次`Newton`迭代。'
- en: '`leaf_estimation_backtracking` — The type of backtracking to be used during
    gradient descent. The default is `AnyImprovement`. `AnyImprovement` decreases
    the descent step, up to where the loss function value is smaller than it was in
    the last iteration. `Armijo` reduces the descent step until the [Armijo condition](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature) is
    met.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaf_estimation_backtracking` — 梯度下降过程中使用的回溯类型。默认值是`AnyImprovement`。`AnyImprovement`会减少下降步长，直到损失函数值小于上一次迭代中的值。`Armijo`会减少下降步长，直到满足[Armijo条件](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature)。'
- en: '`boosting_type` — The boosting scheme. It can be `plain` for the classic gradient
    boosting scheme, or `ordered`, which offers better quality on smaller datasets.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boosting_type` — 提升方案。可以是`plain`，用于经典的梯度提升方案，或`ordered`，在较小的数据集上提供更好的质量。'
- en: '`score_function` — The [score type](https://catboost.ai/docs/concepts/algorithm-score-functions.html) used
    to select the next split during tree construction. `Cosine` is the default option.
    The other available options are `L2`, `NewtonL2`, and `NewtonCosine`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_function` — 用于在树构建过程中选择下一个分裂点的[评分类型](https://catboost.ai/docs/concepts/algorithm-score-functions.html)。`Cosine`是默认选项。其他可选项包括`L2`、`NewtonL2`和`NewtonCosine`。'
- en: '`early_stopping_rounds` — When `True`, sets the overfitting detector type to `Iter` and
    stops the training when the optimal metric is achieved.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`early_stopping_rounds` — 当设置为`True`时，将过拟合检测器类型设置为`Iter`，并在达到最佳指标时停止训练。'
- en: '`classes_count` — The number of classes for multi-classification problems.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classes_count` — 多分类问题中的类别数量。'
- en: '`task_type` — Whether you are using a CPU or GPU. CPU is the default.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_type` — 指示是否使用CPU或GPU。默认是CPU。'
- en: '`devices` — The IDs of the GPU devices to be used for training.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`devices` — 用于训练的GPU设备ID。'
- en: '`cat_features` — The array with the categorical columns.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cat_features` — 包含分类列的数组。'
- en: '`text_features` —Used to declare text columns in classification problems.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_features` — 用于在分类问题中声明文本列。'
- en: Regression Example
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归示例
- en: CatBoost uses the scikit-learn standard in its implementation. Let’s see how
    we can use it for regression.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost在其实现中使用了scikit-learn标准。让我们看看如何将其用于回归。
- en: The first step — as always — is to import the regressor and instantiate it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶段——像往常一样——是导入回归器并实例化它。
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When fitting the model, CatBoost also enables use to visualize it by setting `plot=true`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型时，CatBoost还允许通过设置`plot=true`来可视化模型：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Image for post](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)'
- en: 'It also allows you to perform cross-validation and visualize the process:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它还允许你进行交叉验证并可视化过程：
- en: '![Image for post](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)'
- en: 'Similarly, you can also perform grid search and visualize it:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你也可以执行网格搜索并可视化结果：
- en: '![Image for post](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)'
- en: We can also use CatBoost to plot a tree. Here’s the plot is for the first tree.
    As you can see from the tree, the leaves on every level are being split on the
    same condition—e.g 297, value >0.5.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用CatBoost绘制树图。下面的图是第一棵树的图。可以看到，树的每一层的叶子都基于相同的条件进行分裂——例如297，值>0.5。
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Image for post](../Images/1bf072864f605a5db714f0a388c18dd4.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/1bf072864f605a5db714f0a388c18dd4.png)'
- en: CatBoost also gives us a dictionary with all the model parameters. We can print
    them by iterating through the dictionary.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost还提供了一个包含所有模型参数的字典。我们可以通过遍历字典来打印这些参数。
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Image for post](../Images/33f889fb3e9caa39f98841f2938006c5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/33f889fb3e9caa39f98841f2938006c5.png)'
- en: Final Thoughts
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: In this piece, we’ve explored the benefits and limitations of CatBoost, along
    with its primary training parameters. Then, we worked through a simple regression
    implementation with scikit-learn. Hopefully this gives you enough information
    on the library so that you can explore it further.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这部分中，我们探讨了CatBoost的优点和局限性，以及其主要训练参数。然后，我们通过scikit-learn进行了简单的回归实现。希望这能为你提供足够的信息，以便你可以进一步探索这个库。
- en: '[**CatBoost - state-of-the-art open-source gradient boosting library with categorical
    features support**](https://catboost.ai/)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[**CatBoost - 具有分类特征支持的最先进开源梯度提升库**](https://catboost.ai/)'
- en: CatBoost is an algorithm for gradient boosting on decision trees. It is developed
    by Yandex researchers and engineers...
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost是一种用于决策树的梯度提升算法，由Yandex的研究人员和工程师开发...
- en: '[**The Data Science Bootcamp in Python**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Python 数据科学训练营**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)'
- en: Learn Python for Data Science,NumPy,Pandas,Matplotlib,Seaborn,Scikit-learn,
    Dask,LightGBM,XGBoost,CatBoost and much...
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 学习 Python 数据科学、NumPy、Pandas、Matplotlib、Seaborn、Scikit-learn、Dask、LightGBM、XGBoost、CatBoost
    等等...
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Derrick Mwiti](https://derrickmwiti.com/)** 是一名数据分析师、作家和导师。他致力于在每项任务中取得优异成绩，并且是
    Lapid Leaders Africa 的导师。'
- en: '[Original](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a).
    Reposted with permission.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a)。经授权转载。'
- en: '**Related:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[LightGBM: A Highly-Efficient Gradient Boosting Decision Tree](/2020/06/lightgbm-gradient-boosting-decision-tree.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LightGBM：高效的梯度提升决策树](https://www.kdnuggets.com/2020/06/lightgbm-gradient-boosting-decision-tree.html)'
- en: '[Understanding Gradient Boosting Machines](/2019/02/understanding-gradient-boosting-machines.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解梯度提升机](https://www.kdnuggets.com/2019/02/understanding-gradient-boosting-machines.html)'
- en: '[Mastering Fast Gradient Boosting on Google Colaboratory with free GPU](/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Google Colaboratory 上利用免费 GPU 掌握快速梯度提升](https://www.kdnuggets.com/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)'
- en: More On This Topic
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关内容
- en: '[Top 5 Advantages That CatBoost ML Brings to Your Data to Make it Purr](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CatBoost ML 给你的数据带来的 5 大优势，让数据变得更出色](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)'
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[终极指南：掌握季节性和提升商业成果](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 在稀疏性下能走多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用快速克里金法（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何让 Python 代码运行得极快](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
