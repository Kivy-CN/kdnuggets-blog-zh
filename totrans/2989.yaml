- en: State of the art in AI and Machine Learning – highlights of papers with code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能和机器学习领域的最新进展——代码论文亮点
- en: 原文：[https://www.kdnuggets.com/2019/02/paperswithcode-ai-machine-learning-highlights.html](https://www.kdnuggets.com/2019/02/paperswithcode-ai-machine-learning-highlights.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/02/paperswithcode-ai-machine-learning-highlights.html](https://www.kdnuggets.com/2019/02/paperswithcode-ai-machine-learning-highlights.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: As any Machine Learning, AI or Computer Scientist enthusiast will know, finding
    resources and papers on subjects you’re interested in can be a hassle. Often you’re
    required to sign up to a website and some will even try to charge you a subscription
    fee for reading the work of others.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 正如任何机器学习、人工智能或计算机科学爱好者所知，找到感兴趣主题的资源和论文可能是一项麻烦的工作。通常，你需要注册一个网站，有些甚至会收取订阅费用来阅读他人的研究成果。
- en: '![Papers With Code](../Images/ae8fdd1ad0dd5c8d5c8d870703ed1a7c.png)This is
    what makes the site *[Papers with code](https://paperswithcode.com/)* so great;
    they provide a magnitude of free resources covering a whole host of subjects.
    Their mission statement reads:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![Papers With Code](../Images/ae8fdd1ad0dd5c8d5c8d870703ed1a7c.png)这就是使* [Papers
    with code](https://paperswithcode.com/)*如此出色的原因；他们提供了大量免费的资源，涵盖了各种主题。他们的使命声明如下：'
- en: '*The mission of Papers With Code is to create a free and open resource with
    Machine Learning papers, code and evaluation tables.*'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Papers With Code 的使命是创建一个免费的开放资源，提供机器学习论文、代码和评估表格。*'
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*We believe this is best done together with the community and powered by automation.*'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*我们相信，这最好是与社区共同完成并通过自动化实现的。*'
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*We''ve already automated the linking of code to papers, and we are now working
    on automating the extraction of evaluation metrics from papers.*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*我们已经自动化了代码与论文的链接，现在正致力于自动化从论文中提取评估指标。*'
- en: On top of this, they have their own [slack channel](https://join.slack.com/t/paperswithcode/shared_invite/enQtNTI3NDE2NjQ0ODM0LTdmNzNjODkwOGY0MjU4YzgzNDZhNGM1YWIzYmZhNzk5MTFkYWU4YWNjN2JjZDhlNjJiYjFkYjYwNjkzYzdiZDk)
    and they allow users to download all of the data that helps run the site. They’re
    open to contributions, so feel free to dive in on and keep the community growing!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在此基础上，他们有自己的[slack频道](https://join.slack.com/t/paperswithcode/shared_invite/enQtNTI3NDE2NjQ0ODM0LTdmNzNjODkwOGY0MjU4YzgzNDZhNGM1YWIzYmZhNzk5MTFkYWU4YWNjN2JjZDhlNjJiYjFkYjYwNjkzYzdiZDk)，并允许用户下载所有帮助运行网站的数据。他们欢迎贡献，所以可以随时参与进来，继续壮大社区！
- en: 'In celebration of this great resource, we’ve attempted to summarise 6 of our
    favourite topics (what the website calls “tasks”) on the site and some of the
    papers they offer:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了庆祝这一伟大资源，我们尝试总结了网站上我们最喜欢的6个主题（网站称之为“任务”）及其提供的一些论文：
- en: '**Semantic Segmentation**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**语义分割**'
- en: 'The concept of semantic segmentation is to recognize and understand what is
    in an image at the pixel level. This is one of the biggest categories in terms
    of content on the site, with 322 papers with code. The most popular of these is
    entitled *[Encoder-Decoder with Atrous Separable Convolution for Semantic Image
    Segmentation](https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable-co3)*.
    This paper aims to combine the advantages of both methods of semantic segmentation:
    Spatial pyramid pooling module and encode-decoder structure. The paper is accompanied
    with a publicly-available reference implementation of the proposed models in TensorFlow.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割的概念是识别和理解图像中的每一个像素。这是网站上内容最多的类别之一，共有322篇带代码的论文。其中最受欢迎的论文标题为*[带有Atrous可分离卷积的编码器-解码器用于语义图像分割](https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable-co3)*。该论文旨在结合语义分割的两种方法的优势：空间金字塔池化模块和编码-解码结构。该论文附带了一个公开的TensorFlow模型实现。
- en: 'Other top papers on Semantic Segmentation:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其他顶级语义分割论文：
- en: '[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://paperswithcode.com/paper/mobilenetv2-inverted-residuals-and-line3)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[MobileNetV2：倒置残差和线性瓶颈](https://paperswithcode.com/paper/mobilenetv2-inverted-residuals-and-line3)'
- en: '[Rethinking Atrous Convolution for Semantic Image Segmentation](https://paperswithcode.com/paper/rethinking-atrous-convolution-for-semant2)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[重新思考用于语义图像分割的Atrous卷积](https://paperswithcode.com/paper/rethinking-atrous-convolution-for-semant2)'
- en: '[Mask R-CNN](https://paperswithcode.com/paper/mask-r-cnn)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mask R-CNN](https://paperswithcode.com/paper/mask-r-cnn)'
- en: '[Pyramid Scene Parsing Network](https://paperswithcode.com/paper/pyramid-scene-parsing-network)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[金字塔场景解析网络](https://paperswithcode.com/paper/pyramid-scene-parsing-network)'
- en: '**NLP**'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**'
- en: 'Natural Language Processing is one of the biggest collections of tasks on the
    site, with subsections on Machine Translation, Language Modelling, Sentiment Analysis,
    Text Classification and many others. One the most popular categories within this
    is Question Answering, with over 200 papers on the subject. The top ranked paper
    on this subject is by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova
    and is titled *[BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding](https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional2)*.
    The paper introduces a new language representation model called BERT, which stands
    for **B**idirectional **E**ncoder **R**epresentations from **T**ransformers. Unlike
    recent language representation models, BERT is designed to pre-train deep bidirectional
    representations by jointly conditioning on both left and right context in all
    layers.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理是站点上最大的一类任务集合之一，涵盖了机器翻译、语言建模、情感分析、文本分类等多个子领域。在这些子领域中，问答系统是最受欢迎的类别之一，相关论文超过200篇。该领域排名最高的论文由Jacob
    Devlin、Ming-Wei Chang、Kenton Lee和Kristina Toutanova撰写，题为*[BERT：用于语言理解的深度双向变换器预训练](https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional2)*。该论文介绍了一种新的语言表示模型，称为BERT，代表**双向**编码器**表征**来自**变换器**。与近期的语言表示模型不同，BERT旨在通过在所有层中共同考虑左右上下文来进行深度双向表示的预训练。
- en: 'Other top papers on NLP:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 其他顶级NLP论文：
- en: '[Exploring the Limits of Language Modeling](https://paperswithcode.com/paper/exploring-the-limits-of-language-modelin2)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[探索语言建模的极限](https://paperswithcode.com/paper/exploring-the-limits-of-language-modelin2)'
- en: '[Semi-Supervised Sequence Modeling with Cross-View Training](https://paperswithcode.com/paper/semi-supervised-sequence-modeling-with-c3)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[基于交叉视角训练的半监督序列建模](https://paperswithcode.com/paper/semi-supervised-sequence-modeling-with-c3)'
- en: '[Can Active Memory Replace Attention?](https://paperswithcode.com/paper/can-active-memory-replace-attention)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[活跃记忆能取代注意力机制吗？](https://paperswithcode.com/paper/can-active-memory-replace-attention)'
- en: '[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional2)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[BERT：用于语言理解的深度双向变换器预训练](https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional2)'
- en: '**Transfer Learning**'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**迁移学习**'
- en: 'Transfer learning is a methodology where weights from a model trained on one
    task are taken and used either:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种方法论，其中从一个任务上训练的模型的权重被提取并用于：
- en: To construct a fixed feature extractor
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个固定的特征提取器
- en: As weight initialization and/or fine-tuning
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为权重初始化和/或微调
- en: 'The most popular paper on transfer learning is *[Semi-supervised Knowledge
    Transfer for Deep Learning from Private Training Data](https://paperswithcode.com/paper/semi-supervised-knowledge-transfer-for-d2)*.
    This paper sets out to solve the problem that affects models using private data,
    in that a model may inadvertently and implicitly store some of its training data
    and that subsequent careful analysis of the model may therefore reveal sensitive
    information. To address this problem, the paper demonstrates a generally applicable
    approach to providing security for sensitive data: Private Aggregation of Teacher
    Ensembles (PATE). The approach combines, in a black-box fashion, multiple models
    trained with disjoint datasets, such as records from different subsets of users.
    This paper also includes a link to the GitHub repo with all the code in TensorFlow
    for this project.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于迁移学习，最受欢迎的论文是*[半监督知识迁移：从私有训练数据中学习](https://paperswithcode.com/paper/semi-supervised-knowledge-transfer-for-d2)*。这篇论文旨在解决一个影响使用私有数据的模型的问题，即模型可能会无意中和隐性地存储一些训练数据，因此对模型的后续仔细分析可能会揭示敏感信息。为了解决这个问题，论文展示了一种通用的提供敏感数据安全性的办法：教师集体的私有聚合（PATE）。这种方法以黑箱的方式结合了用不重叠的数据集训练的多个模型，例如来自不同用户子集的记录。该论文还包括一个指向GitHub仓库的链接，其中包含该项目的所有TensorFlow代码。
- en: 'Other top papers on Transfer Learning:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其他顶级迁移学习论文：
- en: '[Large-scale Simple Question Answering with Memory Networks](https://paperswithcode.com/paper/large-scale-simple-question-answering-wi2)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[大规模简单问答与记忆网络](https://paperswithcode.com/paper/large-scale-simple-question-answering-wi2)'
- en: '[DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition](https://paperswithcode.com/paper/decaf-a-deep-convolutional-activation-f2)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeCAF：用于通用视觉识别的深度卷积激活特征](https://paperswithcode.com/paper/decaf-a-deep-convolutional-activation-f2)'
- en: '[Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation
    Learning](https://paperswithcode.com/paper/tencent-ml-images-a-large-scale-multi-l2)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[腾讯ML-Images：一个用于视觉表示学习的大规模多标签图像数据库](https://paperswithcode.com/paper/tencent-ml-images-a-large-scale-multi-l2)'
- en: '[Bag of Tricks for Image Classification with Convolutional Neural Networks](https://paperswithcode.com/paper/bag-of-tricks-for-image-classification-w2)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[卷积神经网络图像分类技巧集](https://paperswithcode.com/paper/bag-of-tricks-for-image-classification-w2)'
- en: '**Multi-task learning**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**多任务学习**'
- en: 'Multi-task learning aims to learn multiple different tasks simultaneously while
    maximizing performance on one or all of the tasks. The paper with the most stars
    currently is: *[DRAGNN: A Transition-based Framework for Dynamically Connected
    Neural Networks](https://paperswithcode.com/paper/dragnn-a-transition-based-framework-for2)*.
    This work presents a compact, modular framework for constructing novel recurrent
    neural architectures. Again, this paper also features a full working code example
    in TensorFlow.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习旨在同时学习多个不同的任务，同时最大化一个或所有任务的性能。目前星标最多的论文是：*[DRAGNN：一个基于转换的动态连接神经网络框架](https://paperswithcode.com/paper/dragnn-a-transition-based-framework-for2)*。这项工作提出了一个紧凑的模块化框架，用于构建新型的递归神经网络架构。再次提醒，这篇论文还提供了一个完整的TensorFlow工作代码示例。
- en: 'Other top papers on Multi-task learning:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于多任务学习的其他顶级论文：
- en: '[Semi-Supervised Sequence Modeling with Cross-View Training](https://paperswithcode.com/paper/semi-supervised-sequence-modeling-with-c3)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[半监督序列建模与交叉视图训练](https://paperswithcode.com/paper/semi-supervised-sequence-modeling-with-c3)'
- en: '[One Model To Learn Them All](https://paperswithcode.com/paper/one-model-to-learn-them-all)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[一个模型学习所有任务](https://paperswithcode.com/paper/one-model-to-learn-them-all)'
- en: '[Learning General Purpose Distributed Sentence Representations via Large Scale
    Multi-task Learning](https://paperswithcode.com/paper/learning-general-purpose-distributed-sen3)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[通过大规模多任务学习学习通用分布式句子表示](https://paperswithcode.com/paper/learning-general-purpose-distributed-sen3)'
- en: '[A Hierarchical Multi-task Approach for Learning Embeddings from Semantic Tasks](https://paperswithcode.com/paper/a-hierarchical-multi-task-approach-for-l2)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[用于从语义任务中学习嵌入的分层多任务方法](https://paperswithcode.com/paper/a-hierarchical-multi-task-approach-for-l2)'
- en: '**Recommendation Systems**'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**推荐系统**'
- en: A recommendation system aim is to produce a list of recommendations for the
    user. A popular paper in this category is *[Training Deep AutoEncoders for Collaborative
    Filtering](https://paperswithcode.com/paper/training-deep-autoencoders-for-collabora2)*
    by Oleksii Kuchaiev and Boris Ginsburg. This paper suggests a novel model for
    the rating prediction task in recommender systems which significantly outperforms
    previous state-of-the art models on a time-split Netflix data set. The model is
    based on deep autoencoder with 6 layers and is trained end-to-end without any
    layer-wise pre-training. This is an NVIDIA research project in PyTorch with all
    the code used available for public use.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统的目标是为用户生成推荐列表。该领域的一个热门论文是*【训练深度自编码器用于协同过滤](https://paperswithcode.com/paper/training-deep-autoencoders-for-collabora2)*，作者是Oleksii
    Kuchaiev和Boris Ginsburg。这篇论文提出了一种新颖的模型用于推荐系统中的评分预测任务，该模型在时间切分的Netflix数据集上显著超越了以前的最先进模型。该模型基于6层的深度自编码器，并且是端到端训练的，没有任何逐层预训练。这是一个在PyTorch中进行的NVIDIA研究项目，所有使用的代码都可以公开使用。
- en: 'Other top papers on recommendation systems:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于推荐系统的其他顶级论文：
- en: '[fastFM: A Library for Factorization Machines](https://paperswithcode.com/paper/fastfm-a-library-for-factorization-mach2)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[fastFM：一个因式分解机库](https://paperswithcode.com/paper/fastfm-a-library-for-factorization-mach2)'
- en: '[AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural
    Networks](https://paperswithcode.com/paper/autoint-automatic-feature-interaction-l2)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[AutoInt：通过自注意力神经网络自动特征交互学习](https://paperswithcode.com/paper/autoint-automatic-feature-interaction-l2)'
- en: '[Product-based Neural Networks for User Response Prediction over Multi-field
    Categorical Data](https://paperswithcode.com/paper/product-based-neural-networks-for-user-r)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[基于产品的神经网络用于多字段类别数据的用户响应预测](https://paperswithcode.com/paper/product-based-neural-networks-for-user-r)'
- en: '[DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction](https://paperswithcode.com/paper/deepfm-an-end-to-end-wide-deep-learni2)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeepFM：一个端到端的广泛与深度学习框架用于CTR预测](https://paperswithcode.com/paper/deepfm-an-end-to-end-wide-deep-learni2)'
- en: Of course, we have just touched the surface on what *Papers with code* have
    to offer. We hope you love the site as much as we do!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们只是触及了*Papers with Code*提供的表面。我们希望你像我们一样喜欢这个网站！
- en: '**Resources:**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网页的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Multi-Task Learning – 3 Lessons Learned](https://www.kdnuggets.com/2019/02/deep-multi-task-learning.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度多任务学习——3个经验教训](https://www.kdnuggets.com/2019/02/deep-multi-task-learning.html)'
- en: '[How AI can help solve some of humanity’s greatest challenges – and why we
    might fail](https://www.kdnuggets.com/2019/02/ai-help-solve-humanity-challenges.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能如何帮助解决人类面临的一些重大挑战——以及我们可能失败的原因](https://www.kdnuggets.com/2019/02/ai-help-solve-humanity-challenges.html)'
- en: '[Artificial Intelligence and Data Science Advances in 2018 and Trends for 2019](https://www.kdnuggets.com/2019/02/ai-data-science-advances-trends.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能和数据科学在2018年的进展及2019年的趋势](https://www.kdnuggets.com/2019/02/ai-data-science-advances-trends.html)'
- en: '* * *'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业领域。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您所在组织的IT工作'
- en: '* * *'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题更多信息
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最先进的深度学习技术在可解释预测和现时预测中的应用](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Overview of PEFT: State-of-the-art Parameter-Efficient Fine-Tuning](https://www.kdnuggets.com/overview-of-peft-stateoftheart-parameterefficient-finetuning)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PEFT概述：最先进的参数高效微调](https://www.kdnuggets.com/overview-of-peft-stateoftheart-parameterefficient-finetuning)'
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，4月27日：论文与代码简介；…](https://www.kdnuggets.com/2022/n17.html)'
- en: '[A Brief Introduction to Papers With Code](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[论文与代码简介](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)'
- en: '[KDnuggets News, November 2: The Current State of Data Science…](https://www.kdnuggets.com/2022/n43.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，11月2日：数据科学的现状…](https://www.kdnuggets.com/2022/n43.html)'
- en: '[The Current State of Data Science Careers](https://www.kdnuggets.com/2022/10/current-state-data-science-careers.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学职业的现状](https://www.kdnuggets.com/2022/10/current-state-data-science-careers.html)'
