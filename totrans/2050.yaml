- en: Moving from Data Science to Machine Learning Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/11/moving-data-science-machine-learning-engineering.html](https://www.kdnuggets.com/2020/11/moving-data-science-machine-learning-engineering.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Caleb Kaiser](https://www.linkedin.com/in/caleb-kaiser-843249126/), Cortex
    Labs**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the last 20 years, machine learning has been about one question: Can we
    train a model to do *something*?'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '*Something*, of course, can be any task. Predict the next word in a sentence,
    recognize faces in a photo, generate a certain sound. The goal was to see if machine
    learning worked, if we could make accurate predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to decades of work by data scientists, we now have a lot of models that
    can do a lot of *somethings*:'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI’s GPT-2 (and now GPT-3) can generate passably human text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detection models like YOLOv5 (debates over the official version aside)
    can parse objects from 140 frames of video per second.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-to-speech models like Tacotron 2 can generate human-sounding speech.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The work being done by data scientists and ML researchers is incredible, and
    as a result, a second question has naturally arisen:'
  prefs: []
  type: TYPE_NORMAL
- en: '*What can we build with these models, and how can we do it?*'
  prefs: []
  type: TYPE_NORMAL
- en: This is notably *not* a data science question. This is an engineering question.
    To answer it, a new discipline has emerged—**machine learning engineering**.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning engineering is how machine learning gets applied to real-world
    problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The difference between data science and machine learning engineering can feel
    a little intangible at first, and so it’s helpful to look at a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. From image classification, to ML-generated catalogues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Image classification and keyword extraction are classic problems of computer
    vision and natural language processing, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Glisten.ai uses an ensemble of models trained for both tasks to create an API
    that extracts structured information from product images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/6ca61e8c409acbf26be082ab59e53552.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [TechCrunch](https://techcrunch.com/2020/03/13/glisten-uses-computer-vision-to-break-down-fashion-photos-to-their-styles-and-parts/)
  prefs: []
  type: TYPE_NORMAL
- en: The models themselves are impressive feats of data science. The Glisten API,
    however, is a feat of machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. From object detection, to poacher prevention
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Wildlife Protection Solutions is a small nonprofit that uses technology to
    protect endangered species. Recently, they upgraded their video monitoring system
    to incorporate an object detection model trained to recognize poachers. The model
    has already **doubled** its detection rate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/974b9d305cd8e25824fdb5538e9f510d.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Silverpond](https://silverpond.com.au/case-studies/wildlife-protection-solutions/)
  prefs: []
  type: TYPE_NORMAL
- en: Object detection models like YOLOv4 are successes of data science, and Highlighter—the
    platform WPS used to train their model—is an impressive data science tool. WPS’s
    poacher detection system, however, is a feat of machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. From machine translation to a COVID19 moonshot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine translation refers to the use of machine learning to “translate” data
    from one form to another—sometimes between human languages, and sometimes between
    entirely different formats.
  prefs: []
  type: TYPE_NORMAL
- en: 'PostEra is a medicinal chemistry platform that uses machine translation to
    “translate” a compound into an engineering blueprint. Currently, chemists are
    using the platform in an open source effort to find a treatment for COVID19:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/da91f979875c472ddfabed6adb359a85.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [PostEra](https://postera.ai/demo)
  prefs: []
  type: TYPE_NORMAL
- en: Developing a model that can translate a molecule into a series of “routes” (transformations
    to go from one molecule to another) is a feat of data science. Building the PostEra
    platform is a feat of machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. From text generation, to ML dungeon masters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenAI’s GPT-2 was, at the time of its release, the most powerful text generating
    model in history. At an insane 1.5 billion parameters, it represented a big step
    forward in transformer models.
  prefs: []
  type: TYPE_NORMAL
- en: 'AI Dungeon is a classic dungeon crawler with a twist: its dungeon master is
    actually GPT-2 fine tuned on text from choose your own adventure stories:'
  prefs: []
  type: TYPE_NORMAL
- en: Reddit find of the day ???? anyone else have any luck getting your dragon car
    insurance? [pic.twitter.com/TGQh3Tju89](https://t.co/TGQh3Tju89)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — AI Dungeon (@AiDungeon) [June 28, 2020](https://twitter.com/AiDungeon/status/1277352539101356032?ref_src=twsrc%5Etfw)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Training GPT-2 is a historic feat of data science. Building a dungeon crawler
    out of it is a feat of machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: All of these platforms stand on the shoulders of data science. They wouldn’t
    work if they couldn’t train a model for their tasks. But, in order to apply these
    models to real world problems, they need to be engineered into applications.
  prefs: []
  type: TYPE_NORMAL
- en: Put another way, **machine learning engineering is how the innovations of data
    science manifest outside of ML research**.
  prefs: []
  type: TYPE_NORMAL
- en: The central challenge machine learning engineering presents, however, is that
    it introduces an entirely new category of engineering problems—ones we don’t have
    easy answers for just yet.
  prefs: []
  type: TYPE_NORMAL
- en: What goes into machine learning engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At a high-level, we can say that machine learning engineering refers to all
    the tasks required to take a trained model and build production applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/bc362fdecef72165f6e6f46d8e6aab46.png)'
  prefs: []
  type: TYPE_IMG
- en: To make this more tangible, we can use a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go back to AI Dungeon, the ML-powered dungeon crawler. The game’s architecture
    is simple. Players input some text, the game makes a call to the model, the model
    generates a response, and the game displays it. The obvious way to build this
    is to deploy the model as a microservice.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, this should be similar to deploying any other web service. Wrap the
    model in an API with something like FastAPI, containerize it with Docker, deploy
    to a Kubernetes cluster, and expose it with a load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/10fd1a75ebccb83175d1fc2cf0f09284.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Cortex inference architecture](https://github.com/cortexlabs/cortex)
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, GPT-2 complicates things:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GPT-2 is huge**. The fully trained model is over 5 GB. In order to serve
    it, you need a cluster provisioned with large instance types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPT-2 is resource-intensive. **A single prediction can lock up a GPU for
    extended periods of time. Low latency is difficult to achieve, and a single instance
    cannot handle many requests at once.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPT-2 is expensive. **As a result of the above facts, deploying GPT-2 to
    production means that—assuming you have a decent amount of traffic—you will be
    running many large GPU instances, which gets expensive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you consider that the game had over 1 million players very quickly after
    releasing, these problems become more severe.
  prefs: []
  type: TYPE_NORMAL
- en: Writing a performant API, provisioning a cluster with GPU instances, using spot
    instances to optimize costs, configuring autoscaling for inference workloads,
    implementing rolling updates so that the API doesn’t crash every time they update
    the model—it’s a lot of engineering work, and this a *simple *ML application.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of common features—retraining, monitoring, multi-model endpoints,
    batch prediction, etc.—needed for many ML applications, each of which would raise
    the level of complexity significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Solving these problems is what a machine learning engineer (in conjunction with
    an ML platform team, depending on the org) does, and their job is made significantly
    harder by the fact that most tooling for working with machine learning was designed
    for data science, not engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, this is changing.
  prefs: []
  type: TYPE_NORMAL
- en: We’re building a platform for machine learning engineering—not data science
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A couple years ago, a few of us transitioned from software engineering to MLE.
    After spending weeks hacking data science workflows and writing glue code to make
    ML applications work, we started thinking about how we could apply software engineering
    principles to machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: For example, look at AI Dungeon. If they were building a normal API—one that
    didn’t involve GPT-2—they would use something like Lambda to spin up their API
    in 15 minutes. Because of the ML-specific challenges of serving GPT-2, however,
    orchestration tools from software engineering won’t work.
  prefs: []
  type: TYPE_NORMAL
- en: But, why shouldn’t the principles still apply?
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we started working on tools for machine learning engineering, tools that
    applied those principles. [Cortex, our open source API platform](https://github.com/cortexlabs/cortex),
    makes it as easy as possible for machine learning engineers to deploy models as
    APIs, using an interface that will be familiar to any software engineer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e47e923503717626044168af04548cc1.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Cortex repo](https://github.com/cortexlabs/cortex)
  prefs: []
  type: TYPE_NORMAL
- en: 'The API platform is actually what AI Dungeon—as well as every other ML startup
    listed above—used to deploy their models. The design philosophy behind it, and
    all of our work at Cortex, is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '**We treat the challenges of machine learning engineering as engineering—not
    data science—problems.**'
  prefs: []
  type: TYPE_NORMAL
- en: For the API platform, that means that instead of notebooks—which are difficult
    to version, rely on hidden state, and allow for arbitrary execution order—we use
    YAML and Python files. Instead of a GUI with a “Deploy” button, we built a CLI,
    through which you can actually manage deployments.
  prefs: []
  type: TYPE_NORMAL
- en: You can apply this philosophy to many of the challenges of using machine learning
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reproducibility, for example, isn’t only a challenge in machine learning. It’s
    a problem in software engineering too—but we use version control to solve it.
    And while traditional version control software like Git doesn’t work for machine
    learning, you can still apply the principles. DVC (Data Version Control), which
    applies Git-like version control to training data, code, and their resulting models,
    does just this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/ae50340a7a007cc895992da133fa5159.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [DVC](https://dvc.org/doc/use-cases/versioning-data-and-model-files)
  prefs: []
  type: TYPE_NORMAL
- en: And what about all those files of boilerplate and glue code needed to initialize
    a model and generate predictions? In software engineering, we’d design a framework
    for this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we’re seeing this happen in machine learning engineering too. Hugging
    Face’s Transformers library, for example, provides an easy interface for most
    popular transformer models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f0aa7a217fc5ec0e12d3653ba153e737.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [Hugging Face](https://huggingface.co/)
  prefs: []
  type: TYPE_NORMAL
- en: With those six lines of Python, you can download, initialize, and serve predictions
    from GPT-2, one of the most powerful text generating models. That’s six lines
    of Python to do something not even mature, well-funded teams could do three years
    ago.
  prefs: []
  type: TYPE_NORMAL
- en: What makes us so excited about this ecosystem—beyond the fact that we’re a part
    of it—is that it represents the bridge between decades of research into machine
    learning and the problems people face every day. Every time one of these projects
    removes a barrier to machine learning engineering, it becomes that much easier
    for a new team to solve a problem with machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: In the future, machine learning is going to become a part of every engineer’s
    stack. There will hardly be a problem ML doesn’t touch. The pace at which this
    occurs is entirely dependent on how quickly we can develop platforms like Cortex,
    and accelerate the proliferation of machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: If that is exciting to you too, [we’re always happy to welcome new contributors](https://github.com/cortexlabs).
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Caleb Kaiser](https://www.linkedin.com/in/caleb-kaiser-843249126/)**
    ([@KaiserFrose](https://twitter.com/KaiserFrose)) is on the founding team of Cortex
    Labs, where he helps maintain Cortex.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/moving-from-data-science-to-machine-learning-engineering-68916173eaf3).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to deploy PyTorch Lightning models to production](/2020/11/deploy-pytorch-lightning-models-production.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Engineer vs Data Scientist (Is Data Science Over?)](/2020/06/machine-learning-engineer-vs-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[You Don’t Have to Use Docker Anymore](/2020/10/use-docker-anymore.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[25 Free Courses to Master Data Science, Data Engineering, Machine…](https://www.kdnuggets.com/25-free-courses-to-master-data-science-data-engineering-machine-learning-mlops-and-generative-ai)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Collection of Free Courses to Learn Data Science, Data Engineering,…](https://www.kdnuggets.com/collection-of-free-courses-to-learn-data-science-data-engineering-machine-learning-mlops-and-llmops)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Practical Approach To Feature Engineering In Machine Learning](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 13: Linear Algebra for Data Science; 10 Modern…](https://www.kdnuggets.com/2022/n28.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Modern Data Engineering Tools](https://www.kdnuggets.com/2022/07/10-modern-data-engineering-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Complete Data Engineering Study Roadmap](https://www.kdnuggets.com/2022/11/complete-data-engineering-study-roadmap.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
