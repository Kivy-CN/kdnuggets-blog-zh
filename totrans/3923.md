# 为什么你的机器学习代码可能很糟糕的4个原因

> 原文：[https://www.kdnuggets.com/2019/02/4-reasons-machine-learning-code-probably-bad.html](https://www.kdnuggets.com/2019/02/4-reasons-machine-learning-code-probably-bad.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**作者：[诺曼·尼默](https://www.linkedin.com/in/normanniemer/)，首席数据科学家**

![](../Images/6d51fa847ff4f19caeef7e4e039566a7.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT管理

* * *

你当前的工作流程可能将几个函数串联在一起，如下例所示。虽然这种方法很快，但它可能存在许多问题：

+   随着复杂性的增加，它的扩展性较差

+   你必须手动跟踪哪些函数使用了哪些参数

+   你必须手动跟踪数据的保存位置

+   这让其他人很难阅读

```py
import pandas as pd
import sklearn.svm, sklearn.metrics

def get_data():
    data = download_data()
    data = clean_data(data)
    data.to_pickle('data.pkl')

def preprocess(data):
    data = apply_function(data)
    return data

# flow parameters
reload_source = True
do_preprocess = True

# run workflow
if reload_source:
    get_data()

df_train = pd.read_pickle('data.pkl')
if do_preprocess:
    df_train = preprocess(df_train)
model = sklearn.svm.SVC()
model.fit(df_train.iloc[:,:-1], df_train['y'])
print(sklearn.metrics.accuracy_score(df_train['y'],model.predict(df_train.iloc[:,:-1])))
```

### 该如何解决？

与线性链式函数不同，数据科学代码更适合写成一组任务，并且这些任务之间有依赖关系。也就是说，你的数据科学工作流程应该是一个DAG。

所以，与你编写一个执行以下操作的函数相比：

```py
def process_data(data, parameter):

    if parameter:
        data = do_stuff(data)
    else:
        data = do_other_stuff(data)

    data.to_pickle('data.pkl')
    return data
```

你最好编写可以串联在一起的任务，作为DAG来处理：

```py
class TaskProcess(d6tflow.tasks.TaskPqPandas): # define output format

    def requires(self):
        return TaskGetData() # define dependency

    def run(self):
        data = self.input().load() # load input data
        data = do_stuff(data) # process data
        self.save(data) # save output data
```

这样做的好处包括：

+   所有任务遵循相同的模式，无论你的工作流程多么复杂

+   你有一个可扩展的输入 `requires()` 和处理函数 `run()`

+   你可以快速加载和保存数据，而无需硬编码文件名

+   如果输入任务没有完成，它会自动运行

+   如果输入数据或参数发生变化，函数会自动重新运行

### 一个机器学习DAG的示例

以下是一个以DAG表示的机器学习流程的风格化示例。最终，你只需运行 TaskTrain()，它会自动知道需要运行哪些依赖项。有关完整示例，请参见 [https://github.com/d6t/d6tflow/blob/master/docs/example-ml.md](https://github.com/d6t/d6tflow/blob/master/docs/example-ml.md)

```py
import pandas as pd
import sklearn, sklearn.svm
import d6tflow
import luigi

# define workflow
class TaskGetData(d6tflow.tasks.TaskPqPandas):  # save dataframe as parquet

    def run(self):
        data = download_data()
        data = clean_data(data)
        self.save(data) # quickly save dataframe

class TaskPreprocess(d6tflow.tasks.TaskCachePandas):  # save data in memory
    do_preprocess = luigi.BoolParameter(default=True) # parameter for preprocessing yes/no

    def requires(self):
        return TaskGetData() # define dependency

    def run(self):
        df_train = self.input().load() # quickly load required data
        if self.do_preprocess:
            df_train = preprocess(df_train)
        self.save(df_train)

class TaskTrain(d6tflow.tasks.TaskPickle): # save output as pickle
    do_preprocess = luigi.BoolParameter(default=True)

    def requires(self):
        return TaskPreprocess(do_preprocess=self.do_preprocess)

    def run(self):
        df_train = self.input().load()
        model = sklearn.svm.SVC()
        model.fit(df_train.iloc[:,:-1], df_train['y'])
        self.save(model)

# Check task dependencies and their execution status
d6tflow.preview(TaskTrain())

'''
└─--[TaskTrain-{'do_preprocess': 'True'} (PENDING)]
   └─--[TaskPreprocess-{'do_preprocess': 'True'} (PENDING)]
      └─--[TaskGetData-{} (PENDING)]
'''

# Execute the model training task including dependencies
d6tflow.run(TaskTrain())

'''
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 TaskGetData()
    - 1 TaskPreprocess(do_preprocess=True)
    - 1 TaskTrain(do_preprocess=True)
'''

# Load task output to pandas dataframe and model object for model evaluation
model = TaskTrain().output().load()
df_train = TaskPreprocess().output().load()
print(sklearn.metrics.accuracy_score(df_train['y'],model.predict(df_train.iloc[:,:-1])))
# 0.9733333333333334
```

### 结论

将机器学习代码写成一系列线性函数可能会产生许多工作流程问题。由于不同机器学习任务之间的复杂依赖关系，最好将它们写成有向无环图（DAG）。 [https://github.com/d6t/d6tflow](https://github.com/d6t/d6tflow) 可以很容易地实现这一点。或者，你也可以使用 [luigi](https://github.com/spotify/luigi) 和 [airflow](https://airflow.apache.org/)，但它们更适合ETL而非数据科学。

**简介：[诺曼·尼默](https://www.linkedin.com/in/normanniemer/)** 是一家大型资产管理公司的首席数据科学家，在那里他提供数据驱动的投资洞察。他拥有哥伦比亚大学的金融工程硕士学位和伦敦卡斯商学院的银行与金融学士学位。

[原文](https://gist.github.com/d6tdev/44083e201104006b05be7f2ed5eeb5f9)。经许可转载。

**相关内容：**

+   [机器学习项目检查清单](/2018/12/machine-learning-project-checklist.html)

+   [初创公司数据科学项目流程](/2019/01/data-science-project-flow-startups.html)

+   [机器学习项目的端到端指南](/2019/01/end-to-end-guide-machine-learning-project.html)

### 更多相关主题

+   [成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应掌握的 6 种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021 年最佳 ETL 工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [使用管道编写清晰的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [停止学习数据科学以寻找目的，并通过寻找目的来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
