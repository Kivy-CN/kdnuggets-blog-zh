- en: Crop Disease Detection Using Machine Learning and Computer Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html](https://www.kdnuggets.com/2020/06/crop-disease-detection-computer-vision.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn), ZS New York
    AI Center of Excellence**'
  prefs: []
  type: TYPE_NORMAL
- en: International Conference on Learning Representations (ICLR) and Consultative
    Group on International Agricultural Research (CGIAR) jointly conducted a [challenge](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    where over 800 data scientists globally competed to detect diseases in crops based
    on close shot pictures. The objective of this challenge is to build a machine
    learning algorithm to correctly classify if a plant is healthy, has stem rust,
    or has leaf rust.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Wheat rust is a devastating plant disease affecting many crops, reducing yields
    and affecting the livelihoods of farmers and decreasing food security across Africa.
    The disease is difficult to monitor at a large scale, making it difficult to control
    and eradicate. An accurate image recognition model that can detect wheat rust
    from any image will enable a crowd-sourced approach to monitor crops.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The imagery data came from a variety of sources. The bulk of the data was collected
    in-field by International Maize and Wheat Improvement Center ([CIMMYT](https://www.cimmyt.org/))
    and their partners in Ethiopia and Tanzania. The remainder of the data were sourced
    from public images found on Google Images. For this challenge, external data,
    other than the data provided, was prohibited. Below are a few examples of data
    by category viz., healthy wheat, leaf rust and stem rust.
  prefs: []
  type: TYPE_NORMAL
- en: Healthy wheat
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f152ee4e2a672c6878282994bcdc7eb6.png)'
  prefs: []
  type: TYPE_IMG
- en: Leaf rust
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/1c4d05b37984b6c1b8753aa42a214d31.png)'
  prefs: []
  type: TYPE_IMG
- en: Stem rust
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/79d22c1450c08fbfb4ff82378cbc9d5c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1\. Sample images of different categories**'
  prefs: []
  type: TYPE_NORMAL
- en: There were 876 images in the data that were provided to train the AI model (142
    healthy, 358 leaf rust and 376 stem rust). The test data on which the final performance
    would be measured, had 610 images and their labels were not revealed to the participants
  prefs: []
  type: TYPE_NORMAL
- en: Methodology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The state of the art approach for determining a plant’s health based on pictures
    is a type of deep learning called Convolutional Neural Network ([CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)).
    The overall modeling process required several steps for effectively preparing
    the data for the CNN model to yield a good result. Figure 2 below illustrates
    the detailed set of steps involved.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/76522f67abe91265c5480c2bc8a2199b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2\. Model Pipeline**'
  prefs: []
  type: TYPE_NORMAL
- en: Of the various steps in the pipeline, Data Augmentation particularly played
    a significant role in increasing the model performance. We used multiple data
    augmentation techniques -illustrated below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/66a72d0df3223327852648b549ef3114.png)'
  prefs: []
  type: TYPE_IMG
- en: '**a. Vertical and Horizontal Flip**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/66a72d0df3223327852648b549ef3114.png)'
  prefs: []
  type: TYPE_IMG
- en: '**b. Lighting standardization**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/331d9fd11ff318b8e24337fd64df2b6a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**c. Zoom and Crop**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/0e26a9dcb0dc6154b8cd486b1c09f709.png)![Figure](../Images/f77b3def7e9cc27b180629433d112363.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3\. Data augmentation illustration**'
  prefs: []
  type: TYPE_NORMAL
- en: The next critical step is the CNN model architecture design. We used [transfer
    learning](https://en.wikipedia.org/wiki/Transfer_learning) to build on the existing
    [ImageNet](http://www.image-net.org/) models. While there are multiple pre-trained
    models available (viz., VGG, ResNet, InceptionV3, DenseNet, EfficientNet, etc.)
    we chose [DenseNet201](https://www.kaggle.com/pytorch/densenet201) for its lower
    complexity, fewer parameters and cost-effective computation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/9b59e849c35984083589dd4bc5ae7885.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 4\. DenseNet201 model architecture**'
  prefs: []
  type: TYPE_NORMAL
- en: We tuned the model, along with different data augmentation methods iteratively
    before we achieved our final performance. For reference, we show how the model
    performance has evolved over the iterations in Figure 5.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/1b124886c32e7916d0f07d82ea1916dd.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 5\. Model performance over iterations**'
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our final score was a log loss of 0.288 on the test dataset ranking 53^(rd)
    on the [final leaderboard](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    among 839 participants. Over the test sample of 610 images, this translated to
    approximately 580 correctly classified instances – in other words, the model accuracy
    is 95%. This is quite good for practical usage and considering that we trained
    only on the limited competition dataset, the accuracy can be further improved
    by adding more data points.
  prefs: []
  type: TYPE_NORMAL
- en: Performance is great but, [what] has the model learnt?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**a. Model explanations**'
  prefs: []
  type: TYPE_NORMAL
- en: Outside of competition setting, if we expect our model to be used in practical
    applications, it is important to explain why the model classified a given image.
    We explored a few examples using an explainable AI technique called Gradient-weighted
    Class Activation Map (Grad-CAM) to highlight the areas of images that the model
    based its decision on. Figure 6 illustrates a couple examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Leaf Rust: Original Image (Left) and Grad-CAM Heatmap Image (Right)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/d60821983ec7ad8c1c91b022893db7c1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Stem Rust: Original Image (Left) and Grad-CAM Heatmap Image (Right)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/4e4828a96bc8973466d35ba1c840b7b2.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 6\. Explaining model predictions using Grad-CAM**'
  prefs: []
  type: TYPE_NORMAL
- en: From the explanation, we can see that the model managed to latch on to the rust
    portions of leaf and stem to accurately classify the category.
  prefs: []
  type: TYPE_NORMAL
- en: '**b. Inferring how the models see the different classes using Deep Dream**'
  prefs: []
  type: TYPE_NORMAL
- en: One way to visualize what the model has learnt is to turn the network upside
    down and ask it to enhance an input image in such a way as to elicit an output
    class. Say you want to know what sort of image would result in “Banana”, start
    with an image full of random noise, then gradually tweak the image towards what
    the neural net considers a banana. This is called Deep Dream
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/48f343a79fab473ab89fe078e91d94de.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 7\. An Example to let trained model generate Image for Class Banana**'
  prefs: []
  type: TYPE_NORMAL
- en: We applied the deep dream approach on our model and generated the figures for
    the respective classes. The below figures each specify what the model thinks in
    general an image looks like for a respective class.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f17acab9a85e050f6ec1be0c7108733f.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 8\. Deep Dream Results for all classes based on our model**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We notice for different classes, our model has found important distinguishing
    patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Healthy Wheat: Major color is green, has leaf-like features, no rust-related
    colors such as yellow/orange'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Leaf Rust: Has mixture of colors, has leaf-like pattern and there are rust-related
    colors (yellow/orange) on leaf-like pattern'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stem Rust: Has tube-like pattern and there are rust-related colors (yellow/orange)
    on tube-like pattern'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we have shown how deep learning techniques can be applied to
    detect wheat rust in crops based on close shot images. In addition to good prediction
    accuracy, we have also demonstrated that the model is able to effectively learn
    the right representations through the explanations inferred from class activation
    maps. When scaled, this approach can help in digitally monitoring crop health
    and could lead to significant improvement in the agriculture productivity and
    yield.
  prefs: []
  type: TYPE_NORMAL
- en: The ZS AI team ranked in the top 6% on the [final leaderboard](https://zindi.africa/competitions/iclr-workshop-challenge-1-cgiar-computer-vision-for-crop-disease/leaderboard)
    with a prediction accuracy of 95%.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Srinivas Chilukuri](https://in.linkedin.com/in/srinivascsn)** leads
    the ZS New York AI Center of Excellence. He has 15+ years of experience in helping
    clients across industries in designing and implementing AI solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Satellite Image Analysis with fast.ai for Disaster Recovery](/2020/05/satellite-image-analysis-fast-ai-disaster-recovery.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using AI to Identify Wildlife in Camera Trap Images from the Serengeti](/2020/02/using-ai-identify-wildlife-images-serengeti.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning in Agriculture: Applications and Techniques](/2019/05/machine-learning-agriculture-applications-techniques.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
