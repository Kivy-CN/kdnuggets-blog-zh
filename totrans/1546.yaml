- en: How to Capture Data to Make Business Impact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/03/capture-data-make-business-impact.html](https://www.kdnuggets.com/2019/03/capture-data-make-business-impact.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Ramon Serrallonga](https://www.linkedin.com/in/ramonserrallonga/)**'
  prefs: []
  type: TYPE_NORMAL
- en: Every business challenge that is to be solved with a data-driven decision has
    a data universe behind it. This data universe is the set of data that could be
    captured that is linked to the business challenge.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Universe](../Images/05be627fc551e402034426cd01c328ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A data universe is formed by information and noise: Information is data that
    can be transformed into knowledge; noise is data from which no knowledge can be
    extracted (of course, noise data can also be treated and lead to “findings” which
    are false knowledge and not truly useful). Note that data being noise or information
    depends on the business challenge under discussion. In other words, the same datum
    could be noise in one business case and information in another.'
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth mentioning that nobody would collect noise data knowingly,
    i.e., noise data are utilized unwittingly. The reason is that differentiating
    noise and information could be very easy in some cases but not in others.
  prefs: []
  type: TYPE_NORMAL
- en: An example illustrates this well.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the article *[Analítica Predictiva en La Liga Santander](https://www.linkedin.com/pulse/anal%C3%ADtica-predictiva-en-la-liga-santander-%E5%B8%AD%E6%B0%B8%E5%98%89-ramon-serrallonga/)*,
    prescriptive analytics were applied in the Spanish major soccer tournament to
    classify higher. Consider the historic data set of ice cream consumption in Madagascar:
    It would be next to common sense that this data has no relevance in this sports
    case so is clearly noise. But notice that only data from 1995 on is used. Indeed,
    there was data since 1975\. So why the full record was not used? In the season
    1995-1996, Spain adopted the rule of giving 3 points by won match instead of just
    2\. A [Chow test](https://en.wikipedia.org/wiki/Chow_test) was run to see if that
    affected the team’s behavior. And it tested positive. So, data from 1975 to 1994
    was noise and not information. In this case, noticing it requested from a deep
    knowledge of the underlying field of study (and a bit of luck too).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Capturing noise has a side effect: the more noise we store, the more difficult
    it is to find information in the captured data. It is like a needle (information)
    in a haystack (noise). Even if we would easily tell the difference between a needle
    and thatch, it could be very difficult to recognize the needle if it is surrounded
    by a big amount of thatch. The Big Data rule-of-thumb of storing as much data
    as you can and for as large longitude as possible would be a false friend.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we introduce a metric to quantify the efficiency of our data capturing efforts,
    it should follow these two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: The more information we capture, the more efficient we are.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The less noise we capture, the more efficient we are.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, written in a formula it could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Efficiency Formula Figure 1](../Images/dd6c82e61ab8afbcf4392e1f902a0ea3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Rearranging the terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Efficiency Formula Figure 2](../Images/ff9168ac7a560d7b079500f023ca8561.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We could agree that (1) the more captured information we have, the more accurate
    we can be in our data treatments, and that (2) the less noise we capture, the
    more effective our data capturing efforts are. Substituting the terms, the equation
    would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Efficiency Formula Figure 3](../Images/77394a68d8efb5f6ef1efdbbb0db89c6.png)'
  prefs: []
  type: TYPE_IMG
- en: In the optimal case where all captured data is and only is information, *Efficiency*
    would take the value of 1\. The value would be between 0 and 1 when some information
    and some noise is captured. And interestingly, *Efficiency* tends to be 0 as we
    try to capture all data from the data universe even if all information is contained
    in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with our example *[Analítica Predictiva en La Liga Santander](https://www.linkedin.com/pulse/anal%C3%ADtica-predictiva-en-la-liga-santander-%E5%B8%AD%E6%B0%B8%E5%98%89-ramon-serrallonga/)*,
    we could now calculate the efficiency of the data set used. The overall accuracy
    of the model was 91%. We could take this value as a proxy for the percentage of
    information captured. On the other hand, we know with certainty which data we
    used for the treatment from the total available. So, we could calculate it as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Efficiency Formula Figure 4](../Images/f9c4a694819342a6b0b815b342c46e64.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we have a definition for efficiency, we can introduce a new concept,
    Smart Data. In IoT, smart Data is often described as data coming from smart sensors.
    Some others define it as Big Data that has been cleansed, filtered, and prepared
    for analysis. There is no agreed definition for “Smart Data.” But I would like
    to define “smart data” as efficient data. The higher the efficiency, the smarter
    data is. Regardless of the source or cleaning process of the data, the highest
    efficiency (or “smartness”) of the data is 100%.
  prefs: []
  type: TYPE_NORMAL
- en: How can we make data capturing more efficient and only store Smart Data?
  prefs: []
  type: TYPE_NORMAL
- en: It is common to see Big Data initiatives as sequential by technology. Each task
    is independent and follows one another and finding the insights to solve the business
    challenge is the last task.
  prefs: []
  type: TYPE_NORMAL
- en: '![Smart Data](../Images/a9bac4735f5022e52a50c6911895892e.png)'
  prefs: []
  type: TYPE_IMG
- en: If there is no good communication between the parts, it is likely that not all
    the data generated will be information, which reduces *Accuracy*, and that not
    all the data stored will be information, which lowers *Efficacy*. This way, finding
    insights in the data is challenging and, as reported by [Gartner](https://www.linkedin.com/company/gartner/),
    [leads to a 60-85% failure rate of Big Data projects](https://twitter.com/nheudecker/status/928739138169221120).
  prefs: []
  type: TYPE_NORMAL
- en: To optimize data capturing, any Big Data initiative must be an iterative process
    guided by the business needs. Different teams must communicate and collaborate
    closely to iteratively develop a solution around the business challenge. Bring
    in the analytics team early to help the IoT team capture data in the way that
    the data will be used. Separate information from noise in the existing data to
    improve *Efficacy*. Capture feasible data that the analytics team thought was
    unachievable and IoT team thought was irrelevant to increase *Accuracy*.
  prefs: []
  type: TYPE_NORMAL
- en: It is commonly said that data scientists spend 80% of their time cleaning data
    and only 20% analyzing it. With an efficient data capturing, Smart Data can rewrite
    the story where data scientists spend just 20% of their time cleaning data and
    80% getting insights that truly makes a business impact.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio**: [Ramon Serrallonga](https://www.linkedin.com/in/ramonserrallonga/)
    is the Chief Data Officer of Cadifornia, Academic Assistant at ESADE Business
    & Law School, and Lecturer at EAE Business School. Economist, Master in Law, and
    MBA, his career has been developed in the intersection between business and technology.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Overcoming distrust on the path to productive analytics](https://www.kdnuggets.com/2019/03/overcoming-distrust-path-productive-analytics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Securing your future in big data](https://www.kdnuggets.com/2019/03/ntu-online-mba-data-analytics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Active Blogs on AI, Analytics, Big Data, Data Science, Machine Learning
    – updated](https://www.kdnuggets.com/2019/01/active-blogs-ai-analytics-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[From Data Analyst to Data Strategist: The Career Path for Making an Impact](https://www.kdnuggets.com/2023/05/data-analyst-data-strategist-career-path-making-impact.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Use Data Visualization to Add Impact to Your Work Reports…](https://www.kdnuggets.com/2022/08/data-visualization-add-impact-work-reports-presentations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IMPACT 2022: The Data Observability Summit, on Oct. 25-26](https://www.kdnuggets.com/2022/09/monte-carlo-impact-2022-data-observability-summit.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[IMPACT: The Data Observability Summit is back November 8th and the…](https://www.kdnuggets.com/2023/10/monte-carlo-impact-the-data-observability-summit-is-back)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Monte Carlo is Kicking Off IMPACT 2023, Keynotes From Data & AI Pioneers](https://www.kdnuggets.com/2023/11/monte-carlo-is-kicking-off-impact-2023-keynotes-from-data-ai-pioneers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Base Rate Fallacy and its Impact on Data Science](https://www.kdnuggets.com/2023/04/base-rate-fallacy-impact-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
