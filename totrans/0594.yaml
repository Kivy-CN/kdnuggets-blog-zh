- en: 'DINOv2: Self-Supervised Computer Vision Models by Meta AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DINOv2：Meta AI的自监督计算机视觉模型
- en: 原文：[https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/4aed096f2f8f55aecaf8fd2ae15116b7.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![DINOv2：Meta AI的自监督计算机视觉模型](../Images/4aed096f2f8f55aecaf8fd2ae15116b7.png)'
- en: Image from Bing Image Creator
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自Bing图片创作者
- en: Meta AI has just released open-source **DINOv2 models** the first method that
    uses self-supervised learning to train computer vision models. The DINOv2 models
    achieve results that match or are even better than the standard approach and models
    in the field.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Meta AI刚刚发布了开源的**DINOv2模型**，这是第一个利用自监督学习来训练计算机视觉模型的方法。DINOv2模型实现了与该领域标准方法和模型相匹配甚至更优的结果。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The models achieved strong performance without the need to fine-tune which makes
    a perfect choice for many different computer vision tasks and applications. DINOv2
    can learn from various collections of images and features such as depth estimation
    without the need for explicit training thanks to the self-supervised training
    method.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型在无需微调的情况下取得了强大的性能，使其成为许多不同计算机视觉任务和应用的理想选择。由于自监督训练方法，DINOv2可以从各种图像和特征集合中学习，例如深度估计，而无需显式的训练。
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/e00ff5643fe40dad69f9071451809fbf.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![DINOv2：Meta AI的自监督计算机视觉模型](../Images/e00ff5643fe40dad69f9071451809fbf.png)'
- en: 'Figure 1: DINOv2: Self-Supervised Computer Vision Models by Meta AI'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：DINOv2：Meta AI的自监督计算机视觉模型
- en: 1\. The Need for Self-Surprised Learning
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 自监督学习的需求
- en: 1.1\. No fine-tuning is required
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1\. 无需微调
- en: Self-supervised learning is a powerful method used to train machine learning
    models without the need for large amounts of labeled data. DINOv2 models can be
    trained on image corpus without the need for related metadata, specific hashtag,
    or image caption. DinoV2 models, unlike several recent self-supervised learning
    approaches, do not necessitate fine-tuning, thus producing high-performance features
    for different computer vision applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习是一种强大的方法，用于在没有大量标记数据的情况下训练机器学习模型。DINOv2模型可以在图像语料库上进行训练，而不需要相关的元数据、特定的标签或图像标题。与几种最近的自监督学习方法不同，DinoV2模型不需要微调，因此能够为不同的计算机视觉应用提供高性能的特征。
- en: 1.2\. Overcoming human annotation limitations
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2\. 克服人工注释的局限性
- en: Over the past few years, [image-text pre-training](https://arxiv.org/pdf/2210.09263.pdf)
    has become the predominant method for various computer vision applications. However,
    due to its dependence on human-labeled captions to learn the semantic meaning
    of images. This approach often overlooks crucial information that is not explicitly
    included in those captions. For example, a human label caption of a picture of
    a red table in a yellow room might be “A red wooden table”. This caption will
    miss some important information about the background, the position, and the size
    of the table. This will cause a lack of understanding of local information and
    will result in poor performance on tasks that require detailed localization information.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，[图像-文本预训练](https://arxiv.org/pdf/2210.09263.pdf)已成为各种计算机视觉应用的主要方法。然而，由于其依赖于人工标注的标题来学习图像的语义，这种方法往往忽视了标题中未明确包含的重要信息。例如，一张黄房间里的红色桌子的图片的人类标签可能是“一个红色木桌子”。这个标签会遗漏背景、位置和桌子大小等重要信息。这会导致对局部信息的理解不足，从而在需要详细定位信息的任务中表现不佳。
- en: Also, the need for human labels and annotation will limit the amount of data
    that we can collect to train the models. This becomes much harder for certain
    applications for example annotating a cell requires a certain level of human expertise
    that will not be available at the scale required. Using a self-supervised training
    approach on cellular imagery opens the way for a more foundational model and as
    a result, will improve [biological discovery](https://arxiv.org/pdf/2209.07819.pdf).
    The same applies to similar advanced fields as the estimation of [animal density](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS1574954122001844&h=AT2tgMG2np9tKP9LiOPVXwDdkQAlcdDjdBj3xzNdDNvurZkHdzEwyCtKds5-08oeQcJISJklzVm6wKOElXMj9jnYGtK8GAmLPJtKJ4NNNF31w2aj0Nnl5hLcOrMZWWZpZyM).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对人工标签和注释的需求将限制我们收集数据以训练模型的数量。这在某些应用中变得更加困难，例如，注释细胞需要一定水平的人类专业知识，而这种专业知识在所需规模上无法获得。对细胞图像使用自监督训练方法，为基础模型的进一步发展打开了途径，从而改善了[生物发现](https://arxiv.org/pdf/2209.07819.pdf)。同样，类似的高级领域，如[动物密度估计](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS1574954122001844&h=AT2tgMG2np9tKP9LiOPVXwDdkQAlcdDjdBj3xzNdDNvurZkHdzEwyCtKds5-08oeQcJISJklzVm6wKOElXMj9jnYGtK8GAmLPJtKJ4NNNF31w2aj0Nnl5hLcOrMZWWZpZyM)也适用。
- en: Moving from DINO to DINOv2 required overcoming several challenges such as
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从DINO到DINOv2的过渡需要克服多个挑战，如
- en: Creating a large and curated training dataset
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个大型且经过整理的训练数据集
- en: Improving the training algorithm and implementation
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进训练算法和实现
- en: Designing a functional distillation pipeline.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个有效的蒸馏流程。
- en: 2\. From DINO to DINOv2
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 从DINO到DINOv2
- en: '![DINOv2: Self-Supervised Computer Vision Models by Meta AI](../Images/6fab47982db50fa2316c10a565e7eb3c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![DINOv2: Meta AI的自监督计算机视觉模型](../Images/6fab47982db50fa2316c10a565e7eb3c.png)'
- en: 'Figure 2: DINO v1 Vs v2 comparison of segmentation precision'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：DINO v1与v2在分割精度上的比较
- en: 2.1\. Creating a large, curated, and diverse image dataset
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. 创建一个大型、整理过的、多样化的图像数据集
- en: One of the main steps to building the DINOv2 is to train larger architectures
    and models to enhance the model's performance. However, larger models require
    large datasets to be efficiently trained. Since there were no large datasets available
    that meet the requirements researchers leveraged publicly crawled web data and
    built a pipeline to select only useful data as in [LASER](https://ai.facebook.com/blog/laser-multilingual-sentence-embeddings/).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 构建DINOv2的主要步骤之一是训练更大的架构和模型，以提升模型的性能。然而，更大的模型需要大量的数据集才能高效训练。由于没有满足要求的大型数据集，研究人员利用公开抓取的网络数据，建立了一个只选择有用数据的流程，如在[LASER](https://ai.facebook.com/blog/laser-multilingual-sentence-embeddings/)中所示。
- en: 'However, two main tasks should be done to be able to use these datasets:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了能够使用这些数据集，需要完成两个主要任务：
- en: Balance the data across different concepts and tasks
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同概念和任务之间平衡数据
- en: Remove irrelevant images
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除无关的图像
- en: As this task can be accomplished manually, they curated a set of seed images
    from approximately 25 third-party datasets and expanded it by fetching images
    that are closely related to those seed images. This approach allowed them to produce
    a pertaining dataset of a total of 142 million images out of 1.2 billion images.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个任务可以手动完成，他们从大约25个第三方数据集中整理出了一组种子图像，并通过获取与这些种子图像紧密相关的图像来扩展它。这个方法使他们能够从12亿张图像中生成总共1.42亿张相关图像的数据集。
- en: 2.2\. Algorithmic and technical improvements
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. 算法和技术改进
- en: Although using larger models and datasets will lead to better results it comes
    with major challenges. Two of the main challenges are potential instability and
    remaining tractable during training. To make the training more stable DINOv2 includes
    additional regularization methods which were inspired by [similarity search](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F1806.03198&h=AT24VgJn3tbvHSzZQuScS7olEVE3k0ON36WLWv1MIwGvSVDzbGuRHljJq9PcTTD8B8E6JJ6TJcSlk7oKjUhlKM8azoaXKfbckLW-3dYD3G0nL6APxji3pnAGEO9AEF6-1eg)
    and [classification](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F2204.07118&h=AT0uq-EmQFlt_8QbvXmuLC9n7uqnix4IkQwsreJ9VO7xBtPZtlH06fddPmcB4kW_8RLWfSJJXwhfJBUNgLyn_HlgctcwgUYNZyNDSAxpDaz4ZQ1NJihZdK7v_-_o9D3q_1U)
    literature.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用更大的模型和数据集会带来更好的结果，但这也带来了主要挑战。两个主要的挑战是潜在的不稳定性和在训练过程中保持可处理性。为了使训练过程更稳定，DINOv2
    包含了额外的正则化方法，这些方法的灵感来源于[相似性搜索](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F1806.03198&h=AT24VgJn3tbvHSzZQuScS7olEVE3k0ON36WLWv1MIwGvSVDzbGuRHljJq9PcTTD8B8E6JJ6TJcSlk7oKjUhlKM8azoaXKfbckLW-3dYD3G0nL6APxji3pnAGEO9AEF6-1eg)
    和 [分类](https://l.facebook.com/l.php?u=https%3A%2F%2Farxiv.org%2Fabs%2F2204.07118&h=AT0uq-EmQFlt_8QbvXmuLC9n7uqnix4IkQwsreJ9VO7xBtPZtlH06fddPmcB4kW_8RLWfSJJXwhfJBUNgLyn_HlgctcwgUYNZyNDSAxpDaz4ZQ1NJihZdK7v_-_o9D3q_1U)
    文献。
- en: The training process of DINOv2 integrates the latest mixed-precision and distributed
    training implementations provided by the cutting-edge [PyTorch 2](https://l.facebook.com/l.php?u=https%3A%2F%2Fpytorch.org%2F&h=AT2AFAD7WXt6mwgAVGfHVYaqGLTztSUIiS8u9jHa6TcCViFrqmD0_RBFUkSTCKnRMBwqV3wn9nifClNi5aajRuwy6BHIADrrN5ecjMhzyZ9PFcYF2b_5IkDmi1hPLAYyb6o).
    This allowed faster implementation of the codes and using the same hardware for
    training DINO models resulted in double the speed and a third of the memory usage
    which allowed scaling in data and model size.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: DINOv2 的训练过程整合了最新的混合精度和分布式训练实现，这些实现由前沿的[PyTorch 2](https://l.facebook.com/l.php?u=https%3A%2F%2Fpytorch.org%2F&h=AT2AFAD7WXt6mwgAVGfHVYaqGLTztSUIiS8u9jHa6TcCViFrqmD0_RBFUkSTCKnRMBwqV3wn9nifClNi5aajRuwy6BHIADrrN5ecjMhzyZ9PFcYF2b_5IkDmi1hPLAYyb6o)
    提供。这使得代码的实现速度更快，并且使用相同的硬件进行 DINO 模型的训练使速度提高了一倍，内存使用减少到三分之一，从而实现了数据和模型规模的扩展。
- en: 2.3\. Decreasing inference time using models distillation
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3\. 通过模型蒸馏减少推理时间
- en: Running large models in inference requires powerful hardware which will limit
    the practical use of the methods for different use cases. To overcome this problem,
    researchers used model distillation to compress the knowledge of the large models
    into smaller ones. By utilizing this approach, researchers were able to condense
    high-performance architectures into smaller ones with negligible performance costs.
    This resulted in strong ViT-Small, ViT-Base, and ViT-Large models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行大型模型进行推理需要强大的硬件，这将限制这些方法在不同用例中的实际应用。为了解决这个问题，研究人员使用了模型蒸馏技术，将大型模型的知识压缩到较小的模型中。通过这种方法，研究人员能够将高性能的架构浓缩成更小的模型，性能损失几乎可以忽略。这产生了强大的
    ViT-Small、ViT-Base 和 ViT-Large 模型。
- en: 3\. Getting Started with DINOv2
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 开始使用 DINOv2
- en: 'The training and evaluation code requires PyTorch 2.0 and [xFormers](https://github.com/facebookresearch/xformers)
    0.0.18 as well as many other 3rd party packages and also the code expects a Linux
    environment. The following instructions outline how to configure all necessary
    dependencies for training and evaluation purposes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和评估代码需要 PyTorch 2.0 和 [xFormers](https://github.com/facebookresearch/xformers)
    0.0.18 以及许多其他第三方包，并且代码需要在 Linux 环境下运行。以下指令概述了如何配置所有必要的依赖项以进行训练和评估：
- en: Install PyTorch using the instruction [here](https://pytorch.org/get-started/locally/).
    It is advised to install PyTorch with CUDA support.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下指令安装 PyTorch [here](https://pytorch.org/get-started/locally/)。建议安装支持 CUDA
    的 PyTorch。
- en: Download [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载 [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html)
- en: 'Clone the DINOv2 repository using the following command:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下命令克隆 DINOv2 仓库：
- en: Code by Author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: 'Proceed to create and activate a Conda environment named "dinov2" using the
    provided environment definition:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续创建并激活名为 "dinov2" 的 Conda 环境，使用提供的环境定义：
- en: Code by Author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: To install the dependencies required for this project, utilize the provided
    requirements.txt file.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要安装本项目所需的依赖项，请使用提供的 requirements.txt 文件。
- en: Code by Author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: 'Finally, you can load the models using the code below:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，你可以使用以下代码加载模型：
- en: Code by Author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: In conclusion, the release of DINOv2 models by Meta AI marks a significant milestone.
    The self-supervised learning approach used by DINOv2 models provides a powerful
    way to train machine learning models without the need for large amounts of labeled
    data. With the ability to achieve high accuarcy without the demand for fine-tuning,
    these models are suitable for various computer vision tasks and applications.
    Moreover, DINOv2 can learn from different collections of images and can learn
    from features such as depth estimation without explicit training. The availability
    of DINOv2 as an open-source model opens the doors for researchers and developers
    to explore new possibilities in computer vision tasks and applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Meta AI发布的DINOv2模型标志着一个重要的里程碑。DINOv2模型采用的自监督学习方法提供了一种强大的方式来训练机器学习模型，无需大量标记数据。通过在不需要精调的情况下实现高准确率，这些模型适用于各种计算机视觉任务和应用。此外，DINOv2可以从不同的图像集合中学习，并且可以从诸如深度估计等特征中学习，而无需明确的训练。DINOv2作为开源模型的可用性为研究人员和开发者探索计算机视觉任务和应用的新可能性打开了大门。
- en: References
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[DINOv2: State-of-the-art computer vision models with self-supervised learning](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2：具有自监督学习的最先进计算机视觉模型](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)'
- en: '[DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2：无监督学习鲁棒视觉特征](https://arxiv.org/abs/2304.07193)'
- en: '**[Youssef Rafaat](https://www.linkedin.com/in/youssef-hosni-b2960b135)** is
    a computer vision researcher & data scientist. His research focuses on developing
    real-time computer vision algorithms for healthcare applications. He also worked
    as a data scientist for more than 3 years in the marketing, finance, and healthcare
    domain.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Youssef Rafaat](https://www.linkedin.com/in/youssef-hosni-b2960b135)** 是一位计算机视觉研究员和数据科学家。他的研究重点是为医疗保健应用开发实时计算机视觉算法。他还在市场营销、金融和医疗保健领域担任数据科学家超过3年。'
- en: More On This Topic
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow在计算机视觉中的应用 - 转移学习简化](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索计算机视觉的世界：介绍MLM最新的…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的5个应用](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于数据管理的6件事及其重要性…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 2022年3月9日：5分钟内构建机器学习网络应用…](https://www.kdnuggets.com/2022/n10.html)'
- en: '[Meta’s New Data Analyst Professional Certification Has Dropped!](https://www.kdnuggets.com/metas-new-data-analyst-professional-certification-has-dropped)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Meta 新的数据分析师专业认证已推出！](https://www.kdnuggets.com/metas-new-data-analyst-professional-certification-has-dropped)'
