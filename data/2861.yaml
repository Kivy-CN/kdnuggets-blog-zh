- en: 'Research Guide: Advanced Loss Functions for Machine Learning Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 研究指南：用于机器学习模型的高级损失函数
- en: 原文：[https://www.kdnuggets.com/2019/11/research-guide-advanced-loss-functions-machine-learning-models.html](https://www.kdnuggets.com/2019/11/research-guide-advanced-loss-functions-machine-learning-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/11/research-guide-advanced-loss-functions-machine-learning-models.html](https://www.kdnuggets.com/2019/11/research-guide-advanced-loss-functions-machine-learning-models.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[comments](#comments)'
- en: In addition to good training data and the right model architecture, loss functions
    are one of the most important parts of training an accurate machine learning model.
    For this post, I’d love to give developers an overview of some of the more advanced
    loss functions and how they can be used to improve the accuracy of models—or solve
    entirely new tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 除了良好的训练数据和正确的模型架构，损失函数是训练准确机器学习模型的最重要部分之一。在这篇文章中，我希望给开发者概述一些更高级的损失函数及其如何用来提高模型的准确性，或者解决全新的任务。
- en: For example, [semantic segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc) models
    typically use a simple cross-categorical entropy loss function during training,
    but if we want to segment objects with many fine details like hair, adding a gradient
    loss function to the model can vastly improve results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[语义分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc)模型在训练过程中通常使用简单的交叉类别熵损失函数，但如果我们想分割具有许多细节的对象，如头发，向模型中添加梯度损失函数可以显著改善结果。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This is just one example—the following guide explores research centered on a
    variety of advanced loss functions for machine learning models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个例子——以下指南探讨了围绕各种高级损失函数进行的研究。
- en: Robust Bi-Tempered Logistic Loss Based on Bregman Divergences
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于布雷格曼散度的鲁棒双温度逻辑回归损失
- en: Logistic loss functions don’t perform very well during training when the data
    in question is very noisy. Such noise can be caused by outliers and mislabeled
    data. In this paper, Google Brain authors aim to solve the shortcomings of the
    logistic loss function by replacing the logarithm and exponential functions with
    their corresponding “tempered” versions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据非常嘈杂时，逻辑回归损失函数在训练过程中表现不佳。这种噪声可能是由异常值和标记错误的数据造成的。在这篇论文中，谷歌大脑的作者通过用其对应的“温和”版本替换对数和指数函数，旨在解决逻辑回归损失函数的不足。
- en: '[**Bi-Tempered Logistic Loss for Training Neural Nets with Noisy Data**](https://ai.googleblog.com/2019/08/bi-tempered-logistic-loss-for-training.html?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[**双温度逻辑回归损失用于训练含噪声数据的神经网络**](https://ai.googleblog.com/2019/08/bi-tempered-logistic-loss-for-training.html?source=post_page-----aee68ed8a38c----------------------)'
- en: The quality of models produced by machine learning (ML) algorithms directly
    depends on the quality of the training...
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）算法所生产模型的质量直接取决于训练数据的质量……
- en: '![Figure](../Images/19c1267393081ac6fa579cfa61d2473b.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/19c1267393081ac6fa579cfa61d2473b.png)'
- en: '[source](https://arxiv.org/pdf/1906.03361.pdf)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[source](https://arxiv.org/pdf/1906.03361.pdf)'
- en: The authors introduce a temperature into the exponential function and replace
    the softmax output layer of neural nets with a high-temperature generalization.
    The algorithm used in the log loss is replaced by a low-temperature logarithm.
    The two temperatures are tuned to create loss functions that are nonconvex.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在指数函数中引入温度，并用高温的广义版本替换神经网络的softmax输出层。对数损失中使用的算法被低温对数替换。这两种温度经过调整，以创建非凸的损失函数。
- en: The last neural net layer is replaced with the bi-temperature generalization
    of the logistic loss. This makes the training process more robust to noise. The
    method proposed in this paper is based on [Bregman divergences](https://arxiv.org/abs/1905.11545).
    Its performance can be visualized in the figure below.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层神经网络被替换为逻辑损失的双温度推广。这使训练过程对噪声更具鲁棒性。本文提出的方法基于[Bregman散度](https://arxiv.org/abs/1905.11545)。其性能可以在下图中可视化。
- en: '![Figure](../Images/4caf99e60120f3be38f29adc6effbc85.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/4caf99e60120f3be38f29adc6effbc85.png)'
- en: '[source](https://arxiv.org/pdf/1906.03361.pdf)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文档](https://arxiv.org/pdf/1906.03361.pdf)'
- en: For experimentation, the authors added synthetic noise to MNIST and CIFAR-100
    datasets. The results obtained with their bi-temperature loss function was then
    compared to the vanilla logistic loss function. The bi-temperature loss obtains
    an accuracy of 98.56% on MNIST and 62.5% ON CIFAR-100\. The figure below shows
    the performance in detail.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行实验，作者向MNIST和CIFAR-100数据集添加了合成噪声。然后将其双温度损失函数获得的结果与普通逻辑损失函数进行了比较。双温度损失在MNIST上获得98.56%的准确率，在CIFAR-100上为62.5%。下图详细展示了性能。
- en: '![Figure](../Images/0ddf5ccd7cecd4074732e8999f64fe16.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/0ddf5ccd7cecd4074732e8999f64fe16.png)'
- en: '[source](https://arxiv.org/pdf/1906.03361.pdf)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文档](https://arxiv.org/pdf/1906.03361.pdf)'
- en: Machine learning models are moving closer and closer to edge devices. Fritz
    AI is here to help with this transition. [Explore our suite of developer tools
    that makes it easy to teach devices to see, hear, sense, and think.](https://www.fritz.ai/product/premium.html?utm_campaign=buildmodels4&utm_source=heartbeat)
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 机器学习模型正越来越接近边缘设备。Fritz AI来帮助这一过渡。[探索我们的开发者工具套件，使设备学习看、听、感知和思考变得容易。](https://www.fritz.ai/product/premium.html?utm_campaign=buildmodels4&utm_source=heartbeat)
- en: '**GANs Loss Functions**'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GANs损失函数**'
- en: Discriminator loss aims at maximizing the probability given to real and fake
    images. Minimax loss is used [in the paper that introduced GANs](https://arxiv.org/abs/1406.2661).
    This is a strategy aimed at reducing the worst-case-scenario possible loss. It’s
    simply minimizing the maximum loss. This loss is also used in two-player games
    to reduce the maximum loss for a layer.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器损失旨在最大化对真实图像和假图像的概率。最小最大损失在[介绍GAN的论文中](https://arxiv.org/abs/1406.2661)被使用。这是一种旨在减少最坏情况下可能损失的策略。它简单地最小化最大损失。这种损失也用于两人游戏，以减少一层的最大损失。
- en: '[**Are GANs Created Equal? A Large-Scale Study**](https://arxiv.org/abs/1711.10337?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[**GANs是否相等？大规模研究**](https://arxiv.org/abs/1711.10337?source=post_page-----aee68ed8a38c----------------------)'
- en: Generative adversarial networks (GAN) are a powerful subclass of generative
    models. Despite a very rich research...
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）是生成模型的一个强大子类。尽管研究非常丰富...
- en: In the case of GANs, the two players are the generator and discriminator. This
    involves the minimization of the generator’s loss and maximization of the discriminator’s
    loss. Modification of the discriminator loss forms the non-saturating GAN loss,
    whose aim is to tackle the saturation problem. This involves the generator maximizing
    the log of the discriminator probabilities. It is done for the generated images.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN的情况下，两位玩家是生成器和判别器。这涉及到生成器损失的最小化和判别器损失的最大化。判别器损失的修改形成了非饱和GAN损失，其目标是解决饱和问题。这涉及生成器最大化判别器概率的对数。这是针对生成的图像进行的。
- en: Least squares GAN loss was developed to counter the challenges of binary cross-entropy
    loss that resulted in the generated images being very different from the real
    images. This loss function is adopted for the discriminator. As a result of this,
    GANs using this loss function are able to generate higher quality images than
    regular GANs. A comparison of the two is shown in the next figure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘GAN损失是为应对二进制交叉熵损失的挑战而开发的，该损失导致生成的图像与真实图像非常不同。这个损失函数被用于判别器。由于这个原因，使用此损失函数的GAN能够生成比常规GAN更高质量的图像。下一图展示了两者的比较。
- en: '[**NIPS 2016 Tutorial: Generative Adversarial Networks**](https://arxiv.org/abs/1701.00160?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[**NIPS 2016教程：生成对抗网络**](https://arxiv.org/abs/1701.00160?source=post_page-----aee68ed8a38c----------------------)'
- en: This report summarizes the tutorial presented by the author at NIPS 2016 on
    generative adversarial networks (GANs). The...
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本报告总结了作者在NIPS 2016上关于生成对抗网络（GANs）展示的教程。...
- en: '![Figure](../Images/c45b420599bac33a48cabd76bdca208c.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c45b420599bac33a48cabd76bdca208c.png)'
- en: '[sources](https://arxiv.org/pdf/1611.04076.pdf)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[sources](https://arxiv.org/pdf/1611.04076.pdf)'
- en: The Wasserstein loss function is dependent on the modification of the GAN architecture,
    where the discriminator doesn’t perform instance classification. Instead, the
    discriminator outputs a number for each instance. It attempts to make the number
    bigger for real instances than for fake ones.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Wasserstein 损失函数依赖于 GAN 架构的修改，其中鉴别器不进行实例分类。相反，鉴别器对每个实例输出一个数字。它试图使真实实例的数字大于虚假实例的数字。
- en: In this loss function, the discriminator attempts to maximize the difference
    between the output on real instances and the output on fake instances. The generator,
    on the other hand, attempts to maximize the discriminator’s output for its fake
    instances.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个损失函数中，鉴别器试图最大化真实实例输出与虚假实例输出之间的差异。另一方面，生成器试图最大化鉴别器对其虚假实例的输出。
- en: '[**Wasserstein GAN**](https://arxiv.org/abs/1701.07875?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Wasserstein GAN**](https://arxiv.org/abs/1701.07875?source=post_page-----aee68ed8a38c----------------------)'
- en: We introduce a new algorithm named WGAN, an alternative to traditional GAN training.
    In this new model, we show that we...
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了一种名为 WGAN 的新算法，作为传统 GAN 训练的替代方案。在这个新模型中，我们展示了...
- en: Here’s an image showing the performance of the GANs using this loss.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一张展示使用这种损失函数的 GANs 性能的图像。
- en: '![Figure](../Images/f8204a8d8649657f5330afe2605011be.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/f8204a8d8649657f5330afe2605011be.png)'
- en: '[source](https://arxiv.org/abs/1701.07875)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[source](https://arxiv.org/abs/1701.07875)'
- en: Focal Loss for Dense Object Detection
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 焦点损失用于密集目标检测
- en: This paper proposes an improvement to the standard cross-entropy criterion by
    reshaping it such that it down-weights the loss assigned to the well-classified
    examples — focal loss. This loss function is aimed at solving the class imbalance
    problem.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本文通过重塑标准交叉熵标准提出了一种改进，使其对分类正确的样本分配的损失减小——焦点损失。该损失函数旨在解决类别不平衡问题。
- en: Focal loss aims at training on a sparse set of hard examples and prevents easy
    negatives from trouncing the [detector](https://www.fritz.ai/object-detection/) at
    training. For testing, the authors develop RetinaNet — a simple dense detector.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点损失旨在对一组稀疏的困难样本进行训练，防止简单的负样本在训练中压倒[检测器](https://www.fritz.ai/object-detection/)。在测试中，作者开发了
    RetinaNet——一个简单的密集检测器。
- en: '[**Focal Loss for Dense Object Detection**](https://arxiv.org/abs/1708.02002?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Focal Loss for Dense Object Detection**](https://arxiv.org/abs/1708.02002?source=post_page-----aee68ed8a38c----------------------)'
- en: The highest accuracy object detectors to date are based on a two-stage approach
    popularized by R-CNN, where a...
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，最高精度的目标检测器基于 R-CNN 推广的两阶段方法，其中...
- en: In this loss function, the cross-entropy loss is scaled with the scaling factors
    decaying at zero as the confidence in the correct classes increases. The scaling
    factor automatically down weights the contribution of easy examples at training
    time and focuses on the hard ones.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个损失函数中，交叉熵损失与随着正确类置信度增加而递减的缩放因子一起缩放。缩放因子会自动减少训练时简单样本的贡献，专注于困难样本。
- en: '![Figure](../Images/d1f1eb379d7179e323d83d078d643722.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/d1f1eb379d7179e323d83d078d643722.png)'
- en: '[source](https://arxiv.org/abs/1708.02002)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[source](https://arxiv.org/abs/1708.02002)'
- en: Here are the results obtained by the focal loss function on RetinaNet.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是通过焦点损失函数在 RetinaNet 上获得的结果。
- en: '![Figure](../Images/6004f0500be1fb63ba16cca7932c8ae8.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/6004f0500be1fb63ba16cca7932c8ae8.png)'
- en: '[source](https://arxiv.org/abs/1708.02002)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[source](https://arxiv.org/abs/1708.02002)'
- en: Intersection over Union (IoU)-balanced Loss Functions for Single-stage Object
    Detection
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 针对单阶段目标检测的 Intersection over Union (IoU)-平衡损失函数
- en: Loss functions adopted by single-stage detectors perform sub-optimally in localization.
    This paper proposes an IoU-based loss function that consists of IoU-balanced classification
    and IoU-balanced localization loss.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 单阶段检测器采用的损失函数在定位上表现不佳。本文提出了一种基于 IoU 的损失函数，包括 IoU-平衡分类和 IoU-平衡定位损失。
- en: '[**IoU-balanced Loss Functions for Single-stage Object Detection**](https://arxiv.org/abs/1908.05641?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[**IoU-balanced Loss Functions for Single-stage Object Detection**](https://arxiv.org/abs/1908.05641?source=post_page-----aee68ed8a38c----------------------)'
- en: Single-stage detectors are efficient. However, we find that the loss functions
    adopted by single-stage detectors are...
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 单阶段检测器效率高。然而，我们发现单阶段检测器采用的损失函数是...
- en: The IoU-balanced classification loss focuses on positive scenarios with high
    IoU can increase the correlation between classification and the task of localization.
    The loss aims at decreasing the gradient of the examples with low IoU and increasing
    the gradient of examples with high IoU. This increases the localization accuracy
    of models.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: IoU平衡分类损失专注于高IoU的正面场景，可以增加分类与定位任务之间的相关性。该损失旨在减少低IoU示例的梯度，并增加高IoU示例的梯度。这提高了模型的定位准确性。
- en: The loss’s performance on the COCO dataset is shown below.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面展示了该损失在COCO数据集上的表现。
- en: '![Figure](../Images/feb8e2a8fb21155b58779ed20e0090c1.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/feb8e2a8fb21155b58779ed20e0090c1.png)'
- en: '[source](https://arxiv.org/pdf/1908.05641.pdf)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1908.05641.pdf)'
- en: Boundary loss for highly unbalanced segmentation
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 针对高度不平衡分割的边界损失
- en: This [paper proposes a boundary loss](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf) for
    highly unbalanced segmentations. The loss takes the form of a distance metric
    on the space of contours and not regions. This is done to tackle the challenges
    of regional losses for highly unbalanced [segmentation](https://www.fritz.ai/image-segmentation/) problems.
    The loss is inspired by discrete optimization techniques for computing gradient
    flows of curve evolution.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇[论文提出了一种边界损失](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)用于高度不平衡的分割。该损失形式为轮廓空间上的距离度量，而非区域。这是为了应对高度不平衡[分割](https://www.fritz.ai/image-segmentation/)问题的区域损失挑战。该损失受到计算曲线演变梯度流的离散优化技术的启发。
- en: '![Figure](../Images/aa561456754ad2ce4e2fe8b004dea4de.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/aa561456754ad2ce4e2fe8b004dea4de.png)'
- en: '[source](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)'
- en: The boundary loss uses integrals over the boundary between regions as opposed
    to using unbalanced integrals over the regions. An integral approach for computing
    boundary variations is used. The authors express a non-symmetric L2 distance on
    the space of shapes as a regional integral. This avoids local differential computations
    involving contour points. This then yields a boundary loss that’s expressed as
    the sum of the regional softmax probability outputs of the network. The loss is
    easily combined with regional losses and incorporated in existing deep network
    architectures.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 边界损失通过对区域之间的边界进行积分，而不是对区域进行不平衡积分。使用了计算边界变化的积分方法。作者将形状空间上的非对称L2距离表示为区域积分。这避免了涉及轮廓点的局部微分计算。最终得到了一个作为网络区域softmax概率输出之和的边界损失。该损失可以与区域损失轻松结合，并融入现有的深度网络架构中。
- en: The boundary loss was tested on the [Ischemic Stroke Lesion (ISLES)](http://www.isles-challenge.org/) and
    the [White Matter Hyperintensities](https://wmh.isi.uu.nl/) (WMH) benchmark datasets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 边界损失在[缺血性中风病灶（ISLES）](http://www.isles-challenge.org/)和[白质高信号（WMH）](https://wmh.isi.uu.nl/)基准数据集上进行了测试。
- en: '![Figure](../Images/f35d236d1d10b9821c2886c6eb6ff7e0.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/f35d236d1d10b9821c2886c6eb6ff7e0.png)'
- en: '[source](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](http://proceedings.mlr.press/v102/kervadec19a/kervadec19a.pdf)'
- en: Perceptual Loss Function
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 感知损失函数
- en: This loss function is used when images that look similar are being compared.
    The loss function is primarily used for training feedforward neural networks for
    tasks image transformation tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 该损失函数用于比较看起来相似的图像。主要用于训练前馈神经网络，用于图像转换任务。
- en: '![Figure](../Images/bcc0543cda2af0cdac01c9b6ec18667b.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/bcc0543cda2af0cdac01c9b6ec18667b.png)'
- en: '[source](https://arxiv.org/pdf/1603.08155.pdf)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1603.08155.pdf)'
- en: '[**Perceptual Losses for Real-Time Style Transfer and Super-Resolution**](https://arxiv.org/abs/1603.08155?source=post_page-----aee68ed8a38c----------------------)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**实时风格迁移和超分辨率的感知损失**](https://arxiv.org/abs/1603.08155?source=post_page-----aee68ed8a38c----------------------)'
- en: We consider image transformation problems, where an input image is transformed
    into an output image. Recent methods for...
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑图像转换问题，其中输入图像被转换为输出图像。最近的方法...
- en: The perceptual loss function works by adding the squared errors in the middle
    of all pixels and calculating the mean.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 感知损失函数通过将所有像素中间的平方误差相加并计算均值来工作。
- en: '![Figure](../Images/ac8b19fcc0168884743ae6615cc84ac5.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ac8b19fcc0168884743ae6615cc84ac5.png)'
- en: '[source](https://arxiv.org/pdf/1603.08155.pdf)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1603.08155.pdf)'
- en: In [style transfer](https://www.fritz.ai/style-transfer/), perceptual loss enables
    deep learning models to reconstruct finer details better than other loss functions.
    At training time, perceptual losses measure image similarities better than per-pixel
    loss functions. They also enable the transfer of semantic knowledge from the loss
    network to the transformation network.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在[风格迁移](https://www.fritz.ai/style-transfer/)中，感知损失使深度学习模型能够比其他损失函数更好地重建细节。在训练时，感知损失比逐像素损失函数更好地测量图像相似性。它们还使损失网络与转换网络之间的语义知识得以迁移。
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: We should now be up to speed on some of the most common — and a couple of very
    recent — advanced loss functions.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在应该对一些最常见的——以及几种非常新的——高级损失函数有了了解。
- en: The papers/abstracts mentioned and linked to above also contain links to their
    code implementations. We’d be happy to see the results you obtain after testing
    them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 上述提到并链接的论文/摘要也包含了其代码实现的链接。我们很高兴看到你在测试后得到的结果。
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [德里克·姆威提](https://derrickmwiti.com/)** 是一名数据分析师、作家和导师。他致力于在每项任务中取得出色的结果，并且是Lapid
    Leaders Africa的导师。'
- en: '[Original](https://heartbeat.fritz.ai/research-guide-advanced-loss-functions-for-machine-learning-models-aee68ed8a38c).
    Reposted with permission.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/research-guide-advanced-loss-functions-for-machine-learning-models-aee68ed8a38c)。已获转载许可。'
- en: '**Related:**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Research Guide for Neural Architecture Search](/2019/10/research-guide-neural-architecture-search.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经架构搜索研究指南](/2019/10/research-guide-neural-architecture-search.html)'
- en: '[Research Guide for Transformers](/2019/10/research-guide-transformers.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[变压器研究指南](/2019/10/research-guide-transformers.html)'
- en: '[Research Guide for Video Frame Interpolation with Deep Learning](/2019/10/research-guide-video-frame-interpolation-deep-learning.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于深度学习的视频帧插值研究指南](/2019/10/research-guide-video-frame-interpolation-deep-learning.html)'
- en: More On This Topic
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Loss Functions: An Explainer](https://www.kdnuggets.com/2022/03/loss-functions-explainer.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[损失函数：详解](https://www.kdnuggets.com/2022/03/loss-functions-explainer.html)'
- en: '[Multi-label NLP: An Analysis of Class Imbalance and Loss Function…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多标签NLP：类不平衡和损失函数的分析…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
- en: '[Advanced Feature Selection Techniques for Machine Learning Models](https://www.kdnuggets.com/2023/06/advanced-feature-selection-techniques-machine-learning-models.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型的高级特征选择技术](https://www.kdnuggets.com/2023/06/advanced-feature-selection-techniques-machine-learning-models.html)'
- en: '[3 Research-Driven Advanced Prompting Techniques for LLM Efficiency…](https://www.kdnuggets.com/3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3种研究驱动的高级提示技术提升LLM效率…](https://www.kdnuggets.com/3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization)'
- en: '[KDnuggets News, August 3: 10 Most Used Tableau Functions • Is…](https://www.kdnuggets.com/2022/n31.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，8月3日：10个最常用的Tableau函数 • 是…](https://www.kdnuggets.com/2022/n31.html)'
- en: '[How Activation Functions Work in Deep Learning](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习中激活函数的工作原理](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)'
