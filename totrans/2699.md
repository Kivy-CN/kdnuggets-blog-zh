# 关键机器学习技术：嵌套交叉验证，为什么以及如何使用Python代码

> 原文：[https://www.kdnuggets.com/2020/10/nested-cross-validation-python.html](https://www.kdnuggets.com/2020/10/nested-cross-validation-python.html)

[评论](#comments)

**由 [Omar Martinez](https://www.linkedin.com/in/omarmartinez182/), Arcalea**。

在本文中，我们将简要讨论并实现一种技术，这种技术在宏观上可能没有得到应有的关注。之前的陈述源于这样一个观察：有一个众所周知的问题，即某些模型在生产中的表现往往不如在模型构建阶段的表现。虽然有很多潜在的罪魁祸首，这个问题的一个常见原因可能在于模型选择过程。

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT工作

* * *

标准的模型选择过程通常包括一个超参数优化阶段，在此阶段，通过使用验证技术，如k折交叉验证（CV），将基于验证测试的结果选择一个“最佳”模型。然而，这个过程容易受到选择偏差的影响，使得它在许多应用中不可靠。这在Gavin Cawley和Nicola Talbot的一篇论文中有详细讨论，在其中我们可以找到以下信息：

> *“在机器学习研究中偶尔观察到的偏倚评估协议中，初步模型选择步骤是使用所有可用数据进行的，通常作为“初步研究”的一部分。数据随后被反复重新分区，以形成一个或多个随机、互不重叠的设计和测试集。然后使用相同的固定超参数值进行性能评估。这个做法乍一看似乎相当无害，但测试数据已经不再是统计上纯粹的，因为它们在调整超参数时已经被模型‘看到’。”*
> 
> - [关于模型选择中的过拟合及后续性能评估中的选择偏差](https://jmlr.csail.mit.edu/papers/volume11/cawley10a/cawley10a.pdf)，2010年。

为了说明为什么会这样，我们来用一个例子。假设我们在进行一个机器学习任务，其中我们基于*n*轮超参数优化来选择模型，我们通过网格搜索和交叉验证来实现。如果我们在每一轮的*n*次迭代中使用相同的训练和测试数据，这意味着测试集的性能信息通过超参数选择被纳入训练数据中。在每次迭代中，这些信息可以被过程利用，以找到表现最佳的超参数，这会导致测试数据集不再纯粹用于性能评估。如果*n*在某些时候很大，那么我们可能会将测试集视为次要的训练集（宽泛地说）。

从积极的一面来看，有一些技术可以帮助我们解决这个问题。一种方法是使用训练集、测试集和验证集，并根据验证集的表现调整超参数。

另一种策略，也是本文的重点，是**嵌套交叉验证**，它与上述论文中提出的解决方案之一相一致，通过将超参数优化视为模型拟合的一部分，并用不同的验证集来评估它，这些验证集是交叉验证的外层的一部分。

简而言之，拟合，包括超参数的拟合，其中本身包含内部交叉验证过程，就像模型过程中的任何其他部分一样，而不是评估特定拟合方法模型性能的工具。为了评估性能，你需要使用外部交叉验证过程。在实践中，你可以通过让网格搜索（或任何其他用于优化的对象）处理内部交叉验证，然后使用cross_val_score来估计外部循环中的泛化误差。因此，最终得分将通过对多个分割的测试集得分取平均值来获得，就像常规交叉验证过程一样。

这是该方法的简化概述。这一示意图并不是技术上严格的，但旨在提供整个过程的直观理解。

![](../Images/de4aa608e4442ce1f06da7ffe8109d41.png)

*嵌套交叉验证过程的简化示意图。*

### Python中的嵌套交叉验证

感谢[scikit-learn](https://scikit-learn.org/)，在Python中实现嵌套交叉验证相对简单。

让我们看一个例子。我们将开始加载[葡萄酒数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)以及所有必要的模块。

现在，我们开始实例化分类器，并指定我们希望运行的回合/试验次数，换句话说，就是我们将执行多少次完整的内外循环过程。由于这在计算上比较昂贵，我们仅用于演示目的，选择20次。请记住，回合数表示每次交叉验证过程将如何不同地拆分您的数据集。

下一步是创建一个字典，以建立我们将在每轮中探索的超参数空间，并创建两个空数组来存储嵌套和非嵌套过程的结果。

下一步至关重要，我们将创建一个for循环，该循环会迭代我们指定的回合数，并包含两个不同的交叉验证对象。

对于这个示例，我们将使用5折交叉验证作为外层和内层循环，并使用每轮的值（i）作为两个交叉验证对象的random_state。

接着，我们创建并配置用于执行超参数优化的对象。在这种情况下，我们将使用网格搜索。请注意，我们将'inner_cv'对象作为交叉验证方法传递给网格搜索。

随后，请注意，对于“嵌套”交叉验证过程的最终分数，我们使用cross_val_score函数，并将分类器对象'clf'（包括其自身的交叉验证过程）传递给它，这个对象是我们用于执行超参数优化的对象，同时还传递'outer_cv'交叉验证对象。在此过程中，我们还将数据拟合，并将每个过程的结果存储在之前创建的空数组中。

我们现在可以计算“简单”交叉验证和嵌套交叉验证过程的准确性分数差异，以查看它们在平均上有多大分歧。

在这种情况下，通过嵌套交叉验证分数，我们指的是嵌套过程的分数（不要与内部交叉验证过程混淆），并将其与常规过程（非嵌套）的分数进行比较。

**输出：**

[PRE0]

正如我们所见，非嵌套分数平均来看更为乐观。因此，仅依赖该过程的信息可能会导致模型选择偏差。

我们还可以绘制每次迭代的分数，并创建图表以获取两个过程行为的可视化比较。

**输出：**

![](../Images/4fd278f5460b4e7fb02cff5c757ca4a7.png)

最后，我们还可以绘制两个交叉验证过程在每轮中的差异。

**输出：**

![](../Images/2866efccbead0cc67410ff0a538a951f.png)

### 最终想法

尽管交叉验证是评估泛化能力的行业标准，但考虑到具体问题，重要的是实施更严格的过程，以避免在选择最终模型时产生选择偏差。从个人经验来看，当处理小型数据集时，尤其是在系统用于支持复杂决策时，这一点尤为重要。

嵌套交叉验证不是一个完美的过程，它是**计算开销很大的**，而且它绝对不是解决生产中模型性能差的万能药。然而，在大多数情况下，这一过程将使你能够更现实地了解每个模型的泛化能力。

你可以在 [GitHub](https://github.com/omartinez182/data-science-notebooks/blob/master/Nested_Cross_Validation_in_Python.ipynb) 上找到包含本文所有代码的笔记本。

**个人简介：** [爱德华多·马丁内斯](https://www.linkedin.com/in/omarmartinez182/) 是一位拥有商业分析硕士学位的市场营销人员。目前在 [Arcalea](https://arcalea.com/) 工作，爱德华多将数据科学框架与营销流程整合在一起。

**相关：**

+   [如何（以及为什么）创建一个好的验证集](https://www.kdnuggets.com/2017/11/create-good-validation-set.html)

+   [你应该在数据科学项目中使用交叉验证的 5 个理由](https://www.kdnuggets.com/2018/10/5-reasons-cross-validation-data-science-projects.html)

+   [利用交叉验证构建可靠的机器学习模型](https://www.kdnuggets.com/2018/08/building-reliable-machine-learning-models-cross-validation.html)

### 更多相关内容

+   [提示工程中的并行处理：思维骨架……](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)

+   [人工智能、分析、机器学习、数据科学、深度学习……](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)

+   [宣布 PyCaret 3.0：开源、低代码的 Python 机器学习工具](https://www.kdnuggets.com/2023/03/announcing-pycaret-30-opensource-lowcode-machine-learning-python.html)

+   [优化 Python 代码性能：深入了解 Python 性能分析器](https://www.kdnuggets.com/2023/02/optimizing-python-code-performance-deep-dive-python-profilers.html)

+   [2021 年主要发展和 2022 年人工智能、数据科学的关键趋势……](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)

+   [2022 年的数据科学、机器学习、人工智能和分析领域的关键发展](https://www.kdnuggets.com/2022/12/key-data-science-machine-learning-ai-analytics-developments-2022.html)
