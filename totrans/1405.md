# 2020年你需要了解的20个AI、数据科学、机器学习术语（第1部分）

> 原文：[https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html)

[comments](#comments)

过去，KDnuggets曾经涵盖过一些[关键术语](/tag/key-terms)的合集，包括[机器学习](/2016/05/machine-learning-key-terms-explained.html)、[深度学习](/2016/10/deep-learning-key-terms-explained.html)、[大数据](/2016/08/big-data-key-terms-explained.html)、[自然语言处理](/2017/02/natural-language-processing-key-terms-explained.html)等。随着新年的到来，我们最近没有发布任何关键术语合集，我们认为高亮一些我们现在应该熟悉的AI、数据科学和机器学习术语是个好主意，以应对不断发展的格局。

因此，这些术语结合了最近出现的一些新概念以及最近被认为越来越重要的现有概念。这些定义是KDnuggets团队的共同努力，包括[Gregory Piatetsky](/author/gregory-piatetsky)、[Asel Mendis](/author/asel-mendis)、[Matthew Dearing](/author/matthew-dearing)和我自己，[Matthew Mayo](/author/matt-mayo)。

> * * *
> 
> ## 我们的前三大课程推荐
> ## 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路
> 
> ![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能
> 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你在 IT 领域的组织
> 
> * * *
> 
> 另见 [**2020年你需要了解的20个AI、数据科学、机器学习术语（第2部分）**](https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html)

那么，事不宜迟，这里是你需要了解的前10个术语，第二部分将在下周发布，总共20个术语供你在2020年了解。

![Figure](../Images/8b7e157b12f9f58f71312628e357550b.png)

**AutoML**

自动化机器学习（**AutoML**）涵盖了可以合理认为包括在机器学习流程中的相当广泛的任务。

AutoML “解决方案”可能包括数据预处理、特征工程、算法选择、算法架构搜索和超参数调整等任务，或者这些不同任务的某些子集或变体。因此，自动化机器学习现在可以被认为是从仅执行单一任务（如自动化特征工程），到从数据预处理、特征工程、算法选择等全面自动化的管道。

换句话说——说实话，我的*最喜欢*的方式——如果，如[塞巴斯蒂安·拉施卡所描述](/2016/05/explain-machine-learning-software-engineer.html)，计算机编程是关于自动化的，而机器学习是“全自动化的自动化”，那么自动化机器学习就是“自动化的自动化自动化”。 跟我来：编程通过管理单调任务来减轻我们的负担；机器学习允许计算机学习如何最好地执行这些单调任务；自动化机器学习允许计算机学习如何优化学习执行这些单调动作的结果。

这是一个非常强大的想法；尽管我们以前需要担心调整参数和超参数，手动工程特征，执行算法选择等，自动化机器学习系统可以通过多种不同的方法学习如何最佳地调整这些过程以获得最佳结果。

“常规”编程是输入数据和规则，输出答案；机器学习是输入数据和答案，输出规则；自动化机器学习涉及自动化优化一些约束集，以“最佳”方式从数据和答案到达规则，用你喜欢的任何指标定义“最佳”。

**贝叶斯**

贝叶斯方法允许我们应用概率分布来建模现实世界，并在新数据变得可用时更新我们的信念。多年来，统计学家通常依赖于频率主义方法。贝叶斯方法适用于建模只有少量数据的假设，这些数据在频率主义者看来可能不显著。

Brandon Rohrer 的解释是一个很好的简单示例，展示了贝叶斯方法的工作原理：

想象一下你在看电影时，一个观众掉了他们的票。你想引起他们的注意。这是他们从后面看起来的样子。你无法判断他们的性别，只知道他们有长发。你会喊“对不起，女士！”还是“对不起，先生！”根据你对你所在地区男性和女性发型的了解，你可能会假设这是一个女性。（在这个过于简化的例子中，只有两种发型长度和性别。）现在考虑一个情况变体，这个人正在排队等候男厕。凭借这一额外信息，你可能会假设这是一个男性。这种使用常识和背景知识的方式是我们在不加思索的情况下完成的。贝叶斯推理是一种数学方法，可以捕捉这种现象，从而使我们能够做出更准确的预测。 -Brandon Rohrer

**BERT**

[BERT](https://arxiv.org/abs/1810.04805) 代表双向编码器表示的转换器，是一种用于自然语言处理的预训练技术。BERT 的独特之处在于将*双向*训练应用于现有的 Transformer 注意力模型。BERT 在左右上下文中对未标记的文本数据进行深度双向表示的预训练，从而生成一个可以通过仅添加一层进行微调的语言模型。BERT 在包括问答和推理在内的多个 NLP 任务中取得了最先进的性能。BERT 和 Transformer 都是由 Google 开发的。

直观上，双向训练语言模型与从左到右（或从右到左）训练相比，会对语言“理解”和单词意义有更好的感知。双向性允许基于单词周围的整体信息学习单词意义，而不是仅仅根据从一个方向“阅读”到给定单词出现点的信息来做出判断。因此，不同上下文中意义不同的词可以被分开处理，从而更好地捕捉它们的上下文意义（例如，河流的“岸边”和存放钱的“银行”）。

实际上，BERT 可以用于从文本中提取特征，形式为词或句子嵌入，或者 BERT 模型可以在额外的数据上进行微调，以适应特定任务，如问答或文本分类。BERT 有几种不同大小的模型（参数数量），并且激发了一系列与 BERT 相关的模型，如 RoBERTa 和 DistilBERT。

欲了解有关 BERT 的全面讲解和实用教程，请参见 [Chris McCormick 和 Nick Ryan 的精彩文章](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/)。

**CCPA**

CCPA，即[加州消费者隐私法案](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act)，于2020年1月1日生效，对收集个人数据的企业具有重要意义，并且对分析和处理这些数据的企业同样具有影响。它在意图上与[GDPR](/tag/gdpr)类似，但为加州消费者提供了更强的保护。CCPA允许任何加州消费者要求查看公司持有的个人信息，以及与谁分享了这些信息的完整列表。加州消费者还可以访问他们的个人数据，拒绝出售他们的个人数据，并要求公司删除公司所持有的任何个人信息。

适用于任何收集消费者个人数据、在加州开展业务，并满足以下至少一项条件的企业：

+   年收入超过2500万美元；

+   购买或出售50000个或更多加州消费者或家庭的个人信息

+   年收入中超过50%来自销售加州消费者的个人信息

欲了解更多信息，请参见[关于CCPA的维基百科条目](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act)

**数据工程师**

数据工程师负责优化和管理组织数据的存储和检索。数据工程师会制定最佳的数据获取路线图，并创建存储数据的数据库。他们通常会处理云服务，以优化数据存储，并创建算法以理解数据。数据工程师的角色高度技术化，需要在SQL、数据库设计和计算机科学方面有高级知识。

数据工程师越来越倾向于获得云认证，以便在云环境中创建数据库，处理大型复杂数据集，以实现数据检索的扩展和优化。

**深度伪造**

深度伪造是使用先进的[深度学习](/tag/deep-learning)和生成对抗网络[GANs](/tag/gans)技术创建的虚假图像、视频或音频。这项技术非常先进，以至于结果非常逼真，很难识别为伪造。以下是使用奥巴马的图像和声音的深度伪造示例：

深度伪造技术最初在色情内容中变得突出，流行的名人面孔被叠加在成人视频上，但最近，随着像FakeApp这样的应用程序以及更近期的开源替代品，如FaceSwap和DeepFaceLab，技术已经进步。

对于语音，以前需要几分钟的讲话，但最近技术可以仅从几秒钟的讲话生成令人信服的声音模仿。在2019年9月的第一次网络犯罪中，[一家公司被诈骗](https://medium.com/tebs-lab/the-first-known-deep-fake-crime-a-promisingly-habitable-planet-and-californias-gig-worker-bill-7923b81a18d0)支付了24.3万美元，诈骗者使用深度伪造技术模仿了首席执行官的声音。

深度伪造技术已被用于政治虚假信息活动，创建虚假的机器人档案图像，但可能会在2020年被用于通过虚假的声音和图像传播有关候选人的虚假信息。

现在，深度伪造创作者和试图识别这些伪造内容的网络公司之间存在军备竞赛。Facebook及其他几家公司已[宣布了一个1000万美元的竞赛](https://ai.facebook.com/blog/deepfake-detection-challenge/)，以生产识别深度伪造的技术。保持关注，不要自动相信你在网上看到的一切——检查其来源。

**部署/生产化模型**

在这个机器学习、深度学习和人工智能的时代，最终目标是将技术部署到最终消费者手中。许多服务提供商可以通过网络部署模型，如Heroku、AWS、Azure、GCP、Github等。不同的提供商有不同的成本，并提供略有不同的服务。部署和将模型投入生产还需要一定的前端和后端开发知识，以及能够在团队中工作。

由于云计算提供商易于扩展到数百万用户并能够监控扩展成本，许多模型现在正在通过云计算提供商进行部署。生产中的模型允许组织将其货币化，为客户创造更大的价值。

**图神经网络**

数据科学家们在数据中游泳，堆积如山的原始数据可能杂乱无章地流入，其他数据则可能井然有序（或经过整理），以可控的维度格式呈现。对于这些“欧几里得”数据集，如文本、图像和视频，机器学习在文本生成、图像处理和人脸识别应用中取得了巨大成功。将深度学习模型与一个或两个GPU及大量训练数据配对，发现数据中隐藏模式和有意义特征的可能性几乎是无限的。

那些更具关联性的数据呢？数据可以通过依赖关系彼此连接。用户之间的互动可能会影响电子商务平台上的购买决策。药物发现中的化学反应通过复杂的反应互连进行映射。社交网络通过不断变化、不规则和无序的关系形成并演变。人脑由通过交织的意大利面球连接的单独通信的细胞构建。

这些数据关系可以被建模为*图*，其中数据点表示为节点，关系通过互相连接的链接进行编码。传统的机器学习方法，包括深度学习，需要进一步泛化以在非欧几里得的图形空间中进行计算。尽管早期有一些相关工作，但*图神经网络*（GNN）的概念由[Margo Gori及其团队](http://sailab.diism.unisi.it/people/marco-gori/)在2005年定义，随后更多研究扩展到递归和卷积神经网络的图形版本。深度学习研究现在积极致力于将[GNN方法](/2019/08/neighbours-machine-learning-graphs.html)应用于数据即意大利面的来源，这是一个应在2020年密切关注的研究领域。

**MLOps & AIOps**

随着[DevOps](/tag/devops)在IT组织中的广泛成功，将*软件开发人员*的过程与IT服务交付融合在一起，这个术语已经升华为当今的文化热词。在大多数热词扎根后，新环境或适用领域通常会追随这种炒作。

MLOps这一术语用于表示最新的最佳实践，通过与*数据科学家*和IT专业人员的有效合作来开发和部署机器学习模型。对于许多数据科学家来说，在一个定义明确的开发生命周期中工作应该是[相当受欢迎的](/2020/02/machine-learning-projects-manage.html)，因为正式和自学的教育课程往往集中在AI和ML的基础知识上，而对生产部署的要求则[不太熟悉](/2020/02/deploy-machine-learning-model.html)。

扩展这种将人工智能应用于组织运营的范围的是AIOps，它汇集了所有机器学习技术，从IT系统中提取有意义的见解。这种方法将人类的智慧与AI算法结合起来，帮助IT团队做出更好、更快的决策，实时响应事件，并开发优化的应用程序，以促进更有效或自动化的业务流程。根据[高德纳的预测](https://www.gartner.com/smarterwithgartner/how-to-get-started-with-aiops/)，到2023年，只有30%的大型企业CIO将专门使用AIOps来改善运营，因此我们将会看到AIOps在IT组织中的进一步发展。

**迁移学习**

考虑在训练机器学习模型时可能出现的以下一对问题。首先，通常没有足够的训练数据来充分训练模型。其次，即使存在足够的训练数据，训练过程通常也是资源和时间密集型的。

如果考虑到机器学习模型通常是在特定任务的数据上训练的，并且得到的模型是特定任务的，那么这些模型的最大潜力往往没有被实现。一旦数据和计算资源被用于训练一个模型，为什么不在尽可能多的情况下使用这个模型呢？为什么不将所学到的知识转移到新的应用中呢？高度优化的训练模型是否可以被进一步利用于更广泛的任务？

迁移学习涉及利用现有的机器学习模型，用于那些模型最初未被训练的场景。就像人类不会每次开始新任务时都抛弃之前学到的所有知识一样，迁移学习允许机器学习模型将其在训练过程中获得的“知识”迁移到新任务中，扩展了计算和专业知识的结合所带来的影响。简单来说，迁移学习可以节省训练时间并延续现有机器学习模型的实用性。对于那些通常需要大量训练数据来从头开始训练模型的任务，迁移学习也是一种宝贵的技术。

考虑到时间和计算消耗，迁移学习使我们能够更好地最大化模型的实用性。针对训练数据不足的问题，迁移学习允许我们使用在大量数据上预训练的模型，并在较小的特定任务数据上对其进行调整。迁移学习是一种有效的方式来管理机器学习模型训练中的两个潜在短板，因此它越来越受到使用也就不足为奇了。

*此答案部分改编自我为书籍[用Python进行迁移学习](https://www.amazon.ca/Hands-Transfer-Learning-Python-TensorFlow-ebook/dp/B07CB455BF)所写的前言，出版社为Packt。*

**相关**：

+   [2020年必须具备的数据科学技能前5名](/2020/01/top-5-data-science-skills-2020.html)

+   [2020年数据科学前5大趋势](/2020/02/top-5-data-science-trends.html)

+   [2020年AI前5大趋势](/2020/01/top-5-ai-trends-2020.html)

### 更多相关主题

+   [成为优秀数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目的，然后寻找目的去…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
