["```py\ntrain_df[\"sum_diffs\"] = 0\ntrain_df[\"sum_diffs\"] = train_df[diff_cols].sum(axis=1).values\ntrain_df[\"d\"] = train_df[\"sum_diffs\"] ** 0.5\ntrain_df[\"frac\"] = 1 / (1 + train_df[\"d\"]) ** kappa\ntrain_df[\"part\"] = train_df[target_col] * train_df[\"frac\"]\ntest_df.loc[index, \"pred\"] = train_df[\"part\"].sum() / train_df[\"frac\"].sum()\n```", "```py\ndef predict_kernel(F, T, numer, denom, kappa):\n    for i, (x, t) in enumerate(zip(F, T)):\n        d = abs(x - t)  # the distance measure\n        w = 1 / pow(d, kappa)  # parameterize non-linear scaling\n        numer[i] = w\n        denom[i] = d\n\n_tdf = train_df[[att, target_col]].apply_rows(\n    predict_kernel,\n    incols={att: \"F\", \"G3\": \"T\"},\n    outcols={\"numer\": np.float64, \"denom\": np.float64},\n    kwargs={\"kappa\": kappa},\n)\n\np = _tdf[\"numer\"].sum() / _tdf[\"denom\"].sum()  # prediction - weighted average\n```"]