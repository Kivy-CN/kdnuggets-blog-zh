- en: The 10 Statistical Techniques Data Scientists Need to Master
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学家需要掌握的10种统计技术
- en: 原文：[https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html/2](https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html/2](https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html/2)
- en: '****6 — Dimension Reduction:****'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '****6 — 维度缩减：****'
- en: Dimension reduction reduces the problem of estimating *p + 1* coefficients to
    the simple problem of *M + 1* coefficients, where *M < p. *This is attained by
    computing *M* different *linear combinations,* or *projections,* of the variables.
    Then these *M* projections are used as predictors to fit a linear regression model
    by least squares. 2 approaches for this task are *principal component regression*
    and *partial least squares.*
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 维度缩减将估计*p + 1*个系数的问题简化为估计*M + 1*个系数的简单问题，其中*M < p*。这通过计算*M*个不同的*线性组合*，或*投影*来实现。然后，这些*M*个投影被用作预测变量，通过最小二乘法拟合一个线性回归模型。处理此任务的2种方法是*主成分回归*和*偏最小二乘*。
- en: '![](../Images/aaf5c3c81c82d9b597e23931df90d35b.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aaf5c3c81c82d9b597e23931df90d35b.png)'
- en: One can describe **Principal Components Regression** as an approach for deriving
    a low-dimensional set of features from a large set of variables. The *first*principal
    component direction of the data is along which the observations vary the most.
    In other words, the first PC is a line that fits as close as possible to the data.
    One can fit *p* distinct principal components. The second PC is a linear combination
    of the variables that is uncorrelated with the first PC, and has the largest variance
    subject to this constraint. The idea is that the principal components capture
    the most variance in the data using linear combinations of the data in subsequently
    orthogonal directions. In this way, we can also combine the effects of correlated
    variables to get more information out of the available data, whereas in regular
    least squares we would have to discard one of the correlated variables.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以将**主成分回归**描述为从大量变量中派生出低维特征集的一种方法。数据的*第一个*主成分方向是观测值变化最大的方向。换句话说，第一个主成分是一条尽可能贴合数据的直线。可以拟合*p*个不同的主成分。第二个主成分是与第一个主成分不相关的变量的线性组合，并在此约束下具有最大的方差。其理念是主成分通过在随后的正交方向上使用数据的线性组合来捕捉数据中的最大方差。通过这种方式，我们还可以结合相关变量的影响，从现有数据中获取更多信息，而在常规最小二乘法中，我们则需要丢弃一个相关变量。
- en: The PCR method that we described above involves identifying linear combinations
    of *X* that best represent the predictors. These combinations (*directions*) are
    identified in an unsupervised way, since the response *Y* is not used to help
    determine the principal component directions. That is, the response *Y* does not *supervise* the
    identification of the principal components, thus there is no guarantee that the
    directions that best explain the predictors also are the best for predicting the
    response (even though that is often assumed). **Partial least square**s (PLS)
    are a *supervised* alternative to PCR. Like PCR, PLS is a dimension reduction
    method, which first identifies a new smaller set of features that are linear combinations
    of the original features, then fits a linear model via least squares to the new *M* features.
    Yet, unlike PCR, PLS makes use of the response variable in order to identify the
    new features.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们上面描述的PCR方法涉及识别最佳表示预测变量的*X*的线性组合。这些组合（*方向*）是以无监督的方式识别的，因为响应*Y*未用于帮助确定主成分方向。也就是说，响应*Y*并不*监督*主成分的识别，因此没有保证最佳解释预测变量的方向也是预测响应的最佳方向（尽管这通常被假设）。**偏最小二乘**（PLS）是PCR的*有监督*替代方法。与PCR一样，PLS也是一种维度缩减方法，它首先识别出原始特征的线性组合的新特征集，然后通过最小二乘法对新的*M*个特征拟合线性模型。然而，与PCR不同的是，PLS利用响应变量来识别新特征。
- en: '****7 — Nonlinear Models:****'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '****7 — 非线性模型：****'
- en: 'In statistics, nonlinear regression is a form of regression analysis in which
    observational data are modeled by a function which is a nonlinear combination
    of the model parameters and depends on one or more independent variables. The
    data are fitted by a method of successive approximations. Below are a couple of
    important techniques to deal with nonlinear models:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，非线性回归是一种回归分析方法，其中观测数据通过一个非线性组合的模型参数的函数来建模，并且依赖于一个或多个自变量。这些数据通过逐步逼近的方法进行拟合。以下是处理非线性模型的一些重要技术：
- en: A function on the real numbers is called a **step function** if it can be written
    as a finite linear combination of indicator functions of intervals. Informally
    speaking, a step function is a piecewise constant function having only finitely
    many pieces.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个实数上的函数可以写成区间指示函数的有限线性组合，那么这个函数被称为**阶跃函数**。非正式地说，阶跃函数是一个分段常数函数，只有有限多个区间。
- en: A **piecewise function** is a function which is defined by multiple sub-functions,
    each sub-function applying to a certain interval of the main function’s domain.
    Piecewise is actually a way of expressing the function, rather than a characteristic
    of the function itself, but with additional qualification, it can describe the
    nature of the function. For example, a **piecewise polynomial** function is a
    function that is a polynomial on each of its sub-domains, but possibly a different
    one on each.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分段函数** 是由多个子函数定义的函数，每个子函数适用于主函数定义域的某个区间。分段实际上是一种表达函数的方式，而不是函数本身的特性，但经过额外的限定，它可以描述函数的性质。例如，**分段多项式**函数是一个在每个子域上都是多项式的函数，但每个子域上的多项式可能不同。'
- en: '![](../Images/594bd23c68d30b0aa895e2e2b83540c7.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/594bd23c68d30b0aa895e2e2b83540c7.png)'
- en: A **spline** is a special function defined piecewise by polynomials. In computer
    graphics, spline refers to a piecewise polynomial parametric curve. Splines are
    popular curves because of the simplicity of their construction, their ease and
    accuracy of evaluation, and their capacity to approximate complex shapes through
    curve fitting and interactive curve design.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样条函数** 是一种由多项式分段定义的特殊函数。在计算机图形学中，样条函数指的是分段的多项式参数曲线。样条函数因其构造的简单性、评估的便利性和准确性，以及通过曲线拟合和交互式曲线设计来逼近复杂形状的能力而受到欢迎。'
- en: A **generalized additive model**is a generalized linear model in which the linear
    predictor depends linearly on unknown smooth functions of some predictor variables,
    and interest focuses on inference about these smooth functions.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义加性模型**是一种广义线性模型，其中线性预测变量依赖于某些预测变量的未知平滑函数，重点在于对这些平滑函数进行推断。'
- en: '****8 — Tree-Based Methods:****'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '****8 — 基于树的方法:****'
- en: Tree-based methods can be used for both regression and classification problems.
    These involve stratifying or segmenting the predictor space into a number of simple
    regions. Since the set of splitting rules used to segment the predictor space
    can be summarized in a tree, these types of approaches are known as **decision-tree** methods.
    The methods below grow multiple trees which are then combined to yield a single
    consensus prediction.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的方法既可以用于回归问题，也可以用于分类问题。这些方法涉及将预测变量空间划分为若干个简单区域。由于用于划分预测变量空间的分割规则可以用树来总结，这些方法被称为**决策树**方法。以下这些方法生成多个树，然后将它们结合以得出单一的共识预测。
- en: '**Bagging** is the way decrease the variance of your prediction by generating
    additional data for training from your original dataset using combinations with
    repetitions to produce multistep of the same carnality/size as your original data.
    By increasing the size of your training set you can’t improve the model predictive
    force, but just decrease the variance, narrowly tuning the prediction to expected
    outcome.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bagging** 是通过对原始数据集生成额外的数据进行训练，以重复组合的方式减少预测的方差，从而产生与原始数据具有相同规模/大小的多步骤数据。通过增加训练集的规模，无法提升模型的预测能力，只能减少方差，从而将预测值精确调整至预期结果。'
- en: '**Boosting** is an approach to calculate the output using several different
    models and then average the result using a weighted average approach. By combining
    the advantages and pitfalls of these approaches by varying your weighting formula
    you can come up with a good predictive force for a wider range of input data,
    using different narrowly tuned models.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提升** 是一种使用多个不同模型计算输出，然后使用加权平均的方法来平均结果的方式。通过调整加权公式来结合这些方法的优缺点，你可以为更广泛的输入数据提供良好的预测能力，利用不同的精确调优模型。'
- en: '![](../Images/8564dca67fc55bd7baf8ab9137185528.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8564dca67fc55bd7baf8ab9137185528.png)'
- en: The **random forest** algorithm is actually very similar to bagging. Also here,
    you draw random bootstrap samples of your training set. However, in addition to
    the bootstrap samples, you also draw a random subset of features for training
    the individual trees; in bagging, you give each tree the full set of features.
    Due to the random feature selection, you make the trees more independent of each
    other compared to regular bagging, which often results in better predictive performance
    (due to better variance-bias trade-offs) and it’s also faster, because each tree
    learns only from a subset of features.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**算法实际上与袋装方法非常相似。这里，你会从训练集中抽取随机的自助样本。然而，除了自助样本，你还会抽取一个特征的随机子集来训练个体决策树；在袋装方法中，你会给每棵树提供完整的特征集。由于随机特征选择，你使得树之间相对独立于常规袋装方法，这通常会导致更好的预测性能（由于更好的方差-偏差权衡），而且也更快，因为每棵树只从特征的子集学习。'
- en: '****9 — Support Vector Machines:****'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '****9 — 支持向量机：****'
- en: '![](../Images/cce76979f7f43d567a5ca6b735d0d831.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cce76979f7f43d567a5ca6b735d0d831.png)'
- en: SVM is a classification technique that is listed under supervised learning models
    in Machine Learning. In layman’s terms, it involves finding the hyperplane (line
    in 2D, plane in 3D and hyperplane in higher dimensions. More formally, a hyperplane
    is n-1 dimensional subspace of an n-dimensional space) that best separates two
    classes of points with the maximum margin. Essentially, it is a constrained optimization
    problem where the margin is maximized subject to the constraint that it perfectly
    classifies the data (hard margin).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）是一种分类技术，被列在机器学习的监督学习模型下。通俗来说，它涉及到寻找一个超平面（二维中的直线，三维中的平面，以及更高维中的超平面），该超平面能以最大的间隔最好地分离两类点。本质上，这是一个约束优化问题，在约束条件下最大化间隔，即完美分类数据（硬间隔）。
- en: The data points that kind of “support” this hyperplane on either sides are called
    the “support vectors”. In the above picture, the filled blue circle and the two
    filled squares are the support vectors. For cases where the two classes of data
    are not linearly separable, the points are projected to an exploded (higher dimensional)
    space where linear separation may be possible. A problem involving multiple classes
    can be broken down into multiple one-versus-one or one-versus-rest binary classification
    problems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 支持这个超平面的数据点称为“支持向量”。在上图中，填充的蓝色圆圈和两个填充的方块就是支持向量。对于两个类别的数据不能线性可分的情况，这些点会被投影到一个扩展（更高维）空间，在那里可能会实现线性分离。涉及多个类别的问题可以被拆解为多个一对一或一对其余的二分类问题。
- en: '****10 — Unsupervised Learning:****'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '****10 — 无监督学习：****'
- en: 'So far, we only have discussed supervised learning techniques, in which the
    groups are known and the experience provided to the algorithm is the relationship
    between actual entities and the group they belong to. Another set of techniques
    can be used when the groups (categories) of data are not known. They are called
    unsupervised as it is left on the learning algorithm to figure out patterns in
    the data provided. Clustering is an example of unsupervised learning in which
    different data sets are clustered into groups of closely related items. Below
    is the list of most widely used unsupervised learning algorithms:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了监督学习技术，其中组是已知的，算法所提供的经验是实际实体与它们所属组之间的关系。当数据的组（类别）未知时，可以使用另一组技术。这些技术被称为无监督学习，因为它由学习算法去找出提供的数据中的模式。聚类是无监督学习的一个例子，其中不同的数据集被聚类成紧密相关的组。以下是最广泛使用的无监督学习算法列表：
- en: '![](../Images/61f3908308615b6f22c03bc7ae8be331.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61f3908308615b6f22c03bc7ae8be331.png)'
- en: '**Principal Component Analysis** helps in producing low dimensional representation
    of the dataset by identifying a set of linear combination of features which have
    maximum variance and are mutually un-correlated. This linear dimensionality technique
    could be helpful in understanding latent interaction between the variable in an
    unsupervised setting.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**帮助通过识别具有最大方差且互不相关的特征线性组合，生成数据集的低维表示。这种线性维度技术可能有助于在无监督设置中理解变量之间的潜在交互。'
- en: '**k-Means clustering**: partitions data into k distinct clusters based on distance
    to the centroid of a cluster.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**k均值聚类**：根据与簇中心的距离将数据划分为k个不同的簇。'
- en: '**Hierarchical clustering**: builds a multilevel hierarchy of clusters by creating
    a cluster tree.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**层次聚类**: 通过创建聚类树构建多级聚类层次。'
- en: This was a basic run-down of some basic statistical techniques that can help
    a data science program manager and or executive have a better understanding of
    what is running underneath the hood of their data science teams. Truthfully, some
    data science teams purely run algorithms through python and R libraries. Most
    of them don’t even have to think about the math that is underlying. However, being
    able to understand the basics of statistical analysis gives your teams a better
    approach. Have insight into the smallest parts allows for easier manipulation
    and abstraction. I hope this basic data science statistical guide gives you a
    decent understanding!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '-   这是一些基本统计技术的简介，旨在帮助数据科学项目经理或高管更好地理解数据科学团队内部的运作。事实上，一些数据科学团队纯粹通过Python和R库运行算法。他们中的大多数甚至不需要考虑基础数学。然而，能够理解统计分析的基础知识可以为你的团队提供更好的方法。深入了解最小的部分可以更轻松地进行操作和抽象。希望这个基本的数据科学统计指南能给你提供一个不错的理解！'
- en: '*P.S: You can get all the lecture slides and RStudio sessions from *[*my GitHub
    source code here*](https://github.com/khanhnamle1994/statistical-learning)*. Thanks
    for the overwhelming response!*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*附注: 你可以从*[*我的GitHub源码在这里*](https://github.com/khanhnamle1994/statistical-learning)*获取所有讲座幻灯片和RStudio会议记录。感谢你们的热烈回应！*'
- en: '**Bio: [James Le](https://www.linkedin.com/in/khanhnamle94/)** is currently
    applying for Master of Science Computer Science programs in the US for the Fall
    2018 admission. His intended research will focus on Machine Learning and Data
    Mining. In the mean time, he is working as a freelance full-stack web developer.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [詹姆斯·李](https://www.linkedin.com/in/khanhnamle94/)** 目前正在申请2018年秋季入学的美国计算机科学硕士项目。他计划的研究将集中在机器学习和数据挖掘方面。同时，他作为自由职业全栈Web开发人员工作。'
- en: '[Original](https://towardsdatascience.com/the-10-statistical-techniques-data-scientists-need-to-master-1ef6dbd531f7).
    Reposted with permission.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/the-10-statistical-techniques-data-scientists-need-to-master-1ef6dbd531f7)。经许可转载。'
- en: '**Related:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[The 10 Algorithms Machine Learning Engineers Need to Know](/2016/08/10-algorithms-machine-learning-engineers.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习工程师需知的10种算法](/2016/08/10-algorithms-machine-learning-engineers.html)'
- en: '[Top 10 Data Mining Algorithms, Explained](/2015/05/top-10-data-mining-algorithms-explained.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前10大数据挖掘算法解析](/2015/05/top-10-data-mining-algorithms-explained.html)'
- en: '[Top 10 Machine Learning Algorithms for Beginners](/2017/10/top-10-machine-learning-algorithms-beginners.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者的前10大机器学习算法](/2017/10/top-10-machine-learning-algorithms-beginners.html)'
- en: More On This Topic
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为伟大数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学，寻找目的，然后…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
