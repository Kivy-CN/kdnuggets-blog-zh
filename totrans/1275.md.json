["```py\n# Import required libraries\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\nfrom pyspark.ml.regression import GBTRegressor\nfrom pyspark.sql.types import FloatType\n\nimport mlflow\nimport mlflow.spark\nimport mlflow.tracking\n\nmlflow.set_experiment('/Users/dash@streamsets.com/transformer-experiments')\nmlflow_client = mlflow.tracking.MlflowClient()\n\n# Setup variables for convenience and readability \ntrainSplit = ${trainSplit}\ntestSplit = ${testSplit}\nmaxIter = ${maxIter}\nnumberOfCVFolds = ${numberOfCVFolds}\nr2 = 0\nrmse = 0\nstage = \"Staging\"\n\n# The input dataframe is accessbile via inputs[0]\ndf = inputs[0]\n\nfeatures = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n\n# MUST for Spark features\nvectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\ndf = vectorAssembler.transform(df)\n\n# Split dataset into \"train\" and \"test\" sets\n(train, test) = df.randomSplit([trainSplit, testSplit], 42) \n\n# Setup evaluator -- default is F1 score\nclassEvaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n\nwith mlflow.start_run(): \n  # Gradient-boosted tree regression\n  gbt = GBTRegressor(maxIter=maxIter)\n\n  # Setup pipeline\n  pipeline = Pipeline(stages=[gbt])\n\n  # Setup hyperparams grid\n  paramGrid = ParamGridBuilder().build()\n\n  # Setup model evaluators\n  rmseevaluator = RegressionEvaluator() #Note: By default, it will show how many units off in the same scale as the target -- RMSE\n  r2evaluator = RegressionEvaluator(metricName=\"r2\") #Select R2 as our main scoring metric\n\n  # Setup cross validator\n  cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=r2evaluator, numFolds=numberOfCVFolds) \n\n  # Fit model on \"train\" set\n  cvModel = cv.fit(train)\n\n  # Get the best model based on CrossValidator\n  model = cvModel.bestModel\n\n  # Run inference on \"test\" set\n  predictions = model.transform(test)\n\n  rmse = rmseevaluator.evaluate(predictions)\n  r2 = r2evaluator.evaluate(predictions)\n\n  mlflow.log_param(\"transformer-pipeline-id\",\"${pipeline:id()}\")\n\n  mlflow.log_param(\"features\", features)\n  mlflow.log_param(\"maxIter_hyperparam\", maxIter)\n  mlflow.log_param(\"numberOfCVFolds_hyperparam\", numberOfCVFolds)\n  mlflow.log_metric(\"rmse_metric_param\", rmse)\n  mlflow.log_metric(\"r2_metric_param\", r2)\n\n  # Log and register the model\n  mlflow.spark.log_model(spark_model=model, artifact_path=\"SparkML-GBTRegressor-model\", registered_model_name=\"SparkML-GBTRegressor-model\")\n\nmlflow.end_run()\n\n# Transition the current model to 'Staging' or 'Production'\ncurrent_version = mlflow_client.search_model_versions('name=\"SparkML-GBTRegressor-model\"')[0].version\nwhile mlflow_client.search_model_versions('name=\"SparkML-GBTRegressor-model\"')[0].status != 'READY':\n  current_version = current_version\n\nif (r2 >= ${r2Threshold} or rmse <= ${rmseThreshold}):\n  stage = \"Production\"\n\nmlflow_client.transition_model_version_stage(name=\"SparkML-GBTRegressor-model\",stage=stage,version=current_version)\n\noutput = inputs[0]\n```"]