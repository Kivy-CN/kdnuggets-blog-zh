- en: 6 Common Mistakes in Data Science and How To Avoid Them
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html](https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/97882db692355f38fadc7052f944aab0.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Photo by [chuttersnap](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral).*'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In data science or machine learning, we use data for descriptive analytics to
    draw out meaningful conclusions from the data, or we can use data for predictive
    purposes to build models that can make predictions on unseen data. The reliability
    of any model depends on the level of expertise of the data scientist. It is one
    thing to build a machine learning model. It is another thing to ensure the model
    is optimal and of the highest quality. This article will discuss six common mistakes
    that can adversely influence the quality or predictive power of a machine learning
    model with several case studies included.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Common Mistakes in Data Science
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we discuss six common mistakes that can severely impact the
    quality of a data science model. Links to several real applications are included.
  prefs: []
  type: TYPE_NORMAL
- en: '**We often assume that our dataset is of good quality and reliable**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Data is key to any data science and machine learning task. Data comes in different
    flavors such as numerical data, categorical data, text data, image data, voice
    data, and video data. ***The predictive power of a model depends on the quality
    of data used in building the model***. It is therefore extremely important that
    before performing any data science task such as exploratory data analysis or building
    a model, you check the source and reliability of your data because even datasets
    that appear perfect may contain errors. There are several factors that could diminish
    the quality of your data:'
  prefs: []
  type: TYPE_NORMAL
- en: Wrong Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outliers in Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redundancy in Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unbalanced Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of Variability in Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Size of Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more information, please see the following article: [Data is Always Imperfect.](https://medium.com/towards-artificial-intelligence/data-is-always-imperfect-8611d667dd10)'
  prefs: []
  type: TYPE_NORMAL
- en: From my personal experience working on an industrial data science project, my
    team had to work with system engineers, electrical engineers, mechanical engineers,
    field engineers, and technicians over a period of 3 months just to understand
    the available dataset and how we could use it to frame the right questions to
    be answered using the data. Ensuring that your data is error-free and of high
    quality will help improve the accuracy and reliability of your model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Don’t focus on using the entire dataset**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sometimes as a data science aspirant, when you have to work on a data science
    project, you may be tempted to use the entire dataset provided. However, as already
    mentioned above, a dataset could have several imperfections, such as the presence
    of outliers, missing values, and redundant features. If the fraction of your dataset
    containing imperfections is really small, then you may simply eliminate the subset
    of imperfect data from your dataset. However, if the proportion of improper data
    is significant, then methods such as data imputation techniques could be used
    to approximate missing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before implementing a machine learning algorithm, it is necessary to select
    only relevant features in the training dataset. The process of transforming a
    dataset in order to select only relevant features necessary for training is called
    dimensionality reduction. Feature selection and dimensionality reduction are important
    because of three main reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**a) Prevents Overfitting**: A high-dimensional dataset having too many features
    can sometimes lead to overfitting (model captures both real and random effects).'
  prefs: []
  type: TYPE_NORMAL
- en: '**b) Simplicity**: An over-complex model having too many features can be hard
    to interpret, especially when features are correlated with each other.'
  prefs: []
  type: TYPE_NORMAL
- en: '**c) Computational Efficiency**: A model trained on a lower-dimensional dataset
    is computationally efficient (execution of algorithm requires less computational
    time).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information about dimensionality reduction techniques, please see
    the following articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Feature Selection and Dimensionality Reduction Using Covariance Matrix Plot](https://medium.com/towards-artificial-intelligence/feature-selection-and-dimensionality-reduction-using-covariance-matrix-plot-b4c7498abd07)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning: Dimensionality Reduction via Principal Component Analysis](https://medium.com/towards-artificial-intelligence/machine-learning-dimensionality-reduction-via-principal-component-analysis-1bdc77462831)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using dimensionality reduction techniques to remove unnecessary correlations
    between features could help improve the quality and predictive power of your machine
    learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale your data before using it for model building**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scaling your features will help improve the quality and predictive power of
    your model. For example, suppose you would like to build a model to predict a
    target variable *creditworthiness* based on predictor variables such as *income*
    and *credit score*. Because credit scores range from 0 to 850 while annual income
    could range from $25,000 to $500,000, without scaling your features, the model
    will be biased towards the *income* feature. This means the weight factor associated
    with the *income* parameter will be very small, which will cause the predictive
    model to be predicting *creditworthiness* based only on the *income* parameter.
  prefs: []
  type: TYPE_NORMAL
- en: In order to bring features to the same scale, we could decide to use either
    normalization or standardization of features. Most often, we assume data is normally
    distributed and default towards standardization, but that is not always the case.
    It is important that before deciding whether to use either standardization or
    normalization, you first take a look at how your features are statistically distributed.
    If the feature tends to be uniformly distributed, then we may use normalization
    (*MinMaxScale*r). If the feature is approximately Gaussian, then we can use standardization
    (*StandardScaler*). Again, note that whether you employ normalization or standardization,
    these are also approximative methods and are bound to contribute to the overall
    error of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tune hyperparameters in your model**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the wrong hyperparameter values in your model could lead to a non-optimal
    and low-quality model. It is important that you train your model against all hyperparameters
    in order to determine the model with optimal performance. A good example of how
    the predictive power of a model depends on hyperparameters can be found in the
    figure below (source: [Bad and Good Regression Analysis](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/87bb2bae300c321cf46483dfefaa6cd2.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1**. Regression analysis using different values of the learning rate
    parameter. Source: [Bad and Good Regression Analysis](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff),
    Published in Towards AI, February 2019, by Benjamin O. Tayo.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in mind that using default hyperparameters will not always lead to an
    optimal model. For more information about hyperparameters, please see this article:
    [Model Parameters and Hyperparameters in Machine Learning — What is the difference](https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compare different algorithms**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is important to compare the predictive power of several different algorithms
    before selecting your final model. For example, if you are building a ***classification
    model***, you may try the following algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Machines (SVM)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision tree classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-nearest neighbor classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naive Bayes classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are building a ***linear regression model***, you may compare the following
    algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K-neighbors regression (KNR)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support Vector Regression (SVR)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more information about comparing different algorithms, please see the following
    articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[A Comparative Study of Linear and KNN Regression](https://medium.com/towards-artificial-intelligence/a-comparative-study-of-linear-and-knn-regression-a31955e6263d)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Process Tutorial](https://medium.com/swlh/machine-learning-process-tutorial-222327f53efb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quantify random error and uncertainties in your model**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Every machine learning model has an inherent random error. This error arises
    from the inherent random nature of the dataset; from the random nature in which
    the dataset is partitioned into training and testing sets during model building;
    or from randomization of the target column (a method used for detecting overfitting).
    It is important to always quantify how random error affects the predictive power
    of your model. This would help improve the reliability and quality of your model.
    For more information about random error quantification, please see the following
    article: [Random Error Quantification in Machine Learning](https://medium.com/towards-artificial-intelligence/random-error-quantification-in-machine-learning-846f6e78e519).'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In summary, we have discussed six common mistakes that can influence the quality
    or predictive power of a machine learning model. It is useful to always ensure
    that your model is optimal and of the highest quality. Avoiding the mistakes discussed
    above can enable a data science aspirant to build reliable and trustworthy models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Quality Assessment Is Not All Roses. What Challenges Should You Be Aware
    Of?](https://www.kdnuggets.com/2019/09/data-quality-assessment-challenges.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Must-Know: What are common data quality issues for Big Data and how to handle
    them?](https://www.kdnuggets.com/2017/05/must-know-common-data-quality-issues-big-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Scientists think data is their #1 problem. Here’s why they’re wrong.](https://www.kdnuggets.com/2020/09/data-scientist-data-problem-wrong.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Common Python Gotchas (And How To Avoid Them)](https://www.kdnuggets.com/5-common-python-gotchas-and-how-to-avoid-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Crucial Challenges in Conversational AI Development and How to Avoid Them](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Most Common Data Quality Issues and How to Fix Them](https://www.kdnuggets.com/2022/11/10-common-data-quality-issues-fix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
