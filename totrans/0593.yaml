- en: 'Stable Diffusion: Basic Intuition Behind Generative AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定扩散：生成 AI 的基本直觉
- en: 原文：[https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)
- en: '![Stable Diffusion: Basic Intuition Behind Generative AI](../Images/b12ef6f99e4bb18b488bc1b882e2f991.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![稳定扩散：生成 AI 的基本直觉](../Images/b12ef6f99e4bb18b488bc1b882e2f991.png)'
- en: Image generated using [Stable Diffusion](https://huggingface.co/spaces/stabilityai/stable-diffusion)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 [稳定扩散](https://huggingface.co/spaces/stabilityai/stable-diffusion) 生成的图像
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The world of AI has shifted dramatically towards generative modeling over the
    past years, both in Computer Vision and Natural Language Processing. Dalle-2 and
    Midjourney have caught people's attention, leading them to recognize the exceptional
    work being accomplished in the field of Generative AI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，AI 的世界在计算机视觉和自然语言处理方面急剧向生成建模转变。Dalle-2 和 Midjourney 引起了人们的注意，使他们认识到生成 AI
    领域所取得的卓越成果。
- en: Most of the AI-generated images currently produced rely on Diffusion Models
    as their foundation. The objective of this article is to clarify some of the concepts
    surrounding Stable Diffusion and offer a fundamental understanding of the methodology
    employed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，大多数 AI 生成的图像都依赖于扩散模型作为基础。本文的目标是澄清一些围绕稳定扩散的概念，并提供对所用方法的基本理解。
- en: Simplified Architecture
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简化架构
- en: This flowchart shows the simplified version of a Stable Diffusion architecture.
    We will go through it piece by piece to build a better understanding of the internal
    workings. We will elaborate on the training process for better understanding,
    with the inference having only a few subtle changes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 该流程图展示了稳定扩散架构的简化版本。我们将逐步分析，以建立对内部工作原理的更好理解。我们将详细说明训练过程，以便更好地理解，而推理过程则只有一些微妙的变化。
- en: '![Stable Diffusion: Basic Intuition Behind Generative AI](../Images/28393ca4661a8aef89a52c4467bf3b0d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![稳定扩散：生成 AI 的基本直觉](../Images/28393ca4661a8aef89a52c4467bf3b0d.png)'
- en: Image by Author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供
- en: Inputs
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入
- en: The Stable Diffusion models are trained on Image Captioning datasets where each
    image has an associated caption or prompt that describes the image. There are
    therefore two inputs to the model; a textual prompt in natural language and an
    image of size (3,512,512) having 3 color channels and dimensions of size 512.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散模型在图像字幕数据集上进行训练，每个图像都有一个描述图像的字幕或提示。因此，模型有两个输入：自然语言的文本提示和一个大小为 (3,512,512)
    的图像，具有3个颜色通道和512的尺寸。
- en: Additive Noise
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加性噪声
- en: The image is converted to complete noise by adding Gaussian noise to the original
    image. This is done in consequent steps, for example, a small amount is noise
    is added to the image for 50 consecutive steps until the image is completely noisy.
    The diffusion process will aim to remove this noise and reproduce the original
    image. How this is done will be explained further.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向原始图像添加高斯噪声，将图像转换为完全的噪声。这是通过连续步骤完成的，例如，在50个连续步骤中向图像添加少量噪声，直到图像完全噪声化。扩散过程将旨在去除这些噪声并重建原始图像。如何完成这一过程将进一步解释。
- en: Image Encoder
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像编码器
- en: The Image encoder functions as a component of a Variational AutoEncoder, converting
    the image into a 'latent space' and resizing it to smaller dimensions, such as
    (4, 64, 64), while also including an additional batch dimension. This process
    reduces computational requirements and enhances performance. Unlike the original
    diffusion models, Stable Diffusion incorporates the encoding step into the latent
    dimension, resulting in reduced computation, as well as decreased training and
    inference time.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图像编码器作为变分自编码器的一部分，将图像转换为“潜在空间”，并将其调整为更小的尺寸，如(4, 64, 64)，同时还包括额外的批次维度。这个过程减少了计算要求并提高了性能。与原始扩散模型不同，Stable
    Diffusion将编码步骤集成到潜在维度中，从而减少了计算量，以及缩短了训练和推理时间。
- en: Text Encoder
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本编码器
- en: The natural language prompt is transformed into a vectorized embedding by the
    text encoder. This process employs a Transformer Language model, such as BERT
    or GPT-based CLIP Text models. Enhanced text encoder models significantly enhance
    the quality of the generated images. The resulting output of the text encoder
    consists of an array of 768-dimensional embedding vectors for each word. In order
    to control the prompt length, a maximum limit of 77 is set. As a result, the text
    encoder produces a tensor with dimensions of (77, 768).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言提示由文本编码器转换为向量化的嵌入。这个过程使用了Transformer语言模型，如BERT或基于GPT的CLIP文本模型。增强的文本编码器模型显著提高了生成图像的质量。文本编码器的输出结果是每个单词的768维嵌入向量数组。为了控制提示长度，设定了最大限制为77。因此，文本编码器生成了一个尺寸为(77,
    768)的张量。
- en: UNet
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UNet
- en: This is the most computationally expensive part of the architecture and main
    diffusion processing occurs here. It receives text encoding and noisy latent image
    as input. This module aims to reproduce the original image from the noisy image
    it receives. It does this through several inference steps which can be set as
    a hyperparameter. Normally 50 inference steps are sufficient.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是架构中计算开销最大的部分，主要的扩散处理在这里进行。它接收文本编码和嘈杂的潜在图像作为输入。该模块的目标是从接收到的嘈杂图像中重现原始图像。它通过多个推理步骤来实现这一点，这些步骤可以设置为超参数。通常50个推理步骤就足够了。
- en: Consider a simple scenario where an input image undergoes a transformation into
    noise by gradually introducing small amounts of noise in 50 consecutive steps.
    This cumulative addition of noise eventually transforms the original image into
    complete noise. The objective of the UNet is to reverse this process by predicting
    the noise added at the previous timestep. During the denoising process, the UNet
    begins by predicting the noise added at the 50th timestep for the initial timestep.
    It then subtracts this predicted noise from the input image and repeats the process.
    In each subsequent timestep, the UNet predicts the noise added at the previous
    timestep, gradually restoring the original input image from complete noise. Throughout
    this process, the UNet internally relies on the textual embedding vector as a
    conditioning factor.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 设想一个简单的场景，其中输入图像通过在50个连续步骤中逐渐引入少量噪声而转化为噪声。这种噪声的累积最终将原始图像转变为完全的噪声。UNet的目标是通过预测在前一个时间步添加的噪声来逆转这个过程。在去噪过程中，UNet从第50个时间步开始预测初始时间步添加的噪声。然后，它从输入图像中减去预测的噪声，并重复这一过程。在每个随后的时间步中，UNet预测前一个时间步添加的噪声，逐渐从完全的噪声中恢复原始输入图像。在整个过程中，UNet内部依赖于文本嵌入向量作为条件因素。
- en: The UNet outputs a tensor of size (4, 64, 64) that is passed to the decoder
    part of the Variational AutoEncoder.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: UNet输出一个大小为(4, 64, 64)的张量，传递给变分自编码器的解码器部分。
- en: Decoder
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码器
- en: The decoder reverses the latent representation conversion done by the encoder.
    It takes a latent representation and converts it back to image space. Therefore,
    it outputs a (3,512,512) image, the same size as the original input space. During
    training, we aim to minimize the loss between the original image and generated
    image. Given that, given a textual prompt, we can generate an image related to
    the prompt from a completely noisy image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器逆转编码器所做的潜在表示转换。它接收一个潜在表示，并将其转换回图像空间。因此，它输出一个(3,512,512)的图像，与原始输入空间的大小相同。在训练过程中，我们的目标是最小化原始图像与生成图像之间的损失。基于此，给定一个文本提示，我们可以从完全嘈杂的图像中生成与提示相关的图像。
- en: Bringing It All Together
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合一切
- en: During inference, we have no input image. We work only in text-to-image mode.
    We remove the Additive Noise part and instead use a randomly generated tensor
    of the required size. The rest of the architecture remains the same.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，我们没有输入图像。我们仅在文本到图像模式下工作。我们去掉了加性噪声部分，而是使用了随机生成的所需尺寸的张量。其余的架构保持不变。
- en: The UNet has undergone training to generate an image from complete noise, leveraging
    text prompt embedding. This specific input is used during the inference stage,
    enabling us to successfully generate synthetic images from the noise. This general
    concept serves as the fundamental intuition behind all generative computer vision
    models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: UNet 经过训练，可以从完全的噪声中生成图像，利用了文本提示嵌入。这种特定的输入在推理阶段使用，使我们能够成功地从噪声中生成合成图像。这一基本概念是所有生成计算机视觉模型的根本直观。
- en: '**[Muhammad Arham](https://www.linkedin.com/in/muhammad-arham-a5b1b1237/)**
    is a Deep Learning Engineer working in Computer Vision and Natural Language Processing.
    He has worked on the deployment and optimizations of several generative AI applications
    that reached the global top charts at Vyro.AI. He is interested in building and
    optimizing machine learning models for intelligent systems and believes in continual
    improvement.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**[穆罕默德·阿赫曼](https://www.linkedin.com/in/muhammad-arham-a5b1b1237/)** 是一位深度学习工程师，专注于计算机视觉和自然语言处理。他曾参与多项生成
    AI 应用的部署和优化，这些应用在 Vyro.AI 全球排行榜上取得了佳绩。他对构建和优化智能系统的机器学习模型感兴趣，并相信持续改进。'
- en: More On This Topic
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题更多内容
- en: '[Generative AI Playground: Text-to-Image Stable Diffusion with…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成 AI 游乐场：文本到图像的 Stable Diffusion](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion)'
- en: '[Become an AI Artist Using Phraser and Stable Diffusion](https://www.kdnuggets.com/2022/09/become-ai-artist-phraser-stable-diffusion.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Phraser 和 Stable Diffusion 成为 AI 艺术家](https://www.kdnuggets.com/2022/09/become-ai-artist-phraser-stable-diffusion.html)'
- en: '[3 Ways to Generate Hyper-Realistic Faces Using Stable Diffusion](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Stable Diffusion 生成超真实面孔的 3 种方法](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
- en: '[Diffusion and Denoising: Explaining Text-to-Image Generative AI](https://www.kdnuggets.com/diffusion-and-denoising-explaining-text-to-image-generative-ai)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[扩散与去噪：解释文本到图像生成 AI](https://www.kdnuggets.com/diffusion-and-denoising-explaining-text-to-image-generative-ai)'
- en: '[Top 7 Diffusion-Based Applications with Demos](https://www.kdnuggets.com/2022/10/top-7-diffusionbased-applications-demos.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前 7 个基于扩散的应用程序及演示](https://www.kdnuggets.com/2022/10/top-7-diffusionbased-applications-demos.html)'
- en: '[How ChatGPT Works: The Model Behind The Bot](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 如何运作：聊天机器人的模型](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
