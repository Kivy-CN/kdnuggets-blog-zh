# 快速轻松解决任何图像分类问题

> 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)

**作者：[Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)，科学家、工程师及企业家**

![Header image](../Images/0b4cbd51df6a71c1196bb2c9006f0001.png)

[Chris Ried](https://unsplash.com/photos/ieic5Tq8YMk) 在 [Unsplash](https://unsplash.com/search/photos/programming-python) 上的代码之美

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

**深度学习**正在快速成为人工智能应用中的关键工具（LeCun et al. 2015）。例如，在计算机视觉、自然语言处理和语音识别等领域，深度学习已取得了显著成果。因此，对深度学习的兴趣日益增长。

深度学习擅长的一个问题是**图像分类**（Rawat & Wang 2017）。图像分类的目标是根据一组可能的类别对特定图片进行分类。图像分类的经典示例是识别一组图片中的猫和狗（例如，[Dogs vs. Cats Kaggle Competition](https://www.kaggle.com/c/dogs-vs-cats)）。

从深度学习的角度来看，图像分类问题可以通过**迁移学习**来解决。实际上，图像分类领域的几项最先进成果都是基于迁移学习解决方案（Krizhevsky et al. 2012, Simonyan & Zisserman 2014, He et al. 2016）。Pan & Yang (2010) 提供了关于迁移学习的全面综述。

**本文展示了如何实现迁移学习解决方案以应对图像分类问题。** 文章中提出的实现基于 Keras (Chollet 2015)，使用 Python 编程语言。按照本文的实现，你将能够快速轻松地解决任何图像分类问题。

文章的组织方式如下：

1.  迁移学习

1.  卷积神经网络

1.  重用预训练模型

1.  迁移学习过程

1.  基于深度卷积神经网络的分类器

1.  示例

1.  摘要

1.  参考文献

### 1\. 迁移学习

转移学习是一种在计算机视觉中流行的方法，因为它允许我们以**节省时间的方式构建准确的模型**（Rawat & Wang 2017）。通过转移学习，你不是从头开始学习过程，而是从解决不同问题时已学习的模式开始。这样，你可以利用之前的学习成果，避免从头开始。可以将其视为深度学习版本的[Chartres](https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants)的“站在巨人的肩膀上”这一表达。

在计算机视觉中，转移学习通常通过使用**预训练模型**来表达。预训练模型是一个在大型基准数据集上训练的模型，用于解决类似于我们想要解决的问题。因此，由于训练这些模型的计算成本，通常会从已发布的文献中导入和使用模型（例如，[VGG](https://arxiv.org/pdf/1409.1556.pdf)，[Inception](https://arxiv.org/pdf/1512.00567.pdf)，[MobileNet](https://arxiv.org/pdf/1704.04861.pdf)）。Canziani等人（2016）提供了关于使用ImageNet（Deng et al. 2009）挑战数据的预训练模型在计算机视觉问题上的性能的综合评估。

### 2\. 卷积神经网络

许多用于转移学习的预训练模型基于大型**卷积神经网络**（CNN）（Voulodimos et al. 2018）。一般来说，CNN在广泛的计算机视觉任务中表现出色（Bengio 2009）。其高性能和训练的简便性是近年来CNN流行的主要因素之一。

一个典型的CNN有两个部分：

1.  **卷积基础**，由一系列卷积层和池化层组成。卷积基础的主要目标是从图像中生成特征。有关卷积层和池化层的直观解释，请参阅Chollet（2017）。

1.  **分类器**，通常由全连接层组成。分类器的主要目标是根据检测到的特征对图像进行分类。全连接层是一个层，其中的神经元与前一层中的所有激活都有完全的连接。

图1显示了**基于CNN的模型架构**。请注意，这只是一个简化版本，适用于本文的目的。实际上，这种模型的架构比我们在这里建议的要复杂得多。

![](../Images/2d7c77156366d480bd5e8c2be6c4da35.png)

图1\. 基于CNN的模型架构。

这些深度学习模型的一个重要方面是它们可以自动学习**层次特征表示**。这意味着第一层计算的特征是通用的，可以在不同的问题领域中重复使用，而最后一层计算的特征是特定的，并且依赖于选择的数据集和任务。根据 Yosinski 等人（2014）的说法，‘*如果第一层特征是通用的，最后一层特征是特定的，那么网络中一定存在从通用到特定的过渡*’。因此，我们的 CNN 的卷积基础——尤其是其较低层（即靠近输入的层）——涉及到通用特征，而分类器部分以及卷积基础中的一些较高层则涉及到专门化特征。

### 3\. 重新利用预训练模型

当你将一个预训练模型重新用于自己的需求时，首先需要移除原始分类器，然后添加一个适合你目的的新分类器，最后你需要根据以下**三种策略之一微调你的模型**：

1.  **训练整个模型。** 在这种情况下，你使用预训练模型的架构并根据你的数据集进行训练。你将从头开始学习模型，因此你需要一个大数据集（以及大量的计算能力）。

1.  **训练某些层并保持其他层冻结。** 正如你所记得的，较低层涉及到通用特征（与问题无关），而较高层涉及到特定特征（与问题相关）。在这里，我们通过选择调整网络权重的多少来处理这种二分法（冻结层在训练过程中不会改变）。通常，如果你有一个小数据集和大量参数，你会保持更多层被冻结以避免过拟合。相反，如果数据集很大且参数数量较少，你可以通过训练更多层以适应新任务来改进模型，因为过拟合不是问题。

1.  **冻结卷积基础。** 这种情况对应于训练/冻结权衡的极端情况。主要思想是保持卷积基础的原始形式，然后使用其输出作为分类器的输入。你将预训练模型用作固定的特征提取机制，这在计算能力有限、数据集较小和/或预训练模型解决的问题与目标问题非常相似的情况下可能会很有用。

图 2 以示意图的方式呈现了这三种策略。

![](../Images/01215828d6dedde4541e9b70fbe56de4.png)

图 2\. 微调策略。

与**策略3**的**直接**应用不同，**策略1**和**策略2**要求你对卷积部分使用的学习率**要小心**。学习率是一个超参数，它控制着你调整网络权重的幅度。当你使用基于CNN的预训练模型时，明智的做法是使用较小的学习率，因为高学习率会增加丢失先前知识的风险。假设预训练模型已经经过良好训练，这是一种合理的假设，保持较小的学习率将确保你不会过早且过度地扭曲CNN权重。

### 4\. 转移学习过程

从实际角度来看，整个转移学习过程可以总结如下：

1.  **选择一个预训练模型**。在众多可用的预训练模型中，选择一个看起来适合你的问题的模型。例如，如果你使用的是Keras，你可以立即访问一组模型，例如VGG（Simonyan & Zisserman 2014）、InceptionV3（Szegedy et al. 2015）和ResNet5（He et al. 2015）。[这里](https://keras.io/applications/)你可以查看Keras上所有可用的模型。

1.  **根据大小相似性矩阵对你的问题进行分类。**在图3中，你可以看到控制你选择的“矩阵”。该矩阵根据你的数据集的大小及其与预训练模型训练的数据集的相似性来分类你的计算机视觉问题。作为经验法则，如果你的数据集每类少于1000张图片，则认为它是小数据集。至于数据集的相似性，让常识来决定。例如，如果你的任务是识别猫和狗，ImageNet会是一个类似的数据集，因为它有猫和狗的图片。然而，如果你的任务是识别癌细胞，ImageNet就不能被视为类似的数据集。

1.  **微调你的模型。**在这里，你可以使用大小相似性矩阵来指导你的选择，然后参考我们之前提到的关于重新利用预训练模型的三种选项。图4提供了接下来文本的视觉总结。

+   **象限1**。大型数据集，但与预训练模型的数据集不同。这种情况将引导你采用*策略1*。由于你有一个大型数据集，你可以从头开始训练模型，随心所欲。尽管数据集不同，但在实践中，从预训练模型初始化你的模型，使用它的架构和权重仍然可能是有用的。

+   **象限 2。** 大型数据集，并且类似于预训练模型的数据集。在这里你可以进入幻想世界。任何选项都有效。最有效的选项可能是*策略 2*。由于我们有一个大型数据集，过拟合不应成为问题，因此我们可以尽可能多地学习。然而，由于数据集相似，我们可以通过利用先前的知识来节省大量训练工作。因此，仅需训练分类器和卷积基的顶部层即可。

+   **象限 3。** 小型数据集，并且与预训练模型的数据集不同。这是计算机视觉问题中的2-7不适合手牌。一切都对你不利。如果抱怨不是一个选项，你唯一的希望是*策略 2*。很难找到训练和冻结层数之间的平衡。如果你走得太深，模型可能会过拟合；如果你停留在模型的浅层，你将无法学到任何有用的东西。可能，你需要比在象限 2 中走得更深，并且需要考虑数据增强技术（有关数据增强技术的详细总结可以参考[这里](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)）。

+   **象限 4。** 小型数据集，但类似于预训练模型的数据集。我问了尤达大师关于这一点，他告诉我‘*最佳选项应该是策略 3*’。我不知道你怎么想，但我不低估原力。因此，选择*策略 3*。你只需要移除最后一个全连接层（输出层），将预训练模型作为固定特征提取器运行，然后使用生成的特征来训练新的分类器。

![](../Images/cefb71a15b54427582c7d4e630e3e3dc.png) ![](../Images/7b543ae2e3f06d6e2c2c072741aca2fb.png)

图 3 和 图 4\. 尺寸-相似度矩阵（左）和微调预训练模型的决策图（右）。

### 5\. 深度卷积神经网络上的分类器

如前所述，**基于预训练卷积神经网络**的**图像分类模型**通常由**两个部分**组成：

1.  **卷积基**，它执行特征提取。

1.  **分类器**，它根据卷积基提取的特征对输入图像进行分类。

由于在本节中我们重点关注分类器部分，我们必须首先说明构建分类器可以采用不同的方法。其中一些最受欢迎的方法是：

1.  **全连接层。** 对于图像分类问题，标准方法是使用一系列全连接层，后跟一个经过softmax激活的层（Krizhevsky 等 2012，Simonyan & Zisserman 2014，Zeiler & Fergus 2014）。softmax 层输出每个可能类别标签的概率分布，然后我们只需根据最可能的类别对图像进行分类。

1.  **全局平均池化。** Lin 等人（2013）提出了一种基于全局平均池化的不同方法。在这种方法中，我们不在卷积基上添加全连接层，而是添加一个全局平均池化层，并将其输出直接馈入 softmax 激活层。Lin 等人（2013）对这种方法的优缺点进行了详细讨论。

1.  **线性支持向量机。** 线性支持向量机（SVM）是另一种可能的方法。根据 Tang（2013），我们可以通过在卷积基提取的特征上训练线性 SVM 分类器来提高分类准确性。有关 SVM 方法的优缺点的更多详细信息可以在论文中找到。

### 更多相关话题

+   [NExT-GPT 介绍：任意到任意的多模态大型语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)

+   [机器学习与大脑不同第 6 部分：…的重要性](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)

+   [以无需编码的方式轻松从网站抓取图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)

+   [通过 openplayground 在您的笔记本电脑上轻松探索 LLMs](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)

+   [通过 Scikit-LLM 轻松将 LLM 集成到您的 Scikit-learn 工作流程中](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)

+   [使用卷积神经网络 (CNNs) 的图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
