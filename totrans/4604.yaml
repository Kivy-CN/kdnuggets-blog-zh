- en: A 2019 Guide to Semantic Segmentation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2019年语义分割指南
- en: 原文：[https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html?page=2#comments)![Figure](../Images/07f5a30cb23b66cb64bace083c9f4c55.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html?page=2#comments)![图像](../Images/07f5a30cb23b66cb64bace083c9f4c55.png)'
- en: '[Image Source](https://pixabay.com/photos/traffic-locomotion-roadway-mobility-3612474/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://pixabay.com/photos/traffic-locomotion-roadway-mobility-3612474/)'
- en: Semantic segmentation refers to the process of linking each pixel in an image
    to a class label. These labels could include a person, car, flower, piece of furniture,
    etc., just to mention a few.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割是指将图像中的每个像素与一个类别标签关联的过程。这些标签可能包括一个人、车、花、家具等，仅举几例。
- en: We can think of semantic segmentation as [image classification](https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864) at
    a pixel level. For example, in an image that has many cars, segmentation will
    label all the objects as car objects. However, a separate class of models known
    as instance segmentation is able to label the separate instances where an object
    appears in an image. This kind of segmentation can be very useful in applications
    that are used to count the number of objects, such as counting the amount of foot
    traffic in a mall.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将语义分割视为[图像分类](https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864)的像素级别。例如，在一张有很多车的图像中，分割会将所有对象标记为车对象。然而，另一类称为实例分割的模型能够标记图像中对象出现的不同实例。这种分割在用于计数对象的应用中非常有用，例如计算购物中心中的步行流量。
- en: Some of its primary applications are in autonomous vehicles, human-computer
    interaction, robotics, and [photo editing/creativity tools](https://heartbeat.fritz.ai/momento-animating-memories-with-immersive-gifs-powered-by-mobile-machine-learning-81ff52806ae3).
    For example, semantic segmentation is very crucial in self-driving cars and robotics
    because it is important for the models to understand the context in the environment
    in which they’re operating.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些主要应用包括自动驾驶汽车、人机交互、机器人技术和[照片编辑/创意工具](https://heartbeat.fritz.ai/momento-animating-memories-with-immersive-gifs-powered-by-mobile-machine-learning-81ff52806ae3)。例如，语义分割在自动驾驶汽车和机器人技术中非常重要，因为对于模型来说，理解它们所操作的环境中的上下文至关重要。
- en: '![Figure](../Images/0789908d1ccda658ce70c44dd3d29c92.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/0789908d1ccda658ce70c44dd3d29c92.png)'
- en: '[source](http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文件](http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf)'
- en: 'We’ll now look at a number of research papers on covering state-of-the-art
    approaches to building semantic segmentation models, namely:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将查看一些研究论文，这些论文涵盖了构建语义分割模型的最先进方法，即：
- en: '[Weakly- and Semi-Supervised Learning of a Deep Convolutional Network for Semantic
    Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#7efa)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弱监督和半监督学习用于深度卷积网络的语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#7efa)'
- en: '[Fully Convolutional Networks for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#9141)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于语义分割的全卷积网络](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#9141)'
- en: '[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#6ad7)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[U-Net：用于生物医学图像分割的卷积网络](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#6ad7)'
- en: '[The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#3e4b)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一百层提拉米苏：用于语义分割的全卷积DenseNets](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#3e4b)'
- en: '[Multi-Scale Context Aggregation by Dilated Convolutions](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#851f)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多尺度上下文聚合通过膨胀卷积](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#851f)'
- en: '[DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully Connected CRFs](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#60e4)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepLab：利用深度卷积网络、空洞卷积和全连接CRFs进行语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#60e4)'
- en: '[Rethinking Atrous Convolution for Semantic Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#a1f6)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[重新思考膨胀卷积用于语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#a1f6)'
- en: '[Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#1fc4)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带有膨胀可分离卷积的编码器-解码器用于语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#1fc4)'
- en: '[FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#f083)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FastFCN：重新思考骨干网络中的膨胀卷积用于语义分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#f083)'
- en: '[Improving Semantic Segmentation via Video Propagation and Label Relaxation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#ec16)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过视频传播和标签放松来改进语义分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#ec16)'
- en: '[Gated-SCNN: Gated Shape CNNs for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#b3f5)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gated-SCNN：用于语义分割的门控形状CNN](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#b3f5)'
- en: Passionate about machine learning? Same! We’re curating each week’s biggest
    stories, best tutorials, and latest research so you don’t have to. [Sign up for
    weekly updates delivered to your inbox](https://www.deeplearningweekly.com/newsletter?utm_campaign=dlweekly-newsletter-timesaver4&utm_source=heartbeat).
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对机器学习充满热情？我也是！我们每周策划最新的重大新闻、最佳教程和最新研究，省去你自己寻找的麻烦。[注册以获取每周更新](https://www.deeplearningweekly.com/newsletter?utm_campaign=dlweekly-newsletter-timesaver4&utm_source=heartbeat)。
- en: Weakly- and Semi-Supervised Learning of a Deep Convolutional Network for Semantic
    Image Segmentation (ICCV, 2015)
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 弱标注和半监督学习的深度卷积网络用于语义图像分割（ICCV，2015）
- en: This paper proposes a solution to the challenge of dealing with weakly-labeled
    data in deep convolutional neural networks (CNNs), as well as a combination of
    data that’s well-labeled and data that’s not properly labeled.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种解决深度卷积神经网络（CNNs）中处理弱标注数据挑战的方案，以及将标注良好的数据与标注不完全的数据结合的方法。
- en: In the paper, a combination of deep CNNs with a fully-connected conditional [random
    field](https://en.wikipedia.org/wiki/Conditional_random_field) is applied.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，应用了深度CNN与全连接条件[random field](https://en.wikipedia.org/wiki/Conditional_random_field)的结合。
- en: '**[Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation](https://arxiv.org/abs/1502.02734?source=post_page---------------------------)**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**[弱标注和半监督学习的DCNN用于语义图像分割](https://arxiv.org/abs/1502.02734?source=post_page---------------------------)**'
- en: '*Deep convolutional neural networks (DCNNs) trained on a large number of images
    with strong pixel-level annotations have...*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*在大量带有强像素级标注的图像上训练的深度卷积神经网络（DCNNs）具有...*'
- en: On the PASCAL VOC segmentation benchmark, this model gives a [mean intersection-over-union
    (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) score
    above 70%. One of the major challenges faced with this kind of model is that it
    requires images that are annotated at the pixel level during training.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在PASCAL VOC分割基准测试中，该模型的[平均交并比（IOU）](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)分数超过70%。这种模型面临的主要挑战之一是需要在训练期间进行像素级标注的图像。
- en: '![Figure](../Images/1020f5e46e86498cb31e25b77c7fcc11.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/1020f5e46e86498cb31e25b77c7fcc11.png)'
- en: '[source](https://arxiv.org/pdf/1502.02734.pdf)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1502.02734.pdf)'
- en: 'The main contributions of this paper are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的主要贡献是：
- en: Introduction of Expectation-Maximization algorithms for bounding box or image-level
    training that can be applied to both weakly-supervised and semi-supervised settings.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入了期望最大化算法，用于边界框或图像级训练，适用于弱监督和半监督设置。
- en: Proves that combining weak and strong annotations improves performance. The
    writers of this paper reach 73.9% IOU performance on PASCAL VOC 2012 after merging
    annotations from the MS-COCO datasets and PASCAL datasets.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明了结合弱标注和强标注可以提高性能。本文作者在合并来自MS-COCO数据集和PASCAL数据集的标注后，在PASCAL VOC 2012上达到了73.9%的IOU性能。
- en: Proves that their approach achieves higher performance by merging a small number
    of pixel-level annotated images and a large number of bounding-box or image-level
    annotated images.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明了他们的方法通过合并少量像素级标注图像和大量边界框或图像级标注图像来实现更高的性能。
- en: '![Figure](../Images/70e1751ad5aa724af01578f46e6e8623.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/70e1751ad5aa724af01578f46e6e8623.png)'
- en: '[source](https://arxiv.org/pdf/1502.02734.pdf)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/pdf/1502.02734.pdf)'
- en: Fully Convolutional Networks for Semantic Segmentation (PAMI, 2016)
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全卷积网络用于语义分割 (PAMI, 2016)
- en: The model proposed in this paper achieves a performance of 67.2% mean IU on
    PASCAL VOC 2012.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出的模型在 PASCAL VOC 2012 数据集上实现了 67.2% 的均值 IU 性能。
- en: '**[Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211?source=post_page---------------------------)**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[全卷积网络用于语义分割](https://arxiv.org/abs/1605.06211?source=post_page---------------------------)**'
- en: '*Convolutional networks are powerful visual models that yield hierarchies of
    features. We show that convolutional...*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积网络是强大的视觉模型，能够产生特征的层次结构。我们展示了卷积……*'
- en: Fully-connected networks take an image of any size and generate an output of
    the corresponding spatial dimensions. In this model, [ILSVRC classifiers](http://image-net.org/challenges/LSVRC/)are
    cast into fully-connected networks and augmented for dense prediction using pixel-wise
    loss and in-network up-sampling. Training for segmentation is then done by fine-tuning.
    Fine-tuning is done by back-propagation on the entire network.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接网络接收任何尺寸的图像，并生成相应空间维度的输出。在此模型中，[ILSVRC 分类器](http://image-net.org/challenges/LSVRC/)被转换为全连接网络，并通过像素级损失和网络内上采样进行增强。随后，通过微调进行分割训练。微调通过对整个网络进行反向传播完成。
- en: '![Figure](../Images/3ae028eb91479ce7bc8825f79bb2b4a4.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/3ae028eb91479ce7bc8825f79bb2b4a4.png)'
- en: '[source](https://arxiv.org/pdf/1605.06211.pdf)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/pdf/1605.06211.pdf)'
- en: 'U-Net: Convolutional Networks for Biomedical Image Segmentation (MICCAI, 2015)'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'U-Net: 用于生物医学图像分割的卷积网络 (MICCAI, 2015)'
- en: In biomedical image processing, it’s very crucial to get a class label for every
    cell in the image. The biggest challenge in biomedical tasks is that thousands
    of images for training are not easily accessible.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物医学图像处理中，为图像中的每个细胞获取一个类别标签是非常关键的。生物医学任务中的最大挑战是训练所需的成千上万的图像并不容易获得。
- en: '[**U-Net: Convolutional Networks for Biomedical Image Segmentation**](https://arxiv.org/abs/1505.04597?source=post_page---------------------------)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[**U-Net: 用于生物医学图像分割的卷积网络**](https://arxiv.org/abs/1505.04597?source=post_page---------------------------)'
- en: '*There is large consent that successful training of deep networks requires
    many thousand annotated training samples. In...*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*普遍认同的是，深度网络的成功训练需要大量标注的训练样本。在……*'
- en: This paper builds upon the fully convolutional layer and modifies it to work
    on a few training images and yield more precise segmentation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本文在全卷积层的基础上进行构建，并将其修改为在少量训练图像上工作，以实现更精确的分割。
- en: '![Figure](../Images/31f03b8b104d2569ff4f424247711c4f.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/31f03b8b104d2569ff4f424247711c4f.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/abs/1505.04597)'
- en: Since very little training data is available, this model uses data augmentation
    by applying elastic deformations on the available data. As illustrated in figure
    1 above, the network architecture is made up of a contracting path on the left
    and an expansive path on the right.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可用的训练数据非常有限，该模型通过对现有数据进行弹性变形来进行数据增强。如上图 1 所示，网络架构由左侧的收缩路径和右侧的扩展路径组成。
- en: The contracting path is made up of two 3x3 convolutions. Each of the convolutions
    is followed by a rectified linear unit and a 2x2 max pooling operation for downsampling.
    Every downsampling stage doubles the number of feature channels. The expansive
    path steps include an upsampling of the feature channels. This is followed by
    2x2 up-convolution that halves the number of feature channels. The final layer
    is a 1x1 convolution that is used to map the component feature vectors to the
    required number of classes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩路径由两个 3x3 的卷积层组成。每个卷积层后面跟随一个修正线性单元和一个 2x2 的最大池化操作用于下采样。每个下采样阶段都会使特征通道的数量翻倍。扩展路径步骤包括特征通道的上采样。之后是
    2x2 的上卷积，减少特征通道的数量。最终层是一个 1x1 的卷积，用于将组件特征向量映射到所需的类别数量。
- en: '![Figure](../Images/695df8cbe9fd49e377be06a203db4c6b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/695df8cbe9fd49e377be06a203db4c6b.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/abs/1505.04597)'
- en: In this model, training is done using the input images, their segmentation maps,
    and a stochastic gradient descent implementation of Caffe. Data augmentation is
    used to teach the network the required robustness and invariance when very little
    training data is used. This model achieved a [mean intersection-over-union (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) score
    of 92% on one of the experiments.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在该模型中，训练使用输入图像、它们的分割图和Caffe的随机梯度下降实现。数据增强用于教会网络在训练数据非常少时所需的鲁棒性和不变性。该模型在一次实验中达到了[平均交并比（IOU）](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)
    92%的得分。
- en: '![Figure](../Images/819be25a915d06b500daccd66923bf07.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/819be25a915d06b500daccd66923bf07.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/abs/1505.04597)'
- en: 'The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation (2017)'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 《一百层的提拉米苏：用于语义分割的全卷积DenseNets》（2017）
- en: The idea behind DenseNets is that having each layer connected to every layer
    in a feed-forward manner makes the network easier to train and more accurate.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: DenseNets的核心思想是使每一层以前馈方式连接到每一层，从而使网络更容易训练且更准确。
- en: '[**The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation**](https://arxiv.org/abs/1611.09326?source=post_page---------------------------)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[**一百层的提拉米苏：用于语义分割的全卷积DenseNets**](https://arxiv.org/abs/1611.09326?source=post_page---------------------------)'
- en: '*State-of-the-art approaches for semantic image segmentation are built on Convolutional
    Neural Networks (CNNs). The...*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*最先进的语义图像分割方法基于卷积神经网络（CNN）。*'
- en: The model’s architecture is built in dense blocks of downsampling and upsampling
    paths. The downsampling path has 2 Transitions Down (TD) while the upsampling
    path has 2 Transitions Up (TU). The circle and arrows represent connectivity patterns
    within the network.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的架构由下采样和上采样路径的密集块构成。下采样路径有2个下采样过渡（TD），而上采样路径有2个上采样过渡（TU）。圆圈和箭头代表网络内的连接模式。
- en: '![Figure](../Images/f81b34a6f31353f1cf4225530d1d1699.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/f81b34a6f31353f1cf4225530d1d1699.png)'
- en: '[source](https://arxiv.org/pdf/1611.09326.pdf)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1611.09326.pdf)'
- en: 'The main contributions of this paper are:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的主要贡献包括：
- en: Extends the DenseNet architecture to fully convolutional networks for use in
    semantic segmentation.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展了DenseNet架构到完全卷积网络，用于语义分割。
- en: Proposes upsampling paths from dense networks that perform better than other
    upsampling paths.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出了比其他上采样路径表现更好的密集网络上采样路径。
- en: Proves that the network can produce state-of-the-art results on standard benchmarks.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明该网络能够在标准基准上产生最先进的结果。
- en: This model achieves a global accuracy of 88% on the [CamVid dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在[CamVid数据集](http://mi.eng.cam.ac.uk/research/projects/VideoRec/)上的全球准确率达到了88%。
- en: '![](../Images/8c59a5ac4ebeee0242d1b5d5324ae9b5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c59a5ac4ebeee0242d1b5d5324ae9b5.png)'
- en: '![Figure](../Images/d072fcb801ed0438b4ba74eb68b392fe.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/d072fcb801ed0438b4ba74eb68b392fe.png)'
- en: '[source](https://arxiv.org/pdf/1611.09326.pdf)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1611.09326.pdf)'
- en: '* * *'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT需求'
- en: '* * *'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关更多内容
- en: '[Misconceptions About Semantic Segmentation Annotation](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于语义分割注释的误解](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)'
- en: '[The Power of a Semantic Layer: A Data Engineer''s Guide](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层的力量：数据工程师指南](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义向量搜索如何改变客户支持互动](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
- en: '[Semantic Search with Vector Databases](https://www.kdnuggets.com/semantic-search-with-vector-databases)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用向量数据库的语义搜索](https://www.kdnuggets.com/semantic-search-with-vector-databases)'
- en: '[Semantic Layer: The Backbone of AI-powered Data Experiences](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层：AI驱动的数据体验的支柱](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
- en: '[6 Reasons Why a Universal Semantic Layer is Beneficial to Your Data Stack](https://www.kdnuggets.com/2024/01/cube-6-reasons-why-a-universal-semantic-layer-is-beneficial)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么通用语义层对您的数据栈有益的6个原因](https://www.kdnuggets.com/2024/01/cube-6-reasons-why-a-universal-semantic-layer-is-beneficial)'
