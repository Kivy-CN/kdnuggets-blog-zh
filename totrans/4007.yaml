- en: 7 Steps to Mastering Data Cleaning with Python and Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![7-steps-pandas](../Images/044f1484c6d7a0a69ebf6b54bfd06a62.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Pandas is the most widely used Python library for data analysis and manipulation.
    But the data that you read from the source often requires a series of data cleaning
    steps—before you can analyze it to gain insights, answer business questions, or
    build machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: This guide breaks down the process of data cleaning with pandas into 7 practical
    steps. We’ll spin up a sample dataset and work through the data cleaning steps.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Spinning Up a Sample DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Link to Colab Notebook](https://github.com/balapriyac/data-science-tutorials/blob/main/pandas/data_cleaning_with_pandas.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we get started with the actual data cleaning steps, let''s create pandas
    dataframe with employee records. We’ll use Faker for synthetic data generation.
    So install it first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'If you’d like, you can follow along with the same example. You can also use
    a dataset of your choice. Here’s the code to generate 1000 records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s tweak this dataframe a bit to introduce missing values, duplicate records,
    outliers, and more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s create a dataframe with these records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that we set the seed for Faker and not the random module. So there'll be
    some randomness in the records you generate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Understanding the Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Step 0 is always to understand the business question/problem that you are
    trying to solve**. Once you know that you can start working with the data you’ve
    read into your pandas dataframe.'
  prefs: []
  type: TYPE_NORMAL
- en: But before you can do anything meaningful on the dataset, it’s important to
    first get a high-level overview of the dataset. This includes getting some basic
    information on the different fields and the total number of records, inspecting
    the head of the dataframe, and the like.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we run the `info()` method on the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'And inspect the head of the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![df-head](../Images/27e6ebda1c0d9224cc96b742098b8b2f.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of df.head()
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Handling Duplicates'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Duplicate records are a common problem that skews the results of analysis. So
    we should identify and remove all duplicate records so that we're working with
    only the unique data records.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how we find all the duplicates in the dataframe and then drop all the
    duplicates in place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3: Handling Missing Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Missing data is a common data quality issue in many data science projects. If
    you take a quick look at the result of the `info()` method from the previous step,
    you should see that the number of non-null objects is not identical for all fields,
    and there are missing values in the email column. We’ll get the exact count nonetheless.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the number of missing values in each column you can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If there are missing values in one or more numeric column, we can apply suitable
    imputation techniques. But because the ''Email'' field is missing, let''s just
    set the missing emails to a placeholder email like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 4: Transforming Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you’re working on the dataset, there may be one or more fields that do
    not have the expected data type. In our sample dataframe, the ''Join_Date'' field
    has to be cast into a valid datetime object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we have the joining date, it''s actually more helpful to have a `Years_Employed`
    column as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 5: Cleaning Text Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s quite common to run into string fields with inconsistent formatting or
    similar issues. Cleaning text can be as simple as applying a case conversion or
    as hard as writing a complex regular expression to get the string to the required
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the example dataframe that we have, we see that the ''Address'' column contains
    many ‘\n’ characters that hinder readability. So let''s replace them with spaces
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 6: Handling Outliers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you scroll back up, you’ll see that we set some of the values in the 'Salary'
    column to be extremely high. Such outliers should also be identified and handled
    appropriately so that they don’t skew the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll often want to factor in *what* makes a data point an outlier (if it’s
    incorrect data entry or if they’re actually valid values and not outliers). You
    may then choose to handle them: drop records with outliers or get the subset of
    rows with outliers and analyze them separately.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use the z-score and find those salary values that are more than three
    standard deviations away from the mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 7: Merging Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most projects, the data that you have may *not* be the data you’ll want to
    use for analysis. You have to find the most relevant fields to use and also merge
    data from other dataframes to get more useful data that you can use for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: As a quick exercise, create another related dataframe and merge it with the
    existing dataframe on a common column such that the merge makes sense. Merging
    in pandas works very similarly to joins in SQL, so I suggest you try that as an
    exercise!
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'That''s all for this tutorial! We created a sample dataframe with records and
    worked through the various data cleaning steps. Here is an overview of the steps:
    understanding the data, handling duplicates, missing values, transforming data,
    cleaning text data, handling outliers, and merging data.'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn all about data wrangling with pandas, check out [7 Steps
    to Mastering Data Wrangling with Pandas and Python](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python).
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Data Wrangling with Pandas and Python](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mastering the Art of Data Cleaning in Python](https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets™ News 22:n05, Feb 2: 7 Steps to Mastering Machine…](https://www.kdnuggets.com/2022/n05.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Python for Data Science](https://www.kdnuggets.com/2022/06/7-steps-mastering-python-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
