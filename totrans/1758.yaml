- en: 'Data Science for Newbies: An Introductory Tutorial Series for Software Engineers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html](https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Harris Brakmić, Software Engineer.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**Editor''s note**: This is an overview of a multi-part tutorial on data science
    for newbies. The author has given the series a different -- tongue-in-cheek --
    title; take it in stride and recognize that the series'' approach and content
    is a fresh look at getting started with various aspects of data science from a
    software engineering perspective.'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![PySpark console](../Images/4ae095edf852180b5162a23294b12e52.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: The PySpark console.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 1: Getting Started](http://blog.brakmic.com/data-science-for-losers/)**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: To do some serious statistics with Python one should use a proper distribution
    like the one provided by Continuum Analytics. Of course, a manual installation
    of all the needed packages (Pandas, NumPy, Matplotlib etc.) is possible but beware
    the complexities and convoluted package dependencies. In this article we’ll use
    the Anaconda Distribution. The installation under Windows is straightforward but
    avoid the usage of multiple Python installations (for example, Python3 and Python2
    in parallel). It’s best to let Anaconda’s Python binary be your standard Python
    interpreter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2: Analyzing Reddit Comments & Querying Databases](http://blog.brakmic.com/data-science-for-losers-part-2/)**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Patterns are everywhere but many of them can’t be immediately recognized. This
    is one of the reasons why we’re digging deep holes in our databases, data warehouses,
    and other silos. In this article we’ll use a few more methods from Pandas’ DataFrames
    and generate plots. We’ll also create pivot tables and query an MS SQL database
    via ODBC. SqlAlchemy will be our helper in this case and we’ll see that even Losers
    like us can easily merge and filter SQL tables without touching the SQL syntax.
    No matter the task you always need a powerful tool-set in the first place. Like
    the Anaconda Distribution which we’ll be using here. Our data sources will be
    things like JSON files containing reddit comments or SQL-databases like Northwind.
    Many 90’es kids used Northwind to learn SQL.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Reddit comment ratings](../Images/cee5b84ed2764fddb38d5668cbeb509b.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: Highest rated comments for all available sub-reddits.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可用子 Reddit 的最高评分评论。
- en: '**[Part 2 Addendum: Playing SQL with DataFrames](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第二部分附录：使用 DataFrames 玩转 SQL](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**'
- en: So, let’s talk about a few features from Pandas I’ve forgot to mention in the
    last two articles.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们谈谈在前两篇文章中我忘记提到的一些 Pandas 特性。
- en: '**[Part 3: Scala & Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第三部分：Scala 与 Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**'
- en: 'By its own definition Spark is a fast, general engine for large-scale data
    processing. Well, someone would say: but we already have Hadoop, so why should
    we use Spark? Such a question I’d answer with a remark that Hadoop is EJB reinvented
    and that we need something more flexible, more general, more expandable and…much
    faster than MapReduce. Spark handles both batch and streaming processing at a
    very fast rate.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 按照自己的定义，Spark 是一个用于大规模数据处理的快速、通用引擎。有人会说：但我们已经有 Hadoop 了，那为什么还要使用 Spark 呢？对此，我会回答
    Hadoop 是 EJB 的重生，我们需要更灵活、更通用、更可扩展的东西，而且……比 MapReduce 快得多。Spark 以非常快的速度处理批处理和流处理。
- en: '**[Part 4: Machine Learning](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第四部分：机器学习](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**'
- en: 'From my non-scientist perspective I’d define ML as a subset of the Artificial
    Intelligence research which develops self-learning (or self-improving?) algorithms
    that try to gain knowledge from data and make predictions based on it. However,
    ML is not only reserved for academia or some “enlightened circles”. We use ML
    every day without being aware of its existence and usefulness. A few examples
    of ML in the wild would be: spam filters, speech-recognition software, automatic
    text-analysis, “intelligent game characters”, or the upcoming self-driving cars.
    All these entities make decisions based on some ML algorithms.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从我非科学家的角度来看，我会将机器学习定义为人工智能研究的一个子集，它开发自我学习（或自我改进？）的算法，试图从数据中获得知识并基于此做出预测。然而，机器学习不仅仅是学术界或某些“开明圈子”的专利。我们每天都在使用机器学习，却未必意识到它的存在和实用性。机器学习的几个实际应用示例包括：垃圾邮件过滤器、语音识别软件、自动文本分析、“智能游戏角色”或即将到来的自动驾驶汽车。所有这些实体都基于一些机器学习算法做出决策。
- en: '![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)'
- en: DataFrames in the Spark stack.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 堆栈中的 DataFrames。
- en: '**[Part 5: Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第五部分：Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**'
- en: Before we start using DataFrames we first have to prepare our environment which
    will run in Jupyter (formerly known as “IPython”). After you’ve downloaded and
    unpacked the Spark Package you’ll find some important Python libraries and scripts
    inside the python/pyspark directory. These files are used, for example, when you
    start the PySpark REPL in the console. As you may know, Spark supports Java, Scala,
    Python and R. Python-based REPL called PySpark offers a nice option to control
    Spark via Python scripts
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用 DataFrames 之前，我们首先需要准备好将在 Jupyter（以前称为“IPython”）中运行的环境。在下载并解压 Spark
    包后，你会发现 python/pyspark 目录中有一些重要的 Python 库和脚本。这些文件在你启动控制台中的 PySpark REPL 时会被使用。正如你所知道的，Spark
    支持 Java、Scala、Python 和 R。基于 Python 的 REPL 称为 PySpark，它提供了一个通过 Python 脚本控制 Spark
    的良好选项。
- en: '**[Part 6: Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第六部分：Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**'
- en: In this article we’ll explore Microsoft’s Azure Machine Learning environment
    and how to combine Cloud technologies with Python and Jupyter. As you may know
    I’ve been extensively using them throughout this article series so I have a strong
    opinion on how a Data Science-friendly environment should look like. Of course,
    there’s nothing against other coding environments or languages, for example R,
    so your opinion may greatly differ from mine and this is fine. Also AzureML offers
    a very good R-support! So, feel free to adapt everything from this article to
    your needs. And before we begin, a few words about how I came to the idea to write
    about Azure and Data Science.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨微软的 Azure 机器学习环境以及如何将云技术与 Python 和 Jupyter 结合起来。正如你所知道的，我在整个系列文章中广泛使用了它们，所以我对数据科学友好型环境应该是什么样子有很强的看法。当然，也没有什么问题在其他编码环境或语言中，例如
    R，因此你的观点可能与我的大相径庭，这没关系。此外，AzureML 还提供了非常好的 R 支持！因此，请随意将这篇文章中的内容根据你的需要进行调整。在开始之前，先说几句关于我为何想写关于
    Azure 和数据科学的想法。
- en: '**[Part 7: Using Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第七部分：使用 Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**'
- en: While finishing my Data Science and ML Essentials course, I discovered that
    Azure ML has a built-in support for Jupyter and Python which, of course, made
    it very interesting to me because it makes Azure ML an ideal ground for experimentation.
    They even call one of their working areas “Experiments” so one can expect good
    Python (and R) support and many cool off-the-shelf modules. Being no different
    than other tech-enthusiasts I quickly decided to write an article describing some
    of the key parts of Azure ML.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成我的数据科学和机器学习基础课程时，我发现 Azure ML 内置了对 Jupyter 和 Python 的支持，这使得 Azure ML 对我来说非常有趣，因为它使
    Azure ML 成为实验的理想平台。他们甚至把一个工作区域称为“实验”，所以可以期待良好的 Python（和 R）支持以及许多酷炫的现成模块。和其他技术爱好者一样，我很快决定写一篇文章，描述
    Azure ML 的一些关键部分。
- en: '**Bio: [Harris Brakmić](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic))
    is a Software Developer at Advarics GmbH. He writes WebApps with Ractive, React,
    Backbone & DevExtreme, and Azure-based backends with C#.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[哈里斯·布拉克米奇](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic))
    是 Advarics GmbH 的软件开发人员。他使用 Ractive、React、Backbone 和 DevExtreme 开发 Web 应用，并用 C#
    开发基于 Azure 的后台。'
- en: '**Related:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习：完整详细概述](/2016/10/machine-learning-complete-detailed-overview.html)'
- en: '[An Introduction to the MXNet Python API ](/2017/05/intro-mxnet-python-api.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MXNet Python API 入门](/2017/05/intro-mxnet-python-api.html)'
- en: '[Getting Into Data Science: What You Need to Know](/2017/05/data-science-need-to-know.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[进入数据科学：你需要知道的](/2017/05/data-science-need-to-know.html)'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者 Pandas 教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
- en: '[Reinforcement Learning for Newbies](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[强化学习入门](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)'
- en: '[Software Developer vs Software Engineer](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件开发人员与软件工程师](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
- en: '[High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适用于数据工程师和数据科学家的高保真合成数据](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
- en: '[We Don''t Need Data Scientists, We Need Data Engineers](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们不需要数据科学家，我们需要数据工程师](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
- en: '[How Do Data Scientists and Data Engineers Work Together?](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家和数据工程师如何协作？](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)'
