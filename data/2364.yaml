- en: More Performance Evaluation Metrics for Classification Problems You Should Know
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你应该了解的更多分类问题性能评估指标
- en: 原文：[https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)
- en: 'Evaluating a model is a major part of building an effective machine learning
    model. The most frequent classification evaluation metric that we use should be
    ‘**Accuracy**’. You might believe that the model is good when the accuracy rate
    is 99%! However, it is not always true and can be misleading in some situations.
    I’m going to explain the 4 aspects as shown below in this article:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型是构建有效机器学习模型的关键部分。我们使用的最常见分类评估指标应该是**准确率**。你可能会认为当准确率达到99%时模型很好！然而，这并不总是准确的，并且在某些情况下可能会误导。我将在本文中解释如下4个方面：
- en: The Confusion Matrix for a 2-class classification problem
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2类分类问题的混淆矩阵
- en: The key classification metrics: *Accuracy, Recall, Precision, and F1- Score*
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键分类指标：*准确率、召回率、精准率和F1分数*
- en: The difference between *Recall and Precision in specific cases*
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*召回率和精准率在特定情况下的区别*'
- en: Decision Thresholds and Receiver Operating Characteristic (ROC) curve
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策阈值和接收者操作特征（ROC）曲线
- en: The Flow of Machine Learning Model
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型的流程
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In any binary classification task, we model can only achieve two results, either
    our model is **correct** or **incorrect **in the prediction where we only have
    two classes. Imagine we now have a classification task to predict if an image
    is a dog or cat. In supervised learning, we first **fit/train **a model on training
    data, then **test** the model on **testing data**. Once we have the model’s predictions
    from the **X_test** data, we compare it to the** true y_values** (the correct
    labels).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何二分类任务中，我们的模型只能得到两种结果：**正确**或**不正确**。假设我们现在有一个分类任务，要预测一张图像是狗还是猫。在监督学习中，我们首先在训练数据上**拟合/训练**一个模型，然后在**测试数据**上**测试**该模型。一旦我们从**X_test**数据中获得模型的预测结果，我们将其与**真实的
    y_values**（正确标签）进行比较。
- en: '![](../Images/f4563f2583050a1b1671bbc374b1be28.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4563f2583050a1b1671bbc374b1be28.png)'
- en: We feed the image of dog into our trained model before the model prediction.
    The model predicts that this is a dog, and then we compare the prediction to the
    correct label. If we compare the prediction to the label of “dog,” it is correct.
    However, if it predicts that this image is a cat, this comparison to the correct
    label would be incorrect.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型预测之前，我们将狗的图像输入到我们训练好的模型中。模型预测这是一只狗，然后我们将预测结果与正确标签进行比较。如果我们将预测结果与“狗”的标签进行比较，则预测正确。然而，如果预测结果是这张图像是一只猫，那么与正确标签的比较将是不正确的。
- en: We repeat this process for all the images in our X test data. Eventually, we
    will have a count of correctly matched and a count of incorrect matches. The key
    realisation is that not all incorrect or correct matches hold **equal value **in
    reality. Therefore a single metric won’t tell the whole story.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对X测试数据中的所有图像重复这一过程。最终，我们将获得正确匹配的数量和错误匹配的数量。关键的认识是，并非所有的错误或正确匹配在现实中都具有**相同的价值**。因此，单一指标不能全面反映情况。
- en: As mentioned, accuracy is one of the common evaluation metrics in classification
    problems, that is the total number of correct predictions divided by the total
    number of predictions made for a dataset. Accuracy is useful when the target class
    is *well balanced* but is not a good choice with unbalanced classes. Imagine we
    had 99 images of the dog and only 1 image of a cat in our training data, our model
    would be simply a line that always predicted dog, and therefore we got 99% accuracy.
    Data is always imbalanced in reality, such as Spam email, credit card fraud, and
    medical diagnosis. Hence, if we want to have a full picture of the model evaluation,
    other metrics such as recall and precision should also be considered.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，准确率是分类问题中的常见评估指标，即正确预测的总数除以数据集上做出的总预测数。当目标类别*平衡良好*时，准确率是有用的，但对于不平衡的类别就不太适用。想象一下我们有99张狗的图片和只有1张猫的图片在训练数据中，我们的模型将只是一个总是预测狗的线，因此得到了99%的准确率。现实中数据总是失衡的，如垃圾邮件、信用卡欺诈和医疗诊断。因此，如果我们想全面了解模型评估，还应考虑其他指标，如召回率和精准度。
- en: Confusion Matrix
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: Evaluation of the performance of a classification model is based on the counts
    of test records correctly and incorrectly predicted by the model. The confusion
    matrix provides a more insightful picture which is not only the performance of
    a predictive model, but also which classes are being predicted correctly and incorrectly,
    and what type of errors are being made. To illustrate, we can see how the 4 classification
    metrics are calculated (TP, FP, FN, TN), and our predicted value compared to the
    actual value in a confusion matrix is clearly presented in the below confusion
    matrix table.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对分类模型性能的评估基于模型正确和错误预测的测试记录计数。混淆矩阵提供了一个更有洞察力的图景，它不仅展示了预测模型的性能，还显示了哪些类别被正确和错误预测，错误类型是什么。为了说明这一点，我们可以看到四个分类指标（TP、FP、FN、TN）是如何计算的，并且在下面的混淆矩阵表中，我们的预测值与实际值的对比被清晰地呈现出来。
- en: '![](../Images/3d5f3e3de47423d7565d725b846eb01d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d5f3e3de47423d7565d725b846eb01d.png)'
- en: '*Possible Classification Outcomes: TP, FP, FN, TN.*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*可能的分类结果：TP、FP、FN、TN。*'
- en: '*The confusion matrix is useful for measuring Recall (also known as Sensitivity),
    Precision, Specificity, Accuracy, and, most importantly, the AUC-ROC Curve.*'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*混淆矩阵对于测量召回率（也称为敏感性）、精准度、特异性、准确率以及最重要的 AUC-ROC 曲线非常有用。*'
- en: Do you feel confused when you were reading the table? That’s expected. I was
    also before. Let me put it in an interesting scenario in terms of pregnancy analogy
    to explain the terms of TP, FP, FN, TN. We can then understand Recall, Precision,
    Specificity, Accuracy, and, most importantly, the AUC-ROC Curve.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 读表格时你感到困惑吗？这是正常的。我之前也是如此。让我用怀孕类比来解释 TP、FP、FN 和 TN 的术语。这样我们可以理解召回率、精准度、特异性、准确率，更重要的是
    AUC-ROC 曲线。
- en: '![](../Images/88b6a0ff716a6bf5b4af5e4fb6cc4a24.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88b6a0ff716a6bf5b4af5e4fb6cc4a24.png)'
- en: '*[image source](https://dzone.com/articles/understanding-the-confusion-matrix)*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*[图像来源](https://dzone.com/articles/understanding-the-confusion-matrix)*'
- en: The Equations of 4 Key Classification Metrics
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 四个关键分类指标的公式
- en: '![](../Images/8fa9dab027b54588244d29ee3b7acc2b.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fa9dab027b54588244d29ee3b7acc2b.png)'
- en: '**Recall versus Precision**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率与精准度**'
- en: '![](../Images/590c61e5345073ed8a891b794f61e1c7.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/590c61e5345073ed8a891b794f61e1c7.png)'
- en: '**Precision** is the ratio of *True Positives* to all the positives predicted
    by the model.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**精准度** 是模型预测的所有正样本中*真实正样本*的比例。'
- en: 'Low precision: the more False positives the model predicts, the lower the precision.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 低精准度：模型预测的假阳性越多，精准度越低。
- en: '**Recall (Sensitivity)**is the ratio of *True Positives* to all the positives
    in your Dataset.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率（敏感性）** 是数据集中所有正样本中*真实正样本*的比例。'
- en: 'Low recall: the more False Negatives the model predicts, the lower the recall.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 低召回率：模型预测的假阴性越多，召回率越低。
- en: '*The idea of recall and precision seems to be abstract. Let me illustrate the
    difference in three real cases.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率和精准度的概念似乎很抽象。让我通过三个实际案例来说明差异。*'
- en: '![](../Images/caffd27813ca620b178fbec91fbeb25d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/caffd27813ca620b178fbec91fbeb25d.png)'
- en: the result of TP will be that the COVID 19 residents diagnosed with COVID-19.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP 的结果是 COVID-19 居民被诊断为 COVID-19。
- en: the result of TN will be that healthy residents are with good health.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN 的结果是健康的居民身体健康。
- en: the result of FP will be that those actually healthy residents are predicted
    as COVID 19 residents.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP 的结果是那些实际上健康的居民被预测为 COVID-19 居民。
- en: the result of FN will be that those actual COVID 19 residents are predicted
    as the healthy residents
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN 的结果是那些实际的 COVID-19 居民被预测为健康居民。
- en: In case 1, which scenario do you think will have the highest cost?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在情况 1 中，你认为哪个场景的成本会最高？
- en: Imagine that if we predict COVID-19 residents as healthy patients and they do
    not need to quarantine, there would be a massive number of COVID-19 infections.
    The cost of f*alse negatives *is much higher than the cost of f*alse positives.*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果我们将 COVID-19 居民预测为健康患者，而他们不需要隔离，这将导致大量的 COVID-19 感染。假阴性的成本要远高于假阳性的成本。
- en: '![](../Images/27c47014ea641c459da7e6a1bdb23040.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27c47014ea641c459da7e6a1bdb23040.png)'
- en: the result of TP will be that spam emails are placed in the spam folder.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP 的结果是垃圾邮件被放入垃圾邮件文件夹。
- en: the result of TN will be that important emails are received.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN 的结果是重要的电子邮件被收到。
- en: the result of FP will be that important emails are placed in the spam folder.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP 的结果是重要的电子邮件被放入垃圾邮件文件夹。
- en: the result of FN will be that spam emails are received.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN 的结果是垃圾邮件被收到。
- en: In case 2, which scenario do you think will have the highest cost?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在情况 2 中，你认为哪个场景的成本会最高？
- en: Well, since missing important emails will clearly be more of a problem than
    receiving spam, we can say that in this case, FP will have a higher cost than
    FN.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，由于错过重要的电子邮件显然比收到垃圾邮件更严重，我们可以说，在这种情况下，FP 的成本会高于 FN。
- en: '![](../Images/05234286f46dea9a2fff74e5cfc4edd6.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05234286f46dea9a2fff74e5cfc4edd6.png)'
- en: the result of TP will be that bad loans are correctly predicted as bad loans.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP 的结果是坏贷款被正确预测为坏贷款。
- en: the result of TN will be that good loans are correctly predicted as good loans.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN 的结果是好贷款被正确预测为好贷款。
- en: the result of FP will be that (actual) good loans are incorrectly predicted
    as bad loans.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP 的结果是（实际的）好贷款被错误预测为坏贷款。
- en: the result of FN will be that (actual) bad loans are incorrectly predicted as
    good loans.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN 的结果是（实际的）坏贷款被错误预测为好贷款。
- en: In case 3, which scenario do you think will have the highest cost?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在情况 3 中，你认为哪个场景的成本会最高？
- en: The banks would lose a bunch amount of money if the actual bad loans are predicted
    as good loans due to loans not being repaid. On the other hand, banks won't be
    able to make more revenue if the actual good loans are predicted as bad loans.
    Therefore, the cost of *False Negatives *is much higher than the cost of *False
    Positives. *Imagine that.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实际的坏贷款被预测为好贷款，银行将损失大量资金，因为贷款无法偿还。另一方面，如果实际的好贷款被预测为坏贷款，银行将无法获得更多收入。因此，*假阴性*的成本要远高于*假阳性*的成本。想象一下吧。
- en: '**Summary**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**'
- en: '![](../Images/b0c7d23958f29d84cfc490697ab5f3e2.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0c7d23958f29d84cfc490697ab5f3e2.png)'
- en: In practice, the cost of false negatives is not the same as the cost of false
    positives, depending on the different specific cases. It is evident that not only
    should we calculate accuracy, but we should also evaluate our model using other
    metrics, for example, *Recall *and *Precision*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，假阴性的成本与假阳性的成本不同，这取决于具体情况。显然，我们不仅应计算准确率，还应使用其他指标来评估我们的模型，例如 *召回率* 和 *精确率*。
- en: Combining Precision and Recall
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合精确率和召回率
- en: In the above three cases, we want to maximize either recall or precision at
    the expense of the other metric. For example, in the case of a good or bad loan
    classification, we would like to decrease FN to increase recall. However, in cases
    where we want to find an optimal blend of precision and recall, we can combine
    the two metrics using the [F1 score](https://en.wikipedia.org/wiki/F1_score).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述三个情况中，我们希望在牺牲另一个指标的情况下，最大化召回率或精确率。例如，在好贷款或坏贷款分类的情况下，我们希望减少 FN 以提高召回率。然而，在我们希望找到精确率和召回率的最佳结合的情况下，我们可以通过使用
    [F1 分数](https://en.wikipedia.org/wiki/F1_score) 将这两个指标结合起来。
- en: '![](../Images/6cc7f8f2835ab8e0ce9b2674d62faf94.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6cc7f8f2835ab8e0ce9b2674d62faf94.png)'
- en: F-Measure provides a single score that balances both the concerns of precision
    and recall in one number. A good F1 score means that you have low false positives
    and low false negatives, so you’re correctly identifying real threats, and you
    are not disturbed by false alarms. An F1 score is considered perfect when it’s
    1, while the model is a total failure when it’s 0.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: F-Measure 提供了一个综合精确率和召回率的单一评分。一个好的 F1 分数意味着你有低假阳性和低假阴性，因此你能正确识别实际威胁，并且不会被虚假警报所干扰。当
    F1 分数为 1 时，表示模型完美；而当 F1 分数为 0 时，表示模型完全失败。
- en: '![](../Images/af4424d44698efd4190dad446b7b782f.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af4424d44698efd4190dad446b7b782f.png)'
- en: Decision Threshold
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策阈值
- en: ROC is a major visualization technique for presenting the performance of a classification
    model. It summarizes the trade-off between the true positive rate (tpr) and false
    positive rate (fpr) for a predictive model using different probability thresholds.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 是呈现分类模型性能的主要可视化技术。它总结了使用不同概率阈值时预测模型的真正率（tpr）和假正率（fpr）之间的权衡。
- en: '![](../Images/4ba9645520e1252a292cc220de108b25.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ba9645520e1252a292cc220de108b25.png)'
- en: '*The equation of tpr and fpr.*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*tpr 和 fpr 的公式。*'
- en: The true positive rate (tpr) is the recall and the false positive rate (FPR)
    is the probability of a false alarm.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 真正率（tpr）是召回率，而假正率（FPR）是误报的概率。
- en: A ROC curve plots the true positive rate (tpr) versus the false positive rate
    (fpr) as a function of the model’s threshold for classifying a positive. Given
    that **c **is a constant known as decision threshold, the below ROC curve suggests
    that by default c=0.5, when c=0.2, both tpr and fpr increase. When c=0.8, both
    tpr and fpr decrease. In general, tpr and fpr increase as c decrease. In the extreme
    case when c=1, all cases are predicted as negative; tpr=fpr=0\. On the other hand,
    when c=0, all cases are predicted as positive; tpr=fpr=1.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线绘制了真正率（tpr）与假正率（fpr）之间的关系，作为模型分类正例的阈值函数。考虑到**c**是称为决策阈值的常数，下图 ROC 曲线表明默认
    c=0.5，当 c=0.2 时，tpr 和 fpr 都增加；当 c=0.8 时，tpr 和 fpr 都减少。一般来说，tpr 和 fpr 随着 c 的减少而增加。在极端情况下，当
    c=1 时，所有案例被预测为负例；tpr=fpr=0。而当 c=0 时，所有案例被预测为正例；tpr=fpr=1。
- en: '![](../Images/19f60956fb7baa2b0c3430dafd9bbf63.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19f60956fb7baa2b0c3430dafd9bbf63.png)'
- en: '*ROC chart.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*ROC 图。*'
- en: Finally, we can assess the performance of the model by the area under the ROC
    curve (**AUC**). As a rule of thumb, 0.9–1=excellent; 0.8-.09=good; 0.7–0.8=fair;
    0.6–0.7=poor; 0.50–0.6=fail.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们可以通过 ROC 曲线下的面积（**AUC**）来评估模型的性能。作为经验法则，0.9–1=优秀；0.8-0.9=良好；0.7–0.8=中等；0.6–0.7=差；0.50–0.6=失败。
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The Confusion Matrix for a 2-class classification problem
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二分类问题的混淆矩阵
- en: The key classification metrics: *Accuracy, Recall, Precision, and F1- Score*
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要分类指标：*准确率、召回率、精准率和 F1 分数*
- en: The difference between *Recall and Precision in specific cases*
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*召回率与精准率在特定情况下的区别*'
- en: Decision Thresholds and Receiver Operating Characteristic (ROC) curve
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策阈值和接收者操作特征（ROC）曲线
- en: '**[Clare Liu](https://www.linkedin.com/in/clareliuchungyan/)** is a Data Scientist
    at Fintech (bank) industry, based in HK. Passionate in resolving mystery about
    data science and machine learning. Join me on the self-learning journey.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Clare Liu](https://www.linkedin.com/in/clareliuchungyan/)** 是一位在香港金融科技行业的
    数据科学家。热衷于解决关于数据科学和机器学习的难题。加入我，一起踏上自学之旅。'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习评估指标：理论与概述](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类指标详细讲解：逻辑回归与……](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解分类指标：评估模型准确性的指南](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[想用你的数据技能解决全球问题？这里是……](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4 月 13 日：数据科学家应关注的 Python 库](https://www.kdnuggets.com/2022/n15.html)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可以帮助你解决实际问题的数据科学项目](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
