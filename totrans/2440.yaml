- en: 'Loss Functions: An Explainer'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失函数：解释
- en: 原文：[https://www.kdnuggets.com/2022/03/loss-functions-explainer.html](https://www.kdnuggets.com/2022/03/loss-functions-explainer.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/03/loss-functions-explainer.html](https://www.kdnuggets.com/2022/03/loss-functions-explainer.html)
- en: '**Loss function** is a method that evaluates how well the algorithm learns
    the data and produces correct outputs. It computes the distance between our predicted
    value and the actual value using a mathematical formula.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**损失函数**是一种评估算法学习数据并产生正确输出的方法。它使用数学公式计算预测值与实际值之间的距离。'
- en: In layman's terms, a loss function measures how wrong the model is in terms
    of its ability to estimate the relationship between x and y.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通俗来说，损失函数衡量模型在估计x和y之间关系的能力上有多么错误。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Loss functions can be categorized into two groups:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数可以分为两类：
- en: '**Classification** - which is about predicting a label, by identifying which
    category an object belongs to based on different parameters.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类** - 预测标签，通过根据不同的参数识别对象属于哪个类别。'
- en: '**Regression** - which is about predicting a continuous output, by finding
    the correlations between dependent and independent variables.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**回归** - 预测连续输出，通过找出依赖变量和自变量之间的相关性。'
- en: Below is a list of types of loss functions for both Classification and Regression
    tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是分类和回归任务中损失函数的类型列表。
- en: Cross Entropy
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉熵
- en: '**Cross Entropy** and Log Loss measure the same thing, however they are not
    the same and is used for Classification tasks. Cross Entropy measures the difference
    between two probability distributions for a given random variable or set of events.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉熵**和对数损失测量的是相同的内容，但它们并不相同，用于分类任务。交叉熵衡量给定随机变量或事件集的两个概率分布之间的差异。'
- en: 'Types of Cross Entropy:'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉熵的类型：
- en: Binary Cross Entropy - used for binary tasks
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类交叉熵 - 用于二分类任务
- en: 'Categorical Cross Entropy - used for both binary and multiclass tasks. This
    types of Cross Entropy requires the label to be encoded as categorical. For example;
    one-hot encoding for 3 classes will use this representation: [0, 1, 0], [1,0,0]…)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类交叉熵 - 用于二分类和多分类任务。这种交叉熵要求标签被编码为分类。例如；3个类别的独热编码将使用以下表示：[0, 1, 0], [1,0,0]…)
- en: 'Sparse Cross Entropy: - used for both binary and multiclass tasks. This types
    of Cross Entropy requires the label to be an integer; 0 or 1 or n'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏交叉熵 - 用于二分类和多分类任务。这种交叉熵要求标签为整数；0或1或n
- en: 'Code for Cross Entropy:'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉熵的代码：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Log Loss
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数损失
- en: '**Log Loss**, the binary of Cross Entropy is used in Classification tasks.
    It measures the performance of a classification model, where the output is a probability
    with values between 0 and 1.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**对数损失**，即交叉熵的二分类形式，用于分类任务。它衡量分类模型的性能，其中输出是一个介于0和1之间的概率值。'
- en: As the predicted probability gets further away from the actual label, Log loss
    increases. In the ideal world, a perfect model would have a Log Loss of 0.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随着预测概率与实际标签的偏差增大，对数损失增加。在理想情况下，完美的模型对数损失为0。
- en: '![Loss Functions: An Explainer](../Images/f739f48a00ac473c7aa2f07e97123a57.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数：解释](../Images/f739f48a00ac473c7aa2f07e97123a57.png)'
- en: 'Source: [ml-cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[ml-cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)
- en: In the image above, you can see that as the predicted probability reaches 1,
    the Log Loss decreases. On the other hand, you can see that as the predicted probability
    decreases, the Log Loss rapidly increases.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，你可以看到当预测概率达到1时，Log Loss 减少。另一方面，你可以看到当预测概率减少时，Log Loss 快速增加。
- en: Log Loss Using Scikit-learn
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Scikit-learn 计算 Log Loss
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Hinge
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hinge
- en: '**Hinge** is a loss function used for Classification tasks. This type of loss
    function incorporate a margin from the classification boundary against a loss.
    Hinge penalises misclassfied samples aswell are classifying one that are within
    the defined margin from the decision boundary correctly.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hinge** 是一种用于分类任务的损失函数。这种类型的损失函数在分类边界上引入了一个边际，并对损失进行惩罚。Hinge 函数对错误分类的样本进行惩罚，同时对那些在决策边界定义的边际内正确分类的样本进行惩罚。'
- en: '![Loss Functions: An Explainer](../Images/6f2758eea8eb6e7e710645cff3cb3599.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数解释](../Images/6f2758eea8eb6e7e710645cff3cb3599.png)'
- en: 'Source: [StackOverflow](https://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [StackOverflow](https://math.stackexchange.com/questions/782586/how-do-you-minimize-hinge-loss)'
- en: The x-axis represents the distance from the boundary
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x轴表示距离边界的距离
- en: The y-axis represents the loss size, or the penalty the function will incur.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y轴表示损失的大小，或者函数将会承受的惩罚。
- en: The dotted line on the axis represents 1, which means when an instance’s distance
    from boundary is more than 1, the loss size is 0\. If the distance from boundary
    is at 0, the loss size is 1.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 轴上的虚线表示1，这意味着当实例与边界的距离大于1时，损失大小为0。如果与边界的距离为0，损失大小为1。
- en: Correctly classified data points will have a low or 0 loss size; a low hinge
    loss. Whereas incorrectly classified data points will have a high or loss size
    of 1; a high hinge loss.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正确分类的数据点将具有低或 0 的损失大小；低 Hinge 损失。而错误分类的数据点将具有高或 1 的损失大小；高 Hinge 损失。
- en: Hinge Loss Code
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hinge 损失代码
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Mean Square Error Loss
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差损失
- en: '**Mean Square Error Loss** is also known a L2 regularization and is used for
    Regression tasks. It tells you how close a regression line is to a set of data
    points.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mean Square Error Loss** 也被称为 L2 正则化，用于回归任务。它告诉你回归线与一组数据点的接近程度。'
- en: It calculates the square difference between the current output and the expected
    output divided by the number of output. However, Mean Square Error loss is more
    sensitive to outliers due to using the square difference.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 它计算当前输出与预期输出之间的平方差，再除以输出的数量。然而，由于使用平方差，均方误差损失对异常值更敏感。
- en: '![Loss Functions: An Explainer](../Images/e087f1e6b8e997ea4958685404ba8c6f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数解释](../Images/e087f1e6b8e997ea4958685404ba8c6f.png)'
- en: 'Source: [freecodecamp](https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [freecodecamp](https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/)'
- en: Mean Square Error Loss Code
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均方误差损失代码
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Mean Absolute Error Loss
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均绝对误差损失
- en: '**Mean Absolute Error** is also known as L1 regularization and is used for
    Regression tasks. It computes the mean of squares of errors between labeled data
    and predicted data.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mean Absolute Error** 也被称为 L1 正则化，用于回归任务。它计算标签数据和预测数据之间的误差平方的平均值。'
- en: It calculates the absolute difference between the current output and the expected
    output divided by the number of output. It’s aim is to minimise this absolute
    differences. Mean Absolute Error is not sensitive towards outliers as it is based
    on absolute value, unlike Mean Square Error.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 它计算当前输出与预期输出之间的绝对差，再除以输出的数量。其目的是最小化这些绝对差异。均绝对误差对异常值不敏感，因为它基于绝对值，而不是像均方误差那样。
- en: In order to calculate the Mean Absolute Error, you need to take the difference
    between your model’s predictions and the actual labelled outputs. You then apply
    the absolute value to the difference, and then average it out across the whole
    dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算均绝对误差，你需要计算模型预测与实际标签输出之间的差异。然后对差异应用绝对值，并在整个数据集上取平均值。
- en: '![Loss Functions: An Explainer](../Images/dcd53ca57a2d1fc99c851abd9fb8fee8.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数解释](../Images/dcd53ca57a2d1fc99c851abd9fb8fee8.png)'
- en: 'Source: [TowardDataScience](https://medium.com/analytics-vidhya/a-comprehensive-guide-to-loss-functions-part-1-regression-ff8b847675d6)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [TowardDataScience](https://medium.com/analytics-vidhya/a-comprehensive-guide-to-loss-functions-part-1-regression-ff8b847675d6)'
- en: Mean Absolute Error Code
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 均绝对误差代码
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Huber Loss
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Huber 损失
- en: '**Huber Loss** is a combination of Mean Absolute Error and Mean Square Error.
    However, the different is that it is influenced by an additional parameter called
    delta (δ).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**Huber 损失** 是均方误差和平均绝对误差的结合。然而，区别在于它受到一个额外参数 delta (δ) 的影响。'
- en: It is a combination of both as it tells us for loss values which are less than
    delta; use the Mean Square Error. For loss values which are greater than delta,
    use the Mean Absolute Error.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种结合了两者的方法，它告诉我们对于小于 delta 的损失值，使用均方误差；对于大于 delta 的损失值，使用平均绝对误差。
- en: In the below image, Mean Absolute Error is in red, Mean Square Error is in blue,
    and Huber Loss is in green.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图像中，均方误差用红色表示，平均绝对误差用蓝色表示，Huber 损失用绿色表示。
- en: '![Loss Functions: An Explainer](../Images/dde530e71bd8f26927c7761b0e416f7a.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数：解释图](../Images/dde530e71bd8f26927c7761b0e416f7a.png)'
- en: 'Source: [TowardsDataScience](https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [TowardsDataScience](https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3)'
- en: Huber Loss Code
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Huber 损失代码
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: I have briefly gone over 3 loss functions for Classification and Regression
    each. However, there are many more that you can explore.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我简要介绍了分类和回归的 3 种损失函数。然而，还有许多其他损失函数可以探索。
- en: Below is an image showing a list of different types of loss functions for Classification
    and Regression tasks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个图像，展示了分类和回归任务的不同损失函数列表。
- en: '![Loss Functions: An Explainer](../Images/0c0647892e2e2b528e5aa732c98ddbc7.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![损失函数：解释图](../Images/0c0647892e2e2b528e5aa732c98ddbc7.png)'
- en: 'Source: [Heartbeat](https://heartbeat.comet.ml/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Heartbeat](https://heartbeat.comet.ml/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0)'
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**[尼莎·阿雅](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家和自由撰稿人。她特别感兴趣于提供数据科学职业建议或教程及理论知识。她还希望探索人工智能如何能够促进人类寿命的延续。作为一个热心学习者，她寻求拓宽技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Multi-label NLP: An Analysis of Class Imbalance and Loss Function…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多标签自然语言处理：类不平衡和损失函数的分析…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
- en: '[What are Moment-Generating Functions?](https://www.kdnuggets.com/2022/12/momentgenerating-functions.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是矩生成函数？](https://www.kdnuggets.com/2022/12/momentgenerating-functions.html)'
- en: '[Python Lambda Functions, Explained](https://www.kdnuggets.com/2023/01/python-lambda-functions-explained.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python Lambda 函数解析](https://www.kdnuggets.com/2023/01/python-lambda-functions-explained.html)'
- en: '[5 Pandas Plotting Functions You Might Not Know](https://www.kdnuggets.com/2023/02/5-pandas-plotting-functions-might-know.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你可能不知道的 5 个 Pandas 绘图函数](https://www.kdnuggets.com/2023/02/5-pandas-plotting-functions-might-know.html)'
- en: '[In-Database Analytics: Leveraging SQL''s Analytic Functions](https://www.kdnuggets.com/2023/07/indatabase-analytics-leveraging-sql-analytic-functions.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据库内分析：利用SQL的分析函数](https://www.kdnuggets.com/2023/07/indatabase-analytics-leveraging-sql-analytic-functions.html)'
- en: '[4 Python Itertools Filter Functions You Probably Didn''t Know](https://www.kdnuggets.com/2023/08/4-python-itertools-filter-functions-probably-didnt-know.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你可能不知道的 4 个 Python Itertools 过滤函数](https://www.kdnuggets.com/2023/08/4-python-itertools-filter-functions-probably-didnt-know.html)'
