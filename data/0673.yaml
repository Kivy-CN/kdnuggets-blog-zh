- en: Solve any Image Classification Problem Quickly and Easily
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速而轻松地解决任何图像分类问题
- en: 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)'
- en: '**By [Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/), Scientist,
    Engineer & Entrepreneur**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)，科学家、工程师与企业家**'
- en: '![Header image](../Images/0b4cbd51df6a71c1196bb2c9006f0001.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Header image](../Images/0b4cbd51df6a71c1196bb2c9006f0001.png)'
- en: The beauty of code by [Chris Ried](https://unsplash.com/photos/ieic5Tq8YMk)
    on [Unsplash](https://unsplash.com/search/photos/programming-python)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chris Ried](https://unsplash.com/photos/ieic5Tq8YMk) 在 [Unsplash](https://unsplash.com/search/photos/programming-python)
    上的代码之美'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 方面'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Deep learning** is fast becoming a key instrument in artificial intelligence
    applications (LeCun et al. 2015). For example, in areas such as computer vision,
    natural language processing, and speech recognition, deep learning has been producing
    remarkable results. Therefore, there is a growing interest in deep learning.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习**正迅速成为人工智能应用中的关键工具（LeCun et al. 2015）。例如，在计算机视觉、自然语言处理和语音识别等领域，深度学习已经取得了显著的成果。因此，对深度学习的兴趣也在不断增长。'
- en: One of the problems where deep learning excels is **image classification**(Rawat
    & Wang 2017). The goal in image classification is to classify a specific picture
    according to a set of possible categories. A classic example of image classification
    is the identification of cats and dogs in a set of pictures (e.g. [Dogs vs. Cats
    Kaggle Competition](https://www.kaggle.com/c/dogs-vs-cats)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习擅长解决的一个问题是**图像分类**（Rawat & Wang 2017）。图像分类的目标是根据一组可能的类别来分类特定的图片。一个经典的图像分类示例是识别一组图片中的猫和狗（例如，[狗与猫
    Kaggle 竞赛](https://www.kaggle.com/c/dogs-vs-cats)）。
- en: From a deep learning perspective, the image classification problem can be solved
    through **transfer learning**. Actually, several state-of-the-art results in image
    classification are based on transfer learning solutions (Krizhevsky et al. 2012,
    Simonyan & Zisserman 2014, He et al. 2016). A comprehensive review on transfer
    learning is provided by Pan & Yang (2010).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从深度学习的角度来看，图像分类问题可以通过**迁移学习**来解决。实际上，图像分类中的多个最先进成果都是基于迁移学习解决方案（Krizhevsky et
    al. 2012，Simonyan & Zisserman 2014，He et al. 2016）。Pan & Yang（2010）提供了关于迁移学习的全面综述。
- en: '**This article shows how to implement a transfer learning solution for image
    classification problems.** The implementation proposed in this article is based
    on Keras (Chollet 2015), which uses the programming language Python. Following
    this implementation, you will be able to solve any image classification problem
    quickly and easily.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**本文展示了如何实施图像分类问题的迁移学习解决方案。** 本文提出的实现方法基于 Keras（Chollet 2015），使用编程语言 Python。按照这一实现方法，你将能够快速而轻松地解决任何图像分类问题。'
- en: 'The article has been organised in the following way:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 文章的组织方式如下：
- en: Transfer learning
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Convolutional neural networks
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Repurposing a pre-trained model
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新利用预训练模型
- en: Transfer learning process
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移学习过程
- en: Classifiers on top of deep convolutional neural networks
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度卷积神经网络上的分类器
- en: Example
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例
- en: Summary
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 摘要
- en: References
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参考文献
- en: 1\. Transfer learning
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 迁移学习
- en: Transfer learning is a popular method in computer vision because it allows us
    to **build accurate models in a timesaving way** (Rawat & Wang 2017). With transfer
    learning, instead of starting the learning process from scratch, you start from
    patterns that have been learned when solving a different problem. This way you
    leverage previous learnings and avoid starting from scratch. Take it as the deep
    learning version of [Chartres](https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants)’
    expression ‘standing on the shoulder of giants’.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习在计算机视觉中是一种流行的方法，因为它允许我们以**节省时间的方式构建准确的模型**（Rawat & Wang 2017）。通过迁移学习，你不需要从头开始学习，而是从解决不同问题时学到的模式开始。这种方法利用了之前的学习成果，避免了从头开始。把它看作是深度学习版本的[Chartres](https://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants)的“站在巨人的肩膀上”表达。
- en: In computer vision, transfer learning is usually expressed through the use of **pre-trained
    models**. A pre-trained model is a model that was trained on a large benchmark
    dataset to solve a problem similar to the one that we want to solve. Accordingly,
    due to the computational cost of training such models, it is common practice to
    import and use models from published literature (e.g. [VGG](https://arxiv.org/pdf/1409.1556.pdf),
    [Inception](https://arxiv.org/pdf/1512.00567.pdf), [MobileNet](https://arxiv.org/pdf/1704.04861.pdf)).
    A comprehensive review of pre-trained models’ performance on computer vision problems
    using data from the ImageNet (Deng et al. 2009) challenge is presented by Canziani
    et al. (2016).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中，迁移学习通常通过使用**预训练模型**来表达。预训练模型是指在大型基准数据集上训练的模型，用于解决与我们想解决的问题类似的问题。因此，由于训练这些模型的计算成本，常见的做法是从已发布的文献中导入和使用模型（例如
    [VGG](https://arxiv.org/pdf/1409.1556.pdf)、[Inception](https://arxiv.org/pdf/1512.00567.pdf)、[MobileNet](https://arxiv.org/pdf/1704.04861.pdf)）。Canziani等人（2016）对使用ImageNet（Deng等，2009）挑战数据的预训练模型在计算机视觉问题上的表现进行了全面回顾。
- en: 2\. Convolutional neural networks
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 卷积神经网络
- en: Several pre-trained models used in transfer learning are based on large **convolutional
    neural networks** **(CNN) **(Voulodimos et al. 2018). In general, CNN was shown
    to excel in a wide range of computer vision tasks (Bengio 2009). Its high performance
    and its easiness in training are two of the main factors driving the popularity
    of CNN over the last years.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移学习中使用的几种预训练模型基于大型**卷积神经网络（CNN）**（Voulodimos等，2018）。通常，CNN在广泛的计算机视觉任务中表现出色（Bengio
    2009）。其高性能和训练的简便性是近年来CNN受欢迎的两个主要因素。
- en: 'A typical CNN has two parts:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的CNN有两个部分：
- en: '**Convolutional base**, which is composed by a stack of convolutional and pooling
    layers. The main goal of the convolutional base is to generate features from the
    image. For an intuitive explanation of convolutional and pooling layers, please
    refer to Chollet (2017).'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积基础**，由一系列卷积层和池化层组成。卷积基础的主要目标是从图像中生成特征。有关卷积层和池化层的直观解释，请参见Chollet（2017）。'
- en: '**Classifier**, which is usually composed by fully connected layers. The main
    goal of the classifier is to classify the image based on the detected features.
    A fully connected layer is a layer whose neurons have full connections to all
    activation in the previous layer.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类器**，通常由全连接层组成。分类器的主要目标是根据检测到的特征对图像进行分类。全连接层是一个神经元与上一层所有激活都有完全连接的层。'
- en: Figure 1 shows the **architecture of a model based on CNN**. Note that this
    is a simplified version, which fits the purposes of this text. In fact, the architecture
    of this type of model is more complex than what we suggest here.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图1展示了基于**卷积神经网络（CNN）的模型架构**。请注意，这只是一个简化版本，适用于本文的目的。实际上，这类模型的架构比我们在这里所建议的要复杂得多。
- en: '![](../Images/2d7c77156366d480bd5e8c2be6c4da35.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d7c77156366d480bd5e8c2be6c4da35.png)'
- en: Figure 1\. Architecture of a model based on CNN.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 基于CNN的模型架构。
- en: One important aspect of these deep learning models is that they can automatically
    learn **hierarchical feature representations**. This means that features computed
    by the first layer are general and can be reused in different problem domains,
    while features computed by the last layer are specific and depend on the chosen
    dataset and task. According to Yosinski et al. (2014), ‘*if first-layer features
    are general and last-layer features are specific, then there must be a transition
    from general to specific somewhere in the network’*. As a result, the convolutional
    base of our CNN — especially its lower layers (those who are closer to the inputs) — refer
    to general features, whereas the classifier part, and some of the higher layers
    of the convolutional base, refer to specialised features.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些深度学习模型的一个重要方面是它们可以自动学习**层次特征表示**。这意味着第一层计算的特征是通用的，可以在不同的问题领域中重复使用，而最后一层计算的特征是具体的，依赖于选择的数据集和任务。根据Yosinski等人（2014）的说法，‘*如果第一层特征是通用的，而最后一层特征是具体的，那么网络中的某个地方必须有从通用到具体的过渡*’。因此，我们的CNN的卷积基础——尤其是其较低层（那些更接近输入的层）——指的是通用特征，而分类器部分以及卷积基础的一些较高层则指的是专用特征。
- en: 3\. Repurposing a pre-trained model
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 重新利用预训练模型
- en: 'When you’re repurposing a pre-trained model for your own needs, you start by
    removing the original classifier, then you add a new classifier that fits your
    purposes, and finally you have to **fine-tune your model according to one of three
    strategies**:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将预训练模型重新用于自己的需求时，你首先移除原始分类器，然后添加一个适合你目的的新分类器，最后你必须**根据三种策略之一对模型进行微调**：
- en: '**Train the entire model.** In this case, you use the architecture of the pre-trained
    model and train it according to your dataset. You’re learning the model from scratch,
    so you’ll need a large dataset (and a lot of computational power).'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练整个模型。** 在这种情况下，你使用预训练模型的架构，并根据你的数据集对其进行训练。你是从头开始学习模型，因此需要一个大数据集（和大量的计算能力）。'
- en: '**Train some layers and leave the others frozen. **As you remember, lower layers
    refer to general features (problem independent), while higher layers refer to
    specific features (problem dependent). Here, we play with that dichotomy by choosing
    how much we want to adjust the weights of the network (a frozen layer does not
    change during training). Usually, if you’ve a small dataset and a large number
    of parameters, you’ll leave more layers frozen to avoid overfitting. By contrast,
    if the dataset is large and the number of parameters is small, you can improve
    your model by training more layers to the new task since overfitting is not an
    issue.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练一些层并将其他层保持冻结。** 正如你所记得，较低层指的是通用特征（与问题无关），而较高层指的是特定特征（与问题相关）。在这里，我们通过选择要调整网络权重的程度来处理这种二分法（冻结的层在训练过程中不会改变）。通常，如果你有一个小数据集和大量参数，你会保持更多层被冻结以避免过拟合。相反，如果数据集很大而参数数量很少，你可以通过训练更多层以适应新任务来改善你的模型，因为过拟合不是问题。'
- en: '**Freeze the convolutional base. **This case corresponds to an extreme situation
    of the train/freeze trade-off. The main idea is to keep the convolutional base
    in its original form and then use its outputs to feed the classifier. You’re using
    the pre-trained model as a fixed feature extraction mechanism, which can be useful
    if you’re short on computational power, your dataset is small, and/or pre-trained
    model solves a problem very similar to the one you want to solve.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**冻结卷积基础。** 这种情况对应于训练/冻结权衡的极端情况。主要思路是保持卷积基础的原始形式，然后利用其输出喂给分类器。你将预训练模型作为固定的特征提取机制，这在计算能力不足、数据集较小和/或预训练模型解决的问题与您要解决的问题非常相似时非常有用。'
- en: Figure 2 presents these three strategies in a schematic way.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2以示意图的方式展示了这三种策略。
- en: '![](../Images/01215828d6dedde4541e9b70fbe56de4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01215828d6dedde4541e9b70fbe56de4.png)'
- en: Figure 2\. Fine-tuning strategies.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 微调策略。
- en: Unlike **Strategy 3**, whose application is **straightforward**, **Strategy
    1 **and**Strategy 2** require you to **be careful** with the learning rate used
    in the convolutional part. The learning rate is a hyper-parameter that controls
    how much you adjust the weights of your network. When you’re using a pre-trained
    model based on CNN, it’s smart to use a small learning rate because high learning
    rates increase the risk of losing previous knowledge. Assuming that the pre-trained
    model has been well trained, which is a fair assumption, keeping a small learning
    rate will ensure that you don’t distort the CNN weights too soon and too much.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与**策略 3**不同，**策略 1**和**策略 2**需要你在卷积部分**谨慎**调整学习率。学习率是一个超参数，控制你调整网络权重的幅度。当你使用基于
    CNN 的预训练模型时，使用较小的学习率是明智的，因为高学习率会增加丧失先前知识的风险。假设预训练模型已经很好地训练了，这是一种合理的假设，保持较小的学习率将确保你不会过早或过度地扭曲
    CNN 权重。
- en: 4\. Transfer learning process
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4. 迁移学习过程
- en: 'From a practical perspective, the entire transfer learning process can be summarised
    as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，整个迁移学习过程可以总结如下：
- en: '**Select a pre-trained model**. From the wide range of pre-trained models that
    are available, you pick one that looks suitable for your problem. For example,
    if you’re using Keras, you immediately have access to a set of models, such as
    VGG (Simonyan & Zisserman 2014), InceptionV3 (Szegedy et al. 2015), and ResNet5
    (He et al. 2015). [Here](https://keras.io/applications/) you can see all the models
    available on Keras.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择一个预训练模型**。从众多可用的预训练模型中，你可以挑选一个适合你问题的模型。例如，如果你使用 Keras，你可以立即访问一组模型，如 VGG（Simonyan
    & Zisserman 2014）、InceptionV3（Szegedy et al. 2015）和 ResNet5（He et al. 2015）。[这里](https://keras.io/applications/)你可以查看所有在
    Keras 上可用的模型。'
- en: '**Classify your problem according to the Size-Similarity Matrix.** In Figure
    3 you have ‘The Matrix’ that controls your choices. This matrix classifies your
    computer vision problem considering the size of your dataset and its similarity
    to the dataset in which your pre-trained model was trained. As a rule of thumb,
    consider that your dataset is small if it has less than 1000 images per class.
    Regarding dataset similarity, let common sense prevail. For example, if your task
    is to identify cats and dogs, ImageNet would be a similar dataset because it has
    images of cats and dogs. However, if your task is to identify cancer cells, ImageNet
    can’t be considered a similar dataset.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**根据尺寸-相似度矩阵对你的问题进行分类。** 在图 3 中，你有一个“矩阵”来控制你的选择。这个矩阵根据你的数据集的大小和与预训练模型训练数据集的相似度来分类你的计算机视觉问题。一般来说，如果你的数据集每类少于
    1000 张图片，可以认为数据集很小。关于数据集的相似度，使用常识即可。例如，如果你的任务是识别猫和狗，ImageNet 是一个相似的数据集，因为它包含猫和狗的图片。然而，如果你的任务是识别癌细胞，ImageNet
    则不能算作一个相似的数据集。'
- en: '**Fine-tune your model. **Here you can use the Size-Similarity Matrix to guide
    your choice and then refer to the three options we mentioned before about repurposing
    a pre-trained model. Figure 4 provides a visual summary of the text that follows.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调你的模型。** 在这里，你可以使用尺寸-相似度矩阵来指导你的选择，然后参考我们之前提到的关于重新利用预训练模型的三个选项。图 4 提供了接下来文本的视觉总结。'
- en: '**Quadrant 1**. Large dataset, but different from the pre-trained model’s dataset.
    This situation will lead you to *Strategy 1*. Since you have a large dataset,
    you’re able to train a model from scratch and do whatever you want. Despite the
    dataset dissimilarity, in practice, it can still be useful to initialise your
    model from a pre-trained model, using its architecture and weights.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**象限 1**。大型数据集，但与预训练模型的数据集不同。这种情况会引导你到*策略 1*。由于你拥有一个大型数据集，你可以从头开始训练模型，并按你的需求进行操作。尽管数据集存在差异，但在实践中，从预训练模型初始化你的模型，使用其架构和权重仍然是有用的。'
- en: '**Quadrant 2.** Large dataset and similar to the pre-trained model’s dataset.
    Here you’re in la-la land. Any option works. Probably, the most efficient option
    is *Strategy 2*. Since we have a large dataset, overfitting shouldn’t be an issue,
    so we can learn as much as we want. However, since the datasets are similar, we
    can save ourselves from a huge training effort by leveraging previous knowledge.
    Therefore, it should be enough to train the classifier and the top layers of the
    convolutional base.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**象限 2.** 大数据集且与预训练模型的数据集相似。在这里，你如同身处仙境。任何选项都有效。可能，最有效的选项是*策略 2*。由于我们有一个大数据集，过拟合不应成为问题，因此我们可以尽可能多地学习。然而，由于数据集相似，我们可以通过利用先前的知识来节省大量训练工作。因此，训练分类器和卷积基础的顶层应该就足够了。'
- en: '**Quadrant 3.** Small dataset and different from the pre-trained model’s dataset.
    This is the 2–7 off-suit hand of computer vision problems. Everything is against
    you. If complaining is not an option, the only hope you have is *Strategy 2*.
    It will be hard to find a balance between the number of layers to train and freeze.
    If you go to deep your model can overfit, if you stay in the shallow end of your
    model you won’t learn anything useful. Probably, you’ll need to go deeper than
    in Quadrant 2 and you’ll need to consider data augmentation techniques (a nice
    summary on data augmentation techniques is provided [here](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**象限 3.** 小数据集且与预训练模型的数据集不同。这是计算机视觉问题中的2–7不花色手。所有情况都不利于你。如果抱怨不是一个选项，你唯一的希望就是*策略
    2*。找到训练和冻结层数之间的平衡将很困难。如果你深入，模型可能会过拟合；如果你停留在模型的浅层，你将学不到任何有用的东西。你可能需要比象限 2 更深，并且需要考虑数据增强技术（[这里](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)提供了数据增强技术的一个不错总结）。'
- en: '**Quadrant 4.** Small dataset, but similar to the pre-trained model’s dataset.
    I asked Master Yoda about this one he told me that ‘*be the best option, Strategy
    3 should*’. I don’t know about you, but I don’t underestimate the Force. Accordingly,
    go for *Strategy 3*. You just need to remove the last fully-connected layer (output
    layer), run the pre-trained model as a fixed feature extractor, and then use the
    resulting features to train a new classifier.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**象限 4.** 小数据集，但与预训练模型的数据集相似。我问了尤达大师，他告诉我“*最佳选择是策略 3*”。我不知道你怎么看，但我不会低估原力。因此，选择*策略
    3*。你只需去掉最后一层全连接层（输出层），将预训练模型作为固定特征提取器运行，然后使用生成的特征来训练一个新的分类器。'
- en: '![](../Images/cefb71a15b54427582c7d4e630e3e3dc.png) ![](../Images/7b543ae2e3f06d6e2c2c072741aca2fb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cefb71a15b54427582c7d4e630e3e3dc.png) ![](../Images/7b543ae2e3f06d6e2c2c072741aca2fb.png)'
- en: Figures 3 and 4\. Size-Similarity matrix (left) and decision map for fine-tuning
    pre-trained models (right).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3 和 4. 大小-相似度矩阵（左）和用于微调预训练模型的决策图（右）。
- en: 5\. Classifiers on top of deep convolutional neural networks
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5. 深度卷积神经网络上的分类器
- en: 'As mentioned before, **models for image classification** that result from a
    transfer learning approach **based on pre-trained convolutional neural networks** are
    usually composed of **two parts**:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，**图像分类模型**，基于**预训练卷积神经网络**的迁移学习方法，通常由**两部分**组成：
- en: '**Convolutional base**, which performs feature extraction.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积基础**，用于特征提取。'
- en: '**Classifier**, which classifies the input image based on the features extracted
    by the convolutional base.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类器**，根据卷积基础提取的特征对输入图像进行分类。'
- en: 'Since in this section we focus on the classifier part, we must start by saying
    that different approaches can be followed to build the classifier. Some of the
    most popular are:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在这一部分我们专注于分类器部分，我们必须首先说明构建分类器可以采用不同的方法。一些最受欢迎的方法包括：
- en: '**Fully-connected layers. **For image classification problems, the standard
    approach is to use a stack of fully-connected layers followed by a softmax activated
    layer (Krizhevsky et al. 2012, Simonyan & Zisserman 2014, Zeiler & Fergus 2014).
    The softmax layer outputs the probability distribution over each possible class
    label and then we just need to classify the image according to the most probable
    class.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**全连接层。** 对于图像分类问题，标准的方法是使用一系列全连接层，后跟一个 softmax 激活层（Krizhevsky et al. 2012,
    Simonyan & Zisserman 2014, Zeiler & Fergus 2014）。softmax 层输出每个可能类别标签的概率分布，然后我们只需根据最可能的类别对图像进行分类。'
- en: '**Global average pooling. **A different approach, based on global average pooling,
    is proposed by Lin et al. (2013). In this approach, instead of adding fully connected
    layers on top of the convolutional base, we add a global average pooling layer
    and feed its output directly into the softmax activated layer. Lin et al. (2013)
    provides a detailed discussion on the advantages and disadvantages of this approach.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**全局平均池化。** Lin等人（2013）提出了一种基于全局平均池化的不同方法。在这种方法中，我们不是在卷积基础上添加全连接层，而是添加一个全局平均池化层，并将其输出直接输入到softmax激活层中。Lin等人（2013）对这种方法的优缺点进行了详细讨论。'
- en: '**Linear support vector machines.** Linear support vector machines (SVM) is
    another possible approach. According to Tang (2013), we can improve classification
    accuracy by training a linear SVM classifier on the features extracted by the
    convolutional base. Further details about the advantages and disadvantages of
    the SVM approach can be found in the paper.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线性支持向量机。** 线性支持向量机（SVM）是另一种可能的方法。根据Tang（2013）的说法，我们可以通过在卷积基础提取的特征上训练线性SVM分类器来提高分类准确性。有关SVM方法的优缺点的更多细节可以在论文中找到。'
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NExT-GPT介绍：任意对任意的多模态大型语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
- en: '[Machine Learning Is Not Like Your Brain Part 6: The Importance of…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第6部分：重要性…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
- en: '[Scrape Images Easily from Websites in A No-Coding Way](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无需编码即可轻松从网站抓取图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[轻松在你的笔记本电脑上探索LLMs，使用openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
- en: '[Easily Integrate LLMs into Your Scikit-learn Workflow with Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[轻松将LLMs集成到你的Scikit-learn工作流中，使用Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
