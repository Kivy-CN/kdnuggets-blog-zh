- en: 'Must-Know: Why it may be better to have fewer predictors in Machine Learning
    models?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 必知：为什么在机器学习模型中使用较少的预测变量可能更好？
- en: 原文：[https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html](https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html](https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html)
- en: '**Editor''s note:** This post was originally included as an answer to a question
    posed in our [17 More Must-Know Data Science Interview Questions and Answers](/2017/02/17-data-science-interview-questions-answers.html)
    series earlier this year. The answer was thorough enough that it was deemed to
    deserve its own dedicated post.'
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑注：** 本文最初作为对我们[17 个必知的数据科学面试问题与答案](/2017/02/17-data-science-interview-questions-answers.html)系列中一个问题的回答而发布。由于回答内容足够详尽，因此决定将其独立成文。'
- en: 'Here are a few reasons why it might be a better idea to have fewer predictor
    variables rather than having many of them:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为什么使用较少的预测变量可能比使用更多预测变量更好的几个原因：
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Redundancy/Irrelevance:**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**冗余/无关性：**'
- en: If you are dealing with many predictor variables, then the chances are high
    that there are hidden relationships between some of them, leading to redundancy.
    Unless you identify and handle this redundancy (by selecting only the non-redundant
    predictor variables) in the early phase of data analysis, it can be a huge drag
    on your succeeding steps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你处理的预测变量很多，那么很可能它们之间存在隐藏的关系，从而导致冗余。除非你在数据分析的早期阶段识别并处理这些冗余（通过仅选择非冗余的预测变量），否则这可能会对你后续的步骤造成很大阻碍。
- en: It is also likely that not all predictor variables are having a considerable
    impact on the dependent variable(s). You should make sure that the set of predictor
    variables you select to work on does not have any irrelevant ones – even if you
    know that data model will take care of them by giving them lower significance.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，也有可能并不是所有的预测变量对因变量有显著影响。你应该确保你选择的预测变量集合中没有任何无关的变量——即使你知道数据模型会通过赋予它们较低的重要性来处理它们。
- en: '*Note: Redundancy and Irrelevance are two different notions –a relevant feature
    can be redundant due to the presence of other relevant feature(s).*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：冗余和无关性是两个不同的概念——一个相关的特征可能由于存在其他相关特征而变得冗余。*'
- en: '**Overfitting**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合**：'
- en: Even when you have a large number of predictor variables with no relationships
    between any of them, it would still be preferred to work with fewer predictors.
    The data models with large number of predictors (also referred to as complex models)
    often suffer from the problem of overfitting, in which case the data model performs
    great on training data, but performs poorly on test data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你有大量的预测变量，且它们之间没有任何关系，通常还是建议使用较少的预测变量。具有大量预测变量的数据模型（也称为复杂模型）常常会遇到过拟合的问题，在这种情况下，数据模型在训练数据上表现很好，但在测试数据上表现较差。
- en: '**Productivity**:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**生产力**：'
- en: Let’s say you have a project where there are a large number of predictors and
    all of them are relevant (i.e. have measurable impact on the dependent variable).
    So, you would obviously want to work with all of them in order to have a data
    model with very high success rate. While this approach may sound very enticing,
    practical considerations (such of amount of data available, storage and compute
    resources, time taken for completion, etc.) make it nearly impossible.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个项目，其中有大量的预测变量，并且所有这些变量都是相关的（即对因变量有可测量的影响）。因此，你显然希望使用所有变量，以获得一个成功率非常高的数据模型。尽管这种方法听起来非常诱人，但实际考虑因素（如可用数据量、存储和计算资源、完成所需时间等）使得这种方法几乎不可能实现。
- en: Thus, even when you have a large number of relevant predictor variables, it
    is a good idea to work with fewer predictors (shortlisted through feature selection
    or developed through feature extraction). This is essentially similar to the Pareto
    principle, which states that for many events, roughly 80% of the effects come
    from 20% of the causes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使你有大量相关的预测变量，使用较少的预测变量（通过特征选择筛选或通过特征提取开发）也是一个好主意。这本质上类似于帕累托原则，即许多事件中，大约80%的效果来自20%的原因。
- en: Focusing on those 20% most significant predictor variables will be of great
    help in building data models with considerable success rate in a reasonable time,
    without needing non-practical amount of data or other resources.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于这20%最重要的预测变量，将大大有助于在合理时间内建立成功率可观的数据模型，而不需要大量不切实际的数据或其他资源。
- en: '![Training vs complexity](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![训练与复杂度](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
- en: 'Training error & test error vs model complexity (Source: Posted on [Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)
    by [Sergul Aydore](https://www.quora.com/profile/Sergül-Aydöre))'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 训练误差与测试误差对模型复杂度的关系（来源：[Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)由[Sergul
    Aydore](https://www.quora.com/profile/Sergül-Aydöre)发布）
- en: '**Understandability**:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**可理解性**：'
- en: Models with fewer predictors are way easier to understand and explain. As the
    data science steps will be performed by humans and the results will be presented
    (and hopefully, used) by humans, it is important to consider the comprehensive
    ability of human brain. This is basically a trade-off – you are letting go of
    some potential benefits to your data model’s success rate, while simultaneously
    making your data model easier to understand and optimize.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 具有较少预测变量的模型更容易理解和解释。由于数据科学步骤将由人类执行，结果也将由人类展示（并希望被使用），因此考虑到人脑的全面能力非常重要。这实际上是一种权衡——你放弃了一些可能带来数据模型成功率的潜在好处，同时使你的数据模型更易于理解和优化。
- en: This factor is particularly important if at the end of your project you need
    to present your results to someone, who is interested in not just high success
    rate, but also in understanding what is happening “under the hood”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在项目结束时你需要向某人展示结果，而他们不仅对高成功率感兴趣，还希望了解“幕后”的情况，这个因素就尤为重要。
- en: '**Related:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[17 More Must-Know Data Science Interview Questions and Answers](/2017/02/17-data-science-interview-questions-answers.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17个必须了解的数据科学面试问题及答案](/2017/02/17-data-science-interview-questions-answers.html)'
- en: '[Approaching (Almost) Any Machine Learning Problem](/2016/08/approaching-almost-any-machine-learning-problem.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[接近（几乎）任何机器学习问题](/2016/08/approaching-almost-any-machine-learning-problem.html)'
- en: '[Identifying Variables That Might Be Better Predictors](/2017/02/schmarzo-variables-better-predictors.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[识别可能更好预测的变量](/2017/02/schmarzo-variables-better-predictors.html)'
- en: More On This Topic
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Why Do Machine Learning Models Die In Silence?](https://www.kdnuggets.com/2022/01/machine-learning-models-die-silence.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么机器学习模型会默默“死去”？](https://www.kdnuggets.com/2022/01/machine-learning-models-die-silence.html)'
- en: '[What Does ETL Have to Do with Machine Learning?](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL与机器学习有什么关系？](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
- en: '[A (Much) Better Approach to Evaluate Your Machine Learning Model](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[评估你的机器学习模型的（更好）方法](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)'
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么你应该使用线性回归模型而不是……](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Top 13 Skills That Every Data Scientist Should Have](https://www.kdnuggets.com/2022/03/top-13-skills-every-data-scientist.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家应该具备的13项技能](https://www.kdnuggets.com/2022/03/top-13-skills-every-data-scientist.html)'
- en: '[21 Must-Have Cheat Sheets for Data Science Interviews: Unlocking…](https://www.kdnuggets.com/2022/06/21-cheat-sheets-data-science-interviews.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21份数据科学面试必备的备忘单：解锁…](https://www.kdnuggets.com/2022/06/21-cheat-sheets-data-science-interviews.html)'
