["```py\n# Import the nltk library for NLP processes\nimport nltk\n\n# Variable that stores the whole paragraph\ntext = \"...\"\n\n# Tokenize paragraph into sentences\nsentences = nltk.sent_tokenize(text)\n\n# Print out sentences\nfor sentence in sentences:\n\tprint(sentence)\n```", "```py\nimport nltk\n\nsentence_data = \"That dog is a husky breed. They are intelligent and independent.\"\nnltk_tokens = nltk.sent_tokenize(sentence_data)\nprint (nltk_tokens)\n```", "```py\nimport nltk \nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize, sent_tokenize \n\nstop_words = set(stopwords.words('english')) \n\n// Dummy text \ntxt = Everything is all about money.\\\n\n# sent_tokenize is one of the instances of \n# PunktSentenceTokenizer from the nltk.tokenize.punkt module \ntokenized = sent_tokenize(txt) \n\nfor i in tokenized: \n\t# Word tokenizers is used to find the words \n\t# and punctuation in a string \n\twordsList = nltk.word_tokenize(i) \n\t# removing stop words from wordList \n\twordsList = [w for w in wordsList if not w in stop_words] \n\t# Using a Tagger. Which is part-of-speech \n\t# tagger or POS-tagger. \n\ttagged = nltk.pos_tag(wordsList) \n\tprint(tagged) \n\n```", "```py\n# importing NLTK library stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\n\n## print(stopwords.words('english'))\n\n# random sentence with lot of stop words\nsample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n\ntext_tokens = word_tokenize(sample_text)\ntokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n\nprint(text_tokens)\nprint(tokens_without_sw)\n```"]