- en: 'Reinforcement Learning: The Business Use Case, Part 2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/08/reinforcement-learning-business-use-case-part-2.html](https://www.kdnuggets.com/2018/08/reinforcement-learning-business-use-case-part-2.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Aishwarya Srinivasan](https://www.linkedin.com/in/aishwarya-srinivasan/),
    Deep Learning Researcher**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a7567a1008a62ab2dc2721f8a4c2fe4c.png)'
  prefs: []
  type: TYPE_IMG
- en: In my [previous post](https://medium.com/inside-machine-learning/reinforcement-learning-the-business-use-case-part-1-65976c745319),
    I focused on the understanding of computational and mathematical perspective of
    reinforcement learning, and the challenges we face when using the algorithm on
    business use cases.
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I will explore the implementation of reinforcement learning in
    trading. The Financial industry has been exploring the applications of Artificial
    Intelligence and Machine Learning for their use-cases, but the monetary risk has
    prompted reluctance. Traditional algorithmic trading has evolved in recent years
    and now high-computational systems automates the tasks, but traders still build
    the policies that govern choices to buy and sell. An algorithmic model for buying
    stocks based on a list of valuation and growth metric conditions might define
    a “buy” or “sell” signal that would in turn be triggered by some specific rules
    that the trader has defined.
  prefs: []
  type: TYPE_NORMAL
- en: For example, an algorithmic approach might be as simple as buying the S&P index
    whenever it closes above the high of the past 30 days or liquidate the position
    whenever it closes below the low of the past 30 days. Such rules could be trend-following,
    counter-trend, or based on patterns in nature. Different technical analysts would
    inevitably defined both the pattern and confirmation conditions differently. In
    order for this approach to be systematic, the trader would have to specify precise
    mathematical conditions to unambiguously define whether or not a head-and-shoulders
    pattern had been formed, as well as precise conditions that would define a confirmation
    of the pattern.
  prefs: []
  type: TYPE_NORMAL
- en: In the arena of advanced machine learning in the present financial market, we
    can look to the appearance in October 2017 of AI-based Exchange Traded Funds (ETFs)
    from EquBot. EquBot automates these ETFs to compile the market information from
    thousands of US companies, over a million market signals, quarterly news articles,
    and social media postings. A given ETF might select 30 to 70 companies with high
    opportunities for market appreciation and it will continue to learn with every
    trade. Another well-known market player, Horizons, launched a similar Active AI
    Global ETF, which Horizons developed using supervised machine learning that includes
    policy building from traders. With a supervised learning approach, the human traders
    help to choose thresholds, account for latencies, estimate fees, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fbaa34eea3d631b8430751636e30fcab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig 1: Pipeline for Trading using Supervised Learning'
  prefs: []
  type: TYPE_NORMAL
- en: Of course if it’s going to be fully automated, an AI-driven trading model has
    to do more than predict prices. It needs a rule-based policy that takes as input
    the stock price and then decides whether to buy, sell, or hold.
  prefs: []
  type: TYPE_NORMAL
- en: In June 2018, Morgan Stanley appointed [Micheal Kearns](https://en.wikipedia.org/wiki/Michael_Kearns_%28computer_scientist%29),
    a computer scientist from the University of Pennsylvania, in an effort to expand
    the use of artificial intelligence. In an interview with Bloomberg, Dr. Kearns
    pointed out that, “While standard machine learning models make predictions on
    prices, they don’t specify the best time to act, the optimal size of a trade or
    its impact on the market.” He added, “With reinforcement learning, you are learning
    to make predictions that account for what effects your actions have on the state
    of the market.”
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning allows for end-to-end optimization and maximizes the
    reward. Crucially, the RL agent itself adjusts the parameters in order to zero
    in on the optimal result. For instance, we can imagine large negative reward whenever
    there’s a drawdown of more than 30%, which forces the agent to consider a different
    policy. We can also build simulations to improve responses in critical situations.
    For example, we can simulate latencies within the reinforcement learning environment
    in order to generate a negative reward for the agent. That negative reward in
    turn compels the agent to learn work-arounds for latencies. Similar strategies
    allow the agent to auto-tune over time, continually making it more powerful and
    adaptable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/447e75d7debdae2ace6ac9932140fce9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig 2: Pipeline for trading using reinforcement learning Model'
  prefs: []
  type: TYPE_NORMAL
- en: Here at IBM, we’ve built a sophisticated system on the [DSX platform](https://www.ibm.com/products/data-science-experience) that
    makes financial trades using the power of reinforcement learning. The model winds
    around training on the historical stock price data using stochastic actions at
    each time step, and we calculate the reward function based on the profit or loss
    for each trade.
  prefs: []
  type: TYPE_NORMAL
- en: ‘ IBM Data Science Experience is an enterprise data science platform that provides
    teams with the broadest set of open source and data science tools for any skill
    set, the flexibility to build and deploy anywhere in a multicloud environment,
    and the ability to operationalize data science results faster.’
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The following diagrams weave together the reinforcement learning methodology
    with the use case of financial trading.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/036a442bf6cfd04658e5f032fb516312.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/0472dd65e8be68522023d4cc1778ed15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig 3: Reinforcement learning trading model'
  prefs: []
  type: TYPE_NORMAL
- en: We measure the performance of the reinforced trading model with the alpha metric
    (the active return on an investment), and also evaluate the performance of the
    investment against the market index representing market movement overall. Finally,
    we assess the model against a simple [Buy-&-Hold strategy](https://www.investopedia.com/terms/b/buyandhold.asp) and
    against [ARIMA-GARCH](https://www.quantstart.com/articles/ARIMA-GARCH-Trading-Strategy-on-the-SP500-Stock-Market-Index-Using-R).
    We found that the model had much-refined moderation according to the market movements,
    and could even capture the [head-and-shoulder patterns](https://www.investopedia.com/university/charts/charts2.asp),
    which are non-trivial trends that can signal reversals in the market.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning might not apply in every business use case, but its ability
    to capture the subtleties of financial trading certainly demonstrate its sophistication,
    power, and greater potential.
  prefs: []
  type: TYPE_NORMAL
- en: Stay tuned as we test the power of reinforcement learning across more business
    use cases!
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Aishwarya Srinivasan](https://www.linkedin.com/in/aishwarya-srinivasan/)**:
    MS Data Science - Columbia University || IBM - Data Science Elite || Unicorn in
    Data Science || Scikit-Learn Contributor || Deep Learning Researcher'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/inside-machine-learning/reinforcement-learning-the-business-use-case-part-2-c175740999).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[5 Things You Need to Know about Reinforcement Learning](/2018/03/5-things-reinforcement-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explaining Reinforcement Learning: Active vs Passive](/2018/06/explaining-reinforcement-learning-active-passive.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[When reinforcement learning should not be used?](/2017/12/when-reinforcement-learning-not-used.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Hands-on Reinforcement Learning Course Part 3: SARSA](https://www.kdnuggets.com/2022/01/handson-reinforcement-learning-course-part-3-sarsa.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hands-On Reinforcement Learning Course, Part 1](https://www.kdnuggets.com/2021/12/hands-on-reinforcement-learning-course-part-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hands-On Reinforcement Learning Course, Part 2](https://www.kdnuggets.com/2021/12/hands-on-reinforcement-learning-part-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automated Machine Learning with Python: A Case Study](https://www.kdnuggets.com/2023/04/automated-machine-learning-python-case-study.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chip Huyen shares frameworks and case studies for implementing ML systems](https://www.kdnuggets.com/2023/02/sphere-chip-huyen-shares-frameworks-case-studies-implementing-ml-systems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Case of Homegrown Large Language Models](https://www.kdnuggets.com/the-case-of-homegrown-large-language-models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
