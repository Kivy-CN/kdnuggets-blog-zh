- en: 'Managing Machine Learning Workflows with Scikit-learn Pipelines Part 2: Integrating
    Grid Search'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Scikit-learn 管道管理机器学习工作流第 2 部分：集成网格搜索
- en: 原文：[https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html](https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html](https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![Pipeline](../Images/f6e4b8b675c6c9d128270e42ce22de20.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Pipeline](../Images/f6e4b8b675c6c9d128270e42ce22de20.png)'
- en: 'In our [last post](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)
    we looked at Scikit-learn pipelines as a method for simplifying machine learning
    workflows. Designed as a manageable way to apply a series of data transformations
    followed by the application of an estimator, pipelines were noted as being a simple
    tool useful mostly for:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们[上一篇文章](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)中，我们讨论了
    Scikit-learn 管道作为简化机器学习工作流的方法。管道设计为一种可管理的方式，先进行一系列数据转换，然后应用估计器，管道被认为是一个简单的工具，主要用于：
- en: Convenience in creating a coherent and easy-to-understand workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建连贯且易于理解的工作流的便利性
- en: Enforcing workflow implementation and the desired order of step applications
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强制执行工作流实施和所需步骤应用的顺序
- en: Reproducibility
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可复现性
- en: Value in persistence of entire pipeline objects (goes to reproducibility and
    convenience)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整管道对象的持久性价值（涉及可复现性和便利性）
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT'
- en: '* * *'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Another simple yet powerful technique we can pair with pipelines to improve
    performance is **grid search**, which attempts to optimize model hyperparameter
    combinations. Exhaustive grid search -- as opposed to alternate hyperparameter
    combination optimization schemes such as randomized optimization -- tests and
    compares all possible combinations of desired hyperparameter values, an exercise
    in exponential growth. The trade-off in what could end up being exorbitant run
    times would (hopefully) be the best optimized model possible.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可以与管道配对以提高性能的简单但强大的技术是**网格搜索**，它尝试优化模型超参数组合。详尽的网格搜索——与随机优化等替代超参数组合优化方案不同——测试和比较所有可能的期望超参数值组合，这是一个指数增长的过程。在可能最终导致高昂运行时间的权衡中，所期望的是尽可能优化的模型。
- en: 'From the [official documentation](http://scikit-learn.org/stable/modules/grid_search.html):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[官方文档](http://scikit-learn.org/stable/modules/grid_search.html)：
- en: 'The grid search provided by GridSearchCV exhaustively generates candidates
    from a grid of parameter values specified with the param_grid parameter. For instance,
    the following param_grid:'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GridSearchCV 提供的网格搜索会根据 param_grid 参数指定的参数值网格生成候选项。例如，以下 param_grid：
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'specifies that two grids should be explored: one with a linear kernel and C
    values in [1, 10, 100, 1000], and the second one with an RBF kernel, and the cross-product
    of C values ranging in [1, 10, 100, 1000] and gamma values in [0.001, 0.0001].'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 指定应该探索两个网格：一个是线性核和 C 值在 [1, 10, 100, 1000] 之间，另一个是 RBF 核，C 值的交叉乘积范围在 [1, 10,
    100, 1000] 之间，gamma 值在 [0.001, 0.0001] 之间。
- en: Let's first recall the code from the previous post, and run a modified excerpt.
    Since we will be using a single pipeline for this exercise, we have no need for
    a full set as in the last post. We will use the iris dataset once again.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先回顾一下上一篇文章中的代码，并运行修改后的摘录。由于这次练习中我们将使用一个单独的管道，所以不需要像上一篇文章那样使用完整的集合。我们将再次使用鸢尾花数据集。
- en: Let's bring this very simple pipeline to life.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个非常简单的管道实现起来。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And the model''s returned accuracy and hyperparameters:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以及模型返回的准确性和超参数：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note, once again, that we are applying feature scaling, dimensionality reduction
    (using PCA to project data onto 2 dimensional space), and finally applying our
    final estimator.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意，我们正在应用特征缩放、降维（使用 PCA 将数据投影到二维空间），最后应用我们的最终估算器。
- en: Now let's add grid search to our pipeline, with the hopes of optimizing our
    model's hyperparameters and improving its accuracy. Are the default model parameters
    the best bet? Let's find out.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将网格搜索添加到我们的管道中，希望能够优化模型的超参数并提高其准确性。默认模型参数是否是最佳选择？让我们来找出答案。
- en: 'Since our model uses a decision tree estimator, we will use grid search to
    optimize the following hyperparameters:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的模型使用决策树估算器，我们将使用网格搜索来优化以下超参数：
- en: '**criterion** - This is the function used to evaluate the quality of the split;
    we will use both options available in Scikit-learn: Gini impurity and information
    gain (entropy)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**criterion** - 这是用于评估分割质量的函数；我们将使用 Scikit-learn 中的两个选项：基尼不纯度和信息增益（熵）'
- en: '**min_samples_leaf** - This is the minimum number of samples required for a
    valid leaf node; we will use the integer range 1 to 5'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**min_samples_leaf** - 这是构成有效叶节点所需的最小样本数；我们将使用整数范围 1 到 5'
- en: '**max_depth** - The is the maximum depth of the tree; we will use the integer
    range 1 to 5'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**max_depth** - 这是树的最大深度；我们将使用整数范围 1 到 5'
- en: '**min_samples_split** - This is the minimum number of samples required in order
    to split a non-leaf node; we will use the integer range 1 to 5'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**min_samples_split** - 这是拆分非叶节点所需的最小样本数；我们将使用整数范围 1 到 5'
- en: '**presort** - This indicates whether or not to presort the data in order to
    speed up the location of best splits during fitting; this does not have any effect
    on the resulting model accuracy (only on training times), but has been included
    for the benefit of using a True/False hyperparameter in our grid search model
    (fun, right?!?)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**presort** - 这指示是否预排序数据以加速在拟合过程中找到最佳分割；这不会影响最终模型的准确性（仅影响训练时间），但为了在网格搜索模型中使用
    True/False 超参数而被包含在内（有趣吧？！？）'
- en: Here is the code to use exhaustive grid search in our adapted pipeline example.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在我们调整的管道示例中使用详尽的网格搜索的代码。
- en: Of importance, note that our pipeline is the estimator in the grid search object,
    and that it is at the level of the grid search object which we fit our model(s).
    Also note that our grid parameter space is defined in a dictionary and then fed
    to our grid search object.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，请注意我们的管道是网格搜索对象中的估算器，且模型是在网格搜索对象的层级中拟合的。还要注意我们的网格参数空间在一个字典中定义，然后传递给我们的网格搜索对象。
- en: 'What else is is happening during the grid search object''s creation? In order
    to score our resulting models (there are a potential 2 * 5 * 5 * 5 * 2 = 500),
    we will direct our grid search to evaluate them by their accuracy on the test
    set. We also have denoted a cross-validation splitting strategy of 10 folds. Note
    the following about GridSearchCV:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索对象创建过程中还发生了什么？为了对结果模型进行评分（潜在有 2 * 5 * 5 * 5 * 2 = 500 种），我们将引导网格搜索通过在测试集上的准确性来评估它们。我们还指定了
    10 折的交叉验证拆分策略。请注意有关 GridSearchCV 的以下内容：
- en: The parameters of the estimator used to apply these methods are optimized by
    cross-validated grid-search over a parameter grid.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用于应用这些方法的估算器的参数通过对参数网格进行交叉验证网格搜索来优化。
- en: Finally, of course, our model is fit.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，当然，我们的模型已拟合。
- en: You will want to check out the official [GridSearchCV module documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
    for information on all of the other useful configurations, including, but not
    limited to, parallelism.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看官方的 [GridSearchCV 模块文档](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)，以获取所有其他有用配置的信息，包括但不限于并行处理。
- en: Let's try it out.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看。
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And here''s the result:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The script reports back the highest attained accuracy (0.925), which is clearly
    better than the default 0.867, for not much additional computation, at least not
    in absolute terms, given our toy dataset. Our exhaustive approach, which included
    500 models in this case, could have had much more serious computational impacts
    on a formidable dataset, as you could imagine.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本报告了最高的准确度（0.925），这显然比默认的0.867要好，并且额外的计算量并不多，至少在我们的玩具数据集上是这样。我们包括500个模型的详尽方法在强大的数据集上可能会有更严重的计算影响，正如你所想象的那样。
- en: The script also reports back the optimal hyperparameter configuration for the
    model with the highest accuracy, which can be seen above. This difference in our
    simple example should be evidence enough to suggest that Scikit-learn defaults
    should not be followed blindly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本还报告了具有最高准确度的模型的最佳超参数配置，如上所示。在我们的简单示例中，这种差异应该足以表明，不应盲目跟随 Scikit-learn 的默认设置。
- en: This all seems overly simple. And it is. Scikit-learn is almost too easy to
    use, once you know what options are available. Our use of toy datasets is not
    making it seem any more complex either.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切看起来过于简单。确实是。Scikit-learn 使用起来几乎过于简单，只要你知道有哪些选项。我们使用玩具数据集也没有让它看起来更复杂。
- en: 'But look at it this way: pipelines and grid search go together like chocolate
    and peanut butter, and now that we have looked at the basics of how they work
    together, we can take on some more difficult challenges. More complex data? Sure.
    Compare a variety of estimators and numerous parameter search spaces for each
    in order to find the "true" most optimized model possible? Why not? Mix a combination
    of pipeline transformations into the mix for fun and profit? Yasss!'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 不妨这样看：管道和网格搜索就像巧克力和花生酱一样相互配合，现在我们已经了解了它们如何一起工作，接下来我们可以挑战一些更复杂的问题。更复杂的数据？当然可以。比较各种估算器和每个估算器的大量参数搜索空间，以找到“真正的”最优化模型？为什么不呢？将管道转换组合起来，既有趣又有利？是的！
- en: Join us next time when we will push beyond the basics of configuration and the
    toy datasets.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下次加入我们，我们将超越配置和玩具数据集的基础知识。
- en: '**Related:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Managing Machine Learning Workflows with Scikit-learn Pipelines Part 1: A
    Gentle Introduction](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Scikit-learn 管道管理机器学习工作流 第1部分：温和的介绍](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)'
- en: '[7 Steps to Mastering Data Preparation with Python](/2017/06/7-steps-mastering-data-preparation-python.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Python 数据准备的 7 个步骤](/2017/06/7-steps-mastering-data-preparation-python.html)'
- en: '[Machine Learning Workflows in Python from Scratch Part 1: Data Preparation](/2017/05/machine-learning-workflows-python-scratch-part-1.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从零开始的 Python 机器学习工作流 第1部分：数据准备](/2017/05/machine-learning-workflows-python-scratch-part-1.html)'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关主题
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用网格搜索和随机搜索进行超参数调整的 Python 方法](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
- en: '[Integrating ChatGPT Into Data Science Workflows: Tips and Best Practices](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 ChatGPT 集成到数据科学工作流中：技巧和最佳实践](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
- en: '[Building a Visual Search Engine - Part 2: The Search Engine](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-2.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建视觉搜索引擎 - 第2部分：搜索引擎](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-2.html)'
- en: '[Elevate Your Search Engine Skills with Uplimit''s Search with ML Course!](https://www.kdnuggets.com/2023/10/uplimit-elevate-your-search-engine-skills-search-with-ml-course)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过 Uplimit 的机器学习课程提升您的搜索引擎技能！](https://www.kdnuggets.com/2023/10/uplimit-elevate-your-search-engine-skills-search-with-ml-course)'
- en: '[Cutting Down Implementation Time by Integrating Jupyter and KNIME](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过集成 Jupyter 和 KNIME 来缩短实现时间](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)'
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据分析：在 Databricks 中集成 GitHub Copilot](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
