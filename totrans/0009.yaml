- en: Beginnerâ€™s Guide to Building LLM Apps with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://www.kdnuggets.com/beginners-guide-to-building-llm-apps-with-python](https://www.kdnuggets.com/beginners-guide-to-building-llm-apps-with-python)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Beginnerâ€™s Guide to Building LLM Apps with Python](../Images/c380ff86d656d015ad72ec4198aa6f28.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor | Midjourney & Canva
  prefs: []
  type: TYPE_NORMAL
- en: Robin Sharma said, "**Every master was once a beginner. Every pro was once an
    amateur**."Â  You have heard about large language models (LLMs), AI, and Transformer
    models (GPT) making waves in the AI space for a while, and you are confused about
    how to get started. I can assure you that everyone you see today building complex
    applications was once there.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png)1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png)2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png)3\. [Google IT Support Professional
    Certificate](https://www.kdnuggets.com/google-itsupport) - Support your organization
    in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: That is why, in this article, you will be impacted by the knowledge you need
    to start building LLM apps with Python programming language. This is strictly
    beginner-friendly, and you can code along while reading this article.
  prefs: []
  type: TYPE_NORMAL
- en: What will you build in this article? You will create a simple AI personal assistant
    that generates a response based on the user's prompt and deploys it to access
    it globally. The image below shows what the finished application looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![This image shows the user interface of the AI personal assistant that will
    be built in this article](../Images/239aaa46b34aa7ac7d9ae2214c9f7a63.png)'
  prefs: []
  type: TYPE_IMG
- en: This image shows the user interface of the AI personal assistant that will be
    built in this article
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For you to follow through with this article, there are a few things you need
    to have on lock.Â  This includes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Python](https://www.python.org/) (3.5+), and background writing Python scripts.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'OpenAI: [OpenAI](https://openai.com/) is a research organization and technology
    company that aims to ensure artificial general intelligence (AGI) benefits all
    of humanity. One of its key contributions is the development of advanced LLMs
    such as [GPT-3](https://openai.com/index/gpt-3-apps/) and [GPT-4](https://openai.com/index/gpt-4/).
    These models can understand and generate human-like text, making them powerful
    tools for various applications like chatbots, content creation, and more.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Sign up](https://www.openai.com/) for OpenAI and copy your API keys from the
    API section in your account so that you can access the models.Â  Install OpenAI
    on your computer using the command below:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: LangChain:[LangChain](https://www.langchain.com/) is a framework designed to
    simplify the development of applications that leverage LLMs. It provides tools
    and utilities to manage and streamline the various aspects of working with LLMs,
    making building complex and robust applications easier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install LangChain on your computer using the command below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Streamlit: [Streamlit](https://streamlit.io/) is a powerful and easy-to-use
    Python library for creating web applications. Streamlit allows you to create interactive
    web applications using Python alone. You don''t need expertise in web development
    (HTML, CSS, JavaScript) to build functional and visually appealing web apps.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It''s beneficial for building machine learning and data science apps, including
    those that utilize LLMs. Install streamlit on your computer using the command
    below:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Code Along
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With all the required packages and libraries installed, it is time to start
    building the LLM application. Create aÂ  requirement.txt in the root directory
    of your working directory and save the dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Create an app.py file and add the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Imports the Streamlit library, which is used to create interactive web applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: from langchain.llms import OpenAI imports the OpenAI class from the langchain.llms
    module, which is used to interact with OpenAI's language models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: st.title('Simple LLM-App ðŸ¤–') sets the title of the Streamlit web.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: openai_api_key = st.sidebar.text_input('OpenAI API Key', type='password') creates
    a text input widget in the sidebar for the user to input their OpenAI API key.
    The input type is set to 'password' to hide the entered text for security.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: def generate_response(input_text) defines a function named generate_response
    that takes input_text as an argument.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key) initializes the
    OpenAI class with a temperature setting of 0.7 and the provided API key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Temperature** is a parameter used to control the randomness or creativity
    of the text generated by a language model. It determines how much variability
    the model introduces into its predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Low Temperature (0.0 - 0.5)**: This makes the model more deterministic and
    focused.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medium Temperature (0.5 - 1.0)**: Provides a balance between randomness and
    determinism.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High Temperature (1.0 and above)**: Increases the randomness of the output.
    Higher values make the model more creative and diverse in its responses, but this
    can also lead to less coherence and more nonsensical or off-topic outputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: st.info(llm(input_text)) calls the language model with the provided input_text
    and displays the generated response as an informational message in the Streamlit
    app.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: with st.form('my_form') creates a form container named my_form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: text = st.text_area('Enter text:', '') adds a text area input widget within
    the form for the user to enter text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: submitted = st.form_submit_button('Submit') adds a submit button to the form.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if not openai_api_key.startswith('sk-') checks if the entered API key does not
    start with sk-.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: st.warning('Please enter your OpenAI API key!', icon='âš ') displays a warning
    message if the API key is invalid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if submitted and openai_api_key.startswith('sk-') checks if the form is submitted
    and the API key is valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: generate_response(text) calls the generate_response function with the entered
    text to generate and display the response.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Putting it together here is what you have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Running the application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The application is ready; you need to execute the application script using the
    appropriate command for the framework you're using.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By running this code using streamlit run app.py, you create an interactive web
    application where users can enter prompts and receive LLM-generated text responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you execute streamlit run app.py, the following happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Streamlit server starts**: Streamlit starts a local web server on your machine,
    typically accessible at `http://localhost:8501` by default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code execution**: Streamlit reads and executes the code in `app.py,` rendering
    the app as defined in the script.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web interface**: Your web browser automatically opens (or you can manually
    navigate) to the URL provided by Streamlit (usually **http://localhost:8501**),
    where you can interact with your LLM app.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying your LLM application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deploying an LLM app means making it accessible over the internet so others
    can use and test it without requiring access to your local computer. This is important
    for collaboration, user feedback, and real-world testing, ensuring the app performs
    well in diverse environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy the app to the Streamlit Cloud, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a GitHub repository for your app. Make sure your repository includes
    two files: **app.py** and r**equirements.txt**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to [Streamlit Community Cloud](http://share.streamlit.io/), click the "**New
    app**" button from your workspace, and specify the repository, branch, and main
    file path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click the **Deploy** button, and your LLM application will now be deployed to
    Streamlit Community Cloud and can be accessed globally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Beginnerâ€™s Guide to Building LLM Apps with Python](../Images/6f640f2e2be2647ae054b649a22f3ced.png)'
  prefs: []
  type: TYPE_IMG
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Congratulations! You've taken your first steps in building and deploying a LLM
    application with Python. Starting from understanding the prerequisites, installing
    necessary libraries, and writing the core application code, you have now created
    a functional AI personal assistant. By using Streamlit, you've made your app interactive
    and easy to use, and by deploying it to the Streamlit Community Cloud, you've
    made it accessible to users worldwide.
  prefs: []
  type: TYPE_NORMAL
- en: With the skills you've learned in this guide, you can dive deeper into LLMs
    and AI, exploring more advanced features and building even more sophisticated
    applications. Keep experimenting, learning, and sharing your knowledge with the
    community. The possibilities with LLMs are vast, and your journey has just begun.
    Happy coding!
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.linkedin.com/in/olumide-shittu)****[Shittu Olumide](https://www.linkedin.com/in/olumide-shittu/)****
    is a software engineer and technical writer passionate about leveraging cutting-edge
    technologies to craft compelling narratives, with a keen eye for detail and a
    knack for simplifying complex concepts. You can also find Shittu on [Twitter](https://twitter.com/Shittu_Olumide_).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Tools to Help Build Your LLM Apps](https://www.kdnuggets.com/5-tools-to-help-build-your-llm-apps)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building Data Pipelines to Create Apps with Large Language Models](https://www.kdnuggets.com/building-data-pipelines-to-create-apps-with-large-language-models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Web LLM: Bring LLM Chatbots to the Browser](https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Drag-and-Drop UI for Building LLM Flows: Flowise AI](https://www.kdnuggets.com/2023/07/draganddrop-ui-building-llm-flows-flowise-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Things You Need to Know When Building LLM Applications](https://www.kdnuggets.com/2023/08/5-things-need-know-building-llm-applications.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
