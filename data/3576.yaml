- en: 'LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain + Streamlit + Llama：将对话 AI 带到你的本地机器
- en: 原文：[https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/27ddeaf200b7c811937a171c487ffd39.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama：将对话 AI 带到你的本地机器](../Images/27ddeaf200b7c811937a171c487ffd39.png)'
- en: Image By Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: In the past few months, ***Large Language Models (LLMs)*** have gained significant
    attention, capturing the interest of developers across the planet. These models
    have created exciting prospects, especially for developers working on chatbots,
    personal assistants, and content creation. The possibilities that LLMs bring to
    the table have sparked a wave of enthusiasm in the Developer | AI | NLP community.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几个月里，***大型语言模型（LLMs）***受到了广泛关注，吸引了全球开发者的兴趣。这些模型创造了令人兴奋的前景，特别是对于从事聊天机器人、个人助手和内容创作的开发者。LLMs
    带来的可能性在开发者 | AI | NLP 社区中引发了一波热情。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: What are LLMs?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 LLM？
- en: Large Language Models (LLMs) refer to machine learning models capable of producing
    text that closely resembles human language and comprehending prompts in a natural
    manner. These models undergo training using extensive datasets comprising books,
    articles, websites, and other sources. By analyzing statistical patterns within
    the data, LLMs predict the most probable words or phrases that should follow a
    given input.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是指能够生成类似人类语言的文本并以自然方式理解提示的机器学习模型。这些模型通过使用包含书籍、文章、网站和其他来源的大型数据集进行训练。通过分析数据中的统计模式，LLMs
    预测最可能跟随给定输入的词或短语。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/e991e62406a4b0d7a08a09757b8f64d8.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama：将对话 AI 带到你的本地机器](../Images/e991e62406a4b0d7a08a09757b8f64d8.png)'
- en: '**A timeline of LLMs in recent years: **[**A Survey of Large Language Models**](https://arxiv.org/abs/2303.18223)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**近几年 LLM 的时间轴：**[**大型语言模型的调研**](https://arxiv.org/abs/2303.18223)'
- en: By utilizing Large Language Models (LLMs), we can incorporate domain-specific
    data to address inquiries effectively. This becomes especially advantageous when
    dealing with information that was not accessible to the model during its initial
    training, such as a company’s internal documentation or knowledge repository.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用大型语言模型（LLMs），我们可以整合特定领域的数据以有效回答查询。这在处理模型初次训练时未能访问的信息时尤为有利，例如公司的内部文档或知识库。
- en: The architecture employed for this purpose is known as ***Retrieval Augmentation
    Generation*** or, less commonly, ***Generative Question Answering.***
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为此目的采用的架构被称为 ***检索增强生成***，或较少见的 ***生成性问答。***
- en: What is LangChain
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 LangChain
- en: LangChain is an impressive and freely available framework meticulously crafted
    to empower developers in creating applications fueled by the might of language
    models, particularly large language models (LLMs).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个令人印象深刻且免费提供的框架，精心设计用于帮助开发者创建以语言模型，特别是大型语言模型（LLMs）的强大功能为基础的应用程序。
- en: LangChain revolutionizes the development process of a wide range of applications,
    including chatbots, Generative Question-Answering (GQA), and summarization. By
    seamlessly **chaining** together components sourced from multiple modules, LangChain
    enables the creation of exceptional applications tailored around the power of
    LLMs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 彻底改变了各种应用程序的开发过程，包括聊天机器人、生成式问答（GQA）和总结。通过无缝地**串联**来自多个模块的组件，LangChain
    实现了围绕 LLMs 的强大功能创建出色的应用程序。
- en: '**Read More: **[**Official Documentation**](https://python.langchain.com/docs/get_started/introduction.html)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**了解更多：**[**官方文档**](https://python.langchain.com/docs/get_started/introduction.html)'
- en: Motivation?
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机？
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/76904d8d6b7759d86c1d9c30d6e1e002.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到本地机器](../Images/76904d8d6b7759d86c1d9c30d6e1e002.png)'
- en: '**Image By Author**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者提供的图片**'
- en: In this article, I will demonstrate the process of creating your own Document
    Assistant from the ground up, utilizing LLaMA 7b and Langchain, an open-source
    library specifically developed for seamless integration with LLMs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将演示从头开始创建自己的文档助手的过程，利用 LLaMA 7b 和 Langchain，这是一个专为与 LLMs 无缝集成而开发的开源库。
- en: 'Here is an overview of the blog’s structure, outlining the specific sections
    that will provide a detailed breakdown of the process:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是博客结构的概述，概述了将详细说明过程的特定部分：
- en: '`**Setting up the virtual environment and creating file structure**`'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`**设置虚拟环境和创建文件结构**`'
- en: '`**Getting LLM on your local machine**`'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`**将 LLM 安装到本地机器上**`'
- en: '`**Integrating LLM with LangChain and customizing PromptTemplate**`'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`**将 LLM 与 LangChain 集成并自定义 PromptTemplate**`'
- en: '`**Document Retrieval and Answer Generation**`'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`**文档检索和回答生成**`'
- en: '`**Building application using Streamlit**`'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`**使用 Streamlit 构建应用程序**`'
- en: 'Section 1: Setting Up the Virtual Environment and Creating File Structure'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1节：设置虚拟环境和创建文件结构
- en: Setting up a virtual environment provides a controlled and isolated environment
    for running the application, ensuring that its dependencies are separate from
    other system-wide packages. This approach simplifies the management of dependencies
    and helps maintain consistency across different environments.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 设置虚拟环境提供了一个受控且隔离的环境来运行应用程序，确保其依赖项与其他系统范围的包分开。这种方法简化了依赖项的管理，并有助于在不同环境中保持一致性。
- en: To set up the virtual environment for this application, I will provide the pip
    file in my GitHub repository. First, let’s create the necessary file structure
    as depicted in the figure. Alternatively, you can simply clone the repository
    to obtain the required files.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置这个应用程序的虚拟环境，我将在我的 GitHub 仓库中提供 pip 文件。首先，让我们创建图中所示的必要文件结构。或者，你也可以直接克隆仓库以获取所需文件。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/a4c8b4dc938d177ac3e69737c4730181.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到本地机器](../Images/a4c8b4dc938d177ac3e69737c4730181.png)'
- en: '**Image By Author: File Structure**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者提供的图片：文件结构**'
- en: Inside the models' folder, we will store the LLMs that we will download, while
    the pip file will be located in the root directory.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型文件夹中，我们将存储下载的 LLMs，而 pip 文件将位于根目录中。
- en: To create the virtual environment and install all the dependencies within it,
    we can use the `**pipenv install**`command from the same directory or simply run
    `**setup_env.bat**` batch file, It will install all the dependencies from the `**pipfile**`.
    This will ensure that all the necessary packages and libraries are installed in
    the virtual environment. Once the dependencies are successfully installed, we
    can proceed to the next step, which involves downloading the desired models. Here
    is the [repo](https://github.com/afaqueumer/DocQA).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建虚拟环境并安装其中的所有依赖项，我们可以使用 `**pipenv install**`命令，或者直接运行`**setup_env.bat**`批处理文件，它将从 `**pipfile**`中安装所有依赖项。这将确保在虚拟环境中安装所有必要的软件包和库。一旦依赖项成功安装，我们可以继续进行下一步，即下载所需的模型。这里是[仓库](https://github.com/afaqueumer/DocQA)。
- en: 'Section 2: Getting LLaMA on your local machine'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2节：在本地机器上获取 LLaMA
- en: What is LLaMA?
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 LLaMA？
- en: LLaMA is a new large language model designed by Meta AI, which is Facebook’s
    parent company. With a diverse collection of models ranging from 7 billion to
    65 billion parameters, LLaMA stands out as one of the most comprehensive language
    models available. On February 24th, 2023, Meta released the LLaMA model to the
    public, demonstrating their dedication to open science.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA是Meta AI设计的新型大型语言模型，Meta是Facebook的母公司。LLaMA拥有从70亿到650亿参数的多种模型，是现有的最全面的语言模型之一。2023年2月24日，Meta将LLaMA模型公开发布，展示了其对开放科学的承诺。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/821f71d5744b7f82f05e5a4e844c6461.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式AI带到你的本地机器](../Images/821f71d5744b7f82f05e5a4e844c6461.png)'
- en: Image Source: [LLaMA](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [LLaMA](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)'
- en: Considering the remarkable capabilities of LLaMA, we have chosen to utilize
    this powerful language model for our purposes. Specifically, we will be employing
    the smallest version of LLaMA, known as LLaMA 7B. Even at this reduced size, LLaMA
    7B offers significant language processing capabilities, allowing us to achieve
    our desired outcomes efficiently and effectively.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到LLaMA的卓越能力，我们选择使用这个强大的语言模型来满足我们的需求。具体来说，我们将使用LLaMA的最小版本，即LLaMA 7B。即便在这个较小的规模下，LLaMA
    7B仍提供显著的语言处理能力，使我们能够高效且有效地实现所需的结果。
- en: '***Official Research Paper* : **`[**LLaMA: Open and Efficient Foundation Language
    Models**](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)`'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***官方研究论文* : **`[**LLaMA: 开放且高效的基础语言模型**](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)`'
- en: To execute the LLM on a local CPU, we need a local model in GGML format. Several
    methods can achieve this, but the simplest approach is to download the bin file
    directly from the [**Hugging Face Models repository**](https://huggingface.co/models).
    In our case, we will download the Llama 7B model. These models are open-source
    and freely available for download.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地CPU上运行LLM，我们需要一个GGML格式的本地模型。有几种方法可以实现这一点，但最简单的方法是直接从[**Hugging Face模型库**](https://huggingface.co/models)下载bin文件。在我们的案例中，我们将下载Llama
    7B模型。这些模型是开源的，可以自由下载。
- en: If you’re looking to save time and effort, don’t worry — I’ve got you covered.
    Here’s the direct link for you to download the models [?](https://huggingface.co/TheBloke/LLaMa-7B-GGML).
    Simply download any version of it and then move the file into the models directory
    within our root directory. This way, you’ll have the model conveniently accessible
    for your usage.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想节省时间和精力，不用担心——我已经为你准备好了。这里是直接下载模型的链接[?](https://huggingface.co/TheBloke/LLaMa-7B-GGML)。只需下载任何一个版本，然后将文件移动到我们根目录中的models目录下。这样，你就能方便地使用这个模型。
- en: What is GGML? Why GGML? How GGML? LLaMA CPP
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是GGML？为什么选择GGML？如何使用GGML？LLaMA CPP
- en: GGML is a Tensor library for machine learning, it is just a C++ library that
    allows you to run LLMs on just the CPU or CPU + GPU. It defines a binary format
    for distributing large language models (LLMs). GGML makes use of a technique called ***quantization*** that
    allows for large language models to run on consumer hardware.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: GGML是一个用于机器学习的Tensor库，它只是一个C++库，允许你在CPU或CPU+GPU上运行LLMs。它定义了一种用于分发大型语言模型（LLMs）的二进制格式。GGML利用了一种叫做***量化***的技术，使大型语言模型可以在消费者硬件上运行。
- en: Now what is Quantization?
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，什么是量化？
- en: LLM weights are floating point (decimal) numbers. Just like it requires more
    space to represent a large integer (e.g. 1000) compared to a small integer (e.g.
    1), it requires more space to represent a high-precision floating point number
    (e.g. 0.0001) compared to a low-precision floating number (e.g. 0.1). The process
    of ***quantizing*** a large language model involves reducing the precision with
    which weights are represented in order to reduce the resources required to use
    the model. GGML supports a number of different quantization strategies (e.g. 4-bit,
    5-bit, and 8-bit quantization), each of which offers different trade-offs between
    efficiency and performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的权重是浮点（十进制）数字。就像表示一个大整数（例如1000）比表示一个小整数（例如1）需要更多空间一样，表示一个高精度浮点数（例如0.0001）也比表示一个低精度浮点数（例如0.1）需要更多空间。对大型语言模型进行***量化***的过程涉及减少权重表示的精度，以减少使用模型所需的资源。GGML支持多种量化策略（例如4-bit、5-bit和8-bit量化），每种策略在效率和性能之间提供了不同的权衡。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/1c2bbc0d51b28e1de91c6ef15b2ec866.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到您的本地机器](../Images/1c2bbc0d51b28e1de91c6ef15b2ec866.png)'
- en: Quantized Size of Llama
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 的量化大小
- en: To effectively use the models, it is essential to consider the memory and disk
    requirements. Since the models are currently loaded entirely into memory, you
    will need sufficient disk space to store them and enough RAM to load them during
    execution. When it comes to the 65B model, even after quantization, it is recommended
    to have at least 40 gigabytes of RAM available. It’s worth noting that the memory
    and disk requirements are currently equivalent.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效使用模型，考虑内存和磁盘需求是至关重要的。由于模型当前完全加载到内存中，你需要足够的磁盘空间来存储它们，以及足够的 RAM 在执行期间加载它们。对于
    65B 模型，即使经过量化，建议至少拥有 40 GB 的 RAM。值得注意的是，目前的内存和磁盘要求是相等的。
- en: Quantization plays a crucial role in managing these resource demands. Unless
    you have access to exceptional computational resources
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 量化在管理这些资源需求中起着关键作用。除非你有非常强大的计算资源
- en: By reducing the precision of the model’s parameters and optimizing memory usage,
    quantization enables the models to be utilized on more modest hardware configurations.
    This ensures that running the models remains feasible and efficient for a wider
    range of setups.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过减少模型参数的精度和优化内存使用，量化使得模型可以在更低配置的硬件上使用。这确保了在更广泛的设置中运行模型仍然可行和高效。
- en: How do we use it in Python if it's a C++ library?
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果这是一个 C++ 库，我们如何在 Python 中使用它？
- en: That's where Python bindings come into play. Binding refers to the process of
    creating a bridge or interface between two languages for us python and C++. We
    will use `**llama-cpp-python**`which is a Python binding for `**llama.cpp**` which
    acts as an Inference of the LLaMA model in pure C/C++. The main goal of `**llama.cpp**` is
    to run the LLaMA model using 4-bit integer quantization. This integration allows
    us to effectively utilize the LLaMA model, leveraging the advantages of C/C++
    implementation and the benefits of 4-bit integer quantization
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这时 Python 绑定就派上用场了。绑定指的是为我们 Python 和 C++ 之间创建桥梁或接口的过程。我们将使用 `**llama-cpp-python**`，这是
    `**llama.cpp**` 的 Python 绑定，充当 LLaMA 模型在纯 C/C++ 中的推理。`**llama.cpp**` 的主要目标是使用
    4 位整数量化运行 LLaMA 模型。这种集成允许我们有效地利用 LLaMA 模型，结合 C/C++ 实现的优势和 4 位整数量化的好处。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/36db440161ec441ebaedf10dddfeb864.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到您的本地机器](../Images/36db440161ec441ebaedf10dddfeb864.png)'
- en: Supported Models by llama.cpp : [Source](https://github.com/ggerganov/llama.cpp)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: llama.cpp 支持的模型： [来源](https://github.com/ggerganov/llama.cpp)
- en: With the GGML model prepared and all our dependencies in place (thanks to the
    pipfile), it’s time to embark on our journey with LangChain. But before diving
    into the exciting world of LangChain, let’s kick things off with the customary **“Hello
    World”** ritual — a tradition we follow whenever exploring a new language or framework,
    after all, LLM is also a language model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好 GGML 模型并且所有依赖项到位（感谢 pipfile）之后，是时候开始我们的 LangChain 之旅了。但在深入 LangChain 的精彩世界之前，让我们先从惯例
    **“Hello World”** 仪式开始 — 这是我们每次探索新语言或框架时遵循的传统，毕竟 LLM 也是一种语言模型。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/7cb74721780631998d742ea12e5c5e43.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到您的本地机器](../Images/7cb74721780631998d742ea12e5c5e43.png)'
- en: 'Image By Author: Interaction with LLM on CPU'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：在 CPU 上与 LLM 互动
- en: '*Voilà !!! *We have successfully executed our first LLM on the CPU, completely
    offline and in a fully randomized fashion(you can play with the hyper param **temperature**).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*瞧！！！*我们已经成功在 CPU 上执行了第一个 LLM，完全离线并以完全随机的方式（你可以调整超参数 **temperature**）。'
- en: 'With this exciting milestone accomplished, we are now ready to embark on our
    primary objective: question answering of custom text using the LangChain framework.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这个激动人心的里程碑的完成，我们现在准备开始我们的主要目标：使用 LangChain 框架对自定义文本进行问答。
- en: 'Section 3: Getting Started with LLM — LangChain Integration'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：开始使用 LLM — LangChain 集成
- en: In the last section, we initialized LLM using llama cpp. Now, let’s leverage
    the LangChain framework to develop applications using LLMs. The primary interface
    through which you can interact with them is through text. As an oversimplification,
    a lot of models are **text in, text out**. Therefore, a lot of the interfaces
    in LangChain are centered around the text.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用 llama cpp 初始化了 LLM。现在，让我们利用 LangChain 框架来开发基于 LLM 的应用程序。你与它们互动的主要接口是通过文本。简而言之，许多模型是**文本输入，文本输出**。因此，LangChain
    中的许多接口都是围绕文本展开的。
- en: The Rise of Prompt Engineering
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示工程的兴起
- en: In the ever-evolving field of programming a fascinating paradigm has emerged: **Prompting**.
    Prompting involves providing specific input to a language model to elicit a desired
    response. This innovative approach allows us to shape the output of the model
    based on the input we provide.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在不断发展的编程领域中，一个引人入胜的范式已经出现：**提示**。提示涉及向语言模型提供特定输入以引出期望的回应。这种创新的方法允许我们根据提供的输入来塑造模型的输出。
- en: It’s remarkable how the nuances in the way we phrase a prompt can significantly
    impact the nature and substance of the model’s response. The outcome may vary
    fundamentally based on the wording, highlighting the importance of careful consideration
    when formulating prompts.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们措辞方式中的细微差别对模型回应的性质和内容产生显著影响，这一点非常值得注意。结果可能会根据措辞的不同而发生根本性的变化，这突显了在制定提示时需要仔细考虑的的重要性。
- en: For providing seamless interaction with LLMs, LangChain provides several classes
    and functions to make constructing and working with prompts easy using a prompt
    template. It is a reproducible way to generate a prompt. It contains a text string **the
    template**, that can take in a set of parameters from the end user and generates
    a prompt. Let’s take a few examples.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与 LLM 提供无缝互动，LangChain 提供了多个类和函数，通过使用提示模板，使构造和处理提示变得简单。这是一种可重复的生成提示的方式。它包含一个文本字符串**模板**，可以接收来自最终用户的一组参数并生成提示。让我们看几个例子。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/5a8edcd9f81501a0e08b0070b2bf93fd.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到你的本地机器](../Images/5a8edcd9f81501a0e08b0070b2bf93fd.png)'
- en: 'Image By Author: Prompt with no Input Variables'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：没有输入变量的提示
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/8be0c291e1eeb6878ebd2a97aff72294.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到你的本地机器](../Images/8be0c291e1eeb6878ebd2a97aff72294.png)'
- en: 'Image By Author: Prompt with one Input Variables'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：使用单一输入变量的提示
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/a2765b9f4326d4810b39972bcfa3f5ad.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到你的本地机器](../Images/a2765b9f4326d4810b39972bcfa3f5ad.png)'
- en: 'Image By Author: Prompt with multiple Input Variables'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：使用多个输入变量的提示
- en: I hope that the previous explanation has provided a clearer grasp of the concept
    of prompting. Now, let’s proceed to prompt the LLM.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望之前的解释已经让你对提示的概念有了更清晰的理解。现在，让我们继续对 LLM 进行提示。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/27412fb10867abc0e375460b956ed473.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话 AI 带到你的本地机器](../Images/27412fb10867abc0e375460b956ed473.png)'
- en: 'Image By Author: Prompting through Langchain LLM'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：通过 Langchain LLM 进行提示
- en: This worked perfectly fine but this ain’t the optimum utilisation of LangChain.
    So far we have used individual components. We took the prompt template formatted
    it, then took the llm, and then passed those params inside llm to generate the
    answer. Using an LLM in isolation is fine for simple applications, but more complex
    applications require chaining LLMs — either with each other or with other components.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法运行得很好，但这不是 LangChain 的最佳利用方式。到目前为止，我们使用了单独的组件。我们取了提示模板，格式化它，然后取了 llm，然后将这些参数传递给
    llm 以生成答案。单独使用 LLM 对于简单应用程序来说是可以的，但更复杂的应用程序需要将 LLM 链接起来——无论是彼此之间，还是与其他组件之间。
- en: LangChain provides the Chain interface for such **chained**applications. We
    define a Chain very generically as a sequence of calls to components, which can
    include other chains. Chains allow us to combine multiple components together
    to create a single, coherent application. For example, we can create a chain that
    takes user input, formats it with a Prompt Template, and then passes the formatted
    response to an LLM. We can build more complex chains by combining multiple chains
    together, or by combining chains with other components.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 提供了 Chain 接口用于此类**链式**应用。我们非常泛泛地定义 Chain 为一系列对组件的调用，这些组件可以包括其他链。链允许我们将多个组件组合在一起以创建一个单一的、连贯的应用。例如，我们可以创建一个链，它接受用户输入，用提示模板格式化输入，然后将格式化后的响应传递给
    LLM。我们可以通过将多个链组合在一起，或将链与其他组件组合来构建更复杂的链。
- en: To understand one let’s create a very simple **chain** that will take user input,
    format the prompt with it, and then send it to the LLM using the above individual
    components that we’ve already created.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解其中一个，让我们创建一个非常简单的**链**，它将接受用户输入，用它格式化提示，然后使用我们已经创建的上述单独组件将其发送给 LLM。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/d0aef0755947767e82235ed12042833a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到你的本地机器](../Images/d0aef0755947767e82235ed12042833a.png)'
- en: 'Image By Author: Chaining in LangChain'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：LangChain 中的链式操作
- en: When dealing with multiple variables, you have the option to input them collectively
    by utilizing a dictionary. That concludes this section. Now, let’s dive into the
    main part where we’ll incorporate external text as a retriever for question-answering
    purposes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理多个变量时，你可以选择通过使用字典来集体输入它们。到此为止，这一部分结束了。现在，让我们深入到主要部分，我们将结合外部文本作为检索器来进行问答。
- en: 'Section 4: Generating Embeddings and Vectorstore for Question Answering'
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四节：为问答生成嵌入和向量存储
- en: In numerous LLM applications, there is a need for user-specific data that isn’t
    included in the model’s training set. LangChain provides you with the essential
    components to load, transform, store, and query your data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多 LLM 应用中，需要用户特定的数据，这些数据未包含在模型的训练集中。LangChain 为你提供了加载、转换、存储和查询数据的基本组件。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/f43a713bee756508b0a6b149f7f224a2.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到你的本地机器](../Images/f43a713bee756508b0a6b149f7f224a2.png)'
- en: 'Data Connection in LangChain: Source'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 中的数据连接：来源
- en: 'The five stages are:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 五个阶段是：
- en: '**Document Loader:** It is used for loading data as documents.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档加载器：** 用于将数据加载为文档。'
- en: '**Document Transformer:** It split the document into smaller chunks.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档转换器：** 它将文档拆分为较小的块。'
- en: '**Embeddings:** It transforms the chunks into vector representations a.k.a
    embedding.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入：** 它将块转换为向量表示，即嵌入。'
- en: '**Vector Stores:** It is used to store the above chunk vectors in a vector
    database.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**向量存储：** 用于在向量数据库中存储上述块向量。'
- en: '**Retrievers:** It is used for retrieving a set/s of vector/s that are most
    similar to a query in a form of a vector that is embedded in the same Latent space.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索器：** 它用于检索与查询最相似的一组/组向量，这些向量以与查询嵌入在同一潜在空间中的向量形式存在。'
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/6a911e0e7b279f2a0f0b85b8d52ad652.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到你的本地机器](../Images/6a911e0e7b279f2a0f0b85b8d52ad652.png)'
- en: Document Retrieval / Question-Answering Cycle
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 文档检索/问答循环
- en: Now, we will walk through each of the five steps to perform a retrieval of chunks
    of documents that are most similar to the query. Following that, we can generate
    an answer based on the retrieved vector chunk, as illustrated in the provided
    image.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将逐步进行五个步骤，以检索与查询最相似的文档块。随后，我们可以基于检索到的向量块生成答案，如所提供的图像所示。
- en: 'However, before proceeding further, we will need to prepare a text for executing
    the aforementioned tasks. For the purpose of this fictitious test, I have copied
    a text from Wikipedia regarding some popular DC Superheroes. Here is the text:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在进一步进行之前，我们需要准备一个文本以执行上述任务。为了这个虚构的测试，我从维基百科复制了一段关于一些受欢迎的 DC 超级英雄的文本。以下是文本：
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/46d8e1d9012cf4743545a981ede46510.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式 AI 带到你的本地机器](../Images/46d8e1d9012cf4743545a981ede46510.png)'
- en: 'Image By Author: Raw Text for Testing'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：用于测试的原始文本
- en: Loading & Transforming Documents
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载与转换文档
- en: To begin, let’s create a document object. In this example, we’ll utilize the
    text loader. However, Lang chain offers support for multiple documents, so depending
    on your specific document, you can employ different loaders. Next, we’ll employ
    the `**load**` method to retrieve data and load it as documents from a preconfigured
    source.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个文档对象。在这个示例中，我们将使用文本加载器。然而，LangChain支持多种文档，因此根据你的具体文档，你可以使用不同的加载器。接下来，我们将使用`**load**`方法从预配置的源中检索数据并将其加载为文档。
- en: Once the document is loaded, we can proceed with the transformation process
    by breaking it into smaller chunks. To achieve this, we’ll utilize the TextSplitter.
    By default, the splitter separates the document at the ‘\n\n’ separator. However,
    if you set the separator to null and define a specific chunk size, each chunk
    will be of that specified length. Consequently, the resulting list length will
    be equal to the length of the document divided by the chunk size. In summary,
    it will resemble something like this: `**list length = length of doc / chunk size**`.
    Let’s walk the talk.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文档被加载，我们可以通过将其分成较小的块来继续转换过程。为此，我们将使用TextSplitter。默认情况下，分割器在‘\n\n’分隔符处分隔文档。然而，如果你将分隔符设置为null并定义特定的块大小，每个块将具有指定的长度。因此，结果列表的长度将等于文档的长度除以块大小。总之，它将类似于`**list
    length = length of doc / chunk size**`。让我们实践一下。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/c370b5096a0c441ef7de81ca1cf84cca.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式AI带到本地机器](../Images/c370b5096a0c441ef7de81ca1cf84cca.png)'
- en: 'Image By Author: Loading and Transforming Doc'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：加载和转换文档
- en: Part of the journey is the Embeddings !!!
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 旅程的一部分就是嵌入 !!!
- en: This is the most important step. Embeddings generate a vectorized portrayal
    of textual content. This has practical significance since it allows us to conceptualize
    text within a vector space.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最重要的一步。嵌入生成了文本内容的向量化表现。这具有实际意义，因为它允许我们在向量空间中概念化文本。
- en: Word embedding is simply a vector representation of a word, with the vector
    containing real numbers. Since languages typically contain at least tens of thousands
    of words, simple binary word vectors can become impractical due to a high number
    of dimensions. Word embeddings solve this problem by providing dense representations
    of words in a low-dimensional vector space.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入只是单词的向量表示，向量包含实数。由于语言通常包含至少数万词汇，简单的二进制词向量由于维度过高可能变得不切实际。词嵌入通过在低维向量空间中提供密集的词表示来解决这个问题。
- en: When we talk about retrieval, we refer to retrieving a set of vectors that are
    most similar to a query in a form of a vector that is embedded in the same Latent
    space.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论检索时，我们指的是检索与查询最相似的一组向量，这些向量以嵌入在相同潜在空间中的形式存在。
- en: 'The base Embeddings class in LangChain exposes two methods: one for embedding
    documents and one for embedding a query. The former takes as input multiple texts,
    while the latter takes a single text.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain中的基础嵌入类暴露了两个方法：一个用于嵌入文档，另一个用于嵌入查询。前者接受多个文本作为输入，而后者接受单个文本。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/e907d5209ef2487d1333684af40c818a.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话式AI带到本地机器](../Images/e907d5209ef2487d1333684af40c818a.png)'
- en: 'Image By Author: Embeddings'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：嵌入
- en: For a comprehensive understanding of embeddings, I highly recommend delving
    into the fundamentals as they form the core of how neural networks handle textual
    data. I have extensively covered this topic in one of my blogs utilizing TensorFlow.
    Here is the link.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面理解嵌入，我强烈建议深入了解基础知识，因为它们构成了神经网络处理文本数据的核心。我在我的一篇博客中广泛讨论了这个主题，使用了TensorFlow。这里是链接。
- en: Word Embeddings — Text Representation for Neural Networks
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词嵌入——神经网络的文本表示
- en: Creating Vector Store & Retrieving Docs
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建向量存储和检索文档
- en: A vector store efficiently manages the storage of embedded data and facilitates
    vector search operations on your behalf. Embedding and storing the resulting embedding
    vectors is a prevalent method for storing and searching unstructured data. During
    query time, the unstructured query is also embedded, and the embedding vectors
    that exhibit the highest similarity to the embedded query are retrieved. This
    approach enables effective retrieval of relevant information from the vector store.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储高效地管理嵌入数据的存储，并代表你执行向量搜索操作。嵌入和存储生成的嵌入向量是一种存储和搜索非结构化数据的常见方法。在查询时，非结构化查询也会被嵌入，并检索出与嵌入查询具有最高相似度的嵌入向量。这种方法能够有效地从向量存储中检索相关信息。
- en: Here, we will utilize Chroma, an embedding database and vector store specifically
    crafted to simplify the development of AI applications incorporating embeddings.
    It offers a comprehensive suite of built-in tools and functionalities to facilitate
    your initial setup, all of which can be conveniently installed on your local machine
    by executing a simple `**pip install chromadb**` command.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用Chroma，一个专门为简化AI应用程序开发而设计的嵌入数据库和向量存储。它提供了一整套内置工具和功能来简化你的初始设置，所有这些都可以通过执行简单的`**pip
    install chromadb**`命令方便地安装在本地机器上。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/edd0230ac4a9b9ce09f964137857ea7d.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话AI带到你的本地机器](../Images/edd0230ac4a9b9ce09f964137857ea7d.png)'
- en: 'Image By Author: Creating Vector Store'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供：创建向量存储
- en: Up until now, we’ve witnessed the remarkable capability of embeddings and vector
    stores in retrieving relevant chunks from extensive document collections. Now,
    the moment has come to present this retrieved chunk as a context alongside our
    query, to the LLM. With a flick of its magical wand, we shall beseech the LLM
    to generate an answer based on the information that we provided to it. The important
    part is the prompt structure.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经见证了嵌入和向量存储在从大量文档集合中检索相关片段方面的显著能力。现在，时机已到，我们将把这个检索到的片段与查询一起作为上下文呈现给LLM。挥动它的魔法棒，我们将请求LLM基于我们提供的信息生成答案。关键在于提示结构。
- en: However, it is crucial to emphasize the significance of a well-structured prompt.
    By formulating a well-crafted prompt, we can mitigate the potential for the LLM
    to engage in **hallucination **— wherein it might invent facts when faced with
    uncertainty.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须强调结构良好的提示的重要性。通过制定精心设计的提示，我们可以减轻LLM在面对不确定性时可能出现的**幻觉**——即它可能发明事实。
- en: Without prolonging the wait any further, let us now proceed to the final phase
    and discover if our LLM is capable of generating a compelling answer. The time
    has come to witness the culmination of our efforts and unveil the outcome. Here
    we Goooooo ?
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在不再拖延的情况下，让我们进入最后阶段，看看我们的LLM是否能够生成引人注目的答案。时刻来临，见证我们的努力成果并揭示结果吧。我们出发了？
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/944a48f62adf73996e3ea293794b3a81.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama: 将对话AI带到你的本地机器](../Images/944a48f62adf73996e3ea293794b3a81.png)'
- en: 'Image By Author: Q/A with the Doc'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供：与文档的问答
- en: This is the moment we’ve been waiting for! We’ve accomplished it! We have just
    built our very own question-answering bot utilizing the LLM running locally.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们一直期待的时刻！我们成功了！我们刚刚构建了我们自己的问答机器人，利用本地运行的LLM。
- en: 'Section 5: Chain All using Streamlit'
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5部分：使用Streamlit链式操作
- en: This section is entirely optional since it doesn’t serve as a comprehensive
    guide to Streamlit. I won’t delve deep into this part; instead, I’ll present a
    basic application that allows users to upload any text document. They will then
    have the option to ask questions through text input. Behind the scenes, the functionality
    will remain consistent with what we covered in the previous section.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分完全是可选的，因为它并不是Streamlit的全面指南。我不会深入探讨这一部分；相反，我会展示一个基本应用，允许用户上传任何文本文件。然后，他们可以通过文本输入提问。幕后功能将与我们在上一部分中讨论的保持一致。
- en: However, there is a caveat when it comes to file uploads in Streamlit. To prevent
    potential out-of-memory errors, particularly considering the memory-intensive
    nature of LLMs, I’ll simply read the document and write it to the temporary folder
    within our file structure, naming it `**raw.txt.**` This way, regardless of the
    document’s original name, Textloader will seamlessly process it in the future.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 Streamlit 中处理文件上传时有一个警告。为了防止潜在的内存不足错误，特别是考虑到 LLM 的内存密集型特性，我将简单地读取文档并将其写入我们文件结构中的临时文件夹，命名为`**raw.txt.**`。这样，无论文档的原始名称是什么，Textloader
    将在未来无缝处理它。
- en: Currently, the app is designed for text files, but you can adapt it for PDFs,
    CSVs, or other formats. The underlying concept remains the same since LLMs are
    primarily designed for text input and output. Additionally, you can experiment
    with different LLMs supported by the Llama C++ bindings.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，该应用程序设计用于文本文件，但你可以将其适应于 PDF、CSV 或其他格式。基本概念保持不变，因为 LLM 主要用于文本输入和输出。此外，你可以尝试不同的由
    Llama C++ 绑定支持的 LLM。
- en: Without delving further into intricate details, I present the code for the app.
    Feel free to customize it to suit your specific use case.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 不再深入复杂的细节，我提供了应用程序的代码。随意自定义以适应你的特定用例。
- en: Here’s what the streamlit app will look like.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 streamlit 应用程序的外观。
- en: '![LangChain + Streamlit + Llama: Bringing Conversational AI to Your Local Machine](../Images/53f1d5576ae768ec3ddedd9e447eb1d3.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![LangChain + Streamlit + Llama：将对话式 AI 带到本地机器](../Images/53f1d5576ae768ec3ddedd9e447eb1d3.png)'
- en: This time I fed the plot of **The Dark Knight** copied from Wiki and just asked **Whose
    face is severely burnt? **and the LLM replied — **Harvey Dent**.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我提供了从 Wiki 复制的**《黑暗骑士》**的情节，并仅仅问了**“谁的脸被严重烧伤？”**，LLM 回复了——**哈维·丹特**。
- en: All right, all right, all right! With that, we come to the end of this blog.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，好了，好了！至此，我们博客的内容就结束了。
- en: I hope you enjoyed this article! and found it informative and engaging. You
    can **follow me **[Afaque Umer](https://medium.com/u/430bc504f9d9) for **more** such
    articles.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这篇文章！并觉得它既有信息量又有趣。你可以**关注我**[Afaque Umer](https://medium.com/u/430bc504f9d9)以获得**更多**此类文章。
- en: I will try to bring up more **M****achine learning/Data science concepts **and
    will try to break down fancy-sounding terms and concepts into simpler ones.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我将尝试引入更多**机器学习/数据科学概念**，并尝试将复杂的术语和概念拆解成更简单的形式。
- en: '**[Afaque Umer](https://www.linkedin.com/in/afaque-umer/)** is a passionate
    Machine Learning Engineer. He love tackling new challenges using latest tech to
    find efficient solutions. Let''s push the boundaries of AI together!'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Afaque Umer](https://www.linkedin.com/in/afaque-umer/)** 是一位充满激情的机器学习工程师。他喜欢利用最新技术解决新挑战，寻找高效的解决方案。让我们一起推动
    AI 的边界！'
- en: '[Original](https://ai.plainenglish.io/%EF%B8%8F-langchain-streamlit-llama-bringing-conversational-ai-to-your-local-machine-a1736252b172).
    Reposted with permission.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://ai.plainenglish.io/%EF%B8%8F-langchain-streamlit-llama-bringing-conversational-ai-to-your-local-machine-a1736252b172)。已获授权转载。'
- en: More On This Topic
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Llama, Llama, Llama：使用你的内容进行本地 RAG 的 3 个简单步骤](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
- en: '[3 Crucial Challenges in Conversational AI Development and How to Avoid Them](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对话式 AI 开发中的 3 个关键挑战及如何避免](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
- en: '[DIY Automated Machine Learning with Streamlit](https://www.kdnuggets.com/2021/11/diy-automated-machine-learning-app.html)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Streamlit 的 DIY 自动化机器学习](https://www.kdnuggets.com/2021/11/diy-automated-machine-learning-app.html)'
- en: '[Streamlit for Machine Learning Cheat Sheet](https://www.kdnuggets.com/2023/01/streamlit-machine-learning-cheat-sheet.html)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Streamlit 机器学习备忘单](https://www.kdnuggets.com/2023/01/streamlit-machine-learning-cheat-sheet.html)'
- en: '[Answering Questions with HuggingFace Pipelines and Streamlit](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 HuggingFace Pipelines 和 Streamlit 回答问题](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
- en: '[Deploying a Streamlit WebApp to Heroku using DAGsHub](https://www.kdnuggets.com/2022/02/deploying-streamlit-webapp-heroku-dagshub.html)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 Streamlit WebApp 部署到 Heroku 使用 DAGsHub](https://www.kdnuggets.com/2022/02/deploying-streamlit-webapp-heroku-dagshub.html)'
