- en: How Watermarking Can Help Mitigate The Potential Risks Of LLMs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](../Images/ae5b6cf6ecd93c42d65e2eb6c8c2eb22.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need a Watermarking for Large Language Models?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) like ChatGPT, GPT-4, and Bard are revolutionizing
    the way we work. We now have tools that help us code the whole program or write
    a blog post for a new product release. Applications powered by GPT-3.5 are generating
    realistic and diverse texts on multiple topics. Just like all of the new technologies,
    they come with the potential risks of stealing intellectual property, plagiarism,
    misinformation, and online abuse.
  prefs: []
  type: TYPE_NORMAL
- en: How do we ensure that LLMs outputs are trustworthy and accountable? Currently,
    there is no reliable solution. There are some [tools](/2023/02/5-free-tools-detecting-chatgpt-gpt3-gpt2.html)
    for detecting generated text, but they have low accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the paper by the University of Maryland: [A Watermark for Large Language
    Models](https://arxiv.org/pdf/2301.10226.pdf), the authors have proposed a watermarking
    framework for proprietary LLMs. It watermarks the output of generated text with
    invisible signals that can be detected by an algorithm and invisible to humans.'
  prefs: []
  type: TYPE_NORMAL
- en: Watermarking is an effective technique that can be used to prove the ownership,
    authenticity, or integrity of the object.
  prefs: []
  type: TYPE_NORMAL
- en: '**For example:**'
  prefs: []
  type: TYPE_NORMAL
- en: It can help protect the intellectual property (models) of LLM developers, scientists,
    and companies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can prevent plagiarism or misattribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can help detect social media misinformation campaigns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The most important use of watermarking is that it can help monitor and audit
    the use and impact of LLMs and prevent misuse or abuse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does Watermarking work for LLMs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The watermarking [framework](https://arxiv.org/pdf/2301.10226.pdf) consists
    of two components: embedding and detection.'
  prefs: []
  type: TYPE_NORMAL
- en: Embedding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is the process of inserting a watermark into the output of the LLMs. To make
    it possible, the LLM developer needs to slightly modify the model parameters to
    embed the watermark.
  prefs: []
  type: TYPE_NORMAL
- en: The embedding works by selecting a random set of "green" tokens before each
    word is generated, and then softly promoting the use of green tokens during sampling.
    The green tokens are chosen in a way that does not affect the context and quality
    of the text. The embedding also ensures that there are enough tokens in each span
    to make the decision process possible.
  prefs: []
  type: TYPE_NORMAL
- en: Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is the process of extracting the “green” tokens from a given span of text.
    It does not require model parameters or API. The detection works by computing
    a statistic called curvature for each token in the span. Curvature is the measurement
    of how sensitive the probability distribution over tokens is to small changes
    in model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The authors explain that the green tokens have a higher curvature than the normal
    tokes and thus form a detectable pattern in the text.
  prefs: []
  type: TYPE_NORMAL
- en: After performing watermarking detection, the algorithm performs a statistical
    test to determine the confidence level of the result.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more by reading the paper on [arxiv.org](https://arxiv.org/pdf/2301.10226.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face Demo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can try generating text with watermarks by using the [Hugging Space Gradio
    Demo](https://huggingface.co/spaces/tomg-group-umd/lm-watermarking) or you can
    check out the GitHub repository: [jwkirchenbauer/lm-watermarking](https://github.com/jwkirchenbauer/lm-watermarking)
    for running the Python scripts on personal machine.'
  prefs: []
  type: TYPE_NORMAL
- en: '![How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](../Images/83a8474870639053fc1cc5576b37b07e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Hugging Face |  [A Watermark for LLMs ](https://huggingface.co/spaces/tomg-group-umd/lm-watermarking)
  prefs: []
  type: TYPE_NORMAL
- en: How Effective is Watermarking for LLMs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will review the results mentioned in the paper on various tasks such as summarization,
    translation, and dialogue generation.
  prefs: []
  type: TYPE_NORMAL
- en: The paper reports that their framework achieves high embedding rates **> 90%**
    and detection rates **> 99%** across different tasks while maintaining low false
    positive rates **< 1%** and high text quality scores. The authors have also demonstrated
    that the framework is robust to various attacks, such as paraphrasing, mixing,
    or truncating watermarked texts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Embedding rate**: how often green tokens are used in the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detection rate**: how often watermarks are correctly detected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False positive rate**: how often non-watermarked texts are mistakenly detected
    as watermarked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text quality**: how natural and fluent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations and Challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is a start, and the watermark framework comes with limitations and challenges,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: You have to modify model parameters during embedding, and in some cases (API,
    edge device) it is not possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It relies on sampling-based generation methods that are not compatible with
    other methods, such as beam search or nucleus sampling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The watermarks are embedded uniformly across different tasks, and it might not
    be good for certain tasks where certain tokens have more semantic importance than
    others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other implementation challenges and fair use policies that are essential
    for wide adoption of an algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we have discussed the importance of watermarking for large language
    models, how the framework works, results, and limitations. It is the summary of
    a paper that proposes a watermarking framework for proprietary LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: It is a start, and we need frameworks like watermarking to make AI safer for
    everyone. I want you to try the Hugging Face [demo](https://huggingface.co/spaces/tomg-group-umd/lm-watermarking)
    to experience the awesomeness yourself. If you are interested in theory and the
    inner working of algorithms, read the [paper](https://arxiv.org/pdf/2301.10226.pdf)
    and [code source](https://github.com/jwkirchenbauer/lm-watermarking).
  prefs: []
  type: TYPE_NORMAL
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How a Level System can Help Forecast AI Costs](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data access is severely lacking in most companies, and 71% believe…](https://www.kdnuggets.com/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How SAS can help catapult practitioners'' careers](https://www.kdnuggets.com/2023/07/sas-help-catapult-practitioners-careers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Rare Data Science Skills That Can Help You Get Employed](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Generative AI Can Help You Improve Your Data Visualization Charts](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
