# 如何在第一次Kaggle比赛中排名前10%

> 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3)

**模型训练**

我们可以通过调整参数来提升模型的性能。一个模型通常有很多参数，但只有其中少数对其性能至关重要。例如，对于随机森林，最重要的参数是森林中的树木数量和每棵树使用的最大特征数量。**我们需要理解模型如何工作以及每个参数对模型性能的影响，无论是准确性、鲁棒性还是速度。**

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的IT组织

* * *

通常，我们会通过一个称为**[网格搜索](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html))**的过程找到最佳参数组合。实际上，它所做的就是遍历所有可能的组合并找到最佳的一组。

顺便提一下，随机森林通常在`max_features`设置为特征总数的平方根时达到最佳状态。

在这里，我想强调一些关于调整XGB的要点。这些参数通常被认为对其性能有实际影响：

+   `eta`：用于更新权重的步长。较低的`eta`意味着训练较慢但收敛性更好。

+   `num_round`：总迭代次数。

+   `subsample`：每次迭代中使用的训练数据比例。这是为了防止过拟合。

+   `colsample_bytree`：每次迭代中使用的特征比例。这类似于`RandomForestClassifier`中的`max_features`。

+   `max_depth`：每棵树的最大深度。与随机森林不同，**梯度提升如果不限制其深度最终会过拟合**。

+   `early_stopping_rounds`：如果在给定的迭代次数内没有看到验证评分的提升，算法将提前停止。这也是为了防止过拟合。

通常的调整步骤：

1.  保留一部分训练集作为验证集。

1.  将`eta`设置为相对较高的值（例如0.05 ~ 0.1），`num_round`设置为300 ~ 500。

1.  使用网格搜索找到其他参数的最佳组合。

1.  逐渐降低`eta`直到我们达到最佳状态。

1.  **使用验证集作为`watch_list`，用最佳参数重新训练模型。观察每次迭代中验证集上的得分变化。找到`early_stopping_rounds`的最佳值。**

最后，请注意，所有具有随机性的模型都有一个类似于`seed`或`random_state`的参数来控制随机种子。**你必须记录下这一点**以及其他所有参数，当你得到一个好的模型时。否则你将无法重现它。

**交叉验证**

**[交叉验证](https://en.wikipedia.org/wiki/Cross-validation_(statistics))**是模型训练中的一个关键步骤。它告诉我们模型是否有很高的过拟合风险。在许多比赛中，公共LB分数并不非常可靠。通常，当我们改进模型并获得更好的本地交叉验证得分时，LB分数会变得更差。**在这种情况下，人们普遍认为我们应该相信我们的交叉验证得分。**理想情况下，我们希望**不同方法获得的交叉验证得分与LB分数同步提升**，但这并不总是可能的。

通常**5折交叉验证**足够好了。如果我们使用更多折，交叉验证得分会更可靠，但训练也需要更长时间才能完成。然而，如果我们的训练数据有限，我们不应该使用太多折。否则，每一折中的样本可能太少，无法保证统计显著性。

如何正确进行交叉验证并不是一个简单的问题。这需要不断的实验和逐案讨论。许多Kaggle竞赛者在比赛后分享他们的交叉验证方法（比如[这个](https://www.kaggle.com/c/telstra-recruiting-network/forums/t/19277/what-is-your-cross-validation-method)），当他们觉得可靠的交叉验证并不容易时。

**集成生成**

[集成学习](https://en.wikipedia.org/wiki/Ensemble_learning)指的是结合不同模型的技术。它**减少了最终模型的偏差和方差**（你可以在[这里](http://link.springer.com/chapter/10.1007%2F3-540-33019-4_19)找到证明），从而**提高得分并减少过拟合的风险**。最近，在Kaggle竞赛中几乎不可能在不使用集成学习的情况下获奖。

集成学习的常见方法有：

+   **自助法**：使用训练数据的不同随机子集来训练每个基础模型。然后所有基础模型进行投票以生成最终预测。这就是随机森林的工作原理。

+   **提升**：迭代训练基础模型，根据上一轮迭代修改训练样本的权重。这就是梯度提升树的工作原理。（实际上，这并不是全部。除了提升，GBT还尝试学习早期迭代的残差。）它比自助法表现更好，但更容易过拟合。

+   **混合**：使用不重叠的数据训练不同的基础模型，并对它们取加权平均值以获得最终预测。这种方法易于实现，但数据使用较少。

+   **堆叠**：将稍后讨论。

理论上，为了使集成表现良好，有两个因素需要考虑：

+   **基础模型应该尽可能不相关**。这就是为什么我们倾向于在集成中包括非树模型，即使它们的表现不如树模型。数学表明，多样性越大，最终集成的偏差越小。

+   **基础模型的表现不应相差太大。**

实际上，我们在这里有一个**权衡**。在实践中，我们可能会得到性能相当的高度相关模型。然而，我们还是将它们集成在一起，因为这通常会提高整体性能。

**堆叠**

与混合相比，堆叠更好地利用了训练数据。这里是它如何工作的示意图：

[![堆叠](../Images/fb2fd03a6a8cf5851969a1254b354966.png)](http://7xlo8f.com1.z0.glb.clouddn.com/blog-diagram-stacking.jpg)

*（取自 [Faron](https://www.kaggle.com/mmueller)。非常感谢！）*

这很像交叉验证。以5折堆叠为例。首先，我们将训练数据分成5折。接下来，我们将进行5次迭代。在每次迭代中，对4折数据训练每个基础模型，并在保留折上进行预测。**你也必须保留测试数据上的预测。**这样，在每次迭代中，每个基础模型都会对训练数据的1折和所有测试数据进行预测。经过5次迭代后，我们将得到一个形状为`#(训练数据样本数) X #(基础模型数)`的矩阵。这个矩阵然后被输入到第二层的堆叠器（它只是另一个模型）中。在堆叠器拟合后，使用基础模型对测试数据的预测（**每个基础模型训练5次，因此我们需要取平均值以获得相同形状的矩阵**）作为堆叠器的输入，得到最终预测。

也许展示代码更好：

奖项获得者通常拥有更大且更复杂的集成。对于初学者来说，实现一个正确的5折堆叠就足够了。

***管道***

我们可以看到，Kaggle竞赛的工作流程非常复杂，特别是在模型选择和集成方面。理想情况下，我们需要一个高度自动化的管道，能够：

+   **模块化特征转换**。我们只需编写几行代码（或者更好，规则/领域特定语言），新的特征就会被添加到训练集中。

+   **自动化网格搜索**。我们只需设置模型和参数网格，搜索将运行，最佳参数将被记录。

+   **自动化集成选择**。当我们将另一个基础模型加入池中时，使用最佳的K个模型来训练集成。

对于初学者来说，第一个不是很重要，因为特征数量是相当可控的；第三个也不重要，因为通常我们只会在竞赛结束时做几次集成。但第二个是有用的，因为**手动记录每个模型的表现和参数既费时又容易出错**。

[程龙·陈](https://www.kaggle.com/chenglongchen)，[Crowdflower 搜索结果相关性比赛](https://www.kaggle.com/c/crowdflower-search-relevance)的获胜者，曾在[GitHub](https://github.com/ChenglongChen/Kaggle_CrowdFlower)上发布了他的管道。它非常完整和高效，但理解和提取他的所有逻辑以构建通用框架非常困难。这可能是你有足够时间时想做的事情。

### 更多相关话题

+   [LinkedIn 如何利用机器学习来排名你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)

+   [如何在没有任何工作经验的情况下获得你的第一个数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [使用 TensorFlow 和 Keras 构建并训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [它活了！使用 Python 和一些便宜的组件构建你的第一个机器人，…](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)

+   [从零到英雄：使用 PyTorch 创建你的第一个机器学习模型](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)

+   [部署你的第一个机器学习模型](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)
