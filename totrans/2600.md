# 机器学习的持续训练——成功策略的框架

> 原文：[https://www.kdnuggets.com/2021/04/continuous-training-machine-learning.html](https://www.kdnuggets.com/2021/04/continuous-training-machine-learning.html)

[评论](#comments)

**由 [Or Itzary](https://www.linkedin.com/in/or-itzary/) 和 [Liran Nahum](https://www.linkedin.com/in/nahumliran/)，Superwise.ai 的数据科学家**。

![](../Images/6a313d3202e84b51844f14f80a2839ea.png)

*照片来源于 Unsplash 的 Monika Pejkovska。*

‍机器学习模型是基于一个假设构建的，即生产中使用的数据将类似于过去观察到的数据，也就是我们训练模型所用的数据。虽然对于一些特定的应用场景这可能是正确的，但大多数模型在动态数据环境中工作，在这些环境中数据不断变化，并且“概念漂移”可能会发生，进而对模型的准确性和可靠性产生不利影响。

为了应对这一点，机器学习模型需要定期重新训练。或者，正如 Google 在 “[MLOps: Continuous delivery and automation pipelines in machine learning](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)” 中所述：

> “*为了应对这些挑战并保持模型在生产中的准确性，你需要做以下几点：积极监控生产中模型的质量[...] 并频繁重新训练你的生产模型。*”

这个概念被称为‘**持续训练**’（CT），是 MLOps 实践的一部分。持续训练旨在自动和持续地重新训练模型，以适应可能在数据中发生的变化。

执行持续重新训练有不同的方法/方法论，每种方法都有其优点、缺点和成本。然而，与光脚走路的鞋匠类似，我们——数据科学家——似乎过度进行重新训练，有时是手动的，并且常常将其作为一种“默认”解决方案，而没有足够的生产驱动的洞察。

每个机器学习应用场景都有其动态数据环境，这些环境可能导致概念漂移：从实时交易到欺诈检测，其中对手改变了数据分布，或推荐引擎中充满了新电影和新趋势。然而，无论应用场景如何，在设计持续训练策略时都需要解决三个主要问题：

**1 - 什么时候应该重新训练模型？** 由于目标是保持运行中的模型高度相关并在任何时候都表现最佳，那么模型应该多频繁地重新训练？

**2 - 应该使用哪些数据？** 对于选择适当的数据集，常见的假设是数据的相关性与其新近程度相关，这引发了一系列问题：我们应该只使用新数据还是添加到旧数据集中？旧数据和新数据之间的良好平衡是什么？什么时间被视为新数据，或者旧数据和新数据之间的界限是什么？

**3 - 应该再训练什么？** 我们是否可以仅仅更换数据并用相同的超参数再训练相同的模型？还是应该采取更具侵入性的方法，运行一个模拟我们研究过程的完整管道？

上述三个问题中的每一个都可以单独回答，并有助于确定每种情况的最佳策略。然而，在回答这些问题的同时，还有一系列需要考虑的因素，我们在此进行探讨。对于每个问题，我们描述了不同的策略，这些策略对应于机器学习过程的不同自动化水平和成熟度。

### 什么时候再训练？

三种最常见的策略是周期性再训练、基于性能的策略或基于数据变化的策略。

**周期性再训练**

周期性再训练计划是最简单直接的方法。通常，它是基于时间的：模型每三个月再训练一次——但也可以是基于数据量的，例如每10万条新标签。

周期性再训练的优势非常简单明了：这是一个非常直观且易于管理的方法，因为可以清楚地知道下一个再训练迭代的时间，而且**实现起来很容易**。

![](../Images/870a1d90ef8adfb74cba04510c4b9d09.png)

**然而，这种方法往往显示出不适合或效率低下的特征。** 你多久再训练一次模型？每天？每周？每三个月？一年一次？虽然希望频繁再训练以保持模型更新，但在没有实际理由（即没有概念漂移）的情况下，过于频繁地再训练模型是有成本的。此外，即使再训练是自动化的，它仍然需要重要的资源——包括计算资源以及需要监督再训练过程和部署后新模型行为的数据科学团队。尽管如此，间隔较长的再训练可能会忽视持续再训练的要点，无法适应数据变化，还可能面临在噪声数据上再训练的风险。

> *从根本上说，周期性再训练计划是有意义的，前提是其频率与您领域的动态性相一致。否则，选择随机的时间/里程碑可能会使您面临风险，并留下与其前一版本相比相关性较低的模型。*

**基于性能的触发器**

这几乎是基于经典工程格言的常识性说法：“如果它没有坏，就不要修理它。” 第二种最常见的方法是利用基于性能的触发器，一旦检测到性能下降就再训练模型。

![](../Images/c214a01fc8e30b2b21ac3dc3a5f4ae5d.png)

这种方法比第一种方法更具经验性，假设您对模型在生产中的性能有持续的视角。

仅依靠性能的主要限制是你获得真实数据所需的时间——如果你能获得的话。在用户转化预测的情况下，可能需要30或60天才能得到真实数据，甚至在交易欺诈检测或LTV等情况中，可能需要6个月或更长时间。如果你需要等待这么长时间才能获得全面反馈，那就意味着你会在业务已经受到影响之后才会进行模型再训练。

另一个需要回答的非琐碎问题是：什么算作‘性能退化’？你可能依赖于阈值的敏感度和校准的准确性，这可能会导致你过于频繁或不够频繁地进行再训练。

> *总体而言，对于有快速反馈和大量数据的用例，如实时竞价，使用基于性能的触发器是好的，这样你可以尽可能接近预测时间测量模型的性能，在短时间间隔内并以高信心（高量）进行测量。*

‍**驱动数据变化**

这种方法是最具动态性的，能自然地触发来自领域动态的再训练。通过测量输入数据的变化，即模型所使用的特征分布的变化，你可以检测到数据漂移，这表明你的模型可能已经过时，需要在新数据上进行再训练。

这是一种替代基于性能的方法，适用于那些没有快速反馈或不能实时评估模型性能的情况。此外，即使在有快速反馈的情况下，结合使用这种方法也是一个好的做法，因为它可能会指示出次优性能，即使没有退化。**理解数据变化以启动再训练过程是非常有价值的，尤其是在动态环境中。**

![](../Images/bb17768d9ab6714cd1def0af950d2d2a.png)

*来自 superwise.ai 的截图。*

‍上图由监控服务生成，展示了一个营销用例中的数据漂移指标（上图）和性能KPI（下图）。数据漂移图是一个时间轴，Y轴显示了每一天的漂移水平（即该天的数据）相对于训练集。在这个营销用例示例中，新活动非常频繁地推出，业务也扩展到新国家。**显然，生产中的数据正在漂移，并变得与模型训练时的数据不太相似。** 通过对模型在生产中的状态有更全面的了解，可以在业务观察到性能下降之前很早就触发再训练。

> *那么何时重新训练？这取决于关键因素，如反馈的可用性、数据的量以及对模型性能的可见性。总体而言，选择何时重新训练并没有一刀切的答案。相反，根据你的资源，目标应该是尽可能以生产驱动的方式进行。*

### 应该使用什么数据？

虽然我们已经看到时机至关重要（即，我何时重新训练我的模型？），现在让我们关注所有MLOps的核心：数据。在重新训练时，我该如何选择合适的数据？

**固定窗口大小**

最简单的方法是使用固定的窗口大小作为训练集。例如，使用过去X个月的数据。显然，这种方法的优点在于其简单性，因为它非常直接。

缺点源于选择合适窗口的挑战：如果窗口过宽，可能会遗漏新的趋势；而如果窗口过窄，则可能会过拟合且数据噪声较多。窗口大小的选择还应考虑到重新训练的频率：如果你仅使用过去一个月的数据作为训练集，那么每三个月重新训练一次是没有意义的。

此外，选择的数据可能与实际生产中流入的数据非常不同，因为它可能发生在变化点之后（在快速/突发变化的情况下），或者可能包含不规则事件（例如假期或像选举日这样的特殊日子）、数据问题等。

> *总体而言，固定窗口方法就像其他“静态”方法一样，是一种简单的启发式方法，在某些情况下可能效果很好，但在变化速率多变且不规则事件（如假期或技术问题）常见的环境中，将无法捕捉到超高的动态性。*

**动态窗口大小**

动态窗口大小方法试图通过确定在更数据驱动的方式中应该包含多少历史数据，来解决预定义窗口大小的一些限制，并将窗口大小视为可以在重新训练过程中优化的另一个超参数。

这种方法最适合有快速反馈的情况（即，实时竞价或食品配送预估时间）。可以将最相关的数据用作测试集，并优化窗口大小，就像优化模型的另一个超参数一样。在下面的示例中，通过取最后3周的数据可以实现最高性能，这就是这一轮应选择的数据。对于未来的轮次，可以根据与测试集的比较选择不同的窗口。

![](../Images/b9c8152fc1831cf62a498d6668e626d2.png)

动态窗口大小方法的优点在于它更加数据驱动，基于模型性能，这才是关键，因此在高度时间敏感的环境中更加稳健。

不利之处在于，它需要一个更复杂的训练流程（见下一个问题“什么进行训练”）来测试不同的窗口大小并选择最优的窗口大小，而且计算密集度更高。此外，与固定窗口大小一样，它假设最新的数据是最相关的，这并不总是正确的。

**动态数据选择**

第三种选择训练数据的方法旨在实现任何重新训练策略的基本目标，即任何机器学习模型的基本假设：使用与生产数据相似的训练数据。换句话说，模型应该在尽可能类似于现实生活中用于发出预测的数据上进行重新训练。这种方法复杂且需要对生产数据有高度的可视性。

**为此，你需要对生产数据的演变进行全面分析，以了解数据是否以及如何随时间变化。** 一种方法是计算每天输入数据的漂移，即一天的数据与另一天天的数据有多大差异，并生成一个热图，揭示数据随时间变化的模式，如下所示。下面的热图是时间上的漂移评估的可视化，其中轴（列和行）是日期，每个点（矩阵中的单元格）表示两天之间的漂移程度，漂移越高，单元格颜色越红。

![](../Images/3b7287de5d9bbe63a7bf0b11f5f5cdfa.png)

*Superwise 数据 DNA 视图。*

上面，你可以看到由 superwise.ai 自动生成的这种分析结果，以帮助发现尽可能与现在流入的数据相似的数据。从这个视图中可以轻松获得不同类型的见解：

1 - 十二月的数据与其他数据（之前和之后）非常不同。这一洞察使我们能够避免将整个时期视为一个整体，并在重新训练时排除这些天，因为这个月的数据不代表你在生产中观察到的正常数据。

2 - 数据的季节性可以被可视化 - 这可能引发关于是否需要为工作日和周末使用不同模型的讨论。

> *这里还有一个非常强大的点：你实际上可以拥有一张图片，证明最新的数据不一定是最相关的。*

简而言之，选择正确的数据来重新训练模型需要对生产数据的行为有一个全面的了解。虽然使用固定或动态窗口大小可能帮助你“打勾”，但通常这仍然是一个猜测，可能比高效更昂贵。

### 该重新训练什么？

现在我们已经分析了何时再训练以及应使用哪些数据，让我们解决第三个问题：什么应该再训练？可以选择仅根据新数据再训练（重新调整）模型实例，包括一些或所有的数据准备步骤，或采取更深入的方法，运行一个完整的管道模拟研究过程。

再训练的基本假设是，在研究阶段训练的模型将因概念漂移而变得过时，因此需要再训练。然而，在大多数情况下，模型实例只是研究阶段构建的更广泛管道的最后一个阶段，并包括数据准备步骤。问题是：漂移的严重程度及其影响有多大？或者在再训练的背景下，模型管道的哪些部分应该受到挑战？

在研究阶段，你会实验和评估模型管道步骤中的许多元素，以优化模型。这些元素可以分为两个高级部分，数据准备和模型训练。数据准备部分负责准备数据（显然！）以供模型使用，包括特征工程、缩放、插补、降维等方法；模型训练部分负责选择最佳模型及其超参数。最终，你会得到一个由顺序步骤组成的管道，这些步骤接收数据，准备数据以供模型使用，并使用模型预测目标结果。

仅用新相关数据再训练模型，即管道中的最后一步，是最简单和幼稚的方法，可能足以避免性能下降。然而，在某些情况下，这种仅模型的方法可能不够，应该采取更全面的再训练范围。扩大再训练范围可以在两个维度上进行：

1 - **什么需要再训练？** 使用新数据应再训练管道的哪些部分？

2 - **再训练的级别：** 你只是用新数据重新调整模型（或其他步骤）吗？你会做超参数优化吗？还是挑战模型本身的选择并测试其他模型类型？

另一种看待这个问题的方法是，在再训练过程中，你基本上尝试自动化并避免数据科学家在没有自动再训练过程时进行的模型优化研究手动工作。因此，你需要决定要多大程度上模拟手动研究过程，如下图所示。

![](../Images/48341e89d2110bc3f0b5196d3ebafe06.png)

*MLOps：机器学习中的持续交付和自动化管道中描述的模型研究阶段。*

‍请注意，自动化流程的第一步更为复杂，随着更多自动化围绕这些实验的建立，过程变得更加健壮和灵活，能够适应变化，但它也增加了复杂性，因为需要考虑更多的边际情况和检查。

### 示例与结论

比如说，我们的优秀数据科学团队为某个分类任务进行的手动研究所得到的简单模型管道：

![](../Images/2b416c4fbc2bc4cf78a4196bc6ba215c.png)

你可以采取简单的方法，仅仅重新训练模型，让它学习一棵新树，或者你可以包括一些（或全部）数据准备步骤（例如，重新学习插补器中的均值或缩放器中的最小/最大值）。但除了选择要重新训练的步骤，你还需要决定到什么程度。例如，即使你选择仅重新训练模型，也可以在多个层次上进行。你可以只是重新训练模型本身，让它学习一棵新树，即 *model.fit* (*new_X*, *new_y*)，或者你可以搜索并优化模型的超参数（最大深度、最小叶子大小、最大叶子节点等），甚至挑战模型本身的选择，测试其他模型类型（例如，逻辑回归和随机森林）。数据准备步骤也可以（并且应该）被重新训练，以测试不同的缩放器或不同的插补方法，甚至测试不同的特征选择。

当选择更全面的方法进行超参数优化/模型搜索时，你还可以使用设计用来自动化构建和优化模型管道的 Auto-ML 框架，包括数据准备、模型搜索和超参数优化。而且它不必涉及复杂的元学习。它可以很简单：由用户选择一系列模型和参数。有许多工具可供选择：[AutoKeras](https://autokeras.com/)，[Auto SciKitLearn](https://github.com/automl/auto-sklearn)。然而，尽管 AutoML 很诱人，但它并不能免除用户拥有一个健全的过程来跟踪、测量和监控模型的生命周期，特别是在部署到生产环境之前和之后。

到头来，“打开开关”并自动化你的过程必须伴随有健全的流程，以确保你能够控制你的数据和模型。

***为了实现高效的持续训练，你应该能够以生产驱动的见解为主导。对于任何使用案例，构建一个强大的机器学习基础设施在很大程度上依赖于实现对模型健康和生产中数据健康的可见性和控制。这就是成为数据驱动的数据科学家的最终要求。***

[原文](https://www.superwise.ai/resources/framework-for-a-successful-continuous-training-strategy)。经许可转载。

**相关：**

+   [机器学习模型监控清单：7 个需要跟踪的事项](https://www.kdnuggets.com/2021/03/machine-learning-model-monitoring-checklist.html)

+   [MLOps：模型监控 101](https://www.kdnuggets.com/2021/01/mlops-model-monitoring-101.html)

+   [模型再训练的终极指南](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行 IT 管理

* * *

### 更多相关话题

+   [数据质量在成功机器学习模型中的重要性](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)

+   [成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [如何在 2022 年成为成功的数据科学自由职业者](https://www.kdnuggets.com/2022/02/become-successful-data-science-freelancer-2022.html)

+   [KDnuggets 新闻，6月22日：主要监督学习算法…](https://www.kdnuggets.com/2022/n25.html)

+   [Django 框架中的社交用户认证](https://www.kdnuggets.com/2023/01/social-user-authentication-django-framework.html)

+   [AI/ML 模型的风险管理框架](https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html)
