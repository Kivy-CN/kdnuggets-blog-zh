- en: 5 Statistical Paradoxes Data Scientists Should Know
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/02/5-statistical-paradoxes-data-scientists-know.html](https://www.kdnuggets.com/2023/02/5-statistical-paradoxes-data-scientists-know.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/562301ccf1afe501fc699b8a9778ba7d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: As data scientists, we rely on statistical analysis to crawl information from
    the data about the relationships between different variables to answer questions,
    which will help businesses and individuals to make the right decisions. However,
    some statistical phenomena can be counterintuitive, possibly leading to paradoxes
    and biases in our analysis, which will ruin our analysis.
  prefs: []
  type: TYPE_NORMAL
- en: These paradoxes I will explain to you are easy to understand and do not include
    complex formulas.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we will explore 5 statistical paradoxes data scientists should
    be aware of: the accuracy paradox, the False Positive Paradox, Gambler’s Fallacy,
    Simpson’s Paradox, and Berkson’s paradox.'
  prefs: []
  type: TYPE_NORMAL
- en: Each of these paradoxes may be the potential reason for getting the unreliable
    result of your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/ab597d5545e0e90fe48acd142317dcda.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss the definitions of these paradoxes and real-life examples to
    illustrate how these paradoxes can happen in real-world data analysis. Understanding
    these paradoxes will help you remove possible roadblocks to reliable statistical
    analysis.
  prefs: []
  type: TYPE_NORMAL
- en: So, without further ado, let’s dive into the world of paradoxes with Accuracy
    Paradox.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy Paradox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/7e5cb497243a668808380deaf7e831d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy shows that accuracy is not a good evaluation metric when it comes to
    classifying.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you are analyzing a dataset that contains 1000 patient metrics. You
    want to catch a rare kind of disease, which will eventually be shown itself in
    5% of the population. So overall, you have to find 50 people in 1000.
  prefs: []
  type: TYPE_NORMAL
- en: Even if you always say that the people do not have a disease, your accuracy
    will be 95%. And your model can't catch a single sick person in this cluster.
    (0/50)
  prefs: []
  type: TYPE_NORMAL
- en: Digits Data Set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s explain this by giving an example from well-known digits data set.
  prefs: []
  type: TYPE_NORMAL
- en: This data set contains hand-written numbers from 0 to 9.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/f83f8067555a3e7802796201698e1671.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: It is a simple multilabel classification task, but it can also be interpreted
    as image recognition since the numbers are presented as images.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will load these data sets and reshape the data set to apply the machine
    learning model. I am skipping explaining these parts because you might also be
    familiar with this part. If not, try searching digit data set or MNIST data set.
    MNIST data set also contains the same kind of data, but the shape is bigger than
    this one.
  prefs: []
  type: TYPE_NORMAL
- en: Alright, let’s continue.
  prefs: []
  type: TYPE_NORMAL
- en: Now we try to predict if the number is 6 or not. To do that, we will define
    a classifier that predicts not 6\. Let’s look at the cross-validation score of
    this classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here the results will be as the following.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/9b625149f8b42f496b2269390400afc6.png)'
  prefs: []
  type: TYPE_IMG
- en: What does it mean? That means even if you create an estimator that will never
    estimate 6 and you put that in your model, the accuracy can be over 90%. Why?
    Because 9 other numbers exist in our dataset. So if you say the number is not
    6, you will be right 9/10 times.
  prefs: []
  type: TYPE_NORMAL
- en: This shows it’s important to choose your evaluation metrics carefully. Accuracy
    is not a good choice if you want to evaluate your classification tasks. You should
    choose precision or recall.
  prefs: []
  type: TYPE_NORMAL
- en: What are those? They come up in the False Positive Paradox, so continue reading.
  prefs: []
  type: TYPE_NORMAL
- en: False Positive Paradox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/00f8a4860e442a84ed155a9360c6e82b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now, the false positive paradox is a statistical phenomenon that can occur when
    we test for the presence of a rare event or condition.
  prefs: []
  type: TYPE_NORMAL
- en: It is also known as the “base rate fallacy” or “base rate neglect”.
  prefs: []
  type: TYPE_NORMAL
- en: This paradox means there are more false positive results than positive results
    when testing rare events.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the example from Data Science.
  prefs: []
  type: TYPE_NORMAL
- en: Fraud Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/a53755e8783272ec93fd6fdbf792ddd4.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you are working on an ML model to detect fraudulent credit card transactions.
    The dataset you are working with includes a large number of normal (non-fraudulent)
    transactions and a small number of fraudulent transactions. Yet when you deploy
    your model in the real world, you find that it produces a large number of false
    positives.
  prefs: []
  type: TYPE_NORMAL
- en: After further investigation, you realize that the prevalence of fraudulent transactions
    in the real world is much lower than in the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say 1/10,000 transactions will be fraudulent, and suppose the test also
    has a 5% rate of false positives.
  prefs: []
  type: TYPE_NORMAL
- en: TP = 1 out of 10,000
  prefs: []
  type: TYPE_NORMAL
- en: FP = 10,000*(100-40)/100*0,05 = 499,95 out of 9,999
  prefs: []
  type: TYPE_NORMAL
- en: So when a fraudulent transaction is found, what is the possibility that it really
    is a fraudulent transaction?
  prefs: []
  type: TYPE_NORMAL
- en: P = 1/500,95 =0,001996
  prefs: []
  type: TYPE_NORMAL
- en: The result is nearly 0.2%. It means when the event gets flagged as fraudulent,
    there is only a 0.2% probability that it really is a fraudulent event.
  prefs: []
  type: TYPE_NORMAL
- en: And that is a false positive paradox.
  prefs: []
  type: TYPE_NORMAL
- en: Here is how to implement it in Python code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the recall is really high, yet the precision is very low.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/a6ffddff783cb2ffd84fa7200f126b97.png)'
  prefs: []
  type: TYPE_IMG
- en: To understand why systems do that, let me explain the precision/recall and precision/recall
    tradeoff.
  prefs: []
  type: TYPE_NORMAL
- en: Recall (true positive rate) is also called sensitivity. You should first find
    the positives and find the rate of true positives among them.
  prefs: []
  type: TYPE_NORMAL
- en: Recall = TP / TP + FP
  prefs: []
  type: TYPE_NORMAL
- en: Precision is the accuracy of positive prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Precision = TP / TP + FN
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you want a classifier that will do sentiment analysis and predict
    whether the comments will be positive or negative. You might want a classifier
    that has high recall (it correctly identifies a high percentage of positive or
    negative comments). However, to have a higher recall, you should be okay with
    having a lower precision (misclassification of positive comments) because it is
    more important to delete negative comments than delete a few positive comments
    occasionally.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you want to build a spam classifier, you might want a
    classifier that has high precision. It correctly identifies high percentages of
    spam, yet once in a while, it allows spam because it is more important to keep
    important mail.
  prefs: []
  type: TYPE_NORMAL
- en: Now in our case, to find a fraudulent transaction, you sacrifice getting many
    errors that are not fraudulent, yet if you do so, you have to take precautions,
    too, like in banking systems. When they detect fraudulent transactions, they begin
    to do further investigations to be absolutely sure.
  prefs: []
  type: TYPE_NORMAL
- en: Typically they send a message to your phone or email for further approval when
    doing a transaction over a preset limit, etc.
  prefs: []
  type: TYPE_NORMAL
- en: If you allow your model to have a False negative, then your recall will be law.
    Yet, if you allow your model to have a False positive, your Precision will be
    low.
  prefs: []
  type: TYPE_NORMAL
- en: As a data scientist, you should adjust your model or add a step to make further
    investigations because there might be a lot of  False Positives.
  prefs: []
  type: TYPE_NORMAL
- en: Gambler’s Fallacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/060b9846e420e7211b1a203ecb0997e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Gambler’s fallacy, also known as the Monte Carlo fallacy, is the mistaken belief
    that if an event happens more frequently than its normal probability, it will
    happen more often in the following trials.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the example from the Data Science field.
  prefs: []
  type: TYPE_NORMAL
- en: Customer Churn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/7e5c9e2ea97ba717445d90018296629f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that you are building a machine learning model to predict whether the
    customer will churn based on their past behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you collected many different types of data, including the number of customers
    interacting with the services, the length of time they have been a customer, the
    number of complaints they have made, and more.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you can be tempted to think a customer who has been with the
    service for a long time is less likely to churn because they have shown a commitment
    to the service in the past.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is an example of a gambler’s fallacy because the probability of
    a customer churning is not influenced by the length of time they have been a customer.
  prefs: []
  type: TYPE_NORMAL
- en: The probability of churn is determined by a wide range of factors, including
    the quality of the service, the customer's satisfaction with the service, and
    more of these factors.
  prefs: []
  type: TYPE_NORMAL
- en: So if you build a machine learning model, be careful explicitly not to create
    a column that includes the length of a customer and try to explain the model by
    using that. At this point, you should realize that this might ruin your model
    due to Gambler’s fallacy.
  prefs: []
  type: TYPE_NORMAL
- en: Now, this was a conceptual example. Let’s try to explain this by giving an example
    of the coin toss.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s first look at the changes in the coin toss probability. You might be tempted
    to think that if the coin has come up heads several times, the possibility in
    the future will diminish. This is actually a great example of the gambler’s fallacy.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, in the beginning, the possibility fluctuated. Yet when the number
    of flips increases, the possibility of getting heads will converge to 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s see the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/15aaa2df1535b4163ffe9b66968f3a7e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: It is obvious that probability fluctuates over time, but as a result, it will
    converge toward 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: This example shows Gambler’s fallacy because the results of previous flips do
    not influence the probability of getting heads on any given flip. The probability
    remains fixed at 50% regardless of what has happened in the past.
  prefs: []
  type: TYPE_NORMAL
- en: Simpsons Paradox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/d2be3dd08034f53b63d44c5aeaf234a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [Roland Steinmann](https://pixabay.com/users/rollstein-13853955/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=7041935)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=7041935)
  prefs: []
  type: TYPE_NORMAL
- en: This paradox happens when the relationship between two variables appears to
    change when data is aggregated.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to explain this paradox, let’s use the built-in data set in seaborn, tips.
  prefs: []
  type: TYPE_NORMAL
- en: Tips
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/0de06f07e11116533b3bd5bacdc25a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: To explain Simpson’s paradox, we will calculate the mean of the average tips
    women and men made during lunch and overall by using the tips data set. The tips
    dataset contains data on tips given by customers at a restaurant, like total tips,
    sex, day, time, and more.
  prefs: []
  type: TYPE_NORMAL
- en: The tips dataset is a collection of data on tips given by customers at a restaurant.
    It includes information such as the tip amount, the gender of the customer, the
    day of the week, and the time of day. The dataset can be used to analyze customers'
    tipping behavior and identify trends in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Alright, here is our data frame.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/aa1619317f018492aa5e4be7d85713f8.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the average tip is bigger when it comes to lunch between men
    and women. Yet when data is aggregated, the mean is changed.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the bar chart to see the changes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/e33083b2b5729ad54d7f5aa8a5ecd6cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Now, as you can see, the average changes as data are aggregated. Suddenly, you
    have data showing that overall, women tip more than men.
  prefs: []
  type: TYPE_NORMAL
- en: What is the catch?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When observing the trend from the subset version and extracting meaning from
    them, be careful not to forget to check whether this trend is still the case for
    the whole data set or not. Because as you can see, there might not be the case
    in special circumstances. This can lead a Data Scientist to make a misjudgment,
    leading to a poor (business) decision.
  prefs: []
  type: TYPE_NORMAL
- en: Berkson’s Paradox
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Berkson’s Paradox is a statistical paradox that happens when two variables correlated
    to each other in data, yet when the data will subsetted, or grouped, this correlation
    is not observed & changed.
  prefs: []
  type: TYPE_NORMAL
- en: In simple terms, Berkson's Paradox is when a correlation appears to be different
    in different subgroups of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look into it by analyzing the Iris dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Iris Data set
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/6c45311109b9ca66517b029f522e5ae5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The Iris dataset is a commonly used dataset in machine learning and statistics.
    It contains data for different observations of irises, including their petal and
    sepal length and width and the flower species observed.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will draw two graphs showing the relationship between sepal length
    and width. But in the second graph, we filter the species as a setosa.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can see the changes between sepal length and within the setosa species.
    Actually, it shows a different correlation than other species.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/596dda1398e2941cbdb0a0f11cbc5f06.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Also, you can see that setosa’s different correlation in the first graph.
  prefs: []
  type: TYPE_NORMAL
- en: In the second graph, you can see that the correlation between sepal width and
    sepal length has changed. When analyzing all data set, it shows that when sepal
    length increases, sepal width decreases. However, if we start analyzing by selecting
    setosa species, the correlation is now positive and shows that when sepal width
    increases, sepal length increases as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here is the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Statistical Paradoxes Data Scientists Should Know](../Images/af9b8193b2d5bb1aa2229c678a8512c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can see that starting by analyzing with setosa and generalizing the sepal
    width and length correlation will lead you to make a false statement according
    to your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we examined five statistical paradoxes that data scientists
    should be aware of in order to do accurate analysis. Let’s suppose you think that
    you found a trend in your data set, which indicates that when sepal length increases,
    sepal width increases as well. Yet when looking at the whole data set, it is actually
    the total opposite.
  prefs: []
  type: TYPE_NORMAL
- en: Or you might be assessing your classification models by looking at the accuracy.
    You see that even the model that does nothing can achieve over 90% accuracy. If
    you tried to evaluate your model with accuracy and do analysis accordingly, think
    about how many miscalculations you can make.
  prefs: []
  type: TYPE_NORMAL
- en: By understanding these paradoxes, we can take steps to avoid common pitfalls
    and improve the reliability of our statistical analysis. It’s also good to approach
    data analysis with a healthy dose of skepticism and avoid potential paradoxes
    and limitations in your analyses.
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, these paradoxes are important for Data Scientists when it comes
    to high-level analysis, as being aware of them can improve the accuracy and reliability
    of our analysis. We also recommend this “[Statistics Cheat Sheet](https://www.stratascratch.com/blog/a-comprehensive-statistics-cheat-sheet-for-data-science-interviews/?utm_source=blog&utm_medium=click&utm_campaign=kdn+statistical+paradoxes)”
    that can help you understand the important terms and equations for statistics
    and probability and can help you for your next data science interview.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs: []
  type: TYPE_NORMAL
- en: '**[Nate Rosidi](https://www.stratascratch.com)** is a data scientist and in
    product strategy. He''s also an adjunct professor teaching analytics, and is the
    founder of [StrataScratch](https://www.stratascratch.com/), a platform helping
    data scientists prepare for their interviews with real interview questions from
    top companies. Connect with him on [Twitter: StrataScratch](https://twitter.com/StrataScratch)
    or [LinkedIn](https://www.linkedin.com/in/nathanrosidi/).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Libraries Data Scientists Should Know in 2022](https://www.kdnuggets.com/2022/04/python-libraries-data-scientists-know-2022.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Data Scientists Should Know About OpenUSD](https://www.kdnuggets.com/what-data-scientists-should-know-about-openusd)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets™ News 22:n03, Jan 19: A Deep Look Into 13 Data…](https://www.kdnuggets.com/2022/n03.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, May 25: The 6 Python Machine Learning Tools Every…](https://www.kdnuggets.com/2022/n21.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Reasons Why Data Scientists Should Use LightGBM](https://www.kdnuggets.com/2022/01/data-scientists-reasons-lightgbm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
