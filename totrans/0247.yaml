- en: How a Level System can Help Forecast AI Costs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层级系统如何帮助预测 AI 成本
- en: 原文：[https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)
- en: '![How a Level System can Help Forecast AI Costs](../Images/5508d68d4ed86099bfaefeee1139d76a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![层级系统如何帮助预测 AI 成本](../Images/5508d68d4ed86099bfaefeee1139d76a.png)'
- en: Photo by [Hitesh Choudhary](https://unsplash.com/@hiteshchoudhary?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Hitesh Choudhary](https://unsplash.com/@hiteshchoudhary?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供的照片，来自 [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Designing and building AI systems is difficult. Unlike traditional software
    where the majority of the costs are in the development process *before* the systems
    are deployed, with AI systems, most of the costs occur *after*. The behavior of
    AI systems is learned, potentially changing from its initial deployment. Machine
    learning models degrade over time without ongoing investment in data and hyperparameter
    tuning. And design decisions directly affect the ability to scale AI systems.
    A core part of this design difficulty is understanding how they change (or don’t
    change!) over time.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 设计和构建 AI 系统非常困难。与传统软件不同，传统软件的大部分成本发生在系统部署*之前*的开发过程中，而 AI 系统的大部分成本发生在*之后*。AI
    系统的行为是通过学习得来的，可能会在初始部署后发生变化。机器学习模型会随着时间的推移而退化，如果没有持续的数据和超参数调整投资。设计决策直接影响 AI 系统的扩展能力。设计难度的核心部分在于理解这些系统如何随时间变化（或不变化！）。
- en: When building AI systems, it can be useful to talk about their “level”, just
    like [SAE has levels for self-driving cars](https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-for-its-%E2%80%9Clevels-of-driving-automation%E2%80%9D-standard-for-self-driving-vehicles).
    Adopting a level system can help organizations plan and prepare for AI systems
    that scale in complexity over time. Levels can provide core breakpoints for how
    different AI systems can behave.  Employing levels – and making trade-offs between
    levels – can help provide a shorthand for differences post-deployment.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 AI 系统时，讨论它们的“层级”可能会很有用，就像[SAE 为自动驾驶汽车定义的层级](https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-for-its-%E2%80%9Clevels-of-driving-automation%E2%80%9D-standard-for-self-driving-vehicles)一样。采用层级系统可以帮助组织规划和准备随时间扩展复杂性的
    AI 系统。层级可以提供不同 AI 系统行为的核心断点。采用层级，并在层级之间进行权衡，可以提供部署后差异的简要描述。
- en: 'It’s critical to understand *what kind* of behavioral changes the system might
    undergo, and to factor that into the design of the system. The leveling framework
    below outlines core differences in how systems will change over time: we can use
    these when both designing a system and operating it. Different components can
    be at different levels; having an intuition of how they are different can help
    inform planning and execution.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 了解系统可能经历的*哪种类型*的行为变化至关重要，并将其纳入系统设计中。以下的层级框架概述了系统随着时间变化的核心差异：我们可以在设计和操作系统时使用这些差异。不同的组件可以处于不同的层级；对这些差异有直观了解可以帮助指导规划和执行。
- en: System complexity is defined by the scope of its (a) inputs, (b) outputs, and
    (c) objectives.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 系统复杂性由其 (a) 输入、(b) 输出 和 (c) 目标的范围定义。
- en: AI Levels
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 层级
- en: In general, there is increasing value as you move up levels, e.g. one goal might
    be to move a system operating at Level 1 to be at Level 2 – but complexity (*and
    cost*) of system build also increases as levels go up. It can make a lot of sense
    to **start** with a novel feature at a “low” level, where the system behavior
    is well understood, and progressively increase the level - as understanding the
    failure cases of the system becomes more difficult as the level increases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，随着层级的提升，价值会逐渐增加。例如，一个目标可能是将一个在 Level 1 上运行的系统提升到 Level 2，但系统构建的复杂性（*以及成本*）也会随着层级的提升而增加。在“低”层级上开始设计一个新功能通常更有意义，因为在这个层级系统的行为比较明确，而逐步提高层级可以帮助理解系统失败的情况，因为随着层级的提高，这些情况会变得更难以理解。
- en: The focus should be on learning about the problem and the solution space. Lower
    levels are more consistent and can be much better avenues to explore possible
    solutions than higher levels, whose cost and variability in performance can be
    large hindrances.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 重点应放在学习问题及其解决空间上。较低级别的系统更为一致，并且可以比更高级别的系统更好地探索可能的解决方案，因为后者的成本和性能变异性可能是巨大的障碍。
- en: Levels of AI Systems provide breakpoints that dramatically affect system cost,
    in a progression as we move from traditional software (*Level 0*) up to fully
    **Intelligent** software (*Level 4*). Systems at Level 4 essentially maintain
    and improve on their own - they require negligible work from in-house development
    teams.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: AI 系统的级别提供了会显著影响系统成本的断点，从传统软件（*级别 0*）到完全**智能**的软件（*级别 4*）。级别 4 的系统基本上可以自我维护和改进
    - 它们几乎不需要内部开发团队的工作。
- en: Moving up a level has trade-offs. For example, moving from Level 1 to Level
    2 reduces ongoing data requirements and customization work, but introduces a self-reinforcing
    bias problem. Choosing to move up a level requires recognizing the new challenges,
    and the actions to take in designing our AI system.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 升级有其权衡。例如，从级别 1 升级到级别 2 可以减少持续的数据需求和定制工作，但会引入自我增强的偏见问题。选择升级需要认识到新的挑战，以及在设计 AI
    系统时需要采取的行动。
- en: There are significant benefits in scalability (*and typically performance/robustness/etc*)
    in moving up levels. We should recognize the benefits, and costs; when we work
    on a project at level *N*, we should consider the work to get to *N+1*. We should
    target the level appropriate for what we are trying to achieve, and recognize
    when an existing AI system needs to be rebuilt to change levels.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 升级到更高的级别可以在可扩展性（*以及通常的性能/鲁棒性/等*）方面带来显著的好处。我们应该认识到这些好处和成本；当我们在级别 *N* 上工作时，我们应该考虑到达
    *N+1* 的工作。我们应该针对我们想要实现的目标选择适当的级别，并识别出现有 AI 系统何时需要重建以改变级别。
- en: 'Level 0: Deterministic'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 级别 0：确定性
- en: '*No required training data, no required testing data*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*不需要训练数据，不需要测试数据*'
- en: Algorithms that involve no learning (e.g. adapting parameters to data) are at
    level zero.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不涉及学习（例如，调整参数以适应数据）的算法处于零级。
- en: The great benefit of level 0 (traditional algorithms in computer science) is
    that they are very reliable and, if you solve the problem, can be shown to be
    the optimal solution. If you can solve a problem at level 0 it’s hard to beat.
    In some respect, all algorithms - even sorting algorithms (like binary search)
    - are "adaptive" to the data. We do not generally consider sorting algorithms
    to be "learning". Learning involves memory - the system changing how it behaves
    in the future, based on what it's learned in the past.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 级别 0（计算机科学中的传统算法）的一个巨大好处是它们非常可靠，并且如果你解决了问题，可以证明它们是最优解。如果你能在级别 0 解决一个问题，那几乎没有办法超越它。从某种程度上说，所有算法
    - 即使是排序算法（如二分查找） - 都是“适应性”的。我们通常不会认为排序算法是“学习”。学习涉及记忆 - 系统根据过去的经验改变其未来的行为。
- en: However, some problems defy a pre-specified algorithmic solution. The downside
    is that for problems that defy human understanding (either once, or in number)
    it can be difficult to perform well (e.g. speech to text, translation, image recognition,
    utterance suggestion, etc.).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些问题无法用预定义的算法解决。缺点是，对于那些超出人类理解范围的问题（无论是一次性还是数量上的），可能很难表现良好（例如，语音转文本、翻译、图像识别、发音建议等）。
- en: '**Examples:**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: '[Luhn Algorithm](https://en.wikipedia.org/wiki/Luhn_algorithm) for credit card
    validation'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Luhn 算法](https://en.wikipedia.org/wiki/Luhn_algorithm)用于信用卡验证'
- en: Regex-based systems (e.g. simple redaction systems for credit card numbers).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于正则表达式的系统（例如，信用卡号码的简单脱敏系统）。
- en: Information retrieval algorithms like TFIDF retrieval or BM25.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息检索算法，如 TFIDF 检索或 BM25。
- en: Dictionary-based spell correction.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于词典的拼写纠正。
- en: '*Note: In some cases, there can be a small number of parameters to tune. For
    example,* [*ElasticSearch provides the ability to modify BM25 parameters*](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25)*.
    We can regard these as tuning parameters, i.e. set and forget. This is a blurry
    line.*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：在某些情况下，可能需要调整少量参数。例如，* [*ElasticSearch 提供修改 BM25 参数的能力*](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25)*。我们可以将这些视为调整参数，即设置并忘记。这是一个模糊的界限。*'
- en: 'Level 1: Learned'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 级别 1：学习型
- en: '*Static training data, static testing data*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*静态训练数据，静态测试数据*'
- en: Systems where you train the model in an offline setting and deploy to production
    with “frozen” weights. There may be an updating cadence to the model (*e.g. adding
    more annotated data*), but the environment the model operates in does not affect
    the model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在离线环境中训练模型并用“冻结”权重部署到生产环境的系统。模型可能会有更新的节奏（*例如添加更多标注数据*），但模型所操作的环境不会影响模型。
- en: The benefit of level 1 is that you can learn and deploy any function at the
    modest cost of some training data. This is a great place to experiment with different
    types of solutions. And, for problems with common elements (*e.g. speech recognition*)
    you can benefit from diminishing marginal costs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第一级的好处在于你可以以一些训练数据的适度成本学习和部署任何功能。这是一个很好的地方来尝试不同类型的解决方案。而且，对于具有共同元素的难题（*例如语音识别*），你可以从递减的边际成本中获益。
- en: 'The downside is that customization to a single use case is linear in their
    number: you need to curate training data for each use case. And that can change
    over time, so you need to continuously add annotations to preserve performance.
    This cost can be hard to bear.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点是对单一用例的定制在数量上是线性的：你需要为每个用例策划训练数据。这可能会随着时间的推移而变化，因此你需要不断添加注释以保持性能。这种成本可能很难承受。
- en: '**Examples:**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: Custom text classification models
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义文本分类模型
- en: Speech to text (acoustic model)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音转文本（声学模型）
- en: 'Level 2: Self-learning'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二级：自学习
- en: '*Dynamic + static training data, static testing data*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*动态+静态训练数据，静态测试数据*'
- en: Systems that use training data generated from the system for the model to improve.
    In some cases, the data generation is independent of the model (*so we expect
    increasing model performance over time as more data is added*); in other cases,
    the model intervening can reinforce model biases and performance can *get worse*
    over time.  To eliminate the chance of reinforcing biases, we need to evaluate
    new models on static (*potentially annotated*) data sets.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自系统生成的训练数据来改善模型的系统。在某些情况下，数据生成独立于模型（*因此我们预期随着更多数据的加入，模型性能会提高*）；在其他情况下，模型的干预可能会加剧模型的偏差，性能可能会*随着时间的推移变差*。为了消除加剧偏差的可能性，我们需要在静态（*可能经过标注的*）数据集上评估新模型。
- en: Level 2 is great because performance seems to improve over time for free. The
    downside is that, left unattended, the system can get worse - it may not be consistent
    in getting better with more data. The other limitation is that some systems at
    level two might have limited capacity to improve as they essentially feed on themselves
    *(generating their own training data*); addressing this bias can be challenging*.*
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 第二级很棒，因为性能似乎会随着时间的推移而免费改善。缺点是，如果不加以监控，系统可能会变得更糟——它可能不会随着数据的增加而始终一致地变得更好。另一个限制是，某些第二级系统可能具有有限的改进能力，因为它们实际上是依靠自身（*生成自己的训练数据*）；解决这种偏差可能具有挑战性。
- en: '**Examples:**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例：**'
- en: Naive spam filters
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素垃圾邮件过滤器
- en: Common speech to text models (language model)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的语音转文本模型（语言模型）
- en: 'Level 3: Autonomous (*or self-correcting*)'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三级：自主（*或自我纠正*）
- en: '*Dynamic training data, dynamic test data*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*动态训练数据，动态测试数据*'
- en: Systems that both *alter* human behavior (e.g. recommend an action and let the
    user opt-in) and *learn* directly from that behavior, including how the systems'
    choice changes the user behavior. Moving from Level 2 to 3 potentially represents
    a big increase in system reliability and total achievable performance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 同时*改变*人类行为（例如推荐一个行动并让用户选择加入）和*直接从这种行为中学习*的系统，包括系统选择如何改变用户行为。从第二级到第三级的转变可能代表了系统可靠性和可实现性能的大幅提升。
- en: 'Level 3 is great because it can consistently get better over time.  However,
    it is more complex: it might require truly staggering amounts of data, or a very
    carefully designed setup, to do better than simpler systems; its ability to adapt
    to the environment also makes it very hard to debug. It is also possible to have
    truly catastrophic feedback loops. For example, a human corrects an email spam
    filter - however, because the human can only ever correct misclassifications that
    the system made, it learns that all its predictions are wrong and inverts its
    own predictions.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 第三级很棒，因为它可以持续随着时间的推移变得更好。然而，它更复杂：它可能需要真正惊人的数据量，或者一个非常精心设计的设置，才能比简单系统表现更好；它适应环境的能力也使得调试非常困难。也可能出现真正灾难性的反馈循环。例如，人类纠正一个电子邮件垃圾邮件过滤器——然而，由于人类只能纠正系统做出的错误分类，它学会了所有预测都是错误的，从而颠倒了自己的预测。
- en: 'Level 4: Intelligent (*or globally optimizing*)'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第四级：智能（*或全球优化*）
- en: '*Dynamic training data, dynamic test data, dynamic goal*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*动态训练数据，动态测试数据，动态目标*'
- en: Systems that both dynamically interact with an environment **and** globally
    optimizes (e.g. towards some set of downstream objectives), e.g. facilitating
    an agent while optimizing for AHT and CST, or optimizing directly for profit.
    For example, an AutoSuggest model that does not optimize for the next click (*current
    approach*) but for the best series of clicks to optimize the conversation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 既与环境动态互动又进行全局优化（例如，朝向一些下游目标），例如，在优化AHT和CST的同时辅助代理，或直接优化利润。例如，一个不优化下一个点击（*当前方法*）而是优化对话的最佳点击序列的AutoSuggest模型。
- en: Level 4 has awesome promise - it is not always obvious how to get there, and
    unless carefully designed, these systems can optimize towards degenerate solutions.
    Aiming them at the right problem, shaping the reward, and auditing its behavior
    are large and non-trivial tasks.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第4级有着极大的潜力——如何达到这一点并不总是显而易见的，除非经过精心设计，这些系统可能会优化到退化的解决方案。将其对准正确的问题、塑造奖励机制以及审计其行为都是庞大且非平凡的任务。
- en: 'Appendix: Matrix Layout'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 附录：矩阵布局
- en: We can visualize the levels as a matrix as well.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将这些级别可视化为一个矩阵。
- en: '| **Level** | **Narrative Definition** | **Inputs** | **Outputs** | **Objectives**
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **级别** | **叙述定义** | **输入** | **输出** | **目标** |'
- en: '| 0: **Deterministic** | Algorithms that involve no *learning* (e.g. no adapting
    parameters to data) are at level zero. | No training data. | General outputs.
    | No objective target. Metrics (for performance). |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 0: **确定性** | 不涉及*学习*（例如，不调整参数以适应数据）的算法处于第零级别。 | 无训练数据。 | 一般输出。 | 无目标。性能指标。
    |'
- en: '| 1: **Learned** | Systems where model training is in an offline setting and
    is deployed to production with “frozen” weights. There may be an updating cadence
    to the model (e.g. adding more annotated data), but the data used to train the
    model is not generated directly by the system. | Static data, often annotated.
    | Simple output (*simple function approximation*) | Single objective, mapping
    from input data to output. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 1: **已学习** | 模型训练在离线环境中进行，并以“冻结”权重部署到生产中。模型可能有更新的频率（例如，添加更多的标注数据），但用于训练模型的数据并非直接由系统生成。
    | 静态数据，通常是标注过的。 | 简单输出（*简单函数逼近*） | 单一目标，从输入数据映射到输出。 |'
- en: '| 2: **Self Improving** | Systems that use training data generated from the
    system for the model to improve, ideally where the data is stationary (*so we
    expect increasing model performance over time as more data is added*). | Retraining
    using new model inputs generated from the system. | Simple output, proximate to
    the input data. | Single objective, mapping from input data to output. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 2: **自我提升** | 使用从系统生成的训练数据来改进模型的系统，理想情况下数据是静态的（*所以我们期望随着数据的增加模型性能会不断提升*）。
    | 使用从系统生成的新模型输入进行重新训练。 | 简单输出，接近输入数据。 | 单一目标，从输入数据映射到输出。 |'
- en: '| 3: **Autonomous** | Systems that both *alter* human behavior and *learn*
    directly from that behavior. Problems in this category often involve bandit learning
    paradigms such as exploration vs. exploitation. | System is retraining using new
    model input and explicit feedback on the system’s previous outputs. | Policy to
    update model outputs over time. | Cumulative objective(s), capturing how the model
    introduces bias and how people interact with the system. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 3: **自主** | 同时*改变*人类行为和*直接从这种行为中学习*的系统。这一类别的问题通常涉及如探索与开发的赌博学习范式。 | 系统使用新的模型输入和对系统先前输出的明确反馈进行重新训练。
    | 政策以随时间更新模型输出。 | 累积目标，捕捉模型如何引入偏差以及人们如何与系统互动。 |'
- en: '| 4: **Intelligent** | Systems that dynamically interact with an environment
    and optimizes itself towards downstream objectives, e.g. facilitating an agent
    while optimizing for AHT and CST. Problems in this category sometimes involve
    reinforcement learning paradigms. | System looks at downstream impact of model
    decisions and optimizes for entire system performance. | Policy to optimize the
    entire system. | System objectives, downstream from local decisions. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 4: **智能** | 与环境动态互动并朝向下游目标自我优化的系统，例如，在优化AHT和CST的同时辅助代理。这一类别的问题有时涉及强化学习范式。
    | 系统查看模型决策的下游影响，并优化整个系统的性能。 | 政策以优化整个系统。 | 系统目标，从局部决策到下游。'
- en: '**[Michael Griffiths](https://www.linkedin.com/in/msjgriffiths/)** is the director
    of data scientist at ASAPP. He works to identify opportunities to improve the
    customer and agent experience. Prior to ASAPP, Michael spent time in advertising,
    ecommerce, and management consulting.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**[迈克尔·格里菲斯](https://www.linkedin.com/in/msjgriffiths/)** 是 ASAPP 的数据科学总监。他致力于识别提升客户和代理体验的机会。在
    ASAPP 之前，迈克尔曾在广告、电商和管理咨询领域工作。'
- en: More On This Topic
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Baidu Research Unveils Top 10 Tech Trends Forecast for 2022](https://www.kdnuggets.com/2022/02/baidu-research-unveils-top-10-tech-trends-forecast-2022.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[百度研究发布2022年十大科技趋势预测](https://www.kdnuggets.com/2022/02/baidu-research-unveils-top-10-tech-trends-forecast-2022.html)'
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用大型语言模型时优化性能和成本的策略…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学项目如何帮助你解决现实世界问题](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
- en: '[Data access is severely lacking in most companies, and 71% believe…](https://www.kdnuggets.com/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大多数公司数据访问严重不足，71% 认为…](https://www.kdnuggets.com/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)'
- en: '[5 Rare Data Science Skills That Can Help You Get Employed](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5项稀有的数据科学技能可以帮助你找到工作](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
- en: '[How Generative AI Can Help You Improve Your Data Visualization Charts](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成式 AI 如何帮助你改进数据可视化图表](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
