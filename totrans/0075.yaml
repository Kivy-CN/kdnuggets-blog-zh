- en: 'Unlocking Reliable Generations through Chain-of-Verification: A Leap in Prompt
    Engineering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Unlocking Reliable Generations through Chain-of-Verification: A Leap in Prompt
    Engineering](../Images/11b3cf522091679f8a691802527fa3de.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Image created by Author with Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Chain-of-Thought (CoVe) prompt engineering method is designed to mitigate
    hallucinations in LLMs, addressing the generation of plausible yet incorrect factual
    information
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through a four-step process, CoVe enables LLMs to draft, verify, and refine
    responses, fostering a self-verifying mechanism that enhances accuracy, Structured
    Self-Verification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoVe has demonstrated improved performance in various tasks such as list-based
    questions and long-form text generation, showcasing its potential in reducing
    hallucinations and bolstering the correctness of AI-generated text
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: We study the ability of language models to deliberate on the responses they
    give in order to correct their mistakes.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The relentless pursuit of accuracy and reliability in the realm of Artificial
    Intelligence (AI) has ushered in groundbreaking techniques in prompt engineering.
    These techniques play a pivotal role in guiding generative models to provide precise
    and meaningful responses to a myriad of queries. The recent advent of the [Chain-of-Verification](https://arxiv.org/abs/2309.11495)
    (CoVe) method marks a significant milestone in this quest. This innovative technique
    aims to tackle a notorious issue in large language models (LLMs) — the generation
    of plausible yet incorrect factual information, colloquially known as hallucinations.
    By enabling models to deliberate on their responses and undergo a self-verifying
    process, CoVe sets a promising precedent in enhancing the reliability of generated
    text.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The burgeoning ecosystem of LLMs, with their capability to process and generate
    text based on vast corpora of documents, has showcased remarkable proficiency
    in various tasks. However, a lingering concern remains—the propensity to generate
    hallucinated information, especially on lesser-known or rare topics. The Chain-of-Verification
    method emerges as a beacon of hope amidst these challenges, offering a structured
    approach to minimize hallucinations and improve the accuracy of generated responses.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Chain-of-Verification
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CoVe unfolds a four-step mechanism to mitigate hallucinations in LLMs:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Drafting an initial response
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Planning verification questions to fact-check the draft
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answering those questions independently to avoid bias
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating a final verified response based on the answers
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This systematic approach not only addresses the concern of hallucinations but
    also encapsulates a self-verifying process that elevates the correctness of the
    generated text. The method's efficacy has been demonstrated across a variety of
    tasks, including list-based questions, closed book QA, and long-form text generation,
    showcasing a decrease in hallucinations and an improvement in performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Chain-of-Verification
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adopting CoVe involves integrating its four-step process in the workflow of
    LLMs. For instance, when tasked with generating a list of historical events, an
    LLM employing CoVe would initially draft a response, plan verification questions
    to fact-check each event, answer those questions independently, and finally, generate
    a verified list based on the validation received.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: The rigorous verification process intrinsic to CoVe ensures a higher degree
    of accuracy and reliability in the generated responses. This disciplined approach
    toward verification not only enriches the quality of information but also fosters
    a culture of accountability within the AI generation process, marking a significant
    stride towards achieving more reliable AI-generated text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 1**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: List notable inventions of the 20th century.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initial Draft**: Internet, Quantum Mechanics, DNA Structure Discovery'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verification Questions**: Was the Internet invented in the 20th century?
    Was Quantum Mechanics developed in the 20th century? Was the structure of DNA
    discovered in the 20th century?'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Final Verified Response**: Internet, Penicillin Discovery, DNA Structure
    Discovery'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example 2**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Provide a list of countries in Africa.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Initial Draft**: Nigeria, Ethiopia, Egypt, South Africa, Sudan'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Verification Questions**: Is Nigeria in Africa? Is Ethiopia in Africa? Is
    Egypt in Africa? Is South Africa in Africa? Is Sudan in Africa?'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Final Verified Response**: Nigeria, Ethiopia, Egypt, South Africa, Sudan'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adopting CoVe involves integrating its four-step process in the workflow of
    LLMs. For instance, when tasked with generating a list of historical events, an
    LLM employing CoVe would initially draft a response, plan verification questions
    to fact-check each event, answer those questions independently, and finally, generate
    a verified list based on the validation received.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 采用 CoVe 涉及将其四步骤过程整合到 LLM 的工作流程中。例如，当任务是生成历史事件列表时，使用 CoVe 的 LLM 将首先起草一个回应，计划验证问题以核实每个事件，独立回答这些问题，最后根据收到的验证生成一个经过验证的列表。
- en: '![Chain-of-Verification process](../Images/c9e5c2de1ce7d2a54e3285c45c0d0aab.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![Chain-of-Verification 过程](../Images/c9e5c2de1ce7d2a54e3285c45c0d0aab.png)'
- en: '**Figure 1**: The Chain-of-Verification simplified process (Image by Author)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**：简化的 Chain-of-Verification 过程（图像来源：作者）'
- en: The methodology would require in-context examples along with the question to
    pose the LLM, or an LLM could be finetuned on CoVe examples in order to approach
    each question in this manner, should it be desired.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法需要上下文示例以及提问 LLM 的问题，或者可以对 LLM 进行 CoVe 示例的微调，以便在这种方式下处理每个问题，如有需要。
- en: Conclusion
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The advent of the Chain-of-Verification method is a testament to the strides
    being made in prompt engineering towards achieving reliable and accurate AI-generated
    text. By addressing the hallucination issue head-on, CoVe offers a robust solution
    that elevates the quality of information generated by LLMs. The method's structured
    approach, coupled with its self-verifying mechanism, embodies a significant leap
    towards fostering a more reliable and factual AI generation process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Chain-of-Verification 方法的出现证明了在提示工程中朝着实现可靠和准确的 AI 生成文本所取得的进展。通过直面幻觉问题，CoVe 提供了一种强有力的解决方案，提升了
    LLM 生成信息的质量。这种方法的结构化方法，加上其自我验证机制，代表了在促进更可靠和真实的 AI 生成过程方面的重要跃进。
- en: The implementation of CoVe is a clarion call for practitioners and researchers
    alike to continue exploring and refining techniques in prompt engineering. Embracing
    such innovative methods will be instrumental in unlocking the full potential of
    Large Language Models, promising a future where the reliability of AI-generated
    text is not just an aspiration, but a reality.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: CoVe 的实施是对从业者和研究人员的号召，继续探索和完善提示工程技术。拥抱这些创新方法将对释放大型语言模型的全部潜力至关重要，预示着一个未来，在这个未来中，AI
    生成文本的可靠性不仅是一个愿景，而是一个现实。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为 [KDnuggets](https://www.kdnuggets.com/)
    和 [Statology](https://www.statology.org/) 的主编，以及 [Machine Learning Mastery](https://machinelearningmastery.com/)
    的特约编辑，Matthew 旨在使复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、语言模型、机器学习算法以及探索新兴的人工智能。他致力于使数据科学社区的知识民主化。Matthew
    从6岁起就开始编程。'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Ensuring Reliable Few-Shot Prompt Selection for LLMs](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[确保 LLM 的可靠少样本提示选择](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
- en: '[Unlocking GPT-4 Summarization with Chain of Density Prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过密度提示解锁 GPT-4 摘要](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
- en: '[Automating the Chain of Thought: How AI Can Prompt Itself to Reason](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动化思维链：人工智能如何自我提示进行推理](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
- en: '[Unveiling Midjourney 5.2: A Leap Forward in AI Image Generation](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开 Midjourney 5.2 的面纱：AI 图像生成的跃进](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
- en: '[Unveiling the Power of Meta''s Llama 2: A Leap Forward in Generative AI?](https://www.kdnuggets.com/2023/07/unveiling-power-metas-llama-2-leap-forward-generative-ai.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 Meta 的 Llama 2 的力量：生成式 AI 的跃进？](https://www.kdnuggets.com/2023/07/unveiling-power-metas-llama-2-leap-forward-generative-ai.html)'
- en: '[Design effective & reliable machine learning systems!](https://www.kdnuggets.com/2023/05/manning-design-effective-reliable-machine-learning-systems.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[设计有效且可靠的机器学习系统！](https://www.kdnuggets.com/2023/05/manning-design-effective-reliable-machine-learning-systems.html)'
