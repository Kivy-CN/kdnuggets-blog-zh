- en: Generate Realistic Human Face using GAN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GAN生成逼真的人脸
- en: 原文：[https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html](https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html](https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html)
- en: '[comments](#comments)![Figure](../Images/c66cd91eb1e8a0a144f7300a8bfddc33.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图像](../Images/c66cd91eb1e8a0a144f7300a8bfddc33.png)'
- en: '[Credits](https://www.outerplaces.com/science/item/19172-artificial-intelligence-faces-gan)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[致谢](https://www.outerplaces.com/science/item/19172-artificial-intelligence-faces-gan)'
- en: '* * *'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The coolest idea in deep learning in the last 20 years.” — [Yann LeCun on GANs.](https://www.linkedin.com/in/yann-lecun-0b999/)
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “过去20年中深度学习中最酷的想法。” — [Yann LeCun谈GAN](https://www.linkedin.com/in/yann-lecun-0b999/)
- en: We heard the news on [**Artistic Style Transfer**](https://techcrunch.com/tag/style-transfer/) and [**face-swapping
    applications **](https://beebom.com/best-face-swap-apps/) (aka [deepfakes](https://techcrunch.com/tag/deepfakes/)), **Natural
    Voice Generation **([Google Duplex](https://www.youtube.com/watch?v=D5VN56jQMWM)), [**Music
    Synthesis**](https://openai.com/blog/musenet/), [**smart reply**](https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/), [**smart
    compose**](https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html)**,
    etc.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们听说了关于[**艺术风格迁移**](https://techcrunch.com/tag/style-transfer/)和[**面部交换应用**](https://beebom.com/best-face-swap-apps/)（也称为[深伪技术](https://techcrunch.com/tag/deepfakes/)）、**自然语言生成**（[Google
    Duplex](https://www.youtube.com/watch?v=D5VN56jQMWM)）、[**音乐合成**](https://openai.com/blog/musenet/)、[**智能回复**](https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/)、[**智能写作**](https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html)**等。**
- en: The technology behind these kinds of AI is called a **GAN**, or **“Generative
    Adversarial Network”.** A GAN takes a different approach to learning than other
    types of neural networks. GANs algorithmic architectures that use two neural networks
    called a **Generator** and a **Discriminator**, which “compete” against one another
    to create the desired result. The Generator’s job is to create realistic-looking
    fake images, while the Discriminator’s job is to distinguish between real images
    and fake images. If both are functioning at high levels, the result is images
    that are seemingly identical real-life photos.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的人工智能背后的技术叫做**GAN**，或**“生成对抗网络”**。GAN采用了不同于其他神经网络的学习方法。GAN的算法架构使用两个神经网络，一个是**生成器**，另一个是**鉴别器**，它们相互“竞争”以创建期望的结果。生成器的任务是创建逼真的假图像，而鉴别器的任务是区分真实图像和假图像。如果两者都能高效运行，结果就是看起来几乎和真实照片一模一样的图像。
- en: Generative Adversarial Networks have had a huge success since they were introduced
    in 2014 by Ian J. Goodfellow and co-authors in the article [Generative Adversarial
    Nets](https://arxiv.org/abs/1406.2661).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自从2014年由Ian J. Goodfellow及其合著者在文章[《生成对抗网络》](https://arxiv.org/abs/1406.2661)中介绍了生成对抗网络以来，这一技术取得了巨大的成功。
- en: Why were GANs developed in the first place?
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GAN最初为什么会被开发出来？
- en: It has been noticed most of the mainstream neural nets can be easily fooled
    into misclassifying things by adding only a small amount of noise into the original
    data. Surprisingly, the model after adding noise has higher confidence in the
    wrong prediction than when it predicted correctly. The reason for such an adversary
    is that most machine learning models learn from a limited amount of data, which
    is a huge drawback, as it is prone to overfitting. Also, the mapping between the
    input and the output is almost linear. Although it may seem that the boundaries
    of separation between the various classes are linear, in reality, they are composed
    of linearities and even a small change in a point in the feature space might lead
    to misclassification of data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 已经注意到，大多数主流神经网络很容易被欺骗，只需在原始数据中添加少量噪声。令人惊讶的是，添加噪声后的模型对错误预测的信心比正确预测时更高。这种对抗的原因在于，大多数机器学习模型从有限的数据中学习，这是一个巨大的缺陷，因为它容易过拟合。此外，输入和输出之间的映射几乎是线性的。虽然看起来各种类别之间的分界线是线性的，但实际上，它们由线性组成，即使特征空间中的一点小变化也可能导致数据的错误分类。
- en: '![Figure](../Images/a0bda5e3a7d448a715b36064627855bc.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/a0bda5e3a7d448a715b36064627855bc.png)'
- en: '[Credits](https://github.com/Puzer/stylegan-encoder/issues/1)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[参考](https://github.com/Puzer/stylegan-encoder/issues/1)'
- en: How does GANs work?
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GAN是如何工作的？
- en: GANs learn a probability distribution of a dataset by pitting two neural networks
    against each other.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GAN通过将两个神经网络对抗起来来学习数据集的概率分布。
- en: One neural network, called the **Generator**, generates new data instances,
    while the other, the **Discriminator**, evaluates them for authenticity; i.e.
    the discriminator decides whether each instance of data that it reviews belongs
    to the actual training dataset or not.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个神经网络，称为**生成器**，生成新的数据实例，而另一个，称为**判别器**，评估这些实例的真实性；即判别器决定它审查的每个数据实例是否属于实际的训练数据集。
- en: Meanwhile, the generator is creating new, synthetic/fake images that it passes
    to the discriminator. It does so in the hopes that they, too, will be deemed authentic,
    even though they are fake. The fake image is generated from a 100-dimensional
    noise (uniform distribution between -1.0 to 1.0) using the inverse of convolution,
    called transposed convolution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，生成器正在创建新的合成/假图像，并将其传递给判别器。它这样做是希望这些图像也能被认为是真实的，即使它们是假的。假图像是通过逆卷积生成的，称为转置卷积，来自一个100维的噪声（-1.0到1.0之间的均匀分布）。
- en: 'The goal of the generator is to **generate** passable images: to lie without
    being caught. The goal of the **discriminator** is to identify images coming from
    the generator as fake.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的目标是**生成**可通过的图像：即在不被抓住的情况下进行欺骗。判别器的目标是识别来自生成器的图像为假图像。
- en: 'Here are the steps a GAN takes:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是GAN的步骤：
- en: The generator takes in random numbers and returns an image.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器接收随机数字并返回图像。
- en: This generated image is fed into the discriminator alongside a stream of images
    taken from the actual, ground-truth dataset.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个生成的图像会与从实际的真实数据集中提取的一系列图像一起输入到判别器中。
- en: The discriminator takes in both real and fake images and returns probabilities,
    a number between 0 and 1, with 1 representing a prediction of authenticity and
    0 representing fake.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器接收真实和假图像，并返回概率值，一个介于0和1之间的数字，其中1表示对真实性的预测，0表示假图像。
- en: 'So you have a double feedback loop:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你有一个双重反馈循环：
- en: The discriminator is in a feedback loop with the ground truth of the images,
    which we know.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器与我们已知的图像的真实数据处于反馈循环中。
- en: The generator is in a feedback loop with the discriminator.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器与判别器处于反馈循环中。
- en: '![Figure](../Images/36942c0052f4f1ea690517fca98283d1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/36942c0052f4f1ea690517fca98283d1.png)'
- en: '[Credits](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[参考](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
- en: The math behind the GANs
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GAN的数学原理
- en: Let’s dig a little deeper and understand how it works mathematically. Discriminator’s
    job is to perform Binary Classification to detect between Real and Fake so its
    loss function is Binary Cross Entropy. What Generator does is Density Estimation,
    from the noise to real data, and feed it to Discriminator to fool it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解它是如何在数学上工作的。判别器的工作是执行二元分类，以检测真实和虚假的图像，因此其损失函数是二元交叉熵。生成器的工作是密度估计，从噪声到真实数据，并将其输入判别器以欺骗它。
- en: 'The approach followed in the design is to model it as a [**MiniMax game**](https://brilliant.org/wiki/minimax/).
    Now let’s have a look at cost functions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 设计中遵循的方法是将其建模为一个[**MiniMax博弈**](https://brilliant.org/wiki/minimax/)。现在让我们来看一下成本函数：
- en: '![](../Images/a8c31e39ff2c453cd231791c6ccab6ca.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8c31e39ff2c453cd231791c6ccab6ca.png)'
- en: The first term in `J(D)` represents feeding the actual data to the discriminator,
    and the discriminator would want to maximize the log probability of predicting
    one, indicating that the data is real. The second term represents the samples
    generated by `G`. Here, the discriminator would want to maximize the log probability
    of predicting zero, indicating the data is fake. The generator, on the other hand,
    tries to minimize the log probability of the discriminator being correct. The
    solution to this problem is an equilibrium point of the game, which is a saddle
    point of the discriminator loss.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`J(D)`中的第一个项表示将实际数据输入给判别器，判别器希望最大化预测为1的对数概率，表示数据是真实的。第二项表示由`G`生成的样本。在这里，判别器希望最大化预测为0的对数概率，表示数据是假的。另一方面，生成器则尝试最小化判别器正确的对数概率。这个问题的解决方案是博弈的均衡点，即判别器损失的鞍点。'
- en: '**Objective Function**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标函数**'
- en: '![Figure](../Images/2a6524e8ec4c450a0cd45e4e61f4e98f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/2a6524e8ec4c450a0cd45e4e61f4e98f.png)'
- en: '[Credits](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
- en: '**Architecture of GANs**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**GANs的架构**'
- en: '`D()` gives us the probability that the given sample is from training data
    X. For the Generator, we want to minimize `log(1-D(G(z))` i.e. when the value `D(G(z))` is
    high then `D` will assume that `G(z)` is nothing but X and this makes `1-D(G(z))` very
    low and we want to minimize it which this even lower. For the Discriminator, we
    want to maximize `D(X)` and `(1-D(G(z)))`. So the optimal state of D will be `P(x)=0.5`.
    However, we want to train the generator G such that it will produce the results
    for the discriminator D so that D won’t be able to distinguish between z and X.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`D()` 给出给定样本来自训练数据X的概率。对于生成器，我们希望最小化`log(1-D(G(z)))`，即当`D(G(z))`的值很高时，`D`将假设`G(z)`不过是X，这使得`1-D(G(z))`非常低，我们希望最小化它，从而使其更低。对于判别器，我们希望最大化`D(X)`和`(1-D(G(z)))`。所以D的最优状态将是`P(x)=0.5`。然而，我们希望训练生成器G，使其生成的结果能让判别器D无法区分z和X。'
- en: Now the question is why this is a minimax function? It is because the Discriminator
    tries to maximize the objective while the Generator tries to minimize it, due
    to this minimizing/maximizing we get the minimax term. They both learn together
    by alternating gradient descent.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题是为什么这是一个最小最大函数？这是因为判别器尝试最大化目标，而生成器尝试最小化目标，因此我们得到最小最大项。它们通过交替梯度下降一起学习。
- en: While the idea of GAN is simple in theory, it is very difficult to build a model
    that works. In GAN, there are two deep networks coupled together making backpropagation
    of gradients twice as challenging.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管理论上的GAN概念很简单，但构建一个有效的模型是非常困难的。在GAN中，有两个深度网络相互耦合，使得梯度的反向传播变得难度加倍。
- en: '[Deep Convolutional GAN (DCGAN)](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0) is
    one of the models that demonstrated how to build a practical GAN that can learn
    by itself how to synthesize new images. DCGAN is very similar to *GAN*s but specifically
    focuses on using deep convolutional networks in place of fully-connected networks
    used in Vanilla *GAN*s.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[深度卷积GAN（DCGAN）](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0)是展示如何构建一个可以自学合成新图像的实际GAN模型之一。DCGAN与*GAN*s非常相似，但特别专注于使用深度卷积网络来代替在Vanilla
    *GAN*s中使用的全连接网络。'
- en: Convolutional networks help in finding deep correlation within an image, that
    is they look for spatial correlation. This means DCGAN would be a better option
    for image/video data, whereas *GAN*s can be considered as a general idea on which [DCGAN](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0) and
    many other architectures *(CGAN, CycleGAN, StarGAN and many others)* have been
    developed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络有助于发现图像中的深层关联，即它们寻找空间相关性。这意味着DCGAN将是图像/视频数据的更好选择，而*GAN*s可以被视为[DCGAN](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0)及许多其他架构（*CGAN、CycleGAN、StarGAN等*）开发的基础性想法。
- en: Dataset
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集
- en: This dataset is great for training and testing models for face detection, particularly
    for recognizing facial attributes such as finding people with brown hair, are
    smiling, or wearing glasses. Images cover large pose variations, background clutter,
    diverse people, supported by a large number of images and rich annotations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集非常适合用于训练和测试人脸检测模型，特别是识别面部特征，例如找出棕色头发、正在微笑或戴眼镜的人。图像涵盖了大范围的姿势变化、背景杂乱、多样的人群，并且支持大量的图像和丰富的注释。
- en: The dataset can be downloaded from [Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset).
    Our objective is to create a model capable of generating realistic **human** **images
    that do not exist in reality.**
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从[Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset)下载。我们的目标是创建一个能够生成现实中不存在的**真实**
    **人类**图像的模型。
- en: You heard it right!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你没听错！
- en: '**Let us load the dataset and see how the input images look like:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**让我们加载数据集，看看输入图像的样子：**'
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Figure](../Images/2b3cc85ace939295de193e1dd161b6cd.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2b3cc85ace939295de193e1dd161b6cd.png)'
- en: Input images
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像
- en: '**Next step is to create a Generator:**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**下一步是创建生成器：**'
- en: 'The generator goes the other way: It is the artist who is trying to fool the
    discriminator. This network consists of 8 convolutional layers. Here first, we
    take our input, called `gen_input` and feed it into our first convolutional layer.
    Each convolutional layer performs a convolution and then performs batch normalization
    and a leaky ReLu as well. Then, we return the tanh activation function.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的作用正好相反：它是试图欺骗判别器的艺术家。这个网络由8个卷积层组成。这里首先，我们将输入（称为`gen_input`）送入第一个卷积层。每个卷积层执行卷积操作，然后进行批量归一化和泄漏ReLU处理。最后，我们返回tanh激活函数。
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Next, create a Discriminator:**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**接下来，创建判别器：**'
- en: The discriminator network consists of convolutional layers the same as the generator.
    For every layer of the network, we are going to perform a convolution, then we
    are going to perform batch normalization to make the network faster and more accurate
    and finally, we are going to perform a Leaky ReLu.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器网络由与生成器相同的卷积层组成。对于网络的每一层，我们将执行卷积操作，然后进行批量归一化以加快网络速度和提高准确性，最后执行Leaky ReLU。
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Define a GAN Model:**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义一个GAN模型：**'
- en: Next, a GAN model can be defined that combines both the generator model and
    the discriminator model into one larger model. This larger model will be used
    to train the model weights in the generator, using the output and error calculated
    by the discriminator model. The discriminator model is trained separately, and
    as such, the model weights are marked as not trainable in this larger GAN model
    to ensure that only the weights of the generator model are updated. This change
    to the trainability of the discriminator weights only affects when training the
    combined GAN model, not when training the discriminator standalone.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，可以定义一个结合生成器模型和判别器模型的大型GAN模型。这个较大的模型将用于训练生成器中的模型权重，使用判别器模型计算的输出和误差。判别器模型单独训练，因此在这个较大的GAN模型中，模型权重标记为不可训练，以确保只有生成器模型的权重被更新。这个对判别器权重训练性的更改仅在训练组合GAN模型时生效，不在训练判别器模型时生效。
- en: This larger GAN model takes as input a point in the latent space, uses the generator
    model to generate an image, which is fed as input to the discriminator model,
    then output or classified as real or fake.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这个较大的GAN模型以潜在空间中的一个点作为输入，使用生成器模型生成图像，然后将其作为输入送入判别器模型，最后输出或分类为真实或伪造。
- en: Since the output of the Discriminator is sigmoid, we use [**binary cross-entropy**](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a) for
    the loss. [**RMSProp**](https://keras.io/optimizers/) as an optimizer generates
    more realistic fake images compared to [**Adam**](https://keras.io/optimizers/) for
    this case. The learning rate is 0.0001\. Weight decay and clip value stabilize
    learning during the latter part of the training. You have to adjust the decay
    if you want to adjust the learning rate.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于判别器的输出是sigmoid函数，我们使用[**二元交叉熵**](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a)作为损失函数。[**RMSProp**](https://keras.io/optimizers/)作为优化器在本案例中生成更逼真的伪造图像，相比之下[**Adam**](https://keras.io/optimizers/)效果稍差。学习率为0.0001。权重衰减和裁剪值在训练后期稳定学习。如果你想调整学习率，需要调整衰减值。
- en: GANs try to replicate a probability distribution. Therefore, we should use loss
    functions that reflect the distance between the distribution of the data generated
    by the GAN and the distribution of the real data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GAN试图复制概率分布。因此，我们应该使用能够反映GAN生成的数据分布与真实数据分布之间距离的损失函数。
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Rather than just having a single loss function, we need to define three: The
    loss of the generator, the loss of the discriminator when using real images and
    the loss of the discriminator when using fake images. The sum of the fake image
    and real image loss is the overall discriminator loss.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅需要一个损失函数，而是需要定义三个：生成器的损失，使用真实图像时鉴别器的损失，以及使用虚假图像时鉴别器的损失。虚假图像和真实图像损失的总和即为总体鉴别器损失。
- en: '**Training the GAN model:**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练GAN模型：**'
- en: 'Training is the hardest part and since a GAN contains two separately trained
    networks, its training algorithm must address two complications:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是最困难的部分，由于GAN包含两个分别训练的网络，它的训练算法必须解决两个复杂问题：
- en: GANs must juggle two different kinds of training (generator and discriminator).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN必须兼顾两种不同的训练（生成器和鉴别器）。
- en: GAN convergence is hard to identify.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN的收敛性难以识别。
- en: As the generator improves with training, the discriminator performance gets
    worse because the discriminator can’t easily tell the difference between real
    and fake. If the generator succeeds perfectly, then the discriminator has a 50%
    accuracy. In effect, the discriminator flips a coin to make its prediction.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成器的训练进步，鉴别器的性能会变差，因为鉴别器无法轻易区分真实和虚假。如果生成器成功完美，则鉴别器的准确率为50%。实际上，鉴别器像掷硬币一样做出预测。
- en: 'This progression poses a problem for convergence of the GAN as a whole: the
    discriminator feedback gets less meaningful over time. If the GAN continues training
    past the point when the discriminator is giving completely random feedback, then
    the generator starts to train on junk feedback, and its quality may collapse.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种进展给整个GAN的收敛性带来了问题：随着时间的推移，鉴别器的反馈变得越来越没有意义。如果GAN继续训练到鉴别器提供完全随机反馈的地步，那么生成器开始在垃圾反馈上训练，其质量可能会崩溃。
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let us also make the GIF of the output images that have been generated.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要生成输出图像的GIF。
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Output
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 输出
- en: You can get the code in my GitHub repo.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我的GitHub仓库中获取代码。
- en: '**[nageshsinghc4/Face-generation-GAN](https://github.com/nageshsinghc4/Face-generation-GAN)**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**[nageshsinghc4/Face-generation-GAN](https://github.com/nageshsinghc4/Face-generation-GAN)**'
- en: We just saw how a model can generate almost a human-like face if trained sufficiently.
    Due to computation constraints, I have trained the model for 15000 epochs. You
    can try with more epochs to get even better results.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到，如果训练充分，一个模型可以生成几乎像人类一样的面孔。由于计算限制，我已将模型训练了15000个周期。你可以尝试更多的周期以获得更好的结果。
- en: '**“GANs are Dangerous”**'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“GANs是危险的”**'
- en: As time goes on, these algorithms that exist all around us get better and better
    at what they do, meaning these generative models will likely get better at generating
    imitative objects. It is highly likely that another groundbreaking generative
    model is just on the horizon.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，这些存在于我们周围的算法在其工作上会越来越好，这意味着这些生成模型可能会在生成模仿对象方面变得更好。另一个突破性的生成模型很可能就在前方。
- en: This technology can be used for many good things. However, the potential for
    bad is there as well. Recall the 2016 election and many subsequent international
    elections, where false news articles flooded almost all social media platforms.
    Imagine the impact these articles would have had if they had contained accompanying
    “false images” and “false audio”. Propaganda would likely spread far more easily
    in such a world. Essentially, these new generative models, **with enough time
    and data, they can generate very convincing samples from almost *any* distribution.**
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术可以用于许多有益的事情。然而，也存在不良的潜力。回想2016年的选举以及随后的许多国际选举，当时虚假新闻文章充斥几乎所有社交媒体平台。想象一下，如果这些文章还包含了伴随的“虚假图像”和“虚假音频”，其影响会有多大。宣传在这样的世界中可能传播得更快。实质上，这些新的生成模型，**只要有足够的时间和数据，它们可以从几乎*任何*分布中生成非常可信的样本。**
- en: You can go to[ thispersondoesnotexist.com](https://thispersondoesnotexist.com/) and
    can feel the power of GAN models, every time you refresh the website you will
    see a different human figure which doesn't even exist and has been generated via
    GAN. It's truly fascinating.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以访问[ thispersondoesnotexist.com](https://thispersondoesnotexist.com/)，体验GAN模型的强大，每次刷新网站时你都会看到一个不同的人物，这些人物甚至并不存在，而是通过GAN生成的。这确实很令人着迷。
- en: 'Conclusion: The Future of GANs'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论：GAN的未来
- en: Unsupervised learning is [the next frontier](https://www.cs.cornell.edu/content/unsupervised-learning-next-frontier-ai) in
    artificial intelligence and we are moving towards it.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是[人工智能的下一个前沿](https://www.cs.cornell.edu/content/unsupervised-learning-next-frontier-ai)，我们正朝着这个方向发展。
- en: GANs and generative models general are very fun and perplexing. They encapsulate
    another step towards a world where we depend more and more on artificial intelligence.
    GANs have a huge number of applications in cases such as ***Generating examples
    for Image Datasets, Generating Realistic Photographs, Image-to-Image Translation,
    Text-to-Image Translation, Semantic-Image-to-Photo Translation, Face Frontal View
    Generation, Generate New Human Poses, Face Aging, Video Prediction, 3D Object
    Generation, etc.***
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: GAN和生成模型通常非常有趣且令人困惑。它们代表了朝着一个越来越依赖人工智能的世界迈出的另一大步。GAN在以下情况中有广泛的应用，如***生成图像数据集的示例、生成真实照片、图像到图像的翻译、文本到图像的翻译、语义图像到照片的翻译、面部正面视图生成、生成新的人体姿势、面部衰老、视频预测、3D对象生成等。***
- en: Well, this concludes this article on GANs where we have discussed this cool
    domain of AI and how it is practically implemented. I hope you guys have enjoyed
    reading it, feel free to share your comments/thoughts/feedback in the comment
    section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这篇关于GAN的文章到此为止，我们讨论了这一酷炫的AI领域及其实际应用。希望大家喜欢阅读，欢迎在评论区分享你的评论/想法/反馈。
- en: '**Thanks for reading this article!!!**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢阅读本文！！！**'
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[纳格什·辛格·乔汉](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是CirrusLabs的大数据开发人员。他在电信、分析、销售、数据科学等多个领域拥有超过4年的工作经验，并专注于各种大数据组件。'
- en: '[Original](https://towardsdatascience.com/generate-realistic-human-face-using-gan-e6136876e67c).
    Reposted with permission.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/generate-realistic-human-face-using-gan-e6136876e67c)。转载经许可。'
- en: '**Related:**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Intro to Adversarial Machine Learning and Generative Adversarial Networks](/2019/10/adversarial-machine-learning-generative-adversarial-networks.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对抗性机器学习和生成对抗网络简介](/2019/10/adversarial-machine-learning-generative-adversarial-networks.html)'
- en: '[Recreating Fingerprints using Convolutional Autoencoders](/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积自编码器重建指纹](/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html)'
- en: '[Semi-supervised learning with Generative Adversarial Networks](/2020/01/semi-supervised-learning-generative-adversarial-networks.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成对抗网络的半监督学习](/2020/01/semi-supervised-learning-generative-adversarial-networks.html)'
- en: More On This Topic
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[3 Ways to Generate Hyper-Realistic Faces Using Stable Diffusion](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用稳定扩散生成超现实面孔的3种方法](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无监督解缠表示学习（类别不平衡数据集中的弹性Infogan）](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[虚假至真：生成真实的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
- en: '[4 Ways to Generate Passive Income Using ChatGPT](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用ChatGPT生成被动收入的4种方式](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
- en: '[Generate Music From Text Using Google MusicLM](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Google MusicLM从文本生成音乐](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
- en: '[How to Generate Synthetic Tabular Dataset](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何生成合成表格数据集](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
