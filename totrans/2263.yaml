- en: A Comprehensive Guide to Convolutional Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Artificial Intelligence](https://saturncloud.io/glossary/artificial-intelligence/) has
    been witnessing monumental growth in bridging the gap between the capabilities
    of humans and machines. Researchers and enthusiasts alike, work on numerous aspects
    of the field to make amazing things happen. One of many such areas is the domain
    of [Computer Vision](https://saturncloud.io/glossary/computer-vision).'
  prefs: []
  type: TYPE_NORMAL
- en: The agenda for this field is to enable machines to view the world as humans
    do, perceive it in a similar manner, and even use the knowledge for a multitude
    of tasks such as Image & Video recognition, Image Analysis & Classification, Media
    Recreation, Recommendation Systems, [Natural Language Processing](https://saturncloud.io/glossary/natural-language-processing-nlp/),
    etc. The advancements in [Computer Vision](https://saturncloud.io/glossary/computer-vision/) with [Deep
    Learning](https://saturncloud.io/glossary/deep-learning/) have been constructed
    and perfected with time, primarily over one particular [algorithm](https://saturncloud.io/glossary/algorithm) —
    a **Convolutional Neural Network**.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/6c3e53a0b1e8c71f5964729635e036d3.png)'
  prefs: []
  type: TYPE_IMG
- en: A CNN sequence to classify handwritten digits
  prefs: []
  type: TYPE_NORMAL
- en: A **Convolutional Neural Network (ConvNet/CNN)** is a [Deep Learning](https://saturncloud.io/glossary/deep-learning) algorithm
    that can take in an input image, assign importance (learnable weights and biases)
    to various aspects/objects in the image, and be able to differentiate one from
    the other. The pre-processing required in a ConvNet is much lower as compared
    to other classification algorithms. While in primitive methods filters are hand-engineered,
    with enough training, ConvNets have the ability to learn these filters/characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of a ConvNet is analogous to that of the connectivity pattern
    of Neurons in the Human Brain and was inspired by the organization of the Visual
    Cortex. Individual neurons respond to stimuli only in a restricted region of the
    visual field known as the Receptive Field. A collection of such fields overlap
    to cover the entire visual area.
  prefs: []
  type: TYPE_NORMAL
- en: Why ConvNets over Feed-Forward Neural Nets?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/b5e9e919d3baca94fdd076a5ad5d6195.png)'
  prefs: []
  type: TYPE_IMG
- en: Flattening of a 3x3 image matrix into a 9x1 vector
  prefs: []
  type: TYPE_NORMAL
- en: An image is nothing but a matrix of pixel values, right? So why not just flatten
    the image (e.g. 3x3 image matrix into a 9x1 vector) and feed it to a Multi-Level [Perceptron](https://saturncloud.io/glossary/perceptron) for
    classification purposes? Uh.. not really.
  prefs: []
  type: TYPE_NORMAL
- en: In cases of extremely basic binary images, the method might show an average [precision](https://saturncloud.io/glossary/precision) score
    while performing prediction of classes but would have little to no accuracy when
    it comes to complex images having pixel dependencies throughout.
  prefs: []
  type: TYPE_NORMAL
- en: A ConvNet is able to **successfully capture the Spatial and Temporal dependencies** in
    an image through the application of relevant filters. The architecture performs
    a better fitting to the image dataset due to the reduction in the number of parameters
    involved and the reusability of weights. In other words, the network can be trained
    to understand the sophistication of the image better.
  prefs: []
  type: TYPE_NORMAL
- en: Input Image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/7ed1ca092a9f77e56a2d865497452d1b.png)'
  prefs: []
  type: TYPE_IMG
- en: 4x4x3 RGB Image
  prefs: []
  type: TYPE_NORMAL
- en: In the figure, we have an RGB image that has been separated by its three color
    planes — Red, Green, and Blue. There are a number of such color spaces in which
    images exist — Grayscale, RGB, HSV, CMYK, etc.
  prefs: []
  type: TYPE_NORMAL
- en: You can imagine how computationally intensive things would get once the images
    reach dimensions, say 8K (7680×4320). The role of ConvNet is to reduce the images
    into a form that is easier to process, without losing features that are critical
    for getting a good prediction. This is important when we are to design an architecture
    that is not only good at learning features but also scalable to massive datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Convolution Layer — The Kernel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/485b4c8ce8f612cfd67196203cdc04be.png)'
  prefs: []
  type: TYPE_IMG
- en: Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature
  prefs: []
  type: TYPE_NORMAL
- en: Image Dimensions = 5 (Height) x 5 (Breadth) x 1 (Number of channels, eg. RGB)
  prefs: []
  type: TYPE_NORMAL
- en: In the above demonstration, the green section resembles our **5x5x1 input image,
    I**. The element involved in the convolution operation in the first part of a
    Convolutional Layer is called the **Kernel/Filter, K**, represented in color yellow.
    We have selected **K as a 3x3x1 matrix.**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Kernel shifts 9 times because of **Stride Length = 1 (Non-Strided)**, every
    time performing an **elementwise** **multiplication operation ([Hadamard Product](https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29#:~:text=In%20mathematics%2C%20the%20Hadamard%20product,elements%20i%2C%20j%20of%20the))
    between K and the portion P of the image** over which the kernel is hovering.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/5bcc8d31581243408fe4807d14d41171.png)'
  prefs: []
  type: TYPE_IMG
- en: Movement of the Kernel
  prefs: []
  type: TYPE_NORMAL
- en: The filter moves to the right with a certain Stride Value till it parses the
    complete width. Moving on, it hops down to the beginning (left) of the image with
    the same Stride Value and repeats the process until the entire image is traversed.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/5a4a214e679921ebf1b3a0c71136b38c.png)'
  prefs: []
  type: TYPE_IMG
- en: Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel
  prefs: []
  type: TYPE_NORMAL
- en: In the case of images with multiple channels (e.g. RGB), the Kernel has the
    same depth as that of the input image. Matrix Multiplication is performed between
    Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed
    with the bias to give us a squashed one-depth channel Convoluted Feature Output.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/78ec4701f2bf7c3b122ac76e569c04ff.png)'
  prefs: []
  type: TYPE_IMG
- en: Convolution Operation with Stride Length = 2
  prefs: []
  type: TYPE_NORMAL
- en: The objective of the Convolution Operation is to **extract the high-level features** such
    as edges, from the input image. ConvNets need not be limited to only one Convolutional
    Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level
    features such as edges, color, gradient orientation, etc. With added layers, the
    architecture adapts to the High-Level features as well, giving us a network that
    has a wholesome understanding of images in the dataset, similar to how we would.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of results to the operation — one in which the convolved
    feature is reduced in dimensionality as compared to the input, and the other in
    which the dimensionality is either increased or remains the same. This is done
    by applying **Valid Padding** in the case of the former, or **Same Padding** in
    the case of the latter.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/783dd304339da33464092f06b02b1620.png)'
  prefs: []
  type: TYPE_IMG
- en: When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1
    kernel over it, we find that the convolved matrix turns out to be of dimensions
    5x5x1\. Hence the name — **Same Padding**.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if we perform the same operation without padding, we are
    presented with a matrix that has dimensions of the Kernel (3x3x1) itself — **Valid
    Padding**.
  prefs: []
  type: TYPE_NORMAL
- en: The following repository houses many such GIFs which would help you get a better
    understanding of how Padding and Stride Length work together to achieve results
    relevant to our needs.
  prefs: []
  type: TYPE_NORMAL
- en: '[**vdumoulin/conv_arithmetic**'
  prefs: []
  type: TYPE_NORMAL
- en: A technical report on convolution arithmetic in the context of deep learning
    - vdumoulin/conv_arithmeticgithub.com](https://github.com/vdumoulin/conv_arithmetic)
  prefs: []
  type: TYPE_NORMAL
- en: Pooling Layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/6e6b343ded97d184ff5caabfc332274a.png)'
  prefs: []
  type: TYPE_IMG
- en: Similar to the Convolutional Layer, the Pooling layer is responsible for reducing
    the spatial size of the Convolved Feature. This is to **decrease the computational
    power required to process the data** through [dimensionality reduction](https://saturncloud.io/glossary/dimensionality-reduction).
    Furthermore, it is useful for **extracting dominant features** which are rotational
    and positional invariant, thus maintaining the process of effectively training
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of Pooling: [Max Pooling](https://saturncloud.io/glossary/max-pooling) and
    Average Pooling. **Max Pooling** returns the **maximum value** from the portion
    of the image covered by the Kernel. On the other hand, **Average Pooling** returns
    the **average of all the values** from the portion of the image covered by the
    Kernel.
  prefs: []
  type: TYPE_NORMAL
- en: Max Pooling also performs as a **Noise Suppressant**. It discards the noisy
    activations altogether and also performs de-noising along with dimensionality
    reduction. On the other hand, Average Pooling simply performs dimensionality reduction
    as a noise-suppressing mechanism. Hence, we can say that **Max Pooling performs
    a lot better than Average Pooling**.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/b1198726781dbb61c45ebd6bea03a031.png)'
  prefs: []
  type: TYPE_IMG
- en: Types of Pooling
  prefs: []
  type: TYPE_NORMAL
- en: The Convolutional Layer and the Pooling Layer, together form the i-th layer
    of a Convolutional Neural Network. Depending on the complexities in the images,
    the number of such layers may be increased for capturing low-level details even
    further, but at the cost of more computational power.
  prefs: []
  type: TYPE_NORMAL
- en: After going through the above process, we have successfully enabled the model
    to understand the features. Moving on, we are going to flatten the final output
    and feed it to a regular Neural Network for classification purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Classification — Fully Connected Layer (FC Layer)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![A Comprehensive Guide to Convolutional Neural Networks](../Images/f3ecb787dda963fbf5e949d260f7358f.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear
    combinations of the high-level features as represented by the output of the convolutional
    layer. The Fully-Connected layer is learning a possibly non-linear function in
    that space.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have converted our input image into a suitable form for our Multi-Level
    Perceptron, we shall flatten the image into a column vector. The flattened output
    is fed to a feed-forward neural network and backpropagation is applied to every
    iteration of training. Over a series of epochs, the model is able to distinguish
    between dominating and certain low-level features in images and classify them
    using the **Softmax Classification** technique.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various architectures of CNNs available which have been key in building
    algorithms which power and shall power AI as a whole in the foreseeable future.
    Some of them have been listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: LeNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AlexNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: VGGNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GoogLeNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ResNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ZFNet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[Sumit Saha](https://in.linkedin.com/in/linksumitsaha)** is a data scientist
    and machine learning engineer currently working on building AI-driven products.
    He is passionate about the applications of AI for social good, especially in the
    domain of medicine and healthcare. Occasionally I do some technical blogging too.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://saturncloud.io/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Comprehensive Survey on Trustworthy Graph Neural Networks:…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
