["```py\nimport pandas as pd\ndata = {'text': [\"I love cooking!\", \"Baking is fun\", None, \"Japanese cuisine is great!\"]}\ndf = pd.DataFrame(data)\nprint(df)\n```", "```py\n text\n0   I love cooking!\n1   Baking is fun\n2   None\n3   Japanese cuisine is great!\n```", "```py\ndf.dropna(subset=['text'], inplace=True)\nprint(df)\n```", "```py\n text\n0    I love cooking!\n1    Baking is fun\n3    Japanese cuisine is great!\n```", "```py\ndf['text'] = df['text'].str.lower()\nprint(df)\n```", "```py\n text\n0             i love cooking!\n1               baking is fun\n3  japanese cuisine is great!\n```", "```py\nimport re\ndf['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\nprint(df)\n```", "```py\n text\n0             i love cooking\n1              baking is fun\n3  japanese cuisine is great\n```", "```py\ndf['tokens'] = df['text'].str.split()\nprint(df)\n```", "```py\n text                          tokens\n0             i love cooking              [i, love, cooking]\n1              baking is fun               [baking, is, fun]\n3  japanese cuisine is great  [japanese, cuisine, is, great]\n```", "```py\nimport nltk\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\ndf['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\nprint(df['tokens'])\n```", "```py\n0               [love, cooking]\n1                 [baking, fun]\n3    [japanese, cuisine, great]\n```", "```py\nfrom nltk.stem import PorterStemmer\nnltk.download('wordnet')\nstemmer = PorterStemmer()\ndf['stemmed'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\nprint(df[['tokens','stemmed']])\n```", "```py\n tokens                   stemmed\n0             [love, cooking]              [love, cook]\n1               [baking, fun]               [bake, fun]\n3  [japanese, cuisine, great]  [japanes, cuisin, great]\n```", "```py\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndf['text'] = df['tokens'].apply(lambda x: ' '.join(x))\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(df['text'])\nprint(X.toarray())\n```", "```py\n[[0\\.         0.70710678 0\\.         0\\.         0\\.         0\\.       0.70710678]\n[0.70710678 0\\.         0\\.         0.70710678 0\\.         0\\.        0\\.        ]\n[0\\.         0\\.         0.57735027 0\\.         0.57735027 0.57735027        0\\.        ]]\n```"]