- en: Simple NLP Pipelines with HuggingFace Transformers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html](https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Simple NLP Pipelines with HuggingFace Transformers](../Images/1e310be2c1220fd85c3c9ca5c5c49028.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: An extensive package providing APIs and user-friendly tools to work with state-of-the-art
    pretrained models across language, vision, audio, and multi-modal modalities is
    what transformers by HuggingFace is all about. It consists of more than 170 pretrained
    models and supports frameworks such as PyTorch, TensorFlow, and JAX with the ability
    to interoperate among them in between code. The library is also deployment friendly
    as it allows the conversion of models to ONNX and TorchScript formats.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, we will particularly explore the `pipelines` functionality of
    transformers which can be easily used for inference. Pipelines provide an abstraction
    of the complicated code and offer simple API for several tasks such as Text Summarization,
    Question Answering, Named Entity Recognition, Text Generation, and Text Classification
    to name a few. The best thing about these APIs is that all the tasks from preprocessing
    to model evaluation can be performed with just a few lines of code without requiring
    heavy computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s dive right into it!
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to install the transformers package with the following command
    -
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will use the `pipeline` structure to implement different tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The pipeline allows to specify multiple parameters such as `task`, `model`,
    `device`, `batch size`, and other task specific parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with the first task.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Text Summarization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The input to this task is a corpus of text and the model will output a summary
    of it based on the expected length mentioned in the parameters. Here, we have
    kept minimum length as 5 and maximum length as 30.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: One can also choose from the other options of models that have been fine-tuned
    for the summarization task - `bart-large-cnn`, `t5-small`, `t5-large`, `t5-3b`,
    `t5-11b`. You can check out the complete list of available models [here](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads).
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Question Answering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this task, we provide a question and a context. The model will choose the
    answer from the context based on the highest probability score. It also provides
    the starting and ending positions of the text.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Refer [here](https://huggingface.co/models?pipeline_tag=question-answering),
    to check the full list of available models for the Question-Answering task.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Named Entity Recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Named Entity Recognition deals with identifying and classifying the words based
    on the names of persons, organizations, locations and so on. The input is basically
    a sentence and the model will determine the named entity along with its category
    and its corresponding location in the text.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Check out [here](https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads),
    for other options of available models.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Part-of-Speech Tagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PoS Tagging is useful to classify the text and provide its relevant parts of
    speech such as whether a word is a noun, pronoun, verb and so on. The model returns
    PoS tagged words along with their probability scores and respective locations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 5\. Text Classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will perform sentiment analysis and classify the text based on the tone.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Let’s try a few more examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The full list of models for text classification can be found [here](https://huggingface.co/models?filter=text-classification).
  prefs: []
  type: TYPE_NORMAL
- en: '6\. Text Generation:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Access the full list of models for text generation [here](https://huggingface.co/models?filter=text-generation).
  prefs: []
  type: TYPE_NORMAL
- en: '7\. Text Translation:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we will translate the language of text from one language to another. For
    example, we have chosen translation from English to French. We have used the basic
    t5-small model but you can access other advanced models [here](https://huggingface.co/models?pipeline_tag=translation).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You reached till the end, awesome! If you have followed along, you learned how
    to create basic NLP pipelines with Transformers. Refer to the [official documentation](https://huggingface.co/docs/transformers/main_classes/pipelines#natural-language-processing)
    by HuggingFace in order to check out other interesting applications in NLP such
    as Zero Shot Text Classification or Table Question Answering. In order to work
    with your own datasets or implement models from other domains such as vision,
    audio, or multimodal, check out [here](https://huggingface.co/docs/transformers/pipeline_tutorial#pipelines-for-inference).
  prefs: []
  type: TYPE_NORMAL
- en: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** is a passionate
    AI developer and writer pursuing Master’s in Machine Learning from Université
    de Montréal. Yesha is intrigued to explore responsible AI techniques to solve
    challenges that benefit society and share her learnings with the community.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Answering Questions with HuggingFace Pipelines and Streamlit](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Simple to Implement End-to-End Project with HuggingFace](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fine-Tuning BERT for Tweets Classification with HuggingFace](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HuggingFace Has Launched a Free Deep Reinforcement Learning Course](https://www.kdnuggets.com/2022/05/huggingface-launched-free-deep-reinforcement-learning-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beyond Pipelines: Graphs as Scikit-Learn Metaestimators](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unify Batch and ML Systems with Feature/Training/Inference Pipelines](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
