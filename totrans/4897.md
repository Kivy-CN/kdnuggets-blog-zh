# TensorFlow 入门：机器学习教程

> 原文：[https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html](https://www.kdnuggets.com/2017/12/getting-started-tensorflow.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2017/12/getting-started-tensorflow.html/2#comments)

**由 [Dino Causevic](https://www.toptal.com/resume/dino-causevic), Toptal**。

TensorFlow 是由 Google 创建的开源软件库，用于实现机器学习和深度学习系统。这两个名称包含了一系列强大的算法，它们面临着一个共同的挑战——使计算机能够自动识别复杂模式和/或做出最佳决策。

如果你对这些系统的详细信息感兴趣，可以从 Toptal 的博客文章中了解更多内容，具体包括 [机器学习](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer) 和 [深度学习](https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks)。

![](../Images/6e3b08444cb7bdaecec1e430278822de.png)

TensorFlow 从本质上来说是一个用于数据流编程的库。它利用各种优化技术，使数学表达式的计算变得更简单、更高效。

TensorFlow 的一些关键特性包括：

+   高效处理涉及多维数组的数学表达式

+   对深度神经网络和机器学习概念的良好支持

+   GPU/CPU 计算，其中相同的代码可以在这两种架构上执行

+   在机器和大数据集上的高可扩展性

这些特性共同使 TensorFlow 成为生产规模机器智能的完美框架。

在本 TensorFlow 教程中，你将学习如何在 TensorFlow 中使用简单却强大的机器学习方法，以及如何使用一些辅助库来调试、可视化和调整创建的模型。

**安装 TensorFlow**

我们将使用 TensorFlow Python API，该 API 兼容 Python 2.7 和 Python 3.3+。GPU 版本（仅限 Linux）需要 Cuda Toolkit 7.0+ 和 cuDNN v2+。

我们将使用 Conda 包依赖管理系统来安装 TensorFlow。Conda 允许我们在一台机器上分隔多个环境。你可以从 [这里](https://conda.io/docs/user-guide/install/index.html) 学习如何安装 Conda。

安装 Conda 后，我们可以创建用于 TensorFlow 安装和使用的环境。以下命令将创建我们的环境，并附带一些额外的库，例如 [NumPy](https://www.numpy.org/)，一旦开始使用 TensorFlow，这些库将非常有用。

此环境中安装的 Python 版本为 2.7，我们将在本文中使用此版本。

```py
conda create --name TensorflowEnv biopython
```

*为了简化，我们在这里安装 biopython 而不是仅仅安装 NumPy。这包括了 NumPy 和我们需要的其他一些包。你可以随时使用 `conda install` 或 `pip install` 命令按需安装这些包。*

以下命令将激活创建的 Conda 环境。我们将能够使用其中安装的包，而不会与全局或其他环境中安装的包混淆。

```py
source activate TensorFlowEnv
```

pip 安装工具是 Conda 环境的标准部分。我们将使用它来安装 TensorFlow 库。在此之前，一个好的第一步是使用以下命令将 pip 更新到最新版本：

```py
pip install --upgrade pip
```

现在我们准备通过运行以下命令来安装 TensorFlow：

```py
pip install tensorflow
```

TensorFlow 的下载和构建可能需要几分钟。在撰写本文时，这将安装 TensorFlow 1.1.0。

**数据流图**

在 TensorFlow 中，计算是通过数据流图来描述的。图中的每个节点代表一个数学操作（如加法、除法或乘法）的实例，每条边是一个多维数据集（张量），操作是在这些数据集上执行的。

![](../Images/1a9f8cab43009efda34fad441f236123.png)

由于 TensorFlow 使用计算图，它们的管理方式是每个节点代表一个操作的实例，每个操作有零个或多个输入和零个或多个输出。

TensorFlow 中的边可以分为两类：正常边传输数据结构（张量），在这种情况下一个操作的输出可能成为另一个操作的输入；特殊边则用于控制两个节点之间的依赖关系，以设置操作顺序，其中一个节点等待另一个节点完成。

**简单表达式**

在讨论 TensorFlow 的元素之前，我们将首先进行一个 TensorFlow 的工作示例，以了解 TensorFlow 程序的样子。

让我们从简单的表达式开始，假设由于某种原因，我们希望以 TensorFlow 方式计算函数 `y = 5*x + 13`。

在简单的 Python 代码中，它看起来像这样：

```py
x = -2.0
y = 5*x + 13
print y
```

在这种情况下，它给出的结果是 3.0。

现在我们将把上述表达式转换为 TensorFlow 术语。

**常量**

在 TensorFlow 中，常量是使用 `constant` 函数创建的，该函数的签名为 `constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`，其中 `value` 是将在进一步计算中使用的实际常量值，`dtype` 是数据类型参数（例如 float32/64、int8/16 等），`shape` 是可选的维度，`name` 是张量的可选名称，最后一个参数是一个布尔值，用于指示是否验证值的形状。

如果你需要在训练模型中使用具有特定值的常量，则可以使用 `constant` 对象，如下例所示：

```py
z = tf.constant(5.2, name="x", dtype=tf.float32)
```

**变量**

TensorFlow 中的变量是包含张量的内存缓冲区，必须显式初始化并在图中使用，以在会话间保持状态。通过简单地调用构造函数，变量被添加到计算图中。

变量在开始训练模型时尤其有用，它们用于保存和更新参数。作为构造函数参数传递的初始值代表一个张量或对象，可以转换或返回为张量。这意味着，如果我们想用一些预定义或随机值填充变量，以便在训练过程中之后使用并在迭代中更新，我们可以按如下方式定义它：

```py
k = tf.Variable(tf.zeros([1]), name="k")
```

在 TensorFlow 中使用变量的另一种方式是进行计算，其中该变量不可训练，可以按如下方式定义：

```py
k = tf.Variable(tf.add(a, b), trainable=False)
```

**会话**

为了实际评估节点，我们必须在会话中运行计算图。

会话封装了 TensorFlow 运行时的控制和状态。没有参数的会话将使用当前会话中创建的默认图，否则会话类接受一个图参数，该参数用于在该会话中执行。

下面是一个简短的代码片段，展示了如何在 TensorFlow 中使用上述术语来计算一个简单的线性函数。

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    session.run(init)
    print session.run(y)

```

**使用 TensorFlow：定义计算图**

使用数据流图的好处在于，执行模型与其执行（在 CPU、GPU 或某种组合上）是分离的，一旦实现，TensorFlow 中的软件可以在 CPU 或 GPU 上使用，其中所有与代码执行相关的复杂性都被隐藏了。

可以在使用 TensorFlow 库的过程中构建计算图，而不需要显式实例化[Graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph)对象。

TensorFlow 中的图对象可以通过简单的代码行如`c = tf.add(a, b)`创建。这将创建一个操作节点，该节点接收两个张量`a`和`b`，并生成它们的和`c`作为输出。

计算图是一个内置过程，它使用库而不需要直接调用[graph](https://www.tensorflow.org/versions/master/api_docs/python/tf/Graph)对象。TensorFlow 中的图对象包含一组操作和张量作为数据单元，在操作之间使用，这样可以实现相同的过程，并且包含多个图，每个图将分配给不同的会话。例如，简单的代码行`c = tf.add(a, b)`将创建一个操作节点，该节点将两个张量`a`和`b`作为输入，并生成它们的和`c`作为输出。

TensorFlow 还提供了一个馈送机制，用于将张量修补到图中的任何操作，其中馈送会用张量值替换操作的输出。馈送数据作为参数传递给`run()`函数调用。

占位符是 TensorFlow 允许开发者通过在某些表达式中绑定的占位符将数据注入计算图的一种方式。占位符的签名如下：

```py
placeholder(dtype, shape=None, name=None)
```

其中 `dtype` 是张量中元素的类型，可以提供要输入的张量的形状和操作的名称。

如果没有传递形状，则此张量可以用任意形状进行输入。一个重要的注意事项是，占位符张量必须被输入数据，否则，在会话执行时，如果缺少这部分，占位符会生成如下结构的错误：

```py
InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'y' with dtype float
```

占位符的优点在于它们允许开发者创建操作及计算图，而无需事先提供数据，数据可以在运行时从外部来源添加。

让我们以TensorFlow的方式乘以两个整数 `x` 和 `y` 为例，其中一个占位符将与通过会话 `run` 方法的输入机制一起使用。

```py
import tensorflow as tf

x = tf.placeholder(tf.float32, name="x")
y = tf.placeholder(tf.float32, name="y")

z = tf.multiply(x, y, name="z")

with tf.Session() as session:
    print session.run(z, feed_dict={x: 2.1, y: 3.0})

```

**使用 TensorBoard 可视化计算图**

TensorBoard 是一个用于分析数据流图的可视化工具。这对于更好地理解机器学习模型非常有用。

使用 TensorBoard，你可以深入了解有关参数的不同统计信息和计算图部分的详细信息。深度神经网络通常包含大量节点。TensorBoard 允许开发者深入了解每个节点以及 TensorFlow 运行时如何执行计算。

![](../Images/48d7c35fa2fff56b5635fa7bdf908e1c.png)

现在，让我们回到 TensorFlow 教程开头的示例，我们在其中定义了一个线性函数，格式为 `y = a*x + b`。

为了从会话中记录事件以供以后在 TensorBoard 中使用，TensorFlow 提供了 `FileWriter` 类。它可用于创建用于存储 [摘要](https://www.tensorflow.org/api_guides/python/summary) 和 [事件](https://www.tensorflow.org/api_docs/python/tf/Event) 的事件文件，其构造函数接受六个参数，格式如下：

```py
__init__(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None)
```

在这里，`logdir` 参数是必需的，其他参数有默认值。`graph` 参数将从训练程序中创建的会话对象中传递。完整的示例代码如下：

```py
import tensorflow as tf

x = tf.constant(-2.0, name="x", dtype=tf.float32)
a = tf.constant(5.0, name="a", dtype=tf.float32)
b = tf.constant(13.0, name="b", dtype=tf.float32)

y = tf.Variable(tf.add(tf.multiply(a, x), b))

init = tf.global_variables_initializer()

with tf.Session() as session:
    merged = tf.summary.merge_all() // new
    writer = tf.summary.FileWriter("logs", session.graph) // new

    session.run(init)
    print session.run(y)
```

我们只添加了两行新代码。我们将所有在默认图中收集的摘要合并，`FileWriter` 用于将事件转储到文件中，如上所述。

运行程序后，我们在目录 `logs` 中有了文件，最后一步是运行 `tensorboard`：

```py
tensorboard --logdir logs/
```

现在 TensorBoard 已启动并运行在默认端口 6006。打开 https://localhost:6006 并点击页面顶部的 Graphs 菜单项，你将能够看到图像，如下图所示：

![](../Images/d7def7e0a9ba10e06df3f474264fe157.png)

TensorBoard 用特定符号标记常量和摘要节点，这些符号在下面描述。

![](../Images/f39a2398dc314d85d44d6734a1ae94b9.png)

**数学与 TensorFlow**

张量是 TensorFlow 中的基本数据结构，它们代表数据流图中的连接边缘。

张量简单地表示一个多维数组或列表。张量结构可以通过三个参数来识别：秩、形状和类型。

+   秩：识别张量的维度数量。秩也被称为张量的阶数或 n 维度，例如秩为 1 的张量是向量，秩为 2 的张量是矩阵。

+   形状：张量的形状是它的行数和列数。

+   类型：分配给张量元素的数据类型。

要在 TensorFlow 中构建一个张量，我们可以构建一个 n 维数组。这可以通过使用 NumPy 库来轻松完成，或者通过将 Python n 维数组转换为 TensorFlow 张量来完成。

![](../Images/54429bdf3b195d6b7305c5e32546eff4.png)

要构建一个一维张量，我们将使用一个 NumPy 数组，我们将通过传递一个内置的 Python 列表来构造它。

```py
import numpy as np
tensor_1d = np.array([1.45, -1, 0.2, 102.1])
```

使用这种类型的数组类似于使用内置的 Python 列表。主要的区别在于，NumPy 数组还包含一些额外的属性，如维度、形状和类型。

```py
>> print tensor_1d
[   1.45   -1\.      0.2   102.1 ]

>> print tensor_1d[0]
1.45

>> print tensor_1d[2]
0.2

>> print tensor_1d.ndim
1

>> print tensor_1d.shape
(4,)

>> print tensor_1d.dtype
float64

```

一个 NumPy 数组可以通过辅助函数 [convert_to_tensor](https://www.tensorflow.org/versions/master/api_docs/python/tf/convert_to_tensor) 容易地转换为 TensorFlow 张量，该函数帮助开发者将 Python 对象转换为张量对象。此函数接受张量对象、NumPy 数组、Python 列表和 Python 标量。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
```

现在如果我们将张量绑定到 TensorFlow 会话中，我们将能够看到我们转换的结果。

```py
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)

with tf.Session() as session:
    print session.run(tensor)
    print session.run(tensor[0])
    print session.run(tensor[1])

```

输出：

```py
[   1.45   -1\.      0.2   102.1 ]
1.45
-1.0

```

我们可以用类似的方法创建一个二维张量或矩阵：

```py
tensor_2d = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_1 = np.array(np.random.rand(4, 4), dtype='float32')
tensor_2d_2 = np.array(np.random.rand(4, 4), dtype='float32')

m1 = tf.convert_to_tensor(tensor_2d)
m2 = tf.convert_to_tensor(tensor_2d_1)
m3 = tf.convert_to_tensor(tensor_2d_2)
mat_product = tf.matmul(m1, m2)
mat_sum = tf.add(m2, m3)
mat_det = tf.matrix_determinant(m3)

with tf.Session() as session:
    print session.run(mat_product)
    print session.run(mat_sum)
    print session.run(mat_det)

```

**张量运算**

在上面的例子中，我们介绍了一些 TensorFlow 操作，这些操作对向量和矩阵进行特定的计算。这些计算具体是什么在下表中展示。

上表中列出的 TensorFlow 操作与张量对象一起工作，并且是逐元素执行的。因此，如果你想计算向量 x 的余弦值，TensorFlow 操作将对传递的张量中的每个元素进行计算。

```py
tensor_1d = np.array([0, 0, 0])
tensor = tf.convert_to_tensor(tensor_1d, dtype=tf.float64)
with tf.Session() as session:
    print session.run(tf.cos(tensor))

```

输出：

```py
[ 1\.  1\.  1.]

```

**矩阵运算**

矩阵运算对于机器学习模型，如线性回归，非常重要，因为它们通常在模型中使用。TensorFlow 支持所有常见的矩阵运算，如 [乘法](https://www.tensorflow.org/versions/master/api_docs/python/tf/matmul)、[转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、[求逆](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_inverse)、计算 [行列式](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_determinant)、求解 [线性方程](https://www.tensorflow.org/versions/master/api_docs/python/tf/matrix_solve) 和 [更多](https://www.tensorflow.org/versions/master/api_guides/python/math_ops#Matrix_Math_Functions)。

接下来，我们将*深入探讨*一些矩阵运算。它们在机器学习模型中非常重要，比如线性回归。让我们编写一些代码来执行基本的矩阵运算，如乘法、获取 [转置](https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose)、获取行列式、乘法、求解等。

以下是调用这些运算的基本示例。

```py
import tensorflow as tf
import numpy as np

def convert(v, t=tf.float32):
    return tf.convert_to_tensor(v, dtype=t)

m1 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m2 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m3 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m4 = convert(np.array(np.random.rand(4, 4), dtype='float32'))
m5 = convert(np.array(np.random.rand(4, 4), dtype='float32'))

m_tranpose = tf.transpose(m1)
m_mul = tf.matmul(m1, m2)
m_det = tf.matrix_determinant(m3)
m_inv = tf.matrix_inverse(m4)
m_solve = tf.matrix_solve(m5, [[1], [1], [1], [1]])

with tf.Session() as session:
    print session.run(m_tranpose)
    print session.run(m_mul)
    print session.run(m_inv)
    print session.run(m_det)
    print session.run(m_solve)

```

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在 IT 领域

* * *

### 更多相关话题

+   [联邦学习：协作机器学习教程…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)

+   [Scikit-learn 分类入门](https://www.kdnuggets.com/getting-started-with-scikit-learn-for-classification-in-machine-learning)

+   [自动化文本摘要入门](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)

+   [数据清洗入门](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)

+   [SQL 备忘单入门](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)

+   [spaCy NLP 入门](https://www.kdnuggets.com/2022/11/getting-started-spacy-nlp.html)
