["```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom xgboost import XGBClassifier\nfrom concrete.ml.sklearn import XGBClassifier as ConcreteXGBClassifier\n```", "```py\ntrain_data = pd.read_csv(\"./local_datasets/titanic/train.csv\")\ntest_data = pd.read_csv(\"./local_datasets/titanic/test.csv\")\ndatasets = [train_data, test_data]\ntest_ids = test_data[\"PassengerId\"]\n```", "```py\nprint(train_data.isnull().sum())\nprint(test_data.isnull().sum())\n```", "```py\nfor incomp_var in train_data.columns:\n\n  missing_val = pd.concat(datasets)[incomp_var].isnull().sum()\n\n  if missing_val > 0 and incomp_var != \"Survived\":\n\n      total_val = pd.concat(datasets).shape[0]\n\n      print(\n\n         f\"Percentage of missing values in {incomp_var}: \"\n\n   f\"{missing_val/total_val*100:.1f}%\"\n\n      )\n\n```", "```py\nPercentage of missing values in Cabin: 77.5%\nPercentage of missing values in Age: 20.1%\nPercentage of missing values in Embarked: 0.2%\nPercentage of missing values in Fare: 0.1%\n```", "```py\ndrop_column = [\"PassengerId\", \"Ticket\", “Cabin”]\nfor dataset in datasets:\n  dataset.drop(drop_column, axis=1, inplace=True)\n```", "```py\nfor dataset in datasets:\n\n  dataset.Age.fillna(dataset.Age.median(), inplace=True)\n\n  dataset.Embarked.fillna(dataset.Embarked.mode()[0], inplace=True)\n\n  dataset.Fare.fillna(dataset.Fare.median(), inplace=True)\n```", "```py\n# Function that helps generating proper bin names \ndef get_bin_labels(bin_name, number_of_bins):\n\n  labels = []\n\n  for i in range(number_of_bins):\n\n      labels.append(bin_name + f\"_{i}\")\n\n  return labels\n\nfor dataset in datasets:\n\n  dataset[\"FamilySize\"] = dataset.SibSp + dataset.Parch + 1\n\n  dataset[\"IsAlone\"] = 1\n\n  dataset.IsAlone[dataset.FamilySize > 1] = 0\n\n  dataset[\"Title\"] = dataset.Name.str.extract(\nr\" ([A-Za-z]+)\\.\", expand=False\n\n  )\n\n  dataset[\"FareBin\"] = pd.qcut(\ndataset.Fare, 4, labels=get_bin_labels(\"FareBin\", 4)\n\n  )\n\n  dataset[\"AgeBin\"] = pd.cut(\ndataset.Age.astype(int), 5, labels=get_bin_labels(\"AgeBin\", 5)\n\n  )\n\n  # Removing outdated variables\n\n  drop_column = [\"Name\", \"SibSp\", \"Parch\", \"Fare\", \"Age\"]\n\n  dataset.drop(drop_column, axis=1, inplace=True)\n```", "```py\ndata = pd.concat(datasets)\ntitles = data.Title.value_counts()\nprint(titles)\n```", "```py\nuncommon_titles = titles[titles < 10].index\nfor dataset in datasets:\n  dataset.Title.replace(uncommon_titles, \"Rare\", inplace=True)\n```", "```py\ncategorical_features = train_data.select_dtypes(exclude=np.number).columns\nx_train = pd.get_dummies(train_data, prefix=categorical_features)\nx_test = pd.get_dummies(test_data, prefix=categorical_features)\nx_test = x_test.to_numpy()\n```", "```py\ntarget = \"Survived\"\nx_train = x_train.drop(columns=[target])\nx_train = x_train.to_numpy()\ny_train = train_data[target].to_numpy()\n```", "```py\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\nparam_grid = {\n\n  \"max_depth\": list(range(1, 5)),\n\n  \"n_estimators\": list(range(1, 5)),\n\n  \"learning_rate\": [0.01, 0.1, 1],\n}\nmodel = GridSearchCV(\n\n  XGBClassifier(), param_grid, cv=cv, scoring=\"roc_auc\"\n)\nmodel.fit(x_train, y_train)\n```", "```py\nparam_grid[\"n_bits\"] = [2]\nx_train = x_train.astype(np.float32)\nconcrete_model = GridSearchCV(\n\n  ConcreteXGBClassifier(), param_grid, cv=cv, scoring=\"roc_auc\"\n)\nconcrete_model.fit(x_train, y_train)\n```", "```py\nclear_predictions = model.predict(x_test)\n```", "```py\nclear_quantized_predictions = concrete_model.predict(x_test)\n```", "```py\nfhe_circuit = concrete_model.best_estimator_.compile(x_train[:100])\nfhe_predictions = concrete_model.best_estimator_.predict(\n\n  x_test, execute_in_fhe=True\n)\n\n```", "```py\nnumber_of_equal_preds = np.sum(\n\n  fhe_predictions == clear_quantized_predictions\n)\npred_similarity = number_of_equal_preds / len(clear_predictions) * 100\nprint(\n\n  \"Prediction similarity between both Concrete-ML models\" \n\n  f\"(quantized clear and FHE): {pred_similarity:.2f}%\"\n)\n```", "```py\nsubmission = pd.DataFrame(\n\n      {\n\n          \"PassengerId\": test_ids,\n\n          \"Survived\": fhe_predictions,\n\n      }\n\n  )\n\nsubmission.to_csv(\"titanic_submission_fhe.csv\", index=False)\n\nsubmission = pd.DataFrame(\n\n      {\n\n          \"PassengerId\": test_ids,\n\n          \"Survived\": clear_predictions,\n\n      }\n\n  )\n\nsubmission.to_csv(\"titanic_submission_xgb_clear.csv\", index=False)\n```"]