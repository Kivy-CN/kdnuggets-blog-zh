# Apache Arrow与Apache Parquet：为什么我们需要不同的列式数据项目，分别用于磁盘和内存中

> 原文：[https://www.kdnuggets.com/2017/02/apache-arrow-parquet-columnar-data.html](https://www.kdnuggets.com/2017/02/apache-arrow-parquet-columnar-data.html)

**作者：Julien LeDem，架构师， [Dremio](http://www.dremio.com/)。**

列式数据结构相比传统的行式数据结构在分析中提供了许多性能优势。这些优势包括磁盘上的数据——更少的磁盘查找，更有效的压缩，更快的扫描速度——以及内存中数据的CPU使用效率。今天，列式数据非常普遍，大多数分析数据库，包括Teradata、Vertica、Oracle等，都实现了这种结构。

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的IT需求

* * *

在2012年和2013年，我们在Twitter和Cloudera的一些人创建了Apache Parquet（最初称为Red Elm，是Google的Dremel的字母重排）以将这些理念引入Hadoop生态系统。四年后，Parquet已成为磁盘上列式数据的标准，而一个名为Apache Arrow的新项目也已出现，成为内存中列式数据的标准表示方式。本文将深入探讨为什么我们需要两个项目，一个用于磁盘上的数据存储，另一个用于内存中的数据处理，以及它们如何协同工作。

### 行式有什么问题，列式又有什么优点？

回到2007年，Vertica，一款早期的商业列式数据库，曾有一个巧妙的营销口号“局势已变”。这并不是一种糟糕的方式来形象化列式数据库的工作方式——将表格旋转90度，现在曾经的行读取变成了单列读取。这种方法在分析工作负载方面具有很多优点。

![](../Images/ed551a87e16d9473437bf40dfeb79e19.png)

大多数系统都被设计成最小化磁盘查找次数和扫描的数据量，因为这些操作会增加巨大的延迟。在事务工作负载中，当数据写入到行式数据库中的表时，给定行的列会连续写入磁盘，这对写入非常高效。分析工作负载则不同，因为大多数查询一次读取大量行中的少量列。在传统的行式数据库中，系统可能会为每行执行查找，大多数列会不必要地从磁盘读取到内存中。

列式数据库将给定列的值连续地组织在磁盘上。这有助于显著减少多行读取的寻道次数。此外，压缩算法在单一数据类型上往往更为有效，而不是典型行中存在的混合类型。权衡是写入速度较慢，但这是一个很好的优化，用于分析中读取通常远多于写入的情况。

### 列式数据，见 Hadoop

在 Twitter，我们大量使用 Hadoop，它非常可扩展，擅长存储各种数据，并能在数百或数千台服务器上并行处理工作负载。通常 Hadoop 的延迟比较高，因此我们也大量使用 Vertica，它为我们的少量数据提供了出色的性能。

我们认为通过在 HDFS 中以列式模型更好地组织数据，可以显著提高 Hadoop 对分析作业的性能，主要是 Hive 查询，但其他项目也是如此。当时我们大约有 4 亿用户，每天生成超过 100TB 的压缩数据，因此对这个项目有很大的兴趣。

我们在早期测试中看到很多好处：我们减少了 28% 的存储开销，单列读取时间减少了 90%。我们不断优化，增加了列特定的压缩选项、字典压缩、位打包和运行长度编码，最终减少了 52% 的存储和 48% 的读取时间。

![列式数据](../Images/db84f998e32079445312e5e853a9089d.png)

Parquet 也被设计用来处理结构丰富的数据，如 JSON。这对我们在 Twitter 及许多其他早期用户非常有益，如今大多数 Hadoop 用户将数据存储在 Parquet 中。Hadoop 生态系统中对 Parquet 的支持广泛，包括 Spark、Presto、Hive、Impala、Drill、Kite 等。即便在 Hadoop 之外，它也被一些科学社区采纳，例如 CERN 的 ROOT 项目。

### 基于 Parquet 的内存处理理念

自最初启发 Hadoop 的 Google 论文发布以来，硬件已经发生了很大变化。最重要的变化是 RAM 价格的显著下降。

![](../Images/ad2bc32d89913243206f9bbc9fe58f27.png)

现在的服务器比我在 Twitter 时拥有更多的 RAM，因为从内存中读取数据的速度比从磁盘读取数据快几千倍，因此数据界对如何在分析中优化使用 RAM 非常感兴趣。

列式数据的权衡与内存中的情况不同。对于磁盘上的数据，通常 IO 支配延迟，可以通过激进的压缩来解决，但这会增加 CPU 负担。在内存中，访问速度要快得多，我们希望通过关注缓存局部性、流水线处理和 SIMD 指令来优化 CPU 吞吐量。

### 精简系统之间的接口

计算机科学中有趣的一点是，虽然有一套通用的资源——RAM、CPU、存储、网络——但每种语言与这些资源的交互方式完全不同。当不同的程序需要交互时——无论是在语言内部还是跨语言——在交接过程中会出现效率低下的问题，这可能主导了整体成本。这有点像在欧元出现之前的欧洲旅行，你需要为每个国家使用不同的货币，到旅行结束时，你可以确定在所有兑换中丢失了很多钱！

![](../Images/16e8a5fea28863305881f3286da70634.png)

![](../Images/016ddeda494124b5d26a1629156392b8.png)

我们将这些交接视为内存处理中的下一个明显瓶颈，并着手在广泛的项目中开发一套通用接口，以去除在数据传输时不必要的序列化和反序列化。Apache Arrow 标准化了一种高效的内存列式表示，它与传输表示相同。如今，它在超过 13 个项目中包括了一级绑定，包括 Spark、Hadoop、R、Python/Pandas 以及我的公司 Dremio。

![](../Images/c80acb3b2f2ee35321befe15be4dccee.png)

Python 特别在 Pandas 库中有很强的支持，并且支持直接处理 Arrow 记录批次并将其持久化为 Parquet。

这些对于 Apache Arrow 来说仍然是早期阶段，但结果非常有希望。用户在各种工作负载中看到性能提升 10 倍到 100 倍并不罕见。

### Parquet 和 Arrow，协同工作

Parquet 和 Arrow 之间的互操作性从第一天起就是一个目标。虽然每个项目都可以独立使用，但两者都提供了在格式之间读写的 API。 ![](../Images/3fe6329df67b98a388942afb32a69f2d.png)

由于这两者都是列式的，我们可以实现从一种格式到另一种格式的高效向量化转换，并且从 Parquet 读取到 Arrow 的速度比行式表示要快得多。我们仍在努力使这一集成更加无缝，包括向量化的 Java 读取器和完整的类型等价性。

Pandas 是使用这两个项目的一个好例子。用户可以将 Pandas 数据框保存为 Parquet，并将 Parquet 文件读取到内存中的 Arrow。Pandas 可以直接在 Arrow 列上工作，为更快的 Spark 集成铺平道路。

在我目前的公司 Dremio，我们正在努力开发一个广泛使用 Apache Arrow 和 Apache Parquet 的新项目。你可以在 [www.dremio.com](http://www.dremio.com) 了解更多信息。

**简介：** Julien LeDem，建筑师，[Dremio](http://www.dremio.com)的Apache Parquet的共同作者以及项目的PMC主席。他还是Apache Pig的提交者和PMC成员。Julien是Dremio的建筑师，之前是Twitter数据处理工具的技术负责人，他还获得了一个两字符的Twitter用户名（[@J_](https://twitter.com/j_))。在Twitter之前，Julien是Yahoo!内容平台的首席工程师和技术负责人，在那里他获得了Hadoop的初步经验。

**相关：**

+   [Spark与Tungsten的结合更为耀眼](/2016/05/spark-tungsten-burns-brighter.html)

+   [Spark扩展：大数据的机器学习](/2016/09/spark-scale-machine-learning-big-data.html)

+   [大内存正在吞噬大数据——分析用数据集的大小](/2015/11/big-ram-big-data-size-datasets.html)

### 更多相关主题

+   [成为优秀数据科学家需要的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [在生成AI时代，数据科学家是否仍然需要？](https://www.kdnuggets.com/2023/06/data-scientists-still-needed-age-generative-ai.html)

+   [低代码：开发者仍然需要吗？](https://www.kdnuggets.com/2022/04/low-code-developers-still-needed.html)

+   [5种在Python中加载数据的不同方式](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)

+   [数据挖掘与机器学习有何不同？](https://www.kdnuggets.com/2022/06/data-mining-different-machine-learning.html)

+   [如何从不同背景过渡到数据科学？](https://www.kdnuggets.com/2023/05/transition-data-science-different-background.html)
