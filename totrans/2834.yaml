- en: Classify A Rare Event Using 5 Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/01/classify-rare-event-machine-learning-algorithms.html](https://www.kdnuggets.com/2020/01/classify-rare-event-machine-learning-algorithms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Leihua Ye](http://www.linkedin.com/in/leihuaye), UC Santa Barbara**'
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning is the crown of Data Science;
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Supervised Learning is the crown jewel of Machine Learning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Background
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A couple years ago, Harvard Business Review released an article with the following
    title “[Data Scientist: The Sexiest Job of the 21st Century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century).”
    Ever since its release, Data Science or Statistics Departments become widely pursued
    by college students and, and Data Scientists (Nerds), for the first time, is referred
    to as being sexy.'
  prefs: []
  type: TYPE_NORMAL
- en: For some industries, Data Scientists have reshaped the corporation structure
    and reallocated a lot of decision-makings to the “front-line” workers. Being able
    to generate useful business insights from data has never been so easy.
  prefs: []
  type: TYPE_NORMAL
- en: According to Andrew Ng ([Machine Learning Yearning](https://www.deeplearning.ai/machine-learning-yearning/),
    p.9),
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Learning algorithms contribute the majority value to the industry.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There is no doubt why SL generates so much business value. Banks use it to detect
    credit card fraud, traders make purchase decisions based on what models tell them
    to, and factory filter through the production line for defective units (this is
    an area where AI and ML can help traditional companies, according to Andrew Ng).
  prefs: []
  type: TYPE_NORMAL
- en: 'These business scenarios share two common features:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary Results**: fraud VS not fraud, to buy VS not to buy, and defective
    VS not defective.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Imbalanced Data Distribution**: one majority group VS one minority group.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As Andrew Ng points out recently, [small data](https://info.deeplearning.ai/the-batch-self-driving-cars-that-cant-see-pedestrians-evolutionary-algorithms-fish-recognition-fighting-fraud-?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=79686634&_hsenc=p2ANqtz-8JYm57kQehRZzewKP7GRcg1KzCEiTzMaPaYmA1fKuzs_IU9AoooG7ABIqqRLuOubgAU8r8pBVED-l1D6mOoCjVrF6lYw&_hsmi=79686634), [robustness](https://info.deeplearning.ai/the-batch-deepmind-masters-starcraft-2-ai-attacks-on-amazon-a-career-in-robot-management-banks-embrace-bots-1?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=79686634&_hsenc=p2ANqtz-8JYm57kQehRZzewKP7GRcg1KzCEiTzMaPaYmA1fKuzs_IU9AoooG7ABIqqRLuOubgAU8r8pBVED-l1D6mOoCjVrF6lYw&_hsmi=79686634),
    and [human factor](https://blog.deeplearning.ai/blog/the-batch-google-achieves-quantum-supremacy-amazon-aims-to-sway-lawmakers-ai-predicts-basketball-plays-face-detector-preserves-privacy-problems-beyond-bounding-box?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&utm_content=80323254&_hsenc=p2ANqtz-_88W5PvaNASb06SH_AW1uzL2ETjfCivTbmXc7m87jMcF4rrMG42U9qp7EATDPRM-rxHm0biLE3yMyHebUyR-pMaLZm2A&_hsmi=80323254) are
    three obstacles to successful AI projects. To a certain degree, our rare event
    question with one minority group is also a small data question: **the ML algorithm
    learns more from the majority group and may easily misclassify the small data
    group.**
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the million-dollar questions:'
  prefs: []
  type: TYPE_NORMAL
- en: For these rare events, which ML method performs better?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What metrics?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tradeoffs?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this post, we try to answer these questions by applying 5 ML methods to a
    real-life dataset with comprehensive R implementations.
  prefs: []
  type: TYPE_NORMAL
- en: '*For the full description and the original dataset, please check the original *[*dataset*](https://archive.ics.uci.edu/ml/datasets/bank+marketing)*;
    For the complete R code, please check my *[*Github*](https://github.com/LeihuaYe/Machine-Learning-Classification-for-Imbalanced-Data)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Business Question
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A bank in Portugal carries out a marketing strategy of a new banking service
    (a term deposit) and wants to know which types of clients have subscribed to the
    service. So, the bank can adjust its marketing strategy and target specific groups
    of populations in the future. Data Scientists have teamed up with the sells and
    marketing teams to come up with statistical solutions to identify future subscribers.
  prefs: []
  type: TYPE_NORMAL
- en: R Implementations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here comes the pipeline of model selection and R implementations.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Importation, Data Cleaning, and Exploratory Data Analysis**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s load and clean the raw dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It appears to be tedious to clean the raw data as we have to recode missing
    variables and transform qualitative into quantitative variables. It takes even
    more time to clean the data in the real world. **There is a saying “data scientists
    spend 80% of their time cleaning data and 20% building a model.”**
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s explore the distribution of our outcome variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/36ee7036a855eb626f1eab29fa7272c3.png)'
  prefs: []
  type: TYPE_IMG
- en: As can be seen, the dependent variables (service subscription) are not equally
    distributed, with more “No”s than “Yes”s. **The unbalanced distribution should
    flash some warning signs because data distribution affects the final statistical
    model**. It can easily misclassify the minority case using a model developed out
    of a majority case.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Data Split**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, let’s split the dataset into two parts: training and test sets. As a
    rule of thumb, we stick to the 80–20 division: 80% as the training set and 20%
    as the test test. For Time Series data, we train models based on 90% of the data
    and leave the rest 10% as the test dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, let’s create an empty tracking record.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**3\. Train Models**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we define a new function (**calc_error_rate**) and apply it
    to calculate training and test errors of each ML model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This function calculates the rate when the predicted label does not equal to
    the true value.
  prefs: []
  type: TYPE_NORMAL
- en: '**#1 Logistic Regression Model**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a brief introduction of logistic model, please check my other posts: [**Machine
    Learning 101**](https://towardsdatascience.com/machine-learning-101-predicting-drug-use-using-logistic-regression-in-r-769be90eb03d)and [**Machine
    Learning 102**](https://towardsdatascience.com/machine-learning-102-logistic-regression-with-polynomial-features-98a208688c17).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s fit a logistic model including all other variables except the outcome
    variable. Since the outcome is binary, we set the model to binomial distribution
    (“family=binomial”).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to obtain the train error. We set the type to response since
    we are predicting the types of the outcome and adopt a majority rule: if the prior
    probability exceeding or equal to 0.5, we predict the outcome to be a yes; otherwise,
    a no.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '**#2 Decision Tree**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For DT, we follow cross-validation and identify the best nodes of split. For
    a quick intro to DT, please refer to a post ([link](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052))
    by [Prashant Gupta](https://medium.com/u/a84d0e60277a?source=post_page-----fab464573233----------------------).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The best size of cross-validation is 3.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**#3 K-Nearest Neighbors**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a non-parametric method, KNN does not require any prior knowledge of the
    distribution. In simple words, KNN assigns a k number of nearest neighbors to
    the unit of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a quick start, please check my post on KNN: [**Beginner’s Guide to K-Nearest
    Neighbors in R: from Zero to Hero.**](https://towardsdatascience.com/beginners-guide-to-k-nearest-neighbors-in-r-from-zero-to-hero-d92cd4074bdb)For
    detailed explanations of Cross-Validation and the do.chunk function, please redirect
    to my [post](https://towardsdatascience.com/beginners-guide-to-k-nearest-neighbors-in-r-from-zero-to-hero-d92cd4074bdb).'
  prefs: []
  type: TYPE_NORMAL
- en: Using cross-validation, we find the minimal cross-validation error when k=20.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Then, let’s find the best k number that minimizes validation error.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Following the same step, we find the training and test errors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '**#4 Random Forests**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We follow standard steps of constructing a Random Forests model. A quick intro
    to RF ([link](https://towardsdatascience.com/understanding-random-forest-58381e0602d2))
    by [Tony Yiu](https://medium.com/u/840a3210fbe7?source=post_page-----fab464573233----------------------).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**#5 Support Vector Machines**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Similarly, we follow standard steps of constructing SVM. A good intro to the
    method, please refer to a post ([Link](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47))
    by [Rohith Gandhi](https://medium.com/u/8f4e7f7a57e3?source=post_page-----fab464573233----------------------).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Model Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have constructed all ML models following model selection procedures and obtained
    their training and test errors. In this section, we are going to select the best
    model using some model metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '**4.1 Train/Test Errors**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Is it possible to find the best model using the train/test errors?
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s check the results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/5f085edc85c216791260eacc15e4bbb8.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, Random Forests have the minimal training error, though with a similar
    test error with the other methods. As you may notice, the training and test errors
    are very close, and it’s difficult to tell which one is clearly winning.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, classification accuracy, either train error or test error, should not
    be the metrics for highly imbalanced dataset. This is so because the dataset is
    dominated by the majority cases, and even a random guess gives you 50–50 chance
    of getting it right (50% accuracy). Even worse, a highly accuracy model may severely
    penalize the minority case. For that reason, let’s check another metrics ROC Curve.
  prefs: []
  type: TYPE_NORMAL
- en: '**4.2 **Receiver Operating Characteristic (ROC) Curve'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ROC is a graphic representation showing how a classification model performs
    at all classification thresholds. We prefer a classifier that approaches to 1
    quicker than others.
  prefs: []
  type: TYPE_NORMAL
- en: 'ROC Curve plots two parameters — True Positive Rate and False Positive Rate
    — at different thresholds in the same graph:'
  prefs: []
  type: TYPE_NORMAL
- en: TPR (Recall) = TP/(TP+FN)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FPR = FP/(TN+FP)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure](../Images/ab921d7eee025a796dda874ef4124409.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Indon](https://commons.wikimedia.org/wiki/File:ROC_space-2.png)'
  prefs: []
  type: TYPE_NORMAL
- en: To a large extent, ROC Curve does not only measure the level of classification
    accuracy but reaches a nice balance between TPR and FPR. This is quite desirable
    for rare events since we also want to reach a balance between the majority and
    minority cases.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Let’s plot the ROC curves.
  prefs: []
  type: TYPE_NORMAL
- en: We put a abline to show the chance of random assignment. Our classifier should
    perform better than random guess, right?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/45113fac4a08f7a5f11cd1a7bab9aa2c.png)'
  prefs: []
  type: TYPE_IMG
- en: ROC
  prefs: []
  type: TYPE_NORMAL
- en: We have a winner here.
  prefs: []
  type: TYPE_NORMAL
- en: According to the ROC curve, KNN (the blue one) stands above all other methods.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Area Under the Curve (AUC)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the name suggested, AUC is the area under the ROC curve. It is an arithmetic
    representation of the visual AUC curve. AUC provides an aggregated results of
    how classifiers perform across possible classifcation thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Let’s check the AUC values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/878c579193c181bffffce4348328b2ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Also, KNN has the biggest AUC value (0.847).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this post, we find KNN, a non-parametric classifier, performs better than
    its parametric counterparts. In terms of metrics, it’s more reasonable to choose
    ROC Curve over classification accuracy for rare events.
  prefs: []
  type: TYPE_NORMAL
- en: Enjoy reading this one?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please find me at [LinkedIn](https://www.linkedin.com/in/leihuaye/) and [Twitter](https://twitter.com/leihua_ye).
  prefs: []
  type: TYPE_NORMAL
- en: Check out my other posts on Artificial Intelligence and Machine Learning.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Beginner’s Guide to K-Nearest Neighbors in R: from Zero to Hero**](https://towardsdatascience.com/beginners-guide-to-k-nearest-neighbors-in-r-from-zero-to-hero-d92cd4074bdb)'
  prefs: []
  type: TYPE_NORMAL
- en: A pipeline of building a KNN model in R with various measurement metrics
  prefs: []
  type: TYPE_NORMAL
- en: '[**Machine Learning 101: Predicting Drug Use Using Logistic Regression In R**](https://towardsdatascience.com/machine-learning-101-predicting-drug-use-using-logistic-regression-in-r-769be90eb03d)'
  prefs: []
  type: TYPE_NORMAL
- en: Basics, link functions, and plots
  prefs: []
  type: TYPE_NORMAL
- en: '[**Machine Learning 102: Logistic Regression With Polynomial Features**](https://towardsdatascience.com/machine-learning-102-logistic-regression-with-polynomial-features-98a208688c17)'
  prefs: []
  type: TYPE_NORMAL
- en: How to classify when there are nonlinear components
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Leihua Ye](http://www.linkedin.com/in/leihuaye)** ([@leihua_ye](https://twitter.com/leihua_ye))is
    a Ph.D. Candidate at the UC, Santa Barbara. He has 5+ years of research and professional
    experience in Quantitative UX Research, Experimentation & Causal Inference, Machine
    Learning, and Data Science.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/classifying-rare-events-using-five-machine-learning-techniques-fab464573233).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Beginner’s Guide to K-Nearest Neighbors in R: from Zero to Hero](/2020/01/beginners-guide-nearest-neighbors-r.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Classifying Heart Disease Using K-Nearest Neighbors](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Visualize Data in Python (and R)](/2019/11/visualize-data-python-and-r.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Rare Data Science Skills That Can Help You Get Employed](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tackle computer science problems using both fundamental and modern…](https://www.kdnuggets.com/2023/11/packt-tackle-computer-science-problems-fundamental-modern-algorithms-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 22: Primary Supervised Learning Algorithms…](https://www.kdnuggets.com/2022/n25.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Algorithms for Classification](https://www.kdnuggets.com/2022/03/machine-learning-algorithms-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Popular Machine Learning Algorithms](https://www.kdnuggets.com/2022/05/popular-machine-learning-algorithms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
