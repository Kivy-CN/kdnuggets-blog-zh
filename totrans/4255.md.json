["```py\nTrain/Test.txt\n\n2018 O\nSous-total O\nen O\nEUR O\n3,20 O\n€ O\nTVA S-TVA_ID\n(0%) O\n0,00 € S-TVA\nTotal B-TTC_ID\nen I-TTC_ID\nEUR E-TTC_ID\n3,20 S-TTC\n€ O\nServices O\nsoumis O\nau O\nmécanisme O\nd'autoliquidation O\n- O\n```", "```py\n€ 912 457 920 466\nServices 80 486 133 495\nsoumis 136 487 182 495\nau 185 488 200 495\nmécanisme 204 486 276 495\nd'autoliquidation 279 486 381 497\n- 383 490 388 492\n```", "```py\n€ 912 425 920 434 1653 2339 image1.jpg\nTVA 500 441 526 449 1653 2339 image1.jpg\n(0%) 529 441 557 451 1653 2339 image1.jpg\n0,00 € 882 441 920 451 1653 2339 image1.jpg\nTotal 500 457 531 466 1653 2339 image1.jpg\nen 534 459 549 466 1653 2339 image1.jpg\nEUR 553 457 578 466 1653 2339 image1.jpg\n3,20 882 457 911 467 1653 2339 image1.jpg\n€ 912 457 920 466 1653 2339 image1.jpg\nServices 80 486 133 495 1653 2339 image1.jpg\nsoumis 136 487 182 495 1653 2339 image1.jpg\nau 185 488 200 495 1653 2339 image1.jpg\nmécanisme 204 486 276 495 1653 2339 image1.jpg\nd'autoliquidation 279 486 381 497 1653 2339 image1.jpg\n- 383 490 388 492 1653 2339 image1.jpg\n```", "```py\nB-DATE_ID\nB-INVOICE_ID\nB-INVOICE_NUMBER\nB-MONTANT_HT\nB-MONTANT_HT_ID\nB-SELLER\nB-TTC\nB-DATE\nB-TTC_ID\nB-TVA\nB-TVA_ID\nE-DATE_ID\nE-DATE\nE-INVOICE_ID\nE-INVOICE_NUMBER\nE-MONTANT_HT\nE-MONTANT_HT_ID\nE-SELLER\nE-TTC\nE-TTC_ID\nE-TVA\nE-TVA_ID\nI-DATE_ID\nI-DATE\nI-SELLER\nI-INVOICE_ID\nI-MONTANT_HT_ID\nI-TTC\nI-TTC_ID\nI-TVA_ID\nO\nS-DATE_ID\nS-DATE\nS-INVOICE_ID\nS-INVOICE_NUMBER\nS-MONTANT_HT_ID\nS-MONTANT_HT\nS-SELLER\nS-TTC\nS-TTC_ID\nS-TVA\nS-TVA_ID\n```", "```py\n! rm -r unilm\n! git clone -b remove_torch_save https://github.com/NielsRogge/unilm.git\n! cd unilm/layoutlm\n! pip install unilm/layoutlm\n```", "```py\n! rm -r transformers\n! git clone https://github.com/huggingface/transformers.git\n! cd transformers\n! pip install ./transformers\n```", "```py\nfrom torch.nn import CrossEntropyLoss\ndef get_labels(path):\n    with open(path, \"r\") as f:\n        labels = f.read().splitlines()\n    if \"O\" not in labels:\n        labels = [\"O\"] + labels\n    return labels\nlabels = get_labels(\"./labels.txt\")\nnum_labels = len(labels)\nlabel_map = {i: label for i, label in enumerate(labels)}\npad_token_label_id = CrossEntropyLoss().ignore_index\n```", "```py\nfrom transformers import LayoutLMTokenizer\nfrom layoutlm.data.funsd import FunsdDataset, InputFeatures\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nargs = {'local_rank': -1,\n        'overwrite_cache': True,\n        'data_dir': '/content/data',\n        'model_name_or_path':'microsoft/layoutlm-base-uncased',\n        'max_seq_length': 512,\n        'model_type': 'layoutlm',}\n# class to turn the keys of a dict into attributes\nclass AttrDict(dict):\n    def __init__(self, *args, **kwargs):\n        super(AttrDict, self).__init__(*args, **kwargs)\n        self.__dict__ = self\nargs = AttrDict(args)\ntokenizer = LayoutLMTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n# the LayoutLM authors already defined a specific FunsdDataset, so we are going to use this here\ntrain_dataset = FunsdDataset(args, tokenizer, labels, pad_token_label_id, mode=\"train\")\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset,\n                              sampler=train_sampler,\n                              batch_size=2)\neval_dataset = FunsdDataset(args, tokenizer, labels, pad_token_label_id, mode=\"test\")\neval_sampler = SequentialSampler(eval_dataset)\neval_dataloader = DataLoader(eval_dataset,\n                             sampler=eval_sampler,\n                            batch_size=2)\nbatch = next(iter(train_dataloader))\ninput_ids = batch[0][0]\ntokenizer.decode(input_ids)\n```", "```py\nfrom transformers import LayoutLMForTokenClassification\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=num_labels)\nmodel.to(device)\n```", "```py\nrom transformers import AdamW\nfrom tqdm import tqdm\noptimizer = AdamW(model.parameters(), lr=5e-5)\nglobal_step = 0\nnum_train_epochs = 50\nt_total = len(train_dataloader) * num_train_epochs # total number of training steps\n#put the model in training mode\nmodel.train()\nfor epoch in range(num_train_epochs):\n  for batch in tqdm(train_dataloader, desc=\"Training\"):\n      input_ids = batch[0].to(device)\n      bbox = batch[4].to(device)\n      attention_mask = batch[1].to(device)\n      token_type_ids = batch[2].to(device)\n      labels = batch[3].to(device)\n# forward pass\n      outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,\n                      labels=labels)\n      loss = outputs.loss\n# print loss every 100 steps\n      if global_step % 100 == 0:\n        print(f\"Loss after {global_step} steps: {loss.item()}\")\n# backward pass to get the gradients \n      loss.backward()\n#print(\"Gradients on classification head:\")\n      #print(model.classifier.weight.grad[6,:].sum())\n# update\n      optimizer.step()\n      optimizer.zero_grad()\n      global_step += 1\n```", "```py\nmport numpy as np\nfrom seqeval.metrics import (\n    classification_report,\n    f1_score,\n    precision_score,\n    recall_score,\n)\neval_loss = 0.0\nnb_eval_steps = 0\npreds = None\nout_label_ids = None\n# put model in evaluation mode\nmodel.eval()\nfor batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n    with torch.no_grad():\n        input_ids = batch[0].to(device)\n        bbox = batch[4].to(device)\n        attention_mask = batch[1].to(device)\n        token_type_ids = batch[2].to(device)\n        labels = batch[3].to(device)\n# forward pass\n        outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,\n                        labels=labels)\n        # get the loss and logits\n        tmp_eval_loss = outputs.loss\n        logits = outputs.logits\neval_loss += tmp_eval_loss.item()\n        nb_eval_steps += 1\n# compute the predictions\n        if preds is None:\n            preds = logits.detach().cpu().numpy()\n            out_label_ids = labels.detach().cpu().numpy()\n        else:\n            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n            out_label_ids = np.append(\n                out_label_ids, labels.detach().cpu().numpy(), axis=0\n            )\n# compute average evaluation loss\neval_loss = eval_loss / nb_eval_steps\npreds = np.argmax(preds, axis=2)\nout_label_list = [[] for _ in range(out_label_ids.shape[0])]\npreds_list = [[] for _ in range(out_label_ids.shape[0])]\nfor i in range(out_label_ids.shape[0]):\n    for j in range(out_label_ids.shape[1]):\n        if out_label_ids[i, j] != pad_token_label_id:\n            out_label_list[i].append(label_map[out_label_ids[i][j]])\n            preds_list[i].append(label_map[preds[i][j]])\nresults = {\n    \"loss\": eval_loss,\n    \"precision\": precision_score(out_label_list, preds_list),\n    \"recall\": recall_score(out_label_list, preds_list),\n    \"f1\": f1_score(out_label_list, preds_list),\n}\n```", "```py\nPATH='./drive/MyDrive/trained_layoutlm/layoutlm_UBIAI.pt'\ntorch.save(model.state_dict(), PATH)\n```", "```py\n!sudo apt install tesseract-ocr\n!pip install pytesseract\n```", "```py\nmport sys\nsys.path.insert(1, './drive/MyDrive/UBIAI_layoutlm')\nfrom layoutlm_preprocess import *\nimage_path='./content/invoice_test.jpg'\nimage, words, boxes, actual_boxes = preprocess(image_path)\n```", "```py\nmodel_path='./drive/MyDrive/trained_layoutlm/layoutlm_UBIAI.pt'\nmodel=model_load(model_path,num_labels)\nword_level_predictions, final_boxes=convert_to_features(image, words, boxes, actual_boxes, model)\n```", "```py\ndraw = ImageDraw.Draw(image)\nfont = ImageFont.load_default()\ndef iob_to_label(label):\n  if label != 'O':\n    return label[2:]\n  else:\n    return \"\"\nlabel2color = {'data_id':'green','date':'green','invoice_id':'blue','invoice_number':'blue','montant_ht_id':'black','montant_ht':'black','seller_id':'red','seller':'red', 'ttc_id':'grey','ttc':'grey','':'violet', 'tva_id':'orange','tva':'orange'}\nfor prediction, box in zip(word_level_predictions, final_boxes):\n    predicted_label = iob_to_label(label_map[prediction]).lower()\n    draw.rectangle(box, outline=label2color[predicted_label])\n    draw.text((box[0] + 10, box[1] - 10), text=predicted_label, fill=label2color[predicted_label], font=font)\n\nimage\n```"]