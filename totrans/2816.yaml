- en: 20 AI, Data Science, Machine Learning Terms You Need to Know in 2020 (Part 1)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: In the past, KDnuggets has covered collections of [key terms](/tag/key-terms),
    including those for [machine learning](/2016/05/machine-learning-key-terms-explained.html),
    [deep learning](/2016/10/deep-learning-key-terms-explained.html), [big data](/2016/08/big-data-key-terms-explained.html),
    [natural language processing](/2017/02/natural-language-processing-key-terms-explained.html),
    and more. As we get into a new year, and as we have not published any collections
    of key terms in the recent past, we thought it would be a good idea to highlight
    some AI, data science, and machine learning terms that we should all now be familiar
    with in the constantly evolving landscape.
  prefs: []
  type: TYPE_NORMAL
- en: As such, these terms are a combination of some more recently-emerging concepts,
    as well as existing concepts which may be of perceived increased importance of
    late. The definitions for these are a combined effort from the KDnuggets team,
    including [Gregory Piatetsky](/author/gregory-piatetsky), [Asel Mendis](/author/asel-mendis),
    [Matthew Dearing](/author/matthew-dearing), and myself, [Matthew Mayo](/author/matt-mayo).
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See also [**20 AI, Data Science, Machine Learning Terms You Need to Know in
    2020 (Part 2)**](https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And so without any further ado, here are the first 10 terms you need to know,
    with the second 10 coming next week, giving us a total of 20 terms to know for
    2020.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/8b7e157b12f9f58f71312628e357550b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**AutoML**'
  prefs: []
  type: TYPE_NORMAL
- en: Automated machine learning (AutoML) spans the fairly wide chasm of tasks which
    could reasonably be thought of as being included within a machine learning pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: An AutoML "solution" could include the tasks of data preprocessing, feature
    engineering, algorithm selection, algorithm architecture search, and hyperparameter
    tuning, or some subset or variation of these distinct tasks. Thus, automated machine
    learning can now be thought of as anything from solely performing a single task,
    such as automated feature engineering, all the way through to a fully-automated
    pipeline, from data preprocessing, to feature engineering, to algorithm selection,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'To put it another way — and to be honest, my *favorite* way — if, as [Sebastian
    Raschka has described it](/2016/05/explain-machine-learning-software-engineer.html),
    computer programming is about automation, and machine learning is "all about automating
    automation," then automated machine learning is "the automation of automating
    automation." Follow me, here: programming relieves us by managing rote tasks;
    machine learning allows computers to learn how to best perform these rote tasks;
    automated machine learning allows for computers to learn how to optimize the outcome
    of learning how to perform these rote actions.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a very powerful idea; while we previously have had to worry about tuning
    parameters and hyperparameters, manually engineering features, performing algorithm
    selection, and the like, automated machine learning systems can learn the best
    way to tweak these processes for optimal outcomes by a number of different possible
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: '"Regular" programming is data and rules in, answers out; machine learning is
    data and answers in, rules out; automated machine learning involves automating
    the optimization of some set of constraints to "best" get from data and answers
    to rules, defining "best" with any metric you like.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bayesian**'
  prefs: []
  type: TYPE_NORMAL
- en: The Bayesian methodology allows us to apply probability distributions to model
    the real world and update our beliefs as new data becomes available to us. For
    years statisticians have generally relied on the frequentist approach. The Bayesian
    approach is suitable for modelling a hypothesis that has only a small amount of
    data that may not be significant in the eyes of a frequentist.
  prefs: []
  type: TYPE_NORMAL
- en: 'This explanation by Brandon Rohrer is a great simple example on how the Bayesian
    approach works:'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you are at the movies and a fellow moviegoer drops their ticket. You
    want to get their attention. This is what they look like from behind. You can’t
    tell their gender, only that they have long hair. Do you call out “Excuse me ma’am!”
    or “Excuse me sir!” Given what you know about men’s and women’s hairstyles in
    your area, you might assume that this is a woman. (In this oversimplification,
    there are only two hair lengths and genders.). Now consider a variation of the
    situation where this person is standing in line for the men’s restroom. With this
    additional piece of information, you would probably assume that this is a man.
    This use of common sense and background knowledge is something that we do without
    thinking. Bayesian inference is a way to capture this in math so that we can make
    more accurate predictions. -Brandon Rohrer
  prefs: []
  type: TYPE_NORMAL
- en: '**BERT**'
  prefs: []
  type: TYPE_NORMAL
- en: '[BERT](https://arxiv.org/abs/1810.04805) stands for Bidirectional Encoder Representations
    from Transformers, and is a pretraining technique for natural language processing.
    What sets BERT apart from other language representations is the application of
    *bidirectional* training to the existing Transformer attention model. BERT pre-trains
    deep bidirectional representations of unlabeled text data on both left and right
    contexts, resulting in a language model which can be fine-tuned with only a single
    added layer. BERT has achieved state of the art performance on a number of NLP
    tasks, including question answering and inference. Both BERT and the Transformer
    were developed by Google.'
  prefs: []
  type: TYPE_NORMAL
- en: It should be intuitive that training a language model bidirectionally on text
    as opposed to left to right (or right to left) would result in some better sense
    of language "understanding" and word meaning. Bidirectionality allows for the
    learning of word meaning based on the entirety of its surroundings, as opposed
    to making determinations based on what can be gleaned from "reading" from one
    direction up to the point of a given word occurrence. Therefore, words with different
    meanings in different contexts can be treated separately and a better representation
    of their contextual meaning captured (think "bank" of a river versus a "bank"
    where you keep your money).
  prefs: []
  type: TYPE_NORMAL
- en: Practically, BERT can be used to extract features from text in the form of word
    or sentence embeddings, or the BERT models can be fine-tuned on additional data
    for specific tasks such as question answering or text classification. BERT is
    available in a few different sized models (numbers of parameters), and has inspired
    an additional family of BERT-related models, such as RoBERTa and DistilBERT.
  prefs: []
  type: TYPE_NORMAL
- en: For a full treatment and practical tutorial using BERT, see [Chris McCormick
    and Nick Ryan's fantastic write-up](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/).
  prefs: []
  type: TYPE_NORMAL
- en: '**CCPA**'
  prefs: []
  type: TYPE_NORMAL
- en: CCPA, which stands for [California Consumer Privacy Act](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act),
    which went into effect on Jan 1, 2020, has important implications to businesses
    that collect personal data, and by implications to businesses that analyze and
    process such data. It is similar in intent to [GDPR](/tag/gdpr) but offers California
    consumers stronger protections. CCPA allows any California consumer to demand
    to see what information a company has on them, and a full list of third parties
    with whom this information has been shared. California consumers can also access
    their personal data, say no to the sale of their personal data, and request a
    company to delete any part of their personal information that a company has.
  prefs: []
  type: TYPE_NORMAL
- en: 'It applies to any business that collect consumers'' personal data, does business
    in California, and satisfies at least one of the following :'
  prefs: []
  type: TYPE_NORMAL
- en: Annual gross revenues over $25 million;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buys or sells the personal information of 50,000 or more California consumers
    or households
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Earns over 50% of its annual revenue from selling California consumers' personal
    information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information, see [Wikipedia entry on CCPA](https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act)
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Engineer**'
  prefs: []
  type: TYPE_NORMAL
- en: Data engineers are the ones responsible for optimizing and managing the storage
    and retrieval of an organization’s data. A data engineer would set out the road
    map on how best to acquire the data and create databases for storing it. They
    would typically deal with cloud services to optimize data storage and create algorithms
    to make sense out of the data. The role of a data engineer is highly technical
    and requires advanced knowledge in SQL, database design and computer science.
  prefs: []
  type: TYPE_NORMAL
- en: There is an increasing trend for data engineers to be cloud certified to create
    databases in the cloud and handle large complex datasets in a cloud environment
    to scale and optimize data retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deepfakes**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Fakes are fake images, video, or audio that have been created using advanced
    [Deep Learning](/tag/deep-learning) and Generative Adversarial Networks [GANs](/tag/gans)
    technology. This technology is so advanced that the results are very realistic
    and are very hard to identify as fake. Here is an example of Deepfake using Obama''s
    image and voice:'
  prefs: []
  type: TYPE_NORMAL
- en: Deepfakes first became prominent in the context of porn, with popular celebrities
    faces superimposed on top of adult videos, but recently the technology has progressed
    with apps like FakeApp and more recent open-source alternatives like FaceSwap
    and DeepFaceLab.
  prefs: []
  type: TYPE_NORMAL
- en: For voice, it used to require several minutes of speech, but recently technology
    can generate convincing voice imitation from only a few seconds of speech. In
    a first of its kind cybercrime, in Sep 2019 [a company was tricked](https://medium.com/tebs-lab/the-first-known-deep-fake-crime-a-promisingly-habitable-planet-and-californias-gig-worker-bill-7923b81a18d0)
    to pay $243K by scammers who used deep fake technology to imitate the CEO's voice.
  prefs: []
  type: TYPE_NORMAL
- en: Deepfakes have already been used in political disinformation campaigns for creating
    fake images for bot profiles, but are likely to be used in 2020 to spread disinformation
    about candidates using their fake voice and images.
  prefs: []
  type: TYPE_NORMAL
- en: There is now an arms race between creators of DF and web companies that try
    to identify them. Facebook, together with several other companies has [announced
    a $10M contest](https://ai.facebook.com/blog/deepfake-detection-challenge/) to
    produce technology to identify Deepfakes. Stay tuned and don't automatically trust
    everything you see on the web - check its source.
  prefs: []
  type: TYPE_NORMAL
- en: '**Deployment/Productionizing models**'
  prefs: []
  type: TYPE_NORMAL
- en: In this age of machine learning, deep learning and AI, the final objective of
    the process is to deploy the it to put it in the hands of the final consumer.
    There are many services available to deploy a model through the web such as Heroku,
    AWS, Azure, GCP, Github etc. Different providers have different costing and provide
    slightly different services. Deployment and putting models into production will
    require some knowledge of Front-end and Back-end development as well to a certain
    extent as well to be able to work in teams.
  prefs: []
  type: TYPE_NORMAL
- en: Many models are now being deployed using cloud computing providers due to their
    ease of scaling to millions of users while being able to monitor the cost of scaling
    to such a level. A model in production allows an organization to monetize it and
    create better value for their customers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Graph Neural Networks**'
  prefs: []
  type: TYPE_NORMAL
- en: Data Scientists are swimming in data. Piles of data. Some data can be raw and
    unorganized as it streams in through a firehose. Other data can be neat and orderly
    (or curated to be so), formatted within manageable dimensions. With these “Euclidean”
    data sets, such as text, images, and videos, machine learning has provided much
    success in applications for text generation, image manipulation, and facial recognition.
    Pair deep learning models run on a GPU or two with a mountain of training data,
    and the possibilities for discovering hidden patterns and meaningful features
    in the data appear infinite.
  prefs: []
  type: TYPE_NORMAL
- en: What about data that is more interrelated? Data can be connected to one other
    through dependent relationships. Interactions between users might impact purchasing
    decisions on e-commerce platforms. Chemical interactions for drug discovery are
    mapped out through complex interconnections of reactions. Social networks are
    formed and devolve through ever-changing, irregular, and unordered relationships.
    The human brain is built on individually communicating cells connected through
    an intertwined ball of spaghetti.
  prefs: []
  type: TYPE_NORMAL
- en: These sorts of data relationships can be modeled as *graphs* with data points
    represented as nodes and relationships encoded through interconnecting links.
    Traditional machine learning approaches, including deep learning, need to be generalized
    further to compute within a non-Euclidean, graph-based space. While some related
    work was performed earlier, the notion of a *graph neural network* (GNN) was defined
    by [Margo Gori and team](http://sailab.diism.unisi.it/people/marco-gori/) in 2005,
    followed by more research that expanded into the development of graph versions
    of recurrent and convolutional neural networks. Deep learning research is now
    actively working to apply the [GNN approach](/2019/08/neighbours-machine-learning-graphs.html)
    to data-as-spaghetti sources and is an area of study that should be watched closely
    in 2020.
  prefs: []
  type: TYPE_NORMAL
- en: '**MLOps & AIOps**'
  prefs: []
  type: TYPE_NORMAL
- en: Following the expansive success of [DevOps](/tag/devops) in IT organizations
    that merges the processes of *software developers* with IT service delivery, this
    term has been elevated to a present-day cultural buzzword. Not soon after most
    buzzwords take root, will new contexts or areas of applicability latch on to the
    hype.
  prefs: []
  type: TYPE_NORMAL
- en: Such is so with the term MLOps to represent the latest best practices for developing
    and deploying machine learning models through effective collaborations with *data
    scientists* and IT professionals. Working within a well-defined development lifecycle
    should be [quite welcome](/2020/02/machine-learning-projects-manage.html) for
    many data scientists, as formal and self-guided educational tracks tend to focus
    on the fundaments of AI and ML, with [less familiarity](/2020/02/deploy-machine-learning-model.html)
    provided for the requirements of production deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Broadening this scope of leveraging artificial intelligence into the operations
    of an organization is AIOps that pulls in any and all machine learning technologies
    to extract meaningful insights from IT systems. This approach combines the intelligence
    of humans with that of AI algorithms to enhance IT teams in making better and
    faster decisions, responding to incidents in real-time, and developing optimized
    applications to facilitate more effective or automated business processes. With
    [Gartner’s prediction](https://www.gartner.com/smarterwithgartner/how-to-get-started-with-aiops/)
    that only 30% of large enterprise CIOs will be exclusively using AIOps to improve
    operations by 2023, there will be much more to be seen from the evolution of AIOps
    across IT organizations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Transfer Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following pair of issues that can arise while training machine
    learning models. First, often there is not enough training data available to sufficiently
    train a model. Second, even (and especially) if sufficient amounts of training
    data exists, training process is often resource- and time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: If you factor in that machine learning models are generally trained on specific
    data for a particular task, and that resulting models are task-specific, the maximum
    potential of these models is often not realized. Once data and compute are leveraged
    to train a model, why not use this model in as many situations as possible? Why
    not transfer what has been learned to a new application? Could highly-optimized
    trained models not be additionally exploited for a wider assortment of tasks?
  prefs: []
  type: TYPE_NORMAL
- en: Transfer learning involves the leveraging of existing machine learning models
    for use in scenarios in which the models were not originally trained. Much as
    humans do not discard everything they have previously learned and start fresh
    each time they take up a new task, transfer learning allows a machine learning
    model to port the "knowledge" it has acquired during training to new tasks, extending
    the reach of the combination of computation and expertise having been used as
    fuel for the original model. Simply put, transfer learning can save training time
    and extend the usefulness of existing machine learning models. It is also an invaluable
    technique for tasks where the large amounts of training data typically required
    for training a model from scratch are not available.
  prefs: []
  type: TYPE_NORMAL
- en: Considering time- and compute-consumption, transfer learning allows us to better
    maximize the usefulness of a model. Concerning the insufficiency of training data,
    transfer learning allows us to take pretrained models trained on potentially massive
    amounts of data and tweak them on the smaller amounts of task-specific data available.
    Transfer learning is an effective approach to managing 2 distinct potential shortcomings
    in machine learning model training, and so it should be no surprise why it is
    becoming increasingly more used.
  prefs: []
  type: TYPE_NORMAL
- en: '*This answer is adapted in part from my foreword to the book [Transfer Learning
    with Python](https://www.amazon.ca/Hands-Transfer-Learning-Python-TensorFlow-ebook/dp/B07CB455BF)
    from Packt Publishing.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Top 5 must-have Data Science skills for 2020](/2020/01/top-5-data-science-skills-2020.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 5 Data Science Trends for 2020](/2020/02/top-5-data-science-trends.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 5 AI trends for 2020](/2020/01/top-5-ai-trends-2020.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
