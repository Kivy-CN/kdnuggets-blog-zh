- en: How causal inference lifts augmented analytics beyond flatland
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何因果推断将增强分析提升至平面之外
- en: 原文：[https://www.kdnuggets.com/2021/08/causal-inference-augmented-analytics-beyond-flatland.html](https://www.kdnuggets.com/2021/08/causal-inference-augmented-analytics-beyond-flatland.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/causal-inference-augmented-analytics-beyond-flatland.html](https://www.kdnuggets.com/2021/08/causal-inference-augmented-analytics-beyond-flatland.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Michael Klaput](https://www.linkedin.com/in/michael-klaput-67375385),
    Chief Science Officer and Co-Founder at Kausa**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Michael Klaput](https://www.linkedin.com/in/michael-klaput-67375385)，Kausa
    的首席科学官和联合创始人**。'
- en: '![](../Images/d6a1b737c9bf044bc70dc03c45304f61.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6a1b737c9bf044bc70dc03c45304f61.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT 需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'If the world was two-dimensional, life would be very odd indeed. Think about
    it: The earth would not be a sphere but a circle — just like all other stars and
    planets in a 2D universe. Beings would be flattened, too, navigating a plane landscape
    and existence. For example, to pass somebody on the street, you would have to
    jump over that person as there would be no depth whatsoever. For the same reason,
    to just look behind you, you would literally have to turn yourself upside down.
    Fortunately, this is not the world we live in. But unfortunately, this is the
    basis on which most enterprises are run today — perhaps even yours. In any technology-driven
    business, the quality of your decision-making is inevitably based on the quality
    of your data insights. However, in too many companies, those ’insights’ are effectively
    two-dimensional: flat, impractical, and hopelessly inconclusive.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果世界是二维的，生活将会非常奇怪。想象一下：地球将不是一个球体，而是一个圆圈——就像二维宇宙中的其他星星和行星一样。生物也会被压扁，在一个平面上的景观和存在中徘徊。例如，要在街上绕过某人，你必须跳过那个人，因为没有任何深度。同样地，要看在你身后，你实际上需要把自己翻转过来。幸运的是，这不是我们生活的世界。但不幸的是，这正是目前大多数企业运营的基础——也许包括你的公司。在任何技术驱动的业务中，你的决策质量不可避免地取决于数据洞察的质量。然而，在许多公司中，这些“洞察”实际上是二维的：平坦、无用且无望地得出结论。
- en: Businesses usually measure their performance in terms of a KPI. It has thus
    become an objective in data analytics to find the best predictive models of future
    KPI values given historical data. While these models might perform surprisingly
    well, extracting value out of them is just as hard. Aside from a lack of explainability,
    this is also because predictive models are unable to capture reality and are limited
    to low-dimensional explanations. In this article, we will give two arguments why
    this is the case based on bad scaling and unrealistic assumptions made in most
    predictive models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 企业通常通过关键绩效指标（KPI）来衡量其绩效。因此，在数据分析中，找到给定历史数据的未来 KPI 值的最佳预测模型已成为一个目标。虽然这些模型可能表现得出乎意料地好，但从中提取价值同样困难。除了缺乏可解释性之外，这也是因为预测模型无法捕捉现实，只能局限于低维解释。在本文中，我们将给出两个论点，说明为什么这会发生，基于大多数预测模型中的糟糕缩放和不切实际的假设。
- en: But why bother? It is not the well-performing model that improves business performance.
    Instead, the only way to improve a business is through decisions, which should
    ultimately be done by a human. The objective of data analytics in business should
    be to inform decisions by uncovering insights. Unfortunately, these are hidden
    in your data like needles in a haystack. This far from trivial problem motivated
    a relatively young branch of data analytics has been coined augmented analytics
    and has been pushed in a recent Gartner report [[1](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#7342acb5e89f)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么要费心呢？并不是表现良好的模型提升了业务表现。相反，改善业务的唯一途径是通过决策，而这些决策最终应该由人类来做。商业数据分析的目标应该是通过揭示洞察来指导决策。不幸的是，这些洞察隐藏在你的数据中，就像大海捞针一样。这一并非简单的问题促使了数据分析领域一个相对年轻的分支——增强分析（augmented
    analytics）的出现，并在最近的一份Gartner报告中得到了推动[[1](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#7342acb5e89f)]。
- en: '![](../Images/116fd95d11ab92f5bf7081b935807c08.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/116fd95d11ab92f5bf7081b935807c08.png)'
- en: '*Figure 1\. Cover of Flatland: a romance of many dimensions / with illustrations
    by the author, A Square. By Edwin Abbott Abbott (1838-1926). Published: London:
    Seeley & Co., 1884\. *EC85 Ab264 884f Houghton Library, Harvard University*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1\. 《Flatland: a romance of many dimensions》的封面/ 作者A Square插图，作者Edwin Abbott
    Abbott（1838-1926）。出版地：伦敦：Seeley & Co.，1884。*EC85 Ab264 884f 霍顿图书馆，哈佛大学*'
- en: We want to challenge the perception that predictive models should be the default
    option used to inform business decisions. They introduce a costly detour in the
    search for insights and might even render it practically infeasible. We will highlight
    in a simple problem that predictive modeling can offer only little aside from
    a massive overhead. Instead, we will try to mimic how a business analyst would
    operate. This will naturally bring us to methods from causal inference.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望挑战这样一种看法，即预测模型应该是用于指导业务决策的默认选项。它们在寻找洞察的过程中引入了昂贵的绕道，甚至可能使这一过程在实际操作中变得不可行。我们将在一个简单的问题中强调，预测建模除了带来巨大的开销外，几乎不能提供任何有价值的信息。相反，我们将尝试模拟业务分析师的操作方式。这自然会引导我们使用因果推断的方法。
- en: The Impactful Change
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 影响力的变化
- en: 'We will consider the problem of diagnosing errors in regression models in big
    data scenarios. Most of the readers should have encountered the following scenario:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑在大数据场景下诊断回归模型错误的问题。大多数读者可能已经遇到过以下场景：
- en: '*Figure 2\. Key performance indicator actual vs. prediction using a single
    model.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2\. 使用单个模型的关键绩效指标实际值与预测值对比。*'
- en: Clearly, there has been an impactful change in the KPI that seems to persist
    for the time being. On the technical side, a reasonable reaction would be to retrain
    your predictive model on the data after the change point. Do you agree? If so,
    maybe keep this in mind.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，关键绩效指标（KPI）发生了显著变化，并且这一变化似乎在暂时持续。从技术角度来看，一个合理的反应是对变更点之后的数据重新训练你的预测模型。你同意吗？如果同意，可能需要记住这一点。
- en: '*Figure 3\. Key performance indicator actual vs. prediction using two models.*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3\. 使用两个模型的关键绩效指标实际值与预测值对比。*'
- en: The good news is that your model seems to be accurate. The bad news is that
    your manager will inevitably ask what happened to the KPI. But do not be afraid.
    This is an ideal situation for proving your value to the company. Can you identify
    the reason behind this change? Can you uncover insights that will inform the correct
    decision?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是你的模型似乎很准确。坏消息是你的经理不可避免地会问KPI发生了什么。但不要害怕。这是证明你对公司的价值的理想时机。你能找到这种变化背后的原因吗？你能揭示出能够指导正确决策的洞察吗？
- en: The Quest of Why
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要探究？
- en: 'Let''s say your company’s dataset looks something like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你公司的数据集看起来像这样：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Table 1\. Sample company data.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 1\. 示例公司数据。*'
- en: 'Let us further assume that you are dealing with the simplest case: The KPI
    values of data points before and after the jump are perfectly fit using a linear
    regression model. Here, you are dealing with categorical data which you need to
    handle appropriately to use in the regression. A standard approach for this is
    one-hot encoding of categorical values: for each category value, you introduce
    a feature that can be either true or false. For example, in the dataset above
    you would define the feature'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步假设你正在处理最简单的情况：在跳跃前后，KPI值通过线性回归模型完全拟合。在这里，你需要处理分类数据，并需要恰当地处理这些数据以用于回归。一个标准的方法是对分类值进行独热编码：对于每个类别值，引入一个可以为真或假的特征。例如，在上面的数据集中，你会定义特征
- en: '*customer_country = **Germany*.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*customer_country = **Germany*。'
- en: To finally enable feature selection, it is necessary to use a form of regularisation.
    Here,  you will use lasso regularisation (with ten-fold cross-validation).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要最终实现特征选择，有必要使用一种正则化方法。在这里，你将使用套索正则化（配合十折交叉验证）。
- en: After training two lasso regularised linear regression models, one before and
    one after the jump,  you can look at a ranked list of feature weight differences
    between these.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练了两个套索正则化的线性回归模型之后，一个是在跳跃之前，另一个是在跳跃之后，你可以查看这些模型之间的特征权重差异的排名列表。
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Figure 4\. Feature weights using one-hot encoding.*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4\. 使用独热编码的特征权重.*'
- en: It looks like subgroups such as android customers or customers older than 46+
    performed differently before and after the jump. Great, looks like you found the
    reasons for the KPI jump … or did you?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来像是 android 用户或年龄超过 46+ 的用户在跳跃前后的表现不同。很好，看起来你找到了 KPI 跳跃的原因……或者说你找到了吗？
- en: The Curse of Dimensionality
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维度灾难
- en: 'In fact, this is a more non-trivial situation than we have appreciated so far.
    Imagine presenting this to the KPI owner. They will be very happy that you have
    delivered them reasons for the KPI change, and they will now be wondering about
    what to do based on this information. It will automatically lead them to questions
    like the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这种情况比我们目前所理解的要复杂得多。想象一下将这些呈现给 KPI 拥有者。他们会非常高兴你提供了 KPI 变化的原因，他们现在会考虑如何根据这些信息采取行动。这会自动引导他们提出如下问题：
- en: “*Are the actual drivers for the KPI change all android-tv customers, all customers
    older 46, and all customers who made a purchase before? Maybe it could be the
    repeat customers older than 46 and the android-tv customers… or the Android-TV
    customers who purchased something before? Worse, are there maybe other combinations
    of features which you have missed?*”
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: “*KPI 变化的实际驱动因素是否都是 android-tv 用户，都是年龄超过 46 的用户，或者都是之前有购买记录的用户？也许可能是年龄超过 46
    的重复购买用户和 android-tv 用户……或者是之前有购买记录的 android-tv 用户？更糟糕的是，是否还有其他你遗漏的特征组合？*”
- en: '![](../Images/61163868cd07047afeb209817055d2cd.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61163868cd07047afeb209817055d2cd.png)'
- en: '*Figure 5\. Kausa - Because you know better.*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5\. Kausa - 因为你知道得更多。*'
- en: Therefore, to be able to more confidently answer such questions, you would have
    to repeat your regression analysis with more complex one-hot encoded features
    … now representing finer subgroups than before. Thereby, you are searching among
    deeper subgroups of the dataset, see Figure 6, with new features like
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了更自信地回答这些问题，你需要使用更复杂的独热编码特征来重复回归分析……现在代表比之前更细致的子组。这样，你就在更深层次的子组中进行搜索，见图6，新的特征如
- en: '*customer_age = 46+ and first_order_made = yes, customer_age = 18−−21 and first_order_made
    = no.*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*customer_age = 46+ 和 first_order_made = yes，customer_age = 18−−21 和 first_order_made
    = no.*'
- en: Again these subgroups enter via one-hot encoding. This is obviously problematic,
    as you are now falling victim to the *curse of dimensionality*. It is the era
    of big data, and you just increased your number of features by a factorial amount [[2](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#7558d6345a50)]. A
    piece of code that can be used to generate these refined subgroups is
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些子组再次通过独热编码进入。这显然是有问题的，因为你现在陷入了*维度灾难*。这是大数据时代，你刚刚将特征数量增加了一个阶乘量[[2](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#7558d6345a50)]。用于生成这些细化子组的一段代码是
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/130e2a27e777769c746adb14d8cb937a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/130e2a27e777769c746adb14d8cb937a.png)'
- en: '*Figure 6\. Subgroup depth.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6\. 子组深度.*'
- en: Remember that linear regression is based on an inversion of a covariance matrix
    among all features - which scales
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 记住线性回归基于所有特征之间的协方差矩阵的反转——这会随着
- en: '*O(d³),*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*O(d³),*'
- en: with d being the number of features, i.e. in our case the number of possible
    subgroups. This introduces significant opportunity cost in comparison to non-predictive
    feature selection methods - as will be discussed later.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 d 是特征的数量，即在我们的情况下是可能的子组数量。这与非预测性特征选择方法相比引入了显著的机会成本——稍后将讨论。
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*Figure 7\. Feature weights of intersections using one-hot encoding.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7\. 使用独热编码的交集特征权重.*'
- en: After some time, your computation finishes. While your earlier computation took
    just 0.1 seconds, searching for third-order features already took over a minute.
    But it seems to be worth it. You find that the number of groups driving the KPI
    change was actually one, as in Figure 7\. Presenting this insight to your manager,
    he could quickly point to an update that directly affected the subgroup you reported.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，你的计算完成了。虽然早期的计算只需0.1秒，但寻找三阶特征已经花了超过一分钟。但这似乎是值得的。你发现推动KPI变化的群体实际上只有一个，如图7所示。向你的经理展示这一洞察后，他很快指出了一个直接影响你报告的子群体的更新。
- en: By refining the subgroup, you could render it actionable
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过精炼子群体，你可以使其具有可操作性。
- en: While your regression approach finally worked out - it took extremely long to
    compute, resulting in opportunity cost to your company. In a realistic scenario
    of big data, your approach would have failed horribly. Additionally, original
    sets containing only shallow subgroups painted an incorrect picture. Only after
    refining sets and enormous computational effort could you pinpoint the actual
    subgroup that drove the jump in the KPI.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你的回归方法最终奏效了——但计算时间极长，导致了公司机会成本。在大数据的现实场景中，你的方法将会惨遭失败。此外，原始数据集只包含浅层子群体，呈现了不正确的图景。只有在精炼数据集和经过大量计算后，你才找出实际推动KPI跳跃的子群体。
- en: 'This begs several questions:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了几个问题：
- en: Do you actually need to learn a predictive model to answer why the jump happened?
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否真的需要学习一个预测模型来回答跳跃发生的原因？
- en: How can you reduce opportunity costs?
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何减少机会成本？
- en: How can you find subgroups at the appropriate level of granularity?
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何在适当的粒度级别找到子群体？
- en: Is it economical to retrain models at every jump for this piece of information?
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了获取这一信息，在每次跳跃时重新训练模型是否经济？
- en: While answering all these questions is out-of-scope for this post, we will offer
    a new point-of-view that can help to resolve these issues. For this, we will develop
    an approach to feature selection that improves on linear regression.  Augmented
    analytics depends on it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然回答所有这些问题超出了这篇文章的范围，但我们将提供一种新的观点，帮助解决这些问题。为此，我们将开发一种改进线性回归的特征选择方法。增强分析依赖于此。
- en: Learning from Business Analysts and Causal Inference
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从业务分析师和因果推断中学习
- en: Let’s take a step back… what happened here? You started off with a predictive
    model, and you saw that it could neither predict nor explain the observed jump
    in the KPI. Why is that? Because predictive models are unable to capture reality. They
    assume that all data is independently and identically distributed [[3](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#c72ace9e8427)].
    However, in real-life applications, this is often incorrect, as this example shows.
    Data before and after the jump was generated under different conditions. You even
    intuitively made use of this fact, when you used two separate predictive models,
    which (after some tricks) helped us to uncover the reason for that jump.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步看看……这到底发生了什么？你从一个预测模型开始，发现它既无法预测也无法解释观察到的KPI跳跃。为什么会这样？因为预测模型无法捕捉现实。它们假设所有数据是独立同分布的[[3](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#c72ace9e8427)]。然而，现实应用中这通常是不正确的，就像这个例子所示。在跳跃前后的数据是在不同条件下生成的。你甚至直观地利用了这一事实，当你使用两个独立的预测模型时，（经过一些技巧）帮助我们揭示了这个跳跃的原因。
- en: As you had to give up on prediction and ultimately did not predict anything,
    what did the prediction models actually do for you? If you think about it, the
    key is that you are not interested in predicting the KPI as a function of all
    possible subgroups - you are interested in subgroups affecting the KPI! Thus,
    to search for insights at deeper levels, you have to get away from predictive
    modeling. This is where the data scientist can learn from the business analyst.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你不得不放弃预测并且最终没有预测任何东西，那么预测模型实际上对你有什么帮助呢？仔细思考，关键在于你对预测所有可能子群体对KPI的影响并不感兴趣——你真正关心的是子群体对KPI的影响！因此，为了在更深层次上寻找洞察，你必须远离预测建模。这正是数据科学家可以向业务分析师学习的地方。
- en: A business analyst searches for insights through dashboards containing meaningful
    summaries of data. Instead of correlating all features together, as in the regression
    approach above, the business analyst will try to pinpoint what changes happened
    in the data based on summaries (like means, histograms, or metrics) by iteratively
    filtering the data for different conditions. Most importantly, the business analyst
    will never have to look at all features at once. How do you teach a machine to
    do that? How can you learn from a business analyst?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 业务分析师通过包含数据有意义总结的仪表板来寻找洞察。与上述回归方法中将所有特征关联起来不同，业务分析师将尝试通过迭代筛选不同条件下的数据，以总结（如均值、直方图或指标）来确定数据中发生了哪些变化。最重要的是，业务分析师不需要一次查看所有特征。你如何教机器做到这一点？你如何从业务分析师那里学习？
- en: Let us formalise the above in mathematical notation. Let X be a subgroup, e.g.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用数学符号来形式化上述内容。令 X 为一个子群，例如。
- en: '*X = customer_age = 46+ and first_order_made = yes*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*X = customer_age = 46+ 和 first_order_made = yes*'
- en: and
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '*f(KPI[before], KPI[after])*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(KPI[before], KPI[after])*'
- en: some summary of the KPI distributions before and after the jump in the KPI.
    Then, you introduce conditional summaries
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KPI 跳跃前后的 KPI 分布的某些总结。然后，你引入条件总结。
- en: '*f(KPI[before], KPI[after]* ∣ *X)*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(KPI[before], KPI[after]* ∣ *X)*'
- en: where you compute summaries of subsets of KPI values for which X is true. All
    that our method needs to do now, is to compute conditional summaries for each
    subgroup and rank them. I want to stress, that in practice these abstract summaries
    can be objects as means, histograms etc.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你计算 X 为真的 KPI 值子集的总结。我们的方法现在需要做的就是为每个子群计算条件总结并进行排序。我想强调的是，在实践中，这些抽象总结可以是均值、直方图等对象。
- en: The procedure detailed above is actually a common technique from causal inference [[4](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#8dfc0806606a)].
    You thereby implicitly changed our point of view. Now, you consider the mysterious
    jump in the KPI as an intervention that is now assumed to have happened due to
    external or internal *treatments*. An example for an external treatment might
    be the holiday season, an internal treatment might be an ad campaign, a change
    in pricing, or, as in our case, a software update. You are thus explicitly *lifting *the
    wrong assumption that all data is independently and identically distributed. You
    are now searching for subgroups that are *causal* to the change in KPI.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上述程序实际上是因果推断中的一种常见技术[[4](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#8dfc0806606a)]。因此，你隐含地改变了我们的观点。现在，你将
    KPI 中的神秘跳跃视为假设因外部或内部 *处理* 而发生的干预。外部处理的例子可能是节假日，内部处理可能是广告活动、价格变化，或者如我们所示的，软件更新。因此，你显式地
    *提升* 了所有数据独立同分布的错误假设。你现在在寻找对 KPI 变化 *因果* 的子群。
- en: The Quest of Why, Revisited
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重新审视为何的追寻
- en: Now that you have a model of how a business analyst operates, let us proceed
    with the actual implementation. For now, you will use a standard summary used
    in causal inference called Conditional Average Treatment Effect (CATE) [[5](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#cc6447b58903)],
    for which our summary becomes
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了一个关于业务分析师如何操作的模型，让我们继续实际的实现。现在，你将使用一种在因果推断中常用的标准总结，称为条件平均处理效应（CATE）[[5](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#cc6447b58903)]，我们的总结变为
- en: '*f(KPI[before], KPI[after]* ∣ *X) = E*[*KPI[after]* ∣ *X*] *− E*[*KPI[before]*
    ∣ *X*]'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(KPI[before], KPI[after]* ∣ *X) = E*[*KPI[after]* ∣ *X*] *− E*[*KPI[before]*
    ∣ *X*]'
- en: 'The CATE corresponds to the change in the mean of the KPI, conditioned on that
    subgroup X is true. Ranking by magnitude then gives us the correct subgroup as
    a result. To detect multiple subgroups, we repeat this procedure after removing
    the best performing subgroup after each iteration:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: CATE 对应于 KPI 均值的变化，条件是子群 X 为真。按大小排序则给出了正确的子群作为结果。为了检测多个子群，我们在每次迭代后移除表现最好的子群，然后重复这一过程：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Figure 8\. CATE Scores using the one-hot encoding of intersections.*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8\. 使用交集的一热编码的 CATE 分数。*'
- en: This takes a fraction of the cost of our predictive model. The computation for
    first-order features took just 0.02 seconds, searching for third-order features
    took less than a  second.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这只需我们预测模型成本的一小部分。对一阶特征的计算仅花费了 0.02 秒，对三阶特征的搜索则花费了不到一秒钟。
- en: 'Let us take a step back and compare this approach with the earlier one based
    on regression and what their respective objectives are. Feature selection via
    regression answers the question: ” Which subgroups best predict your KPI?”. While
    taking the view of causal inference answers the question: “Which subgroups had
    the biggest causal effect on the KPI?”.  Comparing run-times of a naive implementation
    of CATE with the optimised *sklearn* implementation of linear regression in Figure
    9, we find that they lie order of magnitudes apart. This makes it clear that these
    questions, while superficially similar, have fundamental differences.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，将这种方法与基于回归的早期方法进行比较，并看它们各自的目标是什么。通过回归的特征选择回答了这个问题：“哪些子组最能预测你的 KPI？”。而因果推断的视角则回答了这个问题：“哪些子组对
    KPI 有最大的因果影响？”。通过图9中 CATE 的原始实现与优化后的 *sklearn* 线性回归实现的运行时间比较，我们发现它们的差异量级是不同的。这清楚地表明，这些问题虽然表面上相似，但在根本上有差异。
- en: '*Figure 9\. Log-runtime over subgroup depth of linear regression (sklearn)
    vs. CATE for exhaustive subgroup search.*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9\. 线性回归（sklearn）子组深度与 CATE 的对数运行时间比。*'
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Predictive models have strong shortcomings as means to understand KPI changes,
    especially in multi-dimensional contexts. These models fundamentally answer the
    wrong questions under the wrong assumptions. Instead, business analytics focuses
    on why did something happen rather than what will happen. Having their mind free
    of the auxiliary task of predicting future KPI values, analytics finds reasons
    in the data to understand why the KPI changed, trying to find the answers for
    the right question.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 预测模型在理解 KPI 变化方面存在明显的不足，尤其是在多维背景下。这些模型在错误的假设下根本回答了错误的问题。相反，商业分析关注的是发生了什么而不是将要发生什么。将思维从预测未来
    KPI 值的辅助任务中解放出来，分析通过数据寻找原因，以理解 KPI 变化的原因，试图找到正确问题的答案。
- en: 'Be wary next time you want to explain anything. Firstly, you should ask the
    right question. In addition, multi-dimensional contexts require a scalable technique
    based on causal inference and business analytics methods. This is our mission
    at Kausa: scale business analytics logic and couple it with causal inference to
    provide the right answers to KPI changes.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下次你想解释任何事时要小心。首先，你应该问对的问题。此外，多维背景需要基于因果推断和商业分析方法的可扩展技术。这是我们在 Kausa 的使命：扩展商业分析逻辑，并将其与因果推断结合，以提供
    KPI 变化的正确答案。
- en: '*PS: Code and data to reproduce results from this article are available in
    our GitHub repository [[6](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#5b4e41206487)].*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*PS: 代码和数据以重现本文结果，已在我们的 GitHub 仓库中提供 [[6](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#5b4e41206487)]。*'
- en: '[Original](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland).
    Reposted with permission.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland)。经授权转载。'
- en: '**Bio:** [Michael](https://www.linkedin.com/in/michael-klaput-67375385) [Klaput](https://www.linkedin.com/in/michael-klaput-67375385) is
    the co-founder and CTO at Kausa ([www.kausa.ai](http://www.kausa.ai)), former
    VP Quantitative Analyst at Bank of America Merrill Lynch, and Ph.D. in Theoretical
    Physics Oxford University.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：** [Michael](https://www.linkedin.com/in/michael-klaput-67375385) [Klaput](https://www.linkedin.com/in/michael-klaput-67375385)
    是 Kausa 的联合创始人和 CTO（[www.kausa.ai](http://www.kausa.ai)），曾任美国银行美林证券的量化分析师副总裁，并在牛津大学获得理论物理学博士学位。'
- en: '**Related:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Analytics Engineering Everywhere](https://www.kdnuggets.com/2021/06/analytics-engineering-everywhere.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析工程无处不在](https://www.kdnuggets.com/2021/06/analytics-engineering-everywhere.html)'
- en: '[Why machine learning struggles with causality](https://www.kdnuggets.com/2021/04/machine-learning-struggles-causality.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么机器学习在因果关系上遇到困难](https://www.kdnuggets.com/2021/04/machine-learning-struggles-causality.html)'
- en: '[Must Know for Data Scientists and Data Analysts: Causal Design Patterns](https://www.kdnuggets.com/2021/03/causal-design-patterns.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家和数据分析师必知：因果设计模式](https://www.kdnuggets.com/2021/03/causal-design-patterns.html)'
- en: More On This Topic
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[认识 Gorilla：UC Berkeley 和微软的 API 增强型 LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与…的交汇点](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[Unify Batch and ML Systems with Feature/Training/Inference Pipelines](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过特征/训练/推理管道统一批处理和机器学习系统](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
- en: '[10 Key AI & Data Analytics Trends for 2022 and Beyond](https://www.kdnuggets.com/2021/12/10-key-ai-trends-for-2022.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年及以后10大人工智能和数据分析趋势](https://www.kdnuggets.com/2021/12/10-key-ai-trends-for-2022.html)'
- en: '[Beyond Pipelines: Graphs as Scikit-Learn Metaestimators](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越管道：图作为 Scikit-Learn 元估计器](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
- en: '[Beyond Coding: Why The Human Touch Matters](https://www.kdnuggets.com/beyond-coding-why-the-human-touch-matters)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越编码：为何人性化的触感至关重要](https://www.kdnuggets.com/beyond-coding-why-the-human-touch-matters)'
