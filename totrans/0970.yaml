- en: The Mistake Every Data Scientist Has Made at Least Once
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/09/mistake-every-data-scientist-made-least.html](https://www.kdnuggets.com/2022/09/mistake-every-data-scientist-made-least.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you use a tool where it hasn’t been verified safe, any mess you make is *your* fault… [AI](http://bit.ly/quaesita_donttrust) is
    a tool like any other, so the same rule applies. Never trust it blindly.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, force [machine learning and AI](http://bit.ly/quaesita_emperorm) systems
    to ***earn*** your trust.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to teach with examples, the examples have to be good. If you want
    to trust your student’s ability, the test has to be good.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Always keep in mind that you don’t know anything about the safety of your system
    outside the conditions you checked it in, so check it carefully! Here is a list
    of handy reminders that apply not only to [ML/AI](http://bit.ly/quaesita_emperor) but
    also to *every* solution based on [data](http://bit.ly/quaesita_hist):'
  prefs: []
  type: TYPE_NORMAL
- en: If you didn’t test it, don’t trust it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you didn’t test it in your *environment*, don’t trust it in your *environment*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you didn’t test it with your *user population*, don’t trust it with your *user
    population*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you didn’t test it with your *data population*, don’t trust it with your *data
    population*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*If an *[*input is unusual*](https://bit.ly/mfml_086)*, don’t trust your system
    to output something sensible. Consider using outlier detection and *[*safety nets*](http://bit.ly/quaesita_policy)* (e.g.
    flagging an unusual instance for human review).*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing good tests is what keeps us all safe.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One difference between a data newbie and a [data science](http://bit.ly/quaesita_datascim) expert
    is that the expert has some whopping trust issues… and is happy to have them.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/ff6e1abb94c17c256f50b9fac9a896e0.png)'
  prefs: []
  type: TYPE_IMG
- en: SOURCE: [Pixabay](https://pixabay.com/photos/spider-scary-mistake-hybrid-mouse-2913761/)
  prefs: []
  type: TYPE_NORMAL
- en: The Mistake Experts Make
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our [previous article](http://bit.ly/quaesita_testmistake1), we looked at
    the testing mistake that beginners make and how to avoid it. Now it’s time to
    look at a more insidious mistake that even experts make.
  prefs: []
  type: TYPE_NORMAL
- en: 'For those who haven’t read the [previous article](http://bit.ly/quaesita_testmistake1),
    let’s catch you up on the setup (in a parallel universe where we didn’t make the [newbie
    mistake](http://bit.ly/quaesita_testmistake1), that is):'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/532312a78d2686b8ee83f1e4cc8f1b4d.png)'
  prefs: []
  type: TYPE_IMG
- en: We competently trained a decent [model](http://bit.ly/quaesita_emperorm) using
    70,000 input images (each one you see in the image above is a placeholder that
    stands for 10,000 similar photos with the label Banana, Huxley, or Tesla; one
    of these is my breakfast and the other two are my cats, you figure out which is
    which) and then tested it on 40,000 pristine images.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/602e561aa98b17210928ca7f10d953a8.png)'
  prefs: []
  type: TYPE_IMG
- en: And we get… perfect results! Wow.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/5b895f93c3320a4f7bc284b9fb8148f4.png)'
  prefs: []
  type: TYPE_IMG
- en: When you observe perfect performance on a [machine learning](http://bit.ly/quaesita_emperorm) task,
    you should be very worried indeed. Just as the [previous article](http://bit.ly/quaesita_testmistake1) warned
    you against having the wrong attitude towards 0%, it’s a good habit to smell a
    rat whenever you see *perfect* results. An expert’s first thought would be that
    either the test was much too easy or the labels leaked or the data weren’t as
    pristine as we hoped. Exactly the same thoughts a seasoned college professor would
    have upon discovering that every student answered every question flawlessly. They’d
    be furiously debugging instead of patting themselves on the back for good teaching.
  prefs: []
  type: TYPE_NORMAL
- en: Since 100% isn’t a realistic result for a lifelike scenario, let’s imagine we
    got some other high-but-not-too-high score, say 98%.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/1b568c61e4a41b863007c5fb45543ec4.png)'
  prefs: []
  type: TYPE_IMG
- en: Great performance, right? Sounds like great performance in pristine data to
    boot. With all the [statistical hypothesis testing](http://bit.ly/quaesita_fisher) bells
    and whistles taken care of! We’ve built an awesome Tesla/Huxley detector, let’s
    launch it!!!
  prefs: []
  type: TYPE_NORMAL
- en: Watch out.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll be tempted to jump to conclusions. This might not be a Tes/Hux detector
    at all, even if it gives great results in testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mistake that experts make has less to do with the technical and more to
    do with the human side of things: giving in to wishful thinking.'
  prefs: []
  type: TYPE_NORMAL
- en: Experts aren’t immune to the mistake of wishful thinking.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Don’t assume these results mean anything at all about what the system is *actually* detecting.
    We have no evidence that it has learned — or worse, that “it understands” — how
    to tell Hux and Tes apart. Look closer…
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/210be5351cd4fe060d6a5860ac0887f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Did you notice that little detail that’s present in the background of all photos
    of Tes? Whoops, turns out we accidentally built a radiator / not-radiator classifier!
  prefs: []
  type: TYPE_NORMAL
- en: It’s a very human mistake to over-focus on the parts of the problem and data
    that are interesting to us — like the identity of the two cats — and snooze past
    the other bits, like the presence of the radiator in most of the photos of Tes
    since that’s where she likes to hang out and therefore it’s also where she’s most
    likely to be photographed. Unfortunately, she loves the radiator so much that
    the same issue turns up in both the training data and the test data, so you won’t
    catch the problem by testing on data from the same [population](http://bit.ly/quaesita_vocab) you
    used for training.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Mistake Every Data Scientist Has Made at Least Once](../Images/b2f92b87a1ba16786fc96c50706fbb51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All this is (somewhat) okay as long as you (and your stakeholders and users)
    have the steely discipline of:'
  prefs: []
  type: TYPE_NORMAL
- en: Not reading cute stories into the results, like “This is a Hux/Tes classifier.”
    This kind of language implies something far more general than we have evidence
    for. You’re probably doing it wrong if your understanding of what a machine learning
    system is actually doing fits into a pithy newspaper headline… It should, at a
    minimum, bore you to death with its details.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Staying painfully aware that if there’s a difference between the setting you
    tested your system in and the setting you’re training it in, you have no guarantee
    that your solution will work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This kind of discipline is rare, so until we have better data literacy, all
    I can do is dream big and do my bit for educating people.
  prefs: []
  type: TYPE_NORMAL
- en: This system will only work with photos taken in the same manner as the testing
    and training datasets — photos from the same apartment in the winter, since that’s
    when Tesla tended to hang out by the radiator while Huxley didn’t. If you always
    take photos in the same way and you had a lot of them, who cares how your system
    does the trick of assigning labels as long as it gets you the right ones. If it
    uses the radiator to win at the labeling game, that’s fine… as long as you don’t
    expect it to work in any other context (it won’t). For that, you need better,
    broader training and testing datasets. And if you move the system to a different
    apartment, even if you think you understand how your system works, test it afresh
    anyway to ensure it *still* works.
  prefs: []
  type: TYPE_NORMAL
- en: The world represented by your data is the only one you’re going to succeed in.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Remember, the world represented by your data is the only one you’re going to
    succeed in. So you need to think carefully about the data you’re using.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding the Expert Mistake
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Never assume you understand what an AI system is doing. Believing that your
    simple understanding of a complex thing is bulletproof is the height of arrogance.
    You’ll be punished for it.
  prefs: []
  type: TYPE_NORMAL
- en: Never assume you understand what an AI system is doing. Believing that your
    simple understanding of a complex thing is bulletproof is the height of arrogance.
    You’ll be punished for it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s easy to miss real-world subtleties in your data. No matter how talented
    you are at it, if you work long enough in data science, you’ll almost surely make
    this wishful-thinking mistake at least once until you learn the hard way to severely
    curtail your conclusions — the best habit you can build is to avoid reading extra
    meaning into things until you’ve thoroughly checked the evidence. You’ll know
    you’ve arrived at the next level when your inner monologue about your results
    sounds less like a TED talk and more like the fine-print of the world’s most boring
    contract. This is a good thing. You can dazzle with your fast talk later if you
    insist, just don’t embarrass data literacy by believing your own hyperbolae.
  prefs: []
  type: TYPE_NORMAL
- en: The only thing you can learn from good testing results is that the system works
    well in environments, situations, datasets, and populations that are similar to
    the testing conditions. Any guesses you’d be tempted to make about its performance
    outside those conditions are fiction. Test carefully and don’t jump to conclusions!
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for Reading! How about a YouTube Course?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you had fun here and you’re looking for an applied AI course designed to
    be fun for beginners and experts alike, here’s one I made for your amusement:'
  prefs: []
  type: TYPE_NORMAL
- en: Enjoy the entire course playlist here: [bit.ly/machinefriend](http://bit.ly/machinefriend)
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cassie Kozyrkov](https://kozyrkov.medium.com/)** is a data scientist and
    leader at Google with a mission to democratize Decision Intelligence and safe,
    reliable AI.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://kozyrkov.medium.com/the-mistake-every-data-scientist-has-made-at-least-once-3479002211b4).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Science Has Changed, Not Died!](https://www.kdnuggets.com/2023/08/data-science-changed-died.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Meta’s New Data Analyst Professional Certification Has Dropped!](https://www.kdnuggets.com/metas-new-data-analyst-professional-certification-has-dropped)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Has the Adoption of AI in Algorithmic Trading Affected the…](https://www.kdnuggets.com/2022/04/adoption-ai-algorithmic-trading-affected-finance-industry.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[HuggingFace Has Launched a Free Deep Reinforcement Learning Course](https://www.kdnuggets.com/2022/05/huggingface-launched-free-deep-reinforcement-learning-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Lakes and SQL: A Match Made in Data Heaven](https://www.kdnuggets.com/2023/01/data-lakes-sql-match-made-data-heaven.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
