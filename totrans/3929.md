# 在Python中实现数据预处理的2–6倍加速

> 原文：[https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html](https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

Python 是进行所有机器学习工作的首选编程语言。它易于使用，并拥有许多出色的库，使得数据处理轻松愉快！但是，当处理大量数据时情况就会变得有些复杂……

如今，“大数据”一词通常指的是数据集的规模至少达到数十万，甚至是*百万*的数据点！在这样的规模下，每一点计算都会累积，我们在编写每一步处理程序时需要保持高效。在考虑机器学习系统的效率时，一个常常被忽视的关键步骤是*预处理*阶段，我们必须对所有数据点应用某种操作。

默认情况下，Python程序作为单个进程使用单个CPU执行。大多数现代机器学习机器至少拥有*2*个CPU核心。这意味着，对于2核的例子，当你运行预处理时，50%或更多的计算机处理能力不会被利用！当核心数达到4（现代Intel i5）或6（现代Intel i7）时，情况会变得更糟。

幸运的是，Python内置库中有一个略微隐藏的功能，让我们可以充分利用所有CPU核心！得益于Python的`concurrent.futures`模块，只需3行代码，就能将普通程序转变为能够在CPU核心间并行处理数据的程序。

### 标准方法

让我们以一个简单的例子开始，我们在一个文件夹中有一个图像数据集；也许我们甚至有成千上万张图像！为了处理时间的考虑，我们这里使用1000张。我们希望在将图像传递给我们的深度神经网络之前，将所有图像的尺寸调整为600x600。这是一些你在GitHub上常见的标准Python代码。

这个程序遵循一个在数据处理脚本中常见的简单模式：

1.  你从一个需要处理的文件（或其他数据）列表开始。

1.  你逐个处理每一块数据，使用`for`循环，并在每次循环迭代时运行预处理。

让我们在一个包含1000个jpeg文件的文件夹上测试这个程序，看看运行需要多长时间：

```py
time python standard_res_conversion.py
```

在我的i7–8700k六核CPU上，这个过程花费了**7.9864秒**！对于如此高端的CPU来说，这似乎有点慢。让我们看看如何加快速度。

### 快速方法

要理解我们希望Python如何并行处理事物，直观地考虑并行处理本身会有所帮助。假设我们需要在一块木头上钉入相同的钉子，并且我们有1000个钉子。如果每个钉子需要1秒钟，那么1个人完成这项工作需要1000秒。但如果我们有4个人在团队中，我们将桶中的钉子分成4堆，然后每个人处理自己的一堆钉子。这样，我们只需250秒就能完成！

我们可以让Python在这个例子中对1000张图片做类似的事情：

1.  将jpg文件列表拆分成4个较小的组。

1.  运行4个单独的Python解释器实例。

1.  让每个Python实例处理4个较小的数据组中的一个。

1.  将4个过程的结果结合起来，得到最终的结果列表。

最棒的地方是Python为我们处理所有的繁重工作。我们只需要告诉它我们想运行哪个函数以及要使用多少个Python实例，它就会完成其他所有工作！我们只需更改**3行代码**。

从上面的代码来看：

```py
with concurrent.futures.ProcessPoolExecutor() as executor:
```

启动与你的CPU核心数相同数量的Python进程，在我的情况下是6个。实际的处理行是这一行：

```py
executor.map(load_and_resize, image_files)
```

**executor.map()** 接受你想运行的函数和一个列表作为输入，列表中的每个元素是**函数的单一输入**。由于我们有6个核心，我们将同时处理列表中的6个项目！

如果我们再次运行我们的程序：

```py
time python fast_res_conversion.py
```

我们的运行时间为**1.14265秒**，速度提升了近6倍！

*注意：启动更多Python进程并在它们之间传递数据会有一些开销，因此你不会总是得到如此大的速度提升。但总体而言，你的速度提升通常会相当显著。*

### 是否总是非常快？

使用Python并行池是处理数据列表并对每个数据点执行相似计算的好方法。但是，它并不总是完美的解决方案。并行池处理的数据不会按任何可预测的顺序处理。如果你需要结果按特定顺序处理，那么这个方法可能不适合你。

你处理的数据也需要是Python知道如何“序列化”的类型。幸运的是，这些类型相当常见。来自官方Python文档：

+   `None`、`True` 和 `False`

+   整数、浮点数、复数

+   字符串、字节、字节数组

+   仅包含可序列化对象的元组、列表、集合和字典。

+   在模块的顶层定义的函数（使用`[def](https://docs.python.org/3/reference/compound_stmts.html#def)`，而不是`[lambda](https://docs.python.org/3/reference/expressions.html#lambda)`）

+   在模块的顶层定义的内置函数。

+   在模块的顶层定义的类。

+   类实例的 `[`[__dict__](https://docs.python.org/3/library/stdtypes.html#object.__dict__)` 或调用 `[`__getstate__()](https://docs.python.org/3/library/pickle.html#object.__getstate__)` 的结果是可以 picklable 的（详见 [Pickling 类实例](https://docs.python.org/3/library/pickle.html#pickle-inst)）。

### 喜欢阅读关于极客的内容？

在 [twitter](https://twitter.com/GeorgeSeif94) 上关注我，那里我会发布关于最新最棒的 AI、科技和科学的内容！

**简介: [George Seif](https://towardsdatascience.com/@george.seif94)** 是一名认证的极客和 AI / 机器学习工程师。

[原文](https://towardsdatascience.com/heres-how-you-can-get-a-2-6x-speed-up-on-your-data-pre-processing-with-python-847887e63be5)。经许可转载。

**相关:**

+   [5 个“清晰代码”技巧将极大提高您的生产力](/2018/10/5-clean-code-tips-dramatically-improve-productivity.html)

+   [数据科学家需要了解的5种聚类算法](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)

+   [为回归问题选择最佳的机器学习算法](/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)

* * *

## 我们的前3个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的 IT

* * *

### 更多相关主题

+   [Python 中数据预处理的简易指南](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)

+   [通过这本免费电子书学习数据清理和预处理](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)

+   [掌握数据清理和预处理技术的7个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)

+   [利用 ChatGPT 进行自动化数据清理和预处理](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)

+   [在 Pandas 中清理和预处理文本数据以用于 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)

+   [如何在没有工作经验的情况下获得首份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)
