- en: 7 Steps to Mastering Data Cleaning with Python and Pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握数据清理的7个步骤，使用Python和Pandas
- en: 原文：[https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)
- en: '![7-steps-pandas](../Images/044f1484c6d7a0a69ebf6b54bfd06a62.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![7-steps-pandas](../Images/044f1484c6d7a0a69ebf6b54bfd06a62.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Pandas is the most widely used Python library for data analysis and manipulation.
    But the data that you read from the source often requires a series of data cleaning
    steps—before you can analyze it to gain insights, answer business questions, or
    build machine learning models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是最广泛使用的Python数据分析和操作库。但从源头读取的数据通常需要一系列的数据清理步骤——在你能够分析数据以获得洞察、回答业务问题或构建机器学习模型之前。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This guide breaks down the process of data cleaning with pandas into 7 practical
    steps. We’ll spin up a sample dataset and work through the data cleaning steps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南将数据清理过程拆解为7个实际步骤。我们将创建一个示例数据集并逐步完成数据清理。
- en: Let’s get started!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Spinning Up a Sample DataFrame
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个示例DataFrame
- en: '[Link to Colab Notebook](https://github.com/balapriyac/data-science-tutorials/blob/main/pandas/data_cleaning_with_pandas.ipynb)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[Colab笔记本链接](https://github.com/balapriyac/data-science-tutorials/blob/main/pandas/data_cleaning_with_pandas.ipynb)'
- en: 'Before we get started with the actual data cleaning steps, let''s create pandas
    dataframe with employee records. We’ll use Faker for synthetic data generation.
    So install it first:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始实际的数据清理步骤之前，让我们创建一个包含员工记录的pandas数据框。我们将使用Faker进行合成数据生成。因此，请先安装它：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you’d like, you can follow along with the same example. You can also use
    a dataset of your choice. Here’s the code to generate 1000 records:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，可以跟随相同的示例，也可以使用你选择的数据集。这里是生成1000条记录的代码：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s tweak this dataframe a bit to introduce missing values, duplicate records,
    outliers, and more:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微调整一下这个数据框，以引入缺失值、重复记录、异常值等：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let’s create a dataframe with these records:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个包含这些记录的数据框：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that we set the seed for Faker and not the random module. So there'll be
    some randomness in the records you generate.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们设置的是Faker的种子，而不是随机模块。因此，你生成的记录会有一些随机性。
- en: 'Step 1: Understanding the Data'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：理解数据
- en: '**Step 0 is always to understand the business question/problem that you are
    trying to solve**. Once you know that you can start working with the data you’ve
    read into your pandas dataframe.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**第0步始终是理解你要解决的业务问题/问题**。一旦你知道这一点，你就可以开始处理你已读入pandas数据框的数据。'
- en: But before you can do anything meaningful on the dataset, it’s important to
    first get a high-level overview of the dataset. This includes getting some basic
    information on the different fields and the total number of records, inspecting
    the head of the dataframe, and the like.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 但在你对数据集进行任何有意义的操作之前，首先获取数据集的总体概述是很重要的。这包括获取不同字段的一些基本信息和记录的总数，检查数据框的头部等。
- en: 'Here we run the `info()` method on the dataframe:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们对数据框运行`info()`方法：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And inspect the head of the dataframe:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据框的头部：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![df-head](../Images/27e6ebda1c0d9224cc96b742098b8b2f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![df-head](../Images/27e6ebda1c0d9224cc96b742098b8b2f.png)'
- en: Output of df.head()
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()的输出
- en: 'Step 2: Handling Duplicates'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：处理重复项
- en: Duplicate records are a common problem that skews the results of analysis. So
    we should identify and remove all duplicate records so that we're working with
    only the unique data records.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 重复记录是一个常见问题，会影响分析结果。因此，我们应该识别并删除所有重复记录，以便我们只处理唯一的数据记录。
- en: 'Here’s how we find all the duplicates in the dataframe and then drop all the
    duplicates in place:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何在数据框中查找所有重复项，然后删除所有重复项的方法：
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Step 3: Handling Missing Data'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步：处理缺失数据
- en: Missing data is a common data quality issue in many data science projects. If
    you take a quick look at the result of the `info()` method from the previous step,
    you should see that the number of non-null objects is not identical for all fields,
    and there are missing values in the email column. We’ll get the exact count nonetheless.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据是许多数据科学项目中的常见数据质量问题。如果你快速查看上一步的`info()`方法的结果，你应该会看到非空对象的数量在所有字段中并不相同，并且在电子邮件列中有缺失值。我们仍然会得到准确的计数。
- en: 'To get the number of missing values in each column you can run:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取每列缺失值的数量，你可以运行：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If there are missing values in one or more numeric column, we can apply suitable
    imputation techniques. But because the ''Email'' field is missing, let''s just
    set the missing emails to a placeholder email like so:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个或多个数值列中有缺失值，我们可以应用合适的填补技术。但由于'Email'字段缺失，我们暂时将缺失的电子邮件设置为占位符电子邮件，如下所示：
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Step 4: Transforming Data'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步：数据转换
- en: 'When you’re working on the dataset, there may be one or more fields that do
    not have the expected data type. In our sample dataframe, the ''Join_Date'' field
    has to be cast into a valid datetime object:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理数据集时，可能会有一个或多个字段没有预期的数据类型。在我们的示例数据框中，'Join_Date'字段必须被转换成有效的日期时间对象：
- en: '[PRE12]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Because we have the joining date, it''s actually more helpful to have a `Years_Employed`
    column as shown:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有加入日期，实际上拥有一个`Years_Employed`列会更有帮助，如下所示：
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Step 5: Cleaning Text Data'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步：清理文本数据
- en: It’s quite common to run into string fields with inconsistent formatting or
    similar issues. Cleaning text can be as simple as applying a case conversion or
    as hard as writing a complex regular expression to get the string to the required
    format.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串字段中经常会遇到格式不一致或类似的问题。清理文本可以像应用大小写转换一样简单，也可以像编写复杂的正则表达式以使字符串符合要求格式一样困难。
- en: 'In the example dataframe that we have, we see that the ''Address'' column contains
    many ‘\n’ characters that hinder readability. So let''s replace them with spaces
    like so:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们拥有的示例数据框中，我们看到'地址'列包含许多‘\n’字符，这些字符影响了可读性。所以让我们将它们替换为空格，如下所示：
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Step 6: Handling Outliers'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步：处理异常值
- en: If you scroll back up, you’ll see that we set some of the values in the 'Salary'
    column to be extremely high. Such outliers should also be identified and handled
    appropriately so that they don’t skew the analysis.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你向上滚动，你会看到我们将'薪水'列中的一些值设置得极高。这些异常值也应被识别和适当处理，以免影响分析结果。
- en: 'You’ll often want to factor in *what* makes a data point an outlier (if it’s
    incorrect data entry or if they’re actually valid values and not outliers). You
    may then choose to handle them: drop records with outliers or get the subset of
    rows with outliers and analyze them separately.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常需要考虑*什么*使数据点成为异常值（如果是错误的数据输入，还是它们实际上是有效值而不是异常值）。然后你可以选择处理它们：删除异常值记录或获取包含异常值的行的子集并单独分析。
- en: 'Let''s use the z-score and find those salary values that are more than three
    standard deviations away from the mean:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用z-score找到那些比均值偏离三倍标准差以上的薪资值：
- en: '[PRE18]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Step 7: Merging Data'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7步：合并数据
- en: In most projects, the data that you have may *not* be the data you’ll want to
    use for analysis. You have to find the most relevant fields to use and also merge
    data from other dataframes to get more useful data that you can use for analysis.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数项目中，你拥有的数据可能*不是*你想用于分析的数据。你必须找到最相关的字段并从其他数据框中合并数据，以获得更多有用的数据用于分析。
- en: As a quick exercise, create another related dataframe and merge it with the
    existing dataframe on a common column such that the merge makes sense. Merging
    in pandas works very similarly to joins in SQL, so I suggest you try that as an
    exercise!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个快速练习，创建另一个相关的数据框，并在一个公共列上与现有数据框合并，使合并具有意义。pandas中的合并与SQL中的连接非常相似，因此我建议你将其作为练习尝试！
- en: Wrapping Up
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'That''s all for this tutorial! We created a sample dataframe with records and
    worked through the various data cleaning steps. Here is an overview of the steps:
    understanding the data, handling duplicates, missing values, transforming data,
    cleaning text data, handling outliers, and merging data.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是本教程的全部内容！我们创建了一个包含记录的示例数据框，并逐步完成了各种数据清理步骤。以下是步骤概述：理解数据、处理重复数据、缺失值、数据转换、清理文本数据、处理异常值和合并数据。
- en: If you want to learn all about data wrangling with pandas, check out [7 Steps
    to Mastering Data Wrangling with Pandas and Python](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解关于 pandas 数据整理的所有内容，可以查看 [掌握 Pandas 和 Python 数据整理的 7 个步骤](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python)。
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)
    是来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇点上工作。她的兴趣和专长领域包括 DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和咖啡！目前，她正致力于学习并通过编写教程、操作指南、观点文章等与开发者社区分享她的知识。Bala
    还制作引人入胜的资源概述和编程教程。'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[7 Steps to Mastering Data Wrangling with Pandas and Python](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Pandas 和 Python 数据整理的 7 个步骤](https://www.kdnuggets.com/7-steps-to-mastering-data-wrangling-with-pandas-and-python)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于掌握 SQL、Python、数据清理、数据整理和探索性数据分析的指南合集](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
- en: '[Mastering the Art of Data Cleaning in Python](https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Python 数据清理的艺术](https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python)'
- en: '[KDnuggets™ News 22:n05, Feb 2: 7 Steps to Mastering Machine…](https://www.kdnuggets.com/2022/n05.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n05，2 月 2 日：掌握机器学习的 7 个步骤…](https://www.kdnuggets.com/2022/n05.html)'
- en: '[7 Steps to Mastering Python for Data Science](https://www.kdnuggets.com/2022/06/7-steps-mastering-python-data-science.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据科学 Python 的 7 个步骤](https://www.kdnuggets.com/2022/06/7-steps-mastering-python-data-science.html)'
