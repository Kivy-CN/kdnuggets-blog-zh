- en: A Quick Introduction to Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的快速介绍
- en: 原文：[https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html/3](https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html/3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html/3](https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html/3)
- en: The Multi Layer Perceptron shown in Figure 5 (adapted from Sebastian Raschka's
    [excellent visual explanation of the backpropagation algorithm](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/visual-backpropagation.md))
    has two nodes in the input layer (apart from the Bias node) which take the inputs
    'Hours Studied' and 'Mid Term Marks'. It also has a hidden layer with two nodes
    (apart from the Bias node). The output layer has two nodes as well - the upper
    node outputs the probability of 'Pass' while the lower node outputs the probability
    of 'Fail'.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5 中展示的多层感知器（改编自 Sebastian Raschka 的[优秀的反向传播算法可视化解释](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/visual-backpropagation.md)）在输入层有两个节点（除了偏置节点之外），它们接受输入
    '学习小时数' 和 '期中成绩'。它还具有一个隐藏层，包含两个节点（除了偏置节点之外）。输出层也有两个节点——上面的节点输出 '通过' 的概率，而下面的节点输出
    '失败' 的概率。
- en: In classification tasks, we generally use a [Softmax function](http://cs231n.github.io/linear-classify/#softmax)
    as the Activation Function in the Output layer of the Multi Layer Perceptron to
    ensure that the outputs are probabilities and they add up to 1\. The Softmax function
    takes a vector of arbitrary real-valued scores and squashes it to a vector of
    values between zero and one that sum to one. So, in this case,
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类任务中，我们通常在多层感知器的输出层使用[Softmax 函数](http://cs231n.github.io/linear-classify/#softmax)作为激活函数，以确保输出为概率并且它们的总和为
    1。Softmax 函数将任意实值分数的向量压缩为值在零与一之间的向量，这些值的总和为 1。因此，在这种情况下，
- en: Probability (Pass) + Probability (Fail) = 1
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 概率（通过）+ 概率（失败）= 1
- en: '**Step 1: Forward Propagation**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：前向传播**'
- en: All weights in the network are randomly assigned. Lets consider the hidden layer
    node marked **V** in Figure 5 below. Assume the weights of the connections from
    the inputs to that node are w1, w2 and w3 (as shown).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 网络中的所有权重都是随机分配的。我们考虑下面图 5 中标记为 **V** 的隐藏层节点。假设从输入到该节点的连接权重为 w1、w2 和 w3（如图所示）。
- en: The network then takes the first training example as input (we know that for
    inputs 35 and 67, the probability of Pass is 1).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 网络接着将第一个训练样本作为输入（我们知道，对于输入 35 和 67，Pass 的概率是 1）。
- en: Input to the network = [35, 67]
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络输入 = [35, 67]
- en: Desired output from the network (target) = [1, 0]
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络的期望输出（目标）= [1, 0]
- en: 'Then output V from the node in consideration can be calculated as below (*****f*****
    is an activation function such as sigmoid):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，考虑节点的输出 V 可以如下计算（*****f***** 是一个激活函数，例如 sigmoid）：
- en: V = ***f*** (1*w1 + 35*w2 + 67*w3)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: V = ***f*** (1*w1 + 35*w2 + 67*w3)
- en: Similarly, outputs from the other node in the hidden layer is also calculated.
    The outputs of the two nodes in the hidden layer act as inputs to the two nodes
    in the output layer. This enables us to calculate output probabilities from the
    two nodes in output layer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，隐藏层中其他节点的输出也会被计算出来。隐藏层中两个节点的输出作为输入传递给输出层的两个节点。这使我们能够计算输出层两个节点的输出概率。
- en: Suppose the output probabilities from the two nodes in the output layer are
    0.4 and 0.6 respectively (since the weights are randomly assigned, outputs will
    also be random). We can see that the calculated probabilities (0.4 and 0.6) are
    very far from the desired probabilities (1 and 0 respectively), hence the network
    in Figure 5 is said to have an 'Incorrect Output'.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输出层两个节点的输出概率分别为 0.4 和 0.6（由于权重是随机分配的，输出也将是随机的）。我们可以看到，计算得到的概率（0.4 和 0.6）与期望的概率（分别为
    1 和 0）相差甚远，因此图 5 中的网络被认为有 '不正确的输出'。
- en: '![Screen Shot 2016-08-09 at 11.52.57 PM.png](../Images/03b9ea028c3e2f38889c14e169255473.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-09 at 11.52.57 PM.png](../Images/03b9ea028c3e2f38889c14e169255473.png)'
- en: 'Figure 5: forward propagation step in a multi layer perceptron'
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5：多层感知器中的前向传播步骤
- en: '**Step 2: Back Propagation and Weight Updating**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：反向传播和权重更新**'
- en: We calculate the total error at the output nodes and propagate these errors
    back through the network using Backpropagation to calculate the *gradients*. Then
    we use an optimization method such as *Gradient Descent* to 'adjust' **all** weights
    in the network with an aim of reducing the error at the output layer. This is
    shown in the Figure 6 below (ignore the mathematical equations in the figure for
    now).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算输出节点的总误差，并通过反向传播将这些误差传递回网络，以计算*梯度*。然后，我们使用诸如*梯度下降*之类的优化方法来“调整”**所有**网络中的权重，旨在减少输出层的错误。下图6展示了这一过程（暂时忽略图中的数学方程式）。
- en: Suppose that the new weights associated with the node in consideration are w4,
    w5 and w6 (after Backpropagation and adjusting weights).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设考虑的节点的新权重是w4、w5和w6（经过反向传播和调整权重后）。
- en: '![Screen Shot 2016-08-09 at 11.53.06 PM.png](../Images/658b72bb9d8a4b1f43dc9feaf05e91ef.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-09 at 11.53.06 PM.png](../Images/658b72bb9d8a4b1f43dc9feaf05e91ef.png)'
- en: 'Figure 6: backward propagation and weight updation step in a multi layer perceptron'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6：多层感知器中的反向传播和权重更新步骤
- en: If we now input the same example to the network again, the network should perform
    better than before since the weights have now been adjusted to minimize the error
    in prediction. As shown in Figure 7, the errors at the output nodes now reduce
    to [0.2, -0.2] as compared to [0.6, -0.4] earlier. This means that our network
    has learned to correctly classify our first training example.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在将相同的示例再次输入网络，由于权重已经调整以最小化预测错误，网络的表现应该比之前更好。如图7所示，输出节点的错误现在减少到[0.2, -0.2]，而之前为[0.6,
    -0.4]。这意味着我们的网络已经学会了正确分类第一个训练示例。
- en: '![Screen Shot 2016-08-09 at 11.53.15 PM.png](../Images/b303562a02f5729aa8178e2433fb4808.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-09 at 11.53.15 PM.png](../Images/b303562a02f5729aa8178e2433fb4808.png)'
- en: 'Figure 7: the MLP network now performs better on the same input'
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7：MLP网络现在在相同输入下表现更好
- en: We repeat this process with all other training examples in our dataset. Then,
    our network is said to have *learned* those examples.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用数据集中所有其他训练示例重复这个过程。然后，我们的网络被认为已经*学习*了这些示例。
- en: If we now want to predict whether a student studying 25 hours and having 70
    marks in the mid term will pass the final term, we go through the forward propagation
    step and find the output probabilities for Pass and Fail.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在想预测一个学生在期中考试中获得70分且学习25小时是否能通过期末考试，我们将进行前向传播步骤，并找出通过和未通过的输出概率。
- en: I have avoided mathematical equations and explanation of concepts such as 'Gradient
    Descent' here and have rather tried to develop an intuition for the algorithm.
    For a more mathematically involved discussion of the Backpropagation algorithm,
    refer to [this link](http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里避免了数学方程式和像“梯度下降”这样的概念解释，而是尝试为算法发展直观理解。有关反向传播算法的更数学化讨论，请参阅 [此链接](http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html)。
- en: 3d Visualization of a Multi Layer Perceptron
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多层感知器的3D可视化
- en: Adam Harley has created a [3d visualization](http://scs.ryerson.ca/~aharley/vis/fc/)
    of a Multi Layer Perceptron which has already been trained (using Backpropagation)
    on the MNIST Database of handwritten digits.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Adam Harley 创建了一个 [3D 可视化](http://scs.ryerson.ca/~aharley/vis/fc/) 的多层感知器，该网络已经在
    MNIST 手写数字数据库上经过训练（使用反向传播）。
- en: The network takes 784 numeric pixel values as inputs from a 28 x 28 image of
    a handwritten digit (it has 784 nodes in the Input Layer corresponding to pixels).
    The network has 300 nodes in the first hidden layer, 100 nodes in the second hidden
    layer, and 10 nodes in the output layer (corresponding to the 10 digits) [15].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 网络从28 x 28的手写数字图像中接受784个数值像素作为输入（它在输入层中有784个节点对应像素）。网络在第一个隐藏层中有300个节点，在第二个隐藏层中有100个节点，在输出层中有10个节点（对应10个数字）[15]。
- en: Although the network described here is much larger (uses more hidden layers
    and nodes) compared to the one we discussed in the previous section, all computations
    in the forward propagation step and backpropagation step are done in the same
    way (at each node) as discussed before.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这里描述的网络比我们在上一节讨论的网络要大得多（使用了更多隐藏层和节点），但前向传播步骤和反向传播步骤中的所有计算（在每个节点）都是以之前讨论的相同方式进行的。
- en: Figure 8 shows the network when the input is the digit '5'.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图8 显示了输入为数字 '5' 时的网络。
- en: '![Screen Shot 2016-08-09 at 5.45.34 PM.png](../Images/c07f23238abc74838a1b91b796fb316c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-09 at 5.45.34 PM.png](../Images/c07f23238abc74838a1b91b796fb316c.png)'
- en: 'Figure 8: visualizing the network for an input of ''5'''
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图8: 可视化输入为''5''的网络'
- en: A node which has a higher output value than others is represented by a brighter
    color. In the Input layer, the bright nodes are those which receive higher numerical
    pixel values as input. Notice how in the output layer, the only bright node corresponds
    to the digit 5 (it has an output probability of 1, which is higher than the other
    nine nodes which have an output probability of 0). This indicates that the MLP
    has correctly classified the input digit. I highly recommend playing around with
    this visualization and observing connections between nodes of different layers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 输出值高于其他节点的节点用较亮的颜色表示。在输入层中，亮节点是那些接收到较高数值像素输入的节点。注意，在输出层中，唯一的亮节点对应于数字5（其输出概率为1，比其他九个节点的输出概率0更高）。这表明MLP正确地对输入数字进行了分类。我强烈建议玩弄这个可视化并观察不同层节点之间的连接。
- en: Deep Neural Networks
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: '[What is the difference between deep learning and usual machine learning?](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[深度学习与普通机器学习有何区别？](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)'
- en: '[What is the difference between a neural network and a deep neural network?](http://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network?rq=1)'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络与深度神经网络有什么不同？](http://stats.stackexchange.com/questions/182734/what-is-the-difference-between-a-neural-network-and-a-deep-neural-network?rq=1)'
- en: '[How is deep learning different from multilayer perceptron?](https://www.quora.com/How-is-deep-learning-different-from-multilayer-perceptron)'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[深度学习与多层感知机有何不同？](https://www.quora.com/How-is-deep-learning-different-from-multilayer-perceptron)'
- en: Conclusion
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结论
- en: I have skipped important details of some of the concepts discussed in this post
    to facilitate understanding. I would recommend going through [Part1](http://cs231n.github.io/neural-networks-1/),
    [Part2](http://cs231n.github.io/neural-networks-2/), [Part3](http://cs231n.github.io/neural-networks-3/)
    and [Case Study](http://cs231n.github.io/neural-networks-case-study/) from Stanford's
    Neural Network tutorial for a thorough understanding of Multi Layer Perceptrons.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便理解，我略去了本文讨论的一些重要细节。我建议查阅斯坦福大学的神经网络教程中的[第1部分](http://cs231n.github.io/neural-networks-1/)、[第2部分](http://cs231n.github.io/neural-networks-2/)、[第3部分](http://cs231n.github.io/neural-networks-3/)以及[案例研究](http://cs231n.github.io/neural-networks-case-study/)以全面了解多层感知机。
- en: Let me know in the comments below if you have any questions or suggestions!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或建议，请在下面的评论中告诉我！
- en: 'Bio: [![ujjwal-karn-150](../Images/a2ca7f20cf4747d5e6567bb0a4741fcc.png)Ujjwal
    Karn](https://ujjwalkarn.me/) has 3 years of industry and research experience
    in machine learning and is interested in practical applications of deep learning
    to language and vision understanding.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '简介: [![ujjwal-karn-150](../Images/a2ca7f20cf4747d5e6567bb0a4741fcc.png)Ujjwal
    Karn](https://ujjwalkarn.me/) 具有3年的机器学习行业和研究经验，感兴趣于深度学习在语言和视觉理解中的实际应用。'
- en: References
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Artificial Neuron Models](https://www.willamette.edu/~gorr/classes/cs449/ann-overview.html)'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[人工神经元模型](https://www.willamette.edu/~gorr/classes/cs449/ann-overview.html)'
- en: '[Neural Networks Part 1: Setting up the Architecture (Stanford CNN Tutorial)](http://cs231n.github.io/neural-networks-1/)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络第1部分：设置架构（斯坦福CNN教程）](http://cs231n.github.io/neural-networks-1/)'
- en: '[Wikipedia article on Feed Forward Neural Network](https://en.wikipedia.org/wiki/Feedforward_neural_network)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[前馈神经网络的维基百科文章](https://en.wikipedia.org/wiki/Feedforward_neural_network)'
- en: '[Wikipedia article on Perceptron](https://en.wikipedia.org/wiki/Perceptron)'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[感知机的维基百科文章](https://en.wikipedia.org/wiki/Perceptron)'
- en: '[Single-layer Neural Networks (Perceptrons)](http://computing.dcu.ie/~humphrys/Notes/Neural/single.neural.html)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[单层神经网络（感知机）](http://computing.dcu.ie/~humphrys/Notes/Neural/single.neural.html)'
- en: '[Single Layer Perceptrons](http://www.cs.stir.ac.uk/courses/ITNP4B/lectures/kms/2-Perceptrons.pdf)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[单层感知机](http://www.cs.stir.ac.uk/courses/ITNP4B/lectures/kms/2-Perceptrons.pdf)'
- en: '[Weighted Networks – The Perceptron](http://page.mi.fu-berlin.de/rojas/neural/chapter/K3.pdf)'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[加权网络 – 感知机](http://page.mi.fu-berlin.de/rojas/neural/chapter/K3.pdf)'
- en: '[Neural network models (supervised) (scikit learn documentation)](http://scikit-learn.org/dev/modules/neural_networks_supervised.html)'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络模型（监督学习）（scikit-learn文档）](http://scikit-learn.org/dev/modules/neural_networks_supervised.html)'
- en: '[What does the hidden layer in a neural network compute?](http://stats.stackexchange.com/a/63163/53914)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络中的隐藏层计算了什么？](http://stats.stackexchange.com/a/63163/53914)'
- en: '[How to choose the number of hidden layers and nodes in a feedforward neural
    network?](http://stats.stackexchange.com/a/1097/53914)'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[如何选择前馈神经网络中的隐藏层数量和节点数量？](http://stats.stackexchange.com/a/1097/53914)'
- en: '[Crash Introduction to Artificial Neural Networks](http://ulcar.uml.edu/~iag/CS/Intro-to-ANN.html)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[人工神经网络速成简介](http://ulcar.uml.edu/~iag/CS/Intro-to-ANN.html)'
- en: '[Why the BIAS is necessary in ANN? Should we have separate BIAS for each layer?](http://stackoverflow.com/questions/7175099/why-the-bias-is-necessary-in-ann-should-we-have-separate-bias-for-each-layer)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[为什么在人工神经网络中需要偏置？我们是否需要为每一层设置单独的偏置？](http://stackoverflow.com/questions/7175099/why-the-bias-is-necessary-in-ann-should-we-have-separate-bias-for-each-layer)'
- en: '[Basic Neural Network Tutorial – Theory](https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/)'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[基础神经网络教程 – 理论](https://takinginitiative.wordpress.com/2008/04/03/basic-neural-network-tutorial-theory/)'
- en: '[Neural Networks Demystified (Video Series): Part 1, Welch Labs @ MLconf SF](https://www.youtube.com/watch?v=5MXp9UUkSmc)'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络揭秘（视频系列）：第 1 部分，Welch 实验室 @ MLconf SF](https://www.youtube.com/watch?v=5MXp9UUkSmc)'
- en: A. W. Harley, "An Interactive Node-Link Visualization of Convolutional Neural
    Networks," in ISVC, pages 867-877, 2015 ([link](http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf))
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A. W. Harley, "卷积神经网络的交互式节点-链接可视化," 见 ISVC, 页码 867-877, 2015 ([链接](http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf))
- en: '[Original](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/).'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)。'
- en: '* * *'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Quick Data Science Tips and Tricks to Learn SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速数据科学技巧与窍门：学习 SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
- en: '[7 Pandas Plotting Functions for Quick Data Visualization](https://www.kdnuggets.com/7-pandas-plotting-functions-for-quick-data-visualization)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7 个 Pandas 绘图函数以快速数据可视化](https://www.kdnuggets.com/7-pandas-plotting-functions-for-quick-data-visualization)'
- en: '[A Quick Overview of Voronoi Diagrams](https://www.kdnuggets.com/2022/11/quick-overview-voronoi-diagrams.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Voronoi 图的快速概述](https://www.kdnuggets.com/2022/11/quick-overview-voronoi-diagrams.html)'
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速指南：如何找到合适的注释专家](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的可解释神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引领我们走向 AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
