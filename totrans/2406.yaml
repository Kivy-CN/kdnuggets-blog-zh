- en: 'Linear Machine Learning Algorithms: An Overview'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性机器学习算法概述
- en: 原文：[https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html](https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html](https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html)
- en: '![Linear Machine Learning Algorithms: An Overview](../Images/cb7968557a2d010de52004b42d71d535.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![线性机器学习算法概述](../Images/cb7968557a2d010de52004b42d71d535.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'Linear machine learning algorithms assume a linear relationship between the
    features and the target variable. In this article, we’ll discuss several linear
    algorithms and their concepts. Here’s a glimpse into what you can expect to learn:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 线性机器学习算法假设特征与目标变量之间存在线性关系。在本文中，我们将讨论几种线性算法及其概念。以下是你可以期待学习的内容：
- en: Types of linear ML algorithms.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性机器学习算法的类型。
- en: Assumptions of linear algorithms.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性算法的假设。
- en: The difference between various linear machine learning algorithms.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种线性机器学习算法之间的差异。
- en: How to interpret the results of linear algorithms.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何解读线性算法的结果。
- en: When to use different linear algorithms.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时使用不同的线性算法。
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT工作'
- en: '* * *'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Let’s dive right in.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接深入探讨吧。
- en: Types of Linear Machine Learning Algorithms
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性机器学习算法的类型
- en: You can use linear algorithms for classification and regression problems. Let’s
    start by looking at different algorithms and what problems they solve.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将线性算法用于分类和回归问题。让我们开始了解不同的算法以及它们解决的问题。
- en: Linear regression
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归
- en: Linear regression is arguably one of the oldest and most popular algorithms.
    With roots in the statistics world, the algorithm is used for solving regression
    problems. This means that the final output of the model is a numeric value. The
    algorithm maps a linear relationship between the input features(X) and the output
    (y).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归可以说是最古老也是最流行的算法之一。该算法源于统计学领域，用于解决回归问题。这意味着模型的最终输出是一个数值。该算法映射了输入特征（X）与输出（y）之间的线性关系。
- en: The [Ordinary least squares Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
    is one the most widely used implementations of linear regression. It fits a linear
    model with coefficients `w = (w1, …, wp) to minimize the residual sum of squares
    between the observed targets in the dataset and the targets predicted by the linear
    approximation`. [Source](https://scikit-
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[普通最小二乘线性回归](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)是线性回归中最广泛使用的实现之一。它拟合一个具有系数`w
    = (w1, …, wp)的线性模型，以最小化数据集中观察到的目标与线性近似预测的目标之间的残差平方和`。[来源](https://scikit-'
- en: learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html）。
- en: In this approach, multiple lines are fitted, and the one that returns the least
    error is taken as the **best fit**. The error is the difference between the estimated
    value and the actual value.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，拟合了多条直线，并选择返回误差最小的直线作为**最佳拟合**。误差是估计值与实际值之间的差异。
- en: Since linear regression fits a line, it can extrapolate to future data, unlike
    other algorithms such as random forests. Tree-based algorithms can not predict
    values outside the given data because their predictions are based on the mean
    of the predictions of different decision trees.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线性回归拟合的是一条直线，它可以对未来的数据进行外推，这不同于如随机森林等其他算法。基于树的算法无法预测给定数据之外的值，因为它们的预测基于不同决策树预测值的均值。
- en: '![Linear regression](../Images/e7715eb95f29003470d7588229bcecb1.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归](../Images/e7715eb95f29003470d7588229bcecb1.png)'
- en: '[Residuals for Linear Regression Fit](https://commons.wikimedia.org/wiki/File:Residuals_for_Linear_Regression_Fit.png)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[线性回归拟合的残差](https://commons.wikimedia.org/wiki/File:Residuals_for_Linear_Regression_Fit.png)'
- en: 'For example, when predicting the price of a commodity, a line is fitted between
    the independent and dependent variables. The general equation of a linear regression
    line looks like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当预测商品价格时，会在自变量和因变量之间拟合一条直线。线性回归线的一般方程如下：
- en: 'where:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: c is the intercept, that is, the value of y when x is zero.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: c 是截距，即当 x 为零时 y 的值。
- en: m is the slope of the line.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: m 是直线的斜率。
- en: x is the independent variable.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x 是自变量。
- en: y is the dependent variable.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y 是因变量。
- en: 'Other linear regression algorithms include:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其他线性回归算法包括：
- en: '[**Lasso regression**](https://scikit-learn.org/stable/modules/linear_model.html#lasso)
    a linear model that introduces the ***L1 regularization*** whose objective is
    to minimize the absolute sum of the coefficients. In this algorithm, the weights
    of insignificant features are driven to zero. Hence insignificant features are
    dropped from the linear equation making the final equation simpler.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**套索回归**](https://scikit-learn.org/stable/modules/linear_model.html#lasso)
    是一种引入了***L1正则化***的线性模型，其目标是最小化系数的绝对和。在此算法中，不重要特征的权重被驱动到零。因此，不重要的特征会从线性方程中去除，使最终方程更简单。'
- en: '[**Ridge regression**](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)
    whose coefficients minimize a penalized residual sum of squares. This regularization
    is referred to as ***L2 regularization***. In this algorithm, the weights of insignificant
    features are reduced to small numbers close to zero but not zero. This is handy
    for trimming coefficients while keeping all features while adjusting the weights
    accordingly.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**岭回归**](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression)
    的系数最小化了一个带惩罚的残差平方和。此正则化被称为***L2正则化***。在此算法中，不重要特征的权重被减少到接近零的小数值，但不会完全为零。这对于修剪系数同时保留所有特征并相应调整权重非常有用。'
- en: Assumptions of linear regression
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归的假设
- en: 'Linear regression is sensitive to outliers in the data. Other items to look
    out for include:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归对数据中的异常值非常敏感。其他需要注意的事项包括：
- en: The data has a normal distribution.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据呈正态分布。
- en: That the relationship between the input variables and the output is linear.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入变量和输出之间的关系是线性的。
- en: The variables are not highly correlated. In the event of this occurrence, remove
    highly correlated variables.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量之间的相关性不高。如果出现这种情况，请去除高度相关的变量。
- en: Standardizing or normalizing the data also doesn’t hurt the algorithm!
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化或归一化数据也不会对算法造成伤害！
- en: Logistic Regression
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is a linear model for classification problems. It generates
    a probability between 0 and 1\. This happens by fitting a [logistic function,
    also known as the sigmoid function.](https://en.wikipedia.org/wiki/Logistic_function)
    The function is responsible for mapping the predicted values to numbers between
    0 and 1.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种用于分类问题的线性模型。它生成一个介于 0 和 1 之间的概率。这是通过拟合一个 [逻辑函数，也称为 sigmoid 函数](https://en.wikipedia.org/wiki/Logistic_function)
    实现的。该函数负责将预测值映射到介于 0 和 1 之间的数字。
- en: '![Logistic regression](../Images/b2a09333fc8a8e506d0da6a66f57387f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归](../Images/b2a09333fc8a8e506d0da6a66f57387f.png)'
- en: The Logistic Function | [Image source](https://christophm.github.io/interpretable-ml-book/images/logistic-function-1.png)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Logistic 函数 | [图像来源](https://christophm.github.io/interpretable-ml-book/images/logistic-function-1.png)
- en: When used for multi-class classification, it is referred to as multinomial regression.
    This is done by adjusting the logistic regression algorithm to predict a multinormal
    distribution. It is achieved by changing the loss function used to train the model
    from log-loss to cross-entropy loss. The algorithm is also altered to output a
    probability for each class instead of a single probability.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当用于多类别分类时，称为多项式回归。这是通过调整逻辑回归算法来预测一个多项分布来实现的。通过将训练模型所用的损失函数从对数损失更改为交叉熵损失来实现。同时，算法也被修改为为每个类别输出一个概率，而不是单一的概率。
- en: One of the most popular implementations of Logistic Regression is done in [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).
    This implementation handles imbalanced datasets by setting the `class_weight`
    parameter to `balanced.` In this case, the algorithm will adjust the weights to
    give more importance to the class with fewer samples, enabling the algorithm to
    learn more from that class.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归最受欢迎的实现之一是在[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)中完成的。该实现通过将`class_weight`参数设置为`balanced`来处理不平衡数据集。在这种情况下，算法将调整权重以给予样本较少的类别更多的权重，从而使算法能从该类别中学到更多。
- en: '**Logistic regression assumptions**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归假设**'
- en: Logistic regression algorithm assumptions are similar to those of linear regression. 
    The unique addition here is that the algorithm expects the target variable to
    be categorical.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归算法的假设类似于线性回归的假设。这里的独特之处在于，该算法期望目标变量是分类的。
- en: Support Vector Machines
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Support Vector Machines(SVM) is a supervised machine learning algorithm that
    can be used for regression and classification problems. It is mostly used for
    classification.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）是一种监督式机器学习算法，可用于回归和分类问题。它主要用于分类。
- en: Linear SVM is used when data is linearly separable. In this case, the data is
    easily separated using a single line.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据线性可分时使用线性SVM。在这种情况下，数据可以通过一条直线轻松分隔。
- en: Classification is done by finding the hyperplane that best separates the two
    categories. SVM uses extreme data points in creating decision boundaries. These
    extreme data points are referred to as ***support vectors***, hence the name Support
    Vector Machines.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是通过找到最佳分隔两个类别的超平面来完成的。SVM使用极端数据点来创建决策边界。这些极端数据点被称为***支持向量***，因此得名支持向量机。
- en: '![Support Vector Machines](../Images/a568d50869df8b516cb48fa4688edb92.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![支持向量机](../Images/a568d50869df8b516cb48fa4688edb92.png)'
- en: '[Support Vector Machine model. Support vectors are created to maximize the
    separation between two groups](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/800px-Svm_separating_hyperplanes_%28SVG%29.svg.png).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[支持向量机模型。支持向量被创建以最大化两个组之间的分隔](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/800px-Svm_separating_hyperplanes_%28SVG%29.svg.png)。'
- en: The distance between the vectors is known as a ***margin***. The algorithm works
    by maximizing the gap between the two categories––the margin.  The ***optimal
    hyperplane*** is the hyperplane with the maximum margin.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 向量之间的距离称为***间隔***。该算法通过最大化两个类别之间的间隙——即间隔来工作。***最优超平面***是具有最大间隔的超平面。
- en: '![Maximum-margin hyperplane and margin for an SVM trained on two classes.](../Images/4dc921330b99b4983a2477f5d7cc3058.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![SVM在两个类别上训练得到的最大间隔超平面和间隔。](../Images/4dc921330b99b4983a2477f5d7cc3058.png)'
- en: '[Maximum-margin hyperplane and margin for an SVM trained on two classes.](https://commons.wikimedia.org/wiki/File:SVM_margin.png)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[SVM在两个类别上训练得到的最大间隔超平面和间隔。](https://commons.wikimedia.org/wiki/File:SVM_margin.png)'
- en: SVM can also compute boundaries for non-linear classification through a technique
    known as the ***kernel trick***. It works by adding a third dimension and separating
    the data points in a 3D space.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: SVM还可以通过一种称为***核技巧***的技术计算非线性分类的边界。它通过添加第三维度并在3D空间中分隔数据点来工作。
- en: '![An illustration of kernel trick in SVM](../Images/5a6183e7b8cbdeed889cd6c6e15b3bd3.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![SVM中的核技巧示意图](../Images/5a6183e7b8cbdeed889cd6c6e15b3bd3.png)'
- en: '[An illustration of kernel trick in SVM](https://commons.wikimedia.org/wiki/File:Kernel_trick_idea.svg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[SVM中的核技巧示意图](https://commons.wikimedia.org/wiki/File:Kernel_trick_idea.svg)'
- en: Difference Between SVM, Linear, and Logistic Regression
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM、线性回归和逻辑回归之间的区别
- en: A linear regression algorithm is different from logistic regression in that
    the logistic regression outputs probabilities. Hence, the logistic regression
    algorithm can be used for classification while the linear regression algorithm
    can’t. While the logistic regression algorithm output values between 0 and 1,
    the linear regression algorithm will extrapolate and output values above and below
    zero.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归算法与逻辑回归的不同在于逻辑回归输出概率。因此，逻辑回归算法可用于分类，而线性回归算法则不能。逻辑回归算法输出0到1之间的值，而线性回归算法则会外推并输出零以上或以下的值。
- en: SVM is more memory efficient because it uses a subset of the training data in
    the decision function. Unlike the logistic regression algorithm, SVM doesn’t provide
    probability estimates. SVM is also not prone to outliers like logistic regression
    because it is mainly concerned with the data points closest to the hyperplanes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: SVM更具内存效率，因为它在决策函数中使用了训练数据的一个子集。与逻辑回归算法不同，SVM不提供概率估计。SVM也不像逻辑回归那样容易受到异常值的影响，因为它主要关注的是最接近超平面的数据点。
- en: 'Interpreting Linear Algorithm Results: Summary Statistics'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性算法结果解释：汇总统计
- en: A linear regression outputs a coefficient for each independent variable. Let’s
    take an example of an independent variable X1 used to predict the price of a commodity.
    If the coefficient of X1 is 6.2, it can be interpreted as follows; when all factors
    are held constant, a one-unit increase in F1 will lead to a  6.2 increase in the
    commodity's price.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归输出每个自变量的系数。以一个用来预测商品价格的自变量X1为例。如果X1的系数是6.2，可以这样解释：在所有因素保持不变的情况下，X1每增加一个单位，商品价格将增加6.2。
- en: A logistic regression algorithm outputs the probability of an item belonging
    to a certain class. Therefore, interpreting the results is done by setting a threshold
    of 0.5 to separate the two classes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归算法输出一个项目属于某个类别的概率。因此，通过设置0.5的阈值来解释结果，从而分隔这两个类别。
- en: Given a certain dataset with two classes, the SVM algorithm will predict the
    class an item belongs to by computing the best hyperplane. It does not compute
    any probabilities but uses the distance of the data points from the optimal hyperplane
    to separate the categories.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个包含两个类别的数据集，SVM算法将通过计算最佳超平面来预测项目属于哪个类别。它不计算任何概率，而是使用数据点与最优超平面的距离来分隔类别。
- en: When to Use Logistic Regression vs. Support Vector Machines
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用逻辑回归与支持向量机
- en: Logistic regression and Support Vector Machines are two popular algorithms in
    classification. However, in certain situations, you might prefer one over the
    other. For instance, it’s better to use SVM when there are outliers because they
    don’t affect how the algorithm separates the two classes. SVM is also a better
    choice when the data is of high dimension.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归和支持向量机是分类中两种流行的算法。然而，在某些情况下，你可能会偏好其中一个。例如，当存在异常值时，使用SVM更好，因为它们不会影响算法如何分离两个类别。SVM在数据维度较高时也是更好的选择。
- en: Logistic regression is a better choice when classes are not well separated.
    Otherwise, use SVM. However, it’s common to start with a logistic regression model
    to create a baseline model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当类别没有很好地分离时，逻辑回归是更好的选择。否则，使用支持向量机（SVM）。不过，通常会先使用逻辑回归模型来创建基线模型。
- en: Final Thoughts
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: Linear algorithms are quite popular in machine learning. In this article, we
    have looked at a couple of linear models and their inner workings. We have also
    talked about when you would prefer one over the other. Generally, the choice of
    algorithm will depend on the problem and the dataset.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 线性算法在机器学习中非常流行。在这篇文章中，我们探讨了几种线性模型及其内部工作原理。我们还讨论了何时偏好使用其中一种算法。一般来说，算法的选择将依赖于问题和数据集。
- en: Resources
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Regularization for sparsity](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[稀疏性正则化](https://developers.google.com/machine-learning/crash-course/regularization-for-sparsity/l1-regularization)'
- en: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** is experienced
    in data science, machine learning, and deep learning with a keen eye for building
    machine learning communities.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**[德里克·穆伊提](https://www.linkedin.com/in/mwitiderrick/)** 在数据科学、机器学习和深度学习方面经验丰富，并且在构建机器学习社区方面具有敏锐的眼光。'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[Understanding Machine Learning Algorithms: An In-Depth Overview](https://www.kdnuggets.com/understanding-machine-learning-algorithms-an-indepth-overview)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解机器学习算法：深入概述](https://www.kdnuggets.com/understanding-machine-learning-algorithms-an-indepth-overview)'
- en: '[Data Labeling for Machine Learning: Market Overview, Approaches, and Tools](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习数据标注：市场概述、方法和工具](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)'
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习评估指标：理论与概述](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
- en: '[Top 3 Free Resources to Learn Linear Algebra for Machine Learning](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习机器学习线性代数的三大免费资源](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的主要监督学习算法](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
