- en: How Retrieval Augment Generation Makes LLMs Smarter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何检索增强生成使LLM变得更聪明
- en: 原文：[https://www.kdnuggets.com/how-retrieval-augment-generation-makes-llms-smarter](https://www.kdnuggets.com/how-retrieval-augment-generation-makes-llms-smarter)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/how-retrieval-augment-generation-makes-llms-smarter](https://www.kdnuggets.com/how-retrieval-augment-generation-makes-llms-smarter)
- en: '![How Retrieval Augment Generation Makes LLMs Smarter Than Before](../Images/ab38ea2eabccfbf98ef8e8a9dc26f39b.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何检索增强生成使LLM变得比以往更聪明](../Images/ab38ea2eabccfbf98ef8e8a9dc26f39b.png)'
- en: Ideal Generative AI vs. Reality
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理想生成型AI vs. 现实
- en: Foundational LLMs have read every byte of text they could find and their chatbot
    counterparts can be prompted to have intelligent conversations and be asked to
    perform specific tasks. Access to comprehensive information is democratized; No
    more figuring out the right keywords to search or picking sites to read from.
    However, LLMs are prone to rambling and generally respond with the statistically
    most probable response you’d want to hear ([sycophancy](https://arxiv.org/abs/2310.13548))
    an inherent result of the transformer model. Extracting 100% accurate information
    out of an LLM’s knowledge base doesn’t always yield trustworthy results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 基础的LLM（大规模语言模型）已经阅读了它们能找到的每一个字节的文本，它们的聊天机器人对等体可以被提示进行智能对话，并被要求执行特定任务。获取全面的信息已经实现了民主化；不再需要找出正确的搜索关键词或挑选阅读的网站。然而，LLM容易唠叨，并且通常会以统计上最可能的回应来回答你想听的内容（[谄媚](https://arxiv.org/abs/2310.13548)），这是变压器模型的固有结果。从LLM的知识库中提取100%准确的信息并不总是能得到可信的结果。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Chat LLMs are infamous for making up citations to scientific papers or court
    cases that don’t exist. [Lawyers filing a suit against an airline ](https://www.theguardian.com/technology/2023/jun/23/two-us-lawyers-fined-submitting-fake-court-citations-chatgpt)included
    citations to court cases that never actually happened. [A 2023 study reported](https://arxiv.org/abs/2309.09401),
    that when ChatGPT is prompted to include citations, it had only provided references
    that exist only 14% of the time. Falsifying sources, rambling, and delivering
    inaccuracies to appease the prompt are dubbed hallucination, a huge obstacle to
    overcome before AI is fully adopted and trusted by the masses.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天型LLM因编造不存在的科学论文或法院案件的引用而臭名昭著。[对航空公司提起诉讼的律师](https://www.theguardian.com/technology/2023/jun/23/two-us-lawyers-fined-submitting-fake-court-citations-chatgpt)包括了实际上从未发生过的法院案件的引用。[2023年的一项研究报告](https://arxiv.org/abs/2309.09401)显示，当ChatGPT被提示包含引用时，它仅在14%的时间里提供了实际存在的参考文献。伪造来源、唠叨以及为了迎合提示而提供不准确的信息被称为幻觉，这是在AI被大众全面采纳和信任之前需要克服的一大障碍。
- en: One counter to LLMs making up bogus sources or coming up with inaccuracies is
    retrieval-augmented generation or RAG. Not only can RAG decrease the tendency
    of LLMs to hallucinate but several other advantages as well.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 应对LLM编造虚假来源或产生不准确内容的一种对策是检索增强生成（RAG）。RAG不仅可以减少LLM的幻觉倾向，还有其他几个优势。
- en: These advantages include access to an updated knowledge base, specialization
    (*e.g.* by providing private data sources), empowering models with information
    beyond what is stored in the parametric memory (allowing for smaller models),
    and the potential to follow up with more data from legitimate references.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优势包括访问更新的知识库，专业化（*例如* 提供私有数据源），赋予模型超越参数记忆中存储的信息（允许更小的模型），以及有可能从合法的参考资料中获得更多的数据。
- en: What is RAG (Retrieval Augmented Generation)?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是RAG（检索增强生成）？
- en: 'Retrieval-Augmented Generation (RAG) is a deep learning architecture implemented
    in LLMs and transformer networks that retrieves relevant documents or other snippets
    and adds them to the context window to provide additional information, aiding
    an LLM to generate useful responses. A typical RAG system would have two main
    modules: retrieval and generation.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）是一种深度学习架构，实施在LLMs和变换器网络中，通过检索相关文档或其他片段并将其添加到上下文窗口中以提供额外的信息，从而帮助LLM生成有用的响应。一个典型的RAG系统有两个主要模块：检索和生成。
- en: '![retrieval augmented generation architecture - RAG](../Images/d69cffca46379cd698dcd2203c816120.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![检索增强生成架构 - RAG](../Images/d69cffca46379cd698dcd2203c816120.png)'
- en: The main reference for RAG is a [paper by Lewis et al.](https://arxiv.org/abs/2005.11401) from
    Facebook. In the paper, the authors use a pair of BERT-based document encoders
    to transform queries and documents by embedding the text in a vector format. These
    embeddings are then used to identify the top-*k* (typically 5 or 10) documents
    via a maximum inner product search (MIPS). As the name suggests, MIPS is based
    on the inner (or dot) product of the encoded vector representations of the query
    and those in a vector database pre-computed for the documents used as external,
    non-parametric memory.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: RAG的主要参考文献是Facebook的[一篇由Lewis等人撰写的论文](https://arxiv.org/abs/2005.11401)。在论文中，作者使用一对基于BERT的文档编码器通过将文本嵌入到向量格式中来转换查询和文档。这些嵌入随后用于通过最大内积搜索（MIPS）来识别前*k*（通常是5或10）个文档。顾名思义，MIPS基于查询的编码向量表示与预计算的文档向量数据库中的向量表示之间的内积（或点积）。
- en: As described in the piece by Lewis *et al.*, RAG was designed to make LLMs better
    at knowledge-intensive tasks which “humans could not reasonably be expected to
    perform without access to an external knowledge source”. Consider taking an open
    book and non-open book exam and you’ll have a good indication of how RAG might
    supplement LLM-based systems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Lewis *等人* 在文章中所描述的那样，RAG的设计目的是让LLMs在处理“人类在没有外部知识来源的情况下无法合理完成的知识密集型任务”时表现得更好。考虑一下开放书籍和非开放书籍考试的对比，你就能很好地理解RAG如何补充基于LLM的系统。
- en: RAG with the Hugging Face 🤗 Library
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Hugging Face 🤗 库的RAG
- en: Lewis *et al.* open-sourced their RAG models on the Hugging Face Hub, thus we
    can experiment with the same models used in the paper. A new Python 3.8 virtual
    environment with virtualenv is recommended.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Lewis *等人* 在Hugging Face Hub上开源了他们的RAG模型，因此我们可以使用论文中相同的模型进行实验。推荐使用Python 3.8的虚拟环境，并使用virtualenv。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After activating the environment, we can install dependencies using pip: transformers
    and datasets from Hugging Face, the FAISS library from Facebook that RAG uses
    for vector search, and PyTorch for use as a backend.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 激活环境后，我们可以使用pip安装依赖项：来自Hugging Face的transformers和datasets，RAG使用的Facebook的FAISS库用于向量搜索，以及用于作为后端的PyTorch。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Lewis *et al.* implemented two different versions of RAG: rag-sequence and
    rag-token. Rag-sequence uses the same retrieved document to augment the generation
    of an entire sequence whereas rag-token can use different snippets for each token.
    Both versions use the same Hugging Face classes for tokenization and retrieval,
    and the API is much the same, but each version has a unique class for generation.
    These classes are imported from the transformers library.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Lewis *等人* 实现了两种不同版本的RAG：rag-sequence 和 rag-token。rag-sequence使用相同的检索文档来增强整个序列的生成，而rag-token可以为每个标记使用不同的片段。这两个版本都使用相同的Hugging
    Face类进行标记化和检索，API也基本相同，但每个版本都有一个独特的生成类。这些类是从transformers库中导入的。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first time the RagRetriever model with the default “wiki_dpr” dataset is
    instantiated it will initiate a substantial download (about 300 GB). If you have
    a large data drive and want Hugging Face to use it (instead of the default cache
    folder in your home drive), you can set a shell variable, HF_DATASETS_CACHE.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当首次实例化具有默认“wiki_dpr”数据集的RagRetriever模型时，它将启动大规模下载（约300 GB）。如果你有一个大型数据驱动器并希望Hugging
    Face使用它（而不是默认的缓存文件夹），可以设置一个Shell变量HF_DATASETS_CACHE。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Ensure the code is working before downloading the full wiki_dpr dataset. To
    avoid the big download until you’re ready, you can pass use_dummy_dataset=True
    when instantiating the retriever. You’ll also instantiate a tokenizer to convert
    strings to integer indices (corresponding to tokens in a vocabulary) and vice-versa.
    Sequence and token versions of RAG use the same tokenizer. RAG sequence (rag-sequence)
    and RAG token (rag-token) each have fine-tuned (*e.g. *rag-token-nq) and base
    versions (*e.g.* rag-token-base).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下载完整的wiki_dpr数据集之前，请确保代码正常运行。为了避免大规模下载直到你准备好，你可以在实例化检索器时传递use_dummy_dataset=True。你还需要实例化一个标记器，将字符串转换为整数索引（对应于词汇表中的标记）及反之。RAG的序列版本和标记版本使用相同的标记器。RAG序列（rag-sequence）和RAG标记（rag-token）各自有经过微调的（*例如*
    rag-token-nq）和基础版本（*例如* rag-token-base）。
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once your models are instantiated, you can provide a query, tokenize it, and
    pass it to the “generate” function of the model. We’ll compare results from rag-sequence,
    rag-token, and RAG using a retriever with the dummy version of the wiki_dpr dataset. Note
    that these rag-models are case-insensitive
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的模型被实例化，你可以提供查询，进行标记化，然后将其传递给模型的“generate”函数。我们将比较使用带有dummy版本wiki_dpr数据集的rag-sequence、rag-token和RAG的结果。请注意，这些rag模型是不区分大小写的。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In general, rag-token is correct more often than rag-sequence, (though both
    are often correct), and rag-sequence is more often right than RAG using a retriever
    with a dummy dataset.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，rag-token的正确率高于rag-sequence（尽管两者都经常正确），而rag-sequence的正确率高于使用dummy数据集的RAG。
- en: “What sort of context does the retriever provide?” You may wonder. To find out,
    we can deconstruct the generation process. Using the seq_retriever and seq_model
    instantiated as above, we query “What is the name of the oldest tree on Earth”
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: “检索器提供了什么样的上下文？”你可能会好奇。为了找出答案，我们可以解构生成过程。使用上面实例化的seq_retriever和seq_model，我们查询“地球上最古老的树叫什么名字”
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can code our model to print the variable “best context” to see what was captured
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写代码让模型打印“best context”变量，以查看捕获了什么。
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'based on the retrieved context:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 基于检索到的上下文：
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We can also print the answer by calling the `generated_string` variable. The
    rag-sequence-nq answers 'what is the name of the oldest tree on Earth?' with 'Prometheus'.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过调用`generated_string`变量来打印答案。rag-sequence-nq回答“地球上最古老的树叫什么名字？”为“Prometheus”。
- en: What Can You Do with RAG?
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你可以用RAG做什么？
- en: In the last year and a half, there has been a veritable explosion in LLMs and
    LLM tools. The BART base model used in Lewis *et al.* was only 400 million parameters,
    a far cry from the current crop of LLMs, which typically start in the billion
    parameter range for “lite” variants. Also, many models being trained, merged,
    and fine-tuned today are multimodal, combining text inputs and outputs with images
    or other tokenized data sources. Combining RAG with other tools can build complex
    capabilities, but the underlying models won’t be immune to common LLM shortcomings.
    The problems of sycophancy, hallucination, and reliability in LLMs all remain
    and run the risk of growing just as LLM use grows.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去一年半里，LLMs和LLM工具经历了真正的爆炸性增长。Lewis *等* 使用的BART基础模型仅有4亿个参数，与当前的LLMs相比，后者通常以十亿参数级别的“轻量”变体为起点。此外，许多正在训练、合并和微调的模型都是多模态的，将文本输入和输出与图像或其他标记化的数据源结合起来。将RAG与其他工具结合可以构建复杂的能力，但基础模型仍然不能免于常见LLM缺陷。谄媚、幻觉和可靠性的问题依然存在，并有可能随着LLM的使用增长而加剧。
- en: The most obvious applications for RAG are variations on conversational semantic
    search, but perhaps they also include incorporating multimodal inputs or image
    generation as part of the output. For example, RAG in LLMs with domain knowledge
    can make software documentation you can chat with. Or RAG could be used to keep
    interactive notes in a literature review for a research project or thesis.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: RAG最明显的应用是对话语义搜索的变体，但它们也可能包括将多模态输入或图像生成作为输出的一部分。例如，具有领域知识的LLM中的RAG可以生成你可以聊天的软件文档。或者RAG可以用于在文献综述的研究项目或论文中保持互动笔记。
- en: Incorporating a ‘chain-of-thought’ reasoning capability, you could take a more
    agentic approach to empower your models to query RAG system and assemble more
    complex lines of inquiry or reasoning.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合“链式思维”推理能力，你可以采取更具代理性的方式，赋能你的模型查询RAG系统并组装更复杂的询问或推理路径。
- en: It is also very important to keep in mind that RAG does not solve the common
    LLM pitfalls (hallucination, sycophancy, etc.) and serves only as a means to alleviate
    or guide your LLM to a more niche response. The endpoints that ultimately matter,
    are specific to your use case, the information you feed your model, and how the
    model is finetuned.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要特别注意的是，RAG 并不能解决常见的大型语言模型（LLM）问题（如幻觉、谄媚等），它仅作为一种缓解或引导你的 LLM 达到更专业回应的手段。最终重要的是，取决于你的使用案例、你提供给模型的信息以及模型的微调方式。
- en: '**[Kevin Vu](https://blog.exxactcorp.com/)** manages [Exxact Corp blog](https://blog.exxactcorp.com/)
    and works with many of its talented authors who write about different aspects
    of Deep Learning.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kevin Vu](https://blog.exxactcorp.com/)** 负责管理 [Exxact Corp 博客](https://blog.exxactcorp.com/)，并与许多才华横溢的作者合作，他们撰写关于深度学习不同方面的文章。'
- en: More On This Topic
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与…的结合](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[Making Intelligent Document Processing Smarter: Part 1](https://www.kdnuggets.com/2023/02/making-intelligent-document-processing-smarter-part-1.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[让智能文档处理更智能：第 1 部分](https://www.kdnuggets.com/2023/02/making-intelligent-document-processing-smarter-part-1.html)'
- en: '[How to Optimize SQL Queries for Faster Data Retrieval](https://www.kdnuggets.com/2023/06/optimize-sql-queries-faster-data-retrieval.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何优化 SQL 查询以加快数据检索速度](https://www.kdnuggets.com/2023/06/optimize-sql-queries-faster-data-retrieval.html)'
- en: '[Bark: The Ultimate Audio Generation Model](https://www.kdnuggets.com/2023/05/bark-ultimate-audio-generation-model.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bark：终极音频生成模型](https://www.kdnuggets.com/2023/05/bark-ultimate-audio-generation-model.html)'
- en: '[The Future of AI: Exploring the Next Generation of Generative Models](https://www.kdnuggets.com/2023/05/future-ai-exploring-next-generation-generative-models.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能的未来：探索下一代生成模型](https://www.kdnuggets.com/2023/05/future-ai-exploring-next-generation-generative-models.html)'
- en: '[Unveiling Midjourney 5.2: A Leap Forward in AI Image Generation](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 Midjourney 5.2：AI 图像生成的跃进](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
