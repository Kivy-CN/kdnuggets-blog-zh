- en: ChatGPT, GPT-4, and More Generative AI News
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/02/chatgpt-gpt4-generative-ai-news.html](https://www.kdnuggets.com/2023/02/chatgpt-gpt4-generative-ai-news.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![ChatGPT, GPT-4, and More Generative AI News](../Images/894c27fa78d5b859719907b1147c6287.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Robolawyer. Credit: Midjourney'
  prefs: []
  type: TYPE_NORMAL
- en: If you read my work you probably know that I publish my articles first and foremost
    in my AI newsletter, [The Algorithmic Bridge](https://thealgorithmicbridge.substack.com/).
    What you may not know is that every Sunday I publish a special column I call “what
    you may have missed,” where I review everything that has happened during the week
    with analyses that help you make sense of the news.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT, ChatGPT, and more ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft-OpenAI $10-billion deal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Semafor reported](https://www.semafor.com/article/01/09/2023/microsoft-eyes-10-billion-bet-on-chatgpt) two
    weeks ago that, if everything goes according to the plan, Microsoft will close
    a $10B investment deal with OpenAI before the end of January (Satya Nadella, Microsoft’s
    CEO, announced the [extended partnership](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) officially
    on Monday).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s been some misinformation about the deal which implied that OpenAI execs
    weren’t sure about the company’s long-term viability. However, [it was later clarified](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/) that
    the deal looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ChatGPT, GPT-4, and More Generative AI News](../Images/b6af7ac33c95fbe37a08bda4cfc43c70.png)'
  prefs: []
  type: TYPE_IMG
- en: Credit: [Fortune](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/)
  prefs: []
  type: TYPE_NORMAL
- en: Leo L’Orange, who writes The Neuron, [explains](https://twitter.com/nonmayorpete/status/1613234091197071360) that
    “once $92 billion in profit plus $13 billion in initial investment are repaid
    to Microsoft and once the other venture investors earn $150 billion, all of the
    equity reverts back to OpenAI.”
  prefs: []
  type: TYPE_NORMAL
- en: People are divided. Some say the deal is “cool” or “interesting”, whereas others
    say it’s “odd” and “crazy”. What I perceive with my non-expert eyes is that OpenAI
    and Sam Altman *do* trust (some would say *overtrust*) the company’s long-term
    ability to achieve its goals.
  prefs: []
  type: TYPE_NORMAL
- en: However, as [Will Knight writes](https://www.wired.com/story/chatgpt-has-investors-drooling-but-can-it-bring-home-the-bacon/) for
    WIRED, “it’s unclear what products can be built on the technology.” OpenAI must
    figure out a viable business model soon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Changes to ChatGPT: New features and monetization'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[OpenAI updated ChatGPT](https://help.openai.com/en/articles/6825453-chatgpt-release-notes) on
    Jan 9 (from the previous update on Dec 15). Now the chatbot has “improved factuality”
    and you can stop it mid-generation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'They’re also working on a “professional version of ChatGPT” (which is rumored
    to go out at [$42/month](https://twitter.com/DotCSV/status/1616742341389291520))
    as OpenAI’s president [Greg Brockman announced](https://twitter.com/gdb/status/1612986134048698369) on
    Jan 11\. These are the three main features:'
  prefs: []
  type: TYPE_NORMAL
- en: “Always available (no blackout windows).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fast responses from ChatGPT (i.e. no throttling).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As many messages as you need (at least 2X regular daily limit).”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To sign up for the waitlist you have to [fill out a form](https://docs.google.com/forms/d/e/1FAIpQLSfCVqahRmA5OxQXbRlnSm531fTd8QBdUCwZag7mI9mrlOOIaw/viewform) where
    they ask you, among other things, how much you’d be willing to pay (and how much
    would be too much).
  prefs: []
  type: TYPE_NORMAL
- en: If you plan to take it seriously, you should consider going deep into OpenAI’s
    product stack with the [OpenAI cookbook repo](https://github.com/openai/openai-cookbook).
    Bojan Tunguz said it is “[the top trending repo on GitHub this month](https://twitter.com/tunguz/status/1612435428300423168).”
    Always a good sign.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT, the fake scientist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT has entered the scientific domain. [Kareem Carr](https://twitter.com/kareem_carr/status/1613325029848092672) posted
    a screenshot on Thursday of a paper of which ChatGPT is a co-author.
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/kareem_carr/status/1613325029848092672)'
  prefs: []
  type: TYPE_NORMAL
- en: But why, given that ChatGPT is a tool? “People are starting to treat ChatGPT
    as if it were a bona fide, well-credentialed scientific *collaborator*,” explains
    Gary Marcus [in a Substack post](https://garymarcus.substack.com/p/scientists-please-dont-let-your-chatbots).
    “Scientists, please don’t let your chatbots grow up to be co-authors,” he pleads.
  prefs: []
  type: TYPE_NORMAL
- en: 'More worrisome are those cases where there’s no disclosure of AI use. Scientists [have
    found](https://www.biorxiv.org/content/10.1101/2022.12.23.521610v1) that they
    can’t reliably identify abstracts written by ChatGPT — its eloquent bullshit fools
    even experts in their field. As Sandra Wachter, who “studies technology and regulation”
    at Oxford, told Holly Else for [a piece on Nature](https://www.nature.com/articles/d41586-023-00056-7):'
  prefs: []
  type: TYPE_NORMAL
- en: '*“If we’re now in a situation where the experts are not able to determine what’s
    true or not, we lose the middleman that we desperately need to guide us through
    complicated topics.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ChatGPT’s challenge to education
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT has been banned in education centers all across the globe (e.g. [New
    York public schools](https://www.theguardian.com/us-news/2023/jan/06/new-york-city-schools-ban-ai-chatbot-chatgpt), [Australian
    universities](https://www.republicworld.com/world-news/australia/australian-universities-to-go-back-to-pen-and-paper-exam-after-students-caught-using-ai-tool-articleshow.html),
    and [UK lecturers](https://www.theguardian.com/technology/2023/jan/13/end-of-the-essay-uk-lecturers-assessments-chatgpt-concerns-ai) are
    thinking about it). As I argued in [a previous essay](https://thealgorithmicbridge.substack.com/p/chatgpt-and-the-future-present-were),
    I don’t think this is the wisest decision but merely a reaction due to being unprepared
    for the fast development of generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: '[NYT’s Kevin Roose argues](https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html) that
    “[ChatGPT’s] potential as an educational tool outweighs its risks.” Terence Tao,
    the great mathematician, [agrees](https://twitter.com/DataChaz/status/1612766340321796096):
    “In the long term, it seems futile to fight against this; perhaps what we as lecturers
    need to do is to move to an “open books, open AI” mode of examination.”'
  prefs: []
  type: TYPE_NORMAL
- en: '[Giada Pistilli](https://www.linkedin.com/posts/giada-pistilli-295a36a1_why-schools-should-not-ban-chatgpt-activity-7019290804770721792-gc9H/),
    the principal ethicist at Hugging Face, explains the challenge schools face with
    ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Unfortunately, the educational system seems forced to adapt to these new
    technologies. I think it is understandable as a reaction, since not much has been
    done to anticipate, mitigate or elaborate alternative solutions to contour the
    possible resulting problems. Disruptive technologies often demand user education
    because they cannot simply be thrown at people uncontrollably.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'That last sentence captures perfectly where the problem arises and the potential
    solution lies. We have to make an extra effort to educate users on how this tech
    works and what’s possible and not to do with them. That’s the approach Catalonia
    has taken. As [Francesc Bracero and Carina Farreras report](https://www.lavanguardia.com/vida/20230115/8683575/chatgtp-irrumpe-aulas-revoluciona.html) for
    La Vanguardia:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“In Catalonia, the Department of Education is not going to prohibit it ‘in
    the entire system and for everyone, since this would be an ineffective measure.’
    According to sources from the ministry, it is better to ask the centers to educate
    in the use of AI, ‘which can provide a lot of knowledge and advantages.’”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The student’s best friend: A database of ChatGPT errors'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gary Marcus and Ernest Davis have set up an “[error tracker](https://researchrabbit.typeform.com/llmerrors?typeform-source=garymarcus.substack.com)”
    to capture and classify the errors language models like ChatGPT make ([here’s
    more info](https://garymarcus.substack.com/p/large-language-models-like-chatgpt) about
    why they’re compiling this document and what they plan to do with it).
  prefs: []
  type: TYPE_NORMAL
- en: 'The database is public and anyone can participate. It’s a great resource that
    allows for rigorous study of how these models misbehave and how people could avoid
    misuse. Here’s a hilarious example of why this matters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/LiquidSloshalot/status/1614384524024250368)'
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI is aware of this and wants to fight mis- and disinformation: “[Forecasting
    Potential Misuses of Language Models for Disinformation Campaigns — and How to
    Reduce Risk](https://openai.com/blog/forecasting-misuse/).”'
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4 info and misinfo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: New information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Sam Altman hinted](https://twitter.com/readkrystalhu/status/1613761499612479489) at
    a delay in GPT-4’s release in a conversation with [Connie Loizos](https://twitter.com/Cookie),
    the silicon valley editor at TechCrunch. Altman said that “in general, we are
    going to release technology much more slowly than people would like. We’re going
    to sit on it for much longer…” This is my take:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/Alber_RomGar/status/1613880177733341184)'
  prefs: []
  type: TYPE_NORMAL
- en: (Altman also said there’s a video model in the works!)
  prefs: []
  type: TYPE_NORMAL
- en: Misinformation about GPT-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a “GPT-4 = 100T” claim going viral everywhere on social media (I’ve
    mostly seen it on Twitter and LinkedIn). In case you haven’t seen it, it looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/AlexHormozi/status/1612913266195587072)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Or this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/SimonHoiberg/status/1613089457116258306)'
  prefs: []
  type: TYPE_NORMAL
- en: 'All are slightly different versions of the same thing: An appealing visual
    graph that captures attention, and a strong hook with the GPT-4/GPT-3 comparison
    (they use GPT-3 as a proxy for ChatGPT).'
  prefs: []
  type: TYPE_NORMAL
- en: I think sharing rumors and speculations and framing them as such is okay ([I
    feel partly responsible for this](https://thealgorithmicbridge.substack.com/p/gpt-4-a-viral-case-of-ai-misinformation)),
    but posting unverifiable info with an authoritative tone and without references
    is reprehensible.
  prefs: []
  type: TYPE_NORMAL
- en: People doing this aren’t far from being as useless and dangerous as ChatGPT
    as sources of information — and with much stronger incentives to keep doing it.
    Beware of this because it’ll pollute every channel of information about AI going
    forward.
  prefs: []
  type: TYPE_NORMAL
- en: More generative AI news
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A robot lawyer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Joshua Browder, CEO at DoNotPay, [posted this on Jan 9](https://twitter.com/jbrowder1/status/1612312707398795264):'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/jbrowder1/status/1612312707398795264)'
  prefs: []
  type: TYPE_NORMAL
- en: As it couldn’t be otherwise, this bold claim generated [a lot of debate](https://www.cbsnews.com/news/ai-powered-robot-lawyer-takes-its-first-court-case/) to
    the point that Twitter now flags the tweet with a link to the [Supreme Court page
    of prohibited items](https://www.supremecourt.gov/visiting/prohibited-items.aspx).
  prefs: []
  type: TYPE_NORMAL
- en: Even if they finally can’t do it due to legal reasons, it’s worth considering
    the question from an ethical and social standpoint. What happens if the AI system
    makes a serious mistake? Could [people without access](https://twitter.com/harikunzru/status/1612614168062087168) to
    a lawyer benefit from a mature version of this technology?
  prefs: []
  type: TYPE_NORMAL
- en: Litigation against Stable Diffusion has begun
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Matthew Butterick [published this on Jan 13](https://stablediffusionlitigation.com/):'
  prefs: []
  type: TYPE_NORMAL
- en: '*“On behalf of three won­der­ful *[*artist plain­tiffs*](https://stablediffusionlitigation.com/#plaintiffs)* — *[*Sarah
    Ander­sen*](https://stablediffusionlitigation.com/#sarah-andersen)*, *[*Kelly
    McK­er­nan*](https://stablediffusionlitigation.com/#kelly-mckernan)*, and *[*Karla
    Ortiz*](https://stablediffusionlitigation.com/#karla-ortiz)* — we’ve filed a class-action
    law­suit against *[*Sta­bil­ity AI*](https://stablediffusionlitigation.com/#stability-ai)*, *[*DeviantArt*](https://stablediffusionlitigation.com/#deviantart)*,
    and *[*Mid­jour­ney*](https://stablediffusionlitigation.com/#midjourney)* for
    their use of *[*Sta­ble Dif­fu­sion*](https://stability.ai/blog/stable-diffusion-announcement)*,
    a 21st-cen­tury col­lage tool that remixes the copy­righted works of mil­lions
    of artists whose work was used as train­ing data.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It begins — the first steps in what promises to be a long fight to moderate
    the training and use of generative AI. I agree with the motivation: “AI needs
    to be fair & eth­i­cal for every­one.”'
  prefs: []
  type: TYPE_NORMAL
- en: But, [like many others](https://twitter.com/NickEMoran/status/1614315147832565768),
    I’ve found inaccuracies in the blog post. It goes deep into the technicalities
    of Stable Diffusion but fails to explain correctly some bits. Whether this is
    intentional as a means to bridge the technical gap for people who don’t know —
    and don’t have the time to learn — about how this technology works (or as a means
    to characterize the tech in a way that benefits them) or a mistake is open to
    speculation.
  prefs: []
  type: TYPE_NORMAL
- en: I argued [in a previous article](https://thealgorithmicbridge.substack.com/i/96141502/a-peaceful-coexistence-with-generative-ai) that
    right now the clash between AI art and traditional artists is strongly emotional.
    The responses to this lawsuit won’t be any different. We’ll have to wait for the
    judges to decide the outcome.
  prefs: []
  type: TYPE_NORMAL
- en: CNET publishing AI-generated articles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Futurism reported](https://futurism.com/the-byte/cnet-publishing-articles-by-ai) this
    a couple of weeks ago:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“*CNET*, a massively popular tech news outlet, has been quietly employing
    the help of “automation technology” — a stylistic euphemism for AI — on a new
    wave of financial explainer articles.”*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gael Breton, who first spotted this, [wrote a deeper analysis on Friday](https://www.authorityhacker.com/has-ai-already-won/).
    He explains that Google doesn’t seem to be hindering traffic to these posts. “Is
    AI content ok now?” [he asks](https://twitter.com/GaelBreton/status/1613110191029121024).
  prefs: []
  type: TYPE_NORMAL
- en: 'I find it CNET’s decision [to fully disclose the use of AI](https://www.cnet.com/tech/cnet-is-experimenting-with-an-ai-assist-heres-why/) in
    their articles a good precedent. How many people are publishing content right
    now using AI without disclosing it? However, the consequence is that people may
    lose their jobs if this works out (as I, and many others, [predicted](https://thealgorithmicbridge.substack.com/p/generative-ai-my-enhancement-your)). [It’s
    already happening](https://twitter.com/JasonColavito/status/1611710986871767041):'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/JasonColavito/status/1611710986871767041)'
  prefs: []
  type: TYPE_NORMAL
- en: 'I fully agree with this Tweet from Santiago:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/svpino/status/1610984481342771200)'
  prefs: []
  type: TYPE_NORMAL
- en: RLHF for image generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If reinforcement learning through human feedback works for language models,
    why not for text-to-image? That’s what PickaPic is trying to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: '[The demo](https://pickapic.io/) is for research purposes but could be an interesting
    addition to Stable Diffusion or DALL-E (Midjourney does something similar — they
    internally guide the model to output beautiful and artistic images).'
  prefs: []
  type: TYPE_NORMAL
- en: A recipe to “make Siri/Alexa 10x better”
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recipes that mix different generative AI models to create some better than
    the sum of the parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Source](https://twitter.com/DrJimFan/status/1612496633056620545)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Alberto Romero](https://medium.com/@albertoromgar)** is a freelance writer
    who focuses on tech and AI. He writes [The Algorithmic Bridge](https://thealgorithmicbridge.substack.com/),
    a newsletter that helps non-technical people make sense of news and events on
    AI. He''s also a tech analyst at CambrianAI, where he specializes in large language
    models.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://albertoromgar.medium.com/chatgpt-gpt-4-and-more-generative-ai-news-17e0b114a96c).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Google Answer to ChatGPT by Adding Generative AI into Docs and Gmail](https://www.kdnuggets.com/2023/03/google-answer-chatgpt-adding-generative-ai-docs-gmail.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This Week in AI, August 7: Generative AI Comes to Jupyter & Stack…](https://www.kdnuggets.com/2023/mm/this-week-ai-2023-08-07.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Visual ChatGPT: Microsoft Combine ChatGPT and VFMs](https://www.kdnuggets.com/2023/03/visual-chatgpt-microsoft-combine-chatgpt-vfms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChatGPT CLI: Transform Your Command-Line Interface Into ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 29: 20 Basic Linux Commands for Data Science…](https://www.kdnuggets.com/2022/n26.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Between Dreams and Reality: Generative Text and Hallucinations](https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
