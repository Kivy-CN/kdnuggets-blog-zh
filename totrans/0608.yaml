- en: 'Building a Visual Search Engine – Part 1: Data Exploration'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-1.html](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-1.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Why?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ever wonder how Google or Bing finds similar images to your image. The algorithms
    for generating text based 10 blue-links are very different from finding visually
    similar or related images. In this article, we will explain one such method to
    build a visual search engine. We will use the Caltech [101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)
    dataset which contains images of common objects used in daily life. We will only
    cover a prototype algorithm and discuss what will be required to develop a full
    scaled visual search engine.
  prefs: []
  type: TYPE_NORMAL
- en: '****About dataset****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Caltech 101 dataset contains 101 classes of objects like face, tick, knife,
    mobile, money, etc. It contains 40–200 images per class. In addition to 101 classes,
    it also contains a background class / noise class to test the model on negative
    images. The dataset contains 8677 images excluding 486 background images. Below
    is the frequency distribution of images in classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Building a Visual Search Engine - Part 1: Data Exploration](../Images/c40a016d818f5d778126ff31acb90d75.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of images in each class follows long tail distribution. The most
    frequent class contains ~16x more images than the least frequent class. Approximately
    5% of classes (5 classes) contains ~30% of images. Approximately 90% of classes
    have less than 100 images.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** This imbalance in the dataset can lead to skewed batches when training
    the model.'
  prefs: []
  type: TYPE_NORMAL
- en: '****Exploratory Data Analysis****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We take random images from randomly selected classes. Please find below some
    sample images.
  prefs: []
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/7750a853db646a7f48ff576d682897a6.png)'
  prefs: []
  type: TYPE_IMG
- en: '![XXXXX](../Images/b3fbcaf16f496cb4cd24d7f132afe9aa.png)'
  prefs: []
  type: TYPE_IMG
- en: '****Observations****'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aspect Ratio:** Images are of different aspect ratio but the maximum side
    of the image is resized to 300px. Additionally, we try to get the distribution
    of the aspect ratio to better understand the dataset. We found that most of the
    images have aspect ratio 0.5–0.8, i.e. the width is larger than height.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/52cd93aca1c29e97bf80778ac30cf957.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Color vs Grayscale**: We noticed that a lot of images in some directory were
    grayscale images. We implemented a grayscale images check and found that 411 images
    across 101 classes were greyscale. Next, we checked the class-wise distribution
    and found that the car-side class had only grayscale images. There are few other
    classes which contain greyscale images but all of them except the car-side contains
    color images too.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/ce923a7690d00a2e72514f216cae9ab0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Data Biases:**'
  prefs: []
  type: TYPE_NORMAL
- en: '***faces and faces_easy***: These classes contain images of faces and cropped
    faces respectively. But there are multiple images of the same person with slight
    perspective change. Additionally, the images are very similar in terms of occlusion,
    background and lighting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/d3f2a566d94cd377f13259197589ae6f.png)'
  prefs: []
  type: TYPE_IMG
- en: '***flamingo and flamingo_head*****:** One class contains the whole body of
    flamingo and the other contains just the head part of it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/c92c1889215d34d2859f8e3764f120dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'similar case: **chair** and **windsor_chair**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**accordion** — images are rotated 45 degrees with black padding'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Animated images**: A lot of classes contain cartoon images. Cartoon images
    are semantically right but have different textures compared to real-life images.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object Location and Scale**: We found out that the dataset is biased towards
    certain scale and location in the image. Object in focus is always in the center
    of the image and has a similar scale. Objects in the center might not be any problem
    because CNN models are translation invariant (when used with max pooling or average
    pooling). But training the model with fixed scale may cause the model to work
    on similar scale objects only. This will cause the model to fail on images with
    different scales, which generally occurs in real-life. We propose two solutions
    to this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Two Stage Pipeline**: We can create a two stage pipeline, the first component
    predicts the bounding box of the object in focus and the second component predicts
    what the object is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Resizing Objects using Data Augmentation**: We can apply data augmentation
    techniques to rescale the object in focus and train the model on that augmented
    dataset. This may require the model size to be increased, as it will now store
    more information (object recognition as multiple scales, because CNNs are not
    scale invariant)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Occlusion and Background**: Majority of images in the dataset have a clean
    background and the object in focus is not occluded.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Rasterisation:** Some classes have images that seem to be resized from
    smaller dimensions. Because of this images looks very rasterised'
  prefs: []
  type: TYPE_NORMAL
- en: '****Embeddings Visualisation****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we visualise images using the embeddings generated from pre-trained
    model. For this purpose, we used the MobileNetV2 model pre-trained on ImageNet
    with 2.2M parameters. We used the output of the global average pooling layer,
    which generates embedding of size 1280.
  prefs: []
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/ddfd3ccad1caefd7835b3399d70f9793.png)'
  prefs: []
  type: TYPE_IMG
- en: The two dimensional plot of the vector is not very intuitive. This is because
    the two dimensions combined explains only 8.5% of variance in the data. We also
    plot these embeddings in three dimensions using TF Projector. The 3D embedding
    plot explains ~15% of the variance in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/64521ba4c2b75c4bea735ce724db9a21.png)'
  prefs: []
  type: TYPE_IMG
- en: We did not observe any clear cluster of objects from the graph above. But the
    cosine similarity between images was good representative of the images. For most
    cases, the images near to a certain image embedding were of the same class. This
    proves that the model we have used to generate embeddings, focuses on the right
    aspect of the image and is able to figure out the object of interest in the image.
  prefs: []
  type: TYPE_NORMAL
- en: The t-SNE visualisation of the embedding shows a lot of concentrated clusters
    of classes. Browsing through these visualisations also revealed some similar classes
    like schooner and ketch, helicopter and airplane, crayfish and lobster, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![XXXXX](../Images/b89dd0fb00657acb3ee36c18d14dcf9c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Editor''s note:** Join us next week for the exciting conclusion of Building
    a Visual Search Engine, where we move on from data exploration to cover building
    the visual search engine itself.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Mudit Bachhawat](https://www.linkedin.com/in/muditbac/?originalSubdomain=in)**
    works as a machine learning engineer at Google, and has more than 5 years of experience
    in data science, deep learning, computer vision, multi-modal information retrieval,
    and optimization. Feel free to drop any comments or questions.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building a Visual Search Engine - Part 2: The Search Engine](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Elevate Your Search Engine Skills with Uplimit''s Search with ML Course!](https://www.kdnuggets.com/2023/10/uplimit-elevate-your-search-engine-skills-search-with-ml-course)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Qdrant: Open-Source Vector Search Engine with Managed Cloud Platform](https://www.kdnuggets.com/2023/02/qdrant-open-source-vector-search-engine-managed-cloud-platform.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Geospatial Application in Python with Google Earth…](https://www.kdnuggets.com/2022/03/building-geospatial-application-python-google-earth-engine-greppo.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChatGPT-Powered Data Exploration: Unlock Hidden Insights in Your Dataset](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
