- en: 7 More Steps to Mastering Machine Learning With Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精通 Python 机器学习的 7 个步骤
- en: 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)
- en: So, you have been thinking about picking up machine learning, but given the
    confusing state of the web you don't know where to begin? Or maybe you have finished
    [the first 7 steps](/2015/11/seven-steps-machine-learning-python.html) and are
    looking for some follow-up material, beyond the introductory?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你一直在考虑学习机器学习，但由于网络上信息混乱，你不知道从哪里开始？或者你已经完成了[前 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)并希望找到一些后续材料，超出入门内容？
- en: '![Machine learning algorithms](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)'
- en: Machine learning algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法。
- en: This post is the second installment of the [7 Steps to Mastering Machine Learning
    in Python](/2015/11/seven-steps-machine-learning-python.html) series (since there
    are 2 parts, I guess it now qualifies as a series). If you have started with the
    [original post](/2015/11/seven-steps-machine-learning-python.html), you should
    already be satisfactorily up to speed, skill-wise. If not, you may want to review
    that post first, which may take some time, depending on your current level of
    understanding; however, I assure you that doing so will be worth your effort.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是[精通 Python 机器学习的 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)系列的第二部分（既然有两个部分，我想它现在算是一个系列）。如果你已经开始阅读[原始文章](/2015/11/seven-steps-machine-learning-python.html)，你应该已经在技能上有所进步。如果没有，你可能需要先回顾那篇文章，这可能需要一些时间，具体取决于你当前的理解水平；不过，我保证这样做会值得你的努力。
- en: After a quick review -- and a few options for a fresh perspective -- this post
    will focus more categorically on several sets of related machine learning tasks.
    Since we can safely skip the foundational modules this time around -- Python basics,
    machine learning basics, etc. -- we will jump right into the various machine learning
    algorithms. We can also categorize our tutorials better along functional lines
    this time.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速回顾——以及提供几种新视角的选项之后——这篇文章将更系统地聚焦于几组相关的机器学习任务。由于这次我们可以安全地跳过基础模块——如 Python 基础、机器学习基础等——我们将直接进入各种机器学习算法。这次我们还可以更好地按功能对教程进行分类。
- en: I will, once again, state that the material contained herein is all freely available
    on the web, and all rights and recognition for the works belong to their original
    authors. If something has not been properly attributed, please feel free to [let
    me know](https://twitter.com/mattmayo13).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我再次声明，本文所含材料都在网上免费提供，所有权利和荣誉归原作者所有。如果有任何内容未被适当归属，请随时[告诉我](https://twitter.com/mattmayo13)。
- en: 'Step 1: Machine Learning Basics Review & A Fresh Perspective'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：机器学习基础回顾与新视角
- en: 'Just to review, these are the steps covered in the [original post](/2015/11/seven-steps-machine-learning-python.html):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 仅作回顾，这些是[原始文章](/2015/11/seven-steps-machine-learning-python.html)中涵盖的步骤：
- en: Basic Python Skills
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础 Python 技能
- en: Foundational Machine Learning Skills
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础机器学习技能
- en: Scientific Python Packages Overview
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 科学 Python 包概述
- en: 'Getting Started with Machine Learning in Python: Introduction & model evaluation'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用 Python 进行机器学习：介绍 & 模型评估
- en: 'Machine Learning Topics with Python: k-means clustering, decision trees, linear
    regression & logistic regression'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 的机器学习主题：k-means 聚类、决策树、线性回归 & 逻辑回归
- en: 'Advanced Machine Learning Topics with Python: Support vector machines, random
    forests, dimension reduction with PCA'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高级机器学习主题：支持向量机、随机森林、PCA 降维
- en: Deep Learning in Python
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python 中的深度学习
- en: As stated above, if you are looking to start from square one, I would suggest
    going back to the first article and proceeding accordingly. I will also note that
    the appropriate *getting started* material, including any and all installation
    instructions, are including in the previous article.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，如果你希望从头开始，我建议回到第一篇文章并按照顺序进行。我还要说明，适当的*入门*材料，包括所有安装说明，都包含在前一篇文章中。
- en: 'If, however, you are really green, I would start with the following, covering
    the absolute basics:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你真的很基础，我建议从以下内容开始，涵盖绝对基础：
- en: '[Machine Learning Key Terms, Explained](/2016/05/machine-learning-key-terms-explained.html),
    by Matthew Mayo'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习关键术语解释](/2016/05/machine-learning-key-terms-explained.html)，作者 Matthew
    Mayo'
- en: '[Statistical Classification on Wikipedia](https://en.wikipedia.org/wiki/Statistical_classification)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[维基百科上的统计分类](https://en.wikipedia.org/wiki/Statistical_classification)'
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html),
    by Alex Castrounis'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习：完整而详细的概述](/2016/10/machine-learning-complete-detailed-overview.html)，作者
    Alex Castrounis'
- en: 'If you are looking for some alternative or complementary approaches to learning
    the basics of machine learning, I have recently been enjoying Shai Ben-David''s
    video lectures and freely available textbook written with Shai Shalev-Shwartz.
    Find them both here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在寻找一些替代或补充的方式来学习机器学习的基础，我最近一直在欣赏 Shai Ben-David 的视频讲座和与 Shai Shalev-Shwartz
    合著的免费教科书。你可以在这里找到这两者：
- en: '[Shai Ben-David''s introductory machine learning video lectures](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm),
    University of Waterloo'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Shai Ben-David 的机器学习入门视频讲座](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm)，滑铁卢大学'
- en: '[Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html),
    by Shai Ben-David & Shai Shalev-Shwartz'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解机器学习：从理论到算法](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html)，作者
    Shai Ben-David 和 Shai Shalev-Shwartz'
- en: Remember, the introductory material does not all need to be digested before
    moving forward with the rest of the steps (in either this post or the original).
    Video lectures, texts, and other resources can be consulted when implementing
    models using the reflected machine learning algorithms, or when applicable concepts
    are being used practically in subsequent steps. Use your judgment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，入门材料并不需要在继续其他步骤之前完全消化（无论是在此帖子中还是在原始内容中）。在实施模型时可以查阅视频讲座、文本和其他资源，或者在后续步骤中实际应用相关概念时使用。请自行判断。
- en: 'Step 2: More Classification'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步：更多分类
- en: We begin with the new material by first strengthening our classification know-how
    and introducing a few additional algorithms. While part 1 of our post covered
    decision trees, support vector machines, and logistic regression -- as well as
    the ensemble classifier Random Forests -- we will add k-nearest neighbors, the
    Naive Bayes classier, and a multilayer perceptron into the mix.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过加强分类知识和引入一些额外算法来开始学习新材料。虽然我们帖子中的第1部分涵盖了决策树、支持向量机和逻辑回归——以及集成分类器随机森林——我们还将加入k最近邻、朴素贝叶斯分类器和多层感知器。
- en: '![Scikit-learn classifiers](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Scikit-learn 分类器](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)'
- en: Scikit-learn classifiers.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 分类器。
- en: '**k-nearest neighbors (kNN)** is a simple classifier and an example of a lazy
    learner, in which all computation occurs at classification time (as opposed to
    occurring during a training step ahead of time). kNN is [non-parametric](https://en.wikipedia.org/wiki/Nonparametric_statistics),
    and functions by comparing a data instance with the *k* closest instances when
    making decisions about how it should be classified.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**k最近邻（kNN）** 是一种简单的分类器，是懒惰学习者的一个例子，其中所有计算发生在分类时（而不是在训练阶段提前发生）。kNN 是 [非参数的](https://en.wikipedia.org/wiki/Nonparametric_statistics)，通过在做出分类决策时将数据实例与
    *k* 个最近实例进行比较来工作。'
- en: '[K-Nearest Neighbor classification using python](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 进行 K-最近邻分类](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)'
- en: '**Naive Bayes** is a classifier based on [Bayes'' Theorem](https://en.wikipedia.org/wiki/Bayes''_theorem).
    It assumes that there is independence among features, and that the presence of
    any particular feature in one class is not related to any other feature''s presence
    in the same class.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯** 是一种基于 [贝叶斯定理](https://en.wikipedia.org/wiki/Bayes''_theorem) 的分类器。它假设特征之间是独立的，并且某个类中特定特征的存在与同一类中其他特征的存在没有关系。'
- en: '[Document Classification with scikit-learn](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html),
    by Zac Stewart'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 scikit-learn 进行文档分类](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html)，作者
    Zac Stewart'
- en: The **multilayer perceptron (MLP)** is a simple [feedforward](https://en.wikipedia.org/wiki/Feedforward_neural_network)
    neural network, consisting of multiple layers of nodes, where each layer is fully
    connected with the layer which comes after it. The MLP was introduced in Scikit-learn
    version 0.18.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**多层感知器（MLP）** 是一种简单的 [前馈](https://en.wikipedia.org/wiki/Feedforward_neural_network)
    神经网络，由多个节点层组成，每一层与其后续层完全连接。MLP 在 Scikit-learn 版本 0.18 中引入。'
- en: First read an overview of the MLP classifier from the Scikit-learn documentation,
    and then practice implementation with a tutorial.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读 Scikit-learn 文档中的 MLP 分类器概述，然后通过教程进行实践。
- en: '[Neural network models (supervised)](http://scikit-learn.org/stable/modules/neural_networks_supervised.html),
    Scikit-learn documentation'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络模型（有监督）](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)，Scikit-learn
    文档'
- en: '[A Beginner’s Guide to Neural Networks with Python and SciKit Learn 0.18!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html),
    by Jose Portilla'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 和 SciKit Learn 0.18 的神经网络入门指南!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html)，作者
    Jose Portilla'
- en: 'Step 3: More Clustering'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步：更多聚类
- en: We now move on to clustering, a form of unsupervised learning. In the first
    post we covered the k-means algorithm; we will introduce DBSCAN and Expectation-maximization
    (EM) herein.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们转向聚类，这是一种无监督学习形式。在第一篇文章中，我们介绍了 k-means 算法；本文将介绍 DBSCAN 和期望最大化（EM）。
- en: '![Scikit-learn clustering algorithms](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![Scikit-learn 聚类算法](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)'
- en: Scikit-learn clustering algorithms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 聚类算法。
- en: 'First off, read these introductory posts; the first is a quick comparison of
    k-means and EM clustering techniques, a nice segue into new forms of clustering,
    and the second is an overview of clustering techniques available in Scikit-learn:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，阅读这些介绍性文章；第一篇是对 k-means 和 EM 聚类技术的快速比较，是进入新型聚类形式的良好过渡，第二篇则是 Scikit-learn
    中可用聚类技术的概述：
- en: '[Comparing Clustering Techniques: A Concise Technical Overview](/2016/09/comparing-clustering-techniques-concise-technical-overview.html),
    by Matthew Mayo'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较聚类技术：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)，作者
    Matthew Mayo'
- en: '[Comparing different clustering algorithms on toy datasets](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html),
    Scikit-learn documentation'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在玩具数据集上比较不同的聚类算法](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)，Scikit-learn
    文档'
- en: '**Expectation-maximization (EM)** is a probabilistic clustering algorithm,
    and, as such, involves determining the probabilities that instances belong to
    particular clusters. EM ”approaches maximum likelihood or maximum a posteriori
    estimates of parameters in statistical models” (Han, Kamber & Pei). The EM process
    begins with a set of parameters, iterating until clustering is maximized, with
    respect to *k* clusters.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**期望最大化（EM）** 是一种概率聚类算法，涉及确定实例属于特定簇的概率。EM "接近最大似然或最大后验估计统计模型中的参数"（Han, Kamber
    & Pei）。EM 过程从一组参数开始，迭代直到聚类在 *k* 个簇的情况下最大化。'
- en: First read a tutorial on the EM algorithm. Next, have a look at the relevant
    Scikit-learn documentation. Finally, follow a tutorial and implement EM clustering
    yourself with Python.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读有关 EM 算法的教程。接下来，查看相关的 Scikit-learn 文档。最后，跟随教程并用 Python 实现 EM 聚类。
- en: '[A Tutorial on the Expectation Maximization (EM) Algorithm](/2016/08/tutorial-expectation-maximization-algorithm.html),
    by Elena Sharova'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[期望最大化（EM）算法教程](/2016/08/tutorial-expectation-maximization-algorithm.html)，作者
    Elena Sharova'
- en: '[Gaussian mixture models](http://scikit-learn.org/stable/modules/mixture.html),
    Scikit-learn documentation'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯混合模型](http://scikit-learn.org/stable/modules/mixture.html)，Scikit-learn
    文档'
- en: '[Quick introduction to gaussian mixture models with Python](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/),
    by Tiago Ramalho'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 快速介绍高斯混合模型](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/)，作者
    Tiago Ramalho'
- en: 'If "[Gaussian mixture models](https://en.wikipedia.org/wiki/Mixture_model)"
    is confusing at first glance, this relevant section from the Scikit-learn documentation
    should alleviate any unnecessary worries:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果"[高斯混合模型](https://en.wikipedia.org/wiki/Mixture_model)"乍一看让人感到困惑，这部分来自 Scikit-learn
    文档的内容应该能缓解你的不必要的担忧：
- en: The `GaussianMixture` object implements the expectation-maximization (EM) algorithm
    for fitting mixture-of-Gaussian models.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`GaussianMixture` 对象实现了期望最大化（EM）算法，用于拟合高斯混合模型。'
- en: '**Density-based spatial clustering of applications with noise (DBSCAN)** operates
    by grouping densely-packed data points together, and designating low-density data
    points as outliers.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于密度的空间聚类算法（DBSCAN）**通过将密集的数据点分组在一起，并将低密度的数据点标记为异常值来进行操作。'
- en: 'First read and follow an example implementation of DBSCAN from Scikit-learn''s
    documentation, and then follow a concise tutorial:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读并遵循Scikit-learn文档中的DBSCAN示例实现，然后跟随简明教程：
- en: '[Demo of DBSCAN clustering algorithm](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html),
    Scikit-learn documentation'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DBSCAN聚类算法演示](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)，Scikit-learn文档'
- en: '[Density-based clustering algorithm (DBSCAN) and Implementation](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于密度的聚类算法（DBSCAN）及其实现](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT工作'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
