- en: Fast and Intuitive Statistical Modeling with Pomegranate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/12/fast-intuitive-statistical-modeling-pomegranate.html](https://www.kdnuggets.com/2020/12/fast-intuitive-statistical-modeling-pomegranate.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: What is Pomegranate?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First and foremost, it is a delicious fruit.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c763727dc1da12b587b94061e7bd3bd0.png)'
  prefs: []
  type: TYPE_IMG
- en: Image source: [Pixabay](https://pixabay.com/photos/pomegranate-fruit-seeds-food-fresh-3259161/) (Free
    for commercial use)
  prefs: []
  type: TYPE_NORMAL
- en: But there is a double delight for fruit-lover data scientists!
  prefs: []
  type: TYPE_NORMAL
- en: It is also [a Python package](https://pomegranate.readthedocs.io/en/latest/index.html) that
    implements fast and flexible probabilistic models ranging from individual probability
    distributions to compositional models such as [**Bayesian networks**](https://en.wikipedia.org/wiki/Bayesian_network) and [**Hidden
    Markov Models**](https://en.wikipedia.org/wiki/Hidden_Markov_model).
  prefs: []
  type: TYPE_NORMAL
- en: The central idea behind this package is that **all probabilistic models can
    be viewed as a probability distribution. **That means they all yield probability
    estimates for samples and can be updated/fitted given samples and their associated
    weights. The primary consequence of this realization is that the implemented classes
    can be stacked and chained more flexibly than those available from other common
    packages.
  prefs: []
  type: TYPE_NORMAL
- en: What’s different from Scipy or Numpy?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a fair question. However, you will see that the implemented classes
    in the Pomegranate package are super intuitive and have uniform interfaces although
    they cover a wide range of statistical modeling aspects,
  prefs: []
  type: TYPE_NORMAL
- en: General distributions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Markov chains
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hidden Markov Models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayes classifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is like having useful methods from multiple Python libraries together with
    a uniform and intuitive API.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see some cool usage of this nifty little package.
  prefs: []
  type: TYPE_NORMAL
- en: Probability distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let is initialize with a `NormalDistribution` class.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/703465a91389ed5457606cff8252a516.png)'
  prefs: []
  type: TYPE_IMG
- en: Generate a few samples,
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/ad5bcb1ff9b1d91e8dc2b6e9e90b22d6.png)'
  prefs: []
  type: TYPE_IMG
- en: We can, now, easily check the probability of a sample data point (or an array
    of them) belonging to this distribution,
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/db8cb522d3cc5baa34e5988a56350053.png)'
  prefs: []
  type: TYPE_IMG
- en: Fitting data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is where it gets more interesting. Fitting with a data sample is super
    easy and fast.
  prefs: []
  type: TYPE_NORMAL
- en: As initialized above, we can check the parameters (mean and std. dev) of the `n1` object.
    We expect them to be 5.0 and 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/6a1cfdf759de6d173fe69898f8172835.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let us create some synthetic data by adding random noise to a Gaussian.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c5993281371810a23c1b2e782ab25ee5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: We can fir this new data to the `n1` object and then check the estimated parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/7c658d2d264e526dcf5c8c368257a455.png)'
  prefs: []
  type: TYPE_IMG
- en: Phew! It looks like that `n1` has updated its estimated mean and std.dev parameters
    to match with the input data now. The peak of the histogram is close to 4.0 from
    the plot and that’s what the estimated mean shows.
  prefs: []
  type: TYPE_NORMAL
- en: Create the distribution directly from a data sample
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We showed how to fit data to a distribution class. Alternatively, one can create
    the object directly from the data,
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/bc0cd9e59ce71876e85f096f5ae09646.png)'
  prefs: []
  type: TYPE_IMG
- en: Plotting (histogram) is natively supported
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Plotting is easy on the distribution class with the `plot()` method, which also
    supports all the keywords for a Matplotlib histogram method. We illustrate by
    plotting a Beta distribution object.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a229ebbbe710bb318cda2780f75080b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: Discrete distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is where it gets more interesting. Instead of passing parameters to a known
    statistical distribution (e.g. Normal or Beta), you can pass in a **dictionary** where
    keys can be ***any objects*** and values are the corresponding probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an illustration with some Hogwarts characters. Note, **when we try to
    calculate the probability of ‘Hagrid’, we get a flat zero** because the distribution
    does not have any finite probability for the ‘Hagrid’ object.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/756bc6090c3e728c4149c6b0dfd076a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Fitting data to a discrete distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can do much more interesting things by fitting data to a discrete distribution
    object. Here is an example with a fictitious DNA nucleic acid sequence. It is
    common to have this type of sequence data in a string, and we can read the data
    and calculate the probabilities of the four nucleic acids in the sequence with
    simple code.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/323bfd09209999834b0c5979ba65cdfe.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple DNA sequence matching application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can write an extremely simple (and naive) DNA sequence matching application
    in just a few lines of code. The assumption is that the** sequences, which have
    similar frequencies/probabilities of nucleic acids, are closer to each other**.
    Somewhat arbitrarily, we choose to calculate the root-mean-square-distance for
    this distance metric.
  prefs: []
  type: TYPE_NORMAL
- en: You can look at the [Jupyter notebook](https://github.com/tirthajyoti/Stats-Maths-with-Python/blob/master/Pomegranate.ipynb) for
    the helper function and the exact code, but here is a sample output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/41e20711244ff6980df8d267a261e3b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Gaussian Mixture Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pomegranate makes working with data, coming from multiple Gaussian distributions,
    easy.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create some synthetic data,
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/0e2981d673fa702e3dd1e3afab1dc9d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: As usual, we can create a model directly from the data with one line of code.
    When we print the estimated parameters of the model, we observe that it has captured
    the ground truth (the parameters of the generator distributions) pretty well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/6b39f4d7d708a32e5c4fcf59a6d2c21d.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the model is generated with data samples, we can calculate the probabilities
    and plot them easily. The code is in the [Notebook](https://github.com/tirthajyoti/Stats-Maths-with-Python/blob/master/Pomegranate.ipynb),
    here is the illustrative plot — the left side shows a single Gaussian, and the
    right-side shows a Mixture Model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/5afcdba8190d030088333622206e0012.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: Markov Chain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can easily model a simple Markov chain with Pomegranate and calculate the
    probability of any given sequence.
  prefs: []
  type: TYPE_NORMAL
- en: We will have the quintessential rainy-cloudy-sunny example for this one. Here
    is the transition probability table,
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/914f7bed0b3dce6fe89753a53ea901a1.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Figure](../Images/a4609561aa136af2688d48e3eb90d48d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by the author
  prefs: []
  type: TYPE_NORMAL
- en: We also know that, on average, there are 20% rainy days, 50% sunny days, and
    30% cloudy days. We encode both the discrete distribution and the transition matrix
    in the `MarkovChain` class,
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/d263fea7b5fa5d2f6e8fa10559c82617.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we can calculate the probability of any given sequence using this object.
    For example, if you look at the table above, you can convince yourself that **a
    sequence like “*Cloudy-Rainy-Cloudy*” has a high likelihood whereas a sequence
    like “*Rainy-Sunny-Rainy-Sunny*” is unlikely to show up**. We can confirm this
    with precise probability calculations (we take logarithm to handle small probability
    numbers),
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/6dce0ded2aab26e85c87c684046346e1.png)'
  prefs: []
  type: TYPE_IMG
- en: Fitting data to a GMM class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We write a small function to generate a random sequence of rainy-cloudy-sunny
    days and feed that to the GMM class.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/3a0b35730c28dad0ff586cb9670f763b.png)'
  prefs: []
  type: TYPE_IMG
- en: First, we feed this data for 14 days’ observation— “Rainy-Sunny-Rainy-Sunny-Rainy-Sunny-Rainy-Rainy-Sunny-Sunny-Sunny-Rainy-Sunny-Cloudy”.
    The probability transition table is calculated for us.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/2af80fb6e4d3310f0099d575073acdb0.png)'
  prefs: []
  type: TYPE_IMG
- en: If we generate a random sequence of 10 years i.e. 3650 days, then we get the
    following table. **Because our random generator is uniform, as per the characteristic
    of a Markov Chain, the transition probabilities will assume limiting values of
    ~0.333** each.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/3b4088637259d45c6ead59283ddaffcb.png)'
  prefs: []
  type: TYPE_IMG
- en: Hidden Markov Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are a lot of cool things you can do with the HMM class in Pomegranate.
    Here, we just show a small example of **detecting the high-density occurrence
    of a sub-sequence within a long string** using HMM predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we are recording the names of four characters in a Harry Potter novel
    as they appear one after another in a chapter, and we are interested in detecting
    some portion where Harry and Dumbledore are appearing together. However, because
    they may be conversing and may mention Ron or Hagrid’s names in these portions,
    the sub-sequence is not clean i.e. it does not strictly contain Harry and Dumbledore’s
    names.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/d5af1845d9a8c8181c501ecde5b111f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Collage created by author from Wikimedia Commons and Pixabay images
  prefs: []
  type: TYPE_NORMAL
- en: Following code initiates a uniform probability distribution, a skewed probability
    distribution, two states with names, and the HMM model with these states.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/81f86a6c986642934159c8ea4342ce8c.png)'
  prefs: []
  type: TYPE_IMG
- en: Then, we need to add the state transition probabilities and ‘bake’ the model
    for finalizing the internal structure. Note the **high self-loop probabilities** for
    the transition i.e. the states tend to stay in their current state with high likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/ef435a6fa8d69e8298f815a3724ad55d.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we have an observed sequence and we will feed this to the HMM model as
    an argument to the `predict` method. The transition and emission probabilities
    will be calculated and a sequence of 1’s and 0’s will be predicted where we can **notice
    the island of 0’s indicating the portion rich with the appearance of ‘Harry-Dumbledore’
    together**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/5b1e4faed165ad47cb74d05a8862243c.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we introduced a fast and intuitive statistical modeling library
    called Pomegranate and showed some interesting usage examples. Many more tutorials
    can be found here. Examples in this article were also inspired by these tutorials.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Pomegranate Tutorials from their Github repo**](https://github.com/jmschrei/pomegranate/tree/master/tutorials)'
  prefs: []
  type: TYPE_NORMAL
- en: The library offers utility classes from various statistical domains — general
    distributions, Markov chain, Gaussian Mixture Models, Bayesian networks — with
    uniform API that can be instantiated quickly with observed data and then can be
    used for parameter estimation, probability calculations, and predictive modeling.
  prefs: []
  type: TYPE_NORMAL
- en: You can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    code, ideas, and resources in machine learning and data science. If you are, like
    me, passionate about AI/machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter](https://twitter.com/tirthajyotiS).
  prefs: []
  type: TYPE_NORMAL
- en: '[**Tirthajyoti Sarkar - Sr. Principal Engineer - Semiconductor, AI, Machine
    Learning**](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)'
  prefs: []
  type: TYPE_NORMAL
- en: Making data science/ML concepts easy to understand through writing
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/statistical-modeling-with-pomegranate-fast-and-intuitive-4d605d9c33a9).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Overview of data distributions](/2020/06/overview-data-distributions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Before Probability Distributions](/2020/07/before-probability-distributions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing Machine Learning Models: Statistical vs. Practical Significance](/2019/01/comparing-machine-learning-models-statistical-vs-practical-significance.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple and Fast Data Streaming for Machine Learning Projects](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Fast and Effective Way to Audit ML for Fairness](https://www.kdnuggets.com/2023/01/fast-effective-way-audit-ml-fairness.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
