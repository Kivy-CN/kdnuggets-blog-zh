# 使用 K-最近邻分类心脏病

> 原文：[https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html](https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html?page=2#comments)

对象分类是各种领域研究和应用的重要领域。在完全了解基础概率的情况下，贝叶斯决策理论提供了最佳错误率。在信息缺失的情况下，许多算法利用样本间的距离或相似性作为分类手段。

本文分为两部分。第一部分，我们将讨论 K-NN 机器学习算法，第二部分，我们将实际应用 K-NN 并对心脏病患者进行分类。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT

* * *

**目录**

1.  K-NN 算法是什么？

1.  K-NN 算法是如何工作的？

1.  什么时候选择 K-NN？

1.  如何选择 K 的最佳值？

1.  什么是维度灾难？

1.  使用 Python 的 sci-kit learn 构建 K-NN 分类器。

1.  如何提高分类器的性能？

### K-NN 算法是什么？

![](../Images/fe225aa90f1f3ec39506d32db01afc17.png)

[K-NN 算法表示](https://acadgild.com/blog/k-nearest-neighbor-algorithm)

K-NN 或者说 K-最近邻算法，因其简单性和准确性，目前是业界最著名的分类算法之一。

K-NN 是一种简单的算法，它存储所有可用的案例，并根据相似性度量（例如，距离函数）对新案例进行分类。KNN 从 1970 年代初期就被用作统计估计和模式识别的非参数技术。

该算法假设相似的事物会彼此接近。换句话说，相似的实体会一起存在。

### K-NN 算法是如何工作的？

在 K-NN 中，K 是最近邻的数量。邻居的数量是核心决定因素。**如果类别数量为 2，K 通常是奇数**。当 K=1 时，该算法称为最近邻算法。这是最简单的情况。

在下图中，假设黄色的“**？**”表示P是需要预测标签的点。首先，找到与P最近的一个点，然后将最近点的标签分配给P。

![](../Images/861a2f7b786e09051bbd0d37b8db1857.png)

其次，你找到与P最接近的k个点，然后通过其K个邻居的多数投票对点进行分类。每个对象对其类别进行投票，票数最多的类别被作为预测结果。为了找到最相似的点，我们使用距离度量，如欧几里得距离、汉明距离、曼哈顿距离和闵可夫斯基距离，计算点之间的距离。算法具有以下基本步骤：

1.  计算距离

1.  查找最近的邻居

1.  为标签投票

![](../Images/be2fc1f9343745ff2ec1e5a9747b2f7a.png)

用于计算点P及其最近邻之间距离的三种最常用的距离度量表示为：

![](../Images/82d48a4486aae9019ed734c5115b1878.png)

在本文中，我们将深入了解欧几里得距离，因此先了解它。

**欧几里得距离：** 它是最常用的距离度量，也称为简单距离。当数据是密集或连续时，强烈推荐使用欧几里得距离度量。欧几里得距离是最佳的接近度量。两点之间的欧几里得距离是连接它们的路径的长度。毕达哥拉斯定理给出了两点之间的距离。

下图展示了如何在二维平面中计算两点之间的欧几里得距离。

![图](../Images/181a263e28b55514150e7ae38d495336.png)

[二维空间中两点的欧几里得距离](https://mccormickml.com/2013/08/15/the-gaussian-kernel/)

### 什么时候使用K-NN算法？

KNN可用于分类和回归预测问题。然而，在工业中，它更广泛用于分类问题。为了评估任何技术，我们通常关注三个重要方面：

1.  易于解释输出

1.  算法的计算时间

1.  预测能力

让我们将KNN与不同的模型进行比较：

![图](../Images/d52f21040e5ef16e8e24e34609aa2528.png)

来源：Analytics Vidhya

正如你所见，K-NN在我们考虑的各个方面超越了逻辑回归、CART和随机森林。

### 如何选择K的最佳值？

K-NN中的邻居数量（K）是一个超参数，你需要在构建模型时选择。你可以将K视为预测模型的控制变量。

现在，选择K的最佳值最好是通过首先检查数据来完成。一般来说，大的K值更精确，因为它减少了整体噪声，但没有保证。交叉验证是另一种通过使用独立数据集来验证K值，从而追溯确定良好K值的方法。历史上，大多数数据集的最佳K值在3到10之间。这比1NN（当K=1时）产生更好的结果。

通常，如果类别数为偶数，则选择奇数值。你也可以通过在不同的K值上生成模型并检查其性能来进行验证。

### 维度诅咒

K-NN在特征数量较少时表现更好，而不是特征数量较多。可以说，当特征数量增加时，需要更多的数据。维度的增加也会导致过拟合问题。为了避免过拟合，所需的数据量需要随着维度的增加而呈指数增长。这种高维度问题被称为维度诅咒。

![](../Images/40e1bba71a6b963a2370165dc5a23d79.png)

从上述图形表示中可以清楚地看到，随着特征（维度）数量的增加，你的模型性能下降。

为了应对维度诅咒的问题，需要在应用任何机器学习算法之前进行主成分分析（PCA），或者也可以使用特征选择方法。研究表明，在大维度下，欧几里得距离不再有用。因此，可以选择其他测量方法，如余弦相似度，它受高维度的影响较小。

> **KNN算法可以与最精确的模型竞争，因为它提供了高度准确的预测。因此，你可以使用KNN算法进行那些需要高准确性但不需要人类可读模型的应用。 — **来源：[IBM](https://www.ibm.com/support/knowledgecenter/en/SS6NHC/com.ibm.swg.im.dashdb.analytics.doc/doc/r_knn_usage.html)

计算K-NN算法的步骤：

1.  确定参数K = 最近邻的数量。

1.  计算查询实例与所有训练样本之间的距离。

1.  排序距离，并根据第K小距离确定最近邻。

1.  收集最近邻的类别

1.  使用最近邻的类别的简单多数作为查询的预测值。

在下一部分，我们将使用K-NN算法解决一个实际场景。

### 更多相关内容

+   [从理论到实践：构建一个k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [分类的最近邻](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn中的K最近邻](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [使用BERT对长文本进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)

+   [使用Python自动化Microsoft Excel和Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)

+   [如何使用Python确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)
