- en: 'A Layman’s Guide to Data Science. Part 3: Data Science Workflow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学的外行指南。第3部分：数据科学工作流程
- en: 原文：[https://www.kdnuggets.com/2020/07/laymans-guide-data-science-workflow.html](https://www.kdnuggets.com/2020/07/laymans-guide-data-science-workflow.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/07/laymans-guide-data-science-workflow.html](https://www.kdnuggets.com/2020/07/laymans-guide-data-science-workflow.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Sciforce](https://sciforce.solutions)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Sciforce](https://sciforce.solutions)**。'
- en: 'Note: here is part 1: [**How to Become a (Good) Data Scientist – Beginner Guide**](https://www.kdnuggets.com/2019/10/good-data-scientist-beginner-guide.html)
    and'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：这是第1部分：[**如何成为一名（优秀的）数据科学家 – 初学者指南**](https://www.kdnuggets.com/2019/10/good-data-scientist-beginner-guide.html)
    和
- en: 'part 2: [**A Layman’s Guide to Data Science. How to Build a Data Project**](https://www.kdnuggets.com/2020/04/guide-data-science-build-data-project.html)
    of this series'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第2部分：[**数据科学的外行指南。如何构建数据项目**](https://www.kdnuggets.com/2020/04/guide-data-science-build-data-project.html)
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](../Images/d4b0e7f575720d537f17451ed86bb3af.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4b0e7f575720d537f17451ed86bb3af.png)'
- en: '*Data science workflow.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据科学工作流程。*'
- en: By now, you have already gained enough [knowledge and skills about Data Science](https://medium.com/sciforce/a-laymans-guide-to-data-science-how-to-become-a-good-data-scientist-97927ad51ed8) and [have
    built your first (or even your second and third) project](https://www.kdnuggets.com/2020/04/guide-data-science-build-data-project.html).
    At this point, it is time to improve your workflow to facilitate further development
    process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经获得了足够的[数据科学知识和技能](https://medium.com/sciforce/a-laymans-guide-to-data-science-how-to-become-a-good-data-scientist-97927ad51ed8)和[完成了你的第一个（或甚至是第二个和第三个）项目](https://www.kdnuggets.com/2020/04/guide-data-science-build-data-project.html)。此时，是时候改进你的工作流程，以便进一步发展过程。
- en: There is no specific template for solving any data science problem (otherwise,
    you’d see it in the first textbook you come across). Each new dataset and each
    new problem will lead to a different roadmap. However, there are similar high-level
    steps in many different projects.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 解决任何数据科学问题没有特定的模板（否则你会在你遇到的第一本教科书中看到它）。每个新的数据集和每个新的问题都会导致不同的路线图。然而，许多不同项目中有类似的高层步骤。
- en: In this post, we offer a clean workflow that can be used as a basis for data
    science projects. Every stage and step in it, of course, can be addressed on its
    own and can even be implemented by different specialists in larger-scale projects.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们提供了一个可以作为数据科学项目基础的清晰工作流程。它的每个阶段和步骤当然可以单独处理，甚至可以由更大规模项目中的不同专家实施。
- en: Framing the problem and the goals
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定问题和目标
- en: As you already know, at the starting point, you’re asking questions and trying
    to get a handle on what data you need. Therefore, think of the problem you are
    trying to solve. What do you want to learn more about? For now, forget about modeling,
    evaluation metrics, and data science-related things. Clearly stating your problem
    and defining goals are the first step to providing a good solution. Without it,
    you could lose the track in the data-science forest.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你已经知道的，在起始点，你会提出问题并尝试掌握你需要什么数据。因此，考虑你想解决的问题。你想了解更多什么？现在，忘记建模、评估指标和数据科学相关的事物。明确陈述问题和定义目标是提供良好解决方案的第一步。没有这些，你可能会在数据科学的森林中迷失方向。
- en: Data Preparation Phase
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备阶段
- en: In any Data Science project, getting the right kind of data is critical. Before
    any analysis can be done, you must acquire the relevant data, reformat it into
    a form that is amenable to computation and clean it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何数据科学项目中，获取正确的数据是关键。在进行任何分析之前，你必须获取相关数据，将其重新格式化为适合计算的形式，并进行清理。
- en: '![](../Images/32d1dc2f3d53e0ed7d21a1e13d1d9ba3.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32d1dc2f3d53e0ed7d21a1e13d1d9ba3.png)'
- en: '**Acquire data**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取数据**'
- en: 'The first step in any data science workflow is to acquire the data to analyze.
    Data can come from a variety of sources:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 任何数据科学工作流的第一步是获取要分析的数据。数据可以来自各种来源：
- en: imported from CSV files from your local machine;
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从本地计算机的CSV文件中导入；
- en: queried from SQL servers;
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从SQL服务器中查询；
- en: stripped from online repositories such as public websites;
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从在线存储库中剥离，如公共网站；
- en: streamed on-demand from online sources via an API;
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API从在线源按需流式传输；
- en: automatically generated by physical apparatus, such as scientific lab equipment
    attached to computers;
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由物理设备自动生成，如连接到计算机的科学实验室设备；
- en: generated by computer software, such as logs from a webserver.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由计算机软件生成，如来自网络服务器的日志。
- en: In many cases, collecting data can become messy, especially if the data isn’t
    something people have been collecting in an organized fashion. You’ll have to
    work with different sources and apply a variety of tools and methods to collect
    a dataset.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，收集数据可能会变得混乱，特别是当数据不是以有组织的方式收集时。你需要处理不同的来源，并应用各种工具和方法来收集数据集。
- en: 'There are several key points to remember while collecting data:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 收集数据时有几个关键点需要记住：
- en: '***Data provenance***: It is important to accurately track provenance, i.e.,
    where each piece of data comes from and whether it is still up-to-date since data
    often needs to be re-acquired later to run new experiments. Re-acquisition can
    be helpful if the original data sources get updated or if researchers want to
    test alternate hypotheses. Besides, we can use provenance to trace back downstream
    analysis errors to the original data sources.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据来源***：准确追踪数据来源，即每一条数据来自何处以及是否仍然是最新的非常重要，因为数据常常需要重新获取以进行新的实验。重新获取数据是有帮助的，特别是当原始数据源更新时，或者研究人员想要测试替代假设时。此外，我们可以利用数据来源追溯下游分析错误到原始数据源。'
- en: '***Data management***: To avoid data duplication and confusion between different
    versions, it is critical to assign proper names to data files that they create
    or download and then organize those files into directories. When new versions
    of those files are created, corresponding names should be assigned to all versions
    to be able to keep track of their differences. For instance, scientific lab equipment
    can generate hundreds or thousands of data files that scientists must name and
    organize before running computational analyses on them.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据管理***：为了避免数据重复和不同版本之间的混淆，必须为创建或下载的数据文件分配适当的名称，然后将这些文件组织到目录中。当创建这些文件的新版本时，所有版本应分配相应的名称，以便能够跟踪它们之间的差异。例如，科学实验室设备可以生成数百或数千个数据文件，科学家们必须在对其进行计算分析之前对这些文件进行命名和组织。'
- en: '***Data storage***: With modern almost limitless access to data, it often happens
    that there is so much data that it cannot fit on a hard drive, so it must be stored
    on remote servers. While cloud services are gaining popularity, a significant
    amount of data analysis is still done on desktop machines with data sets that
    fit on modern hard drives (i.e., less than a terabyte).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据存储***：随着现代数据访问几乎没有限制，常常出现数据量如此庞大的情况，以至于无法放入硬盘中，因此必须存储在远程服务器上。尽管云服务越来越受欢迎，但大量的数据分析仍然是在桌面计算机上进行的，数据集可以适应现代硬盘（即少于一太字节）。'
- en: '![](../Images/27087f3ec8354e90f30977526e647bd0.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27087f3ec8354e90f30977526e647bd0.png)'
- en: '**Reformat and clean data**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**重新格式化和清理数据**'
- en: Raw data is usually not in a convenient format to run an analysis since it was
    formatted by somebody else without that analysis in mind. Moreover, raw data often
    contains semantic errors, missing entries, or inconsistent formatting, so it needs
    to be “cleaned” prior to analysis.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据通常不以便于分析的格式出现，因为这些数据是由其他人格式化的，而没有考虑到分析的需求。此外，原始数据通常包含语义错误、缺失条目或格式不一致，因此在分析之前需要“清理”。
- en: '***Data wrangling (munging)*** is the process of cleaning data, putting everything
    together into one workspace, and making sure your data has no faults in it. It
    is possible to reformat and clean the data either manually or by writing scripts.
    Getting all of the values in the correct format can involve stripping characters
    from strings, converting integers to floats, or many other things. Afterward,
    it is necessary to deal with missing values and null values that are common in
    sparse matrices. The process of handling them is called ***missing data imputation*** ,
    where the missing data are replaced with substituted data.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据整理（munging）***是清理数据的过程，将所有内容放入一个工作空间，并确保数据没有缺陷。可以通过手动或编写脚本来重新格式化和清理数据。将所有值转换为正确的格式可能涉及从字符串中剥离字符、将整数转换为浮点数等许多操作。之后，需要处理缺失值和稀疏矩阵中常见的空值。处理这些数据的过程称为***缺失数据插补***，即用替代数据替换缺失的数据。'
- en: '***Data integration*** is a related challenge since data from all sources needs
    to be integrated into a central MySQL relational database, which serves as the
    master data source for his analyses.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据集成***是一个相关的挑战，因为所有来源的数据需要整合到一个中心MySQL关系数据库中，该数据库作为分析的主数据源。'
- en: Usually, it consumes a lot of time and cannot be fully automated, but at the
    same time, it can provide insights into the data structure and quality as well
    as the models and analyses that might be optimal to apply.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这需要大量时间，无法完全自动化，但同时它可以提供有关数据结构和质量以及可能应用的模型和分析的洞察。
- en: '![](../Images/88a694d4c783f6454db005e4e097bdf9.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88a694d4c783f6454db005e4e097bdf9.png)'
- en: '**Explore the data**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索数据**'
- en: 'Here’s where you’ll start getting summary-level insights of what you’re looking
    at and extracting the large trends. At this step, there are three dimensions to
    explore: whether the data imply supervised learning or unsupervised learning?
    Is this a classification problem, or is it a regression problem? Is this a prediction
    problem or an inference problem? These three sets of questions can offer a lot
    of guidance when solving your data science problem.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你将开始获取关于你所查看内容的概要级洞察，并提取大的趋势。在这一步，有三个维度需要探索：数据是否暗示监督学习还是无监督学习？这是分类问题，还是回归问题？这是预测问题还是推断问题？这三组问题在解决数据科学问题时可以提供很多指导。
- en: There are many tools that help you understand your data quickly. You can start
    by checking out the first few rows of the data frame to get the initial impression
    of the data organization. Automatic tools incorporated in multiple libraries,
    such as Pandas’ .describe(), can quickly give you the mean, count, standard deviation,
    and you might already see things worth diving deeper into. With this information,
    you’ll be able to determine which variable is our target and which features we
    think are important.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多工具可以帮助你快速理解数据。你可以从检查数据框的前几行开始，获得数据组织的初步印象。集成在多个库中的自动工具，如Pandas的.describe()，可以快速提供均值、计数、标准差，你可能已经会发现值得深入研究的内容。有了这些信息，你将能够确定哪个变量是目标，哪些特征是重要的。
- en: Analysis Phase
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析阶段
- en: Analysis is the core phase of data science that includes writing, executing,
    and refining computer programs to analyze and obtain insights from the data prepared
    at the previous phase. Though there are many programming languages for data science
    projects ranging from interpreted “scripting” languages such as Python, Perl,
    R, and MATLAB to compiled ones such as Java, C, C++, or even Fortran, the workflow
    for writing analysis software is similar across the languages.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分析是数据科学的核心阶段，包括编写、执行和完善计算机程序，以从前一阶段准备的数据中分析并获取洞察。尽管有许多编程语言用于数据科学项目，从解释型的“脚本”语言如Python、Perl、R和MATLAB到编译型的语言如Java、C、C++或甚至Fortran，但编写分析软件的工作流程在不同语言中是类似的。
- en: As you can see, analysis is a repeated *iteration cycle* of editing scripts
    or programs, executing to produce output files, inspecting the output files to
    gain insights and discover mistakes, debugging, and re-editing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，分析是一个重复的*迭代循环*，涉及编辑脚本或程序、执行以生成输出文件、检查输出文件以获取洞察和发现错误、调试以及重新编辑。
- en: '![](../Images/e99fad50e35a25b75368c730230eb9d5.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e99fad50e35a25b75368c730230eb9d5.png)'
- en: '**Baseline Modeling**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**基线建模**'
- en: As a data scientist, you will build a lot of models with a variety of algorithms
    to perform different tasks. At the first approach to the task, it is worthwhile
    to avoid advanced complicated models but to stick to simpler and more traditional ***linear
    regression*** for regression problems and ***logistic regression*** for classification
    problems as a baseline upon which you can improve.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你将构建许多使用不同算法的模型来执行不同任务。在处理任务的初期，值得避免使用复杂的高级模型，而是坚持使用更简单、更传统的***线性回归***用于回归问题，***逻辑回归***用于分类问题作为基线，从而进行改进。
- en: At the model preprocessing stage, you can separate out features from dependent
    variables, scale the data, and use a train-test-split or cross-validation to prevent
    overfitting of the model — the problem when a model too closely tracks the training
    data and doesn’t perform well with new data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型预处理阶段，你可以将特征与依赖变量分开，缩放数据，并使用训练-测试拆分或交叉验证来防止模型过拟合——过拟合是指模型过于紧密地跟踪训练数据，并且在新数据上表现不佳的问题。
- en: With the model ready, it can be fitted on the training data and tested by having
    it predict *y *values for the *X_test* data. Finally, the model is evaluated with
    the help of [metrics](https://www.saedsayad.com/model_evaluation_r.htm) that are
    appropriate for the task, such as [R-squared](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit) for
    regression problems and [accuracy](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/) or [ROC-AUC ](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)scores
    for classification tasks.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准备好后，可以在训练数据上进行拟合，并通过预测*X_test*数据的*y*值来进行测试。最后，使用适合任务的[评估指标](https://www.saedsayad.com/model_evaluation_r.htm)来评估模型，如回归问题的[R平方](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)和分类任务的[准确率](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/)或[ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)分数。
- en: '![](../Images/b623b8a5fcbbb667dd0fb21206201825.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b623b8a5fcbbb667dd0fb21206201825.png)'
- en: '![](../Images/a5d1981372f82eb76cb142c8ed592995.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5d1981372f82eb76cb142c8ed592995.png)'
- en: '**Secondary Modeling**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**次级建模**'
- en: Now it is time to go into deeper analysis and, if necessary, use more advanced
    models, such as **neural networks**, **XGBoost**, or Random Forests. It is important
    to remember that such models can initially render worse results than simple and
    easy-to-understand models due to a small dataset that cannot provide enough data
    or to the collinearity problem with features providing similar information.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是进行更深入分析的时候，如果需要，可以使用更高级的模型，如**神经网络**、**XGBoost**或随机森林。重要的是要记住，这些模型可能因为数据集较小无法提供足够的数据或特征之间存在共线性问题而最初表现得比简单易懂的模型差。
- en: Therefore, the key task of the secondary modeling step is parameter tuning.
    Each algorithm has a set of parameters you can optimize. Parameters are the variables
    that a machine learning technique uses to adjust to the data. Hyperparameters
    that arethe variables that govern the training process itself, such as the number
    of nodes or hidden layers in a neural network, are tuned by running the whole
    training job, looking at the aggregate accuracy, and adjusting.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，次级建模步骤的关键任务是参数调优。每种算法都有一组可以优化的参数。参数是机器学习技术用于调整数据的变量。超参数是管理训练过程本身的变量，如神经网络中的节点数或隐藏层数，通过运行整个训练过程、查看整体准确性并进行调整来进行调优。
- en: Reflection Phase
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反思阶段
- en: 'Data scientists frequently alternate between the *analysis* and *reflection* phases:
    whereas the analysis phase focuses on programming, the reflection phase involves
    thinking and communicating about the outputs of analyses. After inspecting a set
    of output files, a data scientist, or a group of data scientists can make comparisons
    between output variants and explore alternative paths by adjusting script code
    and/or execution parameters. Much of the data analysis process is trial-and-error:
    a scientist runs tests, graphs the output, reruns them, graphs the output, and
    so on. Therefore, graphs are the central comparison tool that can be displayed
    side-by-side on monitors to visually compare and contrast their characteristics.
    A supplementary tool is taking notes, both physical and digital, to keep track
    of the line of thought and experiments.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家经常在*分析*和*反思*阶段之间交替进行：分析阶段专注于编程，而反思阶段涉及对分析结果的思考和沟通。在检查一组输出文件后，数据科学家或数据科学家团队可以比较输出变体，通过调整脚本代码和/或执行参数来探索替代路径。数据分析过程中的许多部分是试错的：科学家运行测试，绘制输出图形，然后重新运行测试，重新绘制图形，依此类推。因此，图形是主要的比较工具，可以并排显示在显示器上以便直观地比较和对比它们的特征。补充工具包括记笔记，既有纸质的也有数字的，以跟踪思路和实验过程。
- en: Communication Phase
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交流阶段
- en: The final phase of data science is disseminating results either in the form
    of a data science product or as written reports such as internal memos, slideshow
    presentations, business/policy white papers, or academic research publications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的最终阶段是传播结果，这些结果可以是数据科学产品的形式，也可以是书面报告，例如内部备忘录、幻灯片演示、业务/政策白皮书或学术研究出版物。
- en: A ***data science product*** implies getting your model into production. In
    most companies, data scientists will be working with the software engineering
    team to write the production code. The software can be used both to reproduce
    the experiments or play with the prototype systems and as an independent solution
    to tackle a known issue on the market, like, for example, assessing the risk of
    financial fraud.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '***数据科学产品***意味着将你的模型投入生产。在大多数公司中，数据科学家将与软件工程团队合作编写生产代码。该软件既可以用于重现实验或测试原型系统，也可以作为独立解决方案来应对市场上的已知问题，例如评估金融欺诈的风险。'
- en: 'Alternatively, to the data product, you can create a **data science report**.
    You can showcase your results with a presentation and offer a technical overview
    of the process. Remember to keep your audience in mind: go into more detail if
    presenting to fellow data scientists or focus on the findings if you address the
    sales team or executives. If your company allows publishing the results, it is
    also a good opportunity to have feedback from other specialists. Additionally,
    you can write a blog post and push your code to GitHub so the data science community
    can learn from your success. Communicating your results is an important part of
    the scientific process, so this phase should not be overlooked.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你还可以创建**数据科学报告**。你可以通过演示展示你的结果，并提供过程的技术概述。记住要考虑你的观众：如果是向数据科学同行展示，可以详细说明；如果是向销售团队或高管汇报，则应关注发现。如果公司允许发布结果，这也是获得其他专家反馈的好机会。此外，你还可以写博客文章，并将代码推送到GitHub，以便数据科学社区可以从你的成功中学习。沟通结果是科学过程的重要部分，因此这一阶段不应被忽视。
- en: '[Original](https://medium.com/sciforce/a-laymans-guide-to-data-science-part-3-data-science-workflow-eec301da3ffa?source=friends_link&sk=72bad5a9cdc66deb895c7023260a64c3).
    Reposted with permission.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/sciforce/a-laymans-guide-to-data-science-part-3-data-science-workflow-eec301da3ffa?source=friends_link&sk=72bad5a9cdc66deb895c7023260a64c3)。已获授权转载。'
- en: '**Bio:** [SciForce](https://sciforce.solutions) is a Ukraine-based IT company
    specialized in development of software solutions based on science-driven information
    technologies. We have wide-ranging expertise in many key AI technologies, including
    Data Mining, Digital Signal Processing, Natural Language Processing, Machine Learning,
    Image Processing and Computer Vision.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [SciForce](https://sciforce.solutions) 是一家总部位于乌克兰的IT公司，专注于基于科学驱动的信息技术的软件解决方案开发。我们在许多关键AI技术方面拥有广泛的专业知识，包括数据挖掘、数字信号处理、自然语言处理、机器学习、图像处理和计算机视觉。'
- en: '**Related:**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Managing Machine Learning Cycles: Five Learnings from comparing Data Science
    Experimentation/ Collaboration Tools](https://www.kdnuggets.com/2020/01/managing-machine-learning-cycles.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理机器学习周期：比较数据科学实验/协作工具的五个经验教训](https://www.kdnuggets.com/2020/01/managing-machine-learning-cycles.html)'
- en: '[A Beginner’s Guide to the Data Science Pipeline](https://www.kdnuggets.com/2018/05/beginners-guide-data-science-pipeline.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学流程初学者指南](https://www.kdnuggets.com/2018/05/beginners-guide-data-science-pipeline.html)'
- en: '[Data Science Project Flow for Startups](https://www.kdnuggets.com/2019/01/data-science-project-flow-startups.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初创公司数据科学项目流程](https://www.kdnuggets.com/2019/01/data-science-project-flow-startups.html)'
- en: More On This Topic
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应掌握的 6 个预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021 年最佳 ETL 工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
