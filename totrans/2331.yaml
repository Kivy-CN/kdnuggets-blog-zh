- en: An Introduction to SMOTE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/11/introduction-smote.html](https://www.kdnuggets.com/2022/11/introduction-smote.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![An Introduction to SMOTE](../Images/8b829ac989ef7e8c411cf74f02fca11b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: When we have an imbalance classification dataset, there are few minority class
    examples for the model to learn the decision boundary. It also affects the model's
    performance overall.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: You can solve this problem by oversampling the minority class, and you can achieve
    it by duplicating the examples of a minority class in the training dataset. It
    will balance the class distribution, but it won’t improve the model performance,
    as it does not provide extra information to the model.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do you balance the class distribution and improve the model performance
    at the same time? By synthesizing new examples from a minority class using SMOTE
    (Synthetic Minority Oversampling Technique).
  prefs: []
  type: TYPE_NORMAL
- en: What is SMOTE?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SMOTE (Synthetic Minority Oversampling Technique) is an oversampling method
    of balancing class distribution in the dataset. It selects the minority examples
    that are close to the feature space. Then, it draws the line between the examples
    in the features space and draws a new sample at a point along that line.
  prefs: []
  type: TYPE_NORMAL
- en: In simple words, the algorithm selects the random example from the minority
    class and selects a random neighbor using K Nearest Neighbors. The synthetic example
    is created between two examples in the feature space.
  prefs: []
  type: TYPE_NORMAL
- en: There is a drawback to using SMOTE, as it does not consider the majority class
    while creating synthetic examples. This can cause issues where there is a strong
    overlap between the classes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see SMOTE in action by using the Imbalanced-Learn library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Note:** we are using a Deepnote notebook to run the experiments.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Unbalanced Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will create an imbalanced classification dataset using make_classification
    from sci-kit learn’s dataset module.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As we can observe, there are 1K samples. 970 belongs to **0** labels, and only
    30 belongs to **1**.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We will then visualize the dataset using matplotlib’s pyplot.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there are only a few yellow dots (1s) on the graph compared to
    purple. It is a clear example of an imbalanced dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![An Introduction to SMOTE](../Images/b0df5995c9c02ac685d26f27b7cfdc01.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Training and Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we balanced the dataset using oversampling, we need to set a baseline
    for the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the Decision Tree classification model on the dataset using 10-fold,
    3-times cross-validation for training and evaluation. In short, we will be training
    and evaluating 30 models on the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The stratification in RepeatedStratifiedKFold means that each cross-validation
    is split so that they have the same class distribution as the original dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We got the **ROC AUC** mean score of **0.626** which is quite low.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Oversampling using SMOTE()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now apply an oversampling method SMOTE to balance our dataset. We will
    be using [imbalanced-learn](https://pypi.org/project/imbalanced-learn/)’s SMOTE
    function and provide it with features(X) and labels(y).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Both 0, 1 labels are now balanced with 970 samples in each.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Let’s visualize the synthetically balanced dataset. We can clearly see that
    we have equal amounts of yellow and purple dots.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![An Introduction to SMOTE](../Images/14e3502b11ed60dc043e62ace29e3f20.png)'
  prefs: []
  type: TYPE_IMG
- en: Model Training and Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now train the model on a synthetic dataset and evaluate the results.
    We are keeping everything the same, so that we compare it with our baseline result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: After training for a few seconds we got an improved result or **ROC AUC** mean
    score of **0.834**. It clearly shows that oversampling does improve the model
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The original SMOTE [paper](https://arxiv.org/abs/1106.1813) suggests that we
    should combine oversampling (SMOTE) with the undersampling of the majority class,
    as SMOTE does not consider the majority class while creating new samples. The
    combination of oversampling of minority class (SMOTE) and undersampling of majority
    class give us better results.
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we have learned about why we use SMOTE and how it works. We
    have also learned about the imbalanced-learn library and how we can use it to
    improve the model performance and balance the class distribution.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you like my work, don’t forget to follow me on social media to learn
    about DS, ML, NLP, MLOps, Python, Julia, R, and Tableau.
  prefs: []
  type: TYPE_NORMAL
- en: Reference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[SMOTE for Imbalanced Classification with Python - MachineLearningMastery.com](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[7 SMOTE Variations for Oversampling](https://www.kdnuggets.com/2023/01/7-smote-variations-oversampling.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Binary Classification with PyCaret](https://www.kdnuggets.com/2021/12/introduction-binary-classification-pycaret.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Clustering in Python with PyCaret](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Math for Data Science: Visual Introduction to Singular…](https://www.kdnuggets.com/2022/06/essential-math-data-science-visual-introduction-singular-value-decomposition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Pandas for Data Science](https://www.kdnuggets.com/2020/06/introduction-pandas-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Brief Introduction to Papers With Code](https://www.kdnuggets.com/2022/04/brief-introduction-papers-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
