["```py\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport re\n\nsession = requests.Session()\n\nsp500 = 'https://www.reuters.com/finance/markets/index/.SPX'\n\npage = 1\nregex = re.compile(r'/finance/stocks/overview/.*')\nsymbols = []\n\nwhile True:\n  print('Scraping page:', page)\n  params = params={'sortBy': '', 'sortDir' :'', 'pn': page}\n  html = session.get(sp500, params=params).text\n  soup = BeautifulSoup(html, \"html.parser\")\n  pagenav = soup.find(class_='pageNavigation')\n  if not pagenav:\n    break\n  companies = pagenav.find_next('table', class_='dataTable')\n  for link in companies.find_all('a', href=regex):\n    symbols.append(link.get('href').split('/')[-1])\n  page += 1\n\nprint(symbols)\n\n```", "```py\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\n\nsession = requests.Session()\n\nofficers = 'https://www.reuters.com/finance/stocks/company-officers/{symbol}'\n\nsymbols = ['MMM.N', [...], 'ZTS.N']\ndfs = []\n\nfor symbol in symbols:\n  print('Scraping symbol:', symbol)\n  html = session.get(officers.format(symbol=symbol)).text\n  soup = BeautifulSoup(html, \"html.parser\")\n  officer_table = soup.find('table', {\"class\" : \"dataTable\"})\n  df = pd.read_html(str(officer_table), header=0)[0]\n  df.insert(0, 'symbol', symbol)\n  dfs.append(df)\n\ndf = pd.concat(dfs)\ndf.to_pickle('data.pkl')\n\n```", "```py\n\nimport pandas as pd\nimport networkx as nx\nfrom networkx.readwrite.gexf import write_gexf\n\ndf = pd.read_pickle('data.pkl')\n\nG = nx.Graph()\n\nfor row in df.itertuples():\n  G.add_node(row.symbol, type='company')\n  G.add_node(row.Name,type='officer')\n  G.add_edge(row.symbol, row.Name)\n\nwrite_gexf(G, 'graph.gexf')\n\n```"]