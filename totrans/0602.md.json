["```py\n# Importing the Pandas libraries  \nimport pandas as panda  \n\n# Importing the OpenCV libraries  \nimport cv2  \n\n# Importing the time module  \nimport time  \n\n# Importing the datetime function of the datetime module  \nfrom datetime import datetime \n```", "```py\n# Assigning our initial state in the form of variable initialState as None for initial frames  \ninitialState = None  \n\n# List of all the tracks when there is any detected of motion in the frames  \nmotionTrackList= [ None, None ]  \n\n# A new list ‘time’ for storing the time when movement detected  \nmotionTime = []  \n\n# Initialising DataFrame variable ‘dataFrame’ using pandas libraries panda with Initial and Final column  \ndataFrame = panda.DataFrame(columns = [\"Initial\", \"Final\"])  \n```", "```py\n# starting the webCam to capture the video using cv2 module  \nvideo = cv2.VideoCapture(0)  \n\n# using infinite loop to capture the frames from the video \nwhile True:  \n\n   # Reading each image or frame from the video using read function \n\n   check, cur_frame = video.read()  \n\n   # Defining 'motion' variable equal to zero as initial frame \n\n   var_motion = 0  \n\n   # From colour images creating a gray frame \n\n   gray_image = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)  \n\n   # To find the changes creating a GaussianBlur from the gray scale image  \n\n   gray_frame = cv2.GaussianBlur(gray_image, (21, 21), 0)  \n\n   # For the first iteration checking the condition\n\n   # we will assign grayFrame to initalState if is none  \n\n   if initialState is None:  \n\n       initialState = gray_frame  \n\n       continue  \n\n   # Calculation of difference between static or initial and gray frame we created  \n\n   differ_frame = cv2.absdiff(initialState, gray_frame)  \n\n   # the change between static or initial background and current gray frame are highlighted \n\n   thresh_frame = cv2.threshold(differ_frame, 30, 255, cv2.THRESH_BINARY)[1]  \n\n   thresh_frame = cv2.dilate(thresh_frame, None, iterations = 2)  \n\n   # For the moving object in the frame finding the coutours \n\n   cont,_ = cv2.findContours(thresh_frame.copy(),   \n\n                      cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n\n   for cur in cont:  \n\n       if cv2.contourArea(cur) < 10000:  \n\n           continue  \n\n       var_motion = 1  \n\n       (cur_x, cur_y,cur_w, cur_h) = cv2.boundingRect(cur)  \n\n       # To create a rectangle of green color around the moving object  \n\n       cv2.rectangle(cur_frame, (cur_x, cur_y), (cur_x + cur_w, cur_y + cur_h), (0, 255, 0), 3)  \n\n  # from the frame adding the motion status   \n\n   motionTrackList.append(var_motion)  \n\n   motionTrackList = motionTrackList[-2:]  \n\n   # Adding the Start time of the motion \n\n   if motionTrackList[-1] == 1 and motionTrackList[-2] == 0:  \n\n       motionTime.append(datetime.now())  \n\n  # Adding the End time of the motion \n\n   if motionTrackList[-1] == 0 and motionTrackList[-2] == 1:  \n\n       motionTime.append(datetime.now())  \n\n  # In the gray scale displaying the captured image \n\n   cv2.imshow(\"The image captured in the Gray Frame is shown below: \", gray_frame)  \n\n   # To display the difference between inital static frame and the current frame \n\n   cv2.imshow(\"Difference between the  inital static frame and the current frame: \", differ_frame)  \n\n   # To display on the frame screen the black and white images from the video  \n\n   cv2.imshow(\"Threshold Frame created from the PC or Laptop Webcam is: \", thresh_frame)  \n\n   # Through the colour frame displaying the contour of the object\n\n   cv2.imshow(\"From the PC or Laptop webcam, this is one example of the Colour Frame:\", cur_frame)  \n\n   # Creating a key to wait  \n\n   wait_key = cv2.waitKey(1)  \n\n   # With the help of the 'm' key ending the whole process of our system   \n\n   if wait_key == ord('m'):  \n\n       # adding the motion variable value to motiontime list when something is moving on the screen  \n\n       if var_motion == 1:  \n\n           motionTime.append(datetime.now())  \n\n       break \n```", "```py\n# At last we are adding the time of motion or var_motion inside the data frame  \nfor a in range(0, len(motionTime), 2):  \n\n   dataFrame = dataFrame.append({\"Initial\" : time[a], \"Final\" : motionTime[a + 1]}, ignore_index = True)  \n\n# To record all the movements, creating a CSV file  \ndataFrame.to_csv(\"EachMovement.csv\")  \n\n# Releasing the video   \nvideo.release()  \n\n# Now, Closing or destroying all the open windows with the help of openCV  \ncv2.destroyAllWindows()\n```", "```py\n# Importing the Pandas libraries  \nimport pandas as panda  \n\n# Importing the OpenCV libraries  \nimport cv2  \n\n# Importing the time module  \nimport time  \n\n# Importing the datetime function of the datetime module  \nfrom datetime import datetime \n\n# Assigning our initial state in the form of variable initialState as None for initial frames  \ninitialState = None  \n\n# List of all the tracks when there is any detected of motion in the frames  \nmotionTrackList= [ None, None ]  \n\n# A new list 'time' for storing the time when movement detected  \nmotionTime = []  \n\n# Initialising DataFrame variable 'dataFrame' using pandas libraries panda with Initial and Final column  \ndataFrame = panda.DataFrame(columns = [\"Initial\", \"Final\"])\n\n# starting the webCam to capture the video using cv2 module  \nvideo = cv2.VideoCapture(0)  \n\n# using infinite loop to capture the frames from the video \nwhile True:  \n\n   # Reading each image or frame from the video using read function \n\n   check, cur_frame = video.read()  \n\n   # Defining 'motion' variable equal to zero as initial frame \n\n   var_motion = 0  \n\n   # From colour images creating a gray frame \n\n   gray_image = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2GRAY)  \n\n   # To find the changes creating a GaussianBlur from the gray scale image  \n\n   gray_frame = cv2.GaussianBlur(gray_image, (21, 21), 0)  \n\n   # For the first iteration checking the condition\n\n   # we will assign grayFrame to initalState if is none  \n\n   if initialState is None:  \n\n       initialState = gray_frame  \n\n       continue  \n\n   # Calculation of difference between static or initial and gray frame we created  \n\n   differ_frame = cv2.absdiff(initialState, gray_frame)  \n\n   # the change between static or initial background and current gray frame are highlighted \n\n   thresh_frame = cv2.threshold(differ_frame, 30, 255, cv2.THRESH_BINARY)[1]  \n\n   thresh_frame = cv2.dilate(thresh_frame, None, iterations = 2)  \n\n   # For the moving object in the frame finding the coutours \n\n   cont,_ = cv2.findContours(thresh_frame.copy(),   \n\n                      cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  \n\n   for cur in cont:  \n\n       if cv2.contourArea(cur) < 10000:  \n\n           continue  \n\n       var_motion = 1  \n\n       (cur_x, cur_y,cur_w, cur_h) = cv2.boundingRect(cur)  \n\n       # To create a rectangle of green color around the moving object  \n\n       cv2.rectangle(cur_frame, (cur_x, cur_y), (cur_x + cur_w, cur_y + cur_h), (0, 255, 0), 3)  \n\n  # from the frame adding the motion status   \n\n   motionTrackList.append(var_motion)  \n\n   motionTrackList = motionTrackList[-2:]  \n\n   # Adding the Start time of the motion \n\n   if motionTrackList[-1] == 1 and motionTrackList[-2] == 0:  \n\n       motionTime.append(datetime.now())  \n\n  # Adding the End time of the motion \n\n   if motionTrackList[-1] == 0 and motionTrackList[-2] == 1:  \n\n       motionTime.append(datetime.now())  \n\n  # In the gray scale displaying the captured image \n\n   cv2.imshow(\"The image captured in the Gray Frame is shown below: \", gray_frame)  \n\n   # To display the difference between inital static frame and the current frame \n\n   cv2.imshow(\"Difference between the  inital static frame and the current frame: \", differ_frame)  \n\n   # To display on the frame screen the black and white images from the video  \n\n   cv2.imshow(\"Threshold Frame created from the PC or Laptop Webcam is: \", thresh_frame)  \n\n   # Through the colour frame displaying the contour of the object\n\n   cv2.imshow(\"From the PC or Laptop webcam, this is one example of the Colour Frame:\", cur_frame)  \n\n   # Creating a key to wait  \n\n   wait_key = cv2.waitKey(1)  \n\n   # With the help of the 'm' key ending the whole process of our system   \n\n   if wait_key == ord('m'):  \n\n       # adding the motion variable value to motiontime list when something is moving on the screen  \n\n       if var_motion == 1:  \n\n           motionTime.append(datetime.now())  \n\n       break \n\n# At last we are adding the time of motion or var_motion inside the data frame  \nfor a in range(0, len(motionTime), 2):  \n\n   dataFrame = dataFrame.append({\"Initial\" : time[a], \"Final\" : motionTime[a + 1]}, ignore_index = True)  \n\n# To record all the movements, creating a CSV file  \ndataFrame.to_csv(\"EachMovement.csv\")  \n\n# Releasing the video   \nvideo.release()  \n\n# Now, Closing or destroying all the open windows with the help of openCV  \ncv2.destroyAllWindows()\n```"]