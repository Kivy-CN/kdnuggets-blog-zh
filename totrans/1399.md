# 2020年你需要知道的20个人工智能、数据科学、机器学习术语（第2部分）

> 原文：[https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html](https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html)

[评论](#comments)

这是我们列出2020年需要了解的20个人工智能、数据科学、机器学习术语的第二部分。这里是[**2020年你需要知道的20个人工智能、数据科学、机器学习术语（第1部分）**](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html)。

这些定义由KDnuggets编辑[马修·迪尔](https://www.kdnuggets.com/author/matthew-dearing)、[马修·梅奥](https://www.kdnuggets.com/author/matt-mayo)、[阿塞尔·门迪斯](https://www.kdnuggets.com/author/asel-mendis)和[格雷戈里·皮亚特斯基](https://www.kdnuggets.com/author/gregory-piatetsky)编纂。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT需求

* * *

在本期中，我们解释

+   双重下降

+   人工智能伦理

+   可解释性（可解释的人工智能）

+   全栈数据科学

+   地理空间

+   GPT-2

+   自然语言生成（NLG）

+   PyTorch

+   强化学习

+   变换器架构

### 双重下降

这是一个非常有趣的概念，[佩德罗·多明戈斯](https://en.wikipedia.org/wiki/Pedro_Domingos)（一位领先的人工智能研究员）称其为2019年机器学习理论中最重要的进展之一。该现象如图1所示。

![OpenAI双重下降图](../Images/74f2dd93c859947a79b736628f930f7f.png)

**图1： 测试/训练误差与模型规模（来源：OpenAI** [**博客**](https://openai.com/blog/deep-double-descent/)**)**

随着模型的增大，误差最初下降，然后误差随着模型开始过拟合而增加，但随着模型规模、数据量或训练时间的增加，误差再次下降。

经典统计理论认为，更大的模型由于过拟合而表现更差。然而，现代机器学习实践表明，较大的深度学习模型通常比小型模型更好。

OpenAI [博客](https://openai.com/blog/deep-double-descent/)指出，这种现象发生在CNNs、ResNets和变换器中。OpenAI研究人员观察到，当模型不够大以适应训练集时，更大的模型有更高的测试误差。然而，在超过这一阈值后，随着模型规模的增加和数据量的增多，更大的模型开始表现更好。

阅读原始OpenAI博客和Rui Aguiar的更长[解释](https://towardsdatascience.com/deep-double-descent-when-more-data-and-bigger-models-are-a-bad-thing-3a3f108d5538)。

*由[格雷戈里·皮亚捷茨基](/author/gregory-piatetsky)撰写*。

### [人工智能中的伦理](/tag/ethics/)

人工智能伦理关注的是实际人工智能技术的伦理。

人工智能伦理是一个非常广泛的领域，涵盖了各种看似非常不同的伦理关切方面。关于人工智能及所有技术类型的使用的担忧，自这些技术首次被构想到现在就一直存在。然而，鉴于人工智能、机器学习及相关技术的近期爆炸式增长，以及它们在整个社会中的日益快速的采纳和整合，这些伦理关切已成为许多人，既包括人工智能社区内的人，也包括外界人士，关注的重点。

虽然像有感知的机器人未来可能的权利这样的深奥和目前抽象的伦理问题也可以被纳入人工智能伦理的范畴，但更紧迫的当代问题，如人工智能系统的透明度、这些系统可能存在的偏见，以及在这些系统工程中社会参与者的代表性包容，可能更令大多数人关注。人工智能系统中的决策是如何做出的？这些系统对世界和其中的人有什么假设？这些系统是否由单一主导的多数群体、性别和种族制造？

美国旧金山大学应用数据伦理中心主任瑞秋·托马斯[Rachel Thomas](https://www.fast.ai/2018/09/24/ai-ethics-resources/)对从事人工智能伦理工作的定义进行了说明，这超越了直接涉及人工智能系统低层次创建的关注点，并考虑了所谓的更广泛的背景：

> **创建科技公司并以伦理方式开发产品；
> 
> 提倡和推动更公正的法律和政策；
> 
> 尝试追究不良行为者的责任；
> 
> 以及在这一领域的研究、写作和教学。**

自动驾驶汽车的出现带来了与人工智能伦理相关的额外特定挑战，人工智能系统的潜在武器化以及日益增长的国际人工智能军备竞赛也是如此。与某些人想让我们相信的情况相反，这些问题并不是注定会发生在反乌托邦未来的难题，然而这些问题确实需要经过一些深思熟虑、适当的准备和广泛的合作。即便我们认为已经进行了充分的考虑，人工智能系统仍可能被证明是独特且内生性的问题，人工智能系统的意外后果，作为人工智能伦理的另一个方面，也需要被考虑。*由[马修·梅奥](/author/matt-mayo)撰写*

### [可解释性](/tag/explainability) ([可解释人工智能](/tag/explainable-ai))

随着人工智能和机器学习在我们的生活中扮演越来越重要的角色，例如智能手机、医疗诊断、自动驾驶汽车、智能搜索、自动信用决策等，AI做出的决策变得越来越普遍，一个重要的方面逐渐受到关注——可解释性。人类通常能够解释他们基于知识的决策（无论这些解释是否准确是另一个问题），这有助于其他人对这些决策的信任。AI和机器学习算法能否解释它们的决策？这是重要的。

+   提高对决策的理解和信任

+   决定在出现问题时的问责或责任。

+   避免在决策中出现歧视和社会偏见

我们注意到，[GDPR](https://www.kdnuggets.com/2018/03/gdpr-machine-learning-illegal.html)要求某种形式的可解释性。

可解释人工智能（[XAI](/tag/xai)）正成为一个重要领域，DARPA于2018年启动了[XAI计划](https://www.darpa.mil/program/explainable-artificial-intelligence)。

![可解释人工智能维恩图](../Images/9e36474a8c22f1ad3a399824608f7a1a.png)

**图 2：可解释人工智能维恩图。**（[来源](https://www.kdnuggets.com/2019/01/explainable-ai.html)）。

可解释性是一个多方面的话题。它不仅包括单独的模型，还包括包含这些模型的更大系统。它不仅指模型输出的决策是否可以解释，还指整个过程和围绕模型的意图是否可以得到适当解释。目标是实现准确性和可解释性之间的高效权衡，并拥有出色的人机界面，这可以帮助将模型转化为用户易于理解的表示。

一些更受欢迎的可解释人工智能方法包括[LIME](/tag/lime)和[SHAP](https://www.kdnuggets.com/2020/01/explaining-black-box-models-ensemble-deep-learning-lime-shap.html)。

现在，Google ([Explainable AI服务](https://www.kdnuggets.com/2019/12/googles-new-explainable-ai-service.html))、[IBM AIX 360](https://github.com/IBM/AIX360)以及其他供应商提供了可解释性工具。

另见Preet Gandhi的[KDnuggets博客](https://www.kdnuggets.com/2019/01/explainable-ai.html)关于[可解释的人工智能](https://www.kdnuggets.com/2019/01/explainable-ai.html)和[可解释的人工智能（XAI）：概念、分类、机会和面向负责任人工智能的挑战](https://arxiv.org/abs/1910.10045)（arxiv 1910.10045）。*由[Gregory Piatetsky](/author/gregory-piatetsky)撰写*。

### 全栈数据科学

全栈数据科学家是数据科学独角兽的典范。既具备统计学家的技能，能够建模现实场景；又具备计算机科学家的技能，能够管理数据库并将模型部署到网上；还具备商人的技能，将见解和模型转化为可操作的见解，供通常不关心后台工作的高级管理人员使用。

以下是两个很棒的演讲，可以让你了解端到端数据科学产品的不同细微差别。

1\. 通过数据科学全面发展：使用技术准备，由Emily Gorcenski

2\. [视频：#42 完整数据科学（与Vicki Boykis一起）- DataCamp](https://www.youtube.com/watch?v=EICvvS6MUt8)。

阅读 [#42 完整数据科学（与Vicki Boykis一起）- 文本记录](https://www.r-bloggers.com/full-stack-data-science-transcript/)。

*作者：[Asel Mendis](/author/asel-mendis)*。

### [地理空间](/tag/geospatial)

地理空间是指具有空间/位置/地理成分的任何数据。由于跟踪用户移动并生成地理空间数据的技术出现，地理空间分析的受欢迎程度逐渐上升。用于空间分析的最著名技术（地理信息系统 – GIS）包括 [ArcGIS](https://www.arcgis.com/index.html)、[QGIS](https://www.qgis.org/en/site/)、[CARTO](https://carto.com/) 和 [MapInfo](https://www.pitneybowes.com/us/location-intelligence/geographic-information-systems/mapinfo-pro.html)。

当前的冠状病毒疫情由 [ARCGIS仪表板](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6) 追踪，由约翰斯·霍普金斯大学系统科学与工程中心开发。

![2020年3月2日的冠状病毒，约翰斯·霍普金斯](../Images/2d9fa602b92c76f86079aed611f721f6.png)

**图3：根据约翰斯·霍普金斯CSSE仪表板，截至2020年3月2日的冠状病毒统计数据。**

地理空间数据可以用于从销售预测建模到评估政府资助计划等各种应用。由于数据参考了特定位置，因此我们可以获得许多见解。不同国家记录和测量其空间数据的方式不同，并且程度各异。一个国家的地理边界不同，必须视为每个国家的独特特征。 *作者：[Asel Mendis](/author/asel-mendis)*。

### [GPT-2](/tag/gpt-2)

[GPT-2](https://openai.com/blog/better-language-models/) 是由 [OpenAI](/tag/openai) 创建的基于变换器的语言模型。GPT-2 是一个生成语言模型，这意味着它通过逐词预测序列中下一个词来生成文本，基于模型之前学到的内容。在实践中，用户提供的提示会呈现给模型，然后生成随后的词。GPT-2 被训练用于预测在大量（40 GB）互联网文本中的下一个词，并且完全使用变换器解码块构建（与使用编码块的BERT相比）。有关变换器的更多信息，请参见下文。

GPT-2并不是一个特别新颖的项目；然而，它与类似模型不同之处在于其可训练参数的数量以及这些训练参数所需的存储大小。虽然OpenAI最初发布了一个缩小版的训练模型——出于对可能出现恶意用途的担忧——但完整模型包含15亿个参数。这15亿个可训练参数模型需要6.5 GB的训练参数（等同于“训练模型”）存储。

GPT-2发布时引起了大量的关注和热议，这在很大程度上是由于随之而来的示例，其中最著名的一个——记录安第斯山脉发现说英语的独角兽的新闻报道——[可以在这里阅读](https://pbs.twimg.com/media/DzYpsJOU0AA1PO9.png:large)。GPT-2模型的一个独特应用是AI Dungeon，这是一款在线文字冒险游戏，将用户提供的文本视为对模型的输入提示，并使用生成的输出推动游戏进程和用户体验。你可以[在这里试用AI Dungeon](https://aidungeon.io/)。

尽管通过下一个词预测生成文本是GPT-2及解码器块变换器的主要功能（以及亮点），它们在语言翻译、文本摘要、音乐生成等其他相关领域也展现了潜力。有关GPT-2模型的技术细节和更多信息，请参见Jay Alammar的精彩[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2)。*作者：[Matthew Mayo](/author/matt-mayo)*。

### NLG ([自然语言生成](/tag/natural-language-generation))

自然语言理解方面取得了重大进展——使计算机能够解释人类输入并提供有意义的回应。许多人通过个人设备，如亚马逊Alexa和Google Home，每天都在享受这一技术。毫不意外，孩子们特别喜欢要求讲笑话。

这里的技术是机器学习后端经过各种输入的训练，例如“请告诉我一个笑话”，机器可以从预定的响应列表中选择一个。如果Alexa或Google Home能够讲一个*原创*笑话，即基于大量人类创作的笑话进行即时创作，那就是[自然语言*生成*](https://www.kdnuggets.com/2020/01/guide-natural-language-generation.html)。

原创笑话只是个开始（一个训练好的[机器学习模型甚至能搞笑](http://joking.abdn.ac.uk/webversion/welcome.php)吗？），强大的NLG应用正被开发用于生成能够被人类理解的数据集摘要。计算机的创造性方面也可以通过NLG技术进行探索，这些技术能够输出[原创电影剧本](https://www.youtube.com/watch?v=LY7x2Ihqjmc)，甚至有[David Hasselhoff](https://www.youtube.com/watch?v=5qPgG98_CQ8)主演的剧本，以及类似于[你可以跟随的教程](https://www.kdnuggets.com/2019/07/training-neural-network-write-like-lovecraft.html)的基于文本的故事，利用长短期记忆（LSTM）这种反馈的递归神经网络架构，这是当前的热门研究话题之一。

尽管计算机生成语言在商业分析和娱乐应用方面可能颇具吸引力并能改变文化，但伦理问题已经引发了大量关注。自然语言生成（NLG）能够自主生成并传播“假新闻”的能力令人不安，即使其意图并非被编程为恶意。例如，OpenAI [小心发布](https://www.kdnuggets.com/2019/03/openai-gpt-2-model-hype-controversy.html)了他们的GPT-2语言模型，研究表明该模型可以生成令人信服的文本输出，难以被检测为合成内容，并且可以被微调以进行不当使用。他们现在利用这项研究来开发可能对人类带来麻烦的AI，以更好地理解如何控制这些令人担忧的偏见和恶意使用文本生成器的潜力。 *作者：[Matthew Dearing](/author/matthew-dearing)*。

### [PyTorch](/tag/pytorch)

[Torch包](https://github.com/torch/torch7)最早于2002年发布，使用C语言实现，是一个包含多种算法的张量库，支持深度学习。 [Facebook AI研究](https://research.fb.com/)实验室对Torch产生了兴趣，并在2015年初将该库开源，同时也融入了许多机器学习工具。次年，他们发布了一个Python实现的框架，名为PyTorch，经过优化以支持GPU加速。

随着强大的Torch工具现在对Python开发者开放，许多主要企业将PyTorch整合到他们的开发堆栈中。如今，这个曾经是Facebook内部的机器学习框架已成为[最受欢迎的深度学习库](https://www.kdnuggets.com/2020/01/openai-pytorch-adoption.html)之一，OpenAI是最新加入使用PyTorch的公司和研究人员中的一员。Google在2017年发布的竞争软件包TensorFlow，自诞生以来一直主导深度学习社区，并且现在明显趋势是PyTorch将在2020年晚些时候超越TensorFlow。

如果你在寻找第一个机器学习包进行学习，或者是一个经验丰富的TensorFlow用户，你可以[开始使用](https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html)PyTorch，亲自找出哪个框架最适合你的开发需求。*作者：[Matthew Dearing](/author/matthew-dearing)*。

### [强化学习](/tag/reinforcement-learning)

除了监督学习和无监督学习，[强化学习](https://www.kdnuggets.com/2017/12/interview-rich-sutton-reinforcement-learning.html)（RL）是机器学习中的一种基本方法。其核心思想是一个训练算法，它为一个试错决策“代理”提供奖励反馈，该代理尝试执行某些计算任务。换句话说，如果你将一根棍子扔到院子里让Rover去取，而你的新小狗决定把棍子还给你以获得奖励，那么它下次将更快、更有效地重复相同的决策。这种方法的一个令人兴奋的特点是无需标记数据——模型可以通过编码的奖励在已知和未知数据中探索，朝着最佳解决方案前进。

强化学习是那些令人惊叹的、打破纪录的、战胜人类的国际象棋、视频游戏以及[AlphaGo的致命一击](https://www.kdnuggets.com/2017/10/alphago-zero-biggest-ai-advance.html)的基础。AlphaGo在没有任何硬编码到算法中的指令下学会了围棋。然而，虽然这些人工智能超人能力的发展是显著的，它们是在规则不变的游戏这样的明确定义的计算机表征内进行的。强化学习[并不能直接推广到现实世界的复杂性](https://www.kdnuggets.com/2020/01/modern-ai-from-neurips-2019.html)，正如[OpenAI的魔方模型](https://openai.com/blog/solving-rubiks-cube/)所示，该模型在模拟中能够解出难题，但在通过机器人手臂转化时却需要多年才能看到远不完美的结果。

因此，在强化学习领域还有大量的开发和改进工作需要进行，2019年见证了[潜在的复兴正在进行中](https://www.kdnuggets.com/2019/12/review-what-happened-ai.html)。将强化学习扩展到实际应用将是2020年的一个热门话题，[重要的实施工作](https://www.kdnuggets.com/2020/01/created-lazy-ai.html)已经在进行中。*作者：[Matthew Dearing](https://www.kdnuggets.com/author/matthew-dearing)*。

### [变压器](/tag/transformer)

Transformer是一种基于自注意力机制的新型神经网络架构，特别适合于自然语言处理和自然语言理解。它在2017年由Google AI研究人员提出的[Attention Is All You Need](https://goo.gl/dwSBxB)论文中提出。Transformer是一种“变换”一个序列为另一个序列的架构，借助编码器和解码器，但它不使用递归网络或LSTM。它使用注意力机制，这使得它能够查看输入序列中的其他位置以帮助改进编码。

这里有一个例子，由Jay Alammar解释得很好。假设我们要翻译

“动物没有过马路，因为它太累了。”

“它”指的是什么？人们理解“它”指的是动物，而不是街道，但对计算机来说这个问题很难。当编码“it”时，自注意力机制关注“动物”，并将这些词与“it”联系起来。

![Transformer 自注意力机制](../Images/90f5c8c65f8f3dc6a706383cc8c4d0ab.png)

**图4：当transformer编码“it”这个词时，部分注意力机制专注于“动物”，并将其表示连接到“it”的编码中。** ([来源](https://jalammar.github.io/illustrated-transformer/).)

Google报告称，Transformer在翻译任务上显著优于其他方法。Transformer架构被用于许多NLP框架中，如BERT（**B**idirectional **E**ncoder **R**epresentations from **T**ransformers）及其后代。

欲了解详细的视觉说明，请参见 [插图式Transformer](https://jalammar.github.io/illustrated-transformer/)，由Jay Alammar编写。*由[Gregory Piatetsky](/author/gregory-piatetsky)撰写*。

**相关：**

+   [2020年你需要了解的20个AI、数据科学、机器学习术语（第1部分）](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html)

+   [277个数据科学关键术语解析](https://www.kdnuggets.com/2017/09/data-science-key-terms-explained.html)

+   [什么是数据科学？](https://www.kdnuggets.com/2019/11/what-is-data-science.html)

### 更多相关话题

+   [建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，并找到目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [数据科学学习统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)
