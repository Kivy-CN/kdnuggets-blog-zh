- en: Working with Python APIs For Data Science Project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/09/python-apis-data-science-project.html](https://www.kdnuggets.com/2021/09/python-apis-data-science-project.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)<picture>![Working with Python APIs For Data Science Project](../Images/70890df2bdfc855812b2da3ffefaaaf6.png)</picture>
    * * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Working with APIs for data science is a necessary [skill set for all data scientists](https://www.stratascratch.com/blog/most-in-demand-data-science-technical-skills/) and
    should be incorporated into your data science projects. In our previous blog - [data
    analytics project ideas](https://www.stratascratch.com/blog/data-analytics-project-ideas-that-will-get-you-the-job/),
    we outlined the only data science project you’ll ever need and talked about how
    important it is to work with APIs to collect your data for your data science project.
    So in this article, we want to show you how to pull data from an API specifically [using
    python](https://www.stratascratch.com/blog/how-much-python-is-required-for-data-science/) to
    pull data from the YouTube API and the request library that's found in python.
  prefs: []
  type: TYPE_NORMAL
- en: So let's understand how to work with an API for data science. We'll pull the
    data and look through the JSON response that we get and then we'll save all of
    this data into a Pandas DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![How to work with an API for data science](../Images/84584c537b252fc875798a0a958762df.png)</picture>
    We'll do this all programmatically with good software engineering skills so your
    code looks clean and concise, and not like some 10 years old wrote it. This article
    isn’t about how to work with the Youtube API but it’s about how to work with APIs
    in general, so we’ll make sure to use libraries and techniques that can be used
    for any API service.
  prefs: []
  type: TYPE_NORMAL
- en: Why collect data from an API?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You might be thinking that why we don''t just use a CSV or pull data from a
    database? There are two reasons why you should learn APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1.** An API is a very common industry, professional way of collecting data
    and so if you ever work as a data scientist, you’ll be required to learn how to
    do this.'
  prefs: []
  type: TYPE_NORMAL
- en: '**2.** It’s the more complicated and advanced way to collect data compared
    to pulling data from a database. So, just another reason to learn APIs and to
    impress your colleagues and hiring manager.'
  prefs: []
  type: TYPE_NORMAL
- en: Tools and Platforms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Platform**'
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to use Google Colabs which is basically Jupyter notebooks. You can
    use Jupyter notebooks if you want but we will use Colabs because it’s easy to
    spin up and get saved our work in Google drive.
  prefs: []
  type: TYPE_NORMAL
- en: '**Imports**'
  prefs: []
  type: TYPE_NORMAL
- en: Now the first thing is to import and the libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![Import APIs](../Images/5d35319068d540d42e3a2e39ed8dc9f4.png)</picture>
    The request library is a library that is going to allow us to make API calls.
    You can use this library to make a request to any API so depending on what API
    you want to grab data from, the techniques covered here will be the same. If you
    want to learn more about the requests library, here’s a link - https://realpython.com/python-requests/.
    Then we have the Pandas library because we're going to save our data into a Pandas
    DataFrame and then there's a time library.
  prefs: []
  type: TYPE_NORMAL
- en: '**API Key**'
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to get an API key. We’re going to grab data from the Youtube
    API, specifically, going to grab data from our channel here. In order to access
    our channel information via API, we need to apply for an API key. You can do so
    by going to this link - https://www.slickremix.com/docs/get-api-key-for-youtube/.
    We don’t want to make this article specifically about how to work with the Youtube
    API so we’ll leave you to getting the API key yourself. But in general, whenever
    you’re working with an API, you’ll always need a key. And the way to get a key
    is different for each API service. So let’s say you went through the process and
    got your API key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will grab all the videos that we have in our channel and then we will
    grab the metrics from each video:'
  prefs: []
  type: TYPE_NORMAL
- en: '**List of Videos from Channel**'
  prefs: []
  type: TYPE_NORMAL
- en: Video ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video Title
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publish Date
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Video Metrics**'
  prefs: []
  type: TYPE_NORMAL
- en: View Count
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Link Count
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dislike Count
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comment Count
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now what we need is our channel ID. So these two parameters will be used to
    make our API call.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Testing With The requests Library
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s quickly test out an API call. Using the request library, you can make
    a call just by putting the URL of the API in the get() method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![Testing With The requests Library](../Images/da5cc43a29478a7fa00970e07ad9ec96.png)</picture>
    To grab some data, we are using the get() method. The data is located at api.github.com.
    We're passing the URL to the get() method and add the json() method which will
    return a JSON object in the response.
  prefs: []
  type: TYPE_NORMAL
- en: '**What''s a JSON file?**'
  prefs: []
  type: TYPE_NORMAL
- en: It's a popular data file sent over as a JS object and contains your data usually
    as attribute-value pairs or in an array. And save the data in a variable called
    response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s view the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![Testing With The requests Library](../Images/5f42c9380dea80a3243c3e192fa6fc83.png)</picture>
    As you can see in the output, the entire result is encapsulated in curly braces
    and each line has an attribute or key and each key has a value. This is a list
    of URLs that you can access for specific information from Github.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you want to find user emails, you’d use the email_url in your
    get() method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We were just testing out the request library and quickly testing out its functionality.
    Let’s now make a call to the Youtube API and grab some data.
  prefs: []
  type: TYPE_NORMAL
- en: Working With The YouTube API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So the hardest part of making an API call is figuring out how to structure the
    URL, mainly what parameters to add into the URL. We currently have a root URL
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is the location of our data. We just need to define what type of data we
    want to collect. In order to do that we now need to add parameters to the URL
    to get specific video information from our specific channel.
  prefs: []
  type: TYPE_NORMAL
- en: The hardest part is figuring out which parameters and properties to add to the
    URL? How do you figure that out? The best way is to read the official documentation.
    https://developers.google.com/youtube/v3/docs/search
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to make a “search” and include several parameters like “part”, “channelID”
    and my API key. And within the “parts” parameter, we’ll add the id and snippet
    properties to grab ID data which includes videoID and information about the video
    itself as you see here in the list.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![Working With The YouTube API](../Images/ca0756b2d7890b238e54ad0319065ca8.png)</picture>
    Now we’re going to write the entire URL with the parameters which will give us
    all the data we want to collect. Again, this article isn’t about YouTube specifically
    so we won’t go into how we figured out which parameters to use and all that. Lots
    of it was trial and error. But let us guide you on how we're structuring this
    URL.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We’re performing a “search” through the YouTube API. Everything to the right
    of the '?' is parameters we add to request specific information.
  prefs: []
  type: TYPE_NORMAL
- en: First, we add our API key that’s stored in the API_KEY variable in this key
    parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We specify the channel ID we want to collect information from.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next is the part parameter where we’re specifying that we want snippet and ID
    data. From the documentation, it tells us what data we can expect to get when
    we ask for snippet and ID data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Order the data by date and then we want the maxResults of 10000 videos in our
    API call.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, the pageToken is a token, which is a code, that is needed to get to
    the next page of the search results. We’ll deal with this later when we try to
    extract all the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building this can be hard and it’s a lot of trial and error. But once you play
    around with it and get the data you want, you won't have to worry about it again.
    So this entire URL is saved in our URL variable.
  prefs: []
  type: TYPE_NORMAL
- en: Response From Making API Call
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We make the API call in the exact same way we did for the Github example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: And here’s the output of the API call.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![Response From Making API Call](../Images/1ded876e6225f683eb6564a7c923c1ee.png)</picture>
    As you can see we have the same JSON object saved in the response variable. You’ll
    see all the properties for id and snippet.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing Through The Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How do you make heads or tails out of this data? First, let’s identify what
    we’re interested in? We see the etag key at the top and then the items key as
    the 2nd key in the response. The items key starts with a square brace and then
    basically is listing all the videos in our channel. If we go to the end of the
    response, we finally see the last video in our channel and the closing square
    bracket for the items key. Then we see the other keys kind, nextPageToken, and
    so forth.
  prefs: []
  type: TYPE_NORMAL
- en: You can also see that we have 95 results but only retrieved 50\. The nextPageToken
    key will help us with getting the videos on the next page of the search. But we’ll
    cover that later.
  prefs: []
  type: TYPE_NORMAL
- en: So our API call gave us a search result of all of our videos and some information
    about the video. All this information is stored in the items key. So let’s just
    grab that data and filter out the rest.
  prefs: []
  type: TYPE_NORMAL
- en: You can do that easily by specifying just the items key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![Parsing Through The Data](../Images/533342403610eb0fb029f7312a1c7e93.png)</picture>
    You see that the output starts with the square brackets and it lists all the videos
    we have on our channel. In order to isolate one video, we can specify the position.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![isolate one video using python api for data science](../Images/16f99992a89b0e2af2fb1ff5d8bd2e61.png)</picture>
    So, this is our latest video.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing through the output and saving it to variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s obvious that what we need to do is loop through all the videos in the items
    key and save specific pieces of information. Let’s save the information into variables
    first and build the loop last.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s save the video ID. In order to do that, we need to call the response variable,
    item key, and 1st position. Then once we have that, we are selecting the id key
    and then the videoID key. We can save that value in the video_id variable. That’s
    basically how you will navigate through the array and save the data you want.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Let’s do the same with the video title. Here we're also replacing any & (ampersand)
    symbols with a blank)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Then let’s grab the upload date
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We want to grab just the date and leave out the timestamp.
  prefs: []
  type: TYPE_NORMAL
- en: <picture>![Parsing through the output and saving it to variables](../Images/524aaef64e8fc910d9e5f5813a1f0056.png)</picture>
    To do that we can split on the T and grab the left side of the output.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: So that’s how you save all the information.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Loop
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s create a Loop to go through all the videos collected in the API call and
    save the information.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be going through the response[‘items’] array so our 'for Loop' starts
    with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Next, we have to add some logic that ensures we’re only going to collect video
    information. So in order to ensure this logic, we need to make sure that we’re
    looking only at videos. If you check the response, you’ll see
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: So we’ll add an if statement just to ensure we’re saving video information.
    As you can also see instead of response['items'] we’re using the video variable
    because we’re in the 'for loop'.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: And lastly, all the variables that we built out to collect the information from
    the response, we’ll use those again but we’ll just need to change the variable
    name to video. Your end result will look like this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Making A Second API Call
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Collecting this information is great but it’s not interesting. We also want
    to collect the view count, likes and dislikes for each of our videos. That’s not
    in the first API call. What we need to do is now make a second API call to collect
    this information because we need to use the video_id that we collected from the
    first API call to then make a second API call to grab the view, like, dislike,
    and comment counts.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we''ve shown you exactly how to make an API call, we suggest figuring out
    a way to make this second API call yourself. And if you''re successful in making
    the second API call, it should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have to add it to the ''for loop''. And we''ll get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Saving To A Pandas DataFrame
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let’s build out a Pandas DataFrame so that we can save all of this information.
    Since we already know all the information we want to save, we’ll create a blank
    Pandas DataFrame with the column headers above the 'for loop'.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will append the data we’ve saved in the variables in the 'for loop'
    to that Pandas DataFrame. Let's use the append() method to do this inside the
    'for loop'.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The entire ''for loop'' will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: <picture>![Python API for data science output of a pandas dataframe](../Images/f9b80b8229a1758b4ae90efb2a56d39c.png)</picture>
    Now we have all of our data in this Pandas DataFrame and the output should be
    a Pandas DataFrame with all the video statistics.
  prefs: []
  type: TYPE_NORMAL
- en: '<picture>![Saving APIs to a Pandas DataFrame](../Images/aa980dab7b66f759a42ca8122dd6ba55.png)</picture>
    ### Creating the Functions'
  prefs: []
  type: TYPE_NORMAL
- en: The code we’ve written so far works perfectly but there are some things that
    can be improved. The main part to improve is to separate the API call that grabs
    video information from the main part because the logic for the 2nd API call doesn’t
    need to be mixed into the logic of saving the data.
  prefs: []
  type: TYPE_NORMAL
- en: So we can separate the 2nd API call into its own function and just pass the
    video_id we collected from the 1st API call.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can then wrap the main work into its function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we can call the functions in this way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let's see our final output, where we get a Pandas DataFrame, video_id, video_title,
    upload_date, view_count, like_count, dislike_count, and comment_count.
  prefs: []
  type: TYPE_NORMAL
- en: '<picture>![Youtube Python APIs for Data Science final output](../Images/0052acefeb78e9123f9c90ce0cc6fc02.png)</picture>
    ### **Conclusion**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is how you can work with Python API for your data science project and
    grab data from an API and save it to a Pandas DataFrame. As a data scientist,
    you’ll be expected to know how to grab data from APIs. Let''s break down the steps
    we performed:'
  prefs: []
  type: TYPE_NORMAL
- en: Learned the request library to make an API call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Made API call to YouTube API: We passed a URL to the API that specified what
    data we want. We had to read the documentation carefully to build the URL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Collected data as JSON: We collected the data as a JSON object and parsed through
    the data saving it as variables first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saved the data as a Pandas DataFrame
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, we just added some error handling logic and cleaned up the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Find some exciting [Python interview questions for data scientist position](https://www.stratascratch.com/blog/python-interview-questions-for-data-scientist-position/) that
    are for beginners or someone who is looking for more challenging tasks.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: Nathan Rosidi** (**[@StrataScratch](https://twitter.com/StrataScratch)**)
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of [StrataScratch](https://www.stratascratch.com/),
    a platform helping data scientists prepare for their interviews with real interview
    questions from top companies.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Production-Ready Machine Learning NLP API with FastAPI and spaCy](/2021/04/production-ready-machine-learning-nlp-api-fastapi-spacy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building RESTful APIs using Flask](/2021/05/building-restful-apis-flask.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build Your First Data Science Application](/2021/02/build-first-data-science-application.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Guide to Working with SQLite Databases in Python](https://www.kdnuggets.com/a-guide-to-working-with-sqlite-databases-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[FastAPI Tutorial: Build APIs with Python in Minutes](https://www.kdnuggets.com/fastapi-tutorial-build-apis-with-python-in-minutes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Deep Learning working in the wild: A Data-Centric Course](https://www.kdnuggets.com/2022/04/corise-deep-learning-wild-data-centric-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Soft Skills for Data Scientists Working Remotely](https://www.kdnuggets.com/2022/05/6-soft-skills-data-scientists-working-remotely.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Working with Big Data: Tools and Techniques](https://www.kdnuggets.com/working-with-big-data-tools-and-techniques)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Deep Learning working in the wild: A Data-Centric Course](https://www.kdnuggets.com/2022/11/corise-deep-learning-wild-data-centric-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
