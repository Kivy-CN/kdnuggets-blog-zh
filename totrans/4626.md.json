["```py\n#Import libraries\nimport pandas as pd\nimport numpy as np\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n```", "```py\n#Bayesian optimization\ndef bayesian_optimization(dataset, function, parameters):\n   X_train, y_train, X_test, y_test = dataset\n   n_iterations = 5\n   gp_params = {\"alpha\": 1e-4}\n\n   BO = BayesianOptimization(function, parameters)\n   BO.maximize(n_iter=n_iterations, **gp_params)\n\n   return BO.max\n```", "```py\ndef rfc_optimization(cv_splits):\n    def function(n_estimators, max_depth, min_samples_split):\n        return cross_val_score(\n               RandomForestClassifier(\n                   n_estimators=int(max(n_estimators,0)),                                                               \n                   max_depth=int(max(max_depth,1)),\n                   min_samples_split=int(max(min_samples_split,2)), \n                   n_jobs=-1, \n                   random_state=42,   \n                   class_weight=\"balanced\"),  \n               X=X_train, \n               y=y_train, \n               cv=cv_splits,\n               scoring=\"roc_auc\",\n               n_jobs=-1).mean()\n\n    parameters = {\"n_estimators\": (10, 1000),\n                  \"max_depth\": (1, 150),\n                  \"min_samples_split\": (2, 10)}\n\n    return function, parameters\n```", "```py\ndef xgb_optimization(cv_splits, eval_set):\n    def function(eta, gamma, max_depth):\n            return cross_val_score(\n                   xgb.XGBClassifier(\n                       objective=\"binary:logistic\",\n                       learning_rate=max(eta, 0),\n                       gamma=max(gamma, 0),\n                       max_depth=int(max_depth),                                               \n                       seed=42,\n                       nthread=-1,\n                       scale_pos_weight = len(y_train[y_train == 0])/\n                                          len(y_train[y_train == 1])),  \n                   X=X_train, \n                   y=y_train, \n                   cv=cv_splits,\n                   scoring=\"roc_auc\",\n                   fit_params={\n                        \"early_stopping_rounds\": 10, \n                        \"eval_metric\": \"auc\", \n                        \"eval_set\": eval_set},\n                   n_jobs=-1).mean()\n\n    parameters = {\"eta\": (0.001, 0.4),\n                  \"gamma\": (0, 20),\n                  \"max_depth\": (1, 2000)}\n\n    return function, parameters\n```", "```py\n#Train model\ndef train(X_train, y_train, X_test, y_test, function, parameters):\n    dataset = (X_train, y_train, X_test, y_test)\n    cv_splits = 4\n\n    best_solution = bayesian_optimization(dataset, function, parameters)      \n    params = best_solution[\"params\"]\n\n    model = RandomForestClassifier(\n             n_estimators=int(max(params[\"n_estimators\"], 0)),\n             max_depth=int(max(params[\"max_depth\"], 1)),\n             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n             n_jobs=-1, \n             random_state=42,   \n             class_weight=\"balanced\")\n\n    model.fit(X_train, y_train)\n\n    return model\n```"]