# 使我作为数据科学家工作的5件事

> 原文：[https://www.kdnuggets.com/2021/08/5-things-job-data-scientist-easier.html](https://www.kdnuggets.com/2021/08/5-things-job-data-scientist-easier.html)

[评论](#comments)

**作者 [Shree Vandana](https://www.linkedin.com/in/shree-vandana-kachroo/)，数据科学家**

![](../Images/eab6356aa161c77e51612b5ad099acf3.png)

照片由 [Boitumelo Phetla](https://unsplash.com/@writecodenow?utm_source=medium&utm_medium=referral) 提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

## **1\. 使用 Pandas 进行时间序列数据处理**

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行 IT 工作

* * *

如果你处理时间序列数据，可能花了大量时间来处理缺失记录或通过 SQL 查询或编写自定义函数在特定时间粒度下聚合数据。Pandas 有一个非常高效的 [resample 函数](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html)，可以通过简单地将 DataFrame 索引设置为时间戳列来帮助你以特定频率处理数据。

我将使用房间占用数据集来举例说明这个函数。你可以在 [这里](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+) 找到这个数据集。这个数据集记录了每分钟的观察数据。

```py
import pandas as pd
data = pd.read_csv('occupancy_data/datatest.txt').reset_index(drop = True)
data.head(5)
```

![](../Images/29a461400322969483420453ce8443ce.png)

首先，我展示了一种简单的聚合方法，可以在每小时级别获取指标。

```py
data.index = pd.to_datetime(data['date'])
pd.DataFrame(data.resample('H').agg({'Temperature':'mean',
                                     'Humidity':'mean',
                                     'Light':'last',
                                     'CO2':'last',
                                     'HumidityRatio' : 'mean',
                                     'Occupancy' : 'mean'})).head(5)
```

![](../Images/5f7c9c9be8f0f4c162090ad81dde8e41.png)

尽管这个数据集不是稀疏的，但在现实世界中，我们经常遇到缺失记录的数据。重要的是要考虑这些记录，因为如果没有记录，可能需要填入0值，或者使用前一个或下一个时间步进行填补。下面，我删除了第15小时的记录，展示如何使用第14小时的时间戳填补缺失值：

```py
data = pd.read_csv('occupancy_data/datatest.txt').reset_index(drop = True)data_missing_records = data[~(pd.to_datetime(data.date).dt.hour == 15)].reset_index(drop = True)data_missing_records.index = pd.to_datetime(data_missing_records['date'])data_missing_records.resample('H', base = 1).agg({'Temperature':'mean',
        'Humidity':'mean',
        'Light':'last',
        'CO2':'last',
        'HumidityRatio' : 'mean',
         'Occupancy' : 'mean'}).fillna(method  = 'ffill').head(5)
```

![](../Images/009745c1069e4f2d84483a2fb297aa01.png)

## **2\. 通过 Plotly Express 快速可视化**

从分析到模型训练再到模型报告，通常需要可视化。特别是在时间序列图中，我发现我花了很多时间在 matplotlib 中调整 x 轴刻度的大小和角度。切换到使用 Plotly Express 后，我减少了大约 70% 的时间来使图表看起来更清晰/锐利。如果我想在可视化中实现具体细节，我仍然可以使用 Plotly Graph Objects。此外，Plotly 提供了很多通过 Express 实现的简单选项，如设置图表中的分组颜色，从而实现更强大的可视化效果。

```py
import plotly.express as px
data['Temp_Bands'] = np.round(data['Temperature'])
fig = px.line(data, x = 'date',
              y = 'HumidityRatio',
              color = 'Temp_Bands',
             title = 'Humidity Ratio across dates as a function of
             Temperature Bands',
             labels = {'date' : 'Time Stamp',
                      'HumidityRatio' : 'Humidity Ratio',
                      'Temp_Bands' : 'Temperature Band'})
fig.show()
```

使用上述提到的 occupancy 数据集，我使用 Plotly Express 创建了带有颜色分组的折线图。我们可以看到，仅通过两个函数就能轻松创建这些图表。

![](../Images/2cc650a306207e8b6bf4107a7739414c.png)

## **3\. 通过 Swifter 加速 pandas apply()**

我有时会遇到即使在大实例的笔记本上运行代码时处理 pandas 列的长时间等待问题。相反，有一个简单的单词添加可以用来加速 pandas DataFrame 中的 apply 功能。只需导入 swifter 库即可。

```py
def custom(num1, num2):

    if num1 > num2:
        if num1 < 0:
            return "Greater Negative"
        else:
            return "Greater Positive"
    elif num2 > num1:
        if num2 < 0:
            return "Less Negative"
        else:
            return "Less Positive"
    else:
        return "Rare Equal"import swifter 
import pandas as pd
import numpy as npdata_sample = pd.DataFrame(np.random.randint(-10000, 10000, size = (50000000, 2)), columns = list('XY'))
```

我创建了一个包含 5000 万行的 DataFrame，并比较了使用 `swifter apply()` 和普通 `apply()` 处理它所需的时间。我还创建了一个简单的 if else 条件的虚拟函数，以测试这两种方法的效果。

```py
%%timeresults_arr = data_sample.apply(lambda x : custom(x['X'], x['Y']), axis = 1)
```

![](../Images/7f54a9bc5220fd5514f4be79b76a38b3.png)

```py
%%timeresults_arr = data_sample.swifter.apply(lambda x : custom(x['X'], x['Y']), axis = 1)
```

![](../Images/873ffa8e12274b90bfa47f28c87c20e0.png)

我们将处理时间从 7 分钟 53 秒减少了 64.4%，降至 2 分钟 38 秒。

## **4\. Python 中的多进程**

讨论减少时间复杂度的话题时，我经常处理希望在多个粒度上处理的数据集。使用 Python 中的多进程可以通过利用多个工作者来节省时间。

我使用上面创建的相同 5000 万行数据框演示了多进程的有效性。只是这次我添加了一个类别变量，它是从一组元音中随机选择的值。

```py
import pandas as pd
import numpy as np
import randomstring =  'AEIOU'data_sample = pd.DataFrame(np.random.randint(-10000, 10000, size = (50000000, 2)), columns = list('XY'))
data_sample['random_char'] = random.choices(string, k = data_sample.shape[0])
unique_char = data_sample['random_char'].unique()
```

我使用了 for 循环与来自 concurrent.futures 的 Process Pool 执行器来演示我们可以实现的运行时减少。

```py
%%timearr = []for i in range(len(data_sample)):

    num1 = data_sample.X.iloc[i]
    num2 = data_sample.Y.iloc[i]

    if num1 > num2:
        if num1 < 0:
            arr.append("Greater Negative")
        else:
            arr.append("Greater Positive")
    elif num2 > num1:
        if num2 < 0:
            arr.append("Less Negative")
        else:
            arr.append("Less Positive")
    else:
        arr.append("Rare Equal")
```

![](../Images/e5aef2cf79229d7315a2f46fab1addc9.png)

```py
def custom_multiprocessing(i):

    sample = data_sample[data_sample['random_char'] == \
    unique_char[i]]

    arr = []

    for j in range(len(sample)):
        if num1 > num2:
            if num1 < 0:
                arr.append("Greater Negative")
            else:
                arr.append("Greater Positive")
        elif num2 > num1:
            if num2 < 0:
                arr.append("Less Negative")
            else:
                arr.append("Less Positive")
        else:
            arr.append("Rare Equal")

    sample['values'] = arr

    return sample
```

我创建了一个允许我分别处理每个元音分组的函数：

```py
 %%time 
import concurrentdef main():
    aggregated = pd.DataFrame()

    with concurrent.futures.ProcessPoolExecutor(max_workers = 5) as executor:
        results = executor.map(custom_multiprocessing, range(len(unique_char)))if __name__ == '__main__':
    main()
```

![](../Images/52cd40667af3a9d836024fb5bbc8bd0c.png)

我们看到 CPU 时间减少了 99.3%。不过必须记住，小心使用这些方法，因为它们不会序列化输出，因此通过分组使用它们可以很好地利用这种能力。

## **5\. MASE 作为一个指标**

随着机器学习和深度学习方法在时间序列预测中的兴起，使用**非**仅基于预测值和实际值之间距离的指标是至关重要的。预测模型的指标还应考虑来自时间趋势的误差，以评估模型的表现，而不仅仅是瞬时误差估计。进入 [均值绝对尺度误差](https://robjhyndman.com/publications/another-look-at-measures-of-forecast-accuracy/)! 这个指标考虑了如果我们使用随机游走方法（即上一个时间戳的值作为下一个时间戳的预测值）会得到的误差。它将模型的误差与天真的预测误差进行比较。

```py
def MASE(y_train, y_test, pred): 

    naive_error = np.sum(np.abs(np.diff(y_train)))/(len(y_train)-1)        
    model_error = np.mean(np.abs(y_test - pred))return model_error/naive_error
```

如果 MASE > 1，则模型的表现比随机游走还差。MASE 越接近 0，预测模型越好。

在这篇文章中，我们探讨了一些我常用的技巧，以让作为数据科学家的生活更轻松。评论分享你的一些技巧吧！我很想了解其他数据科学家在工作中使用的技巧。

这也是我的第一篇 Medium 文章，我觉得像是在对着虚空说话，所以如果你有任何反馈，请随时批评和联系我 :)

感谢 Anne Bonner。

**简介：[Shree Vandana](https://www.linkedin.com/in/shree-vandana-kachroo/)** 是亚马逊的数据科学家，拥有罗切斯特大学的数据科学硕士学位，对数据和机器学习充满热情！

[原文](https://towardsdatascience.com/5-things-that-make-my-job-as-a-data-scientist-easier-dc0820f0f136)。经许可转载。

**相关：**

+   [如何为你的数据科学问题选择初始模型](/2021/08/select-initial-model-data-science-problem.html)

+   [ROC 曲线解释](/2021/07/roc-curve-explained.html)

+   [如何查询你的 Pandas 数据框](/2021/08/query-pandas-dataframe.html)

### 更多相关内容

+   [如何让代码文档编写更轻松](https://www.kdnuggets.com/2022/12/make-documenting-code-easier.html)

+   [Ploomber 与 Kubeflow：让 MLOps 更轻松](https://www.kdnuggets.com/2022/02/ploomber-kubeflow-mlops-easier.html)

+   [选择下一个数据科学职位前需要注意的 5 件事](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)

+   [数据分析中的职位趋势：NLP 用于职位趋势分析](https://www.kdnuggets.com/job-trends-in-data-analytics-nlp-for-job-trend-analysis)

+   [5 个让数据科学家与其他职业区别开来的因素](https://www.kdnuggets.com/2021/11/5-things-set-data-scientist-apart-other-professions.html)

+   [数据科学职位名称导航：数据分析师 vs. 数据科学家……](https://www.kdnuggets.com/navigating-data-science-job-titles-data-analyst-vs-data-scientist-vs-data-engineer)
