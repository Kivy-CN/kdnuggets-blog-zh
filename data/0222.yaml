- en: 'Machine Learning Is Not Like Your Brain Part 6: The Importance of Precise Synapse
    Weights and the Ability to Set Them Quickly'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习并不像你的大脑第6部分：精确突触权重的重要性及其快速设置的能力
- en: 原文：[https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
- en: As far as we know, the weight of a synapse can only be changed by near-concurrent
    firing of the two neurons it connects. This is completely at odds with the fundamental
    architecture of ML’s backpropagation algorithm.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，突触的权重只能通过连接它的两个神经元的近乎同时的发放来改变。这完全与机器学习反向传播算法的基本架构相悖。
- en: You could think of backpropagation as a little man sitting on the sidelines
    of a neural network who looks at the network output, compares it to the desired
    output, and then dictates new weights for the synapses within the network. In
    a biological system, there is no mechanism to dictate the weight of any specific
    synapse. You might try to increase the synapse weight by firing the two neurons
    it connects, but there is no way to do that either. You can’t just request to
    fire neurons 1000 and 1001 to increase the synapse between them because there
    is no way to fire a specific neuron in the network.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把反向传播想象成一个坐在神经网络旁边的小人，他查看网络输出，将其与期望输出进行比较，然后为网络中的突触指示新的权重。在生物系统中，没有机制可以指示任何特定突触的权重。你可以尝试通过发放连接的两个神经元来增加突触权重，但也没有办法做到这一点。你不能仅仅要求发放神经元1000和1001来增加它们之间的突触，因为没有办法在网络中发放特定的神经元。
- en: The only mechanism we’re sure of to adjust a synapse weight is called Hebbian
    Learning. It is the mechanism which is often whimsically expressed as, “Neurons
    which fire together, wire together.” But as in all things biological, it’s not
    as simple as that. Studies in “synaptic plasticity” yield curves such as those
    in the Figures which show that to strengthen a synapse connecting a source neuron
    to a target neuron, the source needs to fire shortly before the target. To reduce
    a synapse weight, the target must fire shortly before the source. This makes overall
    sense in that if a neuron contributes to another’s firing, the synapse connecting
    the two should be strengthened and vice versa.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确定的唯一调整突触权重的机制被称为赫布学习。它是一个常被俏皮地表述为“同时发放的神经元会连接在一起”的机制。但正如所有生物学现象一样，它并不那么简单。在“突触可塑性”的研究中，得到的曲线如图所示，表明要增强连接源神经元和目标神经元的突触，源神经元需要在目标神经元之前稍微发放。要减少突触权重，目标神经元必须在源神经元之前稍微发放。这在整体上是有意义的，因为如果一个神经元对另一个神经元的发放有贡献，那么连接这两个神经元的突触应该被加强，反之亦然。
- en: There are a few more issues to note in the diagrams.  First, although the overall
    concept is summarized in Figure B, Figure A shows a large amount of scatter in
    the observed data. This means that the ability to set a synapse to any specific
    value is very limited, as has been confirmed with simulation.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图中还有一些需要注意的问题。首先，尽管整体概念在图B中进行了总结，图A显示了观察数据中大量的散布。这意味着，将突触设定为任何特定值的能力非常有限，这一点已通过模拟得到确认。
- en: You can also observe that to make any substantive change in a synapse weight
    takes a number of repetitions. Even in a theoretical environment (without the
    scatter), you can conclude that the greater precision you need in a synapse value,
    the longer it will take to set it. For example, if you’d like a synapse to take
    one of 256 different values, you could define that each enhancing spike pair would
    increase the weight by 1/256th. It might take 256 spike pairs (to the source and
    target) to set the weight. At the leisurely speed of biological neurons, this
    would take a full second.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以观察到，要对突触权重进行任何实质性的改变需要多次重复。即使在理论环境中（没有干扰的情况下），你也可以得出结论：对突触值的精确度要求越高，设定它所需的时间就越长。例如，如果你希望一个突触有256种不同的值之一，你可以定义每对增强性尖峰将权重增加1/256。可能需要256对尖峰（到源头和目标）才能设置权重。在生物神经元的缓慢速度下，这将需要整整一秒钟。
- en: Imagine building a computer where a single memory write of one byte takes about
    a second. Further, imagine the support circuitry needed to set a value of x, arranging
    for exactly x spikes to the source and target neurons. This is assuming it started
    at a weight of 0 which is yet another issue because there is no way to know the
    current weight of any synapse. Finally, imagine how any use of the network containing
    this synapse would modify the synapse weight so such a system couldn’t store accurate
    values anyway. The whole concept of storing specific values in specific synapses
    is completely implausible.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下构建一台计算机，其中单个字节的内存写入需要大约一秒钟。此外，设想需要支持电路来设置一个值x，安排准确的x次脉冲到源神经元和目标神经元。这假设它从0的权重开始，这又是另一个问题，因为没有办法知道任何突触的当前权重。最后，想象一下网络中的任何使用如何修改突触权重，使得这样的系统无论如何都无法存储准确的值。在特定突触中存储特定值的整个概念完全不切实际。
- en: There’s another way to look at it which makes a great deal more sense. Consider
    a synapse to be a binary device with a value of 0 or 1 (or -1 in the case of an
    inhibitory synapse). Now, the specific weight of the synapse represents the importance
    of that synapse and the likelihood of forgetting the data bit it represents. If
    we think in terms of neurons firing bursts of spikes (perhaps 5), then any weight
    over .2 represents a 1 and any weight below represents a 0\. Such a system can
    learn in a single burst and is immune to random changes in memory content. This
    is a completely plausible scenario, but it is also completely at odds with modern
    Machine Learning Approaches.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种看法更为合理。考虑将突触视为一个二进制设备，值为0或1（或者在抑制突触的情况下为-1）。现在，突触的特定权重代表了该突触的重要性以及遗忘它所代表的数据位的可能性。如果我们考虑神经元发射脉冲（可能是5次），那么任何超过0.2的权重代表1，任何低于0.2的权重代表0。这样的系统可以在一次脉冲中学习，并且对内存内容的随机变化具有免疫力。这是一个完全合理的情景，但它与现代机器学习方法完全相悖。
- en: Having thusfar focused on things the ML and perceptrons can do which neurons
    cannot,  I’ll turn the tables in Part 7 of this series and describe a few things
    at which neurons are particularly good.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 到目前为止，集中讨论了ML和感知机可以做到而神经元不能做到的事情，我将在本系列的第7部分扭转局面，描述一些神经元特别擅长的事情。
- en: '![Machine Learning Is Not Like Your Brain Part 6: The Importance of Precise
    Synapse Weights and the Ability to Set Them Quickly](../Images/69031318b3e16f9c8fe2bf85cbd61f7d.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习不像你的大脑 第6部分：精确突触权重的重要性及其快速设置能力](../Images/69031318b3e16f9c8fe2bf85cbd61f7d.png)'
- en: 'Figure A: Showing how the relative spike timings of source and target neurons
    influence a synapse weight. Figure B: An idealized representation of Hebbian learning
    useable in simulation. *From: Piochon, Claire & Kruskal, Peter & Maclean, Jason
    & Hansel, Christian. (2012). Non-Hebbian Spike-Timing Dependent Plasticity in
    Cerebellar Circuits. Frontiers in neural circuits. 6\. 124\. 10.3389/fncir.2012.00124.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图A：显示源神经元和目标神经元的相对脉冲时间如何影响突触权重。图B：一个理想化的Hebbian学习在仿真中可用的表示。*摘自：Piochon, Claire
    & Kruskal, Peter & Maclean, Jason & Hansel, Christian. (2012). 小脑回路中的非Hebbian脉冲时间依赖性可塑性。神经回路前沿。6.
    124. 10.3389/fncir.2012.00124.*
- en: For more information, visit [https://www.youtube.com/watch?v=jdaAKy-XkA0](https://www.youtube.com/watch?v=jdaAKy-XkA0)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请访问 [https://www.youtube.com/watch?v=jdaAKy-XkA0](https://www.youtube.com/watch?v=jdaAKy-XkA0)
- en: '**[Charles Simon](https://futureai.guru/Founder.aspx)** is a nationally recognized
    entrepreneur and software developer, and the CEO of FutureAI. Simon is the author
    of Will the Computers Revolt?: Preparing for the Future of Artificial Intelligence,
    and the developer of Brain Simulator II, an AGI research software platform. For
    more information, [visit here](https://futureai.guru/Founder.aspx).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**[查尔斯·西蒙](https://futureai.guru/Founder.aspx)** 是一位全国知名的企业家和软件开发者，也是FutureAI的首席执行官。西蒙是《计算机会反叛吗？：为人工智能的未来做准备》的作者，以及Brain
    Simulator II的开发者，这是一个AGI研究软件平台。欲了解更多信息，[请访问这里](https://futureai.guru/Founder.aspx)。'
- en: More On This Topic
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Machine Learning Is Not Like Your Brain Part 4: The Neuron’s…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第4部分：神经元的……](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第一部分：神经元很慢，……](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
- en: '[Machine Learning Is Not Like Your Brain Part Two: Perceptrons vs Neurons](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第二部分：感知器与神经元](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 3: Fundamental Architecture](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第三部分：基本架构](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 5: Biological Neurons…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第五部分：生物神经元](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
- en: '[Machine Learning is Not Like Your Brain Part Seven: What Neurons…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第七部分：神经元的作用](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)'
