["```py\npip install torchmetrics\npip install lightning-flash\npip install lightning-flash[image]\n```", "```py\n# ...\nimport pytorch_lightning as pl\n\n# replace: from pytorch_lightning.metrics import functional as FM\n# with the one below\nimport torchmetrics\n\n# import lightning_flash, which we’ll use later\nimport flash\nfrom flash.image import ImageClassifier, ImageClassificationData                \n# ...\n```", "```py\n# ...\n# in training_step\ny_pred = output.argmax(-1).cpu().numpy()\ny_tgt = y.cpu().numpy()\n\n# remove the line below line:\n# accuracy = sklearn.metrics.accuracy_score(y_tgt, y_pred)\nself.log(\"train loss\", loss)\n\n# and this one: self.log(\"train accuracy\", accuracy)\nreturn loss\n# ...\n```", "```py\n# ...\n# in validation_epoch_end\ny_preds = preds.cpu().numpy()\ny_tgts = tgts.cpu().numpy()\n# remove the lines below:\n# fm_accuracy = FM.accuracy(outputs, tgts)\n# accuracy = sklearn.metrics.accuracy_score(y_tgts, y_preds)\n# self.log(\"val_accuracy\", accuracy)\nself.log(\"val_loss\", loss)\n# ...\n```", "```py\n# ...\n# in training_step\n\naccuracy = torchmetrics.functional.accuracy(y_pred, y_tgt)\nf1_score = torchmetrics.functional.f1(y_pred, y_tgt,\naverage=\"micro\")\nauroc = torchmetrics.functional.auroc(y_pred, y_tgt,\nnumber_classes=10, average=\"micro\")\nself.log(\"train_loss\", loss)\nself.log(\"train_accuracy\", accuracy)\nself.log(\"train_f1\", f1_score)\nself.log(\"train_auroc\", auroc)\nreturn loss\n# ...\n```", "```py\n# ...\naccuracy = torchmetrics.functional.accuracy(outputs, tgts)\nf1_score = torchmetrics.functional.f1(outputs, tgts,\naverage=\"micro\")\nauroc = torchmetrics.functional.auroc(outputs, tgts,\nnumber_classes=10, average=\"micro\")\nself.log(\"val_accuracy\", accuracy)\nself.log(\"val_f1_score\", f1_score)\nself.log(\"val_auroc\", auroc)\nself.log(\"val_loss\", loss)\n# ...\n```", "```py\nclass MyClassifier(pl.LightningModule):\n    def __init__(self, dim=28, activation=nn.ReLU()):\n        super(MyClassifier, self).__init__()\n        self.image_dim = dim\n        self.hid_dim = 128\n        self.num_classes = 10\n        self.act = activation\n        # add metrics\n        self.train_acc = torchmetrics.Accuracy()\n        self.train_f1 = torchmetrics.F1(number_classes=10,\n        average=\"micro\")\n        self.train_auroc = torchmetrics.AUROC(number_classes=10,\n        average=\"micro\")\n        self.val_acc = torchmetrics.Accuracy()\n        self.val_f1 = torchmetrics.F1(number_classes=10,\n        average=\"micro\")\n        self.val_auroc = torchmetrics.AUROC(number_classes=10,\n        average=\"micro\")\n\n        # __init__ function continues\n        # ...\n```", "```py\ndef training_step(self, batch, batch_index):\n    x, y = batch\n    output = self.forward(x)\n    loss = F.nll_loss(F.log_softmax(output, dim = -1), y)\n    y_pred = output.softmax(dim=-1)\n    y_tgt = y\n    # accumulate and return metrics for logging\n    acc = self.train_acc(y_pred, y_tgt)\n    f1 = self.train_f1(y_pred, y_tgt)\n    # just accumulate\n    self.train_auroc.update(y_pred, y_tgt)\n    self.log(\"train_loss\", loss)\n    self.log(\"train_accuracy\", acc)\n    self.log(\"train_f1\", f1)\n    return loss\ndef validation_step(self, batch, batch_idx):\n    x, y = batch\n    output = self.forward(x)\n    loss = F.cross_entropy(output, y)\n    pred = output.softmax(dim=-1)\n    self.val_acc.update(pred, y)\n    self.val_f1.update(pred, y)\n    self.val_auroc.update(pred, y)\n    return loss\n```", "```py\ndef training_epoch_end(self, training_step_outputs):\n    # compute metrics\n    train_accuracy = self.train_acc.compute()\n    train_f1 = self.train_f1.compute()\n    train_auroc = self.train_auroc.compute()\n    # log metrics\n    self.log(\"epoch_train_accuracy\", train_accuracy)\n    self.log(\"epoch_train_f1\", train_f1)\n    # reset all metrics\n    self.train_acc.reset()\n    self.train_f1.reset()\n    print(f\"\\ntraining accuracy: {train_accuracy:.4}, \"\\\n    f\"f1: {train_f1:.4}, auroc: {train_auroc:.4}\")\n\ndef validation_epoch_end(self, validation_step_outputs):\n    # compute metrics\n    val_loss = torch.tensor(validation_step_outputs).mean()\n    val_accuracy = self.val_acc.compute()\n    val_f1 = self.val_f1.compute()\n    val_auroc = self.val_auroc.compute()\n    # log metrics\n    self.log(\"val_accuracy\", val_accuracy)\n    self.log(\"val_loss\", val_loss)\n    self.log(\"val_f1\", val_f1)\n    self.log(\"val_auroc\", val_auroc)\n    # reset all metrics\n    self.val_acc.reset()\n    self.val_f1.reset()\n    self.val_auroc.reset()\n    print(f\"\\nvalidation accuracy: {val_accuracy:.4} \"\\\n    f\"f1: {val_f1:.4}, auroc: {val_auroc:.4}\")\n```", "```py\nmetrics_10 = [torchmetrics.Accuracy(), \\\n    torchmetrics.F1(num_classes=10, average=\"micro\")]\nvalidation_interval = 1.0\ntrain_dataset = CIFAR10(os.getcwd(), download=True, \\\n    train=True) #, transform=transforms.ToTensor())\nval_dataset = CIFAR10(os.getcwd(), download=True, \\\n    train=False) #, transform=transforms.ToTensor())\ndatamodule = ImageClassificationData.from_datasets(\ntrain_dataset=train_dataset,\\\n    val_dataset=val_dataset)\nmodel = ImageClassifier(backbone=\"resnet18\", \\\n    num_classes=10, metrics=metrics_10)\ntrainer = flash.Trainer(max_epochs=25, \\\nval_check_interval=validation_interval, gpus=1)\ntrainer.fit(model, datamodule=datamodule)\n```", "```py\ntrain_dataset = CIFAR100(os.getcwd(), download=True, \\\n    train=True) #, transform=transforms.ToTensor())\nval_dataset = CIFAR100(os.getcwd(), download=True, \\\n    train=False) #, transform=transforms.ToTensor())\nmetrics_100 = [torchmetrics.Accuracy(), \\\n    torchmetrics.F1(num_classes=100, average=\"micro\")]\ndatamodule = ImageClassificationData.from_datasets(\ntrain_dataset=train_dataset,\\\n    val_dataset=val_dataset)\nmodel_2 = ImageClassifier(backbone=(model.backbone, 512),\\\n    num_classes=100, metrics=metrics_100)\ntrainer_2 = flash.Trainer(max_epochs=15, \\\n    val_check_interval=validation_interval, gpus=1)\ntrainer_2.finetune(model_2, datamodule=datamodule,\\\n    strategy=\"freeze\")\n```", "```py\ncurl https://pl-flash-data.s3.amazonaws.com/hymenoptera_data.zip \\\n    -o hymenoptera_data.zip\nunzip hymenoptera_data.zip\n\nflash image_classification --trainer.max_epochs 10 –model.backbone \\\n    resnet18 from_folders --train_folder \\\n    ./hymenoptera_data/train/\n```"]