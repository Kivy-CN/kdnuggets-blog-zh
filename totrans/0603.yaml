- en: How to Convert an RGB Image to Grayscale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/12/convert-rgb-image-grayscale.html](https://www.kdnuggets.com/2019/12/convert-rgb-image-grayscale.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Occasionally the need arises to convert a color image to grayscale. This need
    came up when loading images taken on the surface of Mars as part of [End-to-End
    Machine Learning Course 313, Advanced Neural Network Methods](https://end-to-end-machine-learning.teachable.com/p/advanced-neural-network-methods).
    We were working with a mixture of color and grayscale images and needed to transform
    them into a uniform format - all grayscale. We'll be working in Python using the
    Pillow, Numpy, and Matplotlib packages.
  prefs: []
  type: TYPE_NORMAL
- en: By the way, all the interesting information in this post all comes from [the
    Wikipedia entry on Grayscale](https://en.wikipedia.org/wiki/Grayscale). (If you
    find it helpful, [maybe send them a dollar](https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&country=US&uselang=en&utm_medium=sidebar&utm_source=donate&utm_campaign=C13_en.wikipedia.org).)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Read in a Color Image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The [code we''re working from](https://github.com/brohrer/cottonwood_martian_images/blob/master/image_loader.py) loads
    jpeg images for an autoencoder to use as inputs. This is accomplished with using
    Pillow and Numpy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This reads the image in and converts it into a Numpy array. For a detailed description
    of what this does and why, check out the prequel post to this one: [How to Convert
    a Picture into Numbers](https://brohrer.github.io/images_to_numbers.html). For
    grayscale images, the result is a two-dimensional array with the number of rows
    and columns equal to the number of pixel rows and columns in the image. Low numeric
    values indicate darker shades and higher values lighter shades. The range of pixel
    values is often 0 to 255\. We divide by 255 to get a range of 0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: Color images are represented as three-dimensional Numpy arrays - a collection
    of three two-dimensional arrays, one each for red, green, and blue channels. Each
    one, like grayscale arrays, has one value per pixel and their ranges are identical.
  prefs: []
  type: TYPE_NORMAL
- en: '![Three dimensional image array structure](../Images/4ca9846e2120338949d3ec950a8e487e.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Figure](../Images/b61919db92ac4e6ae4bab1f098d97892.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image credit: Diane Rohrer'
  prefs: []
  type: TYPE_NORMAL
- en: 'Easy Peasy: Average the Channels'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An intuitive way to convert a color image 3D array to a grayscale 2D array is,
    for each pixel, take the average of the red, green, and blue pixel values to get
    the grayscale value. This combines the lightness or *luminance* contributed by
    each color band into a reasonable gray approximation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `axis=2` argument tells `numpy.mean()` to average values across all three
    color channels. (`axis=0` would average across pixel rows and `axis=1` would average
    across pixel columns.)
  prefs: []
  type: TYPE_NORMAL
- en: '![Gray from averaging red, green, and blue channels](../Images/905b2292724d8aa2c01f659a0670ba6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Well, Actually... Channel-dependent Luminance Perception
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To our eyes green looks about ten times brighter than blue. Through many repetitions
    of carefully designed experiments, psychologists have figured out how different
    we perceive the luminance or red, green, and blue to be. They have provided us
    a different set of weights for our channel averaging to get total luminance.
  prefs: []
  type: TYPE_NORMAL
- en: '[![Equation for combining red, green, and blue channels](../Images/07e545e6886030e0ab53c00977c5dc85.png)](https://en.wikipedia.org/wiki/Grayscale#Colorimetric_(perceptual_luminance-preserving)_conversion_to_grayscale)'
  prefs: []
  type: TYPE_NORMAL
- en: The results are noticeably different and, to my eye, more accurate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gray from weighted averaging red, green, and blue channels](../Images/5a1bcd7bc191e37523bd1f6dbb96e6f8.png)'
  prefs: []
  type: TYPE_IMG
- en: Well, Actually... Gamma Compression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are able to see small differences when luminance is low, but at high luminance
    levels, we are much less sensitive to them. In order to avoid wasting effort representing
    imperceptible differences at high luminance, the color scale is warped, so that
    it concentrates more values in the lower end of the range, and spreads them out
    more widely in the higher end. This is called gamma compression.
  prefs: []
  type: TYPE_NORMAL
- en: 'To undo the effects of gamma compression before calculating the grayscale luminance,
    it''s necessary to apply the inverse operation, gamma expansion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Nonlinear transformation of gamma](../Images/2dc74756a003859bbd1e9b226f13bf20.png)](https://en.wikipedia.org/wiki/Grayscale#Colorimetric_(perceptual_luminance-preserving)_conversion_to_grayscale)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gamma compression function](../Images/f5e98853566862762b4c0d81947a0c47.png)'
  prefs: []
  type: TYPE_IMG
- en: The benefit of gamma compression is that it gets rid of banding in smoothly
    varying dark colors, like a photo of the sky at twilight. The downside is that
    if we want to do anything like adding, subtracting, or averaging bands, we first
    have to undo the compression and get the luminance back into a linear representation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Gray accounting for gamma compression](../Images/cba8097bba797dcffc9d6c8c8374fc0b.png)'
  prefs: []
  type: TYPE_IMG
- en: There is lightening throughout the image after accounting for gamma compression.
    It brings the luminance up to be a closer match to that of the original image.
    Finally, we have a high quality grayscale representation.
  prefs: []
  type: TYPE_NORMAL
- en: Well, Actually... A Linear Approximation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The gamma decompression and re-compression rack up quite a large computation
    cost, compared to the weighted averages we were working with before. Sometimes
    speed is more desirable than accurate-as-possible luminance calculations. For
    situations like these, there is a linear approximation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation for combining red, green, and blue channels](../Images/07a95fe9ad4c404e73d78bcba841f190.png)'
  prefs: []
  type: TYPE_IMG
- en: This lets you get a result that's a little closer to the gamma-compression-corrected
    version, but without the extra computation time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear approximation of gray accounting for gamma compression](../Images/3e371291a241ad99f52ca0f9aa662f7f.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the results are not bad at all. They tend to be a little darker,
    especially through the red mid-range values, but arguably just as good in most
    practical respects.
  prefs: []
  type: TYPE_NORMAL
- en: This method of calculating luminance is codified in the standard [ITU-R BT.601
    Studio encoding parameters of digital television for standard 4:3 and wide screen
    16:9 aspect ratios. ](https://www.itu.int/dms_pubrec/itu-r/rec/bt/R-REC-BT.601-7-201103-I!!PDF-E.pdf)which
    incidentally was awarded an Emmy in 1983.
  prefs: []
  type: TYPE_NORMAL
- en: Which One Should I Use?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If close is good enough or if you really care about speed, use the linear approximation
    of gamma correction. This is the approach used by [MATLAB](https://www.mathworks.com/help/matlab/ref/rgb2gray.html), [Pillow](https://pillow.readthedocs.io/en/3.1.x/reference/Image.html),
    and [OpenCV](https://github.com/opencv/opencv/blob/8c0b0714e76efef4a8ca2a7c410c60e55c5e9829/modules/imgproc/src/color.simd_helpers.hpp).
    It is included in my [Lodgepole image and video processing toolbox](https://github.com/brohrer/lodgepole/blob/master/lodgepole/image_tools.py):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'But if you simply must have the best results, splurge on the whole gamma decompression
    - perceptual luminance corrected - gamma re-compression pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If after reading this far you insist on straight up averaging the three channels
    together, I will judge you.
  prefs: []
  type: TYPE_NORMAL
- en: Now go make beautiful grayscale images!
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://brohrer.github.io/convert_rgb_to_grayscale.html). Reposted
    with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Brandon Rohrer**](https://www.linkedin.com/in/brohrer/) is a Staff Machine
    Learning Engineer at LinkedIn. Brandon''s specialty is creating algorithms and
    computational methods. You can find examples of his work [here](https://brandonrohrer.com/portfolio).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to Use ChatGPT to Convert Text into a PowerPoint Presentation](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convert Text Documents to a TF-IDF Matrix with tfidfvectorizer](https://www.kdnuggets.com/2022/09/convert-text-documents-tfidf-matrix-tfidfvectorizer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convert Python Dict to JSON: A Tutorial for Beginners](https://www.kdnuggets.com/convert-python-dict-to-json-a-tutorial-for-beginners)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Convert JSON Data into a DataFrame with Pandas](https://www.kdnuggets.com/how-to-convert-json-data-into-a-dataframe-with-pandas)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convert Bytes to String in Python: A Tutorial for Beginners](https://www.kdnuggets.com/convert-bytes-to-string-in-python-a-tutorial-for-beginners)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
