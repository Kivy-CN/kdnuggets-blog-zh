- en: Unlock the Secrets to Choosing the Perfect Machine Learning Algorithm!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁选择完美机器学习算法的秘密！
- en: 原文：[https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)
- en: One of the key decisions you need to make when solving a data science problem
    is which [machine learning](https://medium.com/p/313730eb5aa2) algorithm to use.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决数据科学问题时，您需要做出的关键决策之一是选择使用哪种[machine learning](https://medium.com/p/313730eb5aa2)算法。
- en: There are hundreds of machine learning algorithms to choose from, each with
    its own advantages and disadvantages. Some algorithms may work better than others
    on specific types of problems or on specific data sets.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法有数百种可供选择，每种算法都有其优缺点。有些算法在特定类型的问题或数据集上可能比其他算法更有效。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT 工作'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The [“No Free Lunch” (NFL) theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem) states
    that there is no one algorithm that works best for every problem, or in other
    words, all algorithms have the same performance when their performance is averaged
    over all the possible problems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[“无免费午餐” (NFL) 定理](https://en.wikipedia.org/wiki/No_free_lunch_theorem) 认为，没有一种算法对每个问题都最好，换句话说，所有算法的表现都在所有可能问题的平均表现中相同。'
- en: '![Which ML Algorithm to Choose?](../Images/db7baeaa9d1b6dda200b7c6976d98f00.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![选择哪个 ML 算法？](../Images/db7baeaa9d1b6dda200b7c6976d98f00.png)'
- en: Different machine learning models
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的机器学习模型
- en: In this article, we will discuss the main points you should consider when choosing
    a model for your problem and how to compare different machine learning algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将讨论在为您的问题选择模型时需要考虑的主要点以及如何比较不同的机器学习算法。
- en: Key Algorithm Aspects
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键算法方面
- en: 'The following list contains 10 questions you may ask yourself when considering
    a specific machine-learning algorithm:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表包含了您在考虑特定机器学习算法时可以问自己的10个问题：
- en: Which type of problems can the algorithm solve? Can the algorithm solve only
    regression or classification problems, or can it solve both? Can it handle multi-class/multi-label
    problems or only binary classification problems?
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法可以解决哪类型的问题？它能仅解决回归或分类问题，还是两者皆能？它能处理多类/多标签问题还是仅二分类问题？
- en: Does the algorithm have any assumptions about the data set? For example, some
    algorithms assume that the data is linearly separable (e.g., perceptron or linear
    SVM), while others assume that the data is normally distributed (e.g., Gaussian
    Mixture Models).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法是否对数据集有任何假设？例如，一些算法假设数据是线性可分的（如感知机或线性 SVM），而其他算法假设数据是正态分布的（如高斯混合模型）。
- en: Are there any guarantees about the performance of the algorithm? For example,
    if the algorithm tries to solve an optimization problem (as in logistic regression
    or neural networks), is it guaranteed to find the global optimum or only a local
    optimum solution?
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于算法的性能是否有任何保证？例如，如果算法尝试解决优化问题（如逻辑回归或神经网络），它是否保证找到全局最优解或仅局部最优解？
- en: How much data is needed to train the model effectively? Some algorithms, like
    deep neural networks, are more data-savvy than others.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型有效需要多少数据？有些算法，如深度神经网络，比其他算法更能处理大量数据。
- en: Does the algorithm tend to overfit? If so, does the algorithm provide ways to
    deal with overfitting?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法是否容易过拟合？如果是，它是否提供处理过拟合的方法？
- en: What are the runtime and memory requirements of the algorithm, both during training
    and prediction time?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法在训练和预测过程中需要多少运行时间和内存？
- en: Which data preprocessing steps are required to prepare the data for the algorithm?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了准备数据以供算法使用，需要哪些数据预处理步骤？
- en: How many hyperparameters does the algorithm have? Algorithms that have a lot
    of hyperparameters take more time to train and tune.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法有多少个超参数？超参数较多的算法在训练和调整时需要更多的时间。
- en: Can the results of the algorithm be easily interpreted? In many problem domains
    (such as medical diagnosis), we would like to be able to explain the model’s predictions
    in human terms. Some models can be easily visualized (such as decision trees),
    while others behave more like a black box (e.g., neural networks).
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法的结果是否容易解释？在许多问题领域（如医学诊断），我们希望能够用人类的语言解释模型的预测。一些模型可以被轻松可视化（例如决策树），而其他模型则表现得更像一个黑箱（例如神经网络）。
- en: Does the algorithm support online (incremental) learning, i.e., can we train
    it on additional samples without rebuilding the model from scratch?
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法是否支持在线（增量）学习，即我们是否可以在不从头开始重建模型的情况下对其进行额外样本的训练？
- en: Algorithm Comparison Example
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法比较示例
- en: For example, let’s take two of the most popular algorithms: [decision trees](https://medium.com/@roiyeho/decision-trees-part-1-da4e613d2369) and [neural
    networks](https://medium.com/@roiyeho/perceptrons-the-first-neural-network-model-8b3ee4513757),
    and compare them according to the above criteria.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们比较两个最流行的算法：[决策树](https://medium.com/@roiyeho/decision-trees-part-1-da4e613d2369)和[神经网络](https://medium.com/@roiyeho/perceptrons-the-first-neural-network-model-8b3ee4513757)，并根据上述标准进行比较。
- en: Decision Trees
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决策树
- en: Decision trees can handle both classification and regression problems. They
    can also easily handle multi-class and multi-label problems.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树可以处理分类和回归问题。它们也可以轻松处理多类别和多标签问题。
- en: Decision tree algorithms do not have any specific assumptions about the data
    set.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树算法对数据集没有任何特定的假设。
- en: A decision tree is built using a greedy algorithm, which is not guaranteed to
    find the optimal tree (i.e., the tree that minimizes the number of tests required
    to classify all the training samples correctly). However, a decision tree can
    achieve 100% accuracy on the training set if we keep extending its nodes until
    all the samples in the leaf nodes belong to the same class. Such trees are usually
    not good predictors, as they overfit the noise in the training set.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树是使用贪婪算法构建的，这种算法并不能保证找到最优树（即最小化分类所有训练样本所需测试次数的树）。然而，如果我们不断扩展其节点直到所有叶节点中的样本都属于同一类，决策树可以在训练集上达到100%的准确率。这种树通常不是好的预测器，因为它们会过拟合训练集中的噪声。
- en: Decision trees can work well even on small or medium-sized data sets.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树即使在小型或中型数据集上也能表现良好。
- en: Decision trees can easily overfit. However, we can reduce overfitting by using
    tree pruning. We can also use [ensemble methods](https://medium.com/@roiyeho/introduction-to-ensemble-methods-226a5a421687) such
    as random forests that combine the output of multiple decision trees. These methods
    suffer less from overfitting.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树容易过拟合。然而，我们可以通过使用树剪枝来减少过拟合。我们还可以使用[集成方法](https://medium.com/@roiyeho/introduction-to-ensemble-methods-226a5a421687)，例如随机森林，这些方法结合了多个决策树的输出。这些方法在过拟合方面表现较好。
- en: The time to build a decision tree is *O*(*n*²*p*), where n is the number of
    training samples, and *p* is the number of features. The prediction time in decision
    trees depends on the height of the tree, which is usually logarithmic in *n*,
    since most decision trees are fairly balanced.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建决策树的时间为*O*(*n*²*p*)，其中 n 是训练样本的数量，*p* 是特征的数量。决策树中的预测时间取决于树的高度，通常与*n*的对数成正比，因为大多数决策树都相当平衡。
- en: Decision trees do not require any data preprocessing. They can seamlessly handle
    different types of features, including numerical and categorical features. They
    also do not require normalization of the data.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树不需要任何数据预处理。它们可以无缝处理不同类型的特征，包括数值特征和分类特征。它们也不需要对数据进行归一化。
- en: Decision trees have several key hyperparameters that need to be tuned, especially
    if you are using pruning, such as the maximum depth of the tree and which impurity
    measure to use to decide how to split the nodes.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树有几个关键的超参数需要调整，特别是如果你使用了剪枝方法，比如树的最大深度以及用来决定如何分裂节点的纯度度量。
- en: Decision trees are simple to understand and interpret, and we can easily visualize
    them (unless the tree is very large).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树易于理解和解释，我们可以轻松地对其进行可视化（除非树非常大）。
- en: Decision trees cannot be easily modified to take into account new training samples
    since small changes in the data set can cause large changes in the topology of
    the tree.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树不能轻易修改以考虑新的训练样本，因为数据集的细微变化可能会导致树的拓扑结构发生重大变化。
- en: Neural Networks
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络
- en: Neural networks are one of the most general and flexible machine learning models
    that exist. They can solve almost any type of problem, including classification,
    regression, time series analysis, automatic content generation, etc.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络是现存最通用和灵活的机器学习模型之一。它们几乎可以解决任何类型的问题，包括分类、回归、时间序列分析、自动内容生成等。
- en: Neural networks do not have assumptions about the data set, but the data needs
    to be normalized.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络对数据集没有假设，但数据需要被规范化。
- en: Neural networks are trained using gradient descent. Thus, they can only find
    a local optimum solution. However, there are various techniques that can be used
    to avoid getting stuck in local minima, such as momentum and adaptive learning
    rates.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络使用梯度下降法进行训练。因此，它们只能找到局部最优解。然而，有多种技术可以用来避免陷入局部最小值，例如动量和自适应学习率。
- en: Deep neural nets require a lot of data to train in the order of millions of
    sample points. In general, the larger the network is (the more layers and neurons
    it has), more we need data to train it.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度神经网络需要大量数据进行训练，通常在数百万个样本点的数量级。一般来说，网络越大（层数和神经元越多），所需的数据量也越多。
- en: Networks that are too large might memorize all the training samples and not
    generalize well. For many problems, you can start from a small network (e.g.,
    with only one or two hidden layers) and gradually increase its size until you
    start overfitting the training set. You can also add [regularization](https://medium.com/@roiyeho/regularization-19b1879415a1) in
    order to deal with overfitting.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过大的网络可能会记住所有训练样本而无法很好地泛化。对于许多问题，你可以从一个小型网络（例如，只有一两层隐藏层）开始，逐渐增加其规模，直到出现过拟合。你还可以添加 [正则化](https://medium.com/@roiyeho/regularization-19b1879415a1) 以应对过拟合。
- en: The training time of a neural network depends on many factors (the size of the
    network, the number of gradient descent iterations needed to train it, etc.).
    However, prediction time is very fast since we only need to do one forward pass
    over the network to get the label.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络的训练时间取决于许多因素（网络的大小、训练所需的梯度下降迭代次数等）。然而，预测时间非常快，因为我们只需对网络进行一次前向传播即可获得标签。
- en: Neural networks require all the features to be numerical and normalized.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络要求所有特征都为数值型并进行规范化。
- en: Neural networks have a lot of hyperparameters that need to be tuned, such as
    the number of layers, the number of neurons in each layer, which activation function
    to use, the learning rate, etc.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络有许多超参数需要调整，如层数、每层的神经元数量、使用哪个激活函数、学习率等。
- en: The predictions of neural networks are hard to interpret as they are based on
    the computation of a large number of neurons, each of which has only a small contribution
    to the final prediction.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络的预测结果难以解释，因为它们基于大量神经元的计算，每个神经元对最终预测的贡献都很小。
- en: Neural networks can easily adapt to include additional training samples, as
    they use an incremental learning algorithm (stochastic gradient descent).
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络可以轻松适应包括额外的训练样本，因为它们使用增量学习算法（随机梯度下降）。
- en: Time Complexity
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间复杂度
- en: The following table compares the training and prediction times of some popular
    algorithms (*n* is the number of training samples and *p* is the number of features).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下表比较了一些流行算法的训练和预测时间（*n* 是训练样本的数量，*p* 是特征的数量）。
- en: '![Which ML Algorithm to Choose?](../Images/c71fb69ae4ca01cad051997816b89691.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![选择哪个机器学习算法？](../Images/c71fb69ae4ca01cad051997816b89691.png)'
- en: Most Successful Algorithms in Kaggle Competitions
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kaggle竞赛中最成功的算法
- en: According to a survey that was done in 2016, the most frequently used algorithms
    by Kaggle competition winners were gradient boosting algorithms (XGBoost) and
    neural networks (see [this article](https://www.kaggle.com/code/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/report?scriptVersionId=0)).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 根据2016年进行的一项调查，Kaggle竞赛获胜者最常用的算法是梯度提升算法（XGBoost）和神经网络（参见 [这篇文章](https://www.kaggle.com/code/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/report?scriptVersionId=0)）。
- en: Amongst the 29 Kaggle competition winners in 2015, 8 of them used XGBoost, 9
    used deep neural nets, and 11 used an ensemble of both.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在2015年的29名Kaggle竞赛获胜者中，有8人使用了XGBoost，9人使用了深度神经网络，11人则使用了两者的集成。
- en: XGBoost was mainly used in problems that dealt with structured data (e.g., relational
    tables), whereas neural networks were more successful in handling unstructured
    problems (e.g., problems that deal with image, voice, or text).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 主要用于处理结构化数据（例如关系表格）的问题，而神经网络在处理非结构化问题（例如涉及图像、声音或文本的问题）方面更为成功。
- en: It would be interesting to check if this is still the situation today or whether
    the trends have changed (is anyone up for the challenge?)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这种情况是否仍然存在或者趋势是否已经改变会很有趣（有人愿意接受这个挑战吗？）
- en: Thanks for reading!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: '**[Dr. Roi Yehoshua](https://www.linkedin.com/in/roi-yehoshua/)** is a teaching
    professor at Northeastern University in Boston, teaching classes that make up
    the Master''s program in Data Science. His research in multi-robot systems and
    reinforcement learning has been published in the top leading journals and conferences
    in AI. He is also a top writer on the Medium social platform, where he frequently
    publishes articles on Data Science and Machine Learning.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Roi Yehoshua 博士](https://www.linkedin.com/in/roi-yehoshua/)** 是波士顿东北大学的教授，教授数据科学硕士课程。他在多机器人系统和强化学习方面的研究已经在人工智能领域的顶级期刊和会议上发表。他还是
    Medium 社交平台的顶级作者，经常发布有关数据科学和机器学习的文章。'
- en: '[Original](https://medium.com/towards-artificial-intelligence/which-ml-algorithm-to-choose-f9caf674219e).
    Reposted with permission.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/towards-artificial-intelligence/which-ml-algorithm-to-choose-f9caf674219e)。经许可转载。'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Unlock the Secrets of LLMs in 60-Minute with Andrej Karpathy](https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 60 分钟内解锁 LLM 的秘密，与 Andrej Karpathy 一起](https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy)'
- en: '[Choosing the Right Clustering Algorithm for Your Dataset](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为你的数据集选择合适的聚类算法](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
- en: '[Unlock the Power of AI - A Special Release by KDnuggets and Machine…](https://www.kdnuggets.com/2023/07/mlm-unlock-power-ai-special-release-kdnuggets-machine-learning-mastery.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[释放 AI 的力量 - KDnuggets 和 Machine 的特别发布…](https://www.kdnuggets.com/2023/07/mlm-unlock-power-ai-special-release-kdnuggets-machine-learning-mastery.html)'
- en: '[Unlock Your Potential with This FREE DevOps Crash Course](https://www.kdnuggets.com/2023/03/corise-unlock-potential-with-this-free-devops-crash-course.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这个免费的 DevOps 短期课程释放你的潜力](https://www.kdnuggets.com/2023/03/corise-unlock-potential-with-this-free-devops-crash-course.html)'
- en: '[ChatGPT-Powered Data Exploration: Unlock Hidden Insights in Your Dataset](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 驱动的数据探索：解锁数据集中的隐藏见解](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
- en: '[Unlock your next move: Save up to 67% on in-demand data upskilling](https://www.kdnuggets.com/2023/03/datacamp-unlock-next-move-save-67-indemand-data-upskilling.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解锁你的下一步行动：在热门数据技能提升课程中节省高达 67%](https://www.kdnuggets.com/2023/03/datacamp-unlock-next-move-save-67-indemand-data-upskilling.html)'
