- en: How a Level System can Help Forecast AI Costs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How a Level System can Help Forecast AI Costs](../Images/5508d68d4ed86099bfaefeee1139d76a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Hitesh Choudhary](https://unsplash.com/@hiteshchoudhary?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: Designing and building AI systems is difficult. Unlike traditional software
    where the majority of the costs are in the development process *before* the systems
    are deployed, with AI systems, most of the costs occur *after*. The behavior of
    AI systems is learned, potentially changing from its initial deployment. Machine
    learning models degrade over time without ongoing investment in data and hyperparameter
    tuning. And design decisions directly affect the ability to scale AI systems.
    A core part of this design difficulty is understanding how they change (or don’t
    change!) over time.
  prefs: []
  type: TYPE_NORMAL
- en: When building AI systems, it can be useful to talk about their “level”, just
    like [SAE has levels for self-driving cars](https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-for-its-%E2%80%9Clevels-of-driving-automation%E2%80%9D-standard-for-self-driving-vehicles).
    Adopting a level system can help organizations plan and prepare for AI systems
    that scale in complexity over time. Levels can provide core breakpoints for how
    different AI systems can behave.  Employing levels – and making trade-offs between
    levels – can help provide a shorthand for differences post-deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s critical to understand *what kind* of behavioral changes the system might
    undergo, and to factor that into the design of the system. The leveling framework
    below outlines core differences in how systems will change over time: we can use
    these when both designing a system and operating it. Different components can
    be at different levels; having an intuition of how they are different can help
    inform planning and execution.'
  prefs: []
  type: TYPE_NORMAL
- en: System complexity is defined by the scope of its (a) inputs, (b) outputs, and
    (c) objectives.
  prefs: []
  type: TYPE_NORMAL
- en: AI Levels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In general, there is increasing value as you move up levels, e.g. one goal might
    be to move a system operating at Level 1 to be at Level 2 – but complexity (*and
    cost*) of system build also increases as levels go up. It can make a lot of sense
    to **start** with a novel feature at a “low” level, where the system behavior
    is well understood, and progressively increase the level - as understanding the
    failure cases of the system becomes more difficult as the level increases.
  prefs: []
  type: TYPE_NORMAL
- en: The focus should be on learning about the problem and the solution space. Lower
    levels are more consistent and can be much better avenues to explore possible
    solutions than higher levels, whose cost and variability in performance can be
    large hindrances.
  prefs: []
  type: TYPE_NORMAL
- en: Levels of AI Systems provide breakpoints that dramatically affect system cost,
    in a progression as we move from traditional software (*Level 0*) up to fully
    **Intelligent** software (*Level 4*). Systems at Level 4 essentially maintain
    and improve on their own - they require negligible work from in-house development
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: Moving up a level has trade-offs. For example, moving from Level 1 to Level
    2 reduces ongoing data requirements and customization work, but introduces a self-reinforcing
    bias problem. Choosing to move up a level requires recognizing the new challenges,
    and the actions to take in designing our AI system.
  prefs: []
  type: TYPE_NORMAL
- en: There are significant benefits in scalability (*and typically performance/robustness/etc*)
    in moving up levels. We should recognize the benefits, and costs; when we work
    on a project at level *N*, we should consider the work to get to *N+1*. We should
    target the level appropriate for what we are trying to achieve, and recognize
    when an existing AI system needs to be rebuilt to change levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Level 0: Deterministic'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*No required training data, no required testing data*'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms that involve no learning (e.g. adapting parameters to data) are at
    level zero.
  prefs: []
  type: TYPE_NORMAL
- en: The great benefit of level 0 (traditional algorithms in computer science) is
    that they are very reliable and, if you solve the problem, can be shown to be
    the optimal solution. If you can solve a problem at level 0 it’s hard to beat.
    In some respect, all algorithms - even sorting algorithms (like binary search)
    - are "adaptive" to the data. We do not generally consider sorting algorithms
    to be "learning". Learning involves memory - the system changing how it behaves
    in the future, based on what it's learned in the past.
  prefs: []
  type: TYPE_NORMAL
- en: However, some problems defy a pre-specified algorithmic solution. The downside
    is that for problems that defy human understanding (either once, or in number)
    it can be difficult to perform well (e.g. speech to text, translation, image recognition,
    utterance suggestion, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Luhn Algorithm](https://en.wikipedia.org/wiki/Luhn_algorithm) for credit card
    validation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regex-based systems (e.g. simple redaction systems for credit card numbers).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information retrieval algorithms like TFIDF retrieval or BM25.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dictionary-based spell correction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Note: In some cases, there can be a small number of parameters to tune. For
    example,* [*ElasticSearch provides the ability to modify BM25 parameters*](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25)*.
    We can regard these as tuning parameters, i.e. set and forget. This is a blurry
    line.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Level 1: Learned'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Static training data, static testing data*'
  prefs: []
  type: TYPE_NORMAL
- en: Systems where you train the model in an offline setting and deploy to production
    with “frozen” weights. There may be an updating cadence to the model (*e.g. adding
    more annotated data*), but the environment the model operates in does not affect
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of level 1 is that you can learn and deploy any function at the
    modest cost of some training data. This is a great place to experiment with different
    types of solutions. And, for problems with common elements (*e.g. speech recognition*)
    you can benefit from diminishing marginal costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The downside is that customization to a single use case is linear in their
    number: you need to curate training data for each use case. And that can change
    over time, so you need to continuously add annotations to preserve performance.
    This cost can be hard to bear.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples:**'
  prefs: []
  type: TYPE_NORMAL
- en: Custom text classification models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech to text (acoustic model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Level 2: Self-learning'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Dynamic + static training data, static testing data*'
  prefs: []
  type: TYPE_NORMAL
- en: Systems that use training data generated from the system for the model to improve.
    In some cases, the data generation is independent of the model (*so we expect
    increasing model performance over time as more data is added*); in other cases,
    the model intervening can reinforce model biases and performance can *get worse*
    over time.  To eliminate the chance of reinforcing biases, we need to evaluate
    new models on static (*potentially annotated*) data sets.
  prefs: []
  type: TYPE_NORMAL
- en: Level 2 is great because performance seems to improve over time for free. The
    downside is that, left unattended, the system can get worse - it may not be consistent
    in getting better with more data. The other limitation is that some systems at
    level two might have limited capacity to improve as they essentially feed on themselves
    *(generating their own training data*); addressing this bias can be challenging*.*
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples:**'
  prefs: []
  type: TYPE_NORMAL
- en: Naive spam filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common speech to text models (language model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Level 3: Autonomous (*or self-correcting*)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Dynamic training data, dynamic test data*'
  prefs: []
  type: TYPE_NORMAL
- en: Systems that both *alter* human behavior (e.g. recommend an action and let the
    user opt-in) and *learn* directly from that behavior, including how the systems'
    choice changes the user behavior. Moving from Level 2 to 3 potentially represents
    a big increase in system reliability and total achievable performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Level 3 is great because it can consistently get better over time.  However,
    it is more complex: it might require truly staggering amounts of data, or a very
    carefully designed setup, to do better than simpler systems; its ability to adapt
    to the environment also makes it very hard to debug. It is also possible to have
    truly catastrophic feedback loops. For example, a human corrects an email spam
    filter - however, because the human can only ever correct misclassifications that
    the system made, it learns that all its predictions are wrong and inverts its
    own predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Level 4: Intelligent (*or globally optimizing*)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Dynamic training data, dynamic test data, dynamic goal*'
  prefs: []
  type: TYPE_NORMAL
- en: Systems that both dynamically interact with an environment **and** globally
    optimizes (e.g. towards some set of downstream objectives), e.g. facilitating
    an agent while optimizing for AHT and CST, or optimizing directly for profit.
    For example, an AutoSuggest model that does not optimize for the next click (*current
    approach*) but for the best series of clicks to optimize the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: Level 4 has awesome promise - it is not always obvious how to get there, and
    unless carefully designed, these systems can optimize towards degenerate solutions.
    Aiming them at the right problem, shaping the reward, and auditing its behavior
    are large and non-trivial tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Appendix: Matrix Layout'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can visualize the levels as a matrix as well.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Level** | **Narrative Definition** | **Inputs** | **Outputs** | **Objectives**
    |'
  prefs: []
  type: TYPE_TB
- en: '| 0: **Deterministic** | Algorithms that involve no *learning* (e.g. no adapting
    parameters to data) are at level zero. | No training data. | General outputs.
    | No objective target. Metrics (for performance). |'
  prefs: []
  type: TYPE_TB
- en: '| 1: **Learned** | Systems where model training is in an offline setting and
    is deployed to production with “frozen” weights. There may be an updating cadence
    to the model (e.g. adding more annotated data), but the data used to train the
    model is not generated directly by the system. | Static data, often annotated.
    | Simple output (*simple function approximation*) | Single objective, mapping
    from input data to output. |'
  prefs: []
  type: TYPE_TB
- en: '| 2: **Self Improving** | Systems that use training data generated from the
    system for the model to improve, ideally where the data is stationary (*so we
    expect increasing model performance over time as more data is added*). | Retraining
    using new model inputs generated from the system. | Simple output, proximate to
    the input data. | Single objective, mapping from input data to output. |'
  prefs: []
  type: TYPE_TB
- en: '| 3: **Autonomous** | Systems that both *alter* human behavior and *learn*
    directly from that behavior. Problems in this category often involve bandit learning
    paradigms such as exploration vs. exploitation. | System is retraining using new
    model input and explicit feedback on the system’s previous outputs. | Policy to
    update model outputs over time. | Cumulative objective(s), capturing how the model
    introduces bias and how people interact with the system. |'
  prefs: []
  type: TYPE_TB
- en: '| 4: **Intelligent** | Systems that dynamically interact with an environment
    and optimizes itself towards downstream objectives, e.g. facilitating an agent
    while optimizing for AHT and CST. Problems in this category sometimes involve
    reinforcement learning paradigms. | System looks at downstream impact of model
    decisions and optimizes for entire system performance. | Policy to optimize the
    entire system. | System objectives, downstream from local decisions. |'
  prefs: []
  type: TYPE_TB
- en: '**[Michael Griffiths](https://www.linkedin.com/in/msjgriffiths/)** is the director
    of data scientist at ASAPP. He works to identify opportunities to improve the
    customer and agent experience. Prior to ASAPP, Michael spent time in advertising,
    ecommerce, and management consulting.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Baidu Research Unveils Top 10 Tech Trends Forecast for 2022](https://www.kdnuggets.com/2022/02/baidu-research-unveils-top-10-tech-trends-forecast-2022.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data access is severely lacking in most companies, and 71% believe…](https://www.kdnuggets.com/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Rare Data Science Skills That Can Help You Get Employed](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Generative AI Can Help You Improve Your Data Visualization Charts](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
