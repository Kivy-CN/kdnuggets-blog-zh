# 机器学习部署的软件接口

> 原文：[https://www.kdnuggets.com/2020/03/software-interfaces-machine-learning-deployment.html](https://www.kdnuggets.com/2020/03/software-interfaces-machine-learning-deployment.html)

[评论](#comments)

**由[Luigi Patruno](https://mlinproduction.com/about/)、数据科学家和 ML in Production 创始人**。

![](../Images/741c813aec2c11d4c0beb00d70c39134.png)

在我们[之前的文章](https://www.kdnuggets.com/2020/02/deploy-machine-learning-model.html)中，我们介绍了什么是机器学习模型的部署。我们了解到，为了使训练好的模型的预测结果对用户和其他软件系统可用，我们需要考虑多个因素，包括预测生成的频率以及是否应在单个数据样本或一批样本上生成预测。在本文中，我们将开始探讨**如何实现**部署过程。

尽管许多博客文章直接跳到实现 Flask APIs 或使用工作流调度程序，但我们将从更基础的层面开始。我们将首先讨论*软件接口*，可以将其视为软件之间的边界。一个类比是，一块软件是一个拼图块，而整个软件系统就是完成的拼图。设计得当时，接口可以连接许多不同的软件组件，从而形成大型复杂的项目。

> 在机器学习部署方面，精心构造的接口有助于实现可重复的、自动化的、即插即用的部署。一个好的接口可以让你轻松推出模型更新，版本控制你部署的模型，等等。

让我们开始吧！

### 什么是接口？

想象一个经理给员工分配创建报告的任务。一个好的经理可能会说：“我需要你制作一个包含以下图表和数据的报告。为了生成这个报告，请使用客户交易数据。”经理明确了期望的结果（报告）并暗示了一种方法（使用客户交易数据）。

相比之下，一个糟糕的经理可能会做以下任何一项：

+   **没有指定输入**——要求报告但没有指定使用哪个数据或提示员工应该与谁沟通以发现适当的数据集。

+   **没有明确交付物**——给员工一堆数据，但不告诉员工应该生成什么。

+   **微观管理**——告诉员工使用什么工具来生成报告，按照什么步骤操作，并承诺任何偏离计划的行为都将受到迅速而严格的惩罚。

[软件接口](https://blog.robertelder.org/interfaces-most-important-software-engineering-concept/)就像经理一样。一个好的接口明确说明了必要的输入和它产生的输出。例如，实现为函数的接口将列出所有必需的参数以及函数返回的内容。接口可以被视为不同软件部分之间的"边界"，定义了不同的软件如何相互通信。当接口构建良好时，即使是由不同团队或公司开发的软件，也能进行沟通并协同工作。

软件工程师被教导要关注他们开发的接口，而不是函数的实现方式。实现很重要，但总是可以更新。然而，一旦接口发布后，更新接口要困难得多，尤其是当你的接口面向外部时。因此，花时间定义接口是值得的。

### 机器学习模型的基本接口

软件工程师如何思考机器学习模型实际做了什么？抽象地说，模型接受数据，对数据进行某种操作，然后返回结果。就是这么简单。模型如何对数据进行操作可能非常复杂，比如卷积神经网络的前向传递对图像数据的张量应用卷积，但这些都是实现细节。

机器学习模型的边界由模型的输入，即特征，以及模型预测的输出组成。因此，构建良好的接口必须考虑输入特征和预测输出。为了说明这一点，让我们用一个简单的函数定义这个接口：

```py
def predict(model, input_features):
    '''
    Function that accepts a model and input data and returns a prediction.

    Args:
    ---
    model: a machine learning model.
    input_features: Features required by the model to generate a 
    prediction. Numpy array of shape (1, n) where n is the dimension
    of the feature vector.

    Returns:
    --------
    prediction: Prediction of the model. Numpy array of shape (1,).
    ''' 

```

这个函数以*model*和一组*input_features*作为输入，并返回一个预测。注意我们还没有*实现*这个函数，即我们没有编写*如何*将模型和特征结合起来生成预测。我们只是创建了一个合同或承诺——我们保证如果调用者提供了一个*model*和*input_features*，函数将返回一个预测。

### 机器学习模型的多个接口

我们定义的*predict()*方法接受一个特征向量并返回一个预测。我们怎么知道这一点？文档指出*input_features*是一个形状为*(1, n)*的numpy数组，其中*n*是特征向量的维度。如果你的模型期望一次预测一个实例，这很好，但如果模型还需要对样本批次进行预测，这就不太好了。你可以通过编写for循环来解决这个问题，但循环效率可能不会很高。相反，我们应该定义另一个方法，直接处理批量情况。我们称之为*predict_batch*：

```py
def predict_batch(model, batch_input_features):
    '''
    Function that predicts a batch of samples.

    Args:
    ---
    model: a machine learning model.
    batch_input_features: A batch of features required by the model to
    generate predictions. Numpy array of shape (m, n) where m is the
    number of instances and n is the dimension of the feature vector.

    Returns:
    --------
    predictions: Predictions of the model. Numpy array of shape (m,).
    '''

```

这个方法定义了一个契约，即如果提供了模型和一批输入特征，它承诺返回一批预测结果。同样，我们没有实现这个方法——这留给方法的开发者。开发者可以选择使用循环不断调用 *predict*。或者开发者可以做其他事情。这对于部署而言是无关紧要的。*重要* 的是我们有两个接口：一个用于预测单个样本，另一个用于预测一批样本。

### 机器学习面向对象编程 – MLOOP

到目前为止，我们忽略了 *model* 参数，该参数是 *predict* 和 *predict_batch* 方法都需要的。让我解释一下为什么这对机器学习来说是个问题。

目前大多数开发机器学习模型的工程师希望使用最佳工具。如果工程师正在构建经典模型，如逻辑回归或随机森林，工程师可能会选择使用 [scikit-learn](https://scikit-learn.org/stable/)。但对于深度学习，工程师可能会选择使用 [Tensorflow](https://www.tensorflow.org/) 或 [PyTorch](https://pytorch.org/)。即使在经典 ML 中，工程师也可能选择 [xgboost](https://xgboost.readthedocs.io/en/latest/) 实现的梯度提升树。每个库的模型对象有略微不同的 API。我们无法预测未来的 ML 库会实现什么 API。这将使我们的接口实现变得非常混乱。例如，我们不希望我们的实现看起来像这样：

```py
def predict(model, input_features):
    ...
    if isinstance(model, sklearn.base.BaseEstimator)
        ...
    elif isinstance(model, xgboost.core.Booster): 
        ...
    elif isinstance(model, tensorflow.keras.Model): 
        ...
    elif isinstance(model, torch.nn.module):
        ...
    ... 

```

这种实现将很难维护，并且会使调试运行时错误变得困难。此外，想象一下，如果我们希望在使用一个模型时传递额外的参数，但在另一个模型中不传递会发生什么。例如，如果我们希望传递额外的参数，仅在使用 sklearn 模型时进行预测。函数的参数数量将增加，但这些参数对非 sklearn 模型来说将毫无用处。我们如何在文档中描述这一点？这些只是为什么面向对象编程、创建类和对象更受欢迎的几个原因。

我们的接口由两个方法组成：*predict* 和 *predict_batch*。让我们定义一个包含这两个方法的基础类：

```py
class Model:
    def __init__(self, model):
        self.model = model

    def predict(self, input_features):
        '''
        Function that accepts input data and returns a prediction.

        Args:
        ---
        input_features: Features required by the model to generate prediction. Numpy
        array of shape (1, n) where n is the dimension of the feature vector.

        Returns:
        --------
        prediction: Prediction of the model. Numpy array of shape (1,).
        '''
        raise NotImplementedError

    def predict_batch(self, batch_input_features):
        '''
        Function that predicts a batch of samples.

        Args:
        ---
        batch_input_features: A batch of features required by the model to generate
            predictions. Numpy array of shape (m, n) where m is the number of
            instances and n is the dimension of the feature vector.

        Returns:
        --------
        prediction: Predictions of the model. Numpy array of shape (m, 1).
        '''
        raise NotImplementedError

```

这个基础类充当我们数据科学团队的 *模板*。如果数据科学家想使用 scikit-learn 模型，他只需要继承 Model 类并实现必要的方法。如果另一个数据科学家想使用 Tensorflow，没问题，只需创建一个 Tensorflow 子类！为了说明，让我们创建 sklearn 子类：

```py
class SklearnModel(Model):
    def __init__(self, model):
        super().__init__(model) 

    def predict(self, input_features):
        y = self.model.predict(input_features.reshape(1, -1))
        return y

    def predict_batch(self, batch_input_features):
        ys = self.model.predict(batch_input_features)
        return ys

```

由于 sklearn 的预测器期望 2D 输入，我们在 *predict* 方法中重新调整了 input_features 参数。这是面向对象方法的一个关键优点。我们可以定义与我们正在解决的问题类型相关的接口 *AND* 利用 [优秀的第三方机器学习库！](https://github.com/EthicalML/awesome-production-machine-learning)

而且好处还不止于此。我们可以添加额外的方法来简化我们的ML工作流程。例如，一旦模型被训练完成，我们通常需要一种序列化模型的方法，然后在推理时对其进行反序列化。因此，我们可以在接口中添加两个方法，`serialize()`和`deserialize()`。我们甚至可以在基类`Model`中提供这些方法的默认实现，并在子类中创建特定于库的实现。

其他有用的接口方法示例包括将序列化的模型从本地文件系统移动到某些模型存储或远程文件系统如S3。你可以添加的方法没有限制。

> 预先创建良好的接口将为你的机器学习团队节省大量时间，使得在处理额外项目时，部署变得自动化和可重复。

[原文](https://mlinproduction.com/software-interfaces-for-machine-learning-deployment-deployment-series-02/)。经许可转载。

**简介：** [Luigi Patruno](https://twitter.com/MLinProduction) 是一位数据科学家和机器学习顾问。他目前是2U的数据科学总监，领导一个负责构建机器学习模型和基础设施的数据科学团队。作为顾问，Luigi帮助公司通过应用现代数据科学方法来实现战略业务和产品计划的价值。他创办了 [MLinProduction.com](http://mlinproduction.com/) 来收集和分享机器学习操作化的最佳实践，并且他曾教授统计学、数据分析和大数据工程的研究生课程。

**相关：**

+   [部署机器学习模型意味着什么？](https://www.kdnuggets.com/2020/02/deploy-machine-learning-model.html)

+   [生产级机器学习的MLOps](https://www.kdnuggets.com/2019/11/cnvrg-mlops-production-machine-learning.html)

+   [使用Flask部署机器学习模型](https://www.kdnuggets.com/2019/12/excelr-deployment-machine-learning-flask.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的IT

* * *

### 更多相关内容

+   [机器学习算法的全面端到端部署](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)

+   [从数据收集到模型部署：数据科学项目的6个阶段](https://www.kdnuggets.com/2023/01/data-collection-model-deployment-6-stages-data-science-project.html)

+   [回到基础 第四周：高级主题与部署](https://www.kdnuggets.com/back-to-basics-week-4-advanced-topics-and-deployment)

+   [前 7 名模型部署和服务工具](https://www.kdnuggets.com/top-7-model-deployment-and-serving-tools)

+   [软件开发人员与软件工程师](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)

+   [软件错误与权衡：Tomasz Lelek 和他的最新书籍](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)
