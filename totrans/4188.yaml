- en: Getting Started with PyTorch Lightning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch Lightning 入门
- en: 原文：[https://www.kdnuggets.com/2021/10/getting-started-pytorch-lightning.html](https://www.kdnuggets.com/2021/10/getting-started-pytorch-lightning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/getting-started-pytorch-lightning.html](https://www.kdnuggets.com/2021/10/getting-started-pytorch-lightning.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![Getting Started with PyTorch Lightning](../Images/d90c82e8ba6cac010727d13ce27b16a8.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![PyTorch Lightning 入门](../Images/d90c82e8ba6cac010727d13ce27b16a8.png)'
- en: '**Getting Started with PyTorch Lightning: a High-Level Library for High Performance
    Research**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**PyTorch Lightning 入门：高性能研究的高级库**'
- en: Libraries like TensorFlow and PyTorch take care of most of the intricacies of
    building deep learning models that train and infer fast. Predictably, this leaves
    machine learning engineers spending most of their time on the next level up in
    abstraction, running hyperparameter search, validating performance, and versioning
    models and experiments to keep track of everything.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 像 TensorFlow 和 PyTorch 这样的库处理了大多数构建深度学习模型时的复杂性，这些模型既能快速训练又能快速推断。可以预测的是，这使得机器学习工程师大部分时间都花在了抽象的下一层级上，进行超参数搜索、验证性能，以及对模型和实验进行版本管理，以跟踪所有内容。
- en: There’s a lot more to deep learning than just gluing some layers together.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习远不止将一些层拼接在一起。
- en: If PyTorch and TensorFlow (and now JAX) are the deep learning cake, higher-level
    libraries are the icing. For years now TensorFlow has had its “icing on the cake”
    in the high-level Keras API, which became an official part of TensorFlow itself
    with the release of TF 2.0 in 2019\. Similarly, PyTorch users have benefited from
    the high-level fastai library, which is exceptionally well-suited for efficiency
    and transfer learning. This makes fastai a favorite of successful data scientists
    on the Kaggle contest platform. More recently, another streamlined wrapper for
    PyTorch has been quickly gaining steam in the aptly named [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果说 PyTorch 和 TensorFlow（现在还有 JAX）是深度学习的蛋糕，那么更高层次的库就是糖霜。多年来，TensorFlow 在高层次的
    Keras API 上有了它的“糖霜”，该 API 自 2019 年 TF 2.0 发布后成为 TensorFlow 的官方部分。同样，PyTorch 用户受益于高层次的
    fastai 库，该库在效率和迁移学习方面表现非常出色。这使得 fastai 成为 Kaggle 竞赛平台上成功数据科学家的最爱。最近，另一个简化的 PyTorch
    封装库在恰如其名的 [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)
    中迅速获得关注。
- en: PyTorch Lighting has actually been around, at least in some capacity, since
    2019\. It started as a sort of side project undertaken by William Falcon during
    his PhD research at New York University. By the time 2020 rolled around (and we
    mean the 2020 that started in March) PyTorch Lightning was no longer just a personal
    project as Falcon[ announced venture funding](https://medium.com/pytorch/pytorch-lightning-0-7-1-release-and-venture-funding-dd12b2e75fb3).
    Around the same time the open source (under the Apache 2.0 License) repository
    moved from Falcon’s personal GitHub profile to its own dedicated profile. As of
    this writing PyTorch Lightning has grown to over 15,000 stars and nearly 2,000
    forks, becoming nearly as popular as[ fastai](https://github.com/fastai/fastai) (which
    has over 21,000 stars) and handily more popular than the in-house high-level library
    from PyTorch,[ Ignite](https://github.com/pytorch/ignite), which has about 4,000
    stars!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning 实际上从 2019 年起就存在，至少在某种程度上。它起初是 William Falcon 在纽约大学攻读博士期间进行的一个副项目。到
    2020 年（我们指的是从 3 月开始的 2020 年），PyTorch Lightning 不再只是个人项目，因为 Falcon [宣布了风险投资](https://medium.com/pytorch/pytorch-lightning-0-7-1-release-and-venture-funding-dd12b2e75fb3)。与此同时，开源（在
    Apache 2.0 许可证下）代码库从 Falcon 的个人 GitHub 账户迁移到了其专用的个人资料。截止目前，PyTorch Lightning 已增长到超过
    15,000 个星标和近 2,000 个分叉，几乎与 [fastai](https://github.com/fastai/fastai)（有超过 21,000
    个星标）一样受欢迎，并且明显比 PyTorch 内部的高层次库 [Ignite](https://github.com/pytorch/ignite)（约有
    4,000 个星标）更受欢迎！
- en: Where fastai was designed to facilitate the inaugural fastai course,[ Practical
    Deep Learning for Coders](https://course.fast.ai/), PyTorch Lightning is intended
    to streamline production research. Fastai has a focus on transfer learning and
    efficiency and its ease of use has made it a popular high-level library on the
    Kaggle data science competition platform, with over[ 4,500 notebooks](https://www.kaggle.com/search?q=fastai) referencing
    the library. Compare that to just[ over 100](https://www.kaggle.com/search?q=ignite) notebook
    results referring to PyTorch Ignite, and[ about 500](https://www.kaggle.com/search?q=PyTorch+Lightning) for
    PyTorch Lightning. PyTorch Lightning is a relatively newer library, but it also
    targets a different demographic. PyTorch Lightning streamlines the engineering
    aspects of developing a new model, such as logging, validation and hooks, and
    it’s targeted toward machine learning researchers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 旨在促进首个 fastai 课程，[ 实用深度学习编程课程](https://course.fast.ai/)，而 PyTorch Lightning
    的目的是简化生产研究。Fastai 专注于迁移学习和效率，其易用性使其成为 Kaggle 数据科学竞赛平台上受欢迎的高级库，有超过[ 4,500 个笔记本](https://www.kaggle.com/search?q=fastai)
    参考该库。相比之下，关于 PyTorch Ignite 的只有[ 100 多个](https://www.kaggle.com/search?q=ignite)
    笔记本，而 PyTorch Lightning 有[ 约 500 个](https://www.kaggle.com/search?q=PyTorch+Lightning)。PyTorch
    Lightning 是一个相对较新的库，但它也针对不同的用户群体。PyTorch Lightning 简化了开发新模型的工程方面，如日志记录、验证和钩子，目标是机器学习研究人员。
- en: Research is all about answering falsifying questions, and in this tutorial we’ll
    take a look at what PyTorch Lightning can do for us to make that process easier.
    We’ll set up a simple mock research question of whether there is any advantage
    to using a “fancy” activation function (such as the so-called[ swish function](https://en.wikipedia.org/wiki/Swish_function))
    versus a more standard rectified linear unit ([ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)).
    We’ll use the vanishingly small (in terms of both number of samples and image
    size) digits dataset from SciKit-Learn to set up our experiment. Starting with
    digits should make this an accessible project for someone running the code on
    an efficient laptop, but readers are encouraged to swap in a more realistic images
    dataset like CIFAR10 for extra credit.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 研究就是回答和验证问题，在本教程中，我们将看看 PyTorch Lightning 如何帮助我们简化这个过程。我们将设置一个简单的模拟研究问题，是否使用“高级”激活函数（如所谓的[ swish
    函数](https://en.wikipedia.org/wiki/Swish_function)）相较于更标准的修正线性单元（[ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))）具有任何优势。我们将使用来自
    SciKit-Learn 的极其小的数字数据集来设置实验。从数字开始应该使这个项目对在高效笔记本上运行代码的人更易于访问，但鼓励读者使用更真实的图像数据集，如
    CIFAR10，以获取额外积分。
- en: As a library designed for production research, PyTorch Lightning streamlines
    hardware support and distributed training as well, and we’ll show how easy it
    is to move training to a GPU toward the end.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个专为生产研究设计的库，PyTorch Lightning 也简化了硬件支持和分布式训练，我们将在最后展示如何轻松将训练转移到 GPU。
- en: '****Getting Started: Installing PyTorch Lightning****'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****开始使用：安装 PyTorch Lightning****'
- en: 'Like many Python projects these days, PyTorch Lightning installs easily using
    pip, and we recommend using your favorite virtual environment manager to manage
    installs and dependencies without cluttering up your base Python installation.
    We’ll provide three examples, the first of which is using `virtualenv` and pip,
    and we are assuming you are using a Unix-style command line on Linux or Mac, or
    that you are savvy enough to adapt the examples for Windows using something like
    Git Bash or Anaconda Prompt. After navigating to the project folder for this tutorial:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在许多 Python 项目都可以轻松通过 pip 安装 PyTorch Lightning，我们建议使用你喜欢的虚拟环境管理器来管理安装和依赖项，以免混乱你的基本
    Python 安装。我们将提供三个示例，第一个是使用 `virtualenv` 和 pip，我们假设你使用的是 Linux 或 Mac 的 Unix 风格命令行，或者你足够聪明，可以使用类似
    Git Bash 或 Anaconda Prompt 的工具适配 Windows。导航到本教程的项目文件夹后：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can also use[ Anaconda](https://www.anaconda.com/) to manage your virtual
    environment:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用[ Anaconda](https://www.anaconda.com/)来管理你的虚拟环境：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Or even combine the two, creating a new anaconda environment and then using
    pipt o install packages. For more general usage there are some[ caveats](https://www.anaconda.com/blog/using-pip-in-a-conda-environment) to
    using pip and Anaconda together, but for purposes of this tutorial it should be
    fine:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 或者结合这两者，创建一个新的 Anaconda 环境，然后使用 pip 安装软件包。对于更一般的使用，使用 pip 和 Anaconda 一起有一些[ 警告](https://www.anaconda.com/blog/using-pip-in-a-conda-environment)，但对于本教程来说应该没问题：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Using PyTorch Lightning
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PyTorch Lightning
- en: The design strategy employed by PyTorch Lightning revolves around the LightningModule
    class. This class, itself inheriting from the `pytorch.nn.Module` class, provides
    a convenient entry point and attempts to organize as much of the training and
    validation process as possible all in one place.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning采用的设计策略围绕着LightningModule类。这个类继承自`pytorch.nn.Module`类，提供了一个方便的入口点，并尝试尽可能将训练和验证过程的许多内容组织在一个地方。
- en: A key feature of this strategy is that the contents of a typical training and
    validation loop is instead defined in the model itself, accessible via a `fit` API
    very similar to keras, fastai, or even SciKit-Learn. Unlike those other examples
    where `fit` is accessed through the model itself, in PyTorch Lightning `fit` is
    accessed via a Trainer object. But that’s getting ahead of ourselves, first let’s
    set the stage for our experiment by importing everything we’ll need.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略的一个关键特性是，典型的训练和验证循环的内容被定义在模型本身中，可以通过一个类似于keras、fastai甚至SciKit-Learn的`fit`
    API访问。与其他示例中`fit`是通过模型本身访问不同，在PyTorch Lightning中，`fit`是通过Trainer对象访问的。但我们还是提前了，首先让我们通过导入我们需要的一切来为我们的实验做准备。
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then we can go ahead and define our model:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以继续定义我们的模型：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notably, training functionality is devolved to the module itself in the `training_step` function.
    Most ML practitioners having some practice with PyTorch will already be quite
    familiar with the practice of overloading the `forward` function, and LightningModule
    objects have many more methods to overload for fine-grained control of the relatively
    painless logging and evaluation features that are built-in.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，训练功能被委托给`training_step`函数中的模块本身。大多数有一定PyTorch实践经验的机器学习从业者会对重载`forward`函数的做法非常熟悉，而LightningModule对象还有许多更多的方法可以重载，以实现对内置的相对无痛的日志记录和评估功能的精细控制。
- en: The code that defines our `MyClassifier` model class might seem pretty verbose,
    but this strategy massively simplifies things when it’s time to actually start
    training, which we’ll see later. There are plenty of other callbacks and functions
    that are included in the `LightningModule` class, and all of them can be overloaded
    for more fine-tuned control. A full list of these callbacks can be found[ in the
    PyTorch Lightning documentation.](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#hooks)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 定义我们的`MyClassifier`模型类的代码可能看起来相当冗长，但这种策略在实际开始训练时大大简化了流程，我们稍后将看到。`LightningModule`类中包含了许多其他的回调和函数，所有这些都可以被重载以实现更精细的控制。这些回调的完整列表可以在[PyTorch
    Lightning文档](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#hooks)中找到。
- en: For this tutorial, we’ll also define a `torch.utils.data.Dataset` object to
    wrap the digits dataset from SciKit-Learn. This should make it easy to rapidly
    get everything working before switching to a larger and more informative dataset
    like MNIST or CIFAR10.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们还将定义一个`torch.utils.data.Dataset`对象来包装来自SciKit-Learn的数字数据集。这应该使得在切换到像MNIST或CIFAR10这样更大、更具信息量的数据集之前，能够快速地让一切正常运行。
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'With all that out of the way, actually launching a training run becomes incredibly
    simple. All we have to do is create a dataset and feed it into a `DataLoader`,
    instantiate our model, create a PyTorch Lightning `Trainer` object, and call the
    trainer’s fit method. Here’s a simplified version:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 既然所有的准备工作都完成了，实际启动训练运行变得非常简单。我们只需要创建一个数据集，并将其输入到`DataLoader`中，实例化我们的模型，创建一个PyTorch
    Lightning `Trainer`对象，然后调用trainer的fit方法。以下是一个简化版本：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: But of course we will want to continuously log validation metrics throughout
    the training process, making use of the `validation_step` and `validation_epoch_end` methods
    we overloaded in our model. Here’s the actual code I use to launch a training
    run, using the `if __name__ == "__main__":` pattern that provides a simple entry
    point for running a Python file as a module.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但当然，我们会希望在整个训练过程中持续记录验证指标，利用我们在模型中重载的`validation_step`和`validation_epoch_end`方法。以下是我用来启动训练运行的实际代码，使用`if
    __name__ == "__main__":`模式，这为将Python文件作为模块运行提供了一个简单的入口点。
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: When you run the code above, you should see a progress bar displayed in your
    terminal that looks something like the one below.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行上面的代码时，你应该会在终端中看到一个进度条，看起来像下面的那个。
- en: '![pl-terminal-1.png](../Images/28210cdaae631256933e335d905b6fb6.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![pl-terminal-1.png](../Images/28210cdaae631256933e335d905b6fb6.png)'
- en: After allowing training to run for a while, have a look in your working directory
    and you’ll notice a new folder called **lightning_logs**. This is where PyTorch
    Lightning records your training sessions, and you can quickly boot up a Tensorboard
    session to see how things are going. After launching tensorboard with the line
    below, use a browser to navigate to localhost:6006 (by default) to open up the
    dashboard.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在允许训练运行一段时间后，查看你的工作目录，你会发现一个名为**lightning_logs**的新文件夹。这是 PyTorch Lightning 记录你的训练会话的地方，你可以快速启动
    Tensorboard 会话以查看情况。在用下面的命令启动 tensorboard 后，使用浏览器导航到 localhost:6006（默认）以打开仪表板。
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If it took you a few starts and stops to get training to take off, you’ll notice
    a list of training runs displayed in the left sidebar with version_0, version_1,
    version_2 and so on. PyTorch Lightning automatically versions your training runs
    this way, so it should be pretty easy to compare a few different experimental
    conditions or random seeds..
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果训练过程经历了几次停顿和重启，你会注意到左侧边栏显示了训练运行列表，包括 version_0、version_1、version_2 等等。PyTorch
    Lightning 以这种方式自动版本化你的训练运行，因此比较不同的实验条件或随机种子应该很简单。
- en: For example, if we wanted to run our little experiment comparing the efficacy
    of using Swish versus ReLU activations, we can use the code below.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想运行一个小实验，比较使用 Swish 和 ReLU 激活函数的效果，我们可以使用下面的代码。
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And after running our little experiment we’ll find our results nicely logged
    for our perusal in Tensorboard.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行我们的小实验后，我们会发现结果在 Tensorboard 中被很好地记录，供我们查看。
- en: '![pl-tensorboard-1.png](../Images/60cae6ec1ddb4e9612d2f76104311e20.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![pl-tensorboard-1.png](../Images/60cae6ec1ddb4e9612d2f76104311e20.png)'
- en: You’ll probably notice we have the option to run training on the much larger
    MNIST dataset. At 60,000 training samples of 28 by 28 pixel images, it’s closer
    to a useful real-world dataset than the miniaturized sklearn digits dataset, which
    provides fewer than 2,000 samples of 8 by 8 images. However, you probably won’t
    want to run 6 replicate training runs on the MNIST dataset using an underpowered
    laptop CPU, so we’ll want to move everything over to a GPU first.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到我们有选项在更大的 MNIST 数据集上运行训练。MNIST 数据集有 60,000 个 28x28 像素的训练样本，比提供不到 2,000
    个 8x8 图像的缩小版 sklearn digits 数据集更接近一个实际的真实世界数据集。然而，你可能不希望在使用性能不足的笔记本 CPU 上运行 6
    次重复训练，因此我们需要首先将所有内容转移到 GPU 上。
- en: If you are already used to building experiments and training pipelines in standard
    PyTorch from scratch, you probably know the frustration of a forgotten tensor
    languishing on a CPU device, and the show-stopping errors they generate. It’s
    usually an easy fix, but frustrating nonetheless.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经习惯了从头构建标准 PyTorch 实验和训练管道，你可能知道一个被遗忘的张量在 CPU 设备上滞留带来的沮丧，以及它们生成的令人头疼的错误。通常这是一个简单的修复，但仍然令人沮丧。
- en: '**Using a GPU for Training**'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**使用 GPU 进行训练**'
- en: 'If you’re working with a machine with an available GPU, you can easily use
    it to train. To launch training on the GPU instead of the CPU, we’ll have to modify
    some of the code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用具有可用 GPU 的机器，你可以轻松地利用 GPU 进行训练。为了在 GPU 上启动训练而不是 CPU，我们需要修改一些代码：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: That’s right, by modifying a single line of code defining the trainer object
    we can run training on the GPU. No worrying about forsaken tensors and with all
    the convenience of logging and validation we built into our original model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 没错，通过修改定义 trainer 对象的单行代码，我们可以在 GPU 上运行训练。无需担心被遗忘的张量，且保留了我们在原始模型中构建的所有日志记录和验证的便利性。
- en: '![pl-tensorboard-2.png](../Images/040ed16ce6762f52159139f7c5ae3211.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![pl-tensorboard-2.png](../Images/040ed16ce6762f52159139f7c5ae3211.png)'
- en: '****Next Steps****'
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****下一步****'
- en: A striking aspect of working with PyTorch Lightning is that it seems to get
    easier the further along you go. Defining our `MyClassifer` model was a little
    more complicated than a model of similar complexity sub-classed from `torch.nn.Module` up
    front, but once we had training, validation, and logging all taken care of by
    the `LightningModule` model, every subsequent step was easier than it would have
    been normally.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch Lightning 的一个显著特点是它似乎随着进展变得越来越容易。定义我们的`MyClassifer`模型比从`torch.nn.Module`子类化的类似复杂度模型要复杂一点，但一旦我们通过`LightningModule`模型处理了训练、验证和日志记录，之后的每一步都比通常情况更简单。
- en: PyTorch Lightning also makes managing hardware a breeze, and we caught a glimpse
    of just how simple this is when we switched to training MNIST on a GPU. PyTorch
    Lightning also readily facilitates training on more esoteric hardware like Google’s
    Tensor Processing Units, and on multiple GPUs, and it is being developed in parallel
    alongside [Grid](https://www.grid.ai/), a cloud platform for scaling up experiments
    using PyTorch Lightning, and [Lightning Bolts](https://www.pytorchlightning.ai/bolts) a
    modular toolbox of deep learning examples driven by the PyTorch Lightning community.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning 也让硬件管理变得轻松，我们在切换到 GPU 训练 MNIST 时见证了这一点。PyTorch Lightning 也方便在如
    Google 的 Tensor Processing Units 和多个 GPU 上进行训练，它与 [Grid](https://www.grid.ai/)
    平台并行开发，用于通过 PyTorch Lightning 扩展实验，以及 [Lightning Bolts](https://www.pytorchlightning.ai/bolts)
    模块化的深度学习示例工具箱，由 PyTorch Lightning 社区驱动。
- en: That covers our “Hello, World” introduction to PyTorch Lightning, but we’ve
    barely scratched the surface of what Lightning intends to deliver to your deep
    learning workflow.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这涵盖了我们对 PyTorch Lightning 的“Hello, World”介绍，但我们只是浅尝辄止，Lightning 旨在为你的深度学习工作流提供更全面的功能。
- en: '**In our next PyTorch Lightning tutorial, we’ll dive into two complementary
    PyTorch Lightning libraries: Lightning Flash and TorchMetrics.** TorchMetrics
    unsurprisingly provides a modular approach to define and track useful metrics
    across batches and devices, while Lightning Flash offers a suite of functionality
    facilitating more efficient transfer learning and data handling, and a recipe
    book of state-of-the-art approaches to typical deep learning problems.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**在我们下一个 PyTorch Lightning 教程中，我们将深入探讨两个互补的 PyTorch Lightning 库：Lightning Flash
    和 TorchMetrics。** TorchMetrics 提供了模块化的方法来定义和跟踪批次和设备上的有用指标，而 Lightning Flash 提供了一整套功能，便于更高效的迁移学习和数据处理，以及一系列最新的深度学习问题解决方案。'
- en: '**Now, on to our next PyTorch Lightning tutorial:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**接下来，我们进入下一个 PyTorch Lightning 教程：**'
- en: '[PyTorch Lightning Tutorial #2: Using TorchMetrics and Lightning Flash](https://www.exxactcorp.com/blog/Deep-Learning/advanced-pytorch-lightning-using-torchmetrics-and-lightning-flash)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning 教程 #2：使用 TorchMetrics 和 Lightning Flash](https://www.exxactcorp.com/blog/Deep-Learning/advanced-pytorch-lightning-using-torchmetrics-and-lightning-flash)'
- en: '**Bio: [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact
    Corp blog and works with many of its talented authors who write about different
    aspects of Deep Learning.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** 负责管理 Exxact Corp
    博客，并与许多才华横溢的作者合作，他们撰写有关深度学习不同方面的内容。'
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/getting-started-with-pytorch-lightning).
    Reposted with permission.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.exxactcorp.com/blog/Deep-Learning/getting-started-with-pytorch-lightning).
    经许可转载。'
- en: '**Related:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Introduction to PyTorch Lightning](/2021/10/introduction-pytorch-lightning.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning 介绍](/2021/10/introduction-pytorch-lightning.html)'
- en: '[How to deploy PyTorch Lightning models to production](/2020/11/deploy-pytorch-lightning-models-production.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何将 PyTorch Lightning 模型部署到生产环境](/2020/11/deploy-pytorch-lightning-models-production.html)'
- en: '[PyTorch Multi-GPU Metrics Library and More in New PyTorch Lightning Release](/2020/07/pytorch-multi-gpu-metrics-library-pytorch-lightning.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 多 GPU 评估库及其他新 PyTorch Lightning 发布内容](/2020/07/pytorch-multi-gpu-metrics-library-pytorch-lightning.html)'
- en: '* * *'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning 入门](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库简介：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[Getting Started with PyTorch in 5 Steps](https://www.kdnuggets.com/5-steps-getting-started-pytorch)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 步骤开始使用 PyTorch](https://www.kdnuggets.com/5-steps-getting-started-pytorch)'
- en: '[Using Lightning AI Studio For Free](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费使用 Lightning AI Studio](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
- en: '[Getting Started with SQL Cheatsheet](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL 入门备忘单](https://www.kdnuggets.com/2022/08/getting-started-sql-cheatsheet.html)'
- en: '[Getting Started with PyCaret](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyCaret 入门指南](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)'
