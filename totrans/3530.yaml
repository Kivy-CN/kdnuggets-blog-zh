- en: 'Machine Learning Wars: Amazon vs Google vs BigML vs PredicSis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2015/05/machine-learning-wars-amazon-google-bigml-predicsis.html](https://www.kdnuggets.com/2015/05/machine-learning-wars-amazon-google-bigml-predicsis.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2015/05/machine-learning-wars-amazon-google-bigml-predicsis.html/2#comments)**By
    [Louis Dorard](http://www.louisdorard.com/#home)**'
  prefs: []
  type: TYPE_NORMAL
- en: '***UPDATE** - NEW BIGML RESULTS: As pointed out by Francisco Martin, if you
    just change the objective field (SeriousDlqin2yrs) to be numeric instead of categorical,
    BigML''s accuracy for a [single model](https://bigml.com/shared/model/joejTuzK2F33nUZBI9WxF7o8vtZ)
    goes to 0.853 (whereas it was initially reported as 0.790 - the accuracy in the
    table above and the Kaggle rank below have been updated to reflect that).*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Amazon ML](http://aws.amazon.com/machine-learning/) (Machine Learning) made
    a lot of noise [when it came out](http://www.infoq.com/news/2015/04/aws-launches-machine-learning)
    last month. Shortly afterwards, someone posted a link to [Google Prediction API](https://cloud.google.com/prediction/)
    on HackerNews and it quickly became one of the most popular posts. Google’s product
    is quite similar to Amazon’s but it’s actually much older since it was introduced
    in 2011\. Anyway, this gave me the idea of comparing the performance of Amazon’s
    new ML API with that of Google. For that, I used the [Kaggle “give me some credit”
    challenge](https://www.kaggle.com/c/GiveMeSomeCredit). But I didn’t stop there:
    I also included startups who provide competing APIs in this comparison — namely,
    [PredicSis](http://launch.predicsis.com/) and [BigML](https://bigml.com/). In
    this wave of new ML services, the giant tech companies are getting all the headlines,
    but bigger companies do not necessarily have better products.'
  prefs: []
  type: TYPE_NORMAL
- en: '![machine-learning-amazon-bigml-google-predicsis](../Images/b07d1daf97a82862594d92fdcaa3cd0a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is a tweet-size summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amazon Machine Learning most accurate'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: BigML fastest
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PredicSis best trade-off
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Google (Prediction API) last**
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Methodology**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Loan](../Images/b015d07921ea0d4067c84f58867004ae.png) The ML problem in the
    Kaggle credit challenge is a binary classification one: you’re given a dataset
    of input-output pairs where each input corresponds to an individual who has applied
    for a credit and the output says whether he later defaulted or not. The idea is
    to use ML to predict whether a new individual applying for a credit will default.'
  prefs: []
  type: TYPE_NORMAL
- en: 'ML has two phases: train and predict. The “train” phase consists in using a
    set of input-output examples to create a model that maps inputs to outputs. The
    “predict” phase consists in using the model on new inputs to get predictions of
    the associated outputs. Amazon ML, Google Prediction API, PredicSis and BigML
    all have similar API methods for each phase:'
  prefs: []
  type: TYPE_NORMAL
- en: One method that takes in a dataset (in csv format for instance), and that returns
    the id of a model trained on this dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One method that takes a model id and an input, and that returns a prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Data = data-lazy-src=](../Images/e8a57f4972516a1d3218894eabc89576.png)'
  prefs: []
  type: TYPE_IMG
