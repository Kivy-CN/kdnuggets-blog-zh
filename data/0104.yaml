- en: 'This Week in AI, August 18: OpenAI in Financial Trouble • Stability AI Announces
    StableCode'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本周人工智能动态，8月18日：OpenAI财务困境 • Stability AI宣布StableCode
- en: 原文：[https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html](https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html](https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html)
- en: '![### ALT ###](../Images/ed6e88542b41e9889a22780056e09561.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![### ALT ###](../Images/ed6e88542b41e9889a22780056e09561.png)'
- en: Image created by Editor with Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑使用Midjourney创建
- en: Welcome to this week's edition of "This Week in AI" on KDnuggets. This curated
    weekly post aims to keep you abreast of the most compelling developments in the
    rapidly advancing world of artificial intelligence. From groundbreaking headlines
    that shape our understanding of AI's role in society to thought-provoking articles,
    insightful learning resources, and spotlighted research pushing the boundaries
    of our knowledge, this post provides a comprehensive overview of AI's current
    landscape. This weekly update is designed to keep you updated and informed in
    this ever-evolving field. Stay tuned and happy reading!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本周的“本周人工智能动态”版块，这里是KDnuggets的每周精选帖子，旨在让你了解人工智能快速发展的世界中的最引人注目的进展。从塑造我们对AI在社会中角色理解的突破性头条到引发思考的文章、富有洞察力的学习资源和推动我们知识边界的研究，这篇帖子提供了AI当前格局的全面概述。本周更新旨在让你在这一不断发展的领域中保持更新和知情。敬请关注，阅读愉快！
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Headlines
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 头条新闻
- en: The "Headlines" section discusses the top news and developments from the past
    week in the field of artificial intelligence. The information ranges from governmental
    AI policies to technological advancements and corporate innovations in AI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: “头条新闻”部分讨论了过去一周在人工智能领域的顶级新闻和发展信息。信息涵盖了政府AI政策、技术进步和企业AI创新。
- en: '???? **[ChatGPT In Trouble: OpenAI may go bankrupt by 2024, AI bot costs company
    $700,000 every day](https://www.firstpost.com/tech/news-analysis/openai-may-go-bankrupt-by-2024-chatgpt-costs-company-700000-dollars-every-day-12986012.html)**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[ChatGPT陷入困境：OpenAI可能在2024年破产，AI机器人每天给公司带来70万美元成本](https://www.firstpost.com/tech/news-analysis/openai-may-go-bankrupt-by-2024-chatgpt-costs-company-700000-dollars-every-day-12986012.html)**
- en: OpenAI is facing financial trouble due to the high costs of running ChatGPT
    and other AI services. Despite rapid early growth, ChatGPT's user base has declined
    in recent months. OpenAI is struggling to effectively monetize its technology
    and generate sustainable revenue. Meanwhile, it continues to burn through cash
    at an alarming rate. With competition heating up and enterprise GPU shortages
    hindering model development, OpenAI needs to urgently find pathways to profitability.
    If it fails to do so, bankruptcy may be on the horizon for the pioneering AI startup.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI因运行ChatGPT和其他AI服务的高成本而面临财务困境。尽管早期增长迅猛，但ChatGPT的用户基础在最近几个月有所下降。OpenAI正努力有效地变现其技术并产生可持续收入。同时，其现金消耗速度惊人。随着竞争加剧和企业GPU短缺阻碍模型开发，OpenAI需要紧急寻找盈利路径。如果未能实现，破产可能在这家开创性AI初创企业的视野之内。
- en: ???? **[Stability AI Announces StableCode, An AI Coding Assistant for Developers](https://www.maginative.com/article/stability-ai-announces-stablecode-an-ai-coding-assistant-for-developers/)**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[Stability AI宣布StableCode，一款为开发者提供的AI编码助手](https://www.maginative.com/article/stability-ai-announces-stablecode-an-ai-coding-assistant-for-developers/)**
- en: Stability AI has released StableCode, its first generative AI product optimized
    for software development. StableCode incorporates multiple models trained on over
    500 billion tokens of code to provide intelligent autocompletion, respond to natural
    language instructions, and manage long spans of code. While conversational AI
    can already write code, StableCode is purpose-built to boost programmer productivity
    by understanding code structure and dependencies. With its specialized training
    and models that can handle long contexts, StableCode aims to enhance developer
    workflows and lower the barrier to entry for aspiring coders. The launch represents
    Stability AI's foray into AI-assisted coding tools amidst growing competition
    in the space.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Stability AI 发布了其首个专为软件开发优化的生成 AI 产品 StableCode。StableCode 集成了多个在超过 5000 亿个代码标记上训练的模型，提供智能自动补全、响应自然语言指令，并管理长跨度的代码。尽管对话式
    AI 已经可以编写代码，StableCode 的设计目的是通过理解代码结构和依赖关系来提高程序员的生产力。凭借其专门的训练和能够处理长上下文的模型，StableCode
    旨在提升开发者工作流程，并降低新手编码者的入门门槛。此次发布标志着 Stability AI 在 AI 辅助编码工具领域的首次尝试，面对日益激烈的竞争。
- en: ???? **[Introducing Superalignment by OpenAI](https://www.kdnuggets.com/2023/08/introducing-superalignment-openai.html)**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**[OpenAI 推出 Superalignment](https://www.kdnuggets.com/2023/08/introducing-superalignment-openai.html)**'
- en: OpenAI is proactively working to address potential risks from superintelligent
    AI through their new Superalignment team, which is using techniques like reinforcement
    learning from human feedback to align AI systems. Key goals are developing scalable
    training methods leveraging other AI systems, validating model robustness, and
    stress testing the full alignment pipeline even with intentionally misaligned
    models. Overall, OpenAI aims to show machine learning can be conducted safely
    by pioneering approaches to responsibly steer superintelligence.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 正在通过其新成立的 Superalignment 团队积极应对超级智能 AI 可能带来的风险，该团队使用诸如从人类反馈中进行强化学习等技术来对齐
    AI 系统。主要目标包括开发可扩展的训练方法，利用其他 AI 系统进行验证模型的鲁棒性，并对即使是故意失调的模型也进行全面的对齐管道压力测试。总体而言，OpenAI
    旨在通过开创负责任地引导超级智能的方法来证明机器学习可以安全进行。
- en: ???? **[Learn as you search (and browse) using generative AI](https://blog.google/products/search/google-search-generative-ai-learning-features/)**
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**[通过生成 AI 学习（和浏览）](https://blog.google/products/search/google-search-generative-ai-learning-features/)**'
- en: Google is announcing several updates to its Search Engine Generation (SGE) AI
    capabilities including hover definitions for science/history topics, color-coded
    syntax highlighting for code overviews, and an early experiment called "SGE while
    browsing" that summarizes key points and helps users explore pages when reading
    long-form content on the web. These aim to enhance understanding of complex topics,
    improve digestion of coding information, and aid navigation and learning as users
    browse. The updates represent Google's continued efforts to evolve its AI search
    experience based on user feedback, with a focus on comprehension and extracting
    key details from complex web content.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Google 宣布对其搜索引擎生成 (SGE) AI 能力进行多项更新，包括为科学/历史主题提供悬停定义、代码概述的彩色语法高亮显示，以及一项名为“浏览时
    SGE”的早期实验，该实验在用户阅读网页上的长篇内容时总结关键点并帮助探索页面。这些更新旨在增强对复杂主题的理解，提高对编码信息的消化能力，并在用户浏览时帮助导航和学习。这些更新代表了
    Google 基于用户反馈不断发展其 AI 搜索体验的努力，重点是理解和提取复杂网页内容中的关键细节。
- en: ???? **[Together.ai extend Llama2 to a 32k context window](https://huggingface.co/togethercomputer/LLaMA-2-7B-32K)**
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Together.ai 将 Llama2 扩展到 32k 上下文窗口](https://huggingface.co/togethercomputer/LLaMA-2-7B-32K)**'
- en: LLaMA-2-7B-32K is an open-source, long context language model developed by Together
    Computer that extends the context length of Meta's LLaMA-2 to 32K tokens. It leverages
    optimizations like FlashAttention-2 to enable more efficient inference and training.
    The model was pre-trained using a mixture of data including books, papers, and
    instructional data. Examples are provided for fine-tuning on long-form QA and
    summarization tasks. Users can access the model via Hugging Face or use the OpenChatKit
    for customized fine-tuning. Like all language models, LLaMA-2-7B-32K can generate
    biased or incorrect content, requiring caution in use.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA-2-7B-32K 是由 Together Computer 开发的开源长上下文语言模型，它将 Meta 的 LLaMA-2 的上下文长度扩展到
    32K 令牌。它利用了像 FlashAttention-2 这样的优化技术，实现了更高效的推理和训练。该模型使用包括书籍、论文和教学数据在内的数据混合进行了预训练。示例提供了对长篇
    QA 和总结任务的微调。用户可以通过 Hugging Face 访问该模型，或使用 OpenChatKit 进行自定义微调。像所有语言模型一样，LLaMA-2-7B-32K
    可能生成有偏见或不正确的内容，因此使用时需要小心。
- en: Articles
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文章
- en: The "Articles" section presents an array of thought-provoking pieces on artificial
    intelligence. Each article dives deep into a specific topic, offering readers
    insights into various aspects of AI, including new techniques, revolutionary approaches,
    and ground-breaking tools.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: “文章”部分展示了一系列引人深思的人工智能相关文章。每篇文章深入探讨了特定主题，为读者提供了对 AI 各个方面的见解，包括新技术、革命性方法和突破性工具。
- en: ???? **[LangChain Cheat Sheet](https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html)**
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[LangChain 速查表](https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html)**
- en: With LangChain, developers can build capable AI language-based apps without
    reinventing the wheel. Its composable structure makes it easy to mix and match
    components like LLMs, prompt templates, external tools, and memory. This accelerates
    prototyping and allows seamless integration of new capabilities over time. Whether
    you're looking to create a chatbot, QA bot, or multi-step reasoning agent, LangChain
    provides the building blocks to assemble advanced AI rapidly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LangChain，开发者可以构建强大的 AI 语言应用程序，而无需重新发明轮子。其可组合的结构使得轻松混合和匹配 LLM、提示模板、外部工具和记忆等组件。这加快了原型设计，并允许随着时间的推移无缝集成新功能。无论你是想创建聊天机器人、QA
    机器人还是多步骤推理代理，LangChain 都提供了快速组装高级 AI 的构建模块。
- en: ???? **[How to Use ChatGPT to Convert Text into a PowerPoint Presentation](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)**
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[如何使用 ChatGPT 将文本转换为 PowerPoint 演示文稿](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)**
- en: The article outlines a two-step process for using ChatGPT to convert text into
    a PowerPoint presentation, first summarizing the text into slide titles and content,
    then generating Python code to convert the summary to PPTX format using the python-pptx
    library. This allows rapid creation of engaging presentations from lengthy text
    documents, overcoming tedious manual efforts. Clear instruction is provided on
    crafting the ChatGPT prompts and running the code, offering an efficient automated
    solution for presentation needs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该文章概述了一个两步流程，用于使用 ChatGPT 将文本转换为 PowerPoint 演示文稿，首先将文本总结成幻灯片标题和内容，然后生成 Python
    代码，将总结转换为 PPTX 格式，使用 python-pptx 库。这允许快速创建引人入胜的演示文稿，从长篇文本中避免繁琐的手动工作。文章提供了有关如何编写
    ChatGPT 提示和运行代码的清晰说明，提供了一种高效的自动化演示解决方案。
- en: ???? **[Open challenges in LLM research](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html)**
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[LLM 研究中的开放挑战](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html)**
- en: 'The article provides an overview of 10 key research directions to improve large
    language models: reducing hallucination, optimizing context length/construction,
    incorporating multimodal data, accelerating models, designing new architectures,
    developing GPU alternatives like photonic chips, building usable agents, improving
    learning from human feedback, enhancing chat interfaces, and expanding to non-English
    languages. It cites relevant papers across these areas, noting challenges like
    representing human preferences for reinforcement learning and building models
    for low-resource languages. The author concludes that while some issues like multilinguality
    are more tractable, others like architecture will require more breakthroughs.
    Overall, both technical and non-technical expertise across researchers, companies
    and the community will be critical to steer LLMs positively.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章概述了改进大型语言模型的10个关键研究方向：减少幻觉、优化上下文长度/构建、融入多模态数据、加速模型、设计新架构、开发像光子芯片这样的GPU替代品、构建可用的代理、改进从人类反馈中学习、增强聊天界面，以及扩展到非英语语言。它引用了这些领域的相关论文，指出了诸如为强化学习表示人类偏好和为低资源语言构建模型等挑战。作者总结说，虽然像多语言能力这样的某些问题更易于解决，但像架构这样的其他问题则需要更多突破。总体而言，研究人员、公司和社区中的技术和非技术专长将对推动LLMs的积极发展至关重要。
- en: ???? **[Why You (Probably) Don’t Need to Fine-tune an LLM](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/)**
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[为什么你（可能）不需要微调LLM](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/)**
- en: 'The article provides an overview of 10 key research directions to improve large
    language models: reducing hallucination, optimizing context length/construction,
    incorporating multimodal data, accelerating models, designing new architectures,
    developing GPU alternatives like photonic chips, building usable agents, improving
    learning from human feedback, enhancing chat interfaces, and expanding to non-English
    languages. It cites relevant papers across these areas, noting challenges like
    representing human preferences for reinforcement learning and building models
    for low-resource languages. The author concludes that while some issues like multilinguality
    are more tractable, others like architecture will require more breakthroughs.
    Overall, both technical and non-technical expertise across researchers, companies
    and the community will be critical to steer LLMs positively.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章概述了改进大型语言模型的10个关键研究方向：减少幻觉、优化上下文长度/构建、融入多模态数据、加速模型、设计新架构、开发像光子芯片这样的GPU替代品、构建可用的代理、改进从人类反馈中学习、增强聊天界面，以及扩展到非英语语言。它引用了这些领域的相关论文，指出了诸如为强化学习表示人类偏好和为低资源语言构建模型等挑战。作者总结说，虽然像多语言能力这样的某些问题更易于解决，但像架构这样的其他问题则需要更多突破。总体而言，研究人员、公司和社区中的技术和非技术专长将对推动LLMs的积极发展至关重要。
- en: ???? **[Best Practices to Use OpenAI GPT Model](https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html)**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[使用OpenAI GPT模型的最佳实践](https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html)**
- en: The article outlines best practices for obtaining high-quality outputs when
    using OpenAI's GPT models, drawing on community experience. It recommends providing
    detailed prompts with specifics like length and persona; multi-step instructions;
    examples to mimic; references and citations; time for critical thinking; and code
    execution for precision. Following these tips on instructing the models, such
    as specifying steps and personas, can lead to more accurate, relevant, and customizable
    results. The guidance aims to help users structure prompts effectively to get
    the most out of OpenAI's powerful generative capabilities.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章概述了使用OpenAI的GPT模型时获得高质量输出的最佳实践，借鉴了社区经验。建议提供详细的提示，包括长度和角色等细节；多步骤的指示；要模仿的示例；参考文献和引文；用于关键思考的时间；以及执行代码以提高精确度。按照这些关于如何指导模型的建议，比如明确步骤和角色，可以得到更准确、相关且可定制的结果。该指导旨在帮助用户有效地构建提示，以充分发挥OpenAI强大的生成能力。
- en: ???? **[We're All Wrong About AI](https://arnoldkling.substack.com/p/were-all-wrong-about-ai)**
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ???? **[我们对人工智能的看法都错了](https://arnoldkling.substack.com/p/were-all-wrong-about-ai)**
- en: The author argues that current AI capabilities are underestimated, using examples
    like creativity, search, and personalization to counter common misconceptions.
    He states that AI can be creative by recombining concepts, not merely generating
    random ideas; it is not just a supercharged search engine like Google; and it
    can develop personalized relationships, not just generic skills. While unsure
    which applications will prove most useful, the author urges an open mind rather
    than dismissiveness, emphasizing that the best way to determine AI's potential
    is by continued hands-on exploration. He concludes that our imagination around
    AI is limited and its uses likely far exceed current predictions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者认为当前的 AI 能力被低估了，使用创造力、搜索和个性化等例子来反驳常见误解。他指出，AI 可以通过重新组合概念展现创造力，而不仅仅是生成随机想法；它不仅是一个超级搜索引擎像
    Google；它可以发展个性化关系，而不仅仅是通用技能。尽管不确定哪些应用最有用，作者呼吁保持开放的心态而非轻视，强调最好的方式是通过持续的实践探索来确定
    AI 的潜力。他总结道，我们对 AI 的想象力有限，它的用途可能远远超出当前预测。
- en: Tools
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工具
- en: The "Tools" section lists useful apps and scripts created by the community for
    those who want to get busy with practical AI applications. Here you will find
    a range of tool types, from large comprehensive code bases to small niche scripts.
    *Note that tools are shared without endorsement, and with no guarantee of any
    sort. Do your own homework on any software prior to installation and use!*
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: “工具”部分列出了社区创建的实用应用程序和脚本，供那些希望忙于实际 AI 应用的用户使用。在这里，你会找到各种类型的工具，从大型综合代码库到小型利基脚本。*请注意，工具的分享并不代表推荐，也没有任何形式的保证。在安装和使用任何软件之前，请自行调查！*
- en: '????️ **[MetaGPT: The Multi-Agent Framework](https://github.com/geekan/MetaGPT)**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ????️ **[MetaGPT：多代理框架](https://github.com/geekan/MetaGPT)**
- en: MetaGPT takes a one line requirement as input and outputs user stories / competitive
    analysis / requirements / data structures / APIs / documents, etc. Internally,
    MetaGPT includes product managers / architects / project managers / engineers.
    It provides the entire process of a software company along with carefully orchestrated
    SOPs.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: MetaGPT 接受一行需求作为输入，并输出用户故事/竞争分析/需求/数据结构/API/文档等。内部，MetaGPT 包括产品经理/架构师/项目经理/工程师。它提供了一个软件公司完整的过程以及精心编排的标准操作程序。
- en: ????️ **[GPT LLM Trainer](https://github.com/mshumer/gpt-llm-trainer)**
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ????️ **[GPT LLM Trainer](https://github.com/mshumer/gpt-llm-trainer)**
- en: The goal of this project is to explore an experimental new pipeline to train
    a high-performing task-specific model. We try to abstract away all the complexity,
    so it's as easy as possible to go from idea -> performant fully-trained model.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该项目的目标是探索一种实验性的新管道，用于训练高性能的任务特定模型。我们尝试抽象出所有复杂性，使从构想到高效的完全训练模型的过程尽可能简单。
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simply input a description of your task, and the system will generate a dataset
    from scratch, parse it into the right format, and fine-tune a LLaMA 2 model for
    you.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 只需输入任务描述，系统将从零开始生成数据集，将其解析为正确的格式，并为你微调 LLaMA 2 模型。
- en: ????️ **[DoctorGPT](https://github.com/llSourcell/DoctorGPT)**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ????️ **[DoctorGPT](https://github.com/llSourcell/DoctorGPT)**
- en: DoctorGPT is a Large Language Model that can pass the US Medical Licensing Exam.
    This is an open-source project with a mission to provide everyone their own private
    doctor. DoctorGPT is a version of Meta's Llama2 7 billion parameter Large Language
    Model that was fine-tuned on a Medical Dialogue Dataset, then further improved
    using Reinforcement Learning & Constitutional AI. Since the model is only 3 Gigabytes
    in size, it fits on any local device, so there is no need to pay an API to use
    it.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: DoctorGPT 是一个能够通过美国医学执照考试的大型语言模型。这是一个开源项目，旨在为每个人提供自己的私人医生。DoctorGPT 是 Meta 的
    Llama2 70 亿参数大型语言模型的一个版本，经过医学对话数据集的微调，随后使用强化学习和宪法 AI 进一步改进。由于模型只有 3GB 大小，因此可以在任何本地设备上运行，无需支付
    API 使用费。
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Unveiling StableCode: A New Horizon in AI-Assisted Coding](https://www.kdnuggets.com/2023/08/unveiling-stablecode-new-horizon-ai-assisted-coding)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 StableCode：AI 辅助编码的新视野](https://www.kdnuggets.com/2023/08/unveiling-stablecode-new-horizon-ai-assisted-coding)'
- en: '[This Week in AI, August 7: Generative AI Comes to Jupyter & Stack…](https://www.kdnuggets.com/2023/mm/this-week-ai-2023-08-07.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本周 AI 动态，8月7日：生成式 AI 进入 Jupyter 和 Stack…](https://www.kdnuggets.com/2023/mm/this-week-ai-2023-08-07.html)'
- en: '[Generative AI Playground: Text-to-Image Stable Diffusion with…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成式AI游乐场：文本到图像的稳定扩散与…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion)'
- en: '[8 Ways to Improve Your Search Application this Week](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本周提升搜索应用的8种方法](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
- en: '[Back to Basics Week 1: Python Programming & Data Science Foundations](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回归基础 第1周：Python编程与数据科学基础](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
- en: '[Back to Basics Week 3: Introduction to Machine Learning](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回归基础 第3周：机器学习简介](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
