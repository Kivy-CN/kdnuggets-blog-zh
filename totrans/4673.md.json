["```py\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn\nimport numpy as np \nimport pandas as pd \n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn import preprocessing\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNetCV, ElasticNet\nfrom xgboost import XGBRegressor, plot_importance \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\ndf = pd.read_csv('house_train.csv')\ndf.shape\n```", "```py\n(df.isnull().sum() / len(df)).sort_values(ascending=False)[:20]\n```", "```py\ndf.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id'], axis=1, inplace=True)\n```", "```py\nsns.distplot(df['SalePrice'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(df['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n# Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Sale Price distribution')\n\n# Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(df['SalePrice'], plot=plt)\nplt.show();\n```", "```py\nsns.distplot(np.log1p(df['SalePrice']) , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(np.log1p(df['SalePrice']))\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n# Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('log(Sale Price+1) distribution')\n\n# Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(np.log1p(df['SalePrice']), plot=plt)\nplt.show();\n```", "```py\npd.set_option('precision',2)\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.drop(['SalePrice'],axis=1).corr(), square=True)\nplt.suptitle(\"Pearson Correlation Heatmap\")\nplt.show();\n```", "```py\ncorr_with_sale_price = df.corr()[\"SalePrice\"].sort_values(ascending=False)\nplt.figure(figsize=(14,6))\ncorr_with_sale_price.drop(\"SalePrice\").plot.bar()\nplt.show();\n```", "```py\nsns.pairplot(df[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars']])\nplt.show();\n```", "```py\nfeature_importance = pd.Series(index = X_train.columns, data = np.abs(cv_model.coef_))\n\nn_selected_features = (feature_importance>0).sum()\nprint('{0:d} features, reduction of {1:2.2f}%'.format(\n    n_selected_features,(1-n_selected_features/len(feature_importance))*100))\n\nfeature_importance.sort_values().tail(30).plot(kind = 'bar', figsize = (12,5));\n```", "```py\nfrom collections import OrderedDict\nOrderedDict(sorted(xgb_model2.get_booster().get_fscore().items(), key=lambda t: t[1], reverse=True))\n```"]