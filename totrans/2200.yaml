- en: 'Free MIT Course: TinyML and Efficient Deep Learning Computing'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 免费MIT课程：TinyML和高效深度学习计算
- en: 原文：[https://www.kdnuggets.com/free-mit-course-tinyml-and-efficient-deep-learning-computing](https://www.kdnuggets.com/free-mit-course-tinyml-and-efficient-deep-learning-computing)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/free-mit-course-tinyml-and-efficient-deep-learning-computing](https://www.kdnuggets.com/free-mit-course-tinyml-and-efficient-deep-learning-computing)
- en: '![Free MIT Course: TinyML and Efficient Deep Learning Computing](../Images/79d52c66736c561112d0d409c1e62a68.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![免费MIT课程：TinyML和高效深度学习计算](../Images/79d52c66736c561112d0d409c1e62a68.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In today’s tech-savvy world, we''re surrounded by mind-blowing AI-powered wonders:
    voice assistants answering our questions, smart cameras identifying faces, and
    self-driving cars navigating roads. They''re like the superheroes of our digital
    age! However, making these technological wonders work smoothly on our everyday
    devices is tougher than it seems. These AI superheroes have a special need: **significant
    computing power** and **memory resources**. It''s like trying to fit an entire
    library into a tiny backpack. And guess what? Most of our regular devices like
    phones, smartwatches, etc. don’t have enough ‘**brainpower**’ to handle these
    AI superheroes. This poses a major problem in the widespread deployment of the
    AI technology.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的科技时代，我们被令人惊叹的AI技术奇迹所包围：语音助手回答我们的疑问，智能摄像头识别面孔，自驾车在道路上行驶。这些就像我们数字时代的超级英雄！然而，使这些技术奇迹在我们日常设备上顺利运行比看起来要困难得多。这些AI超级英雄有一个特殊需求：**显著的计算能力**
    和 **内存资源**。这就像试图将整个图书馆塞进一个小背包。更糟糕的是，大多数我们的普通设备如手机、智能手表等并没有足够的‘**脑力**’来处理这些AI超级英雄。这在AI技术的广泛部署中带来了重大问题。
- en: 'Hence, it is crucial to improve the efficiency of these large AI models to
    make them accessible. This course: **"**[**TinyML and Efficient Deep Learning
    Computing**](https://youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB&si=bM9vsKYkcdATaPuJ)**"**
    by MIT HAN lab tackles this core obstacle. It introduces methods to optimize AI
    models, ensuring their viability in real-world scenarios. Let’s take a detailed
    look at what it offers:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提高这些大型AI模型的效率，使其更易获取至关重要。本课程：**"**[**TinyML和高效深度学习计算**](https://youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB&si=bM9vsKYkcdATaPuJ)**"**
    由MIT HAN实验室解决了这一核心障碍。它介绍了优化AI模型的方法，确保其在实际场景中的可行性。让我们详细了解一下它提供的内容：
- en: Course Overview
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程概览
- en: 'Course Structure:'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程结构：
- en: '**Duration:** Fall 2023'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**持续时间：** 2023年秋季'
- en: '**Timing:** Tuesday/Thursday 3:35-5:00 pm Eastern Time'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间：** 星期二/星期四 下午3:35-5:00 东部时间'
- en: '**Instructor:** [Professor Song Han](https://hanlab.mit.edu/songhan)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**讲师：** [宋汉教授](https://hanlab.mit.edu/songhan)'
- en: '**Teaching Assistants:** [Han Cai](https://hanlab.mit.edu/team/hancai) and
    [Ji Lin](https://hanlab.mit.edu/team/ji-lin)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**助教：** [Han Cai](https://hanlab.mit.edu/team/hancai) 和 [Ji Lin](https://hanlab.mit.edu/team/ji-lin)'
- en: As this is an ongoing course, you can watch the live streaming at this [link](https://www.youtube.com/channel/UCcA-9WYwGaUrWiZaEDo84ng/live).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个进行中的课程，你可以通过这个 [链接](https://www.youtube.com/channel/UCcA-9WYwGaUrWiZaEDo84ng/live)
    观看直播。
- en: 'Course Approach:'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程方法：
- en: '**Theoretical Foundation:** Starts with foundational concepts of Deep Learning,
    then advances into sophisticated methods for efficient AI computing.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**理论基础：** 从深度学习的基础概念开始，逐步深入到高效AI计算的复杂方法。'
- en: '**Hands-on Experience:** Provides practical experience by enabling students
    to deploy and work with large language models like LLaMA 2 on their laptops.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**实践经验：** 通过让学生在其笔记本电脑上部署和使用像LLaMA 2这样的语言模型，提供实际经验。'
- en: Course Modules
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程模块
- en: 1\. Efficient Inference
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 高效推理
- en: 'This module primarily focuses on enhancing the efficiency of AI inference processes.
    It delves into techniques such as pruning, sparsity, and quantization aimed at
    making inference operations faster and more resource-efficient. Key topics covered
    include:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本模块主要集中在提高 AI 推理过程的效率。它深入探讨了如剪枝、稀疏性和量化等技术，旨在加快推理操作并提高资源效率。涵盖的关键主题包括：
- en: '**Pruning and Sparsity (Part I & II):** Exploring methods to reduce the size
    of models by removing unnecessary parts without compromising performance.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**剪枝与稀疏性（第一部分和第二部分）：** 探索通过移除不必要的部分来减少模型大小的方法，同时不影响性能。'
- en: '**Quantization (Part I & II):** Techniques to represent data and models using
    fewer bits, saving memory and computational resources.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化（第一部分和第二部分）：** 使用更少的位数表示数据和模型的技术，节省内存和计算资源。'
- en: '**Neural Architecture Search** **(Part I & II):** These lectures explore automated
    techniques for discovering the best neural network architectures for specific
    tasks. They demonstrate practical uses across various areas such as NLP, GAN,
    point cloud analysis, and pose estimation.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经架构搜索（第一部分和第二部分）：** 这些讲座探讨了发现特定任务最佳神经网络架构的自动化技术。它们展示了在 NLP、GAN、点云分析和姿态估计等各个领域的实际应用。'
- en: '**Knowledge Distillation**: This session focuses on knowledge distillation,
    a process where a compact model is trained to mimic the behavior of a larger,
    more complex model. It aims to transfer knowledge from one model to another.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识蒸馏：** 本次会议专注于知识蒸馏，这是一种训练紧凑模型以模仿较大、更复杂模型行为的过程。旨在将知识从一个模型转移到另一个模型。'
- en: '**MCUNet: TinyML on Microcontrollers:** This lecture introduces MCUNet, which
    focuses on deploying TinyML models on microcontrollers, allowing AI to run efficiently
    on low-power devices. It covers the essence of TinyML, its challenges, creating
    compact neural networks, and its diverse applications.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MCUNet：微控制器上的 TinyML：** 本讲座介绍了 MCUNet，专注于在微控制器上部署 TinyML 模型，使 AI 能够在低功耗设备上高效运行。讲座内容包括
    TinyML 的本质、挑战、创建紧凑的神经网络以及其多种应用。'
- en: '**TinyEngine and Parallel Processing:** This part discusses TinyEngine, exploring
    methods for efficient deployment and parallel processing strategies like loop
    optimization, multithreading, and memory layout for AI models on constrained devices.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TinyEngine 和并行处理：** 本部分讨论 TinyEngine，探讨了在受限设备上高效部署和并行处理策略的方法，如循环优化、多线程和内存布局。'
- en: 2\. Domain-Specific Optimization
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 领域特定优化
- en: 'In the Domain-Specific Optimization segment, the course covers various advanced
    topics aimed at optimizing AI models for specific domains:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在领域特定优化部分，本课程涵盖了旨在优化特定领域 AI 模型的各种高级主题：
- en: '**Transformer and LLM (Part I & II):** It dives into Transformer basics, design
    variants, and covers advanced topics related to efficient inference algorithms
    for LLMs. It also explores efficient inference systems and fine-tuning methods
    for LLMs.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer 和 LLM（第一部分和第二部分）：** 探讨了 Transformer 基础、设计变体，并涉及与 LLM 相关的高效推理算法的高级主题。还探讨了
    LLM 的高效推理系统和微调方法。'
- en: '**Vision Transformer:** This section introduces Vision Transformer basics,
    efficient ViT strategies, and diverse acceleration techniques. It also explores
    self-supervised learning methods and multi-modal Large Language Models (LLMs)
    to enhance AI capabilities in vision-related tasks.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉 Transformer：** 本部分介绍了视觉 Transformer 基础、高效的 ViT 策略和各种加速技术。还探讨了自监督学习方法和多模态大语言模型（LLMs），以增强
    AI 在视觉相关任务中的能力。'
- en: '**GAN, Video, and Point Cloud:** This lecture focuses on enhancing Generative
    Adversarial Networks (GANs) by exploring efficient GAN compression techniques
    (using NAS+distillation), AnyCost GAN for dynamic cost, and Differentiable Augmentation
    for data-efficient GAN training. These approaches aim to optimize models for GANs,
    video recognition, and point cloud analysis.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GAN、视频和点云：** 本讲座专注于通过探讨高效的 GAN 压缩技术（使用 NAS+蒸馏）、动态成本的 AnyCost GAN 和数据高效的 GAN
    训练的可微增强来提升生成对抗网络（GAN）。这些方法旨在优化 GAN、视频识别和点云分析模型。'
- en: '**Diffusion Model:** This lecture offers insights into the structure, training,
    domain-specific optimization, and fast-sampling strategies of Diffusion Models.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩散模型：** 本讲座提供了对扩散模型结构、训练、领域特定优化以及快速采样策略的深入见解。'
- en: 3\. Efficient Training
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 高效训练
- en: 'Efficient training refers to the application of methodologies to optimize the
    training process of machine learning models. This chapter covers the following
    key areas:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 高效训练指的是应用方法优化机器学习模型的训练过程。本章节涵盖了以下关键领域：
- en: '**Distributed Training (Part I & II):** Explore strategies to distribute training
    across multiple devices or systems. It provides strategies for overcoming bandwidth
    and latency bottlenecks, optimizing memory consumption, and implementing efficient
    parallelization methods to enhance the efficiency of training large-scale machine
    learning models across distributed computing environments.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式训练（第一部分和第二部分）：** 探索在多个设备或系统间分布训练的策略。提供了克服带宽和延迟瓶颈、优化内存消耗和实施高效并行化方法的策略，以提高在分布式计算环境中训练大规模机器学习模型的效率。'
- en: '**On-Device Training and Transfer Learning:** This session primarily focuses
    on training models directly on edge devices, handling memory constraints, and
    employing transfer learning methods for efficient adaptation to new domains.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备端训练和迁移学习：** 本节主要关注直接在边缘设备上训练模型，处理内存限制，并采用迁移学习方法以高效适应新领域。'
- en: '**Efficient Fine-tuning and Prompt Engineering:** This section focuses on refining
    Large Language Models (LLMs) through efficient fine-tuning techniques like BitFit,
    Adapter, and Prompt-Tuning. Additionally, it highlights the concept of Prompt
    Engineering and illustrates how it can enhance model performance and adaptability.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效微调和提示工程：** 本节重点介绍通过高效微调技术（如BitFit、Adapter和Prompt-Tuning）来优化大型语言模型（LLMs）。此外，还强调了提示工程的概念，并说明了如何提升模型的性能和适应性。'
- en: 4\. Advanced Topics
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 高级主题
- en: 'This module covers topics about an emerging field of Quantum Machine Learning.
    While the detailed lectures for this segment are not available yet, the planned
    topics for coverage include:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本模块涵盖了量子机器学习这一新兴领域的主题。虽然该部分的详细讲座尚未提供，但计划涉及的主题包括：
- en: '**Basics of Quantum Computing**'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量子计算基础**'
- en: '**Quantum Machine Learning**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量子机器学习**'
- en: '**Noise Robust Quantum ML**'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**噪声鲁棒量子机器学习**'
- en: These topics will provide a foundational understanding of quantum principles
    in computing and explore how these principles are applied to enhance machine learning
    methods while addressing the challenges posed by noise in quantum systems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主题将提供对计算中量子原理的基础理解，并探讨这些原理如何应用于增强机器学习方法，同时解决量子系统中噪声带来的挑战。
- en: 'If you are interested in digging deeper into this course then check the playlist
    below:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣深入了解这门课程，请查看下面的播放列表：
- en: Concluding Remarks
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结发言
- en: This course has received fantastic feedback, especially from AI enthusiasts
    and professionals. Although the course is ongoing and scheduled to conclude by
    December 2023, I highly recommend joining! If you're taking this course or intend
    to, share your experiences. Let's chat and learn together about TinyML and how
    to make AI smarter on small devices. Your input and insights would be valuable!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这门课程收到了极好的反馈，特别是来自AI爱好者和专业人士。虽然课程正在进行中，计划于2023年12月结束，但我强烈推荐加入！如果你正在参加这门课程或有意参加，请分享你的经验。让我们一起聊聊TinyML，讨论如何在小型设备上让AI变得更聪明。你的意见和见解将非常宝贵！
- en: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal is a machine learning engineer and a technical writer with a profound passion
    for data science and the intersection of AI with medicine. She co-authored the
    ebook "Maximizing Productivity with ChatGPT". As a Google Generation Scholar 2022
    for APAC, she champions diversity and academic excellence. She''s also recognized
    as a Teradata Diversity in Tech Scholar, Mitacs Globalink Research Scholar, and
    Harvard WeCode Scholar. Kanwal is an ardent advocate for change, having founded
    FEMCodes to empower women in STEM fields.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal是一名机器学习工程师和技术作家，对数据科学及AI与医学的交汇处充满热情。她共同撰写了电子书《利用ChatGPT最大化生产力》。作为2022年APAC的Google
    Generation Scholar，她倡导多样性和学术卓越。她还被认可为Teradata技术多样性学者、Mitacs Globalink研究学者和Harvard
    WeCode学者。Kanwal是变革的坚定倡导者，她创办了FEMCodes，以赋能STEM领域的女性。'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Why TinyML Cases Are Becoming Popular?](https://www.kdnuggets.com/2022/10/tinyml-cases-becoming-popular.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么TinyML案例越来越受欢迎？](https://www.kdnuggets.com/2022/10/tinyml-cases-becoming-popular.html)'
- en: '[Free MIT Courses on Calculus: The Key to Understanding Deep Learning](https://www.kdnuggets.com/2020/07/free-mit-courses-calculus-key-deep-learning.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费 MIT 微积分课程：理解深度学习的关键](https://www.kdnuggets.com/2020/07/free-mit-courses-calculus-key-deep-learning.html)'
- en: '[A Collection Of Free Data Science Courses From Harvard, Stanford,…](https://www.kdnuggets.com/a-collection-of-free-data-science-courses-from-harvard-stanford-mit-cornell-and-berkeley)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[来自哈佛、斯坦福等大学的免费数据科学课程合集](https://www.kdnuggets.com/a-collection-of-free-data-science-courses-from-harvard-stanford-mit-cornell-and-berkeley)'
- en: '[5 Free MIT Courses to Learn Math for Data Science](https://www.kdnuggets.com/5-free-mit-courses-to-learn-math-for-data-science)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 门免费 MIT 课程学习数据科学数学](https://www.kdnuggets.com/5-free-mit-courses-to-learn-math-for-data-science)'
- en: '[8 Free MIT Courses to Learn Data Science Online](https://www.kdnuggets.com/2022/03/8-free-mit-courses-learn-data-science-online.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8 门免费 MIT 数据科学在线课程](https://www.kdnuggets.com/2022/03/8-free-mit-courses-learn-data-science-online.html)'
- en: '[KDnuggets News, April 6: 8 Free MIT Courses to Learn Data Science…](https://www.kdnuggets.com/2022/n14.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4 月 6 日：8 门免费 MIT 数据科学课程](https://www.kdnuggets.com/2022/n14.html)'
