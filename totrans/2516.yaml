- en: Dealing with Data Leakage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/10/dealing-data-leakage.html](https://www.kdnuggets.com/2021/10/dealing-data-leakage.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Susan Currie Sivek, Ph.D.](https://www.linkedin.com/in/ssivek/), Senior
    Data Science Journalist**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/0837488b007543b7781e158aa9753758.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Captured still [via GIPHY](https://giphy.com/gifs/cartoonhangover-cartoons-bravestwarriors-etBlg1EQTz6pCzdKmd)
  prefs: []
  type: TYPE_NORMAL
- en: You’re studying for an upcoming exam. The exam is open-book, so you’re using
    your reference materials as you review, and you’re doing great.
  prefs: []
  type: TYPE_NORMAL
- en: But when you show up on test day, suddenly you’re told the exam isn’t open-book
    anymore. It doesn’t go so well.
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/funny-exam-vXKDrRey28YCY)'
  prefs: []
  type: TYPE_NORMAL
- en: This sounds like an academic overachiever’s anxiety dream, but it’s similar
    to what’s happening when target leakage occurs in a machine learning model. Say
    you build a model that’s intended to predict a certain outcome, and you train
    it with information that helps the model make its prediction. That model may perform
    well ... perhaps suspiciously well. But if some of that information won’t be available
    to the model at the actual time it has to make its prediction, its real performance
    will be lower. That’s the result of target leakage — a data scientist’s anxiety
    dream!
  prefs: []
  type: TYPE_NORMAL
- en: I recently heard one of our in-house Alteryx experts call target leakage the
    toughest problem in machine learning. But how does it happen, and how can you
    avoid this issue with your models? And how does it relate to “data leakage” more
    generally?
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/underground-leak-sprinkler-Nf1O8cYzypC1O)'
  prefs: []
  type: TYPE_NORMAL
- en: Target Leakage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Target leakage occurs when a model is trained with data that it will not have
    available at the time of prediction. The model does well when it is initially
    trained and tested, but when it’s put into production, the lack of that now-missing
    data causes the model to perform poorly. Just like you studying with your books,
    then taking the exam without them, the model is missing helpful information that
    improved its performance during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some scenarios that represent target leakage:'
  prefs: []
  type: TYPE_NORMAL
- en: Including the outcome to be predicted as a feature in the dataset used to train
    the model (this may sound silly, but it could happen; for example, duplicating
    and renaming your target variable field, then forgetting about that duplication,
    could lead you to inadvertently use the extra version of the target as a predictor);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including a feature representing the number of years a student attended a college
    in a model predicting whether the student would accept an offer of admission to
    that college;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including a feature representing the number of months of a subscription in a
    model predicting whether a potential customer would subscribe or not;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including a feature representing whether a fire-related insurance claim was
    approved in a model predicting fires in homes with a certain type of siding; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including information from other datasets that introduces details not otherwise
    available to the model at the time of prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all of these cases, information that can’t be known at the time of prediction
    was included when the model was built. We can’t know how many months a customer
    will subscribe when we are still trying to figure out if they’ll subscribe in
    the first place. (Can we build a model that could try to predict how many months
    a subscriber will subscribe? Sure. But we’d base that on our data about known
    subscribers, not the entire pool of those who may or may not subscribe.) Similarly,
    if we’ve told a model that people in homes built with certain materials have made
    fire insurance claims, we’re introducing knowledge from after the fires have occurred
    into our model trying to predict the fires.
  prefs: []
  type: TYPE_NORMAL
- en: Even seemingly innocent details like file size or timestamps can unintentionally
    be proxies for a target variable. For example, a 2013 Kaggle competition [had
    to be paused](https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865#25839)
    and the dataset revamped because of this kind of issue. The team that discovered
    (and diligently reported) the leakage enjoyed a brief stint on the top of the
    leaderboard!
  prefs: []
  type: TYPE_NORMAL
- en: What results from data leakage is overfitting to your training data. Your model
    can be very good at predicting with that extra knowledge — excelling on the open-book
    exam — but not so good when that information isn’t provided at prediction time.
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/fix-having-leak-hQtlzrmpE0gKY)'
  prefs: []
  type: TYPE_NORMAL
- en: Train-Test Contamination
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another form of data leakage is sometimes called “train-test contamination.”
    This problem may not specifically involve your target variable, but it does affect
    model performance. It’s another way we might inadvertently add knowledge about
    future data into our training data, resulting in performance metrics that look
    better than they would in production. (By the way, if you look for more reading
    on this topic, be forewarned that “data leakage” is also a term sometimes used
    by cybersecurity folks to talk about [data breaches](https://en.wikipedia.org/wiki/Data_breach).)
  prefs: []
  type: TYPE_NORMAL
- en: A common way train-test contamination occurs is preprocessing your dataset in
    its entirety before splitting it into training and test sets or prior to using
    cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: For example, [normalizing data](https://community.alteryx.com/t5/Data-Science/Normalization-Standardization-and-Regularization-in-Alteryx-and/ba-p/733996?utm_content=827583&utm_source=kdn)
    requires using the numerical range of each variable in the dataset. Normalizing
    the entire dataset as a whole provides that “knowledge” to the model when it’s
    evaluated. However, a model that is put into production won’t have that knowledge,
    and so won’t perform as well when it is used for prediction. Similarly, standardizing
    the full dataset would inappropriately inform the model about the mean and standard
    deviation of the entire dataset. Imputing missing values also uses summary statistics
    about your dataset (e.g., median, mean).
  prefs: []
  type: TYPE_NORMAL
- en: All of these clues can help the model perform better on your training and test
    data than it will when it is eventually introduced to brand-new data. [This article](https://machinelearningmastery.com/data-preparation-without-data-leakage/)
    provides an in-depth exploration of this kind of data leakage, including code
    to demonstrate.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue can emerge if you’re using [k-fold cross-validation](https://community.alteryx.com/t5/Data-Science/Holdouts-and-Cross-Validation-Why-the-Data-Used-to-Evaluate-your/ba-p/448982?utm_content=827583&utm_source=kdn)
    to evaluate your model. As long as your dataset includes only one observation
    from each individual person/source, this type of leakage should not be an issue
    for you. However, if you have multiple observations (i.e., rows of data) from
    each person or source in your dataset, all of those observations from the same
    source need to be grouped together when the subsets or “folds” of your data are
    created for training and testing the model.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you may end up using training data from person A to predict an
    outcome for test data from person A, if observations from person A end up included
    in both the training group and the test group. The model will seem to perform
    better on the test set — which again includes person A — because it already knows
    something about person A from the training set. But in production, it won’t have
    that advantage of prior exposure. For more elaboration on this issue (sometimes
    called “group leakage”), check out this article.
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/xyShS1HDFNNZe)'
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Data Leakage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a faucet drips in your house, you know it by the sound and puddles. But
    these types of leakage can be difficult to detect. There are still preventive
    maintenance and repairs you can do to address this challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Unusually good model performance may be a sign of leakage. If your model is
    performing shockingly, remarkably well, resist the temptation to pat yourself
    on the back and ship it. That performance might be the result of garden-variety
    overfitting, but it may also be reflecting target or data leakage.
  prefs: []
  type: TYPE_NORMAL
- en: To try to stave off data leakage in the first place, you can do thorough [exploratory
    data analysis](https://community.alteryx.com/t5/Data-Science/Adventures-in-Data-Exploratory-Data-Analysis/ba-p/545267?utm_content=827583&utm_source=kdn)
    (EDA) and look for features that have especially high correlations with your outcome
    variable. It’s worth looking closely at those relationships to ensure there isn’t
    the potential for leakage if the highly correlated features are used together
    in the model. This review can be challenging if you have a high-dimensional dataset
    with many features, so using a tool like the [Pearson Correlation Tool](https://community.alteryx.com/t5/Alteryx-Designer-Knowledge-Base/Tool-Mastery-Pearson-Correlation/ta-p/388744?utm_content=827583&utm_source=kdn)
    in Alteryx Designer and filtering and/or visualizing its output could be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid train-test contamination, be sure to split your data into training/test/holdout
    sets prior to applying any transformations such as normalization, then train the
    model on the training set. Follow up by applying the transformations to the test/holdout
    sets with the same parameters applied to the training set, then test your model’s
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/cartoonhangover-cartoons-bravestwarriors-etBlg1EQTz6pCzdKmd)'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, be sure you fully understand all the features in your dataset.
    [This Kaggle example](https://www.kaggle.com/alexisbcook/data-leakage) shows how
    a feature named “expenditures” in a credit card application approval dataset could
    cause target leakage if used in a model to predict approved applications. “Expenditures”
    as a feature name could mean a lot of things, but in this case, it referred to
    how much credit card users spent on their cards. That feature implied that they
    were indeed approved for the cards and informed the model’s prediction of approvals
    inappropriately, since expenditure information would not be available at the time
    of prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, checking your features’ relative importance and reviewing other interpretability
    tools could help you catch leakage. In the credit card application approval example
    above, “expenditures” might have looked like a really important feature in a prediction
    of credit card approvals. If in doubt, you can try removing a feature to see how
    your model’s performance changes, and then determine whether the model suddenly
    performs at a more realistic level.
  prefs: []
  type: TYPE_NORMAL
- en: '[via GIPHY](https://giphy.com/gifs/season-16-the-simpsons-16x16-xT5LMXBrV5NkVZHKms)'
  prefs: []
  type: TYPE_NORMAL
- en: Leakproofing Your Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I hope this overview has provided you some new plumbing skills to help you avoid
    these leaky situations! With careful EDA and thorough knowledge of your dataset,
    as well as correct preprocessing and cross-validation setup, you should be able
    to keep your targets nicely contained and your datasets free from contamination.
  prefs: []
  type: TYPE_NORMAL
- en: Recommended Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Ask a Data Scientist: Data Leakage](https://insidebigdata.com/2014/11/26/ask-data-scientist-data-leakage/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Leakage in Machine Learning](https://machinelearningmastery.com/data-leakage-machine-learning/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Target Leakage in ML](https://aiukraine.com/wp-content/uploads/2018/09/12_00-Yuriy-Guts-Target-Leakage-in-Machine-Learning-.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Originally published on the [Alteryx Community Data Science Blog](https://community.alteryx.com/t5/Data-Science/Dealing-with-Data-Leakage/ba-p/827583?utm_content=827583&utm_source=kdn).
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Susan Currie Sivek, Ph.D.](https://www.linkedin.com/in/ssivek/)** is
    the senior data science journalist for the Alteryx Community, where she explores
    data science concepts with a global audience. She is also the host of the [Data
    Science Mixer](https://community.alteryx.com/t5/Data-Science-Mixer/bg-p/mixer?utm_content=733996&utm_source=kdn)
    podcast. Her background in academia and social science informs her approach to
    investigating data and communicating complex ideas — with a dash of creativity
    from her training in journalism.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://community.alteryx.com/t5/Data-Science/Dealing-with-Data-Leakage/ba-p/827583?utm_content=827583&utm_source=kdn).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Continuous Training for Machine Learning – a Framework for a Successful Strategy](/2021/04/continuous-training-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Essential Papers on AI Training Data](/2020/06/5-essential-papers-ai-training-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dataset Splitting Best Practices in Python](/2020/05/dataset-splitting-best-practices-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Dealing With Noisy Labels in Text Data](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dealing with Position Bias in Recommendations and Search](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Navigating Data Science Job Titles: Data Analyst vs. Data Scientist…](https://www.kdnuggets.com/navigating-data-science-job-titles-data-analyst-vs-data-scientist-vs-data-engineer)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Scientist, Data Engineer & Other Data Careers, Explained](https://www.kdnuggets.com/2021/05/data-scientist-data-engineer-data-careers-explained.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Scientist vs Data Analyst vs Data Engineer](https://www.kdnuggets.com/2022/01/data-scientist-data-analyst-data-engineer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
