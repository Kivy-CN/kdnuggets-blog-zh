- en: 10 New Things I Learnt from fast.ai Course V3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从fast.ai课程V3中学到的10个新知识
- en: 原文：[https://www.kdnuggets.com/2019/06/things-learnt-fastai-course.html](https://www.kdnuggets.com/2019/06/things-learnt-fastai-course.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/06/things-learnt-fastai-course.html](https://www.kdnuggets.com/2019/06/things-learnt-fastai-course.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Raimi Bin Karim](https://www.linkedin.com/in/raimibkarim/), AI Singapore**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Raimi Bin Karim](https://www.linkedin.com/in/raimibkarim/)，AI Singapore**'
- en: '![fast ai version three](../Images/1af1367ed8151657b506321ff250b94b.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![fast ai version three](../Images/1af1367ed8151657b506321ff250b94b.png)'
- en: Everyone’s talking about the **fast.ai** Massive Open Online Course (MOOC) so
    I decided to have a go at their 2019 deep learning course [Practical Deep Learning
    for Coders, v3](https://course.fast.ai/).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 大家都在谈论**fast.ai**的大规模开放在线课程（MOOC），所以我决定尝试一下他们2019年的深度学习课程[实用深度学习（程序员版）v3](https://course.fast.ai/)。
- en: I’ve always known some deep learning concepts/ideas (I’ve been in this field
    for about a year now, dealing mostly with computer vision), but never really understood
    some intuitions or explanations. I also understand that [Jeremy Howard](https://medium.com/@jeremyphoward),
    [Rachel Thomas](https://medium.com/@racheltho) and Sylvain Gugger (follow them
    on Twitter!) are influential people in the deep learning sphere (Jeremy has a
    lot of experience with Kaggle competitions), so I hope to gain new insights and
    intuitions, and some tips and tricks for model training from them. I have so much
    to learn from these folks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直了解一些深度学习概念/想法（我已经在这个领域待了一年，主要处理计算机视觉），但从未真正理解过一些直觉或解释。我也了解到[Jeremy Howard](https://medium.com/@jeremyphoward)、[Rachel
    Thomas](https://medium.com/@racheltho)和Sylvain Gugger（关注他们的Twitter！）是深度学习领域的影响力人物（Jeremy有丰富的Kaggle竞赛经验），所以我希望从他们那里获得新的见解和直觉，并得到一些模型训练的技巧和窍门。我有很多东西要向这些人学习。
- en: 'So, here I am after 3 weeks of watching the videos (I didn’t do any exercises
    ????????????????) and writing this post to compartmentalise **the** **new things
    I learnt** to share with you. There were of course some things I was clueless
    about so I did a little bit more research on them, and presented them in this
    article. Towards the end, I also write about how I felt about the course (spoiler
    alert: I love it ❣️).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我在观看视频3周后（我没有做任何练习 ????????????????)，写下这篇文章来将**我学到的** **新知识**进行整理与分享。当然，也有一些我一头雾水的内容，所以我做了一些额外的研究，并在这篇文章中呈现。最后，我也写了一下对这门课程的感受（剧透：我喜欢它❣️）。
- en: '**Disclaimer** Different people gather different learning points, depending
    on what deep learning background you have. This post is not recommended for beginners
    of deep learning and is **not a summary of the course contents.** This post instead
    assumes you have basic knowledge of neural networks, gradient descent, loss functions,
    regularisation techniques and generating embeddings. Some experience of the following
    would be great too: image classification, text classification, semantic segmentation
    and generative adversarial networks.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明** 不同的人会有不同的学习要点，这取决于你有何种深度学习背景。此文不适合深度学习初学者，也**不是课程内容的总结**。这篇文章假设你已具备神经网络、梯度下降、损失函数、正则化技术和生成嵌入的基础知识。以下经验也很有帮助：图像分类、文本分类、语义分割和生成对抗网络。'
- en: 'I organised the content of my 10 learning points as such: from the theory of
    neural networks, to architectures, to things related to loss function (learning
    rate, optimiser), to model training (and regularisation), to the deep learning
    tasks and finally model interpretability.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我将我的10个学习要点内容组织如下：从神经网络理论，到架构，再到与损失函数（学习率、优化器）相关的内容，到模型训练（及正则化），再到深度学习任务，最终到模型可解释性。
- en: '**Contents: 10 *New* Things I Learnt**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录：10个*新*知识点**'
- en: The Universal Approximation Theorem
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通用逼近定理
- en: 'Neural Networks: Design & Architecture'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络：设计与架构
- en: Understanding the Loss Landscape
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解损失景观
- en: Gradient Descent Optimisers
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度下降优化器
- en: Loss Functions
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失函数
- en: Training
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练
- en: Regularisation
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正则化
- en: Tasks
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任务
- en: Model Interpretability
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型可解释性
- en: 'Appendix: Jeremy Howard on Model Complexity & Regularisation'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 附录：Jeremy Howard谈模型复杂性与正则化
- en: '**0\. Fast.ai & Transfer Learning**'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**0. Fast.ai & 转移学习**'
- en: “It’s always good to use transfer learning [to train your model] if you can.” — Jeremy Howard
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “如果可以，使用转移学习[来训练你的模型]总是好的。” — Jeremy Howard
- en: Fast.ai is synonymous to transfer learning and achieving great results in a
    short amount of time. The course really lives up to its name. Transfer learning
    and experimentalism are the two key ideas that Jeremy Howard keeps emphasizing
    in order to be efficient Machine Learning Practitioners.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Fast.ai 等同于迁移学习，并在短时间内取得出色成果。这个课程真的名副其实。迁移学习和实验主义是 Jeremy Howard 强调的两个关键理念，以便成为高效的机器学习从业者。
- en: '**1\. The Universal Approximation Theorem**'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1\. 通用逼近定理**'
- en: '![olympics](../Images/c41c363e94ced5fd799553db19e35f09.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/c41c363e94ced5fd799553db19e35f09.png)'
- en: Photo by [Vincentiu Solomon](https://unsplash.com/photos/ln5drpv_ImI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/search/photos/astronomy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Vincentiu Solomon](https://unsplash.com/photos/ln5drpv_ImI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    在 [Unsplash](https://unsplash.com/search/photos/astronomy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: The [universal approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)
    says that you can approximate *any* function with just one hidden layer in a feed-forward
    neural network. This follows that you can also achieve the same kind of approximation
    for any neural network that goes deeper.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[通用逼近定理](https://en.wikipedia.org/wiki/Universal_approximation_theorem) 说明你可以用一个隐藏层的前馈神经网络来逼近*任何*函数。由此可见，你也可以对任何更深层的神经网络实现相同类型的逼近。'
- en: I mean, wow! I just got to know this like only *now*. This *is* the fundamental
    of deep learning. If you have stacks of affine functions (or matrix multiplications)
    and nonlinear functions, the thing you end up with can approximate any function
    arbitrarily closely. It is the reason behind the race for different combinations
    of affine functions and nonlinearities. It’s *the* reason why architectures are
    getting deeper.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，哇！我刚刚才知道这个，*现在*才知道。这 *是* 深度学习的基础。如果你有堆叠的仿射函数（或矩阵乘法）和非线性函数，最终得到的结果可以逼近任何函数。这是追求不同仿射函数和非线性组合的原因。这也是架构越来越深的*原因*。
- en: '**2\. Neural Networks: Design & Architecture**'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**2\. 神经网络：设计与架构**'
- en: '![](../Images/ac809cf72f7c6582afb9a74143f24e5b.png)In this section, I will
    highlight the architectures that were in the limelight during the course, and
    certain designs incorporated into state-of-the-art (SOTA) models like dropout.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/ac809cf72f7c6582afb9a74143f24e5b.png)在这一部分，我将重点介绍在课程中受到关注的架构，以及像丢弃法这样的最先进（SOTA）模型中纳入的一些设计。'
- en: '**ResNet-50** is pretty much SOTA, hence you would generally want to use it
    for many image-related tasks like image classification and object detection. This
    architecture is used a lot in the course’s Jupyter notebooks.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNet-50** 几乎是最先进的，因此你通常会希望在许多图像相关任务中使用它，比如图像分类和目标检测。这个架构在课程的 Jupyter 笔记本中使用得很频繁。'
- en: '**U-net** is pretty much the state of the art for image segmentation tasks.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**U-net** 几乎是图像分割任务中的最先进技术。'
- en: For convolutional neural networks (CNNs), stride=2 convolutions are common for
    the first few layers
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于卷积神经网络（CNNs），前几层常见使用步幅=2 的卷积。
- en: DenseNet uses concatenation as the final operation in the building blocks, whereas
    ResNet uses the addition operation.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DenseNet 在构建块的最终操作中使用了拼接，而 ResNet 使用了加法操作。
- en: '**Dropout**'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**丢弃法**'
- en: 'At random, we throw away *activations*. Intuition: so that no activation can
    memorise any part of the input. This would help with overfitting wherein some
    part of the model is basically learning to recognise a particular image rather
    than a particular feature or item. There’s also **embedding dropout** but that
    was briefly touched upon.'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们随机丢弃 *激活*。直观理解：这样没有任何激活可以记住输入的任何部分。这有助于解决过拟合问题，其中模型的某一部分基本上是在学习识别特定图像，而不是特定特征或项目。还有
    **嵌入丢弃**，但这一点只是略微提及。
- en: '**Batch normalisation (BatchNorm)**'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量归一化（BatchNorm）**'
- en: 'BatchNorm does 2 things: (1) normalise activations, and (2) introduce scaling
    and shifting parameters to each normalised activation. However, it turns out that
    (1) is not as important as (2). In the paper [How Does Batch Normalization Help
    Optimization?](https://t.co/mvCCL1DLYF), it was mentioned that “[BatchNorm] reparametrizes
    the underlying optimization problem to make its landscape significantly smooth[er].”
    Intuition is this: because it’s now less bumpy, we can use a higher learning rate,
    hence faster convergence (see Fig. 3.1).'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: BatchNorm 做了 2 件事：（1）规范化激活值，（2）为每个规范化的激活值引入缩放和平移参数。然而，结果表明（1）不如（2）重要。在论文 [Batch
    Normalization 如何帮助优化？](https://t.co/mvCCL1DLYF) 中提到，“[BatchNorm] 重新参数化了底层优化问题，使其景观显著平滑。”
    直观上讲：因为它现在不那么崎岖，我们可以使用更高的学习率，因此收敛更快（见图 3.1）。
- en: 3\. Understanding the Loss Landscape
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 理解损失景观
- en: '![olympics](../Images/cb49c9865f179d0113ede9cecd3f92dd.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/cb49c9865f179d0113ede9cecd3f92dd.png)'
- en: 'Fig 3.1: Loss landscapes; left landscape has many bumps, right is a smooth
    landscape. Source: [https://arxiv.org/abs/1712.09913](https://arxiv.org/abs/1712.09913)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：损失景观；左侧景观有很多凸起，右侧则是平滑的景观。来源：[https://arxiv.org/abs/1712.09913](https://arxiv.org/abs/1712.09913)
- en: Loss functions usually have bumpy and flat areas (if you visualise them in 2D
    or 3D diagrams). Have a look at Fig. 3.2\. If you end up in a *bumpy* area, that
    solution will tend not to generalise very well. This is because you found a solution
    that is good in one place, but it’s not very good in other place. But if you found
    a solution in a *flat* area, you probably will generalise well. And that’s because
    you found a solution that is not only good at one spot, but *around* it as well.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数通常有崎岖和平坦区域（如果你将其可视化为二维或三维图）。看看图 3.2。如果你进入一个 *崎岖* 区域，该解决方案通常不会很好地泛化。这是因为你找到的解决方案在一个地方很好，但在其他地方不太好。但如果你在
    *平坦* 区域找到了解决方案，你可能会有很好的泛化能力。这是因为你找到的解决方案不仅在一个点很好，而且在 *周围* 也很好。
- en: '![olympics](../Images/4f58cd8f2bd167281b0e80116e34d9b6.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/4f58cd8f2bd167281b0e80116e34d9b6.png)'
- en: 'Fig. 3.2: Loss landscape visualised in a 2D diagram. Screenshot from course.fast.ai.
    Most of the above paragraph are quoted from Jeremy Howard. Such a simple and beautiful
    explanation.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：在二维图中可视化的损失景观。截取自 course.fast.ai。以上大部分内容引自 Jeremy Howard。这是一个简单而美丽的解释。
- en: '**4\. Gradient Descent Optimisers**'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4\. 梯度下降优化器**'
- en: 'The new thing I learnt was that the RMSprop optimiser acts as an “accelerator”.
    Intuition: if your gradient has been small for the past few steps, obviously you
    need to go a little bit faster now.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我学到的新知识是 RMSprop 优化器充当了“加速器”。直观理解：如果你的梯度在过去几步中很小，很明显你现在需要加快一点速度。
- en: (For an overview of gradient descent optimisers, I have written a post titled
    [10 Gradient Descent Optimisation Algorithms](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9).)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: （有关梯度下降优化器的概述，我写了一篇题为 [10 Gradient Descent Optimisation Algorithms](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9)
    的文章。）
- en: '**5\. Loss Functions**'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5\. 损失函数**'
- en: 'Learnt 2 new loss functions:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 学习了 2 个新的损失函数：
- en: Pixel mean squared error (**Pixel MSE**). This can be used in semantic segmentation,
    which was one of the course contents but not covered in this article.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像素均方误差 (**Pixel MSE**)。这可以用于语义分割，这是课程内容之一，但本文没有涵盖。
- en: '**Feature loss ????**. This can be used in image restoration tasks. See Task:
    Image Generation.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征损失 ????**。这可以用于图像恢复任务。见任务：图像生成。'
- en: '****6\. Training****'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****6\. 训练****'
- en: '![olympics](../Images/05e65137b181548ba34871b05129bb5d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/05e65137b181548ba34871b05129bb5d.png)'
- en: Photo by [Victor Freitas](https://www.pexels.com/@victorfreitas?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    from [Pexels](https://www.pexels.com/photo/man-about-to-lift-barbell-2261477/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Victor Freitas](https://www.pexels.com/@victorfreitas?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    提供，自 [Pexels](https://www.pexels.com/photo/man-about-to-lift-barbell-2261477/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
- en: 'This section looks into a combination of tweaks for:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本节探讨了一些调整的组合：
- en: Weight initialisation
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重初始化
- en: Hyperparameter setting
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数设置
- en: Model fitting/fine-tuning
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型拟合/微调
- en: Other improvements
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他改进
- en: '**Transfer learning**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习**'
- en: Model weights can either be (i) randomly initialised, or (ii) transferred from
    a pre-trained model in a process called **transfer learning**. Transfer learning
    makes use of pre-trained weights. Pre-trained weights *have useful information*.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重可以是（i）随机初始化的，或者（ii）通过一种称为 **转移学习** 的过程从预训练模型中转移来的。转移学习利用了预训练的权重。预训练的权重 *包含有用的信息*。
- en: 'The usual model fitting for transfer learning works like this: train the weights
    that are closer to the output and freezes the other layers.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习中的常见模型拟合方法如下：训练靠近输出的权重，并冻结其他层。
- en: It is important that for transfer learning, one uses the **same ‘stats’ that
    the pre-trained model was applied with**, eg. correcting the image RGB values
    with a certain bias.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于转移学习，使用 **与预训练模型相同的‘统计数据’** 是很重要的，例如，用某种偏差校正图像的 RGB 值。
- en: '**❤️ 1cycle policy ❤️**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**❤️ 1cycle 策略 ❤️**'
- en: This is truly the best thing I learnt in this course. I am guilty of taking
    learning rates for granted all this while. [Finding a good learning rate](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)
    is important, because we can at the very least provide our gradient descent with
    an educated guess of a learning rate, rather than some gut feeling value that
    might just be suboptimal.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在这门课程中学到的最重要的知识。我一直以来对学习率掉以轻心。[找到一个好的学习率](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)
    非常重要，因为我们至少可以为梯度下降提供一个经过深思熟虑的学习率，而不是一个可能只是次优的直觉值。
- en: 'Jeremy Howard keeps using `lr_finder()` and `fit_one_cycle()` in his code and
    it bothers me that it works well but I don’t know why it works. So I read the
    [paper](https://arxiv.org/abs/1803.09820) by Leslie Smith and Sylvain Gugger’s
    [blog post](https://sgugger.github.io/the-1cycle-policy.html) (recommended readings!),
    and this is how **1cycle** works:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Jeremy Howard 在他的代码中持续使用 `lr_finder()` 和 `fit_one_cycle()`，这让我困惑，因为它虽然效果很好，但我不知道为什么它能有效。所以我阅读了
    Leslie Smith 的 [论文](https://arxiv.org/abs/1803.09820) 和 Sylvain Gugger 的 [博客文章](https://sgugger.github.io/the-1cycle-policy.html)（推荐阅读！），这就是
    **1cycle** 的工作原理：
- en: '1\. Perform an **LR range test**: train the model with (linearly) increasing
    learning rates from a small number (10e-8) to a high number (1 or 10). Plot a
    loss vs. learning rate graph like below.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 执行 **LR 范围测试**：用从小到大的（线性）学习率训练模型，从一个小值（10e-8）增加到一个大值（1 或 10）。绘制损失与学习率的图表，如下所示。
- en: '![olympics](../Images/f77e6ed2fb5541b1e84aef537b8992f6.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![奥林匹克](../Images/f77e6ed2fb5541b1e84aef537b8992f6.png)'
- en: 'Fig 6.1: Loss vs learning rate. [Source: https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1：损失与学习率的关系。[来源： https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)
- en: 2\. Choose minimum and maximum learning rate. To choose maximum learning rate,
    look at the graph and pick a learning rate that is high enough and give lower
    loss values (not too high, not too low). Here you’d pick 10e-2\. Choosing the
    minimum can be about ten times lower. Here it’d be 10e-3\. For more information
    how to pick these values.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 选择最小和最大学习率。选择最大学习率时，查看图表并选择一个足够高的学习率，以获得较低的损失值（既不要太高也不要太低）。在这里，你可以选择 10e-2。选择最小学习率时，可以选择约低十倍的值。在这里，它是
    10e-3。有关如何选择这些值的更多信息。
- en: 3\. Fit the model by the no. of cycles of **cyclical learning rate**. One cycle
    is when your training runs through the learning rates from the chosen minimum
    learning rate to the chosen maximum, then back to the minimum.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 根据 **周期性学习率** 的周期数来拟合模型。一个周期是指你的训练过程通过从选择的最小学习率到选择的最大学习率，然后再返回到最小值的学习率。
- en: '![olympics](../Images/1de06e6c524f21514cf9bb05381bbf43.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![奥林匹克](../Images/1de06e6c524f21514cf9bb05381bbf43.png)'
- en: 'Source: https://sgugger.github.io/the-1cycle-policy.html'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 来源： https://sgugger.github.io/the-1cycle-policy.html
- en: So why do we do it this way? The whole idea is the following. In a loss landscape,
    we want to jump over the bumps (because we don’t want to get stuck at some trench).
    So increasing the learning rate at the start helps the model to jump out away
    from that trench, explore the function surface and try to find areas where the
    loss is low and the region is not bumpy (because if it’s bumpy, it gets kicked
    out again). This enables us to train the model more quickly. We also tend to end
    up with much more generalisable solutions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们为什么这样做呢？整个想法是这样的。在损失地形中，我们希望跳过凸起（因为我们不想陷入某个沟壑）。因此，在开始时增加学习率有助于模型跳出沟壑，探索函数表面，并尝试找到损失较低且区域不崎岖的地方（因为如果地形崎岖，模型会再次被推出）。这使得我们可以更快地训练模型。我们还往往会得到更具泛化能力的解决方案。
- en: '![olympics](../Images/e3ad8465a2b40a016bd70b67d5ebf269.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/e3ad8465a2b40a016bd70b67d5ebf269.png)'
- en: 'Fig. 6.2: Screenshot from course.fast.ai'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2：来自 course.fast.ai 的截图
- en: '**Discriminative learning rates for pre-trained models**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于预训练模型的判别学习率**'
- en: Train earlier layer(s) with super low learning rate, and train later layers
    with higher learning rate. The idea is to not drastically alter the almost-perfect
    pre-trained weights except for minuscule amounts, and to be more aggressive with
    teaching the layers near the outputs. Discriminative learning rate was introduced
    in ULMFiT.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用超低学习率训练早期层，使用较高学习率训练后期层。这个想法是除了微小的调整外，不要剧烈改变几乎完美的预训练权重，对接近输出层的层进行更激进的训练。判别学习率是在
    ULMFiT 中引入的。
- en: '**A magic number divisor**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个神奇的数字除数**'
- en: In the 1cycle fitting, to get the minimum learning rate, divide maximum with
    2.6⁴. This number works for NLP task. See https://course.fast.ai/videos/?lesson=4
    at 33:30 for more information.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1cycle 拟合中，要获取最小学习率，将最大值除以 2.6⁴。这个数字适用于 NLP 任务。有关更多信息，请参见 https://course.fast.ai/videos/?lesson=4
    的 33:30。
- en: '**Random forest for hyperparameter search**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于超参数搜索的随机森林**'
- en: It was mentioned that random forest can be used to search for hyperparameters.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 提到可以使用随机森林来搜索超参数。
- en: '**Using default values**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用默认值**'
- en: When using a library or implementing a paper’s code, use the default hyperparameter
    values and “don’t be a hero”.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用库或实现论文代码时，使用默认超参数值，“不要做英雄”。
- en: '**Model fine-tuning for pre-trained models**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**针对预训练模型的模型微调**'
- en: 'I notice Jeremy’s style: after training the last layers, unfreeze all layers
    and train all weights. However, this step is experimental because it may or may
    not improve accuracy. If it doesn’t, I hope you have saved your last trained weights
    ????.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我注意到 Jeremy 的风格：在训练最后一层之后，解冻所有层并训练所有权重。然而，这一步是实验性的，因为它可能会或可能不会提高准确性。如果没有提高，我希望你保存了最后训练的权重
    ????。
- en: '**Progressive resizing**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**渐进式调整图像大小**'
- en: This is most applicable to image-related tasks. Start training using smaller
    versions of the images. Then, train using larger versions. To do this, use transfer
    learning to port the trained weights to a model with the same architecture but
    accepts different input size. Genius.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这最适用于图像相关任务。首先使用较小版本的图像进行训练。然后，使用较大版本的图像进行训练。为此，使用迁移学习将训练好的权重迁移到具有相同架构但接受不同输入大小的模型中。真是天才。
- en: '**Mixed precision training**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**混合精度训练**'
- en: A simplified version what this does is to use *single precision* (float32) data
    type for backpropagation, but *half precision* (float16) for forward pass.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 简化版的解释是：使用*单精度*（float32）数据类型进行反向传播，但使用*半精度*（float16）进行前向传递。
- en: '****7\. Regularisation****'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****7\. 正则化****'
- en: '![olympics](../Images/641fbc388d9cba403d9d62999f61f2ac.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/641fbc388d9cba403d9d62999f61f2ac.png)'
- en: Photo by [Rosemary Ketchum](https://www.pexels.com/@ketchumcommunity?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    from [Pexels](https://www.pexels.com/photo/man-wearing-black-officer-uniform-1464230/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Rosemary Ketchum](https://www.pexels.com/@ketchumcommunity?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    提供，来源于 [Pexels](https://www.pexels.com/photo/man-wearing-black-officer-uniform-1464230/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
- en: Use the **magic number 0.1** for weight decay. If you use too much weight decay,
    your model won’t trained well enough (underfitting). If too little, you’ll tend
    to overfit but that’s okay because you can stop the training early.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**神奇的数字 0.1**作为权重衰减。如果使用过多的权重衰减，你的模型训练得不够好（欠拟合）。如果使用过少，你可能会过拟合，但没关系，因为你可以提前停止训练。
- en: '**8\. Tasks**'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**8\. 任务**'
- en: '![](../Images/9f2ec74d3ae4ab722b3ab6c7a695cbca.png)Note that not all tasks
    covered in the course are mentioned here.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/9f2ec74d3ae4ab722b3ab6c7a695cbca.png)请注意，并非所有课程中涉及的任务都在此处提及。'
- en: Multi-label classification
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多标签分类
- en: Language Modelling
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模
- en: Tabular Data
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表格数据
- en: Collaborative Filtering
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协同过滤
- en: Image Generation
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像生成
- en: '**a) Multi-label classification**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**a) 多标签分类**'
- en: I’ve always wondered how you can carry out an [image] classification task whose
    number of labels can vary, i.e. [multi-label classification](https://en.wikipedia.org/wiki/Multi-label_classification)
    (not to be confused with [multi-class classification/multinomial classification](https://en.wikipedia.org/wiki/Multiclass_classification)
    whose sibling is [binary classification](https://en.wikipedia.org/wiki/Binary_classification)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直在想如何进行[图像]分类任务，其标签数量可能会变化，即[多标签分类](https://en.wikipedia.org/wiki/Multi-label_classification)（不要与[多类分类/多项式分类](https://en.wikipedia.org/wiki/Multiclass_classification)混淆，其相关概念是[二分类](https://en.wikipedia.org/wiki/Binary_classification)）。
- en: It was not mentioned how the loss function works for multi-label classification
    in detail. But after googling, I found out that the labels should be a vector
    of multi-hot encoding. This means that each element must be applied to a sigmoid
    function in the final model output. The loss function, which is a function of
    the output and ground truth, is calculated using binary cross entropy to penalise
    each element independently.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 没有详细说明多标签分类的损失函数如何工作。但经过搜索，我发现标签应该是多热编码的向量。这意味着每个元素必须在最终模型输出中应用sigmoid函数。损失函数，即输出和真实值的函数，是使用二元交叉熵来计算的，以独立地惩罚每个元素。
- en: '**b) Language Modelling**'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**b) 语言建模**'
- en: 'For this language modelling task, I like how ‘language model’ is defined (rephrased):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个语言建模任务，我喜欢“语言模型”如何被定义（重新表述）：
- en: '*A language model is a model that learns to predict the next word of a sentence.
    In order to do so, you need to know quite a lot of about English and world knowledge.*'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*语言模型是一个学习预测句子下一个词的模型。为了做到这一点，你需要对英语和世界知识有相当多的了解。*'
- en: This means you need to train the model with a lot of data. This is the part
    where the course introduces **ULMFiT**, a model that can be reused based on pre-training
    (transfer learning, in other words).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你需要用大量的数据来训练模型。这部分课程介绍了**ULMFiT**，这是一个可以基于预训练（换句话说，就是迁移学习）进行重用的模型。
- en: '**c) Tabular Data**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**c) 表格数据**'
- en: This is my first encounter of using deep learning for tabular data wi with categorical
    variables! I didn’t know you could do that? Anyway, what we can do is we can create
    **embeddings from categorical variables**. I wouldn’t have thought about this
    if I hadn’t taken this course. A little googling away got me a post by Rachel
    Thomas on [An Introduction to Deep Learning for Tabular Data](https://www.fast.ai/2018/04/29/categorical-embeddings/)
    on the use of such embeddings.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我第一次遇到使用深度学习处理具有分类变量的表格数据！我之前不知道可以这样做？无论如何，我们可以做的是我们可以从**分类变量中创建嵌入**。如果我没有上过这门课程，我可能不会想到这一点。稍微搜索了一下，我找到了Rachel
    Thomas写的关于[表格数据深度学习入门](https://www.fast.ai/2018/04/29/categorical-embeddings/)的帖子，介绍了这种嵌入的使用。
- en: 'So then, the question is how do you combine (a) the vector of continuous variables
    and (b) the embeddings from categorical variables? The course didn’t mention anything
    about this but this StackOverflow [post](https://datascience.stackexchange.com/questions/29634/how-to-combine-categorical-and-continuous-input-features-for-neural-network-trai)
    highlights 3 possible ways:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，问题是如何将(a)连续变量的向量和(b)来自分类变量的嵌入结合起来？课程中没有提到这一点，但这个StackOverflow的[帖子](https://datascience.stackexchange.com/questions/29634/how-to-combine-categorical-and-continuous-input-features-for-neural-network-trai)强调了三种可能的方法：
- en: 2 models – one for (a), one for (b). Ensemble them.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2个模型——一个用于(a)，一个用于(b)。将它们进行集成。
- en: 1 model, 1 input. This input is a concatenation between (a) and (b).
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1个模型，1个输入。这个输入是(a)和(b)的连接。
- en: 1 model, 2 inputs. The 2 inputs are (a) and (b). You concatenate these two in
    the model itself.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1个模型，2个输入。这两个输入分别是(a)和(b)。你将这两个输入在模型内部连接起来。
- en: '**d) Collaborative Filtering**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**d) 协同过滤**'
- en: Collaborative filtering is when you’re tasked to predict how much a *user* is
    going to like a certain *item* (in this example, let’s say we’re using movie ratings).
    The course introduced the use **embedding** to solve this. This is my first encounter
    of collaborative filtering using deep learning (as if I had much experience with
    collaborative filtering in the first place)!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤是当你需要预测一个*用户*对某个*项目*的喜好程度时（在这个例子中，我们以电影评分为例）。课程中介绍了使用**嵌入**来解决这个问题。这是我第一次遇到使用深度学习的协同过滤（就像我之前对协同过滤的经验很丰富一样）！
- en: The goal is to create an embedding of size *n* for each user and item. To do
    that, we initialise each embedding vector randomly. Then, for every user rating
    for a movie, we compare it with the dot product of their respective embeddings,
    using MSE, for example. Then we perform gradient descent optimisation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是为每个用户和项目创建大小为*n*的嵌入。为此，我们随机初始化每个嵌入向量。然后，对于每个用户对电影的评分，我们将其与各自嵌入的点积进行比较，例如，使用均方误差（MSE）。接着我们进行梯度下降优化。
- en: '**e) Image Generation**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**e) 图像生成**'
- en: 'Here are some things I learnt:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我学到的一些东西：
- en: ‘**Crappification**’ for generating data, as and how we want them to be. I just
    like this term that was coined.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ‘**劣化**’用于生成数据，按我们希望的方式。这个术语我特别喜欢。
- en: Generative Adversarial Networks (GANs) **hate** **momentum**, so set it to 0.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）**讨厌** **动量**，所以将其设置为0。
- en: It’s hard to know how the model is performing by just looking at losses. One
    must **personally see generated images** from time to time (though the losses
    towards the end should roughly stay the same for both discriminator and generator).
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅仅通过观察损失很难了解模型的表现。必须**亲自查看生成的图像**（尽管在训练结束时，判别器和生成器的损失大致应保持不变）。
- en: One way to improve the quality of the generated image is by including *perceptual
    loss* (AKA **feature loss** in fast.ai) in our loss function. Feature loss is
    computed by taking the values from a tensor somewhere in the middle of the network.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高生成图像质量的一种方法是在我们的损失函数中包含*感知损失*（也称为fast.ai中的**特征损失**）。特征损失通过取网络中间某处张量的值来计算。
- en: '****9\. Model Interpretability****'
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****9. 模型可解释性****'
- en: '![olympics](../Images/c3f4183af3e96ee1b642f3a1fbef6edb.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![奥林匹克](../Images/c3f4183af3e96ee1b642f3a1fbef6edb.png)'
- en: Photo by [Maria Teneva](https://unsplash.com/photos/2Wa88Py0h0A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/search/photos/understand?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Maria Teneva](https://unsplash.com/photos/2Wa88Py0h0A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来自[Unsplash](https://unsplash.com/search/photos/understand?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: In one of the lessons, Jeremy Howard showed an **activation** **heat-map** of
    an image for an image classification task. This heat map displays the pixels that
    were ‘activated’. This kind of visualisation will help us understand what features
    or parts of an image resulted in the outputs of the model ????????.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在其中一节课中，Jeremy Howard展示了一个**激活** **热图**，用于图像分类任务。这个热图显示了被“激活”的像素。这种可视化将帮助我们理解哪些特征或图像的部分导致了模型的输出???????。
- en: '**10\. Appendix: Jeremy Howard on Model Complexity & Regularisation**'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**10. 附录：Jeremy Howard谈模型复杂度与正则化**'
- en: '![olympics](../Images/a55d90113349f5f117b3a1ddbe9b6113.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![奥林匹克](../Images/a55d90113349f5f117b3a1ddbe9b6113.png)'
- en: Photo by [NEW DATA SERVICES](https://unsplash.com/photos/UO-QYR28hS0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/search/photos/dialogue?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[NEW DATA SERVICES](https://unsplash.com/photos/UO-QYR28hS0?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来自[Unsplash](https://unsplash.com/search/photos/dialogue?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: I transcribed this part of the course (Lesson 5) because the intuition is just
    so compelling ❤️. Here Jeremy first rounds up people who think that increasing
    model complexity is not the way to go, then reshapes their perspective, then brings
    them to [**L2 regularisation**](https://en.wikipedia.org/wiki/Regularization_%28mathematics%29).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我转录了这部分课程（第5课），因为直觉实在太引人入胜了❤️。这里Jeremy首先总结了那些认为增加模型复杂度不是解决办法的人的观点，然后改变了他们的看法，接着带他们了解[**L2正则化**](https://en.wikipedia.org/wiki/Regularization_%28mathematics%29)。
- en: Oh and I was from Statistics so he caught me off guard there ????.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，我以前学的是统计学，所以他在这方面让我措手不及????。
- en: And so if any of you are unlucky enough to have been brainwashed by a background
    in statistics or psychology or econometrics or any of these kinds of courses,
    you’re gonna have to unlearn the idea that you need less parameters because what
    you instead need to realise this is you will fit this lie that you need less parameters
    because it’s a convenient fiction for the real truth which is you don’t want your
    function be too complex. And having less parameters is one way of making it less
    complex.
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以，如果你们中的任何人不幸地被统计学、心理学、计量经济学或类似课程的背景洗脑了，你们需要重新认识你们需要更少参数的想法，因为你们实际上需要意识到的是，你们会适应这种谎言，即你们需要更少的参数，因为这是一个方便的虚构，真实的情况是你们不希望你的函数过于复杂。而拥有更少的参数是使其不那么复杂的一种方式。
- en: ''
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But what if you had a thousand parameters and 999 of those parameters were 1e-9\.
    Or what if there was 0? If there’s 0 then they’re not really there. Or if they’re
    1e-9, they’re hardly there.
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但是如果你有一千个参数，其中999个参数是`1e-9`呢？或者如果有0呢？如果是0，那它们实际上并不存在。或者如果它们是`1e-9`，那它们几乎也不存在。
- en: ''
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So why can’t I have lots of parameters if lots of them are really small? And
    the answer is you can. So this thing, [where] counting the number of parameters
    is how we limit complexity, is actually extremely limiting. It’s a fiction that
    really has a lot of problems, right? And so, if in your head complexity is scored
    by how many parameters you have, you’re doing it all wrong. Score it properly.
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么如果很多参数都非常小，我为什么不能有很多参数呢？答案是你可以。实际上，用[参数数量]来限制复杂性的做法是极其有限的。这是一个有很多问题的虚构方法，对吧？因此，如果在你脑海中复杂性是通过参数数量来衡量的，那你是完全错误的。要正确地衡量它。
- en: ''
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So why do we care? Why would I want to use more parameters?
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么我们为什么在乎呢？我为什么要使用更多的参数？
- en: ''
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Because more parameters means more nonlinearities, more interactions, more curvy
    bits, right? And real life (of loss landscape) is full of curvy bits. Real life
    does not look like this [under fitted line]. But we don’t want them to be more
    curvy than necessary, or more interacting than necessary.
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 因为更多的参数意味着更多的非线性、更复杂的交互、更曲折的部分，对吧？而现实生活（损失景观）充满了曲折的部分。现实生活并不像这个[欠拟合的直线]。但我们不希望它们比必要的更加曲折，或更多地交互。
- en: ''
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So therefore let’s use lots of parameters and then penalise complexity.
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以我们使用大量参数，然后惩罚复杂性。
- en: ''
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Okay so one way to penalise complexity is, as I kind of suggested before: Let’s
    sum up the value of your parameters. Now that doesn’t quite work because some
    parameters are positive and some are negative, right? So what if we sum up the
    square of the parameters.'
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 好的，一种惩罚复杂性的方法是，正如我之前建议的那样：让我们求出参数值的总和。不过这并不完全有效，因为有些参数是正的，有些是负的，对吧？那我们可以求出参数平方的总和。
- en: ''
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And that’s actually a really good idea.
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这实际上是一个非常好的主意。
- en: ''
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s actually create a model and in the loss function we’re gonna add the sum
    of the square of the parameters. Now here’s a problem with that though. Maybe
    that number is way too big and it’s so big that the best loss is to set all of
    the parameters to 0\. Now that would be no good. So actually we wanna make sure
    that doesn’t happen. So therefore let’s not just add the sum of the squares of
    the parameters to the model but let’s multiply that by some number that we choose.
    And that number that we choose in fast is called `wd`.
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 让我们实际创建一个模型，并在损失函数中添加参数平方的总和。不过这里有一个问题。也许那个数字太大，以至于最佳的损失是将所有参数设置为0。那样就不好了。因此，我们实际上希望避免这种情况发生。因此，不仅仅是将参数平方的总和添加到模型中，而是将其乘以我们选择的某个数字。在fastai中，我们选择的那个数字叫做`wd`。
- en: You might also like to check out my article Intuitions on L1 and L2 Regularisation
    how I explain these two regularisation techniques using gradient descent [here](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能也想看看我的文章《L1和L2正则化的直观解释》，我在[这里](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261)解释了这两种正则化技术。
- en: '**Conclusion**'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: 'I really love this course. Here are some reasons why:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我真的很喜欢这门课程。以下是一些原因：
- en: They give intuitions and easy-to-understand explanations.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们提供了直观且易于理解的解释。
- en: They supplement their courses with great resources.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们用很棒的资源来补充他们的课程。
- en: They encourage you to apply deep learning to your respective domains to build
    things.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们鼓励你将深度学习应用到你各自的领域中去构建事物。
- en: They seem like they’re always up to date with interesting and novel publications,
    and incorporate them into the fastai library where appropriate.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们似乎总是跟上有趣且新颖的出版物，并在适当的地方将它们融入fastai库中。
- en: 'They also do a lot of research on deep learning (read: ULMFiT).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们还进行大量关于深度学习的研究（请参阅：ULMFiT）。
- en: They have built a community around the fastai library hence you will get support
    easily.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们围绕fastai库建立了一个社区，因此你将容易获得支持。
- en: Their tips and tricks are good for Kagglers and accuracy-driven modelling.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们的技巧和窍门对Kagglers和以准确性为驱动的建模非常有用。
- en: Looking forward to the next part of the course!
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 期待课程的下一部分！
- en: '**Bio: [Raimi Bin Karim](https://www.linkedin.com/in/raimibkarim/)** is an
    AI Engineer at AI Singapore'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Raimi Bin Karim](https://www.linkedin.com/in/raimibkarim/)** 是AI Singapore的AI工程师'
- en: '[Original](https://towardsdatascience.com/10-new-things-i-learnt-from-fast-ai-v3-4d79c1f07e33).
    Reposted with permission.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/10-new-things-i-learnt-from-fast-ai-v3-4d79c1f07e33)。经许可转载。'
- en: '**Related:**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[fast.ai Deep Learning Part 1 Complete Course Notes](/2018/07/fast-ai-deep-learning-part-1-notes.html)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[fast.ai 深度学习第 1 部分完整课程笔记](/2018/07/fast-ai-deep-learning-part-1-notes.html)'
- en: '[Quick Feature Engineering with Dates Using fast.ai](/2018/03/feature-engineering-dates-fastai.html)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 fast.ai 进行快速特征工程](/2018/03/feature-engineering-dates-fastai.html)'
- en: '[An Overview of 3 Popular Courses on Deep Learning](/2017/10/3-popular-courses-deep-learning.html)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习 3 门热门课程概述](/2017/10/3-popular-courses-deep-learning.html)'
- en: '* * *'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 在稀疏性下的最快速度是多少？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用快速克里金（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何让 Python 代码运行得极快](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
- en: '[Step up your Python game with Fast Python for Data Science!](https://www.kdnuggets.com/2022/06/manning-step-python-game-fast-python-data-science.html)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过快速 Python 提升你的数据科学技能！](https://www.kdnuggets.com/2022/06/manning-step-python-game-fast-python-data-science.html)'
- en: '[Practical Deep Learning from fast.ai is Back!](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Practical Deep Learning from fast.ai 回来了！](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
- en: '[Simple and Fast Data Streaming for Machine Learning Projects](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习项目的简单快速数据流处理](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
