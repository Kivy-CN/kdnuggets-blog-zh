- en: 'MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MiniGPT-4：一种轻量级的 GPT-4 替代方案，增强视觉-语言理解
- en: 原文：[https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html](https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html](https://www.kdnuggets.com/2023/04/minigpt4-lightweight-alternative-gpt4-enhanced-visionlanguage-understanding.html)
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/a8065b229bd81d10ac5915b9cbd4dd3a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4：一种轻量级的 GPT-4 替代方案，增强视觉-语言理解](../Images/a8065b229bd81d10ac5915b9cbd4dd3a.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: We are seeing rapid development of ChatGPT [open-source alternatives](/2023/04/8-opensource-alternative-chatgpt-bard.html),
    but no one is working on the GPT-4 alternative, which provides multimodality.
    GPT-4 is an advanced and powerful multimodal model that accepts images and text
    as input and outputs text response. It can solve complex problems with greater
    accuracy and learn from its mistakes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到 ChatGPT 的 [开源替代品](/2023/04/8-opensource-alternative-chatgpt-bard.html)
    发展迅速，但没有人专注于提供多模态能力的 GPT-4 替代品。GPT-4 是一种先进且强大的多模态模型，能够接受图像和文本输入并输出文本响应。它可以更准确地解决复杂问题并从错误中学习。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业之路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this post, we will learn about MiniGPT-4, an open-source alternative to OpenAI’s
    GPT-4 that can understand both visual and textual context while being lightweight.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将了解 MiniGPT-4，这是一种开源替代品，旨在提供轻量级的视觉和文本理解能力，与 OpenAI 的 GPT-4 类似。
- en: What is MiniGPT-4?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 MiniGPT-4？
- en: Similar to GPT-4, MiniGPT-4 can exhibit detailed image description generation,
    write stories using images, and create a website using the hand-drawn user interface.
    It achieves that by utilization of a more advanced large language model (LLM).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与 GPT-4 类似，MiniGPT-4 能够生成详细的图像描述、使用图像编写故事，以及利用手绘用户界面创建网站。它通过使用更先进的大型语言模型（LLM）来实现这一点。
- en: 'You can experience it yourself by trying out the demo: [MiniGPT-4 - a Hugging
    Face Space by Vision-CAIR](https://huggingface.co/spaces/Vision-CAIR/minigpt4).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过尝试演示来亲身体验：[MiniGPT-4 - 由 Vision-CAIR 提供的 Hugging Face 空间](https://huggingface.co/spaces/Vision-CAIR/minigpt4)。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/e8ba20ea87bdaa0b5c63e9e15eb48ec3.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4：一种轻量级的 GPT-4 替代方案，增强视觉-语言理解](../Images/e8ba20ea87bdaa0b5c63e9e15eb48ec3.png)'
- en: Image by Author | MiniGPT-4 Demo
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | MiniGPT-4 演示
- en: 'The authors of [MiniGPT-4: Enhancing Vision-language Understanding with Advanced
    Large Language Models](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf)
    found that pre-training on raw image-text pairs could produce poor results that
    lack coherency, including repetition and fragmented sentences. To counter this
    issue, they curated a high-quality, well-aligned dataset and fine-tuned the model
    using a conversational template.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[MiniGPT-4：利用先进的大型语言模型增强视觉-语言理解](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf)
    的作者发现，直接在原始图像-文本对上进行预训练可能会产生缺乏连贯性的较差结果，包括重复和断裂的句子。为了解决这个问题，他们策划了一个高质量、良好对齐的数据集，并使用对话模板对模型进行了微调。'
- en: The MiniGPT-4 model is highly computationally efficient, as they have trained
    only a projection layer utilizing approximately 5 million aligned image-text pairs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: MiniGPT-4 模型在计算上非常高效，因为他们仅训练了一个投影层，利用了大约 500 万对对齐的图像-文本对。
- en: How does MiniGPT-4 work?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MiniGPT-4 如何工作？
- en: MiniGPT-4 aligns a frozen visual encoder with a frozen LLM called Vicuna using
    just one projection layer. The visual encoder consists of pretrained ViT and Q-Former
    models that are connected to an advanced Vicuna large language model via a single
    linear projection layer.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: MiniGPT-4 将一个冻结的视觉编码器与一个名为 Vicuna 的冻结 LLM 对齐，使用的只是一个投影层。视觉编码器由预训练的 ViT 和 Q-Former
    模型组成，这些模型通过一个线性投影层与先进的 Vicuna 大型语言模型连接。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/3ffbd6cd020c6ce173649aeaadc957c4.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/3ffbd6cd020c6ce173649aeaadc957c4.png)'
- en: Image by Author | The architecture of MiniGPT-4.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | MiniGPT-4 的架构。
- en: MiniGPT-4 only requires training the linear layer to align the visual features
    with Vicuna. So, it is lightweight, requires less computational resources, and
    produces similar results to GPT-4.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: MiniGPT-4 仅需训练线性层即可将视觉特征与 Vicuna 对齐。因此，它体积小、所需计算资源少，并且产生的结果与 GPT-4 相似。
- en: Results
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: If you look at the official results at [minigpt-4.github.io](https://minigpt-4.github.io/##Results:~:text=of%20MiniGPT%2D4.-,Results,-Acknowledgement),
    you will see that the authors have created a website by uploading the hand-drawn
    UI and asking it to write an HTML/JS website. The MiniGPT-4 understood the context
    and generated HTML, CSS, and JS code. It is amazing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 [minigpt-4.github.io](https://minigpt-4.github.io/##Results:~:text=of%20MiniGPT%2D4.-,Results,-Acknowledgement)
    的官方结果，你会看到作者通过上传手绘 UI 并要求其生成 HTML/JS 网站创建了一个网站。MiniGPT-4 理解了上下文，并生成了 HTML、CSS
    和 JS 代码。这真是令人惊叹。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/b9659591239a34c0a4fd206ffaf4b638.png)![MiniGPT-4: A Lightweight
    Alternative to GPT-4 for Enhanced Vision-language Understanding](../Images/66fe0efa5e05d4ffef73526e5b0bde17.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/b9659591239a34c0a4fd206ffaf4b638.png)![MiniGPT-4: A Lightweight
    Alternative to GPT-4 for Enhanced Vision-language Understanding](../Images/66fe0efa5e05d4ffef73526e5b0bde17.png)'
- en: Image from [minigpt-4.github.io](https://minigpt-4.github.io/##Results:~:text=of%20MiniGPT%2D4.-,Results,-Acknowledgement)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [minigpt-4.github.io](https://minigpt-4.github.io/##Results:~:text=of%20MiniGPT%2D4.-,Results,-Acknowledgement)
- en: They have also shown how you can use the model to generate a recipe by providing
    food images, writing advertisements for the product, describing a complex image,
    explaining the painting, and more.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还展示了如何通过提供食物图像生成食谱、为产品编写广告、描述复杂图像、解释画作等。
- en: Let’s try this on our own by heading to the [MiniGPT-4](https://huggingface.co/spaces/Vision-CAIR/minigpt4)
    demo. As we can see, I have provided the Bing AI-generated image and asked the
    MiniGPT-4 to write a story using it. The result is amazing.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过访问 [MiniGPT-4](https://huggingface.co/spaces/Vision-CAIR/minigpt4) 演示自行尝试。正如我们所见，我提供了
    Bing AI 生成的图像，并要求 MiniGPT-4 使用它编写一个故事。结果令人惊叹。
- en: The story is coherent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 故事是连贯的。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/4100135b4ad29364b00cfea1c211ff08.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/4100135b4ad29364b00cfea1c211ff08.png)'
- en: Image by Author | MiniGPT-4 Demo
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | MiniGPT-4 演示
- en: I wanted to know more, so I asked it to continue writing, and just like an AI
    chatbot, it kept writing the plot.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我想了解更多，因此我让它继续写作，就像一个 AI 聊天机器人一样，它不断编写情节。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/19adcb1a7ff0d2012b34a246a782cabd.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/19adcb1a7ff0d2012b34a246a782cabd.png)'
- en: Image by Author | MiniGPT-4 Demo
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | MiniGPT-4 演示
- en: In the second example, I asked it to help me improve the design of the image
    and then asked it to generate subtitles for the blog using the image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个例子中，我让它帮助我改进图像设计，然后要求它为博客生成图像字幕。
- en: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/9878fc323da686c9292cde6507b7bc2b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![MiniGPT-4: A Lightweight Alternative to GPT-4 for Enhanced Vision-language
    Understanding](../Images/9878fc323da686c9292cde6507b7bc2b.png)'
- en: Image by Author | MiniGPT-4 Demo
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | MiniGPT-4 演示
- en: MiniGPT-4 is amazing. It learns from mistakes and produces high-quality responses.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: MiniGPT-4 真是太棒了。它从错误中学习，并生成高质量的回应。
- en: Limitations
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局限性
- en: MiniGPT-4 has many advanced vision-language capabilities, but it still faces
    several limitations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: MiniGPT-4 具有许多先进的视觉-语言能力，但仍然面临一些局限性。
- en: Currently, the model inference is slow even with high-end GPUs, which can result
    in slow results.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前，即使使用高端 GPU，模型推断仍然很慢，这可能导致结果延迟。
- en: The model is built upon LLMs, so it inherits their limitations like unreliable
    reasoning ability and hallucinating non-existent knowledge.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型基于大型语言模型（LLMs），因此继承了它们的一些局限性，例如推理能力不可靠和产生虚假知识。
- en: The model has limited visual perception and may struggle to recognize detailed
    textual information in images.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型的视觉感知有限，可能难以识别图像中的详细文本信息。
- en: Getting Started
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用
- en: The project comes with training, fine-tuning, and inference of source code.
    It also includes publicly available model weights, dataset, research paper, demo
    video, and link to the Hugging Face demo.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目包括源代码的训练、微调和推理。还包括公开的模型权重、数据集、研究论文、演示视频以及 Hugging Face 演示的链接。
- en: You can start hacking, start fine-tuning the model on your dataset, or just
    experience the model through various instances of the official demo on the official
    page.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以开始编程，开始在你的数据集上微调模型，或者通过官方页面上的各种演示实例体验模型。
- en: '**Official Page:** [minigpt-4.github.io](https://minigpt-4.github.io)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**官方网站：** [minigpt-4.github.io](https://minigpt-4.github.io)'
- en: '**Research Paper:** [MiniGPT-4/MiniGPT_4.pdf](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究论文：** [MiniGPT-4/MiniGPT_4.pdf](https://github.com/Vision-CAIR/MiniGPT-4/blob/main/MiniGPT_4.pdf)'
- en: '**GitHub:** [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GitHub：** [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)'
- en: '**Gradio Demo:** [Demo of MiniGPT-4](https://48da7e23bcadec7551.gradio.live/)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Gradio 演示：** [MiniGPT-4 演示](https://48da7e23bcadec7551.gradio.live/)'
- en: '**Demo Video:** [MiniGPT-4: Enhancing Vision-Language Understanding with Advanced
    Large Language Models](https://www.youtube.com/watch?v=__tftoxpBAw)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**演示视频：** [MiniGPT-4：利用先进的大型语言模型提升视觉-语言理解](https://www.youtube.com/watch?v=__tftoxpBAw)'
- en: '**Model Weights:** [Vision-CAIR/MiniGPT-4](https://huggingface.co/Vision-CAIR/MiniGPT-4)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型权重：** [Vision-CAIR/MiniGPT-4](https://huggingface.co/Vision-CAIR/MiniGPT-4)'
- en: '**Dataset:** [Vision-CAIR/cc_sbu_align](https://huggingface.co/datasets/Vision-CAIR/cc_sbu_align)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集：** [Vision-CAIR/cc_sbu_align](https://huggingface.co/datasets/Vision-CAIR/cc_sbu_align)'
- en: It is the first version of the model. You will see a more improved version in
    the upcoming days, so stay tuned.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是模型的第一个版本。你将在接下来的日子里看到一个更改进的版本，敬请关注。
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证的数据科学专业人士，热衷于构建机器学习模型。目前，他专注于内容创作和撰写有关机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是利用图神经网络为那些挣扎于心理疾病的学生打造一个
    AI 产品。'
- en: More On This Topic
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关内容
- en: '[ChatGLM-6B: A Lightweight, Open-Source ChatGPT Alternative](https://www.kdnuggets.com/2023/04/chatglm6b-lightweight-opensource-chatgpt-alternative.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGLM-6B：一种轻量级、开源的 ChatGPT 替代品](https://www.kdnuggets.com/2023/04/chatglm6b-lightweight-opensource-chatgpt-alternative.html)'
- en: '[Bringing Human and AI Agents Together for Enhanced Customer Experience](https://www.kdnuggets.com/2024/06/softweb/bringing-human-and-ai-agents-together-for-enhanced-customer-experience)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将人类与 AI 代理结合起来提升客户体验](https://www.kdnuggets.com/2024/06/softweb/bringing-human-and-ai-agents-together-for-enhanced-customer-experience)'
- en: '[Alternative Feature Selection Methods in Machine Learning](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的替代特征选择方法](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)'
- en: '[OpenChatKit: Open-Source ChatGPT Alternative](https://www.kdnuggets.com/2023/03/openchatkit-opensource-chatgpt-alternative.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenChatKit：开源 ChatGPT 替代品](https://www.kdnuggets.com/2023/03/openchatkit-opensource-chatgpt-alternative.html)'
- en: '[8 Open-Source Alternative to ChatGPT and Bard](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8 种开源 ChatGPT 和 Bard 替代方案](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)'
- en: '[HuggingChat Python API: Your No-Cost Alternative](https://www.kdnuggets.com/2023/05/huggingchat-python-api-alternative.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingChat Python API：你的无成本替代方案](https://www.kdnuggets.com/2023/05/huggingchat-python-api-alternative.html)'
