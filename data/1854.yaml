- en: 'Introducing Dask for Parallel Programming: An Interview with Project Lead Developer'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Dask 的并行编程：与项目首席开发者的访谈
- en: 原文：[https://www.kdnuggets.com/2016/09/introducing-dask-parallel-programming.html](https://www.kdnuggets.com/2016/09/introducing-dask-parallel-programming.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/09/introducing-dask-parallel-programming.html](https://www.kdnuggets.com/2016/09/introducing-dask-parallel-programming.html)
- en: In the coming weeks, KDnuggets plans on sharing some information and tutorials
    about [Dask](https://github.com/dask/dask).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几周内，KDnuggets 计划分享一些关于 [Dask](https://github.com/dask/dask) 的信息和教程。
- en: 'What is Dask, you ask? From its [documentation](http://dask.pydata.org/en/latest/):'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 是什么，你问？从它的 [文档](http://dask.pydata.org/en/latest/)：
- en: Dask is a flexible parallel computing library for analytics.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Dask 是一个灵活的并行计算库，用于分析。
- en: Is your interest piqued? If you are interested in learning more about a software
    project built for computation and interactive data science which could literally
    help revolutionize the way you perform data processing and parallelize your own
    projects, read the the discussion I had with Matthew Rocklin, lead developer of
    Dask.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你的兴趣被激起了吗？如果你有兴趣了解更多关于一个为计算和交互式数据科学构建的软件项目，这可能会彻底改变你处理数据和并行化自己项目的方式，请阅读我与 Dask
    首席开发者 Matthew Rocklin 的讨论。
- en: '![Matthew Rocklin](../Images/6f5d90ad47d44c38416155cfeab3e476.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![Matthew Rocklin](../Images/6f5d90ad47d44c38416155cfeab3e476.png)'
- en: '**Matthew Mayo: First off, can you give us the one sentence overview of Dask?**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matthew Mayo: 首先，你能给我们一个关于 Dask 的一句话概述吗？**'
- en: '**Matthew Rocklin:** Ha, that''s tough.  Dask is used in a few very different
    ways so we''ll have to be fairly general here.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matthew Rocklin:** 哈，这很难说。Dask 的使用方式非常不同，所以我们必须在这里保持相当通用。'
- en: Dask is a Python library for parallel programming that leverages task scheduling
    for computational problems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 是一个 Python 库，用于并行编程，利用任务调度解决计算问题。
- en: '**It would be easy to draw comparisons with other superficially similar projects.
    What other open source projects do *you* see Dask competing with?**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**很容易与其他表面上类似的项目进行比较。你认为 Dask 主要与哪些开源项目竞争？**'
- en: 'Dask straddles two different groups of "competitor" projects:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 跨越了两个不同的“竞争者”项目群体：
- en: Dynamic task schedulers like AirFlow/Luigi/Celery
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像 AirFlow/Luigi/Celery 这样的动态任务调度器
- en: '"Big Data" analysis frameworks like Hadoop/Spark.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像 Hadoop/Spark 这样的“大数据”分析框架。
- en: 'At its core Dask looks a lot like a tweaked Airflow/Luigi/Celery.  There is
    a central task scheduler that sends jobs (Python functions) out to lots of worker
    processes either on the same machine or on a cluster:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，Dask 看起来很像经过调整的 Airflow/Luigi/Celery。它有一个中央任务调度器，将作业（Python 函数）分发到许多工作进程，无论是在同一台机器上还是在集群上：
- en: '*Worker A, please compute x = f(1), Worker B please compute y = g(2).*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*Worker A，请计算 x = f(1)，Worker B 请计算 y = g(2)。*'
- en: '*Worker A, when g(2) is done please get y from Worker B and compute z = h(x,
    y).*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*Worker A，当 g(2) 完成后，请从 Worker B 获取 y 并计算 z = h(x, y)。*'
- en: Where Dask differs is that while Airflow/Luigi/Celery were primarily designed
    for long-ish running data engineering jobs Dask was designed for computation and
    interactive data science.  We focus less on running jobs regularly (like Airflow)
    or integrating with lots of Data engineering services (like Luigi) and much more
    on millisecond response times, inter-worker data sharing, Jupyter notebook integration,
    etc..  I wouldn't use Dask to do a daily ingest of data, but I would use it to
    design and run algorithms to analyze that data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Dask 的不同之处在于，尽管 Airflow/Luigi/Celery 主要设计用于较长时间运行的数据工程作业，但 Dask 是为计算和交互式数据科学设计的。我们更注重毫秒级响应时间、工作进程间数据共享、Jupyter
    notebook 集成等，而不是定期运行作业（如 Airflow）或与大量数据工程服务集成（如 Luigi）。我不会使用 Dask 进行每日数据摄取，但我会用它来设计和运行分析数据的算法。
- en: On top of this task scheduler we built higher-level array, dataframe, and list
    interfaces that mimic NumPy, Pandas, and Python iterators.  This pushes Dask into
    the space of the popular "Big Data" frameworks like Hadoop and Spark.  The dominance
    of Spark in particular these days is pretty huge, especially in business analytics
    use cases (data ingest, SQL stuff, some light machine learning.)  Most of the
    people who use Dask in these use cases use it either because they want to stay
    in Python, because they love Pandas, or because they were doing things that were
    a bit too complex for Spark, like N-dimensional arrays, or some of the fancier
    Pandas time series functionality.  Dask generally feels a bit lighter weight if
    you're already in Python.  That being said, Spark is way more mature and definitely
    does what it was designed to do very very well.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个任务调度器之上，我们构建了更高层次的数组、数据框和列表接口，这些接口模仿了 NumPy、Pandas 和 Python 迭代器。这将 Dask 推向了类似
    Hadoop 和 Spark 的流行“大数据”框架领域。尤其是 Spark 在今天的主导地位非常巨大，特别是在业务分析用例（数据摄取、SQL 操作、一些轻量级机器学习）中。大多数在这些用例中使用
    Dask 的人，要么是因为他们希望继续使用 Python，要么是因为他们喜欢 Pandas，或者是因为他们在处理一些 Spark 过于复杂的任务，比如 N
    维数组，或一些更高级的 Pandas 时间序列功能。如果你已经在使用 Python，Dask 通常感觉更轻量。然而，Spark 远远更成熟，确实在其设计目的上表现得非常出色。
- en: '![Dask collections, schedulers](../Images/886235e58709b73171859e19b96bbcd7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Dask collections, schedulers](../Images/886235e58709b73171859e19b96bbcd7.png)'
- en: '**What does Dask do better than any other potential solution?**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dask 比其他潜在解决方案做得更好是什么？**'
- en: Well, first, lets say that Dask does lots of things *worse* than other potential
    solutions.  It's not trying to implement SQL or be a parallel database.  It's
    not going to out-compete MPI on super computers.  Nor is it going to out-compete
    your hand-tuned C code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Dask 确实有很多方面做得比其他潜在解决方案*差*。它不试图实现 SQL 或成为一个并行数据库。它不会在超级计算机上超越 MPI。它也不会超越你手工优化的
    C 代码。
- en: Second, lets say how Dask most often gets used.  Most users use Dask.dataframe
    or Dask.bag to analyze directories of CSV or JSON files.  However if Dask disappeared
    today these users would be fine, there are loads of software projects trying to
    solve this problem.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们来看看 Dask 最常被使用的场景。大多数用户使用 Dask.dataframe 或 Dask.bag 来分析 CSV 或 JSON 文件目录。然而，如果
    Dask 今天消失了，这些用户也会没问题，因为有很多软件项目在尝试解决这个问题。
- en: OK, so what's left?  Quite a lot of un-served territory actually.  The people
    for whom Dask is really a life saver are people with custom or irregular computational
    problems that need parallelism.  These are scientists, quants, algorithm developers,
    and a growing contingent of enterprise research groups.  These people have novel
    problems that require them to build their own parallel computing solutions.  The
    core of Dask (the part that looks like Airflow/Luigi/Celery) seems to suit their
    needs well.  They want someone else to handle sockets/threads/resiliency/dat<wbr>a-locality
    for them, but they want to be in charge of everything else at a fairly granular
    level (more granular than map/reduce/groupby).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那剩下的是什么？实际上还有相当多未被服务的领域。Dask 真正为之提供生命救援的，是那些需要并行处理的定制或不规则计算问题的人。这些人包括科学家、量化分析师、算法开发者以及越来越多的企业研究团队。这些人遇到的新问题需要他们构建自己的并行计算解决方案。Dask
    的核心部分（看起来像 Airflow/Luigi/Celery）似乎很好地满足了他们的需求。他们希望其他人处理套接字/线程/弹性/数据本地化，但希望在较为细粒度的层面上（比
    map/reduce/groupby 更细粒度）掌控其他一切。
- en: '**Dask''s interface (for instance, Dask DataFrame, Dask Array, Dask Bag) seems
    incredibly straightforward. What else about Dask do you think makes it attractive
    for potential adopters?**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dask 的接口（例如，Dask DataFrame、Dask Array、Dask Bag）似乎非常简单明了。你认为 Dask 的其他哪些特性使其对潜在用户具有吸引力？**'
- en: Yeah, as you suggest copying the NumPy and Pandas interfaces definitely lowers
    the barrier to entry.  Many people know and love NumPy and Pandas.  This sounds
    silly, but this choice to copy the interface also reduces the amount of time Dask
    developers spend stressing about and bikesheding over API.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，正如你所建议的，复制 NumPy 和 Pandas 接口确实降低了入门的门槛。许多人熟悉并喜爱 NumPy 和 Pandas。这听起来可能有些傻，但选择复制这些接口也减少了
    Dask 开发者在 API 设计上的压力和纠结。
- en: The ease of installation and ability to start immediately on a laptop is a big
    win.  The fact that Dask is a pure Python library that can be installed with standard
    Python package managers and just runs without setup or config files helps with
    a broad class of user.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 安装的便捷性和能够在笔记本电脑上立即启动是一个很大的优势。Dask 是一个纯 Python 库，可以通过标准的 Python 包管理器安装，并且可以直接运行而无需设置或配置文件，这对广泛的用户群体非常有帮助。
- en: Conceptually there is a big leap from "just a library" to "a framework" in people's
    minds.  You can use dask in a way that feels like "just a library" like the multiprocessing
    module, Joblib, or concurrent.futures modules in Python.  Dask was designed to
    be the smallest possible library that would complement the existing PyData ecosystem
    with parallelism.  It was never designed to replace anything.  A lot of the core
    developers of other libraries seem to be buying into it for this reason.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从“仅仅是一个库”到“一个框架”在人们的心中有一个巨大的飞跃。你可以像使用 Python 中的多进程模块、Joblib 或 concurrent.futures
    模块那样使用 Dask，感觉就像“仅仅是一个库”。 Dask 被设计成尽可能小的库，以补充现有的 PyData 生态系统中的并行性。它从未设计成要替代任何东西。很多其他库的核心开发者似乎正因为这个原因而接受它。
- en: Finally, Dask focused the first year of its life on just single machine parallelism. 
    It served the needs of people with "moderately large data" who want to use all
    of the power within their laptop or a heavy workstation.  There is a huge community
    of users, mostly in science and finance, who have "moderately large data" and
    don't want to deal with the separation of running their code on a cluster.  Dask
    was a huge hit with these users early on.  Also, the performance and productivity
    of a single heavy workstation is pretty hard to beat for all but the largest of
    problems.  We've since moved on to distributed systems, but single-machine parallelism
    still accounts for something like 80% of use today.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Dask 在其生命的第一年专注于单机并行性。它满足了那些拥有“中等规模数据”的用户的需求，这些用户希望利用其笔记本电脑或高性能工作站中的所有计算能力。大多数用户来自科学和金融领域，他们有“中等规模数据”，并且不想处理在集群上运行代码的复杂性。Dask
    在这些用户中早期取得了巨大的成功。此外，单台重型工作站的性能和生产力在所有问题中几乎都是难以超越的。我们随后转向了分布式系统，但单机并行性至今仍占用了约 80%
    的使用比例。
- en: '**Could you describe a simple use case for Dask, to give readers something
    to visualize?**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**你能描述一下 Dask 的一个简单用例，以便让读者有个直观的理解吗？**'
- en: I'll give two, one for task scheduling (Airflow-like) and one for big data collections
    (Spark-like)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我会提供两个用例，一个用于任务调度（类似于 Airflow），另一个用于大数据集合（类似于 Spark）。
- en: A hypothetical quality assurance group at an automobile company is looking for
    failures using a combination of collected telemetry data (they collect data from
    hundreds of sensors in each car) and from engineering models about how they think
    their car components function.  Several different researchers in a team are in
    charge of different components of the car, and build custom Python functions to
    model how these components respond to different situations.  Other researchers
    in charge of integrating these components take the models that the previous level
    of component-focused researchers created and combine them to create a complex
    tree of relationships (cars are complex).  They run these models over millions
    of situations coming from their data.  Their aggregate model has tons of parallelism,
    but it's very messy.  They throw all of their functions into Dask which manages
    this parallelism for them, running on their team's laptops during prototyping
    and their cluster when they want to run over the full dataset.  Afterwards they
    generate visual reports, and get together to look at the results.  Based on the
    results the researchers at various parts go away and tweak various parts of their
    models, changing small parts of the Dask graph, rerunning only the parts of the
    computation that were affected.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个汽车公司的质量保证小组正在使用收集到的遥测数据（他们从每辆车上的数百个传感器中收集数据）和关于汽车部件如何运作的工程模型来寻找故障。团队中的多个研究人员负责不同的汽车部件，并构建自定义
    Python 函数来模拟这些部件在不同情况下的响应。其他负责整合这些部件的研究人员则将前一阶段的部件专注研究人员创建的模型结合起来，形成复杂的关系树（汽车是复杂的）。他们对来自数据的数百万种情况运行这些模型。他们的综合模型有大量的并行性，但非常混乱。他们将所有函数都投入
    Dask，由 Dask 管理这些并行操作，在原型开发期间运行在团队的笔记本电脑上，在需要处理完整数据集时运行在集群上。之后，他们生成可视化报告，聚在一起查看结果。根据结果，各部分的研究人员会去调整模型的各个部分，修改
    Dask 图中的小部分，仅重新运行受影响的计算部分。
- en: For big-data collections (array/dataframe/list) lets look at climate science. 
    Climate scientists have data that looks like "the temperature, air pressure, and
    windspeed measured every square kilometer of the Earth, for various altitudes,
    going back fifty years."  They want to sift through this 5D dense data cube, grouping
    it, joining it against other datasets, and reducing it down to aggregates that
    help them answer their research questions.  They use the popular [XArray project](http://xarray.pydata.org/en/stable/) to
    manage their data.  XArray uses NumPy when datasets are small and fit in memory
    (say, 1GB) but switches to Dask.array when datasets grow larger than memory but
    still fit on disk (say 10GB-100GB).  On these larger datasets a full computation
    might take a minute or two (disks are sometimes slow), but the climate scientist
    is happy because they are able to keep working on their laptop, rather than switch
    to a cluster. They now look at finer resolution data that goes back longer in
    time without really worrying about scale, all from their personal machine and
    with the same interface they used before on in-memory data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大数据集合（数组/数据框/列表），让我们来看一下气候科学。气候科学家拥有的数据看起来像是“在地球上每平方公里的温度、气压和风速，涵盖各种高度，回溯五十年”。他们希望在这个5维密集数据立方体中筛选数据，将其分组，与其他数据集进行连接，并将其减少到帮助回答研究问题的汇总数据。他们使用流行的[XArray项目](http://xarray.pydata.org/en/stable/)来管理他们的数据。XArray在数据集较小并适合存储在内存中（例如，1GB）时使用NumPy，但当数据集大于内存但仍适合存储在磁盘上（例如10GB-100GB）时则切换到Dask.array。在这些较大的数据集上，完整的计算可能需要一两分钟（磁盘有时较慢），但气候科学家感到满意，因为他们可以继续在笔记本电脑上工作，而无需切换到集群。他们现在可以查看更高分辨率的数据，这些数据在时间上回溯得更久，而不必真正担心规模，一切都在他们的个人计算机上完成，并且使用之前处理内存数据时相同的接口。
- en: '![Dask logo](../Images/0b8634648f8ce3dace49e6acf212ca23.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Dask logo](../Images/0b8634648f8ce3dace49e6acf212ca23.png)'
- en: '**How did you get involved in Dask development, Matthew?**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**你是如何参与Dask开发的，Matthew？**'
- en: This is actually my full time job.  I work for [Continuum Analytics](https://www.continuum.io/),
    a for-profit company embedded in the open source numeric Python ecosystem.  They're
    a bit like RedHat for numeric Python.  The company has strong incentives to keep
    the open source Python ecosystem strong so they build open source projects that
    fill perceived gaps.  Dask is one of those projects, along with others like [Conda](http://conda.pydata.org/docs/),
    [Numba](http://numba.pydata.org/), and [Bokeh](http://bokeh.pydata.org/en/latest/).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是我的全职工作。我在[Continuum Analytics](https://www.continuum.io/)工作，这是一个嵌入在开源数值Python生态系统中的盈利公司。他们有点像数值Python的RedHat。公司有强烈的动力保持开源Python生态系统的强大，因此他们构建开源项目来填补感知的空白。Dask就是其中一个项目，还有其他项目如[Conda](http://conda.pydata.org/docs/)、[Numba](http://numba.pydata.org/)和[Bokeh](http://bokeh.pydata.org/en/latest/)。
- en: '**What''s the best way to get involved in Dask development, if there are any
    readers so inclined?**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果有读者有兴趣，最好的参与Dask开发的方法是什么？**'
- en: 'The docs are a good start:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 文档是一个很好的起点：
- en: '[http://dask.<wbr>readthedocs.io/en/latest/](http://dask.readthedocs.io/en/latest/)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://dask.<wbr>readthedocs.io/en/latest/](http://dask.readthedocs.io/en/latest/)'
- en: 'There is an issue tracker with a label for Introductory issues:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个问题跟踪器，带有介绍性问题的标签：
- en: '[https://github.com/<wbr>dask/dask/issues](https://github.com/dask/dask/issues)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/<wbr>dask/dask/issues](https://github.com/dask/dask/issues)'
- en: 'I also suggest trying out the quickstart for the distributed scheduler, which
    is a bit more focused on Airflow/Luigi workloads:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我还建议尝试一下分布式调度器的快速入门，它更专注于Airflow/Luigi工作负载。
- en: '[http://distributed.<wbr>readthedocs.io/en/latest/<wbr>quickstart.html](http://distributed.readthedocs.io/en/latest/quickstart.html)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://distributed.<wbr>readthedocs.io/en/latest/<wbr>quickstart.html](http://distributed.readthedocs.io/en/latest/quickstart.html)'
- en: Mostly though the core parts of Dask feel pretty solid at this point.  I'd say
    that the best thing to do now is to use Dask on novel problems and see how they
    can break it.  Every time this happens we learn more about how to perform task
    scheduling better.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，目前Dask的核心部分感觉相当稳固。我认为现在最好的做法是将Dask应用于新问题，看看它们如何被打破。每当发生这种情况，我们都会学习如何更好地执行任务调度。
- en: '**Is there anything else we should know about Dask?**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们还需要了解Dask的其他事项吗？**'
- en: Yeah, people are paying for this stuff now, which is crazy.  Dask is mostly
    grant funded (thanks DARPA and Moore!) but I'm now starting to get e-mails pretty
    regularly from companies asking to pay for the development of particular open
    source features.  Gone is the conversation where we have to convince them that
    open-sourcing the work would be better for everyone. *They* bring it up right
    away.  So if you're into open source software you should be really happy.  And
    if you're a company interested in a flexible distributed computing system in Python,
    you know how to get in contact with me :)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，现在人们都在为这些东西付费，这真是疯狂。 Dask 主要由资助资助（感谢 DARPA 和 Moore！），但我现在开始定期收到来自公司请求支付特定开源功能开发的电子邮件。
    已经不需要我们说服他们开源工作对大家都更好。*他们* 立刻就提出来了。 所以如果你喜欢开源软件，你应该非常高兴。 如果你是对 Python 中灵活分布式计算系统感兴趣的公司，你知道怎么联系我
    :)
- en: '**I want to thank you for your time, Matthew. Your name seems synonymous with
    Dask development on the interwebs, and I''m sure it keeps you busy. We appreciate
    you taking the time to talk with us.**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**我要感谢你的时间，Matthew。你的名字似乎与 Dask 开发在网络上同义，我相信这让你忙碌不已。我们感谢你抽出时间与我们交谈。**'
- en: Heh, that's only because I'm the loudest :)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 呵呵，那只是因为我是最吵的 :)
- en: There are several others without whom Dask would never be where it is today. 
    There are core developers like Jim Crist, Martin Durant, Erik Welch, Masakai Horikoshi,
    Blake Griffith, and about 70 others.  There are developers of other PyData libraries
    like MinRK (Jupyter), Stephan Hoyer (XArray, Pandas), Jeff Reback (Pandas), Stefan
    van der Walt (NumPy, SKImage), Olivier Grisel (SKLearn, Joblib) that collaborate
    heavily to make sure that Dask integrates well with the rest of the Python ecosystem. 
    There are people within Continuum like Ben Zaitlen, Kris Overholt, Daniel Rodriguez,
    and Christine Doig who make sure that systems run smoothly so that development
    happens rapidly.  There are also people who fund Dask's development, like the
    DARPA XData project, the Moore Foundation, and private companies.  These organizations
    make sure that people like me can work on projects like Dask full time; which
    is pretty great!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多其他人，如果没有他们，Dask 绝不会达到今天的地步。 有核心开发者如 Jim Crist、Martin Durant、Erik Welch、Masakai
    Horikoshi、Blake Griffith 和大约 70 位其他人。 还有其他 PyData 库的开发者，如 MinRK（Jupyter）、Stephan
    Hoyer（XArray、Pandas）、Jeff Reback（Pandas）、Stefan van der Walt（NumPy、SKImage）、Olivier
    Grisel（SKLearn、Joblib），他们密切合作，以确保 Dask 能很好地融入 Python 生态系统。 Continuum 中还有 Ben Zaitlen、Kris
    Overholt、Daniel Rodriguez 和 Christine Doig，他们确保系统平稳运行，从而加快开发进程。 还有那些资助 Dask 开发的人，如
    DARPA XData 项目、Moore 基金会和私营公司。 这些组织确保像我这样的人可以全职从事 Dask 项目；这真的很棒！
- en: I'm definitely forgetting several awesome people in that list.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我肯定在那个列表中遗漏了几位了不起的人物。
- en: '**Related**:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容**：'
- en: '[An Introduction to Scientific Python (and a Bit of the Maths Behind It) –
    Matplotlib](/2016/06/intro-scientific-python-matplotlib.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[科学 Python 介绍（及其背后的数学）— Matplotlib](/2016/06/intro-scientific-python-matplotlib.html)'
- en: '[Whitepaper: Big Data Visualization With Datashader](/2016/08/whitepaper-big-data-visualization-datashader.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[白皮书：使用 Datashader 进行大数据可视化](/2016/08/whitepaper-big-data-visualization-datashader.html)'
- en: '[Thinking About Analytics Readiness](/2016/06/thinking-domain-readiness.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析准备的思考](/2016/06/thinking-domain-readiness.html)'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Parallel Processing Large File in Python](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 处理大文件的并行处理](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)'
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，7月20日：机器学习算法解释…](https://www.kdnuggets.com/2022/n29.html)'
- en: '[Parallel Processing in Prompt Engineering: The Skeleton-of-Thought…](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程中的并行处理：思维骨架…](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)'
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 Objectiv：开源产品分析基础设施](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[John Snow Labs 介绍医疗保健专用的大型语言模型](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
- en: '[Introducing OpenChat: The Free & Simple Platform for Building…](https://www.kdnuggets.com/2023/06/introducing-openchat-free-simple-platform-building-custom-chatbots-minutes.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 OpenChat：一个免费且简单的平台，用于在几分钟内构建自定义聊天机器人](https://www.kdnuggets.com/2023/06/introducing-openchat-free-simple-platform-building-custom-chatbots-minutes.html)'
