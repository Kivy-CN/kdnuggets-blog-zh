- en: Model Drift in Machine Learning – How To Handle It In Big Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的模型漂移——如何在大数据中处理
- en: 原文：[https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html](https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html](https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Sai Geetha](https://www.saigeetha.in/about), an expert in Big Data Engineering
    and Data Science**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Sai Geetha](https://www.saigeetha.in/about) 撰写，她是一位大数据工程和数据科学的专家**。'
- en: '![](../Images/ac179ecb1bad142c35e7ed68f869139d.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac179ecb1bad142c35e7ed68f869139d.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The **Rendezvous architecture** proposed by Ted Dunning and Ellen Friedman in
    their book on *Machine Learning Logistics* was a wonderful solution I found for
    a specific architectural problem I was working on. I was looking for a tried and
    tested design pattern or architectural pattern that helps me run Challenger and
    Champion models together in a maintainable and supportable way. The rendezvous
    architecture was significantly more useful in the big data world because you are
    dealing with heavy data and large pipelines.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**约会架构**由 Ted Dunning 和 Ellen Friedman 在他们的《*机器学习物流*》一书中提出，是我为一个特定架构问题找到的一个很好的解决方案。我在寻找一个经过验证的设计模式或架构模式，帮助我以可维护和可支持的方式同时运行挑战者和冠军模型。约会架构在大数据领域特别有用，因为你需要处理大量数据和大型管道。'
- en: The ability to run Challenger and Champion models together on all data is a
    very genuine need in machine learning, where the model performance can drift over
    time and where you want to keep improving on the performance of your models to
    something better always.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据上同时运行挑战者和冠军模型的能力是机器学习中一个非常真实的需求，因为模型性能可能会随着时间的推移而漂移，而你总是希望不断提高模型的性能。
- en: So, before I delve deeper into this architecture, I would like to clarify some
    of the jargon I have used above. What is a Champion model? What is a Challenger
    model? What is model drift, and why does it occur? Then, we can look at the rendezvous
    architecture itself and the problems it solves.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在深入探讨这种架构之前，我想澄清一些我上面使用的术语。什么是冠军模型？什么是挑战者模型？什么是模型漂移，它为什么会发生？然后，我们可以查看约会架构本身及其解决的问题。
- en: Model Drift
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型漂移
- en: Once you put your model into production, assuming it will always perform well
    is a mistake. In fact, it is said - "**The moment you put a model into production,
    it starts degrading**." (*Note, most often '**performance**' in ML is used to
    mean statistical performance -- be it accuracy, precision, recall, sensitivity,
    specificity or whatever the appropriate metric is for your use case*).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你将模型投入生产，假设它会一直表现良好是一个错误。事实上，常说 - "**你将模型投入生产的那一刻，它就开始退化**。" (*注意，在机器学习中，'**性能**'通常指统计性能——无论是准确度、精确度、召回率、敏感度、特异性还是适用于你的用例的其他度量标准*)。
- en: Why does this happen? The model is trained on some past data. It performs excellently
    for any data with the same characteristics. However, as time progresses, the actual
    data characteristics can keep changing, and the model is not aware of these changes
    at all. This causes model drift, i.e., degradation in model performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会发生这种情况？模型是在一些过去的数据上训练的。它对具有相同特征的数据表现出色。然而，随着时间的推移，实际数据特征可能不断变化，而模型对此完全没有意识。这会导致模型漂移，即模型性能的下降。
- en: For example, you trained a model to detect spam mail versus ham mail. The model
    performs well when deployed. Over time, the types of spam keep morphing, and hence
    the accuracy of the prediction comes down. This is called **model drift**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你训练了一个模型来检测垃圾邮件和正常邮件。模型在部署时表现良好。随着时间的推移，垃圾邮件的类型不断变化，从而导致预测准确性下降。这被称为**模型漂移**。
- en: The model drift could happen because of a **concept drift** or a **data drift.**
    I am not getting into these today, so it will suffice us to understand that the
    performance of a model does not remain constant. Hence we need to continuously
    monitor the performance of a model. Most often, it is best to retrain the model
    with fresher data more frequently or probably based on a threshold level in performance
    degradation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 模型漂移可能是由于**概念漂移**或**数据漂移**引起的。我今天不深入探讨这些，所以我们只需了解模型的性能不会保持不变。因此，我们需要持续监控模型的性能。通常情况下，最好是用更新的数据更频繁地重新训练模型，或者可能根据性能退化的阈值进行调整。
- en: Sometimes, even retraining the model does not improve the performance further.
    This would imply that you might have to understand the changes in the characteristics
    of the problem and go through the whole process of data analysis, feature creation,
    and model building with more appropriate models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，即使重新训练模型也无法进一步提高性能。这意味着你可能需要了解问题特征的变化，并通过更合适的模型进行数据分析、特征创建和模型构建的整个过程。
- en: This cycle can be shortened if you can work with Challenger models even while
    we have one model in production currently. This is a continuous improvement process
    of machine learning and is very much required.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能在当前生产中有一个模型的同时使用 Challenger 模型，那么这个周期可以缩短。这是一个持续改进的机器学习过程，非常必要。
- en: Champion-Challenger Models
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Champion-Challenger 模型
- en: Typically, the model in production is called the **Champion** model. And any
    other model that seems to work well in your smaller trials and is ready for going
    into production is a **Challenger** model. These Challenger models have been proposed
    because we assume there is a chance that they perform better than the Champion
    model. But how do we prove it?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，生产中的模型被称为**Champion**模型。任何在较小试验中表现良好并准备投入生产的模型都是**Challenger**模型。提出这些 Challenger
    模型是因为我们假设它们有可能比 Champion 模型表现更好。但是我们如何证明这一点呢？
- en: A Champion model typically runs on all the incoming data to provide the predictions.
    However, on what data does the Challenger model run?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Champion 模型通常在所有进入的数据上运行以提供预测。然而，Challenger 模型在什么数据上运行？
- en: There are two ways that the Challenger models can be tested. The ideal case
    would be to run the Challenger model in parallel with the Champion model on all
    data and compare the results. This would truly prove the Challenger model can
    perform better or not. However, this seems prohibitive, especially in the big
    data world, and hence the Challenger is always trialed out on a subset of the
    incoming data. Once that seems to perform well, it is gradually rolled out to
    more and more data, almost like alpha-beta testing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Challenger 模型可以通过两种方式进行测试。理想的情况是将 Challenger 模型与 Champion 模型在所有数据上并行运行并比较结果。这将真正证明
    Challenger 模型是否表现更好。然而，在大数据的世界里，这似乎不可行，因此 Challenger 模型总是先在一部分新数据上进行试验。一旦表现良好，它将逐渐扩展到更多的数据上，几乎就像是
    alpha-beta 测试。
- en: As you might be aware, in alpha-beta testing, a small percentage of users or
    incoming data, in this case, is sent through a new test or Challenger pipeline,
    and the rest all go through the original Champion pipeline. This kind of alpha-beta
    testing is good for some applications but clearly not very impressive in the world
    of machine learning. You are not comparing the models on the same data and hence
    can rarely say with confidence that one is better than the other for the whole
    data. There could be lurking surprises once you roll it out for all data, and
    the model drift can start sooner than expected.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，在 alpha-beta 测试中，一小部分用户或进入的数据会通过新的测试或 Challenger 管道，其余的数据则通过原始的 Champion
    管道。这种 alpha-beta 测试对某些应用来说是有效的，但在机器学习的世界里显然不是很令人印象深刻。你没有在相同的数据上比较模型，因此很难自信地说一个模型比另一个模型更适合全部数据。一旦全面推出，可能会出现意外情况，模型漂移可能比预期更早开始。
- en: 'A typical alpha-beta pipeline would look like this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的 alpha-beta 管道如下：
- en: '![](../Images/815ebfe995cca0d92ee17be5ae9b10ca.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/815ebfe995cca0d92ee17be5ae9b10ca.png)'
- en: The data is split between the two pipelines based on some criteria, like the
    category of a product. This data split keeps increasing towards Challenger as
    the confidence in the performance of the Challenger model grows.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据根据一些标准，如产品类别，分配到两个管道中。这种数据分割会随着对 Challenger 模型性能信心的增加而不断扩大。
- en: From a data scientist's perspective, this is not ideal. The ideal would be to
    be able to run the Challenger model in parallel for **all the data** along with
    the Champion model. As I earlier said, this is very expensive.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学家的角度来看，这并不理想。理想的情况是能够与 Champion 模型一起并行运行**所有数据**的 Challenger 模型。正如我之前所说，这非常昂贵。
- en: Consider the worst-case scenario. If you want them to run in parallel, you have
    to set up two data pipelines that run through all the steps independently.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑最坏情况。如果你希望它们并行运行，你必须建立两个数据管道，这些管道独立完成所有步骤。
- en: 'It would look something like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来像这样：
- en: '![](../Images/79af4a7798d8a039595f6e3b3d2a5d9b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79af4a7798d8a039595f6e3b3d2a5d9b.png)'
- en: This has huge engineering implications and, hence, time to market implications.
    The cost of this can get prohibitive over time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这具有巨大的工程影响，因此也有市场时间的影响。随着时间的推移，成本可能会变得过高。
- en: A few of the top implications are the time and effort in building these pipelines
    over and over again without being sure if the Challenger model is indeed going
    to perform as expected. The CI/CD process, the deployments, the monitoring, authentication
    mechanisms, etc., are a few to mention. In addition, the other cost is around
    the infrastructure that has to be doubly provisioned.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一些主要影响包括不断构建这些管道的时间和精力，而不确定 Challenger 模型是否真的会按预期执行。CI/CD 过程、部署、监控、认证机制等都是其中的一部分。此外，另一个成本是基础设施的双重配置。
- en: Considering if these pipelines are big data pipelines, it becomes all the more
    significant. Very soon, you realise that this is not a scalable model. We certainly
    have to see how we can move away from parallel pipelines or even from the alpha-beta
    testing method.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些管道是大数据管道，情况会更加重要。你很快会意识到这不是一个可扩展的模型。我们确实需要看看如何摆脱并行管道，甚至是 alpha-beta 测试方法。
- en: As a corollary, the best-case scenario would be when we can reuse much of the
    data pipelines. The idea is to minimize the amount one has to develop and deploy
    again into production. This would also ensure optimization of infrastructure usage.
    This is one line of thinking about how to optimize.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作为推论，最佳情况是我们可以重复使用大量数据管道。这个想法是最小化需要重新开发和部署到生产中的部分。这也将确保基础设施使用的优化。这是优化的一种思路。
- en: Even better would be to be able to just **plug in the Challenger model,** and
    the rest of the pipeline plays as if nothing has changed. Wouldn't that be fantastic?
    And this is what is made possible by the **Rendezvous architecture.**
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是能够**插入 Challenger 模型，**其余的管道表现得像什么都没改变一样。这不是很棒吗？这正是**Rendezvous 架构**所实现的。
- en: Rendezvous Architecture
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Rendezvous 架构
- en: 'The Rendezvous architecture, as written in the book, is tilted towards ML with
    smaller data. I have tweaked it to meet the needs of the big data world and associated
    pipelines as shown in the diagram below: *(References to the book and another
    article are given below in the references section)*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如书中所述，Rendezvous 架构倾向于处理较小数据的机器学习。我对它进行了调整，以满足大数据世界及相关管道的需求，如下图所示：*(书籍和另一篇文章的参考文献见参考部分)*
- en: '![](../Images/64f95c58d6146d8d3da9b7dea09f8ef5.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64f95c58d6146d8d3da9b7dea09f8ef5.png)'
- en: Let me now explain section by section of this architecture.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我逐部分解释这个架构。
- en: '**Part 1:**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**第1部分：**'
- en: This consists of the standard data pipeline for receiving incoming data, cleansing
    it, preparing it, and creating the required features. This should be just one
    pipeline for every model that is to be deployed. The prepared data should maintain
    a standard interface that has all the features that may be required in that domain
    irrespective of the model on hand. (*I understand this is not always possible
    and may need tweaking piecemeal over time. But we can deal with that piece in
    isolation when required.*)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括标准的数据管道，用于接收传入数据、清洗数据、准备数据和创建所需的特征。每个要部署的模型应仅有一个这样的管道。准备好的数据应保持一个标准接口，具有该领域所需的所有特征，而不论当前模型如何。(*我理解这并不总是可能的，可能需要随时间进行局部调整。但我们可以在需要时单独处理那部分。*)
- en: '**Part 2:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**第2部分：**'
- en: This is a messaging infrastructure like Kafka that comes into play by bringing
    in the sense of asynchronicity. The data that is prepared as features are published
    onto the message bus. Now, every model listens to this message bus and triggers
    off, executing itself with the prepared data. This message bus is what enables
    a plug-and-play architecture here.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种类似于Kafka的消息基础设施，通过引入异步性来发挥作用。准备好的特征数据被发布到消息总线中。现在，每个模型都监听这个消息总线，并根据准备好的数据触发执行。这个消息总线就是使得这里实现即插即用架构的关键。
- en: '**Part 3:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**第3部分：**'
- en: This is the part where all models are deployed one by one. A new Challenger
    model can be deployed and made to listen to the message bus, and as data flows
    in, it can execute. Any number of models can be deployed here and not just one
    Challenger model! Also, the infra requirement is only for the extra model to run.
    Neither the pre-model pipelines nor the post-model pipelines need to be separately
    developed or deployed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是所有模型逐一部署的部分。新的挑战者模型可以被部署并监听消息总线，当数据流入时，它可以执行。这里可以部署任意数量的模型，而不仅仅是一个挑战者模型！此外，基础设施要求仅仅是额外模型的运行。既无需单独开发预处理模型管道，也无需单独开发后处理模型管道。
- en: As you can see in the figure, you can have many challenger models as long as
    the data scientist sees them mature enough to be tested against real data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如图中所示，只要数据科学家认为这些挑战者模型足够成熟以进行实际数据测试，就可以拥有多个挑战者模型。
- en: Also, there is a special model called the decoy model. In order to ensure that
    each of the model processes is not burdened with persistence, the prepared data
    is also read by what is called a **decoy model,** whose only job is to read the
    prepared data and persist. This helps for audit purposes, tracing, and debugging
    when required.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，还有一个特殊的模型叫做诱饵模型。为了确保每个模型处理过程不被持久化负担所困扰，准备好的数据也会被所谓的**诱饵模型**读取，该模型的唯一工作就是读取准备好的数据并进行持久化。这有助于审计、追踪和在需要时进行调试。
- en: '**Part 4:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**第4部分：**'
- en: All these models again output their predictions or scores into another message
    bus, thus not bringing any dependency between themselves. Also, again this plays
    an important role in ensuring the pluggability of a model without disrupting anything
    else in the pipeline.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些模型再次将其预测或分数输出到另一个消息总线，从而不会在它们之间产生任何依赖关系。此外，这也在确保模型的可插拔性方面发挥了重要作用，而不会破坏管道中的其他内容。
- en: From there, the rendezvous process picks up the scores and decides what needs
    to be done, as described in Part 5.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，接头过程获取分数并决定需要做什么，正如第5部分所描述的。
- en: '**Part 5:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**第5部分：**'
- en: This is where the new concept of a **Rendezvous process** is introduced, which
    has two important sub-processes. One immediate subprocess takes care of streaming
    out the correct output from the pipeline for a consumer from among the many scores
    it has received, and the other process is to persist the output from all models
    for further comparison and analysis.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，引入了**接头过程**的新概念，该过程有两个重要的子过程。一个即时子过程负责从接收到的多个分数中，为消费者流出正确的输出，而另一个过程是持久化所有模型的输出，以便进行进一步的比较和分析。
- en: 'So, we have achieved two things here:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在这里实现了两个目标：
- en: The best output is provided to the consumer.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最佳输出提供给消费者。
- en: All the data has gone through all the models, and hence they are totally comparable
    in like circumstances on their performance.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有的数据都经过了所有模型，因此它们在类似情况下的性能是完全可以比较的。
- en: How does it decide which model's output should be sent out? This can be based
    on multiple criteria like a subset of data should always be from Challenger, and
    another subset should always be from Champion. This is almost like achieving the
    alpha-beta testing. However, the advantage here is that while it sounds like alpha-beta
    testing for a consumer, for the data scientist, all data has been through both
    the models and so they can compare the two outputs and understand which is performing
    better.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如何决定应该发送哪个模型的输出？这可以基于多个标准，例如数据的一个子集应始终来自挑战者，另一个子集应始终来自冠军。这几乎像是在进行alpha-beta测试。然而，优势在于，尽管对消费者来说这听起来像是alpha-beta测试，但对数据科学家而言，所有数据都经过了这两个模型，因此他们可以比较两个输出并了解哪个表现更好。
- en: Another criterion could be that the output should be based on model performance.
    In this case, the rendezvous process waits for all models to complete and publish
    to the message bus. Then, it seeks the best performance metric and sends out that
    as the result.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个标准可能是输出应基于模型性能。在这种情况下，汇合过程会等待所有模型完成并发布到消息总线，然后它会寻找最佳性能指标并将其作为结果发送出去。
- en: Yes, another criterion can be that of time or latency. If we need to have the
    result in, say, less than 5 seconds, for example, the process waits for all the
    results from models, up to 5 seconds, compares only those, and returns the best
    data. Even though another model comes back in the 6th second that may have performed
    much better, that is ignored as it does not meet the latency criteria.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，另一个标准可以是时间或延迟。例如，如果我们需要在不到5秒的时间内得到结果，过程会等待所有模型的结果，最多5秒，比较这些结果并返回最佳数据。即使另一个模型在第6秒返回并且表现更好，它也会被忽略，因为它不符合延迟标准。
- en: But how does this process know what is the criteria to follow for which data
    or which model? This can be put in as part of the input data into the message
    bus in Part 2\. Note that the Rendezvous process is also listening to these messages
    and gets to know what to do with the output that corresponds to an input. There
    could be other clever ways too, but this is one of the ways proposed.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但这个过程如何知道对哪个数据或哪个模型遵循什么标准？这可以作为输入数据的一部分放入消息总线中。请注意，汇合过程也在监听这些消息，并了解如何处理与输入对应的输出。还有其他聪明的方式，但这是提出的其中一种方法。
- en: Conclusion
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: By introducing asynchronicity through message buses, a level of decoupling has
    been introduced, bringing in the ability to plug-and-play models into an otherwise
    rigid data pipeline.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过消息总线引入异步性，带来了一个解耦的层次，使得在原本僵化的数据管道中可以实现模型的即插即用。
- en: By introducing the rendezvous process, the ability to select between various
    model outputs, persist them, compare them were all introduced. And with this,
    it now does not seem a herculean task to introduce or support any number of new
    models for the same data set.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入汇合过程，选择不同模型输出、持久化它们、比较它们的能力都得到了引入。有了这一点，为同一数据集引入或支持任意数量的新模型似乎不再是难以完成的任务。
- en: '**Summary**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**'
- en: The rendezvous architecture gives great flexibility at various levels.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 汇合架构在各个层次上提供了极大的灵活性。
- en: A variety of criteria can be used to decide what score, output, or prediction
    can be sent out of the prediction process. These criteria could be latency-based,
    model performance-based, or simple time-based.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用各种标准来决定预测过程中可以发送的分数、输出或预测。这些标准可以是基于延迟的、基于模型性能的或简单的时间基准。
- en: It provides the ability to define and change these criteria dynamically through
    the rendezvous process. You can take it to another level by introducing a rule
    engine here.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它提供了通过汇合过程动态定义和更改这些标准的能力。你可以通过引入规则引擎将其提升到另一个层次。
- en: It provides the ability to make all the data go through all the pipelines or
    choose only a subset to go through many pipelines. For example, if you have grocery
    and general merchandising products for which you are forecasting, groceries could
    go through their own Champion and Challenger models, while general merchandise,
    which are typically slow sellers, can have their own pipelines.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它提供了让所有数据通过所有管道的能力，或者仅选择子集通过多个管道。例如，如果你有超市和一般商品的预测，超市产品可以通过它们自己的冠军和挑战者模型，而通常慢销的通用商品可以有自己的管道。
- en: It also provides the ability to run many models at a time without redeveloping
    or redeploying a large part of a big data pipeline. Apart from effort and time
    savings, the infrastructure costs are also optimised.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它还提供了同时运行多个模型的能力，而无需重新开发或重新部署大部分大数据管道。除了节省努力和时间，基础设施成本也得到了优化。
- en: References
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Machine Learning Logistics](https://learning.oreilly.com/library/view/machine-learning-logistics/9781491997628/)
    by Ted Dunning; Ellen Friedman - 3rd Chapter on "The Rendezvous Architecture for
    Machine Learning"'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[机器学习物流](https://learning.oreilly.com/library/view/machine-learning-logistics/9781491997628/)
    作者：Ted Dunning；Ellen Friedman - 第三章《机器学习的汇合架构》'
- en: An article on [towardsdatascience.com](http://towardsdatascience.com/), "[Rendezvous
    Architecture for Data Science in Production](https://towardsdatascience.com/rendezvous-architecture-for-data-science-in-production-79c4d48f12b)"
    by Jan Teichmann
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文章来自 [towardsdatascience.com](http://towardsdatascience.com/)，标题为"[数据科学生产中的相遇架构](https://towardsdatascience.com/rendezvous-architecture-for-data-science-in-production-79c4d48f12b)"，作者为
    Jan Teichmann
- en: '[Original](https://www.saigeetha.in/post/machine-learning-rendezvous-architecture).
    Reposted with permission.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.saigeetha.in/post/machine-learning-rendezvous-architecture)。经许可重新发布。'
- en: '**Bio:** [Sai Geetha](https://www.linkedin.com/in/saigeethamn/) ([@saigeethamn](https://twitter.com/saigeethamn))
    is an architect with experience in creating strategic roadmaps and innovating
    based on the enterprise needs and leading technologies. A Big Data specialist
    with Data Science knowledge who can bridge the gap between the two worlds and
    bring success to any large data initiative in your enterprise.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：** [Sai Geetha](https://www.linkedin.com/in/saigeethamn/) ([@saigeethamn](https://twitter.com/saigeethamn))
    是一位架构师，拥有创建战略路线图和基于企业需求及领先技术进行创新的经验。作为一名具有数据科学知识的大数据专家，能够弥合这两个领域之间的差距，为您的企业中的大型数据项目带来成功。'
- en: '**Related:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Good-bye Big Data. Hello, Massive Data!](https://www.kdnuggets.com/2020/10/sqream-massive-data.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[再见，大数据。你好，海量数据！](https://www.kdnuggets.com/2020/10/sqream-massive-data.html)'
- en: '[The Ultimate Guide to Model Retraining](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型再训练的终极指南](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)'
- en: '[The Hidden Risk of AI and Big Data](https://www.kdnuggets.com/2019/09/risk-ai-big-data.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 和大数据的隐藏风险](https://www.kdnuggets.com/2019/09/risk-ai-big-data.html)'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Eurybia 检测数据漂移以确保生产 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[Managing Model Drift in Production with MLOps](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 MLOps 管理生产中的模型漂移](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
- en: '[KDnuggets News, August 31: The Complete Data Science Study Roadmap…](https://www.kdnuggets.com/2022/n35.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8月31日：完整的数据科学学习路线图……](https://www.kdnuggets.com/2022/n35.html)'
- en: '[7 Techniques to Handle Imbalanced Data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理不平衡数据的 7 种技术](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
- en: '[How to Handle Missing Data with Scikit-learn''s Imputer Module](https://www.kdnuggets.com/how-to-handle-missing-data-with-scikit-learns-imputer-module)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Scikit-learn 的 Imputer 模块处理缺失数据](https://www.kdnuggets.com/how-to-handle-missing-data-with-scikit-learns-imputer-module)'
- en: '[Masked Arrays in NumPy to Handle Missing Data](https://www.kdnuggets.com/masked-arrays-in-numpy-to-handle-missing-data)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NumPy 中的掩码数组以处理缺失数据](https://www.kdnuggets.com/masked-arrays-in-numpy-to-handle-missing-data)'
