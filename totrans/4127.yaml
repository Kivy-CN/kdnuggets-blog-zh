- en: Find a Picture in an Image Without Marking it Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/09/find-picture-image-without-marking.html](https://www.kdnuggets.com/2022/09/find-picture-image-without-marking.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/c8e88b597a7b216d33b872bae4f8a214.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author | Edited by Editor
  prefs: []
  type: TYPE_NORMAL
- en: 'We often see pictures in images: comics, for example, combine several pictures
    into one. And if you have an entertainment app where people post memes, like in
    our iFunny, you''re going to run into that all the time. Neural networks are already
    capable of finding animals, people, or other objects, but what if we need to find
    but another image in the image? Let''s take a closer look at our algorithm so
    that you can test it with [a notebook](https://colab.research.google.com/drive/1u42OGNz4OEZCb7RakFhw6TETWpLCG3sb?usp=sharing)
    in Google Colaboratory and even implement it in your project.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, memes. Many of them consist of a picture and its caption, with the former
    serving as the context to the verbal joke:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/9aa85b245aa2501e310b9c303a932d6e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A meme can include several images with text:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/221b84c117a986122e16da9fc4b989b1.png)'
  prefs: []
  type: TYPE_IMG
- en: One of the popular types of memes is screenshots of social network posts e.g.
    from Twitter. The picture occupies a relatively small area in them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/faab49e34222707e3e662b92e57e6c00.png)'
  prefs: []
  type: TYPE_IMG
- en: Initially, the task of finding a picture in the image came up when we were sending
    push notifications. Before the advent of full-page push messages on Android, all
    the pictures in such messages were very small. The text was unreadable (Why would
    the user need it then?), and all the objects in the notification image were hardly
    informative. They were also less attractive.
  prefs: []
  type: TYPE_NORMAL
- en: We decided to bet on pictures from memes. To increase the visual part, we made
    an algorithm that cuts out all the frames around the image, regardless of what
    is shown on it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see the algorithm in action on a few examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here''s how the algorithm handled the black background and the app watermark:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/9aa85b245aa2501e310b9c303a932d6e.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/6f80913f6e05d01a8f9123ed967679d6.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following example, it did not separate the images, even though there
    was a large line between them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/af311ed5f6a73eea5c7fe0dd7d1dccc1.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/181c8402915f6cdc65961e90522a56ea.png)'
  prefs: []
  type: TYPE_IMG
- en: This method is also suitable for large vertical text, which occupies about 50%
    of the area of the entire image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/221b84c117a986122e16da9fc4b989b1.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/1f277aa6d4cc39e6d06c80e8feb20a62.png)'
  prefs: []
  type: TYPE_IMG
- en: '*However, the algorithm missed the application watermark (there is still work
    to be done).*'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm handled the following example with flying colors, even though
    the desired image occupied a relatively small percentage of the meme. The algorithm
    also trimmed the white frames on the sides.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/faab49e34222707e3e662b92e57e6c00.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/83034fad8066afe3ff6b39e0a915cfb5.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next example, there were two backgrounds at once (white and black), but
    the algorithm coped with this. However, it left the white frames on the sides.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/70bdcaa9b72cff3264fadf36ae2bce1f.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/2ec933a697142f461d77b86f81f04bd9.png)'
  prefs: []
  type: TYPE_IMG
- en: The last example is particularly interesting because the image itself contains
    many lines. But even this did not confuse our algorithm. The upper boundary is
    a little bigger than we wanted it to be, but it's a great result for such a difficult
    case!
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/5431b4496b7a25f47b04adebff729b34.png)
    ![Find a Picture in an Image Without Marking it Up](../Images/15a5f532b42c120e31830db9b0100f5b.png)'
  prefs: []
  type: TYPE_IMG
- en: Recall that it was possible to achieve these results without markup.
  prefs: []
  type: TYPE_NORMAL
- en: The Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's skip the uninformative parts of the code. You can find and run them yourself
    in the full [implementation](https://colab.research.google.com/drive/1u42OGNz4OEZCb7RakFhw6TETWpLCG3sb?usp=sharing)
    of the algorithm. In this article, we will focus only on the main idea.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take this image with the puppies as an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/2dd41777378e3e81cab6cffd74e02b75.png)'
  prefs: []
  type: TYPE_IMG
- en: It has text at the top and a small strip of white background along with a watermark
    of our application at the bottom.
  prefs: []
  type: TYPE_NORMAL
- en: To get just the picture with the puppies, we need to remove the two horizontal
    rectangles at the bottom and top. The basic idea is to recognize all the straight
    lines with the image using the [Hough Transform](https://en.wikipedia.org/wiki/Hough_transform)
    and then select those that border a white or black monotone area, which we will
    consider the background.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1\. Conversion of the image to Grayscale
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step of image processing here is converting it to a monochrome format.
    There are many ways to do this, but I prefer getting the L-channel (lightness)
    in the [Lab](https://en.wikipedia.org/wiki/CIELAB_color_space) color space. This
    approach has proven to be the best in most cases. But you can try other approaches,
    say the V-channel (value) of the [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV)
    color space.
  prefs: []
  type: TYPE_NORMAL
- en: To eliminate the sharp contrast differences that create unnecessary lines in
    the image, we apply the Gaussian filter to the resulting black-and-white image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here we used functions from the OpenCV library. In addition to the image, the
    cv2.GaussianBlur function accepts the Gaussian kernel size (width, height) and
    the standard deviation along the X axis (along the Y axis, it is 0 by default).
    When using 0 as the standard deviation, it is [calculated](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa)
    based on the size of the kernel. The parameters we use are based on subjective
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/99abc872fafeeb532d2a0308fe09852a.png)'
  prefs: []
  type: TYPE_IMG
- en: This is what we get at this point.
  prefs: []
  type: TYPE_NORMAL
- en: You can find and use similar methods from the [scikit-image](https://scikit-image.org)
    library, but be careful, as they differ in both results and input parameters.
    The Lightness channel of the [skimage.color.rgb2lab](https://scikit-image.org/docs/stable/api/skimage.color.html#skimage.color.rgb2lab)
    function result is in the range [0,100], and the Gaussian filter [skimage.filters.gaussian](https://scikit-image.org/docs/stable/api/skimage.filters.html#skimage.filters.gaussian)
    is more sensitive to kernel parameters. This affects the end result.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2\. Detecting edges
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Hough Transform, which is the basis of our algorithm, can only work with
    binary images that consist of a background and edges taking the values 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: We use [the Canny Transform](https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html)
    to create a binary image. In short, this algorithm calculates the gradient in
    the intensity function of the pixel coordinate and finds its local maxima, the
    areas of which are defined as the desired edge.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/6e20048a154222c90e73f8908e79705e.png)'
  prefs: []
  type: TYPE_IMG
- en: Result of the Transform
  prefs: []
  type: TYPE_NORMAL
- en: We use the Canny function of the Feature module from the [scikit-image](https://scikit-image.org)
    library to perform the transform. You can find a similar function in the OpenCV
    library, but its implementation includes a 5x5 Gaussian filter smoothing, which
    makes it a bit difficult to control the situation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Step 3\. The Hough Transform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we need to detect the straight lines among all the lines we have found.
    Hough's straight line transformation excels at this task. The algorithm draws
    a line at a given distance ? from the origin and a certain angle ? to the X-axis,
    as shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/b25bfa629d23e33535a3584b20ed8e4b.png)'
  prefs: []
  type: TYPE_IMG
- en: For each such line, it calculates the number of the binary image light pixels
    that lie on the drawn line. The procedure is repeated for all ? and ? values in
    the selected range. The result is an intensity map in (?, ?) coordinates. Thus,
    the maxima in the resulting graph will be reached when the drawn straight line
    and the line in the image coincide.![Find a Picture in an Image Without Marking
    it Up](../Images/b01b061c663c9c41883a58d77b69e3cc.png)
  prefs: []
  type: TYPE_NORMAL
- en: Illustration of the Hough Transform (right figure) for the two black lines in
    the figure on the left.
  prefs: []
  type: TYPE_NORMAL
- en: In our algorithm, we use [this](https://scikit-image.org/docs/stable/auto_examples/edges/plot_line_hough_transform.html)
    implementation from scikit-image because it is easier to configure. Also, this
    library provides a convenient method for selecting local maxima that resemble
    the lines the most. The OpenCV [implementation](https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html)
    doesn't have a similar feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The transform outputs the angles and distances to the found lines. Drawing these
    lines is a bit trickier than the lines we are used to, so here is an additional
    snippet of code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The found distance is the hypotenuse and the position of the line along the
    y-axis is the cathetus, so we divide the distance value by the sine of the resulting
    angle.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/9e192008b469877c437bb925df6a153a.png)'
  prefs: []
  type: TYPE_IMG
- en: As a result of running this code, you will see the following
  prefs: []
  type: TYPE_NORMAL
- en: Our algorithm found all the necessary lines! The border of our app watermark
    at the very bottom is also detected.
  prefs: []
  type: TYPE_NORMAL
- en: Step 4\. Classification of lines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we need to determine which is the bottom line and which is the top
    one while also removing unnecessary lines, such as the one above the black bar.
  prefs: []
  type: TYPE_NORMAL
- en: '![Find a Picture in an Image Without Marking it Up](../Images/e5ee01f7e7c83b4e391967bfbaf01842.png)'
  prefs: []
  type: TYPE_IMG
- en: Final result
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we added a check of the areas above and below the found
    lines. Since we work with memes and their captions, we expect the background outside
    the picture to be white and the text on it to be black. Or vice versa: black background
    and white letters.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, our algorithm is based on checking the percentage of white and black
    pixels in the separated areas.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this approach, we used 3 variables:'
  prefs: []
  type: TYPE_NORMAL
- en: white_limit is the lower limit for defining the white color. All pixels with
    a value in the range (230; 256) will be considered white.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: black_limit is the upper limit for defining the black color. All pixels with
    a value in the range (0; 35) will be considered black.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: percent_limit is the minimum percentage of white/black pixels in the area at
    which the area will be considered as background with text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, the comparison takes place in each color channel independently,
    which is a general enough condition that allows you to correctly handle rare exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: The next few lines of code select the lowest line among the upper limits and
    the top line among the lower limits. We also added a condition for the size of
    the selected area. If the resulting vertical line cuts off more than 60% of the
    image height, we consider it an error and return the top or bottom border of the
    original image. This parameter is chosen based on the assumption of the area occupied
    by the meme image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The final algorithm, which you can find in the Functions section [here](https://colab.research.google.com/drive/1u42OGNz4OEZCb7RakFhw6TETWpLCG3sb?usp=sharing),
    also includes finding and adjusting vertical borders, allowing you to remove frames
    on the sides of the image.
  prefs: []
  type: TYPE_NORMAL
- en: What's next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To improve results, you need to learn how to measure quality, and for that you
    need markup. If you want to create a training dataset, our algorithm will make
    your manual markup easier, allowing you to collect the required number of examples
    faster.
  prefs: []
  type: TYPE_NORMAL
- en: To generalize our approach for more cases, you can replace the background color
    check in the algorithm with a monochrome check. This will allow the method to
    be used regardless of the background color.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Yaroslav Murzaev**](https://funcorp.dev/blog) is a Data Scientist at Funcorp.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python String Matching Without Complex RegEx Syntax](https://www.kdnuggets.com/2023/02/python-string-matching-without-complex-regex-syntax.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to MLOps like a Boss: A Guide to Machine Learning without Tears](https://www.kdnuggets.com/2023/06/mlops-like-boss-guide-machine-learning-without-tears.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How To Find The Best Data Science Remote Jobs](https://www.kdnuggets.com/2022/12/find-best-data-science-remote-jobs.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
