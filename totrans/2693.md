# 探索暴力K-近邻算法

> 原文：[https://www.kdnuggets.com/2020/10/exploring-brute-force-nearest-neighbors-algorithm.html](https://www.kdnuggets.com/2020/10/exploring-brute-force-nearest-neighbors-algorithm.html)

[评论](#comments)

**作者：[Murugan Yuvaraaj](https://www.linkedin.com/in/murugan-yuvaraaj-m-p-a369019a/)，普拉克西斯商学院**

![标题图片](../Images/97ae97e55099f6b9421805e97dcccecb.png)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 在IT方面支持你的组织

* * *

你发现这两个图表之间有什么不同吗？

两者都显示了K值在1到10之间的分类问题的准确性。

两个图表都使用了带有“暴力法”算法和“欧几里得”距离度量的KNN分类器模型，并在相同的数据集上进行比较。那么为什么两个图表之间的准确性会有差异呢？

在回答这个问题之前，让我先带你了解一下KNN算法的伪代码。

我希望大家对k近邻算法都很熟悉。如果不熟悉，你可以在[https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)上阅读有关基础知识。

我们可以按照以下步骤实现KNN模型：

1.  加载数据

1.  初始化k的值

1.  要获得预测的类别，请从1迭代到训练数据点的总数。

1.  计算测试数据和每一行训练数据之间的距离。这里我们将使用欧几里得距离作为我们的距离度量，因为它是最流行的方法。其他可以使用的度量包括切比雪夫距离、余弦距离等。

1.  根据距离值对计算出的距离进行升序排序

1.  从排序后的数组中获取前k行

1.  获取这些行中最频繁的类别

1.  返回预测的类别

对于我们的分析，让我们专注于第7步，即获取这些行中最频繁的类别。

在获得前k行后，我们从这些行中选择最频繁的类别（众数）。这存在一些问题。

如果k是奇数邻居，则列表中总会有一个主要类别。因此，奇数k邻居不会有问题。

那么偶数k邻居的情况如何，如果两个或更多类别获得相同的多数？

KNN算法对于数据集中k是偶数邻居时也可以提供高准确率。它并不仅限于使用奇数k邻居来获得主要类别。

举个例子：

如果k = 4，且我们在列表中有类别A = 2和类别B = 2。在这种情况下，算法将选择前K行中的类别，而不是查看距离度量。

为了解决这个问题，我们在算法中使用了**距离 - 模式 - 距离**作为偶数k邻居的标准。

我们的算法与暴力算法的工作方式相同，但在偶数k邻居的情况下差异很大。

我们的算法做的事情非常简单。它从距离度量中选取前k行。在k值为奇数的情况下，它选择多数类。对于偶数个k行，选择多数类。如果有两个或更多的类别具有多数情况，这些主要类别的距离将再次进入距离度量循环，检查哪个类别的距离度量最小，该类别被选为主要类别。

让我们看看这个是如何工作的。

对于我们的分析，我们使用了企鹅数据集。

**暴力算法：**

![Image](../Images/e2ffb131bc18c7520ff8bad8817223fd.png)

这里我们设置了k = 4。

类别‘Chinstrap’和‘Adelie’最终模式为2。在根据模式排列K邻居后，暴力算法选择了第一个类别，而不是选择距离度量中最小距离的类别。

这会影响当k值为偶数时暴力算法的准确性。

**我们的模型：**

![Image](../Images/811e79aeb0610d3b53c518090d21cdef.png)

我们的模型能够在偶数邻居的情况下提高准确性。

**结果：**

我已经将我们模型的准确性与暴力算法进行了比较，以下是结果。

| **K** | **暴力算法** | **我们的模型** |
| --- | --- | --- |
| 1 | 0.805 | 0.805 |
| 2 | 0.746 | 0.805 |
| 3 | 0.761 | 0.761 |
| 4 | 0.746 | 0.791 |
| 5 | 0.776 | 0.776 |
| 6 | 0.716 | 0.791 |
| 7 | 0.746 | 0.746 |
| 8 | 0.686 | 0.746 |
| 9 | 0.746 | 0.746 |
| 10 | 0.701 | 0.776 |

我还将结果与**kd树和球树算法**进行了比较，得到了类似的结果。

GitHub链接: [https://github.com/myuvarajmp/Exploring_KNN_Algorithm](https://github.com/myuvarajmp/Exploring_KNN_Algorithm)

感谢你的时间，请对我的反馈保持友好，因为这是我的第一篇文章。

**简介: [Murugan Yuvaraaj](https://www.linkedin.com/in/murugan-yuvaraaj-m-p-a369019a/)** 是印度班加罗尔Praxis商学院的学生。

**相关：**

+   [R中k-最近邻的初学者指南：从零到英雄](/2020/01/beginners-guide-nearest-neighbors-r.html)

+   [通过示例介绍k-最近邻算法](/2020/04/introduction-k-nearest-neighbour-algorithm-using-examples.html)

+   [使用K-最近邻分类心脏病](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

### 更多相关内容

+   [从理论到实践：构建k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [分类中的最近邻](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn中的K最近邻](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [3年内40%的劳动力将受AI影响](https://www.kdnuggets.com/40-of-labour-force-will-be-affected-by-ai-in-3-years)

+   [数据库优化：探索SQL中的索引](https://www.kdnuggets.com/2023/07/database-optimization-exploring-indexes-sql.html)

+   [探索AI/DL的最新趋势：从元宇宙到量子计算](https://www.kdnuggets.com/2023/07/exploring-latest-trends-aidl-metaverse-quantum-computing.html)
