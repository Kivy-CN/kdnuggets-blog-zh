["```py\ntorch.save(learner.model, PATH)\n```", "```py\nimport dill as dill\ntorch.save(learner.model, PATH, pickle_module=dill)\n```", "```py\n\n# Model class must be defined somewhere\nmodel = torch.load(PATH)\nmodel.eval()\n\n```", "```py\ntorch.save(model.state_dict(), PATH)\n```", "```py\nmodel = TheModelClass(*args, **kwargs) # Model class must be defined somewhere\nmodel.load_state_dict(torch.load(PATH))\nmodel.eval() # run if you only want to use it for inference\n```", "```py\n\n$ docker run --rm -p 8888:8888 -e JUPYTER_ENABLE_LAB=yes -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook:e5c5a7d3e52d\n\n```", "```py\n\n$ docker exec -it {container-id} /bin/bash\n\n```", "```py\n\npip install torch_nightly -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n\n```", "```py\n\npip install -U flask\n\n```", "```py\n# add your custom labels\nlabels = ['Not Choripan', 'Choripan']\n​\n# set your data directory\ndata_dir = 'data'\n​\n# set the URL where you can download your model weights\nMODEL_URL = 'https://s3.amazonaws.com/nicolas-dataset/stage1.pth' # example weights\n​\n# set some deployment settings\nPORT = 8080\n```", "```py\n# flask_app/server.py\n​\n# import libraries\nprint('importing libraries...')\nfrom flask import Flask, request, jsonify\nimport logging\nimport random\nimport time\n​\nfrom PIL import Image\nimport requests, os\nfrom io import BytesIO\n​\n# import fastai stuff\nfrom fastai import *\nfrom fastai.vision import *\nimport fastai\n​\n# import settings\nfrom settings import * # import\n​\nprint('done!\\nsetting up the directories and the model structure...')\n```", "```py\n\n# set dir structure\ndef make_dirs(labels, data_dir):\n    root_dir = os.getcwd()\n    make_dirs = ['train', 'valid', 'test']\n    for n in make_dirs:\n        name = os.path.join(root_dir, data_dir, n)\n        for each in labels:\n            os.makedirs(os.path.join(name, each), exist_ok=True)\nmake_dirs(labels=labels, data_dir=data_dir) # comes from settings.py\npath = Path(data_dir)\n\n```", "```py\n# download model weights if not already saved\npath_to_model = os.path.join(data_dir, 'models', 'model.pth')\nif not os.path.exists(path_to_model):\n    print('done!\\nmodel weights were not found, downloading them...')\n    os.makedirs(os.path.join(data_dir, 'models'), exist_ok=True)\n    filename = Path(path_to_model)\n    r = requests.get(MODEL_URL)\n    filename.write_bytes(r.content)\nprint('done!\\nloading up the saved model weights...')\nfastai.defaults.device = torch.device('cpu') # run inference on cpu\nempty_data = ImageDataBunch.single_from_classes(\n    path, labels, tfms=get_transforms(), size=224).normalize(imagenet_stats)\nlearn = create_cnn(empty_data, models.resnet34)\nlearn = learn.load('model')\n\n```", "```py\n\nprint('done!\\nlaunching the server...')\n# set flask params\napp = Flask(__name__)\n@app.route(\"/\")\ndef hello():\n    return \"Image classification example\\n\"\n@app.route('/predict', methods=['GET'])\ndef predict():\n    url = request.args['url']\n    app.logger.info(\"Classifying image %s\" % (url),)\n\n    response = requests.get(url)\n    img = open_image(BytesIO(response.content))\n    t = time.time() # get execution time\n    pred_class, pred_idx, outputs = learn.predict(img)\n    dt = time.time() - t\n    app.logger.info(\"Execution time: %0.02f seconds\" % (dt))\n    app.logger.info(\"Image %s classified as %s\" % (url, pred_class))\n    return jsonify(pred_class)\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", debug=True, port=PORT)\n​\n```", "```py\n\n* Serving Flask app \"server\" (lazy loading)\n * Environment: production\n   WARNING: Do not use the development server in a production environment.\n   Use a production WSGI server instead.\n * Debug mode: on\n * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n * Restarting with stat\nimporting libraries...\ndone!\nsetting up the directories and the model structure...\ndone!\nloading up the saved model weights...\ndone!\nlaunching the server...\n * Debugger is active!\n * Debugger PIN: 261-786-850\n```", "```py\n\n$ curl http://ec2-100-24-34-242.compute-1.amazonaws.com:8080/predict?url=https://media.minutouno.com/adjuntos/150/imagenes/028/853/0028853430.jpg\n\"Choripan\"\n\n```", "```py\n\n[2018-11-13 16:49:32,245] INFO in server: Classifying image https://media.minutouno.com/adjuntos/150/imagenes/028/853/0028853430.jpg\n[2018-11-13 16:49:33,836] INFO in server: Execution time: 1.35 seconds\n[2018-11-13 16:49:33,858] INFO in server: Image https://media.minutouno.com/adjuntos/150/imagenes/028/853/0028853430.jpg classified as Choripan\n\n```", "```py\n\nfrom clipper_admin import ClipperConnection, DockerContainerManager\nclipper_conn = ClipperConnection(DockerContainerManager())\n\n```", "```py\n\nclipper_conn.start_clipper()\nclipper_addr = clipper_conn.get_query_addr()\n\n```", "```py\n\n!docker ps --filter label=ai.clipper.container.label\n\n```", "```py\n\napp_name = \"squeezenet-classsifier\"\ndefault_output = \"default\"\nclipper_conn.register_application(\n    name=app_name,\n    input_type=\"bytes\",\n    default_output=default_output,\n    slo_micros=10000000)\n\n```", "```py\n\nclipper_conn.get_all_apps()\n\n```", "```py\n\nfrom torchvision import models, transforms\nmodel = models.squeezenet1_1(pretrained=True)\n\n```", "```py\n\n# First we define the preproccessing on the images:\nnormalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\npreprocess = transforms.Compose([\n   transforms.Scale(256),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   normalize\n])\n# Then we download the labels:\nlabels = {int(key):value for (key, value)\n          in requests.get('https://s3.amazonaws.com/outcome-blog/imagenet/labels.json').json().items()}\n\n```", "```py\n\nimport clipper_admin.metrics as metrics\ndef predict_torch_model(model, imgs):\n    import io\n    import PIL.Image\n    import torch\n    import clipper_admin.metrics as metrics\n\n    metrics.add_metric(\"batch_size\", 'Gauge', 'Batch size passed to PyTorch predict function.')\n    metrics.report_metric('batch_size', len(imgs)) # TODO: Fill in the batch size\n\n    # We first prepare a batch from `imgs`\n    img_tensors = []\n    for img in imgs:\n        img_tensor = preprocess(PIL.Image.open(io.BytesIO(img)))\n        img_tensor.unsqueeze_(0)\n        img_tensors.append(img_tensor)\n    img_batch = torch.cat(img_tensors)\n\n    # We perform a forward pass\n    with torch.no_grad():\n        model_output = model(img_batch)\n\n    # Parse Result\n    img_labels = [labels[out.data.numpy().argmax()] for out in model_output]\n\n    return img_labels\n\n```", "```py\n\nfrom clipper_admin.deployers import pytorch as pytorch_deployer\npytorch_deployer.deploy_pytorch_model(\n    clipper_conn,\n    name=\"pytorch-model\",\n    version=1,\n    input_type=\"bytes\",\n    func=predict_torch_model, # predict function wrapper\n    pytorch_model=model, # pass model to function\n    )\n\n```", "```py\n\nclipper_conn.link_model_to_app(app_name=\"squeezenet-classsifier\", model_name=\"pytorch-model\")\n\n```", "```py\n\nimport requests\nimport json\nimport base64\n\nclipper_addr = 'localhost:1337'\n\nfor img in ['img1.jpg', 'img2.jpg', 'img3.jpg']: # example with local images\n  req_json = json.dumps({\n          \"input\":\n          base64.b64encode(open(img, \"rb\").read()).decode() # bytes to unicode\n      })\n\n  response = requests.post(\n           \"http://%s/%s/predict\" % (clipper_addr, 'squeezenet-classsifier'),\n           headers={\"Content-type\": \"application/json\"},\n           data=req_jsn)\n\n  print(response.json())\n\n```", "```py\n\nclipper_conn.stop_all()\n\n```", "```py\n\n!docker ps --filter label=ai.clipper.container.label\n\n```", "```py\n\nsudo apt install npm # if not already installed\nsudo npm install -g now\n\n```", "```py\n\nwget https://github.com/fastai/course-v3/raw/master/docs/production/zeit.tgz\ntar xf zeit.tgz\ncd zeit\n\n```", "```py\n\nnow\n\n```", "```py\n\nimport torch\nimport torchvision\n​\n# An instance of your model.\nmodel = torchvision.models.resnet18()\n​\n# An example input you would normally provide to your model's forward() method.\nexample = torch.rand(1, 3, 224, 224)\n​\n# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\ntraced_script_module = torch.jit.trace(model, example)\n​\n# Save the model\ntraced_script_module.save(\"model-resnet18-jit.pt\")\n```"]