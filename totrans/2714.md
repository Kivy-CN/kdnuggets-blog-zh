# 提升TensorFlow模型的4种方法——你需要了解的关键正则化技术

> 原文：[https://www.kdnuggets.com/2020/08/tensorflow-model-regularization-techniques.html](https://www.kdnuggets.com/2020/08/tensorflow-model-regularization-techniques.html)

[评论](#comments)

![](../Images/aff83738ac2aa42970007ee48d1054b9.png)

*照片由 [Jungwoo Hong](https://unsplash.com/@oowgnuj?utm_source=medium&utm_medium=referral) 提供，发布于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。*

### 正则化

根据维基百科，

> *在数学、统计学和计算机科学，特别是机器学习和逆问题中，**正则化**是为了在解决一个不适定问题或防止过拟合时添加额外信息的过程。*

这意味着我们添加一些额外的信息以解决问题并防止过拟合。

过拟合意味着我们的机器学习模型在某些数据上训练良好，在这些数据上表现极佳，但在新的未见过的样本上则会失败。

我们可以在这个简单的例子中看到过拟合现象

![](../Images/41d0f948b244917fedbb1ad53f1e1238.png)

*[http://mlwiki.org/index.php/Overfitting](http://mlwiki.org/index.php/Overfitting)*

当我们的数据严格附着于训练样本时，这会导致测试/开发集上的性能较差，而训练集上的性能良好。

![](../Images/f0d1eb3f9aac8909353ede22ad87482f.png)

*[http://mlwiki.org/index.php/Overfitting](http://mlwiki.org/index.php/Overfitting)*

因此，为了提高模型性能，我们使用不同的正则化技术。虽然有几种技术，但我们将讨论4种主要技术。

1.  **L1正则化**

1.  **L2正则化**

1.  **丢弃法**

1.  **批量归一化**

我将简要解释这些技术是如何工作的，以及如何在Tensorflow 2中实现它们。

为了更好地理解这些技术如何及其工作原理，我推荐你观看Andrew NG教授的讲座，这些讲座在Youtube上很容易找到。

*首先，我将编写一个没有正则化的模型，然后展示如何通过添加不同的正则化技术来改进它。我们将使用IRIS数据集来展示正则化如何显著改善模型。*

### 无正则化的模型

**代码：**

+   **基本预处理**

+   **模型构建**

**model1.summary()**

[PRE0]

训练模型后，如果我们使用以下代码在Tensorflow中评估模型，我们可以找到测试集上的*准确率*、*损失*和*mse*。

[PRE1]

![](../Images/bcc914cd55999fa3fbccbcc855b51ed2.png)

让我们检查验证损失和训练损失的图表。

[PRE2]

![](../Images/999093c9c77070fbcc3966d963759c55.png)

在这里，我们可以看到验证损失在**≈ 60**个周期后逐渐增加，而训练损失保持稳定。这表明我们的模型发生了过拟合。

同样地，对于模型准确率图，

[PRE3]

![](../Images/ce2630b3aede2497175cc83d4267f212.png)

这再次表明，与训练准确率相比，验证准确率较低，这再次显示出过拟合的迹象。

### L1正则化：

一种常用的正则化技术是L1正则化，也称为Lasso正则化。

L1正则化的主要概念是我们必须通过将权重的绝对值添加到损失函数中，乘以正则化参数lambda **λ**，其中**λ**是手动调节为大于0的。

L1的方程是

![](../Images/a3e67233246feda637e7c604bd4f2e2c.png)

*图片来源: [数据科学前沿](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261#2a1f)。*

**Tensorflow代码：**

这里，我们添加了一个额外的参数*kernel_regularizer*，我们将其设置为‘l1’，用于L1正则化。

现在我们来评估并绘制模型。

[PRE4]

![](../Images/12ce08d7b04a93c399fc82a29720239c.png)

嗯，准确率差不多一样，我们来看一下图表以获得更好的直观感觉。

[PRE5]

![](../Images/bafec1e420bc0d14ed9989b77a7f4fe5.png)

对于准确率，

[PRE6]

![](../Images/564a85d559cd6798cfd8f8ad66c1ba5d.png)

好吧，相当大的改进，我想，因为过拟合的验证损失没有像之前那样增加，但验证准确率提升不大。让我们在更多层中添加l1以检查是否能改善模型。

[PRE7]

训练后，我们来评估模型。

[PRE8]

![](../Images/dd8649d166180440ae16a48caefbc217.png)

好了，准确率现在有了相当大的提高，从92跳升到了94。我们来看看图表。

**损失**

[PRE9]

![](../Images/4b383f796e638d58b976918b359db9f4.png)

现在，两条线大致重叠，这意味着我们的模型在测试集上的表现与在训练集上的表现相同。

**准确率**

[PRE10]

![](../Images/11f1226d2cfbd2ffcd9cc75dd69ecce8.png)

我们可以看到，与训练损失相比，模型的验证损失没有增加，验证准确率也在上升。

### L2正则化

L2正则化是另一种正则化技术，也称为**岭回归**。在L2正则化中，我们将权重的平方大小添加到损失函数中以惩罚我们的损失。

![](../Images/75665aa67638080b50c4650abf10e2bc.png)

*图片来源: [数据科学前沿](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261#2a1f)。*

**Tensorflow代码：**

[PRE11]

训练后，我们来评估模型。

[PRE12]

输出结果是

![](../Images/2e0ab66c243db0af399a772b08e4f0f1.png)

在这里我们可以看到验证准确率为97%，这是相当不错的。我们来绘制更多图表以获得更直观的感觉。

![](../Images/91daa2781a6680f346a0ec85fbbc0e7d.png)

在这里我们可以看到，我们没有过拟合数据。让我们绘制准确率。

![](../Images/6d9448767ff37f3f0cdda2ed4ce4586b.png)

在仅一层中添加“L2”正则化大大改善了我们的模型。

现在让我们在所有其他层中添加**L2**。

[PRE13]

现在我们在所有层中添加了L2。训练后，我们来评估一下。

[PRE14]

![](../Images/a982288a4c9676e91e0bfa14a759d342.png)

让我们绘图以获得更多直观感受。

[PRE15]

![](../Images/4e91d8818f4f27683a61a88665bc6cde.png)

对于准确率

![](../Images/9f1fcf25ad26e8abc9ed7678e7bee914.png)

我们可以看到这个模型也表现良好，并没有过拟合数据集。

### 丢弃法

另一种常见的正则化方法是使用丢弃法。使用丢弃法的主要思想是根据一定的概率随机关闭我们层中的一些神经元。你可以通过教授 NG 的视频了解更多关于它的工作原理，[这里](https://www.youtube.com/watch?v=ARq74QuavAo)。

让我们在 TensorFlow 中编写代码。

之前的导入都是一样的，我们这里只是添加了一个额外的导入。

为了实现丢弃法，我们只需从*tf.keras.layers*中添加一个*Dropout*层并设置丢弃率。

[PRE16]

训练之后，让我们在测试集上进行评估。

[PRE17]

![](../Images/309f287e682e15e861501a280db355e5.png)

哇，我们的结果非常有希望，我们在测试集上的表现达到了97%。让我们绘制损失和准确率图，以获得更好的直观感受。

[PRE18]

![](../Images/023280950cc8a67e0368962442a95302.png)

在这里，我们可以看到我们的模型在验证数据上的表现优于训练数据，这真是好消息。

现在让我们绘制准确率图。

![](../Images/b20e02b39a9d2a32185c9cff67dde23b.png)

我们可以看到，我们的模型在验证数据集上的表现优于训练集。

让我们添加更多丢弃层来查看我们的模型表现如何。

[PRE19]

让我们评估一下。

[PRE20]

![](../Images/e82928464719a82f92f7d4d2552ec1ea.png)

这个模型也非常好，因为它在测试集上的表现达到了98%。让我们绘图以获得更好的直观感受。

[PRE21]

![](../Images/da0c05863284a9584568bbfdeafeb527.png)

我们可以看到，添加更多丢弃层会使模型在训练时表现稍逊，但在验证集上，它表现得非常好。

现在让我们绘制准确率图。

![](../Images/7cf13a5c5ae4d14095e39147df5ae02f.png)

我们在这里看到相同的模式，即我们的模型在训练时表现不佳，但在评估时表现非常好。

### 批量归一化

批量归一化的主要思想是我们通过使用几种技术（在我们的案例中是*sklearn.preprocessing.StandardScaler*）对输入层进行归一化，从而提高模型性能。如果输入层通过归一化受益，那为何不对隐藏层进行归一化，以进一步提高和加快学习呢？

要学习数学并获得更多直观感受，我会再次引导你到教授 NG 的讲座，[这里](https://www.youtube.com/watch?v=tNIpEZLv_eg)和[这里](https://www.youtube.com/watch?v=nUUqwaxLnWs)。

要在你的 TensorFlow 模型中添加它，只需在你的层后面添加*tf.keras.layers.BatchNormalization()*。

让我们看看代码。

[PRE22]

在这里，如果你注意到我已经去掉了*batch_size*选项。这是因为在仅使用*tf.keras.BatchNormalization()*作为正则化时，添加*batch_size*参数会导致模型性能非常差。我尝试在网上寻找原因，但未能找到。如果你真的想在训练时使用*batch_size*，也可以将优化器从*sgd*更改为*rmsprop*或*adam*。

训练后，让我们评估模型。

[PRE23]

![](../Images/6a854c3c9d073d3f3f44e478a9660b6b.png)

对于一个批量归一化的准确性，其验证准确性不如其他技术。让我们绘制损失和准确性图，以获得更好的直观感受。

![](../Images/b9881c940d7824f31926e7bdfc5693d5.png)

![](../Images/ebb6014ef2837e4e79571228264431ed.png)

在这里，我们可以看到我们的模型在验证集上的表现不如在测试集上的表现。让我们将归一化添加到所有层中以查看结果。

[PRE24]

让我们来评估一下。

[PRE25]

![](../Images/d61fcb3880fd979dba67308394ea06c7.png)

通过在每一层中添加批量归一化，我们实现了良好的准确性。让我们绘制损失和准确性图。

![](../Images/5c2682bc581e0a3ee0752adb14e1bd35.png)

![](../Images/00908e06a1cdc384b166744b2e4f4776.png)

通过绘制准确性和损失，我们可以看到我们的模型在训练集上的表现仍优于验证集，但仍在提升性能。

### 结果：

这篇文章简要介绍了如何在 TensorFlow 中使用不同的技术。如果你对理论不够了解，我建议你学习 Coursera 深度学习专项课程中的第 2 和第 3 课程，以了解更多关于正则化的内容。

你还需要学习何时使用哪些技术，以及如何将不同技术结合起来，以产生真正有成效的结果。

希望现在你对如何在 TensorFlow 2 中实现不同的正则化技术有了一个概念。

**相关：**

+   [开始使用 TensorFlow 2](https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html)

+   [深度神经网络中的批量归一化](https://www.kdnuggets.com/2020/08/batch-normalization-deep-neural-networks.html)

+   [深度学习中的过拟合问题](https://www.kdnuggets.com/2019/12/fighting-overfitting-deep-learning.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 需求

* * *

### 更多相关话题

+   [成为伟大的数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [每个数据科学家都应该了解的三个R语言库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [一项90亿美元的人工智能失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)
