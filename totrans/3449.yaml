- en: The Hard Problems AI Can’t (Yet) Touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/07/hard-problems-ai-cant-yet-touch.html](https://www.kdnuggets.com/2016/07/hard-problems-ai-cant-yet-touch.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: Who's better, Lebron James or Stephen Curry? Which country is more powerful,
    the United States or China? How advanced is modern AI compared to humans? Of the
    three ridiculous questions above, which appears most underspecified? However misguidedly,
    we often discuss complex, multi-faceted issues as though they were easily reduced
    to single scalar quantities.
  prefs: []
  type: TYPE_NORMAL
- en: In the past few years, modern AI techniques have made great strides, accomplishing
    a number of feats traditionally associated with human intelligence. In particular,
    machine learning systems using deep neural networks now perform human-level speech
    recognition and transcription. They also caption images, annotating them with
    reasonable natural language descriptions. Just a couple months ago, a system marrying
    reinforcement learning with deep learning beat humans at Go, long thought to be
    the hardest board game for computers to match human abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '[![Professional Go Player Lee Se-dol Set To Play Google AlphaGo](../Images/f39e5f7e6a0c02660fd67f34f65cc5d0.png)](/wp-content/uploads/alphago.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Amid this success, it''s tempting to consider the progress of AI as though
    it were a single monolithic entity, advancing equally on all fronts. And if we
    restrict attention to supervised learning and reinforcement learning for games,
    this seems believable. But we should pause before giving in to Singularitarian
    magical thinking about the advance of AI. While some pop-futurists suggest otherwise,
    AI doesn''t progress uniformly in all directions as cost per calculation falls.
    In contrast, we have made rapid progress on some classes of problems while stagnating
    on others. Our successes have come on problems where objectives are easily and
    uncontroversially quantified. Other problems with fuzzier objectives: personal
    assistants, conversation agents, medical decision-making have seen comparatively
    little advance towards human abilities.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Which Problems are Hard?**'
  prefs: []
  type: TYPE_NORMAL
- en: One recurring theme throughout the history of AI / machine learning research
    is that we are terrible at determining exactly what aspect of human intelligence
    is remarkable. Thirty years ago, many thought that beating a grandmaster at chess
    would constitute a greater feat of intelligence than matching the cognitive feats
    of a high-schooler. And yet while current champion Magnus Carlsen can't withstand
    a Macbook Pro running tree search, modern dialog bots can't match the conversational
    prowess of an average 10 year old. Perhaps, our values regarding various types
    of intelligence are rooted in economic thinking. All else equal, scarce skills
    seem more valuable. Chess champions may appear to possess greater intelligence
    than socialites simply because there are fewer of them.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning problems can be hard for many reasons. Most publicly visible
    AI addresses well-formed pattern matching problems. These include supervised learning
    problems like image classification or reinforcement learning problems like playing
    Chess or Go or Atari. Some of these problems are harder than others on account
    of a paucity of training data, a large action space or many classes, or because
    the patterns to be learned are especially complex, as with raw audio or video
    data. On all these fronts, machine learning research has made considerable progress.
  prefs: []
  type: TYPE_NORMAL
- en: However, machine learning problems can also be difficult for another, overlooked
    reason. For many settings in which we might want to introduce an AI agent, the
    problems are not well-formed. That is, it's not at all obvious what objective
    should be optimized.
  prefs: []
  type: TYPE_NORMAL
- en: Nearly all machine learning tasks consist of some kind of optimization. For
    image classification, our goal is to maximize the percentage of images that are
    correctly classified. For language translation, our goal is to output a string
    that closely agrees with a set of ground truth candidate translations. For games
    like Chess or Go, our goal is simply to win. In short, both supervised learning
    and reinforcement learning assume apriori knowledge of a single scalar quantity
    whose maximization equates to success.
  prefs: []
  type: TYPE_NORMAL
- en: But for many real world settings where we might want to insert an AI agent,
    no one can say at present what the objective function should be. For example,
    what precisely is the goal of a doctor? How can we distill success of a medical
    professional to a single reward that is dolled out as outcomes become known? How
    precisely do we measure quality of life? What is the trade-off between limbs and
    longevity? How much should the doctor value revenue vs patient health (if the
    value of life is infinite then all patients should be seen for free). Sometimes
    the objective function for the doctor might vary from patient to patient depending
    on their preferences. Human doctors implicitly evaluate these tradeoffs constantly,
    but before we learn to canonize our objectives current AI may remain confined
    to more isolated, low-level pattern recognition problems.
  prefs: []
  type: TYPE_NORMAL
- en: '[![doctor-robot-930x523](../Images/6ea76c72845c855c3a1ab506b6343361.png)](/wp-content/uploads/doctor-robot-930x523.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, what is the scalar quantity optimized by a conversant in dialog?
    Is it simply to maximize engagement? What if engagement is maximized by trolling?
    Is the goal to be kind? To be informative? To build lasting relationships? Should
    there be a penalty for being an ass, and if so, how is that quantified?
  prefs: []
  type: TYPE_NORMAL
- en: While we have made dramatic strides in pattern recognition, making headway on
    difficult problems in supervised and reinforcement learning, our entire paradigm
    for learning requires well-formed objectives that are determined a priori. And
    yet for the complicated settings in which we envisage "hard AI" or human-like
    intelligence, determining these objectives presents a formidable obstacle.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, it may be precisely the uncontroversial indicators of success (test
    set accuracy, chess rating achieved) that have enabled progress in the field.
    Unlike other areas which are stymied by subjectivity, machine learning has benefited
    from the objectivity conferred by these metrics. How precisely can the community
    achieve similarly harmonious progress towards more general AI, if the objectives
    are nebulously defined?
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning has entered its golden age. It's fascinating intellectually
    and impactful economically. As progress appears to roll in steadily, it's tempting
    to view this as a one-dimensional march towards a super-intelligence that matches
    or exceeds human capacity in all endeavors. However, we might remember our atrocious
    track record for recognizing what precisely about our intelligence is interesting,
    valuable, or difficult to replicate. Perhaps it's our ability to operate effectively
    despite hazily defined objectives that is most remarkable - an area where machine
    learning has yet to make much progress.
  prefs: []
  type: TYPE_NORMAL
- en: '![Zachary Chase Lipton](../Images/240b273c667af1a53a99fd93d1fd39ce.png) **[Zachary
    Chase Lipton](http://zacklipton.com)** is a PhD student in the Computer Science
    Engineering department at the University of California, San Diego. Funded by the
    [Division of Biomedical Informatics](http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx),
    he is interested in both theoretical foundations and applications of machine learning.
    In addition to his work at UCSD, he has interned at Microsoft Research Labs and
    as a Machine Learning Scientist at Amazon, and is a Contributing Editor at KDnuggets.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Does Deep Learning Come from the Devil?](/2015/10/deep-learning-vapnik-einstein-devil-yandex-conference.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MetaMind Competes with IBM Watson Analytics and Microsoft Azure Machine Learning](/2015/01/metamind-ibm-watson-analytics-microsoft-azure-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning and the Triumph of Empiricism](/2015/07/deep-learning-triumph-empiricism-over-theoretical-mathematical-guarantees.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Myth of Model Interpretability](/2015/04/model-interpretability-neural-networks-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[(Deep Learning’s Deep Flaws)’s Deep Flaws](/2015/01/deep-learning-flaws-universal-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science’s Most Used, Confused, and Abused Jargon](/2015/02/data-science-confusing-jargon-abused.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Beyond Coding: Why The Human Touch Matters](https://www.kdnuggets.com/beyond-coding-why-the-human-touch-matters)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Hard Coding in a Data Science Project - Use Config Files Instead](https://www.kdnuggets.com/2023/06/stop-hard-coding-data-science-project-config-files-instead.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Hard Python Coding Interview Questions For Data Science](https://www.kdnuggets.com/2023/03/3-hard-python-coding-interview-questions-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Hard is it to Get into FAANG Companies](https://www.kdnuggets.com/2023/05/hard-get-faang-companies.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Want to Become a Data Scientist? Part 1: 10 Hard Skills You Need](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
