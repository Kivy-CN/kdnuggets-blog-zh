- en: Ensemble Learning with Examples
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成学习实例
- en: 原文：[https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)
- en: '![Ensemble Learning with Examples](../Images/3b8286cd091c64374aef205988db0dab.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![集成学习实例](../Images/3b8286cd091c64374aef205988db0dab.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: What is Ensemble Learning?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是集成学习？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Ensemble learning combines multiple models to obtain better model performance.
    It helps you improve robustness and provide a generalized model. In short, it
    combines different decisions from the model to improve performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习结合多个模型以获得更好的模型性能。它有助于提高模型的鲁棒性并提供通用模型。简而言之，它结合了模型的不同决策来提高性能。
- en: In this tutorial, we will learn about various ensemble methods with examples.
    We will be using the [Heart Attack Analysis & Prediction](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)
    dataset from Kaggle. Our focus is to find the patents with higher and lower chances
    of heart attack using various features.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将通过示例学习各种集成方法。我们将使用Kaggle上的[心脏病分析与预测](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)数据集。我们的重点是利用各种特征找到心脏病发作的高风险和低风险患者。
- en: '**Output :**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: 0 = less chance of heart attack
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 = 较低的心脏病发作风险
- en: 1 = more chance of heart attack
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 = 更高的心脏病发作风险
- en: Averaging
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均
- en: We will start by importing the required utility and machine learning packages.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从导入所需的实用程序和机器学习包开始。
- en: Simple Average
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单平均
- en: We will take a simple average by adding all of the models' output and dividing
    it by the total number of models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过将所有模型的输出相加并除以模型总数来计算简单平均。
- en: Loaded the heart.csv file using pandas.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas加载了heart.csv文件。
- en: The target is the “output” feature.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标是“输出”特征。
- en: Drop “output” to create training features.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除“输出”以创建训练特征。
- en: Scaled the features using StandardScaler()
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用StandardScaler()对特征进行缩放
- en: Split the data into train and test sets.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据拆分为训练集和测试集。
- en: Build all three model objects. We are using RandomForestClassifier, LogisticRegression,
    and SGDClassifier.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建所有三个模型对象。我们使用的是RandomForestClassifier、LogisticRegression和SGDClassifier。
- en: Training the model on a train set and predicting the output using a test set.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练模型，并使用测试集预测输出。
- en: Using the average formula and rounding the output to show only 1s and 0s.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用平均公式并将输出四舍五入为仅显示1和0。
- en: Displaying accuracy and AUC metrics.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示准确性和AUC指标。
- en: Our model has performed well on default hyperparameters.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型在默认超参数下表现良好。
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Weighted Average
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加权平均
- en: In the weighted average, we give the highest weight to best-performing models
    and the lowest weight to lower-performing models while taking an average.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在加权平均中，我们给表现最佳的模型赋予最高权重，给表现较差的模型赋予最低权重，同时计算平均值。
- en: '|  | **model_1** | **model_2** | **model_3** |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|  | **model_1** | **model_2** | **model_3** |'
- en: '| **Weightage** | 30% | 60% | 10% |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **权重** | 30% | 60% | 10% |'
- en: The code below shows that by giving more weightage to **model_2,** we have achieved
    better performance.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码显示，通过给予**model_2**更高的权重，我们达到了更好的性能。
- en: '**Note:** while giving weightage, make sure they all add up to 1\. For example,
    0.3 + 0.6 + 0.1 = 1'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 在赋予权重时，确保它们的总和为1。例如，0.3 + 0.6 + 0.1 = 1'
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Max Voting
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大投票
- en: Max Voting is generally used for classification problems. In this method, each
    model makes a prediction and votes for each sample. From the sample class, only
    the highest-voted class is included in the final predictive class.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最大投票法通常用于分类问题。在这种方法中，每个模型对每个样本进行预测并投票。从样本类别中，只有得票最高的类别会被纳入最终预测类别。
- en: '![Ensemble Learning with Examples](../Images/b0ec751c949da1bf325fd079623b8a7f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![示例中的集成学习](../Images/b0ec751c949da1bf325fd079623b8a7f.png)'
- en: Image from [rasbt.github.io](http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来自[rasbt.github.io](http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/)
- en: 'In the example below, I have added a fourth model KNeighborsClassifier. We
    will use Scikit-Learn’s VotingClassifier and add three classifiers: RandomForestClassifier,
    LogisticRegression, and KNeighborsClassifier.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，我添加了第四个模型KNeighborsClassifier。我们将使用Scikit-Learn的VotingClassifier，并添加三个分类器：RandomForestClassifier、LogisticRegression和KNeighborsClassifier。
- en: As we can see, we got better results than the simple average.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们得到了比简单平均更好的结果。
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Stacking
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆叠
- en: Stacking combines multiple base models via meta-model (meta-classifier or meta-regression).
    The base models are trained on a full dataset. The meta-model is trained on the
    features from base models(outputs). The base models and the meta-model are generally
    different. In short, meta-models help base models to find useful features to achieve
    high performance.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠通过元模型（meta-classifier或meta-regression）组合多个基础模型。基础模型在完整数据集上进行训练。元模型在基础模型的特征（输出）上进行训练。基础模型和元模型通常是不同的。简而言之，元模型帮助基础模型找到有用的特征，以实现高性能。
- en: '![Ensemble Learning with Examples](../Images/a944ca4e7cd30b427e03b02410333a6a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![示例中的集成学习](../Images/a944ca4e7cd30b427e03b02410333a6a.png)'
- en: Image from [opengenus.org](https://iq.opengenus.org/content/images/2019/08/stacking.PNG)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来自[opengenus.org](https://iq.opengenus.org/content/images/2019/08/stacking.PNG)
- en: In the example, we are going to use Random forest, Logistic regression, and
    AdaBoost classifier for base models (estimators) and GradientBoosting classifier
    as meta-model (final_estimator).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用随机森林、逻辑回归和AdaBoost分类器作为基础模型（估计器），并使用GradientBoosting分类器作为元模型（final_estimator）。
- en: Stacking the models did not produce better results.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠模型未能产生更好的结果。
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Bagging
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bagging
- en: Bagging, also known as Bootstrap Aggregating, is an ensemble method to improve
    the stability and accuracy of machine learning models. It is used for minimizing
    variance and overfitting. Generally, it is applied to decision tree methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging，也称为Bootstrap Aggregating，是一种集成方法，用于提高机器学习模型的稳定性和准确性。它用于最小化方差和过拟合。通常，它应用于决策树方法。
- en: '![Ensemble Learning with Examples](../Images/570d620f6e7244bcaf1398f42b05c5ba.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![示例中的集成学习](../Images/570d620f6e7244bcaf1398f42b05c5ba.png)'
- en: Bagging by [Fernando López](https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging由[Fernando López](https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422)介绍
- en: Bagging randomly creates a subset of training data to get a fair distribution
    of the whole dataset and train the models on it. The final output is created by
    combining all of the output from the base model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging随机创建训练数据的子集，以公平分布整个数据集，并在其上训练模型。最终输出是通过组合所有基础模型的输出生成的。
- en: In our case, we will use one type of model and train it on various subsets of
    training data. A subset is also known as a bag hence the bagging algorithm.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用一种类型的模型，并在不同的训练数据子集上进行训练。一个子集也称为“包”，因此称为bagging算法。
- en: In the example, we are using Scikit-learn's BaggingClassifier and utilizing
    Logistic regression as the base estimator.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用Scikit-learn的BaggingClassifier，并利用逻辑回归作为基础估计器。
- en: Bagging algorithm has produced the best and reliable result.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging算法已产生最佳和可靠的结果。
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Boosting
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升
- en: Boosting combines weak classifiers to create a strong classifier. It reduces
    biases and improves the single model performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 提升方法通过组合弱分类器来创建强分类器。它减少了偏差并改善了单个模型的性能。
- en: You can achieve high performance by training weak classifiers in series. The
    first model is training on training data, then the second model is trained to
    correct the error present in the first model. It is an iterative algorithm that
    adjusts weights based on the previous model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将弱分类器串联训练，你可以实现高性能。第一个模型在训练数据上进行训练，然后第二个模型在第一个模型中纠正错误。这是一个迭代算法，根据之前的模型调整权重。
- en: '![Ensemble Learning with Examples](../Images/2c12322a42716fd36ddbe12ac238a859.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![示例中的集成学习](../Images/2c12322a42716fd36ddbe12ac238a859.png)'
- en: Boosting by [Fernando López](https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Fernando López](https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422)
    提供的提升方法
- en: The boosting algorithm gives more weightage to the observations that previous
    models have predicted accurately. This process continues until all training data
    sets are predicted correctly or it has reached the maximum number of models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 提升算法给予先前模型准确预测的观测值更多的权重。这个过程持续进行，直到所有训练数据集都被正确预测或达到了最大模型数量。
- en: In the example, we will be using the AdaBoost classifier. The adaptive boosting
    algorithm (AdaBoost) is the OG technique of combining weak classifiers into a
    single powerful classifier.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 AdaBoost 分类器。自适应提升算法（AdaBoost）是将弱分类器组合成一个强大分类器的经典技术。
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Conclusion
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Even though ensemble learning should be applied to all machine learning applications,
    in the case of large neural networks, you need to consider throughput, computation,
    and cost of operation to decide whether to train and serve multiple models or
    not.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管集成学习应该应用于所有机器学习应用中，但在大型神经网络的情况下，你需要考虑吞吐量、计算和操作成本，以决定是否训练和服务多个模型。
- en: In this tutorial, we have learned the importance of ensemble learning. Furthermore,
    we have learned about averaging, max voting, stacking, bagging, and boosting with
    code examples.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们学习了集成学习的重要性。此外，我们还学习了平均、最大投票、堆叠、袋装和提升的方法及其代码示例。
- en: I hope you like the tutorial, and if you have any questions regarding the best
    possible technique, do comment in the section below.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这个教程，如果你对最佳技术有任何疑问，请在下面的评论区留言。
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证的数据科学专业人士，他热衷于构建机器学习模型。目前，他专注于内容创作，并撰写有关机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是利用图神经网络为面临心理健康问题的学生构建
    AI 产品。'
- en: More On This Topic
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Ensemble Learning Techniques: A Walkthrough with Random Forests in Python](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[集成学习技术：使用 Python 中的随机森林逐步讲解](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
- en: '[When Would Ensemble Techniques be a Good Choice?](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[何时选择集成技术是一个好选择？](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
- en: '[Picking Examples to Understand Machine Learning Model](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择示例以理解机器学习模型](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)'
- en: '[SQL LIKE Operator Examples](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL LIKE 运算符示例](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学、机器学习和深度学习的可靠计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能、分析、机器学习、数据科学、深度学习……](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
