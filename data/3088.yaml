- en: Selecting the Best Machine Learning Algorithm for Your Regression Problem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择最佳机器学习算法以解决回归问题
- en: 原文：[https://www.kdnuggets.com/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html](https://www.kdnuggets.com/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html](https://www.kdnuggets.com/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '![Image](../Images/4ad2b5bffcfcc54ab520646aaba54ebb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/4ad2b5bffcfcc54ab520646aaba54ebb.png)'
- en: When approaching any type of Machine Learning (ML) problem there are many different
    algorithms to choose from. In machine learning, there’s something called the “No
    Free Lunch” theorem which basically states that no one ML algorithm is best for
    all problems. The performance of different ML algorithms strongly depends on the
    size and structure of your data. Thus, the correct choice of algorithm often remains
    unclear unless we test out our algorithms directly through plain old trial and
    error.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理任何类型的机器学习（ML）问题时，有许多不同的算法可供选择。在机器学习中，有一个称为“无免费午餐”定理的理论，该定理基本上表示没有一种ML算法对所有问题都最好。不同ML算法的性能很大程度上依赖于数据的大小和结构。因此，正确的算法选择通常不明确，除非我们通过简单的试验和错误直接测试算法。
- en: But, there are some pros and cons to each ML algorithm that we can use as guidance.
    Although one algorithm won’t always be better than another, there are some properties
    of each algorithm that we can use as a guide in selecting the correct one quickly
    and tuning hyper parameters. We’re going to take a look at a few prominent ML
    algorithms for regression problems and set guidelines for when to use them based
    on their strengths and weaknesses. This post should then serve as a great aid
    in selecting the best ML algorithm for you regression problem!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，每种机器学习（ML）算法都有其优缺点，我们可以以此作为指导。虽然一种算法并不总是优于另一种，但每种算法都有一些特性，我们可以利用这些特性快速选择合适的算法并调整超参数。我们将查看一些针对回归问题的突出的机器学习算法，并根据它们的优缺点制定使用指南。本文将作为选择最佳机器学习算法以解决回归问题的一个很好的参考！
- en: '**Linear and Polynomial Regression**'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**线性和多项式回归**'
- en: '![](../Images/c5741565cd2db9d609ffeafbb1d47950.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5741565cd2db9d609ffeafbb1d47950.png)'
- en: Linear Regression
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归
- en: Beginning with the simple case, Single Variable Linear Regression is a technique
    used to model the relationship between a single input independent variable (feature
    variable) and an output dependent variable using a linear model i.e a line. The
    more general case is Multi Variable Linear Regressionwhere a model is created
    for the relationship between multiple independent input variables (feature variables)
    and an output dependent variable. The model remains linear in that the output
    is a linear combination of the input variables.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从简单的情况开始，单变量线性回归是一种用于建模单个输入自变量（特征变量）与输出因变量之间关系的技术，即使用线性模型（即一条直线）。更一般的情况是多变量线性回归，其中创建一个模型来表示多个自变量（特征变量）与输出因变量之间的关系。模型仍然是线性的，即输出是输入变量的线性组合。
- en: There is a third most general case called Polynomial Regression where the model
    now becomes a non-linear combination of the feature variables i.e there can be
    exponential variables, sine and cosine, etc. This however requires knowledge of
    how the data relates to the output. Regression models can be trained using Stochastic
    Gradient Descent (SGD).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种第三种更一般的情况叫做多项式回归，其中模型变成了特征变量的非线性组合，即可能包含指数变量、正弦和余弦等。这需要了解数据如何与输出相关。回归模型可以使用随机梯度下降（SGD）进行训练。
- en: '**Pros:**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：**'
- en: Fast to model and is particularly useful when the relationship to be modeled
    is not extremely complex and if you don’t have a lot of data.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型建立快速，特别适用于需要建模的关系不非常复杂且数据量不大的情况。
- en: Linear regression is simple to understand which can be very valuable for business
    decisions.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归容易理解，这对商业决策非常有价值。
- en: '**Cons:**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：**'
- en: For non-linear data, polynomial regression can be quite challenging to design,
    as one must have some information about the structure of the data and relationship
    between feature variables.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于非线性数据，多项式回归的设计可能非常具有挑战性，因为必须对数据的结构和特征变量之间的关系有一些了解。
- en: As a result of the above, these models are not as good as others when it comes
    to highly complex data.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于上述原因，这些模型在处理高度复杂的数据时不如其他模型。
- en: '**Neural Networks**'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**神经网络**'
- en: '![](../Images/b79dd528e35fd383732c591cc86dfdcd.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b79dd528e35fd383732c591cc86dfdcd.png)'
- en: Neural Network
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: A Neural Network consists of an interconnected group of nodes called neurons.
    The input feature variables from the data are passed to these neurons as a multi-variable
    linear combination, where the values multiplied by each feature variable are known
    as weights. A non-linearity is then applied to this linear combination which gives
    the neural network the ability to model complex non-linear relationships. A neural
    network can have multiple layers where the output of one layer is passed to the
    next one in the same way. At the output, there is generally no non-linearity applied.
    Neural Networks are trained using Stochastic Gradient Descent (SGD) and the backpropagation
    algorithm (both displayed in the GIF above).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络由一组互相连接的节点组成，这些节点称为神经元。数据中的输入特征变量作为多变量线性组合传递给这些神经元，其中每个特征变量乘以的值称为权重。然后，对这个线性组合应用非线性，使神经网络能够建模复杂的非线性关系。神经网络可以拥有多个层，其中一层的输出以相同的方式传递给下一层。在输出处，通常不应用非线性。神经网络使用随机梯度下降（SGD）和反向传播算法（在上面的GIF中显示）进行训练。
- en: '**Pros:**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：**'
- en: Since neural networks can have many layers (and thus parameters) with non-linearities,
    they are very effective at modelling highly complex non-linear relationships.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于神经网络可以拥有许多层（因此有多个参数）和非线性，它们在建模高度复杂的非线性关系方面非常有效。
- en: We generally don’t have to worry about the structure of the data at neural networks
    are very flexible in learning almost any kind of feature variable relationships.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通常不必担心数据的结构，因为神经网络在学习几乎任何类型的特征变量关系时都非常灵活。
- en: Research has consistently shown that simply giving the network more training
    data, whether totally new or from augmenting the original data set, benefits network
    performance.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究一致表明，只要给网络更多的训练数据，无论是全新的还是通过增强原始数据集得到的，都能提升网络的性能。
- en: '**Cons:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：**'
- en: Because of the complexity of these models, they’re not easy to interpret and
    understand.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这些模型的复杂性，它们不容易解释和理解。
- en: They can be quite challenging and computationally intensive to train, requiring
    careful hyper-parameter tuning and setting of the learning rate schedule.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的训练可能非常具有挑战性且计算密集，需要仔细调整超参数和设置学习率计划。
- en: They require a lot of data to achieve high performance and are generally outperformed
    by other ML algorithms in “small data” cases.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们需要大量数据才能达到高性能，且在“小数据”情况下通常被其他机器学习算法超越。
- en: '****Regression Trees and Random Forests****'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****回归树和随机森林****'
- en: '![](../Images/bbc7d349f85c1c10074cbf7f4c908957.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bbc7d349f85c1c10074cbf7f4c908957.png)'
- en: Random Forest
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林
- en: Beginning with the base case, a Decision Tree is an intuitive model where by
    one traverses down the branches of the tree and selects the next branch to go
    down based on a decision at a node. Tree induction is the task of taking a set
    of training instances as input, deciding which attributes are best to split on,
    splitting the dataset, and recurring on the resulting split datasets until all
    training instances are categorized. While building the tree, the goal is to split
    on the attributes which create the purest child nodes possible, which would keep
    to a minimum the number of splits that would need to be made in order to classify
    all instances in our dataset. Purity is measured by the concept of information
    gain, which relates to how much would need to be known about a previously-unseen
    instance in order for it to be properly classified. In practice, this is measured
    by comparing entropy, or the amount of information needed to classify a single
    instance of a current dataset partition, to the amount of information to classify
    a single instance if the current dataset partition were to be further partitioned
    on a given attribute.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从基础情况开始，决策树是一个直观的模型，在这个模型中，人们沿着树的分支向下遍历，并根据节点的决策选择下一个要进入的分支。树的归纳任务是将一组训练实例作为输入，决定最适合拆分的属性，拆分数据集，然后对结果拆分的数据集进行递归，直到所有训练实例都被分类。在构建树时，目标是基于属性进行拆分，以创建尽可能纯净的子节点，这将使分类数据集中的所有实例所需的拆分次数最小化。纯度通过信息增益的概念来衡量，这与需要了解多少关于一个先前未见的实例以便正确分类有关。在实践中，通过比较熵，即分类当前数据集分区中的单个实例所需的信息量，与如果对当前数据集分区进行进一步拆分的情况下分类单个实例所需的信息量来进行测量。
- en: Random Forests are simply an ensemble of decision trees. The input vector is
    run through multiple decision trees. For regression, the output value of all the
    trees is averaged; for classification a voting scheme is used to determine the
    final class.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林仅仅是决策树的集成。输入向量通过多个决策树进行计算。对于回归，所有树的输出值取平均；对于分类，使用投票机制来确定最终类别。
- en: '**Pros:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：**'
- en: Great at learning complex, highly non-linear relationships. They usually can
    achieve pretty high performance, better than polynomial regression and often on
    par with neural networks.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 擅长学习复杂的、高度非线性的关系。它们通常能够实现相当高的性能，优于多项式回归，并且通常与神经网络相当。
- en: Very easy to interpret and understand. Although the final trained model can
    learn complex relationships, the decision boundaries that are built during training
    are easy and practical to understand.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常容易解释和理解。尽管最终训练的模型可以学习复杂的关系，但在训练过程中建立的决策边界容易理解且实用。
- en: '**Cons:**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：**'
- en: Because of the nature of training decision trees they can be prone to major
    overfitting. A completed decision tree model can be overly-complex and contain
    unnecessary structure. Though this can sometimes be alleviated using proper tree
    pruning and larger random forest ensembles.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于决策树训练的性质，它们可能容易出现严重的过拟合。一个完成的决策树模型可能过于复杂，并包含不必要的结构。尽管通过适当的树修剪和更大的随机森林集成可以在一定程度上缓解这个问题。
- en: Using larger random forest ensembles to achieve higher performance comes with
    the drawbacks of being slower and requiring more memory.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更大的随机森林集成来实现更高的性能有其缺点，包括速度较慢和需要更多的内存。
- en: '**Conclusion**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Boom! There’s your pros and cons! In the next post we’ll take a look at the
    pros and cons of different classification models. I hope you enjoyed this post
    and learned something new and useful. If you did, feel free to give it some claps.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这就是你的优缺点！在下一篇文章中，我们将探讨不同分类模型的优缺点。希望你喜欢这篇文章并学到了一些新知识。如果有收获，欢迎点赞。
- en: '**Bio: [George Seif](https://towardsdatascience.com/@george.seif94)** is a
    Certified Nerd and AI / Machine Learning Engineer.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [George Seif](https://towardsdatascience.com/@george.seif94)** 是一名认证的极客和人工智能/机器学习工程师。'
- en: '[Original](https://towardsdatascience.com/selecting-the-best-machine-learning-algorithm-for-your-regression-problem-20c330bad4ef).
    Reposted with permission.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/selecting-the-best-machine-learning-algorithm-for-your-regression-problem-20c330bad4ef)。经许可转载。'
- en: '**Related:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Receiver Operating Characteristic Curves Demystified (in Python)](/2018/07/receiver-operating-characteristic-curves-demystified-python.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[接收器操作特性曲线揭秘（Python版）](/2018/07/receiver-operating-characteristic-curves-demystified-python.html)'
- en: '[5 Quick and Easy Data Visualizations in Python with Code](/2018/07/5-quick-easy-data-visualizations-python-code.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 中的 5 个快速简单的数据可视化示例（附代码）](/2018/07/5-quick-easy-data-visualizations-python-code.html)'
- en: '[The 5 Clustering Algorithms Data Scientists Need to Know](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家需要了解的 5 种聚类算法](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
- en: '* * *'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能。'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 需求。'
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Things to Keep in Mind Before Selecting Your Next Data Science Job](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在选择下一个数据科学职位前需考虑的 5 个要点](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)'
- en: '[5 Step Blueprint to Your Next Data Science Problem](https://www.kdnuggets.com/5-step-blueprint-to-your-next-data-science-problem)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解决下一个数据科学问题的 5 步蓝图](https://www.kdnuggets.com/5-step-blueprint-to-your-next-data-science-problem)'
- en: '[The Range of NLP Applications in the Real World: A Different…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[现实世界中的 NLP 应用范围：一种不同的…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
- en: '[Genetic Programming in Python: The Knapsack Problem](https://www.kdnuggets.com/2023/01/knapsack-problem-genetic-programming-python.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 中的遗传编程：背包问题](https://www.kdnuggets.com/2023/01/knapsack-problem-genetic-programming-python.html)'
- en: '[Vanishing Gradient Problem: Causes, Consequences, and Solutions](https://www.kdnuggets.com/2022/02/vanishing-gradient-problem.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梯度消失问题：原因、后果及解决方案](https://www.kdnuggets.com/2022/02/vanishing-gradient-problem.html)'
- en: '[90% of Today''s Code is Written to Prevent Failure, and That''s a Problem](https://www.kdnuggets.com/2022/07/90-today-code-written-prevent-failure-problem.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[今天 90% 的代码是为了防止失败而编写的，这确实是个问题](https://www.kdnuggets.com/2022/07/90-today-code-written-prevent-failure-problem.html)'
