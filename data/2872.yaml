- en: The 5 Classification Evaluation Metrics Every Data Scientist Must Know
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个数据科学家必须知道的5种分类评估指标
- en: 原文：[https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html](https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html](https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '***What do we want to optimize for? ***Most of the businesses fail to answer
    this simple question.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '***我们想要优化什么？***大多数企业未能回答这个简单的问题。'
- en: '***Every business problem is a little different, and it should be optimized
    differently.***'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '***每个商业问题都略有不同，因此应该采取不同的优化方式。***'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We all have created classification models. A lot of time we try to increase
    evaluate our models on accuracy.*** But do we really want accuracy as a metric
    of our model performance?***
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都创建过分类模型。我们很多时候尝试通过准确率来评估我们的模型。***但我们真的希望准确率作为模型性能的指标吗？***
- en: '***What if we are predicting the number of asteroids that will hit the earth.***'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果我们预测的是会撞击地球的小行星数量呢？***'
- en: Just say zero all the time. And you will be 99% accurate. My model can be reasonably
    accurate, but not at all valuable. What should we do in such cases?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 只要说零，你将99%准确。我的模型可能在一定程度上准确，但完全没有价值。在这种情况下我们应该怎么做？
- en: '*Designing a Data Science project is much more important than the modeling
    itself.*'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*设计数据科学项目比建模本身更为重要。*'
- en: '***This post is about various evaluation metrics and how and when to use them.***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***这篇文章关于各种评估指标及其使用时机。***'
- en: '1\. Accuracy, Precision, and Recall:'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1. 准确率、精确度和召回率：
- en: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
- en: A. Accuracy
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A. 准确率
- en: Accuracy is the quintessential classification metric. It is pretty easy to understand.
    And easily suited for binary as well as a multiclass classification problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是典型的分类指标。它比较容易理解，适用于二分类以及多分类问题。
- en: '`Accuracy = (TP+TN)/(TP+FP+FN+TN)`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`准确率 = (TP+TN)/(TP+FP+FN+TN)`'
- en: Accuracy is the proportion of true results among the total number of cases examined.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是指在所有被检查的案例中，真正结果的比例。
- en: '**When to use?**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: Accuracy is a valid choice of evaluation for classification problems which are
    well balanced and not skewed or No class imbalance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平衡良好且没有偏斜或没有类别不平衡的分类问题，准确率是一个有效的评估选择。
- en: '**Caveats**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: Let us say that our target class is very sparse. Do we want accuracy as a metric
    of our model performance? ***What if we are predicting if an asteroid will hit
    the earth? ***Just say `No` all the time. And you will be 99% accurate. My model
    can be reasonably accurate, but not at all valuable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的目标类别非常稀疏。我们是否希望准确率作为模型性能的指标？***如果我们预测的是小行星是否会撞击地球？***只要说`不`，你将99%准确。我的模型可能在一定程度上准确，但完全没有价值。
- en: B. Precision
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B. 精确度
- en: 'Let’s start with *precision*, which answers the following question: what proportion
    of **predicted Positives **is truly Positive?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来谈谈*精确度*，它回答了以下问题：**预测为正例**的比例中有多少是真正的正例？
- en: '`Precision = (TP)/(TP+FP)`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`精确度 = (TP)/(TP+FP)`'
- en: In the asteroid prediction problem, we never predicted a true positive.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在小行星预测问题中，我们从未预测到真正的正例。
- en: And thus precision = 0
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，精确度 = 0
- en: '**When to use?**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: 'Precision is a valid choice of evaluation metric when we want to be very sure
    of our prediction. For example: If we are building a system to predict if we should
    decrease the credit limit on a particular account, we want to be very sure about
    our prediction or it may result in customer dissatisfaction.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要对我们的预测非常确定时，准确率是一个有效的评估指标。例如：如果我们正在建立一个预测是否应该减少某个账户的信用额度的系统，我们希望对我们的预测非常确定，否则可能会导致客户不满意。
- en: '**Caveats**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: '*Being very precise means our model will leave a lot of credit defaulters untouched
    and hence lose money.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*非常准确意味着我们的模型会遗漏很多信用违约者，从而导致损失。*'
- en: C. Recall
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C. 召回率
- en: 'Another very useful measure is* recall*, which answers a different question:
    what proportion of **actual Positives **is correctly classified?'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常有用的度量是*召回率*，它回答了一个不同的问题：**实际正例**中有多少比例被正确分类？
- en: '`Recall = (TP)/(TP+FN)`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`召回率 = (TP)/(TP+FN)`'
- en: In the asteroid prediction problem, we never predicted a true positive.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在小行星预测问题中，我们从未预测到真正的正例。
- en: And thus recall is also equal to 0.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，召回率也等于0。
- en: '**When to use?**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: 'Recall is a valid choice of evaluation metric when we want to capture as many
    positives as possible. For example: If we are building a system to predict if
    a person has cancer or not, we want to capture the disease even if we are not
    very sure.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要捕捉尽可能多的正例时，召回率是一个有效的评估指标。例如：如果我们正在建立一个预测一个人是否患有癌症的系统，即使我们不是很确定，我们也希望捕捉到这种疾病。
- en: '**Caveats**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: '***Recall is 1 if we predict 1 for all examples.***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果我们对所有样本都预测为1，则召回率为1。***'
- en: And thus comes the idea of utilizing tradeoff of precision vs. recall — ***F1
    Score***.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，引出了利用准确率与召回率之间的权衡——***F1分数***。
- en: '2\. F1 Score:'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. F1分数：
- en: This is my ***favorite evaluation metric*** and I tend to use this a lot in
    my classification projects.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我最***喜欢的评估指标***，我在分类项目中经常使用它。
- en: The F1 score is a number between 0 and 1 and is the harmonic mean of precision
    and recall.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数是介于0和1之间的一个数字，是准确率和召回率的调和均值。
- en: '![](../Images/d13bce6c7f3757567b2860521e727525.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d13bce6c7f3757567b2860521e727525.png)'
- en: Let us start with a binary prediction problem. ***We are predicting if an asteroid
    will hit the earth or not.***
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个二分类问题开始。***我们在预测小行星是否会撞击地球。***
- en: So if we say “No” for the whole training set. Our precision here is 0\. What
    is the recall of our positive class? It is zero. What is the accuracy? It is more
    than 99%.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们对整个训练集都说“不”，我们的准确率是0。那么我们正类的召回率是多少？是零。准确率是多少？超过99%。
- en: And hence the F1 score is also 0\. And thus we get to know that the classifier
    that has an accuracy of 99% is basically worthless for our case. And hence it
    solves our problem.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，F1分数也为0。因此我们了解到，准确率为99%的分类器在我们的情况下基本上没有价值。因此，它解决了我们的问题。
- en: '**When to use?**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: We want to have a model with both good precision and recall.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望模型具有良好的准确率和召回率。
- en: '![Figure](../Images/588de63fd8749e1cfea448c9144f6dbe.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/588de63fd8749e1cfea448c9144f6dbe.png)'
- en: Precision-Recall Tradeoff
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率-召回率权衡
- en: Simply stated the ***F1 score sort of maintains a balance between the precision
    and recall for your classifier***. If your precision is low, the F1 is low and
    if the recall is low again your F1 score is low.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，***F1分数在你的分类器的准确率和召回率之间保持某种平衡***。如果你的准确率很低，F1分数也会低；如果召回率很低，那么你的F1分数也会低。
- en: If you are a police inspector and you want to catch criminals, you want to be
    sure that the person you catch is a criminal (Precision) and you also want to
    capture as many criminals (Recall) as possible. The F1 score manages this tradeoff.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你是一个警察检查员，并且你想抓捕罪犯，你需要确保你抓到的人确实是罪犯（准确率），同时你还想尽可能地捕捉到更多的罪犯（召回率）。F1分数可以平衡这种权衡。
- en: '**How to Use?**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: 'You can calculate the F1 score for binary prediction problems using:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下方法计算二分类问题的F1分数：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is one of my functions which I use to get the best threshold for maximizing
    F1 score for binary predictions. The below function iterates through possible
    threshold values to find the one that gives the best F1 score.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我用来获取最大化F1分数的最佳阈值的函数之一。以下函数遍历可能的阈值，找到给出最佳F1分数的阈值。
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Caveats**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: The main problem with the F1 score is that it gives equal weight to precision
    and recall. We might sometimes need to include domain knowledge in our evaluation
    where we want to have more recall or more precision.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数的主要问题是它对准确率和召回率给予了相等的权重。有时候，我们可能需要在评估中加入领域知识，以便我们希望有更多的召回率或更多的准确率。
- en: To solve this, we can do this by creating a weighted F1 metric as below where
    beta manages the tradeoff between precision and recall.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以通过创建一个加权F1指标来实现，其中beta管理精确度和召回率之间的权衡。
- en: '![](../Images/642e02997e7d35b1a68750374c0e6542.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/642e02997e7d35b1a68750374c0e6542.png)'
- en: Here we give β times as much importance to recall as precision.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们给予召回率β倍于精确度的权重。
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: F1 Score can also be used for Multiclass problems. See [this](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1) awesome
    blog post by [Boaz Shmueli](https://medium.com/u/57ee515c83c5?source=post_page-----aa97784ff226----------------------) for
    details.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数也可以用于多类问题。有关详细信息，请查看[这篇](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)精彩的博文，作者是[Boaz
    Shmueli](https://medium.com/u/57ee515c83c5?source=post_page-----aa97784ff226----------------------)。
- en: 3\. Log Loss/Binary Cross-entropy
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 对数损失/二分类交叉熵
- en: Log loss is a pretty good evaluation metric for binary classifiers and it is
    sometimes the optimization objective as well in case of Logistic regression and
    Neural Networks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失是二分类器的一个相当好的评估指标，有时在逻辑回归和神经网络中也是优化目标。
- en: Binary Log loss for an example is given by the below formula where p is the
    probability of predicting 1.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子的二分类对数损失由以下公式给出，其中p是预测1的概率。
- en: '![](../Images/589f6701243bff934d5bab0dac0f4793.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/589f6701243bff934d5bab0dac0f4793.png)'
- en: '![](../Images/5eb3b742cca4ae0ee23b80a85487d7f6.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5eb3b742cca4ae0ee23b80a85487d7f6.png)'
- en: As you can see the log loss decreases as we are fairly certain in our prediction
    of 1 and the true label is 1.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，当我们对1的预测相当确定而真实标签也是1时，对数损失降低。
- en: '**When to Use?**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: '*When the output of a classifier is prediction probabilities. ****Log Loss
    takes into account the uncertainty of your prediction based on how much it varies
    from the actual label. ***This gives us a more nuanced view of the performance
    of our model. In general, minimizing Log Loss gives greater accuracy for the classifier.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*当分类器的输出是预测概率时。****对数损失会考虑到你的预测的不确定性，基于其与实际标签的偏差。***这为我们提供了模型性能的更细致视图。一般来说，最小化对数损失能为分类器带来更高的准确性。'
- en: '**How to Use?**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Caveats**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: It is susceptible in case of [imbalanced](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) datasets.
    You might have to introduce class weights to penalize minority errors more or
    you may use this after balancing your dataset.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在[不平衡](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c)数据集中，它是容易受到影响的。你可能需要引入类别权重以对少数类错误进行更多惩罚，或者在平衡数据集后使用它。
- en: 4\. Categorical Cross-entropy
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 分类交叉熵
- en: 'The log loss also generalizes to the multiclass problem. The classifier in
    a multiclass setting must assign a probability to each class for all examples.
    If there are N samples belonging to M classes, then the *Categorical Cross-entropy* is
    the summation of -`ylogp` values:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对数损失也可以推广到多类问题。在多类设置中，分类器必须为所有示例分配每个类别的概率。如果有N个样本属于M个类别，则*分类交叉熵*是-`ylogp` 值的总和：
- en: '![](../Images/607c37a49856b1fa9722078f40518ccb.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/607c37a49856b1fa9722078f40518ccb.png)'
- en: '`y_ij` is 1 if the sample `i` belongs to class `j` else 0'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_ij` 为1如果样本 `i` 属于类别 `j`，否则为0。'
- en: '`p_ij` is the probability our classifier predicts of sample `i` belonging to
    class `j`.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`p_ij` 是我们分类器预测样本 `i` 属于类别 `j` 的概率。'
- en: '**When to Use?**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: '*When the output of a classifier is multiclass prediction probabilities. We
    generally use Categorical Crossentropy in case of Neural Nets. *In general, minimizing
    Categorical cross-entropy gives greater accuracy for the classifier.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*当分类器的输出是多类预测概率时。我们通常在神经网络中使用分类交叉熵。*一般来说，最小化分类交叉熵能为分类器带来更高的准确性。'
- en: '**How to Use?**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Caveats:**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项：**'
- en: It is susceptible in case of [imbalanced](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) datasets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在[不平衡](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c)数据集中，它是容易受到影响的。
- en: 5\. AUC
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. AUC
- en: AUC is the area under the ROC curve.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: AUC是ROC曲线下的面积。
- en: '***AUC ROC indicates how well the probabilities from the positive classes are
    separated from the negative classes***'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '***AUC ROC 表示正类的概率与负类的概率分离得有多好***'
- en: '***What is the ROC curve?***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***什么是ROC曲线？***'
- en: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
- en: We have got the probabilities from our classifier. We can use various threshold
    values to plot our sensitivity(TPR) and (1-specificity)(FPR) on the cure and we
    will have a ROC curve.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从分类器中获得了概率。我们可以使用不同的阈值来绘制灵敏度（TPR）和（1-特异性）（FPR）的曲线，这样我们就得到了ROC曲线。
- en: Where True positive rate or TPR is just the proportion of trues we are capturing
    using our algorithm.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中真正的正率或TPR只是我们使用算法捕获的真实比例。
- en: '`Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)`'
- en: and False positive rate or FPR is just the proportion of false we are capturing
    using our algorithm.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 而假阳性率或FPR只是我们使用算法捕获的虚假比例。
- en: '`1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)`'
- en: '![Figure](../Images/c1344e1d0fb96baffeb0c4d68b4b55aa.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/c1344e1d0fb96baffeb0c4d68b4b55aa.png)'
- en: ROC Curve
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ROC曲线
- en: Here we can use the ROC curves to decide on a Threshold value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以使用ROC曲线来决定阈值。
- en: The choice of threshold value will also depend on how the classifier is intended
    to be used.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值的选择还将取决于分类器的使用意图。
- en: If it is a cancer classification application you don’t want your threshold to
    be as big as 0.5\. Even if a patient has a 0.3 probability of having cancer you
    would classify him to be 1.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个癌症分类应用，你不希望你的阈值大到0.5。即使一个患者有0.3的癌症概率，你也会将他分类为1。
- en: Otherwise, in an application for reducing the limits on the credit card, you
    don’t want your threshold to be as less as 0.5\. You are here a little worried
    about the negative effect of decreasing limits on customer satisfaction.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，在信用卡额度减少的应用中，你不希望你的阈值低至0.5。你这里有些担心减少额度对客户满意度的负面影响。
- en: '**When to Use?**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: AUC is **scale-invariant**. It measures how well predictions are ranked, rather
    than their absolute values. So, for example, if you as a marketer want to find
    a list of users who will respond to a marketing campaign. AUC is a good metric
    to use since the predictions ranked by probability is the order in which you will
    create a list of users to send the marketing campaign.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: AUC是**尺度不变**的。它衡量预测的排序效果，而不是它们的绝对值。例如，如果你作为市场营销人员想找到一个会对营销活动作出反应的用户列表。AUC是一个很好的指标，因为按概率排序的预测就是你创建用户列表以发送营销活动的顺序。
- en: Another benefit of using AUC is that it is **classification-threshold-invariant **like
    log loss. It measures the quality of the model’s predictions irrespective of what
    classification threshold is chosen, unlike F1 score or accuracy which depend on
    the choice of threshold.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AUC的另一个好处是它像对数损失一样**分类阈值不变**。它衡量模型预测的质量，而不管选择了什么分类阈值，这与F1分数或准确度不同，后者依赖于阈值的选择。
- en: '**How to Use?**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Caveats**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: Sometimes we will need well-calibrated probability outputs from our models and
    AUC doesn’t help with that.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们需要从模型中获得经过良好校准的概率输出，而AUC无法提供帮助。
- en: Conclusion
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: An important step while creating our [machine learning pipeline](https://towardsdatascience.com/6-important-steps-to-build-a-machine-learning-system-d75e3b83686) is
    evaluating our different models against each other. A bad choice of an evaluation
    metric could wreak havoc to your whole system.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建我们的[machine learning pipeline](https://towardsdatascience.com/6-important-steps-to-build-a-machine-learning-system-d75e3b83686)时，一个重要的步骤是对不同模型进行相互评估。评估指标的选择不当可能会对整个系统造成严重影响。
- en: '***So, always be watchful of what you are predicting and how the choice of
    evaluation metric might affect/alter your final predictions.***'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '***因此，始终注意你正在预测什么，以及评估指标的选择可能如何影响/改变你的最终预测。***'
- en: Also, the choice of an evaluation metric should be well aligned with the business
    objective and hence it is a bit subjective. And you can come up with your own
    evaluation metric as well.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，评估指标的选择应与业务目标充分对齐，因此有一定的主观性。你也可以自己制定评估指标。
- en: Continue Learning
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持续学习
- en: If you want to [learn](https://towardsdatascience.com/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------) more
    about how to structure a Machine Learning project and the best practices, I would
    like to call out his awesome [third course](https://click.linksynergy.com/link?id=lVarvwc5BD0&offerid=467035.11421702016&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fmachine-learning-projects) named
    Structuring Machine learning projects in the Coursera [Deep Learning Specialization](https://click.linksynergy.com/deeplink?id=lVarvwc5BD0&mid=40328&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fdeep-learning).
    Do check it out. It talks about the pitfalls and a lot of basic ideas to improve
    your models.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于如何构建机器学习项目及最佳实践的信息，我推荐他在Coursera上的精彩**第三门课程**，名为“机器学习项目结构化”，该课程属于Coursera的[深度学习专业课程](https://click.linksynergy.com/deeplink?id=lVarvwc5BD0&mid=40328&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fdeep-learning)。请务必查看一下。课程讨论了陷阱和许多基本的改进模型的想法。
- en: Thanks for the read. I am going to be writing more beginner-friendly posts in
    the future too. Follow me up at [**Medium**](https://medium.com/@rahul_agarwal?source=post_page---------------------------) or
    Subscribe to my [**blog**](http://eepurl.com/dbQnuX?source=post_page---------------------------) to
    be informed about them. As always, I welcome feedback and constructive criticism
    and can be reached on Twitter [@mlwhiz](https://twitter.com/MLWhiz?source=post_page---------------------------)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。我未来也会写更多适合初学者的文章。关注我在[**Medium**](https://medium.com/@rahul_agarwal?source=post_page---------------------------)或订阅我的[**博客**](http://eepurl.com/dbQnuX?source=post_page---------------------------)，以便获取最新内容。像往常一样，我欢迎反馈和建设性的批评，可以通过Twitter与我联系[@mlwhiz](https://twitter.com/MLWhiz?source=post_page---------------------------)
- en: Also, a small disclaimer — There might be some affiliate links in this post
    to relevant resources as sharing knowledge is never a bad idea.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，附上一个小免责声明——这篇文章中可能包含一些关联链接，因为分享知识从来不是坏主意。
- en: '**Bio: [Rahul Agarwal](https://www.linkedin.com/in/rahulagwl/)** is Senior
    Statistical Analyst at WalmartLabs. Follow him on Twitter [@mlwhiz](https://twitter.com/MLWhiz).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Rahul Agarwal](https://www.linkedin.com/in/rahulagwl/)** 是WalmartLabs的高级统计分析师。关注他的Twitter
    [@mlwhiz](https://twitter.com/MLWhiz)。'
- en: '[Original](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226).
    Reposted with permission.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226)。经许可转载。'
- en: '**Related:**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The 5 Graph Algorithms That Data Scientists Should Know](/2019/09/5-graph-algorithms-data-scientists-know.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家应该了解的5种图算法](/2019/09/5-graph-algorithms-data-scientists-know.html)'
- en: '[The Hitchhiker’s Guide to Feature Extraction](/2019/06/hitchhikers-guide-feature-extraction.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征提取的搭便车指南](/2019/06/hitchhikers-guide-feature-extraction.html)'
- en: '[6 bits of advice for Data Scientists](/2019/09/advice-data-scientists.html)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[给数据科学家的6条建议](/2019/09/advice-data-scientists.html)'
- en: More On This Topic
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[More Performance Evaluation Metrics for Classification Problems You…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更多分类问题的性能评估指标你…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习评估指标：理论与概述](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类指标演练：逻辑回归与…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解分类指标：评估模型准确性的指南](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
- en: '[KDnuggets News, May 25: The 6 Python Machine Learning Tools Every…](https://www.kdnuggets.com/2022/n21.html)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，5月25日：每个数据科学家都应该了解的6个Python机器学习工具](https://www.kdnuggets.com/2022/n21.html)'
- en: '[The 6 Python Machine Learning Tools Every Data Scientist Should Know About](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的6个Python机器学习工具](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
