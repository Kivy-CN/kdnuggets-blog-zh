- en: 'Supervised Learning: Model Popularity from Past to Present'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习：从过去到现在的模型流行度
- en: 原文：[https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html](https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html](https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Matthias Döring](https://linkedin.com/in/matthias-doering)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Matthias Döring](https://linkedin.com/in/matthias-doering)**'
- en: The field of machine learning has gone through enormous changes in the last
    decades. Admittedly, there are some methods that have been around for a long time
    and are still a staple of the field. For example, the concept of least squares
    was already proposed in the early 19th century by [Legendre](https://archive.org/details/nouvellesmthode00legegoog/)
    and [Gauss](https://www.e-rara.ch/zut/content/titleinfo/142787). Other approaches
    such as neural networks, [whose most basic form was introduced in 1958](http://psycnet.apa.org/record/1959-09865-001),
    were substantially advanced in the last decades, while other methods such as [support
    vector machines (SVMs)](https://link.springer.com/article/10.1007/BF00994018)
    are even more recent.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，机器学习领域经历了巨大的变化。诚然，一些方法已经存在了很长时间，并且仍然是该领域的主流。例如，最小二乘法的概念早在19世纪初就已由[勒让德](https://archive.org/details/nouvellesmthode00legegoog/)和[高斯](https://www.e-rara.ch/zut/content/titleinfo/142787)提出。其他方法如神经网络，[其最基本的形式在1958年被引入](http://psycnet.apa.org/record/1959-09865-001)，在过去几十年中得到了显著的进展，而像[支持向量机（SVMs）](https://link.springer.com/article/10.1007/BF00994018)这样的方法则更为近期。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Due to the large number of available approaches for supervised learning, the
    following question is often posed: **What is the best model?** As we all know,
    this question is hard to answer because, as George Box famously stated, *[a]ll
    models are wrong but some are useful*. In particular, the usefulness of the model
    critically depends on the data at hand. Thus, there is no general answer to this
    question. A question that is easier to answer is the following: **What is the
    most popular model?**. This will be the concern of this article.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于监督学习方法的种类繁多，通常会提出以下问题：**哪个模型最好？** 正如乔治·博克著名地指出的那样，这个问题很难回答，因为*所有模型都是错误的，但有些是有用的*。特别是，模型的有用性在很大程度上取决于手头的数据。因此，这个问题没有普遍的答案。一个更容易回答的问题是：**哪个模型最受欢迎？**
    这将是本文讨论的内容。
- en: Measuring the popularity of machine learning models
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量机器学习模型的流行度
- en: 'For the purposes of this article, I will define popularity using a frequentist
    approach. More precisely, I will use the number of scientific publications mentioning
    individual supervised learning models as a surrogate for popularity. Of course,
    there are some limitations to this approach:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将使用频率学派的方法来定义流行度。更准确地说，我将使用提及个别监督学习模型的科学出版物数量作为流行度的替代指标。当然，这种方法也有一些局限性：
- en: There are probably more accurate notions of popularity than the number of publications.
    For example, publications criticizing a certain model do not necessarily imply
    that the model is popular.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能存在比出版数量更准确的流行度概念。例如，批评某一模型的出版物并不一定意味着该模型很受欢迎。
- en: The analysis is influenced by the search terms that are used. To ensure high
    specificities, I did not consider model abbreviations, which is why I likely did
    not retrieve all potential hits. Moreover, sensitivity may be low for models that
    are also referenced by search terms that were not considered in the analysis.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析受到使用的搜索词的影响。为了确保高特异性，我没有考虑模型缩写，这也是我可能未能检索到所有潜在结果的原因。此外，对于那些也被未纳入分析的搜索词提及的模型，灵敏度可能较低。
- en: 'Literature databases are not perfect: sometimes, publications are stored with
    incorrect metadata (e.g. incorrect years) or there may be duplicate publications.
    Thus, some noise in the publication frequencies is to be expected.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文献数据库并不完美：有时，出版物会存储有错误的元数据（例如错误的年份），或者可能存在重复出版物。因此，出版频率中会有一些噪声是可以预期的。
- en: For this piece, I performed two analyses. The first analysis is a longitudinal
    analysis of publication frequencies, while the second analysis compares the overall
    number of publication associated with machine learning models across different
    fields.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这部分内容，我进行了两项分析。第一次分析是对出版频率的纵向分析，而第二次分析则比较了不同领域与机器学习模型相关的整体出版数量。
- en: For the first analysis, I determined the number of publications by scraping
    data from Google Scholar, which considers the titles and abstracts of scientific
    publications. To identify the number of publications associated with individual
    supervised learning approaches, I determined the number of Google Scholar hits
    between 1950 and 2017\. Since data scraping from Google Scholar is notoriously
    hard, I relied on [helpful advice from ScrapeHero](https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/)
    to gather the data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一次分析，我通过从Google Scholar抓取数据来确定出版物的数量，该数据考虑了科学出版物的标题和摘要。为了识别与单个监督学习方法相关的出版物数量，我确定了1950年至2017年间Google
    Scholar的搜索结果数量。由于从Google Scholar抓取数据非常困难，我依靠了[ScrapeHero的有用建议](https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/)来收集数据。
- en: 'I included the following 13 supervised approaches in the analysis: neural networks,
    deep learning, SVMs, random forests, decision trees, linear regression, logistic
    regression, Poisson regression, ridge regression, lasso regression, k-nearest
    neighbors, linear discriminant analysis, and log-linear models. Note that for
    lasso regression, the terms *lasso regression* and *lasso model* were considered.
    For nearest neighbors, the terms *k-nearest neighbor* and *k-nearest neighbour*
    were considered. The resulting data set indicates the [number of publications
    associated with each supervised model from 1950 until now](https://www.datascienceblog.net/data-sets/ml_models_timeline.csv).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我在分析中包括了以下13种监督学习方法：神经网络、深度学习、支持向量机、随机森林、决策树、线性回归、逻辑回归、泊松回归、岭回归、套索回归、k-最近邻、线性判别分析和对数线性模型。请注意，对于套索回归，考虑了*套索回归*和*套索模型*这两个术语。对于最近邻，考虑了*k-最近邻*和*k-最近邻*这两个术语。结果数据集显示了[从1950年至今与每种监督模型相关的出版数量](https://www.datascienceblog.net/data-sets/ml_models_timeline.csv)。
- en: Use of supervised models from 1950 until now
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从1950年至今使用监督学习模型
- en: 'To analyze the longitudinal data, I will differentiate two periods: the early
    days of machine learning (1950 to 1980), in which few models were available, and
    the formative years (1980 until now), in which interest in machine learning surged
    and many new models were developed. Note that in the following visualizations
    only the most relevant methods are shown.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析纵向数据，我将区分两个时期：机器学习的早期（1950年至1980年），在此期间模型较少，以及形成时期（1980年至今），在此期间机器学习的兴趣激增，许多新模型得到开发。请注意，在以下可视化中仅显示最相关的方法。
- en: 'Early days: dominance of linear regression'
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 早期：线性回归的主导地位
- en: '![Figure 1 Early Machine Learning](../Images/4d1a3a46952e4104de58a9c392897a9b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图1 早期机器学习](../Images/4d1a3a46952e4104de58a9c392897a9b.png)'
- en: As we can see from Figure 1, linear regression was the dominating method between
    1950 and 1980\. In comparison, other machine learning models were mentioned extremely
    rarely in the scientific literature. Starting from the 1960s, however, we can
    see that the popularity of neural networks and decision trees began to grow. We
    can also see that logistic regression was not widely available yet, with only
    slight increases in the number of mentions at the end of the 1970s.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从图1中可以看出，线性回归在1950年至1980年间是主导方法。相比之下，其他机器学习模型在科学文献中极少被提及。然而，从1960年代开始，我们可以看到神经网络和决策树的受欢迎程度开始增长。我们还可以看到逻辑回归尚未广泛应用，1970年代末期提及数量仅有轻微增加。
- en: '![Figure2 Formative Machine Learning](../Images/bc11262bb83312c653fb630b9ff4969c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图2 形成性机器学习](../Images/bc11262bb83312c653fb630b9ff4969c.png)'
- en: 'Formative years: diversification and rise of neural networks'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成长岁月：神经网络的多样化与兴起
- en: Figure 2 demonstrates that the supervised models that were mentioned in scientific
    publications became considerably more diverse starting from the late 1980s. Importantly,
    the rate at which machine learning models were mentioned in the scientific literature
    has steadily increased until 2013\. The plot particularly demonstrates the popularity
    of linear regression, logistic regression, and neural networks. As we have seen
    before, linear regression has already been popular way before 1980\. In 1980,
    however, the popularity of neural networks and logistic regression started growing
    rapidly. While the popularity of logistic regression reached its peak in 2010
    where the method nearly became as popular as linear regression, the pooled popularity
    of neural networks and deep learning (curve *Neural Network/Deep Learning* in
    Figure 2) even surpassed the popularity of linear regression in 2015.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图2表明，从1980年代末期开始，在科学出版物中提及的监督模型变得显著多样化。重要的是，机器学习模型在科学文献中的提及率一直稳步增加，直到2013年。图中特别显示了线性回归、逻辑回归和神经网络的受欢迎程度。正如我们之前看到的，线性回归在1980年之前已经非常流行。然而，从1980年开始，神经网络和逻辑回归的受欢迎程度迅速增长。虽然逻辑回归在2010年达到了顶峰，与线性回归几乎持平，但神经网络和深度学习（图2中的*神经网络/深度学习*曲线）的整体受欢迎程度在2015年甚至超过了线性回归的受欢迎程度。
- en: Neural networks have become immensely popular because they have led to breakthroughs
    in machine learning applications such as image recognition ([ImageNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks),
    2012), face recognition ([DeepFace](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Taigman_DeepFace_Closing_the_2014_CVPR_paper.html),
    2014), and gaming ([AlphaGo](https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html),
    2016). The data from Google Scholar suggest that the frequency at which neural
    networks have been mentioned in scientific articles has slightly decreased in
    the last years (not shown in Figure 2). This is likely since the term *deep learning*
    (multilayered neural networks) has supplanted the use of the term *neural network*
    to some extent. The same finding can be made using [Google Trends](https://trends.google.com/trends/explore?date=all&q=deep%20learning,neural%20network).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络变得极为流行，因为它们在图像识别（[ImageNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)，2012年）、面部识别（[DeepFace](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Taigman_DeepFace_Closing_the_2014_CVPR_paper.html)，2014年）和游戏（[AlphaGo](https://ai.googleblog.com/2016/01/alphago-mastering-ancient-game-of-go.html)，2016年）等机器学习应用中取得了突破。Google
    Scholar的数据表明，近几年神经网络在科学文章中的提及频率略有下降（图2中未显示）。这可能是因为*深度学习*（多层神经网络）在某种程度上取代了*神经网络*这一术语。使用[Google
    Trends](https://trends.google.com/trends/explore?date=all&q=deep%20learning,neural%20network)也可以得到相同的发现。
- en: The remaining, slightly less popular supervised approaches are decision trees
    and SVMs. In contrast to the top-3 methods, the rates at which these approaches
    are mentioned are decidedly smaller. On the other hand, there also seems to be
    less fluctuation in the frequency at which these methods are mentioned in the
    literature. Notably, neither the popularity of decision trees nor SVMs has yet
    declined. This is in contrast to other methods such as linear and logistic regression
    whose number of mentions has decreased considerably in the last years. Between
    decision trees and SVMs, SVM mentions seem to exhibit the more favorable growth
    trend as SVMs managed to overtake decision trees merely 15 years after their invention.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的稍微不那么受欢迎的监督方法是决策树和支持向量机。与前三种方法相比，这些方法的提及率明显较低。另一方面，这些方法在文献中的提及频率似乎也波动较小。值得注意的是，决策树和支持向量机的受欢迎程度尚未下降。这与其他方法如线性回归和逻辑回归形成对比，后者的提及数量在近年来显著减少。在决策树和支持向量机之间，支持向量机的提及量似乎展现了更有利的增长趋势，因为支持向量机在其发明仅15年后就超越了决策树。
- en: The number of mentions of the considered machine learning models peaked in 2013
    (589,803 publications) and has slightly decreased since then (462,045 publications
    in 2017).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所考虑的机器学习模型的提及数量在2013年达到了峰值（589,803篇出版物），此后略有下降（2017年为462,045篇出版物）。
- en: Popularity of supervised learning models across different fields
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不同领域的监督学习模型的受欢迎程度
- en: 'In the second analysis, I wanted to investigate whether different communities
    rely on different machine learning techniques. For this purpose, I relied on three
    repositories for scientific publications: [Google Scholar](https://scholar.google.com)
    for general publications, [dblp](https://dblp.uni-trier.de/) for computer science
    publications, and [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/) for publications
    in the biomedical sciences. In each of the three repositories, I determined [the
    frequency at which hits for the 13 machine learning models were found](https://www.datascienceblog.net/data-sets/ml_models_overall.csv).
    The results are shown in Figure 3.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次分析中，我想调查不同社区是否依赖不同的机器学习技术。为此，我依赖了三个科学出版物的数据库：[Google Scholar](https://scholar.google.com)
    用于一般出版物，[dblp](https://dblp.uni-trier.de/) 用于计算机科学出版物，以及 [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/)
    用于生物医学科学的出版物。在这三个数据库中，我确定了 [13种机器学习模型出现的频率](https://www.datascienceblog.net/data-sets/ml_models_overall.csv)。结果显示在图3中。
- en: '![Figure3 Machine Learning Fields](../Images/f5b6570bb0f2fcf2e1d6e7839efb0acd.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Figure3 Machine Learning Fields](../Images/f5b6570bb0f2fcf2e1d6e7839efb0acd.png)'
- en: Figure 3 demonstrates that many methods are quite specific to individual fields.
    In the following, let us analyze the most popular models in each field.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图3展示了许多方法对于个别领域是非常特定的。接下来，让我们分析每个领域中最受欢迎的模型。
- en: Overall use of supervised learning models
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习模型的总体使用情况
- en: 'According to Google Scholar, these are the five most frequently used supervised
    models:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Google Scholar，这五种最常用的监督模型是：
- en: '**Linear regression:** 3,580,000 (34.3%) papers'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线性回归：** 3,580,000 (34.3%) 篇论文'
- en: '**Logistic regression:** with 2,330,000 (22.3%) papers'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逻辑回归：** 2,330,000 (22.3%) 篇论文'
- en: '**Neural networks:** 1,750,000 (16.8%) papers'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经网络：** 1,750,000 (16.8%) 篇论文'
- en: '**Decision trees:** 875,000 (8.4%) papers'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**决策树：** 875,000 (8.4%) 篇论文'
- en: '**Support vector machines:** with 684,000 (6.6%) papers'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**支持向量机：** 684,000 (6.6%) 篇论文'
- en: 'Overall, linear models are clearly dominating, making up more than 50% of hits
    for supervised models. Non-linear methods are not far behind though: neural networks
    make third place with 16.8% of all papers, followed by decision trees (8.4% of
    papers) and SVMs (6.6% of papers).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，线性模型明显占据主导地位，占监督模型的超过50%的提及。非线性方法虽然不远远落后：神经网络以16.8%的论文量排第三，紧随其后的是决策树（8.4%
    的论文）和支持向量机（6.6% 的论文）。
- en: Use of models in the biomedical sciences
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生物医学科学中的模型使用
- en: 'According to PubMed, the five most popular machine learning models in the biomedical
    sciences are:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 PubMed，生物医学科学中最受欢迎的五种机器学习模型是：
- en: '**Logistic regression:** 229,956 (54.5%) papers'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逻辑回归：** 229,956 (54.5%) 篇论文'
- en: '**Linear regression:** 84,850 (20.1%) papers'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线性回归：** 84,850 (20.1%) 篇论文'
- en: '**Cox regression:** 38,801 (9.2%) papers'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Cox 回归：** 38,801 (9.2%) 篇论文'
- en: '**Neural networks:** 23,883 (5.7%) papers'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经网络：** 23,883 (5.7%) 篇论文'
- en: '**Poisson regression:** 12,978 (3.1%) papers'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**泊松回归：** 12,978 (3.1%) 篇论文'
- en: 'In the biomedical sciences, we see an over-representation in the number of
    mentions relating to linear models: four of of the five most popular methods are
    linear. This is probably due to two reasons. First, in medical settings, the number
    of samples is often too small to allow for fitting complex non-linear models.
    Second, the ability to interpret the results is critical for medical applications.
    Since non-linear methods are typically harder to interpret, they are less suited
    for medical applications because high predictive performance alone is typically
    not sufficient.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物医学科学中，我们看到与线性模型相关的提及数量过多：五种最受欢迎的方法中有四种是线性的。这可能由于两个原因。首先，在医学环境中，样本数量通常太少，无法拟合复杂的非线性模型。其次，解释结果的能力对于医学应用至关重要。由于非线性方法通常更难以解释，因此不太适合医学应用，因为仅仅高预测性能通常是不够的。
- en: The popularity of logistic regression in the PubMed data is likely due to the
    large number of publications presenting clinical studies. In these studies, the
    categorical outcome (i.e. treatment success) is often analyzed using logistic
    regression because it is well-suited for interpreting the impact of the features
    on the outcome. Note that that Cox regression is so popular in the PubMed data
    because it is frequently used for analyzing Kaplan-Meier survival data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PubMed 数据中逻辑回归的流行可能与大量展示临床研究的出版物有关。在这些研究中，分类结果（即治疗成功）通常使用逻辑回归进行分析，因为它非常适合解释特征对结果的影响。请注意，Cox
    回归在 PubMed 数据中如此受欢迎，因为它常用于分析 Kaplan-Meier 生存数据。
- en: Use of models in computer science
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机科学中的模型使用
- en: 'The five most popular models in the computer science bibliography retrieved
    from dblp are:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从 dblp 检索的计算机科学参考文献中，五种最受欢迎的模型是：
- en: '**Neural networks:** 63,695 (68.3%) papers'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经网络：** 63,695 (68.3%) 篇论文'
- en: '**Deep learning:** 10,157 (10.9%) papers'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**深度学习：** 10,157 (10.9%) 篇论文'
- en: '**Support vector machines:** 7,750 (8.1%) papers'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**支持向量机：** 7,750 (8.1%) 篇论文'
- en: '**Decision trees:** 4,074 (4.4%) papers'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**决策树：** 4,074 (4.4%) 篇论文'
- en: '**Nearest neighbors:** 3,839 (2.1%) papers'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最近邻：** 3,839 (2.1%) 篇论文'
- en: 'The distribution of machine learning models mentioned in computer science publications
    is quite distinct: the majority of publications seems to deal with recent, non-linear
    methods (e.g. neural networks, deep learning, and support vector machines). If
    we include deep learning, more than three quarters of the retrieved computer science
    publications deal with neural networks.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学出版物中提到的机器学习模型的分布非常独特：大多数出版物似乎涉及最近的非线性方法（例如神经网络、深度学习和支持向量机）。如果我们包括深度学习，那么检索到的计算机科学出版物中超过四分之三的内容涉及神经网络。
- en: A cleavage between communities
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 社区之间的分裂
- en: '![Figure4 Types of ML models in different fields](../Images/be44399c2228e9e9cee01ba99effe8cf.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图4 不同领域中的机器学习模型类型](../Images/be44399c2228e9e9cee01ba99effe8cf.png)'
- en: Figure 4 summarizes the percentage of parametric (including semi-parametric)
    and non-parametric models that are mentioned in the literature. The bar plot demonstrates
    that there is a big difference between the models investigated in machine learning
    research (as evidenced by computer science publications) and the types of models
    that are applied (as evidenced by biomedical and overall publications). While
    more than 90% of computer science publications deal with non-parametric models,
    roughly 90% of biomedical publications deal with parametric models. This showcases
    that machine learning research is heavily focused on state-of-the-art methods
    such as deep neural networks, while users of machine learning often rely on more
    interpretable, parametric models.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4 总结了文献中提到的参数模型（包括半参数模型）和非参数模型的百分比。条形图显示，机器学习研究中探讨的模型（计算机科学出版物的证据）与实际应用的模型类型（生物医学和总体出版物的证据）之间存在很大差异。尽管超过
    90% 的计算机科学出版物涉及非参数模型，但大约 90% 的生物医学出版物涉及参数模型。这表明机器学习研究高度集中于最先进的方法，如深度神经网络，而机器学习的用户往往依赖于更具可解释性的参数模型。
- en: Summary
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: This analysis of mentions of individual supervised learning models in the scientific
    literature showcases the high popularity of artificial neural networks. However,
    we also see that different types of machine learning models are used in different
    fields. Particularly researchers in the biomedical sciences still heavily rely
    on parametric models. It will be interesting to see whether more complex models
    will find widespread use in the biomedical field or whether these models are simply
    not appropriate for typical applications in this sector (e.g. due to insufficient
    interpretability of these models and low generalizability when the sample size
    is small).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对科学文献中个体监督学习模型提及的分析展示了人工神经网络的高度普及。然而，我们也看到不同类型的机器学习模型在不同领域的使用情况。特别是在生物医学科学领域，研究人员仍然大量依赖参数模型。值得关注的是，是否更复杂的模型会在生物医学领域得到广泛应用，还是这些模型由于解释性不足和在样本量小的情况下泛化能力差，而不适用于该领域的典型应用。
- en: '**Bio**: [Matthias Döring](https://linkedin.com/in/matthias-doering) graduated
    as a Master of Science (Bioinformatics) from Saarland University. He is currently
    a PhD candidate at the Max Planck Institute for Informatics where he develops
    computational approaches for improving the treatment and prevention of viral infections.
    Besides supervised learning, he is interested in deploying machine learning models
    through web services and blogging about data science applications with R at [datascienceblog.net](https://www.datascienceblog.net/).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介**：[马蒂亚斯·多林](https://linkedin.com/in/matthias-doering)从萨尔大学获得生物信息学硕士学位。他目前是马克斯·普朗克信息学研究所的博士生，专注于开发改进病毒感染治疗和预防的计算方法。除了监督学习，他还对通过网络服务部署机器学习模型感兴趣，并在
    [datascienceblog.net](https://www.datascienceblog.net/) 上撰写关于数据科学应用的博客。'
- en: '**Resources:**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Multi-Class Text Classification with Doc2Vec & Logistic Regression](https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Doc2Vec 和逻辑回归进行多分类文本分类](https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html)'
- en: '[5 Reasons Logistic Regression should be the first thing you learn when becoming
    a Data Scientist](https://www.kdnuggets.com/2018/05/5-reasons-logistic-regression-first-data-scientist.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为数据科学家时学习逻辑回归的5个理由](https://www.kdnuggets.com/2018/05/5-reasons-logistic-regression-first-data-scientist.html)'
- en: '[A Tour of The Top 10 Algorithms for Machine Learning Newbies](https://www.kdnuggets.com/2018/02/tour-top-10-algorithms-machine-learning-newbies.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手机器学习的前10大算法巡礼](https://www.kdnuggets.com/2018/02/tour-top-10-algorithms-machine-learning-newbies.html)'
- en: More On This Topic
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[The Psychology of Data Visualization: How to Present Data that Persuades](https://www.kdnuggets.com/the-psychology-of-data-visualization-how-to-present-data-that-persuades)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据可视化的心理学：如何展示具有说服力的数据](https://www.kdnuggets.com/the-psychology-of-data-visualization-how-to-present-data-that-persuades)'
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中使用的主要监督学习算法](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
- en: '[KDnuggets News, June 22: Primary Supervised Learning Algorithms…](https://www.kdnuggets.com/2022/n25.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，6月22日：主要监督学习算法…](https://www.kdnuggets.com/2022/n25.html)'
- en: '[Hands-On with Supervised Learning: Linear Regression](https://www.kdnuggets.com/handson-with-supervised-learning-linear-regression)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实践监督学习：线性回归](https://www.kdnuggets.com/handson-with-supervised-learning-linear-regression)'
- en: '[Understanding Supervised Learning: Theory and Overview](https://www.kdnuggets.com/understanding-supervised-learning-theory-and-overview)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解监督学习：理论与概述](https://www.kdnuggets.com/understanding-supervised-learning-theory-and-overview)'
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2：Meta AI 的自监督计算机视觉模型](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
