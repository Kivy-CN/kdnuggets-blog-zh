# 人工智能系统中的不确定性量化

> 原文：[https://www.kdnuggets.com/2022/04/uncertainty-quantification-artificial-intelligencebased-systems.html](https://www.kdnuggets.com/2022/04/uncertainty-quantification-artificial-intelligencebased-systems.html)

# 摘要

尽管基于人工智能（AI）的系统前景广阔，并且越来越多地被用于协助各种复杂任务，但由于不确定性带来的挑战，这些结果并不完全可靠。不确定性量化（UQ）在优化和决策过程中减少不确定性方面发挥了关键作用，应用于解决科学、商业和工程中的各种现实世界应用。本文简明扼要地介绍了不确定性的概念、来源、类型和测量。文章总结了使用贝叶斯技术的多种UQ方法，展示了文献中的问题和不足，提出了进一步的方向，并概述了金融犯罪领域的人工智能系统。

# 引言

近年来，对基于人工智能的系统的需求增加，这些系统本质上是主动的，需要根据事件或环境变化自动行动。这些系统涉及多个领域，从主动数据库到驱动现代企业核心业务流程的应用。然而，在许多情况下，系统必须响应的事件不是由监控工具生成的，而是需要基于复杂的时间谓词从其他事件中推断。机器学习（ML）模型基于其训练数据生成最佳解决方案。在许多应用中，这种推断本质上是不确定的。然而，如果不考虑数据和模型参数中的不确定性，这些最佳解决方案在实际世界中的部署风险很高。

典型的基于人工智能的系统流程包括收集数据、对数据进行预处理、选择一个模型以从数据中学习、选择一个学习算法来训练选定的模型，并从学习到的模型中得出推论。然而，这些步骤中固有的不确定性是不可避免的。例如，数据不确定性可能源于无法可靠地收集或表示真实世界的数据。数据预处理中的缺陷，无论是在策划、清理还是标注过程中，也会产生数据不确定性。由于模型仅作为真实世界的代理，而学习和推理算法依赖于各种简化假设，因此它们引入了建模和推理不确定性。人工智能系统的预测容易受到这些不确定性来源的影响。可靠的不确定性估计为人工智能系统的开发者和用户提供了重要的诊断信息。例如，高数据不确定性可能指向需要改进数据表示过程，而高模型不确定性可能建议需要收集更多数据。对于用户来说，准确的不确定性，尤其是当与有效的沟通策略相结合时，可以增加透明度和信任，这对更好的人工智能辅助决策至关重要。在医学、金融和社会科学等高风险应用中，对人工智能系统的这种信任对于其可靠部署至关重要。

这些观察重新激发了我对不确定性量化（UQ）研究的兴趣。虽然已经提出了许多改进人工智能系统中UQ的方法，但选择特定的UQ方法取决于许多因素：基础模型、机器学习任务的类型（回归、分类或分割）、数据的特征、机器学习模型的透明性和最终目标。如果不当使用，特定的UQ方法可能会产生不良的不确定性估计，并误导用户。此外，即使是非常准确的不确定性估计，如果沟通不善，也可能产生误导。

本文提供了对不确定性类型的扩展介绍，并描述了其来源，讨论了UQ方法，形式化了不确定建模，并阐述了其在复杂系统中的概念。文章概述了在机器学习中使用贝叶斯技术量化不确定性的不同方法。此外，还重点关注了在不同机器学习任务（如分类、回归和分割）中不确定性测量的评估。本文提供了UQ方法中的校准术语，列出了文献中的开放问题，展示了在金融犯罪领域的实际应用中的UQ，并制定了这种系统的通用评估框架。

# 随机不确定性

随机性不确定性（即统计不确定性），是指每次运行相同实验时所出现的未知因素的代表。随机性不确定性指的是由于概率变异性引起的固有不确定性。这种类型的不确定性是不可减少的，因为底层变量总会存在变异。这些不确定性由概率分布特征化。例如，用机械弓射出的单箭，虽然每次发射（相同的加速度、高度、方向和最终速度）都完全重复，但由于箭杆的随机和复杂的振动，箭矢的撞击点不会都落在目标的同一点上，而对这些振动的知识不足以消除撞击点的散布。

# 认识论不确定性

认识论不确定性（即系统性不确定性），是由于一些原则上可以知道但实际上不知道的事情所致。认识论不确定性是对过程模型中的科学不确定性的体现。这是由于数据和知识的有限性造成的。认识论不确定性通过替代模型来表征。对于离散随机变量，认识论不确定性通过替代概率分布进行建模。这种不确定性的一个例子是设计用来测量接近地球表面引力的实验中的拉力。常用的9.8 m/s²的引力加速度忽略了空气阻力的影响，但可以测量物体的空气阻力并将其纳入实验中，从而减少计算引力加速度的结果不确定性。

# 随机性和认识论不确定性互动

随机性和认识论不确定性也可以在单一术语中同时出现，例如，当实验参数表现出随机性不确定性，并且这些实验参数被输入到计算机模拟中时。如果在不确定性量化中使用了替代模型，例如高斯过程或[多项式混沌展开](https://en.wikipedia.org/wiki/Polynomial_chaos#:~:text=Polynomial%20chaos%20(PC)%2C%20also,function%20of%20other%20random%20variables.)，从计算机实验中学习到的这个替代模型会展现出依赖于或与实验参数的随机性不确定性相互作用的认识论不确定性。这种不确定性不能单独归类为随机性或认识论不确定性，而是更一般的推理不确定性。在实际应用中，这两种不确定性同时存在。不确定性量化旨在明确地分别表达这两种不确定性。

对于 aleatoric 不确定性的量化可以相对直接，传统的（频率学派）概率是最基本的形式。蒙特卡罗方法等技术经常被使用。为了评估 epistemic 不确定性，努力去理解系统、过程或机制的知识缺乏。Epistemic 不确定性通常通过贝叶斯概率的视角来理解，其中概率被解释为表示理性人对特定主张的确定程度。

# 模型和数据不确定性

模型不确定性涵盖了由于模型不足所造成的不确定性，这些不足可能是由于训练过程中的错误、模型结构的不充分，或者由于样本未知或训练数据集覆盖不佳导致的知识缺乏。与此相比，数据不确定性与直接源自数据的不确定性相关。数据不确定性是由于在数据样本中表示真实世界和分布时的信息丢失所造成的。

例如，在回归任务中，输入和目标测量中的噪声导致了数据不确定性，网络无法学会纠正。在分类任务中，样本没有足够的信息来以100%确定性识别一个类别，这会导致预测中的数据不确定性。信息丢失是测量系统的结果，例如通过特定分辨率的图像像素表示真实世界的信息，或通过标记过程中的错误。

虽然模型不确定性可以通过改进架构、学习过程或训练数据集（理论上）来减少，但数据不确定性是无法通过解释来消除的。

# 预测不确定性

基于输入数据领域，预测不确定性还可以分为三大类：

+   域内不确定性：代表了与从假定为等于训练数据分布的数据分布中抽取的输入相关的不确定性。域内不确定性源于深度神经网络由于缺乏域内知识而无法解释域内样本。从建模者的角度来看，域内不确定性由设计错误（模型不确定性）和问题的复杂性（数据不确定性）造成。根据域内不确定性的来源，可以通过提高训练数据（集）或训练过程的质量来减少它。

+   域迁移不确定性：表示与从训练分布的偏移版本中抽取的输入相关的不确定性。分布偏移源于训练数据的覆盖不足以及真实世界情况固有的变异性。域迁移可能增加不确定性，因为 DNN 无法解释训练时基于样本的域迁移样本。一些导致域迁移不确定性的错误可以被建模，因此可以减少。

+   跨领域不确定性：表示与从未知数据子空间中提取的输入相关的不确定性。未知数据的分布与训练分布不同且相差甚远。例如，当领域转移不确定性描述像模糊的狗照片这样的现象时，跨领域不确定性描述的是当一个学习了猫和狗分类的网络被要求预测一只鸟的情况。跨领域不确定性源于深度神经网络（DNN）由于缺乏跨领域知识而无法解释跨领域样本。从建模者的角度来看，跨领域不确定性由输入样本造成，这些样本网络并未用于预测，或由训练数据不足造成。

![不确定性类型](../Images/6c3c346df9ccf8e86bbfbec46336d0cd.png) 图1：不确定性类型

# 不确定性与变异性

技术专家经常被要求对不确定量估计“范围”。重要的是要区分他们是否被要求提供变异范围或不确定范围。同样，模型构建者需要知道他们是在建立变异模型还是不确定模型，并了解其关系（如果有的话）。

**不确定性的来源**

+   参数不确定性：来源于输入到数学模型中的模型参数，但实验人员的确切值未知，无法在物理实验中控制，或无法通过统计方法准确推断其值。例如，掉落物体实验中的局部自由落体加速度。

+   参数变异性：来源于模型输入变量的变异。例如，数据中的尺寸可能与假设的不完全相同，这会导致在这个高维数据集上训练的模型表现出变异性。

+   结构性不确定性：也称为模型不适应性、模型偏差或模型差异，来源于对问题中基础物理或原则知识的缺乏。它取决于数学模型在现实情况中对真实系统的描述准确程度，考虑到模型几乎总是对现实的近似。例如，当使用自由落体模型对掉落物体过程进行建模时，由于存在空气阻力，模型本身是不准确的。在这种情况下，即使模型中没有未知参数，模型和真实物理之间仍然会有差异。结构性不确定性存在于我们对模型输出不确定时，因为我们对模型的函数形式不确定。

+   算法不确定性：也称为数值不确定性或离散不确定性。这种类型的不确定性来源于数值错误和计算机模型实现中的数值近似。大多数模型过于复杂，无法精确求解。例如，有限元法或有限差分法可能用于近似求解偏微分方程（这会引入数值错误）。

+   实验不确定性：也称为观测误差。它源于实验测量的变异性。实验不确定性是不可避免的，可以通过多次重复测量并使用完全相同的设置来注意到。

+   插值不确定性：这来源于从模型模拟和/或实验测量中收集的可用数据的不足。对于没有模拟数据或实验测量的其他输入设置，必须进行插值或外推以预测相应的响应。

# 问题类型

不确定性量化中有两种主要问题：一种是前向不确定性传播（即将各种不确定性来源通过模型传播以预测系统响应中的整体不确定性），另一种是模型不确定性和参数不确定性的逆向评估（即使用测试数据同时标定模型参数）。

**前向** ([propagation of uncertainty](https://en.wikipedia.org/wiki/Propagation_of_uncertainty))

不确定性传播是将不确定输入引起的不确定性量化到系统输出中。它关注于不确定性来源中列出的参数变异性对输出的影响。不确定性传播分析的目标可以是：

1.  评估输出的低阶矩，即均值和方差

1.  评估输出的可靠性

1.  评估输出的完整概率分布

**逆向** ([inverse problem](https://en.wikipedia.org/wiki/Inverse_problem))

给定系统的一些实验测量值和来自其数学模型的一些计算机模拟结果，逆向不确定性量化估计实验与数学模型之间的差异（即偏差修正），并估计模型中未知参数的值（即参数标定或简单地称为标定）。

通常，这比前向不确定性传播问题要困难得多；然而，它非常重要，因为它通常在模型更新过程中实施。逆向不确定性量化有几种情境：

1.  仅偏差修正：偏差修正量化模型的不适当性，即实验与数学模型之间的差异

1.  参数标定仅：参数标定估计数学模型中一个或多个未知参数的值。

1.  偏差校正和参数校准：考虑一个具有一个或多个未知参数的不准确模型，其模型更新形式将两者结合起来：这是最全面的模型更新形式，涵盖所有可能的不确定性来源，且需要最多的解决工作。

![不确定性量化中的问题类型](../Images/7897631f8ff6a998ab71d7f305c1b6c2.png) 图 2: 不确定性量化中的问题类型

# 数学形式化

正如我们之前所述（图 1），预测不确定性由两部分组成：认知不确定性和*随机不确定性*，可以表示为这两部分的和：

![XXXXX](../Images/2a448d94ad432369453bf6b08e6ad3e9.png)

认知不确定性可以被表述为对模型参数的概率分布。

设

![XXXXX](../Images/d61d9b41b27d3b9a6573d04381fcb7fc.png)

表示具有输入的训练数据集

![XXXXX](../Images/fbf147decb536dd3743e4a7107c5bcb1.png)

其中 *C* 表示类别数。目标是优化参数

![XXXXX](../Images/bb31d7fa39f8d9299b96485bfb2c2503.png)![XXXXX](../Images/d2f057cd10c5d4c44cbc65b23ab8ca6a.png)

对于分类问题，可以使用 softmax 似然函数：

![XXXXX](../Images/420e87e39a215caf5e3573e5319ecb15.png)

Eq.1

对于回归问题，可以假设高斯似然函数：

![XXXXX](../Images/aac9e8da75f6fe27305e50740b665dcb.png)

Eq.2

![XXXXX](../Images/2ebb528a6c65684f4670c31d371f220b.png)

通过应用贝叶斯定理可以写成如下形式：

![XXXXX](../Images/804d6c3ba4809d62432771207d50c957.png)

Eq.3

![XXXXX](../Images/416e9f9c635e06598698649077abcca7.png)

![XXXXX](../Images/1d0404f81cd048fbfc6c096d3cd07117.png)

Eq.4

这个过程称为推断或边际化。然而，

![XXXXX](../Images/84c09ec8626d73bba595db710a9e5a87.png)

不能通过解析方法计算，但可以通过变分参数来近似

![XXXXX](../Images/612681c3a98057feaaf58fc7f26ab2c0.png)

目标是近似一个与模型获得的后验分布接近的分布。因此，需要最小化与?的 Kullback-Leibler (KL) 散度。两分布之间的相似度可以如下测量：

![Eq.5](../Images/7f0a5281e6330144441ea952f4669786.png)

Eq.5

预测分布可以通过最小化 KL 散度来进行近似，如下所示：

![XXXXX](../Images/045606288218f0d26c0ead25b4027755.png)

Eq.6

其中

![XXXXX](../Images/01fc5e99ba0117c6ddb92398aacb03a2.png)

表示优化的目标。KL 散度最小化也可以重新排列为*证据下界* (ELBO) 最大化：

![Eq.7](../Images/0160825c0c393a04087d25ffea3064c9.png)

Eq.7

其中

![XXXXX](../Images/612681c3a98057feaaf58fc7f26ab2c0.png)

通过最大化第一项并尽可能最小化第二项来很好地描述数据。这个过程称为变分推断（VI）。Dropout VI 是一种最常见的方法，被广泛用于近似复杂模型中的推断。最小化目标如下：

![Eq.8](../Images/e78c8b271aa117e8ff5685435dd9b83e.png)

Eq.8

其中 *N* 和 *P* 分别代表样本数量和 dropout 概率。为了获得数据依赖的不确定性，可以将精度 ? 在（Eq.2）中制定为数据的函数。获得认识性不确定性的一种方法是混合两个函数：

![XXXXX](../Images/f98c43ce329d6b8c7018df06484830ae.png)![XXXXX](../Images/3e6791bfbd5d4b372ef36d3a482a634c.png)

对模型的权重施加先验分布，然后计算在给定数据样本下权重的变化量。欧几里得距离损失函数可以如下调整：![Eq.9](../Images/a6b005c34b1b23ddf318341b9424a094.png)

Eq.9

预测方差可以如下获得：

![Eq.10](../Images/890956d81106099b72720714dcf0a42f.png)

Eq.10

# 选择性方法

尽管已进行了大量研究来解决不确定性量化问题，但大多数研究处理的是不确定性传播。在过去的一到两十年里，也开发了许多针对逆不确定性量化问题的方法，并证明对大多数小到中等规模的问题非常有用。

![图 3：不确定性量化的选择性方法](../Images/bd9a7340a075c12d5fbe03ee953644d8.png)

图 3：不确定性量化的选择性方法

## 前向传播

+   基于模拟的方法：蒙特卡洛模拟、重要性采样、自适应采样等。

+   一般替代模型方法：在非侵入式方法中，学习一个替代模型以用便宜和快速的近似代替实验或模拟。替代模型方法也可以以完全贝叶斯方式使用。这种方法在采样成本极高（例如计算昂贵的模拟）时特别有效。

+   局部展开方法：泰勒级数、扰动方法等。这些方法在处理相对较小的输入变异性和输出不表现高非线性的情况下具有优势。这些线性或线性化方法在《不确定性传播》一文中有详细介绍。

+   基于函数展开的方法：纽曼展开、正交或 Karhunen–Loeve 展开（KLE），以及多项式混沌展开（PCE）和小波展开作为特例。

+   最可能点（MPP）方法：一阶可靠性方法（FORM）和二阶可靠性方法（SORM）。

+   基于数值积分的方法：完全因子数值积分（FFNI）和维度减少（DR）。

对于非概率方法，区间分析、模糊理论、可能性理论和证据理论是最广泛使用的方法之一。

概率方法被认为是工程设计中不确定性分析最严格的方法，因为它与决策分析理论一致。其核心是计算用于采样统计的概率密度函数。这可以对可以作为高斯变量变换获得的随机变量进行严格计算，从而得到精确的置信区间。

## 反向不确定性

1.  频率学派**：**参数估计的标准误差是 readily available的，可以扩展为置信区间。

1.  贝叶斯**：**在贝叶斯框架下存在几种反向不确定性量化的方法。最复杂的方向是解决既有偏差校正又有参数标定的问题。这类问题的挑战不仅包括模型不适应和参数不确定性的影响，还包括来自计算机模拟和实验的数据不足。一个常见的情况是实验和模拟中的输入设置不同。另一个常见情况是从实验中得出的参数被输入到模拟中。对于计算上昂贵的模拟，通常需要一个替代模型，例如高斯过程或多项式混沌展开，定义一个反问题以找到最能逼近模拟的替代模型。

1.  模块化方法：反向不确定性量化的一种方法是模块化贝叶斯方法。模块化贝叶斯方法的名称源于其四个模块的过程。除了当前可用的数据外，还应为未知参数指定先验分布。

    +   高斯过程建模用于模型：为了解决缺乏模拟结果的问题，计算机

        模型被替换为高斯过程（GP）模型

    +   高斯过程建模用于不一致函数：类似于第一个模块，不一致

        函数被替换为 GP 模型

    +   未知参数的后验分布：应用贝叶斯定理计算后验

        未知参数的分布：

    +   实验响应和不一致函数的预测

1.  完全方法：完全贝叶斯方法要求不仅为未知参数指定先验，还需要为其他超参数指定先验。

![使用贝叶斯技术的不确定性量化](../Images/b9d9782932ffb4523b625aabb18437d2.png)

图 4：使用贝叶斯技术的不确定性量化

# 机器学习中的不确定性量化

![XXXXX](../Images/016a2eebcb95d3ddc34d69dda32de7f0.png)

图 5：机器学习中的不确定性量化分类

# 评估分类

+   在分类任务中测量数据不确定性：给定预测，概率向量表示一个类别分布，即为每个类别分配一个成为正确预测的概率。由于预测不是以明确类别的形式给出，而是以概率分布的形式给出，因此可以直接从预测中得出不确定性估计。通常，这种逐点预测可以被视为估计的数据不确定性。然而，模型对数据不确定性的估计会受到模型不确定性的影响，这需要单独考虑。为了评估预测的数据不确定性的量，可以例如应用最大类别概率或熵度量。最大概率代表了确定性的直接表示，而熵描述了随机变量中的信息平均水平。不过，无法仅从单个预测中判断影响该特定预测的模型不确定性有多大。

+   在分类任务中测量模型不确定性：对学习到的模型参数的近似后验分布可以帮助获得更好的不确定性估计。通过这种后验分布，可以评估变异，即随机变量的不确定性。最常见的度量包括互信息（MI）、期望Kullback-Leibler散度（EKL）和预测方差。基本上，这些度量都是计算随机输出与期望输出之间的期望差异。当关于模型参数的知识没有增加最终预测中的信息时，MI最小。因此，MI可以被解释为模型不确定性的度量。Kullback-Leibler散度度量两个给定概率分布之间的差异。EKL可以用来测量可能输出之间的（期望）差异，这也可以被解释为对模型输出的不确定性的度量，因此代表模型不确定性。即使对于一个分析描述的分布，参数不确定性传播到预测中在几乎所有情况下都是不可处理的，必须例如通过蒙特卡罗近似来进行近似。

![XXXXX](../Images/e3ec18b810c6fa2cdfb6441fdc72725c.png)

图6：分类模型中模型和分布不确定性的可视化。***来源****：Jakob Gawlikowski 等人，2022年《深度神经网络不确定性调查》*

+   在分类任务中测量分布不确定性：尽管这些不确定性度量广泛用于捕捉来自贝叶斯神经网络的多个预测之间的变异性，但集成方法无法捕捉输入数据中的分布变化或分布外的示例，这可能导致偏倚的推断过程和错误的置信度陈述。如果所有预测器将较高的概率质量分配给相同的（错误的）类别标签，这会导致估计之间的变异性低。因此，系统似乎对其预测充满信心，而预测本身的不确定性也在下文中进行评估。

![XXXXX](../Images/9b131caebdca2a171fcca6bbec41d101.png)

图7：分类模型的模型和分布不确定性的可视化。***来源****：Jakob Gawlikowski等人2022年《深度神经网络中的不确定性调查》*

+   完整数据集上的性能度量：虽然上述度量评估了单个预测的性能，但其他度量评估了这些度量在样本集上的使用。不确定性度量可以用于区分正确分类和错误分类的样本，或区分领域内和分布外样本。为此，样本被分为两个集合，例如领域内和分布外，或正确分类和错误分类。最常见的两种方法是接收器操作特征（ROC）曲线和精准召回（PR）曲线。这两种方法根据基础度量的不同阈值生成曲线。虽然ROC和PR曲线提供了基础度量如何适合区分两个考虑的测试案例的视觉概念，但它们没有给出定性度量。为了达到这一点，可以评估曲线下面积（AUC）。大致来说，AUC提供了一个概率值，表示随机选择的正样本比随机选择的负样本具有更高度量的可能性。

# 回归评估

+   回归预测中的数据不确定性测量：与分类任务不同，回归任务只预测点估计，而没有数据不确定性的提示。一种常见的方法是让网络预测概率分布的参数，例如，正态分布不确定性的均值向量和标准差。这样，数据不确定性就被直接给出。标准差的预测允许进行分析性描述，即（未知的）真实值位于特定区域内。覆盖真实值的区间具有一定的概率（在假设预测分布正确的情况下）是分位数函数，即累积分布函数的逆函数。对于给定的概率值，分位数函数给出一个边界。分位数假定某种概率分布，并将给定预测解释为该分布的期望值。

与此相反，其他方法直接预测所谓的预测区间（PI），在该区间内假定预测值会落入。这样的区间产生的不确定性表现为均匀分布，而没有给出具体的预测。此类方法的确定性可以像名称所示，通过预测区间的大小直接测量。均值预测区间宽度（MPIW）可用于评估模型的平均确定性。为了评估预测区间的正确性，可以应用预测区间覆盖概率（PICP）。PICP 表示落入预测区间的测试预测值的百分比。

+   回归预测中的模型不确定性测量：模型不确定性主要由模型的结构、训练过程以及训练数据中未充分代表的区域引起。因此，回归任务和分类任务在模型不确定性的原因和影响上没有真正的区别，即回归任务中的模型不确定性可以与分类任务一样进行测量，即在大多数情况下，通过近似平均预测值并测量单个预测值之间的差异。

![XXXXX](../Images/da18a2598e622106a3b540f990959452.png)

图 8：回归模型的模型及分布不确定性的可视化。***来源****：深度神经网络中的不确定性调查，Jakob Gawlikowski 等，2022 年*

![XXXXX](../Images/bd359bb45ebb7a3d1ae7641c63bdd67d.png)

图 9：回归模型的模型及分布不确定性的可视化。***来源****：深度神经网络中的不确定性调查，Jakob Gawlikowski 等，2022 年*

+   在分割任务中评估不确定性：分割任务中的不确定性评估与分类问题的评估非常相似。分割任务中的不确定性通过贝叶斯推断的近似值来估计。在分割的背景下，像素级分割的不确定性通过置信区间、预测方差、预测熵或互信息 (MI) 来衡量。结构估计中的不确定性通过对所有像素级不确定性估计进行平均来获得。体积不确定性的质量通过评估变异系数、平均 Dice 分数或交集并集来评估。这些指标以成对方式测量多个估计之间区域重叠的一致性。理想情况下，错误分割应导致像素级和结构不确定性的增加。要验证是否如此，应评估像素级的真正阳性率，并评估不同不确定性阈值下的假检测率以及保留像素的 ROC 曲线。

# 校准

预测器被称为校准良好，如果所得到的预测置信度能很好地近似实际的正确概率。因此，为了利用不确定性量化方法，必须确保系统已经过良好校准。对于回归任务，校准可以定义为预测的置信区间应该与从数据集中经验计算得到的置信区间相匹配。

一般来说，校准误差是由与模型不确定性相关的因素引起的。这一点直观上是清楚的，因为数据不确定性表示输入 *x* 和目标 *y* 表示相同的现实世界信息的基本不确定性。接下来，正确预测的数据不确定性将导致系统完美校准。这一点很清楚，因为这些方法分别量化了模型和数据不确定性，并旨在减少预测中的模型不确定性。除了通过减少模型不确定性来改善校准的方法外，越来越多的文献研究了显式减少校准误差的方法。这些方法将在下文中介绍，随后是量化校准误差的措施。需要注意的是，这些方法并不减少模型不确定性，而是将模型不确定性传播到数据不确定性的表示上。

例如，如果一个二分类器过拟合，并且将测试集中的所有样本预测为类别 A，概率为 1，而测试样本中实际上有一半是类别 B，那么重新校准方法可能会将网络输出映射到 0.5，以获得可靠的置信度。这个 0.5 的概率不等同于数据不确定性，而是代表了传播到预测数据不确定性的模型不确定性。

## 校准方法

校准方法可以根据其应用的步骤分为三大类：

+   训练阶段应用的正则化方法：这些方法修改目标、优化和/或正则化过程，以构建本质上已校准的系统和网络。

+   训练过程后应用的后处理方法：这些方法需要一个独立的校准数据集来调整预测分数以进行再校准。它们仅在假设留下的验证集的分布等于进行推断的分布的情况下有效。因此，验证数据集的大小也会影响校准结果。

+   神经网络不确定性估计方法：减少神经网络置信预测模型不确定性的方法，也能得到更好的校准预测器。这是因为剩余的预测数据不确定性更好地代表了预测的实际不确定性。这些方法例如基于贝叶斯方法或深度集成（见图4）。

# 实际应用

利用创新技术保护机构，保障消费者和投资者的资产，[NICE Actimize](https://www.niceactimize.com/) 识别金融犯罪，防止欺诈并提供合规监管。它提供实时的跨渠道欺诈预防、反洗钱检测和交易监控解决方案，解决支付欺诈、网络犯罪、制裁监测、市场滥用、客户尽职调查和内幕交易等问题。基于人工智能的系统和先进的分析解决方案能更早更快地发现异常行为，从而消除从盗窃到欺诈、从监管处罚到制裁的财务损失。因此，组织能够减少损失，提高调查效率，并改善合规监管。

随着基于人工智能的系统在金融犯罪中的使用增加，量化和处理不确定性变得越来越重要。一方面，不确定性量化在风险最小化中扮演了重要角色，这在防止欺诈中是必要的。另一方面，有些挑战性的 数据源提供了欺诈调查的增补，但这些数据源很难验证。这使得生成可信的真实数据成为一个非常具有挑战性的任务。

## Actimize的通用评估框架

为应对这些问题，Actimize提供了一个包含各种具体基准数据集和评估指标的评估协议，覆盖所有类型的不确定性，助力不确定性量化研究。此外，还考虑了风险规避和最坏情况的评估。这种通用协议使数据科学研究人员能够轻松地将不同类型的方法与已建立的基准以及实际数据集进行比较。

# 结论

不确定性量化是基于AI的系统和决策过程的关键部分之一。UQ方法在评估各种现实应用中的不确定性时变得越来越受欢迎。如今，不确定性已成为传统机器学习和深度学习方法不可分割的一部分。本文全面回顾了在传统机器学习和深度学习中应用的最重要的UQ概念和方法。

# 参考文献

1.  A. Ashukha, A. Lyzhov, D. Molchanov 和 D. Vetrov，“深度学习中领域内不确定性估计和集成的陷阱”，发表在国际学习表示会议，2020年。

1.  A. G. Wilson 和 P. Izmailov，“贝叶斯深度学习和泛化的概率视角”，发表在《神经信息处理系统进展》会议论文集，H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan 和 H. Lin 编， 第33卷，2020年，第4697–4708页。

1.  A. Kendall 和 Y. Gal，“计算机视觉中的贝叶斯深度学习需要哪些不确定性？” 发表在《神经信息处理系统进展》会议论文集，2017年，第5574–5584页。

1.  A. Kristiadi, M. Hein 和 P. Hennig，“在拉普拉斯近似下的可学习不确定性”，arXiv预印本 arXiv:2010.02720，2020年。

1.  A. Loquercio, M. Segu 和 D. Scaramuzza，“深度学习中不确定性估计的通用框架”，IEEE Robotics and Automation Letters，第5卷，第2期，第3153–3160页，2020年。

1.  A. Malinin 和 M. Gales，“通过先验网络进行预测不确定性估计”，发表在《神经信息处理系统进展》会议论文集，2018年，第7047–7058页。

1.  Chen, Wang 和 Cho 2017 Chen, F.; Wang, C.; 和 Cho, J.-H. 2017\. 集体主观逻辑：可扩展的不确定性基础上的意见推断。发表在2017 IEEE国际大数据会议（Big Data），第7–16页。

1.  G. Kahn, A. Villaflor, V. Pong, P. Abbeel 和 S. Levine，“用于碰撞避免的基于不确定性的强化学习”，arXiv预印本 arXiv:1702.01182，2017年。

1.  G. Wang, W. Li, M. Aertsen, J. Deprest, S. Ourselin 和 T. Vercauteren，“通过测试时间数据增强进行医学图像分割的可变不确定性估计”，Neurocomputing，第338卷，第34–45页，2019年。

1.  J. Van Amersfoort, L. Smith, Y. W. Teh 和 Y. Gal，“使用单一深度确定性神经网络进行不确定性估计”，发表在第37届国际机器学习会议论文集，PMLR，2020年，第9690–9700页。

1.  J. Zeng, A. Lesnikowski 和 J. M. Alvarez，“贝叶斯层定位对深度贝叶斯主动学习模型不确定性的相关性”，arXiv预印本 arXiv:1811.12535，2018年。

1.  Jha, A.; Chandrasekaran, A.; Kim, C.; Ramprasad, R. 数据集不确定性对机器学习模型预测的影响：以聚合物玻璃转变温度为例。Model. Simul. Mater. Sci. Eng. 2019, 27, 024002。

1.  Jøsang 2016 Jøsang, A. 2016\. 主观逻辑：不确定性下推理的形式化方法。Springer。

1.  Lele, S.R. 我们应如何量化统计推断中的不确定性？Front. Ecol. Evol. 2020, 8。

1.  M. S. Ayhan 和 P. Berens, “测试时数据增强以估计深度神经网络中的异方差性随机不确定性，” 载于《医学成像与深度学习会议》，2018年。

1.  Meyer, V.R. 测量不确定性。J. Chromatogr. A 2007, 1158, 15–24。

1.  Senel, O. 《填充位置的确定与相应不确定性的评估》。博士论文，德克萨斯农工大学，科利奇站，TX，美国，2009年。

1.  Siddique, T.; Mahmud, M.S. 《在不确定性下分类 fNIRS 数据：一种贝叶斯神经网络方法》 2021。在线获取： https://ieeexplore.ieee.org/document/9398971 (访问于2021年11月20日)

1.  T. Tsiligkaridis, “通过对不确定性感知的 Dirichlet 网络的置信度估计进行故障预测，” 载于2021年 IEEE 国际声学、语音和信号处理会议。IEEE, 2021, 页3525–3529。

1.  Y. Feldman 和 V. Indelman, “在模型和定位不确定性下的贝叶斯视角依赖的稳健分类，” 载于2018年 IEEE 国际机器人与自动化会议。IEEE, 2018, 页3221–3228。

1.  Y. Gal 和 Z. Ghahramani, “Dropout 作为贝叶斯近似：在深度学习中表示模型不确定性，” 载于《国际机器学习会议》，2016年，页1050–1059。

**[Danny Butvinik](https://www.linkedin.com/in/danny-butvinik/)** 是 NICE Actimize 的首席数据科学家，提供技术和专业领导。Butvinik 是人工智能和数据科学领域的专家，具有构建数据科学愿景和向公司所有部门传达数据驱动分析的能力。Butvinik 着重于数据流中的异常检测和在线机器学习。他定期发表学术论文和研究文章。

### 更多相关内容

+   [导航今天的数据与人工智能市场不确定性](https://www.kdnuggets.com/2024/02/altair-navigating-todays-data-ai-market-uncertainty)

+   [实施推荐系统的十个关键经验教训](https://www.kdnuggets.com/2022/07/ten-key-lessons-implementing-recommendation-systems-business.html)

+   [OLAP 与 OLTP：数据处理系统的比较分析](https://www.kdnuggets.com/2023/08/olap-oltp-comparative-analysis-data-processing-systems.html)

+   [Chip Huyen 分享实施机器学习系统的框架和案例研究](https://www.kdnuggets.com/2023/02/sphere-chip-huyen-shares-frameworks-case-studies-implementing-ml-systems.html)

+   [通过特征/训练/推理管道统一批处理和机器学习系统](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)

+   [了解如何设计与部署负责任的人工智能系统](https://www.kdnuggets.com/2023/10/teradata-design-deploy-responsible-ai-systems-whitepaper)
