- en: 'Text Preprocessing in Python: Steps, Tools, and Examples'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 中的文本预处理：步骤、工具和示例
- en: 原文：[https://www.kdnuggets.com/2018/11/text-preprocessing-python.html](https://www.kdnuggets.com/2018/11/text-preprocessing-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/text-preprocessing-python.html](https://www.kdnuggets.com/2018/11/text-preprocessing-python.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/11/text-preprocessing-python.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/11/text-preprocessing-python.html?page=2#comments)'
- en: '**By Olga Davydova, [Data Monsters](https://datamonsters.com)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 Olga Davydova，[数据怪物](https://datamonsters.com)**。'
- en: 'After a text is obtained, we start with text normalization. Text normalization
    includes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 获取文本后，我们开始进行文本规范化。文本规范化包括：
- en: converting all letters to lower or upper case
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有字母转换为小写或大写
- en: converting numbers into words or removing numbers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数字转换为单词或移除数字
- en: removing punctuations, accent marks and other diacritics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除标点符号、重音符号和其他变音符号
- en: removing white spaces
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除空白字符
- en: expanding abbreviations
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展缩写
- en: removing stop words, sparse terms, and particular words
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除停用词、稀疏词项和特定单词
- en: text canonicalization
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本规范化
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 需求'
- en: '* * *'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We will describe text normalization steps in detail below.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下面详细描述文本规范化步骤。
- en: '![](../Images/1b57451b11f6a00cd631ccd21101e282.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b57451b11f6a00cd631ccd21101e282.png)'
- en: '**Convert text to lowercase**'
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**将文本转换为小写**'
- en: '**Example 1\. Convert text to lowercase**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1\. 转换文本为小写**'
- en: '**Python code:**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python 代码：**'
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Output:**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Remove numbers
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除数字
- en: Remove numbers if they are not relevant to your analyses. Usually, regular expressions
    are used to remove numbers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数字与分析无关，可以移除它们。通常使用正则表达式来移除数字。
- en: '**Example 2\. Numbers removing**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2\. 数字移除**'
- en: '**Python code:**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python 代码：**'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Output:**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Remove punctuation
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除标点符号
- en: 'The following code removes this set of symbols [!”#$%&’()*+,-./:;<=>?@[\]^_`{|}~]:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码移除这组符号 [!”#$%&’()*+,-./:;<=>?@[\]^_`{|}~]：
- en: '**Example 3\. Punctuation removal**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 3\. 标点符号移除**'
- en: '**Python code:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python 代码：**'
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Output:**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Remove whitespaces
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除空白字符
- en: 'To remove leading and ending spaces, you can use the *strip()* function:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要移除前导和尾部空格，可以使用 *strip()* 函数：
- en: '**Example 4\. White spaces removal**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 4\. 空白字符移除**'
- en: '**Python code:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python 代码：**'
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Output:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Tokenization
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分词
- en: Tokenization is the process of splitting the given text into smaller pieces
    called tokens. Words, numbers, punctuation marks, and others can be considered
    as tokens. In [this table](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing) (“Tokenization”
    sheet) several tools for implementing tokenization are described.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 分词是将给定文本拆分成更小的部分称为标记的过程。单词、数字、标点符号等都可以视为标记。在[这个表格](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing)（“分词”工作表）中描述了几个实现分词的工具。
- en: 'Table 1: **Tokenization tools**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: **分词工具**'
- en: '| **Name, Developer, Initial release** | **Features** | **Programming languages**
    | **License** |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **名称、开发者、首次发布** | **特性** | **编程语言** | **许可证** |'
- en: '| [**Natural Language Toolkit (NLTK)**, The University of Pennsylvania, 2001](http://www.nltk.org/index.html)
    | Mac/Unix/Windows support | Python | [Apache License Version 2.0.](http://www.apache.org/licenses/LICENSE-2.0)
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| [**自然语言工具包 (NLTK)**，宾夕法尼亚大学，2001](http://www.nltk.org/index.html) | Mac/Unix/Windows
    支持 | Python | [Apache 许可证第 2.0 版。](http://www.apache.org/licenses/LICENSE-2.0)
    |'
- en: '| [Contains many corpora, toy grammars, trained models, etc [1].](http://www.nltk.org/index.html)
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| [包含多个语料库、玩具语法、训练模型等 [1]。](http://www.nltk.org/index.html) |'
- en: '| [**TextBlob,** Steven Loria, 2013](http://textblob.readthedocs.io/en/dev/)
    | Splitting text into words and sentences | Python | [http://textblob.readthedocs.io/en/dev/license.html](http://textblob.readthedocs.io/en/dev/license.html)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| [**TextBlob**, Steven Loria, 2013](http://textblob.readthedocs.io/en/dev/)
    | 将文本拆分为单词和句子 | Python | [http://textblob.readthedocs.io/en/dev/license.html](http://textblob.readthedocs.io/en/dev/license.html)
    |'
- en: '| [WordNet integration [2]](http://textblob.readthedocs.io/en/dev/) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| [WordNet集成 [2]](http://textblob.readthedocs.io/en/dev/) |'
- en: '| [**Spacy**, Explosion AI, 2016](https://spacy.io/) | Runs on Unix/Linux,
    MacOS/OS X, and Windows. | Python | [MIT License](https://github.com/explosion/spaCy/blob/master/LICENSE)
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| [**Spacy**, Explosion AI, 2016](https://spacy.io/) | 运行于Unix/Linux、MacOS/OS
    X和Windows。 | Python | [MIT许可证](https://github.com/explosion/spaCy/blob/master/LICENSE)
    |'
- en: '| Neural network models |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络模型 |'
- en: '| [multi-language support [3]](https://spacy.io/usage/facts-figures) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| [多语言支持 [3]](https://spacy.io/usage/facts-figures) |'
- en: '| [**Gensim**, RaRe Technologies, 2009](https://radimrehurek.com/gensim/) |
    Can process large, web-scale corpora | Python | [GNU LGPLv2.1 license](https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html)
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| [**Gensim**, RaRe Technologies, 2009](https://radimrehurek.com/gensim/) |
    能处理大规模网络语料库 | Python | [GNU LGPLv2.1许可证](https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html)
    |'
- en: '| Runs on Linux, Windows and OS X |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 运行于Linux、Windows和OS X |'
- en: '| [Vector space modeling and topic modeling [4]](https://radimrehurek.com/gensim/)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| [向量空间建模和主题建模 [4]](https://radimrehurek.com/gensim/) |'
- en: '| [**Apache OpenNLP**, Apache Software Foundation, 2004](https://opennlp.apache.org/)
    | Contains a large number of pre-built models for a variety of languages | Java
    | [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0) |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| [**Apache OpenNLP**, Apache软件基金会, 2004](https://opennlp.apache.org/) | 包含大量预构建的多语言模型
    | Java | [Apache许可证 2.0版](https://www.apache.org/licenses/LICENSE-2.0) |'
- en: '| [Includes annotated text resources [5]](https://opennlp.apache.org/) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| [包含注释文本资源 [5]](https://opennlp.apache.org/) |'
- en: '| [**OpenNMT**, Yoon Kim, harvardnlp, 2016](http://opennmt.net/) | Is a generic
    deep learning framework mainly specialized in sequence-to-sequence models | Python
    | [MIT License](https://github.com/OpenNMT/OpenNMT/blob/master/LICENSE.md) |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| [**OpenNMT**, Yoon Kim, harvardnlp, 2016](http://opennmt.net/) | 是一个通用的深度学习框架，主要专注于序列到序列模型
    | Python | [MIT许可证](https://github.com/OpenNMT/OpenNMT/blob/master/LICENSE.md)
    |'
- en: '| [Can be used either via command line applications, client-server, or libraries.
    [6]](http://opennmt.net/) | Lua |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| [可通过命令行应用程序、客户端-服务器或库使用。[6]](http://opennmt.net/) | Lua |'
- en: '| Has currently 3 main implementations (OpenNMT-lua, OpenNMT-py, OpenNMT-tf)
    |   |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 目前有3种主要实现（OpenNMT-lua, OpenNMT-py, OpenNMT-tf） |   |'
- en: '| [**General Architecture for Text Engineering (GATE)**, GATE research team,
    University of Sheffield, 1995](https://gate.ac.uk/) | Includes an information
    extraction system | Java | [the GNU licenses and other](http://www.gnu.org/licenses/)
    |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| [**文本工程通用架构（GATE）**, GATE研究团队, 谢菲尔德大学, 1995](https://gate.ac.uk/) | 包含信息提取系统
    | Java | [GNU许可证及其他](http://www.gnu.org/licenses/) |'
- en: '| Multiple languages support |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 支持多种语言 |'
- en: '| [Accepts input in various formats [7]](https://gate.ac.uk/) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| [接受多种格式的输入 [7]](https://gate.ac.uk/) |'
- en: '| [**Apache UIMA**, IBM, Apache Software Foundation, 2006](https://uima.apache.org/)
    | [Contains Addons and Sandbox](https://uima.apache.org/sandbox.html) | Java,
    C++ | [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| [**Apache UIMA**, IBM, Apache软件基金会, 2006](https://uima.apache.org/) | [包含附加组件和沙盒](https://uima.apache.org/sandbox.html)
    | Java, C++ | [Apache许可证 2.0](https://www.apache.org/licenses/LICENSE-2.0) |'
- en: '| Cross-platform |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 跨平台 |'
- en: '| [REST requests support [8]](https://uima.apache.org/) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| [REST请求支持 [8]](https://uima.apache.org/) |'
- en: '| [**Memory-Based Shallow Parser (MBSP)**, Vincent Van Asch, Tom De Smedt,
    2010](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer) | Client-server architecture
    | Python | [GPL](http://www.gnu.org/licenses/gpl.html) |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| [**基于记忆的浅层解析器（MBSP）**, Vincent Van Asch, Tom De Smedt, 2010](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    | 客户端-服务器架构 | Python | [GPL](http://www.gnu.org/licenses/gpl.html) |'
- en: '| includes binaries (TiMBL, MBT and MBLEM) Precompiled for Mac OS X |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 包含预编译的二进制文件（TiMBL, MBT和MBLEM）适用于Mac OS X |'
- en: '| [Cygwin usage for Windows [9]](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| [Cygwin在Windows上的使用 [9]](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    |'
- en: '| [**RapidMiner**, RapidMiner, 2006](https://rapidminer.com/) | Unified platform
    | RapidMiner provides a GUI to design and execute analytical workflows | [AGPL](https://en.wikipedia.org/wiki/Affero_General_Public_License)
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| [**RapidMiner**, RapidMiner, 2006](https://rapidminer.com/) | 统一平台 | RapidMiner提供图形界面来设计和执行分析工作流
    | [AGPL](https://en.wikipedia.org/wiki/Affero_General_Public_License) |'
- en: '| Visual workflow design |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 视觉化工作流设计 |'
- en: '| Breadth of functionality |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 功能广泛 |'
- en: '| [Broad connectivity [10]](https://rapidminer.com/) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [广泛的连接性 [10]](https://rapidminer.com/) |'
- en: '| [**MAchine Learning for LanguagE Toolkit  (MALLET)**, Andrew Kachites McCallum,
    University of Massachusetts Amherst, 2002](http://mallet.cs.umass.edu/) | Includes
    sophisticated tools for document classification and sequence tagging | Java |
    [Common Public License](https://opensource.org/licenses/cpl1.0.php) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [**语言处理工具包 (MALLET)**，安德鲁·卡基特斯·麦卡勒姆，马萨诸塞大学阿默斯特分校，2002](http://mallet.cs.umass.edu/)
    | 包含用于文档分类和序列标注的复杂工具 | Java | [通用公共许可证](https://opensource.org/licenses/cpl1.0.php)
    |'
- en: '| [Support for inference in general graphical models [11]](http://mallet.cs.umass.edu/)
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [支持一般图模型推理 [11]](http://mallet.cs.umass.edu/) |'
- en: '| [**Pattern**, T. De Smedt & W. Daeleman,  2012](https://www.clips.uantwerpen.be/pages/pattern-en#parser)
    | Web mining module | Python | [BSD](http://www.linfo.org/bsdlicense.html) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| [**Pattern**，T. De Smedt 和 W. Daeleman，2012](https://www.clips.uantwerpen.be/pages/pattern-en#parser)
    | 网络挖掘模块 | Python | [BSD](http://www.linfo.org/bsdlicense.html) |'
- en: '| runs on Windows, Mac, & Linux |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 兼容 Windows、Mac 和 Linux |'
- en: '| [Multiple languages support [12]](https://www.clips.uantwerpen.be/pages/pattern)
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [多语言支持 [12]](https://www.clips.uantwerpen.be/pages/pattern) |'
- en: '| [**Stanford Tokenizer**, The Stanford Natural Language Processing Group,
    2010](https://nlp.stanford.edu/software/tokenizer.html) | [Tokenizer is not distributed
    separately but is included in several software downloads;](https://nlp.stanford.edu/software/)
    | Java | [GNU General Public License](http://www.gnu.org/licenses/gpl-2.0.html)
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| [**斯坦福分词器**，斯坦福自然语言处理小组，2010](https://nlp.stanford.edu/software/tokenizer.html)
    | [分词器未单独分发，但包含在多个软件下载中；](https://nlp.stanford.edu/software/) | Java | [GNU 通用公共许可证](http://www.gnu.org/licenses/gpl-2.0.html)
    |'
- en: '| Rate of about 1,000,000 tokens per second, |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 每秒约 1,000,000 个标记 |'
- en: '| [There are a number of options that affect how tokenization is performed
    [13]](https://nlp.stanford.edu/software/tokenizer.html#About) |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| [有许多选项影响标记化的执行方式 [13]](https://nlp.stanford.edu/software/tokenizer.html#About)
    |'
- en: '| [**FreeLing**, TALP Research Center, Universitat Politècnica de Catalunya](http://nlp.lsi.upc.edu/freeling/)
    | Provides language analysis functionalities | C++ | [Affero GNU General Public
    License](http://www.gnu.org/licenses/agpl.html) |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| [**FreeLing**，TALP 研究中心，加泰罗尼亚理工大学](http://nlp.lsi.upc.edu/freeling/) | 提供语言分析功能
    | C++ | [Affero GNU 通用公共许可证](http://www.gnu.org/licenses/agpl.html) |'
- en: '| Supports a variety of languages |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 支持多种语言 |'
- en: '| Provides a command-line front-end |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 提供命令行前端 |'
- en: '| [Output formats: XML, JSON, CoNLL [45]](http://nlp.lsi.upc.edu/freeling/)
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| [输出格式：XML，JSON，CoNLL [45]](http://nlp.lsi.upc.edu/freeling/) |'
- en: Remove stop words
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除停用词
- en: “Stop words” are the most common words in a language like “the”, “a”, “on”,
    “is”, “all”. These words do not carry important meaning and are usually removed
    from texts. It is possible to remove stop words using [Natural Language Toolkit
    (NLTK)](http://www.nltk.org/), a suite of libraries and programs for symbolic
    and statistical natural language processing.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: “停用词”是语言中最常见的词汇，如“the”、“a”、“on”、“is”、“all”。这些词没有重要的意义，通常会从文本中删除。可以使用 [自然语言工具包
    (NLTK)](http://www.nltk.org/)，这是一个用于符号和统计自然语言处理的库和程序套件，来移除停用词。
- en: '**Example 7\. Stop words removal**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 7. 停用词移除**'
- en: '**Code:**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Output:**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A [scikit-learn](http://scikit-learn.org/stable/) tool also provides a stop
    words list:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [scikit-learn](http://scikit-learn.org/stable/) 工具还提供了一个停用词列表：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It’s also possible to use [spaCy](https://spacy.io/), a free open-source library:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用 [spaCy](https://spacy.io/)，这是一个免费的开源库：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Remove sparse terms and particular words
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除稀疏词汇和特定词汇
- en: In some cases, it’s necessary to remove sparse terms or particular words from
    texts. This task can be done using stop words removal techniques considering that
    any group of words can be chosen as the stop words.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，需要从文本中删除稀疏词汇或特定词汇。这可以通过停用词移除技术来完成，考虑到任何词组都可以作为停用词。
- en: Stemming
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词干提取
- en: Stemming is a process of reducing words to their word stem, base or root form
    (for example, books — book, looked — look). The main two algorithms are [Porter
    stemming algorithm](https://tartarus.org/martin/PorterStemmer/) (removes common
    morphological and inflexional endings from words [[14])](https://tartarus.org/martin/PorterStemmer/) and [Lancaster
    stemming algorithm](http://web.archive.org/web/20140827005744/http:/www.comp.lancs.ac.uk/computing/research/stemming/index.htm) (a
    more aggressive stemming algorithm). In the [“Stemming” sheet of the table](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing) some
    stemmers are described.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 词干提取是将单词减少到其词干、基础或根形式的过程（例如，books — book，looked — look）。主要的两个算法是 [Porter 词干提取算法](https://tartarus.org/martin/PorterStemmer/)（移除单词中的常见形态和屈折词尾
    [[14])](https://tartarus.org/martin/PorterStemmer/) 和 [Lancaster 词干提取算法](http://web.archive.org/web/20140827005744/http:/www.comp.lancs.ac.uk/computing/research/stemming/index.htm)（一个更具侵略性的词干提取算法）。在
    [“词干提取”表格](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing)
    中描述了一些词干提取器。
- en: '| **Name, Developer, Initial release** | **Features** | **Programming languages**
    | **License** |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **名称，开发者，首次发布** | **特点** | **编程语言** | **许可证** |'
- en: '| [**Natural Language Toolkit (NLTK)**, The University of Pennsylvania, 2001](http://www.nltk.org/index.html)
    | Mac/Unix/Windows support | Python | [Apache License Version 2.0.](http://www.apache.org/licenses/LICENSE-2.0)
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| [**自然语言工具包 (NLTK)**，宾夕法尼亚大学，2001](http://www.nltk.org/index.html) | 支持 Mac/Unix/Windows
    | Python | [Apache 许可证 2.0 版本](http://www.apache.org/licenses/LICENSE-2.0) |'
- en: '| [Contains many corpora, toy grammars, trained models, etc [1].](http://www.nltk.org/index.html)
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| [包含许多语料库、玩具语法、训练模型等 [1].](http://www.nltk.org/index.html) |'
- en: '| [**TextBlob,** Steven Loria, 2013](http://textblob.readthedocs.io/en/dev/)
    | Splitting text into words and sentences | Python | [http://textblob.readthedocs.io/en/dev/license.html](http://textblob.readthedocs.io/en/dev/license.html)
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| [**TextBlob**，Steven Loria，2013](http://textblob.readthedocs.io/en/dev/)
    | 将文本分割成单词和句子 | Python | [http://textblob.readthedocs.io/en/dev/license.html](http://textblob.readthedocs.io/en/dev/license.html)
    |'
- en: '| [WordNet integration [2]](http://textblob.readthedocs.io/en/dev/) |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| [WordNet 集成 [2]](http://textblob.readthedocs.io/en/dev/) |'
- en: '| [**Spacy**, Explosion AI, 2016](https://spacy.io/) | Runs on Unix/Linux,
    MacOS/OS X, and Windows. | Python | [MIT License](https://github.com/explosion/spaCy/blob/master/LICENSE)
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| [**Spacy**，Explosion AI，2016](https://spacy.io/) | 适用于 Unix/Linux、MacOS/OS
    X 和 Windows。 | Python | [MIT 许可证](https://github.com/explosion/spaCy/blob/master/LICENSE)
    |'
- en: '| Neural network models |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络模型 |'
- en: '| [multi-language support [3]](https://spacy.io/usage/facts-figures) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| [多语言支持 [3]](https://spacy.io/usage/facts-figures) |'
- en: '| [**Gensim**, RaRe Technologies, 2009](https://radimrehurek.com/gensim/) |
    Can process large, web-scale corpora | Python | [GNU LGPLv2.1 license](https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html)
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| [**Gensim**，RaRe Technologies，2009](https://radimrehurek.com/gensim/) | 可以处理大型的网络规模语料库
    | Python | [GNU LGPLv2.1 许可证](https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html)
    |'
- en: '| Runs on Linux, Windows and OS X |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 适用于 Linux、Windows 和 OS X |'
- en: '| [Vector space modeling and topic modeling [4]](https://radimrehurek.com/gensim/)
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| [向量空间建模和主题建模 [4]](https://radimrehurek.com/gensim/) |'
- en: '| [**Apache OpenNLP**, Apache Software Foundation, 2004](https://opennlp.apache.org/)
    | Contains a large number of pre-built models for a variety of languages | Java
    | [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| [**Apache OpenNLP**，Apache 软件基金会，2004](https://opennlp.apache.org/) | 包含大量预构建的模型，支持多种语言
    | Java | [Apache 许可证，2.0 版本](https://www.apache.org/licenses/LICENSE-2.0) |'
- en: '| [Includes annotated text resources [5]](https://opennlp.apache.org/) |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| [包含带注释的文本资源 [5]](https://opennlp.apache.org/) |'
- en: '| [**OpenNMT**, Yoon Kim, harvardnlp, 2016](http://opennmt.net/) | Is a generic
    deep learning framework mainly specialized in sequence-to-sequence models | Python
    | [MIT License](https://github.com/OpenNMT/OpenNMT/blob/master/LICENSE.md) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| [**OpenNMT**，Yoon Kim，harvardnlp，2016](http://opennmt.net/) | 是一个通用深度学习框架，主要专注于序列到序列模型
    | Python | [MIT 许可证](https://github.com/OpenNMT/OpenNMT/blob/master/LICENSE.md)
    |'
- en: '| [Can be used either via command line applications, client-server, or libraries.
    [6]](http://opennmt.net/) | Lua |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| [可以通过命令行应用程序、客户端-服务器或库使用 [6]](http://opennmt.net/) | Lua |'
- en: '| Has currently 3 main implementations (OpenNMT-lua, OpenNMT-py, OpenNMT-tf)
    |  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 目前有 3 个主要实现（OpenNMT-lua、OpenNMT-py、OpenNMT-tf） |  |'
- en: '| [**General Architecture for Text Engineering (GATE)**, GATE research team,
    University of Sheffield, 1995](https://gate.ac.uk/) | Includes an information
    extraction system | Java | [the GNU licenses and other](http://www.gnu.org/licenses/)
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| [**General Architecture for Text Engineering (GATE)**，GATE 研究团队，谢菲尔德大学，1995](https://gate.ac.uk/)
    | 包含信息提取系统 | Java | [GNU 许可证及其他](http://www.gnu.org/licenses/) |'
- en: '| Multiple languages support |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 多语言支持 |'
- en: '| [Accepts input in various formats [7]](https://gate.ac.uk/) |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| [接受多种格式的输入 [7]](https://gate.ac.uk/) |'
- en: '| [**Apache UIMA**, IBM, Apache Software Foundation, 2006](https://uima.apache.org/)
    | [Contains Addons and Sandbox](https://uima.apache.org/sandbox.html) | Java,
    C++ | [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| [**Apache UIMA**，IBM，Apache 软件基金会，2006](https://uima.apache.org/) | [包含附加组件和沙箱](https://uima.apache.org/sandbox.html)
    | Java，C++ | [Apache 2.0 许可证](https://www.apache.org/licenses/LICENSE-2.0) |'
- en: '| Cross-platform |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 跨平台 |'
- en: '| [REST requests support [8]](https://uima.apache.org/) |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| [支持 REST 请求 [8]](https://uima.apache.org/) |'
- en: '| [**Memory-Based Shallow Parser (MBSP)**, Vincent Van Asch, Tom De Smedt,
    2010](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer) | Client-server architecture
    | Python | [GPL](http://www.gnu.org/licenses/gpl.html) |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| [**基于记忆的浅层解析器 (MBSP)**，Vincent Van Asch，Tom De Smedt，2010](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    | 客户端-服务器架构 | Python | [GPL](http://www.gnu.org/licenses/gpl.html) |'
- en: '| includes binaries (TiMBL, MBT and MBLEM) Precompiled for Mac OS X |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 包含预编译的二进制文件（TiMBL、MBT 和 MBLEM）适用于 Mac OS X |'
- en: '| [Cygwin usage for Windows [9]](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| [Windows 下的 Cygwin 使用 [9]](https://www.clips.uantwerpen.be/pages/MBSP#tokenizer)
    |'
- en: '| [**RapidMiner**, RapidMiner, 2006](https://rapidminer.com/) | Unified platform
    | RapidMiner provides a GUI to design and execute analytical workflows | [AGPL](https://en.wikipedia.org/wiki/Affero_General_Public_License)
    |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| [**RapidMiner**，RapidMiner，2006](https://rapidminer.com/) | 统一平台 | RapidMiner
    提供一个 GUI 设计和执行分析工作流 | [AGPL](https://en.wikipedia.org/wiki/Affero_General_Public_License)
    |'
- en: '| Visual workflow design |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 视觉工作流设计 |'
- en: '| Breadth of functionality |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 功能广泛 |'
- en: '| [Broad connectivity [10]](https://rapidminer.com/) |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| [广泛的连接性 [10]](https://rapidminer.com/) |'
- en: '| [**MAchine Learning for LanguagE Toolkit  (MALLET)**, Andrew Kachites McCallum,
    University of Massachusetts Amherst, 2002](http://mallet.cs.umass.edu/) | Includes
    sophisticated tools for document classification and sequence tagging | Java |
    [Common Public License](https://opensource.org/licenses/cpl1.0.php) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| [**MAchine Learning for LanguagE Toolkit (MALLET)**，Andrew Kachites McCallum，马萨诸塞大学阿默斯特分校，2002](http://mallet.cs.umass.edu/)
    | 包含文档分类和序列标记的高级工具 | Java | [通用公共许可证](https://opensource.org/licenses/cpl1.0.php)
    |'
- en: '| [Support for inference in general graphical models [11]](http://mallet.cs.umass.edu/)
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| [支持一般图模型中的推理 [11]](http://mallet.cs.umass.edu/) |'
- en: '| [**Pattern**, T. De Smedt & W. Daeleman,  2012](https://www.clips.uantwerpen.be/pages/pattern-en#parser)
    | Web mining module | Python | [BSD](http://www.linfo.org/bsdlicense.html) |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| [**Pattern**，T. De Smedt & W. Daeleman，2012](https://www.clips.uantwerpen.be/pages/pattern-en#parser)
    | 网络挖掘模块 | Python | [BSD](http://www.linfo.org/bsdlicense.html) |'
- en: '| runs on Windows, Mac, & Linux |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 运行于 Windows、Mac 和 Linux |'
- en: '| [Multiple languages support [12]](https://www.clips.uantwerpen.be/pages/pattern)
    |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| [多语言支持 [12]](https://www.clips.uantwerpen.be/pages/pattern) |'
- en: '| [**Stanford Tokenizer**, The Stanford Natural Language Processing Group,
    2010](https://nlp.stanford.edu/software/tokenizer.html) | [Tokenizer is not distributed
    separately but is included in several software downloads;](https://nlp.stanford.edu/software/)
    | Java | [GNU General Public License](http://www.gnu.org/licenses/gpl-2.0.html)
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| [**斯坦福分词器**，斯坦福自然语言处理小组，2010](https://nlp.stanford.edu/software/tokenizer.html)
    | [分词器没有单独发布，而是包含在多个软件下载中；](https://nlp.stanford.edu/software/) | Java | [GNU
    通用公共许可证](http://www.gnu.org/licenses/gpl-2.0.html) |'
- en: '| Rate of about 1,000,000 tokens per second, |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 每秒约 1,000,000 个标记 |'
- en: '| [There are a number of options that affect how tokenization is performed
    [13]](https://nlp.stanford.edu/software/tokenizer.html#About) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| [有多种选项影响分词的执行方式 [13]](https://nlp.stanford.edu/software/tokenizer.html#About)
    |'
- en: '| [**FreeLing**, TALP Research Center, Universitat Politècnica de Catalunya](http://nlp.lsi.upc.edu/freeling/)
    | Provides language analysis functionalities | C++ | [Affero GNU General Public
    License](http://www.gnu.org/licenses/agpl.html) |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| [**FreeLing**，TALP 研究中心，加泰罗尼亚理工大学](http://nlp.lsi.upc.edu/freeling/) | 提供语言分析功能
    | C++ | [Affero GNU 通用公共许可证](http://www.gnu.org/licenses/agpl.html) |'
- en: '| Supports a variety of languages |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 支持多种语言 |'
- en: '| Provides a command-line front-end |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 提供命令行前端 |'
- en: '| [Output formats: XML, JSON, CoNLL [45]](http://nlp.lsi.upc.edu/freeling/)
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| [输出格式：XML，JSON，CoNLL [45]](http://nlp.lsi.upc.edu/freeling/) |'
- en: '**Stemming tools**'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**词干提取工具**'
- en: '**Example 8\. Stemming using NLTK:**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 8\. 使用 NLTK 进行词干提取：**'
- en: '**Code:**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Output:**'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE13]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Lemmatization
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词形还原
- en: The aim of lemmatization, like stemming, is to reduce inflectional forms to
    a common base form. As opposed to stemming, lemmatization does not simply chop
    off inflections. Instead it uses lexical knowledge bases to get the correct base
    forms of words.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原的目标与词干提取类似，都是将屈折形式简化为共同的基本形式。与词干提取不同，词形还原并不会简单地剪切屈折形式。相反，它使用词汇知识库来获取单词的正确基本形式。
- en: Lemmatization tools are presented libraries described above: [NLTK (WordNet
    Lemmatizer)](http://www.nltk.org/_modules/nltk/stem/wordnet.html), [spaCy](https://spacy.io/api/lemmatizer), [TextBlob](http://textblob.readthedocs.io/en/dev/quickstart.html#words-inflection-and-lemmatization), [Pattern](https://www.clips.uantwerpen.be/pages/pattern-en#conjugation), [gensim](https://radimrehurek.com/gensim/utils.html), [Stanford
    CoreNLP](https://stanfordnlp.github.io/CoreNLP/simple.html), [Memory-Based Shallow
    Parser (MBSP)](https://www.clips.uantwerpen.be/pages/MBSP#lemmatizer), [Apache
    OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.lemmatizer.tagging.cmdline), [Apache
    Lucene](http://lucene.apache.org/core/), [General Architecture for Text Engineering
    (GATE)](https://gate.ac.uk/), [Illinois Lemmatizer](https://cogcomp.org/page/software_view/illinois-lemmatizer),
    and [DKPro Core](https://dkpro.github.io/dkpro-core/releases/1.8.0/docs/component-reference.html#_lemmatizer).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原工具包括上文描述的库：[NLTK (WordNet Lemmatizer)](http://www.nltk.org/_modules/nltk/stem/wordnet.html)，[spaCy](https://spacy.io/api/lemmatizer)，[TextBlob](http://textblob.readthedocs.io/en/dev/quickstart.html#words-inflection-and-lemmatization)，[Pattern](https://www.clips.uantwerpen.be/pages/pattern-en#conjugation)，[gensim](https://radimrehurek.com/gensim/utils.html)，[Stanford
    CoreNLP](https://stanfordnlp.github.io/CoreNLP/simple.html)，[Memory-Based Shallow
    Parser (MBSP)](https://www.clips.uantwerpen.be/pages/MBSP#lemmatizer)，[Apache
    OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.lemmatizer.tagging.cmdline)，[Apache
    Lucene](http://lucene.apache.org/core/)，[General Architecture for Text Engineering
    (GATE)](https://gate.ac.uk/)，[Illinois Lemmatizer](https://cogcomp.org/page/software_view/illinois-lemmatizer)
    和 [DKPro Core](https://dkpro.github.io/dkpro-core/releases/1.8.0/docs/component-reference.html#_lemmatizer)。
- en: '**Example 9\. Lemmatization using NLTK:**'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 9\. 使用 NLTK 进行词形还原：**'
- en: '**Code:**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE14]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Output:**'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE15]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Part of speech tagging (POS)
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词性标注（POS）
- en: Part-of-speech tagging aims to assign parts of speech to each word of a given
    text (such as nouns, verbs, adjectives, and others) based on its definition and
    its context. There are many tools containing POS taggers including [NLTK](http://www.nltk.org/book/ch05.html), [spaCy](https://spacy.io/usage/linguistic-features), [TextBlob](http://textblob.readthedocs.io/en/dev/quickstart.html#part-of-speech-tagging), [Pattern](https://www.clips.uantwerpen.be/pages/pattern-en#parser), [Stanford
    CoreNLP](https://nlp.stanford.edu/software/tagger.shtml), [Memory-Based Shallow
    Parser (MBSP)](https://www.clips.uantwerpen.be/pages/MBSP#parser), [Apache OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.postagger.tagging), [Apache
    Lucene](https://lucene.apache.org/core/), [General Architecture for Text Engineering
    (GATE)](https://gate.ac.uk/), [FreeLing](http://nlp.lsi.upc.edu/freeling/), [Illinois
    Part of Speech Tagger](https://cogcomp.org/page/software_view/POS), and [DKPro
    Core](https://dkpro.github.io/dkpro-core/releases/1.9.0/docs/component-reference.html#_part_of_speech_tagger).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注旨在根据每个单词的定义和上下文将其标记为不同的词性（如名词、动词、形容词等）。许多工具包含词性标注器，包括 [NLTK](http://www.nltk.org/book/ch05.html)，[spaCy](https://spacy.io/usage/linguistic-features)，[TextBlob](http://textblob.readthedocs.io/en/dev/quickstart.html#part-of-speech-tagging)，[Pattern](https://www.clips.uantwerpen.be/pages/pattern-en#parser)，[Stanford
    CoreNLP](https://nlp.stanford.edu/software/tagger.shtml)，[Memory-Based Shallow
    Parser (MBSP)](https://www.clips.uantwerpen.be/pages/MBSP#parser)，[Apache OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.postagger.tagging)，[Apache
    Lucene](https://lucene.apache.org/core/)，[General Architecture for Text Engineering
    (GATE)](https://gate.ac.uk/)，[FreeLing](http://nlp.lsi.upc.edu/freeling/)，[Illinois
    Part of Speech Tagger](https://cogcomp.org/page/software_view/POS) 和 [DKPro Core](https://dkpro.github.io/dkpro-core/releases/1.9.0/docs/component-reference.html#_part_of_speech_tagger)。
- en: '**Example 10\. Part-of-speech tagging using TextBlob:**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 10\. 使用 TextBlob 进行词性标注：**'
- en: '**Code:**'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE16]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Output:**'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE17]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Chunking (shallow parsing)
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词组分析（浅层解析）
- en: Chunking is a natural language process that identifies constituent parts of
    sentences (nouns, verbs, adjectives, etc.) and links them to higher order units
    that have discrete grammatical meanings (noun groups or phrases, verb groups,
    etc.) [[23]](https://en.wikipedia.org/wiki/Shallow_parsing). Chunking tools: [NLTK](http://www.nltk.org/book/ch07.html), [TreeTagger
    chunker](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/), [Apache OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.parser.chunking), [General
    Architecture for Text Engineering (GATE)](https://gate.ac.uk/), [FreeLing](http://nlp.lsi.upc.edu/freeling/).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 分块是自然语言处理的一种过程，它识别句子的组成部分（名词、动词、形容词等），并将其连接到具有离散语法意义的更高级单元（名词组或短语、动词组等）[[23]](https://en.wikipedia.org/wiki/Shallow_parsing)。
    分块工具： [NLTK](http://www.nltk.org/book/ch07.html)， [TreeTagger分块器](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/)， [Apache
    OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.parser.chunking)， [通用文本工程架构（GATE）](https://gate.ac.uk/)， [FreeLing](http://nlp.lsi.upc.edu/freeling/)。
- en: '**Example 11\. Chunking using NLTK:**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 11\. 使用NLTK的分块：**'
- en: 'The first step is to determine the part of speech for each word:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是确定每个词的词性：
- en: '**Code:**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Output:**'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE19]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The second step is chunking:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是分块：
- en: '**Code:**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Output:**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: It’s also possible to draw the sentence tree structure using code result.draw()
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用代码 result.draw()绘制句子树结构。
- en: '![](../Images/decd12c76c9568338ba6cc4043f64bfa.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/decd12c76c9568338ba6cc4043f64bfa.png)'
- en: Named entity recognition
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名实体识别
- en: Named-entity recognition (NER) aims to find named entities in text and classify
    them into pre-defined categories (names of persons, locations, organizations,
    times, etc.).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别（NER）的目标是从文本中查找命名实体，并将其分类为预定义类别（个人名字、地点、组织、时间等）。
- en: Named-entity recognition tools: [NLTK](http://www.nltk.org/book/ch07.html), [spaCy](https://spacy.io/usage/linguistic-features#section-named-entities), [General
    Architecture for Text Engineering (GATE) — ANNIE](https://gate.ac.uk/sale/tao/splitch6.html#chap:annie), [Apache
    OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.namefind.recognition), [Stanford
    CoreNLP](https://nlp.stanford.edu/software/CRF-NER.shtml), [DKPro Core](https://dkpro.github.io/dkpro-core/releases/1.9.0/docs/component-reference.html#_named_entity_recognizer), [MITIE](https://github.com/mit-nlp/MITIE), [Watson
    Natural Language Understanding](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#entities), [TextRazor](https://www.textrazor.com/), [FreeLing](http://nlp.lsi.upc.edu/freeling/)are
    described in the [“NER” sheet of the table](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别工具： [NLTK](http://www.nltk.org/book/ch07.html)， [spaCy](https://spacy.io/usage/linguistic-features#section-named-entities)， [通用文本工程架构（GATE）—
    ANNIE](https://gate.ac.uk/sale/tao/splitch6.html#chap:annie)， [Apache OpenNLP](https://opennlp.apache.org/docs/1.8.4/manual/opennlp.html#tools.namefind.recognition)， [斯坦福CoreNLP](https://nlp.stanford.edu/software/CRF-NER.shtml)， [DKPro
    Core](https://dkpro.github.io/dkpro-core/releases/1.9.0/docs/component-reference.html#_named_entity_recognizer)， [MITIE](https://github.com/mit-nlp/MITIE)， [Watson自然语言理解](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#entities)， [TextRazor](https://www.textrazor.com/)， [FreeLing](http://nlp.lsi.upc.edu/freeling/)在 [“NER”表格](https://docs.google.com/spreadsheets/d/1-9rMhfcmxFv2V2Q5ZWn1FfLDZZYsuwb1eoSp9CiEEOg/edit?usp=sharing)中有描述。
- en: '| **Name, Developer, Initial release** | **Features** | **Programming languages**
    | **License** |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| **名称，开发者，初始发布** | **特性** | **编程语言** | **许可证** |'
- en: '| [**Baleen**, Defence Science and Technology Laboratory (Dstl), 2014](https://github.com/dstl/baleen)
    | Works with unstructured and semi-structured data sources | Java | [Apache License
    2.0](https://github.com/dstl/baleen/blob/master/LICENSE.txt) |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| [**Baleen**，国防科学与技术实验室（Dstl），2014](https://github.com/dstl/baleen) | 处理非结构化和半结构化数据源
    | Java | [Apache许可证2.0](https://github.com/dstl/baleen/blob/master/LICENSE.txt)
    |'
- en: '| Includes a built-in server |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 包含内置服务器 |'
- en: '| [[25]](https://github.com/dstl/baleen/) |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| [[25]](https://github.com/dstl/baleen/) |'
- en: '| [**CogComp NER Tagger (Illinois Named Entity Tagger)**, L. Ratinov, D. Roth,
    Cognitive Computation Group, 2009](https://github.com/CogComp/cogcomp-nlp/tree/master/ner)
    | Tags plain text with named entities | Java | [Licensing Agreement](http://cogcomp.org/page/download_view/NETagger)
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| [**CogComp NER Tagger（伊利诺伊命名实体标记器）**，L. Ratinov，D. Roth，认知计算组，2009](https://github.com/CogComp/cogcomp-nlp/tree/master/ner)
    | 用命名实体标记纯文本 | Java | [许可协议](http://cogcomp.org/page/download_view/NETagger) |'
- en: '| 4-label type set (people / organizations / locations / miscellaneous) |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 4标签类型集（人/组织/地点/其他） |'
- en: '| [18-label type set (based on the OntoNotes corpus)  [26]](https://github.com/CogComp/cogcomp-nlp/tree/master/ner)
    |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| [18-label 类型集合（基于 OntoNotes 语料库） [26]](https://github.com/CogComp/cogcomp-nlp/tree/master/ner)
    |'
- en: '| [**Minimal Named-Entity Recognizer (MER)**, LaSIGE, Faculdade de Ciências,
    Universidade de Lisboa, Portugal, 2017](https://github.com/lasigeBioTM/MER) |
    Returns the list of terms recognized in the text, including their exact location
    (annotations) | GNU awk | - |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| [**最小化命名实体识别器 (MER)**, LaSIGE, Faculdade de Ciências, Universidade de Lisboa,
    葡萄牙, 2017](https://github.com/lasigeBioTM/MER) | 返回文本中识别出的术语列表，包括其确切位置（注释） | GNU
    awk | - |'
- en: '| [Only requires a lexicon (text file) with the list of terms representing
    the entities of interest RESTful Web service](http://labs.rd.ciencias.ulisboa.pt/mer/)
    |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| [仅需要包含感兴趣实体术语列表的词典（文本文件）RESTful 网络服务](http://labs.rd.ciencias.ulisboa.pt/mer/)
    |'
- en: '| [[27]](https://github.com/lasigeBioTM/MER) |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| [[27]](https://github.com/lasigeBioTM/MER) |'
- en: '| [**ParallelDots**, ParallelDots](https://www.paralleldots.com/named-entity-recognition)
    | Uses deep learning technology to determine representations of character groupings
    | [excel add-in](https://www.paralleldots.com/excel-docs) | [Pricing](https://www.paralleldots.com/pricing)
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| [**ParallelDots**, ParallelDots](https://www.paralleldots.com/named-entity-recognition)
    | 使用深度学习技术确定字符分组的表示 | [excel 插件](https://www.paralleldots.com/excel-docs) | [定价](https://www.paralleldots.com/pricing)
    |'
- en: '| Discovers the most relevant entities in textual content | [AI APIs](https://www.paralleldots.com/)
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 发现文本内容中最相关的实体 | [AI APIs](https://www.paralleldots.com/) |'
- en: '| Accurate, real-time, customizable |  |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 准确、实时、可定制 |'
- en: '| [[28]](https://blog.paralleldots.com/product/dig-relevant-text-elements-entity-extraction-api/)
    |  |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| [[28]](https://blog.paralleldots.com/product/dig-relevant-text-elements-entity-extraction-api/)
    |  |'
- en: '| [demo](https://www.paralleldots.com/text-analysis-apis#named-entity-recognition)
    |  |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| [演示](https://www.paralleldots.com/text-analysis-apis#named-entity-recognition)
    |  |'
- en: '| [**Open Calais**, Thomson Reuters Corporation](http://www.opencalais.com/about-open-calais/)
    | [Extracts entities (companies, people, places, products, etc.), relationships,
    facts, events, topics. [29]](http://www.opencalais.com/about-open-calais/) | [API](http://www.opencalais.com/opencalais-api/)
    | [Terms of Service](http://www.opencalais.com/open-calais-terms-of-service/)
    |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| [**Open Calais**, Thomson Reuters Corporation](http://www.opencalais.com/about-open-calais/)
    | [提取实体（公司、人物、地点、产品等）、关系、事实、事件、主题 [29]](http://www.opencalais.com/about-open-calais/)
    | [API](http://www.opencalais.com/opencalais-api/) | [服务条款](http://www.opencalais.com/open-calais-terms-of-service/)
    |'
- en: '| [**LingPipe**, Breck Baldwin, 1999](http://alias-i.com/lingpipe/index.html)
    | Finds the names of people, organizations, or locations | Java | [License Matrix](http://alias-i.com/lingpipe/web/download.html)
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| [**LingPipe**, Breck Baldwin, 1999](http://alias-i.com/lingpipe/index.html)
    | 查找人物、组织或地点的名称 | Java | [许可矩阵](http://alias-i.com/lingpipe/web/download.html)
    |'
- en: '| Source code and unit tests |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 源代码和单元测试 |'
- en: '| [Multi-lingual, multi-domain, multi-genre models [30]](http://alias-i.com/lingpipe/index.html)
    |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| [多语言、多领域、多类型模型 [30]](http://alias-i.com/lingpipe/index.html) |'
- en: '| [**Named Entity Recognition Tool**, Guillaume Lample, Miguel Ballesteros,
    Sandeep Subramanian, Kazuya Kawakami, Chris Dyer, 2016](https://github.com/glample/tagger)
    | A neural architecture | Python | [Apache License 2.0](https://github.com/glample/tagger/blob/master/LICENSE.md)
    |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| [**命名实体识别工具**, Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian,
    Kazuya Kawakami, Chris Dyer, 2016](https://github.com/glample/tagger) | 一种神经架构
    | Python | [Apache 许可证 2.0](https://github.com/glample/tagger/blob/master/LICENSE.md)
    |'
- en: '| [state-of-the-art performance in NER on the 4 CoNLL datasets (English, Spanish,
    German and Dutch) without resorting to any language-specific knowledge or resources
    such as gazetteers [31]](https://github.com/glample/tagger) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| [在 4 个 CoNLL 数据集（英语、西班牙语、德语和荷兰语）上实现了最先进的命名实体识别性能，无需依赖任何语言特定的知识或资源，如地名词典 [31]](https://github.com/glample/tagger)
    |'
- en: '| [**MinorThird**, William W. Cohen, Carnegie Mellon University, 2004](http://minorthird.sourceforge.net/old/doc/)
    | Combines tools for annotating and visualizing text with state-of-the-art learning
    methods | Java | [BSD license](https://opensource.org/licenses/bsd-license.php)
    |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| [**MinorThird**, William W. Cohen, Carnegie Mellon University, 2004](http://minorthird.sourceforge.net/old/doc/)
    | 结合了用于注释和可视化文本的工具与最先进的学习方法 | Java | [BSD 许可](https://opensource.org/licenses/bsd-license.php)
    |'
- en: '| Supports active learning and online learning |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 支持主动学习和在线学习 |'
- en: '| [[32]](http://minorthird.sourceforge.net/old/doc/) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| [[32]](http://minorthird.sourceforge.net/old/doc/) |'
- en: '| [**Watson Named Entity Recognition annotator**, IBM](https://www.ibm.com/support/knowledgecenter/en/SS8NLW_10.0.0/com.ibm.watson.wex.aac.doc/aac-tasystemt.html)
    | A person, location, and organization annotators | Python SDK | [Pricing](https://www.ibm.com/watson-analytics/pricing)
    |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| [**Watson 实体识别标注器**，IBM](https://www.ibm.com/support/knowledgecenter/en/SS8NLW_10.0.0/com.ibm.watson.wex.aac.doc/aac-tasystemt.html)
    | 人物、地点和组织标注器 | Python SDK | [定价](https://www.ibm.com/watson-analytics/pricing)
    |'
- en: '| English, Chinese, French, German, Japanese, Spanish languages | Node SDK
    |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 英语、中文、法语、德语、日语、西班牙语 | Node SDK |'
- en: '| [Possibility of adding entries  [33]](https://www.ibm.com/support/knowledgecenter/en/SS8NLW_10.0.0/com.ibm.watson.wex.aac.doc/aac-tasystemt.html)
    | Swift SDK |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| [添加条目的可能性 [33]](https://www.ibm.com/support/knowledgecenter/en/SS8NLW_10.0.0/com.ibm.watson.wex.aac.doc/aac-tasystemt.html)
    | Swift SDK |'
- en: '|  | Java SDK |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | Java SDK |'
- en: '|  | Unity SDK |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  | Unity SDK |'
- en: '|  | .NET Standard library |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | .NET 标准库 |'
- en: '| [**PoolParty Semantic Suite**, Semantic Web Company, 2009](https://www.poolparty.biz/)
    | Modular and flexible | Data is transformed into RDF graphs and can be queried
    with SPARQL | [Price Overview](https://www.poolparty.biz/priceoverview/) |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| [**PoolParty 语义套件**，语义网公司，2009](https://www.poolparty.biz/) | 模块化和灵活性 | 数据被转换成
    RDF 图，并可以使用 SPARQL 查询 | [价格概览](https://www.poolparty.biz/priceoverview/) |'
- en: '| uses standards-based technologies as defined by W3C |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 使用 W3C 定义的标准技术 |'
- en: '| Enriches information with valuable metadata |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 通过有价值的元数据丰富信息 |'
- en: '| [[34]](https://www.poolparty.biz/) |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| [[34]](https://www.poolparty.biz/) |'
- en: '| [**Rosette Entity Extractor**, Basis Technology, 1995](https://www.basistech.com/text-analytics/rosette/entity-extractor/)
    | 20 supported languages | Bindings: cURL, Python, PHP, Java, R, Ruby, C#, Node.js
    | - |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| [**Rosette 实体提取器**，Basis Technology，1995](https://www.basistech.com/text-analytics/rosette/entity-extractor/)
    | 支持 20 种语言 | 绑定：cURL、Python、PHP、Java、R、Ruby、C#、Node.js | - |'
- en: '| 18 entity types detected |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 检测到 18 种实体类型 |'
- en: '| Filter for key entities |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 筛选关键实体 |'
- en: '| [Confidence scores for each result [35]](https://www.basistech.com/text-analytics/rosette/entity-extractor/)
    |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| [每个结果的置信度评分 [35]](https://www.basistech.com/text-analytics/rosette/entity-extractor/)
    |'
- en: '**NER Tools**'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**NER 工具**'
- en: More On This Topic
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清理和预处理文本数据以进行 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[SQL LIKE Operator Examples](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL LIKE 操作符示例](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)'
- en: '[Ensemble Learning with Examples](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带有示例的集成学习](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
- en: '[Picking Examples to Understand Machine Learning Model](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[挑选示例以理解机器学习模型](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)'
- en: '[Easy Guide To Data Preprocessing In Python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 数据预处理简易指南](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
