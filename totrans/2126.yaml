- en: 'Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model](https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/10b39d79a6e686d9cc4e3145e18c937d.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Google DeepMind](https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-represents-how-ai-powered-tools-can-support-us-and-save-time-it-was-created-by-martina-stiftinger-as-part-of-the-visua-18069239/)
  prefs: []
  type: TYPE_NORMAL
- en: '2023 was the year of Large Language Models and Open Source. Many startups and
    companies open-sourced their models and weights to combat proprietary LLMs such
    as ChatGPT and Claude. Some of the important companies and models (open source)
    for 2023 were:'
  prefs: []
  type: TYPE_NORMAL
- en: Meta (LLama, LLamav2)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TII (Falcon 7B, 40B, 180B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mistral (Mistral 7B, Mixtral8x7B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: However, a 7B model which is relatively easy and cheaper to deploy is not up
    to par with bigger models such as 70B. The strongest open-source contender was
    Mistral 7B which would outperform many bigger models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/885bea73025d52991e66d7eda74d2446.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of Mistral-7B from [Mistral.ai](https://mistral.ai/news/announcing-mistral-7b/)
  prefs: []
  type: TYPE_NORMAL
- en: These small models however still do not respond well to natural prompts and
    require good prompt engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zephyr 7B is a model created by the HuggingFace H4 (Helpful, Honest, Harmless,
    Huggy) team whose main goal was to create a smaller language model that is aligned
    with user intent and outperforms even bigger models.
  prefs: []
  type: TYPE_NORMAL
- en: Zephyr is an aligned version of Mistral-7B mainly created with the power of
    Distillation, and is comparable to 70B models in academic and conversational benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/e16f6ba0bbd29b5cb68165720bd5cb79.png)Performance comparison of
    Zephyr-7B | Source: [Zephyr paper](https://arxiv.org/abs/2310.16944)'
  prefs: []
  type: TYPE_IMG
- en: Key Features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The reason behind the outstanding performance of Zephyr is these 4 key techniques
    that the H4 Team has used.
  prefs: []
  type: TYPE_NORMAL
- en: Self-Instruct data creation & DSFT (Distilled Supervised Fine-Tuning)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feedback collection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DDPO (Distilled Direct Preference Optimization) of the DSFT model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '****Self-Instruct Data Creation & DSFT****'
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally **Supervised Fine-Tuning (SFT)** is performed on a Large Language
    Model via a high-quality instruction completion pair. Construction of this data
    is costly and requires human supervision (Chung et al., 2022; Sanh et al., 2021).
  prefs: []
  type: TYPE_NORMAL
- en: One of the interesting approaches here is to use a Teacher model (already trained
    LLM) to generate the instructions and responses. This distillation technique was
    first used on Alpaca (Taori et al., 2023) which proved that a small model can
    outperform larger models with **Distilled Supervised Fine-Tuning**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/e71c20282740d59d9e9fa0a01422208d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Self-Instruct pipeline | Source: [Self-Instruct paper](https://arxiv.org/abs/2212.10560)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The H4 Team used Zephyr for constructing high-quality supervised (instruction,
    completion) datasets that were used for doing DSFT. (Training a model on instructions/completions
    generated is a form of distillation known as DSFT: Distilled Supervised Fine-Tuning).'
  prefs: []
  type: TYPE_NORMAL
- en: '****Feedback Collection****'
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models are aligned typically with the help of **Reinforcement
    learning from human feedback (RLHF)**. Zephyr instead uses Feedback from a better
    teacher model (such as GPT-4) to align the interests of the model, following the
    approach of Ultra Feedback.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/6fd933bf69fbba697ba316aaa0ec5579.png)'
  prefs: []
  type: TYPE_IMG
- en: 'UltraFeedback construction process | Source: [UltraFeedback paper](https://arxiv.org/abs/2310.01377)'
  prefs: []
  type: TYPE_NORMAL
- en: The way it works is that each prompt supervised prompt from SFT is passed to
    4 models (Claude, LLama, Falcon, etc.) and each of the 4 responses against the
    single prompt is scored with the help of GPT-4\. Now we have a dataset of an Input
    (x), highest scoring completion (yw), and a random prompt denoted as low scoring
    completion (yl), i.e we have a triplet of (x, yw, yl).
  prefs: []
  type: TYPE_NORMAL
- en: '****Preference Optimization****'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this last step is to maximize the preference of the model from yw(highest-scoring
    completion) over yl (low-scoring completion). This is done using **DPO** (**Direct
    Preference Optimization**). Using DPO is simpler than using plain RLHF and intuitively
    it performs better than RLHF. The approach in this case is known as **dDPO** because
    it uses a distilled dataset generated with the help of a teacher model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/d5c62eeb7e9fb475d39ffd35cff700e8.png)DPO vs RLHF | Source: [Zephyr
    paper](https://arxiv.org/abs/2310.16944)'
  prefs: []
  type: TYPE_IMG
- en: 'The overall algorithm looks somewhat like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/94a6f3973c2f1e21a14e30e049876142.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And can be translated into the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the probability for (x, yw) and (x, yl) from the dSFT model (forward-only).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the probability for (x, yw) and (x, yl) from the dDPO model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute Eq 1 and backpropagate to update. Repeat
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training Details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The base model that Zephyr used is Mistral-7B which was the state-of-the-art
    open source at the time of release. They used the [TRL](https://github.com/huggingface/trl)
    library for fine-tuning and alignment. Deep-Speed Zero 3 and Flash-Attention 2
    were used to optimize and speed up the training and to fully utilize the GPU.
    The models were trained using AdamW optimizer and no weight decay was used. All
    experiments were run on 16 A100s using bfloat16 precision and typically took 2–4
    hours to complete. You can refer to the [original paper](https://arxiv.org/pdf/2310.16944.pdf)
    for in-depth details on the Training Procedure of Zephyr.
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zephyr team combines the best techniques to train the Large Language Models
    and it matched the performance of 40B models with just 7B parameters and matched
    70B for chat models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/89bd26616561e68efc609e6014d45108.png)Comparison of Zephyr vs
    other LLMs | Source: [Zephyr paper](https://arxiv.org/abs/2310.16944)'
  prefs: []
  type: TYPE_IMG
- en: '![Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language
    Model](../Images/e16f6ba0bbd29b5cb68165720bd5cb79.png)Comparison of Zephyr vs
    other LLMs | Source: [Zephyr paper](https://arxiv.org/abs/2310.16944)'
  prefs: []
  type: TYPE_IMG
- en: Usage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zephyr models are publically available on Hugging Face and can be used similarly
    to any other Language Model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zephyr-7B is a small model that showed the power of distillation from a LLM
    to a smaller model. The resulting model ZEPHYR-7B, based on MISTRAL-7B, sets a
    new state-of-the-art for 7B parameter chat models and even outperforms LLAMA2-CHAT-70B
    on MT-Bench.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Zephyr: Direct Distillation of LM Alignment ([https://arxiv.org/abs/2310.16944](https://arxiv.org/abs/2310.16944))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HuggingFace Zephyr blog ([https://huggingface.co/blog/Isamu136/understanding-zephyr](https://huggingface.co/blog/Isamu136/understanding-zephyr))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Self Instruct: [https://arxiv.org/abs/2212.10560](https://arxiv.org/abs/2212.10560)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'UltraFeedback: [https://arxiv.org/abs/2310.01377](https://arxiv.org/abs/2310.01377)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[](https://twitter.com/AhmadMustafaAn1)**[Ahmad Anis](https://twitter.com/AhmadMustafaAn1)****
    is a passionate machine learning engineer and researcher currently working at
    [redbuffer.ai](https://redbuffer.ai/). Beyond his day job, Ahmad actively engages
    with the machine learning community. He serves as a regional lead for Cohere for
    AI, a nonprofit dedicated to open science, and is an AWS community builder. Ahmad
    is an active contributor at Stackoverflow, where he has 2300+ points. He has contributed
    to many famous open-source projects, including Shap-E by OpenAI.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring Google''s Latest AI Tools: A Beginner''s Guide](https://www.kdnuggets.com/exploring-googles-latest-ai-tools-a-beginners-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Comprehensive List of Resources to Master Large Language Models](https://www.kdnuggets.com/a-comprehensive-list-of-resources-to-master-large-language-models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exploring the Latest Trends in AI/DL: From Metaverse to Quantum Computing](https://www.kdnuggets.com/2023/07/exploring-latest-trends-aidl-metaverse-quantum-computing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ultimate Open-Source Large Language Model Ecosystem](https://www.kdnuggets.com/2023/05/ultimate-opensource-large-language-model-ecosystem.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Large Language Model Fine-tuning](https://www.kdnuggets.com/7-steps-to-mastering-large-language-model-fine-tuning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
