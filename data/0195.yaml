- en: 'Reading Minds with AI: Researchers Translate Brain Waves to Images'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读思维与人工智能：研究人员将脑电波转换为图像
- en: 原文：[https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html](https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html](https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html)
- en: '![Reading Minds with AI: Researchers Translate Brain Waves to Images](../Images/da28d3d2cb03ef1fee6b9dba60eb83e4.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![阅读思维与人工智能：研究人员将脑电波转换为图像](../Images/da28d3d2cb03ef1fee6b9dba60eb83e4.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑提供
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Imagine reliving your memories or constructing images of what someone is thinking.
    It sounds like something straight out of a science fiction movie but with the
    recent advancements in computer vision and deep learning, it is becoming a reality.
    Though neuroscientists still struggle to truly demystify how the human brain converts
    what our eyes see into mental images, it seems like AI is getting better at this
    task. Two researchers, from the Graduate School of Frontier Biosciences at Osaka
    University, proposed a new method using an LDM named Stable Diffusion that accurately
    reconstructed the images from human brain activity that was obtained by functional
    magnetic resonance imaging (fMRI). Although the paper “[High-resolution image
    reconstruction with latent diffusion models from human brain activity“](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full) 
    by [Yu Takagi](https://yu-takagi.github.io/) and [Shinji Nishimotois](https://cinet.jp/english/people/20141086/)
    is not yet peer-reviewed, it has taken the internet by storm as the results are
    shockingly accurate.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下重新体验你的记忆或构建某人正在思考的图像。这听起来像是科幻电影中的情节，但随着计算机视觉和深度学习的最新进展，它正变成现实。尽管神经科学家仍在努力真正揭示人脑如何将我们眼睛所见转化为心理图像，但人工智能似乎在这方面越来越有能力。来自大阪大学前沿生物科学研究生院的两位研究人员提出了一种新方法，使用名为稳定扩散的LDM，准确地重建了通过功能磁共振成像（fMRI）获得的人脑活动图像。虽然由[Yu
    Takagi](https://yu-takagi.github.io/)和[Shinji Nishimotois](https://cinet.jp/english/people/20141086/)撰写的论文“[通过潜在扩散模型从人脑活动中高分辨率重建图像](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full)”尚未经过同行评审，但由于结果令人震惊的准确，它在互联网上引起了轰动。
- en: This technology has the potential to revolutionize fields like psychology, neuroscience,
    and even the criminal justice system. Imagine a suspect is questioned about where
    he was during the time of the murder and he answers that he was home. But the
    reconstructed image shows him at the crime scene. Pretty Interesting right? So
    how does it exactly work? Let's dig deeper into this research paper, its limitations,
    and its future scope.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术有可能彻底改变心理学、神经科学，甚至刑事司法系统等领域。想象一下，一个嫌疑人被询问他在谋杀发生时在哪里，他回答说他在家。但重建的图像却显示他在犯罪现场。相当有趣，对吧？那么它到底是如何工作的呢？让我们深入研究这篇论文、其局限性以及未来的前景。
- en: How does it Work?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: The researchers used the [Natural Scenes Dataset ( NSD)](http://naturalscenesdataset.org/)
     provided by the University of Minnesota. It contained data obtained from fMRI
    scans of four subjects who had looked at 10,000 different images. A subset of
    982 images viewed by all four subjects was used as the test dataset. Two different
    AI models were trained during the process. One was used to link the brain activity
    with the fMRI images while the other one was used to link it with the text descriptions
    of images that the subjects looked at. Together, these models allowed the Stable
    Diffusion to turn the fMRI data into relatively accurate imitations of the images
    that were not part of its training achieving an accuracy of almost 80%.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员使用了由明尼苏达大学提供的[自然场景数据集 (NSD)](http://naturalscenesdataset.org/)。该数据集包含了四名受试者查看的10,000张不同图像的fMRI扫描数据。所有四名受试者查看的982张图像的子集被用作测试数据集。在这个过程中训练了两个不同的AI模型。一个用于将大脑活动与fMRI图像关联，而另一个则用于将其与受试者查看的图像的文字描述关联。这些模型结合起来，使Stable
    Diffusion能够将fMRI数据转化为相对准确的图像模仿，其准确率达到近80%。
- en: '![Reading Minds with AI: Researchers Translate Brain Waves to Images](../Images/e75a12bde28994bcc0f4d2fd4cdc3c4d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![用AI读取思维：研究人员将脑波转化为图像](../Images/e75a12bde28994bcc0f4d2fd4cdc3c4d.png)'
- en: '[Original Images (left) and AI-Generated Images for all Four Subjects](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始图像（左）和所有四名受试者生成的AI图像](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full)'
- en: The first model was able to effectively regenerate the layout and the perspective
    of the image being viewed. But the model struggled with specific objects such
    as the clock tower and It created abstract and cloudy figures. Instead of using
    large datasets to predict more details, researchers used the second AI model to
    associate the keywords from image captions to fMRI scans. For example, if the
    training data has a picture of a clock tower then the system associates the pattern
    of brain activity with that object. During the testing stage, if a similar brain
    pattern was exhibited by the subject participant then the System feds the objects
    keyword into Stable Diffusion’s normal text-to-image generator that resulted in
    the convincing imitation of the real image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个模型能够有效地再现图像的布局和视角。但该模型在处理特定物体如钟楼时遇到了困难，并且生成了抽象且模糊的图像。研究人员并没有使用大型数据集来预测更多细节，而是使用了第二个AI模型，将图像标题中的关键词与fMRI扫描关联起来。例如，如果训练数据中有一张钟楼的照片，那么系统就会将大脑活动的模式与该物体关联起来。在测试阶段，如果被试者表现出类似的大脑模式，那么系统会将物体的关键词输入到Stable
    Diffusion的正常文本到图像生成器中，从而产生对真实图像的逼真模仿。
- en: '![Reading Minds with AI: Researchers Translate Brain Waves to Images](../Images/02e880427252960ab17790154e84001a.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![用AI读取思维：研究人员将脑波转化为图像](../Images/02e880427252960ab17790154e84001a.png)'
- en: (leftmost) Photos seen by study participants, (2nd) Layout and Perspective using
    patterns of brain activity alone, (3rd) Image by textual Information alone, (rightmost)
    Addition of textual information and patterns of brain activity to re-create the
    object in the [photo ](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: （最左侧）研究参与者看到的照片，（第二）仅使用大脑活动模式的布局和视角，（第三）仅使用文字信息的图像，（最右侧）结合文字信息和大脑活动模式来重新创建[照片](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full)中的物体
- en: In this paper, the researchers also claimed that the study was the first of
    its kind where each component of LDM (Stable diffusion) was quantitatively interpreted
    from a neuroscience perspective. They did so by mapping the specific components
    to the distinct regions of the brain. Although the proposed model is still in
    the nascent stage yet people were quick to react to this paper and termed the
    model as the next mind reader.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，研究人员还声称这是首次从神经科学的角度定量解释LDM（Stable Diffusion）的每个组件。他们通过将特定组件映射到大脑的不同区域来实现这一点。尽管所提出的模型仍处于初期阶段，但人们对这篇论文的反应迅速，并将该模型称为下一个思维阅读器。
- en: Limitations and Future Scope
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局限性和未来展望
- en: Although the accuracy of this model is quite impressive, it was tested on the
    brain scan of the people who provided the training brain scans. Using the same
    data for training and test sets can lead to overfitting. However, we should not
    shrug off this paper as such publications attract researchers and we start seeing
    related papers with incremental improvements.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个模型的准确性相当令人印象深刻，但它是在提供训练脑部扫描的人的脑部扫描上进行测试的。使用相同的数据进行训练和测试集可能会导致过拟合。然而，我们不应忽视这篇论文，因为这类出版物吸引了研究人员，我们开始看到相关论文的逐步改进。
- en: 'Considering the improvements in the field of computer vision, this paper makes
    me think: **Will we be able to relive our dreams soon?** Pretty cool and scary
    at the same time. Although it''s quite intriguing, it raises some ethical concerns
    about the invasion of privacy. Also, there is still a long way to go before we
    can actually create the subjective experience of a dream. The model is not yet
    practical for daily use but we are getting closer to understanding how our brain
    functions. Such technology can also bring about tremendous advancements in the
    medical field, especially for people who have communication impairments.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到计算机视觉领域的进步，这篇论文让我思考：**我们是否很快能够重温我们的梦想？** 这既令人兴奋又令人害怕。虽然相当引人入胜，但它引发了有关隐私侵犯的一些伦理问题。此外，要真正创造出梦境的主观体验还有很长的路要走。这个模型尚不适合日常使用，但我们离理解大脑的运作越来越近。这项技术还可能在医疗领域带来巨大的进展，特别是对于那些有沟通障碍的人。
- en: Conclusion
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: If the refinement of the proposed model comes into the picture, this can be
    the **NEXT BREAKTHROUGH** in the world of AI. But the benefits and risks must
    be weighed before the widespread implementation of any technology. I hope you
    enjoyed reading this article and I would love to hear your thoughts about this
    amazing research paper.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所提模型的改进成为现实，这可能是**下一个突破**的人工智能领域。但在广泛实施任何技术之前，必须权衡其利弊。希望你喜欢阅读这篇文章，我很想听听你对这篇惊人研究论文的看法。
- en: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** is an aspiring
    software developer with a keen interest in data science and applications of AI
    in medicine. Kanwal was selected as the Google Generation Scholar 2022 for the
    APAC region. Kanwal loves to share technical knowledge by writing articles on
    trending topics, and is passionate about improving the representation of women
    in tech industry.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** 是一位有抱负的软件开发人员，对数据科学和人工智能在医学中的应用充满兴趣。Kanwal被选为2022年APAC地区的Google
    Generation Scholar。Kanwal喜欢通过撰写关于趋势话题的文章分享技术知识，并热衷于改善女性在技术行业中的代表性。'
- en: More On This Topic
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速指南：如何找到合适的人进行注释](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
- en: '[How to Translate Languages with MarianMT and Hugging Face Transformers](https://www.kdnuggets.com/how-to-translate-languages-with-marianmt-and-hugging-face-transformers)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用MarianMT和Hugging Face Transformers翻译语言](https://www.kdnuggets.com/how-to-translate-languages-with-marianmt-and-hugging-face-transformers)'
- en: '[A Step by Step Guide to Reading and Understanding SQL Queries](https://www.kdnuggets.com/a-step-by-step-guide-to-reading-and-understanding-sql-queries)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逐步指南：阅读和理解SQL查询](https://www.kdnuggets.com/a-step-by-step-guide-to-reading-and-understanding-sql-queries)'
- en: '[2024 Reading List: 5 Essential Reads on Artificial Intelligence](https://www.kdnuggets.com/2024-reading-list-5-essential-reads-on-artificial-intelligence)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2024年阅读清单：5本人工智能必读书籍](https://www.kdnuggets.com/2024-reading-list-5-essential-reads-on-artificial-intelligence)'
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第一部分：神经元速度慢,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
- en: '[How to land an ML job: Advice from engineers at Meta, Google Brain, and SAP](https://www.kdnuggets.com/2022/08/corise-land-ml-job-advice-engineers-meta-google-brain-sap.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何获得机器学习工作：来自Meta、Google Brain和SAP工程师的建议](https://www.kdnuggets.com/2022/08/corise-land-ml-job-advice-engineers-meta-google-brain-sap.html)'
