- en: 'Introduction to Deep Learning Libraries: PyTorch and Lightning AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/291f913d791d2fd9fc8513dccfb9ebc0.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Photo by Google [DeepMind](https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-depicts-the-potential-of-ai-for-society-through-3d-visualisations-it-was-created-by-novoto-studio-as-part-of-the-visua-18069496/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is a branch of the machine learning model based on [neural networks](https://en.wikipedia.org/wiki/Neural_network).
    In the other machine model, the data processing to find the meaningful features
    is often done manually or relying on domain expertise; however, deep learning
    can mimic the human brain to discover the essential features, increasing the model
    performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: There are many applications for deep learning models, including facial recognition,
    fraud detection, speech-to-text, text generation, and many more. Deep learning
    has become a standard approach in many advanced machine learning applications,
    and we have nothing to lose by learning about them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'To develop this deep learning model, there are various library frameworks we
    can rely upon rather than working from scratch. In this article, we will discuss
    two different libraries we can use to develop deep learning models: PyTorch and
    Lighting AI. Let’s get into it.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch is an open-source library framework to train deep-learning neural networks.
    PyTorch was developed by the Meta group in 2016 and has grown in popularity. The
    rise of popularity was thanks to the PyTorch feature that combines the GPU backend
    library from [Torch](http://torch.ch/) with Python language. This combination
    makes the package easy to follow by the user but still powerful in developing
    the deep learning model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: There are a few standout [PyTorch features](https://pytorch.org/features/) that
    are enabled by the libraries, including a nice front-end, distributed training,
    and a fast and flexible experimentation process. Because there are many PyTorch
    users, the community development and investment were also massive. That is why
    learning PyTorch would be beneficial in the long run.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch building block is a [tensor](https://en.wikipedia.org/wiki/Tensor),
    a multi-dimensional array used to encode all the input, output, and model parameters.
    You can imagine a tensor like the NumPy array but with the capability to run on
    GPU.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try out the PyTorch library. It’s recommended to perform the tutorial
    in the cloud, such as Google Colab if you don’t have access to a GPU system (although
    it could still work with a CPU). But, If you want to start in the local, we need
    to install the library via [this page](https://pytorch.org/get-started/locally/).
    Select the appropriate system and specification you have.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: For example, the code below is for pip installation if you have a CUDA-Capable
    system.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: After the installation finishes, let’s try some PyTorch capabilities to develop
    the deep learning model. We will do a simple image classification model with PyTorch
    in this tutorial based on their web tutorial. We would walk on the code and have
    an explanation of what happened within the code.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: First, we would download the dataset with PyTorch. For this example, we would
    use the MNIST dataset, which is the number handwritten classification dataset.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We download both the MNIST train and test datasets to our root folder. Let’s
    see what our dataset looks like.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/5beec8ab85fb6221d4f0f8c808e9fe79.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Every image is a single-digit number between zero and nine, meaning we have
    ten labels. Next, let’s develop an image classifier based on this dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: We need to transform the image dataset into a tensor to develop a deep learning
    model with PyTorch. As our image is a PIL object, we can use the PyTorch ToTensor
    function to perform the transformation. Additionally, we can automatically transform
    the image with the datasets function.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By passing the transformation function to the transform parameter, we can control
    what the data would be like. Next, we would wrap the data into the DataLoader
    object so the PyTorch model could access our image data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the code above, we create a DataLoader object for the train and test data.
    Each data batch iteration would return 64 features and labels in the object above.
    Additionally, the shape of our image is 28 * 28 (height * width).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would develop the Neural Network model object.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the object above, we create a Neural Model with few layer structure. To develop
    the Neural Model object, we use the subclassing method with the nn.module function
    and create the neural network layers within the__init__.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'We initially convert the 2D image data into pixel values inside the layer with
    the flatten function. Then, we use the sequential function to wrap our layer into
    a sequence of layers. Inside the sequential function, we have our model layer:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'By sequence, what happens above is:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: First, the data input which is 28*28 features is transformed using a linear
    function in the linear layer and having 128 features as the output.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ReLU is a non-linear activation function that is present between the model input
    and output to introduce non-linearity.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReLU是一个非线性激活函数，位于模型的输入和输出之间，以引入非线性。
- en: 128 features input to the linear layer and have 128 features output
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 128个特征输入到线性层，输出128个特征。
- en: Another ReLU activation function
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一个ReLU激活函数
- en: 128 features as the input in the linear layer and 10 features as the output
    (our dataset label only has 10 labels).
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性层的输入为128个特征，输出为10个特征（我们的数据集标签只有10个标签）。
- en: Lastly, the forward function is present for the actual input process for the
    model. Next, the model would need a loss function and optimization function.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，前向函数用于模型的实际输入过程。接下来，模型还需要一个损失函数和优化函数。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For the next code, we just prepare the training and test preparation before
    we run the modeling activity.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于下一个代码，我们只是准备训练和测试的准备工作，然后再进行建模活动。
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we are ready to run our model training. We would decide how many epochs
    (iterations) we want to perform with our model. For this example, let’s say we
    want it to run for five times.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好运行模型训练了。我们需要决定模型要运行多少个epoch（迭代次数）。在这个示例中，我们设定为运行五次。
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/a2376135f7b6ed629ed26dea0ac08e4f.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![深度学习库简介：PyTorch和Lighting AI](../Images/a2376135f7b6ed629ed26dea0ac08e4f.png)'
- en: The model now has finished their training and able to be used for any image
    prediction activity. The result could vary, so expect different results from the
    above image.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经完成训练，可以用于任何图像预测活动。结果可能会有所不同，因此请期待与上述图片不同的结果。
- en: It’s just a few things that PyTorch can do, but you can see that building a
    model with PyTorch is easy. If you are interested in the pre-trained model, PyTorch
    has a [hub](https://pytorch.org/hub/) you can access.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是PyTorch可以做的一些事情，但你可以看到，使用PyTorch构建模型很简单。如果你对预训练模型感兴趣，PyTorch有一个你可以访问的[hub](https://pytorch.org/hub/)。
- en: Lighting AI
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lighting AI
- en: '[Lighting AI](https://lightning.ai/) is a company that provides various products
    to minimize the time to train the PyTorch deep learning model and simplify it.
    One of their open-source product is [PyTorch Lighting](https://lightning.ai/pytorch-lightning),
    which is a library that offers a framework to train and deploy the PyTorch model.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lighting AI](https://lightning.ai/)是一家提供各种产品的公司，旨在缩短训练PyTorch深度学习模型的时间并简化过程。他们的一个开源产品是[PyTorch
    Lighting](https://lightning.ai/pytorch-lightning)，这是一个提供训练和部署PyTorch模型框架的库。'
- en: Lighting offers a few features, including code flexibility, no boilerplate,
    minimal API, and improved team collaboration. Lighting also offers features such
    as multi-GPU utilization and swift, low-precision training. This made Lighting
    a good alternative to develop our PyTorch model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Lighting提供了一些功能，包括代码灵活性、无需样板代码、最小化API以及改进的团队协作。Lighting还提供了多GPU利用和快速、低精度训练等功能。这使得Lighting成为开发我们PyTorch模型的一个很好的替代选择。
- en: Let’s try out the model development with Lighting. To start, we need to install
    the package.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试用Lighting进行模型开发。首先，我们需要安装这个包。
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With the Lighting installed, we would also install another Lighting AI product
    called [TorchMetrics](https://lightning.ai/torchmetrics) to simplify the metric
    selection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了Lighting后，我们还将安装另一个Lighting AI产品，名为[TorchMetrics](https://lightning.ai/torchmetrics)，以简化指标选择。
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With all the libraries installed, we would try to develop the same model from
    our previous example using a Lighting wrapper. Below is the whole code for developing
    the model.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所有库都安装完成后，我们将尝试使用Lighting封装器开发与之前示例相同的模型。下面是开发模型的完整代码。
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Let’s break down what happen in the code above. The difference with the PyTorch
    model we developed previously is that the NNModel class now uses subclassing from
    the LightingModule. Additionally, we assign the accuracy metrics to assess using
    the TorchMetrics. Then, we added the training and testing step within the class
    and set up the optimization function.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下上面的代码。与我们之前开发的PyTorch模型的不同之处在于，NNModel类现在使用了LightingModule的子类。此外，我们使用TorchMetrics分配了准确性指标进行评估。然后，我们在类中添加了训练和测试步骤，并设置了优化函数。
- en: With all the models set, we would run the model training using the transformed
    DataLoader object to train our model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有模型设置完成后，我们将使用转换后的DataLoader对象运行模型训练。
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/87749cd3f95ff12d202df318f44ab167.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![深度学习库简介：PyTorch和Lighting AI](../Images/87749cd3f95ff12d202df318f44ab167.png)'
- en: With the Lighting library, we can easily tweak the structure you need. For further
    reading, you could read their [documentation](https://lightning.ai/docs/pytorch/latest/).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Lighting库，我们可以轻松调整所需的结构。有关进一步阅读，你可以查看他们的[文档](https://lightning.ai/docs/pytorch/latest/)。
- en: Conclusion
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: PyTorch is a library for developing deep learning models, and it provides an
    easy framework for us to access many advanced APIs. Lighting AI also supports
    the library, which provides a framework to simplify the model development and
    enhance the development flexibility. This article introduced us to both the library's
    features and simple code implementation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是一个用于开发深度学习模型的库，它为我们提供了一个简单的框架，以便访问许多高级API。Lightning AI 也支持这个库，提供了一个简化模型开发并增强开发灵活性的框架。本文介绍了这个库的功能以及简单的代码实现。
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**是一名数据科学助理经理和数据撰稿人。在全职工作于Allianz
    Indonesia期间，他喜欢通过社交媒体和写作媒体分享Python和数据技巧。'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[入门PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Using Lightning AI Studio For Free](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费使用Lightning AI Studio](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
- en: '[Introduction to Python Libraries for Data Cleaning](https://www.kdnuggets.com/2023/03/introduction-python-libraries-data-cleaning.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python数据清洗库简介](https://www.kdnuggets.com/2023/03/introduction-python-libraries-data-cleaning.html)'
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完全免费的PyTorch深度学习课程](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
- en: '[A Practical Guide to Transfer Learning using PyTorch](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch进行迁移学习的实用指南](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch还是TensorFlow？比较流行的机器学习框架](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
