- en: Boost Your Image Classification Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升您的图像分类模型
- en: 原文：[https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html](https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html](https://www.kdnuggets.com/2019/05/boost-your-image-classification-model.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Aditya Mishra](https://www.linkedin.com/in/aditya-mishra-b50623138/),
    ML Engineer at difference-engine.ai**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Aditya Mishra](https://www.linkedin.com/in/aditya-mishra-b50623138/)，来自
    difference-engine.ai 的机器学习工程师**'
- en: Image classification is assumed to be a nearly solved problem. Fun part is when
    you have to use all your cunning to gain that extra 1% accuracy. I came across
    such a situation, when I participated in [*Intel Scene Classification Challenge
    hosted by Analytics Vidhya*](https://datahack.analyticsvidhya.com/contest/practice-problem-intel-scene-classification-challe/).
    I thoroughly enjoyed the contest as I tried to extract out all the juices from
    my deep learning model. The techniques below can in general be applied to any
    image classification problem at hand.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类被认为是一个几乎解决的问题。有趣的部分是当你必须发挥全部聪明才智来获得额外的 1% 准确度时。我遇到了这样的情况，当我参加了[*Intel 场景分类挑战赛（由
    Analytics Vidhya 主办）*](https://datahack.analyticsvidhya.com/contest/practice-problem-intel-scene-classification-challe/)。我非常享受这次比赛，因为我尽力从我的深度学习模型中提取所有精华。下面的技术通常可以应用于任何图像分类问题。
- en: Problem
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: The problem was to classify a given image into 6 categories
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是将给定的图像分类为 6 个类别
- en: '![Figure](../Images/c624ff42086428fe34c300c631431edb.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/c624ff42086428fe34c300c631431edb.png)'
- en: Data Classes
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类别
- en: We were given **~25K** images from a wide range of natural scenes from all around
    the world
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了**约 25K** 张来自全球各地自然场景的图像
- en: Progressive Resizing
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 渐进式调整图像大小
- en: It is the technique to sequentially resize all the images while training the
    CNNs on smaller to bigger image sizes. Progressive Resizing is described briefly
    in his terrific *fastai* course, “*Practical Deep Learning for Coders*”. A great
    way to use this technique is to train a model with smaller image size say 64x64,
    then use the weights of this model to train another model on images of size 128x128
    and so on. Each larger-scale model incorporates the previous smaller-scale model
    layers and weights in its architecture.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在训练 CNN 时按顺序调整所有图像大小的技术。渐进式调整图像大小在他出色的*fastai* 课程“*实用深度学习课程*”中简要描述了。使用这种技术的一个很好的方法是用较小的图像大小（如
    64x64）训练模型，然后使用该模型的权重来训练另一个图像大小为 128x128 的模型，依此类推。每个更大规模的模型都在其架构中包含了之前较小规模模型的层和权重。
- en: '![Figure](../Images/69a3e4afcb3675da7bcb907ad836b6c5.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/69a3e4afcb3675da7bcb907ad836b6c5.png)'
- en: Progressive Resizing
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 渐进式调整图像大小
- en: FastAI
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FastAI
- en: '![](../Images/c80f21db340c305970c82dd1560f70cb.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c80f21db340c305970c82dd1560f70cb.png)'
- en: The *fastai* library is a powerful deep learning library. If the FastAI team
    finds a particularly interesting paper, they test it out on different datasets
    & work out how to tune it. Once successful, it gets incorporated in their library,
    and is readily available for its users. The library contains many State of the
    art (SOTA)techniques built in. Built on type of pytorch, *fastai* has excellent
    default parameters for most if not all the tasks. Some of the techniques are
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*fastai* 库是一个强大的深度学习库。如果 FastAI 团队发现一篇特别有趣的论文，他们会在不同的数据集上进行测试，并研究如何调整它。一旦成功，它就会被纳入他们的库中，用户可以方便地使用。该库包含了许多最先进（SOTA）的技术。基于
    PyTorch 类型，*fastai* 为大多数（如果不是全部的话）任务提供了出色的默认参数。以下是一些技术：'
- en: Cyclical Learning Rate
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环学习率
- en: One cycle learning
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一周期学习
- en: Deep Learning on Structured Data
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结构化数据上的深度学习
- en: Sane weight initialization
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合理的权重初始化
- en: While checking out standard datasets available, I stumbled across Places365
    dataset. The Places365 dataset contains 1.8 million images from 365 scene categories.
    The dataset provided in the challenge was very similar to this dataset, so the
    model trained on this dataset will already have learned features that are relevant
    to our own classification problem. As, the categories in our problem, was a subset
    of Places365 dataset, I used a ResNet50 model initialised with places365 weights.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看可用的标准数据集时，我偶然发现了 Places365 数据集。Places365 数据集包含了来自 365 个场景类别的 180 万张图像。挑战中提供的数据集与这个数据集非常相似，因此在这个数据集上训练的模型已经学到了与我们分类问题相关的特征。由于我们问题中的类别是
    Places365 数据集的一个子集，我使用了一个用 Places365 权重初始化的 ResNet50 模型。
- en: The model weights were available as [pytorch weights](https://github.com/CSAILVision/places365).
    The below utility function helped us load the data properly into *fastai*’s CNN
    Learner.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重可以通过 [pytorch weights](https://github.com/CSAILVision/places365) 获得。下面的实用函数帮助我们将数据正确加载到
    *fastai* 的 CNN Learner 中。
- en: '![](../Images/24f95a46bbd333f8a0d9a7b8f6eff41c.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24f95a46bbd333f8a0d9a7b8f6eff41c.png)'
- en: Mixup Augmentation
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Mixup 数据增强
- en: Mixup augmentation is a type of augmentation where in we form a new image through
    weighted linear interpolation of two existing images. We take two images and do
    a linear combination of them in terms of tensors of those images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup 数据增强是一种数据增强类型，通过对两个现有图像进行加权线性插值来形成新的图像。我们取两个图像并对它们进行张量的线性组合。
- en: '![Figure](../Images/08c07b693e2d0a012d7460bc203bb05d.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/08c07b693e2d0a012d7460bc203bb05d.png)'
- en: Mixup Augmentation
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup 数据增强
- en: λ is randomly sampled from the beta distribution. Even though the authors of
    the [paper](https://arxiv.org/abs/1710.09412) suggest using λ=0.4, the default
    value in the *fastai* library is set to 0.1
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: λ 是从贝塔分布中随机采样的。尽管[论文](https://arxiv.org/abs/1710.09412)的作者建议使用 λ=0.4，但 *fastai*
    库中的默认值设置为 0.1
- en: '![Figure](../Images/eb50ee63484f9ab7b83261bd0a5d3e59.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/eb50ee63484f9ab7b83261bd0a5d3e59.png)'
- en: Mixup Augmentation in fastai
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*fastai*中的 Mixup 数据增强'
- en: '**Learning Rate Tuning**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**学习率调整**'
- en: Learning rate is one of the most important hyper-parameter for training neural
    networks. *fastai* has a method to find out an appropriate initial learning rate.
    This technique is called *cyclical learning rate, *wherein we run a trial with
    a lower learning rate & increase it exponentially, recording the loss along the
    way. We then plot the loss against learning rate & choose the learning rate where
    the loss is the steepest.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是训练神经网络最重要的超参数之一。*fastai* 提供了一种方法来找到适当的初始学习率。这种技术叫做*循环学习率*，我们通过较低的学习率进行试验并以指数方式增加，记录过程中损失值。然后我们将损失值与学习率绘制成图，并选择损失最陡的学习率。
- en: '![Figure](../Images/49637047df7515f8a3b491e70fbd43b0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/49637047df7515f8a3b491e70fbd43b0.png)'
- en: LR finder in fastai![Figure](../Images/e3faf6964d4f97ffc160e6301215c847.png)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率查找器在 *fastai* 中 ![图](../Images/e3faf6964d4f97ffc160e6301215c847.png)
- en: Loss is steepest at 1e-06
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 损失在 1e-06 时最陡
- en: The library also handles Stochastic Gradient Descent with Restart (SGDR) for
    us automatically. In SGDR, the learning rate is reset at the start of each epoch
    to the original chosen value which decreases over the epoch as in *Cosine Annealing*.
    The main benefit of this, is that since the learning rate is reset at start of
    each epoch, the learner is capable of jumping out of a local minima or a saddle
    point it may be stuck in.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 该库还自动处理了带重启的随机梯度下降（SGDR）。在 SGDR 中，学习率在每个纪元开始时被重置为原始选择值，该值会随着纪元的进行而降低，类似于*余弦退火*。这样做的主要好处是，由于学习率在每个纪元开始时都会重置，学习者能够跳出可能卡住的局部最小值或鞍点。
- en: '![Figure](../Images/3f3d1d88bb2c28651cf80d0fc7fe1839.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3f3d1d88bb2c28651cf80d0fc7fe1839.png)'
- en: SGDR in fastai
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*fastai*中的SGDR'
- en: General Adversarial Networks
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: GANs were introduced by Ian Goodfellow in 2014\. GANs are deep neural net architectures
    comprised of two nets, pitting one against the other. GANs can mimic any distribution
    of data. They can learn to generate data similar to the original data in any domain-images,
    speech, text, etc. We used fast.ai’s Wasserstein GAN implementation to generate
    more training images.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 是由 Ian Goodfellow 在 2014 年引入的。GANs 是由两个网络组成的深度神经网络架构，相互对抗。GANs 可以模拟任何数据分布。它们可以学习生成与原始数据相似的数据，适用于任何领域——图像、语音、文本等。我们使用了
    fast.ai 的 Wasserstein GAN 实现来生成更多的训练图像。
- en: GANs involve training two neural networks, one called the *generator*, which
    generates new data instances, while the other, the *discriminator, *evaluates
    them for authenticity, it decides whether each instance of data belongs to the
    actual training dataset or not. You can refer more about it [here](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-wgan.ipynb).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 涉及训练两个神经网络，一个称为*生成器*，生成新的数据实例，而另一个称为*判别器*，评估这些实例的真实性，它决定每个数据实例是否属于实际的训练数据集。你可以在
    [这里](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-wgan.ipynb)
    找到更多信息。
- en: '![Figure](../Images/4149a50f3f19d426f26a768f38ab8fa7.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/4149a50f3f19d426f26a768f38ab8fa7.png)'
- en: GAN generated sample images
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 生成的样本图像
- en: '**Removing Confusing Images**'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**移除混淆图像**'
- en: The first step to training a neural net is to not touch any neural net code
    at all and instead begin by thoroughly inspecting your data. This step is critical.
    I like to spend copious amount of time (measured in units of hours) scanning through
    thousands of examples, understanding their distribution and looking for patterns.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练神经网络的第一步是不接触任何神经网络代码，而是开始彻底检查你的数据。这一步是至关重要的。我喜欢花费大量时间（以小时为单位）浏览成千上万的样本，理解它们的分布并寻找模式。
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Andrej Karpathy'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- Andrej Karpathy'
- en: As Andrej Karpathy states “Data Investigation” is an important step. Upon data
    investigation, I found that there were some images which contained 2 or more classes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Andrej Karpathy 所说，“数据调查”是一个重要的步骤。在数据调查中，我发现有一些图像包含了两个或更多类别。
- en: '**Approach 1**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法 1**'
- en: Using a previously trained model, I ran prediction on the entire training data.
    Then discarded those images whose predictions were incorrect but the probability
    score was more than 0.9\. These were the images, that the model clearly misclassified.
    Going deep into it, I found that those images were mislabelled by the labeller.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前训练的模型，我对整个训练数据进行了预测。然后丢弃了那些预测结果不正确但概率分数大于0.9的图像。这些是模型明显错误分类的图像。深入分析后，我发现这些图像被标注者错误标记了。
- en: '![Figure](../Images/9f4977002bd240cdc9069f98b8b09605.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/9f4977002bd240cdc9069f98b8b09605.png)'
- en: Confusing Images
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 令人困惑的图像
- en: I also removed those images from the training set, for whom the prediction probability
    was in the range 0.5 to 0.6, the theory being that there might be more than 1
    class present in the image, so the model assigned somewhat equal probabilities
    to each one of them. Upon viewing those images, the theory turned out to be true
    in the end
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我还从训练集中删除了那些预测概率在0.5到0.6范围内的图像，理论是图像中可能存在多个类别，因此模型对每个类别分配了大致相等的概率。查看这些图像后，理论最终被证明是正确的。
- en: '**Approach 2**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法 2**'
- en: fast.ai provides a handy widget “Image Cleaner Widget” that allows you to clean
    and prepare your data for your model. ImageCleaner is for cleaning up images that
    don’t belong in your dataset. It renders images in a row and gives you the opportunity
    to delete the file from your file system.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: fast.ai 提供了一个方便的小工具“图像清理小工具”，允许你清理和准备数据以供模型使用。ImageCleaner 用于清理不属于你的数据集的图像。它以一行的形式渲染图像，并给你机会从文件系统中删除文件。
- en: '![](../Images/74e32569d7006623db95e9f15bae92fd.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74e32569d7006623db95e9f15bae92fd.png)'
- en: '**Test Time Augmentation**'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**测试时间增强**'
- en: Test Time Augmentation involves taking a series of different versions of the
    original image and passing them through the model. The average output is then
    calculated from the different versions and given as the final output for the image.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 测试时间增强涉及对原始图像进行一系列不同版本的处理，并将它们通过模型。然后计算这些不同版本的平均输出，并将其作为图像的最终输出。
- en: '![Figure](../Images/09d9ba8806b597b74cc5b530278a16c5.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/09d9ba8806b597b74cc5b530278a16c5.png)'
- en: Test Time Augmentation in fastai
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在fastai中的测试时间增强
- en: A similar technique called 10-crop testing was used previously. I first read
    about 10-crop technique in [ResNet](https://arxiv.org/pdf/1512.03385.pdf) paper.
    The 10-crop technique involves cropping the original image along the four corners
    and once along the centre giving 5 images. Repeating the same for the it’s inverse,
    gives another 5 images, a total of 10 images. Test time augmentation is however
    faster then 10-crop technique
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 之前使用过一种类似的技术叫做10-crop测试。我第一次在[ResNet](https://arxiv.org/pdf/1512.03385.pdf)论文中了解到10-crop技术。10-crop技术涉及将原始图像裁剪到四个角落，并在中心裁剪一次，总共得到5张图像。对其反向操作重复相同的步骤，再得到另外5张图像，总共10张图像。然而，测试时间增强的速度比10-crop技术要快。
- en: Ensembling
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成学习
- en: Ensembling in machine learning is the technique of using multiple learning algorithms
    to obtain better predictive performance then that could be achieved by a single
    algorithm. Ensembling works best
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，集成学习是一种使用多种学习算法来获得比单一算法更好的预测性能的技术。集成学习效果最佳
- en: Constituent models are of different natures. Eg, ensembling a ResNet50 and InceptionNet
    would be much more useful then combining a ResNet50 and ResNet34 net as they are
    different in nature
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 组成模型具有不同的性质。例如，将 ResNet50 和 InceptionNet 进行集成比将 ResNet50 和 ResNet34 进行组合要有用得多，因为它们的性质不同。
- en: Constituent models have lower correlation
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 组成模型之间的相关性较低
- en: Changing training set for each of the models; so that there is more variation
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个模型更改训练集，以增加变化性。
- en: In this case, I ensembled the prediction from all the models by picking the
    maximum occuring class. In case there’s more than one class having maximum occurence,
    I randomly pick one of the classes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我通过选择出现次数最多的类别来集成所有模型的预测。如果有多个类别出现次数相同，我会随机选择其中一个类别。
- en: '**Results**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结果**'
- en: Public Leaderboard — Rank 29 (0.962)
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 公共排行榜 — 第29名 (0.962)
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Private Leaderboard — Rank 22 (0.9499)
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 私有排行榜 — 第22名 (0.9499)
- en: '**Conclusion**'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Progressive resizing is a great idea to get started.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渐进式调整大小是一个很好的入门主意。
- en: Spending time understanding your data & visualising it is must.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 花时间理解和可视化你的数据是必要的。
- en: A great deep learning library like fastai with sensibly initialised parameters
    definitely helps.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像fastai这样的优秀深度学习库，具有合理初始化的参数，绝对是有帮助的。
- en: Use transfer learning wherever & whenever possible, as it usually gives good
    results. Recently, deep learning & transfer learning has even been applied to
    structured data, so transfer learning should definitely be the first thing to
    try out.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任何可能的地方和情况下使用迁移学习，因为它通常会给出良好的结果。最近，深度学习和迁移学习甚至已应用于结构化数据，因此迁移学习绝对应该是首选尝试的方案。
- en: State of the art techniques like Mixup Augmentation, TTA, Cyclic LR would definitely
    help you push your accuracy score by those extra 1 or 2%.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 先进的技术如Mixup数据增强、TTA、循环学习率一定能帮助你将准确率提高额外的1%或2%。
- en: Always search for datasets that are relevant to your problem & use include them
    in your training data if possible. If there exists, deep learning models trained
    on these datasets, use their weights as initial weights for your model.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 始终寻找与你的问题相关的数据集，并尽可能将其包含在训练数据中。如果存在针对这些数据集训练的深度学习模型，使用它们的权重作为你的模型的初始权重。
- en: '**Bio: [Aditya Mishra](https://www.linkedin.com/in/aditya-mishra-b50623138/)**
    is an ML Engineer at difference-engine.ai.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Aditya Mishra](https://www.linkedin.com/in/aditya-mishra-b50623138/)**
    是difference-engine.ai的机器学习工程师。'
- en: '[Original](https://towardsdatascience.com/boost-your-image-classifier-e1cc7a56b59c).
    Reposted with permission.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/boost-your-image-classifier-e1cc7a56b59c)。经许可转载。'
- en: '**Related:**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Large-Scale Evolution of Image Classifiers](/2019/05/large-scale-evolution-image-classifiers.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大规模图像分类器演变](/2019/05/large-scale-evolution-image-classifiers.html)'
- en: '[Building NLP Classifiers Cheaply With Transfer Learning and Weak Supervision](/2019/03/building-nlp-classifiers-cheaply-transfer-learning-weak-supervision.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过迁移学习和弱监督廉价构建NLP分类器](/2019/03/building-nlp-classifiers-cheaply-transfer-learning-weak-supervision.html)'
- en: '[How to do Everything in Computer Vision](/2019/02/everything-computer-vision.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在计算机视觉中做一切](/2019/02/everything-computer-vision.html)'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Tensorflow训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解分类指标：评估模型准确性的指南](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[Segment Anything Model: Foundation Model for Image Segmentation](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Segment Anything模型：图像分割的基础模型](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
- en: '[Best Architecture for Your Text Classification Task: Benchmarking…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适合您的文本分类任务的最佳架构：基准测试…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
- en: '[Boost your machine learning model performance!](https://www.kdnuggets.com/2023/04/manning-boost-machine-learning-model-performance.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升你的机器学习模型表现！](https://www.kdnuggets.com/2023/04/manning-boost-machine-learning-model-performance.html)'
