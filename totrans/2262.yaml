- en: Calculate Computational Efficiency of Deep Learning Models with FLOPs and MACs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/06/calculate-computational-efficiency-deep-learning-models-flops-macs.html](https://www.kdnuggets.com/2023/06/calculate-computational-efficiency-deep-learning-models-flops-macs.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What are FLOPs and MACs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: FLOPs (Floating Point Operations) and MACs (Multiply-Accumulate Operations)
    are metrics that are commonly used to calculate the computational complexity of
    deep learning models. They are a fast and easy way to understand the number of
    arithmetic operations required to perform a given computation. For example, when
    working with different model architectures such as [MobileNet](https://arxiv.org/pdf/1704.04861.pdf)
    or [DenseNet](https://arxiv.org/abs/1608.06993) for edge devices, people use MACs
    or FLOPs to estimate the model performance. Also, the reason we use the word “estimate”
    is that both metrics are approximations instead of the actual capture of the runtime
    performance model. However, they still can provide very useful insights on energy
    consumption or computational requirements, which is quite useful in edge computing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Calculate Computational Efficiency of Deep Learning Models with FLOPs and
    MACs](../Images/4a5ccca9751b620ab4feb4936c0f27c0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Comparison of different neural nets using FLOPs from “Densely Connected
    Convolutional Networks”'
  prefs: []
  type: TYPE_NORMAL
- en: FLOPs specifically refer to the number of floating-point operations, which include
    addition, subtraction, multiplication, and division operations on floating-point
    numbers. These operations are prevalent in many mathematical computations involved
    in machine learning, such as matrix multiplications, activations, and gradient
    calculations. FLOPs are often used to measure the computational cost or complexity
    of a model or a specific operation within a model. This is helpful when we need
    to provide an estimation of the total arithmetic operations required, which is
    generally used in the context of measuring computation efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: MACs, on the other hand, only count the number of multiply-accumulate operations,
    which involve multiplying two numbers and adding the result. This operation is
    fundamental to many linear algebra operations, such as matrix multiplications,
    convolutions, and dot products. MACs are often used as a more specific measure
    of computational complexity in models that heavily rely on linear algebra operations,
    such as convolutional neural networks (CNNs).
  prefs: []
  type: TYPE_NORMAL
- en: One thing worth mentioning here is that FLOPs cannot be the single factor that
    people calculate to get a sense of computation efficiency. Many other factors
    are considered necessary when estimating the model efficiency. For example, how
    parallel the system setup is; what architecture model has(e.g. group convolution
    costs in MACs); what computing platform the model uses(e.g. Cudnn has GPU acceleration
    for deep neural networks and standard operations such as forward or normalization
    are highly tuned).
  prefs: []
  type: TYPE_NORMAL
- en: Are FLOPS and FLOPs the Same?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FLOPS with all uppercase is the abbreviation of “floating point operations per
    second”, which refers to the computation speed and is generally used as a measurement
    of hardware performance. The "S" in the "FLOPS" stands for "second" and together
    with "P" (as "per"), it is generally used to represent a rate.
  prefs: []
  type: TYPE_NORMAL
- en: FLOPs(lowercase “s” stands for plural) on the other hand, refers to the floating-point
    operations. It is commonly used to calculate the computation complexity of an
    algorithm or model. However, in the discussion of AI, sometimes FLOPs can have
    both of the above meanings and it will leave it to the reader to identify the
    exact one it stands for. There have also been some [discussions](https://www.lesswrong.com/posts/XiKidK9kNvJHX9Yte/avoid-the-abbreviation-flops-use-flop-or-flop-s-instead)
    calling for people to abandon the usage of “FLOPs” completely and use “FLOP” instead
    so it’s easier to tell each one apart. In this article, we will continue to use
    FLOPs.
  prefs: []
  type: TYPE_NORMAL
- en: Relationship between FLOPs and MACs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Relationship between FLOPs and MACs](../Images/8e823f1de50f773fbacece305385bc29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Relationship between GMACs and GLOPs([source](https://github.com/sovrasov/flops-counter.pytorch/issues/16#issuecomment-518585837))'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the previous section, the major difference between FLOPs and
    MACs include what types of arithmetic operations they count and the context in
    which they are used. The general AI community consensus, like the GitHub comment
    in Figure 2, is one MACs equals roughly two FLOPs. For deep neural networks, multiply-accumulate
    operations are heavy in calculations therefore MACs is considered more significant.
  prefs: []
  type: TYPE_NORMAL
- en: How to Calculate FLOPs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The good thing is there are multiple open-source packages available already
    for calculating FLOPs specifically so you don’t have to implement it from scratch.
    Some of the most popular ones include [flops-counter.pytorch](https://github.com/sovrasov/flops-counter.pytorch)
    and [pytorch-OpCounter](https://github.com/Lyken17/pytorch-OpCounter). There are
    also packages such as [torchstat](https://github.com/Swall0w/torchstat) that gives
    users a general network analyzer based on PyTorch. It is also worth noting that
    for these packages the supported layers and models are limited. So if you are
    running a model that consists of customized network layers you might have to calculate
    FLOPs yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we show a code example to calculate FLOPs using pytorch-OpCounter and
    a pre-trained alexnet from torchvision:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this article, we introduced the definition of FLOPs and MACs, when they are
    usually used and the difference between the two attributes.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://github.com/sovrasov/flops-counter.pytorch](https://github.com/sovrasov/flops-counter.pytorch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/Lyken17/pytorch-OpCounter](https://github.com/Lyken17/pytorch-OpCounter)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/Swall0w/torchstat](https://github.com/Swall0w/torchstat)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://arxiv.org/pdf/1704.04861.pdf](https://arxiv.org/pdf/1704.04861.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Danni Li](https://www.linkedin.com/in/danni-li-cs/)** is the current AI
    Resident at Meta. She''s interested in building efficient AI systems and her current
    research focus is on-device ML models. She is also a strong believer of open source
    collaboration and utilizing community support to maximize our potential for innovation.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How To Calculate Algorithm Efficiency](https://www.kdnuggets.com/2022/09/calculate-algorithm-efficiency.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Efficiency Spells the Difference Between Biological Neurons and…](https://www.kdnuggets.com/2022/11/efficiency-spells-difference-biological-neurons-artificial-counterparts.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Research-Driven Advanced Prompting Techniques for LLM Efficiency…](https://www.kdnuggets.com/3-research-driven-advanced-prompting-techniques-for-llm-efficiency-and-speed-optimization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Python Tips for Data Efficiency and Speed](https://www.kdnuggets.com/5-python-tips-for-data-efficiency-and-speed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Elevate Math Efficiency: Navigating Numpy Array Operations](https://www.kdnuggets.com/elevate-math-efficiency-navigating-numpy-array-operations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Maximizing Efficiency in Data Analysis with ChatGPT](https://www.kdnuggets.com/maximizing-efficiency-in-data-analysis-with-chatgpt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
