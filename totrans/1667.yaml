- en: Data Science Interview Guide
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2](https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/04/data-science-interview-guide.html?page=2#comments)'
  prefs: []
  type: TYPE_IMG
- en: Machine Learning Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have our optimal features, it is now time to train our actual model!
    Machine Learning models fall into one of two camps: Supervised and Unsupervised.
    Supervised Learning is when the tags are available. Unsupervised Learning is when
    the tags are unavailable. Get it? SUPERVISE the tags! Pun intended. That being
    said, **DO NOT MIX UP THE DIFFERENCE BETWEEN SUPERVISED AND UNSUPERVISED LEARNING**!!!
    This mistake is enough for the interviewer to cancel the interview. Also, another
    noob mistake people make is not normalizing the features before running the model.
    While some models are resistant to this issue, a lot of models (like linear regression)
    is very sensitive to scaling. Hence. Rule of Thumb. **ALWAYS NORMALIZE THE FEATURES
    BEFORE USE!!!**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear and Logistic Regression**'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e232e92acc891efedd7468d7fff58b80.png)'
  prefs: []
  type: TYPE_IMG
- en: Linear and Logistic Regression are the most basic and commonly used Machine
    Learning algorithms out there. Before doing any analysis **MAKE SURE YOU DO LINEAR/LOGISTIC
    REGRESSION FIRST AS BENCHMARK!**One common interview blooper people make is starting
    their analysis with a more complex model like Neural Network. No doubt, Neural
    Network is highly accurate. However, benchmarks are important. If your simple
    regression model already has a 98% accuracy and really close to over-fitting,
    getting a more complex model is not a smart move. That being said, linear regression
    is used for continuous targets while logistic regression is used for binary targets
    (mainly because the sigmoid curve forces the feature inputs towards either 0 or
    1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/20939a45745017b32c886765e55b6ea6.png)'
  prefs: []
  type: TYPE_IMG
- en: I would recommend the derivation of both logistic and linear regression (both
    single variate and multivariate). On top of preparing for the interview, the linear
    regression model is used as the base of a whole range of other machine learning
    models out there. Hence, it is long term investment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision Trees and Random Forests**'
  prefs: []
  type: TYPE_NORMAL
- en: A slightly more complex model than a linear regression model is the decision
    tree. The decision tree algorithm splits at different feature based on information
    gain, until it hits a pure leaf (i.e. a set of records with only 1 label). A decision
    tree can be made to stop after a certain number of splits to stop it from getting
    pure leafs (common tactic to fix over-fitting problems).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e20328e65d199c954dfda16cf777e68.png)'
  prefs: []
  type: TYPE_IMG
- en: The Information Gain calculated to split the tree is important. **COMMON INTERVIEW
    PROBLEM! ENSURE YOU KNOW HOW INFORMATION GAIN IS CALCULATED!!!** The common Information
    Gain calculation functions are Gini and Entropy.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db440662e7b54fac21f40e19acec35f0.png)'
  prefs: []
  type: TYPE_IMG
- en: What is important in the above curve is that Entropy gives a higher value for
    Information Gain and hence cause more splitting compared to Gini.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/838a4d5884bb85b250b84510beca2142.png)'
  prefs: []
  type: TYPE_IMG
- en: When a Decision Tree isn’t complex enough, a Random Forest is generally used
    (which is nothing more than multiple Decision Trees being grown on a subset of
    the data and a final majority voting is done). Random Forest algorithms can over-fit
    if the number of trees are not determined properly. For more information on decision
    trees, random forest and tree based ensemble models, check out my other blog: [Study
    of Decision Trees and Ensembles on Scikit-Learn](https://medium.com/@sadatnazrul/study-of-decision-trees-and-ensembles-on-scikit-learn-e713a8e532b8)
  prefs: []
  type: TYPE_NORMAL
- en: '**K-Means**'
  prefs: []
  type: TYPE_NORMAL
- en: K-Means is an unsupervised learning model that classifies data points into clusters.
    The number of clusters is provided, causing the model to shift the centroid until
    it iteratively finds the optimal cluster centers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a152b3d8648eb5af546fdd1ffe5902b.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of clusters are determined using an elbow curve.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c2f2cd6d62a61cb2864eec5857b052d.png)'
  prefs: []
  type: TYPE_IMG
- en: The number of clusters may or may not be easy to find (especially if there isn’t
    a clear kink on the curve). Also, realize that the K-Means algorithm optimizes
    locally and not globally. This means that your clusters will depend on your initialization
    value. The most common initialization value is calculated in K-Means++, where
    the initial values are are far from eachother as possible. For more details on
    K-Means and other forms of unsupervised learning algorithms, check out my other
    blog: [Clustering Based Unsupervised Learning](http://clustering%20based%20unsupervised%20learning/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Neural Network**'
  prefs: []
  type: TYPE_NORMAL
- en: Neural Network is one of those buzz word algorithms that everyone is looking
    towards these days.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38e71abec65408d4423face2f02a98e1.png)'
  prefs: []
  type: TYPE_IMG
- en: While it is not possible for me to cover the intricate details on this blog,
    it is important to know the basic mechanisms as well as the concept of back propagation
    and vanishing gradient. It is also important to realize that a Neural Network
    is essentially a black box. If the case study require you to build an interpretive
    model, either pick a different model or be prepared to explain how you will find
    how the weights are contributing to the final result (e.g. the visualization of
    hidden layers during image recognition).
  prefs: []
  type: TYPE_NORMAL
- en: '**Ensemble Models**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a single model may not accurately determine the target. Certain features
    will need special models. For such circumstances, an ensemble of multiple models
    are used. An example is given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/402119ccba64fd8ed9cd92cc0ec9f642.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the models are in layers or stacks. The output of each layer is the input
    for the next layer.
  prefs: []
  type: TYPE_NORMAL
- en: Model Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Classification Score**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/99f4745433a13371f770bfbc82d1d8fc.png)'
  prefs: []
  type: TYPE_IMG
- en: One of the most common way of evaluating model performance is by calculating
    the percentage of records whose records were predicted accurately.
  prefs: []
  type: TYPE_NORMAL
- en: '**Learning Curve**'
  prefs: []
  type: TYPE_NORMAL
- en: Learning Curve is also a common method for evaluating models. Here, we are looking
    to see if our model is too complex or not complex enough.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f8ba954b1859f0c36fcd968320ab3998.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the model is not complex enough (e.g. we decided to use a linear regression
    when the pattern is not linear), we end up with high bias and low variance. When
    our model is too complex (e.g. we decided to use a deep neural network for a simple
    problem), we end up with low bias and high variance. High variance because the
    result will VARY as we randomize the training data (i.e. the model is now very
    stable). **DO NOT MIX UP THE DIFFERENCE BETWEEN BIAS AND VARIANCE DURING THE INTERVIEW!!! **Now,
    in order to determine the model’s complexity, we use a learning curve as shown
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/13df40a8eb07e8506f2ab0e849d29caf.png)'
  prefs: []
  type: TYPE_IMG
- en: On the learning curve, we vary the train-test split on the x-axis and calculate
    the accuracy of the model on the training and validation datasets. If the gap
    between them is too wide, it’s too complex (i.e. over-fitting). If neither one
    of the curves is hitting the desired accuracy and the gap between the curves is
    too small, the dataset is highly biased.
  prefs: []
  type: TYPE_NORMAL
- en: '**ROC**'
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with fraud datasets with heavy class imbalance, a classification
    score does not make much sense. Instead, Receiver Operating Characteristic or
    ROC curves offer a better alternative.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4252f6f09c29106d262ec793d8fb60d5.png)'
  prefs: []
  type: TYPE_IMG
- en: The 45 degree line is the random line, where the Area Under the Curve or AUC
    is 0.5 . The further the curve from this line, the higher the AUC and better the
    model. The highest a model can get is an AUC of 1, where the curve forms a right
    angled triangle. The ROC curve can also help debug a model. For example, if the
    bottom left corner of the curve is closer to the random line, it implies that
    the model is misclassifying at Y=0\. Whereas, if it is random on the top right,
    it implies the errors are occurring at Y=1\. Also, if there are spikes on the
    curve (as opposed to being smooth), it implies the model is not stable. When dealing
    with fraud models, ROC is your best friend.
  prefs: []
  type: TYPE_NORMAL
- en: Additional Materials
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[**Stanford Machine Learning | Coursera**'
  prefs: []
  type: TYPE_NORMAL
- en: '*About this course: Machine learning is the science of getting computers to
    act without being explicitly programmed. In…*www.coursera.org](https://www.coursera.org/learn/machine-learning)'
  prefs: []
  type: TYPE_NORMAL
- en: '[**University of Washington Machine Learning Specialization | Coursera**'
  prefs: []
  type: TYPE_NORMAL
- en: '*This Specialization from leading researchers at the University of Washington
    introduces you to the exciting…*www.coursera.org](https://www.coursera.org/specializations/machine-learning)'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Deep Learning Specialization | Coursera**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep Learning from deeplearning.ai. If you want to break into AI, this Specialization
    will help you do so. Deep…*www.coursera.org](https://www.coursera.org/specializations/deep-learning)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/)** is using
    Machine Learning to catch cyber and financial criminals by day... and writing
    cool blogs by night.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/data-science-interview-guide-4ee9f5dc778).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[The Two Sides of Getting a Job as a Data Scientist](/2018/03/two-sides-getting-job-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Survive Your Data Science Interview](/2018/03/survive-data-science-interview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Hiring Data Scientists](/2018/02/guide-hiring-data-scientists.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interview Kickstart Data Science Interview Course — What Makes It…](https://www.kdnuggets.com/2022/10/interview-kickstart-data-science-interview-course-makes-different.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 1: The Structure](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, May 4: 9 Free Harvard Courses to Learn Data…](https://www.kdnuggets.com/2022/n18.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Answer Data Science Coding Interview Questions](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15 Python Coding Interview Questions You Must Know For Data Science](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
