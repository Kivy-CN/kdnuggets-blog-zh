- en: 17 More Must-Know Data Science Interview Questions and Answers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 17 个必须知道的数据科学面试问题及答案
- en: 原文：[https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2)
- en: Q4\. Why might it be preferable to include fewer predictors over many?
  id: totrans-2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q4\. 为什么包含较少的预测变量比包含许多预测变量更可取？
- en: '**[Anmol Rajpurohit](https://twitter.com/hey_anmol) answers:**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Anmol Rajpurohit](https://twitter.com/hey_anmol) 的回答：**'
- en: 'Here are a few reasons why it might be a better idea to have fewer predictor
    variables rather than having many of them:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个理由说明为什么使用较少的预测变量可能比使用许多预测变量更好：
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT。'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Redundancy/Irrelevance:**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**冗余/不相关：**'
- en: If you are dealing with many predictor variables, then the chances are high
    that there are hidden relationships between some of them, leading to redundancy.
    Unless you identify and handle this redundancy (by selecting only the non-redundant
    predictor variables) in the early phase of data analysis, it can be a huge drag
    on your succeeding steps.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你处理了许多预测变量，那么很可能其中一些变量之间存在隐藏的关系，导致冗余。除非在数据分析的早期阶段识别并处理这些冗余（通过仅选择非冗余的预测变量），否则它可能对后续步骤造成巨大阻碍。
- en: It is also likely that not all predictor variables are having a considerable
    impact on the dependent variable(s). You should make sure that the set of predictor
    variables you select to work on does not have any irrelevant ones – even if you
    know that data model will take care of them by giving them lower significance.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也有可能并非所有预测变量对因变量都有显著影响。你应该确保你选择的预测变量集合中没有任何不相关的变量——即使你知道数据模型会通过赋予这些变量较低的重要性来处理它们。
- en: '*Note: Redundancy and Irrelevance are two different notions –a relevant feature
    can be redundant due to the presence of other relevant feature(s).*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：冗余和不相关是两个不同的概念——一个相关的特征由于存在其他相关特征而可能变得冗余。*'
- en: '**Overfitting**:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合**：'
- en: Even when you have a large number of predictor variables with no relationships
    between any of them, it would still be preferred to work with fewer predictors.
    The data models with large number of predictors (also referred to as complex models)
    often suffer from the problem of overfitting, in which case the data model performs
    great on training data, but performs poorly on test data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你有大量的预测变量，并且它们之间没有任何关系，仍然建议使用较少的预测变量。具有大量预测变量的数据模型（也称为复杂模型）通常会出现过拟合的问题，这种情况下，数据模型在训练数据上表现很好，但在测试数据上表现不佳。
- en: '**Productivity**:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**生产力**：'
- en: Let’s say you have a project where there are a large number of predictors and
    all of them are relevant (i.e. have measurable impact on the dependent variable).
    So, you would obviously want to work with all of them in order to have a data
    model with very high success rate. While this approach may sound very enticing,
    practical considerations (such of amount of data available, storage and compute
    resources, time taken for completion, etc.) make it nearly impossible.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个项目，其中包含大量的预测变量，并且所有这些变量都是相关的（即对因变量有可测量的影响）。显然，你会希望使用所有这些变量，以便构建一个成功率非常高的数据模型。尽管这种方法听起来非常诱人，但实际考虑（如可用数据量、存储和计算资源、完成所需时间等）使得这种做法几乎不可能实现。
- en: Thus, even when you have a large number of relevant predictor variables, it
    is a good idea to work with fewer predictors (shortlisted through feature selection
    or developed through feature extraction). This is essentially similar to the Pareto
    principle, which states that for many events, roughly 80% of the effects come
    from 20% of the causes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使你有大量相关的预测变量，使用较少的预测变量（通过特征选择筛选或通过特征提取开发）也是一个好主意。这本质上类似于帕累托原则，该原则指出，对于许多事件，约80%的效果来自20%的原因。
- en: Focusing on those 20% most significant predictor variables will be of great
    help in building data models with considerable success rate in a reasonable time,
    without needing non-practical amount of data or other resources.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 关注那20%最重要的预测变量，将对在合理时间内构建成功率较高的数据模型非常有帮助，而不需要大量数据或其他资源。
- en: '![](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
- en: '*Training error & test error vs model complexity (Source: Posted on [Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)
    by [Sergul Aydore](https://www.quora.com/profile/Sergül-Aydöre))*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练误差与测试误差 vs 模型复杂性（来源：[Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)
    发布者：[Sergul Aydore](https://www.quora.com/profile/Sergül-Aydöre)）*'
- en: '**Understandability**:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**可理解性**：'
- en: Models with fewer predictors are way easier to understand and explain. As the
    data science steps will be performed by humans and the results will be presented
    (and hopefully, used) by humans, it is important to consider the comprehensive
    ability of human brain. This is basically a trade-off – you are letting go of
    some potential benefits to your data model’s success rate, while simultaneously
    making your data model easier to understand and optimize.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用较少预测变量的模型更易于理解和解释。由于数据科学步骤将由人类执行，结果将由人类呈现（并且希望被使用），因此考虑到人脑的综合能力非常重要。这基本上是一个权衡——你放弃了一些潜在的好处，以提高数据模型的成功率，同时使数据模型更易于理解和优化。
- en: This factor is particularly important if at the end of your project you need
    to present your results to someone, who is interested in not just high success
    rate, but also in understanding what is happening “under the hood”.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在项目结束时你需要向他人展示你的结果，而这些人不仅对高成功率感兴趣，还对“幕后”发生的情况感兴趣，这一点特别重要。
- en: '* * *'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Q5\. What error metric would you use to evaluate how good a binary classifier
    is? What if the classes are imbalanced? What if there are more than 2 groups?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q5. 你会使用什么误差指标来评估一个二分类器的好坏？如果类别不平衡呢？如果有多于2个组呢？
- en: '[**Prasad Pore**](/author/prasad-pore) **answers:**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Prasad Pore**](/author/prasad-pore) **回答：**'
- en: Binary classification involves classifying the data into two groups, e.g. whether
    or not a customer buys a particular product or not (Yes/No), based on independent
    variables such as gender, age, location etc.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类涉及将数据分类为两个组，例如，客户是否购买某一特定产品（是/否），基于性别、年龄、位置等独立变量。
- en: 'As the target variable is not continuous, binary classification model predicts
    the probability of a target variable to be Yes/No. To evaluate such a model, a
    metric called the confusion matrix is used, also called the classification or
    co-incidence matrix. With the help of a confusion matrix, we can calculate important
    performance measures:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 由于目标变量不是连续的，二分类模型预测目标变量为“是/否”的概率。为了评估这样的模型，使用了一种称为混淆矩阵的指标，也叫分类矩阵或一致性矩阵。借助混淆矩阵，我们可以计算出重要的性能指标：
- en: True Positive Rate (TPR) or Hit Rate or Recall or Sensitivity = TP / (TP + FN)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 真阳性率（TPR）或命中率或召回率或敏感性 = TP / (TP + FN)
- en: False Positive Rate(FPR) or False Alarm Rate = 1 - Specificity = 1 - (TN / (TN
    + FP))
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假阳性率（FPR）或假警报率 = 1 - 特异性 = 1 - (TN / (TN + FP))
- en: Accuracy = (TP + TN) / (TP + TN + FP + FN)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确率 = (TP + TN) / (TP + TN + FP + FN)
- en: Error Rate = 1 – accuracy or (FP + FN) / (TP + TN + FP + FN)
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误率 = 1 – 准确率 或 (FP + FN) / (TP + TN + FP + FN)
- en: Precision = TP / (TP + FP)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精确度 = TP / (TP + FP)
- en: 'F-measure: 2 / ( (1 / Precision) + (1 / Recall) )'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'F-measure: 2 / ( (1 / 精确度) + (1 / 召回率) )'
- en: ROC (Receiver Operating Characteristics) = plot of FPR vs TPR
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ROC（接收操作特征曲线）= FPR vs TPR的图示
- en: AUC (Area Under the Curve)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AUC（曲线下面积）
- en: Kappa statistics
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kappa统计量
- en: 'You can find more details about these measures here: [The Best Metric to Measure
    Accuracy of Classification Models](/2016/12/best-metric-measure-accuracy-classification-models.html).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到更多关于这些指标的详细信息：[测量分类模型准确性的最佳指标](/2016/12/best-metric-measure-accuracy-classification-models.html)。
- en: All of these measures should be used with domain skills and balanced, as, for
    example, if you only get a higher TPR in predicting patients who don’t have cancer,
    it will not help at all in diagnosing cancer.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些措施都应结合领域技能并加以平衡，例如，如果你仅在预测无癌症患者时获得更高的TPR，那么在诊断癌症时将没有帮助。
- en: 'In the same example of cancer diagnosis data, if only 2% or less of the patients
    have cancer, then this would be a case of class imbalance, as the percentage of
    cancer patients is very small compared to rest of the population. There are main
    2 approaches to handle this issue:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在癌症诊断数据的相同示例中，如果只有2%或更少的患者有癌症，则这是一个类别不平衡的情况，因为癌症患者的比例相对于其他人群非常小。处理此问题的主要有2种方法：
- en: '**Use of a cost function**: In this approach, a cost associated with misclassifying
    data is evaluated with the help of a cost matrix (similar to the confusion matrix,
    but more concerned with False Positives and False Negatives). The main aim is
    to reduce the cost of misclassifying. The cost of a False Negative is always more
    than the cost of a False Positive. e.g. wrongly predicting a cancer patient to
    be cancer-free is more dangerous than wrongly predicting a cancer-free patient
    to have cancer.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用成本函数**：在这种方法中，借助成本矩阵（类似于混淆矩阵，但更关注假阳性和假阴性）来评估与数据误分类相关的成本。主要目的是减少误分类的成本。假阴性的成本总是高于假阳性的成本。例如，错误地预测癌症患者为无癌症比错误地预测无癌症患者为癌症更危险。'
- en: Total Cost = Cost of FN * Count of FN + Cost of FP * Count of FP
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 总成本 = 假阴性的成本 * 假阴性的数量 + 假阳性的成本 * 假阳性的数量
- en: '**Use of different sampling methods**: In this approach, you can use over-sampling,
    under-sampling, or hybrid sampling. In over-sampling, minority class observations
    are replicated to balance the data. Replication of observations leading to overfitting,
    causing good accuracy in training but less accuracy in unseen data. In under-sampling,
    the majority class observations are removed causing loss of information. It is
    helpful in reducing processing time and storage, but only useful if you have a
    large data set.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用不同的采样方法**：在这种方法中，你可以使用过采样、欠采样或混合采样。在过采样中，少数类观察值被复制以平衡数据。观察值的复制会导致过拟合，导致训练中准确度高但在未见数据中准确度低。在欠采样中，去除多数类观察值会导致信息丢失。这有助于减少处理时间和存储，但仅在你有大量数据集时才有用。'
- en: Find more about class imbalance [here](/2016/08/learning-from-imbalanced-classes.html).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[在这里了解更多关于类别不平衡的信息](/2016/08/learning-from-imbalanced-classes.html)。'
- en: 'If there are multiple classes in the target variable, then a confusion matrix
    of dimensions equal to the number of classes is formed, and all performance measures
    can be calculated for each of the classes. This is called a multiclass confusion
    matrix. e.g. there are 3 classes X, Y, Z in the response variable, so recall for
    each class will be calculated as below:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标变量中有多个类别，则会形成一个与类别数量相等的混淆矩阵，并可以计算每个类别的所有性能指标。这称为多类混淆矩阵。例如，如果响应变量中有3个类别X、Y、Z，那么每个类别的召回率计算如下：
- en: Recall_X = TP_X/(TP_X+FN_X)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Recall_X = TP_X/(TP_X+FN_X)
- en: Recall_Y = TP_Y/(TP_Y+FN_Y)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Recall_Y = TP_Y/(TP_Y+FN_Y)
- en: Recall_Z = TP_Z/(TP_Z+FN_Z)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Recall_Z = TP_Z/(TP_Z+FN_Z)
- en: '* * *'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Q6\. What are some ways I can make my model more robust to outliers?
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q6. 我可以通过哪些方法使我的模型对异常值更具鲁棒性？
- en: '[**Thuy Pham**](/author/thuy-pham) **answers:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Thuy Pham**](/author/thuy-pham) **回答：**'
- en: There are several ways to make a model more robust to outliers, from different
    points of view (data preparation or model building). **An outlier** in the question
    and answer is assumed being unwanted, unexpected, or a must-be-wrong value to
    the human’s knowledge so far (e.g. no one is 200 years old) rather than a rare
    event which is possible but rare.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以使模型对异常值更具鲁棒性，从不同的角度（数据准备或模型构建）。**异常值**在问答中被认为是人类知识中不需要的、意外的或必须是错误的值（例如，没有人200岁），而不是可能但稀有的事件。
- en: Outliers are usually defined in relation to the distribution. Thus outliers
    could be removed in the pre-processing step (before any learning step), by using
    standard deviations (for normality) or interquartile ranges (for not normal/unknown)
    as threshold levels.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值通常是相对于分布来定义的。因此，可以在预处理步骤（任何学习步骤之前）中通过使用标准差（对于正态分布）或四分位数范围（对于非正态/未知分布）作为阈值水平来移除异常值。
- en: '![](../Images/d5cb6f2fe1fb2779c49fcc7574c92c98.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5cb6f2fe1fb2779c49fcc7574c92c98.png)'
- en: '**Outliers.** [Image source](https://www.neuraldesigner.com/blog/3_methods_to_deal_with_outliers)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**异常值。** [图片来源](https://www.neuraldesigner.com/blog/3_methods_to_deal_with_outliers)'
- en: Moreover, **data transformation** (e.g. log transformation) may help if data
    have a noticeable tail. When outliers related to the sensitivity of the collecting
    instrument which may not precisely record small values, **Winsorization** may
    be useful. This type of transformation (named after Charles P. Winsor (1895–1951))
    has the same effect as clipping signals (i.e. replaces extreme data values with
    less extreme values).  Another option to reduce the influence of outliers is using
    **mean absolute difference** rather mean squared error.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**数据转换**（例如对数转换）可能有助于当数据存在明显尾部时。当异常值与收集仪器的灵敏度有关，这些仪器可能无法准确记录小值时，**Winsorization**可能会有用。这种类型的转换（以Charles
    P. Winsor (1895–1951)的名字命名）具有与剪切信号相同的效果（即用不那么极端的值替换极端数据值）。 另一种减少异常值影响的选项是使用**平均绝对差**而不是均方误差。
- en: For model building, some models are resistant to outliers (e.g. [tree-based
    approaches](https://www.quora.com/Why-are-tree-based-models-robust-to-outliers))
    or non-parametric tests. Similar to the median effect, tree models divide each
    node into two in each split. Thus, at each split, all data points in a bucket
    could be equally treated regardless of extreme values they may have. The study
    [Pham 2016] proposed a detection model that incorporates interquartile information
    of data to predict outliers of the data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型构建，一些模型对异常值具有抗性（例如，[基于树的方法](https://www.quora.com/Why-are-tree-based-models-robust-to-outliers)）或非参数测试。类似于中位数效应，树模型在每次分裂时将每个节点分成两个。因此，在每次分裂时，所有数据点在一个桶中都可以被平等对待，无论它们可能有多极端。研究[Pham
    2016]提出了一种检测模型，该模型结合了数据的四分位数信息来预测数据的异常值。
- en: '**References:**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: '[Pham 2016] T. T. Pham, C. Thamrin, P. D. Robinson, and P. H. W. Leong. Respiratory
    artefact removal in forced oscillation measurements: A machine learning approach.
    IEEE Transactions on Biomedical Engineering, 2016.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pham 2016] T. T. Pham, C. Thamrin, P. D. Robinson, 和 P. H. W. Leong. 在强迫振荡测量中的呼吸伪影去除：一种机器学习方法。IEEE生物医学工程学报，2016。'
- en: '[This Quora answer](https://www.quora.com/What-are-methods-to-make-a-predictive-model-more-robust-to-outliers)
    contains further information.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[这个Quora回答](https://www.quora.com/What-are-methods-to-make-a-predictive-model-more-robust-to-outliers)包含了更多信息。'
- en: '* * *'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Here is [part 2](/2017/02/17-data-science-interview-questions-answers-part-2.html)
    and [part 3](/2017/03/17-data-science-interview-questions-answers-part-3.html)
    with more answers.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是[第2部分](/2017/02/17-data-science-interview-questions-answers-part-2.html)和[第3部分](/2017/03/17-data-science-interview-questions-answers-part-3.html)的更多答案。
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[7 Data Analytics Interview Questions & Answers](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7个数据分析面试问题与答案](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
- en: '[5 Python Interview Questions & Answers](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个Python面试问题与答案](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测伪数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测伪数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
