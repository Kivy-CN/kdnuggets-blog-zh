- en: PySyft and the Emergence of Private Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/06/pysyft-emergence-deep-learning.html](https://www.kdnuggets.com/2019/06/pysyft-emergence-deep-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![PySyft](../Images/19a013be7146faf28c0fd9eb45ccbf33.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Trust is a key factor in the implementation of deep learning applications. From
    training to optimization, the lifecycle of a deep learning model is tied to trusted
    data exchanges between different parties. That dynamic is certainly effective
    for a lab environment but results are vulnerable to all sorts of security attacks
    that manipulate the trusted relationships among the different participants in
    a model. Let’s take the example of a credit scoring model that uses a financial
    transaction to classify the credit risk of a specific customer.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional mechanisms for training or optimizing a model assume that the
    entities performing those actions will have full access to those financial datasets
    which opens the door to all sorts of privacy risks. As deep learning evolves,
    the need for mechanisms that enforce privacy constraints during the lifecycle
    of the datasets and model is becoming increasingly important. Among the technologies
    trying to address this monumental challenge, PySyft is a recent framework that
    has been steadily gaining traction within the deep learning community.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of privacy in deep learning application is directly tied to the
    emergence of distributed, multi-party models. The traditional approach to deep
    learning solutions relies on centralized parties that control the entire lifecycle
    of a model even if using large distributed computing infrastructure. This is the
    case of an organization that creates a prediction model that manages the preferences
    of customers visiting its website. However, centralized deep learning topologies
    have proven impractical in scenarios such as mobile or internet of things(IOT)
    that rely on a large number of devices producing data and executing models.
  prefs: []
  type: TYPE_NORMAL
- en: In those scenarios, the distributed parties are not only often producing sensitive
    datasets but also executing and evaluating the performance of deep learning models.
    That dynamic requires a bidirectional privacy relationship between different parties
    responsible for creating, training and executing deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: The transition towards more distributed architectures is one of the primary
    forces behind the need for strong privacy mechanisms in deep learning models.
    That’s the challenge that PySyft setup to address but it wouldn’t have been possible
    without the evolution of several areas of research in machine learning and distributed
    programming.
  prefs: []
  type: TYPE_NORMAL
- en: The Enablers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Privacy in deep learning models has been a well-known problem for years but
    the technologies that can provide a solution are just now achieving certain levels
    of viability. In the case of PySyft, the framework leverages three of the most
    fascinating techniques in machine learning and cryptography of the last decade:'
  prefs: []
  type: TYPE_NORMAL
- en: Secured Multi-Party Computations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Federated Learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Differential Privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secured Multi-Party Computations**'
  prefs: []
  type: TYPE_NORMAL
- en: Secured Multi-Party Computations (sMPC) is a cryptographic technique that allows
    different parties to perform computations over inputs while maintaining those
    inputs private. In computer science theory, sMPC is often seen as a solution to
    the famous [Yao’s Millionaires’ Problem](https://en.wikipedia.org/wiki/Yao%27s_Millionaires%27_Problem) introduced
    in the 1980s by the computer scientist [Andrew Yao](https://en.wikipedia.org/wiki/Andrew_Yao).
    The problem describes a setting in which multiple millionaires would like to know
    which of them is richer without disclosing their actual wealth. The millionaire’s
    problem is present in many real world scenarios such as auctions, elections or
    online gaming.
  prefs: []
  type: TYPE_NORMAL
- en: Conceptually, sMPC replaces the need for a trusted intermediary with secured
    computations. In the sMPC model, a set of parties with private inputs compute
    distributed functions such as security properties like fairness, privacy and correctness
    are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4e038cf411cef1c38f033b41b4c6849.png)**Federated Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning is a new learning architecture for AI systems that operate
    in highly distributed topologies such as mobile or internet of things(IOT) systems.
    Initially proposed by Google research labs, federated learning represents an alternative
    to centralized AI training in which a shared global model is trained under the
    coordination of a central server, from a federation of participating devices.
    In that model, the different devices can contribute to the training and knowledge
    of the model while keeping most of the data in the device.
  prefs: []
  type: TYPE_NORMAL
- en: In a federated learning model, a party downloads the a deep learning model,
    improves it by learning from data on a given device, and then summarizes the changes
    as a small focused update. Only this update to the model is sent to the cloud,
    using encrypted communication, where it is immediately averaged with other user
    updates to improve the shared model. All the training data remains on the original
    device, and no individual updates are stored in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d5cc87e9c4c7f85a2d5ce7a2d0b285d.png)**Differential Privacy**'
  prefs: []
  type: TYPE_NORMAL
- en: Differential privacy is a technique used to limit the impact that statistical
    algorithms can have on the privacy of subjects whose information is part of a
    larger dataset. Roughly, an algorithm is differentially private if an observer
    seeing its output cannot tell if a particular individual’s information was used
    in the computation. Differential privacy often discussed in the context of identifying
    individuals whose information may be in a database. Although it does not directly
    refer to identification and re-identification attacks, differentially private
    algorithms provably resist such attacks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/83abfb2e14682928adc6af8750c87806.png)'
  prefs: []
  type: TYPE_IMG
- en: PySyft
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PySyft is a framework that enables secured, private computations in deep learning
    models. PySyft combines federated learning, secured multiple-party computations
    and differential privacy in a single programming model integrated into different
    deep learning frameworks such as PyTorch, Keras or TensorFlow. The principles
    of PySyft [were originally outlined in a research paper](https://arxiv.org/abs/1811.04017) and
    its [first implementation was lead by OpenMind](https://github.com/OpenMined/PySyft),
    one of the leading decentralized AI platforms.
  prefs: []
  type: TYPE_NORMAL
- en: The core component of PySyft is an abstraction called the SyftTensor. SyftTensors
    are meant to represent a state or transformation of the data and can be chained
    together. The chain structure always has at its head the PyTorch tensor, and the
    transformations or states embodied by the SyftTensors are accessed downward using
    the child attribute and upward using the parent attribute.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b700fddfc2eeb5a0996c1432beedf52.png)'
  prefs: []
  type: TYPE_IMG
- en: Using PySyft is relatively simple and not very different than your standard
    PyTorch or Keras program. The animation below illustrates a simple classification
    model developed using PySyft.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fab6753f72210ae5283f6886f15a4229.png)'
  prefs: []
  type: TYPE_IMG
- en: PySyft represents one of the first attempts to enable robust privacy models
    in deep learning programs. As the space evolves, privacy is likely to become one
    of the foundational building blocks of the next generation of deep learning frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/pysyft-and-the-emergence-of-private-deep-learning-a2d169bb1d0b).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio:** [Jesus Rodriguez](https://www.linkedin.com/in/jesusmrv/) is a technology
    expert, executive investor, and startup advisor. A software scientist by background,
    Jesus is an internationally recognized speaker and author with contributions that
    include hundreds of articles and presentations at industry conferences.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[A Simpler Explanation of Differential Privacy](https://www.kdnuggets.com/2015/11/simpler-explanation-differential-privacy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to build analytic products in an age of data privacy](/2018/05/analytic-products-data-privacy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Autoencoders: Deep Learning with TensorFlow’s Eager Execution](/2019/05/autoencoders-deep-learning-with-tensorflows-eager-execution.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15 Free Machine Learning and Deep Learning Books](https://www.kdnuggets.com/2022/10/15-free-machine-learning-deep-learning-books.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, November 2: The Current State of Data Science…](https://www.kdnuggets.com/2022/n43.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15 More Free Machine Learning and Deep Learning Books](https://www.kdnuggets.com/2022/11/15-free-machine-learning-deep-learning-books.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
