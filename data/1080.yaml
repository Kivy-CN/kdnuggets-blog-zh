- en: 'From Oracle to Databases for AI: The Evolution of Data Storage'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Oracle到AI数据库：数据存储的演变
- en: 原文：[https://www.kdnuggets.com/2022/02/oracle-databases-ai-evolution-data-storage.html](https://www.kdnuggets.com/2022/02/oracle-databases-ai-evolution-data-storage.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/02/oracle-databases-ai-evolution-data-storage.html](https://www.kdnuggets.com/2022/02/oracle-databases-ai-evolution-data-storage.html)
- en: '![From Oracle to Databases for AI: The Evolution of Data Storage](../Images/6c896d3ad813766531a27e53c5468052.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![从Oracle到AI数据库：数据存储的演变](../Images/6c896d3ad813766531a27e53c5468052.png)'
- en: '[Technology vector created by fullvector - www.freepik.com](https://www.freepik.com/vectors/technology)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[技术矢量图由fullvector创作 - www.freepik.com](https://www.freepik.com/vectors/technology)'
- en: Even though machine learning has become commoditized, it’s still the Wild West.
    ML teams across various industries are developing their own techniques for processing
    data, training models, and using them in production. This is clearly not a sustainable
    approach to Machine Learning. Over time, these diverse approaches will become
    standardized. To accelerate that process, the industry needs developer tools designed
    specifically for AI. In this article, you’ll see the difference between traditional
    data storage solutions and databases that are built to address AI use cases.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管机器学习已经变得商品化，但它仍然是西部荒野。各个行业的ML团队正在开发自己的数据处理、模型训练和生产使用的技术。这显然不是一个可持续的机器学习方法。随着时间的推移，这些多样化的方法将会标准化。为了加快这一过程，行业需要专门为AI设计的开发者工具。在本文中，你将看到传统的数据存储解决方案与专为解决AI用例而构建的数据库之间的区别。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Anyone who has worked with an enterprise has seen an interface with rows and
    columns where you diligently add information related to your work.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 任何与企业打过交道的人都见过一个具有行和列的界面，在那里你认真地添加与工作相关的信息。
- en: The Oracle database was introduced more than 40 years ago as a target for this
    kind of data entry. Even though many enterprises were using it as a default database,
    it was a quite complicated product for a regular user. It was also proprietary
    and thus not accessible to developers. Oracle even initiated the DeWitt Clause,
    which prohibits the publication of database benchmarks that haven’t been authorized
    by the creators of the database in question.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle数据库在40多年前作为这种数据输入的目标被引入。尽管许多企业将其作为默认数据库使用，但它对于普通用户来说相当复杂。它也是专有的，因此对开发者不可访问。Oracle甚至启动了DeWitt条款，禁止发布未经数据库创建者授权的数据库基准测试。
- en: Fast forward 15 years, and we saw a new generation of databases like MySQL and
    PostgreSQL. The key differentiator from Oracle's offer was accessibility – the
    new breed of databases were open-source products and could be run on a local machine,
    which made it much easier for developers to set up and use. It’s not that surprising
    that they gained wide adoption during the dot.com boom.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 快进15年，我们见证了像MySQL和PostgreSQL这样的新一代数据库的出现。与Oracle的产品相比，主要的区别在于可访问性——这些新型数据库是开源产品，可以在本地计算机上运行，这使得开发者更容易进行设置和使用。它们在互联网泡沫期间得到了广泛采用也就不足为奇了。
- en: '**Web 2.0 and Open Source Databases Take Off**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Web 2.0和开源数据库的崛起**'
- en: Moving forward in the timeline, we’ve seen the rise of “Web 2.0” in the early
    2000s. Jeff Dean and Sanjay Ghemawat of Google proposed MapReduce, a radically
    new approach to data processing. The logic behind this method was alternatively
    performing mapping and reduction operations on datasets. Mapping operations include
    filtering and sorting of data in rows and columns. Reduction operations involve
    summaries and aggregations of tabular data. The infrastructure was designed to
    run in parallel. This MapReduce approach sits at the core of Hadoop, one of the
    most successful open source projects of the 2000s.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们见证了2000年代初“Web 2.0”的兴起。Google 的 Jeff Dean 和 Sanjay Ghemawat 提出了 MapReduce，一种根本性的新数据处理方法。该方法的逻辑是对数据集执行映射和归约操作。映射操作包括对数据行和列的过滤和排序。归约操作涉及对表格数据的汇总和聚合。该基础设施被设计为并行运行。这种
    MapReduce 方法是 Hadoop 的核心，Hadoop 是2000年代最成功的开源项目之一。
- en: The years of 2007-2012 brought to the world the array of open source NoSQL DBs.
    To name the most popular ones – Apache Cassandra, Google’s BigTable, MongoDB,
    Redis, and Amazon’s DynamoDB.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 2007-2012年间，世界迎来了各种开源 NoSQL 数据库。最受欢迎的有：Apache Cassandra、Google 的 BigTable、MongoDB、Redis
    和 Amazon 的 DynamoDB。
- en: The key differentiator for these databases is that they scale well horizontally.
    Many machines could spin up in parallel and collaboratively serve a database capable
    of housing truly large large datasets. NoSQL databases don’t use a relational
    approach to model their data as rows and columns, and readily accept unstructured
    data without requiring complex data models.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据库的关键区分点在于它们水平扩展良好。许多机器可以并行启动并协作服务一个能够容纳真正大规模数据集的数据库。NoSQL 数据库不使用关系型的方法将数据建模为行和列，且可以轻松接受非结构化数据，而不需要复杂的数据模型。
- en: 'It’s also important to mention that there are two types of databases: transactional
    and analytical. Transactional databases are operational and store critical data,
    like user logs, activity, IP addresses, purchase orders, etc. They are designed
    to be readily available, accept new data quickly, and serve requests for data
    with minimal delay. Analytical databases work much more slowly, can be hosted
    on cheaper storage, and allow for more in-depth analysis of data than would be
    feasible to perform in a transactional database.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要提到的是，有两种类型的数据库：事务型和分析型。事务型数据库是操作性的，存储关键数据，如用户日志、活动、IP 地址、采购订单等。它们被设计为能够快速接受新数据，并以最小的延迟响应数据请求。分析型数据库工作速度较慢，可以托管在更便宜的存储上，并允许对数据进行比在事务型数据库中更深入的分析。
- en: '**Big Data: Analytics and the Beginning of the AI Hype Cycle**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**大数据：分析与人工智能炒作周期的开端**'
- en: The term ‘Big Data’ was initially introduced in 2005, but caught on much later
    as applications became more complex. At that time proper analytics involved pulling
    larger amounts of data from different places. New products entered the market
    to address the rising challenge -- Amazon RedShift, Snowflake, Google BigQuery,
    Clickhouse. These data warehouses have become mainstays for modern enterprises.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “大数据”这一术语最初在2005年引入，但在应用程序变得更加复杂后才被广泛接受。当时，适当的分析涉及从不同地方提取大量数据。为了应对不断上升的挑战，市场上出现了新产品——Amazon
    RedShift、Snowflake、Google BigQuery、Clickhouse。这些数据仓库已经成为现代企业的主流。
- en: The year of 2020 introduced a new solution for data orchestration – the ‘lakehouse’.
    Lakehouses help their users query historical data at a low cost but experience
    little to no degradation in analytical and ML workloads. This turned into something
    of an arms race [between Snowflake and Databricks](https://blocksandfiles.com/2021/11/15/snowflake-rebuts-databricks-snowflake-performance-comparison/).
    While they carry on their battle in the world of tabular data, something big is
    rising from the deep.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年引入了一种新的数据协调解决方案——‘湖屋’。湖屋帮助用户以低成本查询历史数据，但在分析和机器学习工作负载方面几乎没有性能下降。这转变成了[Snowflake和Databricks之间](https://blocksandfiles.com/2021/11/15/snowflake-rebuts-databricks-snowflake-performance-comparison/)的一场军备竞赛。虽然它们在表格数据的世界中继续争斗，但一些重大变化正在深处酝酿。
- en: In 2021, Deep learning (DL) has become mainstream. This is the time of unstructured
    data. Unlike tabular data, which is represented in rows and columns, unstructured
    data consists of images, video-streams, audio, and text. This is data that cannot
    be represented in a spreadsheet.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在2021年，深度学习（DL）已经成为主流。这是非结构化数据的时代。与以行和列表示的表格数据不同，非结构化数据包括图像、视频流、音频和文本。这些数据无法以电子表格形式表示。
- en: Because of last year's lockdowns, the consumption of Netflix, TikTok, and other
    social media has skyrocketed to unprecedented levels. These products all deal
    with and generate large quantities of unstructured data. How should the companies
    manage that data, especially if they want to use it to drive deep insights through
    AI? Can AI teams working with this data use database solutions for their work?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于去年的封锁，Netflix、TikTok以及其他社交媒体的消费量飙升至前所未有的水平。这些产品都处理和生成大量的非结构化数据。公司应该如何管理这些数据，尤其是当他们希望通过AI来挖掘深层次的见解时？AI团队在处理这些数据时是否可以使用数据库解决方案？
- en: You might be surprised, but none of the technologies we’ve discussed fully address
    the needs of deep learning practitioners. Companies like Tesla, which work with
    large amounts of unstructured data, [admit that they had to build their own infrastructure](https://youtu.be/hx7BXih7zx8).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会感到惊讶，但我们讨论的技术没有一个能完全满足深度学习从业者的需求。像特斯拉这样的公司，处理大量非结构化数据，[承认他们不得不构建自己的基础设施](https://youtu.be/hx7BXih7zx8)。
- en: Very few enterprises have enough internal bandwidth to build data infrastructure
    from scratch. The AI industry needs a solid data foundation and a database designed
    specifically for AI.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有企业拥有足够的内部带宽从头开始构建数据基础设施。AI行业需要一个坚实的数据基础和专门为AI设计的数据库。
- en: '**A Database for AI is a Pillar of Deep Learning Innovation**'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**AI数据库是深度学习创新的支柱**'
- en: For a long time now, the industry has been in need of [a simple API for creating](https://github.com/activeloopai/Hub),
    storing and collaborating on AI datasets of any size. More importantly, this tool
    should be created specifically for DL-related tasks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 长期以来，行业一直需要[一个简单的API来创建](https://github.com/activeloopai/Hub)、存储和协作处理任何大小的AI数据集。更重要的是，这个工具应该专门为深度学习相关任务创建。
- en: Traditional DBs store data in-memory to run fast queries, but in-memory storage
    is extremely expensive for ML datasets as they are very big. Even using attached
    disks like AWS EBS is very costly. The most cost-efficient storage layer is object
    storage such as S3, Google Cloud Storage, and MinIO, but these tools are slow
    for rapid querying or computation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 传统数据库将数据存储在内存中以快速执行查询，但内存存储对ML数据集而言极其昂贵，因为它们非常大。即便是使用像AWS EBS这样的附加磁盘也非常昂贵。最具成本效益的存储层是对象存储，例如S3、Google
    Cloud Storage和MinIO，但这些工具在快速查询或计算方面较慢。
- en: A database built specifically for deep learning should support [hosting data
    on those cloud storage systems](/2021/11/design-patterns-machine-learning-pipelines.html)
    and store data in [a format native to deep learning models](/2021/11/after-hdf5-data-storage-format-deep-learning.html).
    This functionality will allow much faster computation and is more cost-effective,
    because accessing data from this type of framework should not incur any additional
    pre-processing costs for ML models. Such a framework would help modern, AI-enabled
    enterprises [save up to 30% on their infrastructure costs.](https://activeloop-forbes.s3.us-west-2.amazonaws.com/forbes_article_-_better_aerial_data_pipelines.pdf)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 专门为深度学习构建的数据库应该支持[在这些云存储系统上托管数据](/2021/11/design-patterns-machine-learning-pipelines.html)并以[深度学习模型原生格式存储数据](/2021/11/after-hdf5-data-storage-format-deep-learning.html)。这种功能将允许更快的计算，并且更具成本效益，因为从这种框架中访问数据不应产生任何额外的预处理成本。这样的框架将帮助现代的AI驱动企业[节省多达30%的基础设施成本。](https://activeloop-forbes.s3.us-west-2.amazonaws.com/forbes_article_-_better_aerial_data_pipelines.pdf)
- en: The framework should be optimized to transfer data from cloud storage to machine
    learning models with minimal latency. This will allow AI to instantly explore
    and visualize massive datasets that could not be housed elsewhere.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架应优化数据从云存储传输到机器学习模型的过程，以尽量减少延迟。这将允许AI即时探索和可视化无法存放在其他地方的大规模数据集。
- en: More importantly, modern databases for AI should be very easy to use with just
    a few lines of code. [According to a recent survey from Kaggle](https://www.kaggle.com/kaggle-survey-2021),
    over 20% of data scientists have less than 3 years of industry experience, and
    another 14% have less than a year. Machine learning is still a young field and
    simplicity is crucial.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，现代AI数据库应该非常易于使用，只需几行代码即可实现。[根据Kaggle最近的调查](https://www.kaggle.com/kaggle-survey-2021)，超过20%的数据科学家在行业经验上少于3年，另有14%的人经验不足一年。机器学习仍然是一个年轻的领域，简单性至关重要。
- en: We have begun to see an emergence of databases built specifically for AI use
    cases. In the next five years, we will witness a [standardization on the ML infrastructure
    stack](https://www.forbes.com/sites/forbestechcouncil/2021/10/08/how-to-enable-data-centric-ai/?sh=5e570ea020f8).
    Organizations that adopt AI databases more quickly will be on the forefront of
    the ML revolution.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经开始看到专门为 AI 使用案例构建的数据库的出现。在未来五年，我们将见证对 [机器学习基础设施堆栈的标准化](https://www.forbes.com/sites/forbestechcouncil/2021/10/08/how-to-enable-data-centric-ai/?sh=5e570ea020f8)。更快采用
    AI 数据库的组织将站在机器学习革命的前沿。
- en: '**[Davit Buniatyan](https://www.linkedin.com/in/davidbuniatyan/)** (**[@DBuniatyan](https://twitter.com/dbuniatyan)**)
    started his Ph.D. at Princeton University at 20\. His research involved reconstructing
    the connectome of the mouse brain under the supervision of Sebastian Seung. Trying
    to solve hurdles he faced analyzing large datasets in the neuroscience lab, David
    became the founding CEO of Activeloop, a Y-Combinator alum startup. He is also
    a recipient of the Gordon Wu Fellowship and AWS Machine Learning Research Award.
    Davit is the creator of [Activeloop](https://www.activeloop.ai/), the Database
    for AI.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Davit Buniatyan](https://www.linkedin.com/in/davidbuniatyan/)** (**[@DBuniatyan](https://twitter.com/dbuniatyan)**)
    在20岁时开始了普林斯顿大学的博士学位。他的研究涉及在Sebastian Seung的指导下重建小鼠大脑的连接组。为了克服在神经科学实验室分析大型数据集时遇到的困难，David
    成为 Activeloop 的创始首席执行官，该公司是 Y-Combinator 的毕业生初创企业。他还是戈登·吴奖学金和 AWS 机器学习研究奖的获得者。Davit
    是 [Activeloop](https://www.activeloop.ai/) 的创始人，这是一个为 AI 设计的数据库。'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[The Evolution From Artificial Intelligence to Machine Learning to…](https://www.kdnuggets.com/2022/08/evolution-artificial-intelligence-machine-learning-data-science.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从人工智能到机器学习的演变](https://www.kdnuggets.com/2022/08/evolution-artificial-intelligence-machine-learning-data-science.html)'
- en: '[Evolution of the Data Landscape](https://www.kdnuggets.com/2023/06/evolution-data-landscape.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据景观的演变](https://www.kdnuggets.com/2023/06/evolution-data-landscape.html)'
- en: '[Evolution in ETL: How Skipping Transformation Enhances Data Management](https://www.kdnuggets.com/evolution-in-etl-how-skipping-transformation-enhances-data-management)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL中的演变：跳过转换如何提升数据管理](https://www.kdnuggets.com/evolution-in-etl-how-skipping-transformation-enhances-data-management)'
- en: '[Analyzing the Probability of Future Success with Intelligence…](https://www.kdnuggets.com/2022/02/analyzing-probability-future-success-intelligence-node-attributes-evolution-model.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析未来成功的概率与智能…](https://www.kdnuggets.com/2022/02/analyzing-probability-future-success-intelligence-node-attributes-evolution-model.html)'
- en: '[The Evolution of Apache Druid](https://www.kdnuggets.com/2022/07/evolution-apache-druid.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Druid 的演变](https://www.kdnuggets.com/2022/07/evolution-apache-druid.html)'
- en: '[The Evolution of Speech Recognition Metrics](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语音识别指标的演变](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
