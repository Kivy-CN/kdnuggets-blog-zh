- en: History and Future of LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的历史与未来
- en: 原文：[https://www.kdnuggets.com/history-and-future-of-llms](https://www.kdnuggets.com/history-and-future-of-llms)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/history-and-future-of-llms](https://www.kdnuggets.com/history-and-future-of-llms)
- en: '![History and Future of LLMs](../Images/6bcb2bd229b7e94e58eaa1678ac68fe3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![LLMs的历史与未来](../Images/6bcb2bd229b7e94e58eaa1678ac68fe3.png)'
- en: Inception of LLMs - NLP and Neural Networks
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs的起源 - NLP与神经网络
- en: 'The creation of Large Language Models didn’t happen overnight. Remarkably,
    the first concept of language models started with rule-based systems dubbed Natural
    Language Processing. These systems follow predefined rules that make decisions
    and infer conclusions based on text input. These systems rely on if-else statements
    processing keyword information and generating predetermined outputs. Think of
    a decision tree where output is a predetermined response if the input contains
    X, Y, Z, or none. For example: If the input includes keywords "mother," output
    "How is your mother?" Else, output, "Can you elaborate on that?"'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的创建并非一蹴而就。值得注意的是，语言模型的第一个概念起源于被称为自然语言处理的规则基础系统。这些系统遵循预定义规则，根据文本输入做出决策和推断结论。这些系统依赖于if-else语句处理关键词信息并生成预定的输出。想象一个决策树，其中输出是如果输入包含X、Y、Z或无，则响应的预定回答。例如：如果输入包括关键词“母亲”，则输出“你的母亲怎么样？”否则，输出“你能详细说明一下吗？”
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![neural networks](../Images/e5dcd3621e34c1e22aa14b2b86224df3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络](../Images/e5dcd3621e34c1e22aa14b2b86224df3.png)'
- en: The biggest early advancement was neural networks, which were considered when
    first introduced in 1943 inspired by neurons in human brain function, by mathematician
    Warren McCulloch. Neural networks even pre-date the term “artificial intelligence”
    by roughly 12 years. The network of neurons in each layer is organized in a specific
    manner, where each node holds a weight that determines its importance in the network.
    Ultimately, neural networks opened closed doors creating the foundation on which
    AI will forever be built.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的重大进展是神经网络，最初由数学家沃伦·麦卡洛赫于1943年提出，受到人脑神经元功能的启发。神经网络甚至在“人工智能”这一术语出现之前大约有12年的历史。每层的神经元网络以特定的方式组织，每个节点都有一个权重，决定了它在网络中的重要性。最终，神经网络打开了封闭的门，创建了人工智能将永远建立的基础。
- en: Evolution of LLMs - Embeddings, LSTM, Attention & Transformers
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs的发展 - 嵌入、LSTM、注意力机制与变换器
- en: Computers can’t comprehend the meanings of words working together in a sentence
    the same way humans can. To improve computer comprehension for semantic analysis,
    a word embedding technique must first be applied which allows models to capture
    the relationships between neighboring words leading to improved performance in
    various NLP tasks. However, there needs to be a method to store word embedding
    in memory.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机无法像人类一样理解句子中单词的意义。为了提高计算机对语义分析的理解，必须首先应用词嵌入技术，这种技术允许模型捕捉相邻单词之间的关系，从而提高各种NLP任务的性能。然而，需要一种方法来将词嵌入存储在内存中。
- en: '![vector databases enable llms to reference data](../Images/0cff9746730357fa0bd4cfbeeae03e1e.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![向量数据库使LLM能够引用数据](../Images/0cff9746730357fa0bd4cfbeeae03e1e.png)'
- en: '[Long Short-Term Memory (LSTM)](https://www.exxactcorp.com/blog/Deep-Learning/5-types-of-lstm-recurrent-neural-networks-and-what-to-do-with-them) and
    Gated Recurrent Units (GRUs) were great leaps within neural networks, with the
    capability of handling sequential data more effectively than traditional neural
    networks. While LSTMs are no longer used, these models paved the way for more
    complex language understanding and generation tasks that eventually led to the
    transformer model.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[长短期记忆网络 (LSTM)](https://www.exxactcorp.com/blog/Deep-Learning/5-types-of-lstm-recurrent-neural-networks-and-what-to-do-with-them)
    和门控循环单元 (GRUs) 是神经网络领域的重要进展，能够比传统神经网络更有效地处理序列数据。虽然LSTM现在已经不再使用，但这些模型为更复杂的语言理解和生成任务铺平了道路，最终催生了Transformer模型。'
- en: The Modern LLM - Attention, Transformers, and LLM Variants
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代LLM - 注意力机制、Transformer及LLM变体
- en: The introduction of the attention mechanism was a game-changer, enabling models
    to focus on different parts of an input sequence when making predictions. Transformer
    models, introduced with the seminal paper "Attention is All You Need" in 2017,
    leveraged the attention mechanism to process entire sequences simultaneously,
    vastly improving both efficiency and performance. The eight Google Scientists
    didn’t realize the ripples their paper would make in creating present-day AI.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制的引入是一次革命性的改变，使得模型在进行预测时能够关注输入序列的不同部分。2017年发表的开创性论文《Attention is All You
    Need》介绍了Transformer模型，这些模型利用注意力机制同时处理整个序列，极大地提高了效率和性能。八位谷歌科学家并未意识到他们的论文会在创建当今AI领域中产生如此深远的影响。
- en: Following the paper, Google’s BERT (2018) was developed and touted as the baseline
    for all NLP tasks, serving as an open-source model used in numerous projects that
    allowed the AI community to build projects and grow. Its knack for contextual
    understanding, pre-trained nature and option for fine-tuning, and demonstration
    of transformer models set the stage for larger models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 紧随其后，谷歌的BERT（2018年）被开发并被誉为所有NLP任务的基准，作为一个开源模型被用于众多项目，使AI社区能够开展项目并成长。其对上下文理解的敏感性、预训练的特性和微调的选项，以及Transformer模型的展示为更大模型的出现奠定了基础。
- en: Alongside BERT, OpenAI released GPT-1 the first iteration of their transformer
    model. GPT-1 (2018), started with 117 million parameters, followed by GPT-2 (2019)
    with a massive leap to 1.5 billion parameters, with progression continuing with
    GPT-3 (2020), boasting 175 billion parameters. OpenAI’s groundbreaking chatbot
    ChatGPT, based on GPT-3, was released two years later on Nov. 30, 2022, marking
    a significant craze and truly democratizing access to powerful AI models. Learn
    about the [difference between BERT and GPT-3.](https://www.exxactcorp.com/blog/deep-learning/gpt-3-vs-bert-llm-comparison)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了BERT，OpenAI还发布了GPT-1，这是他们Transformer模型的第一个迭代版本。GPT-1（2018年）起始于1.17亿个参数，随后GPT-2（2019年）大幅跃升至15亿个参数，GPT-3（2020年）则拥有1750亿个参数。OpenAI的突破性聊天机器人ChatGPT基于GPT-3，于2022年11月30日发布，引发了巨大关注，并真正实现了强大AI模型的民主化。了解[difference
    between BERT and GPT-3](https://www.exxactcorp.com/blog/deep-learning/gpt-3-vs-bert-llm-comparison)。
- en: What Technological Advancements are Driving the Future of LLMs?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么技术进步正在推动LLM的未来？
- en: Advances in hardware, improvements in algorithms and methodologies, and integration
    of multi-modality all contribute to the advancement of large language models.
    As the industry finds new ways to utilize LLMs effectively, the continued advancement
    will tailor itself to each application and eventually entirely change the landscape
    of computing.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件的进步、算法和方法的改进，以及多模态的整合都促进了大语言模型的发展。随着行业找到利用LLM的有效方法，持续的进步将根据每个应用的需求进行调整，并最终彻底改变计算领域的格局。
- en: Advances in Hardware
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 硬件的进步
- en: The most simple and direct method for improving LLMs is to improve the actual
    hardware that the model runs on. The development of specialized hardware like [Graphics
    Processing Units (GPUs)](https://www.exxactcorp.com/category/Deep-Learning-NVIDIA-GPU-Workstations) significantly
    accelerated the training and inference of large language models. GPUs, with their
    parallel processing capabilities, have become essential for handling the vast
    amounts of data and complex computations required by LLMs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提升LLM的最简单直接的方法是改进模型运行的实际硬件。专用硬件如[图形处理单元 (GPUs)](https://www.exxactcorp.com/category/Deep-Learning-NVIDIA-GPU-Workstations)的开发显著加快了大语言模型的训练和推理速度。GPU凭借其并行处理能力，已成为处理LLM所需的大量数据和复杂计算的必备工具。
- en: OpenAI uses NVIDIA GPUs to power its GPT models and was one of the first NVIDIA
    DGX customers. Their relationship spanned from the emergence of AI to the continuance
    of AI where the CEO hand-delivered the first NVIDIA DGX-1 but also the latest
    NVIDIA DGX H200\. These GPUs incorporate huge amounts of memory and parallel computing
    for training, deploying, and inference performance.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 使用 NVIDIA GPUs 来驱动其 GPT 模型，并且是首批 NVIDIA DGX 客户之一。他们的关系从 AI 的出现延续到 AI
    的持续发展，CEO 亲自交付了第一台 NVIDIA DGX-1 以及最新的 NVIDIA DGX H200。这些 GPUs 集成了大量内存和并行计算，用于训练、部署和推理性能。
- en: Improvements in Algorithms and Architectures
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法和架构的改进
- en: The transformer architecture is known for already assisting LLMs. The introduction
    of that architecture has been pivotal to the advancement of LLMs as they are now.
    Its ability to process entire sequences simultaneously rather than sequentially
    has dramatically improved model efficiency and performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器架构已被证实能够支持 LLM。该架构的引入对 LLM 的进步至关重要，因为它们现在就是这样。其能够同时处理整个序列而非按顺序处理，显著提高了模型的效率和性能。
- en: Having said that, more can still be expected of the transformer architecture,
    and how it can continue evolving Large Language Models.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，变换器架构仍有很大的发展空间，以及它如何继续进化大型语言模型。
- en: Continuous refinements to the transformer model, including better attention
    mechanisms and optimization techniques, will lead to more accurate and faster
    models.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对变换器模型的持续改进，包括更好的注意机制和优化技术，将带来更准确、更快速的模型。
- en: Research into novel architectures, such as sparse transformers and efficient
    attention mechanisms, aims to reduce computational requirements while maintaining
    or enhancing performance.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对新型架构的研究，例如稀疏变换器和高效注意机制，旨在减少计算需求，同时保持或增强性能。
- en: Integration of Multimodal Inputs
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多模态输入的集成
- en: The future of LLMs lies in their ability to handle multimodal inputs, integrating
    text, images, audio, and potentially other data forms to create richer and more
    contextually aware models. Multimodal models like OpenAI's CLIP and DALL-E have
    demonstrated the potential of combining visual and textual information, enabling
    applications in image generation, captioning, and more.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的未来在于其处理多模态输入的能力，整合文本、图像、音频以及其他数据形式，以创建更丰富和更具上下文意识的模型。像 OpenAI 的 CLIP 和
    DALL-E 这样的多模态模型展示了结合视觉和文本信息的潜力，使图像生成、图像标注等应用成为可能。
- en: These integrations allow LLMs to perform even more complex tasks, such as comprehending
    context from both text and visual cues, which ultimately makes them more versatile
    and powerful.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些集成使 LLM 能够执行更复杂的任务，例如理解来自文本和视觉线索的上下文，这*最终使它们更具多功能性和强大*。
- en: Future of LLMs
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 的未来
- en: The advancements haven’t stopped, and there are more coming as LLM creators
    plan to incorporate even more innovative techniques and systems in their work.
    Not every improvement in LLMs requires more demanding computation or deeper conceptual
    understanding. One key enhancement is developing smaller, more user-friendly models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 进展并未停止，LLM 创建者计划在他们的工作中融入更多创新技术和系统。并非所有 LLM 的改进都需要更高的计算需求或更深的概念理解。一个关键的提升是开发更小、更易用的模型。
- en: 'While these models may not match the effectiveness of "Mammoth LLMs" like GPT-4
    and LLaMA 3, it''s important to remember that not all tasks require massive and
    complex computations. Despite their size, advanced smaller models like Mixtral
    8x7B and Mistal 7B can still deliver impressive performances. Here are some key
    areas and technologies expected to drive the development and improvement of LLMs:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些模型可能不如像 GPT-4 和 LLaMA 3 这样的“巨型 LLM”有效，但重要的是要记住，并非所有任务都需要庞大而复杂的计算。尽管体积庞大，像
    Mixtral 8x7B 和 Mistal 7B 这样的先进小型模型仍能提供令人印象深刻的表现。以下是一些预计将推动 LLM 发展和改进的关键领域和技术：
- en: 1\. Mixture of Experts (MoE)
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 专家混合（MoE）
- en: '[MoE models](https://www.exxactcorp.com/blog/deep-learning/why-new-llms-use-moe-mixture-of-experts-architecture) use
    a dynamic routing mechanism to activate only a subset of the model''s parameters
    for each input. This approach allows the model to scale efficiently, activating
    the most relevant "experts" based on the input context, as seen below. MoE models
    offer a way to scale up LLMs without a proportional increase in computational
    cost. By leveraging only a small portion of the entire model at any given time,
    these models can use less resources while still providing excellent performance.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[MoE模型](https://www.exxactcorp.com/blog/deep-learning/why-new-llms-use-moe-mixture-of-experts-architecture)使用动态路由机制，为每个输入仅激活模型参数的一个子集。这种方法使模型能够高效扩展，根据输入上下文激活最相关的“专家”，如下面所示。MoE模型提供了一种在不成比例增加计算成本的情况下扩展LLM的方法。通过在任何给定时间仅利用整个模型的一小部分，这些模型能够使用更少的资源，同时仍提供卓越的性能。'
- en: '![future of llms - mixture of experts](../Images/f7b54f73894136d7cf38887a4a9a1638.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![未来的LLMs - 专家混合](../Images/f7b54f73894136d7cf38887a4a9a1638.png)'
- en: 2\. Retrieval-Augmented Generation (RAG) Systems
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 检索增强生成（RAG）系统
- en: '[Retrieval Augmented Generation systems](https://www.exxactcorp.com/blog/deep-learning/how-retrieval-augment-generation-makes-llms-smarter-than-before) are
    currently a very hot topic in the LLM community. The concept questions why you
    should train the LLMs on more data when you can simply make it retrieve the desired
    data from an external source. Then that data is used to generate a final answer.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[检索增强生成系统](https://www.exxactcorp.com/blog/deep-learning/how-retrieval-augment-generation-makes-llms-smarter-than-before)目前在LLM社区中是一个非常热门的话题。这个概念质疑为什么要在更多数据上训练LLM时，你可以简单地让它从外部来源检索所需的数据。然后使用这些数据生成最终答案。'
- en: RAG systems enhance LLMs by retrieving relevant information from large external
    databases during the generation process. This integration allows the model to
    access and incorporate up-to-date and domain-specific knowledge, improving its
    accuracy and relevance. Combining the generative capabilities of LLMs with the
    precision of retrieval systems results in a powerful hybrid model that can generate
    high-quality responses while staying informed by external data sources.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统通过在生成过程中从大型外部数据库检索相关信息来增强LLM。这种集成使模型能够访问和融入最新的领域特定知识，提高其准确性和相关性。将LLM的生成能力与检索系统的精确性结合，产生了一种强大的混合模型，能够生成高质量的回应，同时保持对外部数据源的了解。
- en: '![future of llms - RAG or retreival augmented generation ](../Images/ee607ba231f029f6641aa92d06db40bb.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![未来的LLMs - RAG或检索增强生成](../Images/ee607ba231f029f6641aa92d06db40bb.png)'
- en: 3\. Meta-Learning
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 元学习
- en: Meta-learning approaches allow LLMs to learn how to learn, enabling them to
    adapt quickly to new tasks and domains with minimal training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习方法允许LLM学习如何学习，使其能够快速适应新的任务和领域，所需的训练最少。
- en: 'The concept of Meta-learning depends on several key concepts such as:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习的概念依赖于几个关键概念，如：
- en: 'Few-Shot Learning: by which LLMs are trained to understand and perform new
    tasks with only a few examples, significantly reducing the amount of data required
    for effective learning. This makes them highly versatile and efficient in handling
    diverse scenarios.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 少样本学习：LLM被训练以理解和执行仅凭少量示例的新任务，显著减少了有效学习所需的数据量。这使它们在处理各种场景时非常多才多艺且高效。
- en: 'Self-Supervised Learning: LLMs use large amounts of unlabelled data to generate
    labels and learn representations. This form of learning allows models to create
    a rich understanding of language structure and semantics which is then fine-tuned
    for specific applications.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自监督学习：LLM使用大量未标记的数据生成标签并学习表示。这种学习方式使模型能够深入理解语言结构和语义，然后针对特定应用进行微调。
- en: 'Reinforcement Learning: In this approach, LLMs learn by interacting with their
    environment and receiving feedback in the form of rewards or penalties. This helps
    models to optimize their actions and improve decision-making processes over time.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习：在这种方法中，LLM通过与环境互动并接收奖励或惩罚的反馈来学习。这有助于模型优化其行为并随着时间的推移改善决策过程。
- en: Conclusion
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: LLMs are marvels of modern technology. They’re complex in their functioning,
    massive in size, and groundbreaking in their advancements. In this article, we
    explored the future potential of these extraordinary advancements. Starting from
    their early beginnings in the world of artificial intelligence, we also delved
    into key innovations like Neural Networks and Attention Mechanisms.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是现代技术的奇迹。它们的运作复杂、规模庞大、进展突破性。在这篇文章中，我们探索了这些非凡进展的未来潜力。从它们在人工智能领域的早期起步开始，我们还深入探讨了神经网络和注意力机制等关键创新。
- en: We then examined a multitude of strategies for enhancing these models, including
    advancements in hardware, refinements in their internal mechanisms, and the development
    of new architectures. By now, we hope you have gained a clearer and more comprehensive
    understanding of LLMs and their promising trajectory in the near future.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着审视了多种提升这些模型的策略，包括硬件的进步、内部机制的改进以及新架构的发展。到现在为止，我们希望你对大型语言模型（LLMs）及其在不久的将来充满希望的发展轨迹有了更清晰、更全面的理解。
- en: '**[Kevin Vu](https://blog.exxactcorp.com/)** manages [Exxact Corp blog](https://blog.exxactcorp.com/)
    and works with many of its talented authors who write about different aspects
    of Deep Learning.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kevin Vu](https://blog.exxactcorp.com/)** 管理着 [Exxact Corp 博客](https://blog.exxactcorp.com/)，并与许多才华横溢的作者合作，这些作者撰写关于深度学习的不同方面。'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[A Brief History of the Neural Networks](https://www.kdnuggets.com/a-brief-history-of-the-neural-networks)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络简史](https://www.kdnuggets.com/a-brief-history-of-the-neural-networks)'
- en: '[Forecasting Future Events: The Capabilities and Limitations of AI and ML](https://www.kdnuggets.com/2023/06/forecasting-future-events-capabilities-limitations-ai-ml.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[预测未来事件：人工智能和机器学习的能力与局限](https://www.kdnuggets.com/2023/06/forecasting-future-events-capabilities-limitations-ai-ml.html)'
- en: '[The Rise and Fall of Prompt Engineering: Fad or Future?](https://www.kdnuggets.com/the-rise-and-fall-of-prompt-engineering-fad-or-future)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程的兴衰：潮流还是未来？](https://www.kdnuggets.com/the-rise-and-fall-of-prompt-engineering-fad-or-future)'
- en: '[Generative AI Playground: LLMs with Camel-5b and Open LLaMA 3B on…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-llms-with-camel-5b-and-open-llama-3b)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成性人工智能游乐场：Camel-5b和Open LLaMA 3B的LLMs](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-llms-with-camel-5b-and-open-llama-3b)'
- en: '[Vector Database for LLMs, Generative AI, and Deep Learning](https://www.kdnuggets.com/vector-database-for-llms-generative-ai-and-deep-learning)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LLMs、生成性人工智能和深度学习的向量数据库](https://www.kdnuggets.com/vector-database-for-llms-generative-ai-and-deep-learning)'
- en: '[Quantization and LLMs: Condensing Models to Manageable Sizes](https://www.kdnuggets.com/quantization-and-llms-condensing-models-to-manageable-sizes)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[量化与LLMs：将模型浓缩至可管理的大小](https://www.kdnuggets.com/quantization-and-llms-condensing-models-to-manageable-sizes)'
