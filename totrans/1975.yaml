- en: 'Evolution in ETL: How Skipping Transformation Enhances Data Management'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/evolution-in-etl-how-skipping-transformation-enhances-data-management](https://www.kdnuggets.com/evolution-in-etl-how-skipping-transformation-enhances-data-management)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Evolution in ETL: How Skipping Transformation Enhances Data Management](../Images/473047592011bf33af747cdbc2a528c1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: Few data concepts are more polarizing than ETL (extract-transform-load), the
    preparation technique that has dominated enterprise operations for several decades.
    Developed in the 1970s, ETL shined during an era of large-scale data warehouses
    and repositories. Enterprise data teams centralized data, layered reporting systems
    and data science models on top, and enabled self-service access to business intelligence
    (BI) tools. However, ETL has shown its age in an era of cloud services, data models,
    and digital processes.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Searches such as “Is ETL still relevant/in-demand/obsolete/dead?” populate results
    on Google. The reason why is that enterprise data teams are groaning under the
    weight of preparing data for widespread use across employee roles and business
    functions. ETL doesn’t scale easily to handle vast volumes of historical data
    stored in the cloud. Nor does it deliver real-time data required for rapid executive
    decision-making. In addition, building custom APIs to provide applications with
    data creates significant management complexity. It’s not uncommon for modern enterprises
    to have 500 to 1,000 pipelines in place as they seek to transform data and equip
    users with self-service access to BI tools. However, these APIs are in a constant
    state of evolution as they must be reprogrammed when the data that they pull changes.
    It’s clear this process is too brittle for many modern data requirements, such
    as edge use cases.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, application capabilities have evolved. Source systems provide business
    logic and tools to enforce data quality while consuming applications enable data
    transformation and provide a robust semantic layer. So, teams are less incentivized
    to build point-to-point interfaces to move data at scale, transform it, and load
    it into the data warehouse.
  prefs: []
  type: TYPE_NORMAL
- en: Two innovative techniques point the way to enabling data democratization while
    minimizing transformation burdens. Zero ETL makes data available without moving
    it, whereas reverse ETL pushes rather than pulls data to the applications that
    need it as soon as it is available.
  prefs: []
  type: TYPE_NORMAL
- en: Zero ETL Reduces Data Movement and Transformation Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zero ETL optimizes the movement of smaller data sets. With data replication,
    data is moved to the cloud in its current state for use with data queries or experiments.
  prefs: []
  type: TYPE_NORMAL
- en: But what if teams don’t want to move data at all?
  prefs: []
  type: TYPE_NORMAL
- en: Data virtualization abstracts servers from end users. When users query data
    from a single source, that output is pushed back to them. And with query federation,
    users can query multiple data sources. The tool combines results and presents
    the user with integrated data results.
  prefs: []
  type: TYPE_NORMAL
- en: These techniques are called zero ETL because there is no need to build a pipeline
    or transform data. Users handle data quality and aggregation needs on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: Zero ETL is ideally suited for ad-hoc analysis of near-term data, as executing
    large queries on historical data can harm operational performance and increase
    data storage costs. For example, many retail and consumer packaged goods executives
    use zero ETL to query daily transactional data to focus marketing and sales strategies
    during times of peak demand, such as the holidays.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cortex provides accelerators, enabling zero ETL on [SAP enterprise resource
    planning](https://cloud.google.com/blog/products/sap-google-cloud/google-cloud-cortex-framework-for-procure-to-pay)
    system data. Other companies, such as one of the world’s largest retailers and
    a global food and beverage company, have also adopted zero ETL processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero ETL gains include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Providing speed to access:** Using zero ETL processes to provision data for
    self-service queries saves 40-50% of the time it takes using traditional ETL processes
    since there’s no need to build pipelines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reducing data storage requirements:** Data does not move with data virtualization
    or query federation. Users only store query results, decreasing storage requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Delivering cost savings:** Teams that use zero ETL processes save 30-40%
    on data preparation and storage costs compared to traditional ETL.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improving data performance:** Since users query only the data they want,
    results are delivered 25% faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get started with zero ETL, teams should evaluate which use cases are best
    suited for this technique and identify the data elements they need to execute
    it. They also should configure their zero ETL tool to point to the desired data
    sources. Teams then extract data, create data assets, and expose them to downstream
    users.
  prefs: []
  type: TYPE_NORMAL
- en: Using Reverse ETL to Feed Applications with Data On-Demand
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reverse ETL techniques simplify data flows to downstream applications. Instead
    of using REST APIs or endpoints and writing scripts to pull data, teams leverage
    reverse ETL tools to push data into business processes on time and in full.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using reverse ETL provides the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reducing time and effort:** Using reverse ETL for key use cases reduces the
    time and effort to access data for key use cases by 20-25%. A leading cruise line
    leverages reverse ETL for digital marketing initiatives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Improving data availability:** Teams have greater certainty they’ll have
    access to the data they need for key initiatives, as 90-95% of target data is
    delivered on time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decreasing costs:** Reverse ETL processes reduce the need for APIs, which
    require specialized programming skills and increase management complexity. As
    a result, teams reduce data costs by 20-25%.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get started with reverse ETL, data teams should evaluate use cases that require
    on-demand data. Next, they determine the frequency and volume of data to be delivered
    and choose the proper tooling to handle these data volumes. Then, they point data
    assets in the data warehouse to their destination consumption systems. Teams should
    prototype with one data load to measure efficiency and scale processes.
  prefs: []
  type: TYPE_NORMAL
- en: To Succeed with Data, Use a Variety of Preparation Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Zero ETL and reverse ETL tools provide teams with fresh options for serving
    data to users and applications. They can analyze factors such as use case requirements,
    data volumes, delivery timeframes, and cost drivers to select the best option
    for delivering data, whether traditional ETL, zero ETL, or reverse ETL.
  prefs: []
  type: TYPE_NORMAL
- en: Partners support these efforts by providing insight into the best techniques
    and tools to meet functional and non-functional requirements, providing a weighted
    scorecard, conducting a proof of value (POV) with the winning tool, and then operationalizing
    the tool for more use cases.
  prefs: []
  type: TYPE_NORMAL
- en: With zero ETL and reverse ETL, data teams achieve their goals of empowering
    users and applications with the data they need where and when they need it, driving
    cost and performance gains while avoiding transformation headaches.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/arnab-sen-60b92624/)**[Arnab Sen](https://www.linkedin.com/in/arnab-sen-60b92624/)****is
    an experienced professional with a career spanning over 16 years in the technology
    and decision science industry. He presently serves as the VP-Data Engineering
    at Tredence, a prominent data analytics company, where he helps organizations
    design their AI-ML/Cloud/Big-data strategies. With his expertise in data monetization,
    Arnab uncovers the latent potential of data to drive business transformations
    across B2B & B2C clients from diverse industries.   Arnab''s passion for team
    building and ability to scale people, processes, and skill sets have helped him
    successfully manage multi-million-dollar portfolios across various verticals,
    including Telecom, Retail, and BFSI. He has previously held positions at Mu Sigma
    and IGate, where he played a crucial role in solving clients’ problems by developing
    innovative solutions.   Arnab''s exceptional leadership skills and profound domain
    knowledge have earned him a seat on the Forbes Tech Council.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How Cloud Computing Enhances Data Science Workflows](https://www.kdnuggets.com/2023/08/cloud-computing-enhances-data-science-workflows.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Oracle to Databases for AI: The Evolution of Data Storage](https://www.kdnuggets.com/2022/02/oracle-databases-ai-evolution-data-storage.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Evolution From Artificial Intelligence to Machine Learning to…](https://www.kdnuggets.com/2022/08/evolution-artificial-intelligence-machine-learning-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Evolution of the Data Landscape](https://www.kdnuggets.com/2023/06/evolution-data-landscape.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Analyzing the Probability of Future Success with Intelligence…](https://www.kdnuggets.com/2022/02/analyzing-probability-future-success-intelligence-node-attributes-evolution-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Evolution of Speech Recognition Metrics](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
