- en: Machine Learning Finds “Fake News” with 88% Accuracy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习以88%的准确率发现“虚假新闻”
- en: 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)
- en: '**By George McIntire, Contributing Data Science Writer, ODSC**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**乔治·麦金泰尔，贡献数据科学撰稿人，ODSC**'
- en: '![Donald Trump](../Images/c4c806c5213c7410a605b76b4daa4706.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![特朗普](../Images/c4c806c5213c7410a605b76b4daa4706.png)'
- en: “A lie gets halfway around the world before the truth has a chance to get its
    pants on.”
  id: totrans-4
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: “谎言在真相来得及穿上裤子之前，就已经传遍了半个世界。”
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – Winston Churchill
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 温斯顿·丘吉尔
- en: Since the 2016 presidential election, one topic dominating political discourse
    is the issue of “Fake News”. A number of political pundits claim that the rise
    of significantly biased and/or untrue news influenced the election, though a [study
    by researchers](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)
    from Stanford and New York University concluded otherwise. Nonetheless, fake news
    posts have exploited Facebook users’ feeds to propagate throughout the internet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自2016年总统选举以来，一个主导政治讨论的话题是“虚假新闻”问题。许多政治评论员声称，显著偏见和/或虚假的新闻影响了选举，尽管[斯坦福大学和纽约大学的研究](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)得出了不同的结论。尽管如此，虚假新闻帖子已经利用Facebook用户的信息流在互联网中传播。
- en: '****“What is fake news?”****'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '****“什么是虚假新闻？”****'
- en: Obviously, a deliberately misleading story is “fake news” but lately blathering
    social media discourse,  is changing its definition. Some now use the term to
    dismiss facts counter to their preferred viewpoints, the most prominent example
    being [President Trump](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd).
    Such a vaguely-defined term is ripe for a cynical manipulation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，一个故意误导的故事就是“虚假新闻”，但最近喧闹的社交媒体讨论正在改变它的定义。一些人现在使用这个术语来拒绝与他们偏好的观点相悖的事实，最突出的例子是[特朗普总统](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd)。这样的模糊定义的术语很容易被玩弄。
- en: 'The data science community has responded by [taking action to fight the problem](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/).
    There’s a Kaggle-style competition called the “[Fake News Challenge](http://www.fakenewschallenge.org/)” and
    [Facebook is employing AI](https://techcrunch.com/2016/11/14/facebook-fake-news/) to
    filter fake news stories out of users’ feeds. Combating fake news is a classic
    text classification project with a straight-forward proposition: ***Can you build
    a model that can differentiate between “Real” news vs “Fake” news.***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学社区已经做出回应，[采取行动来解决这个问题](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/)。有一个类似Kaggle的比赛，称为“[虚假新闻挑战](http://www.fakenewschallenge.org/)”，而[Facebook正在使用AI](https://techcrunch.com/2016/11/14/facebook-fake-news/)来过滤用户信息流中的虚假新闻。打击虚假新闻是一个经典的文本分类项目，提出了一个直接的问题：***你能建立一个区分“真实”新闻和“虚假”新闻的模型吗？***
- en: And that’s exactly what I attempted to do for this project. I assembled a dataset
    of fake and real news and employed a [Naive Bayes](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
    classifier in order to create a model to classify an article as fake or real based
    on its words and phrases.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我为这个项目所尝试做的。我组建了一个包含虚假新闻和真实新闻的数据集，并使用了一个[朴素贝叶斯](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)分类器，以便创建一个模型，根据文章中的词汇和短语将其分类为虚假或真实。
- en: Data Gather/Wrangling
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集/整理
- en: There were two parts to the data acquisition process, getting the “fake news”
    and getting the real news. The first part was quick, Kaggle released a [fake news
    dataset](https://www.kaggle.com/mrisdal/fake-news) comprising of 13,000 articles
    published during the 2016 election cycle.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据获取过程分为两个部分：获取“假新闻”和获取真实新闻。第一部分很快，Kaggle 发布了一个[fake news dataset](https://www.kaggle.com/mrisdal/fake-news)，包含了在2016年选举周期内发布的13,000篇文章。
- en: The second part was… a lot more difficult.  To acquire the real news side of
    the dataset, I turned to [All Sides](http://www.allsides.com/), a website dedicated
    to hosting news and opinion articles from across the political spectrum. Articles
    on the website are categorized by topic (environment, economy, abortion, etc…)
    and by political leaning (left, center, and right). I used All Sides because it
    was the best way to web scrape thousands of articles from numerous media outlets
    of differing biases. Plus, it allowed to me download the full text of an article,
    something you cannot do with the New York Times and NPR APIs. After a long and
    arduous process I ended up scraping a total of **5279 articles**. The articles
    in my real news dataset came from media organizations such as the New York Times,
    WSJ, Bloomberg, NPR, and the Guardian and were published in 2015 or 2016.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分要困难得多。为了获取数据集中真实新闻的部分，我转向了[All Sides](http://www.allsides.com/)，这是一个致力于汇集政治光谱各方新闻和观点文章的网站。该网站上的文章按主题（环境、经济、堕胎等）和政治倾向（左派、中立、右派）进行分类。我使用All
    Sides，因为这是从众多媒体渠道中抓取成千上万篇文章的最佳方式。此外，它还允许我下载文章的完整文本，这一点是《纽约时报》和 NPR API 所不具备的。经过漫长而艰辛的过程，我最终抓取了**5279篇文章**。我的真实新闻数据集中的文章来自于《纽约时报》、华尔街日报、彭博社、NPR
    和《卫报》，并且这些文章发表于2015年或2016年。
- en: I decided to construct my full dataset with equal parts fake and real articles,
    thus making my model’s null accuracy 50%. I randomly selected 5279 articles from
    my fake news dataset to use in my complete dataset and left the remaining articles
    to be used as a testing set when my model was complete.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定将我的完整数据集构建为假新闻和真实新闻各占一半，从而使模型的空白准确率为50%。我随机选择了5279篇假新闻文章用于我的完整数据集，其余的文章则留作测试集，以便在我的模型完成时使用。
- en: My finalized dataset was comprised of 10558 total articles with their headlines
    and full body text and their labels (real vs fake). The data is located here in
    this [github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我最终的数据集包含了10558篇文章，包括它们的标题、完整正文和标签（真实与假）。数据存放在这个[github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset)中。
- en: Purpose and Expectations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目的与期望
- en: When I first started this project, I conceded that this would not be the perfect
    project. The purpose of this project was to see how far I could get in creating
    a fake news classification and what insights could be drawn from that, then used
    towards a better model. My game plan was to treat this project the same way as
    a routine spam detection project.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我刚开始这个项目时，我承认这不会是一个完美的项目。这个项目的目的是看看我能在创建假新闻分类器上走多远，并从中获得什么见解，然后用于改进模型。我的计划是将这个项目视为一个常规的垃圾邮件检测项目。
- en: Building a model based on a count vectorizer (using word tallies) or a tfidf
    matrix (word tallies relative to how often they’re used in other articles in your
    dataset) can only get you so far. These methods do not consider important qualities like
    the word ordering and context. It’s very possible for two articles that are similar
    in their word counts to be totally different in their meaning. I did not expect
    my model to be adept at handling fake and real articles whose words and phrases
    overlap. Nonetheless, I expect some valuable insights to come from this project.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基于计数向量化器（使用词频统计）或 tfidf 矩阵（词频相对于它们在数据集中其他文章中的使用频率）来构建模型只能取得一定的效果。这些方法没有考虑重要的特质，比如词序和上下文。两个在词频上类似的文章，其含义可能完全不同。我并没有期望我的模型能够熟练处理那些词语和短语重叠的假新闻和真实新闻。然而，我期待这个项目能够提供一些有价值的见解。
- en: Modeling
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建模
- en: Since this is a text classification project, I only used a Naive Bayes classifier
    as is standard for text-based data science projects.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个文本分类项目，我只使用了朴素贝叶斯分类器，这是文本数据科学项目中的标准做法。
- en: The real work in formulating a model was the text transformation (count vectorizer
    vs tfidf vectorizer) and choosing which type of text to use (headlines vs full
    text). This gave me four pairs of reconfigured datasets to work with.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 制定模型的真正工作是文本转换（**计数向量器**与**tfidf向量器**）和选择使用哪种类型的文本（标题与全文）。这给了我四对重新配置的数据集来进行操作。
- en: The next step was to determine the most optimal parameters for either a countvectorizer
    or tfidf-vectorizer. For those of you who are unfamiliar with text machine learning,
    this means using a n-number of the most common words, using words and/or phrases,
    lower casing or not, removing stop words (common words such as the, when, and
    there) and only using words that appear at least a given number of times in a text
    corpus (a term for a text dataset or a collection of texts).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是确定**计数向量器**或**tfidf向量器**的最优参数。对于那些不熟悉文本机器学习的人来说，这意味着使用n个最常见的词，使用词和/或短语，是否小写，去除停用词（如the、when和there）以及仅使用在文本语料库中出现至少指定次数的词（文本数据集或文本集合的术语）。
- en: To test the performance of multiple parameters and their numerous combinations,
    I utilized the Sci-kit Learn’s GridSearch functionality to efficiently execute
    this task. To learn more about how to perfect your algorithm parameters, please
    review [this tutorial](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试多个参数及其众多组合的性能，我利用了Sci-kit Learn的GridSearch功能来高效地执行此任务。要了解如何**优化算法参数**，请查看[这个教程](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)。
- en: After the grid search cross validation process, I found that my model worked
    best with a count vectorizer instead of a tfidf and produced higher scores when trained
    on the full text of articles instead of their headlines. The optimal parameters
    for count vectorizer are no lowercasing, two-word phrases not single words, and to
    only use words that appear at least three times in the corpus.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索交叉验证过程之后，我发现我的模型在使用**计数向量器**而不是**tfidf**时效果最佳，并且在用文章的全文训练时比训练在标题上产生了更高的分数。**计数向量器**的最佳参数是不进行小写转换、使用两词短语而非单个词，并且仅使用在语料库中出现至少三次的词。
- en: Given my expectations that I outlined earlier in this post, I was surprised
    and almost baffled at the high scores my model produced. My model’s cross-validated
    accuracy score is 91.7%, recall (true positive rate) score is 92.6%, and its AUC
    score is 95%.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我在帖子中之前概述的期望，我对模型产生的高分感到惊讶甚至有些困惑。我的模型的交叉验证准确率为91.7%，召回率（真正率）为92.6%，AUC分数为95%。
- en: Here is the ROC Curve for my model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我模型的ROC曲线。
- en: '[![ROC Curve](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[![ROC 曲线](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)'
- en: If I were to decide on a threshold for a model based on this graph, I would
    choose one that produces a FPR at around 0.08 and a TPR at around 0.90, because
    at that point in the graph the trade off between false positives and true positives
    is equal.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我基于此图决定模型的阈值，我会选择一个在0.08左右产生假阳性率（FPR）和在0.90左右产生真正率（TPR）的阈值，因为在图中此点假阳性与真正率之间的权衡是平衡的。
- en: Results & Conclusion
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果与结论
- en: The true test of my model’s quality would be to see how fake news articles in
    the test set (those not used in the creation of my model) it could accurately
    classify.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我的模型质量的真正考验是看它能多准确地分类测试集中（未用于模型创建的假新闻文章）假新闻文章。
- en: '**Out of the 5234 articles left in the other fake news datasets, my model was
    able to correctly identify 88.2% of them as fake.** This is 3.5 percentage points
    lower than my cross-validated accuracy score, but in my opinion it is pretty decent
    evaluation of my model.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**在5234篇其他假新闻数据集中，我的模型能够正确识别88.2%的假新闻。** 这比我的交叉验证准确率低了3.5个百分点，但在我看来，这是对我的模型的相当不错的评估。'
- en: It turns out that my hypothesis predicting that model would struggle at classifying
    news articles was quite wrong. I thought that an accuracy score in the upper 60s
    or lower 70s would be excellent and I managed to surpass that by a significant
    margin.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，我预测模型在分类新闻文章时会遇到困难的假设是相当错误的。我原本认为60多或70多的准确率是**优秀的**，但我设法显著超越了这个预期。
- en: Even though I created what appears to be a pretty good model given the complexity
    of the task, I am not entirely convinced that it is as good as it appears to be
    and here’s why.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我创建了一个看似相当不错的模型，但考虑到任务的复杂性，我并不完全相信它的表现如同表面上看起来的那样，这就是原因所在。
- en: To be better understand why this might have happened, let’s take a look at the
    “fakest” and “realest” words in the data—I’ll explain what I mean by that.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解为什么会发生这种情况，我们来看看数据中的“最虚假”和“最真实”词汇——我会解释我的意思。
- en: Using a technique I borrowed from Kevin Markham of Data School, here’s how I
    derived the “fakest” and “realest” words in the corpus. First I started off with
    a table two columns wide and 10558 rows long (that’s how many words there are
    in the corpus). The first column represented how many times a given word appeared
    in articles classified as “FAKE” and the second column was how many times a word appeared
    in a “REAL” article.  Then I divided the fake column by the total number of fake
    articles my model classified and so on for the real column. Next, I added the
    number one to every value in the data because I created a new column of “Fake:Real”
    ratios and didn’t want to get an error by dividing zero. This “Fake:Real” is a
    pretty good but by no means perfect metric of just how “fake” or “real a certain
    word. The logic is pretty simple, if a word shows up a bunch in “fake” articles
    and rarely in “real” articles then its fake to real ratio score will be pretty
    high.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我从数据学校的Kevin Markham那里借用的技术，这里是我如何得出语料库中“最虚假”和“最真实”词汇的方法。我首先使用了一个宽两列、长10558行的表格（这就是语料库中的词汇数量）。第一列表示一个词在被分类为“虚假”的文章中出现的次数，第二列表示一个词在“真实”文章中出现的次数。然后，我将虚假列的数值除以我模型分类的虚假文章总数，真实列也做了同样的处理。接着，我在数据的每个值上加了一，因为我创建了一个新的“虚假:真实”比率列，不想因为除以零而产生错误。这个“虚假:真实”是衡量某个词汇“虚假”或“真实”的一个相当不错但并不完美的指标。逻辑很简单，如果一个词在“虚假”文章中频繁出现而在“真实”文章中很少出现，那么它的虚假与真实比率分数将会很高。
- en: Here are the top 20 “fakest” and “realest” words in my dataset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我数据集中前20个“最虚假”和“最真实”的词汇。
- en: '[![Fakest](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[![最虚假](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)'
- en: '[![Realest](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[![最真实](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)'
- en: These two graphics exhibit some baffling results. The words in the “fake” chart
    are a mixed bag that includes some typical internet terminology such as PLEASE,
    Share, Posted, html, and Widget and words that aren’t even words such as tzrwu. However
    I was not surprised to see infowars mentioned nor terms like “Sheeple” or “UFO”
    make it in the top 20 “fakest” words. Infowars is a right-wing conspiracy-laden
    outlet led by Alex Jones that promotes conspiracy theories about chemtrails and
    9/11.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个图表展示了一些令人困惑的结果。“虚假”图表中的词汇种类繁杂，包括一些典型的互联网术语，如PLEASE、Share、Posted、html和Widget，以及一些甚至不是真正的词汇，如tzrwu。然而，看到infowars被提及以及“羊群”和“UFO”等词汇进入前20个“最虚假”词汇并不令人惊讶。Infowars是由Alex
    Jones领导的一个右翼阴谋论媒体，推广关于化学轨迹和9/11的阴谋理论。
- en: The “real” chart is dominated by names and politicians and words frequently
    used in political articles, comprising 60% of the bars in the chart. Seven of
    the twenty terms, including four of the top six, are politician names. This begs
    the question, are articles about politicians more likely to be true? No of course
    not, if anything you’d expect there to be numerous fake news articles spreading
    falsehoods about politicians. I would be committing a huge error if I came to
    the conclusion that articles mentioning politicians are more likely to be to factual.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: “真实”的图表主要由名字、政治家以及在政治文章中经常使用的词汇构成，占据了图表中60%的条形图。二十个词汇中有七个，包括前六名中的四个，是政治家名字。这引发了一个问题，即关于政治家的文章是否更有可能是真实的？当然不是，如果有什么的话，你会预期有大量的虚假新闻传播关于政治家的虚假信息。如果我得出提到政治家的文章更有可能真实的结论，那将是一个巨大的错误。
- en: One big assumption underlying this project is that there is considerable overlap
    in the topics covered by each class of article. As we witnessed above, just because
    a certain word shows up more often in “real” news than “fake” news it doesn’t
    mean that articles with those terms are guaranteed to be “real”, but instead could
    just mean that those words are used in topics more common in the real news dataset
    and vice versa for the fake news dataset.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目的一个重要假设是，各类文章所涵盖的主题有相当大的重叠。正如我们上面所见，仅仅因为某个词在“真实”新闻中出现得比在“虚假”新闻中多，并不意味着包含这些词的文章一定是“真实”的，而只是这些词可能在真实新闻数据集中更常见，而虚假新闻数据集中则反之。
- en: I and another party had a considerable amount of influence in shaping this dataset.
    I made the decision on which articles to use for the “real” dataset. The articles
    in the “fake” dataset were determined by a [chrome extension called “BS Detector”](https://github.com/selfagency/bs-detector) made
    by Daniel Sieradski. There is a significantly high amount of subjectivity going
    into determining what is and what isn’t “fake news”. The reason why politician
    names are rated as “real” so highly is most likely because that half of the corpura disproportionately
    comes from political news. In addition, I did find a couple of articles from what
    I find to be reputable sources of news. One such article came from The Intercept,
    a news organization with high journalism standards. And yes, my model did indeed
    flag this supposed “fake news” article as real.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我和另一方对塑造这个数据集有相当大的影响。我决定了哪些文章用于“真实”数据集。“虚假”数据集中的文章是由[一个名为“BS Detector”的Chrome扩展程序](https://github.com/selfagency/bs-detector)确定的，该程序由Daniel
    Sieradski制作。确定什么是“虚假新闻”、什么不是“虚假新闻”时存在显著的主观性。政治人物的名字被高评级为“真实”的原因，很可能是因为这部分语料库不成比例地来自政治新闻。此外，我确实发现了一些我认为来自可靠新闻来源的文章。其中一篇文章来自The
    Intercept，一个具有高新闻标准的新闻组织。是的，我的模型确实将这篇所谓的“虚假新闻”文章标记为真实。
- en: To make matters even more complicated, we have to decide how to set the threshold
    probability for our model. If I was a data scientist at Facebook tasked with implementing
    a model that sorts out real and fake news in users’ feeds, I’d be faced with the
    dilemma between choosing a model that blocks all or most fake news and some real
    news or a model that allows all or most real news and some fake news. But before
    I make that decision, I need to figure what is the cost of failing to prevent
    fake news vs the cost of blocking real news? How does one attempt to answer such
    an abstract question? Unless we can train a model with a 100% true positive rate
    and 0% false positive rate, we’ll be stuck with this quandary.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使事情变得更加复杂的是，我们必须决定如何为我们的模型设置阈值概率。如果我是一名在 Facebook 的数据科学家，负责实现一个筛选用户动态中真实与虚假新闻的模型，我将面临选择一个屏蔽所有或大部分虚假新闻和一些真实新闻的模型，还是一个允许所有或大部分真实新闻和一些虚假新闻的模型的困境。但在做出决定之前，我需要弄清楚未能阻止虚假新闻与阻挡真实新闻的成本是什么？如何尝试回答这样一个抽象的问题？除非我们能训练一个100%真阳性率和0%假阳性率的模型，否则我们将被困在这个困境中。
- en: In conclusion, while I think that a standard Naive Bayes text classification
    model can provide insight into addressing this issue, a more powerful deep-learning
    tool should be employed to combat fake news in a professional setting.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，虽然我认为标准的朴素贝叶斯文本分类模型可以提供一些解决这个问题的见解，但在专业环境中，应使用更强大的深度学习工具来对抗虚假新闻。
- en: Classifying “fake news” provides a novel challenge to the data science community.
     In many machine learning projects, the distinction between the different classes
    you want to predict is clear, whereas it’s a lot murkier in this case. This project
    validates the notion in data science that intuition and intimacy with your data
    is just as or more important than any model or tool at your disposal.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对“虚假新闻”的分类为数据科学界提供了一个新挑战。在许多机器学习项目中，你想要预测的不同类别之间的区别是明确的，而在这种情况下则要模糊得多。这个项目验证了数据科学中的一种观点，即对数据的直觉和熟悉程度与任何模型或工具一样重要，甚至更为重要。
- en: '**Bio: [George McIntire](https://opendatascience.com/author/george-mcintire/)**
    is a journalist turned data scientist/journalist hybrid. Looking for opportunities
    in data science and/or journalism. Impossibly curious and passionate about learning
    new things. Before completing the Metis Data Science Bootcamp, he worked as a
    freelance journalist in San Francisco for Vice, Salon, SF Weekly, San Francisco
    Magazine, and more.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[乔治·麦金泰尔](https://opendatascience.com/author/george-mcintire/)** 是一位转行的数据科学家/记者混合型人才。寻找数据科学和/或新闻学方面的机会。对新事物充满好奇和热情。在完成Metis数据科学训练营之前，他曾在旧金山为Vice、Salon、SF
    Weekly、San Francisco Magazine等媒体担任自由记者。'
- en: '[Original](https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/).
    Reposted with permission.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/)。已获授权转载。'
- en: '**Related:**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[It’s Getting Hot In Here: Data Science vs Fake News](/2017/03/getting-hot-here-data-science-vs-fake-news.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[这里越来越热：数据科学与假新闻](/2017/03/getting-hot-here-data-science-vs-fake-news.html)'
- en: '[What Happened Last Night in Sweden: Data Science vs Fake News](/2017/03/last-night-sweden-data-science-vs-fake-news.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[昨晚瑞典发生了什么：数据科学与假新闻](/2017/03/last-night-sweden-data-science-vs-fake-news.html)'
- en: '[Beware of Two Data Obfuscation Tactics](/2017/04/beware-two-data-obfuscation-tactics.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[警惕两种数据混淆策略](/2017/04/beware-two-data-obfuscation-tactics.html)'
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[假到成功：生成真实的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[识别假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[识别假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
- en: '[Which Metric Should I Use? Accuracy vs. AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我应该使用哪种指标？准确性与AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类指标解析：逻辑回归与…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
- en: '[Sky''s the Limit: Learn how JetBlue uses Monte Carlo and Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[天高任鸟飞：了解JetBlue如何使用蒙特卡罗方法和Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
