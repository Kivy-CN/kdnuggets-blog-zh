- en: 8 Open-Source Alternative to ChatGPT and Bard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/a2e5643af552ce470bbbdfae6a562743.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 1\. LLaMA
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The [LLaMA](https://arxiv.org/abs/2302.13971) project encompasses a set of foundational
    language models that vary in size from 7 billion to 65 billion parameters. These
    models were training on millions of tokens, and it was training on publicly available
    datasets exclusively. As a result, LLaMA-13B outperforms GPT-3 (175B), and LLaMA-65B
    is performing similarly to the best models like Chinchilla-70B and PaLM-540B.
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/90ba0e0c93caae0a278d5a6fad77384c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [LLaMA](https://arxiv.org/abs/2302.13971)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Research Paper: [LLaMA: Open and Efficient Foundation Language Models (arxiv.org)](https://arxiv.org/abs/2302.13971)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [facebookresearch/llama](https://github.com/facebookresearch/llama)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [Baize Lora 7B](https://huggingface.co/spaces/project-baize/baize-lora-7B)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Alpaca
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stanford [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html) claims that
    it can compete with ChatGPT and anyone can reproduce it in less than 600$. The
    Alpaca 7B is finetuned from the LLaMA 7B model on 52K instruction-following demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/60ffb50f39a318ece225f0d288473b80.png)'
  prefs: []
  type: TYPE_IMG
- en: Training recipe | Image from [Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Blog: [Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [Alpaca-LoRA](https://huggingface.co/spaces/tloen/alpaca-lora) (The official
    demo was drop and this is a recreation of Alpaca model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3\. Vicuna
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Vicuna](https://vicuna.lmsys.org/) is finetuned from the LLaMA model on user-shared
    conversations collected from [ShareGPT](https://sharegpt.com/). The model Vicuna-13B
    has achieved more than 90%* quality of OpenAI ChatGPT and Google Bard. It has
    also outperformed LLaMA and Stanford Alpaca models in 90% of cases. The cost of
    training Vicuna was around 300$.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/4e49e3c4c6f80310070ddf7de4694914.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Vicuna](https://vicuna.lmsys.org/)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Blog post: [Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT
    Quality](https://vicuna.lmsys.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [lm-sys/FastChat](https://github.com/lm-sys/FastChat#fine-tuning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [FastChat (lmsys.org)](https://chat.lmsys.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 4\. OpenChatKit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[OpenChatKit: Open-Source ChatGPT Alternative](/2023/03/openchatkit-opensource-chatgpt-alternative.html)
    is a complete tools kit for creating your chatbot. It provides instruction for
    training your own Instruction-tuned large language model, fine-tuning the model,
    extensible retrieval system for updating the bot response, and bot moderation
    for filtering out questions.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/468f34c99053ce78c84dabf1bb795862.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [TOGETHER](https://www.together.xyz/blog/openchatkit)
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the GPT-NeoXT-Chat-Base-20B model has outperformed base mode
    GPT-NoeX on question and answer, extraction, and classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Blog Post: [Announcing OpenChatKit — TOGETHER](https://www.together.xyz/blog/openchatkit)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [OpenChatKit ](https://huggingface.co/spaces/togethercomputer/OpenChatKit)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model card: [togethercomputer/GPT-NeoXT-Chat-Base-20B](https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5\. GPT4ALL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[GPT4ALL](https://github.com/nomic-ai/gpt4all) is a community-driven project
    and was trained on a massive curated corpus of assistant interactions, including
    code, stories, depictions, and multi-turn dialogue. The team has provided datasets,
    model weights, data curation process, and training code to promote open-source.
    Furthermore, they have released quantized 4-bit versions of the model that can
    run on your laptop. You can even use a Python client to run the model inference.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/f0c2a201d62329663a470ed885d8cc8c.png)'
  prefs: []
  type: TYPE_IMG
- en: Gif from [GPT4ALL](https://github.com/nomic-ai/gpt4all)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Technical Report: [GPT4All](https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [nomic-ai/gpt4al](https://github.com/nomic-ai/gpt4all)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [GPT4All](https://huggingface.co/spaces/rishiraj/GPT4All) (non-official)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model card: [nomic-ai/gpt4all-lora · Hugging Face](https://huggingface.co/nomic-ai/gpt4all-lora)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 6\. Raven RWKV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Raven RWKV 7B](https://huggingface.co/spaces/BlinkDL/Raven-RWKV-7B) is an
    open-source chatbot that is powered by the [RWKV](https://github.com/BlinkDL/RWKV-LM)
    language model that produces similar results to ChatGPT. The model uses RNNs that
    can match transformers in quality and scaling while being faster and saving VRAM.
    The Raven was fine-tuned on Stanford Alpaca, code-alpaca, and more datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/6a01f233c86592bbba3b085143579e8f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Raven RWKV 7B](https://huggingface.co/spaces/BlinkDL/Raven-RWKV-7B)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'GitHub: [BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [Raven RWKV 7B](https://huggingface.co/spaces/BlinkDL/Raven-RWKV-7B)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model card: [BlinkDL/rwkv-4-raven](https://huggingface.co/BlinkDL/rwkv-4-raven)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7\. OPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[OPT](https://arxiv.org/abs/2205.01068): Open Pre-trained Transformer Language
    Models is not great as ChatGPT, but it has shown remarkable capabilities for zero-
    and few-shot learning and Stereotypical Bias analysis. You can also integrate
    it with Alpa, Colossal-AI, CTranslate2, and FasterTransformer to get even better
    results.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** It is on the list because of its popularity, as it has 624,710 monthly
    downloads in the text generation category.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/b2d85448eb08edd4b5dcdefd49a1ffb1.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [(arxiv.org)](https://arxiv.org/abs/2205.01068)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Research Paper: [OPT: Open Pre-trained Transformer Language Models (arxiv.org)](https://arxiv.org/abs/2205.01068)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [facebookresearch/metaseq](https://github.com/facebookresearch/metaseq)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [A Watermark for LLMs](https://huggingface.co/spaces/tomg-group-umd/lm-watermarking)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model card: [facebook/opt-1.3b](https://huggingface.co/facebook/opt-1.3b)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8\. Flan-T5-XXL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Flan-T5-XXL](https://huggingface.co/google/flan-t5-xxl?text=Q%3A+%28+False+or+not+False+or+False+%29+is%3F+A%3A+Let%27s+think+step+by+step#usage)
    fine-tuned T5 models on a collection of datasets phrased as instructions. The
    instruction fine-tuning dramatically improves performance on a variety of model
    classes such as PaLM, T5, and U-PaLM. The Flan-T5-XXL model is fine-tuned on more
    than 1000 additional tasks covering also more languages.'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 Open-Source Alternative to ChatGPT and Bard](../Images/fcc3022916797e0cf409be15b1274f4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Flan-T5-XXL](https://huggingface.co/google/flan-t5-xxl?text=Q%3A+%28+False+or+not+False+or+False+%29+is%3F+A%3A+Let%27s+think+step+by+step#usage)
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:  **'
  prefs: []
  type: TYPE_NORMAL
- en: 'Research Paper: [Scaling Instruction-Fine Tuned Language Models](https://arxiv.org/pdf/2210.11416.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GitHub: [google-research/t5x](https://github.com/google-research/t5x)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demo: [Chat Llm Streaming](https://huggingface.co/spaces/olivierdehaene/chat-llm-streaming)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Model card: [google/flan-t5-xxl](https://huggingface.co/google/flan-t5-xxl?text=Q%3A+%28+False+or+not+False+or+False+%29+is%3F+A%3A+Let%27s+think+step+by+step)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many open-source options available, and I have mentioned popular ones.
    The open-source chatbots and models are getting better, and in the next few months,
    you will see a new model that can completely overtake ChatGPT in terms of performance.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog, I have provided a list of models/chatbot frameworks that can help
    you train and build chatbots similar to ChatGPT and GPT-4\. Don’t forget to give
    them likes and stars.
  prefs: []
  type: TYPE_NORMAL
- en: Do let me know if you have better suggestions in the comment section. I would
    love to add it in the future.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Top 10 Tools for Detecting ChatGPT, GPT-4, Bard, and Claude](https://www.kdnuggets.com/2023/05/top-10-tools-detecting-chatgpt-gpt4-bard-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChatGPT vs Google Bard: A Comparison of the Technical Differences](https://www.kdnuggets.com/2023/03/chatgpt-google-bard-comparison-technical-differences.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChatGPT vs. BARD](https://www.kdnuggets.com/chatgpt-vs-bard)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenChatKit: Open-Source ChatGPT Alternative](https://www.kdnuggets.com/2023/03/openchatkit-opensource-chatgpt-alternative.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ChatGLM-6B: A Lightweight, Open-Source ChatGPT Alternative](https://www.kdnuggets.com/2023/04/chatglm6b-lightweight-opensource-chatgpt-alternative.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dolly 2.0: ChatGPT Open Source Alternative for Commercial Use](https://www.kdnuggets.com/2023/04/dolly-20-chatgpt-open-source-alternative-commercial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
