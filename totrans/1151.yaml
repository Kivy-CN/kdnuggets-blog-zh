- en: How Machine Learning Leverages Linear Algebra to Solve Data Problems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习如何利用线性代数解决数据问题
- en: 原文：[https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html](https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html](https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![](../Images/bfd423cfaf9f4d27734f99ac1249cbe6.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bfd423cfaf9f4d27734f99ac1249cbe6.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
- en: Machines or your computers only understand numbers and these numbers need to
    be represented and processed in a way that enables these machines to solve problems
    by learning from data instead of predefined instruction as in the case of programming.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器或你的计算机只理解数字，这些数字需要以一种方式表示和处理，使这些机器能够通过从数据中学习来解决问题，而不是像编程中那样依赖预定义的指令。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: All types of programming use mathematics at some level and machine learning
    is programming data to learn the function that best describes the data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有类型的编程在某种程度上都使用数学，而机器学习是编程数据以学习最佳描述数据的函数。
- en: The problem(or process) of finding the best parameters of a function using data
    is called **model training **in ML.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据寻找函数最佳参数的问题（或过程）在机器学习中称为**模型训练**。
- en: Therefore, in a nutshell, machine learning is programming to optimize for the
    best possible solution and we need math to understand how that problem is solved.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总的来说，机器学习是编程以优化最佳解决方案，我们需要数学来理解这个问题是如何解决的。
- en: The first step towards learning Math for ML is Linear algebra.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 学习机器学习数学的第一步是线性代数。
- en: '**Linear Algebra is that mathematical foundation that solves the problem of
    representing data as well as computations in machine learning models.**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性代数是解决数据表示问题以及机器学习模型计算问题的数学基础。**'
- en: '**It is the math of arrays** — technically referred to as vectors, matrices,
    and tensors.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是数组的数学**——从技术上讲，指的是向量、矩阵和张量。'
- en: Common Areas of Application — Linear Algebra in Action
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的应用领域——线性代数的实际应用
- en: '![](../Images/2cc6846103ced3c7a63de659bf1bb505.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cc6846103ced3c7a63de659bf1bb505.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
- en: In the ML context, all major phases of developing a model have linear algebra
    running behind the scenes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，模型开发的所有主要阶段都在幕后运行着线性代数。
- en: 'Important areas of application that are enabled by linear algebra are:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由线性代数启用的重要应用领域包括：
- en: data & learned model representation
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据和学习模型表示
- en: word embeddings
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词嵌入
- en: dimensionality reduction
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维
- en: '**Data Representation — **The fuel of ML models, a.k.a. **data**, needs to
    be converted into arrays before feeding into your models, the computations performed
    on these arrays include operations like matrix multiplication(dot product) which
    further returns the output that is also represented as a transformed matrix/tensor
    of numbers.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据表示——**机器学习模型的燃料，也就是**数据**，在输入模型之前需要转换为数组，这些数组上的计算包括矩阵乘法（点积）等操作，进一步返回的输出也表示为转换后的矩阵/张量的数字。'
- en: '![](../Images/6980b736abcfe8843b2ea518afd11ac8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6980b736abcfe8843b2ea518afd11ac8.png)'
- en: '[https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
- en: '**Word embeddings — **don’t worry about the terminology here, it is just about
    representing large-dimensional data(think of a huge number of variables in your
    data) with a smaller dimensional vector.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**词嵌入 — **不要担心术语，这只是表示高维数据（考虑数据中的大量变量）与较小维度向量的过程。'
- en: Natural Language Processing(NLP) deals with textual data. Dealing with text
    means comprehending the meaning of a large corpus of words and each word represents
    a different meaning which might be similar to another word, vector embeddings
    in linear algebra allow us to represent these words more efficiently.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）处理文本数据。处理文本意味着理解大量词汇的含义，每个词汇代表不同的含义，可能与另一个词汇相似，而线性代数中的向量嵌入允许我们更有效地表示这些词汇。
- en: '**Eigenvectors(SVD)** — Finally, concepts like eigenvectors allow us to reduce
    the number of features or dimensions of the data while keeping the essence of
    all of them using something called **principal component analysis.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征向量（SVD）** — 最终，像特征向量这样的概念允许我们在保持数据本质的同时，减少特征或维度的数量，使用一种叫做**主成分分析**的方法。'
- en: From data to Vectors
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从数据到向量
- en: '![](../Images/f1802792a52cf9c312866fe9bf7e62fb.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1802792a52cf9c312866fe9bf7e62fb.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)'
- en: Linear algebra basically deals with vectors & matrices(different shapes of arrays)
    and operations on these arrays. In NumPy, vectors are basically a 1-Dimensional
    array of numbers but geometrically, this has both magnitude and direction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数基本上处理向量和矩阵（不同形状的数组）以及这些数组上的操作。在NumPy中，向量基本上是一个一维数组，但在几何上，它具有大小和方向。
- en: '![](../Images/c55f7691097e60acd80378bf65d936e4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c55f7691097e60acd80378bf65d936e4.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)'
- en: Our data can be represented using a vector. In the figure above, one row in
    this data is represented by a feature vector that has 3 elements or components
    representing 3 different dimensions. N-entries in a vector make it n-dimensional
    vector space and in this case, we can see 3-dimensions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据可以用向量来表示。在上图中，这些数据的一行由一个特征向量表示，该向量具有3个元素或组件，代表3个不同的维度。向量中的N个条目使其成为n维向量空间，在这种情况下，我们可以看到3个维度。
- en: Deep Learning — Tensors flowing through a neural network
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习 — 张量在神经网络中流动
- en: Linear algebra can be seen in action across all the major applications today,
    be it sentiment analysis on a LinkedIn or a Twitter post(embeddings), be it detecting
    a type of lung infection from X-ray images(computer vision), or any speech to
    text bot(NLP).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数可以在今天的所有主要应用中看到，无论是LinkedIn或Twitter上的情感分析（嵌入），还是从X光图像中检测肺部感染类型（计算机视觉），或任何语音转文本的机器人（NLP）。
- en: All of these data types are represented by numbers in tensors and we run vectorized
    operations to learn patterns from them using a neural network which then outputs
    processed tensor which in turn is decoded to produce the final inference of the
    model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据类型在张量中都由数字表示，我们通过向量化操作来学习其中的模式，使用神经网络处理这些数据，然后输出处理后的张量，进一步解码以产生模型的最终推断。
- en: Dimensionality Reduction — Vector space transformation
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维度减少 — 向量空间转换
- en: '![](../Images/dff6198b90f92fb1cc8be1a17893ad21.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dff6198b90f92fb1cc8be1a17893ad21.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)'
- en: When it comes to embeddings, you can basically think of an n-dimensional vector
    being replaced with another vector that belongs to a lower-dimensional space which
    is more meaningful and the one that overcomes computational complexities.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在嵌入方面，你可以基本上认为n维向量被替换为属于更低维度空间的另一个向量，这种空间更有意义，并且能够克服计算复杂性。
- en: For example, here is a 3-dimensional vector that is replaced by a 2-dimensional
    space but you can extrapolate it to a real-world scenario where you have a very
    large number of dimensions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是一个被2维空间替代的3维向量，但你可以将其推断到现实世界中的场景，其中可能有非常多的维度。
- en: Reducing dimensions doesn’t mean dropping features from the data but finding
    new features that are linear functions of the original features and preserves
    the variance of the original features.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 降维并不意味着从数据中丢弃特征，而是寻找新的特征，这些特征是原始特征的线性函数，并且保留了原始特征的方差。
- en: Finding these new variables(features) translates to finding the principal components(PCs)
    which converge to solving eigenvectors and eigenvalues problems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找这些新变量（特征）意味着寻找主成分（PCs），这些主成分收敛到解决特征向量和特征值问题。
- en: Recommendation Engines — Making use of embeddings
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐引擎 — 利用嵌入
- en: You can think of Embedding as a 2D plane being embedded in a 3D space and that’s
    where this term comes from. You can think of the ground you are standing on as
    a 2D plane that is embedded into this space in which we live.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将嵌入视为一个嵌入在三维空间中的二维平面，这就是这个术语的来源。你可以将你站立的地面视为一个二维平面，嵌入到我们生活的空间中。
- en: Just to give you a real-world use case to relate to all of this discussion on
    vector embeddings, all applications that are giving you personalized recommendations
    are using vector embedding in some form.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅为了给你一个现实世界中的应用来联系所有这些关于向量嵌入的讨论，所有提供个性化推荐的应用程序都在以某种形式使用向量嵌入。
- en: '![](../Images/62fa0dcf8d7b91e435b1e2f2fcef1a39.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62fa0dcf8d7b91e435b1e2f2fcef1a39.png)'
- en: For example, here is a graphic from Google’s course on recommendation systems
    where we are given this data on different users and their preferred movies. Some
    users are kids and others are adults, some movies were are all-time classics while
    others are more artistic. Some movies are targeted towards a younger audience
    while movies like memento are preferred by adults.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是来自谷歌推荐系统课程的一个图示，其中展示了不同用户及其偏爱的电影数据。一些用户是孩子，其他的是成年人，一些电影是经典之作，而其他则更具艺术性。一些电影是面向年轻观众的，而像《记忆碎片》这样的电影则更受成年人喜欢。
- en: Now, we not only need to represent this information in numbers but also need
    to find new smaller dimensional vector representations that capture all these
    features well.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不仅需要用数字表示这些信息，还需要找到新的较小维度的向量表示，这些表示能够很好地捕捉所有这些特征。
- en: '![](../Images/28af5bb2a270796195f820a72973e946.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28af5bb2a270796195f820a72973e946.png)'
- en: 'Source: Google’s Machine Learning Course on recommendation systems'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：谷歌的推荐系统机器学习课程
- en: A very quick way to understand how we can pull this task is by understanding
    something called Matrix Factorization which allows us to break a large matrix
    down into smaller matrices.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 理解如何完成这个任务的一个非常快速的方法是理解所谓的矩阵分解，它允许我们将一个大矩阵拆分成较小的矩阵。
- en: Ignore the numbers and colors for now and just try to understand how we have
    broken down one big matrix into two smaller ones.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在忽略数字和颜色，只需尝试理解我们如何将一个大矩阵拆分成两个较小的矩阵。
- en: For example, here this matrix of 4X5, 4 rows, and 5 features were broken down
    into two matrices, one of the shape 4X2 and the other of shape 2X5\. We basically
    have new smaller dimensional vectors for users and movies.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里这个4X5的矩阵，4行和5个特征被拆分成两个矩阵，一个是4X2的形状，另一个是2X5的形状。我们基本上为用户和电影得到了一些新的较小维度的向量。
- en: '![](../Images/93d13f18bbdb51854a94c4f4aee7cdee.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93d13f18bbdb51854a94c4f4aee7cdee.png)'
- en: 'And this allows us to plot this on a 2D vector space, and here you’ll see that
    user #1 and the movie Harry Potter are closer and user #3 and the movie Shrek
    are closer.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够在二维向量空间中绘制图形，你会看到用户#1和电影《哈利·波特》更接近，而用户#3和电影《怪物史莱克》也更接近。
- en: The concept of **dot product(matrix multiplication)** of vectors tells us more
    about the similarity of two vectors. And it has applications in correlation/covariance
    calculation, linear regression, logistic regression, PCA, convolutions, PageRank,
    and numerous other algorithms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**点积（矩阵乘法）**的概念告诉我们关于两个向量的相似性更多信息。它在相关性/协方差计算、线性回归、逻辑回归、主成分分析、卷积、PageRank以及众多其他算法中有应用。'
- en: Industries where you see LA being used heavily
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在哪里看到线性代数被广泛使用的行业
- en: 'By now, I hope you are convinced that Linear algebra is driving the ML initiatives
    in a host of areas today. If not, here is a list to name a few:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我希望你已经相信线性代数正在驱动今天许多领域的机器学习计划。如果还没有，以下是一些领域的列表：
- en: Statistics
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计学
- en: Chemical Physics
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 化学物理学
- en: Genomics
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因组学
- en: Word Embeddings — neural networks/deep learning
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词嵌入 — 神经网络/深度学习
- en: Robotics
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人技术
- en: Image Processing
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像处理
- en: Quantum Physics
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量子物理学
- en: How much should you know to get started with ML / DL
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始学习机器学习/深度学习你需要知道多少
- en: Now, the important question is how can you learn to program these concepts of
    linear algebra. So, the answer is you don’t have to reinvent the wheel, you just
    need to understand the basics of vector algebra computationally and you then learn
    to program those concepts using NumPy.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，重要的问题是你如何学习编程这些线性代数概念。因此，答案是你不需要重新发明轮子，你只需要从计算的角度理解向量代数的基础，然后用NumPy学习编程这些概念。
- en: NumPy is a scientific computation package that gives us access to all the underlying
    concepts of linear algebra. It is fast as it runs compiled C code and it has a
    large number of mathematical and scientific functions that we can use.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy是一个科学计算包，提供了线性代数所有基础概念的访问权限。它运行编译过的C代码，因此速度很快，并且具有大量可以使用的数学和科学函数。
- en: Recommended resources
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐资源
- en: '[**Playlist on Linear Algebra by 3Blue1Brown**](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B)—
    very engaging visualizations that explain the essence of linear algebra and its
    applications. Might be a little too hard for beginners.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**3Blue1Brown的线性代数播放列表**](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B)
    — 非常吸引人的可视化，解释了线性代数的本质及其应用。对初学者来说可能有点难。'
- en: '[**Book on Deep Learning by Ian Goodfellow & Yoshua Bengio**](https://www.deeplearningbook.org/)** —** a
    fantastic resource for learning ML and applied math. Give it a read, few folks
    may find it too technical and notation-heavy, to begin with.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**伊恩·古德费洛和约书亚·本吉奥的深度学习书籍**](https://www.deeplearningbook.org/)** —** 这是学习机器学习和应用数学的极佳资源。阅读它时，刚开始可能会觉得有些技术性和符号密集。'
- en: '[**Foundations of Data Science & ML —**](https://www.wiplane.com/p/foundations-for-data-science-ml) I
    have created a course that gives you enough understanding of Programming, Math(Basic
    Algebra, Linear Algebra & Calculus), and Statistics. A complete package for the
    first steps to learning DS/ML. Learn more [**here**](https://www.wiplane.com/p/foundations-for-data-science-ml).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据科学与机器学习基础 —**](https://www.wiplane.com/p/foundations-for-data-science-ml) 我创建了一门课程，提供了编程、数学（基础代数、线性代数与微积分）和统计学的充分理解。这是学习数据科学/机器学习的第一步的完整包。了解更多 [**这里**](https://www.wiplane.com/p/foundations-for-data-science-ml)。'
- en: ???? You can use the code `TDS10` to get 10% off.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ???? 你可以使用代码`TDS10`获得10%的折扣。
- en: 'Check out the course outline:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 查看课程大纲：
- en: '**Bio: [Harshit Tyagi](https://www.linkedin.com/in/tyagiharshit/)** is an engineer
    with amalgamated experience in web technologies and data science(aka full-stack
    data science). He has mentored over 1000 AI/Web/Data Science aspirants, and is
    designing data science and ML engineering learning tracks. Previously, Harshit
    developed data processing algorithms with research scientists at Yale, MIT, and
    UCLA.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Harshit Tyagi](https://www.linkedin.com/in/tyagiharshit/)** 是一位在网络技术和数据科学（即全栈数据科学）方面有着融合经验的工程师。他已经指导了1000多名AI/网络/数据科学
    aspirants，并正在设计数据科学和机器学习工程学习路径。此前，Harshit与耶鲁大学、麻省理工学院和UCLA的研究科学家合作开发数据处理算法。'
- en: '[Original](https://dswharshit.medium.com/how-machine-learning-leverages-linear-algebra-to-solve-data-problems-4e210a644508).
    Reposted with permission.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://dswharshit.medium.com/how-machine-learning-leverages-linear-algebra-to-solve-data-problems-4e210a644508)。经许可转载。'
- en: '**Related:**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Data Science Learning Roadmap for 2021](/2021/02/data-science-learning-roadmap-2021.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年数据科学学习路线图](/2021/02/data-science-learning-roadmap-2021.html)'
- en: '[Linear Algebra for Natural Language Processing](/2021/08/linear-algebra-natural-language-processing.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理中的线性代数](/2021/08/linear-algebra-natural-language-processing.html)'
- en: '[Antifragility and Machine Learning](/2021/09/antifragility-machine-learning.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[反脆弱性与机器学习](/2021/09/antifragility-machine-learning.html)'
- en: More On This Topic
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[想用你的数据技能解决全球问题？这里是…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学项目可以帮助你解决现实世界的问题](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
- en: '[Top 3 Free Resources to Learn Linear Algebra for Machine Learning](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习机器学习中的线性代数的前三个免费资源](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
- en: '[KDnuggets News, July 13: Linear Algebra for Data Science; 10 Modern…](https://www.kdnuggets.com/2022/n28.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，7月13日：数据科学的线性代数；10种现代…](https://www.kdnuggets.com/2022/n28.html)'
- en: '[Linear Algebra for Data Science](https://www.kdnuggets.com/2022/07/linear-algebra-data-science.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的线性代数](https://www.kdnuggets.com/2022/07/linear-algebra-data-science.html)'
- en: '[5 Free Courses to Master Linear Algebra](https://www.kdnuggets.com/2022/10/5-free-courses-master-linear-algebra.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握线性代数的5门免费课程](https://www.kdnuggets.com/2022/10/5-free-courses-master-linear-algebra.html)'
