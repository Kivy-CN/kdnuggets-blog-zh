- en: 'Introducing OpenLLM: Open Source Library for LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 OpenLLM：LLM 的开源库
- en: 原文：[https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)
- en: '![Introducing OpenLLM: Open Source Library for LLMs](../Images/1efb563e445901db6e7d4ada83d0ed00.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![介绍 OpenLLM：LLM 的开源库](../Images/1efb563e445901db6e7d4ada83d0ed00.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: At this point, we’re all thinking the same thing. Is the world of LLMs really
    taking over? Some of you may have expected the hype to plateau, but it is still
    on the continuous rise. More resources are going into LLMs as it has shown a huge
    demand.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们都在思考同一个问题。LLM 的世界真的在主导吗？一些人可能预计热度会平稳，但它仍在持续上升。更多资源投入到 LLM 中，因为它显示出巨大的需求。
- en: Not only has the performance of LLMs been successful, but also their versatility
    in being able to adapt to various NLP tasks such as translation and sentiment
    analysis. Fine-tuning pre-trained LLMs has made it much easier for specific tasks,
    making it less computationally expensive to build a model from scratch. LLMs have
    swiftly been implemented into various real-world applications, boosting the amount
    of research and development.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 的性能不仅成功，而且它们在适应各种 NLP 任务（如翻译和情感分析）方面的多功能性也非常强。微调预训练的 LLM 使得针对特定任务变得更加容易，减少了从头构建模型的计算成本。LLM
    已迅速被应用于各种现实世界应用，推动了研究和开发的数量。
- en: Open-source models have also been a big plus with LLMs, as the availability
    of open-source models has allowed researchers and organizations to continuously
    improve existing models, and how they can be safely integrated into society.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型也是 LLM 的一个重要优势，因为开源模型的可用性使研究人员和组织能够持续改进现有模型，并探索它们如何安全地融入社会。
- en: What is OpenLLM?
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 OpenLLM？
- en: '[OpenLLM](https://github.com/bentoml/OpenLLM) is an open platform for operating
    LLMs in production. Using OpenLLM, you can run inference on any open-source LLMs,
    fine-tune them, deploy, and build powerful AI apps with ease.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenLLM](https://github.com/bentoml/OpenLLM) 是一个用于生产环境中操作 LLM 的开放平台。使用 OpenLLM，您可以对任何开源
    LLM 进行推理、微调、部署，并轻松构建强大的 AI 应用程序。'
- en: OpenLLM contains state-of-the-art LLMs, such as StableLM, Dolly, ChatGLM, StarCoder
    and more, which are all supported by built-in support. You also have the freedom
    to build your own AI application, as OpenLLM is not just a standalone product
    and supports LangChain, BentoML, and Hugging Face.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: OpenLLM 包含最先进的 LLM，如 StableLM、Dolly、ChatGLM、StarCoder 等，所有这些都由内置支持。您还可以自由构建自己的
    AI 应用程序，因为 OpenLLM 不仅仅是一个独立产品，还支持 LangChain、BentoML 和 Hugging Face。
- en: All these features, and it’s open-source? Sounds a bit crazy right?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能，还开源？听起来有点疯狂，对吧？
- en: And to top it, it’s easy to install and use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 更棒的是，它易于安装和使用。
- en: How to Use OpenLLM?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 OpenLLM？
- en: To make use of LLM, you will need to have at least Python 3.8, as well as pip
    installed on your system. To prevent package conflicts, it is recommended that
    you use a virtual environment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 LLM，您需要系统中至少安装 Python 3.8 以及 pip。为了防止包冲突，建议使用虚拟环境。
- en: 'Once you have these ready, you can easily install OpenLLM by using the following
    command:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦准备好这些，您可以通过使用以下命令轻松安装 OpenLLM：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To ensure that it has been installed correctly, you can run the following command:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为确保正确安装，可以运行以下命令：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In order to start an LLM server, use the following command including the model
    of your choice:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了启动一个 LLM 服务器，请使用以下命令，并包括您选择的模型：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For example, if you’d like to start an [OPT](https://huggingface.co/docs/transformers/model_doc/opt)
    server, do the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您想启动一个 [OPT](https://huggingface.co/docs/transformers/model_doc/opt) 服务器，请执行以下操作：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Supported Models
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的模型
- en: '10 models are supported in OpenLLM. You can also find the installation commands
    below:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: OpenLLM 支持 10 种模型。您还可以在下方找到安装命令：
- en: '[chatglm](https://github.com/THUDM/ChatGLM-6B)'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[chatglm](https://github.com/THUDM/ChatGLM-6B)'
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This model requires a GPU.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型需要 GPU。
- en: '[Dolly-v2](https://github.com/databrickslabs/dolly)'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Dolly-v2](https://github.com/databrickslabs/dolly)'
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This model can be used on both CPU and GPU.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以在 CPU 和 GPU 上使用。
- en: '[falcon](https://falconllm.tii.ae/)'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[falcon](https://falconllm.tii.ae/)'
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This model requires a GPU.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型需要 GPU。
- en: '[flan-t5](https://huggingface.co/docs/transformers/model_doc/flan-t5)'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[flan-t5](https://huggingface.co/docs/transformers/model_doc/flan-t5)'
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This model can be used on both CPU and GPU.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以在 CPU 和 GPU 上使用。
- en: '[gpt-neox](https://github.com/EleutherAI/gpt-neox)'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[gpt-neox](https://github.com/EleutherAI/gpt-neox)'
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This model requires a GPU.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型需要一个 GPU。
- en: '[mpt](https://huggingface.co/mosaicml)'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[mpt](https://huggingface.co/mosaicml)'
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This model can be used on both CPU and GPU.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型可以在 CPU 和 GPU 上使用。
- en: '[opt](https://huggingface.co/docs/transformers/model_doc/opt)'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[opt](https://huggingface.co/docs/transformers/model_doc/opt)'
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This model can be used on both CPU and GPU.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型可以在 CPU 和 GPU 上使用。
- en: '[stablelm](https://github.com/Stability-AI/StableLM)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[stablelm](https://github.com/Stability-AI/StableLM)'
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This model can be used on both CPU and GPU.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型可以在 CPU 和 GPU 上使用。
- en: '[starcoder](https://github.com/bigcode-project/starcoder)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[starcoder](https://github.com/bigcode-project/starcoder)'
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This model requires a GPU.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型需要一个 GPU。
- en: '[baichuan](https://github.com/baichuan-inc/Baichuan-7B)'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[baichuan](https://github.com/baichuan-inc/Baichuan-7B)'
- en: '[PRE13]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This model requires a GPU.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型需要一个 GPU。
- en: To find out more information about runtime implementations, fine-tuning support,
    integrating a new model, and deploying to production - please have a look [here](https://github.com/bentoml/OpenLLM#runtime-implementations-experimental)
    at the one that caters to your needs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关运行时实现、微调支持、集成新模型和生产部署的更多信息，请查看 [这里](https://github.com/bentoml/OpenLLM#runtime-implementations-experimental)，找到适合你需求的方案。
- en: Wrapping it up
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结一下
- en: If you’re looking to use OpenLLM or need some assistance, you can reach out
    and join their [Discord](https://l.bentoml.com/join-openllm-discord) and [Slack
    community](https://l.bentoml.com/join-slack). You can also contribute to OpenLLM's
    codebase using their [Developer Guide](https://github.com/bentoml/OpenLLM/blob/main/DEVELOPMENT.md).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用 OpenLLM 或需要帮助，你可以加入他们的 [Discord](https://l.bentoml.com/join-openllm-discord)
    和 [Slack 社区](https://l.bentoml.com/join-slack)。你也可以通过他们的 [开发者指南](https://github.com/bentoml/OpenLLM/blob/main/DEVELOPMENT.md)
    为 OpenLLM 的代码库做贡献。
- en: Has anybody tried it yet? If you have, let us know what you think in the comments!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有人试过这个？如果试过，请在评论中告诉我们你的想法！
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist,
    Freelance Technical Writer and Community Manager at KDnuggets. She is particularly
    interested in providing Data Science career advice or tutorials and theory based
    knowledge around Data Science. She also wishes to explore the different ways Artificial
    Intelligence is/can benefit the longevity of human life. A keen learner, seeking
    to broaden her tech knowledge and writing skills, whilst helping guide others.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家、自由技术写作者以及
    KDnuggets 的社区经理。她特别感兴趣于提供数据科学职业建议或教程以及有关数据科学的理论知识。她还希望探索人工智能如何/能如何有利于人类寿命的不同方式。她是一位渴望学习者，寻求拓宽自己的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关信息
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 Objectiv：开源产品分析基础设施](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
- en: '[Introducing MPT-7B: A New Open-Source LLM](https://www.kdnuggets.com/2023/05/introducing-mpt7b-new-opensource-llm.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 MPT-7B：一个新的开源 LLM](https://www.kdnuggets.com/2023/05/introducing-mpt7b-new-opensource-llm.html)'
- en: '[Introducing MetaGPT''s Data Interpreter: SOTA Open Source LLM-based…](https://www.kdnuggets.com/metagpt-data-interpreter-open-source-llm-based-data-solutions)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 MetaGPT 的数据解释器：SOTA 开源 LLM 基于……](https://www.kdnuggets.com/metagpt-data-interpreter-open-source-llm-based-data-solutions)'
- en: '[Introducing the Testing Library for Natural Language Processing](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍自然语言处理测试库](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
- en: '[RedPajama Project: An Open-Source Initiative to Democratizing LLMs](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama 项目：一个开源倡议，旨在普及 LLMs](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)'
- en: '[Falcon LLM: The New King of Open-Source LLMs](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Falcon LLM：开源 LLM 的新王者](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
