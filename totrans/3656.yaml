- en: 'Transforming AI with LangChain: A Text Data Game Changer'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用LangChain变革AI：文本数据的游戏改变者
- en: 原文：[https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html](https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html](https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html)
- en: '![XXXXX](../Images/fae8bf3635873f99b3b132732050fed6.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/fae8bf3635873f99b3b132732050fed6.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Over the past few years, Large Language Models — or LLMs for friends — **have
    taken the world of artificial intelligence by storm. **
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，大型语言模型——或者说是朋友们的LLM——**以其风靡的姿态席卷了人工智能领域。**
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: With the groundbreaking release of OpenAI’s GPT-3 in 2020, we have witnessed
    a steady surge in the popularity of LLMs, which has only intensified with recent
    advancements in the field.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着2020年OpenAI发布GPT-3的突破性进展，我们见证了LLM的流行稳步上升，最近该领域的进步更是加剧了这一趋势。
- en: '**These powerful AI models have opened up new possibilities for natural language
    processing applications**, enabling developers to create more sophisticated, human-like
    interactions.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**这些强大的AI模型为自然语言处理应用开辟了新的可能性**，使开发者能够创建更复杂、更像人类的互动。'
- en: '***Isn’t it?***'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '***不是吗？***'
- en: However, when dealing with this AI technology it is hard to scale and generate
    reliable algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在处理这种AI技术时，很难扩展和生成可靠的算法。
- en: Amidst this rapidly evolving landscape, **LangChain has emerged as a versatile
    framework designed to help developers harness the full potential of LLMs for a
    wide range of applications. One of the most important use cases is to deal with
    large** **amounts** **of text data.**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个快速发展的环境中，**LangChain作为一个多功能框架应运而生，旨在帮助开发者充分利用LLM的潜力，应用于各种场景。其中最重要的用例之一就是处理大量**
    **的文本数据。**
- en: Let’s dive in and start harnessing the power of LLMs today!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解并开始利用LLM的力量吧！
- en: LangChain can be used in chatbots, question-answering systems, summarization
    tools, and beyond. **However, one of the most useful - and used - applications
    of LangChain is dealing with text.**
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain可以用于聊天机器人、问答系统、总结工具等。**然而，LangChain最有用且最常用的应用之一就是处理文本。**
- en: Today’s world is flooded with data. And one of the most notorious types is text
    data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当今世界充斥着数据。而最臭名昭著的一种数据是文本数据。
- en: All websites and apps are being bombed with tons and tons of words every single
    day. No human can process this amount of information…
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所有网站和应用每天都被大量文字轰炸。没有人能处理这么多信息……
- en: '**But can computers?**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**但计算机能做到吗？**'
- en: LLM techniques together with LangChain are a great way to reduce the amount
    of text while maintaining the most important parts of the message. This is why
    today we will cover two basic — but really useful — use cases of LangChain to
    deal with text.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LLM技术与LangChain结合，是减少文本量同时保留信息核心的好方法。这就是为什么今天我们将探讨LangChain的两个基本但非常实用的文本处理用例。
- en: '**Summarization:** Express the most important facts about a body of text or
    chat interaction. It can reduce the amount of data while maintaining the most
    important parts.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结：** 表达一段文本或聊天互动中最重要的事实。它可以减少数据量，同时保留最重要的部分。'
- en: '**Extraction:** Pull structured data from a body of text or some user query.
    It can detect and extract keywords within the text.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提取：** 从一段文本或用户查询中提取结构化数据。它可以在文本中检测并提取关键词。'
- en: Whether you’re new to the world of LLMs or looking to take your language generation
    projects to the next level, this guide will provide you with valuable insights
    and hands-on examples to unlock the full potential of LangChain to deal with text.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是对LLM世界感到陌生还是希望将你的语言生成项目提升到一个新水平，本指南将为你提供宝贵的见解和动手示例，帮助你充分发挥LangChain处理文本的潜力。
- en: ⚠️ If you want to have some basic grasp, you can go check ????????
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ⚠️ 如果你想了解一些基础知识，可以查看 ????????
- en: '[**LangChain 101: Build Your Own GPT-Powered Applications — KDnuggets**](/2023/04/langchain-101-build-gptpowered-applications.html)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[**LangChain 101：构建你自己的GPT驱动应用程序 — KDnuggets**](/2023/04/langchain-101-build-gptpowered-applications.html)'
- en: Always remember that for working with OpenAI and GPT models, we need to have
    the OpenAI library installed on our local computer and have an active OpenAI key.
    If you do not know how to do that, you can go check [here](https://medium.com/@rfeers/openai-a-step-by-step-guide-to-getting-your-api-key-gpt-usage-control-artificial-intelligence-2a0917c70f3f).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 请始终记住，要使用OpenAI和GPT模型，我们需要在本地计算机上安装OpenAI库，并拥有一个有效的OpenAI密钥。如果你不知道如何操作，可以查看[这里](https://medium.com/@rfeers/openai-a-step-by-step-guide-to-getting-your-api-key-gpt-usage-control-artificial-intelligence-2a0917c70f3f)。
- en: 1\. Summarization
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 总结
- en: ChatGPT together with LangChain **can summarize information quickly and in a
    very reliable way. **
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT结合LangChain**可以快速且非常可靠地总结信息。**
- en: LLM summarization techniques are a great way to reduce the amount of text while
    maintaining the most important parts of the message. This is why LLMs can be the
    best ally to any digital company that needs to process and analyze large volumes
    of  text data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: LLM总结技术是一种减少文本量同时保留消息最重要部分的好方法。这就是为什么LLM可以成为任何需要处理和分析大量文本数据的数字公司的最佳盟友。
- en: 'To perform the following examples, the following libraries are required:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下示例所需的库有：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 1.1\. Short text summarization
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1\. 简短文本总结
- en: For summaries of short texts, the method is straightforward, in fact, you don’t
    need to do anything fancy other than simple prompting with instructions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于短文本的总结，这种方法很简单，实际上，你只需要简单地进行提示并附上指令即可。
- en: Which basically means generating a template with an input variable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上意味着生成一个带有输入变量的模板。
- en: I know you might be wondering… **what is exactly a prompt template?**
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道你可能在想……**什么是提示模板？**
- en: A prompt template refers to a reproducible way to generate a prompt. It contains
    a text string - a template - that can take in a set of parameters from the end
    user and generates a prompt.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 提示模板指的是一种可重复生成提示的方式。它包含一个文本字符串——模板——可以接受来自最终用户的一组参数并生成提示。
- en: 'A prompt template contains:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 提示模板包含：
- en: '**instructions to the language model** - that allow us to standardize some
    steps for our LLM.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对语言模型的指令** - 允许我们标准化一些步骤，以便于我们的LLM。'
- en: '**an input variable** -  that allows us to apply the previous instructions
    to any input text.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入变量** - 允许我们将先前的指令应用于任何输入文本。'
- en: Let’s see this in a simple example. I can standardize a prompt that generates
    a name of a brand that produces a specific product.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个简单的例子中看看。我可以标准化一个生成特定产品品牌名称的提示。
- en: '![XXXXX](../Images/1c86fcb34a81da268a6f7bb73f911bcc.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/1c86fcb34a81da268a6f7bb73f911bcc.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我Jupyter Notebook的截图。
- en: As you can observe in the previous example, the magic of LangChain is that we
    can define a standardized prompt with a changing input variable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在之前的例子中看到的，LangChain的魔力在于我们可以定义一个带有变化的输入变量的标准化提示。
- en: The instructions to generate a name for a brand remain always the same.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成品牌名称的指令始终保持不变。
- en: The product variable works as an input that can be changed.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品变量作为一个可以改变的输入。
- en: This allows us to define versatile prompts that can be used in different scenarios.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够定义多功能的提示，可在不同的场景中使用。
- en: '*So now that we know what a prompt template is… *'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*所以现在我们知道什么是提示模板了……*'
- en: Let’s imagine we want to define a prompt that summarizes any text using super
    easy-to-understand vocabulary. We can define a prompt template with some specific
    instructions and a text variable that changes depending on the input variable
    we define.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设想一下我们想要定义一个总结任何文本的提示，该提示使用超级易懂的词汇。我们可以定义一个包含一些具体指令和一个根据输入变量定义而变化的文本变量的提示模板。
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So let’s try this prompt template. Using the wikipedia API, I am going to get
    the summary of the USA country and further summarize it in a really easy-to-understand
    tone.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们尝试这个提示模板。使用维基百科API，我将获取美国的摘要，并以一种非常易于理解的语气进一步总结。
- en: '![XXXXX](../Images/796b446babb8aea865223f36c584ae3d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/796b446babb8aea865223f36c584ae3d.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我在Jupyter Notebook中的截图。
- en: So now that we know how to summarize a short text… can I spice this up a bit?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道如何总结短文本……我可以稍微增加一些内容吗？
- en: '*Sure we can with… *'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*当然可以……*'
- en: 1.2\. Long text summarization
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2. 长文本总结
- en: When dealing with long texts, the main problem is that we cannot communicate
    them to our AI model directly via prompt, as they contain too many tokens.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理长文本时，主要的问题是我们无法通过提示直接将它们传达给我们的AI模型，因为它们包含了太多的tokens。
- en: '*And now you might be wondering… what is a token?*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*现在你可能会想……什么是token？*'
- en: Tokens are how the model sees the input — single characters, words, parts of
    words, or segments of text. As you can observe, the definition is not really precise
    and it depends on every model. For instance, OpenAI’s GPT 1000 tokens are approximately
    750 words.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Tokens是模型如何查看输入的方式——单个字符、单词、单词的部分或文本片段。如你所见，定义并不是很精确，这取决于每个模型。例如，OpenAI的GPT中1000
    tokens大约是750个单词。
- en: But the most important thing to learn is that our cost depends on the number
    of tokens and that we cannot send as many tokens as we want in a single prompt. 
    To have a longer text, we will repeat the same example as before but using the
    whole Wikipedia page text.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但最重要的是，我们的费用取决于tokens的数量，而且我们不能在单个提示中发送过多的tokens。为了处理更长的文本，我们将重复之前的示例，但使用整个维基百科页面的文本。
- en: '![XXXXX](../Images/fb4c7a2f319dd269e3149f4a4aafbf76.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/fb4c7a2f319dd269e3149f4a4aafbf76.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我在Jupyter Notebook中的截图。
- en: If we check how long it is… it is around 17K tokens.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查它有多长……大约是17K tokens。
- en: Which is quite a lot to be sent directly to our API.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是非常多的，不能直接发送到我们的API。
- en: '*So what now?*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*那现在怎么办？*'
- en: First, we’ll need to split it up. This process is called **chunking** or **splitting**
    your text into smaller pieces. I usually use [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)
    because it’s easy to control but there are a [bunch](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html)
    you can try.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要将其拆分。这一过程称为**chunking**或**splitting**你的文本为更小的片段。我通常使用[RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)，因为它易于控制，但你可以尝试很多其他的[工具](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html)。
- en: After using it, instead of just having a single piece of text, we get 23 pieces
    which facilitate the work of our GPT model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用它之后，我们不再只有一段文本，而是得到了23段，这有助于我们GPT模型的工作。
- en: Next we need to load up a chain which will make successive calls to the LLM
    for us.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们需要加载一个链，它会为我们进行连续调用LLM。
- en: 'LangChain provides the Chain interface for such **chained** applications. We
    define a Chain very generically as a sequence of calls to components, which can
    include other chains. The base interface is simple:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain为此类**链式**应用提供了Chain接口。我们非常泛泛地定义一个Chain为对组件的调用序列，这些组件可以包括其他链。基本接口很简单：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you want to learn more about chains, you can go check directly in the [LangChain
    documentation. ](https://python.langchain.com/docs/get_started/introduction.html)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于链的信息，可以直接查看[LangChain文档。](https://python.langchain.com/docs/get_started/introduction.html)
- en: So if we repeat again the same procedure with the splitted text - called docs
    - the LLM can easily generate a summary of the whole page.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们再次重复相同的程序，使用被拆分的文本——称为docs——LLM可以轻松生成整个页面的摘要。
- en: '![XXXXX](../Images/dff9ad393005d1e90ee5bf3a9f423920.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/dff9ad393005d1e90ee5bf3a9f423920.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我在Jupyter Notebook中的截图。
- en: '*Useful right?*'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*有用吧？*'
- en: So now that we know how to summarize text, we can move to the second use case!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道如何总结文本，我们可以进入第二个用例了！
- en: 2\. Extraction
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 提取
- en: Extraction is the process of parsing data from a piece of text. This is commonly
    used with output parsing to *structure* our data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 提取是从文本片段中解析数据的过程。这通常与输出解析一起使用，以*结构化*我们的数据。
- en: Extracting key data is really useful in order to identify and parse key words
    within a text.  Common use cases are extracting a structured row from a sentence
    to insert into a database or extracting multiple rows from a long document to
    insert into a database.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 提取关键信息对于识别和解析文本中的关键词非常有用。 常见的用例包括从句子中提取结构化的行以插入数据库，或从长文档中提取多行以插入数据库。
- en: Let’s imagine we are running a digital e-commerce company and we need to process
    all reviews that are stated on our website.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在运营一个数字电子商务公司，需要处理我们网站上所有的评论。
- en: '**I could go read all of them one by one… which would be crazy. **'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**我可以逐一查看所有内容……这将是疯狂的。**'
- en: '*Or I can simply EXTRACT the information that I need from each of them and
    analyze all the data. *'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*或者我可以简单地提取我需要的信息，并分析所有数据。*'
- en: Sounds easy… right?
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很简单……对吧？
- en: 'Let’s start with a quite simple example. First, we need to import the following
    libraries:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个非常简单的示例开始。首先，我们需要导入以下库：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 2.1\. Extracting specific words
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. 提取特定词汇
- en: I can try to look for specific words within some text. In this case, I want
    to parse all fruits that are contained within a text.  Again, it is quite straightforward
    as before. We can easily define a prompt giving clear instructions to our LLM
    stating that identifies all fruits contained in a text and gives back a JSON-like
    structure containing such fruits and their corresponding colors.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以尝试在文本中查找特定的词汇。在这种情况下，我想解析文本中包含的所有水果。再次，这非常直接。我们可以轻松定义一个提示，给出明确的指令，让我们的 LLM
    识别文本中包含的所有水果，并返回一个包含这些水果及其对应颜色的类似 JSON 的结构。
- en: '![XXXXX](../Images/1bab02cad584e793442e4d6652b3961e.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/1bab02cad584e793442e4d6652b3961e.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我的 Jupyter Notebook 截图。
- en: And as we can see before, it works perfectly!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所见，这效果很好！
- en: So now… let’s play a little bit more with it. While this worked this time, it’s
    not a long term reliable method for more advanced use cases. And this is where
    a fantastic LangChain concept comes into play…
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在……让我们再玩一下。虽然这次效果很好，但对于更高级的用例，它不是一种长期可靠的方法。这时，一个出色的 LangChain 概念就派上用场了……
- en: 2.2\. Using LangChain’s Response Schema
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. 使用 LangChain 的响应模式
- en: 'LangChain’s response schema will do two main things for us:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的响应模式将为我们做两件主要的事情：
- en: '**Generate a prompt with bonafide format instructions.** This is great because
    I don’t need to worry about the prompt engineering side, I’ll leave that up to
    LangChain!'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成一个带有真实格式指令的提示。** 这很好，因为我不需要担心提示工程方面的事情，我会把它留给 LangChain！'
- en: '**Read the output from the LLM and turn it into a proper python object for
    me.** Which means, always generate a given structure that is useful and that my
    system can parse.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从 LLM 读取输出并将其转化为合适的 Python 对象。** 这意味着，总是生成一个有用的结构，以便我的系统可以解析。'
- en: '**And to do so, I just need to define what response I except from the model. **'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**为了做到这一点，我只需要定义我期望从模型中获得的响应。**'
- en: So let’s imagine I want to determine the products and brands that users are
    stating in their comments. I could easily perform as before with a simple prompt
    - take advantage of LangChain to generate a more reliable method.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，假设我想确定用户评论中提到的产品和品牌。我可以像以前一样使用简单的提示 - 利用 LangChain 生成更可靠的方法。
- en: So first I need to define a response_schema where I define every keyword I want
    to parse with a name and a description.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我需要定义一个 `response_schema`，在其中定义我想解析的每一个关键字的名称和描述。
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After defining our parser, we generate the format of our instruction using the
    .get_format_instructions() command from LangChain and define the final prompt
    using the ChatPromptTemplate. And now it is as easy as using this output_parser
    object with any input query I can think of, and it will automatically generate
    an output with my desired keywords.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义我们的解析器之后，我们使用 LangChain 的 .get_format_instructions() 命令生成指令格式，并使用 ChatPromptTemplate
    定义最终提示。现在，只需使用这个 output_parser 对象和我想到的任何输入查询，它就会自动生成包含我所需关键字的输出。
- en: '![XXXXX](../Images/cf56304ad3a4912ba5cb6bbcd3ebaa4c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/cf56304ad3a4912ba5cb6bbcd3ebaa4c.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我的 Jupyter Notebook 截图。
- en: 'As you can observe in the example below, with the input of “I run out of Yogurt
    Danone, No-brand Oat Milk and those vegan bugers made by Heura”, the LLM gives
    me the following output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如下面的示例所示，输入为“我用完了 Danone 酸奶、无品牌燕麦奶以及 Heura 制造的那些素食汉堡”，LLM 给出的输出如下：
- en: '![XXXXX](../Images/17bdd2865f3f9ccc6c3eca312c694ac3.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/17bdd2865f3f9ccc6c3eca312c694ac3.png)'
- en: Screenshot of my Jupyter Notebook.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我的Jupyter Notebook截图。
- en: Main Takeaways
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要要点
- en: LangChain is a versatile Python library that helps developers harness the full
    potential of LLMs, especially for dealing with large amounts of text data. It
    excels at two main use cases for dealing with text. LLMs enable developers to
    create more sophisticated and human-like interactions in natural language processing
    applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是一个多功能的Python库，帮助开发者充分利用LLMs，特别是在处理大量文本数据时。它在处理文本方面表现出色。LLMs使开发者能够在自然语言处理应用中创建更复杂和类人化的交互。
- en: 'Summarization: **LangChain can quickly and reliably summarize information**,
    reducing the amount of text while preserving the most important parts of the message.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结：**LangChain可以快速而可靠地总结信息**，减少文本量，同时保留信息中最重要的部分。
- en: 'Extraction: **The library can parse data from a piece of text, allowing for
    structured output** and enabling tasks like inserting data into a database or
    making API calls based on extracted parameters.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取：**该库可以解析文本中的数据，允许结构化输出**，并支持将数据插入数据库或根据提取的参数进行API调用等任务。
- en: LangChain facilitates prompt engineering, which is a crucial technique for maximizing
    the performance of AI models like ChatGPT. With prompt engineering, developers
    can design standardized prompts that can be reused across different use cases,
    making the AI application more versatile and effective.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LangChain促进了提示工程，这是一项关键技术，用于最大化像ChatGPT这样的AI模型的性能。通过提示工程，开发者可以设计可以在不同用例中重复使用的标准化提示，从而使AI应用更加多功能和高效。
- en: Overall, LangChain serves as a powerful tool to enhance AI usage, especially
    when dealing with text data, and prompt engineering is a key skill for effectively
    leveraging AI models like ChatGPT in various applications.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，LangChain作为一个强大的工具，可以增强AI的使用，尤其是在处理文本数据时，而提示工程是有效利用像ChatGPT这样的AI模型在各种应用中的关键技能。
- en: '**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)** is an
    analytics engineer from Barcelona. He graduated in physics engineering and is
    currently working in the Data Science field applied to human mobility. He is a
    part-time content creator focused on data science and technology. You can contact
    him on [LinkedIn](https://www.linkedin.com/in/josep-ferrer-sanchez/), [Twitter](https://twitter.com/rfeers)
    or [Medium](https://medium.com/@rfeers).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)** 是一位来自巴塞罗那的分析工程师。他毕业于物理工程专业，目前在应用于人类流动性的Data
    Science领域工作。他是一名兼职内容创作者，专注于数据科学和技术。你可以通过[LinkedIn](https://www.linkedin.com/in/josep-ferrer-sanchez/)、[Twitter](https://twitter.com/rfeers)或[Medium](https://medium.com/@rfeers)与他联系。'
- en: More On This Topic
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Breaking the Data Barrier: How Zero-Shot, One-Shot, and Few-Shot…](https://www.kdnuggets.com/2023/08/breaking-data-barrier-zeroshot-oneshot-fewshot-learning-transforming-machine-learning.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[打破数据壁垒：零样本、单样本和少样本…](https://www.kdnuggets.com/2023/08/breaking-data-barrier-zeroshot-oneshot-fewshot-learning-transforming-machine-learning.html)'
- en: '[The AIoT Revolution: How AI and IoT Are Transforming Our World](https://www.kdnuggets.com/2022/07/aiot-revolution-ai-iot-transforming-world.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AIoT革命：AI和IoT如何改变我们的世界](https://www.kdnuggets.com/2022/07/aiot-revolution-ai-iot-transforming-world.html)'
- en: '[KDnuggets News, July 27: The AIoT Revolution: How AI and IoT Are…](https://www.kdnuggets.com/2022/n30.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，7月27日：AIoT革命：AI和IoT如何…](https://www.kdnuggets.com/2022/n30.html)'
- en: '[How AI is Transforming the Retail Industry](https://www.kdnuggets.com/how-ai-is-transforming-the-retail-industry)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI如何改变零售行业](https://www.kdnuggets.com/how-ai-is-transforming-the-retail-industry)'
- en: '[Future-Proof Your Data Game: Top Skills Every Data Scientist Needs in 2023](https://www.kdnuggets.com/futureproof-your-data-game-top-skills-every-data-scientist-needs-in-2023)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[未来-proof你的数据技能：2023年每个数据科学家需要的顶级技能](https://www.kdnuggets.com/futureproof-your-data-game-top-skills-every-data-scientist-needs-in-2023)'
- en: '[Step up your Python game with Fast Python for Data Science!](https://www.kdnuggets.com/2022/06/manning-step-python-game-fast-python-data-science.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过《数据科学的快速Python》提升你的Python技能！](https://www.kdnuggets.com/2022/06/manning-step-python-game-fast-python-data-science.html)'
