- en: 'Neural Networks 201: All About Autoencoders'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络 201：自编码器全解
- en: 原文：[https://www.kdnuggets.com/2019/11/all-about-autoencoders.html](https://www.kdnuggets.com/2019/11/all-about-autoencoders.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/11/all-about-autoencoders.html](https://www.kdnuggets.com/2019/11/all-about-autoencoders.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Zak Jost](https://blog.zakjost.com), Research Scientist at Amazon Web
    Services**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Zak Jost](https://blog.zakjost.com)，亚马逊网络服务研究科学家**。'
- en: For those getting started with neural networks, autoencoders can look and sound
    intimidating.  But in fact, they are a conceptually simple and elegant approach
    that will open many doors to an ML practitioner.  They can be used for anomaly
    detection and missing value imputation or help in building better classifiers
    or clusters.  In any case, what makes them unique is that they provide you with
    a mechanism for leveraging your unlabelled data, which often is much easier to
    get than labeled data.  For instance, it's a lot easier to get a collection of
    images than it is to get a collection of images where each one is labeled to tell
    you what's in it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于刚入门神经网络的人来说，自编码器可能看起来令人畏惧。 但实际上，它们是一个概念上简单而优雅的方法，将为机器学习从业者打开许多大门。 它们可以用于异常检测和缺失值填补，或帮助构建更好的分类器或聚类器。
    无论如何，使它们独特的是它们为您提供了一个利用未标记数据的机制，这通常比获取标记数据要容易得多。 例如，获取一组图像要比获取一组每个图像都有标签的图像要容易得多。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: First and foremost, autoencoders are trained via *unsupervised* learning, which
    means you don't need labels.  An autoencoder is learned to *predict its own input*
    by using a noisy version of itself, which forces it to take advantage of structure
    in the data to learn compact ways of representing it.  At a high level, this means
    learning to throw away the noisy details and only keeping the important stuff. 
    Once you have a network that can condense data down to a compact form and discard
    details, that opens up a lot of new doors.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，自编码器通过 *无监督* 学习进行训练，这意味着您不需要标签。 自编码器通过使用自身的噪声版本来 *预测自己的输入*，这迫使其利用数据中的结构来学习紧凑的表示方式。
    从高层次看，这意味着学会丢弃噪声细节，只保留重要的内容。 一旦您拥有一个能够将数据压缩到紧凑形式并丢弃细节的网络，这将打开许多新门。
- en: To get a better understanding of how autoencoders work and how you can put them
    to use, I've made a short video that explains the key concepts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解自编码器的工作原理以及如何使用它们，我制作了一个简短的视频，解释了关键概念。
- en: '**Bio:** [Zak Jost](http://blog.zakjost.com/) ([@ZakJost](https://twitter.com/ZakJost))
    is Machine Learning Research Scientists at Amazon Web Services working on fraud
    applications. Before this, Zak built large-scale modeling tools as a Principal
    Data Scientist at Capital One to support the business''s portfolio risk assessment
    efforts following a previous career as a Material Scientist in the semiconductor
    industry building thin-film nanomaterials.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [Zak Jost](http://blog.zakjost.com/) ([@ZakJost](https://twitter.com/ZakJost))
    是亚马逊网络服务的机器学习研究科学家，专注于欺诈应用。在此之前，Zak 曾在 Capital One 担任首席数据科学家，构建大规模建模工具以支持业务的投资组合风险评估，并在半导体行业担任材料科学家，致力于薄膜纳米材料的开发。'
- en: '**Related:**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Autoencoders: Deep Learning with TensorFlow’s Eager Execution](https://www.kdnuggets.com/2019/05/autoencoders-deep-learning-with-tensorflows-eager-execution.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自编码器：使用 TensorFlow 的急切执行进行深度学习](https://www.kdnuggets.com/2019/05/autoencoders-deep-learning-with-tensorflows-eager-execution.html)'
- en: '[Variational Autoencoders Explained in Detail](https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[变分自编码器详细解释](https://www.kdnuggets.com/2018/11/variational-autoencoders-explained.html)'
- en: '[Deep Learning, The Curse of Dimensionality, and Autoencoders](https://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习、维度灾难与自编码器](https://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html)'
- en: More On This Topic
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在神经网络之前尝试的10个简单方法](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch的可解释神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引导我们走向通用人工智能（AGI）](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用最先进的深度学习进行可解释的预测和实时预测…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNN）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Survey on Trustworthy Graph Neural Networks:…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于可信赖图神经网络的全面调查：…](https://www.kdnuggets.com/2022/05/comprehensive-survey-trustworthy-graph-neural-networks-privacy-robustness-fairness-explainability.html)'
