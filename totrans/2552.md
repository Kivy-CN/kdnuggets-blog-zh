# 你的机器学习代码消耗了多少内存？

> 原文：[https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html](https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html)

[评论](#comments)

![](../Images/e666b93a66f863d32faf7f17039496f7.png)

图片来源： [Pixabay](https://pixabay.com/photos/hourglass-clock-time-period-hours-2910951/)

### 为什么要分析内存使用？

假设你编写了一个很酷的机器学习（ML）应用程序或创建了一个闪亮的神经网络模型。现在你想通过某些网络服务或 REST API 部署这个模型。

或者，你可能已经根据来自制造工厂工业传感器的数据流开发了这个模型，现在你需要将模型部署在工业控制 PC 上，以便根据持续接收的数据进行决策。

![](../Images/d3c66c70d3e3d5a01f9a613c092c6a39.png)

“兴奋于开发了一个闪亮的 ML 模型”。图片来源：[Pixabay](https://pixabay.com/photos/children-win-success-video-game-593313/)

作为数据科学家，你可能会经常遇到工程/平台团队提出的问题是“***你的模型/代码占用多少内存？***”或者“***在处理某些给定数据负载时，你的代码的峰值内存使用是多少？***”

这很自然地引发了担忧，因为**硬件资源可能有限**，一个 ML 模块不应占用系统的全部内存。这**尤其适用于边缘计算场景**，即 ML 应用程序可能运行在边缘，例如在工业 PC 的虚拟化容器中。

另外，你的模型可能是运行在那块硬件上的数百个模型之一，你必须对**峰值内存使用量有一定了解**，因为如果大量模型在同一时间达到内存峰值，可能会导致系统崩溃。

这让你感到好奇了，是不是？

![](../Images/60dfc75688808c42908777a9085c8b0e.png)

图片来源：[Pixabay](https://pixabay.com/photos/child-surprise-think-interactivity-2800835/)

> **… 硬件资源可能有限**，一个 ML 模块不应占用系统的全部内存。这**尤其适用于边缘计算场景…**

### 不要犯这个致命错误

请注意，我们讨论的是你整个代码的运行时内存配置文件（一个动态量）。这与机器学习模型的大小或压缩无关（你可能将其保存为磁盘上的特殊对象，例如[Scikit-learn Joblib 转储](https://scikit-learn.org/stable/modules/model_persistence.html)、一个简单的 Python Pickle 转储、[TensorFlow HFD5](https://www.tensorflow.org/tutorials/keras/save_and_load)等）。

### Scalene：一个整洁的内存/CPU/GPU 分析器

这里有一篇关于一些较旧的内存分析器用于 Python 的文章。

[**如何在 Python 中管理内存**](https://www.pluralsight.com/guides/profiling-memory-usage-in-python)

在本文中，我们将讨论**Scalene**——你的终极工具来回答工程团队提出的这些问题。

根据其 [GitHub 页面](https://github.com/plasma-umass/scalene)，“*Scalene 是一个高性能的 Python CPU、GPU 和内存分析工具，它做了其他 Python 分析工具无法做到的许多事情。它运行速度比其他分析工具快几个数量级，同时提供了更详细的信息。*”

它在马萨诸塞大学开发。请查看这个视频以获得全面介绍。

### 安装

毕竟它是一个 Python 包。所以，通常安装即可，

```py
**pip install scalene**
```

目前仅适用于 Linux 操作系统。我没有在 Windows 10 上测试它。

### 在 CLI 或 Jupyter Notebook 中使用

使用 Scalene 极其简单，

```py
**scalene <yourapp.py>**
```

另外，你可以在 Jupyter notebook 中使用这个魔法命令，

```py
**%load_ext scalene**
```

### 示例输出

这是一个示例输出。我们将很快深入探讨这个问题。

![](../Images/56327d172e1146bf408b00075cfc9130.png)

### 特性

以下是 Scalene 的一些酷炫功能。大多数功能不言而喻，可以从上面的截图中判断，

+   **行或函数**：报告整个函数和每一行独立代码的信息

+   **线程**：支持 Python 线程。

+   **多处理**：支持使用 `multiprocessing` 库

+   **Python vs. C时间**：Scalene 区分了 Python 与本地代码（例如，库）所花费的时间

+   **系统时间**：区分系统时间（例如，睡眠或执行 I/O 操作）

+   **GPU**：还可以报告在 NVIDIA GPU 上花费的时间（如果存在）

+   **复制量**：报告每秒复制的数据量（MB）

+   **检测泄漏**：Scalene 可以自动 pinpoint 可能导致内存泄漏的代码行！

### 一个具体的机器学习代码示例

让我们开始使用 Scalene 进行内存分析标准机器学习代码的工作。我们将查看两种不同类型的 ML 模型——原因稍后会澄清。我们将使用 Scikit-learn 库来处理所有三个模型，并利用其合成数据生成函数来创建我们的数据集。

+   一个多重线性回归模型

+   使用相同数据集的深度神经网络模型

模型代码对所有三个模型遵循完全相同的结构。外部 I/O 操作也在下图中标出，因为我们将看到它们可能会或可能不会主导内存分析，这取决于模型的类型。

![](../Images/bad072eafb90ed13e967f39d8e78549e.png)

图片来源：作者制作（拥有版权）

### 线性回归模型

代码文件在 [我的 GitHub 仓库中](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)。

我们使用标准导入和两个变量 `NUM_FEATURES` 和 `NUM_SAMPLES` 来进行一些实验。

![](../Images/13f542dad7e5f782d08833165ac26985.png)

我们没有展示数据生成和模型拟合的代码。它们相当标准，可以在[这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)查看。我们将拟合好的模型保存为 pickle 文件，并与测试 CSV 文件一起加载用于推断。

![](../Images/58d405dfd5cbd73c8c812d6b95f98183.png)

为了清晰起见，我们将所有内容放在一个`main`循环中，以便于 Scalene 执行和报告（你很快就会明白的）。

![](../Images/ff5d40503e1cab93aaa148f919586e68.png)

当我们运行命令时，

```py
$ scalene linearmodel.py --html >> linearmodel-scalene.html
```

我们得到这些结果作为输出。**注意，我在这里使用了**`**--html**`**标志，并将输出内容导入到一个 HTML 文件中以便于报告**。

![](../Images/b9a015457f196fb99f274789ee2c8455.png)

![](../Images/f47459e528414a38fd1903b9ed9792b7.png)

### **那么，这个结果中最引人注目的是？**

内存占用几乎完全由外部 I/O 主导，如 Pandas 和 Scikit-learn 估算器加载，以及少量用于将测试数据写入磁盘上的 CSV 文件。

实际的 ML 建模、Numpy 或 Pandas 操作和推断对内存没有任何影响！

### 随着模型和数据的扩展，会发生什么？

我们可以调整数据集大小（行数）和模型复杂度（特征数量），然后进行相同的内存分析，以记录各种操作在内存消耗方面的表现。结果如下所示。

这里的**X轴表示特征数量/数据点数量的配对**。注意这个图展示的是百分比而不是绝对值，以展示各种操作的相对重要性。

![](../Images/bfadee308ec5d1872491b943029cc923.png)

图片来源：作者制作（拥有版权）

### 所以，对于线性回归模型……

从这些实验中，我们得出结论，Scikit-learn 线性回归估算器非常高效，**在实际模型拟合或推断中不会消耗太多内存**。

然而，代码本身有固定的内存占用，并且在加载时会消耗那么多内存。然而，随着数据大小和模型复杂度的增加，这部分代码占总内存的百分比会降低。

因此，如果你在处理这样一个**小型线性模型时，你可能需要关注数据文件 I/O，以优化代码**以提高内存性能。

### 深度神经网络会发生什么？

如果我们对一个具有 2 层隐藏层的神经网络（每层 50 个神经元）进行类似实验，那么结果如下所示。[代码文件在这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/mlp.py)。

![](../Images/bdc5ab77dc5b38015239b35d40d382bd.png)

图片来源：作者制作（拥有版权）

显然，**神经网络模型在训练/拟合步骤中消耗大量内存，而线性回归模型则不然**。然而，对于特征数量少而数据量大的情况，拟合所需的内存量较低。

你还可以尝试各种架构和超参数，并记录内存使用情况，以确定适合你情况的设置。

### 遵循实验方法

如果你使用相同的[代码文件](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Memory-profiling/Scalene)重复实验，结果会根据你的硬件、磁盘/CPU/GPU/内存类型而大相径庭。本文的目的不是关注实际值或趋势。我希望你能够掌握进行内存分析实验的方式，以应用到你自己的代码中。

### 一些关键建议

+   最好在代码中编写**专注于单一任务的小函数**

+   保持一些**自由变量**，如特征数量和数据点数量，以便你可以用最小的修改运行相同的代码文件，检查当数据/模型扩展时的内存配置

+   如果你在比较一个 ML 算法与另一个算法时，尽量保持**整体代码结构和流程尽可能相同**，以减少混淆。最好只是更改估算器类，并比较内存配置。

+   **数据和模型 I/O**（导入语句、模型在磁盘上的持久化）在内存占用方面可能会非常重要，具体取决于你的建模场景。在优化时不要忽略它们。

+   出于上述相同的原因，可以考虑比较**来自多个实现/包的相同算法**的内存配置（例如 Keras 与 PyTorch 与 Scikit-learn）。如果内存优化是你的主要目标，你可能需要寻找一个具有最小内存占用且能令人满意地完成工作的实现，即使它在功能或性能方面不是绝对最好的。

+   如果数据 I/O 成为瓶颈，探索**更快的选项或其他存储类型**，例如用 parquet 文件和 Apache Arrow 存储替代 Pandas CSV。请查看这篇文章，

[**读取 Parquet 文件（使用 Arrow）与使用 Pandas 读取 CSV 的速度有多快？**](https://towardsdatascience.com/how-fast-is-reading-parquet-file-with-arrow-vs-csv-with-pandas-2f8095722e94)

### 你可以用 Scalene 做的其他事情

在这篇文章中，我们仅讨论了基本的内存分析，重点是经典的 ML 建模代码。Scalene CLI 还有其他你可以利用的选项，

+   仅分析 CPU 时间，不进行内存分析

+   仅减少非零内存占用的分析

+   指定 CPU 和内存分配的最低阈值

+   设置 CPU 采样率

+   多线程处理并检查差异

### 最终验证有时是必要的

对于资源有限的情况，建议建立一个验证环境/服务器，该服务器将接受给定的建模代码（开发后），并通过内存分析工具运行，以生成运行时统计数据。如果代码通过预设的内存占用标准，才会接受该建模代码进行进一步部署。

![](../Images/834d9c2379f2cc82d9c48a779e04b4cc.png)

图片来源：作者制作（拥有版权）

> 如果内存优化是你的主要目标，你可能需要寻找一个内存占用最小但能令人满意地完成工作的实现方案。

### 总结

在这篇文章中，我们讨论了内存分析对机器学习代码的重要性，以便与部署代码到服务/机器的平台/工程团队顺畅对接。内存分析还可以展示优化代码的意想不到的方法，基于你所处理的数据和算法。

我们展示了一个典型的机器学习建模代码示例，使用强大而轻量的Python库Scalene进行分析。我们演示了一些线性回归和神经网络模型的代表性结果，并提供了一些一般性建议。

希望你能通过这些工具和技术在实现和部署你的机器学习代码到生产环境中获得更多成功。

你可以查看作者的 [**GitHub**](https://github.com/tirthajyoti?tab=repositories) **库**，以获取机器学习和数据科学方面的代码、创意和资源。如果你像我一样，对AI/机器学习/数据科学充满热情，请随时 [在LinkedIn上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) 或 [在Twitter上关注我](https://twitter.com/tirthajyotiS)。

[原文](https://towardsdatascience.com/how-much-memory-is-your-ml-code-consuming-98df64074c8f)。经许可转载。

**相关内容：**

+   [作为数据科学家管理你的可重用Python代码](/2021/06/managing-reusable-python-code-data-scientist.html)

+   [5个Python数据处理技巧和代码片段](/2021/07/python-tips-snippets-data-processing.html)

+   [GitHub Copilot: 你的AI编程伙伴 – 到底是什么引起了这么多关注？](/2021/07/github-copilot-ai-pair-programmer.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT需求

* * *

### 更多关于这个话题

+   [一种（更）好的方法来评估你的机器学习模型](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)

+   [数据科学需要多少数学？](https://www.kdnuggets.com/2020/06/math-data-science.html)

+   [2022年数据科学家的薪资有多少？](https://www.kdnuggets.com/2022/02/much-data-scientists-make-2022.html)

+   [如何在大型数据集上使用Pandas进行内存高效操作](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)

+   [变压器的内存复杂性](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)

+   [Python中的内存分析简介](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)
