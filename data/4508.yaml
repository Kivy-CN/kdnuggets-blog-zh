- en: Recreating Fingerprints using Convolutional Autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积自编码器重建指纹
- en: 原文：[https://www.kdnuggets.com/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html](https://www.kdnuggets.com/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html](https://www.kdnuggets.com/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html)
- en: '[comments](#comments)![Figure](../Images/ad6146b9d7ada2b0c5689c5886abcfbd.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图](../Images/ad6146b9d7ada2b0c5689c5886abcfbd.png)'
- en: '[Source](https://www.pinterest.com/pin/151152131219099327/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://www.pinterest.com/pin/151152131219099327/)'
- en: '**Biometrics** is the technical term for body measurements and calculations.
    It refers to metrics related to human characteristics. Biometrics authentication
    (or realistic authentication) is used in computer science as a form of identification
    and access control. It is also used to identify individuals in groups that are
    under surveillance.'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**生物识别技术** 是身体测量和计算的技术术语。它指的是与人类特征相关的度量。生物识别认证（或现实认证）在计算机科学中用作身份识别和访问控制的一种形式。它也用于识别处于监控中的个人。'
- en: Biometric authentication systems are classified into two types such as Physiological
    Biometrics and Behavioral Biometrics. Physiological biometrics mainly include
    face recognition, fingerprint, hand geometry, iris recognition, and DNA. Whereas
    behavioral biometrics include keystroke, signature and voice recognition.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 生物识别认证系统被分为两种类型：生理生物识别和行为生物识别。生理生物识别主要包括面部识别、指纹、手部几何、虹膜识别和DNA。而行为生物识别包括击键、签名和语音识别。
- en: '![Figure](../Images/ba1145d548e1bb164b5b028bf5e83358.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/ba1145d548e1bb164b5b028bf5e83358.png)'
- en: '[Types of Biometrics](https://www.researchgate.net/figure/Various-types-of-biometric-modalities_fig1_321082969)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[生物识别类型](https://www.researchgate.net/figure/Various-types-of-biometric-modalities_fig1_321082969)'
- en: Fingerprints are the most reliable human characteristics that can be used for
    personal identification and has been widely used in biometric authentication systems
    due to its uniqueness and consistency. Fingerprint recognition systems play a
    crucial role in many situations where a person needs to be verified or identified
    with high confidence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 指纹是用于个人身份识别的最可靠的特征，并且因其独特性和一致性被广泛应用于生物识别认证系统。指纹识别系统在需要高信任度验证或识别个人的许多场合中发挥着关键作用。
- en: Despite the tremendous progress made in Automatic Fingerprint Identification
    Systems (AFIS), highly efficient and accurate fingerprint matching remains a critical
    challenge.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自动指纹识别系统（AFIS）取得了巨大的进展，高效且准确的指纹匹配仍然是一个关键挑战。
- en: 'Fingerprints: As Unique as You'
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指纹：如同你一样独特
- en: Imagine you misplaced your smartphone and start panicking because there’s a
    lot of personal information on that phone. You’re worried because you don’t want
    whoever picks it up to be able to access it. But then you remember that you secured
    it so that no one could use it, should this scenario ever arise. The only person
    your phone will unlock for is you, and it knows it’s you because you use your
    fingerprint.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你把智能手机放错了地方，开始感到恐慌，因为手机里有大量个人信息。你担心，因为你不希望捡到手机的人能够访问它。但随后你记得你已经设置了安全措施，以防这种情况发生。只有你自己才能解锁手机，它知道是你，因为你使用了指纹。
- en: '**Fingerprints** and also toe prints can be used to identify a single individual
    because they are unique to each person and they do not change over time. Amazingly,
    even identical twins have fingerprints that are different from each other, and
    none of your fingers have the same print as the others. Fingerprints consist of **ridges**,
    which are the raised lines, and **furrows**, which are the valleys between those
    lines. And it’s the pattern of those ridges and furrows that are different for
    everyone.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**指纹** 和脚趾印可以用于识别单个个体，因为它们对每个人都是独一无二的，并且不会随着时间而改变。令人惊讶的是，即使是同卵双胞胎的指纹也各不相同，你的手指之间也没有相同的指纹。指纹由**脊线**（即隆起的线条）和**沟壑**（即这些线条之间的凹陷）组成。正是这些脊线和沟壑的图案在每个人身上都是不同的。'
- en: The patterns of the ridges are what is imprinted on a surface when your finger
    touches it. If you get fingerprinted the ridges are printed on the paper and can
    be used to match fingerprints you might leave elsewhere.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 脊线的图案是当你的手指触碰到一个表面时留下的印记。如果你留下了指纹，这些脊线会印在纸上，并可以用来匹配你可能在其他地方留下的指纹。
- en: '**Human fingerprints are detailed, almost unique, difficult to modify, and
    durable over the life of an individual, making them suitable as long-term markers
    of human identity.**'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**人类指纹细节丰富、几乎唯一、难以修改且在个体一生中保持耐用，使其成为长期标记人类身份的合适选择。**'
- en: Characteristics of Fingerprints
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指纹特征
- en: The first encounter with fingerprints makes them look complicated. They may
    leave you wondering how forensic and law enforcement people make use of them.
    Fingerprints may look complicated, but the fact is that they have general ridge
    patterns and each person’s fingerprint is unique making it possible to systematically
    classify them.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次接触指纹时，它们看起来复杂。你可能会想知道法医和执法人员如何利用它们。指纹可能看起来复杂，但实际上它们有一般的脊线图案，每个人的指纹都是独一无二的，这使得系统化分类成为可能。
- en: 'Fingerprints have three basic ridge patterns: “Arch”, “Loop” and “Whorl/Core”.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 指纹有三种基本脊线图案：“拱形”、“环形”和“涡纹/核心”。
- en: Arches
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拱形纹路
- en: '![](../Images/72c6d8bb1c4095745b1a049319323184.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72c6d8bb1c4095745b1a049319323184.png)'
- en: In this pattern type, ridges enter on one side and exit on the other side. 5%
    of the total world’s population is believed to have arches in their fingerprints.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种图案类型中，脊线从一侧进入，从另一侧退出。相信全球5%的人口在指纹中有拱形纹路。
- en: Loops
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环形纹路
- en: '![](../Images/83378601656fb880fe89e6fc480f7f4f.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83378601656fb880fe89e6fc480f7f4f.png)'
- en: This pattern type has ridges entering on one side and exiting on the same side.
    60–65% of the world’s population is believed to have loops in their fingerprints.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种图案类型的脊线从一侧进入，从同一侧退出。相信全球60%–65%的人口在指纹中有环形纹路。
- en: Whorls/Core
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 涡纹/核心
- en: '![](../Images/7236dd1728cc38e53814c3a7d255cca8.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7236dd1728cc38e53814c3a7d255cca8.png)'
- en: Consists of circles, more than one loop, or a mixture of pattern type. 30–35%
    of the world’s population is believed to have whorls in their fingerprints.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 包含圆圈、多个环形或图案类型的混合。相信全球30%–35%的人口在指纹中有涡纹。
- en: 'The **uniqueness** of a fingerprint is exclusively determined by the local
    ridge characteristics and their relationships. The ridges and valleys in a fingerprint
    alternate, flowing in a local constant direction. The two most prominent local
    ridge characteristics are: 1) **ridge ending** and, 2) **ridge bifurcation**.
    A ridge ending is defined as the point where a ridge ends abruptly. A ridge bifurcation
    is defined as the point where a ridge forks or diverges into branch ridges. Collectively,
    these features are called ***minutiae.***'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**指纹的独特性**完全由局部脊线特征及其关系决定。指纹中的脊线和沟壑交替，沿局部恒定方向流动。最显著的局部脊线特征有：1) **脊线终点** 和 2)
    **脊线分叉**。脊线终点定义为脊线突然结束的点。脊线分叉定义为脊线分叉或分裂成支脊的点。这些特征统称为 ***细节点***。'
- en: '![Figure](../Images/5f87e23f9fbee2f9f369d212006a26ef.png)  ![Figure](../Images/35324c16f4f1afeae027911f624f9376.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/5f87e23f9fbee2f9f369d212006a26ef.png)  ![图示](../Images/35324c16f4f1afeae027911f624f9376.png)'
- en: Minutiae points
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 细节点
- en: The set of minutiae points is considered to be the most distinctive feature
    for fingerprint representation and is widely used in fingerprint matching. It
    was believed that the minutiae set do not contain sufficient information to reconstruct
    the original fingerprint image from which minutiae were extracted. However, recent
    studies have shown that it is indeed possible to reconstruct fingerprint images
    from their minutiae representations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 细节点集合被认为是指纹表示中最独特的特征，并广泛用于指纹匹配。曾认为细节点集合不包含足够的信息来重建提取细节点的原始指纹图像。然而，最近的研究表明，确实可以从细节点表示中重建指纹图像。
- en: Building a Convolutional Autoencoder
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建卷积自编码器
- en: After having an overview of the fingerprint, its features, it is time to utilize
    our newly developed skill to build a Neural network that is capable of recreating
    or reconstructing fingerprint images.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在概览指纹及其特征后，是时候利用我们新学会的技能来构建一个能够重建或再现指纹图像的神经网络了。
- en: So, first of all, we’ll explore the dataset including what kind of images it
    has, how to read the images, how to create an array of the images, exploring the
    fingerprint images and finally preprocessing them to be able to feed them in the
    model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将探索数据集，包括它包含哪些图像、如何读取图像、如何创建图像数组、探索指纹图像，最后对它们进行预处理，以便能够输入模型。
- en: I have used convolutional autoencoder for training the model. Next, we will
    visualize the training and validation loss plot and finally predict the test set.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了卷积自编码器来训练模型。接下来，我们将可视化训练和验证损失图，并最终预测测试集。
- en: Here I’m assuming you guys are comfortable with Convolutional Neural Networks
    and AutoEncoders. Anyway, I’ll try to explain them as a one-liner.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我假设你们对卷积神经网络和自编码器已经很熟悉了。不过，我还是会尝试用一句话来解释它们。
- en: A **Convolutional neural network** (CNN) is a neural network that has one or
    more convolutional layers and is used mainly for image processing, classification,
    and segmentation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**卷积神经网络**（CNN）是一个具有一个或多个卷积层的神经网络，主要用于图像处理、分类和分割。
- en: '**OK. Whats an AutoEncoder?**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**好的。什么是自编码器？**'
- en: Autoencoders are a family of Neural Networks for which the input is the same
    as the output. They work by compressing the input into a latent-space representationand
    then reconstructing the output from this representation. Check [this out for more.](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一类神经网络，其输入与输出是相同的。它们通过将输入压缩到一个潜在空间表示中，然后从该表示中重建输出。了解更多请查看 [这个](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/)。
- en: '**Now whats a Convolutional Autoencoders?**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么卷积自编码器是什么？**'
- en: The convolution operator allows filtering an input signal in order to extract
    some part of its content. Autoencoders in their traditional formulation do not
    take into account the fact that a signal can be seen as a sum of other signals.
    Convolutional Autoencoders, instead, use the convolution operator to exploit this
    observation. They learn to encode the input in a set of simple signals and then
    try to reconstruct the input from them. For more [check this out.](https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积运算符允许对输入信号进行滤波，以提取其内容的一部分。传统形式的自编码器没有考虑到信号可以视为其他信号的总和这一事实。而卷积自编码器则使用卷积运算符来利用这一观察结果。它们学习将输入编码成一组简单的信号，然后尝试从这些信号中重建输入。更多信息请 [查看这里](https://pgaleone.eu/neural-networks/2016/11/24/convolutional-autoencoders/)。
- en: '![Figure](../Images/7fb5d9d2f85dcbb24378add7221a21d8.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/7fb5d9d2f85dcbb24378add7221a21d8.png)'
- en: A convolution between a 4x4x1 input and a 3x3x1 convolutional filter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一个4x4x1输入与一个3x3x1卷积滤波器的卷积操作。
- en: The result is a 2x2x1 activation map. [Source](https://github.com/vdumoulin/conv_arithmetic)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个2x2x1的激活图。 [来源](https://github.com/vdumoulin/conv_arithmetic)
- en: The dataset that I’m using is the FVC2002 fingerprint dataset. It consists of
    4 different sensor fingerprints namely Low-cost Optical Sensor, Low-cost Capacitive
    Sensor, Optical Sensor and Synthetic Generator, each sensor having varying image
    sizes. The dataset has 320 images, 80 images per sensor.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用的数据集是FVC2002指纹数据集。它由4种不同的传感器指纹组成，即低成本光学传感器、低成本电容传感器、光学传感器和合成生成器，每种传感器具有不同的图像尺寸。数据集中有320张图片，每种传感器80张图片。
- en: '[Download dataset](http://bias.csr.unibo.it/fvc2002/databases.asp).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[下载数据集](http://bias.csr.unibo.it/fvc2002/databases.asp)。'
- en: '**Load the required libraries:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**加载所需的库：**'
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Load the dataset:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**加载数据集：**'
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now convert these images into float32 array.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将这些图像转换为float32数组。
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Once you have the data loaded properly, you are all set to analyze it in order
    to get some intuition about the dataset.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据正确加载，你就可以开始分析它，以获取对数据集的一些直观理解。
- en: '**Data Exploration:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据探索：**'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From the above output, you can see that the data has a shape of 320 x 224 x
    224 since there are 320 samples each of the 224 x 224-dimensional matrix.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述输出中，你可以看到数据的形状为320 x 224 x 224，因为有320个样本，每个样本是224 x 224维的矩阵。
- en: 'Take a look at a first 5 images in our dataset:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 查看数据集中前5张图片：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure](../Images/edb065cc813b0e104904e0f25f59daec.png)  ![Figure](../Images/4b1dfc787b85ba397749d714cd249533.png)  ![Figure](../Images/dc06d851be4a2a3468f881616a894705.png)![Figure](../Images/8c6146f550eff0a83de7e76e4e4a32b8.png)  ![Figure](../Images/046f442c10ea86db8dc9a3fe1140b5ff.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/edb065cc813b0e104904e0f25f59daec.png)  ![图](../Images/4b1dfc787b85ba397749d714cd249533.png)  ![图](../Images/dc06d851be4a2a3468f881616a894705.png)![图](../Images/8c6146f550eff0a83de7e76e4e4a32b8.png)  ![图](../Images/046f442c10ea86db8dc9a3fe1140b5ff.png)'
- en: Dataset
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集
- en: As we can see that the fingerprints are not very clear, it will be interesting
    to see if the convolutional autoencoder is able to learn the features and is able
    to reconstruct these images properly.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可以看到指纹并不是很清晰，因此观察卷积自编码器是否能够学习特征并正确重建这些图像将会很有趣。
- en: 'The images of the dataset are grayscale images with pixel values ranging from
    0 to 255 having a dimension of 224 x 224, so before we feed the data into the
    model, it is very important to preprocess it. We’ll first convert each 224 x 224
    image of the dataset into a matrix of size 224 x 224 x 1\. 1 for Grayscale image,
    which we can then feed into the Neural Network:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的图像是灰度图像，像素值范围从0到255，尺寸为224 x 224，因此在将数据输入模型之前，预处理非常重要。我们将首先把每个224 x 224的图像转换为224
    x 224 x 1的矩阵，这样我们就可以将其输入神经网络：
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we want to make sure to check the data type of the NumPy array; it should
    be in **float32** format, if not you will need to convert it into this format,
    you also have to rescale the pixel values in range 0–1.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要确保检查NumPy数组的数据类型；它应该是**float32**格式，如果不是，你需要将其转换为这种格式，你还需要将像素值重新缩放到0–1的范围内。
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If we verify we should get `dtype('float32')`
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们验证，应该得到`dtype('float32')`
- en: 'Next, rescale the data with the maximum pixel value of the images in the data:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，用数据中图像的最大像素值来重新缩放数据：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s verify the maximum and minimum value of data which should be 0.0 and 1.0
    after rescaling it!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证数据的最大值和最小值，重新缩放后应该是0.0和1.0！
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If we verify we should get `(1.0, 0.0)`
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们验证，应该得到`(1.0, 0.0)`
- en: 'In order for your model to generalize well, you split the data into two parts:
    training and a validation set. You will train your model on 80% of the data and
    validate it on 20% of the remaining training data.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使你的模型能够很好地泛化，你将数据分为两部分：训练集和验证集。你将在80%的数据上训练模型，并在剩余训练数据的20%上验证它。
- en: This will also help you in reducing the chances of overfitting, as you will
    be validating your model on data it would not have seen in the training phase.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这也有助于减少过拟合的可能性，因为你将在训练阶段未见过的数据上验证你的模型。
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We don’t need training and testing labels that’s why we will pass the training
    images twice. Our training images will both act as the input as well as the ground
    truth similar to the labels you have in the classification task.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要训练和测试标签，这就是为什么我们将训练图像传递两次。我们的训练图像将同时作为输入和地面真实值，类似于分类任务中的标签。
- en: Now we are all set to define the network and feed the data into the network.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以定义网络并将数据输入网络。
- en: '**The Convolutional Autoencoder**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积自编码器**'
- en: The images are of size 224 x 224 x 1 or a 50,176-dimensional vector. We convert
    the image matrix to an array, rescale it between 0 and 1, reshape it so that it’s
    of size 224 x 224 x 1, and feed this as an input to the network.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的大小为224 x 224 x 1或50,176维的向量。我们将图像矩阵转换为数组，将其重新缩放到0和1之间，调整形状使其为224 x 224 x
    1，然后将其作为输入提供给网络。
- en: Also, we will use a batch size of 128 using a higher batch size of 256 or 512
    is also preferable it all depends on the system you train your model. It contributes
    heavily in determining the learning parameters and affects the prediction accuracy.
    We will train your network for 300 epochs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将使用128的批量大小，使用256或512的较大批量大小也是可取的，这完全取决于你训练模型的系统。这对确定学习参数和影响预测准确性有很大作用。我们将训练你的网络300个epochs。
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As you might already know well before, the autoencoder is divided into two
    parts: there are encoder and a decoder.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经知道的那样，自编码器分为两部分：编码器和解码器。
- en: '**Encoder**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**编码器**'
- en: The first layer will have 32 filters of size 3 x 3, followed by a downsampling
    (max-pooling) layer,
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一层将具有32个3 x 3的滤波器，随后是一个下采样（最大池化）层，
- en: The second layer will have 64 filters of size 3 x 3, followed by another downsampling
    layer,
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二层将具有64个3 x 3的滤波器，随后是另一个下采样层，
- en: The final layer of encoder will have 128 filters of size 3 x 3.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器的最终层将具有128个3 x 3的滤波器。
- en: '**Decoder**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**解码器**'
- en: The first layer will have 128 filters of size 3 x 3 followed by an upsampling
    layer,
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一层将具有128个3 x 3的滤波器，随后是一个上采样层，
- en: The second layer will have 64 filters of size 3 x 3 followed by another upsampling
    layer,
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二层将具有64个3 x 3的滤波器，随后是另一个上采样层，
- en: The final layer of encoder will have one filter of size 3 x 3.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器的最终层将具有一个3 x 3的滤波器。
- en: The max-pooling layer will downsample the input by two times each time you use
    it, while the upsampling layer will upsample the input by two times each time
    it is used.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化层每次使用时将输入下采样两倍，而上采样层每次使用时将输入上采样两倍。
- en: '**Note**: The number of filters, the filter size, the number of layers, number
    of epochs you train your model, are all hyperparameters and should be decided
    based on your own intuition, you are free to try new experiments by tweaking with
    these hyperparameters and measure the performance of your model. And that is how
    you will slowly learn the art of deep learning!'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：滤波器的数量、滤波器的大小、层的数量、训练模型的周期数，都是超参数，应该根据你自己的直觉来决定，你可以通过调整这些超参数来进行新的实验，并测量模型的性能。这就是你逐步学习深度学习艺术的方法！'
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Note that you also have to specify the loss type via the argument loss. In
    this case, that’s the mean squared error, since the loss after every batch will
    be computed between the batch of predicted output and the ground truth using mean
    squared error pixel by pixel:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你还必须通过参数loss指定损失类型。在这种情况下，是均方误差，因为每个批次后的损失将通过逐像素均方误差计算预测输出批次和真实值之间的差距：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s visualize the layers that you created in the above step by using the summary
    function; this will show a number of parameters (weights and biases) in each layer
    and also the total parameters in your model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用summary函数来可视化你在上述步骤中创建的层；这将显示每一层中的参数（权重和偏差）数量，以及模型中的总参数。
- en: '![](../Images/1b5aea710a7485aa3e01d758d7d777c6.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b5aea710a7485aa3e01d758d7d777c6.png)'
- en: It’s finally time to train the model with Keras’ fit() function! The model trains
    for 300 epochs.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 终于到了用Keras的fit()函数训练模型的时候了！模型训练了300个周期。
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Finally! You trained the model on the fingerprint dataset for 300 epochs, Now,
    let’s plot the loss plot between training and validation data to visualize the
    model performance.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最终！你在指纹数据集上训练了300个周期的模型，现在，让我们绘制训练和验证数据之间的损失图，以可视化模型性能。
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/785eb6e6086e93f40ab081ef92e782ff.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/785eb6e6086e93f40ab081ef92e782ff.png)'
- en: 'Finally, you can see that the validation loss and the training loss both are
    in sync. It shows that your model is not overfitting: the validation loss is decreasing
    and not increasing,'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以看到验证损失和训练损失都保持同步。这表明你的模型没有过拟合：验证损失在减少而不是增加，
- en: Therefore, you can say that your model’s generalization capability is good.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以说你的模型的泛化能力很好。
- en: Finally, it’s time to reconstruct the test images using the predict() function
    of Keras and see how well your model is able to reconstruct the test data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是时候使用Keras的predict()函数来重建测试图像，看看你的模型能多好地重建测试数据。
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Test images:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 测试图像：
- en: '![](../Images/d8dd22170276dd5a39cc63f16fc55298.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8dd22170276dd5a39cc63f16fc55298.png)'
- en: 'Recreated images:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 重建图像：
- en: '![](../Images/d6500cc0bee861a3749f5130f9121ec6.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6500cc0bee861a3749f5130f9121ec6.png)'
- en: From the above figures, you can observe that your model did a fantastic job
    of reconstructing the test images that you predicted using the model. At least
    visually, the test and the reconstructed images look almost similar.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述图像中，你可以观察到你的模型在重建你用模型预测的测试图像时表现非常出色。至少在视觉上，测试图像和重建图像看起来几乎相似。
- en: You can also find the code in my Github.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在我的Github中找到代码。
- en: '**[nageshsinghc4/Recreating-Fingerprints-using-Convolutional-Autoencoders](https://github.com/nageshsinghc4/Recreating-Fingerprints-using-Convolutional-Autoencoders)**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**[nageshsinghc4/Recreating-Fingerprints-using-Convolutional-Autoencoders](https://github.com/nageshsinghc4/Recreating-Fingerprints-using-Convolutional-Autoencoders)**'
- en: Build a Neural network that is capable of recreating or reconstructing fingerprint
    images. The dataset that I'm using…
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个能够重建或再现指纹图像的神经网络。我使用的数据集…
- en: Conclusion
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: It was never prevised that fingerprint science, which was used for catching
    criminals, would be used for unlocking mobile phones and authenticating payments.
    Phones instantly unlock when a finger registered with it, is put on the sensor,
    but it refuses to recognize the finger next to it, that’s when the uniqueness
    of fingerprints is practically felt.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从未预见到，用于抓捕罪犯的指纹科学会被用于解锁手机和验证支付。当一个注册了的手指放在传感器上时，手机会立即解锁，但它拒绝识别旁边的手指，这就是指纹唯一性的实际体现。
- en: Well, that’s all for this article hope you guys have enjoyed reading it and
    I’ll be glad if the article is of any help. Feel free to share your comments/thoughts/feedback
    in the comment section.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这就是本文的全部内容，希望大家阅读愉快，如果这篇文章对你有帮助，我将非常高兴。欢迎在评论区分享你的评论/想法/反馈。
- en: Thanks for reading!!!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读!!!
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是 CirrusLabs 的大数据开发人员。他在电信、分析、销售、数据科学等多个领域拥有超过 4 年的工作经验，专注于各种大数据组件。'
- en: '[Original](https://towardsdatascience.com/recreating-fingerprints-using-convolutional-autoencoders-5c576e479d4f).
    Reposted with permission.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始链接](https://towardsdatascience.com/recreating-fingerprints-using-convolutional-autoencoders-5c576e479d4f)。转载已获许可。'
- en: '**Related:**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Neural Networks 201: All About Autoencoders](/2019/11/all-about-autoencoders.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络 201：关于自编码器的一切](/2019/11/all-about-autoencoders.html)'
- en: '[Stock Market Forecasting Using Time Series Analysis](/2020/01/stock-market-forecasting-time-series-analysis.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用时间序列分析进行股票市场预测](/2020/01/stock-market-forecasting-time-series-analysis.html)'
- en: '[Exoplanet Hunting Using Machine Learning](/2020/01/exoplanet-hunting-machine-learning.html)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用机器学习进行系外行星猎寻](/2020/01/exoplanet-hunting-machine-learning.html)'
- en: '* * *'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT 工作'
- en: '* * *'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络 (CNNs) 进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络综合指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[Automate Microsoft Excel and Word Using Python](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
- en: '[How to Determine the Best Fitting Data Distribution Using Python](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Python 确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
- en: '[Using Datawig, an AWS Deep Learning Library for Missing Value Imputation](https://www.kdnuggets.com/2021/12/datawig-aws-deep-learning-library-missing-value-imputation.html)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Datawig，一个 AWS 深度学习库进行缺失值插补](https://www.kdnuggets.com/2021/12/datawig-aws-deep-learning-library-missing-value-imputation.html)'
