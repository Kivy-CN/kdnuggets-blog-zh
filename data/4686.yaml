- en: Predict Age and Gender Using Convolutional Neural Network and OpenCV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络和 OpenCV 预测年龄和性别
- en: 原文：[https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)
- en: '[comments](#comments)![Figure](../Images/ab74974a523a926ad87742cfb6a68feb.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图](../Images/ab74974a523a926ad87742cfb6a68feb.png)'
- en: source: [https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/](https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/](https://www.zymr.com/difference-machine-learning-artificial-intelligence-bots/)
- en: Automatic age and gender classification has become relevant to an increasing
    amount of applications, particularly since the rise of social platforms and social
    media. Nevertheless, performance of existing methods on real-world images is still
    significantly lacking, especially when compared to the tremendous leaps in performance
    recently reported for the related task of face recognition. — [**Age and Gender
    Classification using Convolutional Neural Networks**](https://talhassner.github.io/home/publication/2015_CVPR)
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动化的年龄和性别分类在社交平台和社交媒体兴起之后，变得越来越相关。然而，与最近在面部识别任务上取得的巨大进展相比，现有方法在现实世界图像上的表现仍然显著不足。 — [**使用卷积神经网络进行年龄和性别分类**](https://talhassner.github.io/home/publication/2015_CVPR)
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 部门'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: Age and gender, two of the key facial attributes, play a very foundational role
    in social interactions, making age and gender estimation from a single face image
    an important task in intelligent applications, such as access control, human-computer
    interaction, law enforcement, marketing intelligence and visual surveillance,
    etc.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 年龄和性别这两个关键面部特征，在社交互动中起着非常基础的作用，使得从单一面部图像中估计年龄和性别成为智能应用中的一个重要任务，如访问控制、人机交互、执法、市场情报和视觉监控等。
- en: '**Real world use-case :**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**现实世界应用案例：**'
- en: '![Figure](../Images/e68f5884c27d59a18cd0b74421bc2c24.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/e68f5884c27d59a18cd0b74421bc2c24.png)'
- en: Source: [https://www.kiwi-digital.com/produkty/age-gender-detection](https://www.kiwi-digital.com/produkty/age-gender-detection)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.kiwi-digital.com/produkty/age-gender-detection](https://www.kiwi-digital.com/produkty/age-gender-detection)
- en: Recently I came across [**Quividi**](https://www.quividi.com/) which is an AI
    software application which is used to detect age and gender of users who passes
    by based on online face analyses and automatically starts playing advertisements
    based on the targeted audience.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近我遇到了 [**Quividi**](https://www.quividi.com/)，这是一款 AI 软件应用程序，用于基于在线面部分析检测用户的年龄和性别，并根据目标受众自动开始播放广告。
- en: Another example could be [**AgeBot**](https://play.google.com/store/apps/details?id=com.testa.agebot&hl=en_IN) which
    is an Android App that determines your age from your photos using facial recognition.
    It can guess your age and gender along with that can also find multiple faces
    in a picture and estimate the age for each face.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是 [**AgeBot**](https://play.google.com/store/apps/details?id=com.testa.agebot&hl=en_IN)，这是一个
    Android 应用程序，可以通过面部识别从照片中确定你的年龄。它可以猜测你的年龄和性别，并且还可以在一张图片中找到多张面孔，并估计每张面孔的年龄。
- en: 'Inspired by the above use cases we are going to build a simple Age and Gender
    detection model in this detailed article. So let''s start with our use-case:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 受上述用例的启发，我们将在这篇详细的文章中构建一个简单的年龄和性别检测模型。那么让我们开始我们的用例：
- en: '**Use-case **—we will be doing some face recognition, face detection stuff
    and furthermore, we will be using CNN (Convolutional Neural Networks) for age
    and gender predictions from a youtube video, you don’t need to download the video
    just the video URL is fine. The interesting part will be the usage of CNN for
    age and gender predictions on video URLs.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**用例**—我们将进行一些人脸识别、人脸检测工作，并且，我们将使用CNN（卷积神经网络）从YouTube视频中进行年龄和性别预测，你不需要下载视频，只需视频URL即可。令人感兴趣的是在视频URL上使用CNN进行年龄和性别预测。'
- en: '**Requirements :**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**要求：**'
- en: pip install OpenCV-python
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: pip install OpenCV-python
- en: numpy
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: numpy
- en: pip install pafy
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: pip install pafy
- en: pip install youtube_dl (to know more about [youtube_dl](https://rg3.github.io/youtube-dl/))
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: pip install youtube_dl（了解更多关于[youtube_dl](https://rg3.github.io/youtube-dl/)的信息）
- en: '**pafy** : Pafy library is used to retrieve YouTube content and metadata(such
    as Title, rating, viewcount, duration, rating, author, thumbnail, keywords etc).
    To know more about [pafy](https://pypi.org/project/pafy/). Let''s check one sample :'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**pafy**：Pafy库用于检索YouTube内容和元数据（如标题、评分、观看次数、时长、评分、作者、缩略图、关键词等）。了解更多关于[pafy](https://pypi.org/project/pafy/)的信息。我们来看一个示例：'
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output :'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Steps to follow :**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤：**'
- en: Get the video URL from YouTube.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从YouTube获取视频URL。
- en: Face detection with Haar cascades
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Haar级联进行人脸检测
- en: Gender Recognition with CNN
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用CNN进行性别识别
- en: Age Recognition with CNN
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用CNN进行年龄识别
- en: '**1.Get a video URL from YouTube:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 从YouTube获取视频URL：**'
- en: Get the Youtube video URL and try to get the attributes of the video using pafy
    as explained above.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 获取YouTube视频URL，并尝试使用pafy获取视频属性，如上所述。
- en: '**2\. Face detection with Haar cascades :**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 使用Haar级联进行人脸检测：**'
- en: This is a part most of us at least have heard of. OpenCV/JavaCV provide direct
    methods to import Haar-cascades and use them to detect faces. I will not be explaining
    this part in deep. You guys can refer to my previous [article](https://medium.com/analytics-vidhya/how-to-build-a-face-detection-model-in-python-8dc9cecadfe9) to
    know more about face detection using OpenCV.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是大多数人至少听说过的一部分。OpenCV/JavaCV提供了直接的方法来导入Haar级联并用于人脸检测。我不会深入解释这一部分。你们可以参考我之前的[文章](https://medium.com/analytics-vidhya/how-to-build-a-face-detection-model-in-python-8dc9cecadfe9)以了解更多关于使用OpenCV进行人脸检测的内容。
- en: '**3. Gender Recognition with CNN:**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 使用CNN进行性别识别：**'
- en: Gender recognition using OpenCV's fisherfaces implementation is quite popular
    and some of you may have tried or read about it also. But, in this example, I
    will be using a different approach to recognize gender. This method was introduced
    by two Israel researchers, Gil Levi and Tal Hassner in 2015\. I have used the
    CNN models trained by them in this example. We are going to use the OpenCV’s dnn
    package which stands for “Deep Neural Networks”.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenCV的fisherfaces实现进行性别识别非常流行，你们中的一些人可能也尝试过或读过相关内容。但在这个例子中，我将使用一种不同的方法来识别性别。这种方法是由两位以色列研究人员Gil
    Levi和Tal Hassner于2015年提出的。我在这个例子中使用了他们训练的CNN模型。我们将使用OpenCV的dnn包，即“深度神经网络”。
- en: In the dnn package, OpenCV has provided a class called Net which can be used
    to populate a neural network. Furthermore, these packages support importing neural
    network models from well known deep learning frameworks like caffe, tensorflow
    and torch. The researchers I had mentioned above have published their CNN models
    as caffe models. Therefore, we will be using the CaffeImporter import that model
    into our application.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在dnn包中，OpenCV提供了一个叫做Net的类，可以用来填充神经网络。此外，这些包支持从著名的深度学习框架（如caffe、tensorflow和torch）中导入神经网络模型。我之前提到的研究人员已经将他们的CNN模型发布为caffe模型。因此，我们将使用CaffeImporter将该模型导入到我们的应用程序中。
- en: '**4\. Age Recognition with CNN**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**4. 使用CNN进行年龄识别**'
- en: This is almost similar to the gender detection part except that the corresponding
    prototxt file and the caffe model file are “deploy_agenet.prototxt” and “age_net.caffemodel”.
    Furthermore, the CNN’s output layer (probability layer) in this CNN consists of
    8 values for 8 age classes (“0–2”, “4–6”, “8–13”, “15–20”, “25–32”, “38–43”, “48–53”
    and “60-”)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这与性别检测部分几乎相似，区别在于对应的prototxt文件和caffe模型文件是“deploy_agenet.prototxt”和“age_net.caffemodel”。此外，该CNN的输出层（概率层）包含8个值，用于8个年龄类别（“0–2”，“4–6”，“8–13”，“15–20”，“25–32”，“38–43”，“48–53”和“60-”）
- en: A caffe model has 2 associated files,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个caffe模型有2个相关文件，
- en: '**1 .prototxt** — The definition of CNN goes in here. This file defines the
    layers in the neural network, each layer’s inputs, outputs and functionality.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**1 .prototxt**——CNN的定义在这里。该文件定义了神经网络中的层，每一层的输入、输出和功能。'
- en: '**2 .caffemodel** — This contains the information of the trained neural network
    (trained model).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**2 .caffemodel** — 这包含了训练神经网络（训练模型）的信息。'
- en: Download .prtotxt and .caffemodel from [Here](https://talhassner.github.io/home/publication/2015_CVPR).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从[这里](https://talhassner.github.io/home/publication/2015_CVPR)下载.prtotxt和.caffemodel。
- en: Download haar cascade for face detection from [Here](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从[这里](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)下载用于面部检测的haar
    cascade。
- en: So let's start coding our model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们开始编写我们的模型代码。
- en: '**Source Code:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**源代码：**'
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let''s understand the code :'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们理解一下代码：
- en: 'Step 1: Import all the required libraries.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第1步：导入所有必需的库。
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Step 2: Get the Youtube video URL and create an object ‘play’ which contains
    the best resolution of the video in [webm](https://www.webmproject.org/about/)/mp4
    format.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第2步：获取YouTube视频URL并创建一个对象‘play’，该对象包含视频的最佳分辨率，格式为[webm](https://www.webmproject.org/about/)/mp4。
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Step 3: Often, we have to capture live stream with a camera. OpenCV provides
    a very simple interface to this. We can capture the video from the camera, convert
    it into grayscale video and display it. Just a simple task to get started.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步：我们通常需要用相机捕获实时流。OpenCV提供了一个非常简单的接口。我们可以从相机捕获视频，将其转换为灰度视频并显示。这只是一个简单的开始任务。
- en: To capture a video, you need to create a video capture object. Its argument
    can be either the device index or the name of a video file. Device index is just
    the number to specify which camera. Normally one camera will be connected (as
    in my case). So I simply pass 0 (or -1). You can select the second camera by passing
    1 and so on. After that, you can capture frame-by-frame.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕获视频，你需要创建一个视频捕获对象。它的参数可以是设备索引或视频文件的名称。设备索引只是指定哪个相机的数字。通常一个相机会连接（如我的情况）。所以我直接传递0（或-1）。你可以通过传递1选择第二个相机，以此类推。之后，你可以逐帧捕获。
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: But in my case I’m reading an online video URL, for that, I’ll pass ‘play’ object
    to VideoCapture().
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我的情况下，我正在读取一个在线视频URL，因此，我将‘play’对象传递给VideoCapture()。
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Step 4: Using set() I’ll set the height and width of our video frame. **cap.set(propId,
    value),** here 3 is the propertyId of width and 4 is for Height.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步：使用set()我会设置我们视频帧的高度和宽度。**cap.set(propId, value)**，其中3是宽度的propertyId，4是高度的propertyId。
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Step 5: Create 3 separate lists for storing Model_Mean_Values, Age and Gender.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 第5步：创建3个独立的列表来存储Model_Mean_Values、年龄和性别。
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Step 6: I have defined a function to load caffemodel and prototxt of both age
    and gender detector, these are basically pre-trained CNN models which will do
    the detection.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 第6步：我定义了一个函数来加载年龄和性别检测器的caffemodel和prototxt，这些基本上是预训练的CNN模型，用于进行检测。
- en: '[PRE9]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Step 7: Now we will perform face detection, Age detection, and Gender detection
    and for that create a function **video_detector(age_net, gender_net)** inside
    your main function and pass age_net and gender_net as its parameters.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第7步：现在我们将进行面部检测、年龄检测和性别检测，为此在你的主函数中创建一个函数**video_detector(age_net, gender_net)**，并将age_net和gender_net作为参数传递。
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Step 8: Read the cap object which is created from VideoCapture() in step 3.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 第8步：读取第3步中由VideoCapture()创建的cap对象。
- en: '**cap.read() **returns a bool (True/False). If the frame is read correctly,
    it will be True.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**cap.read()**返回一个布尔值（True/False）。如果帧被正确读取，它将为True。'
- en: '#So you can check the end of the video by checking this return value.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#所以你可以通过检查这个返回值来查看视频的结尾。'
- en: '#Sometimes, the cap may not have initialized the capture. In that case, this
    code shows error.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#有时候，cap可能没有初始化捕获。在这种情况下，这段代码会显示错误。'
- en: '#You can check whether it is initialized or not by the method cap.isOpened().
    If it is True, OK. Otherwise, open it using cap.open().'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#你可以通过方法cap.isOpened()检查它是否初始化。如果为True，表示正常。否则，使用cap.open()打开它。'
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Step 9: Convert the image to gray image as OpenCV face detector expects [gray
    images](https://en.wikipedia.org/wiki/Grayscale).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第9步：将图像转换为灰度图像，因为OpenCV面部检测器期望[灰度图像](https://en.wikipedia.org/wiki/Grayscale)。
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Step 10: Load the pre-built model for facial detection.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第10步：加载用于面部检测的预构建模型。
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Step 11: Now, how do we detect a face from an image using the CascadeClassifier ?'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第11步：现在，我们如何使用CascadeClassifier从图像中检测面孔？
- en: Well, again OpenCV’s CascadedClassifier has made it simple for us because of **detectMultiScale()**,
    which detects exactly what you need.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，OpenCV的CascadedClassifier因为**detectMultiScale()**使得这一过程变得简单，它能精确检测你需要的内容。
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Below are arguments which should pass to **detectMultiScale().**
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是应传递给**detectMultiScale()**的参数。
- en: This is a general function to detect objects, in this case, it’ll detect faces
    since we called in the face cascade. If it finds a face, it returns a list of
    positions of said face in the form “Rect(x,y,w,h).”, if not, then returns “None”.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通用的对象检测函数，在这种情况下，它将检测人脸，因为我们调用了人脸级联。如果找到人脸，它会以“Rect(x,y,w,h)”形式返回人脸的位置列表；如果没有找到，则返回“None”。
- en: '**Image:** The first input is the **grayscale image**.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像：** 第一个输入是**灰度图像**。'
- en: '**scaleFactor:** This function compensates a false perception in size that
    occurs when one face appears to be bigger than the other simply because it is
    closer to the camera.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scaleFactor：** 这个函数补偿了当一个人脸看起来比另一个人脸大，仅仅是因为它离摄像机更近时，出现的大小错误感知。'
- en: '**minNeighbors: **Detection algorithm that uses a moving window to detect objects,
    it does so by defining how many objects are found near the current one before
    it can declare the face found.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**minNeighbors：** 检测算法使用移动窗口来检测对象，它通过定义在当前对象附近找到多少个对象来确定是否可以声明找到人脸。'
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Step 12: Loop through the list of faces and draw rectangles on the human faces
    in the video. Here basically we’re finding faces, breaking the faces, their sizes,
    and drawing rectangles.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 12：遍历人脸列表并在视频中的人脸上绘制矩形。这里基本上是寻找人脸，识别这些人脸及其大小，并绘制矩形。
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Step 13 : OpenCV provides a function to facilitate image preprocessing for
    deep learning classification: **blobFromImage()**. It performs :'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 13：OpenCV 提供了一个函数以便于图像预处理用于深度学习分类：**blobFromImage()**。它执行：
- en: Mean subtraction
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值减法
- en: Scaling
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放
- en: And optionally channel swapping
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及可选的通道交换
- en: So blobFromImage*creates 4-dimensional blob from image. Optionally resizes and
    crops image from center, subtract mean values, scales values by scalfactor , swap
    Blue and Red channels*
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以 blobFromImage*创建 4 维的图像 blob。可以选择从中心调整大小和裁剪图像，减去均值，按缩放因子缩放值，交换蓝色和红色通道*
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**image:** This is the input image we want to preprocess before passing it
    through our deep neural network for classification.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**图像：** 这是我们要在传递给深度神经网络进行分类之前预处理的输入图像。'
- en: '**scale factor:** After we perform mean subtraction we can optionally scale
    our images by some factor. This value defaults to `1.0` (i.e., no scaling) but
    we can supply another value as well. It’s also important to note that scale factor
    should be 1/**σ** as we’re actually multiplying the input channels (after mean
    subtraction) by the scale factor.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缩放因子：** 在进行均值减法后，我们可以选择按某个因子缩放图像。此值默认为`1.0`（即不缩放），但我们也可以提供其他值。还要注意，缩放因子应为
    1/**σ**，因为我们实际上是在将输入通道（经过均值减法后）乘以缩放因子。'
- en: '**size:** Here we supply the spatial size that the Convolutional Neural Network
    expects. For most current state-of-the-art neural networks this is either *224×224*, *227×227*,
    or *299×299*.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大小：** 在这里我们提供卷积神经网络期望的空间大小。对于大多数当前最先进的神经网络，这通常是*224×224*、*227×227* 或 *299×299*。'
- en: '**mean:** These are our mean subtraction values. They can be a 3-tuple of the
    RGB means or they can be a single value in which case the supplied value is subtracted
    from every channel of the image. If you’re performing mean subtraction, ensure
    you supply the 3-tuple in `(R, G, B)` order, especially when utilizing the default
    behavior of swapRB=True.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**均值：** 这些是我们的均值减法值。它们可以是一个 RGB 均值的 3 元组，也可以是一个单一值，这种情况下提供的值会从图像的每个通道中减去。如果你进行均值减法，请确保以`(R,
    G, B)`的顺序提供 3 元组，尤其是在使用默认行为 swapRB=True 时。'
- en: '**swapRB** : OpenCV assumes images are in BGR channel order; however, the `mean` value
    assumes we are using RGB order. To resolve this discrepancy we can swap the R
    and B channels in the image by setting this value to `True`. By default, OpenCV
    performs this channel swapping for us.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**swapRB：** OpenCV 假设图像的通道顺序是 BGR；然而，`mean` 值假设我们使用 RGB 顺序。为了解决这个不一致，我们可以通过将此值设置为`True`来交换图像中的
    R 和 B 通道。默认情况下，OpenCV 为我们执行了此通道交换。'
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Step 14: Predict the gender.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 14：预测性别。
- en: '[PRE19]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Step 15: Predict the Age.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 15：预测年龄。
- en: '[PRE20]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Step 16: Now we have to put text on our output frame using putText() module
    of openCV.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 16：现在我们需要使用 OpenCV 的 putText() 模块在输出帧上添加文本。
- en: 'cv2.putText() takes parameters as :'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: cv2.putText() 需要以下参数：
- en: Text data that you want to write
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想写入的文本数据
- en: Position coordinates of where you want to put it ( i.e. bottom-left corner where
    data starts).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想放置文本的位置坐标（即数据开始的左下角）。
- en: Font type (Check [**cv2.putText()**](https://docs.opencv.org/3.1.0/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576) docs
    for supported fonts)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字体类型（查看 [**cv2.putText()**](https://docs.opencv.org/3.1.0/d6/d6e/group__imgproc__draw.html#ga5126f47f883d730f633d74f07456c576)
    文档以获取支持的字体）
- en: Font Scale (specifies the size of font)
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字体缩放（指定字体大小）
- en: regular things like color, thickness, lineType etc. For better look, lineType
    = cv2.LINE_AA is recommended.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常规的参数如颜色、厚度、lineType 等。为了更好的效果，推荐使用 lineType = cv2.LINE_AA。
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Step 17: Finally print your final output.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第 17 步：最后打印你的最终输出。
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'At the end we have :'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们有：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Our program waits up to 1 millisecond for the user to press a key. It then takes
    the value of the key read and ANDs it with `0xFF` which removes anything above
    the bottom 8-bits and compares the result of that with the ASCII code for the
    letter `q` which would mean the user has decided to quit by pressing `q`on the
    keyboard.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的程序最多等待 1 毫秒以便用户按下一个键。然后它获取读取的键值并与 `0xFF` 进行 AND 运算，这样可以去掉低于 8 位的部分，并将结果与字母
    `q` 的 ASCII 码进行比较，这意味着用户通过按下键盘上的 `q` 来决定退出。
- en: '**Output** : Video URL-1: [https://www.youtube.com/watch?v=iH1ZJVqJO3Y](https://www.youtube.com/watch?v=iH1ZJVqJO3Y)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**：视频网址-1：[https://www.youtube.com/watch?v=iH1ZJVqJO3Y](https://www.youtube.com/watch?v=iH1ZJVqJO3Y)'
- en: '![Figure](../Images/a1c89e6e5e72c57f245f31473e3c5c13.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/a1c89e6e5e72c57f245f31473e3c5c13.png)'
- en: Youtube video 1
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Youtube 视频 1
- en: Video URL-2: [https://www.youtube.com/watch?v=qLNhVC296YI](https://www.youtube.com/watch?v=qLNhVC296YI)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 视频网址-2：[https://www.youtube.com/watch?v=qLNhVC296YI](https://www.youtube.com/watch?v=qLNhVC296YI)
- en: '![Figure](../Images/ebf2004b089b2167c848dfe2bf2a1645.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/ebf2004b089b2167c848dfe2bf2a1645.png)'
- en: Youtube video 2
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Youtube 视频 2
- en: Quite interesting isn’t it? Not very accurate though.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 相当有趣，不是吗？不过准确度不是很高。
- en: '**Conclusion :**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**结论：**'
- en: As we have seen in this article that in just a few lines of code we have built
    an age and gender detection model, from here on you can also incorporate emotion
    detection and object detection in the same model and create a fully functional
    application.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在这篇文章中看到的，通过仅几行代码，我们构建了一个年龄和性别检测模型，从这里开始，你还可以在同一个模型中加入情感检测和物体检测，创建一个功能完整的应用程序。
- en: Hopefully, you found this article to be a good read and useful in your quest
    for recognizing a person’s age and gender. Let me know your doubts in the comment
    section.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你发现这篇文章阅读起来愉快，并对你识别年龄和性别的 quest 有所帮助。如果有任何疑问，请在评论区告诉我。
- en: Happy Learning :)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 祝学习愉快 :)
- en: Get in touch with me on [LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在[LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)与我联系。
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Data Science enthusiast. Interested in Big Data, Python, Machine Learning.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[纳戈什·辛格·乔汉](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是一位数据科学爱好者。对大数据、Python 和机器学习感兴趣。'
- en: '[Original](https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6).
    Reposted with permission.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/predict-age-and-gender-using-convolutional-neural-network-and-opencv-fd90390e3ce6)。已获得许可重新发布。'
- en: '**Related:**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[A Beginner’s Guide to Linear Regression in Python with Scikit-Learn](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 中的线性回归初学者指南](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[How to do Everything in Computer Vision](/2019/02/everything-computer-vision.html)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉中的一切](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Pedestrian Detection in Aerial Images Using RetinaNet](/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 RetinaNet 在航拍图像中进行行人检测](/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
- en: More On This Topic
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并通过寻找目的...](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个 90 亿美元的 AI 失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创企业的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
