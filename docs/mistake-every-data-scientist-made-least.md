# 每个数据科学家至少犯过一次的错误

> 原文：[https://www.kdnuggets.com/2022/09/mistake-every-data-scientist-made-least.html](https://www.kdnuggets.com/2022/09/mistake-every-data-scientist-made-least.html)

如果你使用一个工具，而这个工具没有被验证为安全，那么你制造的任何混乱都是*你*的错…… [AI](http://bit.ly/quaesita_donttrust) 是一种工具，就像其他工具一样，因此同样的规则适用。绝不要盲目相信它。

相反，让 [机器学习和 AI](http://bit.ly/quaesita_emperorm) 系统通过***赢得***你的信任。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 在 IT 领域支持你的组织

* * *

> 如果你想通过例子来教学，例子必须要好。如果你想信任学生的能力，测试必须要好。

始终牢记，你对系统在你检查过的条件之外的安全性一无所知，因此要仔细检查！这里有一份实用的提醒清单，不仅适用于[ML/AI](http://bit.ly/quaesita_emperor)，还适用于*每个*基于[data](http://bit.ly/quaesita_hist)的解决方案。

+   如果你没有测试它，就不要信任它。

+   如果你没有在你的*环境*中进行测试，就不要在你的*环境*中信任它。

+   如果你没有用你的*用户群体*进行测试，就不要用你的*用户群体*来信任它。

+   如果你没有用你的*数据集*进行测试，就不要用你的*数据集*来信任它。

+   *如果一个*[*输入不寻常*](https://bit.ly/mfml_086)*，不要信任你的系统输出合理的结果。考虑使用异常检测和*[*安全网*](http://bit.ly/quaesita_policy)*（例如，将不寻常的实例标记为人工审核）。*

> 设计良好的测试是保护我们所有人的安全。

数据新手和[data science](http://bit.ly/quaesita_datascim)专家之间的一个区别是专家有一些巨大的信任问题……并且乐于接受这些问题。

![每个数据科学家至少犯过一次的错误](../Images/ff6e1abb94c17c256f50b9fac9a896e0.png)

来源：[Pixabay](https://pixabay.com/photos/spider-scary-mistake-hybrid-mouse-2913761/)

# 专家犯的错误

在我们的[上一篇文章](http://bit.ly/quaesita_testmistake1)中，我们讨论了初学者犯的测试错误及如何避免它。现在是时候看一个即便是专家也会犯的更隐蔽的错误了。

对于那些还没读过[上一篇文章](http://bit.ly/quaesita_testmistake1)的人，让我们来回顾一下背景（在一个我们没有犯[新手错误](http://bit.ly/quaesita_testmistake1)的平行宇宙中）：

![每个数据科学家至少犯过的错误](../Images/532312a78d2686b8ee83f1e4cc8f1b4d.png)

我们用70,000张输入图像（你在上面图片中看到的每一张图像都是一个代表10,000张类似照片的占位符，标签为香蕉、赫胥黎或特斯拉；其中一种是我的早餐，另外两种是我的猫，你猜哪个是哪个）训练了一个相当不错的[模型](http://bit.ly/quaesita_emperorm)，然后在40,000张原始图像上进行了测试。

![每个数据科学家至少犯过的错误](../Images/602e561aa98b17210928ca7f10d953a8.png)

然后我们得到了……完美的结果！哇。

![每个数据科学家至少犯过的错误](../Images/5b895f93c3320a4f7bc284b9fb8148f4.png)

当你观察到[machine learning](http://bit.ly/quaesita_emperorm)任务上的完美表现时，你应该非常担心。正如[上一篇文章](http://bit.ly/quaesita_testmistake1)警告你对0%有错误态度一样，每当你看到*完美*结果时，保持警惕是一种好习惯。一位专家的第一个想法是测试可能过于简单，或者标签泄露了，或者数据不像我们希望的那样原始。正如一位经验丰富的大学教授发现每个学生完美回答每个问题时的想法一样。他们会疯狂调试，而不是自满于良好的教学。

由于100%在真实场景中不切实际，我们来设想得到一个其他高但不是过高的分数，比如98%。

![每个数据科学家至少犯过的错误](../Images/1b568c61e4a41b863007c5fb45543ec4.png)

很棒的表现，对吧？听起来像是在原始数据上也表现得很棒。而且所有的[统计假设检验](http://bit.ly/quaesita_fisher)的繁杂细节都处理好了！我们已经建立了一个很棒的特斯拉/赫胥黎检测器，赶紧启动吧！！！

小心点。

你会被诱惑去迅速得出结论。即使它在测试中给出了很好的结果，这可能根本不是一个特斯拉/赫胥黎检测器。

专家犯的错误与技术方面关系不大，更与人的思维有关：屈服于愿望思维。

> 专家也不是对愿望思维错误免疫的。

不要认为这些结果意味着系统*实际上*检测到了什么。我们没有证据表明它已经学会了——更糟糕的是，“它理解”——如何区分赫胥黎和特斯拉。再看仔细一点……

![每个数据科学家至少犯过的错误](../Images/210be5351cd4fe060d6a5860ac0887f9.png)

你注意到所有特斯拉照片背景中的那个小细节了吗？哎呀，结果我们不小心建立了一个散热器/非散热器分类器！

过度关注对我们有趣的问题和数据的部分，例如两只猫的身份，而忽视其他部分，如大多数Tes照片中散热器的存在，因为她喜欢待在那里，因此也最可能被拍到。不幸的是，她太喜欢散热器，以至于相同的问题出现在训练数据和测试数据中，因此你不会通过在与训练数据相同的[数据集](http://bit.ly/quaesita_vocab)上进行测试来发现这个问题。

![每个数据科学家至少犯过一次的错误](../Images/b2f92b87a1ba16786fc96c50706fbb51.png)

只要你（以及你的利益相关者和用户）具备如下的严格自律，所有这些（或多或少）都是可以接受的：

+   不要将结果解读成有趣的故事，比如“这是一个Hux/Tes分类器。”这种语言暗示了比我们拥有的证据要一般得多的东西。如果你对机器学习系统实际正在做的事情的理解可以简化成一个简洁的报纸标题… 那你很可能做错了。它至少应该以其细节让你感到乏味。

+   始终清楚地意识到，如果你测试系统的设置与训练系统的设置之间存在差异，你没有保证你的解决方案会有效。

这种自律是罕见的，因此在我们拥有更好的数据素养之前，我唯一能做的就是梦想大，尽我所能地为教育人们做出贡献。

这个系统只能在与测试和训练数据集拍摄方式相同的照片上工作——冬季同一个公寓的照片，因为那时Tesla倾向于待在散热器旁，而Huxley则不。在相同的方式拍摄大量照片的情况下，如果你得到了正确的标签，不管你的系统如何完成标记任务也无所谓。如果它利用散热器来赢得标记游戏，那也没关系…… 只要你不期望它在任何其他背景下工作（它不会）。为此，你需要更好、更广泛的训练和测试数据集。如果你将系统移到另一个公寓，即使你认为你理解了系统的工作原理，也要重新测试以确保它*仍然*有效。

> 由你的数据所代表的世界是你唯一能够成功的世界。

记住，由你的数据所代表的世界是你唯一能够成功的世界。所以你需要仔细考虑你正在使用的数据。

# 避免专家错误

永远不要假设你理解AI系统正在做什么。相信你对复杂事物的简单理解是万无一失的，这是一种极端的傲慢。你会为此受到惩罚。

> 永远不要假设你理解AI系统正在做什么。相信你对复杂事物的简单理解是万无一失的，这是一种极端的傲慢。你会为此受到惩罚。

在你的数据中很容易忽视现实世界的细微差别。不管你有多么有才华，只要你在数据科学领域工作够久，你几乎肯定会至少一次犯这个充满幻想的错误，直到你通过艰苦的经验学会严重限制你的结论——你能建立的最佳习惯就是在你彻底检查证据之前避免在事物中读取额外的含义。当你发现自己对结果的内心独白听起来不再像 TED 演讲，而更像是世界上最无聊合同的细则时，你就知道你达到了下一个水平。这是件好事。如果你坚持的话，你可以稍后用你的快语来惊艳众人，只要别让数据素养因为相信你自己的夸张言辞而尴尬。

从良好的测试结果中你唯一能学到的就是系统在与测试条件相似的环境、情况、数据集和人群中表现良好。任何你可能对其在这些条件之外的表现做出的猜测都是虚构的。要仔细测试，不要草率得出结论！

# 感谢阅读！要不要来看看一个 YouTube 课程？

如果你在这里感到有趣，并且正在寻找一个为初学者和专家都设计的有趣应用 AI 课程，这里有一个我为你的娱乐而制作的：

在这里享受整个课程播放列表：[bit.ly/machinefriend](http://bit.ly/machinefriend)

**[Cassie Kozyrkov](https://kozyrkov.medium.com/)** 是谷歌的数据科学家和领导者，她的使命是使决策智能和安全、可靠的 AI 普及。

[原文](https://kozyrkov.medium.com/the-mistake-every-data-scientist-has-made-at-least-once-3479002211b4)。经许可转载。

### 了解更多相关主题

+   [数据科学已经改变，不是消亡！](https://www.kdnuggets.com/2023/08/data-science-changed-died.html)

+   [Meta 的新数据分析师专业认证已经发布！](https://www.kdnuggets.com/metas-new-data-analyst-professional-certification-has-dropped)

+   [AI 在算法交易中的采用如何影响了……](https://www.kdnuggets.com/2022/04/adoption-ai-algorithmic-trading-affected-finance-industry.html)

+   [HuggingFace 推出了免费的深度强化学习课程](https://www.kdnuggets.com/2022/05/huggingface-launched-free-deep-reinforcement-learning-course.html)

+   [数据湖和 SQL：数据天堂中的绝配](https://www.kdnuggets.com/2023/01/data-lakes-sql-match-made-data-heaven.html)

+   [Pydantic 教程：Python 中的数据验证变得简单](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)
