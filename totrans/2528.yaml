- en: How Machine Learning Leverages Linear Algebra to Solve Data Problems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习如何利用线性代数来解决数据问题
- en: 原文：[https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html](https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html](https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![](../Images/bfd423cfaf9f4d27734f99ac1249cbe6.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bfd423cfaf9f4d27734f99ac1249cbe6.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)'
- en: Machines or your computers only understand numbers and these numbers need to
    be represented and processed in a way that enables these machines to solve problems
    by learning from data instead of predefined instruction as in the case of programming.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器或计算机只能理解数字，这些数字需要以一种方式表示和处理，使这些机器能够通过从数据中学习而不是像编程那样依赖预定义指令来解决问题。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: All types of programming use mathematics at some level and machine learning
    is programming data to learn the function that best describes the data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有类型的编程在某种程度上都使用数学，机器学习是对数据进行编程，以学习最能描述数据的函数。
- en: The problem(or process) of finding the best parameters of a function using data
    is called **model training **in ML.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据找到函数最佳参数的问题（或过程）在机器学习中称为**模型训练**。
- en: Therefore, in a nutshell, machine learning is programming to optimize for the
    best possible solution and we need math to understand how that problem is solved.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总而言之，机器学习就是编程以优化最佳解决方案，我们需要数学来理解问题是如何解决的。
- en: The first step towards learning Math for ML is Linear algebra.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 学习机器学习数学的第一步是线性代数。
- en: '**Linear Algebra is that mathematical foundation that solves the problem of
    representing data as well as computations in machine learning models.**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性代数是解决表示数据和计算在机器学习模型中问题的数学基础。**'
- en: '**It is the math of arrays** — technically referred to as vectors, matrices,
    and tensors.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是数组的数学** — 技术上称为向量、矩阵和张量。'
- en: Common Areas of Application — Linear Algebra in Action
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用的常见领域 — 线性代数的实际应用
- en: '![](../Images/2cc6846103ced3c7a63de659bf1bb505.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cc6846103ced3c7a63de659bf1bb505.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)'
- en: In the ML context, all major phases of developing a model have linear algebra
    running behind the scenes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，开发模型的所有主要阶段背后都运行着线性代数。
- en: 'Important areas of application that are enabled by linear algebra are:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由线性代数使能的重要应用领域包括：
- en: data & learned model representation
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据与学习模型的表示
- en: word embeddings
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词嵌入
- en: dimensionality reduction
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降维
- en: '**Data Representation — **The fuel of ML models, a.k.a. **data**, needs to
    be converted into arrays before feeding into your models, the computations performed
    on these arrays include operations like matrix multiplication(dot product) which
    further returns the output that is also represented as a transformed matrix/tensor
    of numbers.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据表示 —** 机器学习模型的燃料，也就是**数据**，需要在输入模型之前转换成数组，这些数组上执行的计算包括矩阵乘法（点积）等操作，这些操作进一步返回的结果也被表示为转化后的矩阵/张量。'
- en: '![](../Images/6980b736abcfe8843b2ea518afd11ac8.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6980b736abcfe8843b2ea518afd11ac8.png)'
- en: '[https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
- en: '**Word embeddings — **don’t worry about the terminology here, it is just about
    representing large-dimensional data(think of a huge number of variables in your
    data) with a smaller dimensional vector.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**词嵌入 —** 不用担心术语，这只是关于用较小维度的向量表示大维数据（想象一下你数据中的大量变量）。'
- en: Natural Language Processing(NLP) deals with textual data. Dealing with text
    means comprehending the meaning of a large corpus of words and each word represents
    a different meaning which might be similar to another word, vector embeddings
    in linear algebra allow us to represent these words more efficiently.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）处理文本数据。处理文本意味着理解大量单词的含义，每个单词代表不同的意义，这些意义可能与另一个单词相似，线性代数中的向量嵌入使我们能够更有效地表示这些单词。
- en: '**Eigenvectors(SVD)** — Finally, concepts like eigenvectors allow us to reduce
    the number of features or dimensions of the data while keeping the essence of
    all of them using something called **principal component analysis.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征向量（SVD）** — 最后，像特征向量这样的概念使我们能够在保持所有数据本质的同时，减少数据的特征或维度，使用一种叫做**主成分分析**的技术。'
- en: From data to Vectors
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从数据到向量
- en: '![](../Images/f1802792a52cf9c312866fe9bf7e62fb.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1802792a52cf9c312866fe9bf7e62fb.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
- en: Linear algebra basically deals with vectors & matrices(different shapes of arrays)
    and operations on these arrays. In NumPy, vectors are basically a 1-Dimensional
    array of numbers but geometrically, this has both magnitude and direction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数基本上处理向量和矩阵（不同形状的数组）及这些数组上的操作。在 NumPy 中，向量基本上是一个一维的数字数组，但在几何上，它具有大小和方向。
- en: '![](../Images/c55f7691097e60acd80378bf65d936e4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c55f7691097e60acd80378bf65d936e4.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
- en: Our data can be represented using a vector. In the figure above, one row in
    this data is represented by a feature vector that has 3 elements or components
    representing 3 different dimensions. N-entries in a vector make it n-dimensional
    vector space and in this case, we can see 3-dimensions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据可以用向量表示。在上图中，这些数据中的一行由一个特征向量表示，该特征向量有3个元素或成分，表示3个不同的维度。向量中的N个条目使其成为n维向量空间，在这种情况下，我们可以看到3个维度。
- en: Deep Learning — Tensors flowing through a neural network
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习 — 张量在神经网络中流动
- en: Linear algebra can be seen in action across all the major applications today,
    be it sentiment analysis on a LinkedIn or a Twitter post(embeddings), be it detecting
    a type of lung infection from X-ray images(computer vision), or any speech to
    text bot(NLP).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 线性代数在今天所有主要应用中都可以看到，无论是在 LinkedIn 或 Twitter 帖子上的情感分析（嵌入），还是从 X 射线图像中检测肺部感染类型（计算机视觉），或者任何语音到文本的机器人（NLP）。
- en: All of these data types are represented by numbers in tensors and we run vectorized
    operations to learn patterns from them using a neural network which then outputs
    processed tensor which in turn is decoded to produce the final inference of the
    model.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据类型都通过张量中的数字表示，我们运行向量化操作以使用神经网络从中学习模式，然后输出处理过的张量，这些张量反过来被解码以生成模型的最终推断结果。
- en: Dimensionality Reduction — Vector space transformation
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 降维 — 向量空间变换
- en: '![](../Images/dff6198b90f92fb1cc8be1a17893ad21.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dff6198b90f92fb1cc8be1a17893ad21.png)'
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
- en: When it comes to embeddings, you can basically think of an n-dimensional vector
    being replaced with another vector that belongs to a lower-dimensional space which
    is more meaningful and the one that overcomes computational complexities.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 说到嵌入，您可以基本上将一个n维向量想象成被替换成另一个属于较低维空间的向量，这个较低维空间更具意义，并且克服了计算复杂性。
- en: For example, here is a 3-dimensional vector that is replaced by a 2-dimensional
    space but you can extrapolate it to a real-world scenario where you have a very
    large number of dimensions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是一个被替换为二维空间的三维向量，但你可以将其推断到一个现实世界的场景中，在那里你有大量的维度。
- en: Reducing dimensions doesn’t mean dropping features from the data but finding
    new features that are linear functions of the original features and preserves
    the variance of the original features.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 降维并不是从数据中丢弃特征，而是找到新的特征，这些特征是原始特征的线性函数，并且保留了原始特征的方差。
- en: Finding these new variables(features) translates to finding the principal components(PCs)
    which converge to solving eigenvectors and eigenvalues problems.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 找到这些新变量（特征）意味着找到主成分（PCs），这些主成分收敛于解决特征值和特征向量问题。
- en: Recommendation Engines — Making use of embeddings
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐引擎 — 利用嵌入
- en: You can think of Embedding as a 2D plane being embedded in a 3D space and that’s
    where this term comes from. You can think of the ground you are standing on as
    a 2D plane that is embedded into this space in which we live.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将嵌入（Embedding）视为一个 2D 平面嵌入在 3D 空间中，这就是这个术语的来源。你可以把你站立的地面想象成一个嵌入在我们生活的空间中的
    2D 平面。
- en: Just to give you a real-world use case to relate to all of this discussion on
    vector embeddings, all applications that are giving you personalized recommendations
    are using vector embedding in some form.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 只是为了给你一个现实世界的用例，让你与向量嵌入的讨论相关联，所有给你个性化推荐的应用程序都以某种形式使用了向量嵌入。
- en: '![](../Images/62fa0dcf8d7b91e435b1e2f2fcef1a39.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62fa0dcf8d7b91e435b1e2f2fcef1a39.png)'
- en: For example, here is a graphic from Google’s course on recommendation systems
    where we are given this data on different users and their preferred movies. Some
    users are kids and others are adults, some movies were are all-time classics while
    others are more artistic. Some movies are targeted towards a younger audience
    while movies like memento are preferred by adults.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是 Google 推荐系统课程中的一张图，我们获得了关于不同用户及其偏好电影的数据。一些用户是孩子，另一些是成年人，一些电影是永恒的经典，而另一些则更具艺术性。一些电影是针对年轻观众的，而像《记忆碎片》这样的电影则更受成年人欢迎。
- en: Now, we not only need to represent this information in numbers but also need
    to find new smaller dimensional vector representations that capture all these
    features well.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不仅需要将这些信息表示为数字，还需要找到新的、更小维度的向量表示，以便很好地捕捉所有这些特征。
- en: '![](../Images/28af5bb2a270796195f820a72973e946.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28af5bb2a270796195f820a72973e946.png)'
- en: 'Source: Google’s Machine Learning Course on recommendation systems'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Google 的推荐系统机器学习课程
- en: A very quick way to understand how we can pull this task is by understanding
    something called Matrix Factorization which allows us to break a large matrix
    down into smaller matrices.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 了解我们如何执行这项任务的一种非常快速的方法是理解矩阵分解（Matrix Factorization），它允许我们将一个大矩阵分解为较小的矩阵。
- en: Ignore the numbers and colors for now and just try to understand how we have
    broken down one big matrix into two smaller ones.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在忽略这些数字和颜色，只需尝试理解我们如何将一个大矩阵分解成两个较小的矩阵。
- en: For example, here this matrix of 4X5, 4 rows, and 5 features were broken down
    into two matrices, one of the shape 4X2 and the other of shape 2X5\. We basically
    have new smaller dimensional vectors for users and movies.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里一个 4X5 的矩阵，4 行 5 特征，被分解成两个矩阵，一个形状为 4X2，另一个形状为 2X5。我们基本上得到了用户和电影的新较小维度的向量。
- en: '![](../Images/93d13f18bbdb51854a94c4f4aee7cdee.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93d13f18bbdb51854a94c4f4aee7cdee.png)'
- en: 'And this allows us to plot this on a 2D vector space, and here you’ll see that
    user #1 and the movie Harry Potter are closer and user #3 and the movie Shrek
    are closer.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '这使我们可以在 2D 向量空间中绘制图形，在这里你会看到用户 #1 和电影《哈利·波特》更接近，而用户 #3 和电影《怪物史瑞克》更接近。'
- en: The concept of **dot product(matrix multiplication)** of vectors tells us more
    about the similarity of two vectors. And it has applications in correlation/covariance
    calculation, linear regression, logistic regression, PCA, convolutions, PageRank,
    and numerous other algorithms.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**点积（矩阵乘法）**的概念告诉我们两个向量的相似性更多的信息。它在相关性/协方差计算、线性回归、逻辑回归、PCA、卷积、PageRank 和许多其他算法中都有应用。'
- en: Industries where you see LA being used heavily
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性代数被广泛使用的行业
- en: 'By now, I hope you are convinced that Linear algebra is driving the ML initiatives
    in a host of areas today. If not, here is a list to name a few:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我希望你已经相信线性代数在当今多个领域的机器学习（ML）倡议中发挥了重要作用。如果没有，以下是一些例子：
- en: Statistics
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计学
- en: Chemical Physics
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 化学物理学
- en: Genomics
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因组学
- en: Word Embeddings — neural networks/deep learning
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单词嵌入 — 神经网络/深度学习
- en: Robotics
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人技术
- en: Image Processing
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像处理
- en: Quantum Physics
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量子物理学
- en: How much should you know to get started with ML / DL
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你应该了解多少才能开始学习 ML / DL
- en: Now, the important question is how can you learn to program these concepts of
    linear algebra. So, the answer is you don’t have to reinvent the wheel, you just
    need to understand the basics of vector algebra computationally and you then learn
    to program those concepts using NumPy.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，重要的问题是如何学习编程这些线性代数概念。因此，答案是你不需要重新发明轮子，你只需计算机上理解向量代数的基础，然后学习使用NumPy编程这些概念。
- en: NumPy is a scientific computation package that gives us access to all the underlying
    concepts of linear algebra. It is fast as it runs compiled C code and it has a
    large number of mathematical and scientific functions that we can use.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy是一个科学计算包，提供了线性代数所有基础概念的访问。它运行编译的C代码，速度快，并且有大量的数学和科学函数可供使用。
- en: Recommended resources
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐资源
- en: '[**Playlist on Linear Algebra by 3Blue1Brown**](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B)—
    very engaging visualizations that explain the essence of linear algebra and its
    applications. Might be a little too hard for beginners.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**3Blue1Brown 的线性代数播放列表**](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B)
    — 非常吸引人的可视化，解释了线性代数的本质及其应用。对初学者来说可能有点困难。'
- en: '[**Book on Deep Learning by Ian Goodfellow & Yoshua Bengio**](https://www.deeplearningbook.org/)** —** a
    fantastic resource for learning ML and applied math. Give it a read, few folks
    may find it too technical and notation-heavy, to begin with.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Ian Goodfellow 和 Yoshua Bengio 的深度学习书籍**](https://www.deeplearningbook.org/)**
    —** 一本学习ML和应用数学的绝佳资源。值得一读，刚开始时可能会觉得过于技术性和符号繁重。'
- en: '[**Foundations of Data Science & ML —**](https://www.wiplane.com/p/foundations-for-data-science-ml) I
    have created a course that gives you enough understanding of Programming, Math(Basic
    Algebra, Linear Algebra & Calculus), and Statistics. A complete package for the
    first steps to learning DS/ML. Learn more [**here**](https://www.wiplane.com/p/foundations-for-data-science-ml).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据科学与ML基础 —**](https://www.wiplane.com/p/foundations-for-data-science-ml)
    我创建了一个课程，让你对编程、数学（基础代数、线性代数和微积分）和统计学有足够的理解。一个完整的学习DS/ML的起步包。了解更多[**这里**](https://www.wiplane.com/p/foundations-for-data-science-ml)。'
- en: ???? You can use the code `TDS10` to get 10% off.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ???? 你可以使用代码`TDS10`获得10%的折扣。
- en: 'Check out the course outline:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 查看课程大纲：
- en: '**Bio: [Harshit Tyagi](https://www.linkedin.com/in/tyagiharshit/)** is an engineer
    with amalgamated experience in web technologies and data science(aka full-stack
    data science). He has mentored over 1000 AI/Web/Data Science aspirants, and is
    designing data science and ML engineering learning tracks. Previously, Harshit
    developed data processing algorithms with research scientists at Yale, MIT, and
    UCLA.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Harshit Tyagi](https://www.linkedin.com/in/tyagiharshit/)** 是一位在网络技术和数据科学（即全栈数据科学）方面具有丰富经验的工程师。他指导了超过1000名AI/Web/数据科学的
    aspirants，并设计了数据科学和ML工程学习路径。之前，Harshit与耶鲁、麻省理工学院和UCLA的研究科学家一起开发数据处理算法。'
- en: '[Original](https://dswharshit.medium.com/how-machine-learning-leverages-linear-algebra-to-solve-data-problems-4e210a644508).
    Reposted with permission.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://dswharshit.medium.com/how-machine-learning-leverages-linear-algebra-to-solve-data-problems-4e210a644508)。经许可转载。'
- en: '**Related:**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Data Science Learning Roadmap for 2021](/2021/02/data-science-learning-roadmap-2021.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年数据科学学习路线图](/2021/02/data-science-learning-roadmap-2021.html)'
- en: '[Linear Algebra for Natural Language Processing](/2021/08/linear-algebra-natural-language-processing.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的线性代数](/2021/08/linear-algebra-natural-language-processing.html)'
- en: '[Antifragility and Machine Learning](/2021/09/antifragility-machine-learning.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[抗脆弱性与机器学习](/2021/09/antifragility-machine-learning.html)'
- en: More On This Topic
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[想利用你的数据技能解决全球问题？看看这个……](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学项目可以帮助你解决实际问题](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
- en: '[Top 3 Free Resources to Learn Linear Algebra for Machine Learning](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习机器学习的线性代数的三个免费资源](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
- en: '[KDnuggets News, July 13: Linear Algebra for Data Science; 10 Modern…](https://www.kdnuggets.com/2022/n28.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，7月13日：数据科学的线性代数；10个现代……](https://www.kdnuggets.com/2022/n28.html)'
- en: '[Linear Algebra for Data Science](https://www.kdnuggets.com/2022/07/linear-algebra-data-science.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的线性代数](https://www.kdnuggets.com/2022/07/linear-algebra-data-science.html)'
- en: '[5 Free Courses to Master Linear Algebra](https://www.kdnuggets.com/2022/10/5-free-courses-master-linear-algebra.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握线性代数的5个免费课程](https://www.kdnuggets.com/2022/10/5-free-courses-master-linear-algebra.html)'
