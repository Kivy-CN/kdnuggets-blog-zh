# 机器学习的学习曲线

> 原文：[https://www.kdnuggets.com/2018/01/learning-curves-machine-learning.html](https://www.kdnuggets.com/2018/01/learning-curves-machine-learning.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/01/learning-curves-machine-learning.html?page=2#comments)

**作者：[Alex Olteanu](https://www.dataquest.io/blog/author/alex-olteanu/)，Dataquest.io 的学生成功专家**

在构建机器学习模型时，我们希望尽可能降低误差。误差的两个主要来源是偏差和方差。如果我们能够减少这两者，那么我们就可以构建更准确的模型。

那么我们首先如何诊断偏差和方差呢？一旦检测到问题，我们应该采取什么措施？

在这篇文章中，我们将学习如何使用学习曲线回答这两个问题。我们将使用一个真实的数据集，尝试预测发电厂的电能输出。

![topimage](../Images/b33264e06b657964ebe236ca92cc602e.png)

我们将生成学习曲线，同时尝试预测发电厂的电能输出。图片来源： [Pexels](https://www.pexels.com/photo/black-metal-current-posts-157827/)。

假设你对 scikit-learn 和机器学习理论有一定的了解。如果当我提到 *交叉验证* 或 *监督学习* 时你没有皱眉头，那么你可以继续。如果你对机器学习还很陌生且从未尝试过 scikit，建议从 [这篇博客文章](https://www.dataquest.io/blog/machine-learning-tutorial/) 开始。

我们从对偏差和方差的简要介绍开始。

### 偏差-方差权衡

在监督学习中，我们 *假设* 特征和目标之间存在真实的关系，并用模型来估计这种未知的关系。假如假设成立，确实存在一个模型，我们称之为 ![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png)，它完美描述了特征和目标之间的关系。

在实际操作中， ![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png) 几乎总是完全未知的，我们尝试用模型来估计它 ![Equation](../Images/a94d66a6aee949360df0defda68828.png)（注意 ![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png) 和 ![Equation](../Images/a94d66a6aee949360df0defda68828.png) 之间的符号略有不同）。我们使用一个 *特定* 的训练集，得到一个 *特定* 的 ![Equation](../Images/a94d66a6aee949360df0defda68828.png)。如果我们使用不同的训练集，很可能会得到不同的 ![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。随着训练集的不断变化，我们会得到不同的 ![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。随着训练集的变化， ![Equation](../Images/f882e047405752e27ee94c30f948ef78.png) 的变化量被称为 **方差**。

为了估计真实的![Equation](../Images/0124e78268c96059dbff35809fb67ffe.png)，我们使用不同的方法，如线性回归或随机森林。例如，线性回归假设特征与目标之间存在线性关系。然而，对于大多数现实场景，特征与目标之间的真实关系复杂且远非线性。简化的假设会给模型带来**偏差**。假设与真实关系的偏差越大，偏差也越高，反之亦然。

通常，模型![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)在一些测试数据上会有一些误差。可以通过[数学方法](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff#Bias.E2.80.93variance_decomposition_of_squared_error)证明，偏差和方差只能增加模型的误差。我们希望误差较低，因此需要将偏差和方差保持在最小。然而，这并不完全可能。偏差和方差之间存在权衡。

低偏差的方法在训练数据上的拟合非常好。如果我们更改训练集，将会得到显著不同的模型![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。

![low_bias](../Images/ab1470baaa9fe78506fbcac164556371.png)

你可以看到，低偏差的方法捕捉了不同训练集之间的大多数差异（甚至是微小的差异）。![Equation](../Images/f882e047405752e27ee94c30f948ef78.png) *变化* 很大，这表明了高方差。

偏差越小的方法，拟合数据的能力越强。这种能力越强，方差也越高。因此，偏差越低，方差越大。

反之亦然：偏差越大，方差越低。高偏差的方法构建的简单模型通常不适合训练数据。当我们更改训练集时，高偏差算法得到的模型一般彼此之间差异不大。

![high_bias](../Images/86c72c905bc8f130a0bba3d54a627202.png)

如果在更改训练集时![Equation](../Images/f882e047405752e27ee94c30f948ef78.png)变化不大，那么方差较低，这证明了我们的观点：偏差越大，方差越低。

从数学角度来看，我们清楚为何要低偏差和低方差。如上所述，偏差和方差只能增加模型的误差。然而，从更直观的角度来看，我们希望低偏差，以避免构建一个过于简单的模型。在大多数情况下，一个简单的模型在训练数据上的表现较差，并且很可能在测试数据上重复这种不良表现。

类似地，我们希望降低方差以避免建立过于复杂的模型。这样的模型几乎完美地拟合了训练集中的所有数据点。然而，训练数据通常包含噪声，并且只是来自更大人群的一个样本。一个过于复杂的模型会捕捉到这些噪声。当在*out-of-sample*数据上测试时，性能通常较差。这是因为模型过于精确地学习了*样本*训练数据。它对某些东西了解很多，但对其他方面了解甚少。

实际上，我们需要接受一种权衡。我们不能同时拥有低偏差和低方差，因此我们希望在两者之间找到一个平衡点。

![biasvariance](../Images/6938ccb23dc3c764c12b74135c1b9c98.png)

来源： [Scott Fortmann-Roe - 理解偏差-方差权衡](http://scott.fortmann-roe.com/docs/BiasVariance.html)

我们将在下面生成和解释学习曲线时，尝试建立对这种权衡的实际直觉。

### 学习曲线 - 基本概念

假设我们有一些数据并将其拆分为训练集和[验证集](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set#19051)。我们从训练集中取一个单独的实例（没错，就是一个！）并用它来估计模型。然后我们测量模型在验证集和那个单一训练实例上的错误。训练实例上的错误将是0，因为完美拟合单个数据点相对容易。然而，验证集上的错误将非常大。这是因为模型围绕一个单一实例建立，几乎肯定无法在未见过的数据上准确泛化。

现在假设我们不是取一个训练实例，而是取十个并重复错误测量。然后我们取五十个、一百个、五百个，直到我们使用整个训练集。随着我们改变训练集，错误评分将或多或少地变化。

因此，我们有两个错误评分需要监控：一个是验证集的，另一个是训练集的。如果我们绘制这两个错误评分随着训练集变化的演变，我们将得到两条曲线。这些被称为*学习曲线*。

简而言之，学习曲线展示了随着训练集大小增加，错误如何变化。下面的图表应该能帮助你可视化到目前为止描述的过程。在训练集栏中，你可以看到我们不断增加训练集的大小。这导致了模型的微小变化！[Equation](../Images/f882e047405752e27ee94c30f948ef78.png)。

在第一行中，其中 n = 1 (*n* 是训练实例的数量)，模型完美拟合了那个单一的训练数据点。然而，同样的模型对20个不同数据点的验证集拟合非常差。因此，模型在训练集上的错误为0，但在验证集上的错误则高得多。

随着训练集大小的增加，模型不能再完美地拟合训练集。因此，训练误差变大。然而，模型在更多数据上训练，因此它能够更好地拟合验证集。因此，验证误差减少。提醒一下，验证集在所有三个情况下保持不变。

![模型](../Images/266e92e6dd9cc26c3063532071441905.png)

如果我们绘制每个训练大小的误差分数，我们会得到两个看起来类似于这些的学习曲线：

![学习曲线](../Images/41b716750016cb9f85f40fba3a46795d.png)

学习曲线为我们提供了诊断监督学习模型中的偏差和方差的机会。接下来我们将看到这如何实现。

### 引入数据

上面绘制的学习曲线是为了教学目的而理想化的。然而，在实际应用中，它们通常看起来会有所不同。因此，让我们通过使用一些真实世界的数据，将讨论转移到实际设置中。

我们将尝试建立预测发电厂每小时电力输出的回归模型。我们使用的数据来自土耳其研究人员Pınar Tüfekci和Heysem Kaya，可以从[这里](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)下载。由于数据存储在`.xlsx`文件中，我们使用pandas的`read_excel()` [函数](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html?highlight=read_excel#pandas.read_excel)来读取它：

```py
import pandas as pd

electricity = pd.read_excel('Folds5x2_pp.xlsx')

print(electricity.info())
electricity.head(3)
```

```py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 9568 entries, 0 to 9567
Data columns (total 5 columns):
AT    9568 non-null float64
V     9568 non-null float64
AP    9568 non-null float64
RH    9568 non-null float64
PE    9568 non-null float64
dtypes: float64(5)
memory usage: 373.8 KB
None
```

|  | AT | V | AP | RH | PE |
| --- | :-- | :-- | :-- | :-- | :-- |
| 0 | 14.96 | 41.76 | 1024.07 | 73.17 | 463.26 |
| 1 | 25.18 | 62.96 | 1020.04 | 59.08 | 444.37 |
| 2 | 5.11 | 39.40 | 1012.16 | 92.14 | 488.56 |

让我们快速解读每一列的名称：

| ABBREVIATION | 全名 |
| :-- | :-- |
| AT | 环境温度 |
| V | 排气真空 |
| AP | 环境压力 |
| RH | 相对湿度 |
| PE | 电力输出 |

`PE`列是目标变量，它描述了每小时的电力输出。所有其他变量都是潜在特征，每个变量的值实际上是每小时的平均值（不是净值，像`PE`一样）。

电力由燃气轮机、蒸汽轮机和余热回收蒸汽发生器生成。根据数据集的文档，真空度对蒸汽轮机有影响，而其他三个变量则影响燃气轮机。因此，我们将在回归模型中使用所有特征列。

在这一步，我们通常会放置一个测试集，彻底探索训练数据，移除任何离群值，测量相关性等。然而，为了教学目的，我们将假设这些工作已经完成，直接生成一些学习曲线。在开始之前，值得注意的是没有缺失值。此外，数据是未经缩放的，但我们将避免使用对未缩放数据有问题的模型。

### 决定训练集大小

首先决定我们要使用什么训练集大小来生成学习曲线。

最小值是1。最大值由训练集中的实例数量决定。我们的训练集有9568个实例，因此最大值是9568。

然而，我们还没有预留出一个验证集。我们将使用80:20的比例，最终得到一个7654个实例的训练集（80%），以及一个1914个实例的验证集（20%）。鉴于我们的训练集有7654个实例，我们生成学习曲线时可以使用的最大值是7654。

对于我们的情况，我们使用这六个大小：

```py
train_sizes = [1, 100, 500, 2000, 5000, 7654]
```

一个重要的注意事项是，对于每个指定的大小都会训练一个新的模型。如果你使用交叉验证，我们将在这篇文章中使用*k*个模型（其中*k*由交叉验证中使用的折数决定）。为了节省代码运行时间，最好将训练集大小限制在5-10个。

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 更多相关话题

+   [KDnuggets 新闻，12月14日：3 个免费的机器学习课程…](https://www.kdnuggets.com/2022/n48.html)

+   [每个机器学习工程师应该掌握的5种机器学习技能…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)

+   [学习数据科学、机器学习和深度学习的坚实计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)

+   [人工智能、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)

+   [突破数据障碍：零样本、单样本和少样本学习…](https://www.kdnuggets.com/2023/08/breaking-data-barrier-zeroshot-oneshot-fewshot-learning-transforming-machine-learning.html)

+   [联邦学习：带教程的协作机器学习…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)
