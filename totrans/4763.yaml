- en: Introduction to Deep Learning with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 深度学习简介
- en: 原文：[https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html/2](https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html/2](https://www.kdnuggets.com/2018/10/introduction-deep-learning-keras.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/10/introduction-deep-learning-keras.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/10/introduction-deep-learning-keras.html?page=2#comments)'
- en: '****Compiling the ANN****'
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****编译人工神经网络****'
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Compiling is basically applying a stochastic gradient descent to the whole neural
    network. The first parameter is the algorithm you want to use to get the optimal
    set of weights in the neural network. The algorithm used here is a stochastic
    gradient algorithm. There are many variants of this. A very efficient one to use
    is adam. The second parameter is the loss function within the stochastic gradient
    algorithm. Since our categories are binary we use the *binary_crossentropy *loss
    function. Otherwise we would have used *categorical_crossentopy. *The final argument
    is the criterion we’ll use to evaluate our model. In this case we use the accuracy.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 编译基本上是将随机梯度下降应用于整个神经网络。第一个参数是你想用来获得神经网络最佳权重集合的算法。这里使用的算法是随机梯度算法。这有很多变体，一种非常有效的是
    adam。第二个参数是随机梯度算法中的损失函数。由于我们的类别是二元的，我们使用 *binary_crossentropy* 损失函数。否则我们会使用 *categorical_crossentropy*。最后一个参数是我们用来评估模型的标准。在这种情况下，我们使用准确率。
- en: '****Fitting our ANN to the training set****'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****将我们的人工神经网络拟合到训练集****'
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: X_train represents the independent variables we’re using to train our ANN, and
    y_train represents the column we’re predicting. Epochs represents the number of
    times we’re going to pass our full dataset through the ANN. Batch_size is the
    number of observations after which the weights will be updated.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: X_train 代表我们用来训练人工神经网络的自变量，而 y_train 代表我们要预测的列。Epochs 代表我们将数据集通过人工神经网络的次数。Batch_size
    是更新权重后的一组观察值的数量。
- en: '****Predicting using the training set****'
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****使用训练集进行预测****'
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will show us the probability of a claim being fraudulent. We then set a
    threshold of 50% for classifying a claim as fraudulent. This means that any claim
    with a probability of 0.5 or more will be classified as fraudulent.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这将展示索赔是欺诈性的概率。然后我们设定了一个 50% 的阈值来将索赔分类为欺诈性。这意味着任何概率为 0.5 或以上的索赔将被分类为欺诈性。
- en: '[PRE3]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This way the insurance firm can be able to first track claims that are not suspicious
    and then take more time evaluating claims flagged as fraudulent.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，保险公司可以首先跟踪那些不被怀疑的索赔，然后花更多时间评估被标记为欺诈的索赔。
- en: '****Checking the confusion matrix****'
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****检查混淆矩阵****'
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/800b08e12858392425e5c21b213ab1af.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/800b08e12858392425e5c21b213ab1af.png)'
- en: The confusion matrix can be interpreted as follows. Out of 2000 observations,
    1550 + 175 observations were correctly predicted while 230 + 45 were incorrectly
    predicted. You can calculate the accuracy by dividing the number of correct predictions
    by the total number of predictions. In this case (1550+175) / 2000, which gives
    you 86%.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵可以这样解释。在 2000 个观察值中，1550 + 175 个被正确预测，而 230 + 45 个被错误预测。你可以通过将正确预测的数量除以预测的总数来计算准确率。在这种情况下是
    (1550+175) / 2000，结果是 86%。
- en: '****Making a single Prediction****'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****做出单一预测****'
- en: Let’s say the insurance company gives you a single claim. They’d like to know
    if the claim is fraudulent. What would you do to find out?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设保险公司给你一个索赔，他们希望知道这个索赔是否是欺诈性的。你会怎么做来找出答案？
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: where a,b,c,d represents the features you have.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 a、b、c、d 代表你拥有的特征。
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Since our classifier expects numpy arrays, we have to transform the single observation
    into a numpy array and use the standard scaler to scale it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的分类器期望的是 numpy 数组，我们必须将单个观察值转换为 numpy 数组，并使用标准缩放器进行缩放。
- en: '****Evaluating our ANN****'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****评估我们的人工神经网络****'
- en: After training the model one or two times, you’ll notice that you keep getting
    different accuracies. So you’re not quite sure which one is the right one. This
    introduces the bias variance trade off. In essence, we’re trying to train a model
    that will be accurate and not have too much variance of accuracy when trained
    several times. To solve this problem we use the K-fold cross validation with K
    equal to 10\. This will split the training set into 10 folds. We’ll then train
    our model on 9 folds and test it on the remaining fold. Since we have 10 folds,
    we’re going to do this iteratively through 10 combinations. Each iteration will
    gives us its accuracy. We’ll then find the mean of all accuracies and use that
    as our model accuracy. We also calculate the variance to ensure that it’s minimal.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型一两次后，你会注意到准确度不断变化。这使得你不太确定哪一个是正确的。这引入了偏差方差权衡。本质上，我们试图训练一个模型，使其准确且在多次训练时不会有太大的准确度方差。为了解决这个问题，我们使用K折交叉验证，K等于10。这将把训练集分成10折。然后我们将在9折上训练模型，并在剩下的折上测试。由于我们有10折，我们将通过10种组合进行迭代。每次迭代都会给我们一个准确度。然后我们计算所有准确度的均值，并将其作为我们的模型准确度。我们还计算方差，以确保其最小。
- en: Keras has a scikit learn wrapper (KerasClassifier) that enables us to include
    K-fold cross validation in our keras code.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Keras有一个scikit learn的封装器（KerasClassifier），使我们可以在我们的Keras代码中包含K折交叉验证。
- en: '[PRE7]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next we import the k-fold cross validation function from scikit_learn
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们从scikit_learn导入k折交叉验证函数。
- en: '[PRE8]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The KerasClassifier expects one of its arguments to be a function, so we need
    to build that function.The purpose of this function is to build the architecture
    of our ANN.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: KerasClassifier期望其参数之一是一个函数，因此我们需要构建这个函数。这个函数的目的是建立我们的ANN架构。
- en: This function will build the classifier and return it for use in the next step.
    The only thing we have done here is wrap our previous ANN architecture in a function
    and return the classifier.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将构建分类器并返回，以便在下一步中使用。我们在这里做的唯一事情就是将我们之前的ANN架构封装在一个函数中并返回分类器。
- en: We then create a new classifier using K-fold cross validation and pass the parameter *build_fn *as
    the function we just created above. Next we pass the batch size and the number
    of epochs, just like we did in the previous classifier.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个新的分类器，使用K折交叉验证，并将参数*build_fn*传递为我们刚刚创建的函数。接下来，我们传递批次大小和训练轮数，就像我们在之前的分类器中做的那样。
- en: '[PRE9]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To apply the k-fold cross validation function we can use scikit-learn’s *cross_val_score* function.
    The estimator is the classifier we just built with *make_classifier* and n_jobs=-1
    will make use of all available CPUs. cv is the number of folds and 10 is a typical
    choice. The *cross_val_score *will return the ten accuracies of the ten test folds
    used in the computation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用k折交叉验证函数，我们可以使用scikit-learn的*cross_val_score*函数。估算器是我们刚刚用*make_classifier*构建的分类器，n_jobs=-1将利用所有可用的CPU。cv是折数，10是一个典型的选择。*cross_val_score*将返回计算中使用的十个测试折的准确度。
- en: '[PRE10]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To obtain the relative accuracies we get the mean of the accuracies.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得相对准确度，我们需要计算准确度的均值。
- en: '[PRE11]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The variance can be obtained as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 方差可以按以下方式获得：
- en: '[PRE12]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The goal is to have a small variance between the accuracies.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是使准确度之间的方差尽可能小。
- en: '****Fighting Overfitting****'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****对抗过拟合****'
- en: Overfitting in machine learning is what happens when a model learns the details
    and noise in the training set such that it performs poorly on the test set. This
    can be observed when we have huge differences between the accuracies of the test
    set and training set or when you observe a high variance when applying k-fold
    cross validation. In artificial neural networks, we counteract this using a technique
    called dropout regularization. Dropout regularization works by randomly disabling
    some neurons at each iteration of the training to prevent them from being too
    dependent on each other.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，过拟合是指模型学习了训练集中的细节和噪声，从而在测试集上表现不佳。这可以通过测试集和训练集的准确度之间存在巨大差异，或在应用k折交叉验证时观察到高方差来发现。在人工神经网络中，我们使用一种叫做丢弃正则化的技术来对抗这一问题。丢弃正则化通过在每次训练迭代时随机禁用一些神经元，以防止它们过于依赖彼此。
- en: In this case we apply the dropout after the first hidden layer and after the
    second hidden layer. Using a rate of 0.1 means that 1% of the neurons will be
    disabled at each iteration. It is advisable to start with a rate of 0.1\. However
    you should never go beyond 0.4 because you will now start to get underfitting.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们在第一个隐藏层和第二个隐藏层之后应用 dropout。使用0.1的比率意味着每次迭代时1%的神经元将被禁用。建议从0.1的比率开始。然而，你绝不要超过0.4，因为这会导致欠拟合。
- en: '****Parameter Tuning****'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '****参数调优****'
- en: Once you obtain your accuracy you can tune the parameters to get a higher accuracy.
    Grid Search enable us to test different parameters in order to obtain the best
    parameters.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得准确率，你可以调整参数以获得更高的准确率。网格搜索使我们能够测试不同的参数，以获得最佳参数。
- en: The first step here is to import the *GridSearchCV *module from sklearn.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是从sklearn中导入 *GridSearchCV *模块。
- en: '[PRE13]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We also need to modify our make_classifier function as follows. We create a
    new variable called ***optimizer ***that will allow us to add more than one optimizer
    in our params variable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要按如下方式修改我们的make_classifier函数。我们创建一个名为 ***optimizer ***的新变量，以便在我们的params变量中添加多个优化器。
- en: We’ll still use the KerasClassifier, but we won’t pass the batch size and number
    of epochs since these are the parameters we want to tune.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然使用KerasClassifier，但不传递批量大小和迭代次数，因为这些是我们想要调优的参数。
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The next step is to create a dictionary with the parameters we’d like to tune — in
    this case the batch size, the number of epochs, and the optimizer function. We
    still use adam as an optimizer and add a new one called rmsprop. The Keras documentation
    recommends rmsprop when dealing with Recurrent Neural Networks. However we can
    try it for this ANN to see if it gives us a better result.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个包含我们想要调优的参数的字典——在这个例子中是批量大小、迭代次数和优化器函数。我们仍然使用adam作为优化器，并添加一个名为rmsprop的新优化器。Keras文档推荐在处理递归神经网络时使用rmsprop。然而，我们可以尝试在这个人工神经网络中使用它，看是否能得到更好的结果。
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We then use Grid Search to test these parameters. The grid search function expects
    our estimator, the parameters we just defined, the scoring metric and the number
    of k-folds.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用网格搜索来测试这些参数。网格搜索函数期望我们的估算器、我们刚刚定义的参数、评分指标和折叠数。
- en: '[PRE16]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Like in previous objects we need to fit our training set.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 像以前的对象一样，我们需要对训练集进行拟合。
- en: '[PRE17]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can get the best selection of parameters using *best_params *from the grid
    search object. Likewise we use the best_score_ to get the best score.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用*best_params*从网格搜索对象中获取最佳参数选择。同样，我们使用best_score_来获取最佳分数。
- en: '[PRE18]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It’s important to note that this process will take a while as it searches for
    the best parameters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这个过程会花费一些时间，因为它会搜索最佳参数。
- en: '**Conclusion**'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Artificial Neural Networks are just one type of deep neural network. There are
    other networks such Recurrent Neural Networks (RNN), Convolutional Neural Network
    (CNN), and Boltzmann machine. RNNs can predict if the price of a stock will go
    up or down in the future. CNNs are used in computer vision — recognizing cats
    and dogs in a set of images or recognizing the presence of cancer cells in a brain
    image. Boltzmann machines are used in programming recommender systems. Maybe we
    can cover one of these neural networks in the future.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络只是深度神经网络的一种。还有其他网络，例如递归神经网络（RNN）、卷积神经网络（CNN）和玻尔兹曼机。RNN可以预测股票价格未来是上涨还是下跌。CNN用于计算机视觉——例如识别图像中的猫和狗或识别脑部图像中的癌细胞。玻尔兹曼机用于编程推荐系统。也许我们可以在未来讨论这些神经网络中的某一个。
- en: Cheers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 干杯。
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Derrick Mwiti](https://derrickmwiti.com/)** 是一位数据分析师、作家和导师。他致力于在每个任务中交付卓越的成果，并且是Lapid
    Leaders Africa的导师。'
- en: '[Original](https://heartbeat.fritz.ai/introduction-to-deep-learning-with-keras-c7c3d14e1527).
    Reposted with permission.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/introduction-to-deep-learning-with-keras-c7c3d14e1527)。经许可转载。'
- en: '**Related:**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The Keras 4 Step Workflow](/2018/06/keras-4-step-workflow.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras 4步工作流程](/2018/06/keras-4-step-workflow.html)'
- en: '[7 Steps to Mastering Deep Learning with Keras](/2017/10/seven-steps-deep-learning-keras.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握Keras深度学习的7个步骤](/2017/10/seven-steps-deep-learning-keras.html)'
- en: '[Beginner Data Visualization & Exploration Using Pandas](/2018/10/beginner-data-visualization-exploration-using-pandas-beginner.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者数据可视化与探索使用 Pandas](/2018/10/beginner-data-visualization-exploration-using-pandas-beginner.html)'
- en: '* * *'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[Keras 3.0: Everything You Need To Know](https://www.kdnuggets.com/2023/07/keras-30-everything-need-know.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras 3.0：你需要知道的一切](https://www.kdnuggets.com/2023/07/keras-30-everything-need-know.html)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库介绍：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学、机器学习和深度学习的实用计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月27日：简要介绍 Papers With Code；…](https://www.kdnuggets.com/2022/n17.html)'
- en: '[Introduction to Statistical Learning, Python Edition: Free Book](https://www.kdnuggets.com/2023/07/introduction-statistical-learning-python-edition-free-book.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学习导论，Python 版：免费图书](https://www.kdnuggets.com/2023/07/introduction-statistical-learning-python-edition-free-book.html)'
