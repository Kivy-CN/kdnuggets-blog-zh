- en: A Rising Library Beating Pandas in Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越 Pandas 性能的 Rising Library
- en: 原文：[https://www.kdnuggets.com/2020/12/rising-library-beating-pandas-performance.html](https://www.kdnuggets.com/2020/12/rising-library-beating-pandas-performance.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/12/rising-library-beating-pandas-performance.html](https://www.kdnuggets.com/2020/12/rising-library-beating-pandas-performance.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Ezz El Din Abdullah](https://www.linkedin.com/in/ezzeddinabdullah/),
    Data Platform Engineer**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Ezz El Din Abdullah](https://www.linkedin.com/in/ezzeddinabdullah/)，数据平台工程师**'
- en: '![Header image](../Images/69442ed2c7287d82e6fe40287b3f23b9.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Header image](../Images/69442ed2c7287d82e6fe40287b3f23b9.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持你的组织
    IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**pandas **was initially released in 2008 written in [Python, Cython, and C](https://en.wikipedia.org/wiki/Pandas_%28software%29).
    Today, we’re comparing the performance of this well-known library with [**pypolars**](https://github.com/ritchie46/polars),
    a rising DataFrame library written in Rust. We compare the two while sorting and
    concatenating a 25Mil-record data and also when joining two CSVs.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas** 最初在 2008 年发布，使用 [Python, Cython 和 C](https://en.wikipedia.org/wiki/Pandas_%28software%29)
    编写。今天，我们将比较这个著名库与 [**pypolars**](https://github.com/ritchie46/polars) 的性能，后者是一个使用
    Rust 编写的新兴 DataFrame 库。我们在排序和连接 2500 万记录的数据以及连接两个 CSV 文件时进行了比较。'
- en: Downloading Reddit Usernames data
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载 Reddit 用户名数据
- en: 'Let’s first download a CSV file that contains ~26 million reddit usernames
    from Kaggle: [https://www.kaggle.com/colinmorris/reddit-usernames](https://www.kaggle.com/colinmorris/reddit-usernames)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先从 Kaggle 下载一个包含约 2600 万个 Reddit 用户名的 CSV 文件：[https://www.kaggle.com/colinmorris/reddit-usernames](https://www.kaggle.com/colinmorris/reddit-usernames)
- en: 'And let’s form another CSV file that we will use, you can create it with your
    favorite text editor or through the command line:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建另一个 CSV 文件，你可以使用你喜欢的文本编辑器或通过命令行创建它：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Sorting
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 排序
- en: 'Now, let’s compare the sorting algorithm of the two:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们比较这两种排序算法：
- en: '**pandas**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**pypolars**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**pypolars**'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**~24 seconds meaning pypolars here is 1.4x faster than pandas**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**约 24 秒，意味着 pypolars 在这里比 pandas 快 1.4 倍**'
- en: Concatenation
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 级联
- en: We’ll see now how each will perform while concatenating two data frames and
    stacking them into one data frame
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将查看在连接两个数据框并将它们堆叠成一个数据框时每种工具的表现
- en: '**pandas**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: 18 seconds taken by pandas
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 用时 18 秒
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**pypolars**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**pypolars**'
- en: ‍
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ‍
- en: '**Here  pypolars is 1.2x faster**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**在这里 pypolars 快 1.2 倍**'
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Joining
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连接
- en: '**Downloading COVID Tracking data**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载 COVID 跟踪数据**'
- en: 'Downloading data from [COVID Tracking Project](https://covidtracking.com/data/download) from
    this command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [COVID Tracking Project](https://covidtracking.com/data/download) 下载数据，使用这个命令：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: will get you the latest data of the coronavirus spread across all the US in
    this **all-states-history.csv **file
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将获得你所需的最新冠状病毒传播数据，这些数据存储在 **all-states-history.csv** 文件中
- en: '**Downloading states data**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载州数据**'
- en: 'This is a CSV file indicating the abbreviations of each state since we need
    it to join with the previous CSV which has only the abbreviations listed in *state *column.
    Let’s get this data from this command:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 CSV 文件，指示了每个州的缩写，因为我们需要将其与之前只列出了*州*列缩写的 CSV 进行连接。我们通过这个命令获取数据：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will output **states.csv**, the file that has two columns: *State* and *Abbreviation*
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出 **states.csv** 文件，该文件包含两列：*State* 和 *Abbreviation*
- en: '**pandas**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: 'Let’s use **csvcut** to filter out this resulted **joined_pd.csv** file:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 **csvcut** 来筛选出这个结果文件 **joined_pd.csv**：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Looks like the join is working and it’s left join. If you’re curious why the
    associated *State* values of AS and DC are nulls, that’s because there are no
    abbreviations existing in the **states.csv** file itself. If you look into the *Abbreviation* column,
    you’ll find no values for AS nor DC.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来连接正常，且是左连接。如果你对 AS 和 DC 的相关*State* 值为何为空感到好奇，那是因为在**states.csv**文件中不存在这些缩写。如果你查看*Abbreviation*列，你会发现
    AS 和 DC 的值都为空。
- en: 'Here no AS abbreviations:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有 AS 缩写：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'and here no values for DC:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 DC 的值为空：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: P.S. if it’s not clear what **csvcut** is used for; we have some tutorials on
    csvkit (the command-line utility that contains csvcut and some other useful command-line
    tools for cleaning, processing, and analyzing CSVs).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 附言：如果你不清楚**csvcut**的用途，我们有一些关于 csvkit 的教程（csvkit 是一个命令行工具，包含 csvcut 及其他用于清理、处理和分析
    CSV 的实用命令行工具）。
- en: '[Part 1 of cleaning CSV data](https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[清理 CSV 数据的第 1 部分](https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line)'
- en: '[Part 2 of cleaning CSV data](https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line-part-2) [‍](https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[清理 CSV 数据的第 2 部分](https://www.ezzeddinabdullah.com/posts/how-to-clean-csv-data-at-the-command-line-part-2)
    [‍](https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line)'
- en: '**pypolars**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**pypolars**'
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s see now how the joined data frame looks like:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看合并的数据框是怎样的：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'so it looks like here **pypolars** missed the null values for the column it
    joined on, but that’s because the default join is inner join unlike pandas’ default
    join which is left join. To get the same result as pandas you need to change line
    8 to:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所以看起来**pypolars**在连接的列中遗漏了空值，但这是因为默认的连接方式是内连接，而不像 pandas 默认的连接方式是左连接。要获得与 pandas
    相同的结果，你需要将第 8 行更改为：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'which on my machine got ~317ms meaning here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上花费了大约 317 毫秒，这意味着：
- en: '**pypolars is 3x faster in left join**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**pypolars 在左连接中快 3 倍**'
- en: Final thoughts
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的思考
- en: In the end, we’ve found how performant **pypolars** is compared to **pandas**.
     Of course, **pandas** is more mature since it’s been 12 years now and the community
    is still investing in it, but if more collaborations are made on **pypolars**;
    this rising library will rock!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们发现了**pypolars**与**pandas**的性能对比。当然，**pandas**更成熟，因为它已经有 12 年了，社区仍在继续投入，但如果对**pypolars**进行更多的合作，这个新兴库会很出色！
- en: 'You might find these tutorials useful:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现这些教程很有用：
- en: '[How to clean text data at the command line](https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line)‍'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在命令行清理文本数据](https://www.ezzeddinabdullah.com/posts/how-to-clean-text-data-at-the-command-line)‍'
- en: ‍[Why we use docker](https://www.ezzeddinabdullah.com/posts/penguins-in-docker-a-tutorial-on-why-we-use-docker)‍
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ‍[我们为何使用 Docker](https://www.ezzeddinabdullah.com/posts/penguins-in-docker-a-tutorial-on-why-we-use-docker)‍
- en: Take care, will see you in the next tutorials :)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 保重，下次教程见 :)
- en: Peace!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 和平！
- en: '**[**Click here**](https://upbeat-crafter-1565.ck.page/0f7fd6d5d6)** to get
    fresh content to your inbox****'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**[**点击这里**](https://upbeat-crafter-1565.ck.page/0f7fd6d5d6)** 获取最新内容到你的邮箱****'
- en: '**Resources**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源**'
- en: '[pandas Wikipedia](https://en.wikipedia.org/wiki/Pandas_%28software%29)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas 维基百科](https://en.wikipedia.org/wiki/Pandas_%28software%29)'
- en: '[pandas documentation](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas 文档](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)'
- en: '[pypolars repo authored by Ritchie Vink](https://github.com/ritchie46/polars)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[由 Ritchie Vink 编写的 pypolars 仓库](https://github.com/ritchie46/polars)'
- en: '[pypolars documentation](https://ritchie46.github.io/polars/pypolars/frame.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pypolars 文档](https://ritchie46.github.io/polars/pypolars/frame.html)'
- en: '[Ritchie Vink comment on Reddit](https://www.reddit.com/r/rust/comments/jqiwpj/xsv_a_commandline_toolkit_for_csv_data_written_in/gbrfexy?utm_source=share&utm_medium=web2x&context=3)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ritchie Vink 在 Reddit 的评论](https://www.reddit.com/r/rust/comments/jqiwpj/xsv_a_commandline_toolkit_for_csv_data_written_in/gbrfexy?utm_source=share&utm_medium=web2x&context=3)'
- en: '[COVID Tracking Data](https://covidtracking.com/data/download)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[COVID 跟踪数据](https://covidtracking.com/data/download)'
- en: '[States Abbreviations Data](https://worldpopulationreview.com/states/state-abbreviations)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[州缩写数据](https://worldpopulationreview.com/states/state-abbreviations)'
- en: '[Reddit usernames dataset | Kaggle](https://www.kaggle.com/colinmorris/reddit-usernames)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Reddit 用户名数据集 | Kaggle](https://www.kaggle.com/colinmorris/reddit-usernames)'
- en: '**Bio: [Ezz El Din Abdullah](https://www.linkedin.com/in/ezzeddinabdullah/)**
    ([ezzeddinabdullah.com](http://ezzeddinabdullah.com)) is a Data Platform Engineer
    at Affectiva.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Ezz El Din Abdullah](https://www.linkedin.com/in/ezzeddinabdullah/)**
    ([ezzeddinabdullah.com](http://ezzeddinabdullah.com)) 是 Affectiva 的数据平台工程师。'
- en: '[Original](https://www.ezzeddinabdullah.com/posts/a-rising-library-beating-pandas-in-performance).
    Reposted with permission.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.ezzeddinabdullah.com/posts/a-rising-library-beating-pandas-in-performance)。经许可转载。'
- en: '**Related:**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Merging Pandas DataFrames in Python](/2020/12/merging-pandas-dataframes-python.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Python中合并Pandas数据框](/2020/12/merging-pandas-dataframes-python.html)'
- en: '[Pandas on Steroids: End to End Data Science in Python with Dask](/2020/11/pandas-steroids-dask-python-data-science.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas的强化版：使用Dask进行端到端的数据科学](/2020/11/pandas-steroids-dask-python-data-science.html)'
- en: '[Every Complex DataFrame Manipulation, Explained & Visualized Intuitively](/2020/11/dataframe-manipulation-explained-visualized.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每种复杂数据框操作的直观解释与可视化](/2020/11/dataframe-manipulation-explained-visualized.html)'
- en: More On This Topic
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为伟大数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学，找到目的，再找到目的...] (https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，深入探讨](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
