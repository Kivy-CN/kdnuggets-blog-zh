- en: The 10 Statistical Techniques Data Scientists Need to Master
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html](https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Header image](../Images/192409ea180b5be09e1a283158eb89e2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Regardless of where you stand on the matter of Data Science sexiness, it’s
    simply impossible to ignore the continuing importance of data, and our ability
    to analyze, organize, and contextualize it. Drawing on their vast stores of employment
    data and employee feedback, Glassdoor ranked Data Scientist #1 in their [25 Best
    Jobs in America](https://www.glassdoor.com/Best-Jobs-in-America-LST_KQ0,20.htm) list.
    So the role is here to stay, but unquestionably, the specifics of what a Data
    Scientist does will evolve. With technologies like Machine Learning becoming ever-more
    common place, and emerging fields like Deep Learning gaining significant traction
    amongst researchers and engineers — and the companies that hire them — Data Scientists
    continue to ride the crest of an incredible wave of innovation and technological
    progress.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: While having a strong coding ability is important, data science isn’t all about
    software engineering (in fact, have a good familiarity with Python and you’re
    good to go). Data scientists live at the intersection of coding, statistics, and
    critical thinking. [As Josh Wills](https://www.quora.com/What-is-the-difference-between-a-data-scientist-and-a-statistician) put
    it, *“data scientist is a person who is better at statistics than any programmer
    and better at programming than any statistician.”* I personally know too many
    software engineers looking to transition into data scientist and blindly utilizing
    machine learning frameworks such as TensorFlow or Apache Spark to their data without
    a thorough understanding of statistical theories behind them. So comes the study
    of [statistical learning](https://en.wikipedia.org/wiki/Statistical_learning_theory),
    a theoretical framework for machine learning drawing from the fields of statistics
    and functional analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why study Statistical Learning?** It is important to understand the ideas
    behind the various techniques, in order to know how and when to use them. One
    has to understand the simpler methods first, in order to grasp the more sophisticated
    ones. It is important to accurately assess the performance of a method, to know
    how well or how badly it is working. Additionally, this is an exciting research
    area, having important applications in science, industry, and finance. Ultimately,
    statistical learning is a fundamental ingredient in the training of a modern data
    scientist. Examples of Statistical Learning problems include:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify the risk factors for prostate cancer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classify a recorded phoneme based on a log-periodogram.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict whether someone will have a heart attack on the basis of demographic,
    diet and clinical measurements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customize an email spam detection system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the numbers in a handwritten zip code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classify a tissue sample into one of several cancer classes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish the relationship between salary and demographic variables in population
    survey data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In my last semester in college, I did an Independent Study on Data Mining. The
    class covers expansive materials coming from 3 books: [Intro to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (Hastie,
    Tibshirani, Witten, James), [Doing Bayesian Data Analysis](https://sites.google.com/site/doingbayesiandataanalysis/)(Kruschke),
    and [Time Series Analysis and Applications](http://www.stat.pitt.edu/stoffer/tsa4/) (Shumway,
    Stoffer). We did a lot of exercises on Bayesian Analysis, Markov Chain Monte Carlo,
    Hierarchical Modeling, Supervised and Unsupervised Learning. This experience deepens
    my interest in the Data Mining academic field and convinces me to specialize further
    in it. Recently, I completed the [Statistical Learning online course](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about) on
    Stanford Lagunita, which covers all the material in the [**Intro to Statistical
    Learning book**](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370) I
    read in my Independent Study. Now being exposed to the content twice, I want to
    share the 10 statistical techniques from the book that I believe any data scientists
    should learn to be more effective in handling big datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on with these 10 techniques, I want to differentiate between
    statistical learning and machine learning. I wrote [one of the most popular Medium
    posts on machine learning](https://gab41.lab41.org/the-10-algorithms-machine-learning-engineers-need-to-know-f4bb63f5b2fa) before,
    so I am confident I have the expertise to justify these differences:'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning arose as a subfield of Artificial Intelligence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical learning arose as a subfield of Statistics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning has a greater emphasis on large scale applications and prediction
    accuracy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical learning emphasizes models and their interpretability, and precision
    and uncertainty.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But the distinction has become and more blurred, and there is a great deal of
    “cross-fertilization.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning has the upper hand in Marketing!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '****1 — Linear Regression:****'
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, linear regression is a method to predict a target variable by
    fitting the *best linear relationship* between the dependent and independent variable.
    The *best fit* is done by making sure that the sum of all the distances between
    the shape and the actual observations at each point is as small as possible. The
    fit of the shape is “best” in the sense that no other position would produce less
    error given the choice of shape. 2 major types of linear regression are *Simple
    Linear Regression* and *Multiple Linear Regression***.** **Simple Linear Regression**uses
    a single independent variable to predict a dependent variable by fitting a best
    linear relationship. **Multiple Linear Regression** uses more than one independent
    variable to predict a dependent variable by fitting a best linear relationship.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef9c3a012f80c3ae290f8a8106b0e553.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Pick any 2 things that you use in your daily life and that are related. Like,
    I have data of my monthly spending, monthly income and the number of trips per
    month for the last 3 years. Now I need to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What will be my monthly spending for next year?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which factor (monthly income or number of trips per month) is more important
    in deciding my monthly spending?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How monthly income and trips per month are correlated with monthly spending?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '****2 — Classification:****'
  prefs: []
  type: TYPE_NORMAL
- en: Classification is a data mining technique that assigns categories to a collection
    of data in order to aid in more accurate predictions and analysis. Also sometimes
    called a Decision Tree, classification is one of several methods intended to make
    the analysis of very large datasets effective. 2 major Classification techniques
    stand out: *Logistic Regression* and *Discriminant Analysis***.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Logistic Regression** is the appropriate regression analysis to conduct when
    the dependent variable is dichotomous (binary). Like all regression analyses,
    the logistic regression is a predictive analysis. Logistic regression is used
    to describe data and to explain the relationship between one dependent binary
    variable and one or more nominal, ordinal, interval or ratio-level independent
    variables. Types of questions that a logistic regression can examine:'
  prefs: []
  type: TYPE_NORMAL
- en: How does the probability of getting lung cancer (Yes vs No) change for every
    additional pound of overweight and for every pack of cigarettes smoked per day?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do body weight calorie intake, fat intake, and participant age have an influence
    on heart attacks (Yes vs No)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/b938a7f44237a2491b90de2f19a3c6c7.png)'
  prefs: []
  type: TYPE_IMG
- en: In **Discriminant Analysis**, 2 or more groups or clusters or populations are
    known a priori and 1 or more new observations are classified into 1 of the known
    populations based on the measured characteristics. Discriminant analysis models
    the distribution of the predictors X separately in each of the response classes,
    and then uses Bayes’ theorem to flip these around into estimates for the probability
    of the response category given the value of X. Such models can either be *linear* or *quadratic***.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear Discriminant Analysis** computes “discriminant scores” for each observation
    to classify what response variable class it is in. These scores are obtained by
    finding linear combinations of the independent variables. It assumes that the
    observations within each class are drawn from a multivariate Gaussian distribution
    and the covariance of the predictor variables are common across all k levels of
    the response variable Y.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quadratic Discriminant Analysis** provides an alternative approach. Like
    LDA, QDA assumes that the observations from each class of Y are drawn from a Gaussian
    distribution. However, unlike LDA, QDA assumes that each class has its own covariance
    matrix. In other words, the predictor variables are not assumed to have common
    variance across each of the k levels in Y.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '****3 — Resampling Methods:****'
  prefs: []
  type: TYPE_NORMAL
- en: Resampling is the method that consists of drawing repeated samples from the
    original data samples. It is a non-parametric method of statistical inference.
    In other words, the method of resampling does not involve the utilization of the
    generic distribution tables in order to compute approximate p probability values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Resampling generates a unique sampling distribution on the basis of the actual
    data. It uses experimental methods, rather than analytical methods, to generate
    the unique sampling distribution. It yields unbiased estimates as it is based
    on the unbiased samples of all the possible results of the data studied by the
    researcher. In order to understand the concept of resampling, you should understand
    the terms *Bootstrapping* and *Cross-Validation*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/13226e7dc419f46ee9646e6742c25c15.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Bootstrapping** is a technique that helps in many situations like validation
    of a predictive model performance, ensemble methods, estimation of bias and variance
    of the model. It works by sampling with replacement from the original data, and
    take the “*not chosen*” data points as test cases. We can make this several times
    and calculate the average score as estimation of our model performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, **cross validation** is a technique for validating the model
    performance, and it’s done by split the training data into k parts. We take the
    k — 1 parts as our training set and use the “*held out*” part as our test set.
    We repeat that k times differently. Finally, we take the average of the k scores
    as our performance estimation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually for linear models, ordinary least squares is the major criteria to be
    considered to fit them into the data. The next 3 methods are the alternative approaches
    that can provide better prediction accuracy and model interpretability for fitting
    linear models.
  prefs: []
  type: TYPE_NORMAL
- en: '****4 — Subset Selection:****'
  prefs: []
  type: TYPE_NORMAL
- en: This approach identifies a subset of the *p* predictors that we believe to be
    related to the response. We then fit a model using the least squares of the subset
    features.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6379988a88899a4e3fce74341f2ba5a0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Best-Subset Selection:** Here we fit a separate OLS regression for each possible
    combination of the *p* predictors and then look at the resulting model fits. The
    algorithm is broken up into 2 stages: (1) Fit all models that contain *k* predictors,
    where *k* is the max length of the models, (2) Select a single model using cross-validated
    prediction error. It is important to use *testing* or *validation error,* and
    not training error to assess model fit because RSS and R² monotonically increase
    with more variables. The best approach is to cross-validate and choose the model
    with the highest R² and lowest RSS on testing error estimates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forward Stepwise Selection** considers a much smaller subset of *p*predictors.
    It begins with a model containing no predictors, then adds predictors to the model,
    one at a time until all of the predictors are in the model. The order of the variables
    being added is the variable, which gives the greatest addition improvement to
    the fit, until no more variables improve model fit using cross-validated prediction
    error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backward Stepwise Selection** begins will all *p* predictors in the model,
    then iteratively removes the least useful predictor one at a time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid Methods** follows the forward stepwise approach, however, after adding
    each new variable, the method may also remove variables that do not contribute
    to the model fit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '****5 — Shrinkage:****'
  prefs: []
  type: TYPE_NORMAL
- en: This approach fits a model involving all *p* predictors, however, the estimated
    coefficients are shrunken towards zero relative to the least squares estimates.
    This shrinkage, aka *regularization* has the effect of reducing variance. Depending
    on what type of shrinkage is performed, some of the coefficients may be estimated
    to be exactly zero. Thus this method also performs variable selection. The two
    best-known techniques for shrinking the coefficient estimates towards zero are
    the *ridge regression* and the *lasso*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1b75295dced1b4ca5439ddd13fa90199.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Ridge regression** is similar to least squares except that the coefficients
    are estimated by minimizing a slightly different quantity. Ridge regression, like
    OLS, seeks coefficient estimates that reduce RSS, however they also have a shrinkage
    penalty when the coefficients come closer to zero. This penalty has the effect
    of shrinking the coefficient estimates towards zero. Without going into the math,
    it is useful to know that ridge regression shrinks the features with the smallest
    column space variance. Like in prinicipal component analysis, ridge regression
    projects the data into *d*directional space and then shrinks the coefficients
    of the low-variance components more than the high variance components, which are
    equivalent to the largest and smallest principal components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ridge regression had at least one disadvantage; it includes all *p* predictors
    in the final model. The penalty term will set many of them close to zero, but
    never *exactly* to zero. This isn’t generally a problem for prediction accuracy,
    but it can make the model more difficult to interpret the results. **Lasso** overcomes
    this disadvantage and is capable of forcing some of the coefficients to zero granted
    that *s* is small enough. Since *s* = 1 results in regular OLS regression, as *s* approaches
    0 the coefficients shrink towards zero. Thus, Lasso regression also performs variable
    selection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
