- en: Creating a simple text classifier using Google CoLaboratory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/03/simple-text-classifier-google-colaboratory.html](https://www.kdnuggets.com/2018/03/simple-text-classifier-google-colaboratory.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Sudipto Dasgupta](https://www.linkedin.com/in/dsudipto/), Flipkart.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Platform**: Google has scored another hit with CoLaboratory, its in-house
    data science platform that is freely available for anyone to use. It gives several
    benefits of Jupyter, free GPU time, easy code sharing and storage, no requirement
    of software installation, coding using a chrome browser and compatibility with
    the Python language and access to modules such as scikit-learn. This is a truly
    great step in making AI and data accessible to all.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Context**: I work for an e-commerce organization, where mis-shipments
    are ubiquitous in the business. When the information regarding a mis-shipment
    is received in the system, a team of experts read the comments generated by the
    customer against every case, to determine how to investigate it. As open text
    fields are difficult to control, customers are free to post messages which may
    not be actionable, or sometimes even understandable. Reading comments take up
    a considerable amount of time, and given previous labelling information, the junk
    comments can be easily labelled by text classification algorithms. Given below
    is a simple classifier which can generate labels with a high level of accuracy
    given sufficient training data and balanced label distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Binary Text Classifier](../Images/b19924393dc974c34e1cfb8aad65a7d5.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Loading the corpus**: The training data consists of two columns, the first
    containing comments and the second, the labels (0 and 1). First, we load the data
    onto the colab environment with the following code -'
  prefs: []
  type: TYPE_NORMAL
- en: '**from** google**.**colab **import** files'
  prefs: []
  type: TYPE_NORMAL
- en: '**import** pandas **as** pd'
  prefs: []
  type: TYPE_NORMAL
- en: '**import** io'
  prefs: []
  type: TYPE_NORMAL
- en: uploaded = files.upload()
  prefs: []
  type: TYPE_NORMAL
- en: df = pd.read_csv(io.StringIO(uploaded['data_train.csv'].decode('utf-8')),header=None)
  prefs: []
  type: TYPE_NORMAL
- en: Executing this block (known as cell in colab) generates an upload widget, by
    which the training data needs to be uploaded. Once this operation is complete,
    columns are given name references –
  prefs: []
  type: TYPE_NORMAL
- en: raw_text = df[0]
  prefs: []
  type: TYPE_NORMAL
- en: y = df[1]
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-Processing**:'
  prefs: []
  type: TYPE_NORMAL
- en: Though there are several different methods to classify, the one I have used
    involve the NLTK python package.
  prefs: []
  type: TYPE_NORMAL
- en: Stemming involves reducing a derived word to its base form. For example, the
    word ‘fish’ is a root for words such as ‘fishing’, ‘fished’, and ‘fisher’. Martin
    Porter’s algorithm is a popular stemming tool, which can be found in NLTK. Stopwords
    are words that do not add much meaning to a sentence from a feature extraction
    point of view. Words such as ‘after’, ‘few’, ‘right’ etc. are frequently ignored
    by search engines. A list of common stopwords can be found [HERE](https://www.webconfs.com/stop-words.php).
    I have imported the ‘PorterStemmer’ and ‘Stopwords’ from NLTK using the following
    commands.
  prefs: []
  type: TYPE_NORMAL
- en: '**import** nltk'
  prefs: []
  type: TYPE_NORMAL
- en: nltk**.**download**(**'stopwords'**),**nltk**.**download**(**'porter_test'**)**
  prefs: []
  type: TYPE_NORMAL
- en: Another pre-processing step was conducted using the [Regular Expressions](https://docs.python.org/3/howto/regex.html)
    or ‘re’ module. This involved removing whitespaces, tabs, punctuations and finally
    converting all text in lowercase. This step is commonly known as normalization.
    A function named ‘pre_process’ was created to implement all these steps in a single
    line to any text or block of text.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now let us look at what this function does to text using the code on the first
    5 comments in the corpus.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Running the cell generates the following output in which you can compare lines
    to see the combined effect of pre-processing steps.
  prefs: []
  type: TYPE_NORMAL
- en: '##Original Comment###'
  prefs: []
  type: TYPE_NORMAL
- en: Item is not same as shown in pciture
  prefs: []
  type: TYPE_NORMAL
- en: cmbissue :- cust called for the return and ...
  prefs: []
  type: TYPE_NORMAL
- en: Different item
  prefs: []
  type: TYPE_NORMAL
- en: Dial color is white  I have ordered blackItem ...
  prefs: []
  type: TYPE_NORMAL
- en: issue with quality and price tag missing
  prefs: []
  type: TYPE_NORMAL
- en: '###Transformed Comment###'
  prefs: []
  type: TYPE_NORMAL
- en: item shown pcitur
  prefs: []
  type: TYPE_NORMAL
- en: cmbissucust call return refund due discript ...
  prefs: []
  type: TYPE_NORMAL
- en: differ item
  prefs: []
  type: TYPE_NORMAL
- en: dial color white order blackitem receivvari...
  prefs: []
  type: TYPE_NORMAL
- en: issuqualiti price tag miss
  prefs: []
  type: TYPE_NORMAL
- en: '**Tokenization:** Let’s consider the sentence- ‘How are you?’. Obviously, programs
    don’t understand words, they only understand characters. So, if a bag of words
    model is brought into play, the sentence ‘How are you?’ and ‘are How you?’ are
    same. However, the bigrams for the sentences would be different. Bigrams are subset
    of n-grams, which is a collection of base pairs, syllables or words. N-grams are
    highly popular not only in NLP, but also in other fields such as DNA sequencing!
    The bigrams are:'
  prefs: []
  type: TYPE_NORMAL
- en: ‘How are you?’  ----  ‘How are’ , ‘are you’
  prefs: []
  type: TYPE_NORMAL
- en: ‘are How you?’  ----  ‘are How’ , ‘How you’
  prefs: []
  type: TYPE_NORMAL
- en: 'The bigram generation code is:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating Unigram & Bigram Vectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**from** sklearn**.**feature_extraction**.**text **import** TfidfVectorizer'
  prefs: []
  type: TYPE_NORMAL
- en: vectorizer **=**TfidfVectorizer**(**ngram_range**=(**1**,**2**))**
  prefs: []
  type: TYPE_NORMAL
- en: X_ngrams**=**vectorizer**.**fit_transform**(**processed**)**
  prefs: []
  type: TYPE_NORMAL
- en: The term frequency (tf) measures the occurrences of each n-gram for each training
    example. This is down weighted with the inverse document frequency (idf), ensuring
    that words/word pairs distinctive to either class have higher weights, while common
    grams have lower weights.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating the classifier**: Once the features are generated by the previous
    block of code, the next step is to fit the model using the data. The data is split
    in 80/20 ratio, and modelled using (Binary) Logistic Regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '#Train/Test Split'
  prefs: []
  type: TYPE_NORMAL
- en: '**from** sklearn**.**model_selection **import** train_test_split'
  prefs: []
  type: TYPE_NORMAL
- en: X_train**,**X_test**,**y_train**,**y_test**=**train_test_split**(**X_ngrams**,**y**,**test_size**=**0.2**,**stratify**=**y**)**
  prefs: []
  type: TYPE_NORMAL
- en: Running the Classsifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**from** sklearn**.**linear_model **import** LogisticRegression'
  prefs: []
  type: TYPE_NORMAL
- en: clf**=**LogisticRegression**()**
  prefs: []
  type: TYPE_NORMAL
- en: clf**.**fit**(**X_train**,**y_train**)**
  prefs: []
  type: TYPE_NORMAL
- en: At this point one can use a metric such as F1 score to evaluate model performance.
  prefs: []
  type: TYPE_NORMAL
- en: The machine has learnt!
  prefs: []
  type: TYPE_NORMAL
- en: '![Machine learning robot](../Images/65cdcf419067bd98e8d68da1c84c8f30.png)'
  prefs: []
  type: TYPE_IMG
- en: Next, we need a wrapper function to separate the pearlsfrom the junk.
  prefs: []
  type: TYPE_NORMAL
- en: '**def** pearl_or_junk**(**message**):**# Wrapper Function'
  prefs: []
  type: TYPE_NORMAL
- en: '**if** clf**.**predict**(**vectorizer**.**transform**([**pre_process**(**message**)])):**'
  prefs: []
  type: TYPE_NORMAL
- en: '**return** ''pearl'''
  prefs: []
  type: TYPE_NORMAL
- en: '**else****:**'
  prefs: []
  type: TYPE_NORMAL
- en: '**return** ''junk'''
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s it! The wrapper function can process comment columns to classify whether
    a comment is useful or not. An example file can be passed using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: uploaded **=**files**.**upload**()**
  prefs: []
  type: TYPE_NORMAL
- en: test_data**=**pd**.**read_csv**(**io**.**StringIO**(**uploaded**[**'test_file.csv'**].**decode**(**'utf-8'**)),**header**=****None****)**
  prefs: []
  type: TYPE_NORMAL
- en: test_data**[**1**]=**test_data**[**0**].**apply**(**pearl_or_junk**)**
  prefs: []
  type: TYPE_NORMAL
- en: test_data**.**to_csv**(**'newfile.csv'**,** index **=****None****,** header
    **=****False****)**
  prefs: []
  type: TYPE_NORMAL
- en: files**.**download**(**'newfile.csv'**)**
  prefs: []
  type: TYPE_NORMAL
- en: The code will create a column with labels ‘pearl’ and ‘junk’ against every line
    of comment which you will find in the file named ‘newfile’ that will be automatically
    downloaded to your system.
  prefs: []
  type: TYPE_NORMAL
- en: '**What next?** As I stated earlier, this is a simple piece of code, and has
    a lot of improvement areas. If there is class imbalance in the training data,
    this model will predict the dominating class, and to address that a resampling
    technique such as SMOTE may help.'
  prefs: []
  type: TYPE_NORMAL
- en: There are several NLP techniques such as lemmatization, that can boost the pre-processing.
    Usually increasing the n-gram to a 3 or 4 combination increases the load on the
    machine, and in my case, it just gave me a message that it is too tired to handle
    such complicated stuff. FYI, the bigram generated over 36,000 features in a sparse
    matrix. Imagine what will happen if you increase N.
  prefs: []
  type: TYPE_NORMAL
- en: The modelling was super simple. Model stacking may help increase the accuracy,
    and other algorithms such as Naïve Bayes or SVC are known to handle such stuff
    better. I did not try a neural network, but that may also give better results,
    if the training data is sufficiently large. Google colab does provide free GPU
    also, so that may be worth a try.
  prefs: []
  type: TYPE_NORMAL
- en: '![Google colab notebook](../Images/7bb1889dead5dd2c3101c7a50bb01ac5.png)'
  prefs: []
  type: TYPE_IMG
- en: Though I created this code in Jupyter, moving it to coLaboratory was a breeze.
    Thank you, Google!
  prefs: []
  type: TYPE_NORMAL
- en: 'Tags: NLP; Machine Learning; Regression;'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bio:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sudipto Dasgupta **is currently working as a Specialist – Process Design
    for Flipkart India Pvt. Ltd., the largest e-commerce organization in India. He
    has 15+ years of experience in Business Analytics in domains such as software,
    market research, education and supply chain. He is an experienced Six Sigma Master
    Black Belt and project management professional (PMP) with an educational background
    in Mathematics and Statistics. He has an active interest in the Data Sciences.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[3 Essential Google Colaboratory Tips & Tricks](https://www.kdnuggets.com/2018/02/essential-google-colaboratory-tips-tricks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automated Text Classification Using Machine Learning](https://www.kdnuggets.com/2018/01/automated-text-classification-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning Development with Google Colab, TensorFlow, Keras & PyTorch](https://www.kdnuggets.com/2018/02/google-colab-free-gpu-tutorial-tensorflow-keras-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Creating A Simple Docker Data Science Image](https://www.kdnuggets.com/2023/08/simple-docker-data-science-image.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Generate Music From Text Using Google MusicLM](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Simple Steps Series: Master Python, SQL, Scikit-learn, PyTorch &…](https://www.kdnuggets.com/5-simple-steps-series-master-python-sql-scikit-learn-pytorch-google-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Winning The Room: Creating and Delivering an Effective Data-Driven…](https://www.kdnuggets.com/2022/04/franks-winning-room-creating-delivering-effective-data-driven-presentation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Practices for Creating Domain-Specific AI Models](https://www.kdnuggets.com/2022/07/best-practices-creating-domainspecific-ai-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
