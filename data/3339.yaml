- en: What I Learned Implementing a Classifier from Scratch in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我在Python中从零实现分类器的所学
- en: 原文：[https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html](https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html](https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html)
- en: '**By Jean-Nicholas Hould, [JeanNicholasHould.com](http://JeanNicholasHould.com/?utm_source=kdnugget).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Jean-Nicholas Hould，[JeanNicholasHould.com](http://JeanNicholasHould.com/?utm_source=kdnugget)。**'
- en: This post is part of the author's [Learning Machine Learning](http://www.jeannicholashould.com/learning-machine-learning.html)
    series. It’s based on Chapter 1 and 2 of [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3).
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文是作者[《学习机器学习》](http://www.jeannicholashould.com/learning-machine-learning.html)系列的一部分。内容基于[《Python机器学习》](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)的第1章和第2章。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Machine learning can be intimidating for a newcomer. The concept of a machine
    learning things alone is quite abstract. How does that work in practice?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对新手来说，机器学习可能会让人感到畏惧。机器学习独自工作的概念相当抽象。这在实际操作中是如何运作的呢？
- en: In order to demystify some of the magic behind machine learning algorithms,
    I decided to implement a simple machine learning algorithm from scratch. I will
    not be using a library such as *scikit-learn* which already has many algorithms
    implemented. Instead, I’ll be writing all of the code in order to have a working
    binary classifier algorithm. The goal of this exercise is to understand its inner
    workings.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了揭开机器学习算法背后的神秘面纱，我决定从零实现一个简单的机器学习算法。我不会使用像*scikit-learn*这样已经实现了许多算法的库。相反，我会编写所有代码，以实现一个工作的二元分类器算法。这个练习的目标是理解其内部运作。
- en: So, what the heck is a binary classifier?
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那么，什么是二元分类器？
- en: A classifier is a machine-learning algorithm that determines the class of an
    input element based on a set of features. For example, a classifier could be used
    to predict the category of a beer based on its characteristics, it’s “features”.
    These features could include its alcohol content, aroma, appearance, etc. A machine
    learning classifier could potentially be used to predict that a beer with 8% alcohol
    content, 100 IBU and with strong aromas of oranges is an Indian Pale Ale.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器是一种机器学习算法，根据一组特征确定输入元素的类别。例如，可以使用分类器预测一瓶啤酒的类别，基于其特征。这些特征可能包括其酒精含量、香气、外观等。机器学习分类器可以用来预测一瓶8%酒精含量、100
    IBU并具有强烈橙子香气的啤酒是一种印度淡色艾尔。
- en: 'In machine learning, there are three main types of tasks: unsupervised learning,
    supervised learning and reinforcement learning. The classifier algorithm falls
    under the supervised learning category. Supervised learning means that we know
    the right answer beforehand. The desired outputs are known. In the case of the
    beer example, we could realistically have a dataset describing beers and their
    category. We could train the classifier algorithm to predict those categories
    based on the beers features.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，有三种主要任务类型：无监督学习、监督学习和强化学习。分类器算法属于监督学习类别。监督学习意味着我们事先知道正确答案。期望的输出是已知的。在啤酒的例子中，我们可以现实地拥有一个描述啤酒及其类别的数据集。我们可以训练分类器算法来预测这些类别，基于啤酒的特征。
- en: A binary classifier classifies elements in two groups. Zero or one. True or
    false. IPA or not.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类器将元素分为两组。零或一。真或假。IPA或非IPA。
- en: Building a machine learning model
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建机器学习模型
- en: There are four steps to build and use a machine learning model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和使用机器学习模型有四个步骤。
- en: Preprocessing
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理
- en: Learning
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学习
- en: Evaluation
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估
- en: Prediction
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测
- en: '![](../Images/ab50ecd3646752080fe903493cb7c77b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab50ecd3646752080fe903493cb7c77b.png)'
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Python机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    作者：塞巴斯蒂安·拉什卡。
- en: Preprocessing
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预处理
- en: The preprocessing is the first step in building a machine learning model. At
    this step, you acquire and prepare the data for future usage. You clean up the
    data, tidy it and select the features you want to use from your data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理是构建机器学习模型的第一步。在这一步，你获取并准备数据以供未来使用。你清理数据，整理数据，并从中选择你想要使用的特征。
- en: 'The following tasks can be considered as part of the “preprocessing”:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下任务可以被视为“预处理”的一部分：
- en: Extract features from raw data
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据中提取特征
- en: Clean and format the data
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理和格式化数据
- en: Remove superfluous features (or highly correlated features)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除多余的特征（或高度相关的特征）
- en: Reduce the number of features for performance
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少特征数量以提高性能
- en: Standardize the range of feature data (also named [Feature Scaling](https://en.wikipedia.org/wiki/Feature_scaling))
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化特征数据的范围（也称为[特征缩放](https://en.wikipedia.org/wiki/Feature_scaling)）
- en: 'Split your dataset randomly: training dataset and test dataset'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机划分你的数据集：训练数据集和测试数据集
- en: Learning or Training
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习或训练
- en: Once you have your datasets ready to be used, the second step is to select an
    algorithm to perform your desired task. In our case, the algorithm we selected
    is a binary classifier called Perceptron. There are many algorithms designed to
    do different tasks. They each have their strengths and weaknesses.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的数据集准备好使用，第二步是选择一个算法来执行你期望的任务。在我们的例子中，我们选择的算法是一个叫做感知器的二分类器。有许多算法被设计用来执行不同的任务。它们各有优缺点。
- en: At this step, you can test a few algorithms, see how they perform and select
    the best performing one. There are a wide variety of metrics that can be used
    to measure the performance of a machine learning model. According to Raschka,
    “one commonly used metric is classification accuracy, which is defined as the
    proportion of correctly classified instances”. At this step, you will make adjustments
    to the parameters of your machine learning algorithm. These are named hyperparameters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，你可以测试一些算法，查看它们的表现，并选择表现最好的一个。有多种指标可以用来衡量机器学习模型的性能。根据Raschka的说法，“一个常用的指标是分类准确率，它被定义为正确分类实例的比例”。在这一步，你将对机器学习算法的参数进行调整，这些参数被称为超参数。
- en: In this post, we’ll mainly focus on this part of the machine learning work flow.
    We’ll deep dive in the algorithm inner workings. If you are interested in the
    other sections of the machine learning work flow, which you should be, I’ll be
    linking to a great notebook at the end of this post.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将主要关注机器学习工作流的这一部分。我们将深入探讨算法的内部工作原理。如果你对机器学习工作流的其他部分感兴趣，我会在文章末尾链接到一个很棒的笔记本。
- en: Evaluation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估
- en: When the model has been “trained” on the dataset it can be evaluated on new
    unseen data. The goal here is to measure the [generalization error](https://en.wikipedia.org/wiki/Generalization_error).
    This metric measures “how accurately an algorithm is able to predict outcome values
    for previously unseen data”. Once you are satisfied with the results, you can
    use your machine learning model to make predictions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型在数据集上“训练”完成后，它可以在新的未见数据上进行评估。这里的目标是测量[泛化误差](https://en.wikipedia.org/wiki/Generalization_error)。这个指标测量“算法在对之前未见数据进行预测时的准确性”。一旦你对结果满意，你可以使用你的机器学习模型进行预测。
- en: Introducing the Perceptron
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍感知器
- en: The algorithm that we’ll be re-implementing is a [Perceptron](https://en.wikipedia.org/wiki/Perceptron)
    which is one of the very first machine learning algorithm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新实现的算法是[感知器](https://en.wikipedia.org/wiki/Perceptron)，这是最早的机器学习算法之一。
- en: The Perceptron algorithm is simple but powerful. Given a training dataset, the
    algorithm automatically learns “the optimal weight coefficients that are then
    multiplied with the input features in order to make the decision of whether a
    neuron fires or not”.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器算法简单但强大。给定一个训练数据集，算法会自动学习“最佳权重系数，这些系数与输入特征相乘以决定神经元是否激活”。
- en: But, how does the algorithm do that?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，算法是如何做到这一点的呢？
- en: The Algorithm
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法
- en: 'Here’s the sequence of the algorithm:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是算法的序列：
- en: First, we initialize an array with the weights equal to zero. The array length
    is equal to the number of features plus one. This additional feature is the “threshold”.
    It’s important to note that in the case of the Perceptron algorithm, the features
    must be of numerical value.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们用权重初始化一个数组，初始值为零。数组的长度等于特征的数量加一。这个额外的特征是“阈值”。值得注意的是，对于感知器算法，特征必须是数值型的。
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Secondly, we start a loop equal to the number of iterations `n_iter`. This is
    an hyperparameter defined by the data scientist.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们开始一个等于迭代次数`n_iter`的循环。这是数据科学家定义的超参数。
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thirdly, we start a loop on each training data point and it’s target. The target
    is the desired output we want the algorithm to eventually predict. Since this
    is a binary classifier, the targets are either `-1` or `1`. They are of binary
    value.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们对每个训练数据点及其目标进行循环。目标是我们希望算法最终预测的期望输出。由于这是一个二分类器，目标值要么是`-1`，要么是`1`。它们是二进制值。
- en: 'Based on the data point features, the algorithm will predict the category:
    `1` or `-1`. The prediction calculation is a matricial multiplication of the features
    with their appropriate weights. To this multiplication we add the value of the
    threshold. If the result is above 0, the predicted category is `1`. If the result
    is below 0, the predicted category is `-1`.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 基于数据点特征，算法将预测类别：`1`或`-1`。预测计算是特征与其相应权重的矩阵乘法。我们在这个乘法结果上加上阈值。如果结果大于0，预测类别是`1`。如果结果小于0，预测类别是`-1`。
- en: At each iteration on a data point, if the prediction is not accurate, the algorithm
    will adjust the weights. During the first few iterations, the predictions are
    not likely to be accurate because the weights haven’t been adjusted many times.
    They haven’t had a chance to start converging. The adjustments are made proportionally
    to the difference between the target and the predicted value. This difference
    is then multiplied by the learning rate `eta`, an hyperparameter of value between
    zero and one set by the data scientist. The higher the `eta` is, the larger the
    correction on the weights will be. If the prediction is accurate, the algorithm
    won’t adjust the weights.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次数据点的迭代中，如果预测不准确，算法将调整权重。在最初的几次迭代中，预测不太可能准确，因为权重尚未调整多次，它们还没有开始收敛。这些调整是根据目标值和预测值之间的差异进行的。这个差异乘以学习率`eta`，这是一个由数据科学家设定的在零到一之间的超参数。`eta`越高，对权重的修正就越大。如果预测准确，算法不会调整权重。
- en: The Perceptron will converge only if the two classes are linearly separable.
    Simply said, if you are able to draw a straight line to entirely separate the
    two classes, the algorithm will converge. Else, the algorithm will keep iterating
    and will readjust weights until it reaches the maximum number of iterations `n_iter`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当两个类别线性可分时，感知器才会收敛。简单来说，如果你能画一条直线完全分隔两个类别，算法将会收敛。否则，算法将继续迭代并调整权重，直到达到最大迭代次数`n_iter`。
- en: '![](../Images/81a651a78516e9af6e96c47b4ee0f87f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81a651a78516e9af6e96c47b4ee0f87f.png)'
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Python机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    作者：Sebastian Raschka。
- en: Complete Code
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整代码
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Python机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    作者：Sebastian Raschka。
- en: Three Learnings
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 三个学习点
- en: 1\. Learning Rate, Number of Iteration & Convergence
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 学习率、迭代次数与收敛
- en: Parameters such as `learning rate` and `number of iteration` can seem very abstract
    if you jump in straight to using an algorithm from a library like `scikit-learn`.
    It’s hard to grasp what these really do. By implementing the algorithm, it’s now
    clear for me what they represent in the context of the Perceptron.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如 `learning rate` 和 `number of iteration` 这样的参数，如果直接使用像 `scikit-learn` 这样的库中的算法，可能会显得非常抽象。很难理解它们的实际作用。通过实现算法，我现在清楚了它们在感知器（Perceptron）中的含义。
- en: '**Learning Rate**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习率**'
- en: The learning rate is a ratio by which the weights are corrected when the prediction
    is not accurate. The value needs to be between zero and one. As you can see in
    the snippet below, the `fit` function will iterate on each observation, call the
    `predict` function and then adjust the weights based on the difference between
    the target and the predicted value and then multiplied by the learning rate.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是一个比率，用于在预测不准确时修正权重。这个值需要介于零和一之间。如下面的代码片段所示，`fit` 函数将对每个观察值进行迭代，调用 `predict`
    函数，然后根据目标值和预测值之间的差异调整权重，并乘以学习率。
- en: A higher learning rate means that the algorithm will adjust the weights more
    aggressively. At each iteration, the weights will be adjusted if the predicted
    value is inaccurate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的学习率意味着算法将更积极地调整权重。在每次迭代中，如果预测值不准确，权重将被调整。
- en: '**Number of iterations**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**迭代次数**'
- en: The number of iteration is the number of times the algorithm will run through
    the training dataset. If the number of iteration was set to one, the algorithm
    would loop through the dataset only once and update the weights one time for each
    data point. The resulting model would be more likely to be inaccurate than a model
    with a higher number of iteration. On large datasets, there is a cost to having
    a high number of iterations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代次数是算法遍历训练数据集的次数。如果将迭代次数设置为一，算法将仅遍历一次数据集，并为每个数据点更新一次权重。结果模型很可能不如具有更高迭代次数的模型准确。在大型数据集中，较高的迭代次数是有成本的。
- en: The `learning rate` and `number of iteration` go hands-in-hand. They need to
    be adjusted together. For example, if you have a very low `learning rate`, which
    means that the algorithm will adjust it’s weight only marginally at each iteration,
    you will probably need a higher number of iteration.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`learning rate` 和 `number of iteration` 是密切相关的。它们需要一起调整。例如，如果你有一个非常低的 `learning
    rate`，这意味着算法在每次迭代中只会轻微调整权重，你可能需要更高的迭代次数。'
- en: 2\. Linear Algebra
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 线性代数
- en: It’s critical to mention that the capabilities of the Perceptron algorithm are
    attributable to linear algebra. The whole algorithm can be described through linear
    algebra formulas. If you have never done linear algebra in college, the formulas
    will be cryptic. As usual, [Khan Academy](https://www.khanacademy.org/math/linear-algebra)
    is a great place to start with if you want to get familiar with linear algebra.
    It’s also a great place to get a refresher on the topic.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要提到，感知器算法的能力归因于线性代数。整个算法可以通过线性代数公式来描述。如果你在大学时从未学习过线性代数，这些公式会显得难以理解。像 [可汗学院](https://www.khanacademy.org/math/linear-algebra)
    这样的地方是了解线性代数的好起点。它也是一个很好的复习这个主题的地方。
- en: For me, the main learning here is how fundamental linear algebra is to this
    machine learning algorithm.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这里主要的学习是线性代数对这个机器学习算法的重要性。
- en: 3\. Type Everything
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 类型一切
- en: This learning is actually a concept I re-learned while going through the code
    for this post. It’s not specific to machine learning and it has nothing to do
    with the Perceptron.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个学习实际上是我在编写本文的过程中重新学到的概念。它并不特定于机器学习，也与感知器无关。
- en: Back in 2012 when I was learning to code Ruby on Rails, a web application development
    framework, I realized that typing down all of the code examples from tutorials
    really helped me memorize and understand the concepts. I spent weeks writing code
    while following tutorials. No copy and paste. I typed all the code. This may sound
    stupid but it was extremely helpful to grasp the concepts. During the process,
    I inevitably made typos and spend some time figuring out what was broken. These
    moments were crucial because that’s when you usually stop and think.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2012 年，当我学习 Ruby on Rails 这款 Web 应用程序开发框架时，我意识到将教程中的所有代码示例输入一遍确实帮助我记忆和理解了这些概念。我花了几周的时间在跟随教程时编写代码。不复制粘贴。我输入了所有的代码。这听起来可能很愚蠢，但这对掌握概念极有帮助。在这个过程中，我不可避免地犯了错，并花时间弄清楚问题出在哪里。这些时刻非常关键，因为那时你通常会停下来思考。
- en: If you are going through the Perceptron code, don’t copy and paste the code
    from the [repository](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb).
    Type it down in your own Jupyter Notebook. Type everything. Don’t read passively.
    Get involved, type it down and you’ll assimilate the concepts faster.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在阅读 Perceptron 代码时，不要从 [代码库](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)
    中复制粘贴代码。将其输入到你自己的 Jupyter Notebook 中。把所有内容都输入。不要被动阅读。参与其中，输入代码，你会更快地掌握这些概念。
- en: Next Steps
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步
- en: In this post, my goal was to share my understanding of the algorithm and the
    learnings I’ve made while reimplementing it. However, you can do much more than
    simply reimplementing the model. You can actually use it with real data in order
    to do some simple predictions. In Python Machine Learning, Raschka uses the Perceptron
    to [predict the class of Iris flower](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)
    based on a the sepal and petal length of the flower. With actual data, you can
    then evaluate the model and make predictions on unseen data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我的目标是分享我对算法的理解以及在重新实现它时所获得的经验。然而，你可以做的不仅仅是重新实现模型。你实际上可以将其与真实数据结合使用，以进行一些简单的预测。在
    Python 机器学习中，Raschka 使用 Perceptron 来[预测鸢尾花的类别](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)，基于花朵的萼片和花瓣长度。使用实际数据后，你可以评估模型，并对未见过的数据进行预测。
- en: '**Bio: Jean-Nicholas Hould** is a [Data Scientist from Montreal, Canada](http://jeannicholashould.com/?utm_source=kdnugget).
    Author at JeanNicholasHould.com.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：** **让-尼古拉斯·霍尔德** 是来自 [加拿大蒙特利尔的数据科学家](http://jeannicholashould.com/?utm_source=kdnugget)。JeanNicholasHould.com
    的作者。'
- en: '[Original](http://www.jeannicholashould.com/what-i-learned-implementing-a-classifier-from-scratch.html).
    Reposted with permission.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](http://www.jeannicholashould.com/what-i-learned-implementing-a-classifier-from-scratch.html)。转载已获许可。'
- en: '**Related:**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Web Scraping for Dataset Curation, Part 1: Collecting Craft Beer Data](/2017/02/web-scraping-dataset-curation-part-1.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据集策划中的网页抓取，第一部分：收集精酿啤酒数据](/2017/02/web-scraping-dataset-curation-part-1.html)'
- en: '[Tidying Data in Python](/2017/01/tidying-data-python.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中整理数据](/2017/01/tidying-data-python.html)'
- en: '[Central Limit Theorem for Data Science](/2016/08/central-limit-theorem-data-science.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的中心极限定理](/2016/08/central-limit-theorem-data-science.html)'
- en: More On This Topic
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从理论到实践：构建一个 k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
- en: '[What I Learned From Using ChatGPT for Data Science](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我从使用 ChatGPT 进行数据科学中学到了什么](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
- en: '[Implementing DBSCAN in Python](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中实现 DBSCAN](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
- en: '[KDnuggets News, August 24: Implementing DBSCAN in Python • How to…](https://www.kdnuggets.com/2022/n34.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8月24日：在 Python 中实现 DBSCAN • 如何…](https://www.kdnuggets.com/2022/n34.html)'
- en: '[Understanding and Implementing Genetic Algorithms in Python](https://www.kdnuggets.com/understanding-and-implementing-genetic-algorithms-in-python)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解和实现 Python 中的遗传算法](https://www.kdnuggets.com/understanding-and-implementing-genetic-algorithms-in-python)'
- en: '[Machine Learning from Scratch: Decision Trees](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从头开始学习机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
