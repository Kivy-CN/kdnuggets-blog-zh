- en: DBSCAN Clustering Algorithm in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的DBSCAN聚类算法
- en: 原文：[https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)
- en: '![Figure](../Images/d2cb5b01a0ce10194d0ada7a6d683441.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/d2cb5b01a0ce10194d0ada7a6d683441.png)'
- en: '[Credits](https://www.stratio.com/blog/graph-database-clustering-solution/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://www.stratio.com/blog/graph-database-clustering-solution/)'
- en: '* * *'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In 2014, the DBSCAN algorithm was awarded the test of time award (an award given
    to algorithms which have received substantial attention in theory and practice)
    at the leading data mining conference, ACM [SIGKDD](https://en.wikipedia.org/wiki/SIGKDD).
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2014年，DBSCAN算法在领先的数据挖掘会议ACM [SIGKDD](https://en.wikipedia.org/wiki/SIGKDD)上获得了“时间考验奖”（颁发给理论和实践中获得大量关注的算法）。
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — [Wikipedia](https://en.wikipedia.org/wiki/DBSCAN)
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: — [维基百科](https://en.wikipedia.org/wiki/DBSCAN)
- en: Introduction
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Clustering analysis is an unsupervised learning method that separates the data
    points into several specific bunches or groups, such that the data points in the
    same groups have similar properties and data points in different groups have different
    properties in some sense.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是一种无监督学习方法，它将数据点分为几个特定的组或群体，使得同一组的数据点具有相似的属性，而不同组的数据点在某种意义上具有不同的属性。
- en: It comprises of many different methods based on different distance measures.
    E.g. K-Means (distance between points), Affinity propagation (graph distance),
    Mean-shift (distance between points), DBSCAN (distance between nearest points),
    Gaussian mixtures (Mahalanobis distance to centers), Spectral clustering (graph
    distance), etc.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 它包括许多不同的方法，基于不同的距离度量。例如，K均值（点之间的距离）、亲和传播（图距离）、均值漂移（点之间的距离）、DBSCAN（最近点之间的距离）、高斯混合（到中心的马氏距离）、谱聚类（图距离）等。
- en: Centrally, all clustering methods use the same approach i.e. first we calculate
    similarities and then we use it to cluster the data points into groups or batches.
    Here we will focus on the **Density-based spatial clustering of applications with
    noise** (**DBSCAN**) clustering method.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，所有的聚类方法都使用相同的方法，即首先计算相似性，然后利用这些相似性将数据点聚集成组或批次。这里我们将重点讨论**基于密度的噪声应用空间聚类**（**DBSCAN**）聚类方法。
- en: If you are unfamiliar with the clustering algorithms, I advise you to read the [Introduction
    to Image Segmentation with K-Means clustering](https://towardsdatascience.com/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3).
    You may also read the article on [Hierarchical Clustering](https://medium.com/swlh/what-is-hierarchical-clustering-c04e9972e002).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对聚类算法不熟悉，我建议你阅读[使用K均值聚类进行图像分割的介绍](https://towardsdatascience.com/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3)。你也可以阅读关于[层次聚类](https://medium.com/swlh/what-is-hierarchical-clustering-c04e9972e002)的文章。
- en: '**Why do we need a Density-Based clustering algorithm like DBSCAN when we already
    have K-means clustering?**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么我们需要像DBSCAN这样的基于密度的聚类算法，而不是已经有K均值聚类？**'
- en: K-Means clustering may cluster loosely related observations together. Every
    observation becomes a part of some cluster eventually, even if the observations
    are scattered far away in the vector space. Since clusters depend on the mean
    value of cluster elements, each data point plays a role in forming the clusters.
    A slight change in data points *might* affect the clustering outcome. This problem
    is greatly reduced in DBSCAN due to the way clusters are formed. This is usually
    not a big problem unless we come across some odd shape data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: K-均值聚类可能将松散相关的观测值聚集在一起。即使观测值在向量空间中分散得很远，每个观测值最终也会成为某个簇的一部分。由于簇依赖于簇元素的均值，每个数据点在形成簇时都会发挥作用。数据点的轻微变化可能会影响聚类结果。这一问题在
    DBSCAN 中由于簇形成方式的不同得到了很大程度的减少。除非我们遇到一些奇特的形状数据，否则这通常不是一个大问题。
- en: Another challenge with *k*-means is that you need to specify the number of clusters
    (“*k*”) in order to use it. Much of the time, we won’t know what a reasonable *k* value
    is *a priori*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个挑战是 *k*-均值算法，你需要指定簇的数量（“*k*”）才能使用它。很多时候，我们不知道合理的 *k* 值是什么 *a priori*。
- en: 'What’s nice about DBSCAN is that you don’t have to specify the number of clusters
    to use it. All you need is a function to calculate the distance between values
    and some guidance for what amount of distance is considered “close”. DBSCAN also
    produces more reasonable results than *k*-means across a variety of different
    distributions. Below figure illustrates the fact:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN 的优点是你不需要指定要使用的簇的数量。你只需要一个计算值之间距离的函数和一些关于什么距离被认为是“接近”的指导。DBSCAN 在各种不同的分布中也比 *k*-均值算法产生更合理的结果。下图说明了这一点：
- en: '![Figure](../Images/e50803f50d89d5d6ebad229f6ccec366.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/e50803f50d89d5d6ebad229f6ccec366.png)'
- en: '[Credits](https://github.com/NSHipster/DBSCAN)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[致谢](https://github.com/NSHipster/DBSCAN)'
- en: Density-Based Clustering Algorithms
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于密度的聚类算法
- en: '**Density**-Based **Clustering** refers to unsupervised learning methods that
    identify distinctive groups/clusters in the data, based on the idea that a cluster
    in data space is a contiguous region of high point density, separated from other
    such clusters by contiguous regions of low point density.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于密度**的**聚类** 指的是无监督学习方法，通过识别数据中的独特组/簇来进行分类，其基于这样一个理念：数据空间中的簇是高点密度的连续区域，由低点密度的连续区域与其他簇隔开。'
- en: Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a base
    algorithm for density-based clustering. It can discover clusters of different
    shapes and sizes from a large amount of data, which is containing noise and outliers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基于密度的空间聚类（DBSCAN）是基于密度的聚类的基础算法。它可以从大量数据中发现不同形状和大小的簇，这些数据包含噪声和离群点。
- en: 'The DBSCAN algorithm uses two parameters:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN 算法使用两个参数：
- en: '**minPts:** The minimum number of points (a threshold) clustered together for
    a region to be considered dense.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**minPts:** 为了使一个区域被认为是密集的，聚集在一起的最小点数（阈值）。'
- en: '**eps (ε):** A distance measure that will be used to locate the points in the
    neighborhood of any point.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**eps (ε):** 用于定位任何点的邻域内点的距离度量。'
- en: These parameters can be understood if we explore two concepts called Density
    Reachability and Density Connectivity.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们探索两个叫做密度可达性（Density Reachability）和密度连接性（Density Connectivity）的概念，就能理解这些参数。
- en: '**Reachability** in terms of density establishes a point to be reachable from
    another if it lies within a particular distance (eps) from it.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**可达性** 从密度的角度来说，建立一个点从另一个点可达的条件是它在该点的特定距离（eps）范围内。'
- en: '**Connectivity**, on the other hand, involves a transitivity based chaining-approach
    to determine whether points are located in a particular cluster. For example,
    p and q points could be connected if p->r->s->t->q, where a->b means b is in the
    neighborhood of a.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**连接性**，另一方面，涉及基于传递性的链式方法来确定点是否位于特定簇中。例如，如果 p->r->s->t->q，则 p 和 q 点可以连接，其中
    a->b 表示 b 在 a 的邻域内。'
- en: 'There are three types of points after the DBSCAN clustering is complete:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN 聚类完成后，有三种类型的点：
- en: '![](../Images/0cf15c12e52f0f6b8bc9a54334ba2888.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cf15c12e52f0f6b8bc9a54334ba2888.png)'
- en: '**Core** — This is a point that has at least *m* points within distance *n* from
    itself.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核心点** — 这是一个距离自身不超过 *n* 的区域内至少有 *m* 个点的点。'
- en: '**Border** — This is a point that has at least one Core point at a distance *n*.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边界点** — 这是一个在距离 *n* 内至少有一个核心点的点。'
- en: '**Noise** — This is a point that is neither a Core nor a Border. And it has
    less than *m* points within distance *n* from itself.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**噪声** — 这是一个既不是核心点也不是边界点的点。它在自身距离 *n* 内的点少于 *m* 个。'
- en: '**Algorithmic steps for DBSCAN clustering**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**DBSCAN聚类的算法步骤**'
- en: The algorithm proceeds by arbitrarily picking up a point in the dataset (until
    all points have been visited).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法通过任意选择数据集中的一个点（直到所有点都被访问）来进行。
- en: If there are at least ‘minPoint’ points within a radius of ‘ε’ to the point
    then we consider all these points to be part of the same cluster.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在半径为‘ε’的范围内有至少‘minPoint’个点，则我们将这些点视为同一簇的一部分。
- en: The clusters are then expanded by recursively repeating the neighborhood calculation
    for each neighboring point
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，通过递归地重复每个邻近点的邻域计算来扩展簇。
- en: '![Figure](../Images/c8cebaa015d5f15db51754a37b800bf8.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/c8cebaa015d5f15db51754a37b800bf8.png)'
- en: '[DBSCAN in action](https://www.digitalvidya.com/blog/the-top-5-clustering-algorithms-data-scientists-should-know/)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[DBSCAN的实际应用](https://www.digitalvidya.com/blog/the-top-5-clustering-algorithms-data-scientists-should-know/)'
- en: Parameter Estimation
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参数估计
- en: Every data mining task has the problem of parameters. Every parameter influences
    the algorithm in specific ways. For DBSCAN, the parameters **ε** and **minPts** are
    needed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据挖掘任务都有参数问题。每个参数都会以特定的方式影响算法。对于DBSCAN，需要**ε**和**minPts**这两个参数。
- en: '**minPts**: As a rule of thumb, a minimum *minPts* can be derived from the
    number of dimensions *D* in the data set, as `***minPts* ≥ *D* + 1**`. The low
    value `***minPts* = 1**` does not make sense, as then every point on its own will
    already be a cluster. With `***minPts* ≤ 2**`, the result will be the same as
    of [hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering) with
    the single link metric, with the dendrogram cut at height ε. Therefore, *minPts* must
    be chosen at least 3\. However, larger values are usually better for data sets
    with noise and will yield more significant clusters. As a rule of thumb,`** *minPts* =
    2·*dim***` can be used, but it may be necessary to choose larger values for very
    large data, for noisy data or for data that contains many duplicates.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**minPts**: 作为经验法则，最小*minPts*可以从数据集中的维度数*D*推导出来，公式为`***minPts* ≥ *D* + 1**`。低值`***minPts* =
    1**`是没有意义的，因为那样每个点本身就会形成一个簇。`***minPts* ≤ 2**`的结果将与使用单链接度量的[hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering)相同，树状图的剪切高度为ε。因此，*minPts*至少应选择为3。然而，对于有噪声的数据集，较大的值通常更好，会产生更显著的簇。作为经验法则，可以使用`** *minPts* =
    2·*dim***`，但对于非常大的数据集、噪声数据或包含许多重复的数据，可能需要选择更大的值。'
- en: '**ε**: The value for ε can then be chosen by using a [k-distance graph](https://en.wikipedia.org/wiki/Nearest_neighbor_graph),
    plotting the distance to the `***k* = *minPts*-1**` nearest neighbor ordered from
    the largest to the smallest value. Good values of ε are where this plot shows
    an “elbow”: if ε is chosen much too small, a large part of the data will not be
    clustered; whereas for a too high value of ε, clusters will merge and the majority
    of objects will be in the same cluster. In general, small values of ε are preferable,
    and as a rule of thumb, only a small fraction of points should be within this
    distance of each other.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ε**: 可以通过使用一个[k-distance图](https://en.wikipedia.org/wiki/Nearest_neighbor_graph)来选择ε的值，该图绘制了距离到`***k* = *minPts*-1**`最近邻的距离，并按从大到小的顺序排列。好的ε值是在该图上显示“肘部”的位置：如果ε选择得太小，大部分数据将无法被聚类；而ε值过高，则聚类会合并，大多数对象会在同一个簇中。一般来说，小的ε值是更可取的，作为经验法则，只有少量的点应该在彼此的这个距离之内。'
- en: '**Distance function**: The choice of distance function is tightly linked to
    the choice of ε, and has a major impact on the outcomes. In general, it will be
    necessary to first identify a reasonable measure of similarity for the data set,
    before the parameter ε can be chosen. There is no estimation for this parameter,
    but the distance functions need to be chosen appropriately for the data set.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**距离函数**: 距离函数的选择与ε的选择密切相关，并对结果有重大影响。通常，在选择参数ε之前，需要首先确定数据集的合理相似度度量。没有此参数的估计，但需要为数据集选择适当的距离函数。'
- en: DBSCAN Python Implementation Using Scikit-learn
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scikit-learn的DBSCAN Python实现
- en: Let us first apply DBSCAN to cluster spherical data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先对球形数据应用DBSCAN进行聚类。
- en: We first generate 750 spherical training data points with corresponding labels.
    After that standardize the features of your training data and at last, apply DBSCAN
    from the sklearn library.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先生成750个球形训练数据点及其对应的标签。之后对训练数据的特征进行标准化，最后应用sklearn库中的DBSCAN。
- en: '![](../Images/41b07d566d9620c082570549d34d0606.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41b07d566d9620c082570549d34d0606.png)'
- en: '![Figure](../Images/1e525079ab694b4045301028a5362803.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/1e525079ab694b4045301028a5362803.png)'
- en: DBSCAN to cluster spherical data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN对球形数据的聚类
- en: The black data points represent outliers in the above result. Next, apply DBSCAN
    to cluster non-spherical data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上述结果中的黑色数据点代表离群点。接下来，应用DBSCAN对非球形数据进行聚类。
- en: '![](../Images/7b63b835b30fbbbf9fdb264633ed815c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b63b835b30fbbbf9fdb264633ed815c.png)'
- en: '![Figure](../Images/9a389869897afcf88efcddccd8c73c75.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/9a389869897afcf88efcddccd8c73c75.png)'
- en: DBSCAN to cluster non-spherical data
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN对非球形数据的聚类
- en: 'Which is absolutely perfect. If we compare with K-means it would give a completely
    incorrect output like:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这完全是完美的。如果与K-means进行比较，它会给出完全不正确的结果，如下所示：
- en: '![Figure](../Images/7083a07ac0e7d75433e0c904a6bd8a6c.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/7083a07ac0e7d75433e0c904a6bd8a6c.png)'
- en: K-means clustering result
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 聚类结果
- en: The Complexity of DBSCAN
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DBSCAN的复杂度
- en: '**Best Case:** If an indexing system is used to store the dataset such that
    neighborhood queries are executed in logarithmic time, we get `**O(nlogn)**` average
    runtime complexity.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最佳情况:** 如果使用索引系统存储数据集，以便邻域查询以对数时间执行，则平均运行时间复杂度为`**O(nlogn)**`。'
- en: '**Worst Case:** Without the use of index structure or on degenerated data (e.g.
    all points within a distance less than ε), the worst-case run time complexity
    remains `**O(*n*²)**`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最坏情况:** 如果没有使用索引结构或在退化数据上（例如所有点在小于ε的距离内），最坏情况下的运行时间复杂度仍为`**O(*n*²)**`。'
- en: '**Average Case:** Same as best/worst case depending on data and implementation
    of the algorithm.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均情况:** 根据数据和算法实现，与最佳/最坏情况相同。'
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Density-based clustering algorithms can learn clusters of arbitrary shape, and
    with the Level Set Tree algorithm, one can learn clusters in datasets that exhibit
    wide differences in density.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 基于密度的聚类算法可以学习任意形状的簇，借助Level Set Tree算法，可以在展示广泛密度差异的数据集中学习簇。
- en: However, I should point out that these algorithms are somewhat more arduous
    to tune contrasted to parametric clustering algorithms like K-Means. Parameters
    like the epsilon for DBSCAN or for the Level Set Tree are less intuitive to reason
    about compared to the number of clusters parameter for K-Means, so it’s more difficult
    to choose good initial parameter values for these algorithms.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我要指出，与像K-Means这样的参数化聚类算法相比，这些算法在调整时要复杂一些。比如DBSCAN的ε参数或Level Set Tree的参数相比于K-Means的簇数量参数，直观理解较难，因此为这些算法选择好的初始参数值更具挑战性。
- en: That is all for this article. I hope you guys have enjoyed reading it, please
    share your suggestions/views/questions in the comment section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 本文到此为止。希望你们阅读愉快，请在评论区分享你的建议/观点/问题。
- en: '**Thanks for Reading!**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢阅读！**'
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是CirrusLabs的大数据开发工程师。他在电信、分析、销售、数据科学等各个领域拥有超过4年的工作经验，专注于各种大数据组件。'
- en: '[Original](https://medium.com/swlh/dbscan-clustering-algorithm-in-machine-learning-d465a4cca1e8).
    Reposted with permission.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/swlh/dbscan-clustering-algorithm-in-machine-learning-d465a4cca1e8)。经许可转载。'
- en: More On This Topic
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Implementing DBSCAN in Python](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Python中实现DBSCAN](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
- en: '[KDnuggets News, August 24: Implementing DBSCAN in Python • How to…](https://www.kdnuggets.com/2022/n34.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，8月24日：在Python中实现DBSCAN • 如何……](https://www.kdnuggets.com/2022/n34.html)'
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类揭示：理解K-Means聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
- en: '[Choosing the Right Clustering Algorithm for Your Dataset](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为你的数据集选择正确的聚类算法](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是K-Means聚类及其算法如何工作？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
- en: '[Clustering with scikit-learn: A Tutorial on Unsupervised Learning](https://www.kdnuggets.com/2023/05/clustering-scikitlearn-tutorial-unsupervised-learning.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用scikit-learn进行聚类：无监督学习教程](https://www.kdnuggets.com/2023/05/clustering-scikitlearn-tutorial-unsupervised-learning.html)'
