- en: Command Line Tricks For Data Scientists
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学家的命令行技巧
- en: 原文：[https://www.kdnuggets.com/2018/06/command-line-tricks-data-scientists.html](https://www.kdnuggets.com/2018/06/command-line-tricks-data-scientists.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/06/command-line-tricks-data-scientists.html](https://www.kdnuggets.com/2018/06/command-line-tricks-data-scientists.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Kade Killary](http://kadekillary.work/), Data Scientist & Engineer**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Kade Killary](http://kadekillary.work/)，数据科学家与工程师**'
- en: '![Image](../Images/41bfa054c7f477d9be3f2d3a5bcb3cee.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/41bfa054c7f477d9be3f2d3a5bcb3cee.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: For many data scientists, data manipulation begins and ends with Pandas or the
    Tidyverse. In theory, there is nothing wrong with this notion. It is, after all,
    why these tools exist in the first place. Yet, these options can often be overkill
    for simple tasks like delimiter conversion.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多数据科学家来说，数据处理开始和结束于 Pandas 或 Tidyverse。理论上，这种观念没有错。毕竟，这些工具存在的初衷就是如此。然而，这些选项对于像分隔符转换这样简单的任务来说，往往会显得过于复杂。
- en: Aspiring to master the command line should be on every developer’s list, especially
    data scientists. Learning the ins and outs of your terminal will undeniably make
    you more productive. Beyond that, the command line serves as a great history lesson
    in computing. For instance, awk — a data-driven scripting language. Awk first
    appeared in 1977 with the help of [Brian Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan),
    the *K* in the legendary [K&R book](https://en.wikipedia.org/wiki/The_C_Programming_Language).
    Today, some near 50 years later, awk remains relevant with [new books](https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS) still
    appearing every year! Thus, it’s safe to assume that an investment in command
    line wizardry won’t depreciate any time soon.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个开发者，尤其是数据科学家，都应该把掌握命令行作为目标。学习你终端的来龙去脉无疑会让你更高效。除此之外，命令行还为计算机科学提供了极好的历史课程。例如，awk——一种基于数据的脚本语言。Awk
    最早出现在 1977 年，得到了 [布赖恩·柯宁汉](https://en.wikipedia.org/wiki/Brian_Kernighan) 的帮助，他是传奇的
    [K&R 书籍](https://en.wikipedia.org/wiki/The_C_Programming_Language) 中的 *K*。直到今天，近
    50 年后，awk 依然相关，每年都有 [新书](https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS)
    继续出版！因此，可以放心地认为，对命令行技巧的投资不会很快贬值。
- en: What We’ll Cover
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们将涵盖的内容
- en: ICONV
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICONV
- en: HEAD
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HEAD
- en: TR
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TR
- en: WC
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WC
- en: SPLIT
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SPLIT
- en: SORT & UNIQ
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SORT & UNIQ
- en: CUT
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUT
- en: PASTE
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PASTE
- en: JOIN
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JOIN
- en: GREP
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GREP
- en: SED
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SED
- en: AWK
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWK
- en: ICONV
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ICONV
- en: File encodings can be tricky. For the most part files these days are all UTF-8
    encoded. To understand some of the magic behind UTF-8, check out this [excellent
    video](https://www.youtube.com/watch?v=MijmeoH9LT4). Nonetheless, there are times
    where we receive a file that isn’t in this format. This can lead to some wonky
    attempts at swapping the encoding schema. Here, `iconv` is a life saver. Iconv
    is a simple program that will take text in one encoding and output the text in
    another.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 文件编码可能很棘手。现在大多数文件都是 UTF-8 编码的。要了解 UTF-8 背后的部分魔力，可以查看这个 [精彩视频](https://www.youtube.com/watch?v=MijmeoH9LT4)。尽管如此，有时我们会收到不是这种格式的文件。这可能会导致一些奇怪的尝试去更换编码方案。在这里，`iconv`
    是救星。Iconv 是一个简单的程序，可以将一种编码的文本转换为另一种编码的文本。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Useful options:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`iconv -l` list all known encodings'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iconv -l` 列出所有已知编码'
- en: '`iconv -c` silently discard characters that cannot be converted'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iconv -c` 静默丢弃无法转换的字符'
- en: HEAD
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HEAD
- en: If you are a frequent Pandas user then `head` will be familiar. Often when dealing
    with new data the first thing we want to do is get a sense of what exists. This
    leads to firing up Pandas, reading in the data and then calling `df.head()` -
    strenuous, to say the least. Head, without any flags, will print out the first
    10 lines of a file. The true power of `head` lies in testing out cleaning operations.
    For instance, if we wanted to change the delimiter of a file from commas to pipes.
    One quick test would be: `head mydata.csv | sed 's/,/|/g'`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是频繁使用Pandas的用户，那么`head`将是熟悉的。通常在处理新数据时，我们首先想要了解数据的内容。这导致我们启动Pandas，读取数据，然后调用`df.head()`——可以说是相当费劲。`head`在没有任何标志的情况下，会打印出文件的前10行。`head`的真正力量在于测试清理操作。例如，如果我们想将文件的分隔符从逗号更改为管道字符。一个快速的测试方法是：`head
    mydata.csv | sed 's/,/|/g'`。
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Useful options:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`head -n` print a specific number of lines'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head -n` 打印特定行数'
- en: '`head -c` print a specific number of bytes'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head -c` 打印特定字节数'
- en: TR
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TR
- en: Tr is analogous to translate. This powerful utility is a workhorse for basic
    file cleaning. An ideal use case is for swapping out the delimiters within a file.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`tr`类似于翻译。这个强大的工具在基本文件清理中是一个主力军。一个理想的用例是用于在文件中交换分隔符。'
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Another feature of `tr` is all the built in `[:class:]` variables at your disposal.
    These include:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`tr`的另一个特性是所有内置的`[:class:]`变量。这些包括：'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can chain a variety of these together to compose powerful programs. The
    following is a basic word count program you could use to check your READMEs for
    overuse.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将各种这些选项链在一起，组成强大的程序。以下是一个基本的单词计数程序，你可以用来检查你的README文件是否过度使用。
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Another example using basic regex:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个使用基本正则表达式的示例：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Useful options:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`tr -d` delete characters'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tr -d` 删除字符'
- en: '`tr -s` squeeze characters'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tr -s` 压缩字符'
- en: '`\b` backspace'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\b` 退格键'
- en: '`\f` form feed'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\f` 换页符'
- en: '`\v` vertical tab'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\v` 垂直制表符'
- en: '`\NNN` character with octal value NNN'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\NNN` 具有八进制值NNN的字符'
- en: WC
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: WC
- en: Word count. Its value is primarily derived from the `-l` flag, which will give
    you the line count.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 单词计数。其值主要由`-l`标志派生，该标志会给出行数。
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This tool comes in handy to confirm the output of various commands. So, if we
    were to convert the delimiters within a file and then run `wc -l` we would expect
    the total lines to be the same. If not, then we know something went wrong.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工具很方便用来确认各种命令的输出。因此，如果我们将文件中的分隔符转换，然后运行`wc -l`，我们可以期望总行数保持不变。如果不一致，那么我们知道出现了问题。
- en: 'Useful options:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`wc -c` print the byte counts'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wc -c` 打印字节计数'
- en: '`wc -m` print the character counts'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wc -m` 打印字符计数'
- en: '`wc -L` print length of longest line'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wc -L` 打印最长行的长度'
- en: '`wc -w` print word counts'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wc -w` 打印单词计数'
- en: SPLIT
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SPLIT
- en: 'File sizes can range dramatically. And depending on the job, it could be beneficial
    to split up the file — thus `split`. The basic syntax for split is:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 文件大小可以有很大差异。根据任务的不同，拆分文件可能会有好处——因此使用`split`。`split`的基本语法是：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Two quirks are the naming convention and lack of file extensions. The suffix
    convention can be numeric via the `-d` flag. To add file extensions, you’ll need
    to run the following `find` command. It will change the names of *ALL* files within
    the current directory by appending `.csv`, so be careful.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 两个怪癖是命名约定和缺乏文件扩展名。后缀约定可以通过`-d`标志设置为数字。要添加文件扩展名，你需要运行以下`find`命令。它会通过追加`.csv`来更改当前目录下*所有*文件的名称，因此要小心。
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Useful options:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`split -b` split by certain byte size'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split -b` 按特定字节大小拆分'
- en: '`split -a` generate suffixes of length N'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split -a` 生成长度为N的后缀'
- en: '`split -x` split using hex suffixes'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`split -x` 使用十六进制后缀进行拆分'
- en: SORT & UNIQ
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SORT & UNIQ
- en: 'The preceding commands are obvious: they do what they say they do. These two
    provide the most punch in tandem (i.e. unique word counts). This is due to `uniq`,
    which only operates on duplicate adjacent lines. Thus, the reason to `sort` before
    piping the output through. One interesting note is that `sort -u`will achieve
    the same results as the typical `sort file.txt | uniq` pattern.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令很直观：它们执行的正是它们所描述的功能。这两个命令配合使用效果最佳（即唯一词汇计数）。这是因为`uniq`只作用于相邻的重复行。因此，原因在于在将输出通过管道传输之前需要`sort`。一个有趣的说明是，`sort
    -u`将实现与典型的`sort file.txt | uniq`模式相同的结果。
- en: 'Sort does have a sneakily useful ability for data scientists: the ability to
    sort an entire CSV based on a particular column.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`sort`对数据科学家有一个非常有用的功能：根据特定列对整个CSV文件进行排序。'
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `-t` option here is to specify the comma as our delimiter. More often than
    not spaces or tabs are assumed. Furthermore, the `-k` flag is for specifying our
    key.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 `-t` 选项用于指定逗号作为分隔符。更常见的是假定使用空格或制表符。此外，`-k` 标志用于指定键。
- en: 'Useful options:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`sort -f` ignore case'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sort -f` 忽略大小写。'
- en: '`sort -r` reverse sort order'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sort -r` 反向排序。'
- en: '`sort -R` scramble order'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sort -R` 打乱顺序。'
- en: '`uniq -c` count number of occurrences'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uniq -c` 计算出现次数。'
- en: '`uniq -d` only print duplicate lines'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uniq -d` 仅打印重复的行。'
- en: CUT
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUT
- en: Cut is for removing columns. To illustrate, if we only wanted the first and
    third columns.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Cut 用于删除列。例如，如果我们只想要第一列和第三列。
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To select every column other than the first.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 选择除第一列之外的所有列。
- en: '[PRE11]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In combination with other commands, `cut` serves as a filter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 结合其他命令，`cut` 作为一个过滤器。
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finding out the number of unique values within the second column.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 找出第二列中的唯一值数量。
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: PASTE
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PASTE
- en: Paste is a niche command with an interesting function. If you have two files
    that you need merged, and they are already sorted, `paste` has you covered.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Paste 是一个具有有趣功能的小众命令。如果你有两个需要合并的文件，并且它们已经排序，`paste` 能满足你的需求。
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For a more SQL-esque variant, see below.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更类似 SQL 的变体，请参见下面的内容。
- en: JOIN
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: JOIN
- en: 'Join is a simplistic, quasi-tangential, SQL. The largest differences being
    that `join`will return all columns and matches can only be on one field. By default, `join` will
    try and use the first column as the match key. For a different result, the following
    syntax is necessary:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Join 是一种简单的、类 SQL 的操作。最大区别在于 `join` 会返回所有列，匹配只能在一个字段上进行。默认情况下，`join` 会尝试使用第一列作为匹配键。要获得不同的结果，需要使用以下语法：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The standard join is an inner join. However, an outer join is also viable through
    the `-a` flag. Another noteworthy quirk is the `-e` flag, which can be used to
    substitute a value if a missing field is found.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的 join 是内连接。然而，通过 `-a` 标志也可以进行外连接。另一个值得注意的特点是 `-e` 标志，可以在找到缺失字段时替换一个值。
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Not the most user-friendly command, but desperate times, desperate measures.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 不是最用户友好的命令，但在紧急情况下，采取紧急措施。
- en: 'Useful options:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`join -a` print unpairable lines'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`join -a` 打印无法配对的行。'
- en: '`join -e` replace missing input fields'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`join -e` 替换缺失的输入字段。'
- en: '`join -j` equivalent to `-1 FIELD -2 FIELD`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`join -j` 等同于 `-1 FIELD -2 FIELD`。'
- en: GREP
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GREP
- en: Global search for a regular expression and print, or `grep`; likely, the most
    well known command, and with good reason. Grep has a lot of power, especially
    for finding your way around large codebases. Within the realm of data science,
    it acts as a refining mechanism for other commands. Although its standard usage
    is valuable as well.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 全局搜索正则表达式并打印，或 `grep`；可能是最知名的命令，也是有充分理由的。Grep 功能强大，特别是在大型代码库中查找内容时。在数据科学领域，它作为其他命令的精炼机制。虽然它的标准用法也很有价值。
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Count total number of lines containing word / pattern.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 计算包含词语/模式的总行数。
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Grep for multiple values using the or operator — `\|`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用或操作符 `\|` 为多个值执行 grep。
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Useful options
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的选项：
- en: '`alias grep="grep --color=auto"` make grep colorful'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alias grep="grep --color=auto"` 使 grep 显示彩色。'
- en: '`grep -E` use extended regexps'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grep -E` 使用扩展正则表达式。'
- en: '`grep -w` only match whole words'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grep -w` 仅匹配完整单词。'
- en: '`grep -l` print name of files with match'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grep -l` 打印包含匹配项的文件名。'
- en: '`grep -v` inverted matching'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grep -v` 反向匹配。'
- en: THE BIG GUNS
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大招
- en: Sed and Awk are the two most powerful commands in this article. For brevity,
    I’m not going to go into exhausting detail about either. Instead, I will cover
    a variety of commands that prove their impressive might. If you want to know more, [there
    is a book](https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255/ref=sr_1_1?ie=UTF8&qid=1524381457&sr=8-1&keywords=sed+and+awk) just
    for that.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Sed 和 Awk 是本文中最强大的两个命令。为了简洁，我不会详细讨论它们。相反，我将介绍各种证明其强大能力的命令。如果你想了解更多，[有一本书](https://www.amazon.com/sed-awk-Dale-Dougherty/dp/1565922255/ref=sr_1_1?ie=UTF8&qid=1524381457&sr=8-1&keywords=sed+and+awk)专门讲解这些内容。
- en: SED
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SED
- en: At its core `sed` is a stream editor that operates on a line-by-line basis.
    It excels at substitutions, but can also be leveraged for all out refactoring.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，`sed` 是一个逐行操作的流编辑器。它擅长于替换，但也可以用于全面的重构。
- en: The most basic `sed` command consists of `s/old/new/g`. This translates to search
    for old value, replace all occurences in-line with new. Without the `/g`our command
    would terminate after the first occurrence on the line.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的 `sed` 命令是 `s/old/new/g`。这表示搜索旧值，将所有出现的旧值替换为新值。如果没有 `/g`，我们的命令将在行中第一次出现后终止。
- en: 'To get a quick taste of the power lets dive into an example. In this scenario
    you’ve been given the following file:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速体验这种强大功能，我们来看看一个例子。在这个场景中，你会得到以下文件：
- en: '[PRE20]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The first thing we may want to do is remove the dollar signs. The `-i` flag
    indicates in-place. The `''` is to indicate a zero-length file extension, thus
    overwriting our initial file. Ideally, you would test each of these individually
    and then output to a new file.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先可能要做的是移除美元符号。`-i`标志表示就地修改。`''`表示零长度的文件扩展名，从而覆盖我们的初始文件。理想情况下，你应当逐一测试这些命令，然后输出到新文件。
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Next up, the commas in our `balance` column values.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是我们`balance`列值中的逗号。
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Lastly, Jack up and decided to quit one day. So, au revoir, mon ami.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Jack决定有一天辞职了。所以，再见，我的朋友。
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As you can see, `sed` packs quite a punch, but the fun doesn’t stop there.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`sed`确实非常强大，但乐趣并不止于此。
- en: AWK
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWK
- en: 'The best for last. Awk is much more than a simple command: it is a full-blown
    language. Of everything covered in this article, `awk` is by far the coolest.
    If you find yourself impressed there are loads of great resources - see [here](https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X/ref=sr_1_1?ie=UTF8&qid=1524388936&sr=8-1&keywords=awk), [here](http://www.grymoire.com/Unix/Awk.html)and [here](https://www.tutorialspoint.com/awk/index.htm).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的最好。Awk不仅仅是一个简单的命令：它是一种全面的语言。在本文涵盖的一切中，`awk`无疑是最酷的。如果你感到印象深刻，还有很多很棒的资源 - 见[这里](https://www.amazon.com/AWK-Programming-Language-Alfred-Aho/dp/020107981X/ref=sr_1_1?ie=UTF8&qid=1524388936&sr=8-1&keywords=awk)、[这里](http://www.grymoire.com/Unix/Awk.html)和[这里](https://www.tutorialspoint.com/awk/index.htm)。
- en: 'Common use cases for `awk` include:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`的常见用例包括：'
- en: Text processing
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本处理
- en: Formatted text reports
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格式化文本报告
- en: Performing arithmetic operations
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行算术操作
- en: Performing string operations
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行字符串操作
- en: Awk can parallel `grep` in its most nascent form.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Awk可以在最初形态上与`grep`并驾齐驱。
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Or with a little more magic the combination of `grep` and `cut`. Here, `awk`prints
    the third and fourth column, tab separated, for all lines with our *word*. `-F,` merely
    changes our delimiter to a comma.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 或者通过一些魔法结合`grep`和`cut`。这里，`awk`打印第三和第四列，以制表符分隔，针对所有包含我们*word*的行。`-F,`只是将分隔符改为逗号。
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Awk comes with a lot of nifty variables built-in. For instance, `NF` - number
    of fields - and `NR` - number of records. To get the fifty-third record in a file:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Awk内置了许多有用的变量。例如，`NF` - 字段数 - 和`NR` - 记录数。要获取文件中的第53条记录：
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: An added wrinkle is the ability to filter based off of one or more values. The
    first example, below, will print the line number and columns for records where
    the first column equals *string*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一个额外的功能是基于一个或多个值进行筛选。下面的第一个例子，将打印记录的行号和列，对于第一列等于*string*的记录。
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Multiple numerical expressions:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 多个数值表达式：
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Sum the third column:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 求第三列的和：
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The sum of the third column, for values where the first column equals “something”.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一列等于“something”的值，第三列的总和。
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Get the dimensions of a file:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 获取文件的尺寸：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Print lines appearing twice:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出现两次的行：
- en: '[PRE32]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Remove duplicate lines:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 移除重复行：
- en: '[PRE33]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Substitute multiple values using built-in function `gsub()`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内置函数`gsub()`替换多个值。
- en: '[PRE34]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This `awk` command will combine multiple CSV files, ignoring the header and
    then append it at the end.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`awk`命令会合并多个CSV文件，忽略头部，然后在末尾追加。
- en: '[PRE35]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Need to downsize a massive file? Welp, `awk` can handle that with help from `sed`.
    Specifically, this command breaks one big file into multiple smaller ones based
    on a line count. This one-liner will also add an extension.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 需要缩小一个庞大的文件？嗯，`awk`可以在`sed`的帮助下处理。具体来说，这条命令会根据行数将一个大文件拆分成多个小文件。这条单行命令也会添加一个扩展名。
- en: '[PRE36]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: CLOSING
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束
- en: The command line boasts endless power. The commands covered in this article
    are enough to elevate you from zero to hero in no time. Beyond those covered,
    there are many utilities to consider for daily data operations. [Csvkit](http://csvkit.readthedocs.io/en/1.0.3/), [xsv](https://github.com/BurntSushi/xsv) and [q](https://github.com/harelba/q) are
    three of note. If you’re looking to take an even deeper dive into command line
    data science, then look no further than [this book](https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853/ref=sr_1_1?ie=UTF8&qid=1524390894&sr=8-1&keywords=data+science+at+the+command+line).
    It’s also available online [for free](https://www.datascienceatthecommandline.com/)!
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行具有无尽的力量。本文所涵盖的命令足以让你迅速从新手成长为高手。除了这些，还有许多实用工具可供考虑，以应对日常数据操作。[Csvkit](http://csvkit.readthedocs.io/en/1.0.3/)、[xsv](https://github.com/BurntSushi/xsv)
    和 [q](https://github.com/harelba/q) 是值得注意的三个。如果你希望进一步深入探讨命令行数据科学，那么不妨看看 [这本书](https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853/ref=sr_1_1?ie=UTF8&qid=1524390894&sr=8-1&keywords=data+science+at+the+command+line)。这本书也可以在线
    [免费阅读](https://www.datascienceatthecommandline.com/)！
- en: '[More on my blog!](http://kadekillary.work/post/statusline/)'
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[更多内容请见我的博客！](http://kadekillary.work/post/statusline/)'
- en: LINKS
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 链接
- en: '[Sed One-Liners](http://sed.sourceforge.net/sed1line.txt)'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sed 一行命令](http://sed.sourceforge.net/sed1line.txt)'
- en: '[Awk One-Liners](http://www.catonmat.net/blog/wp-content/uploads/2008/09/awk1line.txt)'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Awk 一行命令](http://www.catonmat.net/blog/wp-content/uploads/2008/09/awk1line.txt)'
- en: '[Working With CSVs on the Command Line](http://bconnelly.net/working-with-csvs-on-the-command-line/)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命令行中的 CSV 处理](http://bconnelly.net/working-with-csvs-on-the-command-line/)'
- en: '[Appending file extensions](https://stackoverflow.com/questions/1108527/recursively-add-file-extension-to-all-files)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[附加文件扩展名](https://stackoverflow.com/questions/1108527/recursively-add-file-extension-to-all-files)'
- en: '[My Best AWK Tricks](http://blog.jpalardy.com/posts/my-best-awk-tricks/)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我最好的 AWK 技巧](http://blog.jpalardy.com/posts/my-best-awk-tricks/)'
- en: '[Bioinformatics one-liners](https://github.com/stephenturner/oneliners)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生物信息学一行命令](https://github.com/stephenturner/oneliners)'
- en: '[The UNIX School](http://www.theunixschool.com/)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[UNIX 学校](http://www.theunixschool.com/)'
- en: '[Sed — An Intro and Tutorial](http://www.grymoire.com/Unix/Sed.html)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Sed — 介绍与教程](http://www.grymoire.com/Unix/Sed.html)'
- en: '**Bio: [Kade Killary](http://kadekillary.work/)** is a Data Scientist & Engineer
    at XMedia.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Kade Killary](http://kadekillary.work/)** 是 XMedia 的数据科学家和工程师。'
- en: '[Original](https://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da).
    Reposted with permission.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@kadek/command-line-tricks-for-data-scientists-c98e0abe5da)。经许可转载。'
- en: '**Related:**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Top 12 Essential Command Line Tools for Data Scientists](/2018/03/top-12-essential-command-line-tools-data-scientists.html)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的 12 大必备命令行工具](/2018/03/top-12-essential-command-line-tools-data-scientists.html)'
- en: '[Data Science at the Command Line: Exploring Data](/2018/02/data-science-command-line-book-exploring-data.html)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命令行中的数据科学：探索数据](/2018/02/data-science-command-line-book-exploring-data.html)'
- en: '[7 Steps to Mastering Data Preparation with Python](/2017/06/7-steps-mastering-data-preparation-python.html)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 掌握数据准备的 7 个步骤](/2017/06/7-steps-mastering-data-preparation-python.html)'
- en: More On This Topic
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Data Science at the Command Line: The Free eBook](https://www.kdnuggets.com/2022/03/data-science-command-line-free-ebook.html)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命令行中的数据科学：免费电子书](https://www.kdnuggets.com/2022/03/data-science-command-line-free-ebook.html)'
- en: '[5 More Command Line Tools for Data Science](https://www.kdnuggets.com/2023/03/5-command-line-tools-data-science.html)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的 5 个命令行工具](https://www.kdnuggets.com/2023/03/5-command-line-tools-data-science.html)'
- en: '[ChatGPT CLI: Transform Your Command-Line Interface Into ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT CLI：将你的命令行界面转变为 ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
- en: '[Master The Art Of Command Line With This GitHub Repository](https://www.kdnuggets.com/master-the-art-of-command-line-with-this-github-repository)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这个 GitHub 仓库掌握命令行的艺术](https://www.kdnuggets.com/master-the-art-of-command-line-with-this-github-repository)'
- en: '[Build a Command-Line App with Python in 7 Easy Steps](https://www.kdnuggets.com/build-a-command-line-app-with-python-in-7-easy-steps)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 在 7 个简单步骤中构建命令行应用](https://www.kdnuggets.com/build-a-command-line-app-with-python-in-7-easy-steps)'
- en: '[10 Jupyter Notebook Tips and Tricks for Data Scientists](https://www.kdnuggets.com/2023/06/10-jupyter-notebook-tips-tricks-data-scientists.html)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的 10 个 Jupyter Notebook 技巧与窍门](https://www.kdnuggets.com/2023/06/10-jupyter-notebook-tips-tricks-data-scientists.html)'
