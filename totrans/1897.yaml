- en: 21 Must-Know Data Science Interview Questions and Answers, part 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers-part2.html/2](https://www.kdnuggets.com/2016/02/21-data-science-interview-questions-answers-part2.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Q14\. What method do you use to determine whether the statistics published in
    an article (or appeared in a newspaper or other media) are either wrong or presented
    to support the author's point of view, rather than correct, comprehensive factual
    information on a specific subject?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A simple rule, suggested by Zack Lipton, is
  prefs: []
  type: TYPE_NORMAL
- en: if some statistics are published in a newspaper, then they are wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a more serious answer by [**Anmol Rajpurohit**.](/author/anmol-rajpurohit)
  prefs: []
  type: TYPE_NORMAL
- en: Every media organization has a target audience. This choice impacts a lot of
    decisions such as which article to publish, how to phrase an article, what part
    of an article to highlight, how to tell a given story, etc.
  prefs: []
  type: TYPE_NORMAL
- en: In determining the validity of statistics published in any article, one of the
    first steps will be to examine the publishing agency and its target audience.
    Even if it is the same news story involving statistics, you will notice that it
    will be published very differently across Fox News vs. WSJ vs. ACM/IEEE journals.
    So, data scientists are smart about where to get the news from (and how much to
    rely on the stories based on sources!).
  prefs: []
  type: TYPE_NORMAL
- en: '![Misleading chart on Fox News: if Bush tax cuts expire](../Images/eb886ced5bdb342f16550bf377a9e77b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Fig 14a: Example of a very misleading bar chart that appeared on Fox News**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Objective chart: if Bush tax cuts expire](../Images/f50f650eb9fee02ec09e8b314ceff44d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Fig 14b: how the same data should be presented objectively**, from [5 Ways
    to Avoid Being Fooled By Statistics](http://www.iacquire.com/blog/5-ways-to-avoid-being-fooled-by-statistics)'
  prefs: []
  type: TYPE_NORMAL
- en: Often the authors try to hide the inadequacy of their research through canny
    storytelling and omitting important details to jump on to enticingly presented
    false insights. Thus, a thumb's rule to identify articles with misleading statistical
    inferences is to examine whether the article includes details on the research
    methodology followed and any perceived limitations of the choices made related
    to research methodology. Look for words such as "sample size", "margin of error",
    etc. While there are no perfect answers as to what sample size or margin of error
    is appropriate, these attributes must certainly be kept in mind while reading
    the end results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another common case of erratic reporting are the situations when journalists
    with poor data-education pick up an insight from one or two paragraphs of a published
    research paper, while ignoring the rest of research paper, just in order to make
    their point. So, here is how you can be smart to avoid being fooled by such articles:
    Firstly, a reliable article must not have any unsubstantiated claims. All the
    assertions must be backed with reference to past research. Or otherwise, is must
    be clearly differentiated as an "opinion" and not an assertion. Secondly, just
    because an article is referring to renowned research papers, does not mean that
    it is using the insight from those research papers appropriately. This can be
    validated by reading those referred research papers "in entirety", and independently
    judging their relevance to the article at hand. Lastly, though the end-results
    might naturally seem like the most interesting part, it is often fatal to skip
    the details about research methodology (and spot errors, bias, etc.).'
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, I wish that all such articles publish their underlying research data
    as well as the approach. That way, the articles can achieve genuine trust as everyone
    is free to analyze the data and apply the research approach to see the results
    for themselves.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Q15\. Explain Edward Tufte's concept of "chart junk."
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Answer by [Gregory Piatetsky](/author/gregory-piatetsky):**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chartjunk](https://en.wikipedia.org/wiki/Chartjunk) refers to all visual elements
    in charts and graphs that are not necessary to comprehend the information represented
    on the graph, or that distract the viewer from this information.'
  prefs: []
  type: TYPE_NORMAL
- en: The term chartjunk was coined by [Edward Tufte](https://en.wikipedia.org/wiki/Edward_Tufte)
    in his 1983 book [*The Visual Display of Quantitative Information*](http://www.edwardtufte.com/tufte/books_vdqi).
  prefs: []
  type: TYPE_NORMAL
- en: '![Tufte Chartjunk](../Images/58fd299951b23cd3ee4c376d8e9eb172.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Fig 15.** Tufte [writes](http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=00040Z):
    "an unintentional Necker Illusion, as two back planes optically flip to the front.
    Some pyramids conceal others; and one variable (stacked depth of the stupid pyramids)
    has no label or scale."'
  prefs: []
  type: TYPE_NORMAL
- en: '![An example of Chartjunk](../Images/d820b8880a509dedff5ca4830b27fd82.png)
    Here is a more modern example from [ exceluser](http://exceluser.com/blog/1133/good-examples-of-bad-charts-chart-junk-from-a-surprising-source.html)
    where it is very hard to understand the column plot because of workers and cranes
    that obscure them.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem with such decorations is that they forces readers to work much harder
    than necessary to discover the meaning of data.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 16\. How would you screen for outliers and what should you do if you find one?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Answer by [**Bhavya Geethika**](/author/geethika).
  prefs: []
  type: TYPE_NORMAL
- en: 'Some methods to screen outliers are z-scores, modified z-score, box plots,
    Grubb''s test, Tietjen-Moore test exponential smoothing, Kimber test for exponential
    distribution and moving window filter algorithm. However two of the robust methods
    in detail are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inter Quartile Range**'
  prefs: []
  type: TYPE_NORMAL
- en: An outlier is a point of data that lies over 1.5 IQRs below the first quartile
    (Q1) or above third quartile (Q3) in a given data set.
  prefs: []
  type: TYPE_NORMAL
- en: High = (Q3) + 1.5 IQR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Low = (Q1) - 1.5 IQR
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tukey Method**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It uses interquartile range to filter very large or very small numbers. It
    is practically the same method as above except that it uses the concept of "fences".
    The two values of fences are:'
  prefs: []
  type: TYPE_NORMAL
- en: Low outliers = Q1 - 1.5(Q3 - Q1) = Q1 - 1.5(IQR)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High outliers = Q3 + 1.5(Q3 - Q1) = Q3 + 1.5(IQR)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything outside of the fences is an outlier.
  prefs: []
  type: TYPE_NORMAL
- en: When you find outliers, you should not remove it without a qualitative assessment
    because that way you are altering the data and making it no longer pure. It is
    important to understand the context of analysis or importantly "The Why question
    - Why an outlier is different from other data points?"
  prefs: []
  type: TYPE_NORMAL
- en: This reason is critical. If outliers are attributed to error, you may throw
    it out but if they signify a new trend, pattern or reveal a valuable insight into
    the data you should retain it.
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Data Analytics Interview Questions & Answers](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Python Interview Questions & Answers](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, May 4: 9 Free Harvard Courses to Learn Data…](https://www.kdnuggets.com/2022/n18.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
