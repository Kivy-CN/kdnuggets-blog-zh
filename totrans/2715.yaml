- en: DeepMind’s Three Pillars for Building Robust Machine Learning Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/08/deepmind-three-pillars-building-robust-machine-learning-systems.html](https://www.kdnuggets.com/2020/08/deepmind-three-pillars-building-robust-machine-learning-systems.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![Figure](../Images/6003320fe75417b0d6cc3e182e6c0838.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Source: [https://tutorials.datasciencedojo.com/building-robust-machine-learning-models/attachment/2412/](https://tutorials.datasciencedojo.com/building-robust-machine-learning-models/attachment/2412/)
  prefs: []
  type: TYPE_NORMAL
- en: 'I recently started a new newsletter focus on AI education. TheSequence is a
    no-BS( meaning no hype, no news etc) AI-focused newsletter that takes 5 minutes
    to read. The goal is to keep you up to date with machine learning projects, research
    papers and concepts. Please give it a try by subscribing below:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Image](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Building machine learning systems differs from traditional software development
    in many aspects of its lifecycle. Established software methodologies for testing,
    debugging and troubleshooting result simply impractical when applied to machine
    learning models. While the behavior of traditional software components like websites,
    mobile apps or APIs is exclusively dictated by its code, machine learning models
    evolve their knowledge over time depending on specific datasets. How to define
    and write robust machine learning agents is one of the existential challenges
    for the entire space. Last year, artificial intelligence(AI) researchers from
    DeepMind [published some ideas about that topic](https://deepmind.com/blog/article/robust-and-verified-ai).
  prefs: []
  type: TYPE_NORMAL
- en: When we think about writing robust software, we immediately relate to two code
    that behaves according to a predefined set of specifications. In the case of machine
    learning there is no established definition of correct specifications or robust
    behavior. The accepted practice is to train a machine learning model using a specific
    dataset and test it using a different dataset. That approach is incredibly efficient
    achieving above average behaviors in both datasets but is not always efficient
    when comes to edge cases. A classic example of these challenges are seeing in
    image classification models that can be completely disrupted by introducing small
    variations in the input dataset that are completely imperceptible to the human
    eye.
  prefs: []
  type: TYPE_NORMAL
- en: The notion of robustness in machine learning model should go beyond performing
    well against training and testing datasets but should also behave according to
    a predefined set of specifications that describe a desirable behavior of the system.
    Using our previous example, a requirement specification might detail the expected
    behavior of a machine learning model against adversarial perturbations or a given
    set of safety constraints.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing robust machine learning programs is a combination of many aspects ranging
    from accurate training dataset to efficient optimization techniques. However,
    most of these processes can be model as a variation of three main pillars that
    constitute the core focus on DeepMind’s research:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/11effdabde597bb8cebf065aacca4eaf.png)'
  prefs: []
  type: TYPE_IMG
- en: '***Testing Consistency with Specifications: ****Techniques to test that machine
    learning systems are consistent with properties (such as invariance or robustness)
    desired by the designer and users of the system.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***Training Machine Learning models to be Specification-Consistent:**** Even
    with copious training data, standard machine learning algorithms can produce predictive
    models that make predictions inconsistent with desirable specifications like robustness
    or fairness — this requires us to reconsider training algorithms that produce
    models that not only fit training data well, but also are consistent with a list
    of specifications.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***Formally Proving that Machine Learning Models are Specification-Consistent: ****There
    is a need for algorithms that can verify that the model predictions are provably
    consistent with a specification of interest for all possible inputs. While the
    field of formal verification has studied such algorithms for several decades,
    these approaches do not easily scale to modern deep learning systems despite impressive
    progress.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specification Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adversarial examples are a great mechanism to test the behavior of machine learning
    models against a given set of specifications. Unfortunately, most of the relevant
    work in adversarial training has been constrained to image classification models.
    Expanding some of those ideas into more generic areas such as reinforcement learning
    could provide a general-purpose mechanism to test the robustness of machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Following some of the ideas of adversarial training, DeepMind developed two
    complementary approaches for adversarial testing of RL agents. The first technique
    uses a derivative-free optimization to directly minimize the expected reward of
    an agent. The second method learns an adversarial value function which predicts
    from experience which situations are most likely to cause failures for the agent.
    The learned function is then used for optimization to focus the evaluation on
    the most problematic inputs. These approaches form only a small part of a rich,
    growing space of potential algorithms, and we are excited about future development
    in rigorous evaluation of agents.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/99ccec26d349a7aecddded2021589a71.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://deepmind.com/blog/article/robust-and-verified-ai](https://deepmind.com/blog/article/robust-and-verified-ai)
  prefs: []
  type: TYPE_NORMAL
- en: The adversarial approaches showed tangible improvements over traditional testing
    methods in reinforcement learning agents. Adversarial testing uncovered errors
    that typically go unnoticed while also surfaced qualitatively behavior in the
    agents that was not expected based on the composition of the training dataset.
    For instance, the following figure shows the effect of adversarial training in
    a 3D navigation task., Even though the agent can achieve human level performance,
    adversarial training shows that it can still fail in super simple tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Specification Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Adversarial testing is incredibly effective detecting errors but still fails
    to uncover examples that deviate from a given specification. If we think about
    the concept of requirements from a machine learning standpoint, they can be modeled
    as a mathematical relationship between inputs and outputs. Using that idea, the
    DeepMind team created a method that geometrically calculates the consistency of
    a model with a given specification by using lower and upper bounds. Known as Interval
    Bound Propagation, DeepMind’s method maps a specification to a bounded box that
    can be evaluated across each layer of the network as shown in the following figure.
    The technique proven to decrease provable error rates across a wide variety of
    machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/732db3a9709521550d3969acd81eb314.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://deepmind.com/blog/article/robust-and-verified-ai](https://deepmind.com/blog/article/robust-and-verified-ai)
  prefs: []
  type: TYPE_NORMAL
- en: Formal Verification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Accurate testing and training are necessary steps to achieve robustness in machine
    learning models but largely insufficient to ensure that a system behaves according
    to its expectations. In large-scale models, enumerating all possible outputs for
    a given set of inputs (for example, infinitesimal perturbations to an image) is
    intractable due to the astronomical number of choices for the input perturbation.
    Formal verification techniques is an active area of research that focuses on finding
    efficient approaches to setting geometric bounds based on a given specification.
  prefs: []
  type: TYPE_NORMAL
- en: DeepMind recently developed a formal verification method that models the verification
    problem as an optimization problem that tries to find the largest violation of
    the property being verified. The technique iterates several times until it finds
    the correct bound which indirectly guarantees that there can be no further violation
    of a given property. Although initially applied to reinforcement learning models,
    DeepMind’s approach is very easy to generalize to other machine learning techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a1773aba811d13f6bc222b52c6eb8abd.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://deepmind.com/blog/article/robust-and-verified-ai](https://deepmind.com/blog/article/robust-and-verified-ai)
  prefs: []
  type: TYPE_NORMAL
- en: The combination of testing, training and formal verification of specifications
    constitute three key pillars for the implementation of robust machine learning
    models. DeepMind ideas area a great starting point but we should expect these
    concepts to evolve into functional datasets or frameworks that enable the modeling
    and verification of specifications related to machine learning models. The path
    towards robust machine learning will also be enabled by machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/swlh/deepminds-three-pillars-for-building-robust-machine-learning-systems-a9679e56250a).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Learning by Forgetting: Deep Neural Networks and the Jennifer Aniston Neuron](/2020/06/learning-forgetting-deep-neural-networks-jennifer-aniston.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DeepMind’s Suggestions for Learning #AtHomeWithAI](/2020/05/deepmind-suggested-resources-learning-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Facebook Uses Bayesian Optimization to Conduct Better Experiments in Machine
    Learning Models](/2020/08/facebook-bayesian-optimization-better-experiments-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Inside DeepMind’s New Efforts to Use Deep Learning to Advance Mathematics](https://www.kdnuggets.com/2021/12/inside-deepmind-new-efforts-deep-learning-advance-mathematics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Will DeepMind’s AlphaCode Replace Programmers?](https://www.kdnuggets.com/2022/04/deepmind-alphacode-replace-programmers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[First Open Source Implementation of DeepMind’s AlphaTensor](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Design effective & reliable machine learning systems!](https://www.kdnuggets.com/2023/05/manning-design-effective-reliable-machine-learning-systems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Uncertainty Quantification in Artificial Intelligence-based Systems](https://www.kdnuggets.com/2022/04/uncertainty-quantification-artificial-intelligencebased-systems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
