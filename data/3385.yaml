- en: An Intuitive Explanation of Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的直观解释
- en: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html/3)
- en: Putting it all together – Training using Backpropagation
  id: totrans-2
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 综合起来—使用反向传播进行训练
- en: As discussed above, the Convolution + Pooling layers act as Feature Extractors
    from the input image while Fully Connected layer acts as a classifier.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，卷积+池化层作为从输入图像中提取特征的工具，而全连接层作为分类器。
- en: Note that in **Figure 15** below, since the input image is a boat, the target
    probability is 1 for Boat class and 0 for other three classes, i.e.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在**图15**中，由于输入图像是一艘船，目标概率对于船类是1，对于其他三个类别是0，即
- en: Input Image = Boat
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像 = 船
- en: Target Vector = [0, 0, 1, 0]
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标向量 = [0, 0, 1, 0]
- en: '![Screen Shot 2016-08-07 at 9.15.21 PM.png](../Images/5bb4a90b9c753c8a606458431de7e989.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 9.15.21 PM.png](../Images/5bb4a90b9c753c8a606458431de7e989.png)'
- en: Figure 15: Training the ConvNet
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15：训练ConvNet
- en: 'The overall training process of the Convolution Network may be summarized as
    below:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络的整体训练过程可以总结如下：
- en: '**Step1:** We initialize all filters and parameters / weights with random values'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤1：** 我们用随机值初始化所有过滤器和参数/权重'
- en: '**Step**2:**** The network takes a training image as input, goes through the
    forward propagation step (convolution, ReLU and pooling operations along with
    forward propagation in the Fully Connected layer) and finds the output probabilities for each
    class.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤2：** 网络将一张训练图像作为输入，经过前向传播步骤（包括卷积、ReLU和池化操作以及全连接层中的前向传播），并找到每个类别的输出概率。'
- en: Lets say the output probabilities for the boat image above are [0.2, 0.4, 0.1,
    0.3]
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设上述船图像的输出概率是[0.2, 0.4, 0.1, 0.3]
- en: Since weights are randomly assigned for the first training example, output probabilities
    are also random.
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于权重在第一次训练示例中是随机分配的，输出概率也是随机的。
- en: '**Step3:** Calculate the total error at the output layer (summation over all
    4 classes)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤3：** 计算输出层的总误差（对所有4个类别进行求和）'
- en: '**Total Error = ∑  ½ (target probability – output probability) ²**'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总误差 = ∑  ½ (目标概率 – 输出概率)²**'
- en: '**Step4:** Use Backpropagation to calculate the *gradients* of the error with
    respect to all weights in the network and use *gradient descent* to update all
    filter values / weights and parameter values to minimize the output error.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤4：** 使用反向传播计算相对于网络中所有权重的*梯度*，并使用*梯度下降*更新所有过滤器值/权重和参数值，以最小化输出误差。'
- en: The weights are adjusted in proportion to their contribution to the total error.
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重根据它们对总误差的贡献进行调整。
- en: When the same image is input again, output probabilities might now be [0.1,
    0.1, 0.7, 0.1], which is closer to the target vector [0, 0, 1, 0].
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当再次输入相同的图像时，输出概率现在可能是[0.1, 0.1, 0.7, 0.1]，这更接近目标向量[0, 0, 1, 0]。
- en: This means that the network has *learnt* to classify this particular image correctly
    by adjusting its weights / filters such that the output error is reduced.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这意味着网络已经*学会*通过调整其权重/过滤器以减少输出误差，从而正确分类这张特定的图像。
- en: Parameters like number of filters, filter sizes, architecture of the network
    etc. have all been fixed before Step 1 and do not change during training process
    – only the values of the filter matrix and connection weights get updated.
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像过滤器数量、过滤器大小、网络结构等参数在步骤1之前已固定，并且在训练过程中不会改变——只有过滤器矩阵和连接权重的值会被更新。
- en: '**Step5:** Repeat steps 2-4 with all images in the training set.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤5：** 对训练集中的所有图像重复步骤2-4。'
- en: The above steps *train* the ConvNet – this essentially means that all the weights
    and parameters of the ConvNet have now been optimized to correctly classify images
    from the training set.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤*训练*了ConvNet——这基本上意味着ConvNet的所有权重和参数现在已经优化，以正确分类训练集中的图像。
- en: When a new (unseen) image is input into the ConvNet, the network would go through
    the forward propagation step and output a probability for each class (for a new image,
    the output probabilities are calculated using the weights which have been optimized
    to correctly classify all the previous training examples). If our training set
    is large enough, the network will (hopefully) generalize well to new images and
    classify them into correct categories.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个新的（未见过的）图像输入到 ConvNet 中时，网络将经过前向传播步骤，为每个类别输出一个概率（对于新图像，输出概率是使用已优化的权重来正确分类所有之前训练样本计算的）。如果我们的训练集足够大，网络将（希望）能很好地推广到新图像，并将其分类到正确的类别中。
- en: '**Note 1:** The steps above have been oversimplified and mathematical details
    have been avoided to provide intuition into the training process. See [4] and [12]
    for a mathematical formulation and thorough understanding.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意 1：** 上述步骤已被过度简化，并且为了提供对训练过程的直观理解，避开了数学细节。有关数学公式和深入理解，请参见 [4] 和 [12]。'
- en: '**Note 2:** In the example above we used two sets of alternating Convolution
    and Pooling layers. Please note however, that these operations can be repeated
    any number of times in a single ConvNet. In fact, some of the best performing
    ConvNets today have tens of Convolution and Pooling layers! Also, it is not necessary to
    have a Pooling layer after every Convolutional Layer. As can be seen in the **Figure
    16** below, we can have multiple Convolution + ReLU operations in succession before
    a having a Pooling operation. Also notice how each layer of the ConvNet is visualized
    in the Figure 16 below.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意 2：** 在上述示例中，我们使用了两个交替的卷积和池化层。不过，请注意，这些操作可以在单个 ConvNet 中重复任意次数。实际上，今天一些表现最好的
    ConvNet 具有数十个卷积和池化层！此外，并不一定要在每个卷积层后都有一个池化层。如**图 16**所示，我们可以在进行池化操作之前连续进行多个卷积 +
    ReLU 操作。还请注意下图 16 中每层卷积网络的可视化。'
- en: '![car.png](../Images/408e15a0f1b5418c7f4a5849f161bdb3.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![car.png](../Images/408e15a0f1b5418c7f4a5849f161bdb3.png)'
- en: 'Figure 16: Source [4]'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 16：来源 [4]
- en: Visualizing Convolutional Neural Networks
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积神经网络的可视化
- en: 'In general, the more convolution steps we have, the more complicated features
    our network will be able to learn to recognize. For example, in Image Classification
    a ConvNet may learn to detect edges from raw pixels in the first layer, then use
    the edges to detect simple shapes in the second layer, and then use these shapes
    to deter higher-level features, such as facial shapes in higher layers [14]. This
    is demonstrated in **Figure 17** below – these features were learnt using a [Convolutional
    Deep Belief Network](http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf) and
    the figure is included here just for demonstrating the idea (this is only an example:
    real life convolution filters may detect objects that have no meaning to humans).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，卷积步骤越多，我们的网络能够学习识别的特征就会越复杂。例如，在图像分类中，卷积网络可能会在第一层从原始像素中学习检测边缘，然后在第二层使用这些边缘检测简单的形状，再在更高层使用这些形状检测更高层次的特征，如面部轮廓
    [14]。这在下面的**图 17**中得到了演示——这些特征是使用 [卷积深度置信网络](http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf)
    学到的，此图仅用于展示该思想（这只是一个例子：现实中的卷积滤波器可能会检测到对人类没有意义的对象）。
- en: '![Screen Shot 2016-08-10 at 12.58.30 PM.png](../Images/b2e500c81759b10bf09e7ce4132e932a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-10 at 12.58.30 PM.png](../Images/b2e500c81759b10bf09e7ce4132e932a.png)'
- en: 'Figure 17: Learned features from a Convolutional Deep Belief Network'
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 17：来自卷积深度置信网络的学习特征
- en: Adam Harley created amazing visualizations of a Convolutional Neural Network
    trained on the MNIST Database of handwritten digits [13]. I highly recommend [playing
    around with it](http://scs.ryerson.ca/~aharley/vis/conv/flat.html) to understand
    details of how a CNN works.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Adam Harley 创建了卷积神经网络在 MNIST 手写数字数据库上训练的惊人可视化。我强烈推荐 [玩一玩这个](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)
    以了解 CNN 如何工作的细节。
- en: We will see below how the network works for an input ‘8’. Note that the visualization
    in **Figure 18** does not show the ReLU operation separately.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将下面看到网络如何处理输入‘8’。请注意，**图 18** 中的可视化并未单独展示 ReLU 操作。
- en: '![conv_all.png](../Images/1cd0018da396b25aab0d675ef4fbfae2.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![conv_all.png](../Images/1cd0018da396b25aab0d675ef4fbfae2.png)'
- en: 'Figure 18: Visualizing a ConvNet trained on handwritten digits'
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 18：可视化一个训练过的卷积网络在手写数字上的效果
- en: The input image contains 1024 pixels (32 x 32 image) and the first Convolution
    layer (Convolution Layer 1) is formed by convolution of six unique 5 × 5 (stride
    1) filters with the input image. As seen, using six different filters produces
    a feature map of depth six.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像包含 1024 个像素（32 x 32 图像），第一卷积层（卷积层 1）是通过将六个独特的 5 × 5（步幅为 1）滤波器与输入图像进行卷积形成的。如所见，使用六个不同的滤波器会产生深度为六的特征图。
- en: Convolutional Layer 1 is followed by Pooling Layer 1 that does 2 × 2 max pooling
    (with stride 2) separately over the six feature maps in Convolution Layer 1\.
    You can move your mouse pointer over any pixel in the Pooling Layer and observe
    the 4 x 4 grid it forms in the previous Convolution Layer (demonstrated in **Figure
    19**). You’ll notice that the pixel having the maximum value (the brightest one)
    in the 4 x 4 grid makes it to the Pooling layer.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层 1 后面跟着池化层 1，该层对卷积层 1 中的六个特征图进行 2 × 2 最大池化（步幅为 2）。你可以将鼠标指针移动到池化层中的任何像素上，并观察它在前一卷积层中形成的
    4 x 4 网格（如**图 19**所示）。你会注意到，4 x 4 网格中值最大的像素（最亮的一个）进入池化层。
- en: '![Screen Shot 2016-08-06 at 12.45.35 PM.png](../Images/c92ebd4788136abee4a516bfb643eea5.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-06 at 12.45.35 PM.png](../Images/c92ebd4788136abee4a516bfb643eea5.png)'
- en: 'Figure 19: Visualizing the Pooling Operation'
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 19：可视化池化操作
- en: Pooling Layer 1 is followed by sixteen 5 × 5 (stride 1) convolutional filters
    that perform the convolution operation. This is followed by Pooling Layer 2 that
    does 2 × 2 max pooling (with stride 2). These two layers use the same concepts
    as described above.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层 1 后面跟着十六个 5 × 5（步幅为 1）卷积滤波器，执行卷积操作。随后是池化层 2，该层进行 2 × 2 最大池化（步幅为 2）。这两层使用与上述相同的概念。
- en: 'We then have three fully-connected (FC) layers. There are:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们有三个全连接（FC）层。它们是：
- en: 120 neurons in the first FC layer
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一 FC 层中的 120 个神经元
- en: 100 neurons in the second FC layer
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二 FC 层中的 100 个神经元
- en: 10 neurons in the third FC layer corresponding to the 10 digits – also called
    the Output layer
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三 FC 层中的 10 个神经元对应 10 个数字——也称为输出层
- en: Notice how in **Figure 20**, each of the 10 nodes in the output layer are connected
    to all 100 nodes in the 2nd Fully Connected layer (hence the name Fully Connected).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意在**图 20**中，输出层中的每个 10 个节点都连接到第二个全连接层中的所有 100 个节点（因此得名全连接）。
- en: Also, note how the only bright node in the Output Layer corresponds to ‘8’ –
    this means that the network correctly classifies our handwritten digit (brighter
    node denotes that the output from it is higher, i.e. 8 has the highest probability
    among all other digits).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意输出层中唯一明亮的节点对应于 ‘8’——这意味着网络正确地分类了我们的手写数字（更亮的节点表示其输出更高，即 8 在所有数字中具有最高的概率）。
- en: '![final.png](../Images/2ba5a08fc4e55407d80314354c093f4b.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![final.png](../Images/2ba5a08fc4e55407d80314354c093f4b.png)'
- en: 'Figure 20: Visualizing the Filly Connected Layers'
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20：可视化全连接层
- en: The 3d version of the same visualization is available [here](http://scs.ryerson.ca/~aharley/vis/conv/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的 3D 版本可在 [这里](http://scs.ryerson.ca/~aharley/vis/conv/) 查看。
- en: Other ConvNet Architectures
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 其他 ConvNet 架构
- en: Convolutional Neural Networks have been around since early 1990s. We discussed
    the LeNet above whichwas one of the very first convolutional neural networks.
    Some other influential architectures are listed below [3] [4].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络自 1990 年代早期以来就存在。我们讨论了上面的 LeNet，这是最早的卷积神经网络之一。其他一些有影响力的架构列在下面 [3] [4]。
- en: '**LeNet (1990s):** Already covered in this article.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LeNet (1990s)：** 已在本文中介绍。'
- en: '**1990s to 2012:** In the years from late 1990s to early 2010s convolutional
    neural network were in incubation. As more and more data and computing power became
    available, tasks that convolutional neural networks could tackle became more and
    more interesting.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1990 年代至 2012 年：** 从 1990 年代末到 2010 年代初，卷积神经网络处于孕育阶段。随着数据和计算能力的不断增加，卷积神经网络可以处理的任务变得越来越有趣。'
- en: '**AlexNet (2012) – **In 2012, Alex Krizhevsky (and others) released [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
    which was a deeper and much wider version of the LeNet and won by a large margin
    the difficult ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012\.
    It was a significant breakthrough with respect to the previous approaches and
    the current widespread application of CNNs can be attributed to this work.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AlexNet (2012) –** 2012年，Alex Krizhevsky（及其他人）发布了[AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)，这是一个比LeNet更深、更宽的版本，并且以较大优势赢得了2012年的ImageNet大型视觉识别挑战赛（ILSVRC）。这一突破性进展相较于之前的方法具有显著改进，目前广泛应用的卷积神经网络（CNN）可以归功于这项工作。'
- en: '**ZF Net (2013) –** The ILSVRC 2013 winner was a Convolutional Network from
    Matthew Zeiler and Rob Fergus. It became known as the [ZFNet](http://arxiv.org/abs/1311.2901)
    (short for Zeiler & Fergus Net). It was an improvement on AlexNet by tweaking
    the architecture hyperparameters.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ZF Net (2013) –** ILSVRC 2013的冠军是Matthew Zeiler和Rob Fergus的卷积网络。它被称为[ZFNet](http://arxiv.org/abs/1311.2901)（即Zeiler
    & Fergus Net的缩写）。通过调整架构超参数，它对AlexNet进行了改进。'
- en: '**GoogLeNet (2014) – **The ILSVRC 2014 winner was a Convolutional Network from
    [Szegedy et al.](http://arxiv.org/abs/1409.4842) from Google. Its main contribution
    was the development of an *Inception Module* that dramatically reduced the number
    of parameters in the network (4M, compared to AlexNet with 60M).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GoogLeNet (2014) –** ILSVRC 2014的冠军是来自[Szegedy et al.](http://arxiv.org/abs/1409.4842)的Google卷积网络。其主要贡献是开发了一个*Inception
    Module*，显著减少了网络中的参数数量（4M，相较于AlexNet的60M）。'
- en: '**VGGNet (2014) –** The runner-up in ILSVRC 2014 was the network that became
    known as the [VGGNet](http://www.robots.ox.ac.uk/~vgg/research/very_deep/). Its
    main contribution was in showing that the depth of the network (number of layers)
    is a critical component for good performance.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VGGNet (2014) –** ILSVRC 2014的亚军是被称为[VGGNet](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)的网络。它的主要贡献在于展示了网络的深度（层数）是良好性能的关键因素。'
- en: '**ResNets (2015) – **[Residual Network](http://arxiv.org/abs/1512.03385) developed
    by Kaiming He (and others) was the winner of ILSVRC 2015. ResNets are currently
    by far state of the art Convolutional Neural Network models and are the default
    choice for using ConvNets in practice (as of May 2016).'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNets (2015) –** 由Kaiming He（及其他人）开发的[Residual Network](http://arxiv.org/abs/1512.03385)赢得了ILSVRC
    2015。ResNets目前是最先进的卷积神经网络模型，并且是实际应用中使用卷积神经网络的默认选择（截至2016年5月）。'
- en: '**DenseNet (August 2016) –** Recently published by Gao Huang (and others),
    the [Densely Connected Convolutional Network](http://arxiv.org/abs/1608.06993) has
    each layer directly connected to every other layer in a feed-forward fashion.
    The DenseNet has been shown to obtain significant improvements over previous state-of-the-art
    architectures on five highly competitive object recognition benchmark tasks. Check
    out the Torch implementation [here](https://github.com/liuzhuang13/DenseNet).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DenseNet (2016年8月) –** 最近由Gao Huang（及其他人）发布的[Densely Connected Convolutional
    Network](http://arxiv.org/abs/1608.06993)中，每一层都直接与其他所有层进行前馈连接。DenseNet在五个高度竞争的物体识别基准任务上相较于之前的最先进架构取得了显著的改进。可以在[这里](https://github.com/liuzhuang13/DenseNet)查看Torch实现。'
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 结论
- en: In this post, I have tried to explain the main concepts behind Convolutional
    Neural Networks in simple terms. There are several details I have oversimplified
    / skipped, but hopefully this post gave you some intuition around how they work.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我尝试用简单的术语解释卷积神经网络的主要概念。有几个细节我进行了简化或跳过，但希望这篇文章能为你提供一些关于它们如何工作的直观理解。
- en: This post was originally inspired from [Understanding Convolutional Neural Networks
    for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)
    by Denny Britz (which I would recommend reading) and a number of explanations
    here are based on that post. For a more thorough understanding of some of these
    concepts, I would encourage you to go through the [notes](http://cs231n.github.io/) from
    [Stanford’s course on ConvNets](http://cs231n.stanford.edu/) as well as other
    excellent resources mentioned under References below. If you face any issues understanding
    any of the above concepts or have questions / suggestions, feel free to leave
    a comment below.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本文最初受到了[Denny Britz的“理解卷积神经网络用于NLP”](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)的启发（我建议你阅读一下），本文中许多解释基于该文章。为了更深入地理解这些概念，建议你查阅[斯坦福大学卷积神经网络课程的笔记](http://cs231n.github.io/)以及下方参考文献中提到的其他优秀资源。如果你在理解上述概念时遇到任何问题或有问题/建议，欢迎在下方留言。
- en: All images and animations used in this post belong to their respective authors
    as listed in References section below.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的所有图片和动画均属于其各自的作者，详细信息请参见下方的参考文献部分。
- en: References
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Clarifai Home Page](https://www.clarifai.com/)'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Clarifai 主页](https://www.clarifai.com/)'
- en: 'Shaoqing Ren, *et al, *“Faster R-CNN: Towards Real-Time Object Detection with
    Region Proposal Networks”, 2015, [arXiv:1506.01497 ](http://arxiv.org/pdf/1506.01497v3.pdf)'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任少卿，*等*，“Faster R-CNN：基于区域提议网络的实时目标检测”，2015，[arXiv:1506.01497](http://arxiv.org/pdf/1506.01497v3.pdf)
- en: '[Neural Network Architectures](http://culurciello.github.io/tech/2016/06/04/nets.html), Eugenio
    Culurciello’s blog'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络架构](http://culurciello.github.io/tech/2016/06/04/nets.html)，Eugenio Culurciello的博客'
- en: '[CS231n Convolutional Neural Networks for Visual Recognition, Stanford](http://cs231n.github.io/convolutional-networks/)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[CS231n 视觉识别的卷积神经网络，斯坦福大学](http://cs231n.github.io/convolutional-networks/)'
- en: '[Clarifai / Technology](https://www.clarifai.com/technology)'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Clarifai / 技术](https://www.clarifai.com/technology)'
- en: '[Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.2gfx5zcw3)'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[机器学习很有趣！第3部分：深度学习与卷积神经网络](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.2gfx5zcw3)'
- en: '[Feature extraction using convolution, Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用卷积的特征提取，斯坦福大学](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)'
- en: '[Wikipedia article on Kernel (image processing) ](https://en.wikipedia.org/wiki/Kernel_(image_processing))'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[关于卷积核（图像处理）的维基百科文章](https://en.wikipedia.org/wiki/Kernel_(image_processing))'
- en: '[Deep Learning Methods for Vision, CVPR 2012 Tutorial ](http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[视觉的深度学习方法，CVPR 2012教程](http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12)'
- en: '[Neural Networks by Rob Fergus, Machine Learning Summer School 2015](http://mlss.tuebingen.mpg.de/2015/slides/fergus/Fergus_1.pdf)'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Rob Fergus的神经网络，2015年机器学习夏令营](http://mlss.tuebingen.mpg.de/2015/slides/fergus/Fergus_1.pdf)'
- en: '[What do the fully connected layers do in CNNs? ](http://stats.stackexchange.com/a/182122/53914)'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[CNN中的全连接层有什么作用？](http://stats.stackexchange.com/a/182122/53914)'
- en: '[Convolutional Neural Networks, Andrew Gibiansky ](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[卷积神经网络，Andrew Gibiansky](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)'
- en: A. W. Harley, “An Interactive Node-Link Visualization of Convolutional Neural
    Networks,” in ISVC, pages 867-877, 2015 ([link](http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf))
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A. W. Harley，“卷积神经网络的交互式节点-链接可视化”，发表于ISVC，第867-877页，2015 ([link](http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf))
- en: '[Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[理解卷积神经网络用于NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)'
- en: '[Backpropagation in Convolutional Neural Networks](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[卷积神经网络中的反向传播](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)'
- en: '[A Beginner’s Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner''s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[理解卷积神经网络的初学者指南](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner''s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)'
- en: Vincent Dumoulin, *et al*, “A guide to convolution arithmetic for deep learning”,
    2015, [arXiv:1603.07285](http://arxiv.org/pdf/1603.07285v1.pdf)
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vincent Dumoulin, *等人*, “深度学习卷积算术指南”，2015年，[arXiv:1603.07285](http://arxiv.org/pdf/1603.07285v1.pdf)
- en: '[What is the difference between deep learning and usual machine learning?](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[深度学习与普通机器学习的区别是什么？](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)'
- en: '[How is a convolutional neural network able to learn invariant features?](https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features)'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[卷积神经网络如何学习不变特征？](https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features)'
- en: '[A Taxonomy of Deep Convolutional Neural Nets for Computer Vision](http://journal.frontiersin.org/article/10.3389/frobt.2015.00036/full)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[计算机视觉的深度卷积神经网络分类法](http://journal.frontiersin.org/article/10.3389/frobt.2015.00036/full)'
- en: '[Original post](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/): Reposted
    with permission.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[原创帖子](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)：转载经许可。'
- en: '**Bio:** [Ujjwal Karn](https://ujjwalkarn.me/) has 3 years of industry and
    research experience in machine learning and is interested in practical applications
    of deep learning to language and vision understanding.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：** [Ujjwal Karn](https://ujjwalkarn.me/) 在机器学习领域拥有 3 年的行业和研究经验，并对将深度学习应用于语言和视觉理解的实际应用感兴趣。'
- en: '**Related:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Deep Learning cleans podcast episodes from ‘ahem’ sounds](/2016/11/deep-learning-cleans-podcast-ahem-sounds.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习清除播客中的‘咳嗽’声](/2016/11/deep-learning-cleans-podcast-ahem-sounds.html)'
- en: '[How Convolutional Neural Networks Work](/2016/08/brohrer-convolutional-neural-networks-explanation.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络的工作原理](/2016/08/brohrer-convolutional-neural-networks-explanation.html)'
- en: '[Deep Learning Key Terms, Explained](/2016/10/deep-learning-key-terms-explained.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习关键术语解释](/2016/10/deep-learning-key-terms-explained.html)'
- en: '* * *'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络综合指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：直观方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
