# 你从未学过的重要统计学……因为它们从未被教授

> 原文：[https://www.kdnuggets.com/2017/08/vital-statistics-never-learned-never-taught.html](https://www.kdnuggets.com/2017/08/vital-statistics-never-learned-never-taught.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

![Header](../Images/85c910744831014464778dcbc6d8c9f3.png)

**KG: 从头开始，什么是统计学，它是如何发展的？您能给我们一个简短的定义和学科历史吗？**

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的捷径。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的 IT

* * *

**FH:** 这是一个复杂的问题，最好的回答是参考我们最伟大的统计学历史学家之一Stephen Stigler的众多著作（例如见[https://en.wikipedia.org/wiki/History_of_statistics](https://en.wikipedia.org/wiki/History_of_statistics)）。

简而言之，统计学最初是一种了解国家运作、生产力、预期寿命、农业产量等的方式，并从样本中进行估计（这种统计学例子可以追溯到公元前5世纪的雅典）。 大致而言，统计学发展成了几个广泛领域：

+   描述性（例如，常见的棒球统计数据），

+   推断性（例如，棒球击球手在主场打球时的成功概率是否不同？），

+   估计性（例如，通过一个因素实验，如果我们保持面粉和糖的量不变，改变烘焙温度的效果是什么）和

+   预测性（例如，财务预测或预测一个患者在疾病复发前能持续多久）。 

关于统计学的定义，它是一个独立的科学领域，惠及所有其他领域和日常生活。 统计学的独特之处在于其在不确定性面前的决策工具、理解变异和偏差来源，以及最重要的统计思维。 统计思维是一种不同的思考方式，既是侦探式的，又是怀疑的，并涉及对问题的不同看法。 统计学涉及测量改进、实验设计、数据分析、推断以及趋势和证据的解释。

**KG: 决策者在有效使用统计学进行决策时需要了解的最基本的内容是什么？**

**FH:** 始终最重要的问题是理解测量的意义和可靠性，以及理解数据解释与实验设计之间的联系。随着数据量的增加，平均数据分析师对设计的关注变得更加放松，我们因此看到许多数据解释的失败（请参见[https://youtu.be/TGGGDpb04Yc](https://youtu.be/TGGGDpb04Yc)的一个很好的例子）。当没有设计（如随意数据收集）或所用的设计与项目目标不一致（前瞻性与回顾性设计；随机设计与观察性设计等）时，统计分析很少能够提供帮助。现代统计学创始人之一R. A. Fisher的一句名言很好地总结了这个问题：

> “实验结束后咨询统计学家，通常只是要求他进行一次尸检。他也许能说出实验失败的原因。”

关于测量，我看到许多统计学家忘记了“质疑一切”的格言，盲目信任客户选择或计算的测量。例如，精确的连续测量常常被分类，从而导致信息、功效、精确性和普遍性的巨大损失。或者研究人员可能会使用归一化程序得出响应变量，这种情况最好是建模而不是用来创建比率。鉴于良好的设计和适当的测量，统计分析的方法需要基于良好的统计原则，正如我在[http://www.fharrell.com/2017/01/fundamental-principles-of-statistics.html](http://www.fharrell.com/2017/01/fundamental-principles-of-statistics.html)中尝试概述的那样。

然后，结果需要通过估计对客户有用的尺度（例如，相对治疗效果、预测风险、预期寿命、贝叶斯后验概率）来使其具有可操作性。一个非常常见的问题是，随着机器学习的兴起（见下文），分类与预测的错误使用；分类对客户的假设过多，并且没有提供灰色区域。我在[http://www.fharrell.com/2017/01/classification-vs-prediction.html](http://www.fharrell.com/2017/01/classification-vs-prediction.html)中详细讨论了这一点。

**KG: 统计学的主要领域或分支有哪些？它们有何不同？**

**FH:** 有三种思想流派：

最常用的是**频率学派统计学**，它涉及估计、显著性检验、置信区间和假设检验，基于对研究的假想重复（抽样分布）。由于需要考虑抽样分布和“样本空间”，频率学派方法可能变得相当复杂，并且需要针对每个抽样方案定制解决方案，例如，当进行序列检验并希望在有足够证据证明某效应存在时停止。频率学派结果的统计陈述已被证明对于非统计学家（以及一些统计学家）而言非常难以解释。

接下来是**贝叶斯**统计学派，它实际上比频率学派早了一个多世纪，源于贝叶斯和拉普拉斯的工作。直到强大的计算机变得对统计学家可用之前，它的使用并不广泛。贝叶斯方法要求指定一个锚点/起始点（“先验分布”），这可能需要很多思考，但也可以仅仅指定对数据应用的怀疑程度。进行这一步的好处很大——无需为复杂的设计/抽样方案创建一次性解决方案，贝叶斯方法提供了直接可操作的概率——例如效果是正面的概率，相对于频率学派的p值，后者是关于效果是否正面的断言的概率，而实际上这些效果可能是零。

最后是**似然**学派，它类似于贝叶斯学派，但没有先验分布。像贝叶斯方法一样，似然方法避免了样本空间，因此更为简洁，但它们主要提供相对证据而非绝对证据，并且不处理包含大量参数的模型。除了这三种学派之外，每个学派内部还有不同的工具，特别是在频率学派内——如自助法、非参数方法和缺失数据插补方法。

**KG: 从你的观点来看，机器学习和数据科学是否与统计学不同？**

**FH:** 是的。简单来说，我会说数据科学是应用统计学 + 计算机科学，它更注重估计和预测，而不是统计理论和假设检验。机器学习是一种极其实证的方法来进行统计建模，它不太关心是否能够分离变量的影响。许多机器学习从业者在统计学方面有很好的基础，但也有很多没有。后者似乎不断地重复过去已经被统计学证明无效的方法。

一位优秀统计学家的标志是知道如何量化估计和预测的准确性。后者的机器学习从业者从未学习过预测准确性（包括正确的概率准确性评分）背后的原则和理论，他们不断开发“分类器”，而问题需要的是预测或最佳贝叶斯决策。这些分类器存在许多问题，包括未能推广到新样本中具有不同结果频率的情况，详细讨论请参见[http://www.fharrell.com/2017/03/damage-caused-by-classification.html](http://www.fharrell.com/2017/03/damage-caused-by-classification.html)。

> 机器学习从业者似乎也对**特征选择**情有独钟，却没有意识到，强行折磨数据以试图确定“重要”预测因子，与从所有预测因子中获得最大信息的目标相悖，后者与最大化预测区分度有很大关系。

**KG：你质疑了许多常见的统计实践，并且在批评中经常非常直言不讳。实践者最常犯的错误是什么？**

**FH：** 首先，我从算术开始。令人惊讶的是，许多人不知道，除非比率表示的是互斥事件的比例，否则不应将比率相加。一般来说，比率是相乘的。我经常看到论文要么分析比率却没有取对数，要么分析从基线的百分比变化，却没有注意到数学运算不成立。例如，假设一个受试者的初始值为1.0，增加到2.0。这是100%的增加。然后考虑一个受试者初始值为2.0，减少到1.0。这是50%的减少。100%和-50%的平均值是+25%，而实际上这两个值应该抵消，得到的平均值是0%。百分比变化是一个不对称的度量，除非在特殊限制下，否则不能用于统计分析。

关于不当添加比率的问题，许多医学论文在应添加这些比率的对数时却添加了比值比或危险比。一个简单的例子说明了原因。假设在开发风险评分时，有两个风险因素在逻辑回归模型中的回归系数分别为1和-1。这两个比值比为2.72和0.37。直接将这些比值比相加会假装这两个风险因素都是有害的，而实际上第二个风险因素是保护性的。基线变化有很多其他问题，如我的博客所述。我们应该将原始响应变量作为因变量进行分析，并对原始基线变量进行协变量调整。统计学家和其他数据分析师需要仔细审视他们合作伙伴使用的数学方法！

说到统计模型，有许多常见的陷阱，包括

+   试图在样本量允许的情况下学习过多内容（例如，使用特征选择或估计过多参数），导致过拟合/过度解释；

+   做出不太可能真实的假设，如非线性；

+   尝试多种转换并假装最终的转换是预先指定的，破坏了结果的统计推断性质（而不是使用样条函数）；

+   使用不适当的准确性评分；

+   在非大信号:噪声的情况下使用分类而非预测；

+   尝试对因变量进行不同的转换或受该变量中的离群值影响，而不是使用稳健的半参数有序回归模型。

然后是逐步回归——别让我说下去……

**二分法**是对数据的最大犯罪之一。这是信息丧失、随意的，并且假设自然界中不存在的非连续关系。对连续的因变量或自变量进行分类几乎从来不是一个好主意。

我们每天还会看到许多其他问题，包括使用无效的图形，如饼图和条形图。

**KG: 最后，统计学正迅速发展，新方法不断出现。你认为统计学在10-15年后会是什么样的？**

**FH:** 哎呀——又一个难题！我确信我们会看到贝叶斯模型被更频繁地使用，因为它们提供了我们真正需要的输出（前向时间、前向信息流概率），并允许我们正式地融入外部信息，即使这些信息，比如某种治疗的比值比不可能大于10。我们还会看到更多可解释、灵活和稳健的预测方法，更直观和强大的统计软件和图形，以及总体上更多不假设正态性或依赖大样本理论的统计方法。

**谢谢你，Frank！**

**[Kevin Gray](https://www.linkedin.com/in/cannongray)** 是 [Cannon Gray](http://cannongray.com/home) 的总裁，该公司是一家市场科学和分析咨询公司。

[**Frank Harrell**](http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell) 是范德堡大学医学院生物统计学教授和生物统计学系创始主任。他还担任FDA药物评估与研究中心生物统计办公室的专家统计顾问。他著有众多出版物，包括具有影响力的书籍《回归建模策略》以及R包rms和Hmisc。他可以通过他的博客[**统计思维**](http://www.fharrell.com/)进行关注。

[原文](https://www.linkedin.com/pulse/vital-statistics-you-never-learnedbecause-theyre-taught-kevin-gray)。经许可转载。

*本文首次发表于2017年8月的Greenbook。*

**相关内容：**

+   [因果关系：为什么在什么之下](/2017/08/causation-why-beneath-what.html)

+   [统计建模：入门](/2017/03/statistical-modeling-primer.html)

+   [时间序列分析：入门](/2017/01/time-series-analysis-primer.html)

### 更多相关内容

+   [大型语言模型是什么，如何运作？](https://www.kdnuggets.com/2023/05/large-language-models-work.html)

+   [基础模型是什么，如何运作？](https://www.kdnuggets.com/2023/05/foundation-models-work.html)

+   [向量数据库是什么，为什么它们对LLMs重要？](https://www.kdnuggets.com/2023/06/vector-databases-important-llms.html)

+   [你的特征重要吗？这并不意味着它们是好的](https://www.kdnuggets.com/your-features-are-important-it-doesnt-mean-they-are-good)

+   [我从使用ChatGPT进行数据科学中学到了什么](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)

+   [机器学习的统计学：成为认证专家所需了解的知识](https://www.kdnuggets.com/2024/03/sas-statistics-machine-learning-need-know-become-certified-expert)
