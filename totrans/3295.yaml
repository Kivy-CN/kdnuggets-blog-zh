- en: How Feature Engineering Can Help You Do Well in a Kaggle Competition – Part
    I
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程如何帮助你在Kaggle比赛中表现出色——第一部分
- en: 原文：[https://www.kdnuggets.com/2017/06/feature-engineering-help-kaggle-competition-1.html](https://www.kdnuggets.com/2017/06/feature-engineering-help-kaggle-competition-1.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/06/feature-engineering-help-kaggle-competition-1.html](https://www.kdnuggets.com/2017/06/feature-engineering-help-kaggle-competition-1.html)
- en: '**By Gabriel Moreira, CI&T.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Gabriel Moreira, CI&T。**'
- en: '![Header](../Images/958dca69141a213fb3f1a688fa29066b.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![标题](../Images/958dca69141a213fb3f1a688fa29066b.png)'
- en: It is midnight on January 18, 2017, and the [Outbrain Click Prediction machine
    learning competition](https://www.kaggle.com/c/outbrain-click-prediction) has
    just finished. It has been three and a half months of working late. As I scroll
    through the leaderboard page, I found my name in the 19th position, which was
    the top 2% from nearly 1,000 competitors. Not bad for the first Kaggle competition
    I had decided to put a real effort in!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是2017年1月18日午夜，[Outbrain点击预测机器学习比赛](https://www.kaggle.com/c/outbrain-click-prediction)刚刚结束。经过三个月半的熬夜工作，当我浏览排行榜页面时，发现我的名字排在第19位，这在近1000名竞争者中排名前2%。对于我决定全力以赴的第一次Kaggle比赛，这个成绩还不错！
- en: '![](../Images/889ea6594cecd18b937a52bf46ccf7f0.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/889ea6594cecd18b937a52bf46ccf7f0.png)'
- en: One of the reasons why I managed to score well was the fact that Google Cloud
    Platform (GCP) made my life easier and I could focus on the data. Now I will take
    you through my journey!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我取得良好成绩的原因之一是Google Cloud Platform (GCP) 让我的工作变得更简单，我能够专注于数据。现在我将带你了解我的经历！
- en: The challenge
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 挑战
- en: The Kaggle competition was sponsored by [Outbrain](http://www.outbrain.com/),
    which pairs relevant content and readers with 250 billion personalized recommendations
    every month across several thousand sites. In that competition, ‘Kagglers’ were
    challenged to predict on which ads and other forms of sponsored content its global
    base of users would click.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这次Kaggle比赛由[Outbrain](http://www.outbrain.com/)赞助，该公司每月在数千个网站上提供2500亿个个性化推荐，匹配相关内容和读者。在这次比赛中，“Kagglers”被挑战预测全球用户会点击哪些广告和其他形式的赞助内容。
- en: Outbrain maintains a network of publishers and advertisers. In the image below,
    for example, paid content (ads) are presented to a user in a CNN (publisher) news
    page.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Outbrain维持着一个发布者和广告商网络。例如，在下图中，付费内容（广告）展示给用户时会出现在CNN（发布者）的新闻页面上。
- en: '![](../Images/2017d974e38726964e37718f82b41e7a.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2017d974e38726964e37718f82b41e7a.png)'
- en: From [Outbrain Click Prediction competition](https://www.kaggle.com/c/outbrain-click-prediction/data).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[Outbrain点击预测比赛](https://www.kaggle.com/c/outbrain-click-prediction/data)。
- en: In this competition, competitors were asked to accurately rank recommendations
    by predicted likelihood of being clicked. CTR (Click-Through Rate) prediction
    is very relevant for industries like e-commerce and advertisement, as tiny improvements
    in user conversion may lead to significant increases in profits, while providing
    a better user experience.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次比赛中，参赛者被要求根据预测点击概率准确排名推荐内容。CTR（点击率）预测对电子商务和广告等行业非常重要，因为用户转化的小改进可能会显著增加利润，同时提供更好的用户体验。
- en: Dataset and infrastructure
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集和基础设施
- en: 'One of the competition challenges was to handle the massive dataset: 2 billion
    page views and roughly 17 million click records from 700 million unique users,
    across 560 sites. It contained a sample of users’ pageviews and clicks, as observed
    on multiple publishing sites in the United States between June 14, 2016, and June
    28, 2016.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 比赛中的一个挑战是处理巨大的数据集：20亿页面浏览量和大约1700万点击记录，来自7亿独立用户，涵盖560个网站。数据集包含了2016年6月14日至2016年6月28日之间在美国多个发布网站上观察到的用户页面浏览和点击样本。
- en: Considering it was a large relational database, with some tables not fitting
    ‘in memory’, [Apache Spark](http://spark.apache.org/) was very suitable for data
    exploration and fast distributed pre-processing. [Google Cloud Platform (GCP)](https://cloud.google.com/)
    provided the main components I needed for storage and distributed processing.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这是一个大型关系数据库，其中一些表无法“在内存中”处理，[Apache Spark](http://spark.apache.org/) 非常适合数据探索和快速分布式预处理。[Google
    Cloud Platform (GCP)](https://cloud.google.com/) 提供了我所需的主要存储和分布式处理组件。
- en: It was easy to deploy a Spark cluster using [Google Cloud Dataproc](https://cloud.google.com/dataproc/)
    managed service. I found out that a cluster with 1 master and 8 worker nodes of
    “n1-highmem-4” instance type (~4 CPU cores and 16 GB RAM) was able to process
    all competition data in about one hour, including joining large tables, transforming
    features and storing vectors.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Google Cloud Dataproc](https://cloud.google.com/dataproc/)托管服务部署Spark集群非常简单。我发现一个由1个主节点和8个“n1-highmem-4”实例类型的工作节点（约4个CPU核心和16GB
    RAM）组成的集群能够在约一个小时内处理所有竞赛数据，包括连接大表、转换特征和存储向量。
- en: My main development environment was Jupyter notebooks, a very productive Python
    interface. [This GCP tutorial](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)
    describes how to easily set up Jupyter in Dataproc master node, making PySpark
    libraries available for usage.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我的主要开发环境是Jupyter notebooks，这是一个非常高效的Python接口。[这个GCP教程](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)描述了如何在Dataproc主节点上轻松设置Jupyter，使PySpark库可用。
- en: Dataproc Spark clusters use [Google Cloud Storage](https://cloud.google.com/storage/)
    (GCS) as distributed file system instead of default HDFS. As a managed storage,
    it makes it easy to transfer and store large files between instances. Spark jobs
    are able to use data directly from GCS for distributed processing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Dataproc Spark集群使用[Google Cloud Storage](https://cloud.google.com/storage/)（GCS）作为分布式文件系统，而不是默认的HDFS。作为一个托管存储，它使得在实例之间传输和存储大文件变得容易。Spark作业能够直接从GCS使用数据进行分布式处理。
- en: I also employed some machine learning frameworks (FTRL, FFM, GBM, etc.), which
    worked on parallelized — not distributed — computation, requiring high CPU cores
    and RAM memory for large datasets. A ‘n1-highmem-32’ instance (32 CPUs and 256
    RAM) deployed on [Google Compute Engine (GCE)](https://cloud.google.com/compute/)
    made it possible to run jobs in less than one hour. As their processing was very
    I/O intensive, I attached a SSD disk to the instance to avoid bottlenecks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我还使用了一些机器学习框架（FTRL、FFM、GBM等），这些框架在并行化计算上运行，而非分布式计算，需要高CPU核心和RAM内存来处理大数据集。一个部署在[Google
    Compute Engine (GCE)](https://cloud.google.com/compute/)上的‘n1-highmem-32’实例（32个CPU和256GB
    RAM）使得作业可以在不到一小时内完成。由于处理非常依赖I/O，我为实例附加了一个SSD磁盘以避免瓶颈。
- en: In the [second part](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)
    of this post series, I will talk more about those machine learning models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在[本系列文章的第二部分](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)中，我将进一步讨论这些机器学习模型。
- en: First approach
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一种方法
- en: The [competition evaluation metric](https://www.kaggle.com/c/outbrain-click-prediction/details/evaluation)
    was MAP@12 (Mean Average Precision at 12), which measures the quality of ad ranking.
    In other words, this metric assesses whether the actual clicked ad was well ranked
    by the model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[竞赛评估指标](https://www.kaggle.com/c/outbrain-click-prediction/details/evaluation)是MAP@12（12的平均精度均值），它衡量广告排名的质量。换句话说，这一指标评估实际点击的广告是否被模型良好排名。'
- en: 'It’s common sense that the ads’ average popularity may be a good predictor
    of new clicks. The main idea was then to rank ads displayed for users by their
    decreasing CTR (*#clicks / #views*).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '常识表明，广告的平均受欢迎程度可能是新点击的良好预测指标。主要思想是根据广告的CTR（*#clicks / #views*）对展示给用户的广告进行排名。'
- en: In the following Python snippets, I show how to compute ads CTR based on train
    set (click_trains.csv) using PySpark. This CSV file has more than 87 million rows
    and was stored on GCS. The full script runs in less than 30 seconds in a Dataproc
    Spark cluster with 8 worker nodes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的Python代码片段中，我展示了如何使用PySpark计算基于训练集（click_trains.csv）的广告CTR。这个CSV文件包含超过8700万行，并存储在GCS上。完整脚本在一个有8个工作节点的Dataproc
    Spark集群中运行不到30秒。
- en: Loads training data (click_train.csv) into a Spark DataFrame and get rows count.Get
    count of distinct ads.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练数据（click_train.csv）加载到Spark DataFrame中，并获取行数。获取不同广告的计数。
- en: 'In the next snippet, I define a new DataFrame grouping rows by ad_id and aggregating
    the sum of clicks and count of views. The processing of the CTR is made by a UDF
    (User Defined Function) named *ctr_udf*. The snippet output is a table with a
    sample of 10 ad_ids and their respective #clicks, #views e CTR.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个代码片段中，我定义了一个新的DataFrame，通过ad_id分组行，并汇总点击总数和查看次数。CTR的处理是通过一个名为*ctr_udf*的UDF（用户定义函数）完成的。代码片段的输出是一个包含10个ad_ids及其各自#clicks、#views和CTR的样本表格。
- en: Calculating average CTR for ads.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 计算广告的平均CTR。
- en: To increase the CTR confidence, we can consider only ads with more than five
    views. With the *collectAsMap()* action, the distributed collection is converted
    to an in-memory lookup dictionary, whose key is the ad_id and the value is the
    corresponding average CTR.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高CTR的信心，我们可以仅考虑浏览次数超过五次的广告。通过*collectAsMap()*操作，分布式集合被转换为内存中的查找字典，其中键是ad_id，值是相应的平均CTR。
- en: This was the submitted baseline by most of the competitors and, even without
    any machine learning algorithm, would give you MAP@12 of **0.637**. As a reference,
    the official baseline competition was based on ads ranking by their ids (random-like
    approach), for which MAP@12 was **0.485**. Thus, this initial approach actually
    does a nice job for click prediction.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是大多数竞争者提交的基准，即使没有任何机器学习算法，也能给出MAP@12为**0.637**。作为参考，官方基准比赛基于按ID（随机类似方法）排序的广告，其MAP@12为**0.485**。因此，这种初始方法在点击预测中表现不错。
- en: Data Analysis
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据分析
- en: As always, before applying any machine learning technique, it is very important
    to analyze the data and to formulate hypotheses about which features and algorithms
    would be useful to tackle the problem. I implemented an EDA (Exploratory Data
    Analysis) to unveil the largest dataset (page_views.csv ~ 100 GB) using PySpark.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，在应用任何机器学习技术之前，分析数据和提出有关哪些特征和算法对解决问题有用的假设非常重要。我使用PySpark实施了EDA（探索性数据分析）来揭示最大数据集（page_views.csv
    ~ 100 GB）。
- en: My [EDA Kernel](https://www.kaggle.com/gspmoreira/outbrain-click-prediction/unveiling-page-views-csv-with-pyspark),
    showing how to use Python, Spark SQL, and Jupyter notebooks in Dataproc to analyze
    the competition largest dataset, was shared with other competitors and turned
    out to be the second most-voted contribution (gold medal). Based on my Kernel
    [comments](https://www.kaggle.com/gspmoreira/outbrain-click-prediction/unveiling-page-views-csv-with-pyspark),
    it appears that many Kagglers are considering trying Google Dataproc and Spark
    for machine learning competitions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我的[EDA内核](https://www.kaggle.com/gspmoreira/outbrain-click-prediction/unveiling-page-views-csv-with-pyspark)，展示了如何使用Python、Spark
    SQL和Jupyter notebooks在Dataproc中分析比赛的最大数据集，与其他竞争者共享，并成为第二多票选贡献（奖牌）。根据我的Kernel [评论](https://www.kaggle.com/gspmoreira/outbrain-click-prediction/unveiling-page-views-csv-with-pyspark)，许多Kagglers正在考虑尝试Google
    Dataproc和Spark进行机器学习比赛。
- en: My analysis helped me to figure out how to extract value from the dataset, by
    joining it with training and test data (events.csv). For example, in the cumulative
    chart shown below, we can see that 65% of the users have only one page view, 77%,
    have at most two views and 89% of the users have at most five views.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我的分析帮助我弄清楚如何从数据集中提取价值，通过将其与训练数据和测试数据（events.csv）结合。例如，在下面显示的累计图表中，我们可以看到65%的用户只有一个页面浏览记录，77%的用户最多有两个浏览记录，89%的用户最多有五个浏览记录。
- en: '![](../Images/b821f026d86c4d98ddde68f3b835a9dd.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b821f026d86c4d98ddde68f3b835a9dd.png)'
- en: Cumulative percentage of users with at most N page views.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 用户最多N页浏览的累计百分比。
- en: This is a typical ‘cold-start’ scenario where we know almost nothing about most
    users and need to predict which recommended content they will click on.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的‘冷启动’场景，我们几乎对大多数用户一无所知，需要预测他们会点击哪些推荐内容。
- en: In general, traditional recommender system techniques like Collaborative Filtering
    and Content-Based Filtering will fail in this scenario. My strategy was then to
    employ machine learning algorithms that are able to leverage contextual information
    about the users’ events and recommended sponsored content.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，传统的推荐系统技术如协同过滤和基于内容的过滤在这种情况下会失败。因此，我的策略是采用能够利用用户事件和推荐的赞助内容的上下文信息的机器学习算法。
- en: Feature Engineering
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征工程
- en: Feature engineering refers to the essential step of selecting or creating the
    right features to be used in a machine learning model. Usually, it may consume
    up to 80% of the total effort, depending on the data complexity.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是选择或创建用于机器学习模型的正确特征的关键步骤。通常，这一步骤可能占总工作量的80%，具体取决于数据的复杂性。
- en: In the following picture, I show the competition original data model, with features
    colored by their data type.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我展示了比赛的原始数据模型，其中特征按数据类型着色。
- en: '![](../Images/e54a298f669725bc5b88d1209febaeab.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e54a298f669725bc5b88d1209febaeab.png)'
- en: Outbrain Click Prediction large relational database.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Outbrain点击预测大型关系数据库。
- en: All categorical fields were originally represented as integer numbers. Depending
    on the machine learning algorithm, ids represented as ordinal values may teach
    the model that one category has a greater relevance than the other. For example,
    if Argentina id is 1 and Brazil is 2, an algorithm could infer that Brazil is
    twice as more representative than Argentina. To deal with such issue, it’s common
    to use techniques like [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot)(OHE)
    where each categorical field is transformed into a sparse vector. In the sparse
    vector all positions have zero values, except the one corresponding to the id
    value.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 所有类别字段最初都是以整数形式表示的。根据机器学习算法的不同，将id表示为序数值可能会使模型认为一个类别比另一个类别更重要。例如，如果阿根廷的id是1，而巴西是2，则算法可能会推断巴西的代表性是阿根廷的两倍。为了解决这个问题，通常使用[独热编码](https://en.wikipedia.org/wiki/One-hot)(OHE)等技术，其中每个类别字段被转换为一个稀疏向量。在稀疏向量中，所有位置的值都为零，只有与id值对应的位置有非零值。
- en: Another popular technique for categorical features with large number of unique
    values is [Feature Hashing](https://en.wikipedia.org/wiki/Feature_hashing), which
    maps categories to a fixed length vector using hashing functions. This approach
    provides lower sparsity and higher compression compared to OHE and deals nicely
    with new and rare categorical values (eg. previously unseen user-agents). It also
    may cause some collisions when mapping more than one feature to the same vector
    position, but machine learning algorithms are usually robust enough to deal with
    these conflicts. I used both techniques in my approach.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种适用于具有大量唯一值的类别特征的流行技术是[特征哈希](https://en.wikipedia.org/wiki/Feature_hashing)，它通过哈希函数将类别映射到固定长度的向量。与OHE相比，这种方法提供了更低的稀疏性和更高的压缩率，并且可以很好地处理新的和稀有的类别值（例如，之前未见过的用户代理）。它在将多个特征映射到相同向量位置时也可能导致一些冲突，但机器学习算法通常足够健壮，可以处理这些冲突。我在我的方法中使用了这两种技术。
- en: I also used ‘B[inning’](https://en.wikipedia.org/wiki/Data_binning) for the
    numerical scalar features. Some features are very noisy, and we'd better reduce
    the effects of minor observation errors or differences with this transformation.
    For example, I ‘binned’ the event ‘hour’ in periods like morning, midday, afternoon,
    evening, etc., because my hypotheses is that user behavior wouldn’t be too different
    if observed at 10am or 11am, for instance.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我还使用了‘[分箱](https://en.wikipedia.org/wiki/Data_binning)’方法来处理数值标量特征。一些特征非常嘈杂，我们最好通过这种变换来减少小观察误差或差异的影响。例如，我将事件‘小时’‘分箱’为早晨、中午、下午、晚上等，因为我的假设是，如果在早上10点或11点观察用户行为，用户行为不会有太大不同。
- en: 'For long-tail distributed variables, like *user_views_count*, most users had
    only one page view logged and very few users with high number of views were present.
    Applying transformations like log(1 + #views) was useful to smooth out the distribution.
    A user that has 1,000 page views might not be very different from a user with
    500 views, they both are equally outliers in this context.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '对于长尾分布变量，如*user_views_count*，大多数用户只有一个页面浏览记录，而高浏览量的用户则很少出现。应用诸如log(1 + #views)的变换对平滑分布是有用的。一个有1,000次页面浏览的用户可能与一个有500次浏览的用户没有很大区别，在这种情况下，他们都是同样的异常值。'
- en: '[Standardization and normalization](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)
    are also important for most machine learning algorithms using optimization techniques
    like gradient descent. In general, only Decision Trees based models are robust
    to deal with raw numeric features in different scales and variances.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[标准化和归一化](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)对大多数使用梯度下降等优化技术的机器学习算法也很重要。一般来说，只有基于决策树的模型能够处理具有不同尺度和方差的原始数值特征。'
- en: A more detailed presentation of the main Feature Engineering techniques I have
    used can be found in this [slides](https://www.slideshare.net/gabrielspmoreira/feature-engineering-getting-most-out-of-data-for-predictive-models).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我所使用的主要特征工程技术的详细介绍可以在这个[幻灯片](https://www.slideshare.net/gabrielspmoreira/feature-engineering-getting-most-out-of-data-for-predictive-models)中找到。
- en: Based on insights and hypotheses I gleaned from my EDA, I managed to create
    and transform features for my machine learning models, besides the original features
    provided in the [competition data](https://www.kaggle.com/c/outbrain-click-prediction/data).
    Here it follows some of those features.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基于从我的EDA中获得的见解和假设，除了在[比赛数据](https://www.kaggle.com/c/outbrain-click-prediction/data)中提供的原始特征外，我还成功创建并转换了用于我的机器学习模型的特征。以下是其中一些特征。
- en: '***User profiles***'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '***用户配置文件***'
- en: '**user_has_already_viewed_doc -** For each content recommended to the user,
    verify whether the user had previously visited that pages.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_has_already_viewed_doc -** 对于推荐给用户的每个内容，验证用户是否之前访问过这些页面。'
- en: '**user_views_count -** Do eager readers behave differently from other users?
    Let’s add this feature and let machine learning models guess that.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_views_count -** 热衷的读者与其他用户行为有何不同？让我们添加这个特征，让机器学习模型来预测。'
- en: '**user_views_categories, user_views_topics, user_views_entities -** User profile
    vectors based on categories, topics and entities of documents that users have
    previously viewed (weighted by confidence and TF-IDF), to model users preferences
    in a Content-Based Filtering approach.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_views_categories, user_views_topics, user_views_entities -** 基于用户之前查看的文档的类别、话题和实体的用户画像向量（按置信度和
    TF-IDF 加权），以在基于内容的过滤方法中建模用户偏好。'
- en: '**user_avg_views_of_distinct_docs -** Ratio between*(#user_distinct_docs_views
    / #user_views)*, indicating how often users read previously visited pages again.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_avg_views_of_distinct_docs -** *(#用户独特文档浏览 / #用户浏览)* 的比率，指示用户重新阅读之前访问的页面的频率。'
- en: '***Ads and Documents***'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '***广告与文档***'
- en: '**doc_ad_days_since_published, doc_event_days_since_published -** Days elapsed
    since the ad document was published in a given user visit. The general assumption
    is that new content is more relevant to users. But if you are reading an old post,
    you might be interested in other old posts.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**doc_ad_days_since_published, doc_event_days_since_published -** 从广告文档发布到用户访问的天数。一般假设是新内容对用户更相关。但如果你正在阅读一篇旧帖子，你可能对其他旧帖子感兴趣。'
- en: '**doc_avg_views_by_distinct_users_cf -** Average page views of the ad document
    by distinct users. Is this a webpage people usually return to?'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**doc_avg_views_by_distinct_users_cf -** 不同用户对广告文档的平均页面浏览量。这是一个人们通常会回到的网页吗？'
- en: '**ad_views_count, doc_views_count -** How popular is a document or ad?'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ad_views_count, doc_views_count -** 文档或广告的受欢迎程度如何？'
- en: '***Events***'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '***事件***'
- en: '**event_local_hour (binned), event_weekend** — Event timestamps were in UTC-4,
    so I processed event geolocation to get timezones and adjust for users'' local
    time. They were binned in periods like morning, afternoon, midday, evening, night.
    A flag indicating whether it was a weekend was also included. The assumption here
    is that time influences the kind of content users will read.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**event_local_hour (binned), event_weekend** — 事件时间戳为 UTC-4，因此我处理了事件地理位置以获取时区并调整用户的本地时间。它们被分为早晨、下午、正午、傍晚、夜晚等时间段。还包括了一个标志，指示是否为周末。这里的假设是时间会影响用户阅读的内容类型。'
- en: '**event_country, event_country_state -** The field *event_geolocation* was
    parsed to extract the user’s country and state in a page visit.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**event_country, event_country_state -** 字段 *event_geolocation* 被解析以提取用户在页面访问中的国家和州。'
- en: '**ad_id, doc_event_id, doc_ad_id, ad_advertiser, …** — All of the original
    categorical fields were One-Hot Encoded to be used by the models, generating about
    126,000 features.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ad_id, doc_event_id, doc_ad_id, ad_advertiser, …** — 所有原始的分类字段都进行了独热编码，以便被模型使用，生成了大约
    126,000 个特征。'
- en: '***Average CTR***'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '***平均点击率***'
- en: '**avg_ctr_ad_id, avg_ctr_publisher_id, avg_ctr_advertiser_id, avg_ctr_campain_id,
    avg_ctr_entity_id_country … -** Average CTR *(#clicks / #views)* given some categorical
    combinations and CTR confidence (details on [Part II](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)
    post). Eg. P(click | category01, category02).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**avg_ctr_ad_id, avg_ctr_publisher_id, avg_ctr_advertiser_id, avg_ctr_campain_id,
    avg_ctr_entity_id_country … -** 平均点击率 *(#点击 / #浏览)*，针对某些类别组合和点击率置信度（详细信息见 [第二部分](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)
    文章）。例如：P(点击 | 类别01, 类别02)。'
- en: '***Content-Based Similarities***'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '***基于内容的相似性***'
- en: These features used [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) technique
    to build profile vectors for the users and landing pages, modeling user preferences
    and context respectively. The profiles were compared to candidate ad documents
    using [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity), which
    is a very popular Information Retrieval based on the angle between of two vectors,
    ignoring their magnitude.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征使用了 [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 技术来构建用户和着陆页面的画像向量，分别建模用户偏好和上下文。通过使用
    [余弦相似度](https://en.wikipedia.org/wiki/Cosine_similarity) 比较这些画像与候选广告文档的相似度，这是一种基于信息检索的非常流行的方法，计算两个向量之间的角度，忽略它们的大小。
- en: '**user_doc_ad_sim_categories, user_doc_ad_sim_topics, user_doc_ad_sim_entities
    -** Cosine similarity between user profile and ad document profile vectors (TF-IDF).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**user_doc_ad_sim_categories, user_doc_ad_sim_topics, user_doc_ad_sim_entities
    -** 用户画像与广告文档画像向量之间的余弦相似度（TF-IDF）。'
- en: '**doc_event_doc_ad_sim_categories, doc_event_doc_ad_sim_topics, doc_event_doc_ad_sim_entities
    -** Cosine similarity between event document (landing page context) and ad document
    profile vectors (TF-IDF).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**doc_event_doc_ad_sim_categories, doc_event_doc_ad_sim_topics, doc_event_doc_ad_sim_entities
    -** 事件文档（登录页面上下文）与广告文档配置文件向量（TF-IDF）之间的余弦相似度。'
- en: We have generated features based on some of our hypotheses about aspects that
    might influence users’ decisions on which sponsored content to click on. And the
    data is now ready for some machine learning models!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据对可能影响用户点击赞助内容的假设生成了特征。数据现在已准备好用于一些机器学习模型！
- en: Next up…
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步…
- en: In the [Part II](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)
    of this post series, I will present the cross-validation strategy, the machine
    learning models implemented and the ‘Ensemble’ techniques employed to climb up
    to the Top 2% of the competition leaderboard.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本系列文章的 [第二部分](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-ii-3645d92282b8)，我将介绍交叉验证策略、实现的机器学习模型以及采用的“集成”技术，以期在竞赛排行榜上晋升到前2%。
- en: Stay tuned!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 敬请关注！
- en: '**Bio: [Gabriel Moreira](https://about.me/gspmoreira)** is a scientist passionate
    about solving problems with data. He is a Doctoral student at Instituto Tecnológico
    de Aeronáutica - ITA, researching on Recommender Systems and Deep Learning. Currently,
    he is [Lead Data Scientist at CI&T](https://medium.com/unstructured), leading
    the team in the solution of customer''s challenging problems using machine learning
    on big and unstructured data.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[加布里埃尔·莫雷拉](https://about.me/gspmoreira)** 是一位热衷于利用数据解决问题的科学家。他是 Instituto
    Tecnológico de Aeronáutica - ITA 的博士生，专注于推荐系统和深度学习的研究。目前，他是 [CI&T 的首席数据科学家](https://medium.com/unstructured)，带领团队利用机器学习在大规模和非结构化数据上解决客户的挑战性问题。'
- en: '[Original](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-i-9cc9a883514d).
    Reposted with permission.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://medium.com/unstructured/how-feature-engineering-can-help-you-do-well-in-a-kaggle-competition-part-i-9cc9a883514d)。经许可转载。'
- en: '**Related:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to Rank 10% in Your First Kaggle Competition](/2016/11/rank-ten-precent-first-kaggle-competition.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在第一次 Kaggle 竞赛中排名前 10%](/2016/11/rank-ten-precent-first-kaggle-competition.html)'
- en: '[In Deep Learning, Architecture Engineering is the New Feature Engineering](/2016/07/deep-learning-architecture-engineering-feature-engineering.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在深度学习中，架构工程是新的特征工程](/2016/07/deep-learning-architecture-engineering-feature-engineering.html)'
- en: '[Machine Learning Crash Course: Part 1](/2017/05/machine-learning-crash-course-part-1.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习速成课程：第一部分](/2017/05/machine-learning-crash-course-part-1.html)'
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 需求'
- en: '* * *'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Feature Store Summit 2022: A free conference on Feature Engineering](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Feature Store Summit 2022: 一场关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)'
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可以帮助你解决实际问题的数据科学项目](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
- en: '[5 Rare Data Science Skills That Can Help You Get Employed](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 种稀有的数据科学技能，可以帮助你找到工作](https://www.kdnuggets.com/5-rare-data-science-skills-that-can-help-you-get-employed)'
- en: '[How Generative AI Can Help You Improve Your Data Visualization Charts](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成式 AI 如何帮助你改善数据可视化图表](https://www.kdnuggets.com/how-generative-ai-can-help-you-improve-your-data-visualization-charts)'
- en: '[Free Python Resources That Can Help You Become a Pro](https://www.kdnuggets.com/free-python-resources-that-can-help-you-become-a-pro)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可以帮助你成为专家的免费 Python 资源](https://www.kdnuggets.com/free-python-resources-that-can-help-you-become-a-pro)'
- en: '[How a Level System can Help Forecast AI Costs](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[等级系统如何帮助预测 AI 成本](https://www.kdnuggets.com/2022/03/level-system-help-forecast-ai-costs.html)'
