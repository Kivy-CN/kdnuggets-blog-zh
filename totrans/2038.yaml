- en: Introducing dbt, the ETL and ELT Disrupter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/03/dbt-etl-elt-disrupter.html](https://www.kdnuggets.com/2021/03/dbt-etl-elt-disrupter.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8218fc5fb0678ac4d3578f6a9337014f.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by Peter H from Pixabay.*'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Every day, petabytes and petabytes of data are collected, operated on, and stored
    for a vast range of analytical purposes all across the world. Without pipelines
    to get this data and use it properly, large scale data science simply wouldn’t
    be possible. Traditionally, one of two processes, dubbed ETL and ELT, are used
    to grab large amounts of data, pick apart the bits that mattered, and then load
    these into a data lake or data store. However, both of these pipelines have their
    drawbacks, and in 2020 — as the world becomes ever more dependent on analytics
    and real-time data — ETL and ELT simply aren’t the sharpest swords anymore.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’m going to compare ETL and ELT, summarizing how each works,
    how they’ve been conventionally used both in the past and today, and why most
    leaders in data science think they’re obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: ELT, ETL, What’s the difference?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../Images/5cf611bb1565d657c9d5ff8ccb337637.png)'
  prefs: []
  type: TYPE_IMG
- en: '*[Image from Census with permission](https://blog.getcensus.com/a-complete-guide-to-revenue-cohort-analysis/).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**ELT** stands for Extract, Load, Transform, while its partner ETL similarly
    signifies Extract, Transform, Load. These three steps are crucial processes in
    any important data transformation. Whether you realize it or not, they’re used
    in millions of applications all across the globe. Every time you purchase an item
    from your nearby grocery store, your transaction, whether it be anonymous or identified,
    will be shuffled down one of these pipelines for financial and marketing analytics.
    Let’s see how ELT stacks up against ETL.'
  prefs: []
  type: TYPE_NORMAL
- en: If we’re collecting data from various sources, such as multiple stores across
    a country, or let’s say, many different instruments at different points on a water
    dam to give a scientific example, we need to gather all this data together, and
    then take only the parts that matter to the analytics we want to create. This
    could be the net sales from each store, and in that case, you’d need to normalize
    and total up all the transactions. Or, in the dam example, it could be all the
    water pressure readings that need to be listed. This is the transform process,
    and it is essential for creating analytics. Specifically, it is what allows us
    to use business intelligence tools like Tableau or Periscope.
  prefs: []
  type: TYPE_NORMAL
- en: When we’re using ELT — that is Extract, Load, Transform — our intention is to
    save our primary machine from performing all these computationally expensive operations
    by doing them on a data server. Instead of using the grocery store’s computer
    to total up the transactions, we send the raw data to a data lake or other storage
    machine, and only then do we enact the transform stage to get the overall profit
    — adding up transactions and subtracting costs, for example.
  prefs: []
  type: TYPE_NORMAL
- en: ELT is great for large amounts of data where we’re just doing simple calculations,
    such as the grocery store example. We can extract the data from all our sources,
    e.g., the card readers, load them into our data storage, and then transform them
    so we can easily conduct analytics.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, you have **ETL**. This works better with the dam example.
    In total, we don’t collect a lot of data necessarily, but there are many different
    kinds of readings, and it’s likely you’ll want to perform lots of calculations
    on it for insightful analytics. Preferably we also want this data in real time
    so that we can prevent any floods! In this case, Extract, Transfer, Load is better
    suited. Instead of sending our raw data to a data storage and then doing our operations,
    we perform them as they are being sent to the data storage, in what is called
    “transformation stages”. This way, we can establish a continuous stream of data
    that is being processed before it is even loaded into the data storage!
  prefs: []
  type: TYPE_NORMAL
- en: These two analogies are good at highlighting the advantages and disadvantages
    of ETL vs ELT. With ELT, it’s great when you have a ton of data, such as hundreds
    of transactions, but you only want to perform some relatively simple operations,
    like calculating profit or mapping sales to time in the day.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, ETL works better for real-time cases where we don’t have tons of
    data, but we do have lots of specialized data that needs to be sorted properly,
    and therefore more calculations are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Tools for ETL and ELT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Luckily for the modern world, we don’t have to do a ton of programming to create
    a streamlined pipeline for our data anymore! There are many ETL and ELT tools
    that allow us to perform these functions, from a wide variety of data sources
    to an extensive range of data warehouses or machines.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the Hevo no-coding data pipeline is popularly used among retailers
    and other physical businesses who want to collect sales data or activity information
    about their stores. But it’s also great for real-time data too, so if you want
    to measure the foot traffic outside your storefront and map that over time, you
    can use Hevo too!
  prefs: []
  type: TYPE_NORMAL
- en: There’s also Fivetran, which is built around pre-built connectors and functionality
    for a “plug and play” experience.
  prefs: []
  type: TYPE_NORMAL
- en: dbt — a better approach!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ELT and ETL might sound like perfectly reasonable methods to use to get data
    from A to B for analytics, but they’re actually both pretty inconvenient on their
    own. With ELT and ETL, you have to know exactly what analytics you want to create
    before loading your data. Luckily, they’re quite trivial with modern tools like [Fivetran](https://blog.getcensus.com/dbt-the-etl-elt-disrupter/fivetran.com),
    Airflow, Stitch, etc., and cloud warehouses like BigQuery, [Snowflake](https://www.snowflake.com/),
    and Redshift.
  prefs: []
  type: TYPE_NORMAL
- en: Even then, the hard part still remains in the transform layer. The transform
    layer is a crucial element in your data pipeline, but if it’s bottlenecking you
    from getting the most relevant insights, then there must be a better way.
  prefs: []
  type: TYPE_NORMAL
- en: With some more advanced pipeline techniques, however, we can increase our options
    and allow us to create many different kinds of analytics without having to resend
    data through the pipeline and keep doing different transformations on it!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77e1a6900ccf94fd42df4107dd0afedc.png)'
  prefs: []
  type: TYPE_IMG
- en: '*[Image from Census with permission](https://blog.getcensus.com/a-complete-guide-to-revenue-cohort-analysis/).*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s called **dbt**, or [Data Build Tool](https://getdbt.com/), and it’s a super
    flexible command line data pipeline tool that allows us to collect and transform
    data for analytics really fast and really easily! There’s no need with dbt to
    completely reprogram your pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: dbt is still built on SQL like conventional databases, but it has additional
    functionality built on top of it using templating engines like jinja. This effectively
    allows you to bring more logic (i.e., loops, functions, etc.) into your SQL to
    access, rearrange and organize your data—kind of like programming your dataset
    but with much more flexibility and options.
  prefs: []
  type: TYPE_NORMAL
- en: With this code, you can then use dbt’s run command to compile the code and run
    it on your SQL data to get exactly the parts you need in the transformations you’re
    looking for. It can also be quickly programmed, tested, and modified without substantial
    waiting times for it to run through all your data, meaning you can create new,
    better versions of your programs on a tight schedule.
  prefs: []
  type: TYPE_NORMAL
- en: dbt does not entirely replace ELT and, but it does allow for significantly more
    flexibility — it super boosts your “T”ransform layer/stage. **With dbt, you can
    aggregate, normalize and sort the data again and again however you like, without
    constantly updating your pipeline and resending.**
  prefs: []
  type: TYPE_NORMAL
- en: dbt isn’t a replacement for ETL and ELT, but these pipeline methods stand-alone
    are becoming obsolete with modern technology taking its place. Whether you follow
    ETL or ELT, one thing for sure is that dbt is such a big improvement for the T(ransform)
    layer in every way that you can think of.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to check out dbt. You can start with the [quick start guide
    here](https://docs.getdbt.com/tutorial/setting-up) and join their super [helpful
    community here](https://community.getdbt.com/). When you start using dbt, you
    will wonder how you did any data modelling work before.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/introducing-dbt-the-etl-elt-disrupter-4351adc34123).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[ETL vs ELT: Considering the Advancement of Data Warehouses](https://www.kdnuggets.com/2018/05/etl-vs-elt-considering-advancement-data-warehouses.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why the Future of ETL Is Not ELT, But EL(T)](https://www.kdnuggets.com/2020/12/future-etl-is-elt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Engineering — the Cousin of Data Science, is Troublesome](https://www.kdnuggets.com/2021/01/data-engineering-troublesome.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[SQL and Data Integration: ETL and ELT](https://www.kdnuggets.com/2023/01/sql-data-integration-etl-elt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ETL vs ELT: Data Integration Showdown](https://www.kdnuggets.com/2022/08/etl-elt-data-integration-showdown.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ETL vs ELT: Which One is Right for Your Data Pipeline?](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Warehousing and ETL Best Practices](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Scalable ETL with SQL + Python](https://www.kdnuggets.com/2022/04/building-scalable-etl-sql-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Does ETL Have to Do with Machine Learning?](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
