["```py\nartifact_path: model\nflavors:\n  python_function:\n    env: conda.yaml\n    loader_module: MLflow.sklearn\n    model_path: model.pkl\n    python_version: 3.8.2\n  sklearn:\n    pickled_model: model.pkl\n    serialization_format: cloudpickle\n    sklearn_version: 0.24.2\nrun_id: 39c46969dc7b4154b8408a8f5d0a97e9\nutc_time_created: '2021-05-29 23:24:21.753565'\n```", "```py\nname: example-decision-tree\nconda_env: conda.yaml\nentry_points:\n  main:\n    parameters:\n      tree_depth: {type: int, default: 2}\n    command: \"python main.py {tree_depth}\"\n```", "```py\n$ mlflow run model/example-decision-tree -P tree_depth=3\n$ mlflow run git@github.com:FernandoLpz/MLflow-example.git -P tree_depth=3\n```", "```py\n$ mlflow server\n```", "```py\nimport MLflow \nremote_server_uri = \"http://127.0.0.1:5000\"\nMLflow.set_tracking_uri(remote_server_uri)\nwith MLflow.start_run():\n   MLflow.log_param(\"test-param\", 1)\n   MLflow.log_metric(\"test-metric\", 2)\n```", "```py\n# For darwin based OS\n$ brew install nginx\n\n# For debian based OS\n$ apt-get install nginx\n\n# For redhat based OS\n$ yum install nginx\n\n```", "```py\nsudo htpasswd -c /usr/local/etc/nginx/.htpasswd MLflow-user\n```", "```py\nserver {\n       listen       8080;\n       server_name  localhost;\n       # charset koi8-r;\n       # access_log  logs/host.access.log  main;\n       location / {\n           root   html;\n           index  index.html index.htm;\n       }\n\n```", "```py\n\nserver {\n       # listen       8080;\n       # server_name  localhost;\n\n       # charset koi8-r;\n\n       # access_log  logs/host.access.log  main;\n\n       location / {\n           proxy_pass http://localhost:5000;\n           auth_basic \"Restricted Content\";\n           auth_basic_user_file /usr/local/etc/nginx/.htpasswd;\n       }\n\n```", "```py\n$ MLflow server --host localhost\n```", "```py\n$ export MLflow_TRACKING_USERNAME=MLflow-user\n$ export MLflow_TRACKING_PASSWORD=MLflow-password\n```", "```py\nimport MLflow\n\n# Define MLflow Server URI\nremote_server_uri = \"http://localhost\"\nMLflow.set_tracking_uri(remote_server_uri)\n\nwith MLflow.start_run():\n   MLflow.log_param(\"test-param\", 2332)\n   MLflow.log_metric(\"test-metric\", 1144)\n```", "```py\nwith MLflow.start_run():\n\n   model = DecisionTreeModel(max_depth=max_depth)\n   model.load_data()\n   model.train()\n   model.evaluate()\n\n   MLflow.log_param(\"tree_depth\", max_depth)\n   MLflow.log_metric(\"precision\", model.precision)\n   MLflow.log_metric(\"recall\", model.recall)\n   MLflow.log_metric(\"accuracy\", model.accuracy)\n\n   # Register the model\n   MLflow.sklearn.log_model(model.tree, \"MyModel-dt\",      registered_model_name=\"Decision Tree\")\n```", "```py\nclient = MLflowClient()\nclient.transition_model_version_stage(\n    name=\"Decision Tree\",\n    version=2,\n    stage=\"Staging\"\n)\n```", "```py\n$ export MLflow_TRACKING_URI=http://localhost\n$ mlflow models serve -m \"models:/MyModel-dt/Production\"\n```", "```py\n$ curl http://localhost/invocations -H 'Content-Type: application/json' -d '{\"inputs\": [[0.39797844703998664, 0.6739875109527594, 0.9455601866618499, 0.8668404460733665, 0.1589125298570211]}'\n[1]%\n\n```"]