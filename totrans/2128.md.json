["```py\n!git clone --depth 1 https://github.com/ggerganov/llama.cpp.git\n```", "```py\n%cd llama.cpp\n\n!make LLAMA_CUBLAS=1\n```", "```py\n!wget https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q2_K.gguf\n```", "```py\nfrom google.colab.output import eval_js\nprint(eval_js(\"google.colab.kernel.proxyPort(6589)\"))\n```", "```py\nhttps://8fx1nbkv1c8-496ff2e9c6d22116-6589-colab.googleusercontent.com/\n```", "```py\n%cd /content/llama.cpp\n\n!./server -m mixtral-8x7b-instruct-v0.1.Q2_K.gguf -ngl 27 -c 2048 --port 6589\n```"]