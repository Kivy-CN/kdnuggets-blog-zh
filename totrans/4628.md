# 使用 K-最近邻算法分类心脏病

> 原文：[https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html](https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html?page=2#comments)

对象分类是各种领域中的一个重要研究和应用领域。在完全了解潜在概率的情况下，贝叶斯决策理论提供了最佳的错误率。在这些信息缺失的情况下，许多算法利用样本之间的距离或相似性进行分类。

这篇文章分为两部分。第一部分，我们将讨论 K-NN 机器学习算法，第二部分，我们将实际应用 K-NN 并分类心脏病患者。

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT 工作

* * *

**内容表**

1.  什么是 K-NN 算法？

1.  K-NN 算法是如何工作的？

1.  何时选择 K-NN？

1.  如何选择 K 的最佳值？

1.  什么是维度诅咒？

1.  使用 Python 的 sci-kit learn 构建 K-NN 分类器。

1.  如何提高分类器的性能？

### 什么是 K-NN 算法？

![](../Images/fe225aa90f1f3ec39506d32db01afc17.png)

[K-NN 算法表示](https://acadgild.com/blog/k-nearest-neighbor-algorithm)

K-NN 或 K-最近邻算法是当前业界最著名的分类算法之一，主要因其简单性和准确性。

K-NN 是一种简单的算法，它存储所有可用的案例，并根据相似度度量（例如，距离函数）对新案例进行分类。KNN 已经在 1970 年代初期作为一种非参数技术被用于统计估计和模式识别。

该算法假设相似的事物存在于近距离内。换句话说，相似的实体会聚集在一起。

### K-NN 算法如何工作？

在 K-NN 中，K 是最近邻居的数量。邻居的数量是核心决定因素。**如果类别数为 2，则 K 通常是奇数**。当 K=1 时，算法被称为最近邻算法。这是最简单的情况。

在下图中，假设黄色的“**?**”假设 P 是需要预测标签的点。首先，找到离 P 最近的一个点，然后将最近点的标签分配给 P。

![](../Images/861a2f7b786e09051bbd0d37b8db1857.png)

其次，找到离 P 最近的 k 个点，然后通过 K 个邻居的多数投票来分类点。每个对象为其类别投票，获得最多票数的类别被视为预测。为了找到最接近的相似点，我们使用距离度量（如欧几里得距离、汉明距离、曼哈顿距离和闵可夫斯基距离）来计算点之间的距离。算法的基本步骤如下：

1.  计算距离

1.  找到最近的邻居

1.  为标签投票

![](../Images/be2fc1f9343745ff2ec1e5a9747b2f7a.png)

计算点 P 与其最近邻点之间距离的三种最常用的度量方式为：

![](../Images/82d48a4486aae9019ed734c5115b1878.png)

在本文中，我们将首先使用欧几里得距离，所以先了解它。

**欧几里得距离：** 这是最常用的距离度量，也称为简单距离。当数据是密集或连续时，强烈建议使用欧几里得距离度量。欧几里得距离是最佳的接近度量。两点之间的欧几里得距离是连接它们的路径长度。毕达哥拉斯定理给出了两点之间的距离。

下图展示了如何计算二维平面上两点之间的欧几里得距离。

![图](../Images/181a263e28b55514150e7ae38d495336.png)

[二维空间中两点的欧几里得距离](https://mccormickml.com/2013/08/15/the-gaussian-kernel/)

### 何时使用 K-NN 算法？

KNN 可用于分类和回归预测问题。然而，在行业中，它更多地用于分类问题。要评估任何技术，我们通常关注三个重要方面：

1.  输出易于解释

1.  算法的计算时间

1.  预测能力

让我们将 KNN 与不同模型进行比较：

![图](../Images/d52f21040e5ef16e8e24e34609aa2528.png)

来源：Analytics Vidhya

如你所见，K-NN 在我们考虑的方面上超越了逻辑回归、CART 和随机森林。

### 如何选择 K 的最佳值？

K-NN 中的邻居数量（K）是一个超参数，你需要在构建模型时选择。你可以将 K 看作是预测模型的控制变量。

现在，选择 K 的最佳值最好是通过首先检查数据来完成。通常，较大的 K 值更精确，因为它减少了总体噪声，但不能保证。交叉验证是另一种回顾性地确定良好 K 值的方法，通过使用独立的数据集来验证 K 值。从历史上看，大多数数据集的最佳 K 值在 3 到 10 之间。它比 1NN（当 K=1 时）产生更好的结果。

通常，如果类别数量是偶数，则选择奇数。你也可以通过生成不同 K 值的模型并检查它们的性能来验证。

### 维度诅咒

K-NN 在特征较少时表现更好，而不是特征较多时。你可以说，当特征数量增加时，它需要更多的数据。维度增加还会导致过拟合问题。为了避免过拟合，随着维度数量的增加，需要的数据量也需要呈指数增长。这种高维度的问题称为维度诅咒。

![](../Images/40e1bba71a6b963a2370165dc5a23d79.png)

从上述图形表示可以明显看出，随着特征（维度）数量的增加，你的模型性能会下降。

为了解决维度诅咒的问题，你需要在应用任何机器学习算法之前进行主成分分析（PCA），或者你也可以使用特征选择方法。研究表明，在高维情况下，欧几里得距离不再有用。因此，你可以选择其他度量方法，例如余弦相似度，它受到高维度的影响较小。

> **KNN 算法可以与最精确的模型竞争，因为它提供了非常准确的预测。因此，你可以使用 KNN 算法用于需要高精度但不需要人类可读模型的应用。—**来源：[IBM](https://www.ibm.com/support/knowledgecenter/en/SS6NHC/com.ibm.swg.im.dashdb.analytics.doc/doc/r_knn_usage.html)

计算 K-NN 算法的步骤：

1.  确定参数 K = 最近邻的数量。

1.  计算查询实例与所有训练样本之间的距离。

1.  对距离进行排序，并根据第 K 个最小距离确定最近邻。

1.  收集最近邻的类别

1.  使用最近邻类别的简单多数作为查询的预测值。

在下一节中，我们将使用 K-NN 算法解决一个实际问题。

### 更多相关话题

+   [从理论到实践：构建 k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [分类的最近邻](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn 中的 K-最近邻](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [使用 BERT 对长文本进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)

+   [使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)

+   [如何使用 Python 确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)
