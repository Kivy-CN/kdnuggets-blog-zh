["```py\n# for results (maximum of 50 per request)\nAPI_KEY = \"{{API KEY}}\"\nMAX_RESULTS = 250\nGROUP_SIZE = 50\n```", "```py\npython ./bing_image_scraper.py  --query \"{{TERM}}\" --output {{DIR}}\n```", "```py\n#A sereis of operations that were selected to apply to images to create a greater amount of image variation\ndatagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')#root directory for data augmentation\nrootdir = '/xxx/data/'\n```", "```py\n#Move through the designated root directory and traverse through the individual files inside\nfor subdir, dirs, files in os.walk(rootdir):\n    print(\"working in \" +subdir)\n    #Iterate over only the compatible image files\n    for file in files:\n        if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n            #Loading the image\n            img = load_img(subdir + \"/\" + file)\n            #The Numpy array responsible for shape adhearance\n            x = img_to_array(img) \n            x = x.reshape((1,) + x.shape)            # the .flow() command below generates batches of randomly transformed images\n            # and saves the results to the `preview/` directory\n            i = 0\n            for batch in datagen.flow(x, batch_size=1,\n                                      save_to_dir= subdir + \"/\", save_prefix='DA', save_format='jpg'):\n                i += 1\n                #Set to desired iterations\n                if i > 3:\n                    #Setting bound to break loop so to avoid indefinite run\n                    break\n```", "```py\n#The number of class labels == total number of categories which == length of the folders in .dir\ndata=load_files(dataDir, load_content= False)\ntotal_categories=len(data.category_names)# input image dimensions\nimg_rows, img_cols = 64, 64\ndataDir= '{{INPUT YOUR TOP LEVEL IMAGE DIR}}'#The function responsible for connecting the image data with the categories created\ndef build_data(data):\n    X = []\n    y = []\n    #Operations to assign the categories to data structures\n    encoder = LabelBinarizer()\n    encoded_dict=dict()\n    hotcoded_label = encoder.fit_transform(data.category_names)\n    #Matching the category target names to the labels\n    for i in range(len(data.category_names)):\n        encoded_dict[data.category_names[i]]=hotcoded_label[i]\n    for country in os.listdir(dataDir):\n        label=encoded_dict[country]\n        #labeling the images\n        for each_flag in os.listdir(dataDir+'/'+country): \n            actual_path = os.path.join(dataDir,country,each_flag)\n            img_data = cv2.imread(actual_path)\n            img_data = cv2.resize(img_data, (img_rows, img_cols))\n            X.append(np.array(img_data))\n            y.append(label)\n    #Creating a test and training set split with space for declaed variables\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=36)\n    X_train = np.asarray(X_train)\n    X_test = np.asarray(X_test)\n    y_train = np.asarray(y_train)\n    y_test = np.asarray(y_test)#returns the training and testing set\n    return [X_train, X_test, y_train, y_test]\n```", "```py\n#epochs = number of passes through entire training set\nepochs = 100def create_model(input_shape,classes):\n    #Takes the specifications of the image inputted\n    img_input = Input(shape=input_shape)\n    #The following is an architecture structuring\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    x = Flatten(name='flatten')(x)\n    x = Dense(512, activation='relu', name='fc1')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(256, activation='relu', name='fc2')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(classes, activation='softmax', name='final_output')(x)model = Model(img_input, x, name='flag')\n    return model\n```", "```py\ndef train_model(x_train, x_test, y_train, y_test):\n    input_shape=(img_rows,img_cols,3)\n    model=create_model(input_shape,total_countries)\n    adams=optimizers.Adam(lr=1e-4)\n    model.compile(loss=’categorical_crossentropy’,\n                optimizer= adams,\n                metrics=[‘accuracy’])\n    model.fit(x = x_train, y = y_train, epochs=epochs)\n    score = model.evaluate(x_test, y_test, verbose=1)\n    print(‘Test loss:’, score[0])\n    print(‘Test accuracy:’, score[1])\n    model.save(‘flagFinder.model’)   \n    return model\n```", "```py\ndef flag_identify(positiveDir):    #An array to keep the list of countries built from the data ingestion step\n    countries = []    #iterate through the ingestion stage names and append them to a list for ease of labeling\n    for i in range(len(datas.target_names)):\n        i += 1\n        countries.append(datas.target_names[i-1])    #Another data preperation step for image ingestion for prediction identification\n    def prepare(filepath):\n        IMG_SIZE = 64\n        img_array = cv2.imread(filepath)\n        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n        return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)    #Load in the previously built model\n    model = tf.keras.models.load_model(\"flagFinder.model\")    #Traverses through the given directory containing test images\n    for filename in os.listdir(positiveDir):\n        #Accpets various photo formats that were processed previous\n        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n            prediction = model.predict([prepare(positiveDir + filename)])\n            topCountry = int(np.argmax(prediction, axis=1))\n            secondCountry = int(np.argmax(prediction, axis=1)-1)\n            #Writes predictions to a set directory for ease of view\n            with open(\"/xxx/flags.txt\", \"a\") as myfile:\n                #Generic sentence for output both the filename and the TOP PREDICTION (can be adjusted for other predictions)\n                myfile.write(\"A flag was found in photo: \" + filename + \", It is most likely to from the Nation: \" + countries[topCountry] +\", or ,\" + countries[secondCountry] +\"\\n\" )\n```", "```py\ndef build_flag_identifier():\n    x_train, x_test, y_train, y_test = build_data(datas)\n    train_model(x_train, x_test, y_train, y_test)def main():\n    build_flag_identifier()\n    flag_identify({{DIR}})if __name__ == \"__main__\":\n    main()\n```"]