- en: Five Interesting Data Engineering Projects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 五个有趣的数据工程项目
- en: 原文：[https://www.kdnuggets.com/2020/03/data-engineering-projects.html](https://www.kdnuggets.com/2020/03/data-engineering-projects.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/data-engineering-projects.html](https://www.kdnuggets.com/2020/03/data-engineering-projects.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Dmitriy Ryaboy](https://www.linkedin.com/in/dmitriy-ryaboy/), VP Software
    Engineering at Zymergen**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Zymergen的软件工程副总裁Dmitriy Ryaboy](https://www.linkedin.com/in/dmitriy-ryaboy/)撰写**。'
- en: There’s been a lot of activity in the data engineering world lately, and a ton
    of really interesting projects and ideas have come on the scene in the past few
    years. This post is an introduction to (just) five that I think a data engineer
    who wants to stay current needs to know about.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在数据工程领域有很多活动，过去几年中出现了许多非常有趣的项目和想法。这篇文章是我认为想要跟上潮流的数据工程师需要了解的（仅）五个项目的介绍。
- en: DBT
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DBT
- en: '![](../Images/3d4f5f9c0fe981793933a5ca46fb4a12.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d4f5f9c0fe981793933a5ca46fb4a12.png)'
- en: 'DBT, or “data build tool,” is a clean, well-executed take on what’s fundamentally
    a simple idea: SQL statements for doing important work should be version controlled,
    and it’d be nice if they could be easily parametrized, and maybe refer to each
    other. DBT is aimed at “data analysts” rather than data engineers (though there’s
    no reason data engineers wouldn’t use it). Everything is done in SQL (well, that
    and YAML).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: DBT，或者称为“数据构建工具”，对基本上是一个简单概念进行了干净而有效的处理：用于执行重要工作的SQL语句应该进行版本控制，并且如果能够轻松参数化并且可能相互引用，那将会很好。DBT主要面向“数据分析师”而不是数据工程师（尽管没有理由数据工程师不会使用它）。一切都是用SQL完成的（好吧，还有YAML）。
- en: By cleanly structuring how projects are laid out, how queries referring to other
    queries works, and what fields need to be populated in a config, DBT enforces
    a lot of great practices and vastly improves what can often be a messy workflow.
    With all this in place, it can run your workflow — and it can also generate documentation,
    help you run validation and testing queries, share code via packages, and more.
    It has a gentle on-ramp and gives the analyst many powerful tools if she chooses
    to take advantage of them — or stay out of the way, if not.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过清晰地组织项目布局，处理引用其他查询的查询以及配置中需要填充的字段，DBT强制执行了许多良好的实践，并显著改进了通常会变得混乱的工作流程。一旦这些都到位了，它可以运行您的工作流程，并且还可以生成文档、帮助您运行验证和测试查询、通过软件包分享代码等等。它有一个温和的入门过程，如果分析师选择利用这些强大的工具，可以给她提供很多有力的工具；如果不利用，也不会挡道。
- en: If you or someone in your life does a lot of SQL, they need to check out DBT.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你或你生活中的某人经常使用SQL，他们需要查看DBT。
- en: Prefect
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Prefect
- en: '![](../Images/426e5b49e7ef2f1bf56d29090406bd29.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/426e5b49e7ef2f1bf56d29090406bd29.png)'
- en: 'Prefect is an up-and-coming challenger to AirFlow: [yet another data pipeline
    manager](https://github.com/pditommaso/awesome-pipeline) that helps set up DAGs
    of processes, parametrize them, react appropriately to error conditions, create
    schedules and processing triggers, and so on. If you look past their slightly
    arrogant marketing (apparently, Prefect is already a “global leader in dataflow
    automation,” and Airflow is just a “historically important tool”), Prefect has
    a few neat things going that earn it much praise from adopters:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Prefect 是对 AirFlow 的一个新兴挑战者：[又一个数据管道管理器](https://github.com/pditommaso/awesome-pipeline)，它帮助设置进程的DAG，对其进行参数化，并对错误条件做出适当反应，创建时间表和处理触发器等等。如果你能忽略他们有些傲慢的营销（显然，Prefect
    已经是“全球领先的数据流自动化”工具，而Airflow只是“历史上重要的工具”），Prefect 有一些很棒的功能受到用户的高度称赞：
- en: It cleanly separates the actual data flows from the scheduling/triggering aspect
    of job management, making things like backfills, ad-hoc runs, parallel workflow
    instances, etc., easier to achieve.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它清晰地将实际数据流与作业管理的调度/触发方面分开，使得像回填、临时运行、并行工作流实例等更容易实现。
- en: It’s got a neat functional (as well as an Airflow-like imperative-style) [API](https://docs.prefect.io/core/concepts/flows.html#apis)
    for creating DAGs.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一个漂亮的函数式（以及类似Airflow的命令式）[API](https://docs.prefect.io/core/concepts/flows.html#apis)，用于创建DAG。
- en: It avoids the Airflow’s XCom trap of communicating data between tasks through
    a sort of weird side channel that occasionally blows up on you, and instead relies
    on transparent (except when *it *blows up on you) serialization and explicit inputs/outputs
    for individual tasks.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它避免了Airflow的XCom陷阱，即通过一种奇怪的侧通道在任务之间传递数据，有时会给你带来麻烦，而是依赖于透明（除非它在你身上*爆炸*）的序列化和单个任务的显式输入/输出。
- en: It makes [dealing with parameters](https://docs.prefect.io/core/concepts/parameters.html)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使 [处理参数](https://docs.prefect.io/core/concepts/parameters.html)
- en: You can do all this in Airflow, but the Prefect team argues their APIs make
    for a much cleaner and intuitive ways of addressing these and other challenges.
    They seem to have gained quite a few fans who agree.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 Airflow 中完成所有这些操作，但 Prefect 团队认为他们的 API 提供了更清晰和直观的解决方案。他们似乎获得了相当多的粉丝认可。
- en: Dask
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dask
- en: '![](../Images/0b1d18ab2f26894dfe46c8345561261a.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b1d18ab2f26894dfe46c8345561261a.png)'
- en: Are people still sleeping on Dask? Stop sleeping on Dask.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 人们还在忽视 Dask 吗？停止忽视 Dask。
- en: “[Dask](https://dask.org/) is a “flexible library for parallel computing in
    Python.” If you are using Python a lot for data work, mostly sticking to NumPy
    / Scikit-learn / Pandas, you might find that throwing Dask in makes things whirr
    incredibly easily. It’s lightweight and fast, it works great on a single machine
    or on a cluster, it [works well with RAPIDS](https://rapids.ai/dask.html) to get
    you GPU acceleration, and it’s likely going to be a much easier transition for
    scale-up than moving your python code over to PySpark. They have a surprisingly
    well-balanced doc talking about pros and cons vs. Spark here: [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html) .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '“[Dask](https://dask.org/) 是一个“用于 Python 的灵活并行计算库”。如果你经常使用 Python 进行数据工作，主要使用
    NumPy / Scikit-learn / Pandas，你可能会发现使用 Dask 会让事情变得异常简单。它轻量快速，单机或集群上都能很好地工作，它与
    [RAPIDS](https://rapids.ai/dask.html) 配合良好，以获得 GPU 加速，而且它在扩展时可能比将 Python 代码迁移到
    PySpark 更容易。他们有一个意外地平衡的文档讨论了与 Spark 相比的优缺点，链接在这里: [https://docs.dask.org/en/latest/spark.html](https://docs.dask.org/en/latest/spark.html)。'
- en: DVC
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DVC
- en: '![](../Images/91351f50fee592559d2d048429aa68aa.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91351f50fee592559d2d048429aa68aa.png)'
- en: DVC stands for “data version control.” This project invites data scientists
    and engineers to a Git-inspired world, where all workflow versions are tracked,
    along with all the data artifacts and models, as well as associated metrics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DVC 代表“数据版本控制”。该项目邀请数据科学家和工程师进入一个受 Git 启发的世界，其中所有工作流版本以及所有数据工件和模型以及相关的指标都会被跟踪。
- en: 'To be honest, I’m a bit of a skeptic on “git for data” and various automated
    data/workflow versioning schemes: various approaches I’ve seen in the past were
    either too partial to be useful, or required too drastic a change in how data
    scientists worked to get a realistic chance at adoption. So I ignored, or even
    explicitly avoided, checking DVC out as the buzz grew. I’ve finally checked it
    out and… it looks like maybe this has legs? Metrics tied to branches/versions
    are a great feature. Tying the idea of git-like braches to training multiple models
    makes the value prop clear. The implementation, using Git for code and datafile
    index storage, while leveraging scalable data stores for data, and trying to reduce
    overall storage cost by being clever about reuse, looks sane. A lot of what they
    have to say in [https://dvc.org/doc/understanding-dvc](https://dvc.org/doc/understanding-dvc) rings
    true. Thoughtworks used DVC as their demo tool of choice to [discuss “CD4ML”](https://martinfowler.com/articles/cd4ml.html).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，我对“数据的 Git”和各种自动化数据/工作流版本控制方案有点怀疑：我过去见过的各种方法要么过于局部无法实用，要么需要对数据科学家的工作方式进行过于剧烈的改变，才能有实际采用的机会。因此，我忽视了，甚至明确避免了，随着关注度的增加而查看
    DVC。我终于查看了它，并且……这看起来也许有潜力？与分支/版本相关的指标是一个很棒的功能。将类似 Git 的分支概念与训练多个模型结合起来，使其价值主张变得清晰。使用
    Git 进行代码和数据文件索引存储，同时利用可扩展数据存储来存储数据，并通过巧妙的重用来减少整体存储成本，这样的实现看起来很合理。他们在 [https://dvc.org/doc/understanding-dvc](https://dvc.org/doc/understanding-dvc)
    上说的很多内容都很真实。Thoughtworks 使用 DVC 作为他们的演示工具来 [讨论“CD4ML”](https://martinfowler.com/articles/cd4ml.html)。
- en: On the other hand, I’m not super keen on handing over pipeline definition to
    DVC — Airflow or Prefect or a number of other tools appear to offer much more
    on that front. A casual perusal of internet resources revealed multiple mentions
    of using DVC alongside MLFlow or other tools, but it’s not clear how well that
    works and what one gives up.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我对将管道定义交给 DVC 不太热衷——Airflow 或 Prefect 或其他许多工具似乎在这方面提供了更多。对互联网资源的随意浏览显示了多次提到将
    DVC 与 MLFlow 或其他工具一起使用，但不清楚效果如何以及会放弃什么。
- en: Still — DVC is the technology that keeps coming up whenever the problem of “git
    for data” or “git for ML” comes up. It’s definitely worth checking out and keeping
    an eye on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不过——DVC 是每当提到“数据的 Git”或“ML 的 Git”时总会出现的技术。它绝对值得关注和关注。
- en: Great Expectations
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Great Expectations
- en: '![](../Images/a08bbfba2cd52652d4134822e076bac9.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a08bbfba2cd52652d4134822e076bac9.png)'
- en: Great Expectations is a really nice Python library that allows you to declare
    rules to which you expect certain datasets to confirm and validate those as you
    encounter (produce or consume) those datasets. These would be expectations such
    as *expect_colum_values_to_match_strftime_format or expect_column_distinct_values_to_be_in_set*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Great Expectations是一个非常好的Python库，它允许你声明期望某些数据集符合的规则，并在遇到（生成或消费）这些数据集时对其进行验证。这些期望值可能是*expect_colum_values_to_match_strftime_format*或*expect_column_distinct_values_to_be_in_set*。
- en: It’s not wrong to think of these as assertions for data. Expectations can be
    evaluated using a number of common data compute environments (Spark, SQL, Pandas)
    and integrate cleanly into a number of various workflow engines, including DBT
    and Prefect discussed above (as well as Airflow, of course). The [introduction](https://docs.greatexpectations.io/en/latest/intro.html) and [glossary
    of expectations](https://docs.greatexpectations.io/en/latest/expectation_glossary.html) sections
    of their docs are fairly self-explanatory.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些看作数据的断言并不错误。期望可以在许多常见的数据计算环境（如Spark、SQL、Pandas）中进行评估，并且可以无缝集成到许多不同的工作流引擎中，包括上面讨论的DBT和Prefect（当然还有Airflow）。他们文档中的[introduction](https://docs.greatexpectations.io/en/latest/intro.html)和[glossary
    of expectations](https://docs.greatexpectations.io/en/latest/expectation_glossary.html)部分相当自解释。
- en: On top of providing ways to define and validate these assertions, Great Expectations
    provides automated data profilers that will *generate the expectations and clean
    HTML data documentation*. How cool is that?!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供定义和验证这些断言的方法外，Great Expectations还提供了自动化数据分析器，它将*生成期望值和清晰的HTML数据文档*。这有多酷？！
- en: It’s not a completely novel idea, but it appears to be well-executed, and the
    library is gaining traction.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个完全新颖的想法，但看起来执行得很好，而且这个库正在获得关注。
- en: Bonus Round
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 奖励回合
- en: 'Maybe it’s a post-Hadoop effect, maybe it’s The Cloud, maybe it’s just that
    Python finally has type hints, but it’s downright difficult to narrow the list
    of interesting projects to five. Here are a few more that I personally would love
    to spend some time with, and think you, a reader so committed that you are still
    here, might enjoy as well, in alphabetical order:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这是后Hadoop效应，也许是云计算，也许只是Python终于有了类型提示，但确实很难将有趣的项目列表缩小到五个。这里有一些我个人很想花时间研究的项目，认为你作为一个如此投入的读者也可能会喜欢，按字母顺序排列：
- en: '[Amundsen](https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234)
    is an interesting “data discovery and metadata platform” from Lyft. Every self-respecting
    tech unicorn seems to have one of these now. Can we stop and choose a winner?'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Amundsen](https://eng.lyft.com/open-sourcing-amundsen-a-data-discovery-and-metadata-platform-2282bb436234)是Lyft推出的一个有趣的“数据发现和元数据平台”。现在每个自尊心强的科技独角兽似乎都有一个这样的平台。我们能否停下来选择一个赢家？'
- en: '[Cadence](http://cadenceworkflow.io/) is a “fault-oblivious stateful code platform”
    or, in other words, a way to outsource some of the common concerns about having
    long-lived state in your functions to somebody else. Anyway, find time to watch
    this video and consider where this might apply in your life: [https://www.youtube.com/watch?v=llmsBGKOuWI](https://www.youtube.com/watch?v=llmsBGKOuWI)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Cadence](http://cadenceworkflow.io/)是一个“容错的有状态代码平台”，换句话说，就是将有关函数中的长期状态的一些常见问题外包给其他人。无论如何，抽时间观看这个视频，并考虑它在你生活中可能的应用：
    [https://www.youtube.com/watch?v=llmsBGKOuWI](https://www.youtube.com/watch?v=llmsBGKOuWI)'
- en: '[Calcite](https://calcite.apache.org/) is the core of the deconstructed database,
    providing a SQL parser, a database-agnostic query execution planner and optimizer,
    and more. It [can be found](https://calcite.apache.org/docs/powered_by.html) in
    a number of the “big data” projects that offer SQL support (Hive, Flink, Drill,
    Phoenix…)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Calcite](https://calcite.apache.org/)是解构数据库的核心，提供SQL解析器、数据库无关的查询执行计划和优化器等。它[可以在](https://calcite.apache.org/docs/powered_by.html)许多提供SQL支持的“大数据”项目中找到（如Hive、Flink、Drill、Phoenix等）。'
- en: '[Dagster](https://github.com/dagster-io/dagster) is a data workflow engine
    from the creator of GraphQL, and aims to transform developer ergonomics for data
    engineers in the way GraphQL did for frontend engineers. It’s good stuff, and
    probably deserves a separate post.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dagster](https://github.com/dagster-io/dagster)是GraphQL创建者开发的数据工作流引擎，旨在像GraphQL为前端工程师所做的那样，改变数据工程师的开发体验。这是很棒的东西，可能值得单独写一篇文章。'
- en: '[Json-Schema](https://json-schema.org/) is not at all new, but for whatever
    reason, people seem to not know it exists. It exists, it’s been growing, and you
    should define and validate your dang schemas. There are specs, there are tools,
    you can hang this on your existing JSON APIs and not suffer Avro/Thrift/Proto
    envy.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Json-Schema](https://json-schema.org/) 并不新鲜，但无论什么原因，人们似乎不知道它的存在。它确实存在，正在发展，你应该定义和验证你的架构。有规格，有工具，你可以将其挂载到现有的JSON
    API上，而不必羡慕Avro/Thrift/Proto。'
- en: '[Original](https://medium.com/@squarecog/five-interesting-data-engineering-projects-48ffb9c9c501).
    Reposted with permission.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@squarecog/five-interesting-data-engineering-projects-48ffb9c9c501)。经许可转载。'
- en: '**Related:**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[7 Resources to Becoming a Data Engineer](https://www.kdnuggets.com/2020/01/resources-become-data-engineer.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为数据工程师的7个资源](https://www.kdnuggets.com/2020/01/resources-become-data-engineer.html)'
- en: '[The thin line between data science and data engineering](https://www.kdnuggets.com/2019/09/thin-line-between-data-science-data-engineering.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学与数据工程之间的细微差别](https://www.kdnuggets.com/2019/09/thin-line-between-data-science-data-engineering.html)'
- en: '[A Beginner’s Guide to Data Engineering  –  Part I](https://www.kdnuggets.com/2018/01/beginners-guide-data-engineering-1.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据工程初学者指南 — 第一部分](https://www.kdnuggets.com/2018/01/beginners-guide-data-engineering-1.html)'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[3 Interesting Uses of Python''s Context Managers](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python上下文管理器的3个有趣用法](https://www.kdnuggets.com/3-interesting-uses-of-python-context-managers)'
- en: '[KDnuggets™ News 22:n03, Jan 19: A Deep Look Into 13 Data…](https://www.kdnuggets.com/2022/n03.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n03, 1月19日：深入了解13个数据…](https://www.kdnuggets.com/2022/n03.html)'
- en: '[Become a Data Science Professional in Five Steps](https://www.kdnuggets.com/2022/03/become-data-science-professional-five-steps.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[五步成为数据科学专业人士](https://www.kdnuggets.com/2022/03/become-data-science-professional-five-steps.html)'
- en: '[Top Five SQL Window Functions You Should Know For Data Science Interviews](https://www.kdnuggets.com/2022/01/top-five-sql-window-functions-know-data-science-interviews.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试中你应该了解的五个SQL窗口函数](https://www.kdnuggets.com/2022/01/top-five-sql-window-functions-know-data-science-interviews.html)'
- en: '[Five Signs of an Effective Data Science Manager](https://www.kdnuggets.com/2022/06/five-signs-effective-data-science-manager.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[有效数据科学经理的五个迹象](https://www.kdnuggets.com/2022/06/five-signs-effective-data-science-manager.html)'
- en: '[Five Ways to do Conditional Filtering in Pandas](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Pandas中进行条件筛选的五种方法](https://www.kdnuggets.com/2022/12/five-ways-conditional-filtering-pandas.html)'
