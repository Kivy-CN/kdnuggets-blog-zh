- en: H2O Framework for Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/01/h2o-framework-machine-learning.html](https://www.kdnuggets.com/2020/01/h2o-framework-machine-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [ActiveWizards](https://activewizards.com/)**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/afeb834ecb031a7a68e910ad9f98000b.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: H2O is a scalable and fast open-source platform for machine learning. We will
    apply it to perform classification tasks. The dataset we are using is the [Bank
    Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing). Here
    we need to train a model which will be able to predict if the client of the bank
    opens the term deposit on the basis of his/her personal features of the client,
    marketing campaign features and current macroeconomic conditions.
  prefs: []
  type: TYPE_NORMAL
- en: During the model creation we explore various core components and functions from
    the H2O toolkit. You should understand that while this article covers some basic
    concepts of H2O, if you need more detailed information you should go to the H2O
    website and read [documentation](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: for installation instructions please use the [official website](https://www.h2o.ai/download/).*'
  prefs: []
  type: TYPE_NORMAL
- en: Preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We need to import needed libraries first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing you should do is to start the H2O. You can run method h2o.init() to
    initialize H2O. Many different parameters can be given to h2o.init() method in
    order to set up the H2O according to your needs. So, here you can change some
    global settings of the H2O. Nevertheless, in most cases it is enough to call this
    methods without any parameters, like we did below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/cd4be79d1f7fee58cdb0ed356521f72f.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the output from this method consists of some meta-information
    about your H2O cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing we should do is to import the dataset we will work with. This
    is the .csv file and the H2O has function upload_file() which will load the dataset
    in the memory. It is worth to say that the H2O can work with several data sources
    (both local and remote) and support different file formats.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: To take a look at the dataset, you can simply type in its name and run the cell.
    The top 10 rows are displayed by default.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b7a8b49bc6ab217d3f769359b501727b.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at the type of this variable, we can see that the type is h2o.frame.H2OFrame.
    So, this is not a pandas object, but the own object of the H2O.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d60ecff9f4cf56d1f81d00b4f6d083a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, you can index and slice this H2OFrame in a familiar manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/821c67ca1f753d5460f0ea9be20728f5.png)'
  prefs: []
  type: TYPE_IMG
- en: You can check the shape of the H2OFrame by accessing .shape attribute of it.
    Also, some useful information (type of columns, min, average, max values, standard
    deviation, number of zeros, missing values) can be generated by .describe() method.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75137e03c97f4807f652857a10b472d3.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/8378bbc9dbe6e90fd837bdb8ff38ed0d.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, there are no missing data in our dataset. We have 20 columns
    with different categorical, integer and real number features and 1 target column
    (y). The target variable is binary and can take values "yes" if the customer want
    to subscribe a term deposit or "no" if not.
  prefs: []
  type: TYPE_NORMAL
- en: In the next cell we extract the names of columns into the variable x. Then,
    we remove the name of the target column (y) from this list. Also, we write the
    name of the target variable in the variable y.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/6bbaee011874624cda56298e1a009cab.png)'
  prefs: []
  type: TYPE_IMG
- en: The first model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let's train certain model. First, we need to split our dataset into training
    and testing parts. H2O allows to do this by using function split_frame(). If you
    pass only one element in the list as the first argument (or argument ratios),
    this element defines the fraction of the training dataset. The rest is the testing
    set. If you pass two elements, the first means training, the second - testing,
    and the rest - validation set. Here we want to take 70% of the sample as training
    set and 30% as testing set. We also fix the random state to get the reproducible
    results.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: For the beginning, we want to use Random Forest model to classify data points.
    The H2ORandomForestEstimator can be found in the module h2o.estimators.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Then we create an instance of the estimator. Here you can specify many different
    parameters. We set the number of trees to 200 by assigning 200 to ntrees parameter.
    After this, we call the method train on the instance of estimator. We should pass
    names of columns with features into variable x and the name of the target column
    into variable y. Also, we specify training and validation samples. After we run
    this cell, we can see the progress bar below it, reflecting the status of the
    training process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d4221b67818e69b4c0253b60c85d4df8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The model details can be accessed by looking at the instance of the estimator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da9f73dd80542cc1d47566a4f55dd7bd.png)'
  prefs: []
  type: TYPE_IMG
- en: A lot of interesting and useful information is available here. You can notice
    two blocks of information. The first one is reported on the train set and the
    second is about test set. There are different model performance metrics (MSE,
    RMSE, LogLoss, AUC, Gini etc.). Confusion matrix is a very interesting metric
    for error analysis. H2O allows to look at confusion matrices both on the train
    and test set. The total fraction of errors as well as for each label are also
    displayed in the confusion matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Interesting table is about maximum metrics at their respective errors. In the
    binary classification, model returns the probability of the instance to have the
    positive class. And then this probability should be compared with some threshold
    to decide if this is the positive class or negative. H2O shows in this table the
    maximum values for different metrics and also specify the thresholds used when
    achieving this maximum metrics. For example, in our case we can achieve the perfect
    precision on the test set by choosing the threshold 0.985\. The maximum accuracy
    on the test set is 0.911 and it can be achieved when you choose 0.5294 as the
    threshold. The highest F1-score corresponds to the threshold 0.331.
  prefs: []
  type: TYPE_NORMAL
- en: While implementing your model in solution you can choose the threshold which
    is the best suitable for your needs. Also, you can try some more advanced things,
    like choosing the threshold by combining thresholds reported for max values of
    different metrics for both train and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: One more interesting table here is the table with feature importances. The most
    informative columns are scaled_importance and percentage. You can see that the duration feature
    has the maximum predictive power for this task and dataset. This feature means
    the duration of a phone call with a client. Top 5 other important features, besides duration are
    macroeconomic indicators euribor3m and nr.employed, and also age and job of the
    client.
  prefs: []
  type: TYPE_NORMAL
- en: Now we want to manually compute the accuracy on the test set.
  prefs: []
  type: TYPE_NORMAL
- en: In the next cell we make predictions. You can see that method predict() returns
    a dataframe with the answer (yes or no) in the first column and the probabilities
    for no and yes in the next two columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/4357413d752756b8eb73390605a7c009.png)'
  prefs: []
  type: TYPE_IMG
- en: In the next cell we count the number of cases where the predictions equals to
    the actual answers and then we compute the mean which will be the accuracy of
    the prediction. We can see that the accuracy is 0.9041 or around 90.4%. If you
    return back and look at the confusion matrix you can notice that if you subtract
    the total error for the test set (0.0958) from 1, you will get ~0.9041, which
    is the accuracy we found manually.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/ba37d12562111f8985e4af419c517db6.png)'
  prefs: []
  type: TYPE_IMG
- en: Other algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: H2O provides several different models for training. Let's try some of them.
  prefs: []
  type: TYPE_NORMAL
- en: The first algorithm we want to train using the neural network. To use this model
    we need to import H2ODeepLearningEstimator from h2o.estimators.deeplearning module.
    Then, we need to create an instance of this estimator. Like in the previous example
    with Random Forest, here you can pass many different parameters to control the
    model and training process. It is important to set up the architecture of the
    neural network. In the parameter hidden we pass a list with a number of neurons
    in hidden layers. So, this parameter controls both the number of hidden layers
    and neurons in these layers. We set up 3 hidden layers with 100, 10 and 4 neurons
    in each respectively. Also, we set the activation function to be Tanh.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d902243700bdc8c9e46dec56ab6ff936.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that the accuracy is slightly lower than with Random Forest. Maybe
    we can fine-tune the model's parameters to get better performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few cells we train linear model. Binomial family means that we want
    to perform classification with logistic regression. lambda_search allows searching
    optimal regularization parameter lambda.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d4221b67818e69b4c0253b60c85d4df8.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/da593c6b719ece668800c0f6dfbf5833.png)'
  prefs: []
  type: TYPE_IMG
- en: The last model we want to use here is the Gradient Boosting algorithm. With
    the default parameters it can give the best results amongst all other algorithms
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/bc15d9f11812e35ff1f6cd98da7d692e.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/45f3299ab86d4d6bd15ae6a24ad4e130.png)'
  prefs: []
  type: TYPE_IMG
- en: It is worth to mention about XGBoost integration in the H2O platform. XGBoost
    is one of the most powerful algorithms which implements the gradient boosting
    idea. You can install it standalone, but it is also very convenient to use XGBoost
    in H2O. In the cell below you can see how to create an instance of H2OXGBoostEstimator and
    how to train it. You should understand that XGBoost uses many parameters and very
    often can be very sensitive to the changes in these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ecabdaaf851178c1fe03cbf3bc6f77ae.png)'
  prefs: []
  type: TYPE_IMG
- en: There are several other models available in the H2O. You should see documentation
    if you want to know more.
  prefs: []
  type: TYPE_NORMAL
- en: Cross validation in H2O
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cross validation is one of the core techniques used in machine learning. The
    basic idea is to split the dataset into several parts (folds) and then train the
    model on all except one fold, which will be used later for testing. On this, the
    current iteration finishes and the next iteration begins. On the next iteration,
    the testing fold is included in the training sample. Instead, certain fold from
    the previous training set is used for testing.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we split the dataset into 3 folds. On first iteration we use 1st
    and 2nd folds for training and 3rd for testing. On the second iteration 1st and
    3rd folds are used for training and 2nd for testing. On the third iteration the
    1st folds is used for testing and the 2nd and 3rd are used for training.
  prefs: []
  type: TYPE_NORMAL
- en: Cross validation allows to estimate the model's performance in a more accurate
    and reliable way.
  prefs: []
  type: TYPE_NORMAL
- en: In H2O it is simple to do cross validation. If the model supports it, there
    is an optional parameter nfolds which can be passed when creating an instance
    of the model. You should specify the number of folds for cross validation using
    this parameter.
  prefs: []
  type: TYPE_NORMAL
- en: H2O builds nfolds + 1 models. An additional model is trained on all the available
    data. This is the main model you will get as the result of training.
  prefs: []
  type: TYPE_NORMAL
- en: Let's train Random Forest and perform cross validation with 3 folds. Note that
    we are not passing the validation (test) set, but the entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/1cdb8bb77d6c41acf495080b9a0e5133.png)'
  prefs: []
  type: TYPE_IMG
- en: If you look at the output in the cell above, you will notice some differences.
  prefs: []
  type: TYPE_NORMAL
- en: The first is that instead of reporting on validation data the model reports
    on cross-validation data.
  prefs: []
  type: TYPE_NORMAL
- en: The second is that there is a table with cross-validation metrics summary. Here
    you can see many different metrics, their values for each of the fold as the test
    fold, the mean of these values and the standard deviation for each of the metric.
    For example, for first fold we get accuracy 0.9006, for second - 0.904, for third
    - 0.903\. The mean of these values is 0.9025 and the standard deviation is 0.001\.
    You should understand that it is important not only to have "good" values for
    metrics, but also to have low standard deviation. This means that your model behaves
    well on different examples in the dataset. But the interpretation of the results
    of the cross-validation isn't actually the goal of this article, so let's move
    to the next chapter!
  prefs: []
  type: TYPE_NORMAL
- en: Model tuning using GridSearch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often, you need to try many different parameters and their combinations to find
    one which produces the best performance of the model. It is hard and sometimes
    tedious to do everything by hand. Grid search allows to automate this process.
    All you need to do is to specify the set of hyperparameters you want to try and
    run the GridSearch instance. The system will try all possible combinations of
    the parameters (train and test models for each combination). Let's look how this
    tool can be used in H2O.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to import the instance of the GridSearch object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now you need to specify all possible parameters which you want to try. We are
    going to search for an optimal combination of parameters for the XGBoost model
    we have built earlier. The parameters are placed inside a python dictionary where
    the keys are the names of the parameters and the values are the lists with possible
    values of these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The next step is a creation of the GridSearch instance. You should pass a model,
    id of the grid, and the dictionary with hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Eventually, you can run the grid search. Note that we set the higher learning
    rate, because grid search is a very time-consuming process. The number of models
    to train grows rapidly with the growth of number of hyperparameters. So, taking
    into account that this is only a learning example, we don't want to test many
    hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can get the results of the grid search by using method get_grid() of the
    GridSearch instance. We want to sort the results by accuracy metric in the descending
    order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ad09d86283a57be704316b58f8195782.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the highest accuracy is obtained by using combination of 1.0
    column sample rate, 0.4 sample rate, 200 trees and the maximum depth of one tree
    equal to 3.
  prefs: []
  type: TYPE_NORMAL
- en: AutoML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: H2O provides the ability to perform automated machine learning. The process
    is very simple and is oriented on the users without much knowledge and experience
    in machine learning. AutoML will iterate through different models and parameters
    trying to find the best. There are several parameters to specify, but in most
    cases all you need to do is to set only the maximum runtime in seconds or maximum
    number of models. You can think about AutoML as something similar to GridSearch
    but on the level of models rather than on the level of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can take a look on the table with all tried models and their corresponding
    performance by checking the .leaderboard attribute of the autoML instance. GBM
    with 0.94 AUC metric seems to be the best model here.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/607ae3b06bfee8055a1eb1882cbc3ff6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Take a look at the best model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a246e130d9b584af3068ce8c2429b2fa.png)'
  prefs: []
  type: TYPE_IMG
- en: You can predict on the test set directly from the autoML instance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This article is just a brief introductory overview of the H2O functionality.
    This is a great machine learning platform that can make some areas of machine
    learning work of engineers work more simple. It is a continuously developing framework.
    In the same way, in our opinion, it cannot be used alone. Instead, other instruments
    used along with H2O can make the machine learning process faster and more convenient.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we covered some basic data manipulation operations in H2O,
    looked at several machine learning models provided by H2O, learned how to perform
    cross-validation and grid search, became familiar with the automated machine learning
    in H2O.
  prefs: []
  type: TYPE_NORMAL
- en: You should understand that there are some features of the H2O which are below
    the scope of this article. So, if you are interested in learning more, please,
    read the official documentation.
  prefs: []
  type: TYPE_NORMAL
- en: '**[ActiveWizards](https://activewizards.com/)** is a team of data scientists
    and engineers, focused exclusively on data projects (big data, data science, machine
    learning, data visualizations). Areas of core expertise include data science (research,
    machine learning algorithms, visualizations and engineering), data visualizations
    ( d3.js, Tableau and other), big data engineering (Hadoop, Spark, Kafka, Cassandra,
    HBase, MongoDB and other), and data intensive web applications development (RESTful
    APIs, Flask, Django, Meteor).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://activewizards.com/blog/h2o-framework-for-machine-learning/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Automated Machine Learning: How do teams work together on an AutoML project?](/2020/01/teams-work-together-automl-project.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automated Machine Learning Project Implementation Complexities](/2019/11/automl-implementation-complexities.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparison of Top 6 Python NLP Libraries](/2018/07/comparison-top-6-python-nlp-libraries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Risk Management Framework for AI/ML Models](https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Social User Authentication in Django Framework](https://www.kdnuggets.com/2023/01/social-user-authentication-django-framework.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Only Prompting Framework for Every Use](https://www.kdnuggets.com/the-only-prompting-framework-for-every-use)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Machine Learning Skills Every Machine Learning Engineer Should…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, December 14: 3 Free Machine Learning Courses for…](https://www.kdnuggets.com/2022/n48.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
