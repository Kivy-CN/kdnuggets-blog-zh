# 自然语言处理的7种人工神经网络类型

> 原文：[https://www.kdnuggets.com/2017/10/7-types-artificial-neural-networks-natural-language-processing.html/2](https://www.kdnuggets.com/2017/10/7-types-artificial-neural-networks-natural-language-processing.html/2)

### 3\. 递归神经网络（RNN）

![](../Images/bce9a470631fe036e9e9f0becdd3aa48.png)

一个简单的递归神经网络结构 ([https://upload.wikimedia.org/wikipedia/commons/6/60/Simple_recursive_neural_network.svg](https://upload.wikimedia.org/wikipedia/commons/6/60/Simple_recursive_neural_network.svg))

递归神经网络（RNN）是一种深度神经网络，通过在一个结构上递归应用相同的权重集合，进行结构化预测或者对可变大小输入结构进行标量预测，通过以拓扑顺序遍历给定结构[[6]](https://en.wikipedia.org/wiki/Recursive_neural_network)。在最简单的架构中，使用非线性函数如tanh，以及在整个网络中共享的权重矩阵来将节点组合成父节点。

### 4\. 循环神经网络（RNN）

循环神经网络（RNN）不同于[前馈神经网络](https://en.wikipedia.org/wiki/Feedforward_neural_network)，它是一种递归人工神经网络的变体，其中神经元之间的连接形成一个有向循环。这意味着输出不仅依赖于当前的输入，还依赖于前一步的神经元状态。这种记忆使得用户能够解决自然语言处理（NLP）问题，例如连写识别或语音识别。在一篇论文中，[使用循环神经网络进行自然语言生成、改写和用户评论总结](http://www.meanotek.ru/files/TarasovDS%282%292015-Dialogue.pdf)，作者展示了一种循环神经网络（RNN）模型，该模型可以生成新颖的句子和文档摘要[[7]](http://www.meanotek.ru/files/TarasovDS%282%292015-Dialogue.pdf)。

Siwei Lai、Liheng Xu、Kang Liu 和 Jun Zhao 创建了一种用于文本分类的递归卷积神经网络，无需人工设计的特征，并在[递归卷积神经网络用于文本分类](https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552)中描述了该模型。他们的模型与现有的文本分类方法如词袋模型、二元组+ LR、SVM、LDA、树核、递归神经网络和CNN进行了比较。结果表明，他们的模型在所有使用的数据集上优于传统方法[[8]](https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552)。

### 5\. 长短期记忆（LSTM）

![](../Images/fbc3b4f78b901a963f9dcd7f21f5233b.png)

带有输入、输出和遗忘门的窥视LSTM块。([https://upload.wikimedia.org/wikipedia/commons/5/53/Peephole_Long_Short-Term_Memory.svg](https://upload.wikimedia.org/wikipedia/commons/5/53/Peephole_Long_Short-Term_Memory.svg))

长短期记忆（LSTM）是一种特定的递归神经网络（RNN）架构，旨在比传统的 RNN 更准确地建模时间序列及其长距离依赖关系[[9]](https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/ListenTerm1201415/sak2.pdf)。LSTM 在其递归组件中不使用激活函数，存储的值不会被修改，并且梯度在训练过程中不会消失。通常，LSTM 单元以“块”形式实现，每个块包含多个单元。这些块有三个或四个“门”（例如，输入门、遗忘门、输出门），利用逻辑函数来控制信息流。

在[用于大规模声学建模的长短期记忆递归神经网络架构](https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/ListenTerm1201415/sak2.pdf)中，Hasim Sak、Andrew Senior 和 Françoise Beaufays 展示了深层 LSTM RNN 架构在大规模声学建模中的先进性能。

在 Peilu Wang、Yao Qian、Frank K. Soong、Lei He 和 Hai Zhao 的[双向长短期记忆递归神经网络的词性标注](https://arxiv.org/pdf/1510.06168.pdf)工作中，提出了一种用于[词性标注（POS）](https://en.wikipedia.org/wiki/Part-of-speech_tagging)的模型[[10]](https://arxiv.org/pdf/1510.06168.pdf)。该模型实现了 97.40% 的标注准确率。苹果、亚马逊、谷歌、微软等公司将 LSTM 作为其产品的基础元素。

### 6\. 序列到序列模型

通常，序列到序列模型由两个递归神经网络组成：一个处理输入的[编码器](https://en.wikipedia.org/wiki/Artificial_neural_network#Encoder.E2.80.93decoder_networks)和一个生成输出的[解码器](https://en.wikipedia.org/wiki/Artificial_neural_network#Encoder.E2.80.93decoder_networks)。编码器和解码器可以使用相同或不同的参数集。

Sequence-to-Sequence 模型主要用于问答系统、聊天机器人和机器翻译。这种多层单元在[使用神经网络的序列到序列学习研究](https://arxiv.org/pdf/1409.3215.pdf) [[11]](https://arxiv.org/pdf/1409.3215.pdf)中的序列到序列模型翻译中得到了成功应用。

在[使用递归自编码器进行释义检测](https://nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf)中，提出了一种新颖的递归自编码器架构。这些表示是 n 维语义空间中的向量，具有相似意义的短语彼此接近[[12]](https://nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf)。

### 7\. 浅层神经网络

除了深度神经网络，浅层模型也是流行且有用的工具。例如，[word2vec](https://ru.wikipedia.org/wiki/Word2vec)是一组用于生成[word embeddings](https://en.wikipedia.org/wiki/Word_embedding)的浅层二层模型。在[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)中提出，word2vec以大量文本语料作为输入，生成一个向量空间[[13]](https://arxiv.org/pdf/1301.3781.pdf)。语料中的每个词汇在这个空间中都会获得对应的向量。其显著特点是语料中来自常见上下文的词汇在向量空间中彼此靠近。

### 摘要

在这篇论文中，我们描述了不同变体的人工神经网络，如深度多层感知器（MLP）、卷积神经网络（CNN）、递归神经网络（RNN）、循环神经网络（RNN）、长短期记忆（LSTM）、序列到序列模型，以及包括word2vec在内的浅层神经网络用于词嵌入。我们展示了这些网络的功能以及它们在自然语言处理任务中的不同应用。我们演示了卷积神经网络主要用于文本分类任务，而递归神经网络则常用于自然语言生成或机器翻译。在本系列的下一部分中，我们将研究讨论过的神经网络类型的现有工具和库。

**资源**

1.  [http://www.aclweb.org/anthology/D14-1181](http://www.aclweb.org/anthology/D14-1181)

1.  [https://arxiv.org/pdf/1502.01710.pdf](https://arxiv.org/pdf/1502.01710.pdf)

1.  [http://www.aclweb.org/anthology/P15-1128](http://www.aclweb.org/anthology/P15-1128)

1.  [https://www.aclweb.org/anthology/K15-1013](https://www.aclweb.org/anthology/K15-1013)

1.  [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)

1.  [https://en.wikipedia.org/wiki/Recursive_neural_network](https://en.wikipedia.org/wiki/Recursive_neural_network)

1.  [http://www.meanotek.ru/files/TarasovDS(2)2015-Dialogue.pdf](http://www.meanotek.ru/files/TarasovDS%282%292015-Dialogue.pdf)

1.  [https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552](https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745/9552)

1.  [https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/ListenTerm1201415/sak2.pdf](https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/ListenTerm1201415/sak2.pdf)

1.  [https://arxiv.org/pdf/1510.06168.pdf](https://arxiv.org/pdf/1510.06168.pdf)

1.  [https://arxiv.org/pdf/1409.3215.pdf](https://arxiv.org/pdf/1409.3215.pdf)

1.  [https://nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf](https://nlp.stanford.edu/courses/cs224n/2011/reports/ehhuang.pdf)

1.  [https://arxiv.org/pdf/1301.3781.pdf](https://arxiv.org/pdf/1301.3781.pdf)

**[数据怪物](https://datamonsters.co/)** 帮助公司和获得资助的初创企业研究、设计和开发实时智能软件，以利用数据技术提升业务。

[原文](https://medium.com/@datamonsters/artificial-neural-networks-for-natural-language-processing-part-1-64ca9ebfa3b2)。已获许可转载。

**相关：**

+   [机器学习翻译与谷歌翻译算法](/2017/09/machine-learning-translation-google-translate-algorithm.html)

+   [5 个免费资源，帮助你入门深度学习自然语言处理](/2017/07/5-free-resources-getting-started-deep-learning-nlp.html)

+   [我如何在过去 2 个月开始学习 AI](/2017/10/how-started-learning-ai.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行 IT 支持

* * *

### 更多相关话题

+   [是什么让 Python 成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [停止学习数据科学来寻找目标，找寻目标再……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [一个 90 亿美元的 AI 失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [每位数据科学家都应该了解的三个 R 语言库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)
