- en: Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models](https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](../Images/ce3a364e3caa086c1d829b53449f1791.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created with DALL-E3
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence has been a complete revolution in the tech world.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Its ability to mimic human intelligence and perform tasks that were once considered
    solely human domains still amazes most of us.
  prefs: []
  type: TYPE_NORMAL
- en: However, no matter how good these late AI leap forwards have been, there’s always
    room for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: And this is precisely where prompt engineering kicks in!
  prefs: []
  type: TYPE_NORMAL
- en: Enter this field that can significantly enhance the productivity of AI models.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discover it all together!
  prefs: []
  type: TYPE_NORMAL
- en: The Essence of Prompt Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prompt engineering is a fast-growing domain within AI that focuses on improving
    the efficiency and effectiveness of language models. It’s all about crafting perfect
    prompts to guide AI models to produce our desired outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Think of it as learning how to give better instructions to someone to ensure
    they understand and execute a task correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Why Prompt Engineering Matters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Enhanced Productivity:** By using high-quality prompts, AI models can generate
    more accurate and relevant responses. This means less time spent on corrections
    and more time leveraging AI’s capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost Efficiency:** Training AI models is resource-intensive. Prompt engineering
    can reduce the need for retraining by optimizing model performance through better
    prompts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Versatility:** A well-crafted prompt can make AI models more versatile, allowing
    them to tackle a broader range of tasks and challenges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before diving into the most advanced techniques, let’s recall two of the most
    useful (and basic) prompt engineering techniques.
  prefs: []
  type: TYPE_NORMAL
- en: A Glimpse into Basic Prompt Engineering Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sequential Thinking with “Let’s think step by step”
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today it is well-known that LLM models’ accuracy is significantly improved when
    adding the word sequence “Let’s think step by step”.
  prefs: []
  type: TYPE_NORMAL
- en: Why… you might ask?
  prefs: []
  type: TYPE_NORMAL
- en: Well, this is because we are forcing the model to break down any task into multiple
    steps, thus making sure the model has enough time to process each of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, I could challenge GPT3.5 with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: If John has 5 pears, then eats 2, buys 5 more, then gives 3 to his friend, how
    many pears does he have?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The model will give me an answer right away. However, if I add the final “Let’s
    think step by step”, I am forcing the model to generate a thinking process with
    multiple steps.
  prefs: []
  type: TYPE_NORMAL
- en: Few-Shot Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the Zero-shot prompting refers to asking the model to perform a task without
    providing any context or previous knowledge, the few-shot prompting technique
    implies that we present the LLM with a few examples of our desired output along
    with some specific question.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we want to come up with a model that defines any term using
    a poetic tone, it might be quite hard to explain. Right?
  prefs: []
  type: TYPE_NORMAL
- en: However, we could use the following few-shot prompts to steer the model in the
    direction we want.
  prefs: []
  type: TYPE_NORMAL
- en: Your task is to answer in a consistent style aligned with the following style.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<user>**: Teach me about resilience.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<system>**: Resilience is like a tree that bends with the wind but never
    breaks.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is the ability to bounce back from adversity and keep moving forward.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<user>**: Your input here.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you have not tried it out yet, you can go challenge GPT.
  prefs: []
  type: TYPE_NORMAL
- en: However, as I am pretty sure most of you already know these basic techniques,
    I will try to challenge you with some advanced techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Prompt Engineering techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Chain of Thought (CoT) Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Introduced by [Google in 2022](https://arxiv.org/abs/2201.11903), this method
    involves instructing the model to undergo several reasoning stages before delivering
    the ultimate response.
  prefs: []
  type: TYPE_NORMAL
- en: Sounds familiar right? If so, you are totally right.
  prefs: []
  type: TYPE_NORMAL
- en: It is like merging both Sequential Thinking and Few-Shot Prompting.
  prefs: []
  type: TYPE_NORMAL
- en: How?
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, CoT prompting directs the LLM to process information sequentially.
    This means we exemplify how to solve a first problem with multiple steps reasoning
    and then send to the model our real task, expecting it to emulate a comparable
    chain of thought when responding to the actual query we want it to solve.
  prefs: []
  type: TYPE_NORMAL
- en: '![Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](../Images/2a7d5fcfa8df7cbef187c9ce7298f57a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image taken from the [paper](https://arxiv.org/abs/2201.11903).
  prefs: []
  type: TYPE_NORMAL
- en: So, following the very first example, we could provide a prompt with the first
    problem and a sequential explanation of how to solve it. Then, we can send our
    input and see how magic happens!
  prefs: []
  type: TYPE_NORMAL
- en: '**<user>** If John has 5 pears, then eats 2, buys 5 more, then gives 3 to his
    friend, how many pears does he have? Let’s think step by step.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<agent>** Let’s go step by step. John starts with 5 pears. He eats 2 pears,
    so he has 5–2 = 3 pears left. Then, he buys 5 more pears. So, he now has 3 + 5
    = 8 pears. Finally, he gives 3 pears to his friend. Therefore, he has 8–3 = 5
    pears left. So, after all these steps, John has 5 pears.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<user>** Your input here.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: However, most of you must be thinking… Do I have to think of a sequential way
    to solve any problem any time I want to ask something on ChatGPT?
  prefs: []
  type: TYPE_NORMAL
- en: Well… you are not the first one! And this leads us to…
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Automatic Chain-of-Thought (Auto-CoT)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In 2022, [Zhang](https://arxiv.org/abs/2210.03493) and colleagues introduced
    a method to avoid this manual process. There are two main reasons to avoid any
    manual task:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be boring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can yield bad results - for instance, when our mental process is wrong.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They suggested using LLMs combined with the "Let's think step by step" prompt
    to sequentially produce reasoning chains for each demonstration.
  prefs: []
  type: TYPE_NORMAL
- en: This means asking ChatGPT how to solve any problem sequentially and then using
    this very same example to train it how to solve any other problem.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Self-Consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Self-consistency is another interesting prompting technique that aims to improve
    the chain of thought prompting for more complex reasoning problems.
  prefs: []
  type: TYPE_NORMAL
- en: So… what’s the main difference?
  prefs: []
  type: TYPE_NORMAL
- en: 'The main idea under Self-Consistency is being aware that we can train the model
    with a wrong example. Just imagine I solve the previous problem with a wrong mental
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '**<User>** If John has 5 pears, then eats 2, buys 5 more, then gives 3 to his
    friend, how many pears does he have? Let’s think step by step.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<Agent>** Start with 5 pears. John eats 2 pears. Then, he gives 3 pears to
    his friend. These actions can be combined: 2 (eaten) + 3 (given) = 5 pears in
    total affected. Now, subtract the total pears affected from the initial 5 pears:
    5 (initial) - 5 (affected) = 0 pears left.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Then, any other task I send to the model will be wrong.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is why Self-Consistency involves sampling from various reasoning paths,
    each of them containing a chain of thought, and then letting the LLM choose the
    best and most consistent path to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](../Images/07b661d8f983b82ca1f7f2e6938338de.png)'
  prefs: []
  type: TYPE_IMG
- en: Image taken from the [paper](https://arxiv.org/abs/2203.11171?ref=mlq.ai)
  prefs: []
  type: TYPE_NORMAL
- en: In this case, and following the very first example again, we can show the model
    different ways of solving the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**<User>** If John has 5 pears, then eats 2, buys 5 more, then gives 3 to his
    friend, how many pears does he have?'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<Agent>** Start with 5 pears. John eats 2 pears, leaving him with 5–2 = 3
    pears. He buys 5 more pears, which brings the total to 3 + 5 = 8 pears. Finally,
    he gives 3 pears to his friend, so he has 8–3 = 5 pears left.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<User>** If John has 5 pears, then eats 2, buys 5 more, then gives 3 to his
    friend, how many pears does he have?'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<Agent>** Start with 5 pears. He then buys 5 more pears. John eats 2 pears
    now.  These actions can be combined: 2 (eaten) + 5 (bought) = 7 pears in total.
    Subtract the pear that Jon has eaten from the total amount of pears 7 (total amount)
    - 2 (eaten) = 5 pears left.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**<User>** Your input here.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And here comes the last technique.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. General Knowledge Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common practice of prompt engineering is augmenting a query with additional
    knowledge before sending the final API call to GPT-3 or GPT-4.
  prefs: []
  type: TYPE_NORMAL
- en: According to [Jiacheng Liu and Co](https://arxiv.org/pdf/2110.08387.pdf?ref=mlq.ai),
    we can always add some knowledge to any request so the LLM knows better about
    the question.
  prefs: []
  type: TYPE_NORMAL
- en: '![Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](../Images/4189d478dcc00efd9c7334b8a686de91.png)'
  prefs: []
  type: TYPE_IMG
- en: Image taken from the [paper](https://arxiv.org/pdf/2110.08387.pdf?ref=mlq.ai).
  prefs: []
  type: TYPE_NORMAL
- en: So for instance, when asking ChatGPT if part of golf is trying to get a higher
    point total than others, it will validate us. But, the main goal of golf is quite
    the opposite. This is why we can add some previous knowledge telling it “The player
    with the lower score wins”.
  prefs: []
  type: TYPE_NORMAL
- en: '![Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](../Images/5a397bad9a0e8a5af2f46cb6b5923543.png)'
  prefs: []
  type: TYPE_IMG
- en: So.. what’s the funny part if we are telling the model exactly the answer?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, this technique is used to improve the way LLM interacts with us.
  prefs: []
  type: TYPE_NORMAL
- en: So rather than pulling supplementary context from an outside database, the paper's
    authors recommend having the LLM produce its own knowledge. This self-generated
    knowledge is then integrated into the prompt to bolster commonsense reasoning
    and give better outputs.
  prefs: []
  type: TYPE_NORMAL
- en: So this is how LLMs can be improved without increasing its training dataset!
  prefs: []
  type: TYPE_NORMAL
- en: Concluding Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prompt engineering has emerged as a pivotal technique in enhancing the capabilities
    of LLM. By iterating and improving prompts, we can communicate in a more direct
    manner to AI models and thus obtain more accurate and contextually relevant outputs,
    saving both time and resources.
  prefs: []
  type: TYPE_NORMAL
- en: For tech enthusiasts, data scientists, and content creators alike, understanding
    and mastering prompt engineering can be a valuable asset in harnessing the full
    potential of AI.
  prefs: []
  type: TYPE_NORMAL
- en: By combining carefully designed input prompts with these more advanced techniques,
    having the skill set of prompt engineering will undoubtedly give you an edge in
    the coming years.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Kick Ass Midjourney Prompts with Poe](https://www.kdnuggets.com/kick-ass-midjourney-prompts-with-poe)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prompt Engineering 101: Mastering Effective LLM Communication](https://www.kdnuggets.com/prompt-engineering-101-mastering-effective-llm-communication)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Things Aren''t Always Normal: Some of the "Other" Distributions](https://www.kdnuggets.com/2023/01/things-arent-always-normal-distributions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[It''s alive! Build your first robots with Python and some cheap,…](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[I Used ChatGPT (Every Day) for 5 Months. Here Are Some Hidden Gems…](https://www.kdnuggets.com/2023/07/used-chatgpt-every-day-5-months-hidden-gems-change-life.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
