- en: 6 Common Mistakes in Data Science and How To Avoid Them
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学中的六个常见错误及如何避免
- en: 原文：[https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html](https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html](https://www.kdnuggets.com/2020/09/6-common-data-science-mistakes.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![](../Images/97882db692355f38fadc7052f944aab0.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97882db692355f38fadc7052f944aab0.png)'
- en: '*Photo by [chuttersnap](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral).*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*照片由 [chuttersnap](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 提供。*'
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: In data science or machine learning, we use data for descriptive analytics to
    draw out meaningful conclusions from the data, or we can use data for predictive
    purposes to build models that can make predictions on unseen data. The reliability
    of any model depends on the level of expertise of the data scientist. It is one
    thing to build a machine learning model. It is another thing to ensure the model
    is optimal and of the highest quality. This article will discuss six common mistakes
    that can adversely influence the quality or predictive power of a machine learning
    model with several case studies included.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学或机器学习中，我们使用数据进行描述性分析，以从数据中得出有意义的结论，或者我们可以将数据用于预测目的，建立可以对未见数据进行预测的模型。任何模型的可靠性取决于数据科学家的专业水平。构建一个机器学习模型是一回事，确保模型最优且质量最高是另一回事。本文将讨论六个常见错误，这些错误可能会对机器学习模型的质量或预测能力产生不利影响，并包含几个案例研究。
- en: 6 Common Mistakes in Data Science
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据科学中的六个常见错误
- en: In this section, we discuss six common mistakes that can severely impact the
    quality of a data science model. Links to several real applications are included.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论六个常见错误，这些错误可能严重影响数据科学模型的质量。包含了几个实际应用的链接。
- en: '**We often assume that our dataset is of good quality and reliable**'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们经常假设我们的数据集质量良好且可靠**'
- en: 'Data is key to any data science and machine learning task. Data comes in different
    flavors such as numerical data, categorical data, text data, image data, voice
    data, and video data. ***The predictive power of a model depends on the quality
    of data used in building the model***. It is therefore extremely important that
    before performing any data science task such as exploratory data analysis or building
    a model, you check the source and reliability of your data because even datasets
    that appear perfect may contain errors. There are several factors that could diminish
    the quality of your data:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何数据科学和机器学习任务的关键。数据有不同的形式，如数值数据、分类数据、文本数据、图像数据、语音数据和视频数据。***模型的预测能力取决于用于构建模型的数据质量***。因此，在执行任何数据科学任务如探索性数据分析或构建模型之前，检查数据的来源和可靠性是极其重要的，因为即使是看似完美的数据集也可能包含错误。有几个因素可能会降低数据的质量：
- en: Wrong Data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误数据
- en: Missing Data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失数据
- en: Outliers in Data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中的离群值
- en: Redundancy in Data
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据冗余
- en: Unbalanced Data
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据不平衡
- en: Lack of Variability in Data
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据缺乏变异性
- en: Dynamic Data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态数据
- en: Size of Data
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据规模
- en: 'For more information, please see the following article: [Data is Always Imperfect.](https://medium.com/towards-artificial-intelligence/data-is-always-imperfect-8611d667dd10)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，请参阅以下文章：[数据总是不完美的。](https://medium.com/towards-artificial-intelligence/data-is-always-imperfect-8611d667dd10)
- en: From my personal experience working on an industrial data science project, my
    team had to work with system engineers, electrical engineers, mechanical engineers,
    field engineers, and technicians over a period of 3 months just to understand
    the available dataset and how we could use it to frame the right questions to
    be answered using the data. Ensuring that your data is error-free and of high
    quality will help improve the accuracy and reliability of your model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我个人在工业数据科学项目中的经验，我的团队花了3个月的时间与系统工程师、电气工程师、机械工程师、现场工程师和技术员合作，才理解现有的数据集以及如何利用这些数据提出正确的问题。确保数据无误且质量高将有助于提高模型的准确性和可靠性。
- en: '**Don’t focus on using the entire dataset**'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不要专注于使用整个数据集**'
- en: Sometimes as a data science aspirant, when you have to work on a data science
    project, you may be tempted to use the entire dataset provided. However, as already
    mentioned above, a dataset could have several imperfections, such as the presence
    of outliers, missing values, and redundant features. If the fraction of your dataset
    containing imperfections is really small, then you may simply eliminate the subset
    of imperfect data from your dataset. However, if the proportion of improper data
    is significant, then methods such as data imputation techniques could be used
    to approximate missing data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 有时作为一个数据科学初学者，当你需要处理一个数据科学项目时，你可能会被诱惑使用提供的整个数据集。然而，如上所述，数据集可能存在若干缺陷，如异常值、缺失值和冗余特征。如果你的数据集中存在缺陷的数据部分非常小，你可以简单地从数据集中删除这些不完美的数据子集。然而，如果不适当数据的比例显著，则可以使用数据插补技术来近似缺失数据。
- en: 'Before implementing a machine learning algorithm, it is necessary to select
    only relevant features in the training dataset. The process of transforming a
    dataset in order to select only relevant features necessary for training is called
    dimensionality reduction. Feature selection and dimensionality reduction are important
    because of three main reasons:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施机器学习算法之前，有必要只选择训练数据集中相关的特征。将数据集转化为只选择训练所需的相关特征的过程称为降维。特征选择和降维很重要，主要有三个原因：
- en: '**a) Prevents Overfitting**: A high-dimensional dataset having too many features
    can sometimes lead to overfitting (model captures both real and random effects).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**a) 防止过拟合**：一个具有过多特征的高维数据集有时可能导致过拟合（模型捕捉到真实和随机效应）。'
- en: '**b) Simplicity**: An over-complex model having too many features can be hard
    to interpret, especially when features are correlated with each other.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**b) 简洁性**：一个特征过多的过于复杂的模型可能难以解释，特别是当特征之间相关时。'
- en: '**c) Computational Efficiency**: A model trained on a lower-dimensional dataset
    is computationally efficient (execution of algorithm requires less computational
    time).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**c) 计算效率**：在低维数据集上训练的模型计算效率高（算法执行所需的计算时间更少）。'
- en: 'For more information about dimensionality reduction techniques, please see
    the following articles:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有关降维技术的更多信息，请参阅以下文章：
- en: '[Feature Selection and Dimensionality Reduction Using Covariance Matrix Plot](https://medium.com/towards-artificial-intelligence/feature-selection-and-dimensionality-reduction-using-covariance-matrix-plot-b4c7498abd07)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用协方差矩阵图进行特征选择和降维](https://medium.com/towards-artificial-intelligence/feature-selection-and-dimensionality-reduction-using-covariance-matrix-plot-b4c7498abd07)'
- en: '[Machine Learning: Dimensionality Reduction via Principal Component Analysis](https://medium.com/towards-artificial-intelligence/machine-learning-dimensionality-reduction-via-principal-component-analysis-1bdc77462831)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习：通过主成分分析进行降维](https://medium.com/towards-artificial-intelligence/machine-learning-dimensionality-reduction-via-principal-component-analysis-1bdc77462831)'
- en: Using dimensionality reduction techniques to remove unnecessary correlations
    between features could help improve the quality and predictive power of your machine
    learning model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用降维技术去除特征之间的不必要相关性可能有助于提高你的机器学习模型的质量和预测能力。
- en: '**Scale your data before using it for model building**'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在使用数据进行模型构建之前对数据进行缩放**'
- en: Scaling your features will help improve the quality and predictive power of
    your model. For example, suppose you would like to build a model to predict a
    target variable *creditworthiness* based on predictor variables such as *income*
    and *credit score*. Because credit scores range from 0 to 850 while annual income
    could range from $25,000 to $500,000, without scaling your features, the model
    will be biased towards the *income* feature. This means the weight factor associated
    with the *income* parameter will be very small, which will cause the predictive
    model to be predicting *creditworthiness* based only on the *income* parameter.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放你的特征将有助于提高模型的质量和预测能力。例如，假设你希望建立一个模型来预测目标变量*信用度*，基于预测变量如*收入*和*信用评分*。由于信用评分的范围从0到850，而年收入的范围可能从25,000美元到500,000美元，如果不对特征进行缩放，模型将会偏向于*收入*特征。这意味着与*收入*参数相关的权重因子将非常小，这将导致预测模型仅仅基于*收入*参数来预测*信用度*。
- en: In order to bring features to the same scale, we could decide to use either
    normalization or standardization of features. Most often, we assume data is normally
    distributed and default towards standardization, but that is not always the case.
    It is important that before deciding whether to use either standardization or
    normalization, you first take a look at how your features are statistically distributed.
    If the feature tends to be uniformly distributed, then we may use normalization
    (*MinMaxScale*r). If the feature is approximately Gaussian, then we can use standardization
    (*StandardScaler*). Again, note that whether you employ normalization or standardization,
    these are also approximative methods and are bound to contribute to the overall
    error of the model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将特征缩放到相同的尺度，我们可以选择对特征进行标准化或归一化。通常情况下，我们假设数据呈正态分布，并默认使用标准化，但这并非总是如此。在决定使用标准化还是归一化之前，重要的是先查看特征的统计分布。如果特征趋向于均匀分布，则可以使用归一化（*MinMaxScaler*）。如果特征大致呈高斯分布，则可以使用标准化（*StandardScaler*）。再次注意，无论你使用归一化还是标准化，这些方法都是近似的，并且会对模型的总体误差产生影响。
- en: '**Tune hyperparameters in your model**'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**调整模型中的超参数**'
- en: 'Using the wrong hyperparameter values in your model could lead to a non-optimal
    and low-quality model. It is important that you train your model against all hyperparameters
    in order to determine the model with optimal performance. A good example of how
    the predictive power of a model depends on hyperparameters can be found in the
    figure below (source: [Bad and Good Regression Analysis](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff)).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型中使用错误的超参数值可能导致模型非最优且质量较低。重要的是你需要对所有超参数进行训练，以确定性能最佳的模型。模型的预测能力如何依赖于超参数的一个很好的示例可以在下面的图中找到（来源：[差劲与优秀的回归分析](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff)）。
- en: '![](../Images/87bb2bae300c321cf46483dfefaa6cd2.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87bb2bae300c321cf46483dfefaa6cd2.png)'
- en: '**Figure 1**. Regression analysis using different values of the learning rate
    parameter. Source: [Bad and Good Regression Analysis](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff),
    Published in Towards AI, February 2019, by Benjamin O. Tayo.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1**。使用不同学习率参数进行回归分析。来源：[差劲与优秀的回归分析](https://medium.com/towards-artificial-intelligence/bad-and-good-regression-analysis-700ca9b506ff)，发布于
    Towards AI，2019年2月，由 Benjamin O. Tayo 编写。'
- en: 'Keep in mind that using default hyperparameters will not always lead to an
    optimal model. For more information about hyperparameters, please see this article:
    [Model Parameters and Hyperparameters in Machine Learning — What is the difference](https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，使用默认超参数并不总能得到最佳模型。有关超参数的更多信息，请参见本文：[机器学习中的模型参数和超参数 — 有什么区别](https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6)。
- en: '**Compare different algorithms**'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**比较不同算法**'
- en: 'It is important to compare the predictive power of several different algorithms
    before selecting your final model. For example, if you are building a ***classification
    model***, you may try the following algorithms:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择最终模型之前，比较几个不同算法的预测能力是很重要的。例如，如果你正在构建一个***分类模型***，你可以尝试以下算法：
- en: Logistic Regression classifier
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归分类器
- en: Support Vector Machines (SVM)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: Decision tree classifier
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树分类器
- en: K-nearest neighbor classifier
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-最近邻分类器
- en: Naive Bayes classifier
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器
- en: 'If you are building a ***linear regression model***, you may compare the following
    algorithms:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在构建一个***线性回归模型***，你可以比较以下算法：
- en: Linear regression
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: K-neighbors regression (KNR)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K-邻近回归（KNR）
- en: Support Vector Regression (SVR)
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量回归（SVR）
- en: 'For more information about comparing different algorithms, please see the following
    articles:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有关比较不同算法的更多信息，请参阅以下文章：
- en: '[A Comparative Study of Linear and KNN Regression](https://medium.com/towards-artificial-intelligence/a-comparative-study-of-linear-and-knn-regression-a31955e6263d)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与KNN回归的比较研究](https://medium.com/towards-artificial-intelligence/a-comparative-study-of-linear-and-knn-regression-a31955e6263d)'
- en: '[Machine Learning Process Tutorial](https://medium.com/swlh/machine-learning-process-tutorial-222327f53efb)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习过程教程](https://medium.com/swlh/machine-learning-process-tutorial-222327f53efb)'
- en: '**Quantify random error and uncertainties in your model**'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量化模型中的随机误差和不确定性**'
- en: 'Every machine learning model has an inherent random error. This error arises
    from the inherent random nature of the dataset; from the random nature in which
    the dataset is partitioned into training and testing sets during model building;
    or from randomization of the target column (a method used for detecting overfitting).
    It is important to always quantify how random error affects the predictive power
    of your model. This would help improve the reliability and quality of your model.
    For more information about random error quantification, please see the following
    article: [Random Error Quantification in Machine Learning](https://medium.com/towards-artificial-intelligence/random-error-quantification-in-machine-learning-846f6e78e519).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 每个机器学习模型都有固有的随机误差。这种误差源于数据集的固有随机特性；源于在模型构建过程中数据集被划分为训练集和测试集的随机方式；或者源于目标列的随机化（用于检测过拟合的方法）。始终量化随机误差对模型预测能力的影响是非常重要的。这将有助于提高模型的可靠性和质量。有关随机误差量化的更多信息，请参见以下文章：[机器学习中的随机误差量化](https://medium.com/towards-artificial-intelligence/random-error-quantification-in-machine-learning-846f6e78e519)。
- en: Summary
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: In summary, we have discussed six common mistakes that can influence the quality
    or predictive power of a machine learning model. It is useful to always ensure
    that your model is optimal and of the highest quality. Avoiding the mistakes discussed
    above can enable a data science aspirant to build reliable and trustworthy models.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们讨论了六个常见的错误，这些错误可能影响机器学习模型的质量或预测能力。始终确保你的模型是最佳的且质量最高是非常有用的。避免上述讨论的错误可以帮助数据科学爱好者构建可靠和值得信赖的模型。
- en: '**Related:**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Data Quality Assessment Is Not All Roses. What Challenges Should You Be Aware
    Of?](https://www.kdnuggets.com/2019/09/data-quality-assessment-challenges.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据质量评估并非全是美好。你应该意识到哪些挑战？](https://www.kdnuggets.com/2019/09/data-quality-assessment-challenges.html)'
- en: '[Must-Know: What are common data quality issues for Big Data and how to handle
    them?](https://www.kdnuggets.com/2017/05/must-know-common-data-quality-issues-big-data.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[必须知道：大数据常见的数据质量问题及其处理方法](https://www.kdnuggets.com/2017/05/must-know-common-data-quality-issues-big-data.html)'
- en: '[Data Scientists think data is their #1 problem. Here’s why they’re wrong.](https://www.kdnuggets.com/2020/09/data-scientist-data-problem-wrong.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家认为数据是他们的头号问题。这就是他们错在哪里。](https://www.kdnuggets.com/2020/09/data-scientist-data-problem-wrong.html)'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个常见的数据科学错误及如何避免](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免这些每个 AI 初学者都会犯的 5 个常见错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
- en: '[5 Common Python Gotchas (And How To Avoid Them)](https://www.kdnuggets.com/5-common-python-gotchas-and-how-to-avoid-them)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个常见的 Python 问题（及如何避免）](https://www.kdnuggets.com/5-common-python-gotchas-and-how-to-avoid-them)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Crucial Challenges in Conversational AI Development and How to Avoid Them](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对话式 AI 开发中的 3 个关键挑战及如何避免](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
- en: '[10 Most Common Data Quality Issues and How to Fix Them](https://www.kdnuggets.com/2022/11/10-common-data-quality-issues-fix.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10 个最常见的数据质量问题及其解决方法](https://www.kdnuggets.com/2022/11/10-common-data-quality-issues-fix.html)'
