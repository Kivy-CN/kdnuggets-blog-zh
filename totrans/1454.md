# 数据科学中没有免费的午餐

> 原文：[https://www.kdnuggets.com/2019/09/no-free-lunch-data-science.html](https://www.kdnuggets.com/2019/09/no-free-lunch-data-science.html)

[评论](#comments)

**由[悉尼·费尔敏](https://www.linkedin.com/in/sydney-firmin-4369a65b/)，Alteryx**。

在你机器学习的历程中，你可能已经遇到过“没有免费午餐”定理。借用这一定理的名字来源于谚语“[没有免费的午餐](https://en.wikipedia.org/wiki/There_ain%27t_no_such_thing_as_a_free_lunch)”，[数学民间定理](https://en.wikipedia.org/wiki/Mathematical_folklore)描述了一个现象：没有一种算法能在所有可能的场景和数据集上表现最佳。

### 没有免费午餐定理

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT

* * *

一般来说，有两个“没有免费午餐”（NFL）定理：一个是机器学习的，另一个是搜索和优化的。这两个定理是相关的，通常被合并为一个通用的公理（民间定理）。

尽管许多不同的研究人员为“没有免费午餐”定理的集体出版物做出了贡献，但与这些工作最相关的名字是David Wolpert。

**没有监督学习的免费午餐**

在他1996年的论文[《学习算法之间的先验区分缺失》](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.390.9412&rep=rep1&type=pdf)中，David Wolpert研究了在不对目标变量做任何假设的情况下，是否可以通过训练数据集和学习算法获得有用的理论结果。

Wolpert在他1996年的论文中（通过一系列数学证明）证明了：在给定一个无噪声数据集（即，没有随机变化，只有趋势）和一个以错误率为成本函数的机器学习算法时，当用[泛化误差率](https://en.wikipedia.org/wiki/Generalization_error)（模型在验证数据集上的误差率）进行评估时，所有机器学习算法都是等效的。

延伸这一逻辑（同样，沃尔珀特用数学方程来说明），他证明了对于任意两个算法A和B，有同样多的场景中A的表现会比B差，也有同样多的场景中A的表现会优于B。这一点即使在其中一个算法是随机猜测时也成立。沃尔珀特证明了对于所有可能的领域（从均匀概率分布中提取的所有可能问题实例），算法A和B的平均性能是相同的。

![](../Images/8c6033a7e2b0fc288269ff8f6338bda7.png)

这是因为几乎所有的（[非机械记忆](https://en.wikipedia.org/wiki/Rote_learning#In_computer_science)）机器学习算法对预测变量和目标变量之间的关系做出了一些假设（称为 [归纳或学习偏差](https://en.wikipedia.org/wiki/Inductive_bias)），从而将 [偏差](https://en.wikipedia.org/wiki/Bias) 引入模型中。机器学习算法所做的假设意味着某些算法在某些数据集上的拟合效果优于其他算法。这也（按定义）意味着会有许多数据集是某个给定算法无法有效建模的。模型的有效性直接依赖于模型所做的假设与数据的真实特性之间的契合程度。

回到午餐的话题，你不能“免费”获得良好的机器学习。你必须利用你对数据及我们所生活的世界（或数据所在的世界）的知识来选择一个合适的机器学习模型。没有所谓的单一、普遍最佳的机器学习算法，也没有任何与背景或用途无关的（[先验](https://en.wikipedia.org/wiki/A_priori_and_a_posteriori)）理由去偏向某一个算法。

有趣的是，这篇1996年的论文是对哲学家 [大卫·休谟](https://en.wikipedia.org/wiki/David_Hume) 工作的数学化形式。我保证稍后会回到这个话题。

**没有免费的午餐**用于搜索和优化

沃尔珀特和麦克雷迪在1997年的论文 [优化的无免费午餐定理](https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf) 展示了类似的“无免费午餐”逻辑在数学领域中的应用，即搜索和优化。

无免费午餐定理对于搜索和优化表明，对于在有限搜索空间中的搜索/优化问题，当被搜索的点 *不* 被重新采样时，任何两个给定的搜索算法在所有可能问题上的性能是相同的。

例如，假设你在徒步寻找地球上的最高点（极值）。为了找到它，你可能总是选择朝着海拔升高的方向前进，表现得像是一个“爬山者”。

这在地球上会很好用，因为地球上最高的点是非常高的山脉的一部分。

![](../Images/e1de396b0d18eb1387393ab0e1dbfdf1.png)

现在，想象一下一个世界，其中地球上最高的点被地球上最低的点所包围。

![](../Images/3da553d6b50555fa7eb0ae68a5a9a464.png)

*这个家伙注定会失望。*

在这种情况下，始终下降海拔的搜索会表现得更好。

无论是爬山算法还是下坡算法在两个星球上都没有表现更好，这意味着随机搜索效果也一样（平均而言）。如果不能假设一个星球上的最高点会出现在其他高点附近（一个平滑的表面），我们无法知道爬山算法是否会比下坡算法表现更好。

归结起来：如果对优化程序没有先验假设，则没有优化策略可以预期比其他策略（包括随机搜索）表现更好。理论上，通用的优化策略是不可能实现的，唯一能使一种策略优于另一种策略的方法是让它专门针对当前特定问题。听起来熟悉吗？也没有免费的高效搜索优化。

在他的2012年论文 [无免费午餐定理的真正含义；如何改进搜索算法](https://sfi-edu.s3.amazonaws.com/sfi-edu/production/uploads/sfi-com/dev/uploads/filer/33/44/33440e97-fe46-4827-a1eb-a27196e1c49a/12-10-017.pdf) 中，Wolpert 讨论了搜索与监督学习之间的紧密关系及其对无免费午餐定理的影响。他证明，在无免费午餐定理的背景下，监督学习与搜索/优化非常相似。对于这两个定理，“搜索算法”似乎可以与“学习算法”互换，而“目标函数”与“目标函数”也是如此。

如果你对无免费午餐定理的每个方面感兴趣，可以参考 [http://www.no-free-lunch.org/](http://www.no-free-lunch.org/) 上的一个很好的总结资源，包括 David Wolpert 关于无免费午餐定理概述的 [幻灯片](http://www.no-free-lunch.org/coev.pdf)。如果你想要更哲学性的解释，可以阅读 [注意：没有免费的午餐，贝叶斯人也不例外](http://www.no-free-lunch.org/Fors99.pdf)。

### 我们对无免费午餐的认识是否准确？

无免费午餐定理 引发了大量的研究和学术出版物。这些出版物并不总是支持无免费午餐（因为谁不想要一个免费午餐呢？）。

“所有可能的问题”这一部分是无免费午餐定理的第一个难点。所有可能的问题并不反映现实世界的条件。实际上，许多人会认为，机器学习和优化所面对的“现实世界”问题，与所有问题中包含的许多领域完全不同。现实世界往往展示出某种模式和结构，而“所有可能的问题”空间则包含了完全随机或混乱的情境。

研究人员还从哲学的角度辩称 [反对取统一平均值](https://pdfs.semanticscholar.org/83cd/86c2c7e507e8ebba9563a9efaba7c966a1b3.pdf)来评估表现。如果你一只手放在热水中，另一只手冻在冰块里，平均而言你两只手的温度看起来正常。对算法表现进行平均可能会导致问题，因为某些算法在大多数问题上表现良好，但在一些边缘情况中却会失败得非常惨烈。

在实证研究中，已经证明一些算法的表现 consistently 优于其他算法。在2014年的论文 [我们是否需要数百个分类器来解决现实世界的分类问题](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf)中，研究人员发现，在所有的 [UCI机器学习库](https://archive.ics.uci.edu/ml/datasets.html?format=&task=&att=&area=life&numAtt=&numIns=&type=&sort=nameUp&view=table) (121个数据集)中，表现最佳的分类器家族包括随机森林、支持向量机(SVM)、神经网络和提升集成方法。

这是一个重要的考虑，因为似乎一些算法 consistently 排名前列或更频繁地被实施到生产环境中。然而，“没有免费的午餐”定理提醒我们每个模型所做的假设，以及我们（通常是无意识的）对数据及其采集环境所做的假设。

### **没有免费的午餐与大卫·休谟**

还记得我在大约800字前承诺会回到那个已故哲学家吗？这就是那个部分。

![](../Images/8e5ea3f3b34dde006bceb3c1d54f818f.png)

*这个家伙…*

[大卫·休谟](https://en.wikipedia.org/wiki/David_Hume)是18^(th)世纪的爱丁堡哲学家，特别关注怀疑主义和经验主义。他对[归纳问题](https://en.wikipedia.org/wiki/Problem_of_induction)进行了大量思考，这属于认识论（知识研究）领域。

为了深入探讨归纳问题，让我们首先将世界分为两种不同类型的知识：先验和后验（这一划分可以追溯到[伊曼努尔·康德](https://en.wikipedia.org/wiki/Immanuel_Kant)的研究）。

先验知识是指独立于经验而存在的知识。这种知识基于思想的关系，例如，2 + 2 = 4，或者一个八边形有八条边。这种知识无论外部世界如何都是真实的。

后验知识或“事实问题”是指需要经验或实证证据的知识。这种知识构成了大多数个人和科学知识。后验知识需要观察。

[归纳推理](https://en.wikipedia.org/wiki/Inductive_reasoning)是一种后验知识的推理方法，我们将观察到的规律模式应用于我们未直接观察过的实例；例如，我观察到的所有雨水都是湿的，因此，我未观察过的所有雨水也必须是湿的。

通过归纳，我们隐含地假设了[自然的统一性](https://en.wikipedia.org/wiki/Uniformitarianism)（有时称为统一性原则或相似性原则），即未来将始终类似于过去。

科学完全基于归纳推理。没有像自然统一性这样的假设，没有任何算法（包括像[科学方法](https://en.wikipedia.org/wiki/Scientific_method)或[交叉验证程序](https://en.wikipedia.org/wiki/Cross-validation_(statistics))这样的高级算法）可以*证明*比随机猜测表现更好。

休谟认为归纳推理和因果关系的信念*不能*被理性地证明。假设统一性没有理由。根据休谟的观点，归纳对人类来说是本能的，就像狗似乎本能地追逐兔子和松鼠一样。休谟并没有真正提出归纳的解决方案或证明——他只是有些耸肩地说，我们无法改变自己的本性，所以不必担心这个问题。（我在想象那种耸肩的样子。）

大卫·沃尔珀特对有监督机器学习的无免费午餐定理的研究是对休谟的形式化。沃尔珀特甚至在他的1996年论文开头引用了这句来自大卫·休谟的名言：

> *即使在观察到物体的频繁联结之后，我们也没有理由对我们没有直接观察过的物体做出任何推断。*
> 
> - 大卫·休谟在《人性论》第一卷第三部分第十二节中。

科学（以及机器学习模型）本质上相信在相同条件下，一切总是以相同的方式发生。没有理由假设因为一个模型在一个数据集上表现良好，它就会在其他数据集上表现良好。此外，科学、统计学和机器学习模型不能根据之前实验的结果对未来实验作出保证。没有系统可以在任何环境下对预测、控制或观察做出保证。

![](../Images/445f511b5797a6bc7b1279c8f02b7d0d.png)

如果你喜欢哲学的绕道，想要了解更多关于休谟和归纳问题的信息，Khan Academy上有一个很棒的视频叫做[休谟：怀疑主义与归纳，第2部分](https://www.khanacademy.org/partner-content/wi-phi/wiphi-history/wiphi-hume/v/humes-skepticism-and-induction-part-2)（[第1部分](https://www.khanacademy.org/partner-content/wi-phi/wiphi-history/wiphi-hume/v/humes-skepticism-part-1)讨论的是先验知识与后验知识）。

### 无免费午餐定理与你

如果你一直跟到这里，你可能在寻找这对你来说意味着什么的解释。从“无免费午餐”定理中可以得出的两个最重要的结论是：

+   **在依赖模型或搜索算法之前，始终检查你的假设。**

+   **没有“超级算法”可以完美适用于所有数据集。**

“无免费午餐”定理并不是为了告诉你在不同情境下应该怎么做。这些定理 是 特别写来反驳如下主张的：

我的机器学习算法/优化策略是 *最好的，永远都是*，适用于所有情境。

模型是对现实特定组件的简化（通过数据观察得出）。为了简化现实，机器学习算法或统计模型需要做出假设并引入偏差（具体称为 [归纳偏差](https://en.wikipedia.org/wiki/Inductive_bias)）。没有偏差的学习是徒劳的，因为一个没有先验假设的学习者在面对新的、未见过的输入数据时，将没有合理的基础来创建估计。一个算法的假设可能对某些数据集有效，但对其他数据集无效。理解这一现象对于理解 [欠拟合](https://en.wikipedia.org/wiki/Overfitting#Underfitting) 和 [偏差/方差权衡](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)的概念非常重要。

你的数据和随机选择的机器学习模型的组合不足以对未来或未知结果做出准确或有意义的预测。你，作为人类，需要对你的数据和我们生活的世界做出假设。积极参与假设的制定只会增强你的模型，使其更有用， [即使它们是错误的](https://community.alteryx.com/t5/Data-Science-Blog/All-Models-Are-Wrong/ba-p/348080)。

[原文](https://community.alteryx.com/t5/Data-Science-Blog/There-is-No-Free-Lunch-in-Data-Science/ba-p/347402)。经许可转载。

**个人简介：** Sydney Firmin是一名受过地理学培训的数据迷，[Sydney Firmin](https://www.linkedin.com/in/sydney-firmin-4369a65b/)坚信，数据和知识在能够清晰传达和理解时最具价值。在她目前担任高级数据科学内容工程师的角色中，她可以全天从事她最喜欢的工作：将技术知识和研究转化为引人入胜、富有创意和趣味的内容，为Alteryx社区提供服务。

**相关内容：**

+   [10种梯度下降优化算法 + 备忘单](https://www.kdnuggets.com/2019/06/gradient-descent-algorithms-cheat-sheet.html)

+   [优化如何工作](https://www.kdnuggets.com/2019/04/how-optimization-works.html)

+   [监督学习与非监督学习](https://www.kdnuggets.com/2018/04/supervised-vs-unsupervised-learning.html)

### 更多相关话题

+   [停止学习数据科学以寻找目标，并通过寻找目标来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [每位数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [9亿美元AI失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [是什么让Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)
