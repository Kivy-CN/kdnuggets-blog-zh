- en: 17 More Must-Know Data Science Interview Questions and Answers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 17个必须知道的数据科学面试问题及答案
- en: 原文：[https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2017/02/17-data-science-interview-questions-answers.html/2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2017/02/17-data-science-interview-questions-answers.html/2#comments)'
- en: The post [21 Must-Know Data Science Interview Questions and Answers](/2016/02/21-data-science-interview-questions-answers.html)
    was the [most viewed post of 2016](/2016/12/top-2016-kdnuggets-stories.html),
    with over 250,000 page views. For 2017, KDnuggets Editors bring you 17 more new
    and important Data Science Interview Questions and Answers. Because some of the
    answers are quite lengthy, we will publish them in 3 parts over 3 weeks. This
    is part 1, which answers the 6 questions below. Here is [part 2](/2017/02/17-data-science-interview-questions-answers-part-2.html)
    and [part 3](/2017/03/17-data-science-interview-questions-answers-part-3.html).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章 [21个必须知道的数据科学面试问题及答案](/2016/02/21-data-science-interview-questions-answers.html)
    是 [2016年最受欢迎的文章](/2016/12/top-2016-kdnuggets-stories.html)，拥有超过250,000次页面浏览。为了2017年，KDnuggets编辑为你带来17个新的重要数据科学面试问题及答案。由于一些答案较长，我们将在3周内分3部分发布。第一部分回答了以下6个问题。这里是
    [第二部分](/2017/02/17-data-science-interview-questions-answers-part-2.html) 和 [第三部分](/2017/03/17-data-science-interview-questions-answers-part-3.html)。
- en: 'This post answers questions:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章回答了以下问题：
- en: Q1\. What are Data Science lessons from failure to predict 2016 US Presidential
    election (and from Super Bowl LI comeback)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q1\. 从未能预测2016年美国总统选举（以及超级碗LI的逆转）中我们能学到什么数据科学课程？
- en: Q2\. What problems arise if the distribution of the new (unseen) test data is
    significantly different than the distribution of the training data?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q2\. 如果新（未见过的）测试数据的分布与训练数据的分布有显著不同，会出现什么问题？
- en: Q3\. What are bias and variance, and what are their relation to modeling data?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q3\. 什么是偏差和方差？它们与数据建模有什么关系？
- en: Q4\. Why might it be preferable to include fewer predictors over many?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q4\. 为什么选择更少的预测变量而不是多个预测变量可能更可取？
- en: Q5\. What error metric would you use to evaluate how good a binary classifier
    is? What if the classes are imbalanced? What if there are more than 2 groups?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q5\. 你会使用什么错误度量来评估一个二分类器的好坏？如果类别不平衡呢？如果有多个组呢？
- en: Q6\. What are some ways I can make my model more robust to outliers?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Q6\. 有哪些方法可以使我的模型对离群值更加稳健？
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你在IT方面的组织'
- en: '* * *'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Q1\. What are Data Science lessons from failure to predict 2016 US Presidential
    election (and from Super Bowl LI comeback)
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q1\. 从未能预测2016年美国总统选举（以及超级碗LI的逆转）中我们能学到什么数据科学课程？
- en: '**[Gregory Piatetsky](/author/gregory-piatetsky) answers:**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Gregory Piatetsky](/author/gregory-piatetsky) 答复：**'
- en: '![nytimes-upshot-forecast-trump-15](../Images/2a793244923ce511c11097d33450cdfc.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![nytimes-upshot-forecast-trump-15](../Images/2a793244923ce511c11097d33450cdfc.png)'
- en: Just before the Nov 8, 2016 election, most pollsters gave Hillary Clinton an
    edge of ~3% in popular vote and 70-95% chance of victory in electoral college.
    Nate Silver's FiveThirtyEight had the highest chances of Trump Victory at ~30%,
    while New York Times Upshot and Princeton Election Consortium estimated only ~15%,
    and other pollsters like Huffington Post gave Trump only 2% chance of victory.
    Still, Trump won. So what are the lessons for Data Scientists?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在2016年11月8日的选举前，大多数民意调查员给希拉里·克林顿的普选票优势约为3%，以及在选举团中获胜的概率为70-95%。Nate Silver的FiveThirtyEight对特朗普获胜的概率估计最高为约30%，而纽约时报的Upshot和普林斯顿选举联盟则估计只有约15%，其他民意调查员如《赫芬顿邮报》则仅给特朗普2%的获胜机会。然而，特朗普仍然获胜了。那么数据科学家可以从中学到什么？
- en: To make a statistically valid prediction we need
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做出统计上有效的预测，我们需要
- en: 1) enough historical data and
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 足够的历史数据和
- en: 2) assumption that past events are sufficiently similar to current event we
    are trying to predict.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 假设过去的事件与我们试图预测的当前事件足够相似。
- en: Events can placed on the scale from deterministic (2+2 will always equal to
    4) to strongly predictable (e.g. orbits of planets and moons, avg. number of heads
    when tossing a fair coin) to weakly predictable (e.g. elections and sporting events)
    to random (e.g. honest lottery).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 事件可以按从确定性（2+2总是等于4）到强预测性（例如行星和卫星的轨道、公平抛硬币的平均正面数）到弱预测性（例如选举和体育赛事）再到随机性（例如诚实的彩票）的尺度进行分类。
- en: If we toss a fair coin 100 million times, we have the expected number of heads
    (mean) as 50 million, the standard deviation =10,000 (using formula 0.5 * SQRT(N)),
    and we can predict that 99.7% of the time the expected number of heads will be
    within [3 standard deviations](https://en.wikipedia.org/wiki/68–95–99.7_rule)
    of the mean.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们公平地抛掷1亿次硬币，我们期望得到的正面朝上的次数（均值）是5000万，标准差=10,000（使用公式0.5 * SQRT(N)），我们可以预测99.7%的时间内，期望的正面朝上的次数将落在均值的[3个标准差](https://en.wikipedia.org/wiki/68–95–99.7_rule)范围内。
- en: But using polling to predict the votes of 100 million people is much more difficult.
    Pollsters need to get a representative sample, estimate the likelihood of a person
    actually voting, make many justified and unjustified assumptions, and avoid following
    their conscious and unconscious biases.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但使用民意调查来预测1亿人的投票结果要困难得多。民意调查员需要获取一个具有代表性的样本，估算一个人实际投票的可能性，做出许多有根据和无根据的假设，并避免受他们有意识和无意识的偏见影响。
- en: In the case of US Presidential election, correct prediction is even more difficult
    because of the antiquated Electoral college system when each state (except for
    Maine and Nebraska) awards the winner all its votes in the electoral college,
    and the need to poll and predict results for each state separately.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国总统选举的情况下，准确预测更加困难，因为存在过时的选举团制度，每个州（缅因州和内布拉斯加州除外）将所有选举团票投给获胜者，而且需要对每个州分别进行民意调查和预测结果。
- en: The chart below shows that in 2016 US presidential elections pollsters were
    off the mark in many states. They mostly underestimated the Trump vote, especially
    in 3 critical states of Michigan, Wisconsin, and Pennsylvania which all flipped
    to Trump.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示，在2016年美国总统选举中，民意调查员在许多州的预测结果都偏离了实际情况。他们大多低估了特朗普的投票率，特别是在密歇根州、威斯康星州和宾夕法尼亚州这三个关键州，这些州都转向了特朗普。
- en: '![Us Elections 2016 Poll Shift, according to 538](../Images/9374b47f7145fa507df38dba4004931f.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![2016年美国选举民意调查变化，根据538](../Images/9374b47f7145fa507df38dba4004931f.png)'
- en: 'Source: [**@NateSilver538**](https://twitter.com/NateSilver538) tweet, Nov
    9, 2016.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[**@NateSilver538**](https://twitter.com/NateSilver538) 推文，2016年11月9日。
- en: A few statisticians like Salil Mehta [@salilstatistics](https://twitter.com/salilstatistics)
    were warning about [unreliability of polls](https://twitter.com/salilstatistics/status/796248050851139584),
    and David Wasserman of 538 actually described this scenario in Sep 2016 [How Trump
    Could Win The White House While Losing The Popular Vote](https://fivethirtyeight.com/features/how-trump-could-win-the-white-house-while-losing-the-popular-vote/?ex_cid=story-twitter),
    but most pollsters were way off.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一些统计学家如Salil Mehta [@salilstatistics](https://twitter.com/salilstatistics)曾警告[民意调查的不可靠性](https://twitter.com/salilstatistics/status/796248050851139584)，而538的David
    Wasserman实际上在2016年9月描述了这一情景，[特朗普如何在输掉普选的情况下赢得白宫](https://fivethirtyeight.com/features/how-trump-could-win-the-white-house-while-losing-the-popular-vote/?ex_cid=story-twitter)，但大多数民意调查员的预测偏差较大。
- en: So a good lesson for Data Scientists is to **question their assumptions** and
    to be very skeptical when predicting a weakly predictable event, especially when
    based on human behavior.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对数据科学家来说一个重要的教训是**质疑他们的假设**，并在预测难以预测的事件时保持高度怀疑，特别是当这些预测基于人类行为时。
- en: Other important lessons are
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 其他重要的教训包括
- en: Examine data quality - in this election polls were not reaching all likely voters
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据质量——在此次选举中，民调未能覆盖所有可能的选民
- en: 'Beware of your own biases: many pollsters were likely Clinton supporters and
    did not want to question the results that favored their candidate. For example,
    Huffington Post had forecast over 95% chance of Clinton Victory.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当心自己的偏见：许多民调人员可能是希拉里的支持者，不愿质疑有利于自己候选人的结果。例如，Huffington Post 预测希拉里的胜率超过 95%。
- en: 'See also other analyses of 2016 polling failures:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另见 2016 年民调失败的其他分析：
- en: 'Wired: [Trump’s Win Isn’t the Death of Data—It Was Flawed All Along](https://www.wired.com/2016/11/trumps-win-isnt-death-data-flawed-along).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wired: [特朗普的胜利不是数据的终结——它一直存在缺陷](https://www.wired.com/2016/11/trumps-win-isnt-death-data-flawed-along)。'
- en: NYTimes [How Data Failed Us in Calling an Election](http://www.nytimes.com/2016/11/10/technology/the-data-said-clinton-would-win-why-you-shouldnt-have-believed-it.html)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NYTimes [数据为何未能准确预测选举结果](http://www.nytimes.com/2016/11/10/technology/the-data-said-clinton-would-win-why-you-shouldnt-have-believed-it.html)
- en: Datanami [Six Data Science Lessons from the Epic Polling Failure](https://www.datanami.com/2016/11/11/data-science-lessons-epic-polling-failure/)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Datanami [从史诗般的民调失败中获得的六个数据科学教训](https://www.datanami.com/2016/11/11/data-science-lessons-epic-polling-failure/)
- en: 'InformationWeek [Trump''s Election: Poll Failures Hold Data Lessons For IT](http://www.informationweek.com/big-data/big-data-analytics/trumps-election-poll-failures-hold-data-lessons-for-it/d/d-id/1327455)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: InformationWeek [特朗普的选举：民调失败为 IT 提供数据教训](http://www.informationweek.com/big-data/big-data-analytics/trumps-election-poll-failures-hold-data-lessons-for-it/d/d-id/1327455)
- en: '[Why I Had to Eat a Bug on CNN](http://www.nytimes.com/2016/11/19/opinion/why-i-had-to-eat-a-bug-on-cnn.html?emc=eta1&_r=0),
    by Sam Wang, Princeton, whose Princeton Election Consortium gave Trump 15% to
    win.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么我在 CNN 上必须吃虫子](http://www.nytimes.com/2016/11/19/opinion/why-i-had-to-eat-a-bug-on-cnn.html?emc=eta1&_r=0)，作者
    Sam Wang，普林斯顿，其普林斯顿选举联盟给特朗普的胜率为 15%。'
- en: '(*Note: this answer is based on a previous KDnuggets post: [/2016/11/trump-shows-limits-prediction.html](/2016/11/trump-shows-limits-prediction.html))*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: (*注：此回答基于之前的 KDnuggets 帖子：[/2016/11/trump-shows-limits-prediction.html](/2016/11/trump-shows-limits-prediction.html))*
- en: We had another example of statistically very unlikely event happen in Super
    Bowl LI on Feb 5, 2017.  After the half time, Atlanta Falcons were leading 21:3
    after halftime and 28:9 after 3rd quarter. ESPN estimated Falcons win probability
    at that time at almost 100%.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2017 年 2 月 5 日超级碗 LI 上，我们又看到一个统计上极不可能发生的事件。在半场后，亚特兰大猎鹰队在半场时领先 21:3，在第三节时 28:9。ESPN
    当时估计猎鹰队的胜率几乎为 100%。
- en: '![Super Bowl 2017 win probability](../Images/d7a31a019989e946ed5aa26be3d6403d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![超级碗 2017 胜率](../Images/d7a31a019989e946ed5aa26be3d6403d.png)'
- en: '(reference: Salil Mehta tweet [Salil Mehta tweet, Feb 6, 2017](https://twitter.com/salilstatistics/status/828581183558713344))'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: (参考：Salil Mehta 推文 [Salil Mehta 推文, 2017年2月6日](https://twitter.com/salilstatistics/status/828581183558713344))
- en: Never before has a team lost a Super Bowl after holding such advantage.  However,
    each Super Bowl is different, and this one was turned out to be very different. 
    Combination of superior skill (Patriots, after all, were favorites before the
    game) and luck (e.g. a very lucky catch by Julian Edelman in 4th quarter, Patriots
    winning coin toss in overtime) gave victory to Pats.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以前没有球队在拥有如此巨大优势的情况下输掉超级碗。然而，每届超级碗都不同，这一届显然非常不同。卓越的技能（毕竟，爱国者队在比赛前是热门）和运气的结合（例如，朱利安·埃德尔曼在第四节的幸运接球，爱国者在加时赛中赢得硬币投掷）使得爱国者队获胜。
- en: This Super Bowl was another good lesson for Data Scientists of danger of having
    **too much confidence** when predicting weakly predictable events. You need to
    understand the risk factors when dealing with such events, and try to avoid using
    probabilities, or if you have to use numbers, have a wide confidence range.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这届超级碗是数据科学家关于在预测弱预测事件时**过度自信**的又一个重要教训。你需要理解处理这种事件时的风险因素，并尽量避免使用概率，或者如果必须使用数字，确保有一个广泛的置信区间。
- en: Finally, if the odds seem to be against you but the event is only weakly predictable,
    go ahead and do your best - sometimes you will be able to beat the odds.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果机会似乎不利于你，但事件的预测仅仅是弱预测，尽力而为吧——有时你可能会逆袭成功。
- en: '* * *'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Q2\. What problems arise if the distribution of the new (unseen) test data is
    significantly different than the distribution of the training data?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q2\. 如果新（未见过的）测试数据的分布与训练数据的分布显著不同，会出现什么问题？
- en: '**[Gregory Piatetsky](/author/gregory-piatetsky) and [Thuy Pham](/author/thuy-pham)
    answer:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Gregory Piatetsky](/author/gregory-piatetsky) 和 [Thuy Pham](/author/thuy-pham)
    回答：**'
- en: The main problem is that the predictions will be wrong !
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 主要问题是预测将会出错！
- en: If the new test data is sufficiently different in key parameters of the prediction
    model from the training data, then predictive model is no longer valid.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果新的测试数据在预测模型的关键参数上与训练数据有显著不同，则预测模型不再有效。
- en: The main reasons this can happen are sample selection bias, population drift,
    or non-stationary environment.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 造成这种情况的主要原因是样本选择偏差、人群漂移或非静态环境。
- en: '**a) Sample selection bias**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**a) 样本选择偏差**'
- en: Here the data is static, but the training examples have been obtained through
    a biased method, such as non-uniform selection or non-random split of data into
    train and test.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，数据是静态的，但训练示例是通过有偏的方法获得的，例如非均匀选择或将数据随机拆分为训练和测试。
- en: If you have a large static dataset, then you should randomly split it into train/test
    data, and the distribution of test data should be similar to training data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个大的静态数据集，那么你应该将其随机拆分为训练/测试数据，并且测试数据的分布应与训练数据类似。
- en: '![Covariate shift](../Images/44bd3aaf781eae2e665248d2bcd34bc8.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![协变量漂移](../Images/44bd3aaf781eae2e665248d2bcd34bc8.png)'
- en: '**b) Covariate shift aka population drift**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**b) 协变量漂移即人群漂移**'
- en: Here the data is not static, with one population used as a training data, and
    another population used for testing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，数据不是静态的，一个人群用于训练数据，另一个人群用于测试。
- en: '*(Figure from http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf).*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*(图示来自 http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf)。*'
- en: Sometimes the training data and test data are derived via different processes
    - eg a drug tested on one population is given to a new population that may have
    significant differences. As a result, a classifier based on training data will
    perform poorly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有时训练数据和测试数据是通过不同的过程获得的——例如，一个药物在一个人群中测试后，给另一个可能有显著差异的新的人群使用。结果，基于训练数据的分类器表现不佳。
- en: One proposed solution is to apply a statistical test to decide if the probabilities
    of target classes and key variables used by the classifier are significantly different,
    and if they are, to retrain the model using new data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提议的解决方案是应用统计测试以确定分类器使用的目标类别和关键变量的概率是否显著不同，如果不同，则使用新数据重新训练模型。
- en: '**c) Non-stationary environments**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**c) 非静态环境**'
- en: Training environment is different from the test one, whether it's due to a temporal
    or a spatial change.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 训练环境与测试环境不同，无论是由于时间变化还是空间变化。
- en: This is similar to case b, but applies to situation when data is not static
    -  we have a stream of data and we periodically sample it to develop predictive
    models of future behavior.  This happens in adversarial classification problems,
    such as spam filtering and network intrusion detection, where spammers and hackers
    constantly change their behavior in response. Another typical case is customer
    analytics where customer behavior changes over time.  A telephone company develops
    a model for predicting customer churn or a credit card company develops a model
    to predict transaction fraud.  Training data is historical data, while (new) test
    data is the current data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于情况 b，但适用于数据不是静态的情况——我们有一个数据流，并且我们定期对其进行采样，以开发预测未来行为的模型。这发生在对抗分类问题中，例如垃圾邮件过滤和网络入侵检测，其中垃圾邮件发送者和黑客会不断调整他们的行为以作出反应。另一个典型的案例是客户分析，其中客户行为随时间变化。一个电话公司开发了一个预测客户流失的模型，或者一个信用卡公司开发了一个预测交易欺诈的模型。训练数据是历史数据，而（新）测试数据是当前数据。
- en: Such models periodically need to be retrained and to determine when you can
    compare the distribution of key variables in the predictive model in the old data
    (training set) and the new data, and if there is a sufficiently significant difference,
    the model needs to be retrained.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型需要定期重新训练，并且需要确定何时可以比较预测模型中旧数据（训练集）和新数据中的关键变量分布，如果存在足够显著的差异，则需要重新训练模型。
- en: For a more detailed and technical discussion, see references below.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更详细和技术性的讨论，请参见以下参考文献。
- en: '**References:**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: '[1] Marco Saerens, Patrice Latinne, Christine Decaestecker: Adjusting the Outputs
    of a Classifier to New a Priori Probabilities: A Simple Procedure. Neural Computation
    14(1): 21-41 (2002)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Marco Saerens, Patrice Latinne, Christine Decaestecker: 调整分类器输出以适应新的先验概率：一个简单的程序。Neural
    Computation 14(1): 21-41 (2002)'
- en: '[2] Machine Learning in Non-stationary Environments: Introduction to Covariate
    Shift Adaptation, Masashi Sugiyama, Motoaki Kawanabe, MIT Press, 2012, ISBN 0262017091,
    9780262017091'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 非平稳环境中的机器学习：协变量转移适应介绍，Masashi Sugiyama, Motoaki Kawanabe，麻省理工学院出版社，2012年，ISBN
    0262017091，9780262017091'
- en: '[3] Quora answer to [What could be some issues if the distribution of the test
    data is significantly different than the distribution of the training data?](https://www.quora.com/What-could-be-some-issues-if-the-distribution-of-the-test-data-is-significantly-different-than-the-distribution-of-the-training-data)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Quora 对 [测试数据的分布与训练数据的分布显著不同可能会有什么问题？](https://www.quora.com/What-could-be-some-issues-if-the-distribution-of-the-test-data-is-significantly-different-than-the-distribution-of-the-training-data)
    的回答'
- en: '[4] [Dataset Shift in Classification: Approaches and Problems](http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf),
    Francisco Herrera invited talk, 2011.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [分类中的数据集转移：方法与问题](http://iwann.ugr.es/2011/pdf/InvitedTalk-FHerrera-IWANN11.pdf)，Francisco
    Herrera 受邀演讲，2011年。'
- en: '[5] [When Training and Test Sets are Different: Characterising Learning Transfer](http://homepages.inf.ed.ac.uk/amos/publications/Storkey2009TrainingTestDifferent.pdf),
    Amos Storkey, 2013.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [训练集和测试集不同：学习转移的特征](http://homepages.inf.ed.ac.uk/amos/publications/Storkey2009TrainingTestDifferent.pdf)，Amos
    Storkey，2013年。'
- en: '* * *'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Q3\. What are bias and variance, and what are their relation to modeling data?
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Q3. 什么是偏差和方差，它们与数据建模有什么关系？
- en: '**[Matthew Mayo](/author/matt-mayo) answers:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Matthew Mayo](/author/matt-mayo) 回答：**'
- en: '**Bias** is how far removed a model''s predictions are from correctness, while
    **variance** is the degree to which these predictions vary between model iterations.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏差**是模型预测与正确性的距离，而**方差**是这些预测在模型迭代之间变化的程度。'
- en: '![Bias vs Variance](../Images/b96b54746b97c6cc4d80a70ba9f99dab.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![偏差与方差](../Images/b96b54746b97c6cc4d80a70ba9f99dab.png)'
- en: '**Bias vs Variance**, [Image source](http://scott.fortmann-roe.com/docs/BiasVariance.html)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏差与方差**，[图片来源](http://scott.fortmann-roe.com/docs/BiasVariance.html)'
- en: '[As an example](/2016/08/bias-variance-tradeoff-overview.html), using a simple
    flawed Presidential election survey as an example, errors in the survey are then
    explained through the twin lenses of bias and variance: selecting survey participants
    from a phonebook is a source of bias; a small sample size is a source of variance.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[举个例子](/2016/08/bias-variance-tradeoff-overview.html)，以一个简单的有缺陷的总统选举调查为例，通过偏差和方差这两个视角来解释调查中的错误：从电话簿中选择调查参与者是偏差的来源；样本量小是方差的来源。'
- en: Minimizing total model error relies on the balancing of bias and variance errors.
    Ideally, models are the result of a collection of **unbiased data of low variance**.
    Unfortunately, however, the more complex a model becomes, its tendency is toward
    less bias but greater variance; therefore an optimal model would need to consider
    a balance between these 2 properties.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化模型的总误差依赖于偏差和方差误差的平衡。理想情况下，模型应该是**低方差的无偏数据**的结果。然而，不幸的是，模型变得越复杂，其倾向于偏差减少但方差增加；因此，优化模型需要在这两个属性之间取得平衡。
- en: The statistical evaluation method of cross-validation is useful in both demonstrating
    the **importance** of this balance, as well as actually **searching** it out.
    The number of data folds to use -- the value of *k* in *k*-fold cross-validation
    -- is an important decision; the lower the value, the higher the bias in the error
    estimates and the less variance.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的统计评估方法在展示这种平衡的**重要性**以及实际**寻找**这种平衡方面都很有用。数据折叠的数量——*k*-折交叉验证中的*k*值——是一个重要的决策；值越低，误差估计的偏差越高，方差越小。
- en: '![Bias variance total error](../Images/110b09d1df30869536aad9bf0fdda2a9.png)**Bias
    and variance contributing to total error**, [Image source](http://scott.fortmann-roe.com/docs/BiasVariance.html)Conversely,
    when *k* is set equal to the number of instances, the error estimate is then very
    low in bias but has the possibility of high variance.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![偏差方差总误差](../Images/110b09d1df30869536aad9bf0fdda2a9.png)**偏差和方差对总误差的贡献**，[图片来源](http://scott.fortmann-roe.com/docs/BiasVariance.html)相反，当*k*设置为实例数量时，误差估计的偏差非常低，但可能具有较高的方差。'
- en: The most important takeaways are that bias and variance are two sides of an
    important trade-off when building models, and that even the most routine of statistical
    evaluation methods are directly reliant upon such a trade-off.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的结论是，偏差和方差是在构建模型时需要权衡的两个方面，即使是最常规的统计评估方法也直接依赖于这种权衡。
- en: On next page, we answer
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一页，我们将回答
- en: Why might it be preferable to include fewer predictors over many?
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么包括更少的预测变量可能比包括更多的预测变量更可取？
- en: What error metric would you use to evaluate how good a binary classifier is?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会使用什么误差指标来评估二分类器的表现？
- en: What are some ways I can make my model more robust to outliers?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我可以采取哪些措施使我的模型对异常值更加鲁棒？
- en: More On This Topic
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[7 Data Analytics Interview Questions & Answers](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7个数据分析面试问题及答案](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
- en: '[5 Python Interview Questions & Answers](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个Python面试问题及答案](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测虚假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测虚假数据科学家的20个问题（附答案）：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
