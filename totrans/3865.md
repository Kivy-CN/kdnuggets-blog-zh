# 如何排查 Python 中的内存问题

> 原文：[https://www.kdnuggets.com/2021/06/troubleshoot-memory-problems-python.html](https://www.kdnuggets.com/2021/06/troubleshoot-memory-problems-python.html)

[评论](#comments)

**由 [Freddy Boulton](https://innovation.alteryx.com/author/freddy/)，Alteryx 的软件工程师**

![如何排查 Python 中的内存问题](../Images/30b767756e098c963065f0aa81571cb8.png)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 工作

* * *

发现一个应用程序内存不足是开发者可能遇到的最糟糕的情况之一。内存问题通常难以诊断和修复，但我认为在 Python 中更为困难。Python 的自动垃圾回收使得使用语言变得容易，但它在不干扰的情况下表现得如此出色，以至于当它没有按预期工作时，开发者可能会不知道如何识别和修复问题。

在这篇博客文章中，我将展示我们如何诊断和修复在[EvalML](https://evalml.alteryx.com/en/stable/)中出现的内存问题，这是 Alteryx 创新实验室开发的开源 AutoML 库。解决内存问题没有魔法配方，但我希望开发者，特别是 Python 开发者，能够了解一些工具和最佳实践，当他们将来遇到这种问题时可以加以利用。

阅读完这篇博客文章后，你应该能获得以下内容：

1.  为什么发现并修复程序中的内存问题很重要，

1.  循环引用是什么以及它们为何会导致 Python 中的内存泄漏，以及

1.  了解 Python 的内存分析工具以及一些可以采取的步骤，以识别内存问题的原因。

### **奠定基础**

EvalML 团队在发布新版本之前，会运行一系列性能测试，以捕捉任何性能回归。这些性能测试包括在各种数据集上运行我们的 AutoML 算法，测量算法的得分以及运行时间，并将这些指标与我们之前发布的版本进行比较。

一天，我在运行测试时，应用程序突然崩溃了。发生了什么？

### **步骤 0 - 什么是内存，什么是泄漏？**

任何编程语言最重要的功能之一是能够将信息存储在计算机的内存中。每当你的程序创建一个新变量时，它会分配一些内存来存储该变量的内容。

内核定义了一个接口，供程序访问计算机的 CPU、内存、磁盘存储等。每种编程语言都提供了向内核请求分配和释放内存块的方法，以供运行中的程序使用。

内存泄漏发生在程序请求内核分配一块内存使用，但由于程序中的错误或崩溃，程序从未告知内核它完成了对那块内存的使用。在这种情况下，内核会继续认为那些被遗忘的内存块仍在被运行的程序使用，而其他程序将无法访问这些内存块。

如果在运行程序时同样的泄漏问题重复发生，被遗忘的内存总量可能会增长到占用计算机内存的很大一部分！在这种情况下，如果程序尝试请求更多内存，内核将会引发“内存不足”错误，程序将停止运行，换句话说，就是“崩溃”。

因此，找到并修复你编写的程序中的内存泄漏很重要，因为如果不修复，你的程序可能最终会耗尽内存并崩溃，或者可能导致其他程序崩溃。

### **步骤 1：确定这是一个内存问题**

应用程序崩溃可能有多种原因——也许运行代码的服务器崩溃了，也许代码本身有逻辑错误——所以确定问题是否为内存问题很重要。

EvalML 性能测试以一种异常安静的方式崩溃了。突然间，服务器停止了进度日志记录，任务悄无声息地完成了。服务器日志会显示由编码错误引起的任何堆栈跟踪，所以我猜测这个安静的崩溃是由于任务使用了所有可用内存。

我再次运行了性能测试，但这次启用了 Python 的 [memory-profiler](https://pypi.org/project/memory-profiler/) 以获取内存使用情况的时间图。测试再次崩溃，当我查看内存图时，我看到了这个：

![图表，折线图

描述自动生成](../Images/b89d4018ae7029f0d96e81d268ee0d20.png)性能测试的内存配置文件

我们的内存使用保持稳定，但然后达到 8GB！我知道我们的应用服务器有 8GB 的 RAM，所以这个配置文件确认我们内存不足。此外，当内存稳定时，我们使用了大约 4GB 的内存，而我们之前的 EvalML 版本使用了大约 2GB 的内存。因此，出于某种原因，这个当前版本使用的内存是正常的两倍。

现在我需要找出原因。

### **步骤 2：使用最小示例在本地重现内存问题**

确定内存问题的原因涉及大量实验和迭代，因为答案通常并不明显。如果明显的话，你可能不会把它写进代码里！因此，我认为用尽可能少的代码行重现问题是很重要的。这个最小示例使你能够在修改代码时快速在性能分析器下运行它，以查看是否有所进展。

在我的案例中，我根据经验知道我们的应用程序运行了一个包含 150 万行的出租车数据集，而我看到大峰值的时间大致相同。我将应用程序缩减到只运行这个数据集的 [部分](https://gist.github.com/freddyaboulton/66159137063d01f3ee9cfb84b0ac2aaa)。我看到的峰值与我上面描述的类似，但这次内存使用达到了 10GB！

看到这一点后，我知道有一个足够好的最小示例可以深入研究了。

![图表，散点图 自动生成的描述](../Images/57a022a7cf02687d0161d62b3f449ece.png)本地重现者在出租车数据集上的内存占用

### **步骤 3：找到分配最多内存的代码行**

一旦我们将问题隔离到尽可能小的代码块中，我们就可以看到程序在哪里分配了最多的内存。这可以成为你重构代码和解决问题的关键证据。

我认为 [filprofiler](https://pypi.org/project/filprofiler/) 是一个很棒的 Python 工具来做这个。它显示了应用程序中每行代码在内存使用峰值时的内存分配。这是我本地示例的输出：

![文本 自动生成的描述](../Images/8ce1abe4d64ab0a96176d21157d4da47.png)fil-profile 的输出

filprofiler 按内存分配对应用程序中的代码行（及其依赖项的代码）进行排序。行越长、颜色越红，分配的内存就越多。

分配最多内存的行是创建 pandas 数据框（pandas/core/algorithms.py 和 pandas/core/internal/managers.py），这些数据总量达到 4GB！我在这里截断了 filprofiler 的输出，但它能够追踪到在 EvalML 中创建 pandas 数据框的 pandas 代码。

看到这一点有些令人困惑。是的，EvalML 确实创建了 pandas 数据框，但这些数据框在 AutoML 算法中是短暂存在的，应该在不再使用时立即释放。既然情况并非如此，这些数据框在 EvalML 完成后仍然在内存中存在了足够长的时间，我怀疑最新版本是否引入了一个 [内存泄漏](https://en.wikipedia.org/wiki/Memory_leak)。

### **步骤 4：识别泄漏对象**

在 Python 的上下文中，泄漏对象是指在使用完毕后，Python 的垃圾回收器没有释放的对象。由于 Python 使用 [引用计数](https://en.wikipedia.org/wiki/Reference_counting) 作为主要的垃圾回收算法之一，这些泄漏对象通常是由于对象持有对它们的引用时间过长所导致的。

这种类型的对象很难找到，但你可以利用一些 Python 工具来使搜索变得可行。第一个工具是垃圾回收器的 [gc.DEBUG_SAVEALL](https://docs.python.org/3/library/gc.html#gc.DEBUG_SAVEALL) 标志。通过设置这个标志，垃圾回收器会将无法访问的对象存储在 gc.garbage 列表中。这将允许你进一步调查这些对象。

第二个工具是 [objgraph](https://pypi.org/project/objgraph/) 库。一旦对象进入 gc.garbage 列表，我们可以过滤这个列表以获取 pandas dataframes，并使用 objgraph 查看其他哪些对象在引用这些 dataframes 并将它们保持在内存中。我通过阅读这篇 O'Reilly 的 [博客文章](https://www.oreilly.com/library/view/python-cookbook/0596001673/ch14s10.html) 得到了这个方法的灵感。

这是我在可视化这些 dataframes 时看到的对象图的一个子集：

![图表描述自动生成](../Images/20a8329f59226382469b80a7194f1839.png)

一张展示 pandas dataframe 使用内存的图，显示了一个导致内存泄漏的循环引用。

这正是我寻找的关键证据！Dataframe 通过一个叫做 PandasTableAccessor 的东西引用自身，这创建了一个 [循环引用](https://en.wikipedia.org/wiki/Circular_reference)，所以这会使对象保持在内存中，直到 Python 的垃圾回收器运行并能够释放它。（你可以通过 dict, PandasTableAccessor, dict, _dataframe 跟踪这个循环。）这对 EvalML 是一个问题，因为垃圾回收器将这些 dataframes 保持在内存中的时间太长，导致我们内存耗尽！

我能够追踪到 PandasTableAccessor 到 [Woodwork](https://woodwork.alteryx.com/en/stable/) 库，并向维护者报告了这个 [问题](https://github.com/alteryx/woodwork/issues/880)。他们在新版本中修复了它，并在 pandas 仓库中提交了相关的 [问题](https://github.com/pandas-dev/pandas/issues/41357) — 这是开源生态系统中可能的合作的一个很好的例子。

Woodwork 更新发布后，我可视化了相同 dataframe 的对象图，循环消失了！

![图表描述自动生成](../Images/5e263655619062aa7c19fc4758280201.png) Woodwork 更新后的 pandas dataframe 对象图。没有更多的循环了！

### **步骤 5：验证修复是否有效**

一旦我在 EvalML 中升级了 Woodwork 版本，我测量了我们应用程序的内存占用。很高兴地报告，现在内存使用量不到以前的一半！

![图表描述自动生成](../Images/91321f74711571f99421d7a0e9e70fb7.png)修复后的性能测试内存

### **总结**

正如我在本文开头所说，修复内存问题没有魔法配方，但这个案例研究提供了一个通用框架和一组工具，如果你将来遇到类似情况，可以加以利用。我发现`memory-profiler`和`filprofiler`是调试Python内存泄漏的有用工具。

我还想强调，Python中的循环引用可能会增加应用程序的内存占用。垃圾回收器最终会释放这些内存，但正如我们在这个案例中看到的，可能会拖到为时已晚！

在Python中，循环引用意外引入的情况出奇容易。我在EvalML、[scikit-optimize](https://github.com/scikit-optimize/scikit-optimize/issues/1028)和[scipy](https://github.com/scipy/scipy/issues/13986)中发现了一个[无意中的循环引用](https://github.com/alteryx/evalml/issues/2226)。我鼓励你保持警惕，如果你发现了循环引用，开始讨论一下它是否真的必要！

**简介: [Freddy Boulton](https://innovation.alteryx.com/author/freddy/)** 是Alteryx的工程师。他喜欢从事开源项目，并骑自行车穿越波士顿。

[原文](https://innovation.alteryx.com/how-to-troubleshoot-memory-problems-in-python/)。经许可转载。

**相关:**

+   [顶级编程语言及其应用](/2021/05/top-programming-languages.html)

+   [数据科学家，你需要学会编程](/2021/06/data-scientists-need-know-code.html)

+   [5个需要用Python自动化的任务](/2021/06/5-tasks-automate-python.html)

### 更多相关主题

+   [Python内存分析简介](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)

+   [如何在Pandas中对大数据集执行内存高效的操作](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)

+   [变压器的内存复杂度](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)

+   [更多分类问题的性能评估指标](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)

+   [常见数据问题（及解决方案）](https://www.kdnuggets.com/2022/02/common-data-problems-solutions.html)

+   [识别机器学习可解决问题的4个因素](https://www.kdnuggets.com/2022/04/4-factors-identify-machine-learning-solvable-problems.html)
