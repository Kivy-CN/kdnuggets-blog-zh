- en: 'Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/06/data-science-project-rotten-tomatoes-movie-rating-prediction-first-approach.html](https://www.kdnuggets.com/2023/06/data-science-project-rotten-tomatoes-movie-rating-prediction-first-approach.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/d3f12f9c00b48733d43b0fb8d5b5dde2.png)Image
    by Author'
  prefs: []
  type: TYPE_NORMAL
- en: It's no secret that predicting the success of a movie in the entertainment industry
    can make or break a studio's financial prospects.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Accurate predictions enable studios to make well-informed decisions about various
    aspects, such as marketing, distribution, and content creation.
  prefs: []
  type: TYPE_NORMAL
- en: Best of all, these predictions can help maximize profits and minimize losses
    by optimizing the allocation of resources.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, machine learning techniques provide a powerful tool to tackle this
    complex problem. No doubt about it, by leveraging data-driven insights, studios
    can significantly improve their decision-making process.
  prefs: []
  type: TYPE_NORMAL
- en: This data science project has been used as a take-home assignment in the recruitment
    process at Meta (Facebook). In this take-home assignment, we will discover how
    Rotten Tomatoes is making labeling as ‘Rotten’, ‘Fresh’ or  ‘Certified Fresh’.
  prefs: []
  type: TYPE_NORMAL
- en: To do that, we will develop two different approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/d2ba235dba50e9a968c7483d9c033db9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Throughout our exploration, we will discuss data preprocessing, various classifiers,
    and potential improvements to enhance the performance of our models.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this post, you will have gained an understanding of how machine
    learning can be employed to predict movie success and how this knowledge can be
    applied in the entertainment industry.
  prefs: []
  type: TYPE_NORMAL
- en: But before going deeper, let’s discover the data we will work on.
  prefs: []
  type: TYPE_NORMAL
- en: 'First Approach: Predicting Movie Status Based on Numerical and Categorical
    Features'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this approach, we will use a combination of numerical and categorical features
    to predict the success of a movie.
  prefs: []
  type: TYPE_NORMAL
- en: The features we will consider include factors such as budget, genre, runtime,
    and director, among others.
  prefs: []
  type: TYPE_NORMAL
- en: We will employ several [machine learning algorithms](https://www.stratascratch.com/blog/machine-learning-algorithms-you-should-know-for-data-science/?utm_source=blog&utm_medium=click&utm_campaign=kdn+rotten+tomatoes)
    to build our models, including Decision Trees, Random Forests, and Weighted Random
    Forests with feature selection.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/ef349f80d0ea44292afd887bee532061.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Let’s read our data and take a glimpse of it.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/80ab8fe1aebf46e262502dbdfd7fa2a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let’s start with Data Preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: There are many columns in our Data set.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see.
  prefs: []
  type: TYPE_NORMAL
- en: To develop a better understanding of the statistical features, let’s use describe
    the () method. Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/83e81ed677afed0819b13a56cb93d54a.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, we have a quick overview of our data, let’s go to the preprocessing stage.
  prefs: []
  type: TYPE_NORMAL
- en: Data Preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we can begin building our models, it's essential to preprocess our data.
  prefs: []
  type: TYPE_NORMAL
- en: This involves cleaning the data by handling categorical features and converting
    them into numerical representations, and scaling the data to ensure that all features
    have equal importance.
  prefs: []
  type: TYPE_NORMAL
- en: We first examined the content_rating column to see the unique categories and
    their distribution in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Then, we will create a bar plot to see the distribution of each content rating
    category.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here is the full code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/cfabddab78f786c89eeb9865985442a2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It is essential to convert categorical features into numeric forms for our
    machine learning models which need numeric inputs. For multiple elements in this
    data science project, we are going to apply two generally accepted methods: ordinal
    encoding and one-hot encoding. Ordinal encoding is better when categories imply
    a degree of intensity, but the one-hot encoding is ideal when no magnitude representation
    is provided. For the "content_rating" assets, we will use a one-hot encoding method.'
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/5474ac96a1205c695b4644b9ff12494e.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's go ahead and process another feature, audience_status.
  prefs: []
  type: TYPE_NORMAL
- en: 'This variable has two options: ''Spilled'' and ''Upright''.'
  prefs: []
  type: TYPE_NORMAL
- en: We did already apply one hot coding, so now it is time to transform this categorical
    variable into a numerical one by using ordinal encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Because each category illustrates an order of magnitude, we will transform these
    into numerical values by using ordinal encoding.
  prefs: []
  type: TYPE_NORMAL
- en: As we did earlier, first let’s find the unique audience status.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Then, let’s create a bar plot and print out the values on top of bars.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here is the full code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/7e9fdc231fab564dd748169fd0638186.png)'
  prefs: []
  type: TYPE_IMG
- en: Okay, now it is time to do ordinal coding by using replace method.
  prefs: []
  type: TYPE_NORMAL
- en: Then let’s view the first five rows by using the head() method.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/e20360e4b3699fc6afde10925e6093b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Since our target variable, tomatometer_status, have three distinct categories,
    'Rotten', 'Fresh', and 'Certified-Fresh', these categories also represent an order
    of magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: That’s why we again will do ordinal encoding to transform these categorical
    variables into numerical variables.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/d2cede449752b53b6ee15418bfde4d03.png)'
  prefs: []
  type: TYPE_IMG
- en: After changing categorial to numerical, it is now time to combine the two data
    frames. We'll use Pandas pd.concat() function for this, and the dropna() method
    to remove rows with missing values across all columns.
  prefs: []
  type: TYPE_NORMAL
- en: Following that, we'll use the head function to look at the freshly formed DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/c48639fb47bbf970ccaabadfff2f9d25.png)'
  prefs: []
  type: TYPE_IMG
- en: Great, now let’s inspect our numerical variables by using describe method.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/d6642d87f1dad3996c8d6a1d87997727.png)'
  prefs: []
  type: TYPE_IMG
- en: Now let’s check the length of our DataFrame by using len method.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/9ffc2bbb2c40a97b36d34cc8cd90a771.png)'
  prefs: []
  type: TYPE_IMG
- en: After removing rows with missing values and doing the transformation for building
    machine learning, now our data frame has 17017 rows.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now analyze the distribution of our target variables.
  prefs: []
  type: TYPE_NORMAL
- en: As we keep constantly doing since the beginning, we will draw a bar graph and
    put the values at the top of the bar.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/9995c293b9ef09be88c2a22fa59776df.png)'
  prefs: []
  type: TYPE_IMG
- en: Our dataset contains 7375 'Rotten,' 6475 'Fresh,' and 3167 'Certified-Fresh'
    films, indicating a class imbalance issue.
  prefs: []
  type: TYPE_NORMAL
- en: The problem will be addressed at a later time.
  prefs: []
  type: TYPE_NORMAL
- en: For the time being, let’s split our dataset into testing and training sets using
    an 80% to 20% split.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/cf106f5eb38848b0de88509d8f86a48c.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision Tree Classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will look at the Decision Tree Classifier, a machine learning
    technique that is commonly used for classification problems and sometimes for
    [regression](https://www.stratascratch.com/blog/overview-of-machine-learning-algorithms-regression/?utm_source=blog&utm_medium=click&utm_campaign=kdn+rotten+tomatoes).
  prefs: []
  type: TYPE_NORMAL
- en: The classifier works by dividing data points into branches, each of which has
    an inner node (which includes a set of conditions) and a leaf node (which has
    the predicted value).
  prefs: []
  type: TYPE_NORMAL
- en: Following these branches and considering the conditions (True or False), data
    points are separated into the proper categories. The process is seen below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/52392afd9add822e7801f26a62f64ddb.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: When we apply a Decision Tree Classifier, we can alter multiple hyperparameters,
    like the maximum depth of the tree and the maximum number of leaf nodes.
  prefs: []
  type: TYPE_NORMAL
- en: For our first attempt, we will limit the number of leaf nodes to three in order
    to make the tree simple and understandable.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, we will create a Decision Tree Classifier with a maximum of three
    leaf nodes. This classifier will then be trained on our training data and used
    to generate predictions on the test data. Finally, we will examine the accuracy,
    precision, and recall metrics to assess the performance of our limited Decision
    Tree Classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s implement the Decision Tree algorithm with sci-kit learn step by step.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s define a Decision Tree Classifier object with a maximum of three
    leaf nodes, using the DecisionTreeClassifier() function from the scikit-learn
    library.
  prefs: []
  type: TYPE_NORMAL
- en: The random_state parameter is used to ensure that the same results are produced
    each time the code is run.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Then it is time to train the Decision Tree Classifier on the training data (X_train
    and y_train), using the .fit() method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Next, we make predictions on the test data(X_test) using the trained classifier
    with the predict method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Here we print the accuracy score and classification report of the predicted
    values compared to the actual target values of the test data. We use the accuracy_score()
    and classification_report() functions from the scikit-learn library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we will plot the confusion matrix to visualize the performance of the
    Decision Tree Classifier on the test data. We use the plot_confusion_matrix()
    function from the scikit-learn library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/71d216300278a3de9a1c1c7c4ce567bc.png)'
  prefs: []
  type: TYPE_IMG
- en: It can be clearly seen from the output, our Decision Tree works well, especially
    taking into consideration that we limited it to three leaf nodes. One of the advantages
    of having a simple classifier is that the decision tree can be visualized and
    understandable.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to understand how the decision tree makes decisions, let’s visualize the
    decision tree classifier by using the plot_tree method from sklearn.tree.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/22869d2d8fcb0fdfd7540eae9d6307b6.png)'
  prefs: []
  type: TYPE_IMG
- en: Now let’s analyze this decision tree, and find out how it carries out the decision-making
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, the algorithm uses the 'tomatometer_rating' feature as the primary
    determinant of each test data point's classification.
  prefs: []
  type: TYPE_NORMAL
- en: If the 'tomatometer_rating' is less than or equal to 59.5, the data point is
    assigned a label of 0 ('Rotten'). Otherwise, the classifier progresses to the
    next branch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second branch, the classifier uses the 'tomatometer_fresh_critics_count'
    feature to classify the remaining data points.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the value of this feature is less than or equal to 35.5, the data point is
    labeled as 1 ('Fresh').
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If not, it is labeled as 2 ('Certified-Fresh').
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This decision-making process closely aligns with the rules and criteria that
    Rotten Tomatoes use to assign movie statuses.
  prefs: []
  type: TYPE_NORMAL
- en: According to the Rotten Tomatoes website, movies are classified as
  prefs: []
  type: TYPE_NORMAL
- en: ‘Fresh' if their tomatometer_rating is 60% or higher.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '''Rotten'' if it falls below 60%.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our Decision Tree Classifier follows a similar logic, classifying movies as
    'Rotten' if their tomatometer_rating is below 59.5 and 'Fresh' otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: However, when distinguishing between 'Fresh' and 'Certified-Fresh' movies, the
    classifier must consider several more features.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to Rotten Tomatoes, films must meet specific criteria to be classified
    as ''Certified-Fresh'', such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Having a consistent Tomatometer score of at least 75%
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At least five reviews from top critics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum of 80 reviews for wide-release films.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our limited Decision Tree model only takes into account the number of reviews
    from top critics to differentiate between 'Fresh' and 'Certified-Fresh' movies.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we understand the logic behind the Decision Tree. So to increase its performance,
    let’s follow the same steps but this time, we will not add the max-leaf nodes
    argument.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the step-by-step explanation of our code. This time I won't expand the
    code too much as we did before.
  prefs: []
  type: TYPE_NORMAL
- en: Define the decision tree classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Train the classifier on the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Predict the test data with a trained tree classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Print the accuracy and classification report.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Plot confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Great now, let’s see them together.
  prefs: []
  type: TYPE_NORMAL
- en: Here's the whole code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/59551a1c7379f5b49c358f22a8ba7773.png)'
  prefs: []
  type: TYPE_IMG
- en: The accuracy, precision, and recall values of our classifier have increased
    as a result of removing the maximum leaf nodes limitation. The classifier now
    reaches 99% accuracy, up from 94% previously.
  prefs: []
  type: TYPE_NORMAL
- en: This displays that when we allow our classifier to pick the optimal number of
    leaf nodes on its own, it performs better.
  prefs: []
  type: TYPE_NORMAL
- en: Although the current result appears to be outstanding, more tuning to reach
    even better accuracy is still possible. In the next part, we'll look into this
    option.
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest Classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Random Forest is an ensemble of Decision Tree Classifiers that have been combined
    into a single algorithm. It uses a bagging strategy to train each Decision Tree,
    which includes randomly picking training data points. Each tree is trained on
    a separate subset of the training data as a result of this technique.
  prefs: []
  type: TYPE_NORMAL
- en: The bagging method has become known for using a bootstrap methodology to sample
    data points, allowing the same data point to be picked for several Decision Trees.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/8d92b624046c6ea940b8819d9547404a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: By using scikit learn, it is really easy to apply a Random forest classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Using Scikit-learn to set up the [Random Forest algorithm](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+rotten+tomatoes)
    is an easy process.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm's performance, like the performance of the Decision Tree Classifier,
    may be increased through changing hyperparameter values such as the number of
    Decision Tree Classifiers, maximum leaf nodes, and maximum tree depth.
  prefs: []
  type: TYPE_NORMAL
- en: We will use default options here first.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the code step-by-step again.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s instantiate a Random Forest Classifier object using the RandomForestClassifier()
    function from the scikit-learn library, with a random_state parameter set to 2
    for reproducibility.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Then, train the Random Forest Classifier on the training data (X_train and y_train),
    using the .fit() method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Next, use the trained classifier to make predictions on the test data (X_test),
    using the .predict() method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Then, print the accuracy score and classification report of the predicted values
    compared to the actual target values of the test data.
  prefs: []
  type: TYPE_NORMAL
- en: We use the accuracy_score() and classification_report() functions from the scikit-learn
    library again.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s plot a confusion matrix to visualize the performance of the Random
    Forest Classifier on the test data. We use the plot_confusion_matrix() function
    from the scikit-learn library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Here is the whole code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/060d5686be6ad07d748f462fcfa37337.png)'
  prefs: []
  type: TYPE_IMG
- en: The accuracy and confusion matrix results show that the Random Forest algorithm
    outperforms the Decision Tree Classifier. This shows the advantage of ensemble
    approaches such as Random Forest over individual [classification algorithms](https://www.stratascratch.com/blog/overview-of-machine-learning-algorithms-classification/?utm_source=blog&utm_medium=click&utm_campaign=kdn+rotten+tomatoes).
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, tree-based machine learning methods allow us to identify the significance
    of each feature once the model has been trained. For this reason, Scikit-learn
    provides the feature_importances_ function.
  prefs: []
  type: TYPE_NORMAL
- en: Great, once again, let’s see the code step by step to understand it.
  prefs: []
  type: TYPE_NORMAL
- en: First, the feature_importances_ attribute of the Random Forest Classifier object
    is used to obtain the importance score of each feature in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The importance score indicates how much each feature contributes to the prediction
    performance of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Next, the feature importances are printed out in descending order of importance,
    along with their corresponding feature names.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Then to visualize features from the most important to least important, let’s
    use argsort() method from the numpy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Finally, a horizontal bar chart is created to visualize the feature importances,
    with features ranked from most to least important on the y-axis and the corresponding
    importance scores on the x-axis.
  prefs: []
  type: TYPE_NORMAL
- en: This chart allows us to easily identify the most important features in the dataset
    and to determine which features have the greatest impact on the model's performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Here is the whole code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/c3065a1fd4ff864dabcf536e0cf9eede.png)'
  prefs: []
  type: TYPE_IMG
- en: By seeing this graph, it is clear that NR, PG-13, R, and runtime did not consider
    important by the model for predicting unseen data points. In the next section,
    whether let’s see addressing this issue can increase our model's performance or
    not.
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest Classifier with Feature Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: In the last section, we discovered that some of our features were considered
    less significant by our Random forest model, in making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, to enhance the model’s performance, let’s exclude these less relevant
    features including NR, runtime, PG-13, R, PG, G, and NC17.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, we will get the feature importance first, then we will
    split to train and test set, but inside the code block we dropped these less significant
    features. Then we will print out the train and test set size.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/ef5a3e2489296672855aa3bffc3c20ed.png)'
  prefs: []
  type: TYPE_IMG
- en: Great, since we dropped these less significant features, let’s see whether our
    performance increased or not.
  prefs: []
  type: TYPE_NORMAL
- en: Because we did this too many times, I quickly explain the following codes.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, we first initialize a random forest classifier and then
    train the random forest on the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Then we calculate the accuracy score and classification report by using test
    data and print them out.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we plot the confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Here is the whole code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/61a3a53b741f51ca254241f03236c745.png)'
  prefs: []
  type: TYPE_IMG
- en: It looks like our new approach works quite well.
  prefs: []
  type: TYPE_NORMAL
- en: After doing feature selection, accuracy has increased to 99.1 %.
  prefs: []
  type: TYPE_NORMAL
- en: Our model's false positive and false negative rates have also lowered marginally
    when compared to the prior model.
  prefs: []
  type: TYPE_NORMAL
- en: This indicates that having more characteristics does not always imply a better
    model. Some insignificant characteristics may create noise which might be the
    reason for lowering the model's prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Now since our model’s performance has increased that far, let’s discover other
    methods to check if we can increase more.
  prefs: []
  type: TYPE_NORMAL
- en: Weighted Random Forest Classifier with Feature Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first section, we realized that our features were a little imbalanced.
    We have three different values, Rotten' (represented by 0), 'Fresh' (represented
    by 1), and 'Certified-Fresh' (represented by 2).
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s see the distribution of our features.
  prefs: []
  type: TYPE_NORMAL
- en: Here's the code for visualizing the label distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/9995c293b9ef09be88c2a22fa59776df.png)'
  prefs: []
  type: TYPE_IMG
- en: It is clear that the amount of data with the ‘Certified Fresh’ feature is much
    less than the others.
  prefs: []
  type: TYPE_NORMAL
- en: To solve the issue of data imbalance, we can use approaches such as the SMOTE
    algorithm to oversample the minority class or provide class weight information
    to the model during the training phase.
  prefs: []
  type: TYPE_NORMAL
- en: Here we will use the second approach.
  prefs: []
  type: TYPE_NORMAL
- en: To compute class weight, we will use the compute_class_weight() function from
    the scikit-learn library.
  prefs: []
  type: TYPE_NORMAL
- en: Inside this function, the class_weight parameter is set to 'balanced' to account
    for imbalanced classes, and the classes parameter is set to the unique values
    in the tomatometer_status column of df_feature.
  prefs: []
  type: TYPE_NORMAL
- en: The y parameter is set to the values of the tomatometer_status column in df_feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Then, the dictionary is created to map the class weights to their respective
    indices.
  prefs: []
  type: TYPE_NORMAL
- en: This is done by converting the class weight list to a dictionary using the dict()
    function and zip() function.
  prefs: []
  type: TYPE_NORMAL
- en: The range() function is used to generate a sequence of integers corresponding
    to the length of the class weight list, which is then used as the keys for the
    dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s see our dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Here is the whole code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/bb3a71287eb61694de069b7487357223.png)'
  prefs: []
  type: TYPE_IMG
- en: Class 0 ('Rotten') has the least weight, while class 2 ('Certified-Fresh') has
    the highest weight.
  prefs: []
  type: TYPE_NORMAL
- en: When we apply our Random Forest classifier, we can now include this weight information
    as an argument.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining code is the same as we did earlier many times.
  prefs: []
  type: TYPE_NORMAL
- en: Let's build a new Random Forest model with class weight data, train it on the
    training set, predict the test data, and display the accuracy score and confusion
    matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data Science Project of Rotten Tomatoes Movie Rating Prediction: First Approach](../Images/969b2ef7332d5a76357b1a70a7b80632.png)'
  prefs: []
  type: TYPE_IMG
- en: Our model's performance increased when we added class weights, and it now has
    an accuracy of 99.2%.
  prefs: []
  type: TYPE_NORMAL
- en: The number of correct predictions for the “Fresh “ label also increased by one.
  prefs: []
  type: TYPE_NORMAL
- en: Using class weights to address the data imbalance problem is a useful method
    since it encourages our model to pay more attention to labels with higher weights
    throughout the training phase.
  prefs: []
  type: TYPE_NORMAL
- en: '**Link to this data science project:** [https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction](https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+rotten+tomatoes)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Nate Rosidi](https://www.stratascratch.com)** is a data scientist and in
    product strategy. He''s also an adjunct professor teaching analytics, and is the
    founder of [StrataScratch](https://www.stratascratch.com/), a platform helping
    data scientists prepare for their interviews with real interview questions from
    top companies. Connect with him on [Twitter: StrataScratch](https://twitter.com/StrataScratch)
    or [LinkedIn](https://www.linkedin.com/in/nathanrosidi/).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Science Project of Rotten Tomatoes Movie Rating Prediction:…](https://www.kdnuggets.com/2023/07/data-science-project-rotten-tomatoes-movie-rating-prediction-second-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 5: A Rotten Data Science Project • 10 AI…](https://www.kdnuggets.com/2023/n24.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311 Call Centre Performance: Rating Service Levels](https://www.kdnuggets.com/2023/03/boxplot-outlier-311-call-center-performance.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Multivariate Time-Series Prediction with BQML](https://www.kdnuggets.com/2023/07/multivariate-timeseries-prediction-bqml.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide On How To Become A Data Scientist (Step By Step Approach)](https://www.kdnuggets.com/2021/05/guide-become-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
