- en: Which flavor of BERT should you use for your QA task?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你应该选择哪种BERT风格用于你的QA任务？
- en: 原文：[https://www.kdnuggets.com/2020/10/flavor-bert-use-qa-task.html](https://www.kdnuggets.com/2020/10/flavor-bert-use-qa-task.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/10/flavor-bert-use-qa-task.html](https://www.kdnuggets.com/2020/10/flavor-bert-use-qa-task.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Olesya Bondarenko](https://www.linkedin.com/in/ovbondarenko/), [Tangible
    AI](https://tangibleai.com/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Olesya Bondarenko](https://www.linkedin.com/in/ovbondarenko/)，[Tangible
    AI](https://tangibleai.com/)**'
- en: '![Figure](../Images/efabd8cadd6a17ae6382400d8e2b50db.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/efabd8cadd6a17ae6382400d8e2b50db.png)'
- en: Photo by [Evan Dennis](https://unsplash.com/@evan__bray?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Evan Dennis](https://unsplash.com/@evan__bray?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Making an intelligent chatbot has never been easier, thanks to the abundance
    of open source natural language processing libraries, curated datasets and the
    power of transfer learning. Building a basic question-answering functionality
    with Transformers library can be as simple as this:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于开源自然语言处理库的丰富、策划的数据集和迁移学习的强大功能，制作一个智能聊天机器人从未如此简单。使用Transformers库构建一个基本的问答功能可以像这样简单：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And here is the output:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是输出结果：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: BOOM! It works!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！它工作了！
- en: That low confidence score is a little worrisome, though. You’ll see how that
    comes into play later, when we talk about BERT’s ability to detect impossible
    questions and irrelevant contexts.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那个低信心评分有点令人担忧。稍后我们讨论BERT检测不可能问题和无关背景的能力时，你会看到它的影响。
- en: However, taking some time to choose the right model for your task will ensure
    that you are getting the best possible out of the box performance from your conversational
    agent. Your choice of both language models and a benchmarking dataset will make
    or break the performance of your chatbot.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，花时间选择适合你任务的正确模型将确保你能从你的对话代理中获得最佳的开箱即用性能。你对语言模型和基准数据集的选择将决定你的聊天机器人的表现。
- en: BERT (Bidirectional Encoding Representations for Transformers) models perform
    very well on complex information extraction tasks. They can capture not only meaning
    of words, but also the context. Before choosing model (or settling for the default
    option) you probably want to evaluate your candidate model for accuracy and resources
    (RAM and CPU cycles) to make sure that it actually meets your expectations. In
    this article you will see how we benchmarked our QA model using [Stanford Question
    Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/). There
    are many other good question-answering datasets you might want to use, including
    Microsoft’s [NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset/), [CommonsenseQA](https://www.tau-nlp.org/commonsenseqa), [ComplexWebQA](https://www.tau-nlp.org/compwebq),
    and many others. To maximize accuracy for your application you’ll want to choose
    a benchmarking dataset representative of the questions, answers, and contexts
    you expect in your application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: BERT（双向编码表示转换器）模型在复杂的信息提取任务中表现非常出色。它们不仅能够捕捉单词的含义，还能捕捉上下文。在选择模型（或采用默认选项）之前，你可能需要评估候选模型的准确性和资源（RAM和CPU周期），以确保它确实符合你的期望。在这篇文章中，你将看到我们如何使用[斯坦福问答数据集（SQuAD）](https://rajpurkar.github.io/SQuAD-explorer/)对我们的QA模型进行基准测试。还有许多其他优秀的问答数据集，你可能也想使用，包括微软的[NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset/)、[CommonsenseQA](https://www.tau-nlp.org/commonsenseqa)、[ComplexWebQA](https://www.tau-nlp.org/compwebq)等。为了最大化应用的准确性，你需要选择一个代表你期望的问题、答案和上下文的基准数据集。
- en: '[Huggingface Transformers library](https://github.com/huggingface/transformers) has
    a large catalogue of pretrained models for a variety of tasks: sentiment analysis,
    text summarization, paraphrasing, and, of course, question answering. We chose
    a few candidate question-answering models from the repository of available [models](https://huggingface.co/models?filter=question-answering).
    Lo and behold, many of them have already been fine-tuned on the SQuAD dataset.
    Awesome! Here are a few SQuAD fine-tuned models we are going to evaluate:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[Huggingface Transformers库](https://github.com/huggingface/transformers)拥有大量针对各种任务的预训练模型：情感分析、文本总结、同义改写，当然还有问答。我们从可用的[模型](https://huggingface.co/models?filter=question-answering)库中选择了一些候选问答模型。果然，许多模型已经在SQuAD数据集上进行了微调。太棒了！这里是我们将要评估的几个SQuAD微调模型：'
- en: distilbert-base-cased-distilled-squad
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: distilbert-base-cased-distilled-squad
- en: bert-large-uncased-whole-word-masking-finetuned-squad
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: bert-large-uncased-whole-word-masking-finetuned-squad
- en: ktrapeznikov/albert-xlarge-v2-squad-v2
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ktrapeznikov/albert-xlarge-v2-squad-v2
- en: mrm8488/bert-tiny-5-finetuned-squadv2
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mrm8488/bert-tiny-5-finetuned-squadv2
- en: twmkn9/albert-base-v2-squad2
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: twmkn9/albert-base-v2-squad2
- en: 'We ran predictions with our selected models on both versions of SQuAD (version
    1 and version 2). The difference between them is that SQuAD-v1 contains only answerable
    questions, while SQuAD-v2 contains unanswerable questions as well. To illustrate
    this, let us look at the below example from the SQuAD-v2 dataset. An answer to
    Question 2 is impossible to derive from the given context from Wikipedia:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在SQuAD的两个版本（版本1和版本2）上使用我们选择的模型进行了预测。它们之间的区别在于，SQuAD-v1只包含可回答的问题，而SQuAD-v2还包含不可回答的问题。为了说明这一点，让我们来看下面来自SQuAD-v2数据集的例子。问题2的答案无法从维基百科提供的上下文中推导出来：
- en: '***Question 1:**** “In what country is Normandy located?”*'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***问题1：****“诺曼底位于哪个国家？”*'
- en: '***Question 2:**** “Who gave their name to Normandy in the 1000’s and 1100’s”*'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***问题2：****“谁在1000年代和1100年代将他们的名字给予了诺曼底？”*'
- en: '***Context:**** “The Normans (Norman: Nourmands; French: Normands; Latin: Normanni)
    were the people who in the 10th and 11th centuries gave their name to Normandy,
    a region in France. They were descended from Norse (“Norman” comes from “Norseman”)
    raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo,
    agreed to swear fealty to King Charles III of West Francia. Through generations
    of assimilation and mixing with the native Frankish and Roman-Gaulish populations,
    their descendants would gradually merge with the Carolingian-based cultures of
    West Francia. The distinct cultural and ethnic identity of the Normans emerged
    initially in the first half of the 10th century, and it continued to evolve over
    the succeeding centuries.”*'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***上下文：****“诺曼人（Norman: Nourmands; French: Normands; Latin: Normanni）是指在10世纪和11世纪将他们的名字给予法国诺曼底地区的人。他们的祖先是来自丹麦、冰岛和挪威的诺斯（‘诺曼’源自‘诺斯人’）劫掠者和海盗，他们在他们的领袖罗洛的带领下，同意对西法兰克国王查理三世宣誓效忠。通过几代人与当地的法兰克人和罗马高卢人的融合，他们的后代逐渐与西法兰克的加洛林文化融合。诺曼人的独特文化和民族身份最初在10世纪上半叶出现，并在随后的几个世纪中不断发展。”*'
- en: Our ideal model should be able to understand that context well enough to compose
    an answer.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理想的模型应该能够充分理解上下文以生成答案。
- en: Let us get started!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: 'To define a model and a tokenizer in Transformers, we can use AutoClasses.
    In most cases Automodels can derive the settings automatically from the model
    name. We need only a few lines of code to set it up:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Transformers中定义模型和分词器，我们可以使用AutoClasses。在大多数情况下，AutoModels可以自动从模型名称中推导出设置。我们只需要几行代码来完成设置：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will use the human level performance as our target for accuracy. SQuAD leaderboard
    provides human level performance for this task, which is 87% accuracy of finding
    the exact answer and 89% f1 score.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以人类水平的表现作为我们的准确性目标。SQuAD排行榜提供了这个任务的人类水平表现，即87%的准确率和89%的F1得分。
- en: You might ask, “How do they know what human performance is?” and “What humans
    are they talking about?” Those Stanford researchers are clever. They just used
    the same crowd-sourced humans that labeled the SQuAD dataset. For each question
    in the test set they had multiple humans provide alternative answers. For the
    human score they just left one of those answers out and checked to see if it matched
    any of the others using the same text comparison algorithm that they used to evaluate
    the machine model. The average accuracy for this “leave one human out” dataset
    is what determined the human level score that the machines are shooting for.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，“他们怎么知道人类表现是什么？”以及“他们说的是哪些人？”那些斯坦福研究人员很聪明。他们只是使用了同一组标记SQuAD数据集的众包人群。对于测试集中的每个问题，他们让多个人工提供不同的答案。为了获得人类得分，他们只是将其中一个答案留出来，并检查它是否与其他答案匹配，使用了与评估机器模型相同的文本比较算法。这种“留一个人类答案”的数据集的平均准确性就是机器所要追求的人类水平得分。
- en: 'To run predictions on our datasets, first we have to transform the SQuAD downloaded
    files into computer-interpretable features. Luckily, the Transformers library
    already has a handy set of functions to do exactly that:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们的数据集上运行预测，首先我们需要将下载的SQuAD文件转换为计算机可解释的特征。幸运的是，Transformers库已经提供了一套方便的函数来完成这一任务：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will use PyTorch and its GPU capability (optional) to make predictions:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用PyTorch及其GPU功能（可选）来进行预测：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Importantly, the model inputs should be adjusted for a DistilBERT model (such
    as `distilbert-base-cased-distilled-squad`). We should exclude the “token_type_ids”
    field due to the difference in DistilBERT implementation compared to BERT or ALBERT
    to avoid the script erroring out. Everything else will stay exactly the same.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，模型输入应该针对 DistilBERT 模型（例如 `distilbert-base-cased-distilled-squad`）进行调整。由于
    DistilBERT 与 BERT 或 ALBERT 的实现差异，我们应该排除“token_type_ids”字段，以避免脚本出错。其他所有内容将保持完全相同。
- en: 'Finally, to evaluate the results, we can apply `squad_evaluate()` function
    from Transformers library:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了评估结果，我们可以应用来自 Transformers 库的 `squad_evaluate()` 函数：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is an example report generated by squad_evaluate:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是由 squad_evaluate 生成的示例报告：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now let us compare exact answer accuracy scores (“exact”) and f1 scores for
    the predictions generated for our two benchmarking datasets, SQuAD-v1 and SQuAD-v2\.
    All models perform substantially better on the dataset without negatives (SQuAD-v1),
    but we do have a clear winner (`ktrapeznikov/albert-xlarge-v2-squad-v2`). Overall,
    it performs better on both datasets. Another great news is that our generated
    report for this model matches exactly the [report](https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2) posted
    by the author. The accuracy and f1 fall just a little short of the human level
    performance, but is still a great result for a challenging dataset like SQuAD.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们比较对我们两个基准数据集 SQuAD-v1 和 SQuAD-v2 生成的精确答案准确率（“exact”）和 f1 分数。所有模型在没有负面样本的数据集（SQuAD-v1）上的表现明显更好，但我们有一个明确的赢家（`ktrapeznikov/albert-xlarge-v2-squad-v2`）。总体而言，它在两个数据集上的表现都更好。另一个好消息是我们为这个模型生成的报告与作者发布的 [报告](https://huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2) 完全一致。准确率和
    f1 分数稍微逊色于人类水平，但对于像 SQuAD 这样具有挑战性的数据集来说仍然是一个很好的结果。
- en: '![Figure](../Images/85a80a058a58873103cf1a94c571a9d7.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/85a80a058a58873103cf1a94c571a9d7.png)'
- en: 'Table 1: Accuracy Scores for Each of 5 Models on SQuAD v1 & v2'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：5 个模型在 SQuAD v1 和 v2 上的准确率得分
- en: 'We are going to compare the full reports for SQuAD-v2 predictions in the next
    table. Looks like `ktrapeznikov/albert-xlarge-v2-squad-v2` did almost equally
    well on both tasks: (1) identifying the correct answers to the answerable questions,
    and (2) weeding out the answerable questions. Interestingly though, `bert-large-uncased-whole-word-masking-finetuned-squad` offers
    a significant (approximately 5%) boost to the prediction accuracy on the first
    task (answerable questions), but completely failing on the second task.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一个表格中比较 SQuAD-v2 预测的完整报告。看起来 `ktrapeznikov/albert-xlarge-v2-squad-v2` 在两个任务上表现几乎一样好：（1）识别可回答问题的正确答案，和（2）筛选出可回答的问题。有趣的是，`bert-large-uncased-whole-word-masking-finetuned-squad`
    在第一个任务（可回答的问题）上提供了大约 5% 的显著提升，但在第二个任务上完全失败。
- en: '![Figure](../Images/ad6851a7b682fa593807d34d0e4eb284.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ad6851a7b682fa593807d34d0e4eb284.png)'
- en: 'Table 2: Separate Accuracy Scores for Impossible Questions'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：不可回答问题的单独准确率得分
- en: 'We can optimize the model to perform better on identifying unanswerable questions
    by adjusting the null threshold for the best f1 score. Remember, the best f1 threshold
    is one of the outputs computed by the squad_evaluate function (`best_f1_thresh`).
    Here is how the prediction metrics for SQuAD-v2 change when we apply `best_f1_thresh` from
    the SQuAD-v2 report:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调整 null 阈值来优化模型在识别不可回答问题方面的表现，以获得最佳的 f1 分数。请记住，最佳的 f1 阈值是由 squad_evaluate
    函数计算的输出之一（`best_f1_thresh`）。以下是当我们应用来自 SQuAD-v2 报告的 `best_f1_thresh` 时 SQuAD-v2
    预测指标的变化情况：
- en: '![Figure](../Images/2d82c766c61c3f4c2ba9836d38e89037.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/2d82c766c61c3f4c2ba9836d38e89037.png)'
- en: 'Table 3: Adjusted Accuracy Scores'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：调整后的准确率得分
- en: While this adjustment helps the model more accurately identify the unanswerable
    questions, it does so at the expense of the accuracy of answered questions. This
    trade-off should be carefully considered in the context of your application.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种调整有助于模型更准确地识别不可回答的问题，但它以回答问题的准确性为代价。这个权衡应该在你的应用背景下仔细考虑。
- en: 'Let’s use the Transformers QA pipeline to test drive the three best models
    with a few questions of our own. We picked the following the following passage
    from a Wikipedia article on computational linguistics as an unseen example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Transformers QA 流水线测试三种最佳模型，并提出一些我们自己的问题。我们从一篇关于计算语言学的维基百科文章中挑选了以下未见示例：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note that the last two questions are impossible to answer from the given context.
    Here is what we got from each model we tested:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，最后两个问题在给定的上下文中是无法回答的。以下是我们测试的每个模型的结果：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, it is hard to evaluate a model based on a single data point,
    since the results are all over the map. While each model gave the correct answer
    to the first question (“When was computational linguistics invented?”), the other
    questions proved to be more difficult. This means that even our best model probably
    should be fine-tuned again on a custom dataset to improve further.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，仅凭单个数据点很难评估模型，因为结果差异很大。虽然每个模型对第一个问题（“计算语言学是什么时候发明的？”）给出了正确答案，但其他问题则更具挑战性。这意味着即使是我们最好的模型也可能需要在自定义数据集上进行进一步调整，以实现更好的效果。
- en: 'Take away:'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 要点：
- en: Open source pretrained (and fine-tuned!) models can kickstart your natural language
    processing project.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开源预训练（和微调过的！）模型可以为你的自然语言处理项目提供快速启动。
- en: Before anything else, try to reproduce the original results reported by the
    author, if available.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在做其他事情之前，尽量复现作者报告的原始结果（如果可用）。
- en: Benchmark your models for accuracy. Even models fine-tuned on the exact same
    dataset can perform very differently.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对模型进行准确性基准测试。即使是对完全相同的数据集进行微调的模型，也可能表现出很大的差异。
- en: '**Bio: [Olesya Bondarenko](https://www.linkedin.com/in/ovbondarenko/)** is
    Lead Developer at Tangible AI where she leads the effort to make QAry smarter.
    QAry is an open source question answering system you can trust with your most
    private data and questions.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Olesya Bondarenko](https://www.linkedin.com/in/ovbondarenko/)** 是 Tangible
    AI 的首席开发者，她负责推动 QAry 变得更智能。QAry 是一个你可以信赖的开源问答系统，适用于最私密的数据和问题。'
- en: '[Original](https://tangibleai.com/benchmarking-bert-based-transformers-for-question-answering-and-reading-comprehension-tests/).
    Reposted with permission.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://tangibleai.com/benchmarking-bert-based-transformers-for-question-answering-and-reading-comprehension-tests/)。经允许转载。'
- en: '**Related:**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[BERT, RoBERTa, DistilBERT, XLNet: Which one to use?](/2019/09/bert-roberta-distilbert-xlnet-one-use.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT、RoBERTa、DistilBERT、XLNet：使用哪一个？](/2019/09/bert-roberta-distilbert-xlnet-one-use.html)'
- en: '[Simple Question Answering (QA) Systems That Use Text Similarity Detection
    in Python](/2020/04/simple-question-answering-systems-text-similarity-python.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中使用文本相似性检测的简单问答系统](/2020/04/simple-question-answering-systems-text-similarity-python.html)'
- en: '[Spotting Controversy with NLP](/2020/05/spotting-controversy-nlp.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 NLP 识别争议](/2020/05/spotting-controversy-nlp.html)'
- en: '* * *'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织中的 IT 工作'
- en: '* * *'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Best Architecture for Your Text Classification Task: Benchmarking…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为你的文本分类任务选择最佳架构：基准测试…](https://www.kdnuggets.com/2023/04/best-architecture-text-classification-task-benchmarking-options.html)'
- en: '[Which Metric Should I Use? Accuracy vs. AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我应该使用哪个指标？准确率与 AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
- en: '[ETL vs ELT: Which One is Right for Your Data Pipeline?](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL 与 ELT：哪个更适合你的数据管道？](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
- en: '[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RAG 与 Finetuning：哪一个是提升你 LLM 应用的最佳工具？](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该使用线性回归模型而不是…的 3 个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
