- en: The “Hello World” of Tensorflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Tensorflow is an open-source end-to-end machine learning framework that makes
    it easy to train and deploy the model.
  prefs: []
  type: TYPE_NORMAL
- en: It consists of two words - tensor and flow. A tensor is a vector or a multidimensional
    array that is a standard way of representing the data in deep learning models.
    Flow implies how the data moves through a graph by undergoing the operations called
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: It is used for numerical computation and large-scale machine learning by bundling
    various algorithms together. Besides, it also allows the flexibility and control
    to build models with high-level Keras API.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will build a beginner-friendly machine learning model using
    TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: We will be using credit card fraud detection data sourced from [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?datasetId=310&sortBy=voteCount).
  prefs: []
  type: TYPE_NORMAL
- en: '**The article is structured as follows:**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understand the problem statement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load the data and required libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the data and evaluation metric for model selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing values
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Transformation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the class imbalance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Build TensorFlow model with class imbalance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate the model performance
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handle class imbalance and train the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare model performance with and without class imbalance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problem Statement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Credit card transactions are subject to the risk of fraud i.e. those transactions
    are made without the knowledge of the customer. Machine learning models are deployed
    at various credit card companies to identify and flag potentially fraudulent transactions
    and timely act on them.
  prefs: []
  type: TYPE_NORMAL
- en: Load Data and Required Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have made two imports from TensorFlow:'
  prefs: []
  type: TYPE_NORMAL
- en: Dense layers where each neuron from the current layer is connected with all
    the neurons from the previous layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another import is the Sequential model which is used to build the neural network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Load Data and Required Libraries](../Images/7fb515c5ded31d4df9c2f0eec291b4d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Get the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Get the Data](../Images/e94204f7189ed8344e1e71f1993cfd1c.png)'
  prefs: []
  type: TYPE_IMG
- en: Splitting Into Train and Test Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have kept 20% of the data for evaluating the model performance and would
    start exploring the train data. Test data will be prepared in the same way as
    the train data along with all the transformations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Splitting Into Train and Test Data](../Images/57d4ea9e8da5ad3d9d3d55341e383a86.png)'
  prefs: []
  type: TYPE_IMG
- en: Understanding the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The data consists of PCA transformed numerical input variables that are masked,
    hence there is limited scope in understanding the attributes from business prerogative.
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding the Data](../Images/7bc56b1038b0995bfbcc4c2434624c05.png)'
  prefs: []
  type: TYPE_IMG
- en: We have used [tensorflow data validation](https://www.tensorflow.org/tfx/data_validation/get_started)
    library to visualize the attributes, it helps in understanding the training and
    the test data by computing descriptive statistics and detecting anomalies.
  prefs: []
  type: TYPE_NORMAL
- en: '![descriptive statistics and detecting anomalies](../Images/1d14eb27040d7e8f70c81215cde4b727.png)'
  prefs: []
  type: TYPE_IMG
- en: Besides, the attributes do not have any missing value and are PCA transformed,
    hence we are not performing any data transformation on these attributes. In the
    above visualization, you also have an option of performing log transformation
    to visualize the transformed data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Missing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There is no missing value in any of the attributes as shown in the missing
    column in the above image, you can also do a quick check to sum all the null values
    across the attributes as below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![no missing value](../Images/a156723c1dfb397290d5598b9a5bb80e.png)'
  prefs: []
  type: TYPE_IMG
- en: Train and Test Characteristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most critical assumptions in ML data modeling is that train and test
    dataset belong to similar distribution, as is evident from graphs below. The degree
    of the overlap between the train and test data distribution gives confidence that
    the trained model will be able to generalize well on the test data. It is important
    to keep monitoring if the serving data distribution deviates from the data on
    which the machine learning model was trained. You can then decide when to [retrain
    the model](https://towardsdatascience.com/when-are-you-planning-to-retrain-your-machine-learning-model-5349eb0c4706)
    with what partition of data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Train and Test Characteristics](../Images/00dd1d863c1e971bd3107ba5ef8a223c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also check out of domain value and detect errors or anomalies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![detect errors or anomalies](../Images/4aa3f41311973d11b76472d1b1081ad9.png)'
  prefs: []
  type: TYPE_IMG
- en: Data Transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As all the attributes except ‘Amount’ are PCA transformed, we will focus on
    ‘Amount’ and standardize it as below:'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Test Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will prepare the test data by applying the same transformations as were
    done on the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![scalar](../Images/3906775bd93df5f78dcce66aa6f0b4f1.png)'
  prefs: []
  type: TYPE_IMG
- en: Build the Baseline TensorFlow Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides the units of neurons and the type of [activation function](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6),
    the first layer needs an additional input in the form of a number of input variables.
    The first two layers have ReLU activation which is a nonlinear function, you can
    read more on it [here](https://deepai.org/machine-learning-glossary-and-terms/relu).
    We need the output as the probability of which class the transaction belongs to,
    hence the sigmoid activation function is chosen in the last layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Build the Baseline TensorFlow Model](../Images/d6655fda301d8e53f982b3b8203758f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Evaluation Metric
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our objective is to reduce the false negatives, that is if the model declares
    a transaction as non-fraud and legitimate and it turns out to be false, then the
    whole purpose of building the model gets defeated. The model has passed through
    the fraudulent transaction which is worse than flagging the legitimate transaction
    as fraud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what cost the ecosystem pays for the False Positives: If the customer
    makes a genuine transaction but due to a high false-positive rate, the model falsely
    claims this to be a fraud, and the transaction is declined. The customer has to
    go through additional authentication steps to confirm that he/she has triggered
    it. This hassle is also a cost but is less than the cost of letting the fraud
    pass through. Having said that, the good model can not block every transaction
    making it a pain for the genuine customers - hence a certain degree of precision
    is also important.'
  prefs: []
  type: TYPE_NORMAL
- en: F1 is the harmonic mean of precision and recall. Depending upon which one is
    more important for the business metric, one can be given more weight than the
    other. This can be achieved by [fbeta_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#:~:text=Compute%20the%20F%2Dbeta%20score,recall%20in%20the%20combined%20score.)
    which is the weighted harmonic mean of precision and recall, where beta is the
    weight of recall in the combined score.
  prefs: []
  type: TYPE_NORMAL
- en: '| beta < 1 | more weight to precision |'
  prefs: []
  type: TYPE_TB
- en: '| beta < 1 | more weight to recall  |'
  prefs: []
  type: TYPE_TB
- en: '| beta = 0 | considers only precision |'
  prefs: []
  type: TYPE_TB
- en: '| beta = inf | considers only recall |'
  prefs: []
  type: TYPE_TB
- en: Hence, for the purpose of this article, we are using an F2 score that gives
    twice the weightage to recall.
  prefs: []
  type: TYPE_NORMAL
- en: Handling the Class Imbalance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have downsampled the majority class by taking a random sample of 10% and
    concatenating it back with the minority class i.e. fraud transactions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Handling the Class Imbalance](../Images/809bcba318ca9f7ee39d971ba6f8aa66.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that we have separated the train and test data before, and kept the test
    data aside to compare the model output from both the versions i.e. trained with
    and without class imbalance handling.
  prefs: []
  type: TYPE_NORMAL
- en: A Model Trained with Class Imbalance Handled
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The new model is trained on data distribution as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A Model Trained with Class Imbalance Handled<](../Images/941ca7d431c415f49b198ec3a708011b.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see above, the recall has increased from 80% to 87% for class 1, albeit
    at the cost of a decline in precision. Also, the F2 score has increased from 82%
    to 84.5% in the revised model trained with improved class-balanced data distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you can adjust the cut-off to achieve the target recall and precision
    values.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we have built a neural network model to identify fraudulent
    transactions. Since the dataset is imbalanced, we have undersampled the majority
    class to improve the class distribution. This has resulted in improved recall
    value (primary metric) for the concerned class i.e. class 1 and improved F2 score.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Vidhi Chugh](https://vidhi-chugh.medium.com/)** is an award-winning AI/ML
    innovation leader and an AI Ethicist. She works at the intersection of data science,
    product, and research to deliver business value and insights. She is an advocate
    for data-centric science and a leading expert in data governance with a vision
    to build trustworthy AI solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free TensorFlow 2.0 Complete Course](https://www.kdnuggets.com/2023/02/free-tensorflow-20-complete-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
