- en: GitHub Copilot and the Rise of AI Language Models in Programming Automation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GitHub Copilot 和 AI 语言模型在编程自动化中的崛起
- en: 原文：[https://www.kdnuggets.com/2021/09/github-copilot-rise-ai-language-models-programming-automation.html](https://www.kdnuggets.com/2021/09/github-copilot-rise-ai-language-models-programming-automation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/09/github-copilot-rise-ai-language-models-programming-automation.html](https://www.kdnuggets.com/2021/09/github-copilot-rise-ai-language-models-programming-automation.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![github-copilot.png](../Images/f743ba56a5a0da8a4fcc8af23f6f1b1e.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![github-copilot.png](../Images/f743ba56a5a0da8a4fcc8af23f6f1b1e.png)'
- en: Should I Use Github Copilot?
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我应该使用 Github Copilot 吗？
- en: If you are a software engineer, or count any of them among your circle of acquaintances,
    then you're probably already aware at some level of [Copilot](https://copilot.github.com/).
    Copilot is GitHub's new deep learning code completion tool.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是软件工程师，或者在你的朋友圈里有软件工程师，那么你可能已经在某种程度上了解过[Copilot](https://copilot.github.com/)。Copilot
    是 GitHub 新推出的深度学习代码补全工具。
- en: Autocomplete tools for programmers are nothing new, and Copilot is not even
    the first to make use of deep learning nor even the first to use a GPT transformer.
    After all,[ TabNine](https://www.tabnine.com/) sprung out of a summer project
    by OpenAI alum[ Jacob Jackson](https://jacobjackson.com/about/) and makes use
    of the [GPT-2](https://www.exxactcorp.com/blog/Deep-Learning/examining-the-transformer-architecture-part-1-the-openai-gpt-2-controversy) general
    purpose transformer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对于程序员来说，自动补全工具并不新鲜，而 Copilot 甚至不是第一个使用深度学习的工具，也不是第一个使用 GPT 转换器的工具。毕竟，[TabNine](https://www.tabnine.com/)
    源自 OpenAI 校友[ Jacob Jackson](https://jacobjackson.com/about/) 的一个夏季项目，并且使用了[GPT-2](https://www.exxactcorp.com/blog/Deep-Learning/examining-the-transformer-architecture-part-1-the-openai-gpt-2-controversy)通用转换器。
- en: Microsoft (which owns GitHub) has packaged their own[ IntelliSense](https://en.wikipedia.org/wiki/IntelliSense#Visual_Studio) code
    completion tool with programming products since at least 1996, and autocomplete
    and text correction has been an active area of research since the 1950s.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 微软（拥有 GitHub）自 1996 年以来就将自己的[ IntelliSense](https://en.wikipedia.org/wiki/IntelliSense#Visual_Studio) 代码补全工具打包到编程产品中，并且自动补全和文本纠正自
    1950 年代以来一直是一个活跃的研究领域。
- en: Read on if you’d like to learn more about what makes Copilot different from
    previous autocomplete tools (including TabNine), and why this particular tool
    has been generating so much controversy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于 Copilot 如何与之前的自动补全工具（包括 TabNine）不同，以及为什么这个特定工具引发了如此多的争议，请继续阅读。
- en: Copyright Controversy
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 版权争议
- en: '![Screenshot demonstrating GitHub Copilot’s eagerness to recite the fast inverse
    square root function from Quake III.](../Images/dba992587634031ad862e0e6b33f6791.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![展示 GitHub Copilot 渴望背诵 Quake III 中的 fast inverse square root 函数的截图。](../Images/dba992587634031ad862e0e6b33f6791.png)'
- en: '*Screenshot of *[*Armin Ronacher*](https://twitter.com/mitsuhiko/status/1410886329924194309)* demonstrating
    GitHub Copilot’s eagerness to recite the *[*fast inverse square root *](https://en.wikipedia.org/wiki/Fast_inverse_square_root#Overview_of_the_code)*function
    from Quake III.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*展示 GitHub Copilot 渴望背诵 Quake III 中的*[*fast inverse square root*](https://en.wikipedia.org/wiki/Fast_inverse_square_root#Overview_of_the_code)*函数的*[*Armin
    Ronacher*](https://twitter.com/mitsuhiko/status/1410886329924194309)*的截图。*'
- en: Since its inception, Copilot has fueled a heated discussion about the product
    and its potential copyright implications. In large part this is due to the way
    the model was trained. GitHub Copilot is based on OpenAI’s Codex, a variant of
    GPT-3 fine-tuned on code. [GPT-3](https://www.exxactcorp.com/blog/Deep-Learning/what-can-you-do-with-the-openai-gpt-3-language-model) is
    OpenAI’s 175 billion-parameter (Codex is apparently based on the 12-billion parameter
    version of GPT-3) general-purpose transformer, and of course any giant transformer
    needs a giant training dataset to be effective. GitHub is just the place to find
    such a dataset, and Copilot’s training dataset[ included all public code](https://nitter.hu/NoraDotCodes/status/1412741339771461635) hosted
    by GitHub.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自推出以来，Copilot 引发了关于该产品及其潜在版权问题的激烈讨论。这在很大程度上是由于模型的训练方式。GitHub Copilot 基于 OpenAI
    的 Codex，这是 GPT-3 的一个变体，经过针对代码的微调。[GPT-3](https://www.exxactcorp.com/blog/Deep-Learning/what-can-you-do-with-the-openai-gpt-3-language-model)是
    OpenAI 的 1750 亿参数的通用转换器（Codex 显然基于 GPT-3 的 120 亿参数版本），当然，任何大型转换器都需要一个巨大的训练数据集才能有效。GitHub
    正是寻找这种数据集的地方，而 Copilot 的训练数据集[包含了 GitHub 上托管的所有公开代码](https://nitter.hu/NoraDotCodes/status/1412741339771461635)。
- en: This is a principal source of controversy surrounding the project, surpassing
    the discussion about[ automating away software engineering](https://aveuiller.github.io/is_copilot_a_threat.html) and
    the impact of tools like Copilot on the future of programming. More technical
    information about the model and its limitations can be found in the[ paper on
    Arxiv](https://arxiv.org/abs/2107.03374).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是围绕该项目争议的主要来源，超出了关于[自动化软件工程](https://aveuiller.github.io/is_copilot_a_threat.html)以及像
    Copilot 这样的工具对编程未来影响的讨论。关于模型及其限制的更多技术信息可以在[Arxiv上的论文](https://arxiv.org/abs/2107.03374)中找到。
- en: '![](../Images/c1f25f2cf0b9c728f2ed25eab6362e01.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1f25f2cf0b9c728f2ed25eab6362e01.png)'
- en: '*Portrait of Edmond de Belamy.” Collective Obvious used open source code to
    generate the piece, later selling for over $400,000 at auction, much to the chagrin
    of Robbie Barrat, whose code they used.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*“贝拉米勋爵的肖像。”* Collective Obvious 使用开源代码生成了这件作品，后来在拍卖会上以超过 40 万美元的价格售出，这让使用了他们代码的
    Robbie Barrat 十分不满。'
- en: Some programmers are simply upset that their code contributed to what is likely
    to become a paid product without their explicit permission, with a few commenters
    on[ hacker news](https://news.ycombinator.com/item?id=27724042) discussing leaving
    the platform.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一些程序员对他们的代码被用于可能成为付费产品的情况感到不满，尤其是在没有他们明确许可的情况下。几位评论者在[黑客新闻](https://news.ycombinator.com/item?id=27724042)上讨论了离开该平台的可能性。
- en: In some ways the reaction to Copilot echoes of the [GAN-generated "painting](https://medium.datadriveninvestor.com/432-000-painting-by-ai-sold-at-christies-my-thoughts-4a33cd94f782?gi=2589317f7968)”
    that sold for nearly half a million dollars at auction. The[ art piece was created
    on top of open source contributions ](https://github.com/robbiebarrat/art-dcgan)with
    a lineage of multiple authors, none of whom received any compensation that we
    know of as reward for the noteworthy success of the work at auction.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，对 Copilot 的反应让人想起了[GAN生成的“画作”](https://medium.datadriveninvestor.com/432-000-painting-by-ai-sold-at-christies-my-thoughts-4a33cd94f782?gi=2589317f7968)，这幅画作在拍卖会上售出了近五十万美元。这[艺术品基于开源贡献](https://github.com/robbiebarrat/art-dcgan)创建，作者有多个，但我们知道的情况是没有人因该作品在拍卖会上的显著成功而获得任何报酬。
- en: The [code](https://github.com/robbiebarrat/art-dcgan) used to produce the artwork,
    and potentially the pre-trained model weights as well, was made publicly available
    under a BSD license by the model’s author, Robbie Barrat, whose own work was based
    on previous open source projects and who later modified the license to disallow
    commercial use of the pre-trained weights. It’s understandable for programmers
    to be frustrated when left out of profitable uses of their work, but there’s more
    to the copyright controversy surrounding Copilot than that.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成艺术作品所用的[代码](https://github.com/robbiebarrat/art-dcgan)及可能的预训练模型权重，都是由模型作者
    Robbie Barrat 以 BSD 许可证公开提供的。Robbie Barrat 的工作基于之前的开源项目，后来修改了许可证以禁止对预训练权重的商业使用。当程序员被排除在他们工作的盈利用途之外时感到沮丧是可以理解的，但围绕
    Copilot 的版权争议远不止于此。
- en: '***”github Copilot has, by their own admission, been trained on mountains of
    gpl code, so i''m unclear on how it''s not a form of laundering open source code
    into commercial works.***”*-Twitter user *[*eevee*](https://twitter.com/eevee/status/1410037309848752128)*.*'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***“github Copilot 依其自身的承认，已经在大量 GPL 代码上进行了训练，因此我不明白它如何不是一种将开源代码洗白为商业作品的方式。”***
    - 推特用户 *[*eevee*](https://twitter.com/eevee/status/1410037309848752128)*。'
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*GitHub Copilot is demonstrably capable of reproducing extended sections of
    copyleft code, which many in the open source community consider a violation of
    the terms of licenses like GPL.*'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*GitHub Copilot 显然能够复制大量 copyleft 代码，这被许多开源社区人士视为违反 GPL 等许可证条款。*'
- en: Copilot was trained on all public code, including permissive open source licenses
    like the[ MIT License](https://mit-license.org/). However, it also copyleft licenses
    like the[ Affero General Public License](https://www.gnu.org/licenses/agpl-3.0.en.html) (AGPL)
    that allows use and modification, but requires modified works to be made available
    under the same license. In some interpretations,[ code generated](https://www.theverge.com/2021/7/7/22561180/github-copilot-legal-copyright-fair-use-public-code) by
    GitHub Copilot can be considered derivative of the original training data, and
    perhaps more problematically Copilot can sometimes[ reproduce code](https://docs.github.com/en/github/copilot/research-recitation#footnote3) from
    the training dataset verbatim. That makes Copilot a trickier case than, say, the
    Google book-scanning precedent often cited as a cornerstone of fair use for scraping
    copyrighted data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot 的训练数据包括所有公共代码，包括诸如[ MIT 许可证](https://mit-license.org/) 这样的宽松开源许可证。然而，它也包括诸如[ Affero
    通用公共许可证](https://www.gnu.org/licenses/agpl-3.0.en.html) (AGPL) 这样的 copyleft 许可证，该许可证允许使用和修改，但要求修改后的作品必须在相同许可证下提供。在一些解释中，[ GitHub
    Copilot 生成的代码](https://www.theverge.com/2021/7/7/22561180/github-copilot-legal-copyright-fair-use-public-code)
    可能被视为原始训练数据的衍生作品，更有问题的是，Copilot 有时可能[ 逐字重现训练数据集中的代码](https://docs.github.com/en/github/copilot/research-recitation#footnote3)。这使得
    Copilot 的情况比例如 Google 图书扫描先例更加复杂，后者通常被引用为版权数据抓取合理使用的基石。
- en: The discussion on potential legal issues continues with little consensus from[ either](https://archive.is/gBPLC)[ side](https://juliareda.eu/2021/07/github-copilot-is-not-infringing-your-copyright/) of
    the debate for now, and the subject may very likely become an issue for the courts
    to resolve.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 关于潜在法律问题的讨论仍在继续，目前两方没有达成共识，[ 两方](https://archive.is/gBPLC)的讨论仍在进行，[ 双方](https://juliareda.eu/2021/07/github-copilot-is-not-infringing-your-copyright/)可能很快就会成为法院裁决的问题。
- en: Even if we assume that Copilot is totally in the clear legally, there may be
    other risks to using the product. If Copilot’s training is considered fair use
    and its output is not considered derivative or copyright/copyleft infringing work,
    it could still produce output that easily fits the criteria for plagiarism in
    the context of something like a PhD student writing code for their thesis research.
    For the time being it may be a good idea to use Copilot carefully, but there’s
    another reason that Copilot is a trending topic of discussion: **Copilot can give
    surprisingly good solutions to common programming tasks, and appears to be both
    quantitatively and qualitatively more capable than previous autocomplete tools.**
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们假设 Copilot 在法律上完全没有问题，使用该产品仍可能存在其他风险。如果 Copilot 的训练被视为合理使用，而其输出不被视为衍生或侵犯版权/开源协议的作品，它仍可能产生容易符合剽窃标准的输出，例如在博士生为其论文研究编写代码的情况下。目前，谨慎使用
    Copilot 可能是一个好主意，但还有另一个原因使 Copilot 成为热门话题：**Copilot 能为常见编程任务提供令人惊讶的好解决方案，并且在数量和质量上都比以前的自动补全工具更强大。**
- en: How Good is GitHub’s Copilot?
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GitHub 的 Copilot 有多好？**'
- en: '![Youtube video showing how Github copilot crushes leetcode interview questions](../Images/93aba992c6a1af14bade88886b2d0306.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![显示 GitHub Copilot 如何打破 Leetcode 面试题的 YouTube 视频](../Images/93aba992c6a1af14bade88886b2d0306.png)'
- en: '*GitHub Copilot CRUSHES Leetcode Interview Questions! [Source](https://www.youtube.com/watch?v=FHwnrYm0mNc)*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*GitHub Copilot 打破了 Leetcode 面试题！[来源](https://www.youtube.com/watch?v=FHwnrYm0mNc)*'
- en: Even if you’re not a programmer, you’ve probably had some experience with autocomplete
    in the form of predictive text on a mobile phone. This will automatically suggest
    the next word as you begin to type it, and may suggest a slightly longer continuation
    such as to finish the current sentence.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不是程序员，你也可能经历过手机上的自动补全，它会在你开始输入时自动建议下一个单词，可能还会建议稍长的补全，比如完成当前句子。
- en: For most programming autocomplete tools the amount and complexity of suggestions
    is roughly similar to what you’d find in a mobile phone keyboard, but not all
    code completion tools use modern (aka deep learning) machine learning.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数编程自动补全工具，建议的数量和复杂性大致类似于你在手机键盘上找到的内容，但并非所有代码补全工具都使用现代（即深度学习）机器学习。
- en: The default autocomplete in vim, for example, will simply offer a list of suggested
    completions based on the words that a user has entered previously. More recently
    developed code completion tools like[ TabNine](https://www.tabnine.com/) or[ Kite](https://www.kite.com/) are
    a little more sophisticated and can suggest the completion of the rest of a line
    or two. The Kite website suggests this is enough to make a programmer nearly twice
    as efficient in terms of the number of keystrokes used, but Github Copilot takes
    this one step further, albeit with a very long stride.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，vim中的默认自动补全功能会根据用户之前输入的单词提供一个建议补全的列表。较新的代码补全工具，如[TabNine](https://www.tabnine.com/)或[Kite](https://www.kite.com/)，则更为复杂，可以建议完成整行或两行的剩余部分。Kite网站建议，这足以使程序员在键击次数上提高近两倍，但GitHub
    Copilot则更进一步，虽然其步伐非常长。
- en: Copilot has similar completion capabilities to the standard language GPT-3 it
    is based on, and working with the code completion tool looks and feels similar
    to the style of “[prompt programming](https://generative.ink/posts/methods-of-prompt-programming/)”
    that GPT-3 experimenters have adopted when working with the model. Copilot can
    interpret the contents of a docstring and write a function to match, or given
    a function and the start of an appropriately named test function it can generate
    unit tests. **That saves a lot more than 50% of a programmer’s keystrokes.**
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot具有与其基础的标准语言GPT-3类似的补全能力，使用该代码补全工具的体验与GPT-3实验者在使用模型时采用的“[提示编程](https://generative.ink/posts/methods-of-prompt-programming/)”风格类似。Copilot可以解释文档字符串的内容并编写匹配的函数，或者在给定函数和适当命名的测试函数开头时生成单元测试。**这比程序员的键击次数节省了超过50%。**
- en: Taken to its logical conclusion, when Copilot works perfectly it turns the job
    of a software engineer into something that looks a lot more like constant code
    review than writing code.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将其推向极致，当Copilot工作完美时，它将软件工程师的工作变成了更像是不断的代码审查，而不是编写代码。
- en: Several programmer-bloggers with early access to the technical preview version
    have put Copilot to the test by essentially challenging the model to solve interview-level
    programming problems. Copilot is pretty impressive in[ how well](https://medium.com/@giacaglia/can-github-copilot-crack-a-facebook-coding-interview-eea172994e06) it
    can solve these types of challenges, but not good enough to warrant using its
    output without carefully reviewing it first.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一些拥有早期技术预览版本的程序员博客作者通过挑战模型解决面试级编程问题来测试Copilot。Copilot在[如何有效](https://medium.com/@giacaglia/can-github-copilot-crack-a-facebook-coding-interview-eea172994e06)解决这些挑战方面相当令人印象深刻，但还不够好，无法在未经仔细审查的情况下直接使用其输出。
- en: Several online software engineers have put the “AI pair programmer” (as GitHub
    puts it) to the test. We’ll go through some of the points identified in the[ Arxiv
    paper](https://arxiv.org/abs/2107.03374) as scenarios where Codex falls short
    and try to find examples in the experiments conducted by programmers involved
    in the technical preview.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一些在线软件工程师已经对“AI配对程序员”（如GitHub所称）进行了测试。我们将探讨[Arxiv 论文](https://arxiv.org/abs/2107.03374)中指出的一些Codex表现不足的场景，并尝试在技术预览阶段的程序员实验中找到相关例子。
- en: The HumanEval Dataset
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HumanEval数据集
- en: 'OpenAI Codex is a ~12 billion parameter GPT-3 fine-tuned on code, with Codex-S
    being the most advanced variant of Codex itself. To evaluate the performance of
    this model, OpenAI built what they call the HumanEval dataset: a collection of
    164 hand-written programming challenges with corresponding unit tests, the sort
    you might find on a coding practice site like[ CodeSignal](https://codesignal.com/),
    Codeforces, or[ HackerRank](https://www.hackerrank.com/).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI Codex是一个大约12亿参数的GPT-3，经过针对代码的微调，其中Codex-S是Codex本身的最先进变体。为了评估该模型的性能，OpenAI建立了他们所称的HumanEval数据集：一个包含164个手写编程挑战及相应单元测试的集合，这些挑战类似于你可能在[CodeSignal](https://codesignal.com/)、Codeforces或[HackerRank](https://www.hackerrank.com/)等编码练习网站上找到的。
- en: In HumanEval, the problem specifications are included in function docstrings,
    and the problems are all written for the Python programming language.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在HumanEval中，问题规范包含在函数文档字符串中，所有问题都为Python编程语言编写。
- en: While an undifferentiated GPT-3 without code-specific was unable to solve any
    of the problems in the HumanEval dataset (at least on the first try), the fine-tuned
    Codex and Codex-S were able to solve 28.8% and 37.7% of problems, respectively.
    By cherry-picking from the top-100 attempts at the problems, Codex-S was further
    able to solve 77.5% of problems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管没有代码特定的GPT-3在HumanEval数据集中无法解决任何问题（至少在第一次尝试时），但经过微调的Codex和Codex-S分别能够解决28.8%和37.7%的问题。通过从前100个问题尝试中挑选，Codex-S进一步解决了77.5%的问题。
- en: One way to interpret this is that if a programmer was using Codex, they could
    expect to find a valid solution to a problem (at roughly the level of complexity
    encountered in technical interviews) by looking through the first 100 suggestions,
    or even blindly throwing attempted solutions at a valid set of unit tests until
    they pass. That’s not to say a better solution can’t be found, if a programmer
    is willing to modify suggestions from Codex, in one of the first few suggestions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解读方式是，如果程序员使用Codex，他们可以期望在查看前100个建议时找到有效的解决方案（大致相当于技术面试中遇到的复杂程度），或者甚至可以盲目地将尝试的解决方案抛向有效的单元测试集，直到它们通过。这并不是说不能找到更好的解决方案，如果程序员愿意修改Codex的建议，可能会在前几个建议中找到。
- en: They also used a more complicated estimator for solving each problem by generating
    around 200 samples and calculating an unbiased estimator of the proportion of
    samples that pass unit tests, which they report as “pass@k” where k is 100, the
    number of samples being estimated. This method has a lower variance than reporting
    pass@k directly.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还使用了一种更复杂的估计器来解决每个问题，通过生成大约200个样本并计算样本通过单元测试的无偏估计器，他们报告为“pass@k”，其中k为100，即正在估计的样本数量。这种方法的方差低于直接报告pass@k。
- en: The Best Codex Model Still Under-Performs a Computer Science Student
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最佳Codex模型仍然不如计算机科学学生
- en: The authors of Codex note that, being trained on over 150GB in hundreds of millions
    of lines of code from GitHub, the model has been trained on significantly more
    code than a human programmer can expect to read over the course of their careers.
    However, the best Codex model (Codex-S with 12 billion parameters) still under-performs
    the abilities of a novice computer science student or someone who spends a few
    afternoons practicing interview-style coding challenges.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Codex的作者指出，由于在GitHub上的数亿行代码中进行了超过150GB的训练，该模型接受了比人类程序员在其职业生涯中能够阅读的代码量多得多的训练。然而，最好的Codex模型（具有120亿参数的Codex-S）仍然表现不如一个新手计算机科学学生或一个花费几个下午练习面试风格编码挑战的人。
- en: In particular, Codex performance degrades rapidly when chaining together several
    operations in a problem specification.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是，当在问题规格中将多个操作链在一起时，Codex的性能会迅速下降。
- en: In fact, the ability of Codex to solve several operations chained together drops
    by a factor of 2 or worse for each additional instruction in the problem specification.
    To quantify this effect, the authors at OpenAI built an evaluation set of string
    manipulations that could operate sequentially (change to lowercase, replace every
    other character with a certain character, etc.). For a single string manipulation,
    Codex passed nearly 25% of problems, dropping to just below 10% for 2 string manipulations
    chained together, 5% for 3, and so on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，Codex解决多个操作链在一起的问题的能力每增加一个问题规格中的额外指令都会降低2倍或更差。为了量化这一效果，OpenAI的作者构建了一组可以顺序操作的字符串处理评估集（例如，将字符改为小写，将每隔一个字符替换为某个字符等）。对于单个字符串处理，Codex通过了近25%的问题，而对于两个字符串处理链在一起的情况则降至不到10%，三个处理降至5%，以此类推。
- en: The rapid drop-off in solving multi-step problems was seen by an early Copilot
    reviewer[ Giuliano Giacaglia](https://medium.com/@giacaglia/can-github-copilot-crack-a-facebook-coding-interview-eea172994e06) on
    Medium. Giuliano reports giving Copilot a problem description of reversing the
    letters in each word in an input string, but instead Copilot suggested a function
    that reverses the order of words in a sentence, not letters in a sentence of words
    (“World Hello” instead of “olleH dlroW”). Copilot did, however, manage to write
    a test that failed for its own implementation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一位早期的Copilot评论员[Giuliano Giacaglia](https://medium.com/@giacaglia/can-github-copilot-crack-a-facebook-coding-interview-eea172994e06)在Medium上观察到了多步问题解决的急剧下降。Giuliano报告称，给Copilot一个问题描述是反转输入字符串中每个单词的字母，但Copilot却建议了一个反转句子中单词顺序的函数，而不是句子中字母的顺序（“World
    Hello”而不是“olleH dlroW”）。不过，Copilot确实设法编写了一个对其自身实现失败的测试。
- en: Although not sticking to the multi-step string manipulation paradigm used by
    Giuliano and OpenAI to test Copilot,[ Kumar Shubham](https://towardsdatascience.com/testing-the-github-copilot-technical-preview-330d1b0d5418) discovered
    an impressive result when Copilot successfully solved a multi-step problem description
    that involved calling system programs to take a screenshot, run optical character
    recognition on the image, and finally extract email addresses from the text. That
    does, however, raise the issue that Copilot may write code that relies on unavailable,
    out-of-date, or untrusted external dependencies. That’s a point raised by OpenAI
    alongside the model’s susceptibility to bias, ability to generate security vulnerabilities,
    and potential economic and energy costs in the section of their paper discussing
    risks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管没有坚持 Giuliano 和 OpenAI 用于测试 Copilot 的多步骤字符串操作范式，[ Kumar Shubham](https://towardsdatascience.com/testing-the-github-copilot-technical-preview-330d1b0d5418)
    发现 Copilot 成功解决了一个多步骤问题描述，该问题涉及调用系统程序截图、对图像进行光学字符识别，最后从文本中提取电子邮件地址。然而，这也提出了一个问题，即
    Copilot 可能会编写依赖于不可用、过时或不受信任的外部依赖项的代码。这一点在 OpenAI 讨论风险的论文部分中提到了模型的偏见、生成安全漏洞的能力以及潜在的经济和能源成本。
- en: Other reviews of Copilot by YouTubers[ DevOps Directive](https://www.youtube.com/watch?v=FHwnrYm0mNc) and[ Benjamin
    Carlson](https://www.youtube.com/watch?v=zlbM1As849c) found impressive results
    when challenging Copilot with interview-style questions from[ leetcode.com](https://leetcode.com/),
    including some that seemed significantly more complex than chaining together a
    series of simple string manipulations. The difference in the complexity of code
    that Copilot can generate and the complexity of problem specifications that Copilot
    can understand is striking.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其他 YouTuber 对 Copilot 的评论，例如[ DevOps Directive](https://www.youtube.com/watch?v=FHwnrYm0mNc)和[ Benjamin
    Carlson](https://www.youtube.com/watch?v=zlbM1As849c)，在用来自[ leetcode.com](https://leetcode.com/)的面试风格问题挑战
    Copilot 时，发现了令人印象深刻的结果，包括一些看起来比简单的字符串操作序列复杂得多的情况。Copilot 能生成的代码复杂性和 Copilot 能理解的题目复杂性之间的差异非常显著。
- en: Perhaps the prevalence of code written in the style of interview practice questions
    in the training dataset leads to Copilot overfitting those types of problems,
    or perhaps it is just more difficult to chain together several steps of modular
    functionality than it is to churn out a big chunk of complex code that is very
    similar to something the model has seen before. Poorly described and poorly interpreted
    specifications are already a common source of complaints for engineers and their
    managers of the human variety, so perhaps it should not be so surprising to find
    an AI coding assistant fails to excel at parsing complicated problem specifications.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 也许训练数据集中面试实践问题风格的代码流行导致 Copilot 过度拟合这些类型的问题，或者也许将几个模块化功能步骤串联起来要比生成一大块与模型之前见过的非常相似的复杂代码更困难。对于工程师及其人类经理来说，描述不清和解读不准确的规格已经是一个常见的投诉来源，因此发现
    AI 编码助手在解析复杂问题规格方面未能表现出色，也许并不那么令人惊讶。
- en: Copilot Alternatives
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Copilot 替代品
- en: 'As of this writing, Copilot is still limited to programmers lucky enough to
    be enrolled in the[ technical preview](https://github.com/features/copilot/signup),
    but fear not: myriad of other code completion assistants (whether using deep learning
    or not) are readily available to try out and it’s not a bad time to reflect on
    what increasing automation might mean for software engineering.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Copilot 仍然仅限于幸运地注册了[ 技术预览](https://github.com/features/copilot/signup)的程序员，但不用担心：其他许多代码补全助手（无论是否使用深度学习）都可以尝试，现在正是思考自动化增加对软件工程可能意味着什么的好时机。
- en: Earlier we mentioned [TabNine](https://www.tabnine.com/), a code completion
    tool based in part on OpenAI’s GPT-2 transformer. Originally built by Jacob Jackson
    and now owned by[ codota](https://web.archive.org/web/20200609042219/https://blog.codota.com/tabnine-part-of-codota/),
    TabNine was able to solve 7.6% of the HumanEval benchmark in the pass@100 metric
    used by OpenAI authors. That’s fairly impressive considering that TabNine was
    designed to be a more hands-on code completion solution, unlike Codex which was
    explicitly inspired by the potential of GPT-3 models to produce code from problem
    descriptions. TabNine has been around since 2018 and has both free and paid versions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们提到过 [TabNine](https://www.tabnine.com/)，这是一种部分基于 OpenAI 的 GPT-2 变换器的代码补全工具。最初由
    Jacob Jackson 构建，现在由 [codota](https://web.archive.org/web/20200609042219/https://blog.codota.com/tabnine-part-of-codota/)
    拥有，TabNine 在 OpenAI 作者使用的 pass@100 基准中解决了 7.6% 的问题。这相当令人印象深刻，因为 TabNine 设计为更具操作性的代码补全解决方案，而
    Codex 则显然受到 GPT-3 模型从问题描述中生成代码的潜力的启发。TabNine 自2018年起存在，并提供免费和付费版本。
- en: '[Kite](https://www.kite.com/) is another code completion tool in the same vein
    as TabNine, with free (desktop) and paid (server) versions that differ in the
    size of the model used by a factor of 25\. According to Kite’s usage statistics,
    coders choose to use the suggested completions often enough to cut their keystrokes
    in half compared to manually typing out every line, and Kite’s cite their users’
    self-reported productivity boost of 18%. Going by the animated demos on their
    website, Kite definitely suggests shorter completions than both TabNine and Copilot.
    This differs in degree from TabNine, which suggests only slightly longer completions
    for the most part, but it''s qualitatively different from Copilot: **Copilot can
    suggest extended blocks of code and changes the experience from choosing the best
    completion to code reviewing several suggested approaches to the problem.**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kite](https://www.kite.com/) 是另一种与 TabNine 相似的代码补全工具，提供免费的（桌面版）和付费的（服务器版），它们在使用的模型大小上相差25倍。根据
    Kite 的使用统计，程序员选择使用建议的补全，通常能将输入次数减少一半，而 Kite 自称其用户的自我报告生产力提升了18%。根据他们网站上的动画演示，Kite
    确实建议比 TabNine 和 Copilot 更短的补全。这与 TabNine 的区别在于，TabNine 大多数情况下建议的补全只略长一些，但与 Copilot
    的不同之处在于：**Copilot 可以建议扩展的代码块，并将体验从选择最佳补全转变为对多个建议的解决方案进行代码审查。**'
- en: Is Copilot Here to Take Your Job or Just Your Code?
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Copilot** 是来取代你的工作还是只是你的代码？'
- en: GitHub Copilot has some software engineers joking that the automation they’ve
    been building for years is finally coming home to roost, and soon we’ll all be
    out of a job. In reality this is very unlikely to be the case for many years as
    there is more to programming than just writing code.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot 让一些软件工程师开玩笑说，他们多年来建立的自动化终于回到他们身上，很快我们所有人都会失业。实际上，这种情况在很多年内都不太可能发生，因为编程不仅仅是编写代码。
- en: Besides, it’s an oft-repeated trope that even interpreting exactly what a client
    or manager wants in a set of software specifications is more of an art than a
    science.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，即使准确解释客户或经理在软件规格中的需求，也常常被认为更多的是一种艺术而非科学。
- en: On the other hand, Copilot and other natural language code completion tools
    like it (and trust us, more are coming) are indeed likely to have a big impact
    on the way software engineers do their jobs. Engineers will probably spend more
    time reviewing code and checking tests, whether the code under scrutiny was written
    by an AI model or a fellow engineer. We’ll probably also see another layer of
    meta to the art of programming as “prompt programming” of machine learning programming
    assistants becomes commonplace.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Copilot 和其他自然语言代码补全工具（相信我们，更多工具即将到来）确实可能对软件工程师的工作方式产生重大影响。工程师可能会花更多时间审查代码和检查测试，无论这些代码是由
    AI 模型还是其他工程师编写的。我们可能还会看到编程艺术的另一层面，即“提示编程”成为机器学习编程助手的常态。
- en: 'As cyberpunk author [William Gibson](https://en.wikipedia.org/wiki/William_Gibson) put
    it all those years ago: “the future is already here — it’s just not evenly distributed.”'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正如赛博朋克作者 [威廉·吉布森](https://en.wikipedia.org/wiki/William_Gibson) 多年前所说：“未来已经到来——只不过不均匀分布。”
- en: Copilot has also ignited a debate on copyright, copyleft, and all manner of
    open source licenses and the philosophy of building good technology, which is
    a discussion that needs to take place sooner rather than later. Additionally,
    most contemporary interpretations of intellectual property require a human author
    for a work to be eligible for copyright. As more code is written in larger proportions
    by machine learning models instead of humans, will those works legally enter the
    public domain upon their creation?
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot 也引发了关于版权、自由版权和各种开源许可证以及构建良好技术的哲学的讨论，这是一个需要尽早进行的讨论。此外，大多数当代知识产权解释要求作品必须有人工作者才能获得版权。随着更多代码由机器学习模型而非人类编写，这些作品在创作时是否会合法地进入公共领域？
- en: Who knows? Perhaps the open source community will finally win in the end, as
    the great-great-great successor to Copilot becomes a staunch open source advocate
    and insists on working only on free and open source software.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 谁知道呢？也许开源社区最终会胜出，因为 Copilot 的伟大后继者成为了坚定的开源倡导者，并坚持只在免费和开源软件上工作。
- en: '**Bio: [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact
    Corp blog and works with many of its talented authors who write about different
    aspects of Deep Learning.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** 负责管理 Exxact Corp
    博客，并与许多才华横溢的作者合作，他们撰写关于深度学习的不同方面。'
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/github-copilot-ai-pair-programmer).
    Reposted with permission.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.exxactcorp.com/blog/Deep-Learning/github-copilot-ai-pair-programmer)。经许可转载。'
- en: '**Related:**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[GitHub Copilot Open Source Alternatives](/2021/07/github-copilot-open-source-alternatives-code-generation.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitHub Copilot 开源替代方案](/2021/07/github-copilot-open-source-alternatives-code-generation.html)'
- en: '[Managing Your Reusable Python Code as a Data Scientist](/2021/06/managing-reusable-python-code-data-scientist.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[作为数据科学家的可重用 Python 代码管理](/2021/06/managing-reusable-python-code-data-scientist.html)'
- en: '[GitHub Copilot: Your AI pair programmer – what is all the fuss about?](/2021/07/github-copilot-ai-pair-programmer.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitHub Copilot：你的 AI 编程伙伴——到底有什么值得关注的？](/2021/07/github-copilot-ai-pair-programmer.html)'
- en: '* * *'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[GitHub Copilot Open Source Alternatives](https://www.kdnuggets.com/2021/07/github-copilot-open-source-alternatives-code-generation.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitHub Copilot 开源替代方案](https://www.kdnuggets.com/2021/07/github-copilot-open-source-alternatives-code-generation.html)'
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据分析：在 Databricks 中集成 GitHub Copilot](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
- en: '[LSTMs Rise Again: Extended-LSTM Models Challenge the Transformer…](https://www.kdnuggets.com/lstms-rise-again-extended-lstm-models-challenge-the-transformer-superiority)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LSTM 再次崛起：扩展 LSTM 模型挑战 Transformer…](https://www.kdnuggets.com/lstms-rise-again-extended-lstm-models-challenge-the-transformer-superiority)'
- en: '[Free Python Automation Course](https://www.kdnuggets.com/2022/07/free-automate-python-course.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费 Python 自动化课程](https://www.kdnuggets.com/2022/07/free-automate-python-course.html)'
- en: '[3 Useful Python Automation Scripts](https://www.kdnuggets.com/2022/11/3-useful-python-automation-scripts.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3 个有用的 Python 自动化脚本](https://www.kdnuggets.com/2022/11/3-useful-python-automation-scripts.html)'
- en: '[Automation in Data Science Workflows](https://www.kdnuggets.com/2023/03/automation-data-science-workflows.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学工作流程中的自动化](https://www.kdnuggets.com/2023/03/automation-data-science-workflows.html)'
