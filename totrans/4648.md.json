["```py\n# Create new entityset\nes = ft.EntitySet(id = 'customers')\n```", "```py\n# Create an entity from the customers dataframe\n\nes = es.entity_from_dataframe(entity_id = 'customers', dataframe = customers_df, index = 'customer_id', time_index = 'join_date' ,variable_types = {\"zip_code\": ft.variable_types.ZIPCode})\n```", "```py\n[featuretools.variable_types.variable.Datetime,\n featuretools.variable_types.variable.Numeric,\n featuretools.variable_types.variable.Timedelta,\n featuretools.variable_types.variable.Categorical,\n featuretools.variable_types.variable.Text,\n featuretools.variable_types.variable.Ordinal,\n featuretools.variable_types.variable.Boolean,\n featuretools.variable_types.variable.LatLong,\n featuretools.variable_types.variable.ZIPCode,\n featuretools.variable_types.variable.IPAddress,\n featuretools.variable_types.variable.EmailAddress,\n featuretools.variable_types.variable.URL,\n featuretools.variable_types.variable.PhoneNumber,\n featuretools.variable_types.variable.DateOfBirth,\n featuretools.variable_types.variable.CountryCode,\n featuretools.variable_types.variable.SubRegionCode,\n featuretools.variable_types.variable.FilePath]\n```", "```py\n# adding the transactions_df\nes = es.entity_from_dataframe(entity_id=\"transactions\",\n                                 dataframe=transactions_df,\n                                 index=\"transaction_id\",\n                               time_index=\"transaction_time\",\n                               variable_types={\"product_id\": ft.variable_types.Categorical})\n\n# adding sessions_df\nes = es.entity_from_dataframe(entity_id=\"sessions\",\n            dataframe=sessions_df,\n            index=\"session_id\", time_index = 'session_start')\n```", "```py\n# adding the customer_id relationship\ncust_relationship = ft.Relationship(es[\"customers\"][\"customer_id\"],\n                       es[\"sessions\"][\"customer_id\"])\n\n# Add the relationship to the entity set\nes = es.add_relationship(cust_relationship)\n\n# adding the session_id relationship\nsess_relationship = ft.Relationship(es[\"sessions\"][\"session_id\"],\n                       es[\"transactions\"][\"session_id\"])\n\n# Add the relationship to the entity set\nes = es.add_relationship(sess_relationship)\n```", "```py\nfeature_matrix, feature_defs = ft.dfs(entityset=es, target_entity=\"customers\",max_depth = 2)\n\nfeature_matrix.head()\n```", "```py\n[<Feature: NUM_UNIQUE(sessions.device)>,\n <Feature: MODE(sessions.device)>,\n <Feature: SUM(transactions.amount)>,\n <Feature: STD(transactions.amount)>,\n <Feature: MAX(transactions.amount)>,\n <Feature: SKEW(transactions.amount)>,\n <Feature: DAY(join_date)>,\n <Feature: YEAR(join_date)>,\n <Feature: MONTH(join_date)>,\n <Feature: WEEKDAY(join_date)>,\n <Feature: SUM(sessions.STD(transactions.amount))>,\n <Feature: SUM(sessions.MAX(transactions.amount))>,\n <Feature: SUM(sessions.SKEW(transactions.amount))>,\n <Feature: SUM(sessions.MIN(transactions.amount))>,\n <Feature: SUM(sessions.MEAN(transactions.amount))>,\n <Feature: SUM(sessions.NUM_UNIQUE(transactions.product_id))>,\n <Feature: STD(sessions.SUM(transactions.amount))>,\n <Feature: STD(sessions.MAX(transactions.amount))>,\n <Feature: STD(sessions.SKEW(transactions.amount))>,\n <Feature: STD(sessions.MIN(transactions.amount))>,\n <Feature: STD(sessions.MEAN(transactions.amount))>,\n <Feature: STD(sessions.COUNT(transactions))>,\n <Feature: STD(sessions.NUM_UNIQUE(transactions.product_id))>]\n```", "```py\npd.get_dummies(sessions_df['device'],drop_first=True)\n```", "```py\nmap_dict = {'low':0,'medium':1,'high':2}\ndef map_values(x):\n    return map_dict[x]\ndf['Temperature_oe'] = df['Temperature'].apply(lambda x: map_values(x))\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder\n# create a labelencoder object\nle = LabelEncoder()\n# fit and transform on the data\nsessions_df['device_le'] = le.fit_transform(sessions_df['device'])\nsessions_df.head()\n```", "```py\nfrom category_encoders.binary import BinaryEncoder\n# create a Binaryencoder object\nbe = BinaryEncoder(cols = ['Club'])\n# fit and transform on the data\nplayers = be.fit_transform(players)\n```", "```py\nplayers = pd.read_csv(\"../input/fifa19/data.csv\")\n\nfrom category_encoders.hashing import HashingEncoder\n# create a HashingEncoder object\nhe = HashingEncoder(cols = ['Club'])\n# fit and transform on the data\nplayers = he.fit_transform(players)\n```", "```py\ntargetc = KFoldTargetEncoderTrain('Pclass','Survived',n_fold=5)\nnew_train = targetc.fit_transform(train)\n\nnew_train[['Pclass_Kfold_Target_Enc','Pclass']]\n```", "```py\ndf.to_csv(‘submission.csv.gz’, index=False, compression=’gzip’)\n```", "```py\ndef haversine_array(lat1, lng1, lat2, lng2): \n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) \n    AVG_EARTH_RADIUS = 6371 # in km \n    lat = lat2 - lat1 \n    lng = lng2 - lng1 \n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) *      np.sin(lng * 0.5) ** 2 \n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d)) \n    return h\n```", "```py\ntrain['haversine_distance'] = train.apply(lambda x: haversine_array(x['pickup_latitude'], x['pickup_longitude'], x['dropoff_latitude'], x['dropoff_longitude']),axis=1)\n```", "```py\ndef dummy_manhattan_distance(lat1, lng1, lat2, lng2): \n    a = haversine_array(lat1, lng1, lat1, lng2) \n    b = haversine_array(lat1, lng1, lat2, lng1) \n    return a + b\n```", "```py\ntrain['manhattan_distance'] = train.apply(lambda x: dummy_manhattan_distance(x['pickup_latitude'], x['pickup_longitude'], x['dropoff_latitude'], x['dropoff_longitude']),axis=1)\n```", "```py\ndef bearing_array(lat1, lng1, lat2, lng2): \n    AVG_EARTH_RADIUS = 6371 # in km \n    lng_delta_rad = np.radians(lng2 - lng1) \n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) \n    y = np.sin(lng_delta_rad) * np.cos(lat2) \n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad) \n    return np.degrees(np.arctan2(y, x))\n```", "```py\ntrain['bearing'] = train.apply(lambda x: bearing_array(x['pickup_latitude'], x['pickup_longitude'], x['dropoff_latitude'], x['dropoff_longitude']),axis=1)\n```", "```py\ntrain.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2 \ntrain.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\n```", "```py\ntrain['log_trip_duration'] = train['trip_duration'].apply(lambda x: np.log(1+x))\n```"]