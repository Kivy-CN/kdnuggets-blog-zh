- en: YOLOv5 PyTorch Tutorial
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLOv5 PyTorch 教程
- en: 原文：[https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)
- en: '![YOLOv5 PyTorch Tutorial](../Images/677a6a1db1a597d6d66c9f2dce9867b3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/677a6a1db1a597d6d66c9f2dce9867b3.png)'
- en: Using YOLOv5 in PyTorch
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用YOLOv5进行PyTorch开发
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 在IT领域支持你的组织'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: YOLO, an acronym for 'You only look once,’ is an open-source software tool utilized
    for its efficient capability of detecting objects in a given image in real time.
    The YOLO algorithm uses convolutional neural network (CNN) models to detect objects
    in an image.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO，即“你只看一次”的缩写，是一种开源软件工具，因其高效的实时物体检测能力而被广泛使用。YOLO算法使用卷积神经网络（CNN）模型来检测图像中的物体。
- en: The algorithm requires only one forward propagation through a given neural network
    to detect all objects in the image. This gives the YOLO algorithm an edge in speed
    over others, making it one of the most well-known detection algorithms to date.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法仅需一次前向传播即可检测图像中的所有对象。这使得YOLO算法在速度上优于其他算法，成为迄今为止最知名的检测算法之一。
- en: What is YOLO Object Detection?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是YOLO物体检测？
- en: An object detection algorithm is an algorithm that is capable of detecting certain
    objects or shapes in a given frame. For example, simple detection algorithms may
    be capable of detecting and identifying shapes in an image such as circles or
    squares, while more advanced detection algorithms can detect more complex objects
    such as humans, bicycles, cars, etc.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测算法是一种能够在给定帧中检测特定对象或形状的算法。例如，简单的检测算法可能能够检测和识别图像中的形状，如圆形或方形，而更高级的检测算法可以检测更复杂的对象，如人类、自行车、汽车等。
- en: Not only does the YOLO algorithm offer high detection speed and performance
    through its one-forward propagation capability, but it also detects them with
    great accuracy and precision.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO算法不仅通过其一次前向传播能力提供了高检测速度和性能，而且还以极高的准确性和精度进行检测。
- en: In this tutorial, we will focus on [YOLOv5](https://github.com/ultralytics/yolov5),
    which is the fifth and latest version of the YOLO software. It was originally
    released on the 18th of May 2020\. The YOLO open-source code can be found on [GitHub](https://github.com/ultralytics/yolov5).
    We will be using YOLO with the well-known PyTorch library.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将重点关注[YOLOv5](https://github.com/ultralytics/yolov5)，这是YOLO软件的第五个也是最新的版本。它最初发布于2020年5月18日。YOLO开源代码可以在[GitHub](https://github.com/ultralytics/yolov5)上找到。我们将使用YOLO与著名的PyTorch库。
- en: '[PyTorch](https://pytorch.org/) is a deep learning open-source package that
    is based on the well-known Torch library. It''s also a Python-based library that
    is more commonly used for natural language processing and computer vision.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[PyTorch](https://pytorch.org/)是一个基于著名Torch库的深度学习开源包。它也是一个基于Python的库，通常用于自然语言处理和计算机视觉。'
- en: How does the YOLO Algorithm Work?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLO算法是如何工作的？
- en: 'Step 1: Residual Blocks (Dividing the Image Into Smaller, Grid-Like Boxes)'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：残差块（将图像划分为更小的网格状框）
- en: In this step, the complete (whole) frame is divided into smaller boxes or grids.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步骤中，完整（整体）帧被划分为更小的框或网格。
- en: All the grids are drawn over the original image sharing the exact shape and
    size. The idea behind these divisions is that each grid box will detect the different
    objects inside it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所有网格都绘制在原始图像上，形状和大小完全一致。这些分割的想法在于每个网格框将检测其内部的不同对象。
- en: '![YOLOv5 PyTorch Tutorial](../Images/b697b57190ca3e06f2f0b3b6d35ee00f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/b697b57190ca3e06f2f0b3b6d35ee00f.png)'
- en: 'Step 2: Bounding Box Regression (Identifying the Object Inside a Bounding Box)'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：边界框回归（识别边界框中的对象）
- en: After detecting a given object in an image, a bounding box is drawn surrounding
    it. The bounding box has parameters such as the **center point, height, width,
    and class (object type detected)**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到图像中的给定对象后，会绘制一个边界框将其包围。边界框具有诸如**中心点、高度、宽度和类别（检测到的对象类型）**等参数。
- en: '![YOLOv5 PyTorch Tutorial](../Images/e8b6c4eab9ee049ccef69744a4194440.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/e8b6c4eab9ee049ccef69744a4194440.png)'
- en: 'Step 3: Intersection Over Union (IOU)'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：交并比（IOU）
- en: '![YOLOv5 PyTorch Tutorial](../Images/30111de8b4f85a72d7daa1d9005134ca.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/30111de8b4f85a72d7daa1d9005134ca.png)'
- en: The **IOU**, short for **intersection over union**, is used to calculate our
    model's accuracy. This is achieved by quantifying the degree of intersection of
    two boxes which are the real value box (red box in image) and the box returned
    from our result (blue box in image).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**IOU**，即**交并比**，用于计算我们模型的准确性。这是通过量化两个框的交集程度来实现的，这两个框分别是实际值框（图中的红框）和从结果中返回的框（图中的蓝框）。'
- en: In the tutorial portion of this article, we identified our IOU value as 40 percent,
    meaning that if the intersection of the two boxes is below 40 percent then this
    prediction should not be taken into consideration. This is done to help us calculate
    the accuracy of our predictions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的教程部分，我们将 IOU 值确定为 40%，这意味着如果两个框的交集低于 40%，则不应考虑该预测。这是为了帮助我们计算预测的准确性。
- en: Below is an image showing the complete process of the YOLO detection algorithm
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是显示 YOLO 检测算法完整过程的图像
- en: '![YOLOv5 PyTorch Tutorial](../Images/1c627f3285b1a1621a7bf28cb7243337.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/1c627f3285b1a1621a7bf28cb7243337.png)'
- en: For additional information on how the YOLO algorithm works, view the [Introduction
    to YOLO algorithm](https://www.section.io/engineering-education/introduction-to-yolo-algorithm-for-object-detection/#:~:text=YOLO%20is%20an%20algorithm%20that,%2C%20parking%20meters%2C%20and%20animals.).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 YOLO 算法如何工作的详细信息，请查看[YOLO 算法简介](https://www.section.io/engineering-education/introduction-to-yolo-algorithm-for-object-detection/#:~:text=YOLO%20is%20an%20algorithm%20that,%2C%20parking%20meters%2C%20and%20animals.)。
- en: What are we Trying to Achieve with our Model?
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们希望通过模型实现什么目标？
- en: The main goal of the example in this tutorial is to use the YOLO algorithm to
    detect a list of chest diseases in a given image. As with any machine learning
    model, we will run ours using thousands of chest-scanned images. The goal is for
    the YOLO algorithm to successfully detect all lesions in the given image.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程示例的主要目标是使用 YOLO 算法检测给定图像中的一系列胸部疾病。与任何机器学习模型一样，我们将使用成千上万张胸部扫描图像来运行我们的模型。目标是让
    YOLO 算法成功检测出给定图像中的所有病变。
- en: Data Set
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: The [VinBigData 512 image Dataset](https://www.kaggle.com/datasets/awsaf49/vinbigdata-512-image-dataset) used
    in this tutorial can be found on Kaggle. The data set is divided into two parts,
    the training, and the testing data sets. The training data set contains 15,000
    images, while the testing data set contains 3,000\. This division of data between
    the training and the testing is somehow optimal as the training data set is usually
    4 to 5 times the size of the testing data set.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中使用的[VinBigData 512 图像数据集](https://www.kaggle.com/datasets/awsaf49/vinbigdata-512-image-dataset)可以在
    Kaggle 上找到。数据集分为两部分，训练数据集和测试数据集。训练数据集包含 15,000 张图像，而测试数据集包含 3,000 张。这种数据划分在训练数据集通常是测试数据集的
    4 到 5 倍的情况下是比较理想的。
- en: '![YOLOv5 PyTorch Tutorial](../Images/495e553306a0277e683d55dfe65641c1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/495e553306a0277e683d55dfe65641c1.png)'
- en: The other part of the data set contains the label for all the images. Inside
    this data set each image is labeled with a class name (chest disease found), along
    with the class ID, width and height of the image, etc. Check the below image to
    view all the columns available.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的另一部分包含所有图像的标签。在这个数据集中，每张图像都标记有一个类别名称（发现的胸部疾病），以及类别 ID、图像的宽度和高度等。查看下面的图像以查看所有可用的列。
- en: '![YOLOv5 PyTorch Tutorial](../Images/ab2b60451cc644a880b98d46a39186da.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![YOLOv5 PyTorch 教程](../Images/ab2b60451cc644a880b98d46a39186da.png)'
- en: YOLOv5 Tutorial
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YOLOv5 教程
- en: '**Note:** You can view the [original code](https://www.kaggle.com/code/mostafaibrahim17/yolov5/notebook) used
    in this example on Kaggle.'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 你可以在 Kaggle 上查看[原始代码](https://www.kaggle.com/code/mostafaibrahim17/yolov5/notebook)。'
- en: 'Step 1: Importing the Necessary Libraries'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：导入必要的库
- en: To start with, we will import the required libraries and packages at the very
    beginning of our code. First, let's explain some of the more common libraries
    that we just imported. NumPy is an open-source numerical Python library that allows
    users to create matrices and perform a number of mathematical operations on them.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将在代码的最开始导入所需的库和包。首先，让我们解释一下我们刚刚导入的一些更常见的库。NumPy 是一个开源的 Python 数值库，允许用户创建矩阵并对其执行多种数学操作。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Step 2: Defining Our Paths'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：定义我们的路径
- en: To make our life easier, we will start by defining the direct paths to the labels
    and the images of the training and testing data sets.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化我们的工作，我们将首先定义训练和测试数据集标签和图像的直接路径。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 3: Importing and Reading the Textual Dataset'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：导入和读取文本数据集
- en: Here we will import and read the textual data set. This data is stored as rows
    and columns in a CSV file format.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将导入和读取文本数据集。这些数据以 CSV 文件格式存储为行和列。
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Note:** the df.head() function prints the first 5 rows of the given data
    set.'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** df.head() 函数打印给定数据集的前 5 行。'
- en: 'Step 4: Filtering and Cleaning the Data Set'
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4：过滤和清理数据集
- en: As no data set is perfect, most of the time a filtering process is necessary
    to optimize a data set, thus optimizing our model’s performance. In this step,
    we would drop any row with a class id that is equal to 14.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有数据集是完美的，因此大多数时候需要一个过滤过程来优化数据集，从而优化我们模型的性能。在此步骤中，我们将删除任何 class id 等于 14 的行。
- en: This class id stands for a no finding in the disease class. The reason we dropped
    this class is that it may confuse our model. Moreover, it will slow it down because
    our data set will be slightly bigger.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 class id 代表疾病类别中没有发现的情况。我们删除这个类别的原因是它可能会混淆我们的模型。此外，它还会减慢模型的速度，因为我们的数据集会稍微变大。
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Step 5: Calculating the Coordinates of the Bounding Box for YOLO'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 5：计算 YOLO 的边界框坐标
- en: As mentioned previously in the **'How does the YOLO algorithm work section'** (particularly
    steps 1 and 2), the YOLO algorithm expects the dataset to be in a certain format.
    Here we will be going through the dataframe and applying a few transformations.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述在**‘YOLO 算法如何工作部分’**（特别是步骤 1 和 2），YOLO 算法期望数据集以某种格式存在。在这里，我们将遍历数据框并应用一些转换。
- en: The end goal of the below code is to calculate the new x-mid, y-mid, width,
    and height dimensions for each data point.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码的最终目标是计算每个数据点的新 x-mid、y-mid、宽度和高度维度。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Step 6: Changing the Provided Data Format'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 6：更改提供的数据格式
- en: In this part of the code, we will change the given data format of all rows in
    the dataset into the following columns; <class> <x_center> <y_center> <width>
    <height>.This is necessary since the YOLOv5 algorithm can only read the data in
    this specific format.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码的这一部分，我们将把数据集中的所有行的给定数据格式更改为以下列：<class> <x_center> <y_center> <width> <height>。这是必要的，因为
    YOLOv5 算法只能以这种特定格式读取数据。
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We will then run the preproccess_data function two times, once with the training
    data set and its images, and the second with the testing data set and its images.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将运行 preproccess_data 函数两次，一次使用训练数据集及其图像，另一次使用测试数据集及其图像。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Using the line below, we will clone the YOLOv5 algorithm into our model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码行，我们将把 YOLOv5 算法克隆到我们的模型中。
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Step 7: Defining our Model’s Classes'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 7：定义我们模型的类别
- en: Here we will define the available 14 chest diseases in our models as classes.
    These are the actual diseases that can be identified in the data set’s images.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将把模型中可用的 14 种胸部疾病定义为类别。这些是可以在数据集的图像中识别的实际疾病。
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Step 8: Training the Model'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 8：训练模型
- en: To start, we will open the YOLOv5 directory. Then we will use pip in order to
    install all the libraries written inside the requirements file.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将打开 YOLOv5 目录。然后，我们将使用 pip 安装 requirements 文件中列出的所有库。
- en: The requirements file contains all the required libraries that the code base
    needs to work. We will also install other libraries such as pycocotools, seaborn,
    and pandas.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: requirements 文件包含代码库运行所需的所有库。我们还将安装其他库，例如 pycocotools、seaborn 和 pandas。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Wandb, short for weights and biases, allows us to monitor a given neural network
    model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Wandb，缩写自 weights and biases，允许我们监控给定的神经网络模型。
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we will train the YOLOv5 on the vinbigdata set provided for 100 epochs.
    We’ll also pass some other flags such as --img 512 which tells the model that
    our image size is 512 pixels, --batch 16 will allow our model to take 16images
    per batch. Using the --data ./vinbigdata.yaml flag we will pass our dataset which
    is the vinbigdata.yaml data set.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将对提供的vinbigdata数据集进行100轮的YOLOv5训练。我们还将传递一些其他标志，例如 --img 512，表示我们的图像大小为512像素，
    --batch 16 允许我们的模型每批处理16张图像。使用 --data ./vinbigdata.yaml 标志，我们将传递我们的数据集，即vinbigdata.yaml数据集。
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Step 9: Evaluating the Model'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第9步：评估模型
- en: First, we will identify the testing data set directory along with the weights
    directory.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将识别测试数据集目录以及权重目录。
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this part, we will use the detect.py as our inference to check the accuracy
    of our predictions. We will also pass some flags such as --conf 0.15\ which is
    the model's confidence threshold. If the confidence rate of a detected object
    is under 15 percent then remove it from our output. The --iou 0.4\ flag informs
    our model that if the intersection over the union of two boxes is below 40 percent
    then it should be removed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用detect.py作为推理工具来检查我们预测的准确性。我们还将传递一些标志，例如 --conf 0.15\，这是模型的置信度阈值。如果检测到的对象的置信度低于15%，则将其从输出中删除。
    --iou 0.4\ 标志告诉我们的模型，如果两个框的交集与并集的比例低于40%，则应将其移除。
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Final Thoughts
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的思考
- en: In this article, we explained what YOLOv5 is and how the basic YOLO algorithm
    works. Next, we went on to briefly explain PyTorch. Then we covered a couple of
    reasons why you should use YOLO over other, similar detection algorithms.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们解释了YOLOv5是什么以及基本的YOLO算法是如何工作的。接下来，我们简要说明了PyTorch。然后我们覆盖了几个使用YOLO而不是其他类似检测算法的理由。
- en: Finally, we walked you through a machine-learning model that is capable of detecting
    chest diseases in x-ray images. In this example, we used YOLO as our main detection
    algorithm to find and locate chest lesions. We then classified each lesion into
    a given class or disease.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们带您了解了一个能够检测X光图像中胸部疾病的机器学习模型。在这个示例中，我们使用YOLO作为主要的检测算法来查找和定位胸部病变。然后，我们将每个病变分类为特定的类别或疾病。
- en: If you are interested in machine learning and building your own models, especially
    models that require the detection of multiple objects in a given image or video
    representation, then YOLOv5 is definitely worth a try.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对机器学习和构建自己的模型感兴趣，特别是那些需要检测给定图像或视频中多个对象的模型，那么YOLOv5绝对值得一试。
- en: '**[Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact Corp
    blog and works with many of its talented authors who write about different aspects
    of Deep Learning.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** 负责管理Exxact Corp博客，并与许多撰写有关深度学习不同方面的才华横溢的作者合作。'
- en: '[Original](https://exxactcorp.com/blog/Deep-Learning/YOLOv5-PyTorch-Tutorial).
    Reposted with permission.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://exxactcorp.com/blog/Deep-Learning/YOLOv5-PyTorch-Tutorial) 经许可转载。'
- en: More On This Topic
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch解释性神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习的完整免费PyTorch课程](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning入门](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Tuning Adam Optimizer Parameters in PyTorch](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调整PyTorch中的Adam优化器参数](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
- en: '[A Practical Guide to Transfer Learning using PyTorch](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch的迁移学习实用指南](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
- en: '[PyTorch Tips to Boost Your Productivity](https://www.kdnuggets.com/2023/08/pytorch-tips-boost-productivity.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升PyTorch生产力的技巧](https://www.kdnuggets.com/2023/08/pytorch-tips-boost-productivity.html)'
