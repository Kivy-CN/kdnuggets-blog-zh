- en: Image Classification with Convolutional Neural Networks (CNNs)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络 (CNN) 进行图像分类
- en: 原文：[https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
- en: '![Image Classification with Convolutional Neural Networks (CNNs)](../Images/d31df1465f041fd9f4014c1e72487e2e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用卷积神经网络 (CNN) 进行图像分类](../Images/d31df1465f041fd9f4014c1e72487e2e.png)'
- en: What Is A Convolutional Neural Network (CNN)?
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是卷积神经网络 (CNN)？
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A Convolutional Neural Network is a special class of neural networks that are
    built with the ability to extract unique features from image data. For instance,
    they are used in face detection and recognition because they can identify complex
    features in image data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络是一类特殊的神经网络，具有从图像数据中提取独特特征的能力。例如，它们被用于面部检测和识别，因为它们能够识别图像数据中的复杂特征。
- en: How Do Convolutional Neural Networks Work?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络如何工作？
- en: Like other types of neural networks, CNNs consume numerical data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他类型的神经网络一样，CNN消耗数值数据。
- en: Therefore, the images fed to these networks must be converted to a numerical
    representation. Since images are made up of pixels, they are converted into a
    numerical form that is passed to the CNN.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，输入这些网络的图像必须转换为数值表示形式。由于图像由像素组成，它们被转换为数值形式，然后传递给CNN。
- en: However, as we will discuss in the upcoming section, the entire numerical representation
    is not passed into the network. To understand how this works, let’s look at some
    of the steps involved in training a CNN.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们将在下一部分讨论的那样，并非所有的数值表示都传递到网络中。要理解这一点，我们来看看训练CNN时涉及的一些步骤。
- en: Convolution
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积
- en: Reducing the size of the numerical representation sent to the CNN is done via
    the ***convolution*** operation. This process is vital so that only features that
    are important in classifying an image are sent to the neural network. Apart from
    improving the accuracy of the network, this also ensures that minimal compute
    resources are used in training the network.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通过***卷积***操作减少传递给CNN的数值表示的大小。这一过程至关重要，以便只有在图像分类中重要的特征被传递给神经网络。除了提高网络的准确性，这也确保了在训练网络时使用最少的计算资源。
- en: The result of the convolution operation is referred to as a **feature map**,
    **convolved feature**, or **activation map**. Applying a **feature detector**
    is what leads to a feature map. The feature detector is also known by other names
    such as **kernel** or **filter**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作的结果称为**特征图**、**卷积特征**或**激活图**。应用**特征检测器**会生成特征图。特征检测器也被称为**核心**或**滤波器**。
- en: The kernel is usually a 3 by 3 matrix. Performing an element-wise multiplication
    of the kernel with the input image and summing the values, outputs the feature
    map. This is done by sliding the kernel on the input image. The sliding happens
    in steps known as **strides**. The strides and the size of the kernel can be set
    manually when creating the CNN.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 核心通常是一个3x3的矩阵。通过对核心与输入图像进行逐元素乘法，并将值求和，得到特征图。这是通过在输入图像上滑动核心来完成的。滑动的步骤被称为**步幅**。在创建CNN时，可以手动设置步幅和核心的大小。
- en: '![Convolution](../Images/f1b3bab4eaa566a6a47f03c428a4caf7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![卷积](../Images/f1b3bab4eaa566a6a47f03c428a4caf7.png)'
- en: '[A 3 by 3 convolutions operation. ](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[3x3 卷积操作](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
- en: For example, given a 5 by 5 input, a kernel of 3 by 3 will output a 3 by 3 output
    feature map.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，给定一个 5x5 的输入，3x3 的卷积核将输出一个 3x3 的特征图。
- en: Padding
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充
- en: In the above operations, we have seen that the size of the feature map reduces
    as part of applying the convolution operation. What if you want the size of the
    feature map to be the same size as that of the input image? That is achieved through
    padding.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述操作中，我们已经看到应用卷积操作时特征图的大小会减少。如果你希望特征图的大小与输入图像相同，该如何实现？这可以通过填充来实现。
- en: Padding involves increasing the size of the input image by “padding” the images
    with zeros. As a result, applying the filter to the image leads to a feature map
    of the same size as the input image.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 填充涉及通过用零“填充”图像来增加输入图像的大小。因此，将滤波器应用于图像会导致特征图的大小与输入图像相同。
- en: '![Padding](../Images/12665ab6d814838225950e1f750f45ca.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![填充](../Images/12665ab6d814838225950e1f750f45ca.png)'
- en: '[The uncolored area represents the padded area. ](https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Padding_strides.gif)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[未着色区域表示填充区域](https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Padding_strides.gif)'
- en: Padding reduces the amount of information lost in the convolution operation.
    It also ensures that the edges of the images are factored more often in the convolution
    operation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 填充减少了卷积操作中丢失的信息量。它还确保图像的边缘在卷积操作中被更频繁地考虑。
- en: When building the CNN, you will have the option to define the type of padding
    you want or no padding at all. The common options here are ***valid*** or ***same***.
    Valid means no padding will be applied while ***same*** means that padding will
    be applied so that the size of the feature map is the same as the size of the
    input image.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建 CNN 时，你将有选项定义所需的填充类型或完全不使用填充。这里常见的选项是 ***valid*** 或 ***same***。Valid 表示不应用填充，而
    ***same*** 表示应用填充，以便特征图的大小与输入图像的大小相同。
- en: '![3 by3 kernel reduces a 5 by 5 input](../Images/3b544f10953e66d230c3775ff00f6337.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![3x3 卷积核对 5x5 输入进行降维](../Images/3b544f10953e66d230c3775ff00f6337.png)'
- en: '[A 3 by3 kernel reduces a 5 by 5 input to a 3 by 3 output ](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[3x3 卷积核将 5x5 输入降维为 3x3 输出](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
- en: Here is what the element-wise multiplication of the above feature map and filter
    would look like.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是上述特征图和滤波器逐元素乘法的效果。
- en: '![Element-wise multiplication of a 5 by input with a 3 by 3 filter](../Images/019f20ad536f4ec66373614bfe4c5f0a.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![5x5 输入与 3x3 滤波器的逐元素乘法](../Images/019f20ad536f4ec66373614bfe4c5f0a.png)'
- en: '[Element-wise multiplication of a 5 by input with a 3 by 3 filter.](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[5x5 输入与 3x3 滤波器的逐元素乘法](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)'
- en: Activation functions
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 激活函数
- en: A Rectified Linear Unit (ReLU) transformation is applied after every convolution
    operation to ensure non-linearity. ReLU is the most popular activation function
    but there are [other activation functions](https://keras.io/api/layers/activations/)
    to choose from.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次卷积操作后应用了一个修正线性单元（ReLU）变换，以确保非线性。ReLU 是最流行的激活函数，但也有[其他激活函数](https://keras.io/api/layers/activations/)可供选择。
- en: After the transformation, all values below zero are returned as zero while the
    other values are returned as they are.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在变换之后，所有低于零的值都被返回为零，而其他值保持不变。
- en: '![ReLu function plot](../Images/fdf8fd39d5c14cdad49d37daee199912.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![ReLu 函数图](../Images/fdf8fd39d5c14cdad49d37daee199912.png)'
- en: '[ReLu function plot](https://www.researchgate.net/figure/ReLU-activation-function_fig3_319235847)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[ReLu 函数图](https://www.researchgate.net/figure/ReLU-activation-function_fig3_319235847)'
- en: Pooling
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化
- en: In this operation, the size of the feature map is reduced further. There are
    various [pooling methods.](https://keras.io/api/layers/pooling_layers/)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个操作中，特征图的大小进一步减少。有各种[池化方法](https://keras.io/api/layers/pooling_layers/)。
- en: A common technique is **max-pooling.** The size of the pooling filter is usually
    a 2 by 2 matrix. In max-pooling, the 2 by 2 filter slides over the feature map
    and picks the largest value in a given box. This operation results in a **pooled
    feature map**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的技术是**最大池化**。池化滤波器的大小通常是一个2×2的矩阵。在最大池化中，2×2的滤波器在特征图上滑动，并在给定的区域中选取最大值。此操作的结果是一个**池化特征图**。
- en: '![Applying a 2 by 2 pooling filter to a 4 by 4 feature map](../Images/44d367354205b41010ff38d754b7142c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![将2×2池化滤波器应用于4×4特征图](../Images/44d367354205b41010ff38d754b7142c.png)'
- en: '[Applying a 2 by 2 pooling filter to a 4 by 4 feature map](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[将2×2池化滤波器应用于4×4特征图](https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks)。'
- en: Pooling forces the network to identify key features in the image irrespective
    of their location. The reduced image size also makes training the network faster.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 池化迫使网络识别图像中的关键特征，而不考虑其位置。减少的图像大小也使训练网络变得更快。
- en: Dropout Regularization
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dropout正则化
- en: Applying Dropout Regularization is a common practice in CNNs. This involves
    randomly dropping some nodes in layers so that they are not updated during back-propagation.
    This prevents overfitting.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 应用Dropout正则化是CNN中常见的做法。这涉及到随机丢弃某些层中的节点，使其在反向传播过程中不会被更新。这可以防止过拟合。
- en: Flattening
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扁平化
- en: Flattening involves transforming the pooled feature map into a single column
    that is passed to the fully connected layer. This is a common practice during
    the transition from convolutional layers to fully connected layers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 扁平化涉及将池化特征图转换为一个单列，然后传递给全连接层。这是在从卷积层过渡到全连接层时的常见做法。
- en: Fully connected layers
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: The flattened feature map is then passed to a fully connected layer. There might
    be several fully connected layers depending on the problem and the network. The
    last fully connected layer is responsible for outputting the prediction.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 扁平化后的特征图接着传递给全连接层。根据问题和网络结构，可能会有多个全连接层。最后一个全连接层负责输出预测结果。
- en: An activation function is used in the final layer depending on the type of problem.
    A [sigmoid activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid)
    is used for binary classification, while a [softmax activation](https://keras.io/api/layers/activation_layers/softmax)
    function is used for multi-class image classification.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最终层使用的激活函数取决于问题的类型。用于二分类的激活函数是 [sigmoid激活函数](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid)，而用于多类图像分类的则是
    [softmax激活函数](https://keras.io/api/layers/activation_layers/softmax)。
- en: '![Fully connected convolutional neural network](../Images/f1b3bab4eaa566a6a47f03c428a4caf7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![全连接卷积神经网络](../Images/f1b3bab4eaa566a6a47f03c428a4caf7.png)'
- en: '[Fully connected convolutional neural network](https://commons.wikimedia.org/wiki/File:Typical_cnn.png)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[全连接卷积神经网络](https://commons.wikimedia.org/wiki/File:Typical_cnn.png)'
- en: Why ConvNets Over Feed-forward Neural Nets?
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择卷积网络而不是前馈神经网络？
- en: Having learned about CNNs, you might be wondering why we can’t use normal neural
    networks for image problems. Normal neural networks can’t extract complex features
    from images as CNNs can.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了CNN之后，你可能会想知道为什么我们不能用普通神经网络处理图像问题。普通神经网络无法像CNN一样从图像中提取复杂特征。
- en: The ability of CNNs to extra features from images through the application of
    filters makes them a better fit for image problems. Also, feeding images directly
    into the feed-forward neural networks would be computationally expensive.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: CNN通过应用过滤器从图像中提取特征的能力使其更适合处理图像问题。此外，直接将图像输入到前馈神经网络中计算成本也很高。
- en: Convolutional Neural Network Architectures
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络架构
- en: 'You can always design your CNNs from scratch. However, you can also take advantage
    of numerous architectures that have been developed and released publicly. Some
    of these networks also come with pre-trained models that you can easily adapt
    for your use case. Some popular architectures include:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从零开始设计你的CNN。然而，你也可以利用许多已经开发并公开发布的架构。其中一些网络还提供了预训练模型，你可以轻松地将其适配到你的用例中。一些流行的架构包括：
- en: '[ResNet50](https://keras.io/api/applications/resnet/#resnet50-function)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ResNet50](https://keras.io/api/applications/resnet/#resnet50-function)'
- en: '[VGG19](https://keras.io/api/applications/vgg/#vgg19-function)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[VGG19](https://keras.io/api/applications/vgg/#vgg19-function)'
- en: '[Xception](https://keras.io/api/applications/xception/)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Xception](https://keras.io/api/applications/xception/)'
- en: '[Inception](https://keras.io/api/applications/inceptionv3)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Inception](https://keras.io/api/applications/inceptionv3)'
- en: 'You can start using these architectures through [Keras applications](https://keras.io/api/applications/).
    For example, here is how to use VGG19:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过[Keras应用](https://keras.io/api/applications/)开始使用这些架构。例如，以下是如何使用VGG19：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Convolutional Neural Networks (CNN) In TensorFlow Example
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow中的卷积神经网络（CNN）示例
- en: Let’s now build a food classification CNN using a [food dataset](http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz).
    The dataset contains over a hundred thousand images belonging to 101 classes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用[食物数据集](http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz)构建一个食物分类CNN。该数据集包含超过十万张属于101个类别的图像。
- en: Loading the images
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载图像
- en: The first step is to download and extract the data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是下载并解压数据。
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s take a look at one image from the dataset.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一看数据集中一张图像。
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![output](../Images/a9134fbc9b70c3c77835fb19d9f32dd4.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![output](../Images/a9134fbc9b70c3c77835fb19d9f32dd4.png)'
- en: Generate a tf.data.Dataset
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成tf.data.Dataset
- en: Next, load the images into a [TensorFlow dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).
    We’ll use 20% of the data for testing and the rest for training. Therefore, we
    have to create an `[ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?authuser=1)`
    for the training and testing set.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将图像加载到[TensorFlow数据集](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)中。我们将使用20%的数据进行测试，其余用于训练。因此，我们需要为训练集和测试集创建一个`[ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?authuser=1)`。
- en: The training set generator will also specify a couple of [image augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)
    techniques, such as zooming and flipping the images. Augmentation prevents overfitting
    in the network.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集生成器还将指定一些[图像增强](https://www.tensorflow.org/tutorials/images/data_augmentation)技术，如缩放和翻转图像。增强可以防止网络的过拟合。
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With the generators at hand, the next step is to use them to load the food images
    from the base directory. While loading the images, we specify the target size
    of the images. All images will be resized to the specified size.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有了生成器，下一步是使用它们从基础目录加载食物图像。在加载图像时，我们指定图像的目标大小。所有图像将被调整为指定的大小。
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When loading the images we also specify:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 加载图像时，我们还指定：
- en: The directory where the images are being loaded from.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载图像的目录。
- en: The batch size, in this case 32, meaning that the images will be loaded in batches
    of 32.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小，此处为32，这意味着图像将以32张为一批加载。
- en: The subset; whether it’s training or validation.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子集；无论是训练还是验证。
- en: The class mode as categorical since we have multiple classes. In the case of
    two classes this would be binary.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别模式为分类，因为我们有多个类别。如果只有两个类别，则为二进制。
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Model definition
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型定义
- en: The next step is to define the CNN model. The architecture of the network will
    look like the steps we discussed in the how CNNs work section. We’ll use the [Keras
    Sequential API](https://keras.io/api/models/sequential/) to define the network.
    CNNs are defined using the [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)
    layer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义CNN模型。网络的架构将类似于我们在CNN工作原理部分讨论的步骤。我们将使用[Keras Sequential API](https://keras.io/api/models/sequential/)来定义网络。CNN是通过[Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)层定义的。
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The Conv2D layer expects:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Conv2D层期望：
- en: The number of filters to be applied, in this case, 32.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要应用的过滤器数量，此处为32。
- en: The size of the kernel, in this case, 3 by 3.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积核的大小，此处为3 x 3。
- en: The size of the input images. 200 by 200 is the size of the image and 3 indicates
    that it’s a colored image.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像的大小。200 x 200是图像的大小，3表示这是一个彩色图像。
- en: The activation function; usually [ReLu](https://keras.io/api/layers/activation_layers/relu).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数；通常是[ReLu](https://keras.io/api/layers/activation_layers/relu)。
- en: In the network, we apply pooling with a filter of 2 by 2 and apply a [Dropout](https://keras.io/api/layers/regularization_layers/dropout/)
    layer to prevent overfitting.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络中，我们应用2 x 2的池化滤波器，并应用[Dropout](https://keras.io/api/layers/regularization_layers/dropout/)层以防止过拟合。
- en: The final layer has 101 units because there are 101 food classes. The activation
    function is [softmax](https://keras.io/api/layers/activation_layers/softmax) because
    it is a multiclass image classification problem.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层有101个单元，因为有101个食物类别。激活函数是[softmax](https://keras.io/api/layers/activation_layers/softmax)，因为这是一个多类别图像分类问题。
- en: Compiling the CNN model
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译CNN模型
- en: We [compile](https://keras.io/api/models/model_training_apis) the network using
    categorical loss and accuracy because it involves multiples classes.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们 [编译](https://keras.io/api/models/model_training_apis) 网络时使用了类别损失和准确率，因为它涉及多个类别。
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Training the CNN model
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练 CNN 模型
- en: Let’s now train the CNN model. We apply the [EarlyStopping](https://keras.io/api/callbacks/early_stopping)
    callback in the training process so that training stops if the model doesn’t improve
    after a number of iterations. In this case 3 epochs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们训练 CNN 模型。我们在训练过程中应用[早停回调](https://keras.io/api/callbacks/early_stopping)，以便在模型在一定迭代次数后没有改进时停止训练。在这种情况下是
    3 个时期。
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The image dataset we are working with here is quite large. We therefore need
    to use GPUs to train this model. Let’s utilize free GPUs offered by [Layer](http://layer)
    to train the model. To do that, we need to bundle all the code we have developed
    above into a single function. This function should return a model. In this case,
    a [TensorFlow](http://link) model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的图像数据集相当大。因此，我们需要使用 GPU 来训练这个模型。我们可以利用 [Layer](http://layer) 提供的免费 GPU
    来训练模型。为此，我们需要将上述开发的所有代码打包到一个函数中。该函数应返回一个模型。在这种情况下是一个 [TensorFlow](http://link)
    模型。
- en: To use GPUs to train the model, just decorate the function with a GPU environment.
    This is specified using the [fabric decorator.](https://docs.app.layer.ai/docs/reference/fabrics)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 GPU 来训练模型，只需将函数装饰为 GPU 环境。这是通过 [fabric 装饰器](https://docs.app.layer.ai/docs/reference/fabrics)
    来指定的。
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Training the model is done by passing the training function to the `layer.run`
    function. If you wish to train the model on your local infrastructure, call the
    `train()` function normally.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将训练函数传递给 `layer.run` 函数来完成模型训练。如果您希望在本地基础设施上训练模型，请正常调用 `train()` 函数。
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![training](../Images/8ee120dd5167c4569cc8d3579c3294ef.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![训练](../Images/8ee120dd5167c4569cc8d3579c3294ef.png)'
- en: Making predictions
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做出预测
- en: 'With the model ready, we can make predictions on a new image. This can be done
    in the following steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准备好后，我们可以对新图像进行预测。可以按照以下步骤进行：
- en: Fetch the trained model from [Layer](http://layer.ai).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 [Layer](http://layer.ai) 获取训练好的模型。
- en: Loading the image of the same size as the one used in the training images.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载与训练图像大小相同的图像。
- en: Convert the image into an array.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像转换为数组。
- en: Transform the numbers in the array to be between 0 and 1 by dividing by 255\.
    The training images were of the same form.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过除以 255，将数组中的数字转换为 0 到 1 之间。训练图像也是这种形式。
- en: Expand the dimensions of the image to add a batch size of 1, since we are making
    predictions on a single image.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展图像的维度，以添加一个批处理大小为 1，因为我们在对单张图像进行预测。
- en: '[PRE11]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Since this is a multiclass network, we’ll use the [softmax function](https://www.tensorflow.org/api_docs/python/tf/nn/softmax?authuser=1)
    to interpret the results. The function converts the [logits](https://developers.google.com/machine-learning/glossary?authuser=1#logits)
    to a probability for each class.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个多类别网络，我们将使用 [softmax 函数](https://www.tensorflow.org/api_docs/python/tf/nn/softmax?authuser=1)
    来解释结果。该函数将 [logits](https://developers.google.com/machine-learning/glossary?authuser=1#logits)
    转换为每个类别的概率。
- en: '[PRE12]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Final Thoughts
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this article, we have covered CNNs at length. Specifically, we talked about:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们详细介绍了 CNN。特别是，我们讨论了：
- en: What are CNNs?
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 CNN？
- en: How CNNs work.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN 的工作原理。
- en: CNN architectures.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN 架构。
- en: How to build a CNN for an image classification problem.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建一个用于图像分类问题的 CNN。
- en: Resources
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Google Colab notebook](https://colab.research.google.com/drive/1qfQijIFG7gva5TdehmL70NXmBfwCJEwe?usp=sharing)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Colab 笔记本](https://colab.research.google.com/drive/1qfQijIFG7gva5TdehmL70NXmBfwCJEwe?usp=sharing)'
- en: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** is experienced
    in data science, machine learning, and deep learning with a keen eye for building
    machine learning communities.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** 在数据科学、机器学习和深度学习方面经验丰富，并且在建立机器学习社区方面具有敏锐的眼光。'
- en: More On This Topic
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络综合指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络前应尝试的 10 个简单方法](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 的可解释神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引领我们走向 AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
