# 数据科学家需要掌握的10种统计技术

> 原文：[https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html](https://www.kdnuggets.com/2017/11/10-statistical-techniques-data-scientists-need-master.html)

![头部图片](../Images/192409ea180b5be09e1a283158eb89e2.png)

不论你对数据科学的吸引力有何看法，数据的重要性以及我们分析、组织和解释数据的能力都不容忽视。Glassdoor依据大量的就业数据和员工反馈，将数据科学家评选为他们的[美国25个最佳职位](https://www.glassdoor.com/Best-Jobs-in-America-LST_KQ0,20.htm)榜单中的第一名。因此，这一角色将持续存在，但无疑，数据科学家的具体工作内容将不断发展。随着机器学习技术的日益普及，以及深度学习等新兴领域在研究人员、工程师及雇佣他们的公司中获得了显著的关注，数据科学家继续在创新和技术进步的浪潮中领航。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速通道进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT工作

* * *

尽管拥有强大的编码能力很重要，但数据科学不仅仅是软件工程（实际上，只要熟悉Python，你就可以上路）。数据科学家活跃于编码、统计学和批判性思维的交汇点。[正如Josh Wills](https://www.quora.com/What-is-the-difference-between-a-data-scientist-and-a-statistician)所说，*“数据科学家是一个在统计学上比任何程序员都强，在编程上比任何统计学家都强的人。”* 我个人认识太多希望转行成为数据科学家的软件工程师，他们盲目地将机器学习框架如TensorFlow或Apache Spark应用于数据，而没有深入理解背后的统计理论。因此，统计学习的研究应运而生，这是一种源自统计学和泛函分析领域的机器学习理论框架。

**为什么学习统计学习？** 理解各种技术背后的思想非常重要，以便知道如何以及何时使用它们。必须首先理解更简单的方法，以便掌握更复杂的方法。准确评估方法的性能也很重要，以了解它运行得好还是不好。此外，这是一个令人兴奋的研究领域，在科学、工业和金融领域有重要应用。*最终*，统计学习是现代数据科学家培训中的一个基本要素。统计学习问题的例子包括：

+   识别前列腺癌的风险因素。

+   基于对数周期图对记录的音素进行分类。

+   根据人口统计、饮食和临床测量来预测某人是否会心脏病发作。

+   定制电子邮件垃圾邮件检测系统。

+   识别手写邮政编码中的数字。

+   将组织样本分类为几种癌症类别之一。

+   确立工资与人口调查数据中人口统计变量之间的关系。

在我大学的最后一个学期，我进行了一项关于数据挖掘的独立研究。该课程涵盖了来自三本书的广泛材料：[统计学习简介](http://www-bcf.usc.edu/~gareth/ISL/)（Hastie, Tibshirani, Witten, James）、[贝叶斯数据分析](https://sites.google.com/site/doingbayesiandataanalysis/)（Kruschke）和[时间序列分析与应用](http://www.stat.pitt.edu/stoffer/tsa4/)（Shumway, Stoffer）。我们做了很多关于贝叶斯分析、马尔可夫链蒙特卡洛、层次建模、有监督和无监督学习的练习。这段经历加深了我对数据挖掘学术领域的兴趣，并说服我进一步专注于此。最近，我完成了斯坦福 Lagunita 上的[统计学习在线课程](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about)，该课程涵盖了我在独立研究中阅读的[**统计学习简介**](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370)一书中的所有材料。现在内容接触了两次，我想分享我认为任何数据科学家都应该学习的10种统计技术，以更有效地处理大数据集。

在介绍这10种技术之前，我想区分统计学习和机器学习。我之前写过[关于机器学习的最受欢迎的 Medium 文章之一](https://gab41.lab41.org/the-10-algorithms-machine-learning-engineers-need-to-know-f4bb63f5b2fa)，因此我相信我有足够的专业知识来解释这些差异：

+   机器学习作为人工智能的一个子领域出现。

+   统计学习作为统计学的一个子领域出现。

+   机器学习更加注重大规模应用和预测准确性。

+   统计学习强调模型及其可解释性，以及精确性和不确定性。

+   但这种区别变得越来越模糊，且存在大量的“交叉融合”。

+   机器学习在营销领域占有优势！

****1 — 线性回归：****

在统计学中，线性回归是一种通过拟合*最佳线性关系*来预测目标变量的方法。*最佳拟合*是通过确保形状与每个点的实际观察之间的所有距离之和尽可能小来完成的。形状的拟合被称为“最佳”，意味着没有其他位置可以在选择的形状下产生更少的误差。线性回归的两个主要类型是*简单线性回归*和*多重线性回归*。**简单线性回归**使用一个自变量通过拟合最佳线性关系来预测因变量。**多重线性回归**使用多个自变量通过拟合最佳线性关系来预测因变量。

![](../Images/ef9c3a012f80c3ae290f8a8106b0e553.png)

选择你日常生活中使用的两个相关的事物。例如，我有过去三年中每月支出、每月收入和每月旅行次数的数据。现在我需要回答以下问题：

+   我明年的月支出将是多少？

+   在决定我的月支出时，哪个因素（每月收入或每月旅行次数）更重要？

+   每月收入和每月旅行次数与月支出之间的相关性如何？

****2 — 分类：****

分类是一种数据挖掘技术，用于将类别分配给数据集合，以帮助更准确的预测和分析。也有时称为决策树，分类是几种旨在使分析非常大数据集有效的方法之一。两个主要的分类技术是*逻辑回归*和*判别分析*。

**逻辑回归**是在因变量是二元的情况下进行的适当回归分析。像所有回归分析一样，逻辑回归是一种预测分析。逻辑回归用于描述数据，并解释一个因变量二元变量与一个或多个名义、序数、区间或比率级别自变量之间的关系。逻辑回归可以检查的问题类型包括：

+   每增加一磅体重和每天吸一包香烟，得肺癌的概率（是与否）如何变化？

+   体重卡路里摄入、脂肪摄入和参与者年龄是否会对心脏病发作（是与否）产生影响？

![](../Images/b938a7f44237a2491b90de2f19a3c6c7.png)

在**判别分析**中，2个或更多的组、簇或总体是已知的，而1个或多个新的观测值会根据测量的特征被分类到已知总体中的1个。判别分析将预测变量X的分布分别建模于每个响应类别中，然后使用贝叶斯定理将这些分布转换为给定X值的响应类别的概率估计。这些模型可以是*线性*的或*二次*的。

+   **线性判别分析**计算每个观测值的“判别分数”以分类它属于哪个响应变量类别。这些分数通过寻找自变量的线性组合来获得。它假设每个类别内的观测值来自多变量高斯分布，并且预测变量的协方差在所有响应变量Y的k个水平上是共同的。

+   **二次判别分析**提供了一种替代方法。与LDA相似，QDA假设每个类别的观测值来自高斯分布。然而，与LDA不同的是，QDA假设每个类别有其自身的协方差矩阵。换句话说，预测变量在Y的每个k级别上不被认为具有共同的方差。

****3 — 重采样方法：****

重采样是一种从原始数据样本中重复抽样的方法。这是一种非参数统计推断方法。换句话说，重采样方法不涉及使用通用分布表来计算近似的p概率值。

重采样通过实际数据生成独特的采样分布。它使用实验方法而非分析方法来生成这一独特的采样分布。由于它基于研究者对所有可能结果的无偏样本，因此生成的估计是无偏的。为了理解重采样的概念，你需要理解*自助法*和*交叉验证*这两个术语：

![](../Images/13226e7dc419f46ee9646e6742c25c15.png)

+   **自助法**是一种在许多情况下有用的技术，如验证预测模型性能、集成方法、估计模型的偏差和方差。它通过从原始数据中进行有放回抽样工作，并将“*未选择*”的数据点作为测试案例。我们可以重复此过程若干次，并计算平均分数作为我们模型性能的估计。

+   另一方面，**交叉验证**是一种验证模型性能的技术，方法是将训练数据分为k部分。我们将k — 1部分作为训练集，将“*保留*”部分作为测试集。我们以不同的方式重复这一过程k次。最后，我们取k个分数的平均值作为我们的性能估计。

对于线性模型而言，普通最小二乘法是主要的拟合标准。接下来的三种方法是可提供更好预测准确性和模型可解释性的替代方法。

****4 — 子集选择：****

这种方法识别出我们认为与响应变量相关的*p*预测变量子集。然后，我们使用这些子集特征的最小二乘法拟合模型。

![](../Images/6379988a88899a4e3fce74341f2ba5a0.png)

+   **最佳子集选择：** 在这里，我们为每个可能的*p*预测变量组合拟合一个单独的OLS回归，然后查看结果模型的拟合情况。算法分为两个阶段：（1）拟合所有包含*k*预测变量的模型，其中*k*是模型的最大长度，（2）使用交叉验证预测误差选择一个模型。重要的是使用*测试*或*验证误差*，而不是训练误差来评估模型拟合，因为RSS和R²随着变量的增加而单调增加。最佳方法是交叉验证，并选择在测试误差估计上具有最高R²和最低RSS的模型。

+   **向前逐步选择**考虑一个较小的*p*预测变量子集。它从一个没有预测变量的模型开始，然后逐一向模型中添加预测变量，直到所有预测变量都被纳入模型。添加变量的顺序是使拟合得到最大改进的变量，直到没有更多变量通过交叉验证预测误差改进模型拟合。

+   **向后逐步选择**从模型中所有*p*预测变量开始，然后逐次移除最不有用的预测变量。

+   **混合方法**遵循向前逐步方法，但在添加每个新变量后，该方法还可能移除对模型拟合没有贡献的变量。

****5 — 压缩：****

这种方法拟合包含所有*p*预测变量的模型，然而，相较于最小二乘估计，估计的系数被压缩至接近零。这种压缩，也称为*正则化*，具有减少方差的效果。根据执行的压缩类型，一些系数可能会被估计为零。因此，这种方法也执行变量选择。将系数估计压缩到零的两种最知名技术是*岭回归*和*套索回归*。

![](../Images/1b75295dced1b4ca5439ddd13fa90199.png)

+   **岭回归**类似于最小二乘法，只是系数的估计通过最小化稍微不同的量。岭回归与OLS一样，寻求减少RSS的系数估计，但当系数接近零时，它们还有一个收缩惩罚。这个惩罚会将系数估计值收缩到接近零。在不深入数学的情况下，了解岭回归会将特征的列空间方差最小的特征收缩是有用的。就像主成分分析一样，岭回归将数据投影到*d*方向空间中，然后将低方差成分的系数收缩得比高方差成分更多，这些成分等同于最大和最小主成分。

+   岭回归至少有一个缺点；它将所有*p*预测变量包括在最终模型中。惩罚项将使许多变量接近零，但从未*完全*为零。这通常不会影响预测精度，但可能使模型的结果更难以解释。**套索回归**克服了这一缺点，并且能够将一些系数强制为零，前提是*s*足够小。由于*s* = 1 结果是常规OLS回归，因此当*s*接近0时，系数会收缩到接近零。因此，套索回归也进行变量选择。

### 更多关于此主题

+   [每个初学者数据科学家都应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [建立一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [成为优秀数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [停止学习数据科学以寻找目标，并通过找到目标来...](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)
