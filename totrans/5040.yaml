- en: 'Mining Twitter Data with Python Part 1: Collecting Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《使用 Python 矿工 Twitter 数据 第 1 部分：数据收集》
- en: 原文：[https://www.kdnuggets.com/2016/06/mining-twitter-data-python-part-1.html](https://www.kdnuggets.com/2016/06/mining-twitter-data-python-part-1.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/06/mining-twitter-data-python-part-1.html](https://www.kdnuggets.com/2016/06/mining-twitter-data-python-part-1.html)
- en: '**By Marco Bonzanini, Independent Data Science Consultant**.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Marco Bonzanini，独立数据科学顾问**。'
- en: '[Twitter](https://www.twitter.com/) is a popular social network where users
    can share short SMS-like messages called *tweets*. Users share thoughts, links
    and pictures on Twitter, journalists comment on live events, companies promote
    products and engage with customers. The list of different ways to use Twitter
    could be really long, and with 500 millions of tweets per day, there’s a lot of
    data to analyse and to play with.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Twitter](https://www.twitter.com/) 是一个流行的社交网络，用户可以分享短消息，称为 *推文*。用户在 Twitter
    上分享思想、链接和图片，记者评论实时事件，公司推广产品并与客户互动。使用 Twitter 的方式可以非常多样，每天有 5 亿条推文，有大量数据供分析和使用。'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This is the first in a series of articles dedicated to mining data on Twitter
    using Python. In this first part, we’ll see different options to collect data
    from Twitter. Once we have built a data set, in the next episodes we’ll discuss
    some interesting data applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个系列文章的第一篇，专注于使用 Python 挖掘 Twitter 数据。在这一部分，我们将探讨从 Twitter 收集数据的不同选项。一旦我们建立了数据集，在接下来的文章中我们将讨论一些有趣的数据应用。
- en: '![Twitter banner](../Images/3da5b4dea824ea453ca3ae25f3548634.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![Twitter 横幅](../Images/3da5b4dea824ea453ca3ae25f3548634.png)'
- en: Register Your App
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注册你的应用程序
- en: In order to have access to Twitter data programmatically, we need to create
    an app that interacts with the Twitter API.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以编程方式访问 Twitter 数据，我们需要创建一个与 Twitter API 互动的应用程序。
- en: 'The first step is the registration of your app. In particular, you need to
    point your browser to [http://apps.twitter.com](http://apps.twitter.com/), log-in
    to Twitter (if you’re not already logged in) and register a new application. You
    can now choose a name and a description for your app (for example “Mining Demo”
    or similar). You will receive a *consumer key* and a *consumer secret*: these
    are application settings that should always be kept private. From the configuration
    page of your app, you can also require an access token and an access token secret.
    Similarly to the consumer keys, these strings must also be kept private: they
    provide the application access to Twitter on behalf of your account. The default
    permissions are read-only, which is all we need in our case, but if you decide
    to change your permission to provide writing features in your app, you must negotiate
    a new access token.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是注册你的应用程序。具体来说，你需要将浏览器指向 [http://apps.twitter.com](http://apps.twitter.com/)，登录
    Twitter（如果尚未登录）并注册一个新应用程序。你现在可以为你的应用程序选择一个名称和描述（例如“矿工演示”或类似名称）。你将收到一个 *consumer
    key* 和一个 *consumer secret*：这些是应用程序设置，应该始终保密。你还可以从应用程序的配置页面申请一个访问令牌和一个访问令牌秘密。与
    consumer keys 类似，这些字符串也必须保密：它们提供应用程序代表你的账户访问 Twitter。默认权限是只读，这正是我们所需的，但如果你决定更改权限以提供写入功能，你必须协商一个新的访问令牌。
- en: 'Important Note: there are rate limits in the use of the Twitter API, as well
    as limitations in case you want to provide a downloadable data-set, see:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明：使用 Twitter API 有速率限制，并且如果你想提供可下载的数据集也有限制，请参见：
- en: '[https://dev.twitter.com/overview/terms/agreement-and-policy](https://dev.twitter.com/overview/terms/agreement-and-policy)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dev.twitter.com/overview/terms/agreement-and-policy](https://dev.twitter.com/overview/terms/agreement-and-policy)'
- en: '[https://dev.twitter.com/rest/public/rate-limiting](https://dev.twitter.com/rest/public/rate-limiting)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dev.twitter.com/rest/public/rate-limiting](https://dev.twitter.com/rest/public/rate-limiting)'
- en: Accessing the Data
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 访问数据
- en: 'Twitter provides [REST APIs](https://dev.twitter.com/rest/public) you can use
    to interact with their service. There is also [a bunch of Python-based clients](https://dev.twitter.com/overview/api/twitter-libraries#python) out
    there that we can use without re-inventing the wheel. In particular, [Tweepy](http://tweepy.readthedocs.org/) in
    one of the most interesting and straightforward to use, so let’s install it:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter 提供了 [REST APIs](https://dev.twitter.com/rest/public) 供我们与他们的服务交互。也有
    [一堆基于 Python 的客户端](https://dev.twitter.com/overview/api/twitter-libraries#python)
    可供使用，我们无需重新发明轮子。特别是，[Tweepy](http://tweepy.readthedocs.org/) 是一个最有趣且易于使用的库，所以我们来安装它：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Update*: the release 3.4.0 of Tweepy has introduced a problem with Python
    3, currently fixed on [github](https://github.com/tweepy/tweepy) but not yet available
    with `pip`, for this reason we’re using version 3.3.0 until a new release is available.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*更新*：Tweepy 的 3.4.0 版本引入了 Python 3 的问题，目前在 [github](https://github.com/tweepy/tweepy)
    上已修复，但通过 `pip` 仍不可用，因此我们使用版本 3.3.0 直到新版本发布。'
- en: '*More Updates*: the release 3.5.0 of Tweepy, already available via pip, seems
    to solve the problem with Python 3 mentioned above.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*更多更新*：Tweepy 的 3.5.0 版本，已通过 pip 提供，似乎解决了上述提到的 Python 3 问题。'
- en: 'In order to authorise our app to access Twitter on our behalf, we need to use
    the OAuth interface:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了授权我们的应用程序代表我们访问 Twitter，我们需要使用 OAuth 接口：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `api` variable is now our entry point for most of the operations we can
    perform with Twitter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`api` 变量现在是我们可以执行的大多数 Twitter 操作的入口点。'
- en: 'For example, we can read our own timeline (i.e. our Twitter homepage) with:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以通过以下方式读取自己的时间线（即我们的 Twitter 首页）：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Tweepy provides the convenient Cursor interface to iterate through different
    types of objects. In the example above we’re using *10* to limit the number of
    tweets we’re reading, but we can of course access more. The `status` variable
    is an instance of the `Status()` class, a nice wrapper to access the data. The
    JSON response from the Twitter API is available in the attribute `_json` (with
    a leading underscore), which is not the raw JSON string, but a dictionary.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Tweepy 提供了方便的 Cursor 接口，用于迭代不同类型的对象。在上面的示例中，我们使用 *10* 来限制我们读取的推文数量，但我们当然可以访问更多。`status`
    变量是 `Status()` 类的一个实例，这是一个很好的封装，用于访问数据。来自 Twitter API 的 JSON 响应在属性 `_json` 中（以一个下划线开头），这不是原始的
    JSON 字符串，而是一个字典。
- en: 'So the code above can be re-written to process/store the JSON:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以上面的代码可以重写为处理/存储 JSON：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'What if we want to have a list of all our followers? There you go:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要一个包含所有关注者的列表？这就来了：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And how about a list of all our tweets? Simple:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，所有推文的列表呢？很简单：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this way we can easily collect tweets (and more) and store them in the original
    JSON format, fairly easy to convert into different data models depending on our
    storage (many NoSQL technologies provide some bulk import feature).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以轻松收集推文（以及更多）并以原始 JSON 格式存储，转换成不同的数据模型相当容易，具体取决于我们的存储（许多 NoSQL 技术提供一些批量导入功能）。
- en: 'The function `process_or_store()` is a place-holder for your custom implementation.
    In the simplest form, you could just print out the JSON, one tweet per line:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `process_or_store()` 是你自定义实现的占位符。在最简单的形式下，你可以将 JSON 打印出来，每条推文占一行：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Streaming
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流式
- en: 'In case we want to “keep the connection open”, and gather all the upcoming
    tweets about a particular event, the streaming API is what we need. We need to
    extend the `StreamListener()` to customise the way we process the incoming data.
    A working example that gathers all the new tweets with the #python hashtag:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '如果我们想要“保持连接打开”，并收集关于特定事件的所有即将到来的推文，流式 API 是我们需要的。我们需要扩展 `StreamListener()`
    以自定义处理传入数据的方式。一个工作示例，收集带有 #python 标签的所有新推文：'
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Depending on the search term, we can gather tons of tweets within a few minutes.
    This is especially true for live events with a world-wide coverage (World Cups,
    Super Bowls, Academy Awards, you name it), so keep an eye on the JSON file to
    understand how fast it grows and consider how many tweets you might need for your
    tests. The above script will save each tweet on a new line, so you can use the
    command `wc -l python.json` from a Unix shell to know how many tweets you’ve gathered.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 根据搜索词，我们可以在几分钟内收集大量推文。尤其是对于具有全球覆盖范围的实时事件（世界杯、超级碗、奥斯卡奖等），请关注 JSON 文件以了解其增长速度，并考虑你可能需要多少推文用于测试。上述脚本将每条推文保存在新的一行中，因此你可以使用命令`wc
    -l python.json`从 Unix shell 中知道你收集了多少条推文。
- en: 'You can see a minimal working example of the Twitter Stream API in the following
    Gist:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下 Gist 中看到 Twitter Stream API 的一个最小工作示例：
- en: '[twitter_stream_downloader.py](https://gist.github.com/bonzanini/af0463b927433c73784d)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[twitter_stream_downloader.py](https://gist.github.com/bonzanini/af0463b927433c73784d)'
- en: Summary
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: We have introduced `tweepy` as a tool to access Twitter data in a fairly easy
    way with Python. There are different types of data we can collect, with the obvious
    focus on the “tweet” object.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了`tweepy`作为一种用 Python 轻松访问 Twitter 数据的工具。我们可以收集不同类型的数据，显然重点是“推文”对象。
- en: Once we have collected some data, the possibilities in terms of analytics applications
    are endless. In the next episodes, we’ll discuss some options.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们收集了一些数据，在分析应用方面的可能性是无穷无尽的。在接下来的章节中，我们将讨论一些选项。
- en: '**Bio: [Marco Bonzanini](https://twitter.com/marcobonzanini)** is a Data Scientist
    based in London, UK. Active in the PyData community, he enjoys working in text
    analytics and data mining applications. He''s the author of "[Mastering Social
    Media Mining with Python](https://www.amazon.com/Mastering-Social-Media-Mining-Python-ebook/dp/B01BFD2Z2Q)"
    (Packt Publishing, July 2016).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Marco Bonzanini](https://twitter.com/marcobonzanini)** 是一位驻伦敦的数据科学家。活跃于
    PyData 社区，他喜欢从事文本分析和数据挖掘应用。他是《"[用 Python 掌握社交媒体挖掘](https://www.amazon.com/Mastering-Social-Media-Mining-Python-ebook/dp/B01BFD2Z2Q)"》(Packt
    Publishing, 2016年7月)的作者。'
- en: '[Original](https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/).
    Reposted with permission.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/)。经授权转载。'
- en: '**Related**:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**：'
- en: '[The Data Awakens: Star Wars Sentiment Analysis](/2016/01/data-awakens-star-wars-sentiment-analysis.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据觉醒：星球大战情感分析](/2016/01/data-awakens-star-wars-sentiment-analysis.html)'
- en: '[Tutorial: Building a Twitter Sentiment Analysis Process](/2015/11/tutorial-twitter-sentiment-analysis.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[教程：构建 Twitter 情感分析过程](/2015/11/tutorial-twitter-sentiment-analysis.html)'
- en: '[Dissecting the Big Data Twitter Community through a Big data Lens](/2015/09/dissecting-big-data-twitter-community.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过大数据视角剖析大数据 Twitter 社区](/2015/09/dissecting-big-data-twitter-community.html)'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[KDnuggets News, April 6: 8 Free MIT Courses to Learn Data Science…](https://www.kdnuggets.com/2022/n14.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月6日：8 门免费 MIT 数据科学课程…](https://www.kdnuggets.com/2022/n14.html)'
- en: '[The Complete Collection of Data Science Cheat Sheets - Part 1](https://www.kdnuggets.com/2022/02/complete-collection-data-science-cheat-sheets-part-1.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学备忘单完整集合 - 第 1 部分](https://www.kdnuggets.com/2022/02/complete-collection-data-science-cheat-sheets-part-1.html)'
- en: '[Building a Visual Search Engine - Part 1: Data Exploration](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-1.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建视觉搜索引擎 - 第 1 部分：数据探索](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-1.html)'
- en: '[The Complete Collection of Data Science Cheat Sheets - Part 2](https://www.kdnuggets.com/2022/02/complete-collection-data-science-cheat-sheets-part-2.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学备忘单完整集合 - 第 2 部分](https://www.kdnuggets.com/2022/02/complete-collection-data-science-cheat-sheets-part-2.html)'
- en: '[The Complete Collection Of Data Repositories - Part 1](https://www.kdnuggets.com/2022/04/complete-collection-data-repositories-part-1.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据存储库完整集合 - 第 1 部分](https://www.kdnuggets.com/2022/04/complete-collection-data-repositories-part-1.html)'
- en: '[The Complete Collection Of Data Repositories - Part 2](https://www.kdnuggets.com/2022/04/complete-collection-data-repositories-part-2.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据存储库完整集合 - 第 2 部分](https://www.kdnuggets.com/2022/04/complete-collection-data-repositories-part-2.html)'
