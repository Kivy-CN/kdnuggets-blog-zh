# 理解强化学习的基础

> 原文：[https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning](https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning)

![理解强化学习的基础](../Images/ae95ebb172fd241073ad13c19e1f1377.png)

图片来源：编辑 | Ideogram

强化学习是人工智能领域专注于构建从经验或试错中学习的系统的领域。这篇文章以非技术性和易于接近的方式揭示了这一引人入胜的人工智能部分的基本概念和应用。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT需求

* * *

## 什么是强化学习？

强化学习（RL）是人工智能的一个分支，在这个领域中，代理——通常是软件程序——通过与环境的交互逐渐学会智能决策。

为了更好地理解RL背后的原理，一个常见的比较是小孩子学习骑自行车。一开始，孩子会尝试不同的动作，通常会导致摔倒。每次孩子摔下自行车时，(s)he 会感受到疼痛（惩罚），而如果孩子能够骑行几米而不摔倒，(s)he 会感到满意（奖励）。孩子逐渐内化哪些动作——或动作序列——能够实现平稳骑行，应用这些动作并提高骑行技能。

同样，在RL中，代理执行动作以获得奖励或惩罚，并迭代地调整其行为以提高性能。

## RL算法的元素

理解RL基础的第一步是介绍RL算法的关键元素。这些元素在下面的图示中展示。

![RL算法的元素](../Images/392daabd31142d084e1bffe0470668d4.png)

+   **代理：** 在环境中做决策并采取行动以实现目标的软件实体。

+   **环境：** 代理通过执行动作与之互动的数字或物理设置。

+   **状态：** 环境由状态组成，代理在给定时间处于某一状态。换句话说，状态代表当前的环境情况，由代理“分析”以做出决策。

+   **动作：** 在给定状态下，代理进行的任何移动或决策，通常会导致因动作而产生的新状态。

+   **奖励：** 代理因采取某一动作导致状态变化而收到的值或反馈。它可以是正面的或负面的（惩罚），表示相对于定义的目标，动作的即时成功或失败。正面奖励往往使代理更接近该目标，反之亦然。

## 强化学习代理如何学习？

我们下一个需要回答的问题是：代理如何学习选择能够带来最大奖励的动作，无论是短期的还是长期的？换句话说，代理在学习过程中利用哪些元素来改善其在不同状态下的决策能力？这就是策略和价值函数的概念发挥作用的地方。

**策略**是代理用来决定在每个可能状态下采取哪个动作的策略。在最简单的情况下，策略可以是一个状态-动作查找表，但通常它是由一个更复杂的数学函数定义，该函数将状态映射到可能的动作。例如，一个学习玩基于平台的视频游戏的代理，其控制的角色当前站在一个平台上（状态），可以向前、向后走或向任何方向跳跃（动作）。

同时，**奖励函数**量化了代理在给定状态下执行动作后获得的正面或负面奖励。从数学上讲，它将状态-动作对映射到一个数值奖励。在视频游戏的例子中，如果角色在边缘上并向前跳跃，它可能会到达对面的另一个平台（正面奖励），而如果它决定不跳跃而是直接走前面，它将会掉落（负面奖励）。

当这些元素共同观察时，允许代理逐步学习最佳的行动路径，以最大化奖励并最终实现所追求的目标。

## 基于模型与无模型强化学习方法

策略和奖励函数来自哪里？是否有人制定了有关环境状态、行动及其奖励的信息？简短的回答是：这要看情况。这些信息的收集方式取决于所使用的强化学习方法类型。从这个角度来看，有两种广泛的方法：基于模型的强化学习和无模型强化学习。

基于模型的强化学习（RL）使用环境的模型（通常通过机器学习或深度学习从数据中学习得到）来评估所采取行动的结果，而无模型强化学习则通过直接与环境互动逐步构建这个模型，依赖纯粹的“试错”而不是预测或估计。

## 强化学习的现实世界影响和障碍

#### 应用与最新趋势

在实验层面，强化学习历史上主要应用于解决游戏和模拟环境中的问题。然而，其应用领域已迅速扩展到机器人技术和推荐引擎等需要实时决策的动态环境中。强化学习的最新应用趋势包括自主驾驶控制及其与生成式人工智能（例如语言模型）的集成，以提高在复杂或高度变化的环境中内容生成决策的效果。

#### 挑战与局限性

强化学习的主要挑战之一是其高计算和数据消耗成本，这由于与环境的密集互动以有效学习，从而使其在某些现实场景中的应用变得更加困难。

## 总结

在这篇文章中，我们介绍了围绕强化学习算法的基本概念及其核心组件：具有目标的代理，通过与环境互动执行动作并逐渐从这些动作的结果中学习。我们还概述了强化学习解决方案的显著实际应用和挑战。尽管充满挑战，强化学习目前因其与生成式人工智能解决方案的共生关系而备受关注，使得内容生成变得更加高效。

[](https://www.linkedin.com/in/ivanpc/)****[伊万·帕洛马雷斯·卡拉索萨](https://www.linkedin.com/in/ivanpc/)**** 是一位领导者、作家、演讲者和人工智能、机器学习、深度学习及大型语言模型领域的顾问。他训练和指导他人如何在实际中利用人工智能。

### 更多相关主题

+   [回到基础第3周：机器学习简介](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)

+   [回到基础，第2部分：梯度下降](https://www.kdnuggets.com/2023/03/back-basics-part-dos-gradient-descent.html)

+   [通过这本免费电子书学习 MLOps 基础知识](https://www.kdnuggets.com/2023/08/learn-mlops-basics-free-ebook.html)

+   [Python 基础：语法、数据类型和控制结构](https://www.kdnuggets.com/python-basics-syntax-data-types-and-control-structures)

+   [回到基础第1周：Python 编程与数据科学基础](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)

+   [回到基础第4周：高级主题与部署](https://www.kdnuggets.com/back-to-basics-week-4-advanced-topics-and-deployment)
