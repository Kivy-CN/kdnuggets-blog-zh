- en: An Introduction to Explainable AI (XAI)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释 AI (XAI) 简介
- en: 原文：[https://www.kdnuggets.com/an-introduction-to-explainable-ai-xai](https://www.kdnuggets.com/an-introduction-to-explainable-ai-xai)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/an-introduction-to-explainable-ai-xai](https://www.kdnuggets.com/an-introduction-to-explainable-ai-xai)
- en: '![An Introduction to Explainable AI (XAI)](../Images/ccfe0fb9da9817f92ee612e339850018.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![可解释 AI (XAI) 简介](../Images/ccfe0fb9da9817f92ee612e339850018.png)'
- en: Image by Editor | Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑 | Midjourney
- en: AI systems are increasingly present in our daily lives, making decisions that
    can be difficult to understand. Explainable AI (XAI) aims to make these decisions
    more transparent and comprehensible. This article introduces the concept of XAI,
    explores its techniques, and discusses its applications in various domains.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: AI 系统在我们日常生活中越来越普遍，做出的决策可能难以理解。可解释 AI (XAI) 旨在使这些决策更加透明和易于理解。本文介绍了 XAI 的概念，探讨了其技术，并讨论了它在各个领域的应用。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: What is Explainable AI (XAI)?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是可解释 AI (XAI)？
- en: Traditional AI models are like "black boxes." They use complex algorithms without
    explaining how they work. This makes it hard to understand their results.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的 AI 模型就像“黑箱”。它们使用复杂的算法而不解释其工作原理。这使得理解其结果变得困难。
- en: XAI aims to make the process transparent. It helps people see and understand
    why AI makes certain choices. It uses simple models and visual aids to explain
    the process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: XAI 旨在使过程透明。它帮助人们了解和理解 AI 为什么做出特定的选择。它使用简单的模型和视觉辅助工具来解释这一过程。
- en: The Need for Explainability
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释性的重要性
- en: There are numerous reasons for explainability in AI systems. Some of the most
    important are listed below.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: AI 系统的可解释性有许多重要原因。以下列出了一些最重要的原因。
- en: '**Trust**: Transparent processes help ensure decisions are fair. This helps
    users trust and accept the results.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**信任**：透明的过程有助于确保决策公平。这帮助用户信任并接受结果。'
- en: '**Fairness**: Transparent processes prevent unfair or discriminatory outcomes.
    They prevent outcomes that might be biased.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**公平性**：透明的过程可以防止不公平或歧视性的结果。它们防止可能存在偏见的结果。'
- en: '**Accountability**: Explainability allows us to review decisions.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问责**：可解释性允许我们审查决策。'
- en: '**Safety**: XAI helps identify and fix errors. This is important to prevent
    harmful outcomes.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安全性**：XAI 有助于识别和修复错误。这对于防止有害结果至关重要。'
- en: Techniques in Explainable AI
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释 AI 技术
- en: Model-Agnostic Methods
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型无关方法
- en: These techniques work with any AI model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术适用于任何 AI 模型。
- en: '**LIME (Local Interpretable Model-agnostic Explanations)**: LIME simplifies
    complex models for individual predictions. It creates a simpler model to show
    how small changes in inputs affect the outcome.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LIME（Local Interpretable Model-agnostic Explanations）**：LIME 简化复杂模型以进行个体预测。它创建一个更简单的模型，以展示输入的小变化如何影响结果。'
- en: '**SHAP (SHapley Additive exPlanations)**: SHAP uses game theory to assign importance
    scores to each feature. It shows how each feature influences the final prediction.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SHAP（SHapley Additive exPlanations）**：SHAP 利用博弈论为每个特征分配重要性评分。它展示了每个特征如何影响最终预测结果。'
- en: Model-Specific Methods
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型特定方法
- en: These techniques are tailored for specific types of AI models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术专门针对特定类型的 AI 模型。
- en: '**Decision Trees**: Decision trees split data into branches to make decisions.
    Each branch represents a rule based on features, and the leaves show the outcomes.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：决策树通过将数据分支来做出决策。每个分支代表一个基于特征的规则，而叶子节点显示结果。'
- en: '**Rule-Based Models**: These models use simple rules to explain their decisions.
    Each rule outlines conditions that lead to an outcome.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于规则的模型**：这些模型使用简单的规则来解释其决策。每个规则概述了导致结果的条件。'
- en: Feature Visualizations
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特征可视化
- en: This technique uses visual tools to show how different features affect AI decisions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术使用可视化工具显示不同特征如何影响人工智能决策。
- en: '**Saliency Maps**: Saliency maps highlight important areas in an image that
    affect the AI''s prediction.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显著性图**：显著性图突出显示图像中影响人工智能预测的重要区域。'
- en: '**Activation Maps**: Activation maps display which parts of a neural network
    are active during decision-making.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活图**：激活图展示了在决策过程中神经网络的哪些部分是活跃的。'
- en: Using LIME for XAI
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LIME进行**可解释人工智能**
- en: We’ll see how we can use LIME to explain a model’s decisions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨如何使用`LIME`来解释模型的决策。
- en: The code uses the LIME library. It explains predictions from a Random Forest
    model. This example uses the Iris dataset.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用`LIME`库。它解释了随机森林模型的预测。这个示例使用了鸢尾花数据集。
- en: 'First ensure that the library is installed:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先确保库已经安装：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then try the following code.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后尝试以下代码。
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![output](../Images/f98315bb4ce44985a556c5f97a2bbc41.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![output](../Images/f98315bb4ce44985a556c5f97a2bbc41.png)'
- en: 'The output has three parts:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出分为三个部分：
- en: '**Prediction Probabilities**: It refers to the probabilities assigned by the
    model to each class for a given input instance. These probabilities show the model''s
    confidence. They reflect the likelihood of each possible outcome.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预测概率**：指的是模型为给定输入实例分配给每个类别的概率。这些概率显示了模型的信心。它们反映了每个可能结果的可能性。'
- en: '**Feature Importances**: This component shows the importance of each feature
    in the local model. It tells how much each feature influenced the prediction for
    that specific instance.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征重要性**：该组件显示了局部模型中每个特征的重要性。它表明每个特征在特定实例的预测中影响了多少。'
- en: '**Local Prediction Explanation**: This part of the output shows how the model
    made its prediction for a specific instance. It breaks down which features were
    important and how they affected the outcome.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**局部预测解释**：输出的这一部分展示了模型如何为特定实例做出预测。它分解了哪些特征是重要的以及它们如何影响结果。'
- en: Application Domains of XAI
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XAI的应用领域
- en: Healthcare
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 医疗保健
- en: AI systems greatly improve diagnostic accuracy by analyzing medical images and
    patient data. They can identify patterns and anomalies in the images. However,
    their true value comes with Explainable AI (XAI). XAI clarifies how AI systems
    make their diagnostic decisions. This transparency helps doctors understand why
    the AI has made certain conclusions. XAI also explains the reasons behind each
    treatment suggestion. This helps doctors design treatment plans.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统通过分析医学影像和患者数据显著提高了诊断准确性。它们可以识别图像中的模式和异常。然而，它们的真正价值在于**可解释人工智能**（XAI）。XAI澄清了人工智能系统如何做出诊断决策。这种透明性帮助医生理解人工智能为何做出某些结论。XAI还解释了每个治疗建议背后的原因。这有助于医生设计治疗计划。
- en: Finance
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 金融
- en: In finance, Explainable AI is used for credit scoring and fraud detection. For
    credit scoring, XAI explains how credit scores are calculated. It shows which
    factors affect a person’s creditworthiness. This helps consumers understand their
    scores and ensures fairness from financial institutions. In fraud detection, XAI
    explains why transactions are flagged. It shows the anomalies detected, helping
    investigators spot and confirm potential fraud.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，**可解释人工智能**用于信用评分和欺诈检测。在信用评分方面，XAI解释了信用评分的计算方式。它显示了哪些因素影响一个人的信用worthiness。这有助于消费者了解他们的评分，并确保金融机构的公平性。在欺诈检测中，XAI解释了为什么交易被标记。它显示了检测到的异常，帮助调查人员发现并确认潜在的欺诈行为。
- en: Law
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 法律
- en: In the legal field, Explainable AI helps make AI decisions clear and understandable.
    It explains how AI reaches conclusions in areas like predicting crime or determining
    case outcomes. This transparency helps lawyers and judges see how AI recommendations
    are made. It also ensures that AI tools used in legal processes are fair and unbiased.
    This promotes trust and accountability in legal decisions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在法律领域，**可解释人工智能**帮助使人工智能决策变得清晰和易于理解。它解释了人工智能在预测犯罪或确定案件结果等领域如何得出结论。这种透明性帮助律师和法官了解人工智能推荐的生成过程。它还确保法律过程中使用的人工智能工具公平且无偏见。这促进了法律决策中的信任和责任感。
- en: Autonomous Vehicles
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自主车辆
- en: In autonomous driving, Explainable AI (XAI) is important for safety and regulations.
    XAI provides real-time explanations of how the vehicle makes decisions. This helps
    users understand and trust the actions of the system. Developers can use XAI to
    improve the performance of the system. XAI also supports regulatory approval by
    detailing how driving decisions are made, ensuring the technology meets safety
    standards for public roads.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在自动驾驶中，解释性人工智能（XAI）对安全性和法规非常重要。XAI提供实时解释，说明车辆如何做出决策。这有助于用户理解和信任系统的行动。开发者可以利用XAI来提高系统的性能。XAI还通过详细说明驾驶决策的制定过程来支持监管批准，确保技术符合公共道路的安全标准。
- en: Challenges in XAI
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XAI中的挑战
- en: '**Complex Models**: Some AI models are very complex. This makes them hard to
    explain.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**复杂模型**：一些AI模型非常复杂。这使得它们很难解释。'
- en: '**Accuracy vs. Explainability**: More accurate models use complex algorithms.
    There is often a trade-off between how well a model performs and how easy it is
    to explain.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准确性与解释性**：更准确的模型使用复杂的算法。模型的性能和解释的易用性之间往往存在权衡。'
- en: '**Lack of Standards**: There is no single method for Explainable AI. Different
    industries applications need different approaches.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**缺乏标准**：没有一种单一的方法来解释AI。不同的行业应用需要不同的方法。'
- en: '**Computational Cost**: Detailed explanations require additional resources.
    This can make the process slow and costly.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算成本**：详细的解释需要额外的资源。这可能使过程变得缓慢和昂贵。'
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Explainable AI is a crucial field that addresses the need for transparency in
    AI decision-making processes. It offers various techniques and methods to make
    complex AI models more interpretable and understandable. As AI continues to evolve,
    the development and implementation of XAI will play a vital role in building trust,
    ensuring fairness, and promoting the responsible use of AI across different sectors.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 解释性人工智能是一个关键领域，解决了AI决策过程中的透明性需求。它提供了各种技术和方法，使复杂的AI模型更具可解释性和理解性。随着AI的不断发展，XAI的开发和实施将在建立信任、确保公平性以及推动不同领域AI的负责任使用中发挥重要作用。
- en: '**[Jayita Gulati](https://www.linkedin.com/in/jayitagulati1998/)** is a machine
    learning enthusiast and technical writer driven by her passion for building machine
    learning models. She holds a Master''s degree in Computer Science from the University
    of Liverpool.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Jayita Gulati](https://www.linkedin.com/in/jayitagulati1998/)** 是一位机器学习爱好者和技术作家，致力于构建机器学习模型。她拥有利物浦大学计算机科学硕士学位。'
- en: More On This Topic
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用最先进的深度学习进行解释性预测和即时预测](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Explaining Explainable AI for Conversations](https://www.kdnuggets.com/2022/10/explaining-explainable-ai-conversations.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为对话解释解释性人工智能](https://www.kdnuggets.com/2022/10/explaining-explainable-ai-conversations.html)'
- en: '[Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解释性人工智能：揭示模型决策的10个Python库](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弥合人类理解与机器学习之间的差距：…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
- en: '[Introduction to Clustering in Python with PyCaret](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyCaret在Python中进行聚类的介绍](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
- en: '[Essential Math for Data Science: Visual Introduction to Singular…](https://www.kdnuggets.com/2022/06/essential-math-data-science-visual-introduction-singular-value-decomposition.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的基础数学：奇异值分解的可视化介绍…](https://www.kdnuggets.com/2022/06/essential-math-data-science-visual-introduction-singular-value-decomposition.html)'
