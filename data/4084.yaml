- en: Parallel Processing Large File in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的大文件并行处理
- en: 原文：[https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)
- en: '![Parallel Processing Large File in Python](../Images/644d2d1ea41ea4a38f2569081bef10d5.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Python中的大文件并行处理](../Images/644d2d1ea41ea4a38f2569081bef10d5.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: For parallel processing, we divide our task into sub-units. It increases the
    number of jobs processed by the program and reduces overall processing time.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于并行处理，我们将任务划分为子单元。这增加了程序处理的作业数量，并减少了总体处理时间。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的IT组织'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: For example, if you are working with a large CSV file and you want to modify
    a single column. We will feed the data as an array to the function, and it will
    parallel process multiple values at once based on the number of available  **workers**.
    These workers are based on the number of cores within your processor.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你正在处理一个大型CSV文件，并且想要修改单列。我们会将数据以数组的形式传递给函数，函数会根据可用的**工作者**的数量同时并行处理多个值。这些工作者的数量基于你处理器中的核心数。
- en: '**Note:** using parallel processing on a smaller dataset will not improve processing
    time.'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 在较小的数据集上使用并行处理不会提高处理速度。'
- en: In this blog, we will learn how to reduce processing time on large files using
    **multiprocessing**, **joblib**, and **tqdm** Python packages. It is a simple
    tutorial that can apply to any file, database, image, video, and audio.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将学习如何使用**multiprocessing**、**joblib**和**tqdm** Python包来减少大型文件的处理时间。这是一个简单的教程，适用于任何文件、数据库、图像、视频和音频。
- en: '**Note:** we are using the Kaggle notebook for the experiments. The processing
    time can vary from machine to machine.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 我们使用的是Kaggle笔记本进行实验。处理时间可能因机器而异。'
- en: Getting Started
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: We will be using the [US Accidents (2016 - 2021)](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)
    dataset from Kaggle which consists of 2.8 million records and 47 columns.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自Kaggle的[美国事故数据集（2016 - 2021）](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)，该数据集包含280万条记录和47列。
- en: We will import `multiprocessing`, `joblib`, and `tqdm` for **parallel processing**,
    `pandas` for **data ingestions**, and `re`, `nltk`, and `string` for **text processing**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入`multiprocessing`、`joblib`和`tqdm`用于**并行处理**，`pandas`用于**数据引入**，以及`re`、`nltk`和`string`用于**文本处理**。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Before we jump right in, let's set `n_workers` by doubling `cpu_count()`. As
    you can see, we have 8 workers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们将`n_workers`设置为`cpu_count()`的两倍。如你所见，我们有8个工作者。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the next step, we will ingest large CSV files using the **pandas** `read_csv`
    function. Then, print out the shape of the dataframe, the name of the columns,
    and the processing time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们将使用**pandas**的`read_csv`函数引入大型CSV文件。然后，打印出数据框的形状、列名和处理时间。
- en: '**Note:** Jupyter’s magic function `%%time` can display **CPU times** and **wall
    time** at the end of the process.'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** Jupyter的魔法函数`%%time`可以在处理结束时显示**CPU时间**和**墙钟时间**。'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Output**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Cleaning the Text
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 清理文本
- en: The `clean_text` is a straightforward function for processing and cleaning the
    text. We will get English **stopwords** using `nltk.copus` the use it to filter
    out stop words from the text line. After that, we will remove special characters
    and extra spaces from the sentence. It will be the baseline function to determine
    processing time for **serial**, **parallel**, and **batch** processing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`clean_text`是一个简单的文本处理和清理函数。我们将使用`nltk.corpus`获取英语**stopwords**，并用它来过滤文本中的停用词。之后，我们将从句子中移除特殊字符和多余的空格。这将成为确定**serial**、**parallel**和**batch**处理时间的基准函数。'
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Serial Processing
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 串行处理
- en: For serial processing, we can use the pandas `.apply()` function, but if you
    want to see the progress bar, you need to activate **tqdm** for **pandas** and
    then use the `.progress_apply()` function.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于串行处理，我们可以使用pandas的`.apply()`函数，但如果你想查看进度条，你需要激活**tqdm**以支持**pandas**，然后使用`.progress_apply()`函数。
- en: We are going to process the 2.8 million records and save the result back to
    the “Description” column column.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理280万条记录，并将结果保存回“Description”列。
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Output**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: It took 9 minutes and 5 seconds for the **high-end** processor to serial process
    2.8 million rows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 高端处理器处理280万行数据的串行处理时间为9分钟5秒。
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Multiprocessing
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多进程
- en: There are various ways to parallel process the file, and we are going to learn
    about all of them. The `multiprocessing` is a built-in python package that is
    commonly used for parallel processing large files.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以并行处理文件，我们将学习所有这些方法。`multiprocessing`是一个内置的Python包，通常用于并行处理大文件。
- en: We will create a multiprocessing **Pool** with **8 workers** and use the **map**
    function to initiate the process. To display progress bars, we are using **tqdm**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个包含**8个工作线程**的多进程**Pool**，并使用**map**函数来启动处理。为了显示进度条，我们使用**tqdm**。
- en: The map function consists of two sections. The first requires the function,
    and the second requires an argument or list of arguments.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: map函数由两个部分组成。第一部分需要函数，第二部分需要一个参数或参数列表。
- en: Learn more by reading [documentation](https://docs.python.org/3/library/multiprocessing.html).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多信息，请阅读[文档](https://docs.python.org/3/library/multiprocessing.html)。
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Output**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: We have improved our processing time by almost **3X**. The processing time dropped
    from **9 minutes 5 seconds** to **3 minutes 51 seconds**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理时间提高了近**3倍**。处理时间从**9分钟5秒**减少到**3分钟51秒**。
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Parallel
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行
- en: We will now learn about another Python package to perform parallel processing.
    In this section, we will use joblib’s **Parallel** and **delayed** to replicate
    the **map** function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将学习另一个Python包来执行并行处理。在这一部分，我们将使用joblib的**Parallel**和**delayed**来模拟**map**函数。
- en: 'The Parallel requires two arguments: n_jobs = 8 and backend = multiprocessing.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parallel需要两个参数：n_jobs = 8和backend = multiprocessing。
- en: Then, we will add **clean_text**  to the **delayed** function.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们将把**clean_text**添加到**delayed**函数中。
- en: Create a loop to feed a single value at a time.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个循环一次处理一个值。
- en: The process below is quite generic, and you can modify your function and array
    according to your needs. I have used it to process thousands of audio and video
    files without any issue.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的过程相当通用，你可以根据需要修改你的函数和数组。我已经用它处理了成千上万的音频和视频文件，没有遇到任何问题。
- en: '**Recommended:** add exception handling using `try:` and `except:`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐：** 使用`try:`和`except:`添加异常处理'
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Add the “Description” column to `text_parallel_clean()`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将“Description”列添加到`text_parallel_clean()`中。
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Output**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: It took our function 13 seconds more than multiprocessing the **Pool.** Even
    then, **Parallel** is 4 minutes and 59 seconds faster than **serial** processing.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的函数比使用**Pool**的多进程慢了13秒。即便如此，**Parallel**比**serial**处理快了4分钟59秒。
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Parallel Batch Processing
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行批处理
- en: There is a better way to process large files by splitting them into batches
    and processing them parallel. Let’s start by creating a batch function that will
    run a `clean_function` on a single batch of values.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种更好的方法来处理大文件，即将其拆分为批次并进行并行处理。让我们从创建一个批处理函数开始，该函数将在一批值上运行`clean_function`。
- en: Batch Processing Function
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批处理函数
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Splitting the File into Batches
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将文件拆分为批次
- en: The function below will split the file into multiple batches based on the number
    of workers. In our case, we get 8 batches.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的函数将根据工作线程的数量将文件拆分为多个批次。在我们的案例中，我们得到8个批次。
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Running Parallel Batch Processing
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行并行批处理
- en: Finally, we will use **Parallel** and **delayed** to process batches.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用**Parallel**和**delayed**来处理批次。
- en: '**Note:** To get a single array of values, we have to run list comprehension
    as shown below.'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 要获取单个值数组，我们必须运行列表推导式，如下所示。'
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Output**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: We have improved the processing time. This technique is famous for processing
    complex data and training deep learning models.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经改进了处理时间。这种技术因处理复杂数据和训练深度学习模型而闻名。
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: tqdm Concurrent
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: tqdm并发
- en: tqdm takes multiprocessing to the next level. It is simple and powerful. I will
    recommend it to every data scientist.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: tqdm将多进程处理提升到了一个新的水平。它简单且强大。我会向每位数据科学家推荐它。
- en: Check out the [documentation](https://tqdm.github.io/) to learn more about multiprocessing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[文档](https://tqdm.github.io/)以了解更多关于多进程的信息。
- en: 'The `process_map` requires:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`process_map` 需要：'
- en: Function name
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数名称
- en: Dataframe column
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据框列
- en: max_workers
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: max_workers
- en: chucksize is similar to batch size. We will calculate the batch size using the
    number of workers or you can add the number based on your preference.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: chucksize类似于批大小。我们将使用工作数量来计算批大小，或者你可以根据个人喜好添加数量。
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Output**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出**'
- en: With a single line of code, we get the best result.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 只需一行代码，我们就能获得最佳结果。
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Conclusion
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You need to find a balance and select the technique that works best for your
    case. It can be serial processing, parallel, or batch processing. The parallel
    processing can backfire if you are working with a smaller, less complex dataset.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要找到一个平衡点，选择最适合你情况的技术。可以是串行处理、并行处理或批处理。如果你处理的是较小且复杂性较低的数据集，并行处理可能会适得其反。
- en: In this mini-tutorial, we have learned about various Python packages and techniques
    that allow us to parallel process our data functions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个迷你教程中，我们学习了各种Python包和技术，这些技术允许我们并行处理数据函数。
- en: If you are only working with a tabular dataset and want to improve your processing
    performance, then I will suggest you try [Dask](https://www.dask.org/), [datatable](https://github.com/h2oai/datatable),
    and [RAPIDS](https://rapids.ai/)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仅处理表格数据集并希望提升处理性能，我建议你尝试[Dask](https://www.dask.org/)、[datatable](https://github.com/h2oai/datatable)和[RAPIDS](https://rapids.ai/)
- en: Reference
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考
- en: '[Parallel batch processing in Python | by Dennis Bakhuis | Towards Data Science](https://towardsdatascience.com/parallel-batch-processing-in-python-8dcce607d226)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python中的并行批处理 | Dennis Bakhuis | Towards Data Science](https://towardsdatascience.com/parallel-batch-processing-in-python-8dcce607d226)'
- en: '[Parallel processing large file in Python · Nurda Bolatov](https://nurdabolatov.com/parallel-processing-large-file-in-python)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python中大文件的并行处理 · Nurda Bolatov](https://nurdabolatov.com/parallel-processing-large-file-in-python)'
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证的数据科学专业人士，热爱构建机器学习模型。目前，他专注于内容创作，并撰写有关机器学习和数据科学技术的技术博客。Abid拥有技术管理硕士学位和电信工程学士学位。他的愿景是利用图神经网络为有心理疾病困扰的学生开发AI产品。'
- en: More On This Topic
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主题更多
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，7月20日：机器学习算法解释](https://www.kdnuggets.com/2022/n29.html)'
- en: '[Parallel Processing in Prompt Engineering: The Skeleton-of-Thought…](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提示工程中的并行处理：思维骨架技术](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)'
- en: '[Monitor Your File System With Python’s Watchdog](https://www.kdnuggets.com/monitor-your-file-system-with-pythons-watchdog)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用Python的Watchdog监控你的文件系统](https://www.kdnuggets.com/monitor-your-file-system-with-pythons-watchdog)'
- en: '[Python String Processing Cheatsheet](https://www.kdnuggets.com/2020/01/python-string-processing-primer.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python字符串处理备忘单](https://www.kdnuggets.com/2020/01/python-string-processing-primer.html)'
- en: '[25 Free Books to Master SQL, Python, Data Science, Machine…](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握SQL、Python、数据科学、机器学习等的25本免费书籍](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级开源大型语言模型](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
- en: '![](../Images/eb105b2b614c4a6165d83fbc2b9711a1.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb105b2b614c4a6165d83fbc2b9711a1.png)'
- en: '[](/news/subscribe.html)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/news/subscribe.html)'
- en: '[Get the FREE ebook ''The Great Big Natural Language Processing Primer'' and
    ''The Complete Collection of Data Science Cheat Sheets'' along with the leading
    newsletter on Data Science, Machine Learning, AI & Analytics straight to your
    inbox.](/news/subscribe.html)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[获取免费的电子书《伟大的自然语言处理入门》和《数据科学备忘单的完整合集》，以及有关数据科学、机器学习、人工智能和分析的领先新闻通讯，直接送到你的收件箱。](/news/subscribe.html)'
- en: By subscribing you accept KDnuggets [Privacy Policy](https://www.kdnuggets.com/news/privacy-policy.html)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅即表示你接受 KDnuggets 的 [隐私政策](https://www.kdnuggets.com/news/privacy-policy.html)
- en: '* * *'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[<= Previous post](https://www.kdnuggets.com/2023/02/data-cleaning-python-cheat-sheet.html)[Next
    post =>](https://www.kdnuggets.com/2023/02/essential-ab-testing-course-data-science.html)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[<= 上一篇文章](https://www.kdnuggets.com/2023/02/data-cleaning-python-cheat-sheet.html)[下一篇文章
    =>](https://www.kdnuggets.com/2023/02/essential-ab-testing-course-data-science.html)'
- en: '[Latest Posts](/news/index.html)'
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[最新文章](/news/index.html)'
- en: '[7 Free Cloud IDE for Data Science That You Are Missing Out](https://www.kdnuggets.com/7-free-cloud-ide-for-data-science-that-you-are-missing-out)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7 个你可能错过的免费的数据科学云 IDE](https://www.kdnuggets.com/7-free-cloud-ide-for-data-science-that-you-are-missing-out)'
- en: '[Bootstrapping Your Data Science Career: A Guide to Self-Learning Pathways](https://www.kdnuggets.com/bootstrapping-your-data-science-career-a-guide-to-self-learning-pathways)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[启动你的数据科学职业生涯：自学路径指南](https://www.kdnuggets.com/bootstrapping-your-data-science-career-a-guide-to-self-learning-pathways)'
- en: '[Developing End-to-End Data Science Pipelines with Data Ingestion, Processing,
    and Visualization](https://www.kdnuggets.com/developing-end-to-end-data-science-pipelines-with-data-ingestion-processing-and-visualization)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开发端到端的数据科学管道，包括数据摄取、处理和可视化](https://www.kdnuggets.com/developing-end-to-end-data-science-pipelines-with-data-ingestion-processing-and-visualization)'
- en: '[How To Trace Memory Allocation in Python](https://www.kdnuggets.com/how-to-trace-memory-allocation-in-python)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何跟踪 Python 中的内存分配](https://www.kdnuggets.com/how-to-trace-memory-allocation-in-python)'
- en: '[How to Import Data in R](https://www.kdnuggets.com/how-to-import-data-in-r)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在 R 中导入数据](https://www.kdnuggets.com/how-to-import-data-in-r)'
- en: '[Top 5 Machine Learning APIs Practitioners Should Know](https://www.kdnuggets.com/top-5-machine-learning-apis-practitioners-should-know)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[值得关注的 5 个机器学习 API](https://www.kdnuggets.com/top-5-machine-learning-apis-practitioners-should-know)'
- en: '|'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Top Posts
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 热门文章
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[5 Hidden Gem Python Libraries for Data Science](https://www.kdnuggets.com/5-hidden-gem-python-libraries-for-data-science)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个数据科学中隐藏的宝石 Python 库](https://www.kdnuggets.com/5-hidden-gem-python-libraries-for-data-science)'
- en: '[7 Steps to Mastering Math for Data Science](https://www.kdnuggets.com/7-steps-to-mastering-math-for-data-science)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据科学所需的 7 个数学步骤](https://www.kdnuggets.com/7-steps-to-mastering-math-for-data-science)'
- en: '[4 Entry-Level Certificates from Microsoft to Land In-Demand Jobs](https://www.kdnuggets.com/4-entry-level-certificates-from-microsoft-to-land-in-demand-jobs)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微软的 4 个入门级证书帮助你找到热门工作](https://www.kdnuggets.com/4-entry-level-certificates-from-microsoft-to-land-in-demand-jobs)'
- en: '[How to Manage Categorical Data Effectively with Pandas](https://www.kdnuggets.com/how-to-manage-categorical-data-effectively-with-pandas)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Pandas 有效管理分类数据](https://www.kdnuggets.com/how-to-manage-categorical-data-effectively-with-pandas)'
- en: '[10 Built-In Python Modules Every Data Engineer Should Know](https://www.kdnuggets.com/10-built-in-python-modules-every-data-engineer-should-know)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据工程师都应该知道的 10 个内置 Python 模块](https://www.kdnuggets.com/10-built-in-python-modules-every-data-engineer-should-know)'
- en: '[Top 5 Machine Learning APIs Practitioners Should Know](https://www.kdnuggets.com/top-5-machine-learning-apis-practitioners-should-know)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[值得关注的 5 个机器学习 API](https://www.kdnuggets.com/top-5-machine-learning-apis-practitioners-should-know)'
- en: '[Using FastAPI for Building ML-Powered Web Apps](https://www.kdnuggets.com/using-fastapi-for-building-ml-powered-web-apps)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 FastAPI 构建 ML 驱动的 Web 应用](https://www.kdnuggets.com/using-fastapi-for-building-ml-powered-web-apps)'
- en: '[I Took Udacity’s Free A/B Testing Course by Google: Here’s What I Learned](https://www.kdnuggets.com/i-took-udacitys-free-a-b-testing-course-by-google-heres-what-i-learned)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我参加了 Udacity 的 Google 免费 A/B 测试课程：我学到了什么](https://www.kdnuggets.com/i-took-udacitys-free-a-b-testing-course-by-google-heres-what-i-learned)'
- en: '[Project Ideas to Master Data Engineering](https://www.kdnuggets.com/project-ideas-to-master-data-engineering)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据工程的项目想法](https://www.kdnuggets.com/project-ideas-to-master-data-engineering)'
- en: '[Using FLUX.1 Locally](https://www.kdnuggets.com/using-flux-1-locally)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 FLUX.1](https://www.kdnuggets.com/using-flux-1-locally)'
- en: '* * *'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: © 2024 [Guiding Tech Media](https://www.guidingtechmedia.com/)   |   [About](/about/index.html)
      |   [Contact](/contact.html)   |   [Advertise](https://mailchi.mp/kdnuggets/media-kit)
    |   [Privacy](/news/privacy-policy.html)   |   [Terms of Service](/terms-of-service.html)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: © 2024 [Guiding Tech Media](https://www.guidingtechmedia.com/)   |   [关于](/about/index.html)
      |   [联系](/contact.html)   |   [广告合作](https://mailchi.mp/kdnuggets/media-kit)
    |   [隐私政策](/news/privacy-policy.html)   |   [服务条款](/terms-of-service.html)
- en: Published on February 21, 2023 by Abid Ali Awan
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 发表时间：2023年2月21日，作者：Abid Ali Awan
