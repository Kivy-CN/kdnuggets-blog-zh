- en: Trust in AI is Priceless
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/08/trust-ai-priceless.html](https://www.kdnuggets.com/2022/08/trust-ai-priceless.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Trust in AI is Priceless](../Images/73c95f144292631c4932253a6248fa51.png)'
  prefs: []
  type: TYPE_IMG
- en: As the co-founder and CTO of an IDE platform for data-centric AI ([Kili Technology](https://kili-technology.com/)),
    I see too many machine learning models failing to deliver. Sadly, it’s often due
    to a lack of focus on data quality.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Quick Catch-up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 10 years ago, during the model-centric AI era, AI peeps like us struggled with
    the model. We lacked infrastructure, tools, toolkits, or frameworks to help us
    create and train ML models.
  prefs: []
  type: TYPE_NORMAL
- en: Today, life-saving packages such as Tensorflow and PyTorch exist. We now have
    to focus on data, from its finding and sorting to its annotation.
  prefs: []
  type: TYPE_NORMAL
- en: But it’s worth it. On many occasions, improving the data quality will have a
    more significant impact on its performance than any tuning of hyperparameters
    or neural network architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'You only need 2 things in [data-centric AI](https://kili-technology.com/blog/data-centric-ai-manifesto):'
  prefs: []
  type: TYPE_NORMAL
- en: Quality data, which consists of clean and diverse data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sufficient volume of training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bigger is Not Always Better
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Big volumes of data are the key to many deep learning successes. But big volumes
    of data come with challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: it is cumbersome and expensive in terms of hardware and human computing resources;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'it poses problems: bias, technical debt and compatibility with the new foundation
    model paradigm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you focus on labeling productivity and apply pre-annotation to documents
    too early, it encourages annotators to include errors from your model in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to minimize bias, there’s no free lunch. Here’s how to proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with rules-based automation if you have some a priori knowledge of the
    task. For instance, regular expressions and dictionaries are useful for NLP.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then go manual labeling. This is where you actually create value for your model
    because you annotate the hard part made of non-trivial examples and edge cases.
    Quality management is vital for this phase as it requires a lot of synchronization
    across the labelers to be consistent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, model pre-labeling to go [from a good to a great dataset](https://kili-technology.com/blog/create-dataset-for-machine-learning).
    It should only be used at the end; otherwise, you will create biases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Trust in AI is Priceless](../Images/f4348b47a78fd4f88e91c6afff26d2fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Technical debt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In software development, doubling the amount of code means doubling many things:'
  prefs: []
  type: TYPE_NORMAL
- en: the number of behaviors our system creates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of unit tests required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For AI, code = data. Doubling the amount of data means doubling:'
  prefs: []
  type: TYPE_NORMAL
- en: the number of behaviors our ML system creates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of ML unit tests required
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the technical debt otherwise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not compatible with foundation models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today, we have giant foundation models (GPT-3, BERT, or DALL-E 2) that have
    been pre-trained on all text or images on the Internet; they understand language
    rules. Since your model needs a huge generalization capability, it needs very
    little data. As a result, every data will have a stronger impact. Thus instead
    of annotating a large volume of data with potential errors, you need to annotate
    less and be more precise about the examples you feed your model, as bad data can
    easily influence them.
  prefs: []
  type: TYPE_NORMAL
- en: Why is Getting Quality Data Challenging?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To reduce the amount of data needed by our ML models, we must improve its quality.
    However, it is challenging since we’ve to address these 2 points simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[data representativeness](https://kili-technology.com/blog/a-brief-introduction-to-imbalanced-datasets)
    (Is the data unbiased? Does the data cover the edge cases?)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: labeling consistency (do the labelers annotate the same way? Have they understood
    the task?).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets are not easy to debug. It is not always easy to give a yes or no answer.
    For instance, in an image classification task, is an image of a house's window
    an image of a house?
  prefs: []
  type: TYPE_NORMAL
- en: The answer will depend on the context, on the task, on the usage, etc. This
    is true for non-expert tasks. This is also true for expert tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Rheumatoid arthritis and malaria have been treated with chloroquine for decades.
    -> treats the relation between chloroquine and malaria.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among 56 subjects reporting to a clinic with symptoms of malaria, 53 (95%) had
    ordinarily effective levels of chloroquine in blood. -> DOES NOT treat the relation
    between chloroquine and malaria.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to Manage Quality at Scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At Kili Technology, we’re committed to sharing [best practices](https://resources.kili-technology.com/nurture/directory-collaboration-project-management)
    with our users willing to manage quality and scale.
  prefs: []
  type: TYPE_NORMAL
- en: Label consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some tips:'
  prefs: []
  type: TYPE_NORMAL
- en: Iterate in small steps on the annotation. Here’s the specific process for [building
    quality datasets](https://kili-technology.com/blog/building-a-training-dataset-ml).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Just so you know: each iteration should last 3 days tops.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The engineer responsible for building the model annotates 50 to 100 examples
    by hand, giving you an idea of the different classes that exist.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write solid definitions and concepts of classes you aim for your model to identify.
    This should include instructions on how to handle specific edge cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iteratively get larger batches of documents annotated (100 or 200 at a time)
    by external partners or others within the company.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iterate to debug at any step: [instructions](https://kili-technology.com/blog/my-state-of-the-art-machine-learning-model-does-not-reach-its-accuracy-promise-what-can-i-do#123),
    ontology, [consensus](https://docs.kili-technology.com/docs/consensus-overview)
    coverage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a tool design to avoid wrong annotation gesture by design.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prevent bad annotations. For instance, in relation extraction, prohibit relationships
    in the UX that don't make sense.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize the number and complexity of annotation actions. For example, on some
    tasks, it is better to draw the object first and then select the class, and on
    other tasks, the opposite is true.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Train your people: labeling needs proper training to get labelers to ramp up
    fast.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect possible errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement rule-based quality checks from the beginning of the project. e.g.,
    isn't the number of annotated vertebrae greater than the number of human vertebrae?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a model to compute the likelihood of your labels and prioritize the review
    at the end of your project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use metrics, such as the consensus at asset and annotators levels to debug your
    labeling process and prioritize your review.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Set a pyramidal review system with layers: pre-annotation models, then labelers,
    then reviewers, and ML engineers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Trust in AI is Priceless](../Images/f69e08d302b3764cb25f316102ac5a37.png)'
  prefs: []
  type: TYPE_IMG
- en: Data representativeness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Two important points here:'
  prefs: []
  type: TYPE_NORMAL
- en: Have unbiased data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have sufficiently rich data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our world is full of biases that need to be removed from the models. For example,
    if I use the embeddings of GPT-2 to build a sentiment analysis model on financial
    news, the names of the companies alone are already tinged with a sentiment: Volkswagen
    is negative because of the scandal of the last few years, over-represented in
    the GPT-2 training data. To correct this, here are some ideas:'
  prefs: []
  type: TYPE_NORMAL
- en: replace sensitive named entities (companies) with placeholders before training
    a language model;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: generate counterfactual data to balance the feelings related to company names;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: orthogonalize the embedding space to remove the bias effect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our world is full of [edge cases](https://kili-technology.com/blog/guide-to-human-in-the-loop-machine-learning#104).
    For example, a chair flying on the highway in self-driving cars images. To build
    a diversified dataset, you can reuse the boosting method, well known in ML, to
    the data. From a reservoir of data candidates:'
  prefs: []
  type: TYPE_NORMAL
- en: Train an initial model and predict on the validation set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use another pre-trained model to extract embeddings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each misclassified validation image, retrieve the nearest neighbors using
    the embeddings. Add these nearest neighbor images to the training set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrain the model with the added images and predict on the validation set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat until you are good.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until now, the ML community has focused on data quantity. Now, we need quality.
    There are many other tips to get this quality at scale.
  prefs: []
  type: TYPE_NORMAL
- en: P.S. [Tweet](http://@edarchimbaud) me your feedback!
  prefs: []
  type: TYPE_NORMAL
- en: '**[Edouard d''Archimbaud](https://www.linkedin.com/in/edouard-d-archimbaud/)**
    ([**@edarchimbaud**](https://twitter.com/edarchimbaud)) is a ML engineer, CTO
    and cofounder of [Kili](https://kili-technology.com/), a leading training data
    platform for enterprise AI. He is passionate about **Data-centric AI**, the new
    paradigm for successful AI.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[In Data We Trust: Data Centric AI](https://www.kdnuggets.com/2022/10/data-trust-data-centric-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sky''s the Limit: Learn how JetBlue uses Monte Carlo and Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Quest for Model Confidence: Can You Trust a Black Box?](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
