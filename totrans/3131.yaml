- en: Ten Machine Learning Algorithms You Should Know to Become a Data Scientist
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html](https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](2018/04/10-machine-learning-algorithms-data-scientist.html/2#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By Muktabh Mayank, [ParallelDots](https://paralleldots.com/)**.'
  prefs: []
  type: TYPE_NORMAL
- en: '![machine learning algorithms](../Images/da0e3450c1e1433e14e7a1b2c34d159e.png)'
  prefs: []
  type: TYPE_IMG
- en: Machine Learning Practitioners have different personalities. While some of them
    are “I am an expert in X and X can train on any type of data”, where X = some
    algorithm, some others are “Right tool for the right job people”. A lot of them
    also subscribe to “Jack of all trades. Master of one” strategy, where they have
    one area of deep expertise and know slightly about different fields of Machine
    Learning. That said, no one can deny the fact that as practicing Data Scientists,
    we will have to know basics of some common [machine learning algorithms](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html),
    which would help us engage with a new-domain problem we come across. This is a
    whirlwind tour of common machine learning algorithms and quick resources about
    them which can help you get started on them.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Principal Component Analysis(PCA)/SVD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PCA is an unsupervised method to understand global properties of a dataset consisting
    of vectors. Covariance Matrix of data points is analyzed here to understand what
    dimensions(mostly)/ data points (sometimes) are more important (ie have high variance
    amongst themselves, but low covariance with others). One way to think of top PCs
    of a matrix is to think of its eigenvectors with highest eigenvalues. SVD is essentially
    a way to calculate ordered components too, but you don’t need to get the covariance
    matrix of points to get it.
  prefs: []
  type: TYPE_NORMAL
- en: '![machine learning algorithms](../Images/d799bb2104583027c8fffea1197d84e1.png)'
  prefs: []
  type: TYPE_IMG
- en: This Algorithm helps one fight curse of dimensionality by getting datapoints
    with reduced dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Libraries:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introductory Tutorial:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org/pdf/1404.1100.pdf](https://arxiv.org/pdf/1404.1100.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 2a. Least Squares and Polynomial Fitting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember your Numerical Analysis code in college, where you used to fit lines
    and curves to points to get an equation. You can use them to fit curves in Machine
    Learning for very small datasets with low dimensions. (For large data or datasets
    with many dimensions, you might just end up terribly overfitting, so don’t bother).
    OLS has a closed form solution, so you don’t need to use complex optimization
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4751b805d2c61703c32e03f0fbb1e165.png)'
  prefs: []
  type: TYPE_IMG
- en: As is obvious, use this algorithm to fit simple curves / regression
  prefs: []
  type: TYPE_NORMAL
- en: 'Libraries:'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html)[https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Introductory Tutorial:'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: 2b. Constrained Linear Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Least Squares can get confused with outliers, spurious fields and noise in data.
    We thus need constraints to decrease the variance of the line we fit on a dataset.
    The right method to do it is to fit a linear regression model which will ensure
    that the weights do not misbehave. Models can have L1 norm (LASSO) or L2 (Ridge
    Regression) or both (elastic regression). Mean Squared Loss is optimized.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/727b71525e3373fc2f7d83ce4e350469.png)'
  prefs: []
  type: TYPE_IMG
- en: Use these algorithms to fit regression lines with constraints, avoiding overfitting
    and masking noise dimensions from model.
  prefs: []
  type: TYPE_NORMAL
- en: '**Libraries:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://scikit-learn.org/stable/modules/linear_model.html](http://scikit-learn.org/stable/modules/linear_model.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introductory Tutorial(s):**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=5asL5Eq2x0A](https://www.youtube.com/watch?v=5asL5Eq2x0A)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=jbwSCwoT51M](https://www.youtube.com/watch?v=jbwSCwoT51M)'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. K means Clustering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Everyone’s favorite unsupervised clustering algorithm. Given a set of data points
    in form of vectors, we can make clusters of points based on distances between
    them. It’s an Expectation Maximization algorithm that iteratively moves the centers
    of clusters and then clubs points with each cluster centers. The input the algorithm
    has taken is the number of clusters which are to be generated and the number of
    iterations in which it will try to converge clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![machine learning algorithms](../Images/351e4ae23251bd092d8c3315e482ceb1.png)'
  prefs: []
  type: TYPE_IMG
- en: As is obvious from the name, you can use this algorithm to create K clusters
    in dataset
  prefs: []
  type: TYPE_NORMAL
- en: '**Library:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introductory Tutorial(s):**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=hDmNF9JG3lo](https://www.youtube.com/watch?v=hDmNF9JG3lo)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.datascience.com/blog/k-means-clustering](https://www.datascience.com/blog/k-means-clustering)'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Logistic Regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Logistic Regression is constrained Linear Regression with a nonlinearity (sigmoid
    function is used mostly or you can use tanh too) application after weights are
    applied, hence restricting the outputs close to +/- classes (which is 1 and 0
    in case of sigmoid). Cross-Entropy Loss functions are optimized using Gradient
    Descent. A note to beginners: Logistic Regression is used for classification,
    not regression. You can also think of Logistic regression as a one layered Neural
    Network. Logistic Regression is trained using optimization methods like Gradient
    Descent or L-BFGS. NLP people will often use it with the name of Maximum Entropy
    Classifier.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a Sigmoid looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0e1fce437687ecfe4d3fb5b72127f730.png)'
  prefs: []
  type: TYPE_IMG
- en: Use LR to train simple, but very robust classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Library:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introductory Tutorial(s):**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=-la3q9d7AKQ](https://www.youtube.com/watch?v=-la3q9d7AKQ)'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. SVM (Support Vector Machines)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SVMs are linear models like Linear/ Logistic Regression, the difference is that
    they have different margin-based loss function (The derivation of Support Vectors
    is one of the most beautiful mathematical results I have seen along with eigenvalue
    calculation). You can optimize the loss function using optimization methods like
    L-BFGS or even SGD.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/076c7aab2765ed2bf0c959f351786eaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Another innovation in SVMs is the usage of kernels on data to feature engineer.
    If you have good domain insight, you can replace the good-old RBF kernel with
    smarter ones and profit.
  prefs: []
  type: TYPE_NORMAL
- en: One unique thing that SVMs can do is learn one class classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: SVMs can used to Train a classifier (even regressors)
  prefs: []
  type: TYPE_NORMAL
- en: '**Library:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Introductory Tutorial(s):**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.youtube.com/watch?v=eHsErlPJWUU](https://www.youtube.com/watch?v=eHsErlPJWUU)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** SGD based training of both Logistic Regression and SVMs are found
    in SKLearn’s [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) ,
    which I often use as it lets me check both LR and SVM with a common interface.
    You can also train it on >RAM sized datasets using mini batches.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
