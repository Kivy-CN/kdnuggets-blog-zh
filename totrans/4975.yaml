- en: 'K-Means & Other Clustering Algorithms: A Quick Intro with Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means 和其他聚类算法：使用 Python 的快速介绍
- en: 原文：[https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html](https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html](https://www.kdnuggets.com/2017/03/k-means-clustering-algorithms-intro-python.html)
- en: '**Nikos Koufos, [LearnDataSci](http://www.learndatasci.com/) Author.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nikos Koufos，[LearnDataSci](http://www.learndatasci.com/) 作者。**'
- en: Clustering is the grouping of objects together so that objects belonging in
    the same group (cluster) are more similar to each other than those in other groups
    (clusters). In this intro cluster analysis tutorial, we'll check out a few algorithms
    in Python so you can get a basic understanding of the fundamentals of clustering
    on a real dataset.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是将对象分组，使得同一组（簇）中的对象彼此之间的相似度高于其他组（簇）中的对象。在本次介绍性聚类分析教程中，我们将查看一些 Python 中的算法，以便你对实际数据集上的聚类基础知识有一个基本了解。
- en: The Dataset
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'For the clustering problem, we will use the famous *Zachary’s Karate Club*
    dataset. The story behind the data set is quite simple: There was a Karate Club
    that had an administrator “John A” and an instructor “Mr. Hi” (both pseudonyms).
    Then a conflict arose between them, causing the students (Nodes) to split into
    two groups. One that followed John and one that followed Mr. Hi.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聚类问题，我们将使用著名的 *Zachary’s Karate Club* 数据集。数据集背后的故事很简单：曾经有一个空手道俱乐部，俱乐部中有一位管理员“John
    A”和一位教练“Mr. Hi”（均为化名）。然后他们之间发生了冲突，导致学生（节点）分成了两组。一组跟随 John，另一组跟随 Mr. Hi。
- en: '![Visualization of Karate Club Clustering](../Images/f34f92e5fccc0a8debafe667480bffb6.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![空手道俱乐部聚类的可视化](../Images/f34f92e5fccc0a8debafe667480bffb6.png)'
- en: 'Source: [Wikipedia](https://en.wikipedia.org/wiki/Zachary''s_karate_club)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[维基百科](https://en.wikipedia.org/wiki/Zachary's_karate_club)
- en: Getting Started with Clustering in Python
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Python 开始进行聚类
- en: But enough with the introductory talk, let’s get to main reason you are here,
    the code itself. First of all, you need to install both [scikit-learn](http://scikit-learn.org/)
    and [networkx](https://networkx.github.io/) libraries to complete this tutorial.
    If you don’t know how, the links above should help you. Also, feel free to follow
    along by grabbing the source code for this tutorial over on [Github](https://github.com/LearnDataSci/blog-post-resources/blob/master/Karate%20Club%20Clustering/Classifiers.py).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，讲解到此为止，我们直接进入你来到这里的主要原因——代码本身。首先，你需要安装 [scikit-learn](http://scikit-learn.org/)
    和 [networkx](https://networkx.github.io/) 库来完成本教程。如果你不知道怎么做，上面的链接应该能帮到你。另外，你可以通过
    [Github](https://github.com/LearnDataSci/blog-post-resources/blob/master/Karate%20Club%20Clustering/Classifiers.py)
    获取本教程的源代码并跟随操作。
- en: 'Usually, the datasets that we want to examine are available in text form (JSON,
    Excel, simple txt file, etc.) but in our case, [networkx](https://networkx.github.io/)
    provide it for us. Also, to compare our algorithms, we want the truth about the
    members (who followed whom) which unfortunately is not provided. But with these
    two lines of code, you will be able to load the data and store the truth (from
    now on we will refer it as ground truth):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们想要检查的数据集以文本形式（JSON、Excel、简单的 txt 文件等）提供，但在我们的案例中，[networkx](https://networkx.github.io/)
    为我们提供了它。此外，为了比较我们的算法，我们希望知道成员之间的真实关系（谁跟随谁），但遗憾的是没有提供。不过，通过这两行代码，你将能够加载数据并存储真实情况（从现在起我们称之为真实数据）：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The final step of the data preprocessing, is to transform the graph into a
    matrix (desirable input for our algorithms). This is also quite simple:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理的最后一步是将图形转换为矩阵（这是我们算法所需的输入）。这也非常简单：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Before we get going with the Clustering Techniques, I would like you to get
    a visualization on our data. So, let’s compile a simple function to do that:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入聚类技术之前，我希望你能对我们的数据有一个可视化。所以，让我们编写一个简单的函数来实现这一点：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: What that function does is to simply extract the number of clusters that are
    in our result and then assign a different color to each of them (up to 10 for
    the given time is fine) before plotting them.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的作用是简单地提取结果中的聚类数量，然后为每个聚类分配不同的颜色（对于给定时间最多10个颜色即可），然后进行绘图。
- en: '![zacharys karate club cluster nodes](../Images/3f4fd1bd77a0f8eccd8114e9294a882b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![zacharys karate club cluster nodes](../Images/3f4fd1bd77a0f8eccd8114e9294a882b.png)'
- en: Clustering Algorithms
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类算法
- en: Some clustering algorithms will cluster your data quite nicely and others will
    end up failing to do so. That is one of the main reasons why clustering is such
    a difficult problem. But don’t worry, we won’t let you drown in an ocean of choices.
    We'll go through a few algorithms that are known to perform very well.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一些聚类算法会很好地对你的数据进行聚类，而另一些可能会失败。这是聚类问题如此困难的主要原因之一。但不用担心，我们不会让你在选择的海洋中迷失。我们将讨论几种已知表现非常好的算法。
- en: '**K-Means Clustering**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-均值聚类**'
- en: '![k-means clustering](../Images/2320bd58c7dced4d4b53fa875a2d2e61.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![k-means clustering](../Images/2320bd58c7dced4d4b53fa875a2d2e61.png)'
- en: 'Source: [github.com/nitoyon/tech.nitoyon.com](https://github.com/nitoyon/tech.nitoyon.com)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[github.com/nitoyon/tech.nitoyon.com](https://github.com/nitoyon/tech.nitoyon.com)
- en: 'K-means is considered by many the gold standard when it comes to clustering
    due to its simplicity and performance, and it''s the first one we''ll try out.
    When you have no idea at all what algorithm to use, K-means is usually the first
    choice. Bear in mind that K-means might under-perform sometimes due to its concept:
    spherical clusters that are separable in a way so that the mean value converges
    towards the cluster center. To simply construct and train a K-means model, use
    the follow lines:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: K-均值被许多人认为是聚类的黄金标准，因为它的简单性和性能，它是我们将尝试的第一个算法。当你完全不知道使用哪个算法时，K-均值通常是首选。请记住，K-均值有时可能表现不佳，因为它的概念是：球形聚类可分离，以便均值收敛到聚类中心。要简单地构建和训练一个
    K-均值模型，请使用以下几行：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Agglomerative Clustering**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚合聚类**'
- en: 'The main idea behind agglomerative clustering is that each node starts in its
    own cluster, and recursively merges with the pair of clusters that minimally increases
    a given linkage distance. The main advantage of agglomerative clustering (and
    hierarchical clustering in general) is that you don’t need to specify the number
    of clusters. That of course, comes with a price: performance. But, in scikit’s
    implementation, you can specify the number of clusters to assist the algorithm’s
    performance. To create and train an agglomerative model use the following code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合聚类的主要思想是每个节点从自己的聚类开始，然后递归地与增加最小链接距离的聚类对合并。聚合聚类（以及一般的层次聚类）的主要优点是你不需要指定聚类的数量。当然，这也有代价：性能。不过，在
    scikit 的实现中，你可以指定聚类的数量以帮助算法的性能。要创建和训练一个聚合模型，请使用以下代码：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Spectral**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**光谱**'
- en: 'The Spectral clustering technique applies clustering to a projection of the
    normalized Laplacian. When it comes to image clustering, spectral clustering works
    quite well. See the next few lines of Python for all the magic:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 光谱聚类技术将聚类应用于归一化拉普拉斯的投影。在图像聚类方面，光谱聚类效果非常好。请查看以下几行 Python 代码，了解所有的魔法：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Affinity Propagation**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**亲和传播**'
- en: 'Well this one is a bit different. Unlike the previous algorithms, you can see
    AF does not require the number of clusters to be determined before running the
    algorithm. AF, performs really well on several computer vision and biology problems,
    such as clustering pictures of human faces and identifying regulated transcripts:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法有些不同。与之前的算法不同，你会发现 AF 在运行算法之前不需要确定聚类的数量。AF 在处理许多计算机视觉和生物学问题上表现非常好，比如人脸图像聚类和识别调控转录本：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Metrics & Plotting
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标与绘图
- en: 'Well, it is time to choose which algorithm is more suitable for our data. A
    simple visualization of the result might work on small datasets, but imagine a
    graph with one thousand, or even ten thousand, nodes. That would be slightly chaotic
    for the human eye. So, let me show how to calculate the Adjusted Rand Score (ARS)
    and the Normalized Mutual Information (NMI):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候选择哪个算法更适合我们的数据了。对于小数据集，简单的可视化结果可能效果不错，但试想一下有一千个甚至一万个节点的图形。这对于人眼来说会有点混乱。所以，让我展示如何计算调整兰德指数（ARS）和归一化互信息（NMI）：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you''re unfamiliar with these metrics, here''s a quick explanation:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些指标不太熟悉，这里有一个简短的解释：
- en: '**Normalized Mutual Information (NMI)**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**归一化互信息（NMI）**'
- en: Mutual Information of two random variables is a measure of the mutual dependence
    between the two variables. Normalized Mutual Information is a normalization of
    the Mutual Information (MI) score to scale the results between 0 (no mutual information)
    and 1 (perfect correlation). In other words, 0 means dissimilar and 1 means perfect
    match.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 两个随机变量的互信息是衡量这两个变量之间相互依赖的度量。归一化互信息是对互信息（MI）得分进行归一化，将结果缩放到0（无互信息）到1（完美相关）之间。换句话说，0表示不相似，1表示完全匹配。
- en: '**Adjusted Rand Score (ARS)**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**调整兰德指数（ARS）**'
- en: Adjusted Rand Score on the other hand, computes a similarity measure between
    two clusters by considering all pairs of samples and counting pairs that are assigned
    in the same or different clusters in the predicted and true clusters. If that's
    a little weird to think about, have in mind that, for now, 0 is the lowest similarity
    and 1 is the highest.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 调整兰德指数则通过考虑所有样本对，并统计在预测和真实聚类中分配到相同或不同聚类的样本对，来计算两个聚类之间的相似度。如果这有点难以理解，请记住，目前的0表示最低相似度，而1表示最高相似度。
- en: So, to get a combination of these metrics (the NMI and ARS), we simply calculate
    the average value of their sum. And remember, the higher the number, the better
    the result.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了得到这些指标（NMI和ARS）的组合，我们只需计算它们总和的平均值。记住，数值越高，结果越好。
- en: 'Below, I have plotted the score evaluation so we can get a better understanding
    of our results. We could plot them in many ways, as points, as a straight line,
    but I think a bar chart is the better choice for our case. To do so, just use
    the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我绘制了评分评估图，以便我们能更好地理解我们的结果。我们可以用很多方式绘制它们，比如点图、折线图，但我认为条形图在我们的情况下更好。为此，只需使用以下代码：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see in the chart below, K-means and Agglomerative clustering have
    the best results for our dataset (best possible outcome). That of course, does
    not mean that Spectral and AF are low-performing algorithms, just that the did
    not fit in our data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在下方图表中看到的，K-means和层次聚类在我们的数据集中表现最佳（最佳可能结果）。当然，这并不意味着谱聚类和AF算法表现较差，只是它们不适合我们的数据。
- en: '![Clustering Score Evaluation](../Images/bc767fb2612fb0eac38cb7a8b335e5bb.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![聚类评分评估](../Images/bc767fb2612fb0eac38cb7a8b335e5bb.png)'
- en: Well, that's it for this one!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，这就是全部内容！
- en: Thanks for joining me in this clustering intro. I hope you found some value
    in seeing how we can easily manipulate a public dataset and apply several different
    clustering algorithms in Python. Let me know if you have any questions in the
    comments below, and feel free to attach a clustering project you've experimented
    with!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你参与这个聚类入门。我希望你在观察如何轻松操作公共数据集并在Python中应用几种不同的聚类算法时，能够发现一些价值。如果你有任何问题，请在下方评论区告诉我，也可以随意附上你尝试过的聚类项目！
- en: '**Bio: Nikos Koufos** is a **[LearnDataSci](http://www.learndatasci.com/)**
    Author, postgraduate in Computer Science & Engineering at the University Ioannina,
    Greece, and Computer Science undergraduate teaching assistant.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：尼科斯·库福斯** 是 **[LearnDataSci](http://www.learndatasci.com/)** 的作者，希腊伊奥尼纳大学计算机科学与工程研究生，并担任计算机科学本科教学助理。'
- en: '[Original](http://www.learndatasci.com/k-means-clustering-algorithms-python-intro/).
    Reposted with permission.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](http://www.learndatasci.com/k-means-clustering-algorithms-python-intro/)。转载已获许可。'
- en: '**Related:**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Comparing Clustering Techniques: A Concise Technical Overview](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较聚类技术：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)'
- en: '[Automatically Segmenting Data With Clustering](/2017/02/automatically-segmenting-data-clustering.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用聚类自动分割数据](/2017/02/automatically-segmenting-data-clustering.html)'
- en: '[Clustering Key Terms, Explained](/2016/10/clustering-key-terms-explained.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类关键术语解析](/2016/10/clustering-key-terms-explained.html)'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类释放：理解k-means 聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[k-means 聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是k-means 聚类及其算法如何工作？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
- en: '[Hands-On with Unsupervised Learning: K-Means Clustering](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[动手实践无监督学习：k-means 聚类](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速指南：如何找到适合注释的头脑](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
- en: '[Quick Data Science Tips and Tricks to Learn SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速数据科学技巧和窍门以学习SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
