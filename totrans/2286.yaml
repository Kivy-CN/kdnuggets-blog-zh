- en: Dealing with Position Bias in Recommendations and Search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: People click on top items in search and recommendations more often because they
    are on top, not because of their relevancy. If you order your search results with
    an ML model, they may eventually degrade in quality because of such a positive
    self-reinforcing feedback loop. How can this problem be solved?
  prefs: []
  type: TYPE_NORMAL
- en: Biases in Ranking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Every time you present a list of things, such as search results or recommendations,
    to a human being, rarely can we fairly evaluate all the items in the list.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/e19a71c400cd938cf225370850923471.png)'
  prefs: []
  type: TYPE_IMG
- en: Item rankings are all around us.
  prefs: []
  type: TYPE_NORMAL
- en: 'A [cascade click model](https://www.semanticscholar.org/paper/An-experimental-comparison-of-click-position-bias-Craswell-Zoeter/1ba36a2a1609cf09e2a08eb4712555848d5d728c)
    assumes that people evaluate all the items in the list sequentially before they
    find the relevant one. But then it means that things on the bottom have a smaller
    chance to be evaluated at all, hence will organically have fewer clicks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/2e7edb8662ba3f6f989e173d03097a11.png)'
  prefs: []
  type: TYPE_IMG
- en: Higher in the list?—?more clicks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Top items receive more clicks only because of their position?—?this behavior
    is called **position bias**. However, the position bias is not the only bias in
    item lists, there are plenty of other dangerous things to watch out for:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Presentation bias**: for example, due to a 3x3 grid layout, an item on position
    #4 (right under the #1 top one) may receive more clicks than item #3 in the corner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model bias**: when you train an ML model on historical data generated by
    the same model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, the position bias is the strongest one?—?and removing it while
    training may improve your model reliability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Experiment: Measuring Position Bias'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We conducted a small crowd-sourced research about position bias. With a [RankLens](https://github.com/metarank/ranklens)
    dataset, we used a [Google Keyword Planner](https://ads.google.com/home/tools/keyword-planner/)
    tool to generate a set of queries to find each particular movie.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/249f75f099d86dba77d2f6a3ae7801e8.png)'
  prefs: []
  type: TYPE_IMG
- en: Abusing Google Keyword Planner to get real queries people use for finding movies.
  prefs: []
  type: TYPE_NORMAL
- en: With a set of movies and corresponding actual queries, we have a perfect search
    evaluation dataset?—?all items are well-known for a wider audience, and we know
    correct labels in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'All major crowd-sourcing platforms like [Amazon Mechanical Turk](https://www.mturk.com/),
    [Scale.com](https://scale.com/) and [Toloka.ai](https://toloka.ai/) have out-of-the-box
    templates for typical search evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/88a42b1a6926e6a3dc460003015e66dc.png)'
  prefs: []
  type: TYPE_IMG
- en: A typical [search ranking evaluation template](https://toloka.ai/en/docs/template-builder/).
  prefs: []
  type: TYPE_NORMAL
- en: 'But there’s a nice trick in such templates, preventing you from shooting yourself
    in the foot with position bias: each item must be examined independently. Even
    if multiple items are present on screen, their ordering is random! But does random
    item order prevents people from clicking on the first results?'
  prefs: []
  type: TYPE_NORMAL
- en: The raw data for the experiment is available on [github.com/metarank/msrd](https://github.com/metarank/msrd),
    but the main observation is that **people still click more on the first position,
    even on randomly-ranked items**!
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/2e1ecb462c90ad95cd534aacbd1055c5.png)'
  prefs: []
  type: TYPE_IMG
- en: More clicks on first items, even for random ranking.
  prefs: []
  type: TYPE_NORMAL
- en: Inverse Propensity Weighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'But how can you offset the impact of position on implicit feedback you get
    from clicks? Each time you measure the click probability of an item, you observe
    the combination of two independent variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bias**: the probability of clicking on a specific position in the list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relevance**: the importance of the item within the current context (like
    BM25 score coming from ElasticSearch, and cosine similarity in recommendations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the MSRD dataset mentioned in the previous paragraph, it’s hard to distinguish
    the impact of position independently from BM25 relevance as you only observe them
    combined together:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/c4c4bbd8903d1fcbf0323e14c6ea84b9.png)'
  prefs: []
  type: TYPE_IMG
- en: When sorted by BM25, people prefer relevant items.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, 18% of clicks are happening on position #1\. Does this only happen
    because we have the most relevant item presented there? Will the same item on
    position #20 get the same amount of clicks?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The [Inverse Propensity Weighting](https://arxiv.org/abs/1608.04468) approach
    suggests that the observed click probability on a position is just a combination
    of two independent variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/e8e6f96d9f6535adcf8fe361113a7de2.png)'
  prefs: []
  type: TYPE_IMG
- en: Is true relevance independent from position?
  prefs: []
  type: TYPE_NORMAL
- en: 'And then, if you estimate the click probability on each position (the propensity),
    you can weight all your relevance labels with it and get an actual unbiased relevance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/830ebf60b98faa14e196324f7735eda8.png)'
  prefs: []
  type: TYPE_IMG
- en: Weighting by propensity
  prefs: []
  type: TYPE_NORMAL
- en: But how can you estimate the propensity in practice? The most common method
    is introducing a minor shuffling to rankings so that the same items within the
    same context (e.g., for a search query) will be evaluated on different positions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/08616038c65c5c57ad67831e8031af39.png)'
  prefs: []
  type: TYPE_IMG
- en: Estimating the propensity by shuffling.
  prefs: []
  type: TYPE_NORMAL
- en: But adding extra shuffling will definitely degrade your business metrics like
    CTR and Conversion Rate. Are there any less invasive alternatives not involving
    shuffling?
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/b1b1ddd9d13976a75764f545f945a169.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A slide from MICES’19 talk [Personalizing Search results in real-time](https://www.youtube.com/watch?v=AYdOpfY8jQU):
    a 2.8% drop in conversion when shuffling search results!'
  prefs: []
  type: TYPE_NORMAL
- en: Position-Aware Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A [position-aware approach to ranking](https://www.semanticscholar.org/paper/PAL%3A-a-position-bias-aware-learning-framework-for-Guo-Yu/4eb8bb576a5603b82c27d7f40e508b7dc8c1c0cc)
    suggests asking your ML model to optimize both ranking relevancy and position
    impact at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: on training time, you use item position as an input feature,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the prediction stage, you replace it with a **constant** value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/62291befb6c882510da1651b44375f6e.png)'
  prefs: []
  type: TYPE_IMG
- en: Replacing biased factors with constants during the inference
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, you trick your ranking ML model into detecting how position
    affects relevance during the training but zero out this feature during the prediction:
    all the items are simultaneously being presented in the same position.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/5a123555f3a5afe1ff2d3a3ea732d1a0.png)'
  prefs: []
  type: TYPE_IMG
- en: v
  prefs: []
  type: TYPE_NORMAL
- en: But which constant value should you choose? The authors of the [PAL](https://www.semanticscholar.org/paper/PAL%3A-a-position-bias-aware-learning-framework-for-Guo-Yu/4eb8bb576a5603b82c27d7f40e508b7dc8c1c0cc)
    paper did a couple of numerical experiments on selecting the optimal value?—?the
    rule of thumb is not to pick too high positions, as there’s too much noise.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/495e2391d7d8b5e3d9a2cebeeb84f108.png)'
  prefs: []
  type: TYPE_IMG
- en: Authors of [PAL](https://www.semanticscholar.org/paper/PAL%3A-a-position-bias-aware-learning-framework-for-Guo-Yu/4eb8bb576a5603b82c27d7f40e508b7dc8c1c0cc)
    tested different position constant values
  prefs: []
  type: TYPE_NORMAL
- en: Practical PAL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The PAL approach is already a part of multiple open-source tools for building
    recommendations and search:'
  prefs: []
  type: TYPE_NORMAL
- en: '[ToRecSys](https://github.com/p768lwy3/torecsys) implements PAL as a bias-elimination
    approach to train recommender systems on biased data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Metarank](https://github.com/metarank/metarank) can use a PAL-driven feature
    to train an unbiased LambdaMART Learn-to-Rank model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As the position-aware approach is just a hack around feature engineering, in
    [Metarank](https://github.com/metarank/metarank), it is only a matter of adding
    yet another feature definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/9d3c0714d0aa703729e7b5e9541b2c3d.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding [position](https://docs.metarank.ai/reference/overview/feature-extractors/relevancy#position)
    as a ranking feature for a Learn-to-Rank model
  prefs: []
  type: TYPE_NORMAL
- en: 'On an MSRD dataset mentioned above, such a PAL-inspired ranking feature has
    quite a high SHAP importance value compared to other ranking features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Dealing with Position Bias in Recommendations and Search](../Images/d3f30503972ffee1dfbc5eb671c512a6.png)'
  prefs: []
  type: TYPE_IMG
- en: Importance of the position while training the LambdaMART model
  prefs: []
  type: TYPE_NORMAL
- en: Last Words
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The position-aware learning approach is not only limited to pure ranking tasks
    and position de-biasing: you can use this trick to overcome any other type of
    bias:'
  prefs: []
  type: TYPE_NORMAL
- en: For the **presentation bias** due to a grid layout, you can introduce a pair
    of features for an item’s row and column position during the training. But swap
    them to a constant during the prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the **model bias**, when items presented more often receive more clicks?—?you
    can introduce a “number of clicks” training feature and replace it with a constant
    value on prediction time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ML model trained with the PAL approach should produce an unbiased prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Roman Grebennikov](https://www.linkedin.com/in/romangrebennikov/)** is a
    Principal Engineer at Delivery Hero SE, working on search personalization and
    recommendations. A pragmatic fan of functional programming, learn-to-rank models
    and performance engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Dealing With Noisy Labels in Text Data](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Elevate Your Search Engine Skills with Uplimit''s Search with ML Course!](https://www.kdnuggets.com/2023/10/uplimit-elevate-your-search-engine-skills-search-with-ml-course)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Visual Search Engine - Part 2: The Search Engine](https://www.kdnuggets.com/2022/02/building-visual-search-engine-part-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Bias-Variance Trade-Off in 3 Minutes](https://www.kdnuggets.com/2020/09/understanding-bias-variance-trade-off-3-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Bias-Variance Trade-off](https://www.kdnuggets.com/2022/08/biasvariance-tradeoff.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
