- en: 'Deep Learning Reading Group: Skip-Thought Vectors'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/11/deep-learning-group-skip-thought-vectors.html](https://www.kdnuggets.com/2016/11/deep-learning-group-skip-thought-vectors.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Books header](../Images/ba0272f2ae69ebcf2a399dfabc406a69.png)'
  prefs: []
  type: TYPE_IMG
- en: Continuing the tour of older papers that started with our [ResNet blog post](https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f#.bc3hiquop),
    we now take on [Skip-Thought Vectors](https://arxiv.org/abs/1506.06726) by [Kiros](http://www.cs.toronto.edu/~rkiros/) *et
    al*. Their goal was to come up with a useful embedding for sentences that was
    not tuned for a single task and did not require labeled data to train. They took
    inspiration from Word2Vec skip-gram (you can find [my explanation of that algorithm
    here](https://gab41.lab41.org/python2vec-word-embeddings-for-source-code-3d14d030fe8f#.e301tsg77))
    and attempt to extend it to sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Skip-thought vectors are created using an encoder-decoder model. The encoder
    takes in the training sentence and outputs a vector. There are two decoders both
    of which take the vector as input. The first attempts to predict the previous
    sentence and the second attempts to predict the next sentence. Both the encoder
    and decoder are constructed from recurrent neural networks (RNN). Multiple encoder
    types are tried including uni-skip, bi-skip, and combine-skip. Uni-skip reads
    the sentence in the forward direction. Bi-skip reads the sentence forwards and
    backwards and concatenates the results. Combined-skip concatenates the vectors
    from uni- and bi-skip. Only minimal tokenization is done to the input sentences.
    A diagram indicating the input sentence and the two predicted sentences is shown
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45e90413b5490ed4bd69beb3b4bca739.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Given a sentence (the grey dots), skip-thought attempts to predict the preceding
    sentence (red dots) and the next sentence (green dots). Figure from the paper.*'
  prefs: []
  type: TYPE_NORMAL
- en: Their model requires groups of sentences in order to train, and so trained on
    the BookCorpus Dataset. The dataset consists of novels by unpublished authors
    and is (unsurprisingly) dominated by romance and fantasy novels. This “bias” in
    the dataset will become apparent later when discussing some of the sentences used
    to test the skip-thought model; some of the retrieved sentences are quite exciting!
  prefs: []
  type: TYPE_NORMAL
- en: 'Building a model that accounts for the meaning of an entire sentence is tough
    because language is remarkably flexible. Changing a single word can either completely
    change the meaning of a sentence or leave it unaltered. The same is true for moving
    words around. As an example:'
  prefs: []
  type: TYPE_NORMAL
- en: One difficulty in building a model to handle sentences is that a single word
    can be changed and yet the meaning of the sentence is the same.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Put a different way:'
  prefs: []
  type: TYPE_NORMAL
- en: One challenge in building a model to handle sentences is that a single word
    can be changed and yet the meaning of the sentence is the same.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Changing a single word has had almost no effect on the meaning of that sentence.
    To account for these word level changes, the skip-thought model needs to be able
    to handle a large variety of words, some of which were not present in the training
    sentences. The authors solve this by using a pre-trained continuous bag-of-words
    (CBOW) Word2Vec model and learning a translation from the Word2Vec vectors to
    the word vectors in their sentences. Below are shown the nearest neighbor words
    after the vocabulary expansion using query words that do not appear in the training
    vocabulary:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/da2cb4c3ebfcd31a0af039184b790316.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Nearest neighbor words for various words that were not included in the training
    vocabulary. Table from the paper.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'So how well does the model work? One way to probe it is to retrieve the closest
    sentence to a query sentence; here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Query: “I’m sure you’ll have a glamorous evening,” she said, giving an exaggerated
    wink.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Retrieved: “I’m really glad you came to the party tonight,” he said, turning
    to her.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'And:'
  prefs: []
  type: TYPE_NORMAL
- en: Query: Although she could tell he hadn’t been too interested in any of their
    other chitchat, he seemed genuinely curious about this.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Retrieved: Although he hadn’t been following her career with a microscope, he’d
    definitely taken notice of her appearance.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The sentences are in fact very similar in both structure and meaning (and a
    bit salacious, as I warned earlier) so the model appears to be doing a good job.
  prefs: []
  type: TYPE_NORMAL
- en: To perform more rigorous experimentation, and to test the value of skip-thought
    vectors as a generic sentence feature extractor, the authors run the model through
    a series of tasks using the encoded vectors with simple, linear classifiers trained
    on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: They find that their generic skip-thought representation performs very well
    for detecting the semantic relatedness of two sentences and for detecting where
    a sentence is paraphrasing another one. Skip-thought vectors perform relatively
    well for image retrieval and captioning (where they use [VGG](https://arxiv.org/pdf/1409.1556.pdf) to
    extract image feature vectors). Skip-thought performs poorly for sentiment analysis,
    producing equivalent results to various bag of word models but at a much higher
    computational cost.
  prefs: []
  type: TYPE_NORMAL
- en: We have used skip-thought vectors a little bit at the Lab, most recently for
    the [Pythia challenge](https://gab41.lab41.org/tell-me-something-i-dont-know-detecting-novelty-and-redundancy-with-natural-language-processing-818124e4013c#.6xf8nejr9).
    We found them to be useful for novelty detection, but incredibly slow. Running
    skip-thought vectors on a corpus of about 20,000 documents took many hours, where
    as simpler (and as effective) methods took seconds or minutes. I will update with
    a link to their blog post when it comes online.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Alexander Gude](https://twitter.com/alex_gude)** is currently a data scientist
    at Lab41 working on investigating recommender system algorithms. He holds a BA
    in physics from University of California, Berkeley, and a PhD in Elementary Particle
    Physics from University of Minnesota-Twin Cities.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Lab41](http://www.lab41.org)** is a “challenge lab” where the U.S. Intelligence
    Community comes together with their counterparts in academia, industry, and In-Q-Tel
    to tackle big data. It allows participants from diverse backgrounds to gain access
    to ideas, talent, and technology to explore what works and what doesn’t in data
    analytics. An open, collaborative environment, Lab41 fosters valuable relationships
    between participants.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://gab41.lab41.org/lab41-reading-group-skip-thought-vectors-fec68c05aa92).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[In Deep Learning, Architecture Engineering is the New Feature Engineering](/2016/07/deep-learning-architecture-engineering-feature-engineering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Up to Speed on Deep Learning: July Update](/2016/08/deep-learning-july-update.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Do Deep Learning Networks Scale?](/2016/07/deep-learning-networks-scale.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Reading Minds with AI: Researchers Translate Brain Waves to Images](https://www.kdnuggets.com/2023/03/reading-minds-ai-researchers-translate-brain-waves-images.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Step by Step Guide to Reading and Understanding SQL Queries](https://www.kdnuggets.com/a-step-by-step-guide-to-reading-and-understanding-sql-queries)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2024 Reading List: 5 Essential Reads on Artificial Intelligence](https://www.kdnuggets.com/2024-reading-list-5-essential-reads-on-artificial-intelligence)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SQL Group By and Partition By Scenarios: When and How to Combine…](https://www.kdnuggets.com/sql-group-by-and-partition-by-scenarios-when-and-how-to-combine-data-in-data-science)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 8: 21 Cheat Sheets for Data Science…](https://www.kdnuggets.com/2022/n23.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
