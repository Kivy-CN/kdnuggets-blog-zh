- en: 'The Three Edge Case Culprits: Bias, Variance, and Unpredictability'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/04/imerit2-bias-variance-unpredictability.html](https://www.kdnuggets.com/2021/04/imerit2-bias-variance-unpredictability.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sponsored Post.
  prefs: []
  type: TYPE_NORMAL
- en: '[![Image](../Images/96634a8676754809b55bcf6130b527eb.png)](https://go.imerit.net/annotation-services?latest_sfdc_campaign=7011Y000002WKAb&latest_sfdc_campaign_status=Responded&utm_campaign=edgecases&utm_medium=blogpost&utm_source=kdnuggets&utm_content=image)'
  prefs: []
  type: TYPE_NORMAL
- en: '[**iMerit is a leader in providing high-quality data**](https://go.imerit.net/annotation-services?latest_sfdc_campaign=7011Y000002WKAb&latest_sfdc_campaign_status=Responded&utm_campaign=edgecases&utm_medium=blogpost&utm_source=kdnuggets&utm_content=toplink)
    for training data sets. In our latest blog post, we bring you the latest in recognising
    and handling edge cases in your ML systems. If you wish to talk to an expert and
    learn more about conquering your edge cases, [please contact us](https://go.imerit.net/annotation-services?latest_sfdc_campaign=7011Y000002WKAb&latest_sfdc_campaign_status=Responded&utm_campaign=edgecases&utm_medium=blogpost&utm_source=kdnuggets&utm_content=toplink).'
  prefs: []
  type: TYPE_NORMAL
- en: Through training, machine learning (ML) systems learn to recognize patterns
    by associating inputs (e.g., pixel values, audio samples, text) to categories
    (e.g., object identities, words, sentiments). This association can be thought
    of as dividing the multi-dimensional space of possible inputs into regions representing
    categories, the regions being defined by decision boundaries. When, during testing
    or operation, an input falls beyond the edge of the region assigned to its category,
    the input will be mis-categorized. We call this an edge case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edge cases occur for three basic reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Bias – the ML system is too ‘simple’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance – the ML system is too ‘inexperienced’
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unpredictability – the ML system operates in an environment full of surprises.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we recognize these edge cases situations, and what can we do about them?
  prefs: []
  type: TYPE_NORMAL
- en: '**Bias**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Bias shows up when an ML system cannot achieve good performance on its training
    data set. This is an indication that the architecture of the ML system, its model,
    does not have a structure that can represent the nuances in the training data.
    A very simple example is shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/75898ebceb439191152f54e74b2cb89f.png)'
  prefs: []
  type: TYPE_IMG
- en: This chart shows the linear decision boundary implemented by a two-input, single-layer,
    two-neuron neural network. Having been trained to try to distinguish the purple
    from the yellow dots, it cannot do a good job because its simple linear decision
    boundary is inadequate to separate the classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/750fa3b408bfe8a04ce9f94c0f90a35c.png)'
  prefs: []
  type: TYPE_IMG
- en: If we make the ML system a bit more complex by adding a pre-processing layer
    to transform the original inputs to polar coordinates, the purple and yellow dots
    line up differently in the new input space presented to the linear part of the
    ML system, and we get a decision boundary that looks like this. This more complex
    ML system performs well on the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '*“The structure of the layers themselves can also make a big difference.”*'
  prefs: []
  type: TYPE_NORMAL
- en: Often the additional complexity needed to overcome bias in an ML system can
    be accomplished simply by adding processing units and layers. However, the structure
    of the layers themselves can also make a big difference. The ImageNet visual database
    has been used since 2010 to benchmark the performance of object recognition ML
    systems. The best performance on this data set jumped 10.8 percentage points in
    [2012](https://en.wikipedia.org/wiki/ImageNet), when Convolutional Neural Networks
    replaced earlier architectures that used pre-processing and Support Vector Machines,
    essentially a more sophisticated version of the simple ML system shown above.
  prefs: []
  type: TYPE_NORMAL
- en: '**Variance**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When an ML system achieves good performance on its training data, but performs
    poorly in testing, the problem is often that the training data set is too small
    to adequately reflect the range of variability in the ML system’s operational
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/d677cb46884bda82dda001e6f7d219d9.png)'
  prefs: []
  type: TYPE_IMG
- en: The primary way to reduce edge cases caused by variance is to gather more training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the object recognition [system](https://users.ece.cmu.edu/~koopman/lectures/Koopman19_SSS_slides.pdf)
    shown here does fine with adults, but apparently doesn’t have much experience
    with children.
  prefs: []
  type: TYPE_NORMAL
- en: Edge cases caused by variance issues is a large problem for automatic facial
    recognition systems. While these systems can be highly accurate in recognizing
    smartphone users, for example, they can produce inaccurate and troubling results
    when used for law enforcement. In a 2018 [test](https://www.nytimes.com/2018/07/26/technology/amazon-aclu-facial-recognition-congress.html),
    28 members of the US Congress were falsely matched to mug shots in a database
    of 25,000 criminals.
  prefs: []
  type: TYPE_NORMAL
- en: The primary way to reduce edge cases caused by variance is to gather more training
    data. [Studies](https://arxiv.org/abs/1707.02968) have shown that ML system performance
    consistently improves as training data set size increases, even for data sets
    that are already very large.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases, [data augmentation](https://en.wikipedia.org/wiki/Data_augmentation)
    can be used to increase the size of training data sets, by making small changes
    to the original data to represent variations such as object rotation, lighting,
    or pose. However, it is particularly important to ensure that training data is
    representative of important but possibly rare situations encountered in the operational
    environment, such as the appearance of children or extreme weather conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Unpredictability**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning relies on finding regular patterns in input data. There is
    always statistical variation in the data, but with an appropriate architecture
    and enough training data, an ML system can often find enough data regularity (achieve
    small enough bias and variance), to make reliable decisions and minimize edge
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/3816de10971d10734b104e810249f50b.png)'
  prefs: []
  type: TYPE_IMG
- en: However autonomous driving is an example of an environment that presents ML
    systems with such a high degree of variability that the possible situations are
    virtually endless. Training data can be gathered through many millions of miles
    of driving without encountering important edge cases.  For example, in 2018 a
    woman was [struck](https://www.nbcnews.com/tech/tech-news/self-driving-uber-car-hit-killed-woman-did-not-recognize-n1079281)
    and killed by a self-driving car, because the ML system had never been trained
    to recognize and respond to a jaywalker with a bicycle.
  prefs: []
  type: TYPE_NORMAL
- en: Handling the virtually unlimited number of edge cases encountered in the unpredictable
    autonomous driving application is a particularly difficult challenge. Two avenues
    are being pursued to deal with this problem. One approach is to develop [‘checker’](https://users.ece.cmu.edu/~koopman/lectures/Koopman19_SSS_slides.pdf)
    ML systems, specifically trained to recognize dangerous or questionable systems
    and take overriding action to maintain safety.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to train autonomous vehicle ML systems to better handle
    edge cases. One way is to use virtual road training [environments](https://www.cognata.com/edge-cases-predicting-the-unpredictable/)
    to expand the range of training situations. Another way uses [adversarial](https://techhq.com/2020/07/how-deepfake-tech-is-speeding-up-autonomous-vehicle-development/)
    training, the technology famous for creating ‘deep fakes’,  to greatly expand
    training sets, allowing ML systems to better handle novelty.
  prefs: []
  type: TYPE_NORMAL
- en: '**Overcoming Edge Cases**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The table below summarizes how to recognize and deal with the edge cases resulting
    from ML bias, variance, and unpredictability:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Culprit | How it Shows Up | What to Try |'
  prefs: []
  type: TYPE_TB
- en: '| Bias | Poor training performance | Better ML system model |'
  prefs: []
  type: TYPE_TB
- en: '| Variance | Poor test performance | More training data |'
  prefs: []
  type: TYPE_TB
- en: '| Unpredictability | Operational surprises | Simulation Adversarial training
    |'
  prefs: []
  type: TYPE_TB
- en: '**Key takeaways**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ensure your training and test data sets are large and diverse enough, (and of
    course accurately labeled!), to expose weaknesses in ML design and to sufficiently
    characterize the diversity of the operational environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For operational environments with high unpredictability, consider augmenting
    training data with examples generated through simulation and adversarial training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor operations and respond to the inevitable appearance of new edge cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Understanding Bias-Variance Trade-Off in 3 Minutes](https://www.kdnuggets.com/2020/09/understanding-bias-variance-trade-off-3-minutes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Bias-Variance Trade-off](https://www.kdnuggets.com/2022/08/biasvariance-tradeoff.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Dealing with Position Bias in Recommendations and Search](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chip Huyen shares frameworks and case studies for implementing ML systems](https://www.kdnuggets.com/2023/02/sphere-chip-huyen-shares-frameworks-case-studies-implementing-ml-systems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Promise of Edge AI and Approaches for Effective Adoption](https://www.kdnuggets.com/the-promise-of-edge-ai-and-approaches-for-effective-adoption)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
