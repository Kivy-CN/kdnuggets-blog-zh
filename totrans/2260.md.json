["```py\n# Importing Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.axes as ax\nfrom IPython.display import clear_output\n```", "```py\n# Dataset Link:\n# https://github.com/AshishJangra27/Machine-Learning-with-Python-GFG/tree/main/Linear%20Regression\n\ndf = pd.read_csv(\"lr_dataset.csv\")\ndf.head()\n\n# Drop null values\ndf = df.dropna()\n\n# Train-Test Split\nN = len(df)\nx_train, y_train = np.array(df.X[0:500]).reshape(500, 1), np.array(df.Y[0:500]).reshape(\n    500, 1\n)\nx_test, y_test = np.array(df.X[500:N]).reshape(N - 500, 1), np.array(\n    df.Y[500:N]\n).reshape(N - 500, 1)\n```", "```py\nclass LinearRegression:\n    def __init__(self):\n        self.Q0 = np.random.uniform(0, 1) * -1  # Intercept\n        self.Q1 = np.random.uniform(0, 1) * -1  # Coefficient of X\n        self.losses = []  # Storing the loss of each iteration\n\n    def forward_propogation(self, training_input):\n        predicted_values = np.multiply(self.Q1, training_input) + self.Q0  # y = mx + c\n        return predicted_values\n\n    def cost(self, predictions, training_output):\n        return np.mean((predictions - training_output) ** 2)  # Calculating the cost\n\n    def finding_derivatives(self, cost, predictions, training_input, training_output):\n        diff = predictions - training_output\n        dQ0 = np.mean(diff)  # d(J(Q0, Q1))/d(Q0)\n        dQ1 = np.mean(np.multiply(diff, training_input))  # d(J(Q0, Q1))/d(Q1)\n        return dQ0, dQ1\n\n    def train(self, x_train, y_train, lr, itrs):\n        for i in range(itrs):\n            # Finding the predicted values (Using the linear equation y=mx+c)\n            predicted_values = self.forward_propogation(x_train)\n\n            # Calculating the Loss\n            loss = self.cost(predicted_values, y_train)\n            self.losses.append(loss)\n\n            # Back Propagation (Finding Derivatives of Weights)\n            dQ0, dQ1 = self.finding_derivatives(\n                loss, predicted_values, x_train, y_train\n            )\n\n            # Updating the Weights\n            self.Q0 = self.Q0 - lr * (dQ0)\n            self.Q1 = self.Q1 - lr * (dQ1)\n\n            # It will dynamically update the plot of the straight line\n            line = self.Q0 + x_train * self.Q1\n            clear_output(wait=True)\n            plt.plot(x_train, y_train, \"+\", label=\"Actual values\")\n            plt.plot(x_train, line, label=\"Linear Equation\")\n            plt.xlabel(\"Train-X\")\n            plt.ylabel(\"Train-Y\")\n            plt.legend()\n            plt.show()\n        return (\n            self.Q0,\n            self.Q1,\n            self.losses,\n        )  # Returning the final model weights and the losses\n```", "```py\nlr = 0.0001  # Learning Rate\nitrs = 30  # No. of iterations\nmodel = LinearRegression()\nQ0, Q1, losses = model.train(x_train, y_train, lr, itrs)\n\n# Output No. of Iteration vs Loss\nfor itr in range(len(losses)):\n    print(f\"Iteration = {itr+1}, Loss = {losses[itr]}\")\n```", "```py\nIteration = 1, Loss = 6547.547538061649\nIteration = 2, Loss = 3016.791083711492\nIteration = 3, Loss = 1392.3048668536044\nIteration = 4, Loss = 644.8855797373262\nIteration = 5, Loss = 301.0011032250385\nIteration = 6, Loss = 142.78129818453215\n.\n.\n.\n.\nIteration = 27, Loss = 7.949420840198964\nIteration = 28, Loss = 7.949411555664398\nIteration = 29, Loss = 7.949405538972356\nIteration = 30, Loss = 7.949401025888949\n```", "```py\n# Prediction on test data\ny_pred = Q0 + x_test * Q1\nprint(f\"Best-fit Line: (Y = {Q1}*X + {Q0})\")\n\n# Plot the regression line with actual data pointa\nplt.plot(x_test, y_test, \"+\", label=\"Data Points\")\nplt.plot(x_test, y_pred, label=\"Predited Values\")\nplt.xlabel(\"X-Test\")\nplt.ylabel(\"Y-Test\")\nplt.legend()\nplt.show()\n```", "```py\nBest-fit Line: (Y = 1.0068007107347927*X + -0.653638673779529)\n```", "```py\n# Importing Extra Libraries\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n```", "```py\ndf = pd.read_csv(\"lr_dataset.csv\")\n\n# Drop null values\ndf = df.dropna()\n\n# Train-Test Split\nY = df.Y\nX = df.drop(\"Y\", axis=1)\nx_train, x_test, y_train, y_test = train_test_split(\n    X, Y, test_size=0.25, random_state=42\n)\n```", "```py\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\n# Plot the regression line with actual data points\nplt.plot(x_test, y_test, \"+\", label=\"Actual values\")\nplt.plot(x_test, y_pred, label=\"Predicted values\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.legend()\nplt.show()\n```"]