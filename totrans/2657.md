# 从零实现 AdaBoost 算法

> 原文：[https://www.kdnuggets.com/2020/12/implementing-adaboost-algorithm-from-scratch.html](https://www.kdnuggets.com/2020/12/implementing-adaboost-algorithm-from-scratch.html)

[评论](#comments)

**由 [James Ajeeth J](https://www.linkedin.com/in/jamesajeeth/)，Praxis 商学院**

在本文结束时，你将能够：

+   理解自适应 Boosting（AdaBoost）算法的工作原理和数学基础。

+   能够从头编写 AdaBoost 的 Python 代码。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你在 IT 领域的职业发展

* * *

### **Boosting 介绍：**

Boosting 是一种集成技术，旨在通过多个弱分类器创建强分类器。与许多专注于单一模型的高质量预测的机器学习模型不同，Boosting 算法通过训练一系列弱模型来提高预测能力，每个模型都弥补了其前身的不足。Boosting 赋予机器学习模型改进预测准确性的能力。

### **AdaBoost:**

AdaBoost，全称为 自适应 [Boosting](https://en.wikipedia.org/wiki/Boosting_(meta-algorithm))，是一个由 Yoav Freund 和 [Robert Schapire](https://en.wikipedia.org/wiki/Robert_Schapire) 制定的 [机器学习](https://en.wikipedia.org/wiki/Machine_learning) [算法](https://en.wikipedia.org/wiki/Meta-algorithm)。AdaBoost 技术采用深度为一的决策树模型。AdaBoost 实质上是一片由树桩组成的森林，而不是树。AdaBoost 通过对难以分类的实例加大权重，对已经处理好的实例减小权重来工作。AdaBoost 算法用于解决分类和回归问题。

AdaBoost 背后的理念：

+   树桩（一个节点和两个叶子）在进行准确分类时效果不佳，因此它只是一个弱分类器/弱学习器。多个弱分类器的组合形成一个强分类器，这就是 AdaBoost 算法背后的原理。

+   一些树桩的性能比其他的更好或分类效果更佳。

+   连续树桩通过考虑之前树桩的错误来制作。

### **从头实现 AdaBoost 算法：**

在这里，我使用了 Iris 数据集作为从零构建算法的示例，并且只考虑了两个类别（Versicolor 和 Virginica）以便于理解。

![图片](../Images/684d4d2f6b75e9cc52851b944bbcc8bb.png)

### **步骤 1：为所有观察值分配相等的权重**

最初为数据集中每个记录分配相同的权重。

**样本权重 = 1/N**

其中 N = 记录数

![Image](../Images/523c83e9b569eaab7c22e1ac785e6e5f.png)

### **步骤 2：使用决策桩分类随机样本**

从原始数据中以与样本权重相等的概率进行有放回的随机抽样，并拟合模型。这里**在 AdaBoost 中使用的模型（基学习器）是决策树。** 决策树的深度为 1，包含一个节点和两个叶子，也称为决策桩。将模型拟合到随机样本中，并预测原始数据的类别。

![Image](../Images/75827366c2da5626c461e8a3b4899753.png)![Image](../Images/b7dfa69c1c768a0195e9d0676398754a.png)![Image](../Images/909572be292032a4501fb9286cf58f17.png)

‘pred1’ 是新预测的类别。

### **步骤 3：计算总误差**

总误差就是被错误分类记录的权重之和。

**总误差** = **错误分类记录的权重**

总误差始终在 0 和 1 之间。

0 表示完美的决策桩（正确分类）

1 表示弱决策桩（错误分类）

![Image](../Images/f9fce9002733b6143b12c503b3b4449d.png)

### **步骤 4：计算决策树的性能**

使用总误差来确定基学习器的性能。计算出的决策树（α）值用于在连续迭代中更新权重，也用于最终预测计算。

**决策树的性能（**α**）** **= ½ ln (1 – 总误差/总误差)**

![Image](../Images/71e36ca2c4146de740943dd37d0dea5c.png)![Image](../Images/820b41fa912784fd293e372d08a276e0.png)

案例：

+   如果总误差为 0.5，则决策树的性能将为零。

+   如果总误差为 0 或 1，那么性能将分别变为无穷大或负无穷大。

当总误差等于 1 或 0 时，上述方程将表现得很奇怪。因此，实际中会添加一个小的误差项以防止这种情况发生。

当性能（α）相对较高时，决策树在分类记录方面表现良好。当性能（α）相对较低时，决策树在分类记录方面表现不佳。**利用性能参数（α），我们可以增加被错误分类记录的权重，并减少被正确分类记录的权重。**

### **步骤 5：更新权重**

根据决策树（α）的性能更新权重。我们需要下一个决策树通过增加相应样本权重和减少正确分类记录的样本权重来正确分类错误分类的记录。

**新权重 = 权重 * e^((性能))** **→** **错误分类记录**

**新权重 = 权重 * e^(-(性能))** **→** **正确分类记录**

![Image](../Images/26e66e6fc54b7e933e7bcad7f23eb31e.png)

如果 ‘Label’ 和 ‘pred1’ 相同（即 1 或 -1），则将这些值代入上述方程会得到正确分类记录对应的方程。类似地，如果这些值不同，则代入上述方程会得到误分类记录对应的方程。

关于 e^(performance)，即分类错误的情况的简短说明

当性能较好时，最后一个基分类器在分类记录方面表现良好，此时新的样本权重会比旧权重大得多。当性能较低时，最后一个基分类器在分类记录方面表现不佳，此时新的样本权重仅比旧权重大一点。

![图像](../Images/ed4a5934f9d10e91107f157793b6267b.png)

关于 e^-(performance)，即没有分类错误的情况的简短说明

当性能较好时，最后一个基分类器在分类记录方面表现良好，此时新的样本权重会比旧权重小得多。当性能较差时，最后一个基分类器在分类记录方面表现不佳，此时新的样本权重仅比旧权重小一点。

![图像](../Images/531899bac550c7b6aa666076e92b70ee.png)

这里更新权重的总和不等于 1，而在初始样本权重的情况下，总权重的和等于 1。因此，为了实现这一点，我们将其除以一个数字，即更新权重的总和（归一化常数）。

**归一化常数 =** ∑ **新权重**

**归一化权重 = 新权重 / 归一化常数**

现在归一化权重的总和等于 1。

![图像](../Images/180a15354bbb57dbbe664b95b8e28bae.png)![图像](../Images/33557a613af3aae1bdd1b56638846780.png)

‘prob2’ 是新更新的权重。

### **步骤 6：迭代中更新权重**

使用归一化权重，创建森林中的第二个基分类器。基于新更新的样本权重，创建一个与原始数据集大小相同的新数据集，其中包含重复的样本。这样，分类错误的记录将有更高的选择概率。重复步骤 2 到 5，再次更新权重，进行指定次数的迭代。

![图像](../Images/56cef35eaa73e308fdda007cbf2266a5.png)

‘prob4’ 是每个观察值的最终权重。

### **步骤 7：最终预测**

最终预测通过获得最终预测值的加权和的符号来完成。

**最终预测/符号（加权和） = ∑ (α[i]*（每次迭代中的预测值）)**

例如：5 个弱分类器可能预测的值为 1.0、1.0、-1.0、1.0、-1.0。通过多数投票，模型似乎会预测值为 1.0 或第一类。这 5 个弱分类器可能具有的性能（α）值分别为 0.2、0.5、0.8、0.2 和 0.9。计算这些预测值的加权和会得到 -0.8，这将是 -1.0 或第二类的集成预测。

计算：

t = 1.0*0.2 + 1.0*0.5 - 1.0*0.8 + 1.0*0.2 - 1.0*0.9 = -0.8

仅考虑符号的话，最终预测将是-1.0或第二类。

![图片](../Images/c77356b05f968155144d230c1b761691.png)

**AdaBoost算法的优点：**

+   AdaBoost算法的众多优点之一是它快速、简单且易于编程。

+   提升法已被证明对过拟合具有鲁棒性。

+   它已被扩展到二分类问题之外的学习问题（即），可以用于文本或数值数据。

**缺点：**

+   AdaBoost对噪声数据和异常值可能敏感。

+   弱分类器过于弱会导致低边际和过拟合。

### **结论：**

AdaBoost通过根据前一个分类器的结果选择每个新分类器的训练集。此外，在组合结果时，它决定每个分类器提议的答案应该给予多少权重。它将弱学习者组合起来，创建一个强学习者，以纠正分类错误，这也是第一个成功的二分类问题的增强算法。

代码文件和数据的GitHub链接：

[https://github.com/jamesajeeth/Data-Science/tree/master/Adaboost%20from%20scratch](https://github.com/jamesajeeth/Data-Science/tree/master/Adaboost%20from%20scratch)

**参考文献：**

书籍：

+   Hastie, Trevor, Tibshirani, Robert, Friedman, Jerome, *《统计学习要素：数据挖掘、推断与预测（第二版）》*

站点：

+   [关于Adaboost算法的简介](https://www.educba.com/adaboost-algorithm/)

+   [Statquest](https://statquest.org/adaboost-clearly-explained/)

+   [维基百科](https://en.wikipedia.org/wiki/AdaBoost)

**个人简介：** [**James Ajeeth J**](https://www.linkedin.com/in/jamesajeeth/) 是印度班加罗尔Praxis商学院的研究生。

**相关：**

+   [机器学习中的集成方法：AdaBoost](/2019/09/ensemble-methods-machine-learning-adaboost.html)

+   [探讨暴力K最近邻算法](/2020/10/exploring-brute-force-nearest-neighbors-algorithm.html)

+   [KNN中最常用的距离度量及其使用时机](/2020/11/most-popular-distance-metrics-knn.html)

### 更多相关话题

+   [在Scikit-learn中实现Adaboost](https://www.kdnuggets.com/2022/10/implementing-adaboost-scikitlearn.html)

+   [从零开始的机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)

+   [从零开始的线性回归与NumPy](https://www.kdnuggets.com/linear-regression-from-scratch-with-numpy)

+   [如何从零开始构建和训练Transformer模型…](https://www.kdnuggets.com/how-to-build-and-train-a-transformer-model-from-scratch-with-hugging-face-transformers)

+   [通过实现理解：决策树](https://www.kdnuggets.com/2023/02/understanding-implementing-decision-tree.html)

+   [在商业中实施推荐系统的十大关键经验](https://www.kdnuggets.com/2022/07/ten-key-lessons-implementing-recommendation-systems-business.html)
