- en: 5 Python Best Practices for Data Science
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/5-python-best-practices-for-data-science](https://www.kdnuggets.com/5-python-best-practices-for-data-science)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![python-ds](../Images/56d49a7b443b03f2fd445ce4015a4194.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Strong Python and SQL skills are both integral to many data professionals. As
    a data professional, you’re probably comfortable with Python programming—so much
    that writing Python code feels pretty natural. But are you following the best
    practices when working on data science projects with Python?
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Though it''s easy to learn Python and build data science applications with
    it, it''s, perhaps, easier to write code that is hard to maintain. To help you
    write better code, this tutorial explores some Python coding best practices which
    help with dependency management and maintainability such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up dedicated virtual environments when working on data science projects
    locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving maintainability using type hints
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modeling and validating data using Pydantic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using vectorized operations when possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let’s get coding!
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Use Virtual Environments for Each Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual environments ensure project dependencies are isolated, preventing conflicts
    between different projects. In data science, where projects often involve different
    sets of libraries and versions, Virtual environments are particularly useful for
    maintaining reproducibility and managing dependencies effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, virtual environments also make it easier for collaborators to
    set up the same project environment without worrying about conflicting dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: You can use tools like Poetry to create and manage virtual environments. There
    are many benefits to using Poetry but if all you need is to create virtual environments
    for your projects, you can also use the [built-in venv module](https://docs.python.org/3/library/venv.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are on a Linux machine (or a Mac), you can create and activate virtual
    environments like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If you’re a Windows user, you can [check the docs](https://docs.python.org/3/library/venv.html)
    on how to activate the virtual environment. Using virtual environments for each
    project is, therefore, helpful to keep dependencies isolated and consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Add Type Hints for Maintainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because Python is a dynamically typed language, you don't have to specify in
    the data type for the variables that you create. However, you can add type hints—indicating
    the expected data type—to make your code more maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example of a function that calculates the mean of a numerical
    feature in a dataset with appropriate type annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, the type hints let the user know that the `calcuate_mean` function takes
    in a list of floating point numbers and returns a floating-point value.
  prefs: []
  type: TYPE_NORMAL
- en: Remember Python does not enforce types at runtime. But you can use mypy or the
    like to raise errors for invalid types.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Model Your Data with Pydantic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously we talked about adding type hints to make code more maintainable.
    This works fine for Python functions. But when working with data from external
    sources, it's often helpful to model the data by defining classes and fields with
    expected data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use built-in dataclasses in Python, but you don’t get data validation
    support out of the box. With Pydantic, you can model your data and also use its
    built-in data validation capabilities. To use Pydantic, you can install it along
    with the email validator using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s an example of modeling customer data with Pydantic. You can create a
    model class that inherits from `BaseModel` and define the various fields and attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You can take this further by adding validation to check if the fields all have
    valid values. If you need a tutorial on using Pydantic—defining models and validating
    data—read [Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple).'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Profile Code to Identify Performance Bottlenecks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Profiling code is helpful if you’re looking to optimize your application for
    performance. In data science projects, you can profile memory usage and execution
    times depending on the context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you''re working on a machine learning project where preprocessing a
    large dataset is a crucial step before training your model. Let''s profile a function
    that applies common preprocessing steps such as standardization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'When you run the script, you should see a similar output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![profiling-output](../Images/994c219538d44ae7c12dcae4d799c8dd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this example, we''re profiling the `preprocess_data()` function, which preprocesses
    sample data. Profiling, in general, helps identify any potential bottlenecks—guiding
    optimizations to improve performance. Here are tutorials on profiling in Python
    which you may find helpful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Profiling Python Code Using timeit and cProfile](https://www.kdnuggets.com/profiling-python-code-using-timeit-and-cprofile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Memory Profiling in Python](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5\. Use NumPy’s Vectorized Operations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For any data processing task, you can always write a Python implementation from
    scratch. But you may not want to do it when working with large arrays of numbers.
    For most common operations—which can be formulated as operations on vectors—that
    you need to perform, you can use NumPy to perform them more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take the following example of element-wise multiplication:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the Python-only and NumPy implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s use the `timeit` function from the `timeit` module to measure the execution
    times for the above implementations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that the NumPy implementation is ~100 times faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this tutorial, we have explored a few Python coding best practices for data
    science. I hope you found them helpful.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in learning Python for data science, check out [5 Free
    Courses Master Python for Data Science](https://www.kdnuggets.com/5-free-courses-to-master-python-for-data-science).
    Happy learning!
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Integrating ChatGPT Into Data Science Workflows: Tips and Best Practices](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Best Practices for Data Science Team Collaboration](https://www.kdnuggets.com/2023/06/5-best-practices-data-science-team-collaboration.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11 Best Practices of Cloud and Data Migration to AWS Cloud](https://www.kdnuggets.com/2023/04/11-best-practices-cloud-data-migration-aws-cloud.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Visualization Best Practices & Resources for Effective Communication](https://www.kdnuggets.com/2023/04/data-visualization-best-practices-resources-effective-communication.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Warehousing and ETL Best Practices](https://www.kdnuggets.com/2023/02/data-warehousing-etl-best-practices.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Practices for Building ETLs for ML](https://www.kdnuggets.com/best-practices-for-building-etls-for-ml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
