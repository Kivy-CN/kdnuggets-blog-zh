- en: Practical Hyperparameter Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/practical-hyperparameter-optimization.html](https://www.kdnuggets.com/2020/02/practical-hyperparameter-optimization.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Pier Paolo Ippolito](https://www.linkedin.com/in/pierpaolo28/), The University
    of Southampton**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e7d267de83d374a4b81eacc48c82c3dc.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Machine Learning models are composed of two different types of parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hyperparameters** = are all the parameters which can be arbitrarily set by
    the user before starting training (eg. number of estimators in Random Forest).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model parameters =** are instead learned during the model training (eg. weights
    in Neural Networks, Linear Regression).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model parameters define how to use input data to get the desired output
    and are learned at training time. Instead, Hyperparameters determine how our model
    is structured in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning models tuning is a type of optimization problem. We have a
    set of hyperparameters and we aim to find the right combination of their values
    which can help us to find either the minimum (eg. loss) or the maximum (eg. accuracy)
    of a function (Figure 1).
  prefs: []
  type: TYPE_NORMAL
- en: This can be particularly important when comparing how different Machine Learning
    models performs on a dataset. In fact, it would be unfair for example to compare
    an SVM model with the best Hyperparameters against a Random Forest model which
    has not been optimized.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this post, the following approaches to Hyperparameter optimization will
    be explained:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manual Search**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Random Search**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Grid Search**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Automated Hyperparameter Tuning (Bayesian Optimization, Genetic Algorithms)**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Artificial Neural Networks (ANNs) Tuning**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure](../Images/a925c643693adacdb575d44ea48f69bb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: ML Optimization Workflow [1]'
  prefs: []
  type: TYPE_NORMAL
- en: In order to demonstrate how to perform Hyperparameters Optimization in Python,
    I decided to perform a complete Data Analysis of the [Credit Card Fraud Detection
    Kaggle Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud). Our objective
    in this article will be to correctly classify which credit card transactions should
    be labelled as fraudulent or genuine (binary classification). This Dataset has
    been anonymized before being distributed, therefore, the meaning of most of the
    features has not been disclosed.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, I decided to use just a subset of the dataset, in order to speed
    up training times and make sure to achieve a perfect balance between the two different
    classes. Additionally, just a limited amount of features has been used to make
    the optimization tasks more challenging. The final dataset is shown in the figure
    below (Figure 2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/ac4eeb1e5f700fc844f3fead905f2a0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Credit Card Fraud Detection Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: All the code used in this article (and more!) is available in my [GitHub repository](https://github.com/pierpaolo28/Kaggle-Challenges/blob/master/credit-card-fraud-model-tuning.ipynb) and [Kaggle
    Profile](https://www.kaggle.com/pierpaolo28/credit-card-fraud-model-tuning).
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First of all, we need to divide our dataset into training and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this article, we will use a Random Forest Classifier as our model
    to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest models are formed by a large number of uncorrelated decision trees,
    which joint together constitute an ensemble. In Random Forest, each decision tree
    makes its own prediction and the overall model output is selected to be the prediction
    which appeared most frequently.
  prefs: []
  type: TYPE_NORMAL
- en: We can now start by calculating our base model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Using the Random Forest Classifier with the default scikit-learn parameters
    lead to 95% overall accuracy. Let’s see now if applying some optimization techniques
    we can achieve better accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Manual Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When using Manual Search, we choose some model hyperparameters based on our
    judgment/experience. We then train the model, evaluate its accuracy and start
    the process again. This loop is repeated until a satisfactory accuracy is scored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main parameters used by a Random Forest Classifier are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**criterion** = the function used to evaluate the quality of a split.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_depth** = maximum number of levels allowed in each tree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**max_features** = maximum number of features considered when splitting a node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**min_samples_leaf** = minimum number of samples which can be stored in a tree
    leaf.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**min_samples_split** = minimum number of samples necessary in a node to cause
    node splitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**n_estimators** = number of trees in the ensemble.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More information about Random Forest parameters can be found on the scikit-learn[ Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
  prefs: []
  type: TYPE_NORMAL
- en: As an example of Manual Search, I tried to specify the number of estimators
    in our model. Unfortunately, this didn’t lead to any improvement in accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Random Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Random Search, we create a grid of hyperparameters and train/test our model
    on just some random combination of these hyperparameters. In this example, I additionally
    decided to perform Cross-Validation on the training set.
  prefs: []
  type: TYPE_NORMAL
- en: When performing Machine Learning tasks, we generally divide our dataset in training
    and test sets. This is done so that to test our model after having trained it
    (in this way we can check it’s performances when working with unseen data). When
    using Cross-Validation, we divide our training set into N other partitions to
    make sure our model is not overfitting our data.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most common used Cross-Validation methods is K-Fold Validation. In
    K-Fold, we divide our training set into N partitions and then iteratively train
    our model using N-1 partitions and test it with the left-over partition (at each
    iteration we change the left-over partition). Once having trained N times the
    model we then average the training results obtained in each iteration to obtain
    our overall training performance results (Figure 3).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/ef469d0bf742072bd0a720a564e8c996.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: K-Fold Cross-Validation [2]'
  prefs: []
  type: TYPE_NORMAL
- en: Using Cross-Validation when implementing Hyperparameters optimization can be
    really important. In this way, we might avoid using some Hyperparameters which
    works really good on the training data but not so good with the test data.
  prefs: []
  type: TYPE_NORMAL
- en: We can now start implementing Random Search by first defying a grid of hyperparameters
    which will be randomly sampled when calling ***RandomizedSearchCV()***. For this
    example, I decided to divide our training set into 4 Folds (***cv = 4***) and
    select 80 as the number of combinations to sample (***n_iter = 80***). Using the
    scikit-learn ***best_estimator_ ***attribute, we can then retrieve the set of
    hyperparameters which performed best during training to test our model.
  prefs: []
  type: TYPE_NORMAL
- en: Once trained our model, we can then visualize how changing some of its Hyperparameters
    can affect the overall model accuracy (Figure 4). In this case, I decided to observe
    how changing the number of estimators and the criterion can affect our Random
    Forest accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f655111ff344502011d6b50d2e15d0ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Criterion vs N Estimators Accuracy Heatmap'
  prefs: []
  type: TYPE_NORMAL
- en: We can then take this a step further by making our visualization more interactive.
    In the chart below, we can examine (using the slider) how varying the number of
    estimators in our model can affect the overall accuracy of our model considered
    the selected min_split and min_leaf parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to play with the graph below by changing the n_estimators parameters,
    zooming in and out of the graph, changing it’s orientation and hovering over the
    single data points to get additional information about them!
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in finding out more about how to create these animations
    using [Plotly](https://towardsdatascience.com/interactive-data-visualization-167ae26016e8),
    my code is available [here](https://www.kaggle.com/kernels/scriptcontent/20590929/download).
    Additionally, this has also been covered in an article written by [Xoel López
    Barata](https://towardsdatascience.com/using-3d-visualizations-to-tune-hyperparameters-of-ml-models-with-python-ba2885eab2e9).
  prefs: []
  type: TYPE_NORMAL
- en: We can now evaluate how our model performed using Random Search. In this case,
    using Random Search leads to a consistent increase in accuracy compared to our
    base model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Grid Seach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Grid Search, we set up a grid of hyperparameters and train/test our model
    on each of the possible combinations.
  prefs: []
  type: TYPE_NORMAL
- en: In order to choose the parameters to use in Grid Search, we can now look at
    which parameters worked best with Random Search and form a grid based on them
    to see if we can find a better combination.
  prefs: []
  type: TYPE_NORMAL
- en: Grid Search can be implemented in Python using scikit-learn ***GridSearchCV() ***function.
    Also on this occasion, I decided to divide our training set into 4 Folds (***cv
    = 4***).
  prefs: []
  type: TYPE_NORMAL
- en: When using Grid Search, all the possible combinations of the parameters in the
    grid are tried. In this case, 128000 combinations (2 × 10 × 4 × 4 × 4 × 10) will
    be used during training. Instead, in the Grid Search example before, just 80 combinations
    have been used.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Grid Search is slower compared to Random Search but it can be overall more effective
    because it can go through the whole search space. Instead, Random Search can be
    faster fast but might miss some important points in the search space.
  prefs: []
  type: TYPE_NORMAL
- en: Automated Hyperparameter Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When using Automated Hyperparameter Tuning, the model hyperparameters to use
    are identified using techniques such as: Bayesian Optimization, Gradient Descent
    and Evolutionary Algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bayesian Optimization can be performed in Python using the Hyperopt library.
    Bayesian optimization uses probability to find the minimum of a function. The
    final aim is to find the input value to a function which can give us the lowest
    possible output value.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization has been proved to be more efficient than random, grid
    or manual search. Bayesian Optimization can, therefore, lead to better performance
    in the testing phase and reduced optimization time.
  prefs: []
  type: TYPE_NORMAL
- en: In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters
    to the function **fmin()**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective Function** = defines the loss function to minimize.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain Space** = defines the range of input values to test (in Bayesian Optimization
    this space creates a probability distribution for each of the used Hyperparameters).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimization Algorithm** = defines the search algorithm to use to select
    the best input values to use in each new iteration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, can also be defined in ***fmin()*** the maximum number of evaluations
    to perform.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian Optimization can reduce the number of search iterations by choosing
    the input values bearing in mind the past outcomes. In this way, we can concentrate
    our search from the beginning on values which are closer to our desired output.
  prefs: []
  type: TYPE_NORMAL
- en: We can now run our Bayesian Optimizer using the **fmin()** function. A **Trials()** object
    is first created to make possible to visualize later what was going on while the **fmin()** function
    was running (eg. how the loss function was changing and how to used Hyperparameters
    were changing).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We can now retrieve the set of best parameters identified and test our model
    using the ***best*** dictionary created during training. Some of the parameters
    have been stored in the ***best*** dictionary numerically using indices, therefore,
    we need first to convert them back as strings before input them in our Random
    Forest.
  prefs: []
  type: TYPE_NORMAL
- en: The classification report using Bayesian Optimization is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Genetic Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Genetic Algorithms tries to apply natural selection mechanisms to Machine Learning
    contexts. They are inspired by the Darwinian process of Natural Selection and
    they are therefore also usually called as Evolutionary Algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine we create a population of N Machine Learning models with some
    predefined Hyperparameters. We can then calculate the accuracy of each model and
    decide to keep just half of the models (the ones that perform best). We can now
    generate some offsprings having similar Hyperparameters to the ones of the best
    models so that to get again a population of N models. At this point, we can again
    calculate the accuracy of each model and repeat the cycle for a defined number
    of generations. In this way, just the best models will survive at the end of the
    process.
  prefs: []
  type: TYPE_NORMAL
- en: In order to implement Genetic Algorithms in Python, we can use the [TPOT Auto
    Machine Learning library](https://epistasislab.github.io/tpot/). TPOT is built
    on the scikit-learn library and it can be used for either regression or classification
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The training report and the best parameters identified using Genetic Algorithms
    are shown in the following snippet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The overall accuracy of our Random Forest Genetic Algorithm optimized model
    is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Artificial Neural Networks (ANNs) Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using KerasClassifier wrapper, it is possible to apply Grid Search and Random
    Search for Deep Learning models in the same way it was done when using scikit-learn
    Machine Learning models. In the following example, we will try to optimize some
    of our ANN parameters such as: how many neurons to use in each layer and which
    activation function and optimizer to use. More examples of Deep Learning Hyperparameters
    optimization are available [here](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The overall accuracy scored using our Artificial Neural Network (ANN) can be
    observed below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can now compare how all the different optimization techniques performed on
    this given exercise. Overall, Random Search and Evolutionary Algorithms performed
    best.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The results obtained, are highly dependent on the chosen grid space and dataset
    used. Therefore, in different situations, different optimization techniques will
    perform better than others.
  prefs: []
  type: TYPE_NORMAL
- en: '*I hope you enjoyed this article, thank you for reading!*'
  prefs: []
  type: TYPE_NORMAL
- en: Contacts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you want to keep updated with my latest articles and projects [follow me
    on Medium](https://medium.com/@pierpaoloippolito28?source=post_page---------------------------) and
    subscribe to my [mailing list](http://eepurl.com/gwO-Dr?source=post_page---------------------------).
    These are some of my contacts details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Personal Blog](https://pierpaolo28.github.io/blog/?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Personal Website](https://pierpaolo28.github.io/?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Medium Profile](https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[GitHub](https://github.com/pierpaolo28?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kaggle](https://www.kaggle.com/pierpaolo28?source=post_page---------------------------)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bibliography
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[1] Hyperparameter optimization: Explanation of automatized algorithms, Dawid
    Kopczyk. Accessed at: [https://dkopczyk.quantee.co.uk/hyperparameter-optimization/](https://dkopczyk.quantee.co.uk/hyperparameter-optimization/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Model Selection, ethen8181\. Accessed at: [http://ethen8181.github.io/machine-learning/model_selection/model_selection.html](http://ethen8181.github.io/machine-learning/model_selection/model_selection.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Pier Paolo Ippolito](https://www.linkedin.com/in/pierpaolo28/)** is
    a final year MSc Artificial Intelligence student at The University of Southampton.
    He is an AI Enthusiast, Data Scientist and RPA Developer.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/hyperparameters-optimization-526348bb8e2d).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Automated Machine Learning Project Implementation Complexities](/2019/11/automl-implementation-complexities.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automated Machine Learning: How do teams work together on an AutoML project?](/2020/01/teams-work-together-automl-project.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Automate Hyperparameter Optimization](/2019/06/automate-hyperparameter-optimization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Hyperparameter Optimization: 10 Top Python Libraries](https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning: GridSearchCV and RandomizedSearchCV, Explained](https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Pipeline Optimization with TPOT](https://www.kdnuggets.com/2021/05/machine-learning-pipeline-optimization-tpot.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SQL Query Optimization Techniques](https://www.kdnuggets.com/2023/03/sql-query-optimization-techniques.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Database Optimization: Exploring Indexes in SQL](https://www.kdnuggets.com/2023/07/database-optimization-exploring-indexes-sql.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
