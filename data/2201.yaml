- en: 'Building Predictive Models: Logistic Regression in Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建预测模型：Python中的逻辑回归
- en: 原文：[https://www.kdnuggets.com/building-predictive-models-logistic-regression-in-python](https://www.kdnuggets.com/building-predictive-models-logistic-regression-in-python)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/building-predictive-models-logistic-regression-in-python](https://www.kdnuggets.com/building-predictive-models-logistic-regression-in-python)
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/9b57e1ab133578eb46103b199d894906.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/9b57e1ab133578eb46103b199d894906.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: When you are getting started with machine learning, logistic regression is one
    of the first algorithms you’ll add to your toolbox. It's a simple and robust algorithm,
    commonly used for binary classification tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当你刚开始学习机器学习时，逻辑回归是你会添加到工具箱中的第一个算法之一。它是一个简单而稳健的算法，通常用于二分类任务。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT。'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Consider a binary classification problem with classes 0 and 1\. Logistic regression
    fits a logistic or sigmoid function to the input data and predicts the probability
    of a query data point belonging to class 1\. Interesting, yes?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个类别为 0 和 1 的二分类问题。逻辑回归将一个逻辑或 sigmoid 函数拟合到输入数据上，并预测查询数据点属于类别 1 的概率。很有趣，对吧？
- en: 'In this tutorial, we’ll learn about logistic regression from the ground up
    covering:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将从基础开始学习逻辑回归，内容包括：
- en: The logistic (or sigmoid) function
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑（或 sigmoid）函数
- en: How we move from linear to logistic regression
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何从线性回归过渡到逻辑回归
- en: How logistic regression works
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归的工作原理
- en: Finally, we’ll build a simple logistic regression model to [classify RADAR returns
    from the ionosphere](https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/52/ionosphere&sa=D&source=editors&ust=1700937825039807&usg=AOvVaw3pi2xfFVRgGw7d3kaG9jKd).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建一个简单的逻辑回归模型来[classify RADAR returns from the ionosphere](https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/52/ionosphere&sa=D&source=editors&ust=1700937825039807&usg=AOvVaw3pi2xfFVRgGw7d3kaG9jKd)。
- en: Logistic Function
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: 'Before we learn more about logistic regression, let''s review how the logistic
    function works. The logistic (or sigmoid function) is given by:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解逻辑回归之前，让我们回顾一下逻辑函数的工作原理。逻辑函数（或称为 sigmoid 函数）由以下公式给出：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/5470699828e45c6e4c6bbbd0ab92f232.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/5470699828e45c6e4c6bbbd0ab92f232.png)'
- en: 'When you plot the sigmoid function, it’ll look like so:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当你绘制 sigmoid 函数时，它看起来是这样的：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/015467f002599f01250517c7d221363c.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/015467f002599f01250517c7d221363c.png)'
- en: 'From the plot, we see that:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中我们可以看出：
- en: When x = 0, σ(x) takes a value of 0.5.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 x = 0 时，σ(x) 的值为 0.5。
- en: When x approaches +∞, σ(x) approaches 1.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 x 接近 +∞ 时，σ(x) 接近 1。
- en: When x approaches -∞, σ(x) approaches 0.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 x 接近 -∞ 时，σ(x) 接近 0。
- en: So for all real inputs, the sigmoid function squishes them to take on values
    in the range [0, 1].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于所有实际输入，sigmoid 函数将它们压缩到 [0, 1] 的范围内。
- en: From Linear Regression to Logistic Regression
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从线性回归到逻辑回归
- en: Let's first discuss why we cannot use linear regression for a binary classification
    problem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们讨论一下为什么我们不能使用线性回归来解决二分类问题。
- en: In a binary classification problem, the output is categorical label (0 or 1).
    Because linear regression predicts continuous-valued outputs which can be less
    than 0 or greater than 1, it does not make sense for the problem at hand.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分类问题中，输出是分类标签（0 或 1）。由于线性回归预测的是连续值的输出，可能小于 0 或大于 1，因此不适用于当前问题。
- en: Also, a straight line may not be the best fit when the output labels belong
    to one of the two categories.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当输出标签属于两类中的一种时，直线可能不是最佳拟合。
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/08e7b90149d1ea9b98cd273de503be32.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/08e7b90149d1ea9b98cd273de503be32.png)'
- en: Image by Author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'So how do we go from linear to logistic regression? In linear regression the
    predicted output is given by:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何从线性回归转向逻辑回归呢？在线性回归中，预测的输出由以下给出：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/5e8d3aac667acaf223b559c5ab0d78b1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/5e8d3aac667acaf223b559c5ab0d78b1.png)'
- en: Where the βs are the coefficients and X_is are the predictors (or features).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中βs 是系数，X_is 是预测变量（或特征）。
- en: 'Without loss of generality, let’s assume X_0 = 1:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不失一般性，假设 X_0 = 1：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/146c38b7a9bf443e3bc8084f0ff8f0fc.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/146c38b7a9bf443e3bc8084f0ff8f0fc.png)'
- en: 'So we can have a more concise expression:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以得到一个更简洁的表达式：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/b13fb0c2ca244c0a3b0abe86c0fe657d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/b13fb0c2ca244c0a3b0abe86c0fe657d.png)'
- en: In logistic regression, we need the predicted probability p_i in the [0,1] interval.
    We know that the logistic function squishes inputs so that they take on values
    in the [0,1] interval.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归中，我们需要预测概率p_i在[0,1]区间内。我们知道逻辑函数将输入值压缩到[0,1]区间内。
- en: 'So plugging in this expression into the logistic function, we have the predicted
    probability as:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所以将这个表达式代入逻辑函数中，我们得到预测概率为：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/61a5d98c740dfeffd22729546d40cb18.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/61a5d98c740dfeffd22729546d40cb18.png)'
- en: Under the Hood of Logistic Regression
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归的内部机制
- en: So how do we find the best fit logistic curve for the given data set? To answer
    this, let’s understand maximum likelihood estimation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何为给定的数据集找到最佳的逻辑回归曲线呢？为了解答这个问题，我们需要理解最大似然估计。
- en: '[Maximum Likelihood Estimation (MLE)](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&sa=D&source=editors&ust=1700937825042844&usg=AOvVaw21aHhVf72aBaA4ufZShBzV) is
    used to estimate the parameters of the logistic regression model by maximizing
    the likelihood function. Let''s break down the process of MLE in logistic regression
    and how the cost function is formulated for optimization using gradient descent.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[最大似然估计 (MLE)](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation&sa=D&source=editors&ust=1700937825042844&usg=AOvVaw21aHhVf72aBaA4ufZShBzV)
    用于通过最大化似然函数来估计逻辑回归模型的参数。让我们深入了解逻辑回归中的MLE过程以及如何使用梯度下降法公式化成本函数进行优化。'
- en: Breaking Down Maximum Likelihood Estimation
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析最大似然估计
- en: 'As discussed, we model the probability that a binary outcome occurs as a function
    of one or more predictor variables (or features):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将二分类结果发生的概率建模为一个或多个预测变量（或特征）的函数：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/6d61301bfda248966710f8d9c80f2b0b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/6d61301bfda248966710f8d9c80f2b0b.png)'
- en: Here, the βs  are the model parameters or coefficients. X_1, X_2,..., X_n are
    the predictor variables.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，βs 是模型参数或系数。X_1, X_2,..., X_n 是预测变量。
- en: MLE aims to find the values of β that maximize the likelihood of the observed
    data. The likelihood function, denoted as L(β), represents the probability of
    observing the given outcomes for the given predictor values under the logistic
    regression model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: MLE 旨在找到使观察到的数据的似然最大化的β值。似然函数，记作L(β)，表示在逻辑回归模型下，给定预测值的情况下观察到给定结果的概率。
- en: Formulating the Log-Likelihood Function
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公式化对数似然函数
- en: To simplify the optimization process, it's common to work with the log-likelihood
    function. Because it transforms products of probabilities into sums of log probabilities.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化优化过程，通常使用对数似然函数。因为它将概率的乘积转换为对数概率的和。
- en: 'The log-likelihood function for logistic regression is given by:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的对数似然函数为：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/e1a36859b3caf1255cfd6dd6ff2fe87e.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/e1a36859b3caf1255cfd6dd6ff2fe87e.png)'
- en: Cost Function and Gradient Descent
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本函数与梯度下降
- en: Now that we know the essence of log-likelihood, let's proceed to formulate the
    cost function for logistic regression and subsequently gradient descent for finding
    the best model parameters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了对数似然的本质，让我们继续制定逻辑回归的成本函数，并随后进行梯度下降，以寻找最佳模型参数
- en: Cost Function for Logistic Regression
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归的成本函数
- en: 'To optimize the logistic regression model, we need to maximize the log-likelihood.
    So we can use the negative log-likelihood as the cost function to minimize during
    training. The negative log-likelihood, often referred to as the logistic loss,
    is defined as:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化逻辑回归模型，我们需要 最大化 对数似然。因此，我们可以使用 负对数似然 作为训练过程中需要 最小化 的成本函数。负对数似然，通常称为逻辑损失，定义为：
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/f5958e87ce2efc03e51e0fc69676c3ec.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/f5958e87ce2efc03e51e0fc69676c3ec.png)'
- en: The goal of the learning algorithm, therefore, is to find the values of ? that
    minimize this cost function. Gradient descent is a commonly used optimization
    algorithm for finding the minimum of this cost function.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，学习算法的目标是找到使这个成本函数最小化的？值。梯度下降是一种常用的优化算法，用于找到这个成本函数的最小值。
- en: Gradient Descent in Logistic Regression
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归中的梯度下降
- en: '[Gradient descent](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Gradient_descent&sa=D&source=editors&ust=1700937825044751&usg=AOvVaw1huVLDtM5ldfX2Ae4YfvwJ) is
    an iterative optimization algorithm that updates the model parameters β in the
    opposite direction of the gradient of the cost function with respect to β. The
    update rule at step t+1 for logistic regression using gradient descent is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[梯度下降](https://www.google.com/url?q=https://en.wikipedia.org/wiki/Gradient_descent&sa=D&source=editors&ust=1700937825044751&usg=AOvVaw1huVLDtM5ldfX2Ae4YfvwJ)
    是一种迭代优化算法，通过与成本函数对β的梯度方向相反的方向更新模型参数β。使用梯度下降进行逻辑回归时，步骤t+1的更新规则如下：'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/6d1026850a60eb36a19268dabe15beec.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/6d1026850a60eb36a19268dabe15beec.png)'
- en: Where α is the learning rate.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中α是学习率。
- en: The partial derivatives can be computed using the chain rule. Gradient descent
    iteratively updates the parameters—until convergence—aiming to minimize the logistic
    loss. As it converges, it finds the optimal values of β that maximize the likelihood
    of the observed data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用链式法则计算偏导数。梯度下降迭代更新参数——直到收敛——旨在最小化逻辑损失。随着收敛，它找到最大化观察数据似然的β的最佳值。
- en: Logistic Regression in Python with Scikit-Learn
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的逻辑回归与Scikit-Learn
- en: Now that you know how logistic regression works, let’s build a predictive model
    using the scikit-learn library.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了逻辑回归的工作原理，让我们使用scikit-learn库构建一个预测模型。
- en: We’ll use the [ionosphere dataset from the UCI machine learning repository](https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/52/ionosphere&sa=D&source=editors&ust=1700937825045668&usg=AOvVaw2GHhc6h9v8DkLk9xMlILvJ) for
    this tutorial. The dataset comprises 34 numerical features. The output is binary,
    one of ‘good’ or ‘bad’ (denoted by ‘g’ or ‘b’). The output label ‘good’ refers
    to RADAR returns that have detected some structure in the ionosphere.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 [UCI机器学习库中的电离层数据集](https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/52/ionosphere&sa=D&source=editors&ust=1700937825045668&usg=AOvVaw2GHhc6h9v8DkLk9xMlILvJ) 进行本教程。数据集包含34个数值特征。输出是二元的，‘good’或‘bad’（用‘g’或‘b’表示）。输出标签‘good’指的是雷达返回信号中检测到的电离层结构。
- en: Step 1 – Loading the Dataset
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤1 – 加载数据集
- en: 'First, download the dataset and read it into a pandas dataframe:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，下载数据集并读取到pandas数据框中：
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Step 2 – Exploring the Dataset
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤2 – 探索数据集
- en: 'Let''s take a look at the first few rows of the dataframe:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看数据框的前几行：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/0abc9ceccca83b2defec4acdc1d9f703.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/0abc9ceccca83b2defec4acdc1d9f703.png)'
- en: Truncated Output of df.head()
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: df.head()的截断输出
- en: 'Let''s get some information about the dataset: the number of non-null values
    and the data types of each of the columns:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 获取有关数据集的一些信息：每列的非空值数量和数据类型：
- en: '[PRE2]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/a5aaae99d5278e347e5418a880cdd2b6.png)
    Truncated Output of df.info()'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/a5aaae99d5278e347e5418a880cdd2b6.png) df.info()的截断输出'
- en: 'Because we have all numeric features, we can also get some descriptive statistics
    using the `describe()` method on the dataframe:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有所有数值特征，我们还可以使用`describe()`方法在数据框上获取一些描述性统计信息：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/85955e4396dd100955cfde03dbbf3410.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/85955e4396dd100955cfde03dbbf3410.png)'
- en: Truncated Output of df.describe()
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 截断输出的df.describe()
- en: 'The column names are currently 0 through 34—including the label. Because the
    dataset does not provide descriptive names for the columns, it just refers to
    them as attribute_1 to attribute_34 if you would like you can rename the columns
    of the data frame as shown:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当前列名为0到34，包括标签。由于数据集没有提供列的描述性名称，它只将其称为attribute_1到attribute_34。如果你愿意，可以如所示重命名数据框的列：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note: This step is purely optional. You can proceed with the default column
    names if you prefer.'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意：这一步是完全可选的。如果你愿意，可以继续使用默认的列名。
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/df9f8a99c2b3225b7a0e5061a3ff9e43.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/df9f8a99c2b3225b7a0e5061a3ff9e43.png)'
- en: Truncated Output of df.head() [After Renaming Columns]
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 截断输出的df.head() [在重命名列后]
- en: Step 3 – Renaming Class Labels and Visualizing Class Distribution
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步 – 重命名类别标签并可视化类别分布
- en: 'Because the output class labels are ‘g’ and ‘b’, we need to map them to 1 and
    0 , respectively. You can do it using `map()` or `replace()`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输出类标签是‘g’和‘b’，我们需要将它们分别映射到1和0。你可以使用`map()`或`replace()`来实现：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s also visualize the distribution of the class labels:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以可视化类别标签的分布：
- en: '[PRE7]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/279fd1c0009397d6c1defb62946ad994.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/279fd1c0009397d6c1defb62946ad994.png)'
- en: Distribution of Class Labels
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 类别标签分布
- en: We see that there is an imbalance in the distribution. There are more records
    belonging to class 1 than to class 0\. We’ll handle this class imbalance when
    building the logistic regression model.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到分布中存在不平衡。属于类别1的记录比属于类别0的记录多。在构建逻辑回归模型时，我们将处理这种类别不平衡。
- en: Step 5 – Preprocessing the Dataset
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步 – 数据集预处理
- en: 'Let’s collect the features and output labels like so:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像这样收集特征和输出标签：
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After splitting the dataset into the train and test sets, we need to preprocess
    the dataset.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据集拆分为训练集和测试集之后，我们需要对数据集进行预处理。
- en: When there are many numeric features—each on a potentially different scale—we
    need to preprocess the numeric features. A common method is to transform them
    such that they follow a distribution with zero mean and unit variance.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当有许多数值特征——每个特征可能有不同的尺度——我们需要对这些数值特征进行预处理。一种常见的方法是将它们转换为均值为零且方差为一的分布。
- en: The `StandardScaler` from scikit-learn’s preprocessing module helps us achieve
    this.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn的`StandardScaler`帮助我们实现这一点。
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Step 6 – Building a Logistic Regression Model
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步 – 构建逻辑回归模型
- en: Now we can instantiate a logistic regression classifier. The `LogisticRegression`
    class is part of scikit-learn’s linear_model module.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以实例化一个逻辑回归分类器。`LogisticRegression`类是scikit-learn的linear_model模块的一部分。
- en: Notice that we have set the `class_weight` parameter to ‘balanced’. This will
    help us account for the class imbalance. By assigning weights to each class—inversely
    proportional to the number of records in the classes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将`class_weight`参数设置为‘balanced’。这将帮助我们处理类别不平衡的问题。通过为每个类别分配权重——权重与类别中的记录数量成反比。
- en: 'After instantiating the class, we can fit the model to the training dataset:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化类之后，我们可以将模型拟合到训练数据集上：
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Step 7 – Evaluating the Logistic Regression Model
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7步 – 评估逻辑回归模型
- en: You can call the `predict()` method to get the model’s predictions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以调用`predict()`方法来获取模型的预测结果。
- en: In addition to the accuracy score, we can also get a classification report with
    metrics like precision, recall, and F1-score.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 除了准确率，我们还可以获得包含精确度、召回率和F1分数等指标的分类报告。
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Building Predictive Models: Logistic Regression in Python](../Images/1a6416799f97aad89cb5c8f9a9468cf5.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![构建预测模型：Python中的逻辑回归](../Images/1a6416799f97aad89cb5c8f9a9468cf5.png)'
- en: Congratulations, you have coded your first logistic regression model!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你，你已经编写了你的第一个逻辑回归模型！
- en: Conclusion
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this tutorial, we learned about logistic regression in detail: from theory
    and math to coding a logistic regression classifier.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们详细了解了逻辑回归：从理论和数学到编码逻辑回归分类器。
- en: As a next step, try building a logistic regression model for a suitable dataset
    of your choice.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，尝试为您选择的适当数据集构建一个逻辑回归模型。
- en: Dataset Credits
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集来源
- en: 'The Ionosphere dataset is licensed under a [Creative Commons Attribution 4.0
    International](https://www.google.com/url?q=https://creativecommons.org/licenses/by/4.0/legalcode&sa=D&source=editors&ust=1700937825057781&usg=AOvVaw2hz8NeH5w9ltvexC6Yg-wA) (CC
    BY 4.0) license:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 电离层数据集在[创意共享署名 4.0 国际](https://www.google.com/url?q=https://creativecommons.org/licenses/by/4.0/legalcode&sa=D&source=editors&ust=1700937825057781&usg=AOvVaw2hz8NeH5w9ltvexC6Yg-wA)（CC
    BY 4.0）许可证下授权使用。
- en: Sigillito,V., Wing,S., Hutton,L., and Baker,K.. (1989). Ionosphere. UCI Machine
    Learning Repository. https://doi.org/10.24432/C5W01B.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Sigillito, V., Wing, S., Hutton, L., 和 Baker, K. (1989). 电离层。UCI 机器学习库。 https://doi.org/10.24432/C5W01B.
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)**
    是一位来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇点上工作。她的兴趣和专长领域包括 DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编码和喝咖啡！目前，她正在通过编写教程、操作指南、观点文章等方式学习并与开发者社区分享她的知识。Bala
    还创建了引人入胜的资源概述和编码教程。**'
- en: More On This Topic
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较线性回归与逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
- en: '[An Overview of Logistic Regression](https://www.kdnuggets.com/2022/02/overview-logistic-regression.html)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逻辑回归概述](https://www.kdnuggets.com/2022/02/overview-logistic-regression.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 22:n12，3月23日：最佳数据科学书籍…](https://www.kdnuggets.com/2022/n12.html)'
- en: '[Logistic Regression for Classification](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分类的逻辑回归](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
- en: '[How Does Logistic Regression Work?](https://www.kdnuggets.com/2022/07/logistic-regression-work.html)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逻辑回归是如何工作的？](https://www.kdnuggets.com/2022/07/logistic-regression-work.html)'
