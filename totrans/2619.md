# 使用 tune-sklearn 在 PyCaret 中进行贝叶斯超参数优化

> 原文：[https://www.kdnuggets.com/2021/03/bayesian-hyperparameter-optimization-tune-sklearn-pycaret.html](https://www.kdnuggets.com/2021/03/bayesian-hyperparameter-optimization-tune-sklearn-pycaret.html)

[评论](#comments)

**由 [Antoni Baum](https://www.linkedin.com/in/yard1/)，PyCaret 的核心贡献者及 Ray Tune 的贡献者**

![Image for post](../Images/6d8d95a8fe51f5d25a1b7858b0b0be43.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT 事务

* * *

这里有一个每个 [PyCaret](https://github.com/pycaret/pycaret) 用户都很熟悉的情况：在从 `compare_models()` 中选择了一个或两个有前景的模型后，是时候使用 `tune_model()` 来调整其超参数，以挖掘模型的全部潜力了。

[PRE0]

（如果你想了解更多关于 PyCaret——一个开源的低代码 Python 机器学习库，[这个指南](https://pycaret.org/guide/) 是一个很好的起点。）

默认情况下，`tune_model()` 使用了经过验证的 `RandomizedSearchCV` 来自 scikit-learn。然而，并不是所有人都了解 `tune_model()` 提供的各种高级选项。

在这篇文章中，我将向你展示如何利用 [tune-sklearn](https://github.com/ray-project/tune-sklearn/)，这是一个替代 scikit-learn 模型选择模块的最前沿超参数调优技术，使得使用 PyCaret 变得轻而易举。我还将报告一系列基准测试结果，展示 tune-sklearn 如何轻松提升分类模型的性能。

### 随机搜索 vs 贝叶斯优化

超参数优化算法的效率可能差异很大。

随机搜索一直是机器学习的一个重要方法，原因很简单：它容易实现、理解，并且在合理的时间内提供了不错的结果。然而，正如其名所示，它是完全随机的——大量时间可能会花在评估不良配置上。考虑到迭代次数是有限的，优化算法专注于那些被认为有前景的配置，并考虑到已经评估过的配置，是有意义的。

本质上，这就是贝叶斯优化（BO）的理念。BO算法跟踪所有评估，并使用这些数据构建一个“代理概率模型”，这个模型的评估速度远快于ML模型。配置被评估得越多，算法就越有信息，代理模型也就越接近实际的目标函数。这样，算法可以在做出有信息的选择时决定下一步评估哪些配置，而不仅仅是随机采样。如果你想了解更多关于贝叶斯优化的信息，请查看这篇[Will Koehrsen的精彩文章](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)。

幸运的是，PyCaret内置了多个优化库的[封装器](https://pycaret.readthedocs.io/en/latest/api/regression.html#pycaret.regression.tune_model)，在本文中，我们将重点介绍[tune-sklearn](https://github.com/ray-project/tune-sklearn)。

### **tune-sklearn在PyCaret中的应用**

[tune-sklearn](https://docs.ray.io/en/master/tune/api_docs/sklearn.html)是scikit-learn模型选择模块的直接替代品。tune-sklearn提供了一个基于scikit-learn的统一API，允许你访问各种流行的最先进优化算法和库，包括Optuna和scikit-optimize。这个统一的API允许你通过一个参数在许多不同的超参数优化库之间切换。

tune-sklearn由[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)提供支持，这是一种用于实验执行和超参数调整的Python库，适用于任何规模。这意味着你可以在不更改代码的情况下，将调优扩展到多个机器上。

为了使事情更简单，从2.2.0版本开始，tune-sklearn已被集成到PyCaret中。你只需执行`pip install "pycaret[full]"`，所有可选依赖项将自动处理。

![帖子图片](../Images/76a744240ca14371222bc358c86aa1d9.png)

它们是如何协同工作的

[PRE1]

只需在`tune_model()`中添加两个参数，即可通过[Hyperopt](http://hyperopt.github.io/hyperopt/)或[Optuna](https://optuna.org/)将随机搜索切换为tune-sklearn驱动的贝叶斯优化。请记住，PyCaret为所有包含的模型提供了内置的搜索空间，但如果你愿意，也可以传入你自己的搜索空间。

但它们与随机搜索相比如何呢？

### **一个简单的实验**

为了观察贝叶斯优化与随机搜索的对比，我进行了一个非常简单的实验。使用了[ Kaggle 房价数据集](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/datasets)，我使用 PyCaret 创建了两个流行的回归模型——[随机森林](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)和[弹性网络](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html?highlight=elasticnet#sklearn.linear_model.ElasticNet)。然后，我使用 scikit-learn 的随机搜索和 tune-sklearn 的 Hyperopt 和 Optuna 搜索器（全部 20 次迭代，最小化 RMSLE）对这两个模型进行了调优。这个过程重复了三次，使用了不同的种子，并对结果进行了平均。以下是代码的简化版本——你可以在[这里](https://gist.github.com/Yard1/97dd054f0a5b154ffdc08df7899ba893)找到完整代码。

[PRE2]

PyCaret 让事情变得如此简单，难道不是吗？无论如何，这里是我在机器上获得的 RMSLE 分数：

实验的 RMSLE 分数

为了让你了解，以下是相较于随机搜索的百分比改进：

相较于随机搜索的百分比改进

所有这些都使用了相同数量的迭代，且时间相当。请记住，考虑到过程的随机性，你的结果可能会有所不同。如果你的改进不明显，尝试将迭代次数（`n_iter`）从默认的 10 增加到 20-30 通常是一个明智的选择。

Ray 的优点在于你可以轻松将规模从单一机器扩展到数十、数百甚至更多的节点集群。虽然 PyCaret 还不支持完全的 Ray 集成，但可以在调优前初始化一个[ Ray 集群](https://docs.ray.io/en/master/cluster/index.html)——tune-sklearn 将自动使用它。

[PRE3]

只要所有必要的配置到位（`RAY_ADDRESS`环境变量），便无需其他操作即可利用 Ray 的分布式计算能力进行超参数调优。由于超参数优化通常是创建 ML 模型中最耗性能的部分，使用 Ray 进行分布式调优可以节省大量时间。

### 结论

为了加快 PyCaret 中的超参数优化，你只需要安装所需的库并更改`tune_model()`中的两个参数——感谢内置的 tune-sklearn 支持，你可以轻松利用 Ray 的分布式计算将规模扩大到本地机器之外。

请务必查看 [PyCaret](https://pycaret.readthedocs.io/)、[Ray Tune](https://docs.ray.io/en/latest/tune/index.html) 和 [tune-sklearn](https://docs.ray.io/en/latest/tune/api_docs/sklearn.html) 的文档，以及 [PyCaret](https://github.com/pycaret/pycaret) 和 [tune-sklearn](https://github.com/ray-project/tune-sklearn) 的 GitHub 仓库。最后，如果你有任何问题或想与社区联系，请加入 [PyCaret 的 Slack](https://pycaret.slack.com/) 和 [Ray 的 Discourse](https://discuss.ray.io/)。

*感谢 Richard Liaw 和 Moez Ali 的校对和建议。*

**个人简介： [Antoni Baum](https://www.linkedin.com/in/yard1/)** 是计算机科学与计量经济学硕士生，也是 PyCaret 的核心贡献者和 Ray Tune 的贡献者。

[原文](https://medium.com/distributed-computing-with-ray/bayesian-hyperparameter-optimization-with-tune-sklearn-in-pycaret-a33b1592662f)。经许可转载。

**相关：**

+   [高级超参数优化/调优算法](/2020/11/algorithms-for-advanced-hyper-parameter-optimization-tuning.html)

+   [5 种轻松进行数据科学的工具](/2021/01/5-tools-effortless-data-science.html)

+   [在 PyCaret 中你做错的 5 件事](/2020/11/5-things-doing-wrong-pycaret.html)

### 更多相关内容

+   [超参数优化：10 个顶级 Python 库](https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html)

+   [PyCaret 中的二分类简介](https://www.kdnuggets.com/2021/12/introduction-binary-classification-pycaret.html)

+   [Python 中使用 PyCaret 的聚类简介](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)

+   [宣布 PyCaret 3.0：开源、低代码 Python 机器学习](https://www.kdnuggets.com/2023/03/announcing-pycaret-30-opensource-lowcode-machine-learning-python.html)

+   [开始使用 PyCaret](https://www.kdnuggets.com/2022/11/getting-started-pycaret.html)

+   [在 Python 中使用网格搜索和随机搜索进行超参数调优](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)
