- en: A Beginner’s Guide to the Top 10 Machine Learning Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初学者指南：十大机器学习算法
- en: 原文：[https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms](https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms](https://www.kdnuggets.com/a-beginner-guide-to-the-top-10-machine-learning-algorithms)
- en: '![A Beginner''s Guide to the Top 10 Machine Learning Algorithms](../Images/c61fade647057aa7f541f92bf60c1c8e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![初学者指南：十大机器学习算法](../Images/c61fade647057aa7f541f92bf60c1c8e.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: One of the fields that underpins data science is machine learning. So, if you
    want to get into data science, understanding machine learning is one of the first
    steps you need to take.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的一个基础领域是机器学习。因此，如果你想进入数据科学，理解机器学习是你需要迈出的第一步。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: But where do you start? You start by understanding the difference between the
    two main types of machine learning algorithms. Only after that, we can talk about
    individual algorithms that should be on your priority list to learn as a beginner.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你从哪里开始呢？你需要了解两种主要机器学习算法的区别。只有在那之后，我们才能谈论作为初学者你应该优先学习的个别算法。
- en: Supervised vs. Unsupervised Machine Learning
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有监督学习与无监督学习
- en: The main distinction between the algorithms is based on how they learn.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的主要区别在于它们的学习方式。
- en: '![A Beginner''s Guide to the Top 10 Machine Learning Algorithms](../Images/9c86c3e47609298d9a1d121b42afa55c.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![初学者指南：十大机器学习算法](../Images/9c86c3e47609298d9a1d121b42afa55c.png)'
- en: Image by Author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: '**Supervised learning algorithms** are trained on a **labeled dataset**. This
    dataset serves as a supervision (hence the name) for learning because some data
    it contains is already labeled as a correct answer. Based on this input, the algorithm
    can learn and apply that learning to the rest of the data.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**有监督学习算法**是在**标记数据集**上训练的。这个数据集作为学习的监督（因此得名），因为其中的一些数据已经标记为正确答案。基于这些输入，算法可以学习并将这些学习应用到其余数据中。'
- en: On the other hand, **unsupervised learning algorithms** learn on an **unlabeled
    dataset**, meaning they engage in finding patterns in data without humans giving
    directions.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**无监督学习算法**在**未标记数据集**上进行学习，这意味着它们在寻找数据中的模式时没有人为的指导。
- en: You can read more in detail about [machine learning algorithms](https://www.stratascratch.com/blog/machine-learning-algorithms-you-should-know-for-data-science/?utm_source=blog&utm_medium=click&utm_campaign=kdn+ml+algorithms+for+beginners)
    and types of learning.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以更详细地阅读关于[机器学习算法](https://www.stratascratch.com/blog/machine-learning-algorithms-you-should-know-for-data-science/?utm_source=blog&utm_medium=click&utm_campaign=kdn+ml+algorithms+for+beginners)和学习类型的内容。
- en: There are also some other types of machine learning, but not for beginners.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他类型的机器学习，但不适合初学者。
- en: Machine Learning Tasks
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习任务
- en: Algorithms are employed to solve two main distinct problems within each type
    of machine learning.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 算法被用于解决每种机器学习类型中的两个主要不同问题。
- en: Again, there are some more tasks, but they are not for beginners.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，还有一些任务，但它们不适合初学者。
- en: '![A Beginner''s Guide to the Top 10 Machine Learning Algorithms](../Images/474bcad6f883c13f494915c57162ba05.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![初学者指南：十大机器学习算法](../Images/474bcad6f883c13f494915c57162ba05.png)'
- en: Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: Supervised Learning Tasks
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有监督学习任务
- en: '**Regression** is the task of predicting a **numerical value**, called **continuous
    outcome variable or dependent variable**. The prediction is based on the predictor
    variable(s) or independent variable(s).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**是预测**数值**的任务，称为**连续结果变量或因变量**。预测是基于预测变量或自变量进行的。'
- en: Think about predicting oil prices or air temperature.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 想想预测油价或空气温度。
- en: '**Classification** is used to predict the **category (class)** of the input
    data. The **outcome variable** here is **categorical or discrete**.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类** 用于预测输入数据的 **类别（类）**。这里的 **结果变量** 是 **分类的或离散的**。'
- en: Think about predicting if the mail is spam or not spam or if the patient will
    get a certain disease or not.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想想预测邮件是否为垃圾邮件，或患者是否会得某种疾病。
- en: Unsupervised Learning Tasks
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习任务
- en: '**Clustering** means **dividing data into subsets or clusters**. The goal is
    to group data as naturally as possible. This means that data points within the
    same cluster are more similar to each other than to data points from other clusters.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类** 意味着 **将数据划分为子集或簇**。目标是尽可能自然地对数据进行分组。这意味着同一簇中的数据点比其他簇中的数据点更相似。'
- en: '**Dimensionality reduction** refers to reducing the number of input variables
    in a dataset. It basically means **reducing the dataset to very few variables
    while still capturing its essence**.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**降维** 指的是减少数据集中输入变量的数量。这基本上意味着 **将数据集减少到很少的变量，同时仍捕捉其本质**。'
- en: Overview of the 10 Machine Learning Algorithms
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 大机器学习算法概述
- en: Here’s an overview of the algorithms I’ll cover.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我将涵盖的算法概述。
- en: '![A Beginner''s Guide to the Top 10 Machine Learning Algorithms](../Images/22605766626df3f651f636f465e1f248.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![初学者指南：前10大机器学习算法](../Images/22605766626df3f651f636f465e1f248.png)'
- en: Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Supervised Learning Algorithms
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习算法
- en: When choosing the algorithm for your problem, it’s important to know what task
    the algorithm is used for.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择适合你问题的算法时，了解该算法的用途非常重要。
- en: As a data scientist, you’ll probably apply these algorithms in Python using
    the [scikit-learn library](https://scikit-learn.org/stable/install.html). Although
    it does (almost) everything for you, it’s advisable that you know at least the
    general principles of each algorithm’s inner workings.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你可能会使用 [scikit-learn 库](https://scikit-learn.org/stable/install.html)
    在 Python 中应用这些算法。虽然它几乎为你做了所有的事情，但建议你至少了解每个算法内部工作的基本原理。
- en: Finally, after the algorithm is trained, you should evaluate how well it performs.
    For that, each algorithm has some standard metrics.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在算法训练完成后，你应该评估它的表现。为此，每个算法都有一些标准指标。
- en: 1\. Linear Regression
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 线性回归
- en: '**Used For:** Regression'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于：** 回归'
- en: '**Description:** [Linear regression draws a straight line](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/1920px-Linear_least_squares_example2.svg.png)
    called a regression line between the variables. This line goes approximately through
    the middle of the data points, thus minimizing the estimation error. It shows
    the predicted value of the dependent variable based on the value of the independent
    variables.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [线性回归绘制了一条直线](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/1920px-Linear_least_squares_example2.svg.png)，称为回归线，连接变量之间的关系。这条线大致穿过数据点的中间，从而最小化估计误差。它显示了基于自变量值的因变量的预测值。'
- en: '**Evaluation Metrics:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: '[Mean Squared Error (MSE)](https://statisticsbyjim.com/regression/mean-squared-error-mse/):
    Represents the average of the squared error, the error being the difference between
    actual and predicted values. The lower the value, the better the algorithm performance.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[均方误差 (MSE)](https://statisticsbyjim.com/regression/mean-squared-error-mse/)：表示平方误差的平均值，误差是实际值和预测值之间的差异。值越低，算法性能越好。'
- en: '[R-Squared](https://statisticsbyjim.com/regression/interpret-r-squared-regression/):
    Represents the variance percentage of the dependent variable that can be predicted
    by the independent variable. For this measure, you should strive to get to 1 as
    close as possible.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R 平方](https://statisticsbyjim.com/regression/interpret-r-squared-regression/)：表示自变量可以预测的因变量的方差百分比。对于这个度量，你应该尽量接近
    1。'
- en: 2\. Logistic Regression
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 逻辑回归
- en: '**Used For:** Classification'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于：** 分类'
- en: '**Description:** It uses a [logistic function](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/2880px-Logistic-curve.svg.png)
    to translate the data values to a binary category, i.e., 0 or 1\. This is done
    using the threshold, usually set at 0.5\. The binary outcome makes this algorithm
    perfect for predicting binary outcomes, such as YES/NO, TRUE/FALSE, or 0/1.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** 它使用 [逻辑函数](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/2880px-Logistic-curve.svg.png)
    将数据值转换为二元类别，即0或1。通常使用0.5的阈值。二元结果使得该算法非常适合预测二元结果，如YES/NO、TRUE/FALSE或0/1。'
- en: '**Evaluation Metrics:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: 'Accuracy: The ratio between correct and total predictions. The closer to 1,
    the better.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度：正确预测与总预测的比率。越接近1越好。
- en: 'Precision: The measure of model accuracy in positive predictions; shown as
    the ratio between correct positive predictions and total expected positive outcomes.
    The closer to 1, the better.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度：模型在正预测中的准确性度量；表示为正确正预测与总期望正结果之间的比率。越接近1越好。
- en: 'Recall: It, too, measures the model’s accuracy in positive predictions. It
    is expressed as a ratio between correct positive predictions and total observations
    made in the class. Read more about these metrics [here](/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率：它同样衡量模型在正预测中的准确性。表示为正确正预测与在类别中所做总观察之间的比率。有关这些指标的更多信息，请参见 [这里](/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)。
- en: '[F1 Score](https://www.v7labs.com/blog/f1-score-guide): The harmonic mean of
    the model’s recall and precision. The closer to 1, the better.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[F1分数](https://www.v7labs.com/blog/f1-score-guide)：模型召回率和精确度的调和平均数。越接近1越好。'
- en: 3\. Decision Trees
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 决策树
- en: '**Used For:** Regression & Classification'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 回归与分类'
- en: '**Description:** [Decision trees](/2020/01/decision-tree-algorithm-explained.html)
    are algorithms that use the hierarchical or tree structure to predict value or
    a class. The root node represents the whole dataset, which then branches into
    decision nodes, branches, and leaves based on the variable values.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [决策树](/2020/01/decision-tree-algorithm-explained.html) 是利用层次或树状结构来预测值或类别的算法。根节点代表整个数据集，然后根据变量值分支成决策节点、分支和叶子。'
- en: '**Evaluation Metrics:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy, precision, recall, and F1 score -> for classification
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度、精确度、召回率和F1分数 -> 用于分类
- en: MSE, R-squared -> for regression
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MSE, R平方 -> 用于回归
- en: 4\. Naive Bayes
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 朴素贝叶斯
- en: '**Used For:** Classification'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 分类'
- en: '**Description:** This is a family of classification algorithms that use [Bayes’
    theorem](https://www.cuemath.com/data/bayes-theorem/), meaning they assume the
    independence between features within a class.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** 这是使用 [贝叶斯定理](https://www.cuemath.com/data/bayes-theorem/) 的分类算法族，即它们假设类别内特征之间是独立的。'
- en: '**Evaluation Metrics:**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度
- en: Precision
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度
- en: Recall
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率
- en: F1 score
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1分数
- en: 5\. K-Nearest Neighbors (KNN)
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. K-最近邻（KNN）
- en: '**Used For:** Regression & Classification'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 回归与分类'
- en: '**Description:** It calculates the distance between the test data and the [k-number
    of the nearest data points](https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning)
    from the training data. The test data belongs to a class with a higher number
    of ‘neighbors’. Regarding the regression, the predicted value is the average of
    the k chosen training points.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** 它计算测试数据与训练数据中 [k个最近数据点](https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning)
    之间的距离。测试数据属于‘邻居’数量较多的类别。关于回归，预测值是k个选定训练点的平均值。'
- en: '**Evaluation Metrics:**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy, precision, recall, and F1 score -> for classification
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确度、精确度、召回率和F1分数 -> 用于分类
- en: MSE, R-squared -> for regression
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MSE, R平方 -> 用于回归
- en: 6\. Support Vector Machines (SVM)
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6\. 支持向量机（SVM）
- en: '**Used For:** Regression & Classification'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 回归与分类'
- en: '**Description:** This algorithm draws a [hyperplane](https://www.spiceworks.com/tech/big-data/articles/what-is-support-vector-machine/)
    to separate different classes of data. It is positioned at the largest distance
    from the nearest points of every class. The higher the distance of the data point
    from the hyperplane, the more it belongs to its class. For regression, the principle
    is similar: hyperplane maximizes the distance between the predicted and actual
    values.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** 该算法绘制一个[超平面](https://www.spiceworks.com/tech/big-data/articles/what-is-support-vector-machine/)来分离不同类别的数据。它的位置距离每个类别的最近点最远。数据点离超平面的距离越远，它越属于该类别。对于回归，原理类似：超平面最大化预测值与实际值之间的距离。'
- en: '**Evaluation Metrics:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy, precision, recall, and F1 score -> for classification
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、精确率、召回率和F1分数 -> 用于分类
- en: MSE, R-squared -> for regression
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差（MSE）、决定系数（R-squared） -> 用于回归
- en: 7\. Random Forest
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7\. 随机森林
- en: '**Used For:** Regression & Classification'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 回归与分类'
- en: '**Description:** [The random forest algorithm](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+ml+algorithms+for+beginners)
    uses an ensemble of decision trees, which then make a decision forest. The algorithm’s
    prediction is based on the prediction of many decision trees. Data will be assigned
    to a class that receives the most votes. For regression, the predicted value is
    an average of all the trees’ predicted values.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [随机森林算法](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+ml+algorithms+for+beginners)使用一组决策树，这些决策树组成一个决策森林。算法的预测基于许多决策树的预测。数据会被分配到获得最多票数的类别中。对于回归，预测值是所有树的预测值的平均值。'
- en: '**Evaluation Metrics:**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy, precision, recall, and F1 score -> for classification
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、精确率、召回率和F1分数 -> 用于分类
- en: MSE, R-squared -> for regression
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差（MSE）、决定系数（R-squared） -> 用于回归
- en: 8\. Gradient Boosting
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8\. 梯度提升
- en: '**Used For:** Regression & Classification'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 回归与分类'
- en: '**Description:** [These algorithms](https://www.javatpoint.com/gbm-in-machine-learning)
    use an ensemble of weak models, with each subsequent model recognizing and correcting
    the previous model''s errors. This process is repeated until the error (loss function)
    is minimized.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [这些算法](https://www.javatpoint.com/gbm-in-machine-learning)使用一组弱模型，每个后续模型识别并纠正前一个模型的错误。这个过程会重复进行，直到错误（损失函数）最小化。'
- en: '**Evaluation Metrics:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: Accuracy, precision, recall, and F1 score -> for classification
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、精确率、召回率和F1分数 -> 用于分类
- en: MSE, R-squared -> for regression
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差（MSE）、决定系数（R-squared） -> 用于回归
- en: Unsupervised Learning Algorithms
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习算法
- en: 9\. K-Means Clustering
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9\. K均值聚类
- en: '**Used For:** Clustering'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 聚类'
- en: '**Description:** [The algorithm](https://realpython.com/k-means-clustering-python/)
    divides the dataset into k-number clusters, each represented by its [centroid
    or geometric center](https://en.wikipedia.org/wiki/Centroid). Through the iterative
    process of dividing data into a k-number of clusters, the goal is to minimize
    the distance between the data points and their cluster’s centroid. On the other
    hand, it also tries to maximize the distance of these data points from the other
    clusters’s centroid. Simply put, the data belonging to the same cluster should
    be as similar as possible and as different as data from other clusters.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [该算法](https://realpython.com/k-means-clustering-python/)将数据集划分为k个簇，每个簇由其[质心或几何中心](https://en.wikipedia.org/wiki/Centroid)表示。通过将数据划分为k个簇的迭代过程，目标是最小化数据点与其簇的质心之间的距离。另一方面，它还试图最大化这些数据点与其他簇的质心之间的距离。简而言之，属于同一簇的数据应该尽可能相似，而与其他簇的数据尽可能不同。'
- en: '**Evaluation Metrics:**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: 'Inertia: The sum of the squared distance of each data point’s distance from
    the closest cluster centroid. The lower the inertia value, the more compact the
    cluster.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惯性：每个数据点距离最近簇质心的距离的平方和。惯性值越低，簇越紧凑。
- en: 'Silhouette Score: It measures the cohesion (data’s similarity within its own
    cluster) and separation (data’s difference from other clusters) of the clusters.
    The value of this score ranges from -1 to +1\. The higher the value, the more
    the data is well-matched to its cluster, and the worse it is matched to other
    clusters.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓分数：它衡量簇的凝聚力（数据在自身簇中的相似性）和分离度（数据与其他簇的差异）。该分数的值范围从-1到+1。值越高，数据越适合其簇，越不适合其他簇。
- en: 10\. Principal Component Analytics (PCA)
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10\. 主成分分析（PCA）
- en: '**Used For:** Dimensionality Reduction'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 降维'
- en: '**Description:** [The algorithm](https://www.turing.com/kb/guide-to-principal-component-analysis)
    reduces the number of variables used by constructing new variables (principal
    components) while still attempting to maximize the captured variance of the data.
    In other words, it limits data to its most common components while not losing
    the essence of the data.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**描述：** [该算法](https://www.turing.com/kb/guide-to-principal-component-analysis)
    通过构建新的变量（主成分）来减少所使用的变量数量，同时仍尝试最大化数据的捕获方差。换句话说，它将数据限制为其最常见的成分，同时不丢失数据的本质。'
- en: '**Evaluation Metrics:**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**评估指标：**'
- en: 'Explained Variance: The percentage of the variance covered by each principal
    component.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释方差：每个主成分覆盖的方差百分比。
- en: 'Total Explained Variance: The percentage of the variance covered by all principal
    components.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总解释方差：所有主成分覆盖的方差百分比。
- en: Conclusion
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Machine learning is an essential part of data science. With these ten algorithms,
    you’ll cover the most common tasks in machine learning. Of course, this overview
    gives you only a general idea of how each algorithm works. So, this is just a
    start.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是数据科学的重要组成部分。通过这十种算法，你将涵盖机器学习中最常见的任务。当然，这个概述仅仅是对每种算法工作原理的一个大致了解。所以，这只是一个开始。
- en: Now, you need to learn how to implement these algorithms in Python and solve
    real problems. In that, I recommend using scikit-learn. Not only because it’s
    a relatively easy-to-use ML library but also because of its [extensive materials](https://scikit-learn.org/stable/index.html)
    on ML algorithms.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你需要学习如何在 Python 中实现这些算法并解决实际问题。在这方面，我推荐使用 scikit-learn。不仅因为它是一个相对易用的机器学习库，还因为它有
    [丰富的资料](https://scikit-learn.org/stable/index.html) 关于机器学习算法。
- en: '[](https://twitter.com/StrataScratch)****[Nate Rosidi](https://twitter.com/StrataScratch)****
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of StrataScratch, a platform helping data scientists
    prepare for their interviews with real interview questions from top companies.
    Nate writes on the latest trends in the career market, gives interview advice,
    shares data science projects, and covers everything SQL.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://twitter.com/StrataScratch)****[内特·罗斯迪](https://twitter.com/StrataScratch)****
    是一位数据科学家和产品策略专家。他还是一名兼职教授，教授分析课程，并且是 StrataScratch 的创始人，该平台帮助数据科学家通过来自顶级公司的真实面试问题来准备面试。内特撰写有关职业市场的最新趋势，提供面试建议，分享数据科学项目，并覆盖所有
    SQL 相关内容。'
- en: More On This Topic
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Essential Machine Learning Algorithms: A Beginner''s Guide](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[必要的机器学习算法：初学者指南](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)'
- en: '[A Beginner''s Guide to End to End Machine Learning](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者终端到终端机器学习指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
- en: '[Beginner’s Guide to Machine Learning with Python](https://www.kdnuggets.com/beginners-guide-to-machine-learning-with-python)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者机器学习 Python 指南](https://www.kdnuggets.com/beginners-guide-to-machine-learning-with-python)'
- en: '[Beginner’s Guide to Machine Learning Testing With DeepChecks](https://www.kdnuggets.com/beginners-guide-to-machine-learning-testing-with-deepchecks)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者机器学习测试指南（使用 DeepChecks）](https://www.kdnuggets.com/beginners-guide-to-machine-learning-testing-with-deepchecks)'
- en: '[Beginner’s Guide to Careers in AI and Machine Learning](https://www.kdnuggets.com/beginners-guide-to-careers-in-ai-and-machine-learning)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者 AI 和机器学习职业指南](https://www.kdnuggets.com/beginners-guide-to-careers-in-ai-and-machine-learning)'
- en: '[KDnuggets News, June 22: Primary Supervised Learning Algorithms…](https://www.kdnuggets.com/2022/n25.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，6月22日：主要监督学习算法……](https://www.kdnuggets.com/2022/n25.html)'
