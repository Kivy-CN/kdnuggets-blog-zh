- en: 'Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Llama，Llama，Llama：3个简单步骤，使用你的内容进行本地RAG
- en: 原文：[https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)
- en: '![3 Simple Steps to Local RAG with Your Content](../Images/c90e6a1c2995d52c9c4f9fc3fc7dc6dd.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![3个简单步骤，使用你的内容进行本地RAG](../Images/c90e6a1c2995d52c9c4f9fc3fc7dc6dd.png)'
- en: Image by Author | Midjourney & Canva
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | Midjourney & Canva
- en: Do you want local RAG with minimal trouble? Do you have a bunch of documents
    you want to treat as a knowledge base to augment a language model with? Want to
    build a chatbot that knows about what you want it to know about?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你想要本地RAG且麻烦最少吗？你是否有一堆文档，想把它们当作知识库来增强语言模型？想要构建一个了解你所需内容的聊天机器人？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Well, here's arguably the easiest way.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这里有一个可以说是最简单的方法。
- en: I might not be the most optimized system for inference speed, vector precision,
    or storage, but it is super easy. Tweaks can be made if desired, but even without,
    what we do in this short tutorial should get your local RAG system fully operational.
    And since we will be using Llama 3, we can also hope for some great results.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能不是最优化的推理速度、向量精度或存储系统，但它超级简单。如果需要，可以进行调整，但即使没有，短时间的教程也应该能让你的本地RAG系统完全运行起来。由于我们将使用Llama
    3，我们也可以期待一些很好的结果。
- en: 'What are we using as our tools today? 3 llamas: Ollama for model management,
    Llama 3 as our language model, and LlamaIndex as our RAG framework. Llama, llama,
    llama.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天使用了什么工具？3只Llama：Ollama用于模型管理，Llama 3作为我们的语言模型，LlamaIndex作为我们的RAG框架。Llama，Llama，Llama。
- en: Let's get started.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 'Step 1: Ollama, for Model Management'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：Ollama，用于模型管理
- en: Ollama can be used to both manage and interact with language models. Today we
    will be using it both for model management and, since LlamaIndex is able to interact
    directly with Ollama-managed models, indirectly for interaction as well. This
    will make our overall process even easier.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Ollama可以用于管理和与语言模型交互。今天我们将使用它进行模型管理，并且由于LlamaIndex能够直接与Ollama管理的模型交互，因此间接用于交互。这将使我们的整体过程更加简便。
- en: We can install Ollama by following the system-specific directions on the application's
    [GitHub repo](https://github.com/ollama/ollama).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过遵循应用程序的[GitHub仓库](https://github.com/ollama/ollama)上的系统特定说明来安装Ollama。
- en: Once installed, we can launch Ollama from the terminal and specify the model
    we wish to use.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装完成，我们可以从终端启动Ollama并指定我们希望使用的模型。
- en: 'Step 2: Llama 3, the Language Model'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步：Llama 3，语言模型
- en: 'Once Ollama is installed and operational, we can download any of the models
    listed on its GitHub repo, or create our own Ollama-compatible model from other
    existing language model implementations. Using the Ollama run command will download
    the specified model if it is not present on your system, and so downloading Llama
    3 8B can be accomplished with the following line:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Ollama安装并正常运行，我们可以从其GitHub仓库下载列出的任何模型，或者从其他现有语言模型实现中创建自己的Ollama兼容模型。使用Ollama运行命令将下载指定的模型，如果系统中未存在该模型，因此可以通过以下命令下载Llama
    3 8B：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Just make sure you have the local storage available to accommodate the 4.7 GB
    download.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 只需确保你有足够的本地存储来容纳4.7 GB的下载。
- en: Once the Ollama terminal application starts with the Llama 3 model as the backend,
    you can go ahead and minimize it. We'll be using LlamaIndex from our own script
    to interact.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Ollama终端应用程序以Llama 3模型作为后台启动，你可以继续并最小化它。我们将使用LlamaIndex从自己的脚本与之进行交互。
- en: 'Step 3: LlamaIndex, the RAG Framework'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步：LlamaIndex，RAG框架
- en: The last piece of this puzzle is [LlamaIndex](https://www.llamaindex.ai/), our
    RAG framework. To use LlamaIndex, you will need to ensure that it is installed
    on your system. As the LlamaIndex packaging and namespace has made recent changes,
    it's best to check the official documentation to get LlamaIndex installed on your
    local environment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个难题的最后一部分是[ LlamaIndex](https://www.llamaindex.ai/)，我们的RAG框架。要使用LlamaIndex，你需要确保它已安装在你的系统上。由于LlamaIndex的打包和命名空间最近发生了变化，最好查看官方文档以确保在本地环境中安装LlamaIndex。
- en: 'Once up and running, and with Ollama running with the Llama3 model active,
    you can save the following to file (adapted from [here](https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/)):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启动并运行，并且Ollama正在运行带有Llama3模型，你可以将以下内容保存到文件中（改编自[这里](https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/)）：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This script is doing the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本执行了以下操作：
- en: Documents are stored in the "data" folder
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档存储在“data”文件夹中
- en: Embeddings model being used to create your RAG documents embeddings is a BGE
    variant from Hugging Face
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于创建RAG文档嵌入的模型是来自Hugging Face的BGE变体
- en: Language model is the aforementioned Llama 3, accessed via Ollama
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型是前面提到的Llama 3，通过Ollama访问
- en: The query being asked of our data ("What are the 5 stages of RAG?") is fitting
    as I dropped a number of RAG-related documents in the data folder
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的数据查询（“RAG的5个阶段是什么？”）是合适的，因为我在数据文件夹中放入了许多与RAG相关的文档
- en: 'And the output of our query:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以及我们查询的输出：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that we would likely want to optimize the script in a number of ways to
    facilitate faster search and maintaining some state (embeddings, for instance),
    but I will leave that for the interested reader to explore.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们可能需要以多种方式优化脚本，以促进更快的搜索并保持某些状态（例如嵌入），但我将留给感兴趣的读者去探索。
- en: Final Thoughts
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终思考
- en: Well, we did it. We managed to get a LlamaIndex-based RAG application using
    Llama 3 being served by Ollama locally in 3 fairly easy steps. There is a lot
    more you could do with this, including optimizing, extending, adding a UI, etc.,
    but simple fact remains that we were able to get our baseline model built with
    but a few lines of code across a minimal set of support apps and libraries.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们做到了。我们成功地在本地使用Ollama在3个相当简单的步骤中搭建了一个基于LlamaIndex的RAG应用程序。你可以做很多其他事情，包括优化、扩展、添加UI等，但简单的事实是，我们能够在几个代码行和一组最小的支持应用程序和库中构建我们的基准模型。
- en: I hope you enjoyed the process.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这个过程。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为[KDnuggets](https://www.kdnuggets.com/)
    & [Statology](https://www.statology.org/)的管理编辑，以及[Machine Learning Mastery](https://machinelearningmastery.com/)的贡献编辑，Matthew的目标是使复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、语言模型、机器学习算法，以及探索新兴的AI。他致力于在数据科学社区中普及知识。Matthew从6岁起就开始编程。'
- en: More On This Topic
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多关于这个话题
- en: '[LangChain + Streamlit + Llama: Bringing Conversational AI to Your…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LangChain + Streamlit + Llama: 将对话式AI带到你的…](https://www.kdnuggets.com/2023/08/langchain-streamlit-llama-bringing-conversational-ai-local-machine.html)'
- en: '[7 Steps to Running a Small Language Model on a Local CPU](https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7 Steps to Running a Small Language Model on a Local CPU](https://www.kdnuggets.com/7-steps-to-running-a-small-language-model-on-a-local-cpu)'
- en: '[GPT4All is the Local ChatGPT for your Documents and it is Free!](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT4All是你的文档的本地ChatGPT，并且它是免费的！](https://www.kdnuggets.com/2023/06/gpt4all-local-chatgpt-documents-free.html)'
- en: '[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RAG 与微调：哪个是提升你的 LLM 应用的最佳工具？](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
- en: '[A Simple Guide to Running LlaMA 2 Locally](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本地运行 LlaMA 2 的简单指南](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)'
- en: '[Octoparse 8.5: Empowering Local Scraping and More](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Octoparse 8.5：增强本地抓取及更多功能](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)'
