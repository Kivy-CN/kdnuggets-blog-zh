# 处理数据不足的 5 种方法

> 原文：[https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)

![如何处理机器学习中的数据不足问题](../Images/03ddce27b377cb1a1c82c79162e21088.png)

图片由编辑提供

在我进行的许多项目中，公司尽管拥有出色的 AI 商业想法，但在意识到他们没有足够的数据时，往往会逐渐感到沮丧……然而，解决方案是存在的！**本文的目的是简要介绍其中一些（我实践中证明有效的）解决方案，而不是列出所有现有的解决方案。**

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您组织的 IT

* * *

数据稀缺的问题非常重要，因为数据是任何 AI 项目的核心。数据集的大小往往是 ML 项目表现不佳的原因。

大多数情况下，数据相关问题是优秀 AI 项目无法完成的主要原因。在一些项目中，你会得出结论，认为没有相关数据或者收集过程太困难且耗时。

监督机器学习模型已成功用于应对各种业务挑战。然而，这些模型对数据的需求很高，其性能在很大程度上依赖于可用的训练数据的大小。在许多情况下，很难创建足够大的训练数据集。

另一个我可以提到的问题是，项目分析师往往低估了处理常见业务问题所需的数据量。我记得自己曾经在收集大型训练数据集时遇到过困难。在为大公司工作时，收集数据更是复杂。

***我需要多少数据？***

好吧，您大约需要模型自由度数量的 10 倍的示例。模型越复杂，越容易出现过拟合，但可以通过验证来避免。**然而，根据使用情况，可以使用更少的数据。**

> ***过拟合：*** 指的是一个模型对训练数据建模得过于精准。当一个模型学习了训练数据中的细节和噪声到影响模型在新数据上表现的程度时，就会发生过拟合。

处理缺失值的问题也值得讨论。特别是如果数据中缺失值的数量足够多（超过5%）。

再次强调，处理缺失值将取决于某些“成功”标准。此外，这些标准因数据集和不同应用（如识别、分割、预测和分类，即使是相同的数据集）而异。

> *重要的是要理解，没有完美的方法来处理缺失数据。*

存在不同的解决方案，但这取决于问题的类型——时间序列分析、机器学习、回归等。

当涉及预测技术时，仅在缺失值不是完全随机观测时使用它们，并且用于填补这些缺失值的变量与缺失值有某种关系，否则可能会产生不准确的估计。

通常，可以使用不同的机器学习算法来确定缺失值。这通过将缺失的特征转化为标签，并使用没有缺失值的列来预测缺失值的列来实现。

根据我的经验，如果你决定构建一个AI驱动的解决方案，你将面临数据不足或缺失数据的问题，**但幸运的是，有办法将这个劣势转化为优势。**

# **数据不足？**

如上所述，无法精确估计AI项目所需的数据最小量。显然，你的项目性质将显著影响你所需的数据量。例如，文本、图像和视频通常需要更多的数据。**然而，为了做出准确的估计，还需要考虑许多其他因素。**

+   **预测的类别数量**

    你的模型期望的输出是什么？基本上，类别或数量越少越好。

+   **模型性能** 如果你计划将产品投入生产，你需要更多的数据。**一个小数据集可能足够用于概念验证，但在生产中，你需要更多的数据。**

通常，小数据集需要具有低复杂度的模型（或[高偏差](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)）以避免[过拟合](https://en.wikipedia.org/wiki/Overfitting)模型到数据上。

# 非技术解决方案

在探索技术解决方案之前，让我们分析一下我们可以做些什么来增强你的数据集。这可能听起来很明显，但在开始AI之前，请尽量通过开发外部和内部工具来获取尽可能多的数据。如果你知道机器学习算法预计要执行的任务，那么你可以提前创建数据收集机制。

> *尝试在组织内建立真实的数据文化。*

为了启动机器学习执行，你可以依赖开源数据。有很多机器学习数据可用，一些公司愿意将其免费提供。

如果你需要外部数据来进行项目，与其他组织建立合作关系以获取相关数据可能会很有益。建立合作关系显然会花费一些时间，但获得的专有数据将为任何竞争对手建立自然障碍。

# 构建一个有用的应用程序，将其免费提供，并利用数据。

我在之前的项目中使用的另一种方法是向客户免费提供对云应用程序的访问权限。进入应用程序的数据可以用于构建机器学习模型。我的前一个客户为医院构建了一个应用程序，并将其免费提供。我们因此收集了大量数据，并成功创建了一个独特的数据集用于我们的机器学习解决方案。确实有助于向客户或投资者展示你已经构建了自己的独特数据集。

![](../Images/e81a847a79f65283b88220dbf58ca256.png)

# 小数据集

根据我的经验，一些常见的方法可以帮助从小数据集中构建预测模型：

![](../Images/417db596333fed2ef9abd993607d884a.png)

一般来说，机器学习算法越简单，它从小数据集中学习得越好。从机器学习的角度看，**小**数据需要具有低复杂性（或高偏差）的模型，以避免过拟合数据。我注意到朴素贝叶斯算法是最简单的分类器之一，因此在相对较小的数据集上学习得非常好。

> ***朴素贝叶斯方法：**** 一组基于应用贝叶斯定理并假设特征对条件独立性的监督学习算法。*

你还可以依赖其他线性模型和决策树。确实，它们在小数据集上也能表现相对良好。基本上，简单模型能比复杂模型（神经网络）更好地从小数据集中学习，因为它们本质上尝试学习的内容更少。

对于非常**小的数据集**，贝叶斯方法通常是最优秀的，尽管结果可能对**先验选择**敏感。我认为朴素贝叶斯分类器和岭回归是最佳的预测模型。

对于**小**数据集，你需要具有少量参数（低复杂性）和/或强先验的模型。你也可以将“先验”解释为你对数据行为的假设。

![](../Images/56e0048653663ded6790e3c968772657.png)

**根据你的业务问题的具体性质和数据集的大小，确实存在许多其他解决方案。**

# 迁移学习

> ***定义：**** 利用现有相关数据或模型来构建机器学习模型的框架。*

迁移学习利用从已学习任务中获得的知识来提升相关任务的性能，通常可以减少所需的训练数据量。

迁移学习技术非常有用，因为它们允许模型利用从另一个数据集或现有机器学习模型中学到的知识，对新领域或任务（即目标领域）进行预测。

**当你没有足够的目标训练数据，而源领域和目标领域有一些相似但并不完全相同时，迁移学习技术应该被考虑。**

![](../Images/f3571fe02830ac79f4da7148726c51f8.png)

天真地聚合模型或不同数据集并不总是有效！如果现有数据集与目标数据非常不同，那么新学习者可能会受到现有数据或模型的负面影响。

迁移学习在你有其他数据集可以用来推断知识时效果很好，但如果你根本没有数据会发生什么呢？这就是数据生成可以发挥作用的地方。当没有数据可用或需要创建比通过聚合获得更多的数据时，就需要使用数据生成。

在这种情况下，存在的小量数据被修改以创建数据的变体来训练模型。例如，可以通过裁剪和缩小一张汽车图片来生成许多汽车的图片。

不幸的是，缺乏高质量标记数据也是数据科学团队面临的最大挑战之一，但通过使用迁移学习和数据生成等技术，可以克服数据稀缺的问题。

迁移学习的另一个常见应用是训练跨客户数据集的模型，以克服冷启动问题。我注意到SaaS公司在将新客户接入其机器学习产品时经常会遇到这个问题。确实，在新客户收集到足够的数据以实现良好的模型性能之前（这可能需要几个月），很难提供价值。

# 数据增强

数据增强意味着增加数据点的数量。在我最新的项目中，我们使用数据增强技术来增加数据集中图像的数量。对于传统的行/列格式数据来说，这意味着增加行数或对象数。

我们别无选择，只能依赖数据增强，原因有二：时间和准确性。每个数据收集过程都涉及成本。这些成本可能是金钱、人力、计算资源，当然还有过程中的时间消耗。

![](../Images/ddc94ff72772016c5a35396446926fd9.png)

因此，我们不得不增强现有数据，以增加输入到机器学习分类器中的数据量，并补偿进一步数据收集所涉及的成本。

> *有很多方法可以增强数据。*

在我们的案例中，你可以旋转原始图像，改变光照条件，或以不同方式裁剪图像，因此可以为一张图像生成不同的子样本。**这样，你可以减少对分类器的过拟合。**

然而，如果你使用过采样方法如SMOTE来生成人工数据，那么很可能会引入过拟合。

> ***过拟合：*** 过拟合模型是指趋势线反映了训练数据中的错误，而不是准确预测未见数据的模型。

**这是在开发AI解决方案时必须考虑的因素。**

![](../Images/197d6782b71346bdea402a2e0f249df1.png)

# **合成数据**

合成数据指的是具有与其“真实”对应物相同的模式和统计属性的虚假数据。基本上，它看起来非常真实，以至于几乎无法判断它不是。

**那么，合成数据的意义是什么？如果我们已经有真实数据，这点为什么重要？**

我见过合成数据的应用，尤其是在我们处理私密数据（如银行、医疗等）时，这使得在某些情况下使用合成数据成为一种更安全的开发方法。

当真实数据不足时，或者针对特定模式的真实数据不足时，通常使用合成数据。其在训练和测试数据集中的使用大致相同。

合成少数类过采样技术（SMOTE）和修改版SMOTE是两种生成合成数据的技术。简单来说，SMOTE将少数类数据点连接起来，创建位于任何两个最近数据点之间直线上的新数据点。

算法计算特征空间中两个数据点之间的距离，将这个距离乘以一个介于0和1之间的随机数，并将新数据点放置在用于距离计算的其中一个数据点的新距离上。

为了生成合成数据，你必须使用训练集来定义模型，这需要验证，然后通过改变感兴趣的参数，可以通过模拟生成合成数据。领域/数据类型很重要，因为它影响整个过程的复杂性。

![](../Images/db543549aa9d731746875d090d0f3264.png)

在我看来，问自己是否拥有足够的数据会揭示出你可能从未发现的不一致性。它有助于突出你认为完美的业务流程中的问题，并使你理解在组织内创建成功数据策略的关键所在。

**[Alexandre Gonfalonieri](https://twitter.com/AGonfalonieri)** 是一位驻扎在巴塞尔的AI顾问和作家。他写作关于脑机接口、M2M经济和新的AI商业模式。他曾在哈佛商业评论和ABC新闻中出现。

[原文](https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92)。转载需经许可。

### 更多相关话题

+   [如何处理机器学习中的分类数据](https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html)

+   [黑色星期五优惠 - 通过 DataCamp 以更低的价格掌握机器学习](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)

+   [如何使用插值技术处理缺失数据](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)

+   [企业如何从机器学习中受益的六种方法](https://www.kdnuggets.com/2022/08/6-ways-businesses-benefit-machine-learning.html)

+   [提升你的机器学习模型的七种方法](https://www.kdnuggets.com/7-ways-to-improve-your-machine-learning-models)

+   [理解贝叶斯定理将如何提升你的数据科学能力的三种方法](https://www.kdnuggets.com/2022/06/3-ways-understanding-bayes-theorem-improve-data-science.html)
