- en: Training Sets, Test Sets, and 10-fold Cross-validation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练集、测试集和10折交叉验证
- en: 原文：[https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Ron Zacharski](http://zacharski.org/), Author of [A Programmer''s Guide
    to Data Mining](http://guidetodatamining.com/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Ron Zacharski](http://zacharski.org/)，[数据挖掘程序员指南](http://guidetodatamining.com/)的作者**'
- en: '* * *'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Editor''s note:** This is an excerpt from Ron Zacharski''s freely available
    online book titled [A Programmer''s Guide to Data Mining: The Ancient Art of the
    Numerati](http://guidetodatamining.com/).'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑注释：** 这是Ron Zacharski的免费在线书籍摘录，标题为[数据挖掘程序员指南：古老的数字艺术](http://guidetodatamining.com/)。'
- en: 'At the end of the previous chapter we worked with three different datasets:
    the women athlete dataset, the iris dataset, and the auto miles-per-gallon one.
    We divided each of these datasets in turn into two subsets. One subset we used
    to construct the classifier. This data set is called the training set. The other
    set was used to evaluate the classifier. That data is called the test set. Training
    set and test set are common terms in data mining.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章的结尾，我们处理了三个不同的数据集：女性运动员数据集、鸢尾花数据集和汽车每加仑行驶里程数据集。我们将这些数据集分别分成了两个子集。一个子集用于构建分类器，这个数据集称为训练集。另一个子集用于评估分类器，这个数据称为测试集。训练集和测试集是数据挖掘中常见的术语。
- en: People in data mining never test with the data they used to train the system.
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据挖掘中的人们从不使用用于训练系统的数据进行测试。
- en: You can see why we don't use the training data for testing if we consider the
    nearest neighbor algorithm. If Marissa Coleman the basketball player from the
    above example, was in our training data, she at 6 foot 1 and 160 pounds would
    be the nearest neighbor of herself. So when evaluating a nearest neighbor algorithm,
    if our test set is a subset of our training data we would always be close to 100%
    accurate. More generally, in evaluating any data mining algorithm, if our test
    set is a subset of our training data the results will be optimistic and often
    overly optimistic. So that doesn’t seem like a great idea.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑最近邻算法，就可以理解为什么我们不使用训练数据进行测试。如果上述例子中的篮球运动员Marissa Coleman在我们的训练数据中，她身高6英尺1寸，体重160磅，那么她自己将是最近的邻居。因此，在评估最近邻算法时，如果我们的测试集是训练数据的一个子集，我们的准确率将始终接近100%。更一般地说，在评估任何数据挖掘算法时，如果我们的测试集是训练数据的子集，结果将会是乐观的，并且往往过于乐观。所以，这似乎不是一个好主意。
- en: How about the idea we used in the last chapter? We divide our data into two
    parts. The larger part we use for training and the smaller part we use for evaluation.
    As it turns out that has its problems too. We could be extremely unlucky in how
    we divide up our data. For example, all the basketball players in our test set
    might be short (like Debbie Black who is only 5 foot 3 and weighs 124 pounds)
    and get classified as marathoners. And all the track people in the test set might
    be short and lightweight for that sport like Tatyana Petrova (5 foot 3 and 108
    pounds) and get classified as gymnasts. With a test set like this, our accuracy
    will be poor. On the other hand, we could be very lucky in our selection of a
    test set. Every person in the test set is the prototypical height and weight for
    their respective sports and our accuracy is near 100%. In either case, the accuracy
    based on a single test set may not reflect the true accuracy when our classifier
    is used with new data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章使用的想法怎么样？我们将数据分成两部分。较大的部分用于训练，较小的部分用于评估。事实证明，这种方法也有其问题。我们可能在数据分割时非常不幸。例如，我们的测试集中的所有篮球运动员可能都很矮（像Debbie
    Black一样，她只有5英尺3英寸高，体重124磅），可能会被分类为马拉松运动员。而测试集中的所有田径运动员可能也都很矮且体重较轻（像Tatyana Petrova一样，她只有5英尺3英寸高，体重108磅），可能会被分类为体操运动员。像这样的测试集会导致我们的准确率很低。另一方面，我们也可能在测试集的选择中非常幸运。测试集中的每个人都是其运动项目的典型身高和体重，我们的准确率接近100%。无论哪种情况，基于单个测试集的准确率可能无法反映我们分类器在处理新数据时的真实准确率。
- en: 'A solution to this problem might be to repeat the process a number of times
    and average the results. For example, we might divide the data in half. Let’s
    call the parts Part 1 and Part 2:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法可能是重复该过程若干次并取平均结果。例如，我们可以将数据分成两部分。我们称这些部分为第1部分和第2部分：
- en: '![Dataset split](../Images/8fab85837aaa7560a11ac3f5aaf1ebde.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![数据集划分](../Images/8fab85837aaa7560a11ac3f5aaf1ebde.png)'
- en: We can use the data in Part 1 to train our classifier and the data in Part 2
    to test it. Then we will repeat the process, this time training with Part 2 and
    testing with Part 1\. Finally we average the results. One problem with this though,
    is that we are only using 1/2 the data for training during each iteration. But
    we can fix this by increasing the number of parts. For example, we can have three
    parts and for each iteration we will train on 2/3 of the data and test on 1/3\.
    So it might look like this
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用第1部分的数据来训练我们的分类器，而使用第2部分的数据来测试它。然后我们将重复这个过程，这次用第2部分进行训练，用第1部分进行测试。最后我们对结果取平均。然而，这样做的一个问题是我们在每次迭代中只使用了1/2的数据来进行训练。但我们可以通过增加部分数量来解决这个问题。例如，我们可以将数据分成三部分，每次迭代时，我们将在2/3的数据上进行训练，并在1/3的数据上进行测试。因此，它可能看起来像这样：
- en: '![Iterations](../Images/18127514c0623615388dde8d724c9245.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![迭代](../Images/18127514c0623615388dde8d724c9245.png)'
- en: In data mining, the most common number of parts is 10, and this method is called
    ...
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据挖掘中，最常见的部分数量是10，这种方法被称为...
- en: 10-Fold Cross Validation
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10折交叉验证
- en: With this method we have one data set which we divide randomly into 10 parts.
    We use 9 of those parts for training and reserve one tenth for testing. We repeat
    this procedure 10 times each time reserving a different tenth for testing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们有一个数据集，将其随机分成10部分。我们使用其中的9部分进行训练，并保留十分之一用于测试。我们重复这个过程10次，每次保留不同的十分之一用于测试。
- en: Let’s look at an example. Suppose I want to build a classifier that just answers
    yes or no to the question *Is this person a professional basketball player?* My
    data consists of information about 500 basketball players and 500 non-basketball
    players.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一个例子。假设我想建立一个分类器来回答问题*这个人是职业篮球运动员吗？* 我的数据包括500名篮球运动员和500名非篮球运动员的信息。
- en: '![10 fold cross validation](../Images/35380c0a8723567e29d40aa4ab5170a7.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![10折交叉验证](../Images/35380c0a8723567e29d40aa4ab5170a7.png)'
- en: 'Often we will put the final results in a table that looks like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会将最终结果放在如下表格中：
- en: '![Table](../Images/23d72c91d86845ce9ab2903a7a941c71.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![表格](../Images/23d72c91d86845ce9ab2903a7a941c71.png)'
- en: So of the 500 basketball players 372 of them were classified correctly. One
    thing we could do is add things up and say that of the 1,000 people we classified
    652 (372 + 280) of them correctly. So our accuracy is 65.2%. The measures we obtain
    using ten-fold cross-validation are more likely to be truly representative of
    the classifiers performance compared with twofold, or three-fold cross-validation.
    This is so, because each time we train the classifier we are using 90% of our
    data compared with using only 50% for two-fold cross-validation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在500名篮球运动员中，有372人被正确分类。我们可以把它们加起来，说明在1,000人中我们正确分类了652人（372 + 280）。所以我们的准确率是65.2%。通过十折交叉验证获得的测量值相比于二折或三折交叉验证，更可能真正代表分类器的性能。这是因为每次训练分类器时，我们使用了90%的数据，而二折交叉验证只使用了50%。
- en: '![Graphic](../Images/2ad062601a62e17bdff1bd99b62f42ce.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2ad062601a62e17bdff1bd99b62f42ce.png)'
- en: 'To read more from this particular discussion, see [chapter 5](http://guidetodatamining.com/chapter5/)
    of Ron Zacharski''s [A Programmer''s Guide to Data Mining: The Ancient Art of
    the Numerati](http://guidetodatamining.com/).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要阅读更多关于这一讨论的内容，请参见Ron Zacharski的[《程序员的数据挖掘指南：古老的Numerati艺术》第五章](http://guidetodatamining.com/chapter5/)。
- en: '**Bio: [Ron Zacharski](http://zacharski.org/)** is a Zen Buddhist monk and
    computational linguist living in Las Cruces, New Mexico, and the author of "A
    Programmer''s Guide to Data Mining: The Ancient Art of the Numerati." His Erdõs
    number is 3\. He has a scientific productivity h-index of 14 and g-index of 41.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介： [Ron Zacharski](http://zacharski.org/)** 是一位禅宗僧侣和计算语言学家，居住在新墨西哥州拉斯克鲁塞斯，他是《程序员的数据挖掘指南：古老的Numerati艺术》的作者。他的Erdõs数是3。他的科学生产力h指数为14，g指数为41。'
- en: '**Related:**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Visualizing Cross-validation Code](/2017/09/visualizing-cross-validation-code.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可视化交叉验证代码](/2017/09/visualizing-cross-validation-code.html)'
- en: '[How (and Why) to Create a Good Validation Set](/2017/11/create-good-validation-set.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何（以及为什么）创建一个好的验证集](/2017/11/create-good-validation-set.html)'
- en: '[Data Mining Techniques, Free Chapter: Derived Variables – Making the Data
    Mean More](/2017/06/jmp-data-mining-techniques-free-chapter.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据挖掘技术，免费章节：派生变量——让数据更有意义](/2017/06/jmp-data-mining-techniques-free-chapter.html)'
- en: More On This Topic
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[5 Ways to Apply AI to Small Data Sets](https://www.kdnuggets.com/2022/02/5-ways-apply-ai-small-data-sets.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将AI应用于小数据集的5种方法](https://www.kdnuggets.com/2022/02/5-ways-apply-ai-small-data-sets.html)'
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过使用自动EDA工具在数据科学评估测试中获胜的方法](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
- en: '[Performing a T-Test in Python](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在Python中执行T检验](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
- en: '[Beyond Accuracy: Evaluating & Improving a Model with the NLP Test Library](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越准确性：使用NLP测试库评估和改进模型](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用TensorFlow和Keras构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[Online Training and Workshops with Nvidia](https://www.kdnuggets.com/2022/07/online-training-workshops-nvidia.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[与Nvidia的在线培训和研讨会](https://www.kdnuggets.com/2022/07/online-training-workshops-nvidia.html)'
