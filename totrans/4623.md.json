["```py\n@DatasetReader.register('imdb')\nImdbDatasetReader(DatasetReaer):\n  def __init__(self, token_indexers, tokenizer):\n    self._tokenizer = tokenizer\n    self._token_indexers = token_indexers\n```", "```py\n@DatasetReader.register('imdb')\nImdbDatasetReader(DatasetReaer):\n    ...\n  def text_to_instance(self, string: str, label: int) -> Instance:\n    fields = {}\n    tokens = self._tokenizer.tokenize(string)\n    fields['tokens'] = TextField(tokens, self._token_indexers)\n    fields['label'] = LabelField(label, skip_indexing=True)\n    return Instance(fields)\n```", "```py\n@Model.register('rnn_classifier')\nclass RnnClassifier(Model):    \ndef __init__(self, vocab, text_field_embedder,\n             seq2vec_encoder, label_namespace):\n  super().__init__(vocab)\n\nself._text_field_embedder = text_field_embedder\n  self._seq2vec_encoder = seq2vec_encoder\n  self._classifier_input_dim = self._seq2vec_encoder.get_output_dim()\n  self._num_labels = vocab.get_vocab_size(namespace=label_namespace)\n\nself._classification_layer = nn.Linear(self._classifier_input_dim, self._num_labels)\n  self._accuracy = CategoricalAccuracy()\n  self._loss = nn.CrossEntropyLoss()\n```", "```py\ndef forward(self, tokens, label=None):\n  embedded_text = self._text_field_embedder(tokens)\n  mask = get_text_field_mask(tokens).float()\n\nencoded_text = self._dropout(self._seq2vec_encoder(embedded_text, mask=mask))\n\nlogits = self._classification_layer(encoded_text)\n  probs = F.softmax(logits, dim=1)\n\noutput_dict = {'logits': logits, 'probs': probs}\n\nif label is not None:\n    loss = self._loss(logits, label.long().view(-1))\n    output_dict['loss'] = loss\n    self._accuracy(logits, label)\n\nreturn output_dict\n```", "```py\ndef get_metrics(self, reset=False):\n  return {'accuracy': self._accuracy.get_metric(reset)}\n```", "```py\nallennlp configure --include-package allennlp_imdb\n```", "```py\n{\n  \"dataset_reader\": {...},\n  \"model\": {...},\n  \"trainer\": {...}\n}\n```", "```py\n\"dataset_reader\": {\n  \"type\": \"imdb\",\n  \"token_indexers\": {\n    \"tokens\": {\n      \"type\": \"single_id\"\n    }\n  },\n  \"tokenizer\": {\n    \"type\": \"word\"\n  }\n}\n```", "```py\n\"model\": {\n  \"type\": \"rnn_classifier\",\n  \"text_field_embedder\": {\n    \"token_embedders\": {\n      \"type\": \"embedding\",\n      ...\n    }\n  },\n  \"seq2vec_encoder\": {\n    \"type\": \"gru\",\n    ...\n  }\n}\n```", "```py\n\"trainer\": {\n  \"num_epochs\": 10,\n  \"optimizer\": {\n    \"type\": \"adam\"\n  }\n}\n```", "```py\nallennlp train \\\n    --include-package allennlp_imdb \\\n    -s /path/to/storage \\\n    -o '{\"trainer\": {\"cuda_device\": 0}} \\\n    training_config/base_cpu.jsonnet\n```", "```py\nallennlp train \\\n    --include-package allennlp_imdb \\\n    -s /path/to/storage \\\n    -o '{\"trainer\": {\"cuda_device\": 0}} \\\n    -o '{\"model\": {\"seq2vec_encoder\": {\"type\": \"lstm\"}}}' \\\n    training_config/base_cpu.jsonnet\n```"]