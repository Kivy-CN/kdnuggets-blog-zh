# 如何检查你在Python中回归模型的质量？

> 原文：[https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html](https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html)

[评论](#comments) ![图像名称](../Images/9e4cbe6f9a615429e47f6d2663996008.png)

### 为什么它很重要（以及为什么你可能会错过它）

尽管对最新深度神经网络架构的复杂性和[xgboost在Kaggle竞赛中的惊人表现](https://blog.kaggle.com/tag/xgboost/)讨论颇多，但对于行业中的大多数人来说，使用[data驱动的分析](https://www.oreilly.com/library/view/creating-a-data-driven/9781491916902/ch01.html)和机器学习（ML）技术，[回归仍然是首选](https://www.surveygizmo.com/resources/blog/regression-analysis/)。

* * *

## 我们的前3大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速通道进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT

* * *

查看2018-19年KDnuggets的投票结果（作者：[Matthew Mayo](https://medium.com/@mattmayo13)）。

[**2018年、2019年最常用的数据科学和机器学习方法**]

*在最新的KDnuggets投票中，读者被问到：你使用了哪些数据科学/机器学习方法和算法……* [www.kdnuggets.com](/2019/04/top-data-science-machine-learning-methods-2018-2019.html)

回归技术有多种形式——线性、非线性、泊松、基于树的——但核心思想在各个领域几乎相同，并且可以应用于金融、医疗、服务行业、制造业、农业等各种预测分析问题。

线性回归是基本技术，[它深深根植于经过时间检验的统计学习和推理理论](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)，并为现代数据科学流程中所有基于回归的算法提供动力。

然而，[**线性回归模型的成功还依赖于一些关于数据本质的基本假设**]，这些数据是模型试图建模的。有关这些假设的简单直观理解，请参阅这篇文章，

[**回归模型假设**]

*我们在使用线性回归建模响应与预测变量之间的关系时做了一些假设……* [www.jmp.com](https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions.html)

因此，通过验证这些假设是否“合理”地被满足（通常使用视觉分析方法，这些方法会受到解释的影响）来检查你的线性回归模型的质量是非常重要的。

> 问题在于，检查模型质量往往是数据科学任务流程中的一个次要方面，因为其他优先级更高的任务，如预测、缩放、部署和模型调优，往往占据主导地位。

这个断言听起来是否太过大胆？其实有一个简单的测试。

在一个行业标准的基于**Python**的数据科学工具链中，你有多少次使用了**Pandas**、**NumPy**、**Scikit-learn**，甚至**PostgreSQL**来进行数据获取、清洗、可视化，以及最终构建和调优你的机器学习模型？我想应该是很多次吧？

那么，你有多少次使用过 [**statsmodels** 库](http://www.statsmodels.org/devel/index.html) 通过运行 [拟合优度测试](https://www.statisticshowto.datasciencecentral.com/goodness-of-fit-test/) 来检验模型？

在一个**基于 Python 的数据科学学习轨迹**中，这种情况非常常见，

![figure-name](../Images/cb1e308ec23bdb945d0601b004ce3e41.png)

“有没有什么遗漏？”这个问题的答案是肯定的！

![figure-name](../Images/c1720435d2c50d68b6bf859f29b66f6a.png)

讨论关于 [正则化](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a)、[偏差-方差权衡](http://scott.fortmann-roe.com/docs/BiasVariance.html) 或可扩展性（学习和复杂性曲线）图表的内容经常出现。但对于以下图表和列表的讨论是否足够充分呢？

+   残差与预测变量的图表

+   拟合值与残差的图

+   归一化残差的直方图

+   归一化残差的 Q-Q 图

+   残差的 Shapiro-Wilk 正态性测试

+   残差的 Cook 距离图

+   预测特征的方差膨胀因子（VIF）

很明显，对于机器学习流程的这部分，你必须戴上 [统计学家的帽子](https://towardsdatascience.com/statistics-for-people-in-a-hurry-a9613c0ed0b)，不仅仅是数据挖掘专业人员。

![figure-name](../Images/de8063c990e653f183c1d99f45e6d855.png)

### Scikit-learn 的问题

可以安全地假设，大多数 [从统计学家转行的数据科学家](https://www.unece.org/info/media/news/statistics/2017/are-official-statisticians-becoming-data-scientists/doc.html) 会定期对他们的回归模型运行 [拟合优度测试](http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/fit.pdf)。

但许多年轻的数据科学家和分析师在数据驱动建模中严重依赖于像**Scikit-learn**这样的机器学习包，虽然它是一个很棒的库，实际上是一个[机器学习和预测任务的银弹](https://medium.com/analytics-vidhya/scikit-learn-a-silver-bullet-for-basic-machine-learning-13c7d8b248ee)，但不支持基于标准统计测试的模型质量的快速评估。

> 因此，除了使用像 Scikit-learn 这样的机器学习库之外，良好的数据科学管道必须包含一些标准化的代码集，以通过统计测试评估模型的质量。

在本文中，我们展示了多元线性回归问题的标准评估集。我们将使用 statsmodels 库进行回归建模和统计测试。

![figure-name](../Images/29b26bda945bc489ce754dabcd76113b.png)

### 线性回归假设及关键的可视化测试简要概述

**假设**

需要测试的四个关键假设是，

+   **线性**：因变量的期望值是每个自变量的线性函数，其他自变量保持不变（请注意，这并不限制你使用自变量的非线性变换，即你仍然可以使用*x²*和*x*作为预测变量来建模 *f(x) = ax² + bx + c*）。

+   **独立性**：误差（拟合模型的残差）彼此独立。

+   **同方差性** **（常数方差）**：误差的方差对预测变量或响应的方差是恒定的。

+   **正态性**：误差来源于正态分布（均值和方差未知，可以从数据中估算）。请注意，这不像上述前三个假设那样是执行线性回归的必要条件。然而，如果不满足这一假设，你将无法轻松计算所谓的“置信”或“预测”区间，因为无法使用对应高斯分布的著名分析表达式。

对于多元线性回归，从统计推断的角度来看，判断**多重共线性**也至关重要。这个假设认为预测变量之间的线性依赖最小或不存在。

**异常值**也可能成为影响模型质量的问题，因为它们对估计的模型参数具有不成比例的影响。

这里是一个可视化回顾，

![figure-name](../Images/de765e96e96c40a55b15bf3608a42821.png)

**哪些图表可以检查？**

因此，误差项非常重要。

> 但有一个不好的消息。无论我们拥有多少数据，我们永远无法知道真正的误差。我们只能估算并推断数据生成的分布。

因此，**真实误差的代理是残差**，即观测值与拟合值之间的差异。

关键点——我们需要绘制残差，检查其随机性、方差和分布，以评估模型质量。**这是线性模型拟合优度估计所需的视觉分析**。

此外，多重共线性可以从相关矩阵和热图中检查，而数据中的异常值（残差）可以通过所谓的**Cook距离图**来检查。

### 回归模型质量评估示例

这个示例的完整代码库 [可以在作者的Github中找到](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Regression_Diagnostics.ipynb)。

我们使用了来自UCI ML门户的 [混凝土抗压强度预测](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength) 问题。混凝土抗压强度是年龄和成分的高度复杂函数。我们能否从这些参数的测量值中预测强度？

**检查线性关系的变量散点图**

我们可以简单地检查散点图，以视觉检查线性假设。

![figure-name](../Images/6ab0fbb97a7803457aff72bca2caf51d.png)

**检查多重共线性的配对散点图和相关性热图**

我们可以使用 [**seaborn** 库中的**pairplot** 函数](https://seaborn.pydata.org/generated/seaborn.pairplot.html) 来绘制所有组合的配对散点图。

![figure-name](../Images/e92931cf3f7b0bd87890ecd47fbf6566.png)

此外，如果数据已加载到Pandas中，我们可以轻松计算相关矩阵，并将其传递给 [statsmodels的特殊绘图函数](https://www.statsmodels.org/stable/generated/statsmodels.graphics.correlation.plot_corr.html#statsmodels.graphics.correlation.plot_corr) 以可视化相关性热图。

![figure-name](../Images/ee188737403d0b7082d46984c8bc1f82.png)

**使用statsmodel.ols()函数的模型拟合**

主模型拟合使用了statsmodels.OLS方法。这是一个令人惊叹的线性模型拟合工具，感觉非常像R中的强大‘lm’函数。最棒的是，它接受R风格的公式来构建完整或部分模型（即涉及所有或一些预测变量）。

你可能会问，在大数据时代，为什么还要考虑创建部分模型而不是将所有数据都投入？那是因为数据中可能存在混杂或隐含偏差，这只能通过 [**控制某些因素**](https://stats.stackexchange.com/questions/78816/how-do-you-control-for-a-factor-variable) 来解决。

无论如何，通过该模型拟合得到的总结已经提供了丰富的统计信息，如所有预测变量的t统计量和p值、R平方和调整后的R平方、AIC和BIC等。

![figure-name](../Images/33a5f6f7a0241f3f0c3bb27a0b13c417.png)

**残差与预测变量的图**

接下来，我们可以绘制残差与每个预测变量的关系图，以检查独立性假设。**如果残差在零 x 轴周围均匀随机分布且没有形成特定的簇**，则假设成立。在这个特定问题中，我们观察到一些簇。

![figure-name](../Images/5c405c5508e0063b5ce131990d60db04.png)

**拟合值与残差图检查同方差性**

当我们绘制拟合响应值（根据模型）与残差的关系图时，我们可以清楚地观察到**残差的方差随着响应变量的大小而增加**。因此，问题不符合同方差性，可能需要某种变量变换以提高模型质量。

![figure-name](../Images/541389612dcb9a96d2c2cf463837f56a.png)

**标准化残差的直方图和 Q-Q 图**

为了检查数据生成过程的正态性假设，我们可以简单地绘制标准化残差的直方图和 Q-Q 图。

![figure-name](../Images/b6fc7dfb1fc4c89f7101d7c473777fb8.png)

此外，我们可以对残差进行 Shapiro-Wilk 检验，以检查其正态性。

**使用 Cook’s 距离图进行异常值检测**

Cook’s 距离本质上测量了删除特定观察值的影响。具有较大 Cook’s 距离的点需要仔细检查是否为潜在的异常值。我们可以使用 Statsmodels 中的[异常值影响类](http://www.statsmodels.org/devel/generated/statsmodels.stats.outliers_influence.OLSInfluence.summary_frame.html)绘制 Cook’s 距离。

![figure-name](../Images/73db1323cc8f847f5d25911ef1dd7b37.png)

**方差影响因子**

该数据集的 OLS 模型摘要显示了多重共线性的警告。但如何检查哪些因素导致了它呢？

我们可以计算每个预测变量的[方差影响因子](https://en.wikipedia.org/wiki/Variance_inflation_factor)。它是具有多个项的模型中方差与仅有一个项的模型中方差的比率。同样，我们利用了 Statsmodels 中的[special outlier influence class](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)。

![figure-name](../Images/c84fa117d048f479d572f32db303e3b1.png)

**其他残差诊断**

Statsmodels 提供了多种其他诊断测试以检查模型质量。你可以查看这些页面。

+   [残差诊断测试](https://www.statsmodels.org/stable/stats.html#module-statsmodels.stats.stattools)

+   [拟合优度检验](https://www.statsmodels.org/stable/stats.html#goodness-of-fit-tests-and-measures)

### 总结与思考

在这篇文章中，我们介绍了如何在线性回归中添加**模型质量评估的必要可视化分析**——各种残差图、正态性测试以及多重共线性检查。

还可以考虑创建一个简单的函数套件，能够接受 scikit-learn 类型的估计器，并生成这些图表，以便数据科学家快速检查模型质量。

目前，尽管 scikit-learn 不具备详细的统计测试或模型质量评估的绘图功能，[Yellowbrick](https://www.scikit-yb.org/en/latest/) 是一个有前途的 Python 库，可以为 scikit-learn 对象添加直观的可视化能力。我们希望在不久的将来，统计测试能够直接添加到 scikit-learn ML 估计器中。

如果你有任何问题或想法，请通过 [**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com) 联系作者。此外，你还可以查看作者的 [**GitHub**](https://github.com/tirthajyoti?tab=repositories)**仓库**，获取其他有趣的 Python、R 或 MATLAB 代码片段及机器学习资源。如果你像我一样对机器学习/数据科学充满热情，请随时 [在 LinkedIn 上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) 或 [在 Twitter 上关注我。](https://twitter.com/tirthajyotiS)

[**Tirthajyoti Sarkar - 高级首席工程师 - 半导体、AI、机器学习 - ON…**](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)

*乔治亚理工学院科学硕士 - MS，分析学 这个 MS 项目提供理论与实践…* [www.linkedin.com](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)

**个人简介：[Tirthajyoti Sarkar](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)** 是 ON Semiconductor 的高级首席工程师，负责深度学习/机器学习基础的设计自动化项目。

[原文](https://towardsdatascience.com/how-do-you-check-the-quality-of-your-regression-model-in-python-fa61759ff685)。转载获许可。

**相关：**

+   [为回归问题选择最佳机器学习算法](/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)

+   [选择正确的评估机器学习模型的指标 - 第 1 部分](/2018/04/right-metric-evaluating-machine-learning-models-1.html)

+   [从噪声中分离信号](/2019/06/separating-signal-noise.html)

### 更多相关主题

+   [数据质量维度：用 Great Expectations 确保你的数据质量](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)

+   [使用 Eurybia 检测数据漂移以确保生产 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)

+   [数据质量在成功机器学习模型中的重要性](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)

+   [3 个新的提示工程资源推荐](https://www.kdnuggets.com/3-new-prompt-engineering-resources)

+   [用 Great Expectations 克服数据质量问题](https://www.kdnuggets.com/2023/01/overcome-data-quality-issues-great-expectations.html)

+   [线性回归模型选择：平衡简洁性与复杂性](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)
