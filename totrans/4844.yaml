- en: Complete Guide to Build ConvNet HTTP-Based Application using TensorFlow and
    Flask RESTful Python API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: This tutorial takes you along the steps required to create a convolutional neural
    network (CNN/ConvNet) using TensorFlow and get it into production by allowing
    remote access via a HTTP-based application using Flask RESTful API.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, a CNN is to be built using TensorFlow NN (tf.nn) module. The
    CNN model architecture is created and trained and tested against the CIFAR10 dataset.
    To make the model remotely accessible, a Flask Web application is created using
    Python to receive an uploaded image and return its classification label using
    HTTP. Anaconda3 is used in addition to TensorFlow on Windows with CPU support.
    This tutorial assumes you have a basic understanding of CNN such as layers, strides,
    and padding. Also knowledge about Python is required.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'The tutorial is summarized into the following steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the Environment by Installing Python, TensorFlow, PyCharm, and Flask
    API.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Downloading and Preparing the CIFAR-10 Dataset.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building the CNN Computational Graph using TensorFlow.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Training the CNN.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Saving the Trained CNN Model.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preparing the Test Data and Restoring the Trained CNN Model.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Testing the Trained CNN Model.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building the Flask Web Application.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upload an Image using HTML Form.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating Helper HTML, JavaScript, and CSS Files.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: HTTP-Based Remote Accessing the Trained Model for Prediction.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 1\. Installing Python, TensorFlow, PyCharm, and Flask API
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before starting building the project, it is required to prepare its environment.
    Python is the first tool to start installing because the environment is fully
    dependent on it. If you already have the environment prepared, you can skip the
    first step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '**1.1 Anaconda/Python Installation**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to install the native Python distribution but it is recommended
    to use an all-in-one package such as Anaconda because it does some stuff for you.
    In this project, Anaconda 3 is used. For Windows, the executable file can be downloaded
    from [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows).
    It could be installed easily.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可以安装原生 Python 发行版，但建议使用如 Anaconda 这样的全功能包，因为它会为你完成一些工作。在这个项目中，使用了 Anaconda 3。对于
    Windows，可以从 [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows)
    下载可执行文件。安装起来很简单。
- en: To ensure Anaconda3 is installed properly, the CMD command (*where python*)
    could be issued as in figure 1\. If Anaconda3 is installed properly, its installation
    path will appear in the command output.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保 Anaconda3 安装正确，可以如图 1 所示发出 CMD 命令（*where python*）。如果 Anaconda3 安装正确，命令输出中会出现其安装路径。
- en: '**Figure 1**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1**'
- en: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
- en: '**1.2 TensorFlow Installation**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.2 TensorFlow 安装**'
- en: After installation Python using Anaconda3, next is to install TensorFlow (TF).
    This tutorial uses TF on Windows with CPU support. The installation instructions
    are found in this page [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows).
    This YouTube video might be helpful ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Anaconda3 安装 Python 后，接下来是安装 TensorFlow (TF)。本教程使用支持 CPU 的 Windows 上的 TF。安装说明可以在此页面找到
    [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows)。这个
    YouTube 视频可能会有帮助 ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU))。
- en: 'TF installation steps are as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TF 安装步骤如下：
- en: '1) Creating a conda environment for TF by invoking this command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 通过调用以下命令创建 TF 的 conda 环境：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This creates an empty folder holding the virtual environment (venv) for TF installation.
    The venv is located under Anaconda3 installation directory in this location (\Anaconda3\envs\tensorflow).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建一个空文件夹以保存 TF 安装的虚拟环境（venv）。venv 位于 Anaconda3 安装目录下的此位置（\Anaconda3\envs\tensorflow）。
- en: '2) Activating the venv for TensorFlow installation using this command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 使用以下命令激活 TensorFlow 安装的 venv：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The above command tells that we are inside the venv and any library installation
    will be inside it. The command prompt is expected to be changed after this command
    to be (tensorflow)C:>. After getting into the directory, we are ready to install
    the library.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令表明我们在 venv 内部，任何库安装都将在其中进行。命令提示符在执行此命令后应更改为 (tensorflow)C:>。进入目录后，我们就准备好安装库了。
- en: '3) After activating the venv, the CPU-only version of Windows TensorFlow could
    be installed by issuing this command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 激活 venv 后，可以通过发出以下命令安装 Windows TensorFlow 的 CPU-only 版本：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To test whether TF is installed properly, we can try to import it as in figure
    2\. But remember before importing TF, its venv must be activated. Testing it from
    the CMD, we need to issue the **python** command in order to be able to interact
    with Python. Because no error occurred in the import line, TF is successfully
    installed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 TF 是否安装正确，我们可以尝试如图 2 所示导入它。但请记住，在导入 TF 之前，必须激活其 venv。从 CMD 测试时，我们需要发出 **python**
    命令以便能够与 Python 交互。由于在导入行中没有出现错误，因此 TF 安装成功。
- en: '**Figure 2**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2**'
- en: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
- en: '**1.3 PyCharm Python IDE Installation**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.3 PyCharm Python IDE 安装**'
- en: For this project, it is recommended to use a Python IDE rather than entering
    commands in CMD. The IDE used in this tutorial is PyCharm. Its Windows executable
    file could be downloaded from this page [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows).
    Its installation instructions are pretty simple.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，建议使用 Python IDE 而不是在 CMD 中输入命令。本教程使用的 IDE 是 PyCharm。其 Windows 可执行文件可以从此页面下载 [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows)。其安装说明相当简单。
- en: After downloading and installation PyCharm Python IDE, next is to link it with
    TF. This is done by setting its Python interpreter to the installed Python under
    the TF venv as in figure 3\. This is done by opening the settings of the IDE and
    choosing the Project interpreter to the **python.exe** file installed inside the
    TF venv.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并安装 PyCharm Python IDE 后，接下来是将其与 TF 连接。这是通过将其 Python 解释器设置为 TF venv 下安装的 Python
    来完成的，如图 3 所示。通过打开 IDE 的设置，选择项目解释器为 TF venv 内的 **python.exe** 文件。
- en: '**Figure 3**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3**'
- en: '![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: '**1.4 Flask Installation**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'The last tool to get installed is the Flask RESTful API. It is a library to
    be installed using pip/conda installer under the TF venv using the following CMD
    command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If not already installed, NumPy and SciPy should be installed inside the venv
    in order to be able to read and manipulate images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: By installing Anaconda (Python), TensorFlow, PyCharm, and Flask, we are ready
    to start building the project.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Downloading and Preparing the CIFAR-10 Dataset
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Python version of the 10 classes CIFAR dataset (CIFAR-10) could be downloaded
    from this page [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html).
    The dataset contains 60,000 images divided into training and testing data. There
    are five files holding the training data where each file has 10,000 images. The
    images are RGB of size 32x32x3\. The training files are named **data_batch_1**, **data_batch_2**,
    and so on. There is a single file holding the test data named **test_batch** with
    10,000 images. A metadata file named **batches.meta** is available that holds
    the dataset classes labels which are **airplane**, **automobile**, **bird**, **cat**, **deer**, **dog**, **frog**, **horse**, **ship**,
    and **truck**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Because each file in the dataset is a binary file, it should be decoded in
    order to retrieve the actual image data. For such reason, a function called unpickle_patch
    is created to do such job defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The method accepts the binary file name and returns a dictionary holding details
    about such file. The dictionary holds the data for all 10,000 samples within the
    file in addition to their labels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: In order to decode the entire training data, a new function called get_dataset_images
    is created. That function accepts the dataset path and works only on the training
    data. As a result, it filters the files under this path and returns only files
    starting with **data_batch_**. The testing data is prepared later after building
    and training the CNN.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: For each training file, it is decoded by calling the unpickle_patch function.
    Based on the dictionary returned by such function, the get_dataset_images function
    returns both the images data and their class labels. The images data is retrieved
    from the **‘data’** key and their class labels are retrieved from the **‘labels’** key.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Because the images data are saved as 1D vector, it should be reshaped to be
    of 3 dimensions. This is because TensorFlow accepts the images of such shape.
    For such reason, the get_dataset_images function accepts the number of rows/columns
    in addition to the number of channels in each image as arguments.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation of such function is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By preparing the training data, we can build and train the CNN model using TF.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Building the CNN Computational Graph using TensorFlow
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The computational graph of the CNN is created inside a function called create_CNN.
    It creates a stack of convolution (conv), ReLU, max pooling, dropout, and fully
    connected (FC) layers and returns the results of the last fully connected layer.
    The output of each layer is the input to the next layer. This requires consistency
    between the sizes of outputs and inputs of neighboring layers. Note that for each
    conv, ReLU, and max pooling layers, there are some of parameters to get specified
    such as strides across each dimension and padding.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的计算图在名为`create_CNN`的函数内创建。它创建了一系列卷积（conv）、ReLU、最大池化、丢弃（dropout）和全连接（FC）层，并返回最后一个全连接层的结果。每层的输出是下一层的输入。这要求相邻层之间的输出和输入大小保持一致。请注意，对于每个卷积、ReLU和最大池化层，有一些参数需要指定，例如每个维度的步幅和填充。
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Because the convolution layer applies the convolution operation between the
    input data and the set of filters used, the create_CNN function accepts the input
    data as an input argument. Such data is what returned by the get_dataset_images
    function. The convolution layer is created using the create_conv_layer function.
    The create_conv_layer function accepts the input data, filter size, and number
    of filters and returns the result of convolving the input data with the set of
    filters. The set of filters have their size set according to the depth of the
    input images. The create_conv_layer is defined as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积层在输入数据和所用过滤器集之间应用卷积操作，因此`create_CNN`函数接受输入数据作为输入参数。这样的数据由`get_dataset_images`函数返回。卷积层使用`create_conv_layer`函数创建。`create_conv_layer`函数接受输入数据、过滤器大小和过滤器数量，并返回将输入数据与过滤器集卷积的结果。过滤器集的大小根据输入图像的深度进行设置。`create_conv_layer`定义如下：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Another argument is the probability of keeping neurons in the dropout layer.
    It specifies how much neurons are dropped by the dropout layer. The dropout layer
    is implemented using the dropout_flatten_layer function as shown below. Such function
    returns a flattened array that will be the input to the fully connected layer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个参数是丢弃层中保留神经元的概率。它指定丢弃层丢弃了多少神经元。丢弃层通过`dropout_flatten_layer`函数实现，如下所示。该函数返回一个扁平化的数组，该数组将作为全连接层的输入。
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Because the last FC layer should have number of output neurons equal to the
    number of dataset classes, the number of dataset classes is used as another input
    argument to the create_CNN function. The fully connected layer is created using
    the fc_layer function. Such function accepts the flattened result of the dropout
    layer, the number of features in such flattened result, and number of output neurons
    from such FC layer. Based on number of inputs and outputs, a weights tensor is
    created which get then multiplied by the flattened layer to get the returned result
    of the FC layer.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最后一个FC层应具有等于数据集类别数的输出神经元数量，因此数据集类别数作为另一个输入参数传递给`create_CNN`函数。全连接层使用`fc_layer`函数创建。该函数接受丢弃层的扁平化结果、扁平化结果中的特征数量以及该FC层的输出神经元数量。根据输入和输出的数量，创建一个权重张量，然后将其乘以扁平化层，以获得FC层的返回结果。
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The computational graph after being visualized using TensorBoard is shown in
    figure 4.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化后的计算图如图4所示。
- en: '**Figure 4**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4**'
- en: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使得Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
