# 从零开始：机器学习可解释性的置换特征重要性

> 原文：[https://www.kdnuggets.com/2021/06/from-scratch-permutation-feature-importance-ml-interpretability.html](https://www.kdnuggets.com/2021/06/from-scratch-permutation-feature-importance-ml-interpretability.html)

**作者：[Seth Billiau](https://www.linkedin.com/in/seth-billiau-b4b062136/)，数据科学家和统计学家**

![](../Images/b22185d12db44de4fd434cebf30c3851.png)

照片由 [Arno Senoner](https://unsplash.com/@arnosenoner) 提供，发布在 [Unsplash](https://unsplash.com/photos/ZxA9vV0phGI)

### 介绍

机器学习中的高级主题通常由黑箱模型主导。顾名思义，黑箱模型是复杂的模型，极难理解模型输入如何组合以进行预测。深度学习模型如 [人工神经网络](https://link.springer.com/article/10.1007/s12518-021-00360-9) 以及集成模型如 [随机森林](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)、梯度提升学习器和 [模型堆叠](https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/) 都是黑箱模型的例子，它们在从 [城市规划](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6567884/) 到 [计算机视觉](https://medium.com/swlh/computer-vision-with-convolutional-neural-networks-22f06360cac9) 的各种领域中提供了极为准确的预测。

![](../Images/8975079b777cc8ef90ea8076241d93cc.png)

黑箱模型示意图

然而，使用这些黑箱模型的一个缺点是，很难解释预测变量如何影响预测结果——尤其是使用传统的统计方法时。本文将解释一种替代方法来解释黑箱模型，即置换特征重要性。置换特征重要性是一种强大的工具，允许我们检测数据集中哪些特征具有预测能力，无论我们使用什么模型。

我们将首先讨论传统统计推断和特征重要性之间的差异，以激发对置换特征重要性的需求。然后，我们将解释置换特征重要性并从头实现它，以发现哪些预测变量对预测Blotchville的房价很重要。最后，我们将讨论这种方法的一些缺点，并介绍一些可以帮助我们在未来进行置换特征重要性的包。

### 统计推断与特征重要性

使用传统的参数统计模型时，我们可以依赖统计推断来准确说明我们的输入如何与输出相关。例如，当我们使用线性回归时，我们知道预测变量的一个单位变化对应于输出的*线性*变化。这个变化的幅度在模型拟合过程中被估计，我们可以利用概率理论为这些估计提供不确定性测量。

![](../Images/9eb6adf2cc2ec36a05fd68bede54b580.png)

照片由 [Javier Allegue Barros](https://unsplash.com/@soymeraki) 拍摄，来源于 [Upsplash](https://unsplash.com/photos/0nOP5iHVaZ8)

不幸的是，当使用黑箱模型时，我们通常无法做出这些类型的声明。深度神经网络可能有数百、数千甚至 [百万](https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33)个可训练权重，这些权重将输入预测变量连接到输出预测（ResNet-50具有超过2300万个可训练参数），以及几个非线性激活函数。当处理如此复杂的模型时，分析性地绘制预测变量和预测之间的关系变得极其困难。

特征重要性技术的开发旨在帮助缓解这一解释性危机。特征重要性技术根据每个预测变量改善预测的能力为其分配一个分数。这使我们可以根据预测变量的相对预测能力对模型中的预测变量进行排名。

生成这些特征重要性分数的一种方法是利用随机置换的力量。下一部分解释了如何使用Python执行置换特征重要性。

### 置换特征重要性

特征重要性的基本思想很简单。对预测有用的输入包含有价值的信息。如果通过随机打乱特征值来破坏这些信息，你的预测质量应该会下降。如果质量下降很小，那么原始预测变量中的信息在确定你的预测时影响不大——即使没有它，你的模型仍然很不错。此外，如果下降很大，则原始预测变量中的信息对你的预测有很大影响。

这个想法通过三个简单的步骤实现。假设你已经训练了一个机器学习模型，并记录了一些预测质量的度量（例如：MSE、对数损失等）。对于数据集中的每个预测变量：

1.  在保持其他预测变量的值不变的情况下，随机打乱预测变量中的数据。

1.  基于打乱的值生成新的预测，并评估你新的预测的质量。

1.  通过计算新预测质量相对于原始预测的下降来计算特征重要性分数。

一旦你计算了所有特征的特征重要性分数，你可以根据预测的有用性对它们进行排名。为了更具体地解释置换特征重要性，请考虑以下合成案例研究。

### 案例研究：预测房价

*注意：代码在最具指导性时包括在内。请参阅本指南的完整代码 *[*这里*](https://github.com/sethbilliau/FeatureImportance)*。*

假设[Blotchville](http://www.hcs.harvard.edu/cs50-probability/hw0705.php)的10,000栋房子的价格由四个因素决定：房屋颜色、邻里密度评分、邻里犯罪率评分和邻里教育评分。Blotchville的房屋要么是红色的，要么是蓝色的，因此颜色被编码为一个二进制指示符。三个定量评分被标准化，并且大致呈正态分布。房屋*i c*的价格可以根据以下数据生成方程从这些因素中确定：

![](../Images/2b8a74c54d0e62acac1872934d2494dc.png)

数据生成方程

数据集还包含五个与房价不相关且没有预测能力的其他预测变量。以下是数据集前五行的快照，`df`。

![](../Images/d80fb79133017e0625f51e15d8f20f41.png)

数据集快照

假设我们想训练一个模型来根据其他九个预测变量预测价格。我们可以使用任何黑箱模型，但为了这个例子，我们训练一个随机森林回归模型。为此，我们将数据分为训练集和测试集。然后，我们使用sklearn拟合一个简单的随机森林模型。

[PRE0]

此时，可以花些时间调整随机森林回归器的超参数。但由于这不是一个关于[超参数调整](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)的指南，我将继续使用这个简单的随机森林模型——它将足以说明置换特征重要性的有用性。

评估回归预测质量的一个常用指标是[root mean squared error (RMSE)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)，它是在测试集上进行评估的。让我们计算我们模型预测的RMSE，并将其存储为`rmse_full_mod`。

[PRE1]

现在，我们可以通过打乱每个预测变量并记录RMSE的增加来实现置换特征重要性。这将允许我们评估哪些预测变量对预测有用。以下是从头开始实现此操作的代码。看看你是否可以将这些代码的注释与我们之前的算法匹配起来。

[PRE2]

结果数据框包含置换特征重要性分数。大分数对应于RMSE的大幅增加——这是预测变量被打乱时模型性能变差的证据。检查表格后，我们看到四个数据生成预测变量（教育、颜色、密度和犯罪）的值相对较大，这意味着它们在我们的模型中具有预测能力。另一方面，五个虚拟预测变量的值相对较小，这意味着它们在预测中不那么有用。

![](../Images/ee79363356fd5e28bdbdfb7a808183f2.png)

Permutation Dataframe的结果

我们还可以使用matplotlib图示化我们的置换特征重要性分数，以便更容易比较。

![](../Images/8ef8103386aea8ad2e72be9f404ee06c.png)

置换特征重要性图

从这项分析中，我们获得了关于模型如何进行预测的宝贵洞察。我们看到教育分数是预测房价时提供最有价值信息的预测器。房屋颜色、密度分数和犯罪分数也似乎是重要的预测器。最后，五个虚拟预测器的预测能力似乎不强。事实上，由于去掉虚拟预测器 3 实际上导致 RMSE 下降，我们可能考虑在未来的分析中进行特征选择，移除这些不重要的预测器。

### 置换特征重要性的缺点

![](../Images/176fcc49ddc9f174be73b548a949f6a7.png)

图片来源于 [Martin Esteve](https://unsplash.com/@tme18) 在 [Upsplash](https://unsplash.com/photos/4y8A6Ve-3GE)

虽然我们看到置换特征重要性的许多好处，但同样重要的是要承认其缺点（无意中）。以下是使用置换特征重要性的一些缺点：

1.  **计算时间：**这个过程可能会非常耗费计算资源，因为它需要你遍历每一个预测器并进行预测。如果进行预测的成本不低，或者你有很多预测器，这可能会非常昂贵。

1.  **在多重共线性存在下表现不佳：**如果你的数据集中有相关特征，置换特征重要性可能表现不佳。如果一个预测器中的信息也存储在一个相关的预测器中，那么即使这些预测器中的一个被打乱，模型可能仍然表现良好。

1.  **分数是相对的，而不是绝对的：**置换重要性分数显示了特征在模型中的*相对*预测能力。然而，这些分数在上下文之外并没有实际的有意义的价值——任何分数都可能因为其他分数的不同而变得很好或很差。

1.  **特征重要性仍然不是统计推断：**特征重要性技术只能告诉你预测器的有用性——它们不能提供关于关系性质（如线性、二次等）或预测器效应的大小的任何洞察。置换特征重要性不是统计推断的替代品，而是当无法进行传统推断时的替代解决方案。

### 结论

置换特征重要性是分析黑箱模型和提供机器学习可解释性的一个有价值的工具。有了这些工具，我们可以更好地理解预测器和预测之间的关系，甚至进行更有原则的特征选择。

尽管我们从头实现了排列特征重要性，但有几个软件包提供了复杂的排列特征重要性实现以及其他模型无关的方法。Python 用户应查看 `eli5`、`alibi`、`scikit-learn`、`LIME` 和 `rfpimp` 软件包，而 R 用户则可以使用 `iml`、`DALEX` 和 `vip`。

祝你排列愉快！如果你有任何问题，请随时留言，我会尽力提供解答。

*致谢：非常感谢出色的 Claire Hoffman 校对和编辑这篇文章，并忍受我对牛津逗号的忽视。我也感激 Leo Saenger 阅读这篇文章并提供建议。*

**简介: [Seth Billiau](https://www.linkedin.com/in/seth-billiau-b4b062136/)** 是一名数据科学家和统计学家，拥有哈佛大学统计学A.B.学位，曾任哈佛大学开放数据项目副主席。邮箱: sethbilliau [at] college.harvard.edu

[原文](https://towardsdatascience.com/from-scratch-permutation-feature-importance-for-ml-interpretability-b60f7d5d1fe9)。经许可转载。

**相关：**

+   [数据可视化是有效特征选择的第一步](/2021/06/data-visualization-feature-selection.html)

+   [特征选择 – 你想知道的一切](/2021/06/feature-selection-overview.html)

+   [用于解释和比较机器学习模型的仪表板](/2021/06/dashboards-interpreting-comparing-machine-learning-models.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT 需求

* * *

### 更多相关主题

+   [神经网络预测中排列的重要性](https://www.kdnuggets.com/2022/12/importance-permutation-neural-network-predictions.html)

+   [用 Python 和 Scikit-learn 简化决策树的可解释性](https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html)

+   [使用 SHAP 值进行机器学习模型的可解释性](https://www.kdnuggets.com/2023/08/shap-values-model-interpretability-machine-learning.html)

+   [2022 年特征商店峰会：关于特征工程的免费会议](https://www.kdnuggets.com/2022/10/hopsworks-feature-store-summit-2022-free-conference-feature-engineering.html)

+   [庆祝对数据隐私重要性的认识](https://www.kdnuggets.com/2022/01/celebrating-awareness-importance-data-privacy.html)

+   [数据科学中实验设计的重要性](https://www.kdnuggets.com/2022/08/importance-experiment-design-data-science.html)
