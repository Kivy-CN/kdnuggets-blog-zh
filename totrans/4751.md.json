["```py\n\ninput_str = ”The 5 biggest countries by population in 2017 are China, India, United States, Indonesia, and Brazil.”\ninput_str = input_str.lower()\nprint(input_str)\n\n```", "```py\n\nthe 5 biggest countries by population in 2017 are china, india, united states, indonesia, and brazil.\n\n```", "```py\n\nimport re\ninput_str = ’Box A contains 3 red and 5 white balls, while Box B contains 4 red and 2 blue balls.’\nresult = re.sub(r’\\d+’, ‘’, input_str)\nprint(result)\n\n```", "```py\n\nBox A contains red and white balls, while Box B contains red and blue balls.\n\n```", "```py\n\nimport string\ninput_str = “This &is [an] example? {of} string. with.? punctuation!!!!” # Sample string\nresult = input_str.translate(string.maketrans(“”,””), string.punctuation)\nprint(result)\n\n```", "```py\n\nThis is an example of string with punctuation\n\n```", "```py\n\ninput_str = “ \\t a string example\\t “\ninput_str = input_str.strip()\ninput_str\n\n```", "```py\n\n‘a string example’\n\n```", "```py\n\ninput_str = “NLTK is a leading platform for building Python programs to work with human language data.”\nstop_words = set(stopwords.words(‘english’))\nfrom nltk.tokenize import word_tokenize\ntokens = word_tokenize(input_str)\nresult = [i for i in tokens if not i in stop_words]\nprint (result)\n\n```", "```py\n\n[‘NLTK’, ‘leading’, ‘platform’, ‘building’, ‘Python’, ‘programs’, ‘work’, ‘human’, ‘language’, ‘data’, ‘.’]\n\n```", "```py\n\nfrom sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n\n```", "```py\n\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n```", "```py\n\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nstemmer= PorterStemmer()\ninput_str=”There are several types of stemming algorithms.”\ninput_str=word_tokenize(input_str)\nfor word in input_str:\n    print(stemmer.stem(word))\n\n```", "```py\n\nThere are sever type of stem algorithm.\n\n```", "```py\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nlemmatizer=WordNetLemmatizer()\ninput_str=”been had done languages cities mice”\ninput_str=word_tokenize(input_str)\nfor word in input_str:\n    print(lemmatizer.lemmatize(word))\n\n```", "```py\n\nbe have do language city mouse\n\n```", "```py\n\ninput_str=”Parts of speech examples: an article, to write, interesting, easily, and, of”\nfrom textblob import TextBlob\nresult = TextBlob(input_str)\nprint(result.tags)\n\n```", "```py\n\n[(‘Parts’, u’NNS’), (‘of’, u’IN’), (‘speech’, u’NN’), (‘examples’, u’NNS’), (‘an’, u’DT’), (‘article’, u’NN’), (‘to’, u’TO’), (‘write’, u’VB’), (‘interesting’, u’VBG’), (‘easily’, u’RB’), (‘and’, u’CC’), (‘of’, u’IN’)]\n\n```", "```py\n\ninput_str=”A black television and a white stove were bought for the new apartment of John.”\nfrom textblob import TextBlob\nresult = TextBlob(input_str)\nprint(result.tags)\n\n```", "```py\n\n[(‘A’, u’DT’), (‘black’, u’JJ’), (‘television’, u’NN’), (‘and’, u’CC’), (‘a’, u’DT’), (‘white’, u’JJ’), (‘stove’, u’NN’), (‘were’, u’VBD’), (‘bought’, u’VBN’), (‘for’, u’IN’), (‘the’, u’DT’), (‘new’, u’JJ’), (‘apartment’, u’NN’), (‘of’, u’IN’), (‘John’, u’NNP’)]\n\n```", "```py\n\nreg_exp = “NP: {?*}”\nrp = nltk.RegexpParser(reg_exp)\nresult = rp.parse(result.tags)\nprint(result)\n\n```", "```py\n\n(S (NP A/DT black/JJ television/NN) and/CC (NP a/DT white/JJ stove/NN) were/VBD bought/VBN for/IN (NP the/DT new/JJ apartment/NN)\nof/IN John/NNP)\n\n```"]