- en: The Importance of Data Cleaning in Data Science
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学中数据清洗的重要性
- en: 原文：[https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)
- en: '![The Importance of Data Cleaning in Data Science](../Images/15e040078d2f4f18c16c97412c1f2d88.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![数据科学中数据清洗的重要性](../Images/15e040078d2f4f18c16c97412c1f2d88.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑者提供的图片
- en: In [data science](/2023/07/first-half-2023-data-science-ai-developments.html),
    the accuracy of predictive models is vitally important to ensure any costly errors
    are avoided and that each aspect is working to its optimal level. Once the data
    has been selected and formatted, the data needs to be cleaned, a crucial stage
    of the model development process.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [数据科学](/2023/07/first-half-2023-data-science-ai-developments.html)中，预测模型的准确性至关重要，以确保避免任何高昂的错误，并且每个方面都能达到其**最佳水平**。数据在选择和格式化后，需要进行清洗，这是模型开发过程中的一个关键阶段。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article, we will provide an overview of the importance of data cleaning
    in data science, including what it is, the benefits, the data cleaning process,
    and the commonly used tools.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将概述数据清洗在数据科学中的重要性，包括它是什么、好处、数据清洗过程以及常用工具。
- en: What Is Data Cleaning?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是数据清洗？
- en: In data science, data cleaning is the process of identifying incorrect data
    and fixing the errors so the final dataset is ready to be used. Errors could include
    duplicate fields, incorrect formatting, incomplete fields, irrelevant or inaccurate
    data, and corrupted data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，数据清洗是识别错误数据并修复错误的过程，以使最终的数据集准备好使用。错误可能包括重复字段、格式不正确、不完整字段、无关或不准确的数据以及损坏的数据。
- en: '![The Importance of Data Cleaning in Data Science](../Images/dd67781f627cb4da75af98a8cebd011d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![数据科学中数据清洗的重要性](../Images/dd67781f627cb4da75af98a8cebd011d.png)'
- en: '[Source](https://anchorcomputersoftware.com/solutions/data-quality/data-cleansing)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://anchorcomputersoftware.com/solutions/data-quality/data-cleansing)'
- en: In a data science project, the cleaning stage [comes before validation](https://www.tableau.com/learn/articles/what-is-data-cleaning)
    in the data pipeline. In the pipeline, each stage ingests input and creates output,
    improving the data each step of the way. The benefit of the data pipeline is that
    each step has a specific purpose and is self-contained, meaning the data is thoroughly
    checked.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学项目中，清洗阶段 [在数据管道中优于验证](https://www.tableau.com/learn/articles/what-is-data-cleaning)。在管道中，每个阶段处理输入并生成输出，逐步改进数据。数据管道的好处在于每个步骤都有特定的目的并且自成一体，意味着数据经过彻底检查。
- en: The Importance of Data Cleaning in Data Science
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学中数据清洗的重要性
- en: Data seldom arrives in a readily usable form; in fact, it can be confidently
    stated that data is never flawless. When collected from diverse sources and real-world
    environments, data is bound to contain numerous errors and adopt different formats.
    Hence, the significance of data cleaning arises -- to render the data error-free,
    pertinent, and easily assimilated by models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据很少以易于使用的形式到达；实际上，可以肯定地说数据从未是完美的。当从不同的来源和实际环境中收集数据时，数据必然包含大量错误，并采用不同的格式。因此，数据清洗的重要性便体现出来了——将数据变得无误、相关且易于模型吸收。
- en: When dealing with extensive datasets from multiple sources, errors can occur,
    including duplication or misclassification. These mistakes greatly affect algorithm
    accuracy. Notably, data cleaning and organization can consume [up to 80% of a
    data scientist's time](https://www.projectpro.io/article/why-data-preparation-is-an-important-part-of-data-science/242),
    highlighting its critical role in the data pipeline.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理来自多个来源的大型数据集时，可能会出现错误，包括重复或错误分类。这些错误严重影响算法的准确性。值得注意的是，数据清理和组织可能会消耗 [数据科学家高达80%的时间](https://www.projectpro.io/article/why-data-preparation-is-an-important-part-of-data-science/242)，突显了其在数据处理流程中的关键作用。
- en: Examples of Data Cleaning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理的示例
- en: Below are three examples of how data cleaning can fix errors within datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是三个数据清理如何修复数据集错误的示例。
- en: '**Data Formatting**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据格式化**'
- en: Data formatting involves [transforming data into a specific format](https://guides.auraria.edu/datamanagement/dataformatting#:~:text=Data%20formatting%20is%20the%20decision,to%20the%20naming%20your%20files.)
    or modifying the structure of a dataset. Ensuring consistency and a well-structured
    dataset is crucial to avoid errors during data analysis. Therefore, employing
    various techniques during the cleaning process is necessary to guarantee accurate
    data formatting. This may encompass converting categorical data to numerical values
    and consolidating multiple data sources into a unified dataset.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据格式化涉及 [将数据转换为特定格式](https://guides.auraria.edu/datamanagement/dataformatting#:~:text=Data%20formatting%20is%20the%20decision,to%20the%20naming%20your%20files.)
    或修改数据集的结构。确保数据集的一致性和良好的结构对于避免数据分析中的错误至关重要。因此，在清理过程中采用各种技术是必要的，以保证准确的数据格式化。这可能包括将分类数据转换为数值以及将多个数据源整合为统一的数据集。
- en: '**Empty/ Missing Values**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**空值/缺失值**'
- en: Data cleaning techniques play a crucial role in resolving data issues such as
    missing or empty values. These techniques involve estimating and filling in gaps
    in the dataset using relevant information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理技术在解决缺失或空值等数据问题中起着至关重要的作用。这些技术包括使用相关信息来估算和填补数据集中的空白。
- en: For instance, consider the location field. If the field is empty, scientists
    can populate it with the average location data from the dataset or a similar one.
    Although not flawless, having the most probable location is preferable to having
    no location information at all. This approach ensures improved data quality and
    enhances the overall reliability of the dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑位置字段。如果字段为空，科学家可以用数据集或类似数据集中的平均位置数据填充该字段。虽然不完美，但拥有最可能的位置总比没有位置信息要好。这种方法确保了数据质量的提升，并增强了数据集的整体可靠性。
- en: '**Identifying Outliers**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**识别异常值**'
- en: Within a dataset, certain data points may lack any substantive connection to
    others (e.g., in terms of value or behavior). Consequently, during data analysis,
    these outliers possess the ability to significantly distort results, leading to
    misguided predictions and flawed decision-making. However, by implementing various
    data cleaning techniques, it is possible to identify and eliminate these outliers,
    ultimately ensuring the integrity and relevance of the dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中，某些数据点可能与其他数据点没有实质性的关联（例如，在数值或行为方面）。因此，在数据分析过程中，这些异常值有可能显著扭曲结果，导致误导性的预测和有缺陷的决策。然而，通过实施各种数据清理技术，可以识别并消除这些异常值，从而确保数据集的完整性和相关性。
- en: '![The Importance of Data Cleaning in Data Science](../Images/50b55e1385e359bbeef572c9203af60d.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![数据科学中数据清理的重要性](../Images/50b55e1385e359bbeef572c9203af60d.png)'
- en: '[Source](https://medium.com/donato-story/improving-data-quality-with-outlier-detection-techniques-a-crisp-dm-approach-to-data-preparation-5a04a9eef844)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://medium.com/donato-story/improving-data-quality-with-outlier-detection-techniques-a-crisp-dm-approach-to-data-preparation-5a04a9eef844)'
- en: The Benefits of Data Cleaning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清理的好处
- en: Data cleaning provides a range of benefits that have a significant impact on
    the accuracy, relevance, usability, and analysis of data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理提供了一系列好处，对数据的准确性、相关性、可用性和分析具有显著影响。
- en: '**Accuracy** - Using data cleaning tools and techniques significantly reduces
    errors and inaccuracies contained in a dataset. This is important for data analysis,
    helping to create models that make accurate predictions.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性** - 使用数据清理工具和技术可以显著减少数据集中的错误和不准确之处。这对于数据分析至关重要，有助于创建能够做出准确预测的模型。'
- en: '**Usability** - Once cleaned and correctly formatted, data can be applied to
    a number of use cases, making it much [more accessible](/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)
    so it can be used in a range of project types.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性** - 一旦数据被清理并正确格式化，它可以应用于多个用例，使其变得更加[可访问](/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)，从而可以用于各种项目类型。'
- en: '**Analysis** - Clean data makes the analysis stage much more effective, allowing
    analysts to gain greater insights and deliver more reliable results.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析** - 清洁的数据使得分析阶段更加有效，允许分析师获得更深入的见解并提供更可靠的结果。'
- en: '**Efficient Data Storage** - By removing unnecessary and duplicate data, storage
    costs are reduced as only relevant, valuable data needs to be retained, whether
    that is on an on-site server or a cloud data warehouse.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效的数据存储** - 通过移除不必要和重复的数据，可以减少存储成本，因为只需保留相关的、有价值的数据，无论是存储在本地服务器还是云数据仓库。'
- en: '**Governance** - Data cleaning can help organizations adhere to strict regulations
    and data governance, protecting the privacy of individuals and avoiding any penalties.
    More data compliance laws have been enacted in recent months. An example is the
    recent [Texas consumer privacy law (TDPSA)](https://www.ipvanish.com/blog/tdpsa-texas-consumer-privacy-law/),
    which prohibits certain data practices such as gathering personal customer data
    that is not reasonably necessary for the purpose of collection.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治理** - 数据清理可以帮助组织遵守严格的法规和数据治理，保护个人隐私并避免处罚。最近几个月出台了更多的数据合规法律。例如，最近的[德克萨斯州消费者隐私法（TDPSA）](https://www.ipvanish.com/blog/tdpsa-texas-consumer-privacy-law/)，禁止某些数据实践，如收集不为收集目的合理必要的个人客户数据。'
- en: 'The Data Cleaning Process: 8 Steps'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清理过程：8个步骤
- en: 'The data cleaning stage of the data pipeline is made up of eight common steps:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道的数据清理阶段由八个常见步骤组成：
- en: The removal of duplicates
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复数据的移除
- en: The removal of irrelevant data
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不相关数据的移除
- en: The standardization of capitalization
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大小写标准化
- en: Data type conversion
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据类型转换
- en: The handling of outliers
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值的处理
- en: The fixing of errors
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误的修正
- en: Language Translation
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言翻译
- en: The handling of any missing values
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理任何缺失值
- en: 1\. The Removal of Duplicates
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 重复数据的移除
- en: Large datasets that utilize multiple data sources are highly likely to have
    errors, including duplicates, particularly when new entries haven't undergone
    quality checks. Duplicate data is redundant and consumes unnecessary storage space,
    necessitating data cleansing to enhance efficiency. Common instances of duplicate
    data comprise repetitive email addresses and phone numbers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 利用多个数据源的大型数据集很可能存在错误，包括重复数据，特别是在新条目没有经过质量检查时。重复数据是冗余的，占用不必要的存储空间，需要进行数据清理以提高效率。常见的重复数据包括重复的电子邮件地址和电话号码。
- en: 2\. The Removal of Irrelevant Data
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 不相关数据的移除
- en: To optimize a dataset, it is [crucial to remove irrelevant data fields](https://segment.com/blog/data-cleaning/).
    This will result in faster model processing and enable a more focused approach
    toward achieving specific goals. During the data cleaning stage, any data that
    does not align with the scope of the project will be eliminated, retaining only
    the necessary information required to fulfill the task.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化数据集，[移除不相关的数据字段](https://segment.com/blog/data-cleaning/)是至关重要的。这将导致模型处理更快，并使得更加专注于实现特定目标。在数据清理阶段，将删除任何与项目范围不符的数据，只保留完成任务所需的必要信息。
- en: 3\. The Standardization of Capitalization
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 大小写标准化
- en: Standardizing text in datasets is crucial for ensuring consistency and facilitating
    easy analysis. Correcting capitalization is especially important, as it prevents
    the creation of false categories that could result in messy and confusing data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中文本的标准化对于确保一致性和便于分析至关重要。纠正大小写尤其重要，因为这可以防止创建虚假的类别，从而导致数据混乱和困惑。
- en: 4\. Data Type Conversion
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 数据类型转换
- en: When working with CSV data using Python to manipulate it, analysts often rely
    on Pandas, the go-to data analysis library. However, there are instances where
    Pandas fall short in processing data types effectively. To guarantee accurate
    data conversion, analysts employ cleaning techniques. This ensures that the correct
    data is easily identifiable when applied to real-life projects.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Python处理CSV数据时，分析师通常依赖于Pandas这一数据分析库。然而，有时Pandas在有效处理数据类型方面会有所不足。为了保证数据转换的准确性，分析师采用清理技术。这确保了在应用于实际项目时，正确的数据能够被轻松识别。
- en: 5\. The Handling of Outliers
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 异常值处理
- en: An outlier is a data point [that lacks relevance to other points](https://careerfoundry.com/en/blog/data-analytics/what-is-an-outlier/),
    deviating significantly from the overall context of the dataset. While outliers
    can occasionally offer intriguing insights, they are typically regarded as errors
    that should be removed.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是[缺乏与其他点相关性的数据点](https://careerfoundry.com/en/blog/data-analytics/what-is-an-outlier/)，在数据集的整体背景中偏离显著。虽然异常值有时可以提供有趣的见解，但它们通常被视为应该删除的错误。
- en: 6\. The Fixing of Errors
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 错误修正
- en: Ensuring the effectiveness of a model is crucial, and rectifying errors before
    the data analysis stage is paramount. Such errors often result from manual data
    entry without adequate checking procedures. Examples include phone numbers with
    incorrect digits, email addresses without an "@" symbol, or unpunctuated user
    feedback.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 确保模型的有效性至关重要，在数据分析阶段之前纠正错误是关键。这些错误通常源于手动数据输入而没有足够的检查程序。例如，包括数字错误的电话号码、没有“@”符号的电子邮件地址或没有标点的用户反馈。
- en: 7\. Language Translation
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 语言翻译
- en: Datasets can be gathered from various sources written in different languages.
    However, when using such data for machine translation, evaluation tools typically
    rely on [monolingual Natural Language Processing (NLP)](https://nlpcloud.com/multilingual-nlp-how-to-perform-nlp-in-non-english-languages.html)
    models, which can only handle one language at a time. Thankfully, during the data
    cleaning phase, AI tools can come to the rescue by converting all the data into
    a unified language. This ensures greater coherence and compatibility throughout
    the translation process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从不同语言的各种来源收集。然而，在使用这些数据进行机器翻译时，评估工具通常依赖于[单语自然语言处理（NLP）](https://nlpcloud.com/multilingual-nlp-how-to-perform-nlp-in-non-english-languages.html)模型，这些模型一次只能处理一种语言。幸运的是，在数据清理阶段，AI
    工具可以通过将所有数据转换为统一语言来提供帮助。这确保了翻译过程中的更大连贯性和兼容性。
- en: 8\. The Handling of Any Missing Values
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 处理任何缺失值
- en: One of the last steps in data cleaning involves addressing missing values. This
    can be achieved by either removing records that have missing values or employing
    statistical techniques to fill in the gaps. A comprehensive understanding of the
    dataset is crucial in making these decisions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理的最后步骤之一涉及处理缺失值。这可以通过删除缺少值的记录或使用统计技术填补空白来实现。全面了解数据集对于做出这些决策至关重要。
- en: Summary
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The importance of data cleaning in data science can never be underestimated
    as it can significantly impact the accuracy and overall success of a data model.
    With thorough data cleaning, the data analysis stage is likely to output flawed
    results and incorrect predictions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中数据清理的重要性不能被低估，因为它会显著影响数据模型的准确性和整体成功。经过彻底的数据清理，数据分析阶段更有可能输出有缺陷的结果和不正确的预测。
- en: Common errors that need to be rectified during the data cleaning stage are duplicate
    data, missing values, irrelevant data, outliers, and converting multiple data
    types or languages into a single form.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清理阶段需要纠正的常见错误包括重复数据、缺失值、不相关数据、异常值以及将多种数据类型或语言转换为单一形式。
- en: '**[Nahla Davies](http://nahlawrites.com/)** is a software developer and tech
    writer. Before devoting her work full time to technical writing, she managed —
    among other intriguing things — to serve as a lead programmer at an Inc. 5,000
    experiential branding organization whose clients include Samsung, Time Warner,
    Netflix, and Sony.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nahla Davies](http://nahlawrites.com/)** 是一名软件开发人员和技术作家。在全职从事技术写作之前，她还曾担任过各种有趣的角色，包括在一家Inc.
    5,000 体验品牌机构担任首席程序员，该机构的客户包括三星、时代华纳、Netflix和索尼。'
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[The Importance of Experiment Design in Data Science](https://www.kdnuggets.com/2022/08/importance-experiment-design-data-science.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实验设计在数据科学中的重要性](https://www.kdnuggets.com/2022/08/importance-experiment-design-data-science.html)'
- en: '[The Importance of Probability in Data Science](https://www.kdnuggets.com/2023/02/importance-probability-data-science.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[概率在数据科学中的重要性](https://www.kdnuggets.com/2023/02/importance-probability-data-science.html)'
- en: '[The Berkson-Jekel Paradox and its Importance to Data Science](https://www.kdnuggets.com/2023/03/berksonjekel-paradox-importance-data-science.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[伯克森-杰克尔悖论及其对数据科学的重要性](https://www.kdnuggets.com/2023/03/berksonjekel-paradox-importance-data-science.html)'
- en: '[Celebrating Awareness of the Importance of Data Privacy](https://www.kdnuggets.com/2022/01/celebrating-awareness-importance-data-privacy.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[庆祝对数据隐私重要性的认识](https://www.kdnuggets.com/2022/01/celebrating-awareness-importance-data-privacy.html)'
- en: '[Importance of Pre-Processing in Machine Learning](https://www.kdnuggets.com/2023/02/importance-preprocessing-machine-learning.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中预处理的重要性](https://www.kdnuggets.com/2023/02/importance-preprocessing-machine-learning.html)'
- en: '[The Importance of Reproducibility in Machine Learning](https://www.kdnuggets.com/2023/06/importance-reproducibility-machine-learning.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中可重复性的重要性](https://www.kdnuggets.com/2023/06/importance-reproducibility-machine-learning.html)'
