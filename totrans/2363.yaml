- en: How to Correctly Select a Sample From a Huge Dataset in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何从机器学习中的巨大数据集中正确选择样本
- en: 原文：[https://www.kdnuggets.com/2019/05/sample-huge-dataset-machine-learning.html](https://www.kdnuggets.com/2019/05/sample-huge-dataset-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/sample-huge-dataset-machine-learning.html](https://www.kdnuggets.com/2019/05/sample-huge-dataset-machine-learning.html)
- en: '![How to correctly select a sample from a huge dataset in machine learning](../Images/09979ee53c1210a7e83d719a441a6d55.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何从机器学习中的巨大数据集中正确选择样本](../Images/09979ee53c1210a7e83d719a441a6d55.png)'
- en: Photo by [Lukas](https://www.pexels.com/@goumbik?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    from [Pexels](https://www.pexels.com/photo/analytics-blur-close-up-commerce-590020/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Lukas](https://www.pexels.com/@goumbik?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
    提供，来自 [Pexels](https://www.pexels.com/photo/analytics-blur-close-up-commerce-590020/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)
- en: 'In machine learning, we often need to train a model with a **very large** dataset
    of thousands or even millions of records. The higher the size of a dataset, the
    higher its **statistical significance** and the information it carries, but we
    rarely ask ourselves: is such a huge dataset **really useful**? Or we could reach
    a satisfying result with a smaller, much more manageable one? Selecting a reasonably
    small dataset carrying the good amount of information can really make us **save
    time** and money.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们常常需要用一个**非常大的**数据集来训练模型。数据集的规模越大，它的**统计意义**和包含的信息就越多，但我们很少问自己：这么大的数据集**真的有用**吗？或者我们能否用一个更小、更易管理的数据集达到令人满意的结果？选择一个适度小的数据集，并包含足够的信息，真的可以让我们**节省时间**和金钱。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT领域'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Let’s make a simple mental experiment. Imagine that we are in a **library**
    and want to learn Dante Alighieri’s *Divina Commedia* word by word.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个简单的心理实验。假设我们在一个**图书馆**里，想要逐字学习但丁·阿利吉耶里的 *神曲*。
- en: 'We have two options:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个选择：
- en: Grab the first edition we find and start studying from it
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取我们找到的第一个版本并开始学习
- en: Grab as many editions as possible and study from all of them
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽可能多地获取不同版本并从中学习
- en: The right answer is very clear. Why would we want to study from different books
    when **just one** of them is enough?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的答案很明确。为什么我们要从不同的书籍中学习，当**仅一本**书就足够呢？
- en: Machine learning is the same thing. We have a model that **learns something**
    and, exactly like us, it needs some time. What we want is the **minimum amount**
    of information that is required to learn properly from the phenomenon, without
    wasting our time. Information redundancy doesn’t contain any business value for
    us.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习也是如此。我们有一个**学习东西**的模型，和我们一样，它也需要一些时间。我们想要的是学习现象所需的**最小信息量**，以免浪费时间。信息冗余对我们没有任何商业价值。
- en: But how can we be sure that our edition isn’t corrupted or incomplete? We must
    perform some kind of **high-level comparison** with the population made by the
    other editions. For example, we could check the number of *canti* and *cantiche*.
    If our book has three *cantiche* and each one of them has 33 *canti*, maybe it’s
    complete and we can safely learn from it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们如何确保我们的版本没有损坏或不完整呢？我们必须与其他版本的集合进行某种形式的**高水平比较**。例如，我们可以检查 *canti* 和 *cantiche*
    的数量。如果我们的书有三本 *cantiche*，每本都有33个 *canti*，也许它是完整的，我们可以安全地从中学习。
- en: What we are doing is learn from a sample (the single *Divina Commedia* edition)
    and check its **statistical significance** (the macro comparison with the other
    books).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在做的是从一个样本（单一的 *神曲* 版本）中学习，并检查其**统计意义**（与其他书籍的宏观比较）。
- en: The same, exact concept can be applied in machine learning. Instead of learning
    from a huge population of many records, we can make a **sub-sampling** of it keeping
    all the **statistics intact**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的概念也可以应用于机器学习。我们可以通过对大量记录的总体进行**子采样**，保持所有**统计信息不变**，而不是直接从庞大的总体中学习。
- en: Statistical Framework
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计框架
- en: In order to take a small, easy to handle dataset, we must be sure we **don’t
    lose** statistical significance with respect to the population. A too small dataset
    won’t carry enough information to learn from, a too huge dataset can be time-consuming
    to analyze. So how can we choose the good **compromise** between size and information?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到一个小而易于处理的数据集，我们必须确保**不会丧失**相对于总体的统计显著性。数据集过小无法提供足够的信息进行学习，而数据集过大则可能需要耗费大量时间进行分析。那么，我们如何在大小和信息之间找到合适的**折中**呢？
- en: Statistically speaking, we want that our sample keeps the **probability distribution**
    of the population under a reasonable **significance level**. In other words, if
    we take a look at the **histogram** of the sample, it must be the same as the
    histogram of the population.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从统计角度来看，我们希望样本保持总体的**概率分布**在合理的**显著性水平**下。换句话说，如果我们查看样本的**直方图**，它必须与总体的直方图相同。
- en: There are many ways to accomplish this goal. The simplest thing to do is taking
    a random sub-sample with **uniform distribution** and check if it’s significant
    or not. If it’s reasonably significant, we’ll keep it. If it’s not, we’ll take
    another sample and repeat the procedure until we get a good significance level.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一目标有许多方法。最简单的方法是随机抽取一个具有**均匀分布**的子样本，并检查其是否显著。如果它具有合理的显著性，我们就保留它。如果不显著，我们将再取一个样本并重复这一过程，直到获得良好的显著性水平。
- en: Multivariate vs. Multiple Univariate
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多变量与多个单变量
- en: If we have a dataset made by *N* variables, it can be clustered in a *N*-variate
    histogram and so can be every sub-sample we can take from it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个由*N*个变量组成的数据集，它可以聚合成一个*N*变量的直方图，任何我们从中提取的子样本也可以是这样。
- en: This operation, although academically correct, can be really difficult to perform
    in reality, especially if our dataset mixes numerical and categorical variables.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这一操作在学术上是正确的，但在实际操作中可能非常困难，特别是当我们的数据集混合了数值变量和分类变量时。
- en: That’s why I prefer a simpler approach, that usually introduces an acceptable
    approximation. What we are going to do is consider each variable **independently**
    from the others. If each one of the single, univariate histograms of the sample
    columns is **comparable** with the correspondent histogram of the population columns,
    we can **assume** that the sample is **not biased**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我更喜欢一种更简单的方法，这通常会引入一个可接受的近似值。我们将考虑每个变量**独立于**其他变量。如果样本列的每一个单变量直方图与总体列的相应直方图**可比**，我们可以**假设**样本是**不偏倚的**。
- en: 'The comparison between sample and population is then made this way:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 样本和总体之间的比较是这样进行的：
- en: Take one variable from the sample
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从样本中选取一个变量
- en: Compare its probability distribution with the probability distribution of the
    same variable of the population
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较它的概率分布与总体中同一变量的概率分布
- en: Repeat with all the variables
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对所有变量重复此过程
- en: Some of you could think that we are forgetting the **correlation** between variables.
    It’s not completely true, in my opinion, if we select our sample **uniformly**.
    It’s widely known that selecting a sub-sample uniformly will produce, with large
    numbers, the **same probability distribution** of the original population. Powerful
    resampling methods like **bootstrap** are built around this concept (see my [previous
    article](https://medium.com/data-science-journal/the-bootstrap-the-swiss-army-knife-of-any-data-scientist-acd6e592be13)
    for more information).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你们中的一些人可能认为我们忽略了变量之间的**相关性**。在我看来，这不完全正确，如果我们**均匀**地选择样本。众所周知，均匀选择子样本在数量足够大的情况下，会产生与原始总体**相同的概率分布**。像**自助法**这样强大的重采样方法就是基于这一概念的（有关更多信息，请参见我的[上一篇文章](https://medium.com/data-science-journal/the-bootstrap-the-swiss-army-knife-of-any-data-scientist-acd6e592be13)）。
- en: Comparing Sample and Population
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较样本和总体
- en: As I said before, for each variable we must compare its probability distribution
    on the sample with the probability distribution on the population.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前所说的，对于每个变量，我们必须将其在样本中的概率分布与在总体中的概率分布进行比较。
- en: The histograms of categorical variables can be compared using **Pearson’s chi-square
    test**, while the cumulative distribution functions of the numerical variables
    can be compared using the **Kolmogorov-Smirnov test**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量的直方图可以使用**Pearson’s chi-square test** 进行比较，而数值变量的累计分布函数可以使用**Kolmogorov-Smirnov
    test** 进行比较。
- en: Both statistical tests work under the null hypothesis that the sample has the
    **same distribution** of the population. Since a sample is made by many columns
    and we want all of them to be **significative**, we can reject the null hypothesis
    if the p-value of **at least one** of the tests is lower than the usual **5% confidence
    level**. In other words, we want **every column** to pass the significance test
    in order to accept the sample as valid.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 两个统计测试都基于原假设，即样本具有**与总体相同的分布**。由于一个样本由许多列组成，我们希望所有列都**具有显著性**，因此如果**至少一个**测试的
    p 值低于通常的**5% 置信水平**，我们可以拒绝原假设。换句话说，我们希望**每一列**都通过显著性测试，以接受样本为有效。
- en: R Example
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R 示例
- en: Let’s move from theory to practice. As usual, I’ll use an example in R language.
    What I’m going to show you is how the statistical tests can **give us a warning**
    when sampling is not done properly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从理论进入实践。像往常一样，我将使用 R 语言中的一个例子。我将展示统计测试如何**给我们警告**，当采样不正确时。
- en: Data simulation
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据模拟
- en: Let’s simulate some (huge) data. We’ll create a data frame with 1 million records
    and 2 columns. The first one has 500.000 records taken from a normal distribution,
    while the other 500.000 records are taken from a uniform distribution. This variable
    is **clearly biased** and it will help me explain the concepts of statistical
    significance later.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们模拟一些（巨大的）数据。我们将创建一个包含 100 万条记录和 2 列的数据框。第一列有 500,000 条记录，取自正态分布，而另一列的 500,000
    条记录取自均匀分布。这个变量是**明显有偏倚的**，它将帮助我解释统计显著性的概念。
- en: The other field is a **factor variable** created by using the first 10 letters
    from the alphabet uniformly distributed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个字段是通过使用前 10 个字母创建的**因子变量**，这些字母均匀分布。
- en: Here follows the code to create such a dataset.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是创建这样一个数据集的代码。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Create a sample and check its significance
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个样本并检查其显著性
- en: Now we can try to create a sample made by 10.000 records from the original dataset
    and check its significance.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以尝试从原始数据集中创建一个包含 10,000 条记录的样本，并检查其显著性。
- en: 'Remember: numerical variables must be checked with the **Kolmogorov-Smirnov**
    test, while categorical variables (i.e. factors in R) need **Pearson’s chi-square**
    test.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 记住：数值变量必须通过**Kolmogorov-Smirnov** 检验，而分类变量（即 R 中的因素）需要**Pearson’s chi-square**
    检验。
- en: For each test, we’ll store its p-value in a named list for the final check.
    If **all the p-values** are greater than 5%, we can say that the sample is not
    biased.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个测试，我们会将其 p 值存储在一个命名列表中以便最终检查。如果**所有的 p 值**都大于 5%，我们可以说样本没有偏倚。
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The p-values are, then:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: p 值如下：
- en: '![How to Correctly Select a Sample From a Huge Dataset in Machine Learning](../Images/436dc733ebd7412f7383722e384d8945.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![如何从机器学习中的巨大数据集中正确选择样本](../Images/436dc733ebd7412f7383722e384d8945.png)'
- en: Each one of them is **greater than 5%**, so we can say that the sample is statistically
    significant.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 它们中的每一个都**大于 5%**，所以我们可以说样本在统计上是显著的。
- en: What happens if we take the first 10.000 records instead of taking them randomly?
    We know that the first half of the X1 variable of the dataset has a different
    distribution than the total, so we expect that such a sample can’t be representative
    of the whole population.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取前 10,000 条记录而不是随机选择，会发生什么？我们知道数据集中 X1 变量的前半部分与总体的分布不同，因此我们期望这样的样本不能代表整个总体。
- en: 'If we repeat the tests, these are the p-values:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重复测试，这些是 p 值：
- en: '![How to Correctly Select a Sample From a Huge Dataset in Machine Learning](../Images/3de7151fc14e6a869ec2ec3b2d63cd60.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![如何从机器学习中的巨大数据集中正确选择样本](../Images/3de7151fc14e6a869ec2ec3b2d63cd60.png)'
- en: As expected, X1 has a too low p-value due to the bias of the population. In
    this case, we must **keep generating** random samples until all the p-values are
    greater than the minimum allowed confidence level.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，由于总体的偏倚，X1 的 p 值过低。在这种情况下，我们必须**不断生成**随机样本，直到所有 p 值都大于允许的最小置信水平。
- en: Conclusions
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, I’ve shown you that a proper sample can be statistically significant
    to represent the whole population. This may help us in machine learning because
    a small dataset can make us train models **more quickly** than a larger one, carrying
    the same amount of information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我展示了一个合适的样本在统计上可以显著地代表整个群体。这可能对机器学习有所帮助，因为一个小数据集可以让我们**更快地**训练模型，而信息量与较大的数据集相同。
- en: However, everything is strongly related to the **significance level** we choose.
    For certain kinds of problems, it can be useful to raise the confidence level
    or discard those variables that don’t show a suitable p-value. As usual, a proper
    data discovery before training can help us decide how to perform a sample correctly.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一切都与我们选择的**显著性水平**密切相关。对于某些问题，提高置信水平或丢弃那些不显示合适p值的变量可能会很有用。像往常一样，训练前的适当数据发现可以帮助我们决定如何正确地进行样本。
- en: '[Original](https://medium.com/data-science-journal/how-to-correctly-select-a-sample-from-a-huge-dataset-in-machine-learning-24327650372c).
    Reposted with permission.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/data-science-journal/how-to-correctly-select-a-sample-from-a-huge-dataset-in-machine-learning-24327650372c)。经授权转载。'
- en: Resources
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网页的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**[Gianluca Malato](http://www.gianlucamalato.it/)** is a writer and blogger,
    but first and foremost a passionate reader. Gianluca writes novels and short stories
    of fantasy, horror and science fiction genres.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**[詹卢卡·马拉托](http://www.gianlucamalato.it/)**是一位作家和博主，但最重要的是一位充满热情的读者。詹卢卡写作奇幻、恐怖和科幻小说和短篇故事。'
- en: More On This Topic
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How to Select Rows and Columns in Pandas Using [ ], .loc, iloc, .at…](https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在Pandas中选择行和列使用[ ], .loc, iloc, .at…](https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html)'
- en: '[How to Create a Dataset for Machine Learning](https://www.kdnuggets.com/2022/02/create-dataset-machine-learning.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何为机器学习创建数据集](https://www.kdnuggets.com/2022/02/create-dataset-machine-learning.html)'
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无监督解缠表示学习中的类别…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
- en: '[Choosing the Right Clustering Algorithm for Your Dataset](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为您的数据集选择正确的聚类算法](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
- en: '[How to Generate Synthetic Tabular Dataset](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何生成合成表格数据集](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
- en: '[ChatGPT-Powered Data Exploration: Unlock Hidden Insights in Your Dataset](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT驱动的数据探索：揭示数据集中的隐藏洞察](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
