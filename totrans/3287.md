# 自驾车中使用的机器学习算法

> 原文：[https://www.kdnuggets.com/2017/06/machine-learning-algorithms-used-self-driving-cars.html](https://www.kdnuggets.com/2017/06/machine-learning-algorithms-used-self-driving-cars.html)

**作者：Savaram Ravindra，[Tekslate.com](https://tekslate.com/)**。

今天，机器学习算法被广泛用于解决制造自驾车过程中出现的各种挑战。随着传感器数据处理的整合到汽车的ECU（电子控制单元）中，提升机器学习的利用率以完成新任务变得至关重要。潜在应用包括通过来自不同外部和内部传感器的数据融合——如激光雷达、雷达、摄像头或物联网（IoT）——评估驾驶员状态或驾驶场景分类。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的IT工作

* * *

运行汽车信息娱乐系统的应用程序可以接收来自传感器数据融合系统的信息，例如，如果它发现驾驶员有问题，可以将汽车引导到医院。这种基于机器学习的应用还包括驾驶员的语音和手势识别以及语言翻译。这些算法被分类为无监督算法和监督算法。它们之间的区别在于它们如何学习。

监督算法利用训练数据集进行学习，并不断学习，直到达到他们期望的信心水平（即错误概率最小化）。监督算法可以细分为回归、分类和异常检测或维度缩减。

无监督算法试图从现有数据中提取价值。这意味着，在现有数据中，算法建立关系以检测模式，或根据数据之间的相似度将数据集划分为子组。无监督算法可以大致细分为关联规则学习和聚类。

强化学习算法是另一类机器学习算法，介于无监督学习和监督学习之间。在监督学习中，每个训练样本都有一个目标标签；在无监督学习中则完全没有标签；强化学习则包含时间延迟和稀疏标签——未来奖励。

代理根据这些奖励学习在环境中的行为。理解算法的局限性和优点，并开发高效的学习算法是强化学习的目标。强化学习有可能解决大量实际应用问题，从人工智能问题到控制工程或运筹学——这些都与自驾车的发展相关。这可以分为间接学习和直接学习。

在自动驾驶汽车中，机器学习算法的主要任务之一是持续渲染周围环境并预测这些环境可能发生的变化。这些任务被分类为4个子任务：

+   物体检测

+   物体识别或分类

+   物体定位和运动预测

机器学习算法大致分为4类：决策矩阵算法、聚类算法、模式识别算法和回归算法。某一类机器学习算法可以用于完成2个或更多的子任务。例如，回归算法可以用于物体定位、物体检测或运动预测。

![](../Images/20bb2bb20ef161caa33b3c4386c0dd82.png)

**决策矩阵算法**

决策矩阵算法系统地分析、识别和评估信息集和价值之间关系的性能。这些算法主要用于决策制定。汽车是否需要刹车或左转取决于这些算法对物体识别、分类和下一个动作预测的信心水平。决策矩阵算法是由各种独立训练的决策模型组成的，这些预测在某种程度上被组合以做出总体预测，同时减少决策错误的可能性。AdaBoosting是最常用的算法。

**AdaBoosting**

自适应提升（AdaBoost）是一种结合多种学习算法的方法，可用于回归或分类。与其他机器学习算法相比，它克服了过拟合问题，且通常对异常值和噪声数据较为敏感。为了创建一个复合强大的学习者，AdaBoost使用多次迭代。因此，它被称为自适应的。通过迭代地添加弱学习者，AdaBoost创建了一个强大的学习者。一个新的弱学习者被添加到实体中，并调整加权向量，以关注在之前轮次中被错误分类的样本。结果是一个比弱学习者的分类器具有更高准确性的分类器。

![](../Images/40f514fc3c968143d21cdb06b669a8b2.png)

AdaBoost帮助将弱阈值分类器提升为强分类器。上图展示了在一个单一文件中实现AdaBoost的代码，代码易于理解。该函数包含一个弱分类器和提升组件。弱分类器试图在数据的一个维度中找到理想的阈值，将数据分为两个类。提升部分会迭代地调用分类器，每次分类步骤后，它会改变被错误分类样本的权重。因此，创建了一系列弱分类器，它们表现得像一个强分类器。

**聚类算法**

有时，系统获取的图像不够清晰，导致定位和检测对象变得困难。有时，分类算法可能会遗漏对象，在这种情况下，它们无法将对象分类并报告给系统。可能的原因包括数据不连续、数据点太少或图像分辨率低。聚类算法专注于从数据点中发现结构。它描述了方法类别和回归等问题类别。聚类方法通常通过建模方法组织，如层次化和基于中心点的方法。所有方法都关注利用数据中固有的结构，将数据完美地组织成最大共同性的组。K-means、多类别神经网络是最常用的算法。

**K-means**

K-means是一种著名的聚类算法。K-means存储k个中心点，用于定义聚类。如果一个点比其他中心点更接近某个中心点，则该点被认为在该中心点定义的特定聚类中。通过在根据当前数据点的聚类分配选择中心点和根据当前中心点分配数据点到聚类之间交替进行。

![](../Images/26ab7951301321e3d249ce87a4896951.png)

K均值算法 – 聚类质心用十字表示，训练样本用点表示。(a) 原始数据集。(b) 随机初始聚类质心。(c-f) 演示了运行2次K均值算法的过程。在每次迭代中，每个训练样本被分配到离其最近的聚类质心，然后每个聚类质心移动到分配给它的点的均值。

**模式识别算法（分类）**

通过传感器获得的高级驾驶辅助系统（ADAS）的图像包含各种环境数据；需要对图像进行过滤，以确定对象类别的实例，排除无关的数据点。在对对象进行分类之前，识别数据集中的模式是一个重要步骤。这类算法被称为数据减少算法。

数据减少算法有助于减少对象的数据集边缘和多边形线段（拟合线段）以及将圆弧转换为边缘。直到一个角落，线段与边缘对齐，之后将开始一个新的线段。圆弧与类似弧形的线段序列对齐。以多种方式，将图像的特征（圆弧和线段）结合起来，形成用于确定对象的特征。

使用PCA（主成分分析）和HOG（方向梯度直方图），SVM（支持向量机）是ADAS中常用的识别算法。K近邻算法（KNN）和贝叶斯决策规则也被使用。

**支持向量机（SVM）**

支持向量机（SVM）依赖于定义决策边界的决策平面概念。决策平面将包含不同类别成员的对象集合分开。下图展示了一个示意图。在这个示意图中，对象属于RED或GREEN类别。分隔线将RED和GREEN对象分开。任何落在左侧的新对象被标记为RED，而如果落在右侧则标记为GREEN。

![](../Images/dc3ed687c5cfc78b43bc3524e1a665d8.png)

**回归算法**

这种算法擅长预测事件。回归分析评估两个或更多变量之间的关系，并整合变量在不同尺度上的影响，主要由3个指标驱动。

+   回归线的形状。

+   依赖变量的类型。

+   自变量的数量。

图像（相机或雷达）在ADAS的激活和定位中起着重要作用，而对于任何算法来说，最大的挑战是开发一个基于图像的特征选择和预测模型。

回归算法利用环境的重复性来创建一个统计模型，该模型描述给定物体在图像中的位置与图像之间的关系。统计模型通过允许图像采样，提供了快速的在线检测，并可以离线学习。它还可以扩展到其他物体，而不需要大量的人为建模。一个物体的位置由算法返回作为在线阶段的输出，并对物体的存在做出信任。

回归算法也可以用于短期预测和长期学习。这类回归算法，包括决策森林回归、神经网络回归和贝叶斯回归等，可以用于自动驾驶汽车。

**神经网络回归**

神经网络被用于回归、分类或无监督学习。它们对未标记的数据进行分组、分类或在监督训练后预测连续值。神经网络通常在网络的最后一层使用一种形式的逻辑回归，将连续数据转换为类似1或0的变量。

![](../Images/e312a2750e3bde49cead3450d9a17fd7.png)

在上图中，‘x’是输入，表示从网络的前一层传递到当前层的特征。每个最后隐藏层的节点都会接收多个x，每个x会乘以一个相应的权重w。偏差的和会被加到产品中，并传递到激活函数。激活函数是ReLU（修正线性单元），因其不会像sigmoid激活函数那样在浅梯度上饱和而被广泛使用。ReLU为每个隐藏节点提供一个输出激活a，这些激活被加到输出节点中，输出节点传递激活的总和。这意味着执行回归的神经网络包含单一的输出节点，这个节点将前一层激活的总和乘以1。网络的估计值‘y hat’将是结果。‘Y hat’是所有x映射到的因变量。你可以用这种方式利用神经网络来获得x（自变量的数量）与y（你试图预测的因变量）之间的关系。

[原始帖子](https://docs.google.com/document/d/1HIuTNmZvXnVh1oiwfsZJYrDSsekqAK-XumK1c8D4g7Q/edit?usp=sharing)。经许可转载。

**简介：** [Savaram Ravindra](https://www.linkedin.com/in/savaram-ravindra-48064641/) 是 [Tekslate.com](https://tekslate.com/) 的内容贡献者，曾是Cognizant Technology Solutions的程序分析师。他拥有VIT大学的纳米技术硕士学位。可以通过savaramravindra4@gmail.com联系他。

**相关：**

+   [我应该使用哪个机器学习算法？](/2017/06/which-machine-learning-algorithm.html)

+   [近期车辆技术进展简要概述](/2017/01/grakn-year-review-vehicle-technologies.html)

+   [自动驾驶车辆成功需要超人般的感知能力](/2017/06/autonomous-vehicles-superhuman-perception-success.html)

### 更多相关话题

+   [停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [数据科学统计学习的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [9 亿美元的 AI 失败案例研究](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)
