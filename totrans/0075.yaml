- en: 'Unlocking Reliable Generations through Chain-of-Verification: A Leap in Prompt
    Engineering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过验证链解锁可靠生成：提示工程的新飞跃
- en: 原文：[https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)
- en: '![Unlocking Reliable Generations through Chain-of-Verification: A Leap in Prompt
    Engineering](../Images/11b3cf522091679f8a691802527fa3de.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![通过验证链解锁可靠生成：提示工程的新飞跃](../Images/11b3cf522091679f8a691802527fa3de.png)'
- en: Image created by Author with Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用Midjourney创建
- en: Key Takeaways
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要收获
- en: The Chain-of-Thought (CoVe) prompt engineering method is designed to mitigate
    hallucinations in LLMs, addressing the generation of plausible yet incorrect factual
    information
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证链（CoVe）提示工程方法旨在减轻LLMs中的幻觉问题，解决生成看似正确但实际上不准确的信息
- en: Through a four-step process, CoVe enables LLMs to draft, verify, and refine
    responses, fostering a self-verifying mechanism that enhances accuracy, Structured
    Self-Verification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过一个四步过程，CoVe使LLMs能够起草、验证和改进回答，培养一种增强准确性的自我验证机制，结构化自我验证
- en: CoVe has demonstrated improved performance in various tasks such as list-based
    questions and long-form text generation, showcasing its potential in reducing
    hallucinations and bolstering the correctness of AI-generated text
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoVe在各种任务中展示了改进的性能，例如基于列表的问题和长文本生成，展示了其在减少幻觉和增强AI生成文本准确性方面的潜力
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的IT工作'
- en: '* * *'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We study the ability of language models to deliberate on the responses they
    give in order to correct their mistakes.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们研究了语言模型在回应过程中反思其回答以纠正错误的能力。
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The relentless pursuit of accuracy and reliability in the realm of Artificial
    Intelligence (AI) has ushered in groundbreaking techniques in prompt engineering.
    These techniques play a pivotal role in guiding generative models to provide precise
    and meaningful responses to a myriad of queries. The recent advent of the [Chain-of-Verification](https://arxiv.org/abs/2309.11495)
    (CoVe) method marks a significant milestone in this quest. This innovative technique
    aims to tackle a notorious issue in large language models (LLMs) — the generation
    of plausible yet incorrect factual information, colloquially known as hallucinations.
    By enabling models to deliberate on their responses and undergo a self-verifying
    process, CoVe sets a promising precedent in enhancing the reliability of generated
    text.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能（AI）领域，对准确性和可靠性的不断追求带来了提示工程中的突破性技术。这些技术在指导生成模型提供精确且有意义的回答方面发挥了关键作用。最近出现的[验证链](https://arxiv.org/abs/2309.11495)（CoVe）方法标志着这一追求的重要里程碑。这一创新技术旨在解决大语言模型（LLMs）中的一个臭名昭著的问题——生成看似正确但实际上不准确的信息，俗称幻觉。通过使模型对其回答进行反思并经历自我验证过程，CoVe在提高生成文本的可靠性方面树立了一个有前途的先例。
- en: The burgeoning ecosystem of LLMs, with their capability to process and generate
    text based on vast corpora of documents, has showcased remarkable proficiency
    in various tasks. However, a lingering concern remains—the propensity to generate
    hallucinated information, especially on lesser-known or rare topics. The Chain-of-Verification
    method emerges as a beacon of hope amidst these challenges, offering a structured
    approach to minimize hallucinations and improve the accuracy of generated responses.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）蓬勃发展的生态系统，凭借其基于大量文档语料库处理和生成文本的能力，在各种任务中表现出卓越的能力。然而，一个持续存在的问题是——生成虚假信息的倾向，尤其是在较少知晓或罕见的话题上。验证链方法在这些挑战中成为了一线希望，提供了一种结构化的方法来最小化虚假信息，并提高生成响应的准确性。
- en: Understanding Chain-of-Verification
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解验证链
- en: 'CoVe unfolds a four-step mechanism to mitigate hallucinations in LLMs:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: CoVe展开了一个四步骤机制，以减轻LLMs中的虚假信息：
- en: Drafting an initial response
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 草拟初步回应
- en: Planning verification questions to fact-check the draft
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划验证问题以核查草稿
- en: Answering those questions independently to avoid bias
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立回答这些问题以避免偏见
- en: Generating a final verified response based on the answers
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于答案生成最终验证回应
- en: This systematic approach not only addresses the concern of hallucinations but
    also encapsulates a self-verifying process that elevates the correctness of the
    generated text. The method's efficacy has been demonstrated across a variety of
    tasks, including list-based questions, closed book QA, and long-form text generation,
    showcasing a decrease in hallucinations and an improvement in performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这种系统化的方法不仅解决了虚假信息的问题，还包含了一个自我验证的过程，提升了生成文本的正确性。该方法的有效性已在各种任务中得到验证，包括基于列表的问题、闭卷问答和长篇文本生成，展示了虚假信息的减少和性能的提升。
- en: Implementing Chain-of-Verification
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施验证链
- en: Adopting CoVe involves integrating its four-step process in the workflow of
    LLMs. For instance, when tasked with generating a list of historical events, an
    LLM employing CoVe would initially draft a response, plan verification questions
    to fact-check each event, answer those questions independently, and finally, generate
    a verified list based on the validation received.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 采用CoVe涉及将其四步骤过程融入LLMs的工作流程。例如，当任务是生成历史事件列表时，使用CoVe的LLM会首先草拟一个回应，计划验证问题以事实核查每个事件，独立回答这些问题，最后根据验证结果生成经过验证的列表。
- en: The rigorous verification process intrinsic to CoVe ensures a higher degree
    of accuracy and reliability in the generated responses. This disciplined approach
    toward verification not only enriches the quality of information but also fosters
    a culture of accountability within the AI generation process, marking a significant
    stride towards achieving more reliable AI-generated text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CoVe固有的严格验证过程确保了生成的回答具有更高的准确性和可靠性。这种对验证的严谨态度不仅提升了信息质量，还在AI生成过程内培养了问责文化，为实现更可靠的AI生成文本迈出了重要一步。
- en: '**Example 1**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1**'
- en: '**Question**: List notable inventions of the 20th century.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：列出20世纪的著名发明。'
- en: '**Initial Draft**: Internet, Quantum Mechanics, DNA Structure Discovery'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初稿**：互联网、量子力学、DNA结构发现'
- en: '**Verification Questions**: Was the Internet invented in the 20th century?
    Was Quantum Mechanics developed in the 20th century? Was the structure of DNA
    discovered in the 20th century?'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证问题**：互联网是在20世纪发明的吗？量子力学是在20世纪发展的吗？DNA的结构是在20世纪发现的吗？'
- en: '**Final Verified Response**: Internet, Penicillin Discovery, DNA Structure
    Discovery'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终验证回应**：互联网、青霉素发现、DNA结构发现'
- en: '**Example 2**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2**'
- en: '**Question**: Provide a list of countries in Africa.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：提供一个非洲国家的列表。'
- en: '**Initial Draft**: Nigeria, Ethiopia, Egypt, South Africa, Sudan'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初稿**：尼日利亚、埃塞俄比亚、埃及、南非、苏丹'
- en: '**Verification Questions**: Is Nigeria in Africa? Is Ethiopia in Africa? Is
    Egypt in Africa? Is South Africa in Africa? Is Sudan in Africa?'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证问题**：尼日利亚在非洲吗？埃塞俄比亚在非洲吗？埃及在非洲吗？南非在非洲吗？苏丹在非洲吗？'
- en: '**Final Verified Response**: Nigeria, Ethiopia, Egypt, South Africa, Sudan'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终验证回应**：尼日利亚、埃塞俄比亚、埃及、南非、苏丹'
- en: Adopting CoVe involves integrating its four-step process in the workflow of
    LLMs. For instance, when tasked with generating a list of historical events, an
    LLM employing CoVe would initially draft a response, plan verification questions
    to fact-check each event, answer those questions independently, and finally, generate
    a verified list based on the validation received.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 采用 CoVe 涉及将其四步骤过程整合到 LLM 的工作流程中。例如，当任务是生成历史事件列表时，使用 CoVe 的 LLM 将首先起草一个回应，计划验证问题以核实每个事件，独立回答这些问题，最后根据收到的验证生成一个经过验证的列表。
- en: '![Chain-of-Verification process](../Images/c9e5c2de1ce7d2a54e3285c45c0d0aab.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![Chain-of-Verification 过程](../Images/c9e5c2de1ce7d2a54e3285c45c0d0aab.png)'
- en: '**Figure 1**: The Chain-of-Verification simplified process (Image by Author)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**：简化的 Chain-of-Verification 过程（图像来源：作者）'
- en: The methodology would require in-context examples along with the question to
    pose the LLM, or an LLM could be finetuned on CoVe examples in order to approach
    each question in this manner, should it be desired.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法需要上下文示例以及提问 LLM 的问题，或者可以对 LLM 进行 CoVe 示例的微调，以便在这种方式下处理每个问题，如有需要。
- en: Conclusion
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The advent of the Chain-of-Verification method is a testament to the strides
    being made in prompt engineering towards achieving reliable and accurate AI-generated
    text. By addressing the hallucination issue head-on, CoVe offers a robust solution
    that elevates the quality of information generated by LLMs. The method's structured
    approach, coupled with its self-verifying mechanism, embodies a significant leap
    towards fostering a more reliable and factual AI generation process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Chain-of-Verification 方法的出现证明了在提示工程中朝着实现可靠和准确的 AI 生成文本所取得的进展。通过直面幻觉问题，CoVe 提供了一种强有力的解决方案，提升了
    LLM 生成信息的质量。这种方法的结构化方法，加上其自我验证机制，代表了在促进更可靠和真实的 AI 生成过程方面的重要跃进。
- en: The implementation of CoVe is a clarion call for practitioners and researchers
    alike to continue exploring and refining techniques in prompt engineering. Embracing
    such innovative methods will be instrumental in unlocking the full potential of
    Large Language Models, promising a future where the reliability of AI-generated
    text is not just an aspiration, but a reality.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: CoVe 的实施是对从业者和研究人员的号召，继续探索和完善提示工程技术。拥抱这些创新方法将对释放大型语言模型的全部潜力至关重要，预示着一个未来，在这个未来中，AI
    生成文本的可靠性不仅是一个愿景，而是一个现实。
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) 拥有计算机科学硕士学位和数据挖掘研究生文凭。作为 [KDnuggets](https://www.kdnuggets.com/)
    和 [Statology](https://www.statology.org/) 的主编，以及 [Machine Learning Mastery](https://machinelearningmastery.com/)
    的特约编辑，Matthew 旨在使复杂的数据科学概念变得易于理解。他的专业兴趣包括自然语言处理、语言模型、机器学习算法以及探索新兴的人工智能。他致力于使数据科学社区的知识民主化。Matthew
    从6岁起就开始编程。'
- en: More On This Topic
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Ensuring Reliable Few-Shot Prompt Selection for LLMs](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[确保 LLM 的可靠少样本提示选择](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
- en: '[Unlocking GPT-4 Summarization with Chain of Density Prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过密度提示解锁 GPT-4 摘要](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)'
- en: '[Automating the Chain of Thought: How AI Can Prompt Itself to Reason](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自动化思维链：人工智能如何自我提示进行推理](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
- en: '[Unveiling Midjourney 5.2: A Leap Forward in AI Image Generation](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭开 Midjourney 5.2 的面纱：AI 图像生成的跃进](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
- en: '[Unveiling the Power of Meta''s Llama 2: A Leap Forward in Generative AI?](https://www.kdnuggets.com/2023/07/unveiling-power-metas-llama-2-leap-forward-generative-ai.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 Meta 的 Llama 2 的力量：生成式 AI 的跃进？](https://www.kdnuggets.com/2023/07/unveiling-power-metas-llama-2-leap-forward-generative-ai.html)'
- en: '[Design effective & reliable machine learning systems!](https://www.kdnuggets.com/2023/05/manning-design-effective-reliable-machine-learning-systems.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[设计有效且可靠的机器学习系统！](https://www.kdnuggets.com/2023/05/manning-design-effective-reliable-machine-learning-systems.html)'
