- en: Questions To Ask When Moving Machine Learning From Practice to Production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/11/moving-machine-learning-practice-production.html](https://www.kdnuggets.com/2016/11/moving-machine-learning-practice-production.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By Ramanan Balakrishnan, Semantics3**.'
  prefs: []
  type: TYPE_NORMAL
- en: With growing interest in neural networks and deep learning, individuals and
    companies are claiming ever-increasing adoption rates of artificial intelligence
    into their daily workflows and product offerings.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Coupled with breakneck speeds in AI-research, the new wave of popularity shows
    a lot of promise for solving some of the harder problems out there.
  prefs: []
  type: TYPE_NORMAL
- en: That said, I feel that this field suffers from a gulf between *appreciating*
    these developments and subsequently *deploying* them to solve "real-world" tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A number of frameworks, tutorials and guides have popped up to democratize machine
    learning, but the steps that they prescribe often don't align with the fuzzier
    problems that need to be solved.
  prefs: []
  type: TYPE_NORMAL
- en: This post is a collection of questions (with some (maybe even incorrect) answers)
    that are worth thinking about when applying machine learning in production.
  prefs: []
  type: TYPE_NORMAL
- en: Garbage in, garbage out
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do I have a reliable source of data? Where do I obtain my dataset?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While starting out, most tutorials usually include well-defined datasets. Whether
    it be [MNIST](http://yann.lecun.com/exdb/mnist/), the [Wikipedia corpus](http://corpus.byu.edu/wikipedia.asp) or
    any of the great options from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/),
    these datasets are often not representative of the problem that you wish to solve.
  prefs: []
  type: TYPE_NORMAL
- en: For your specific use case, an appropriate dataset might not even exist and
    building a dataset could take much longer than you expect.
  prefs: []
  type: TYPE_NORMAL
- en: For example, at Semantics3, we tackle a number of ecommerce-specific problems
    ranging from *product categorization* to *product matching* to *search relevance*.
    For each of these problems, we had to look within and spend considerable effort
    to generate high-fidelity product datasets.
  prefs: []
  type: TYPE_NORMAL
- en: In many cases, even if you possess the required data, significant (and *expensive*)
    manual labor might be required to categorize, annotate and label your data for
    training.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming data to input
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What pre-processing steps are required? How do I normalize my data before using
    with my algorithms?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is another step, often independent of the actual models, that is glossed
    over in most tutorials. Such omissions appear even more glaring when exploring
    deep neural networks, where transforming the data into usable "input" is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: While there exist some standard techniques for images, like cropping, scaling,
    zero-centering and whitening - the final decision is still up to individuals on
    the level of normalization required for each task.
  prefs: []
  type: TYPE_NORMAL
- en: The field gets even messier when working with text. *Is capitalization important?
    Should I use a tokenizer? What about word embeddings? How big should my vocabulary
    and dimensionality be? Should I use pre-trained vectors or start from scratch
    or layer them?*
  prefs: []
  type: TYPE_NORMAL
- en: There is no right answer applicable across all situations, but keeping abreast
    of available options is often half the battle. A recent [post](https://explosion.ai/blog/deep-learning-formula-nlp) from
    the creator of [spaCy](https://spacy.io/) details an interesting strategy to standardize
    deep learning for text.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's begin?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Which language/framework do I use? Python, R, Java, C++? Caffe, Torch, Theano,
    Tensorflow, DL4J?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This might be the question with the most opinionated answers. I am including
    this section here only for completeness and would gladly point you to [the](http://blog.udacity.com/2016/04/languages-and-libraries-for-machine-learning.html) [various](https://github.com/zer0n/deepframeworks) [other](https://deeplearning4j.org/compare-dl4j-torch7-pylearn) [resources](https://www.oreilly.com/ideas/six-reasons-why-i-recommend-scikit-learn) available
    for making this decision.
  prefs: []
  type: TYPE_NORMAL
- en: While each person might have different criteria for evaluation, mine has simply
    been ease of customization, prototyping and testing. In that aspect, I prefer
    to start with [scikit-learn](http://scikit-learn.org/) where possible and use [Keras](https://keras.io/) for
    my deep learning projects.
  prefs: []
  type: TYPE_NORMAL
- en: Further questions like *Which technique should I use? Should I use deep or shallow
    models, what about CNNs/RNNs/LSTMs?* Again, there are a number of resources to
    help make decisions and this is perhaps the most discussed aspect when people
    talk about "using" machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Training models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How do I train my models? Should I buy GPUs, custom hardware, or ec2 (spot?)
    instances? Can I parallelize them for speed?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With ever-rising model complexity, and increasing demands on processing power,
    this is an unavoidable question when moving to production.
  prefs: []
  type: TYPE_NORMAL
- en: A billion-parameter network might promise great performance with its terabyte-sized
    dataset, but most people cannot afford to wait for weeks while the training is
    still in-progress.
  prefs: []
  type: TYPE_NORMAL
- en: Even with simpler models, the infrastructure and tooling required for the build-up,
    training, collation and tear-down of tasks across instances can be quite daunting.
  prefs: []
  type: TYPE_NORMAL
- en: Spending some time on planning your [infrastructure](https://openai.com/blog/infrastructure-for-deep-learning/) ,
    standardizing [setup](https://engineering.semantics3.com/2016/09/24/gpu-enabled-instance-deep-learning/) and
    defining workflows early-on can save valuable time with each additional model
    that you build.
  prefs: []
  type: TYPE_NORMAL
- en: No system is an island
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do I need to make batched or real-time predictions? Embedded models or interfaces?
    RPC or REST?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Your *99%-validation-accuracy* model is not of much use unless it interfaces
    with the rest of your production system[.](https://xkcd.com/1312/) The decision
    here is at least partially driven by your use-case.
  prefs: []
  type: TYPE_NORMAL
- en: A model performing a simple task might perform satisfactorily with its weights
    packaged directly into your application, while more complicated models might require
    communication with centralized heavy-lifting servers.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, most of our production systems perform tasks offline in batches,
    while a minority serve real-time predictions via JSON-RPC over HTTP.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the answer to these questions might also restrict the types of architectures
    that you should consider when building your models. Building a complex model,
    only to later learn that it cannot be deployed within your mobile app is a disaster
    that can be easily avoided.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How do I keep track of my predictions? Do I log my results to a database? What
    about online learning?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After building, training and deploying your models to production, the task is
    still not complete unless you have monitoring systems in place. A crucial component
    to ensuring the success of your models is being able to measure and quantify their
    performance. A number of questions are worth answering in this area.
  prefs: []
  type: TYPE_NORMAL
- en: '*How does my model affect the overall system performance? Which numbers do
    I measure? Does the model correctly handle all possible inputs and scenarios?*'
  prefs: []
  type: TYPE_NORMAL
- en: Having used Postgres in the [past](https://engineering.semantics3.com/2016/07/20/an-unexpected-dba-journey/),
    I favor using it for monitoring my models. Periodically saving production statistics
    (data samples, predicted results, outlier specifics) has proven invaluable in
    performing analytics (and error postmortems) over deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Another import aspect to consider is the online-learning requirement of your
    model. *Should your model learn new features on the fly?* When hoverboards become
    a reality[,](http://www.slate.com/articles/technology/future_tense/2012/11/where_s_my_hoverboard_sorry_you_re_probably_never_getting_one.html) should
    the product-categorizer put it in *Vehicles*, *Toys* or leave it *Uncategorized*?
    Again, these are important questions worth debating when building your system.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping it up
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![there is more to it than just the secret sauce](../Images/dccfceb5534b4afa45333e29828b1d44.png)'
  prefs: []
  type: TYPE_IMG
- en: '*There is more to it than just the secret sauce*'
  prefs: []
  type: TYPE_NORMAL
- en: This post poses more questions than it answers, but that was sort of the point
    really. With many advances in new techniques *and* cells *and* layers *and* network
    architectures, it is easier than ever to miss the forest for the trees.
  prefs: []
  type: TYPE_NORMAL
- en: Greater discussion about end-to-end deployments is required among practitioners
    to take this field forward and truly democratize machine learning for the masses.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Ramanan Balakrishnan](https://www.linkedin.com/in/ramananbalakrishnan)**
    is a Data Scientist at [Semantics3](https://www.semantics3.com/). When not dabbling
    in deep learning, information theory or modern physics, he is also known to participate
    in the occasional lock-picking challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://engineering.semantics3.com/2016/11/13/machine-learning-practice-to-production/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning Research Review: Generative Adversarial Nets](/2016/10/deep-learning-research-review-generative-adversarial-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Embedding smarter decisions deep in the operational IT fabric](/2016/10/zementis-deep-learning-meets-deep-deployment.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Full End-to-End Deployment of a Machine Learning Algorithm into a…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Operationalizing Machine Learning from PoC to Production](https://www.kdnuggets.com/2022/05/operationalizing-machine-learning-poc-production.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deploying Your Machine Learning Model to Production in the Cloud](https://www.kdnuggets.com/deploying-your-ml-model-to-production-in-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prioritizing Data Science Models for Production](https://www.kdnuggets.com/2022/04/prioritizing-data-science-models-production.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Feature Store Summit 2023: Practical Strategies for Deploying ML…](https://www.kdnuggets.com/2023/09/hopsworks-feature-store-summit-2023-practical-strategies-deploying-ml-models-production-environments)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
