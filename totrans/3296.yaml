- en: 'Machine Learning Workflows in Python from Scratch Part 2: k-means Clustering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始的 Python 机器学习工作流 第二部分：k-means 聚类
- en: 原文：[https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html](https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html](https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html)
- en: In the first part of this series, we started off rather slowly but deliberately.
    [The previous post](/2017/05/machine-learning-workflows-python-scratch-part-1.html)
    laid out our goals, and started off with some basic building blocks for our machine
    learning workflows and pipelines we will eventually get to. If you have not yet
    read the first installment in this series, I suggest that you do so before moving
    on.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一系列的第一部分中，我们开始得相当缓慢但有条不紊。[上一篇文章](/2017/05/machine-learning-workflows-python-scratch-part-1.html)阐述了我们的目标，并开始了机器学习工作流和管道的一些基本构建块。如果你还没有阅读该系列的第一部分，建议你先阅读。
- en: This time around we pick up steam, and will be doing so with an implementation
    of the k-means clustering algorithm. We will discuss specific aspects of k-means
    as they come up while coding, but if you are interested in a superficial overview
    of what the algorithm is about, as well as how it relates to other clustering
    methods, you could [check this out](/2016/09/comparing-clustering-techniques-concise-technical-overview.html).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我们将加快进度，通过实现 k-means 聚类算法来进行。我们将在编码过程中讨论 k-means 的具体方面，但如果你对算法的概述以及它如何与其他聚类方法相关感兴趣，可以[查看这个](https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html)。
- en: '![ML workflows header](../Images/decb4017351d3ef6e708866e8c04fed4.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![ML workflows header](../Images/decb4017351d3ef6e708866e8c04fed4.png)'
- en: The k-means clustering algorithm in Python. From scratch.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始的 Python 中的 k-means 聚类算法。
- en: The only real prerequisites moving forward are the [dataset.py](https://gist.github.com/mmmayo13/9859a457760db10ec4842be3aa1a2334)
    module we created in the first post, along with the original [iris.csv](https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv)
    file, so make sure you have both of those handy.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 继续进行的唯一真正先决条件是我们在第一篇文章中创建的 [dataset.py](https://gist.github.com/mmmayo13/9859a457760db10ec4842be3aa1a2334)
    模块，以及原始的 [iris.csv](https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv)
    文件，所以确保你手头有这两个文件。
- en: The k-means Clustering Algorithm
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: k-means 聚类算法
- en: k-means is a simple, yet often effective, approach to clustering. k points are
    randomly chosen as cluster centers, or centroids, and all training instances are
    plotted and added to the closest cluster. After all instances have been added
    to clusters, the centroids, representing the mean of the instances of each cluster
    are re-calculated, with these re-calculated centroids becoming the new centers
    of their respective clusters.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: k-means 是一种简单但通常有效的聚类方法。k 个点被随机选择作为聚类中心或质心，所有训练实例被绘制并分配到最近的聚类中。在所有实例被分配到聚类后，代表每个聚类实例均值的质心被重新计算，这些重新计算的质心成为各自聚类的新中心。
- en: At this point, all cluster membership is reset, and all instances of the training
    set are re-plotted and -added to their closest, possibly re-centered, cluster.
    This iterative process continues until there is no change to the centroids or
    their membership, and the clusters are considered settled.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在此时，所有的聚类成员资格被重置，所有训练集的实例被重新绘制并分配到其最近的、可能重新定位的聚类中。这个迭代过程会持续进行，直到质心或其成员资格没有变化，聚类被视为稳定。
- en: As far as approaches to clustering go, k-means is about as simple as they come
    -- its conceptual simplicity is elegant, almost poetic. It's also a proven workhorse,
    lending to its staying power, often producing useful results.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就聚类方法而言，k-means 几乎是最简单的——它的概念简单优雅，几乎可以说是诗意的。它也是一个经过验证的工作马，具有持久性，常常产生有用的结果。
- en: What were going to do, in a nutshell, is code up a simple k-means implementation
    that will group similar things together and keep dissimilar things apart, at least
    theoretically. Simple enough. Keep in mind that "similar" here is reduced to meaning
    "relatively closely co-located in Euclidean space," or something very non-philosophical
    like that.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们要做的是编码一个简单的 k-means 实现，它将相似的东西分组在一起，至少在理论上将不同的东西分开。很简单。请记住，“相似”在这里被简化为“在欧几里得空间中相对紧密地共处”，或者类似非常非哲学的东西。
- en: 'We will need a few functions here. Thinking about the steps involved in the
    algorithm can help us solidify what those might be:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里需要一些函数。考虑算法中涉及的步骤可以帮助我们确定这些函数是什么。
- en: Set initial centroids
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置初始质心
- en: Measure distances between data instances and centroids
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量数据实例与质心之间的距离
- en: Add data instances as members of closest centroid
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据实例添加为最近质心的成员
- en: Re-calculate centroids
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新计算质心
- en: If necessary, re-measure, re-cluster, re-calculate
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如有必要，重新测量、重新聚类、重新计算
- en: That's the algorithm in a nutshell. But before we get there, a (temporary) step
    backward.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是算法的要点。但在我们到达那里之前，暂时后退一步。
- en: Data Preparation... Again
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备……再一次
- en: While writing this post, it eventually occurred to me that an important part
    of our data preparation workflow was missing. Before we convert our pandas DataFrame
    to a numpy ndarray (matrix), we will want to make sure our numeric values are
    *actually* numeric values, and not strings masquerading as numeric values. Since
    we read our data from a CSV file last time, even our numeric values were being
    stored as strings (apparent at the bottom of the previous post by the fact that
    the numbers are surrounded by single quotes -- e.g. '5.7').
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在写这篇文章时，我终于意识到我们数据准备工作流中缺少了一个重要部分。在我们将 pandas DataFrame 转换为 numpy ndarray（矩阵）之前，我们需要确保我们的数值*实际上*是数值，而不是伪装成数值的字符串。由于上次我们从
    CSV 文件读取数据，即使是我们的数值也被存储为字符串（可以从上一篇文章底部看出，数字被单引号包围——例如 '5.7'）。
- en: 'So, the best way to deal with this is to create another function and add it
    to our dataset.py file, which will convert strings to their numeric value representations
    (we already have a function for converting class names to numeric values, and
    keeping track of these changes). The function went through 3 specific iterations
    as I played with it, namely those which accepted: 1) a dataset and the name of
    a single attribute, the corresponding column of which all values should be converted
    from strings to floats; 2) a dataset and a list of attribute names...; and 3)
    a dataset and either a single attribute as a string, or a list of attributes as
    a **gasp** list.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，处理此问题的最佳方法是创建另一个函数，并将其添加到我们的 dataset.py 文件中，该函数将字符串转换为其数值表示（我们已经有一个将类别名称转换为数值的函数，并跟踪这些变化）。在我调整函数的过程中，它经历了
    3 次具体的迭代，分别是：1) 一个数据集和一个属性名称，其对应列的所有值应从字符串转换为浮点数；2) 一个数据集和一个属性名称列表……；以及 3) 一个数据集和单个属性作为字符串，或属性列表作为
    **喘息** 列表。
- en: The final iteration (the third, more flexible, option) is the one shown below.
    Let's add it to the dataset.py module from last time.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最终迭代（第三个，更灵活的选项）如下所示。让我们将其添加到上次的 dataset.py 模块中。
- en: OK, with that out of the way, we will be able to load a dataset, clean it, and
    create a (fully numeric) matrix representation, which can then be fed into our
    k-means clustering algorithm, once we have one. Speaking of which...
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，处理完这些问题后，我们就可以加载数据集，清理数据，并创建一个（完全数字化的）矩阵表示，然后将其输入到我们的 k-means 聚类算法中，一旦我们有了它。说到这儿……
- en: Initializing Centroids
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化质心
- en: 'The first thing our algorithm needs to do is to create a set of k initial centroids.
    There are a variety of ways to approach this, but we will start with the most
    basic: random initialization. We need a function that accepts a dataset and an
    integer k, and which will return an ndarray of that number of randomly-generated
    centroids.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的算法需要做的第一件事是创建一组 k 个初始质心。有多种方法可以实现这一点，但我们将从最基本的开始：随机初始化。我们需要一个接受数据集和整数 k 的函数，并返回该数量的随机生成的质心的
    ndarray。
- en: You may have already imagined how random initialization could go awry. As a
    quick example, think about 5 distinct, tightly clustered classes in 2 dimensional
    space, with a poorly initialized set of centroids, as shown below.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经想象过随机初始化可能出现的问题。举个简单的例子，考虑在二维空间中存在 5 个不同且紧密聚集的类别，以及一组初始化不佳的质心，如下所示。
- en: '![Poor initialization](../Images/a358cc3edb5802c92183f5a3e01fc170.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![初始化不佳](../Images/a358cc3edb5802c92183f5a3e01fc170.png)'
- en: Obviously non-optimal centroid initialization.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 显然是非最优的质心初始化。
- en: Even without the mathematics to support the intuition, it's clear that these
    centroids are not optimally placed. However, one of k-means' strong attributes
    is its ability to recover from such initialization, with successive rounds of
    clustering moving toward optimal placement by minimizing the mean distance between
    cluster instance members and cluster centroids.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有数学支持直觉，也很明显这些质心并没有被最优地放置。然而，k-means 的一个强大特性是它能够从这种初始化中恢复，随着聚类的多轮迭代，通过最小化簇实例成员和簇质心之间的平均距离，逐步趋向于最优放置。
- en: While this can happen remarkably quickly, poor initialization with sufficient
    amounts of high-dimensionality data can lead to a greater number of clustering
    iterations. The initial data space survey for random placement can also, itself,
    become lengthy. And so alternative methods for centroid initialization are available,
    some of which we may look at in the future.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能发生得非常快，但对于大量高维数据的糟糕初始化可能会导致更多的聚类迭代。随机放置的初始数据空间调查也可能变得冗长。因此，有一些替代的质心初始化方法，我们可能在未来会考虑。
- en: 'A quick note about testing our code: doing so as we go with heavily contrived
    scenarios seems more trouble than it''s worth, so we will hold out until the end
    to see how we did in total.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 关于测试我们代码的一个快速说明：在我们进行的过程中用高度构造的场景进行测试似乎不值得，因此我们会等到最后看看整体效果。
- en: Measuring Distances
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测量距离
- en: With a dataset in hand and a collection of initialized centroids, we will eventually
    have to perform a lot of measurement calculations. In fact, for each clustering
    iteration we will have to measure from each data point to each centroid, in order
    to know which cluster an instance belongs to (perhaps temporarily). So let's write
    a measurement function for Euclidean space. We will use [Scipy](https://www.scipy.org/)
    here for the heavy lifting; while coding a distance measurement is not very difficult,
    [Scipy includes a function](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.euclidean.html)
    optimized for such calculations on vectors, which, conveniently, is exactly what
    we will be doing.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 手头有数据集和一组初始化的质心后，我们最终需要进行大量的测量计算。实际上，对于每次聚类迭代，我们必须测量每个数据点到每个质心的距离，以确定实例属于哪个簇（也许是暂时的）。所以让我们为欧几里得空间编写一个测量函数。我们将在这里使用[Scipy](https://www.scipy.org/)进行繁重的计算；虽然编写距离测量并不困难，[Scipy
    包含一个函数](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.distance.euclidean.html)专门优化用于向量计算，这正是我们将要做的。
- en: Let's wrap this functionality in our own function, in case we want to later
    change or experiment with how we calculate distance.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这个功能封装到我们自己的函数中，以便以后我们想要更改或实验距离计算方式时使用。
- en: With the ability to initialize centroids and to make our measurements, we can
    now write a function to control the logic of our clustering algorithm, and perform
    the few additional required steps.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过初始化质心并进行测量，我们现在可以编写一个函数来控制聚类算法的逻辑，并执行一些额外的必要步骤。
- en: Clustering Instances
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聚类实例
- en: Before we look at the code, here is a simple overview of the process our algorithm
    will be following, taking into account the few functions from above, as well as
    below.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看代码之前，这里是我们算法将遵循的过程的简单概述，考虑到上面和下面的一些函数。
- en: '![k-means diagram](../Images/5d017022938992c978fc2e1c85279b66.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![k-means 图示](../Images/5d017022938992c978fc2e1c85279b66.png)'
- en: Our k-means clustering algorithm process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 k-means 聚类算法过程。
- en: The code below is well-commented, but let's walk through a few of the main points.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码有详细的注释，但让我们逐一了解几个要点。
- en: 'First, our function accepts a dataset as a numpy ndarray, as well as the number
    of clusters we want to use in the clustering process. It returns several things:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们的函数接受一个 numpy ndarray 数据集以及我们希望在聚类过程中使用的聚类数量。它会返回几个东西：
- en: the resulting centroids after clustering is finished
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类完成后的结果质心
- en: the cluster assignments after clustering
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类后的簇分配
- en: the number of iterations which were required by clustering algorithm
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类算法所需的迭代次数
- en: the original centroids
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始质心
- en: An ndarray to store instance cluster assignments and their errors are created,
    and then centroids are initialized, with a copy held to return later.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 ndarray 来存储实例簇分配及其误差，然后初始化质心，并保留一个副本以供后续返回。
- en: A while loop then continues until there has been no change to cluster assignments,
    meaning that convergence has been reached -- note that no additional mechanism
    to limit the number of iterations exists at this point. Instances to centroid
    distances are calculated, with the minimum distance tracked, which is used to
    determine cluster assignment. The closest centroid is then recorded, along with
    the actual distance between the 2 entities (the error), and a check is performed
    to see if the cluster assignment for the particular instances has changed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 while 循环继续，直到聚类分配没有变化，这意味着已达到收敛——注意，在此时并没有额外的机制来限制迭代次数。计算实例到质心的距离，并跟踪最小距离，这用于确定聚类分配。然后记录最近的质心以及两个实体之间的实际距离（误差），并检查特定实例的聚类分配是否发生了变化。
- en: After this has been performed for each instance, the centroid locations are
    updated, simply by using the mean values of the member instances as centroid coordinates.
    The number of iterations are also recorded. A check as to whether convergence
    has been reached kicks control out of the while loop once appropriate, and the
    items outlined above are returned.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在对每个实例执行此操作后，通过使用成员实例的均值作为质心坐标，来更新质心位置。迭代次数也会被记录。当检测到已达到收敛时，控制将跳出 while 循环，并返回上述项目。
- en: I want to point out that some of this code, as well as additional inspiration,
    comes from the book "[Machine Learning in Action](https://www.amazon.com/Machine-Learning-Action-Peter-Harrington/dp/1617290181/)"
    (MLIA), by Peter Harrington. I bought this book when it was first released, and
    it has proven invaluable for reasons related to the criticism the book often receives,
    most of which focuses on either not enough theory and/or issues with code. In
    my humble opinion, however, these are both assets. If you are like me, in that
    you came to the book with theoretical understanding, and are willing and able
    to fight through code which may need tuning, or which is simply enough that you
    can provide your own changes, MLIA can be a useful resource to anyone looking
    to make their first foray into coding machine learning algorithms.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我想指出的是，一些代码以及额外的灵感来自于 Peter Harrington 的书《[机器学习实战](https://www.amazon.com/Machine-Learning-Action-Peter-Harrington/dp/1617290181/)》（MLIA）。我在这本书首次发布时就购买了它，并且它已经证明对我来说是非常宝贵的，原因与这本书经常受到的批评有关，大多数批评集中在理论不足和/或代码问题上。然而，我认为这两者实际上都是资产。如果你像我一样，已经具备理论理解，并且愿意并且能够处理可能需要调整的代码，或者可以提供自己的修改，那么
    MLIA 对任何想要首次尝试编写机器学习算法的人来说，都是一个有用的资源。
- en: Testing Our k-means Clustering Algorithm
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试我们的 k-means 聚类算法
- en: There are a few typical tasks which we are going to forego for this post and
    will revisit later, but I wanted to point them out here.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个典型任务我们将跳过，稍后再回顾，但我想在这里指出这些任务。
- en: First, when clustering, especially with attributes of varying scales, it is
    generally a good idea to at least consider the idea of scaling or otherwise normalizing
    the data, to ensure that a single attribute (or collection of attributes) of a
    vastly greater scale then the others does not end up accounting for more than
    it should. If we have 3 attributes, with the first 2 in the range [0, 1] and the
    third in the range [0, 100], it's easy to see that the third variable will dominate
    the measurements and subsequent cluster membership allocations.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在进行聚类时，特别是当属性具有不同的尺度时，通常最好至少考虑对数据进行缩放或归一化，以确保某个尺度远大于其他尺度的单一属性（或属性集合）不会占据不应有的权重。如果我们有
    3 个属性，其中前两个在 [0, 1] 范围内，第三个在 [0, 100] 范围内，那么很容易看出第三个变量将主导测量结果和随后的聚类成员分配。
- en: Second, when clustering (as with much of machine learning), we can split a dataset
    into training and testing sets, allowing us to train a model on one subset of
    data, and then test the model on the other (separate) set of data. While this
    is not always part of the goal of a given clustering task, as we may simply want
    to build a clustering model and not be concerned with using it to classify subsequent
    instances, it often can be. We will proceed with our test code below without taking
    either of these into consideration at this point, but may double back in a subsequent
    post.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，在聚类（如同大多数机器学习任务）时，我们可以将数据集分成训练集和测试集，允许我们在一个子集上训练模型，然后在另一个（独立的）数据集上测试模型。虽然这并不总是给定聚类任务的目标，因为我们可能只是想构建一个聚类模型而不关心将其用于分类后续实例，但这往往是有用的。我们将在下面的测试代码中继续进行，而此时不考虑这两者，但可能会在后续的帖子中重新回顾。
- en: Before moving ahead, make sure you have added the dataset-related function outlined
    further above to the existing [dataset.py](https://gist.github.com/mmmayo13/935684dd226ef05f7d291e8cf5ed873a)
    module, and have created a [kmeans.py](https://gist.github.com/mmmayo13/956937ec1fc695163b8e052b55c09208)
    module to house all of the relevant functions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请确保你已将上面概述的数据集相关函数添加到现有的 [dataset.py](https://gist.github.com/mmmayo13/935684dd226ef05f7d291e8cf5ed873a)
    模块中，并已创建一个 [kmeans.py](https://gist.github.com/mmmayo13/956937ec1fc695163b8e052b55c09208)
    模块来容纳所有相关函数。
- en: 'Let''s try our code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一下我们的代码：
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Looks good! This particular test of our code resulted in the above, but you
    will find that subsequent iterations return different results -- at least, different
    numbers of iterations and sets of original centroids.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错！这次我们代码的测试结果如上所示，但你会发现随后的迭代会返回不同的结果——至少是不同的迭代次数和初始质心集合。
- en: Looking Ahead
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 展望未来
- en: Though we have not yet evaluated our clustering results, we will stop here for
    now... but, on that note, I bet you can guess what is in store for the next post.
    Next time we will focus on a few more clustering-related activities. We have an
    algorithm which we can use to build models, but there needs to be some mechanisms
    for evaluating and visualizing their results. This is what we will get to next.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们还没有评估我们的聚类结果，但我们现在暂时停在这里……不过，说到这一点，我敢打赌你可以猜到下一篇文章会涉及什么。下次我们将重点关注更多与聚类相关的活动。我们有一个可以用来构建模型的算法，但还需要一些机制来评估和可视化它们的结果。这将是我们接下来要做的事情。
- en: Thinking further ahead, I then plan to turn our attention to classification
    using the k-nearest neighbors algorithm, as well a number of classification-related
    tasks. Once again, I hope you have found this helpful enough to check the next
    installment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步思考，我计划将注意力转向使用k最近邻算法进行分类，以及一些与分类相关的任务。再次希望你觉得这部分内容足够有用，可以查看下一期内容。
- en: '**Related**:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**：'
- en: '[Machine Learning Workflows in Python from Scratch Part 1: Data Preparation](/2017/05/machine-learning-workflows-python-scratch-part-1.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从头开始的Python机器学习工作流第1部分：数据准备](/2017/05/machine-learning-workflows-python-scratch-part-1.html)'
- en: '[Toward Increased k-means Clustering Efficiency with the Naive Sharding Centroid
    Initialization Method](/2017/03/naive-sharding-centroid-initialization-method.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用朴素分片质心初始化方法提升k-means聚类效率](/2017/03/naive-sharding-centroid-initialization-method.html)'
- en: '[K-Means & Other Clustering Algorithms: A Quick Intro with Python](/2017/03/k-means-clustering-algorithms-intro-python.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[K-Means与其他聚类算法：使用Python的快速入门](/2017/03/k-means-clustering-algorithms-intro-python.html)'
- en: '* * *'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类揭秘：理解 K-Means 聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
- en: '[Hands-On with Unsupervised Learning: K-Means Clustering](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无监督学习实操：K-Means 聚类](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[K-Means 聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
- en: '[What is K-Means Clustering and How Does its Algorithm Work?](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是 K-Means 聚类及其算法如何工作？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)'
- en: '[DBSCAN Clustering Algorithm in Machine Learning](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的 DBSCAN 聚类算法](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)'
- en: '[Introduction to Clustering in Python with PyCaret](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyCaret 在 Python 中进行聚类的简介](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
