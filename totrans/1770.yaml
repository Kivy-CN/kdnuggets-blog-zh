- en: Machine Learning Finds “Fake News” with 88% Accuracy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习以88%的准确率发现“假新闻”
- en: 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)
- en: '**By George McIntire, Contributing Data Science Writer, ODSC**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**乔治·麦金太尔，数据科学撰稿人，ODSC**'
- en: '![Donald Trump](../Images/c4c806c5213c7410a605b76b4daa4706.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![特朗普](../Images/c4c806c5213c7410a605b76b4daa4706.png)'
- en: “A lie gets halfway around the world before the truth has a chance to get its
    pants on.”
  id: totrans-4
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: “谎言在真相来得及穿上裤子之前已经绕了半个地球。”
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – Winston Churchill
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 温斯顿·丘吉尔
- en: Since the 2016 presidential election, one topic dominating political discourse
    is the issue of “Fake News”. A number of political pundits claim that the rise
    of significantly biased and/or untrue news influenced the election, though a [study
    by researchers](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)
    from Stanford and New York University concluded otherwise. Nonetheless, fake news
    posts have exploited Facebook users’ feeds to propagate throughout the internet.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自2016年总统选举以来，政治话语中主导的话题之一是“假新闻”问题。许多政治评论员声称，显著偏见和/或不真实新闻的兴起影响了选举，尽管[斯坦福大学和纽约大学的研究者](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)得出了不同的结论。尽管如此，虚假新闻帖子已经利用Facebook用户的动态在互联网上传播。
- en: '****“What is fake news?”****'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '****“什么是假新闻？”****'
- en: Obviously, a deliberately misleading story is “fake news” but lately blathering
    social media discourse,  is changing its definition. Some now use the term to
    dismiss facts counter to their preferred viewpoints, the most prominent example
    being [President Trump](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd).
    Such a vaguely-defined term is ripe for a cynical manipulation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，有意误导的故事是“假新闻”，但最近喧嚣的社交媒体话语正在改变其定义。有些人现在用这个术语来驳斥与他们偏好观点相反的事实，最显著的例子是[特朗普总统](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd)。这样的模糊定义的术语容易受到愤世嫉俗的操控。
- en: 'The data science community has responded by [taking action to fight the problem](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/).
    There’s a Kaggle-style competition called the “[Fake News Challenge](http://www.fakenewschallenge.org/)” and
    [Facebook is employing AI](https://techcrunch.com/2016/11/14/facebook-fake-news/) to
    filter fake news stories out of users’ feeds. Combating fake news is a classic
    text classification project with a straight-forward proposition: ***Can you build
    a model that can differentiate between “Real” news vs “Fake” news.***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学社区已回应，通过[采取行动解决问题](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/)。有一个类似Kaggle的比赛叫做“[假新闻挑战](http://www.fakenewschallenge.org/)”，而[Facebook正在使用人工智能](https://techcrunch.com/2016/11/14/facebook-fake-news/)来过滤用户动态中的虚假新闻。对抗虚假新闻是一个经典的文本分类项目，提出了一个直接的问题：***你能否建立一个模型来区分“真实”新闻与“虚假”新闻？***
- en: And that’s exactly what I attempted to do for this project. I assembled a dataset
    of fake and real news and employed a [Naive Bayes](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
    classifier in order to create a model to classify an article as fake or real based
    on its words and phrases.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我在这个项目中所尝试做的。我组建了一个包含虚假和真实新闻的数据集，并使用了[朴素贝叶斯](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)分类器，以创建一个模型，根据文章的词汇和短语将其分类为虚假或真实。
- en: Data Gather/Wrangling
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集/整理
- en: There were two parts to the data acquisition process, getting the “fake news”
    and getting the real news. The first part was quick, Kaggle released a [fake news
    dataset](https://www.kaggle.com/mrisdal/fake-news) comprising of 13,000 articles
    published during the 2016 election cycle.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据获取过程分为两个部分：获取“假新闻”和获取真实新闻。第一部分很快完成，Kaggle 发布了一个 [假新闻数据集](https://www.kaggle.com/mrisdal/fake-news)，包括13000篇在2016年选举周期内发布的文章。
- en: The second part was… a lot more difficult.  To acquire the real news side of
    the dataset, I turned to [All Sides](http://www.allsides.com/), a website dedicated
    to hosting news and opinion articles from across the political spectrum. Articles
    on the website are categorized by topic (environment, economy, abortion, etc…)
    and by political leaning (left, center, and right). I used All Sides because it
    was the best way to web scrape thousands of articles from numerous media outlets
    of differing biases. Plus, it allowed to me download the full text of an article,
    something you cannot do with the New York Times and NPR APIs. After a long and
    arduous process I ended up scraping a total of **5279 articles**. The articles
    in my real news dataset came from media organizations such as the New York Times,
    WSJ, Bloomberg, NPR, and the Guardian and were published in 2015 or 2016.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分就…困难得多。为了获取数据集中的真实新闻部分，我转向了 [All Sides](http://www.allsides.com/)，一个致力于发布来自不同政治立场的新闻和意见文章的网站。网站上的文章按主题（环境、经济、堕胎等）和政治倾向（左、中、右）进行分类。我使用
    All Sides 是因为这是从众多媒体渠道中抓取数千篇文章的最佳方法。此外，它允许我下载文章的完整文本，而这是纽约时报和 NPR API 无法做到的。在经过漫长而艰难的过程后，我最终抓取了
    **5279 篇文章**。我的真实新闻数据集中的文章来自于纽约时报、华尔街日报、彭博社、NPR 和卫报等媒体组织，并且这些文章的发布时间为2015年或2016年。
- en: I decided to construct my full dataset with equal parts fake and real articles,
    thus making my model’s null accuracy 50%. I randomly selected 5279 articles from
    my fake news dataset to use in my complete dataset and left the remaining articles
    to be used as a testing set when my model was complete.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定将我的完整数据集构建为假新闻和真实新闻各占一半，从而使我的模型的无效准确率为50%。我随机从假新闻数据集中选择了5279篇文章用于我的完整数据集，其余的文章则保留作为模型完成后的测试集。
- en: My finalized dataset was comprised of 10558 total articles with their headlines
    and full body text and their labels (real vs fake). The data is located here in
    this [github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最终数据集包含了总共10558篇文章，包括它们的标题、全文和标签（真实与虚假）。这些数据可以在这个 [github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset)
    中找到。
- en: Purpose and Expectations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目的与期望
- en: When I first started this project, I conceded that this would not be the perfect
    project. The purpose of this project was to see how far I could get in creating
    a fake news classification and what insights could be drawn from that, then used
    towards a better model. My game plan was to treat this project the same way as
    a routine spam detection project.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我刚开始这个项目时，我承认这不会是一个完美的项目。这个项目的目的是看看我能在创建假新闻分类模型上取得多大进展，以及从中能获得什么见解，然后用这些见解改进模型。我的计划是将这个项目当作一个常规的垃圾邮件检测项目来处理。
- en: Building a model based on a count vectorizer (using word tallies) or a tfidf
    matrix (word tallies relative to how often they’re used in other articles in your
    dataset) can only get you so far. These methods do not consider important qualities like
    the word ordering and context. It’s very possible for two articles that are similar
    in their word counts to be totally different in their meaning. I did not expect
    my model to be adept at handling fake and real articles whose words and phrases
    overlap. Nonetheless, I expect some valuable insights to come from this project.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 基于计数向量化器（使用词频）或 tfidf 矩阵（词频相对于在数据集中其他文章中的使用频率）构建模型只能达到一定程度。这些方法并未考虑重要的特性，如词序和上下文。两个在词频上类似的文章可能在意义上完全不同。我并不期望我的模型能够很好地处理词语和短语重叠的假新闻和真实新闻。不过，我期待从这个项目中获得一些有价值的见解。
- en: Modeling
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建模
- en: Since this is a text classification project, I only used a Naive Bayes classifier
    as is standard for text-based data science projects.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个文本分类项目，我仅使用了朴素贝叶斯分类器，这在基于文本的数据科学项目中是标准做法。
- en: The real work in formulating a model was the text transformation (count vectorizer
    vs tfidf vectorizer) and choosing which type of text to use (headlines vs full
    text). This gave me four pairs of reconfigured datasets to work with.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 制定模型的真正工作是文本转换（`count vectorizer`与`tfidf vectorizer`）和选择使用哪种类型的文本（标题与全文）。这给了我四对重新配置的数据集来处理。
- en: The next step was to determine the most optimal parameters for either a countvectorizer
    or tfidf-vectorizer. For those of you who are unfamiliar with text machine learning,
    this means using a n-number of the most common words, using words and/or phrases,
    lower casing or not, removing stop words (common words such as the, when, and
    there) and only using words that appear at least a given number of times in a text
    corpus (a term for a text dataset or a collection of texts).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是确定`countvectorizer`或`tfidf-vectorizer`的最优参数。对于那些不熟悉文本机器学习的人，这意味着使用最常见的`n`个单词，使用单词和/或短语，是否转换为小写，去除停用词（例如“the”、“when”和“there”等常见词），以及仅使用在文本语料库中出现至少给定次数的单词（语料库是文本数据集或文本集合的术语）。
- en: To test the performance of multiple parameters and their numerous combinations,
    I utilized the Sci-kit Learn’s GridSearch functionality to efficiently execute
    this task. To learn more about how to perfect your algorithm parameters, please
    review [this tutorial](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试多个参数及其各种组合的性能，我利用了Sci-kit Learn的GridSearch功能来高效地执行此任务。要了解如何优化算法参数，请查看[这个教程](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)。
- en: After the grid search cross validation process, I found that my model worked
    best with a count vectorizer instead of a tfidf and produced higher scores when trained
    on the full text of articles instead of their headlines. The optimal parameters
    for count vectorizer are no lowercasing, two-word phrases not single words, and to
    only use words that appear at least three times in the corpus.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索交叉验证过程之后，我发现我的模型在`count vectorizer`上表现最佳，而不是在`tfidf`上，并且在训练于文章全文时比在标题上得分更高。`count
    vectorizer`的最优参数是：不转换为小写，使用双词短语而不是单词，并且只使用在语料库中出现至少三次的单词。
- en: Given my expectations that I outlined earlier in this post, I was surprised
    and almost baffled at the high scores my model produced. My model’s cross-validated
    accuracy score is 91.7%, recall (true positive rate) score is 92.6%, and its AUC
    score is 95%.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我在这篇文章中之前概述的期望，我对我的模型所产生的高分感到惊讶甚至困惑。我的模型的交叉验证准确率为91.7%，召回率（真正阳性率）为92.6%，AUC评分为95%。
- en: Here is the ROC Curve for my model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我模型的ROC曲线。
- en: '[![ROC Curve](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[![ROC 曲线](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)'
- en: If I were to decide on a threshold for a model based on this graph, I would
    choose one that produces a FPR at around 0.08 and a TPR at around 0.90, because
    at that point in the graph the trade off between false positives and true positives
    is equal.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我根据这个图表为模型选择一个阈值，我会选择一个在0.08左右产生假阳性率（FPR）和0.90左右产生真正阳性率（TPR）的阈值，因为在图表的那个点上，假阳性和真正阳性的权衡是相等的。
- en: Results & Conclusion
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果与结论
- en: The true test of my model’s quality would be to see how fake news articles in
    the test set (those not used in the creation of my model) it could accurately
    classify.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对我的模型质量的真正考验将是看看它能否准确分类测试集中（那些未用于创建我的模型的）假新闻文章。
- en: '**Out of the 5234 articles left in the other fake news datasets, my model was
    able to correctly identify 88.2% of them as fake.** This is 3.5 percentage points
    lower than my cross-validated accuracy score, but in my opinion it is pretty decent
    evaluation of my model.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**在5234篇其他假新闻数据集中，我的模型能够正确识别88.2%的假新闻。** 这比我的交叉验证准确率低了3.5个百分点，但在我看来，这是对我的模型相当不错的评估。'
- en: It turns out that my hypothesis predicting that model would struggle at classifying
    news articles was quite wrong. I thought that an accuracy score in the upper 60s
    or lower 70s would be excellent and I managed to surpass that by a significant
    margin.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明我预测模型在分类新闻文章时会遇到困难的假设是错误的。我原以为准确率在60多岁或70多岁就已经很出色，但我成功地超越了这个预期。
- en: Even though I created what appears to be a pretty good model given the complexity
    of the task, I am not entirely convinced that it is as good as it appears to be
    and here’s why.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我创建了一个在任务复杂性面前看起来相当不错的模型，但我并不完全相信它看起来那么好，原因如下。
- en: To be better understand why this might have happened, let’s take a look at the
    “fakest” and “realest” words in the data—I’ll explain what I mean by that.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解为什么会发生这种情况，我们来看一下数据中“最虚假”和“最真实”的词汇——我会解释我所说的含义。
- en: Using a technique I borrowed from Kevin Markham of Data School, here’s how I
    derived the “fakest” and “realest” words in the corpus. First I started off with
    a table two columns wide and 10558 rows long (that’s how many words there are
    in the corpus). The first column represented how many times a given word appeared
    in articles classified as “FAKE” and the second column was how many times a word appeared
    in a “REAL” article.  Then I divided the fake column by the total number of fake
    articles my model classified and so on for the real column. Next, I added the
    number one to every value in the data because I created a new column of “Fake:Real”
    ratios and didn’t want to get an error by dividing zero. This “Fake:Real” is a
    pretty good but by no means perfect metric of just how “fake” or “real a certain
    word. The logic is pretty simple, if a word shows up a bunch in “fake” articles
    and rarely in “real” articles then its fake to real ratio score will be pretty
    high.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我从Data School的Kevin Markham那里借用的一种技术，以下是我如何得出语料库中的“最虚假”和“最真实”词汇的。首先，我创建了一个两列宽、10558行长的表格（这是语料库中的词汇数量）。第一列表示某个词在被分类为“虚假”的文章中出现的次数，第二列则是该词在“真实”文章中出现的次数。接着，我将虚假列的数值除以我模型分类的虚假文章总数，真实列也是如此。然后，我在数据中的每个值上加了1，因为我创建了一个新的“虚假:真实”比率列，并且不希望因为除以零而出现错误。这个“虚假:真实”比率是一个相当不错但并非完美的指标，用来衡量一个词汇的“虚假”或“真实”程度。逻辑很简单，如果一个词汇在“虚假”文章中频繁出现，而在“真实”文章中很少出现，那么它的虚假对真实比率得分将会很高。
- en: Here are the top 20 “fakest” and “realest” words in my dataset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我的数据集中前20个“最虚假”和“最真实”的词汇。
- en: '[![Fakest](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[![最虚假](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)'
- en: '[![Realest](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[![最真实](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)'
- en: These two graphics exhibit some baffling results. The words in the “fake” chart
    are a mixed bag that includes some typical internet terminology such as PLEASE,
    Share, Posted, html, and Widget and words that aren’t even words such as tzrwu. However
    I was not surprised to see infowars mentioned nor terms like “Sheeple” or “UFO”
    make it in the top 20 “fakest” words. Infowars is a right-wing conspiracy-laden
    outlet led by Alex Jones that promotes conspiracy theories about chemtrails and
    9/11.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个图表展示了一些令人困惑的结果。“虚假”图表中的词汇是一混合包，包括一些典型的互联网术语，如PLEASE、Share、Posted、html和Widget，以及一些甚至不是词汇的字符组合，如tzrwu。然而，我看到infowars被提及，或者像“Sheeple”或“UFO”这样的词汇进入前20个“最虚假”词汇并不感到惊讶。Infowars是一个由亚历克斯·琼斯领导的右翼阴谋论媒体，推广有关化学喷剂和9/11的阴谋论。
- en: The “real” chart is dominated by names and politicians and words frequently
    used in political articles, comprising 60% of the bars in the chart. Seven of
    the twenty terms, including four of the top six, are politician names. This begs
    the question, are articles about politicians more likely to be true? No of course
    not, if anything you’d expect there to be numerous fake news articles spreading
    falsehoods about politicians. I would be committing a huge error if I came to
    the conclusion that articles mentioning politicians are more likely to be to factual.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: “真实”图表被名字和政治人物主导，这些词汇在政治文章中频繁出现，占图表条形的60%。二十个术语中有七个，包括前六名中的四个，是政治人物的名字。这引发了一个问题：关于政治人物的文章更可能真实吗？当然不是，如果有的话，你会期望有很多关于政治人物的虚假新闻文章传播虚假信息。如果我得出结论认为提到政治人物的文章更有可能是真实的，那将是一个巨大的错误。
- en: One big assumption underlying this project is that there is considerable overlap
    in the topics covered by each class of article. As we witnessed above, just because
    a certain word shows up more often in “real” news than “fake” news it doesn’t
    mean that articles with those terms are guaranteed to be “real”, but instead could
    just mean that those words are used in topics more common in the real news dataset
    and vice versa for the fake news dataset.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的一个重大假设是，每类文章所覆盖的主题之间存在相当大的重叠。正如我们上面所见，仅仅因为某个词在“真实”新闻中出现的频率比在“虚假”新闻中高，并不意味着包含这些词的文章一定是“真实”的，而可能只是因为这些词用于真实新闻数据集中更常见的话题，反之亦然。
- en: I and another party had a considerable amount of influence in shaping this dataset.
    I made the decision on which articles to use for the “real” dataset. The articles
    in the “fake” dataset were determined by a [chrome extension called “BS Detector”](https://github.com/selfagency/bs-detector) made
    by Daniel Sieradski. There is a significantly high amount of subjectivity going
    into determining what is and what isn’t “fake news”. The reason why politician
    names are rated as “real” so highly is most likely because that half of the corpura disproportionately
    comes from political news. In addition, I did find a couple of articles from what
    I find to be reputable sources of news. One such article came from The Intercept,
    a news organization with high journalism standards. And yes, my model did indeed
    flag this supposed “fake news” article as real.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我和另一方在塑造这个数据集方面有着相当大的影响。我决定了哪些文章用于“真实”数据集。“虚假”数据集中的文章则由[一个名为“BS Detector”的 Chrome
    扩展](https://github.com/selfagency/bs-detector)确定，该扩展由 Daniel Sieradski 制作。确定什么是“虚假新闻”存在显著的主观性。政治人物名字被评为“真实”如此之高，很可能是因为语料库的一半不成比例地来自政治新闻。此外，我确实找到了一些我认为是可信新闻来源的文章。其中一篇来自《拦截者》，这是一个具有高标准新闻报道的新闻机构。是的，我的模型确实将这篇所谓的“虚假新闻”文章标记为真实。
- en: To make matters even more complicated, we have to decide how to set the threshold
    probability for our model. If I was a data scientist at Facebook tasked with implementing
    a model that sorts out real and fake news in users’ feeds, I’d be faced with the
    dilemma between choosing a model that blocks all or most fake news and some real
    news or a model that allows all or most real news and some fake news. But before
    I make that decision, I need to figure what is the cost of failing to prevent
    fake news vs the cost of blocking real news? How does one attempt to answer such
    an abstract question? Unless we can train a model with a 100% true positive rate
    and 0% false positive rate, we’ll be stuck with this quandary.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的是，我们必须决定如何为我们的模型设置阈值概率。如果我是 Facebook 的数据科学家，负责实施一个将真实新闻和虚假新闻从用户的动态中分类的模型，我将面临在选择一个阻挡所有或大多数虚假新闻和一些真实新闻的模型，还是选择一个允许所有或大多数真实新闻和一些虚假新闻的模型之间的困境。但在做出决定之前，我需要搞清楚，未能防止虚假新闻与阻挡真实新闻的成本分别是多少？如何尝试回答这样一个抽象的问题？除非我们能训练出一个100%真正率和0%假正率的模型，否则我们将陷入这个困境。
- en: In conclusion, while I think that a standard Naive Bayes text classification
    model can provide insight into addressing this issue, a more powerful deep-learning
    tool should be employed to combat fake news in a professional setting.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，虽然我认为一个标准的朴素贝叶斯文本分类模型可以为解决这个问题提供一些见解，但在专业环境中应使用更强大的深度学习工具来对抗虚假新闻。
- en: Classifying “fake news” provides a novel challenge to the data science community.
     In many machine learning projects, the distinction between the different classes
    you want to predict is clear, whereas it’s a lot murkier in this case. This project
    validates the notion in data science that intuition and intimacy with your data
    is just as or more important than any model or tool at your disposal.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对“虚假新闻”的分类给数据科学界带来了全新的挑战。在许多机器学习项目中，你要预测的不同类别之间的区别很明确，而在这种情况下则模糊得多。这个项目验证了数据科学中的一个观点，即对数据的直觉和熟悉度与任何模型或工具同样重要，甚至更为重要。
- en: '**Bio: [George McIntire](https://opendatascience.com/author/george-mcintire/)**
    is a journalist turned data scientist/journalist hybrid. Looking for opportunities
    in data science and/or journalism. Impossibly curious and passionate about learning
    new things. Before completing the Metis Data Science Bootcamp, he worked as a
    freelance journalist in San Francisco for Vice, Salon, SF Weekly, San Francisco
    Magazine, and more.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/).
    Reposted with permission.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[It’s Getting Hot In Here: Data Science vs Fake News](/2017/03/getting-hot-here-data-science-vs-fake-news.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Happened Last Night in Sweden: Data Science vs Fake News](/2017/03/last-night-sweden-data-science-vs-fake-news.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beware of Two Data Obfuscation Tactics](/2017/04/beware-two-data-obfuscation-tactics.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Which Metric Should I Use? Accuracy vs. AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sky''s the Limit: Learn how JetBlue uses Monte Carlo and Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
