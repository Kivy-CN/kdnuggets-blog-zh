- en: A Friendly Introduction to Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/09/friendly-introduction-support-vector-machines.html](https://www.kdnuggets.com/2019/09/friendly-introduction-support-vector-machines.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![Figure](../Images/87972bdfa7419ae6b2f2b45a2dd0e27b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pic Credit: [analyticsprofile](https://analyticsprofile.com/machine-learning/introduction-to-svm-machine-learning-algorithm-learn-to-code-support-vector-machine-using-sklearn-in-python/)'
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning is considered as a subfield of Artificial Intelligence and
    it is concerned with the development of techniques and methods which enable the
    computer to learn. In simple terms development of algorithms which enable the
    machine to learn and perform tasks and activities. Machine learning overlaps with
    statistics in many ways. Over a period of time, many techniques and methodologies
    were developed for machine learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we are going to learn almost everything about one such supervised
    machine learning algorithm which can be used for both classification and regression(SVR)
    i.e. **Support Vector Machine or simply SVM.** We’ll be focusing on classification
    in this article.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Support Vector Machines(SVM) are among one of the most popular and talked about
    machine learning algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: They were extremely popular around the time they were developed in the 1990s
    and continue to be the go-to method for a high-performing algorithm with a little
    tuning.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of **SVM is to find a hyperplane in an N-dimensional space (N-Number
    of features) that distinctly classifies the data points.**
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine is a generalization of maximal margin classifier. This
    classifier is simple, but it cannot be applied to the majority of the datasets
    since the classes must be separated by a boundary which is linear. But it does
    explain how the SVM works.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of [support-vector machines](https://en.wikipedia.org/wiki/Support-vector_machine),
    the *optimally separating hyperplane* or *maximum-margin hyperplane* is a [hyperplane](https://en.wikipedia.org/wiki/Hyperplane) which
    separates two [convex hulls](https://en.wikipedia.org/wiki/Convex_hull) of points
    and is [equidistant](https://en.wikipedia.org/wiki/Equidistant) from the two.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure](../Images/21c9de8bfed3212c9e2866ebf787bd8a.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Maximum Margin Classifier](https://en.wikipedia.org/wiki/Hyperplane_separation_theorem#/media/File:Separating_axis_theorem2008.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Ok. **What is a hyperplane?**
  prefs: []
  type: TYPE_NORMAL
- en: In an N-dimensional space, a hyperplane is a flat affine subspace of dimension
    N-1\. Visually, in a 2D space, a hyperplane will be a line and in 3D space, it
    will be a flat plane.
  prefs: []
  type: TYPE_NORMAL
- en: In simple terms, hyperplane is a decision boundary that helps classifying data
    points.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure](../Images/47bb5f2de015d58d7a141c6afc7ad8cf.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Hyperplane in 2D and 3D space](https://deepai.org/machine-learning-glossary-and-terms/hyperplane)'
  prefs: []
  type: TYPE_NORMAL
- en: Now, to separate two classes of data points, there are many possible hyperplanes
    that could be chosen. Our objective is to find a plane that has the maximum margin
    i.e. the maximum distance between data points of both classes and below figure
    clearly explains this fact.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/0b8c79e9d74e47fa334c51d999b78352.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Possible Hyperplanes and Hyperplane with maximum margin](https://www.ques10.com/p/41200/support-vector-machine-1/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hyperplane with maximum margin looks something like this in 3D space:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/24f471102f9e058c4f37cfdee15b98fc.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Visual representation of Hyperplane in 3D](http://www.eurospottv.com/support-vector-machines/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:- The dimension of Hyperplane depends on the number of features.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Support Vectors**'
  prefs: []
  type: TYPE_NORMAL
- en: Support Vectors are the data points that are on or closest to the hyperplane
    and influence the position and orientation of the hyperplane. Using these support
    Vectors we maximize the margin of the classifier and deleting these support vectors
    will change the position of the hyperplane. These are actually the points that
    help us build SVM.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a35d721dbf716338c69783e3afefaad5.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Support Vectors](https://www.hackerearth.com/blog/developers/simple-tutorial-svm-parameter-tuning-python-r/)'
  prefs: []
  type: TYPE_NORMAL
- en: Support Vectors are equidistant from the hyperplane. They are called support
    vectors because if their position shifts, the hyperplane shifts as well. This
    means that the **hyperplane depends only on the support vectors** and not on any
    other observations.
  prefs: []
  type: TYPE_NORMAL
- en: SVM that we have discussed until now can only classify the data which is linearly
    separable.
  prefs: []
  type: TYPE_NORMAL
- en: '**What if the data is non-linearly separated?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example: look at the below image where the data is non-linearly separated,
    of course, we cannot draw a straight line to classify the data points.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/0a227385954be9f7ab0ae505cfe206a2.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Non-linearly separated data](https://towardsdatascience.com/applied-deep-learning-part-1-artificial-neural-networks-d7834f67a4f6)'
  prefs: []
  type: TYPE_NORMAL
- en: Here comes the concept of Kernel in SVM to classify non-linearly separated data. **A
    kernel is a function which maps a lower-dimensional data into higher dimensional
    data.**
  prefs: []
  type: TYPE_NORMAL
- en: There are two ways by which kernel SVM will classify non-linear data.
  prefs: []
  type: TYPE_NORMAL
- en: Soft margin
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kernel tricks
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Soft Margin**'
  prefs: []
  type: TYPE_NORMAL
- en: It allows SVM to make a certain number of mistakes and keep the margin as wide
    as possible so that other points can still be classified correctly.
  prefs: []
  type: TYPE_NORMAL
- en: “In other words, SVM tolerates a few dots to get misclassified and tries to
    balance the tradeoff between finding the line that maximizes the margin and minimizes
    misclassification.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'There are two types of misclassifications can happen:'
  prefs: []
  type: TYPE_NORMAL
- en: The data point is on the wrong side of the decision boundary but on the correct
    side
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The data point is on the wrong side of the decision boundary and on the wrong
    side of the margin
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***Degree of tolerance***'
  prefs: []
  type: TYPE_NORMAL
- en: How much tolerance we want to set when finding the decision boundary is an important
    hyper-parameter for the SVM (both linear and nonlinear solutions). In Sklearn,
    it is represented as the penalty term — ‘C’.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a93d285b34038d269643fc90231eeebb.png)'
  prefs: []
  type: TYPE_IMG
- en: The bigger the C, the more penalty SVM gets when it makes misclassification.
    Therefore, the narrower the margin is and fewer support vectors the decision boundary
    will depend on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kernel Trick**'
  prefs: []
  type: TYPE_NORMAL
- en: The idea is mapping the non-linear separable data from a lower dimension into
    a higher dimensional space where we can find a hyperplane that can separate the
    data points.
  prefs: []
  type: TYPE_NORMAL
- en: So it is all about finding the mapping function that transforms the 2D input
    space into a 3D output space and to reduce the complexity of finding the mapping
    function SVM uses Kernel Functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kernel Functions** are generalized functions that take 2 vectors(of any dimension)
    as input and output a score(dot product) that denotes how similar the input vectors
    are. If the dot product is small, vectors are different and if the dot product
    is large, vectors are more similar.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/b561f3ef63d0fab5931d30d854aef027.png)'
  prefs: []
  type: TYPE_IMG
- en: Mathematical representation of Kernel Function
  prefs: []
  type: TYPE_NORMAL
- en: 'Pictorial representation of Kernel Trick :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/6aea321318b92a590e34b7f6534500ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Visual representation of Kernel Trick :'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e09b48870979dd37922d816e3cc87e71.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Kernel Trick in action, by udiprod in Youtube](https://www.youtube.com/watch?v=3liCbRZPrZA)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Types of Kernel Functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Polynomial
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Radial Basis Function(rbf)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sigmoid
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's talk about the most used kernel function i.e. **Radial Basis Function(rbf)**.
  prefs: []
  type: TYPE_NORMAL
- en: Think of rbf as a transformer/processor to generate new features of higher dimension
    by measuring the distance between all other data points to a specific dot.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most popular rbf kernel is Gaussian Radial Basis function. Mathematically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7899ef401799d7ee9a20c1936d4d67bc.png)'
  prefs: []
  type: TYPE_IMG
- en: where gamma(????) controls the influence of new features on the decision boundary.
    Higher the value of ????, more influence of features on the decision boundary.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to Regularization parameter/penalty term(C) in the soft margin, Gamma(????)
    is a hyperparameter that can be tuned when we use kernel trick.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SVM has many uses ranging from face detection, image classification, Bioinformatics,
    Protein fold, and remote homology detection, handwriting recognition, generalized
    Predictive control(GPC), etc.
  prefs: []
  type: TYPE_NORMAL
- en: That's all for this article on Support Vector Machine which is one of the most
    powerful algorithms for both regression and classification. In the next article,
    we’ll see how to solve a real-world problem using SVM.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you guys have enjoyed reading this article, feel free to share your comments/thoughts/feedback
    in the comment section.
  prefs: []
  type: TYPE_NORMAL
- en: Please reach me out over [LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/) for
    any query.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!!!
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Data Science enthusiast. Interested in Big Data, Python, Machine Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/a-friendly-introduction-to-support-vector-machines-svm-925b68c5a079).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction to Image Segmentation with K-Means clustering](/2019/08/introduction-image-segmentation-k-means-clustering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Classifying Heart Disease Using K-Nearest Neighbors](/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Predict Age and Gender Using Convolutional Neural Network and OpenCV](/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Beginner Friendly Python Projects That Are Fun!](https://www.kdnuggets.com/2022/10/beginner-friendly-python-projects-fun.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Beginner-Friendly Projects to Get You Started with ChatGPT](https://www.kdnuggets.com/2023/08/7-beginnerfriendly-projects-get-started-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
