- en: How to Make Large Language Models Play Nice with Your Software Using LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用LangChain让大型语言模型与您的软件良好配合
- en: 原文：[https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/036f2f1921d5d651c1a5c147edef3126.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何使用LangChain让大型语言模型与您的软件良好配合](../Images/036f2f1921d5d651c1a5c147edef3126.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图片
- en: Large Language Models (LLMs) like OpenAI’s GPT-3, Google’s BERT, and Meta’s
    LLaMA are revolutionizing various sectors with their ability to generate a wide
    array of text?—?from marketing copy and data science scripts to poetry.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 像OpenAI的GPT-3、Google的BERT和Meta的LLaMA这样的**大型语言模型**正在以其生成各种文本的能力革新多个领域——从营销文案和数据科学脚本到诗歌。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Even though ChatGPT’s intuitive interface has managed to be in most people's
    devices today, there’s still a vast landscape of untapped potential for using
    LLMs in diverse software integrations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ChatGPT的直观界面已经在大多数人设备上普及，但在多种软件集成中使用LLMs仍有广阔的未开发潜力。
- en: The main problem?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 主要问题是什么？
- en: Most applications require more fluid and native communication with LLMs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数应用程序需要与LLMs进行更流畅和本地化的沟通。
- en: And this is precisely where LangChain kicks in!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 而这正是LangChain发挥作用的地方！
- en: If you are interested in Generative AI and LLMs, this tutorial is tailor-made
    for you.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对生成式AI和LLMs感兴趣，这个教程是为你量身定制的。
- en: So… let’s start!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么…让我们开始吧！
- en: What are LLMs?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM是什么？
- en: Just in case you have been living within a cave and haven’t gotten any news
    lately, I’ll briefly explain Large Language Models or LLMs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最近一直在过着与世隔绝的生活，还没有获得任何新闻，我将简要介绍一下**大型语言模型（LLMs）**。
- en: An LLM is a sophisticated artificial intelligence system built to mimic human-like
    textual understanding and generation. By training on enormous data sets, these
    models discern intricate patterns, grasp linguistic subtleties, and produce coherent
    outputs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LLM（大型语言模型）是一个复杂的人工智能系统，旨在模拟类似人类的文本理解和生成。通过在大量数据集上进行训练，这些模型能够辨别复杂的模式、理解语言的细微差别，并生成连贯的输出。
- en: 'If you wonder how to interact with these AI-powered models, there are two main
    ways to do so:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道如何与这些AI驱动的模型互动，主要有两种方法：
- en: The most common and direct way is talking or chatting with the model. It involves
    crafting a prompt, sending it to the AI-powered model, and getting a text-based
    output as a response.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最常见和直接的方法是与模型对话或聊天。这涉及到编写提示，将其发送到AI驱动的模型，并以文本格式的输出作为响应。
- en: Another method is converting text into numerical arrays. This process involves
    composing a prompt for the AI and receiving a numerical array in return. What
    is commonly known as an “embedding”. It has experienced a recent surge in Vector
    Databases and semantic search.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一种方法是将文本转换为数值数组。这一过程涉及为AI编写一个提示并返回一个数值数组。这就是通常所称的“嵌入”。它在向量数据库和语义搜索中最近经历了激增。
- en: And it is precisely these two main problems that LangChain tries to address.
    If you are interested in the main problems of interacting with LLMs, you can check
    this article [here](/6-problems-of-llms-that-langchain-is-trying-to-assess).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这两个主要问题是LangChain试图解决的。如果你对与LLMs互动的主要问题感兴趣，可以在[这里](/6-problems-of-llms-that-langchain-is-trying-to-assess)查看这篇文章。
- en: LangChain and its basics
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain及其基础知识
- en: LangChain is an open-source framework built around LLMs. It brings to the table
    an arsenal of tools, components, and interfaces that streamline the architecture
    of LLM-driven applications.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个围绕 LLM 构建的开源框架。它提供了一整套工具、组件和接口，简化了 LLM 驱动应用的架构。
- en: With LangChain, engaging with language models, interlinking diverse components,
    and incorporating assets like APIs and databases become a breeze. This intuitive
    framework substantially simplifies the LLM application development journey.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LangChain，与语言模型互动、链接各种组件以及整合如 API 和数据库等资源变得轻而易举。这个直观的框架大大简化了 LLM 应用开发的过程。
- en: The core idea of Long Chain is that we can connect together different components
    or modules, also known as chains, to create more sophisticated LLM-powered solutions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的核心思想是将不同的组件或模块，即链条，连接在一起，创造出更复杂的 LLM 驱动的解决方案。
- en: 'Here are some standout features of LangChain:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 LangChain 的一些突出功能：
- en: Customizable prompt templates to standardize our interactions.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可自定义的提示模板用于标准化我们的互动。
- en: Chain link components tailored for sophisticated use cases.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 针对复杂用例的链条链接组件。
- en: Seamless integration with leading language models, including OpenAI’s GPTs and
    those on HuggingFace Hub.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与领先语言模型的无缝集成，包括 OpenAI 的 GPTs 和 HuggingFace Hub 上的模型。
- en: Modular components for a mix-and-match approach to assess any specific problem
    or task.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模块化组件支持混合搭配的方式来评估任何特定问题或任务。
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/6211aeddcec56539aa3c0d9df71e8a99.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![如何通过 LangChain 让大型语言模型与您的软件配合使用](../Images/6211aeddcec56539aa3c0d9df71e8a99.png)'
- en: Image by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: LangChain is distinguished by its focus on adaptability and modular design.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的特点在于其对适应性和模块化设计的关注。
- en: The main idea behind LangChain is breaking down the natural language processing
    sequence into individual parts, allowing developers to customize workflows based
    on their requirements.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的主要思想是将自然语言处理过程拆分成单独的部分，让开发者根据需求自定义工作流。
- en: Such versatility positions LangChain as a prime choice for building AI solutions
    in different situations and industries.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种多样性使 LangChain 成为在不同情况和行业中构建 AI 解决方案的首选。
- en: Some of its most important components are…
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些最重要的组件是……
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/4aba22d72f234ac9cc55081a479a1e3c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![如何通过 LangChain 让大型语言模型与您的软件配合使用](../Images/4aba22d72f234ac9cc55081a479a1e3c.png)'
- en: Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 1\. LLMs
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. LLM
- en: LLMs are fundamental components that leverage vast amounts of training data
    to understand and generate human-like text. They are at the core of many operations
    within LangChain, providing the necessary language processing capabilities to
    analyze, interpret, and respond to text input.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 是利用大量训练数据理解和生成类人文本的核心组件。它们是 LangChain 内许多操作的核心，提供了必要的语言处理能力来分析、解释和回应文本输入。
- en: '**Usage:** Powering chatbots, generating human-like text for various applications,
    aiding in information retrieval, and performing other language processing'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 为聊天机器人提供动力，为各种应用生成类人文本，辅助信息检索，并执行其他语言处理任务。'
- en: 2\. Prompt templates
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 提示模板
- en: Prompts are fundamental for interacting with LLM, and when working on specific
    tasks, their structure tends to be similar. Prompt templates, which are preset
    prompts usable across chains, allow standardization of “prompts” by adding specific
    values. This enhances the adaptability and customization of any LLM.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是与 LLM 互动的基础，当处理特定任务时，它们的结构往往类似。提示模板，即预设的可跨链条使用的提示，通过添加特定值来标准化“提示”。这增强了任何
    LLM 的适应性和定制性。
- en: '**Usage:** Standardizing the process of interacting with LLMs.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 标准化与 LLM 的互动过程。'
- en: 3\. Output Parsers
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 输出解析器
- en: Output parsers are components that take the raw output from a preceding stage
    in the chain and convert it into a structured format. This structured data can
    then be used more effectively in subsequent stages or delivered as a response
    to the end user.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 输出解析器是将链条前一个阶段的原始输出转换为结构化格式的组件。这些结构化数据可以在后续阶段更有效地使用，或作为最终用户的回应。
- en: '**Usage:** For instance, in a chatbot, an output parser might take the raw
    text response from a language model, extract key pieces of information, and format
    them into a structured reply.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**用途：** 例如，在聊天机器人中，输出解析器可能会从语言模型中获取原始文本响应，提取关键信息，并将其格式化为结构化回复。'
- en: 4\. Components and chains
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 组件和链条
- en: In LangChain, each component acts as a module responsible for a particular task
    in the language processing sequence. These components can be connected to form
    *chains* for customized workflows.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，每个组件作为负责语言处理序列中特定任务的模块。这些组件可以连接起来形成*链*以定制工作流程。
- en: '**Usage:** Generating sentiment detection and response generator chains in
    a specific chatbot.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 在特定聊天机器人中生成情感检测和响应生成链。'
- en: 5\. Memory
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 内存
- en: Memory in LangChain refers to a component that provides a storage and retrieval
    mechanism for information within a workflow. This component allows for the temporary
    or persistent storage of data that can be accessed and manipulated by other components
    during the interaction with the LLM.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，内存指的是一个组件，它为工作流中的信息提供存储和检索机制。这个组件允许暂时或持久地存储数据，其他组件在与LLM交互时可以访问和操作这些数据。
- en: '**Usage:** This is useful in scenarios where data needs to be retained across
    different stages of processing, for example, storing conversation history in a
    chatbot to provide context-aware responses.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 这在需要在不同处理阶段保留数据的场景中很有用，例如，在聊天机器人中存储对话历史，以提供上下文感知的响应。'
- en: 6\. Agents
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 代理
- en: Agents are autonomous components capable of taking actions based on the data
    they process. They can interact with other components, external systems, or users,
    to perform specific tasks within a LangChain workflow.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是能够基于其处理的数据采取行动的自主组件。它们可以与其他组件、外部系统或用户交互，在LangChain工作流中执行特定任务。
- en: '**Usage:** For instance, an agent might handle user interactions, process incoming
    requests, and coordinate the flow of data through the chain to generate appropriate
    responses.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 例如，一个代理可能会处理用户交互、处理传入的请求，并协调数据在链中的流动，以生成适当的响应。'
- en: 7\. Indexes and Retrievers
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 索引和检索器
- en: Indexes and Retrievers play a crucial role in managing and accessing data efficiently.
    Indexes are data structures holding information and metadata from the model’s
    training data. On the other hand, retrievers are mechanisms that interact with
    these indexes to fetch relevant data based on specified criteria and allow the
    model to reply better by supplying relevant context.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 索引和检索器在高效管理和访问数据方面发挥着关键作用。索引是包含模型训练数据的信息和元数据的数据结构。另一方面，检索器是与这些索引交互的机制，根据指定的标准提取相关数据，并通过提供相关上下文，使模型能够更好地回复。
- en: '**Usage:** They are instrumental in quickly fetching relevant data or documents
    from a large dataset, which is essential for tasks like information retrieval
    or question answering.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 它们在从大型数据集中快速获取相关数据或文档方面发挥重要作用，这对于信息检索或问答任务至关重要。'
- en: 8\. Document Transformers
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 文档转换器
- en: In LangChain, Document Transformers are specialized components designed to process
    and transform documents in a way that makes them suitable for further analysis
    or processing. These transformations may include tasks such as text normalization,
    feature extraction, or the conversion of text into a different format.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，文档转换器是专门设计用于以适合进一步分析或处理的方式处理和转换文档的组件。这些转换可能包括文本规范化、特征提取或将文本转换为不同格式等任务。
- en: '**Usage:** Preparing text data for subsequent processing stages, such as analysis
    by machine learning models or indexing for efficient retrieval.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 为后续处理阶段准备文本数据，例如机器学习模型的分析或高效检索的索引。'
- en: 9\. Embedding Models
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 嵌入模型
- en: They are used to convert text data into numerical vectors in a high-dimensional
    space. These models capture semantic relationships between words and phrases,
    enabling a machine-readable representation. They form the foundation for various
    downstream Natural Language Processing (NLP) tasks within the LangChain ecosystem.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 它们用于将文本数据转换为高维空间中的数值向量。这些模型捕捉了词语和短语之间的语义关系，实现机器可读的表示。它们构成了LangChain生态系统中各种下游自然语言处理（NLP）任务的基础。
- en: '**Usage:** Facilitating semantic searches, similarity comparisons, and other
    machine-learning tasks by providing a numerical representation of text.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 通过提供文本的数值表示，促进语义搜索、相似性比较和其他机器学习任务。'
- en: 10\. Vector stores
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 向量存储
- en: Type of database system that specializes to store and search information via
    embeddings, essentially analyzing numerical representations of text-like data.
    VectorStore serves as a storage facility for these embeddings.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一种数据库系统，专门存储和搜索通过嵌入分析的数值表示的文本数据。VectorStore作为这些嵌入的存储设施。
- en: '**Usage:** Allowing efficient search based on semantic similarity.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 允许基于语义相似性进行高效搜索。'
- en: Setting it up and first examples
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和第一个示例
- en: Installing it using PIP
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PIP 安装
- en: The first thing we have to do is make sure we have LangChain installed in our
    environment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要确保环境中已安装 LangChain。
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Environment setup
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境设置
- en: Utilizing LangChain typically means integrating with diverse model providers,
    data stores, APIs, among other components. And as you already know, like any integration,
    supplying the relevant and correct API keys is crucial for LangChain's operation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LangChain 通常意味着与多种模型提供者、数据存储、API 以及其他组件进行集成。正如你已经知道的那样，与任何集成一样，提供相关且正确的 API
    密钥对 LangChain 的操作至关重要。
- en: 'Imagine we want to use our OpenAI API. We can easily accomplish this in two
    ways:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下我们要使用我们的 OpenAI API。我们可以通过两种方式轻松实现这一点：
- en: Setting up key as an environment variable
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将密钥设置为环境变量
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: or
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you choose not to establish an environment variable, you have the option
    to provide the key directly through the openai_api_key named parameter when initiating
    the OpenAI LLM class:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择不建立环境变量，你可以在初始化 OpenAI LLM 类时通过名为 openai_api_key 的参数直接提供密钥：
- en: Directly set up the key in the relevant class.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接在相关类中设置密钥。
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: LangChain in action
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 的实际应用
- en: Switching between LLMs becomes straightforward
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 LLM 之间切换变得非常简单
- en: LangChain provides an LLM class that allows us to interact with different language
    model providers, such as OpenAI and Hugging Face.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 提供了一个 LLM 类，使我们可以与不同的语言模型提供者（如 OpenAI 和 Hugging Face）进行交互。
- en: It is quite easy to get started with any LLM, as the most basic and easiest-to-implement
    functionality of any LLM is just generating text.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用任何 LLM 都相当容易，因为任何 LLM 最基本、最容易实现的功能就是生成文本。
- en: However, asking the very same prompt to different LLMs at once is not so easy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，同时向不同的 LLM 提问相同的提示并不是那么容易。
- en: This is where LangChain kicks in…
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 LangChain 发挥作用的地方……
- en: Getting back to the easiest functionality of any LLM, we can easily build an
    application with LangChain that gets a string prompt and returns the output of
    our designated LLM..
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 回到任何 LLM 最简单的功能，我们可以轻松地使用 LangChain 构建一个应用程序，该应用程序获取一个字符串提示，并返回我们指定 LLM 的输出。
- en: Code by Author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: We can simply use the same prompt and get the response of two different models
    within few lines of code!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以仅用几行代码，使用相同的提示并获取两个不同模型的响应！
- en: Code by Author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: Impressive… right?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 令人印象深刻……对吧？
- en: Giving structure to our prompts with prompt templates
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示模板为我们的提示赋予结构
- en: A common issue with Language Models (LLMs) is their inability to escalate complex
    applications. LangChain addresses this by offering a solution to streamline the
    process of creating prompts, which is often more intricate than just defining
    a task as it requires outlining the AI's persona and ensuring factual accuracy.
    A significant part of this involves repetitive boilerplate text. LangChain alleviates
    this by offering prompt templates, which auto-include boilerplate text in new
    prompts, thus simplifying prompt creation and ensuring consistency across different
    tasks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型（LLMs）常见的问题是它们无法升级复杂的应用程序。LangChain 通过提供简化创建提示过程的解决方案来解决这一问题，这通常比定义任务更为复杂，因为它需要概述
    AI 的角色并确保事实准确性。这一过程的一个重要部分涉及重复的模板文本。LangChain 通过提供提示模板来缓解这一点，提示模板自动包含模板文本，从而简化提示创建，并确保不同任务之间的一致性。
- en: Code by Author
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: Getting structured responses with output parsers
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用输出解析器获取结构化响应
- en: In chat-based interactions, the model's output is merely text. Yet, within software
    applications, having a structured output is preferable as it allows for further
    programming actions. For instance, when generating a dataset, receiving the response
    in a specific format such as CSV or JSON is desired. Assuming a prompt can be
    crafted to elicit a consistent and suitably formatted response from the AI, there's
    a need for tools to manage this output. LangChain caters to this requirement by
    offering output parser tools to handle and utilize the structured output effectively.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于聊天的互动中，模型的输出仅仅是文本。然而，在软件应用中，拥有结构化的输出更为理想，因为这允许进一步的编程操作。例如，在生成数据集时，希望以 CSV
    或 JSON 等特定格式接收响应。假设可以设计一个提示以引导 AI 提供一致且格式合适的响应，那么就需要工具来管理这种输出。LangChain 通过提供输出解析器工具来满足这一需求，从而有效处理和利用结构化输出。
- en: Code by Author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: You can go check the whole code on my [GitHub](https://github.com/rfeers/LangChain/blob/main/1_Main_Basics_of_LangChain.ipynb).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我的 [GitHub](https://github.com/rfeers/LangChain/blob/main/1_Main_Basics_of_LangChain.ipynb)
    上查看完整的代码。
- en: Conclusions
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Not long ago, the advanced capabilities of ChatGPT left us in awe. Yet, the
    technological environment is ever-changing, and now tools like LangChain are at
    our fingertips, allowing us to craft outstanding prototypes from our personal
    computers in just a few hours.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 不久前，ChatGPT 的先进能力让我们惊叹。然而，技术环境不断变化，如今像 LangChain 这样的工具触手可及，让我们可以在个人电脑上仅需几小时便能打造出色的原型。
- en: LangChain, a freely available Python platform, provides a means for users to
    develop applications anchored by LLMs (Language Model Models). This platform delivers
    a flexible interface to a variety of foundational models, streamlining prompt
    handling and acting as a nexus for elements like prompt templates, more LLMs,
    external information, and other resources via agents, as of the current documentation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain，一个免费的Python平台，为用户提供了开发由LLMs（语言模型）驱动的应用程序的手段。该平台提供了对各种基础模型的灵活接口，简化了提示处理，并作为连接点整合了提示模板、更多LLMs、外部信息和其他资源（通过代理），根据当前文档。
- en: Imagine chatbots, digital assistants, language translation tools, and sentiment
    analysis utilities; all these LLM-enabled applications come to life with LangChain.
    Developers utilize this platform to craft custom-tailored language model solutions
    addressing distinct requirements.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下聊天机器人、数字助理、语言翻译工具和情感分析工具；所有这些启用LLM的应用程序都可以通过LangChain实现。开发者利用这个平台来打造量身定制的语言模型解决方案，以满足不同的需求。
- en: As the horizon of natural language processing expands, and its adoption deepens,
    the realm of its applications seems boundless.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自然语言处理的视野扩展和应用的加深，它的应用领域似乎无穷无尽。
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)**
    是一位来自巴塞罗那的分析工程师。他毕业于物理工程专业，目前在数据科学领域专注于人类流动性应用。他还是一位兼职内容创作者，专注于数据科学和技术。Josep 撰写有关人工智能的内容，涵盖该领域的持续爆炸应用。'
- en: More On This Topic
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用大型语言模型时优化性能和成本的策略](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级开源大型语言模型](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
- en: '[More Free Courses on Large Language Models](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更多关于大型语言模型的免费课程](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
- en: '[Learn About Large Language Models](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解大型语言模型](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 John Snow Labs 的医疗保健专用大型语言模型](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
- en: '[What are Large Language Models and How Do They Work?](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大型语言模型是什么？它们如何工作？](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
