# 处理机器学习中的分类特征

> 原文：[https://www.kdnuggets.com/2019/07/categorical-features-machine-learning.html](https://www.kdnuggets.com/2019/07/categorical-features-machine-learning.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**由 [Hugo Ferreira](https://www.linkedin.com/in/hugo-ferreira8)，数据科学家 | 机器学习爱好者 | 物理学家**

如何在 Python 中轻松实现独热编码

![figure-name](../Images/dc204dce3ab7ebd72a010b66b8188048.png)照片由 [Max Nelson](https://unsplash.com/@maxcodes?utm_source=medium&utm_medium=referral) 提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

分类数据在许多数据科学和机器学习问题中很常见，但通常比数值数据更具挑战性。特别是，许多机器学习算法要求其输入为数值型，因此分类特征必须在我们使用这些算法之前转换为数值特征。

转换分类特征的最常见方法之一是 **独热编码**，尤其是在类别之间没有自然排序时（例如，‘城市’特征，包含‘伦敦’，‘里斯本’，‘柏林’等城市名）。对于特征的每个唯一值（例如‘伦敦’），会创建一列（例如‘City_London’），当原始特征在该实例中取该值时，该列的值为 1，否则为 0。

尽管这种编码方式使用非常频繁，但尝试使用 Python 中的 scikit-learn 实现它可能会让人沮丧，因为目前没有简单的变换器可以应用，尤其是当你希望将其用作机器学习管道的一部分时。在这篇文章中，我将描述如何仅使用 scikit-learn 和 pandas 实现它（虽然需要一点努力）。之后，我还会展示如何使用 [category encoders 库](http://contrib.scikit-learn.org/categorical-encoding/index.html) 更轻松地实现相同的功能。

为了说明整个过程，我将使用[乳腺癌数据集](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer)来自[UCI机器学习库](https://archive.ics.uci.edu/ml/index.html)，该数据集具有许多分类特征，可用于实现独热编码。

### 加载数据

我们将使用的数据是来自[UCI机器学习库](https://archive.ics.uci.edu/ml/index.html)的[乳腺癌数据集](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer)。该数据集较小，包含多个分类特征，这将允许我们快速探索几种使用Python、pandas和scikit-learn实现独热编码的方法。

从库中下载数据后，我们将其读入pandas dataframe `df`。

```py
import pandas as pd# names of columns, as per description
cols_names = ['Class', 'age', 'menopause', 'tumor-size',
              'inv-nodes', 'node-caps', 'deg-malig', 'breast',
              'breast-quad', 'irradiat']# read the data
df = (pd.read_csv('breast-cancer.data',
                 header=None, names=cols_names)
        .replace({'?': 'unknown'}))  # NaN are represented by '?'
```

该数据集包含286个实例，具有9个特征和一个目标（‘Class’）。目标和特征在数据集描述中如下：

```py
 1\. Class: no-recurrence-events, recurrence-events.
 2\. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.
 3\. menopause: lt40, ge40, premeno.
 4\. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44,45-49, 50-54, 55-59.
 5\. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.
 6\. node-caps: yes, no.
 7\. deg-malig: 1, 2, 3.
 8\. breast: left, right.
 9\. breast-quad: left-up, left-low, right-up, right-low, central.
10\. irradiat: yes, no.
```

我们将所有列视为‘object’类型，并使用scikit-learn的`train_test_split`拆分训练集和测试集。

```py
from sklearn.model_selection import train_test_splitX = df.drop(columns='Class')
y = df['Class'].copy()X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)
```

### 独热编码

对于分类特征，有几种编码方式（例如，参见[此处](http://psych.colorado.edu/~carey/courses/psyc5741/handouts/Coding%20Categorical%20Variables%202006-03-03.pdf)）。在这篇文章中，我们将专注于最常见且有用的编码方式之一，即**独热编码**。经过转换后，结果数据集的每一列对应于每个原始特征的一个唯一值。

例如，假设我们有以下具有三种不同唯一值的分类特征。

```py
+---------+
| Feature |
+---------+
| value_1 |
| value_2 |
| value_3 |
+---------+
```

一旦进行独热编码，数据集看起来会是这样的：

```py
+-----------------+-----------------+-----------------+
| Feature_value_1 | Feature_value_2 | Feature_value_3 |
+-----------------+-----------------+-----------------+
|               1 |               0 |               0 |
|               0 |               1 |               0 |
|               0 |               0 |               1 |
+-----------------+-----------------+-----------------+
```

我们希望将独热编码应用于乳腺癌数据集，使得生成的数据集适用于机器学习算法。请注意，对于该数据集的许多特征，类别之间存在自然的顺序（例如肿瘤大小），因此其他类型的编码可能更合适，但为了具体说明，我们在本文中将仅专注于独热编码。

### 使用scikit-learn

让我们看看如何使用scikit-learn实现独热编码。scikit-learn中有一个名为`OneHotEncoder`的[转换器](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)，乍一看，它似乎正是我们需要的。

```py
from sklearn.preprocessing import OneHotEncoderohe = OneHotEncoder(sparse=False)
X_train_ohe = ohe.fit_transform(X_train)
```

如果我们尝试应用上述代码，我们会得到一个`ValueError`，因为`OneHotEncoder`要求所有值都是整数，而我们有的是字符串。这意味着我们必须先将所有可能的值编码为整数：对于给定的特征，如果它有*n*个可能值（由*n*个不同的字符串给出），我们将它们编码为0到*n*-1之间的整数。幸运的是，scikit-learn中还有另一个[转换器](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)，称为`LabelEncoder`，它可以做到这一点！

```py
from sklearn.preprocessing import LabelEncoderle = LabelEncoder()
X_train_le = le.fit_transform(X_train)
```

然而，我们又遇到了一个 `ValueError`！实际上，`LabelEncoder` 仅打算用于目标向量，因此它不能处理多列。不幸的是，在 scikit-learn 0.19 版本中，没有可以处理多列的变换器（对 0.20 版本有一些[希望](http://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)）。

一种解决方案是制作我们自己的变换器，我们创造性地称之为 `MultiColumnLabelEncoder`，它在每个特征中应用 `LabelEncoder`。

```py
class MultiColumnLabelEncoder:

    def __init__(self, columns = None):
        self.columns = columns # list of column to encode    def fit(self, X, y=None):
        return self    def transform(self, X):
        '''
        Transforms columns of X specified in self.columns using
        LabelEncoder(). If no columns specified, transforms all
        columns in X.
        '''

        output = X.copy()

        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname, col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)

        return output    def fit_transform(self, X, y=None):
        return self.fit(X, y).transform(X)
```

这次会成功吗？

成功了！为了更好地理解发生了什么，让我们检查原始的训练集。

我们可以看到，例如，年龄段 30–39 被标记为 0，40–49 被标记为 1，其他特征也是类似。

应用 `MultiColumnLabelEncoder` 后，我们可以（终于！）使用 `OneHotEncoder` 对训练集和测试集实施独热编码。

一些评论：

+   `OneHotEncoder` 被拟合到训练集，这意味着对于训练集中*存在的每一个唯一值*，为每个特征创建了一个新列。编码后我们有 39 列。

+   输出是一个 numpy 数组（当使用选项 `sparse=False` 时），这有一个缺点，即丢失了关于原始列名和数值的所有信息。

+   当我们尝试转换测试集时，在将编码器拟合到训练集之后，我们又一次遇到了 `ValueError`。这是因为测试集中有*新的、之前未见过*的唯一值，而编码器不知道如何处理这些值。为了在机器学习算法中同时使用转换后的训练集和测试集，我们需要它们具有相同的列数。

最后一个问题可以通过使用 `OneHotEncoder` 的 `handle_unknown='ignore'` 选项来解决，顾名思义，这将忽略转换测试集时的未见过的值。

就这样！训练集和测试集都有 39 列，并且现在以适合用于需要数值数据的机器学习算法的形式存在。

然而，上述过程相当不优雅，我们失去了数据的 dataframe 格式。有没有更简单的方法来实现这一切？

当然有！

### 使用类别编码器

[**类别编码器**](http://contrib.scikit-learn.org/categorical-encoding/index.html) 是一个与 scikit-learn 兼容的类别变量编码器库，例如：

+   Ordinal

+   One-Hot

+   Binary

+   Helmert Contrast

+   Sum Contrast

+   Polynomial Contrast

+   Backward Difference Contrast

+   Hashing

+   BaseN

+   LeaveOneOut

+   Target Encoding

Ordinal、One-Hot 和 Hashing 编码器是 scikit-learn 中现有编码器的改进版本，具有以下优点：

+   支持 pandas 数据帧作为输入，选择性地作为输出；

+   可以明确配置数据中哪些列通过名称或索引进行编码，或根据输入类型推断非数值列；

+   兼容scikit-learn管道。

对于我们的目的，我们将使用改进的`OneHotEncoder`，并看看我们能简化多少工作流程。首先，我们导入分类编码器库。

```py
import category_encoders as ce
```

然后，让我们尝试将`OneHotEncoder`直接应用于训练集和测试集。

立刻就成功了！不需要先使用`LabelEncoder`！

一些观察：

+   输出是数据框，这使我们能够更轻松地检查各个特征是如何被转换的。和之前一样，每个转换后的数据集有39列，并且可以检查0和1的矩阵是否与之前获得的矩阵相同。

+   我使用了选项`use_cat_names=True`，这样每个特征的所有可能值都会添加到每个新列的特征名称中（例如`age_60-69`）。这样做是为了清晰起见，但默认情况下，它仅添加一个索引（例如`age_1`、`age_2`等）。

+   我们现在可以更容易地理解为什么之前在没有要求忽略测试集中未见值的情况下会出现错误。下面，我们展示了在对训练集（首先）拟合编码器和对测试集（其次）拟合编码器时，独热编码后的测试集所有列。我们看到，在第二种情况下，现在有42列，因为创建了3个新列：`age_20-29`、`tumor-size_5-9`和`breast-quad_unknown`。这些对应于测试集中（`age`中的20–29、`tumor-size`中的5–9和`breast-quad`中的unknown）*在训练集中不存在*的三个值。

比较以上两种方法后，很明显，如果我们打算对数据集中的分类特征进行独热编码，我们应该使用来自分类编码器库的`OneHotEncoder`。

正如一开始所述，独热编码不是对分类特征进行编码的唯一方法，分类编码器库还有[几种编码器](http://contrib.scikit-learn.org/categorical-encoding/index.html)可以探索，因为其他编码器可能更适合不同的分类特征和机器学习问题。

你可以在以下位置找到我的LinkedIn：

[Hugo Ferreira - 研究员 - Instituto Superior Técnico | LinkedIn

查看Hugo Ferreira在LinkedIn上的个人资料，LinkedIn是全球最大的专业社区。Hugo在其…](https://www.linkedin.com/in/hugo-ferreira8)

**简历： [Hugo Ferreira](https://medium.com/@hugorcf)** 是一位数据科学家，拥有数学和物理学背景，并在天体物理学和量子物理学感兴趣的复杂系统的框架和计算工具方面进行了多年的研究。

[原文](https://medium.com/hugo-ferreiras-blog/dealing-with-categorical-features-in-machine-learning-1bb70f07262d)。转载自许可。

**相关：**

+   [特征提取的指南](/2019/06/hitchhikers-guide-feature-extraction.html)

+   [掌握机器学习数据准备的7个步骤——2019年版](/2019/06/7-steps-mastering-data-preparation-python.html)

+   [特征工程速成指南](/2019/02/quick-guide-feature-engineering.html)

### 更多相关话题

+   [停止学习数据科学以寻找目标，并以寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学的顶级统计资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [一个90亿美元的AI失败案例，深入分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [是什么让Python成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应该了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)
