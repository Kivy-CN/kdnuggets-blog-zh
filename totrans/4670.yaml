- en: 'Naive Bayes: A Baseline Model for Machine Learning Classification Performance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html](https://www.kdnuggets.com/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html?page=2#comments)![scikitlearn-pandas-naive-bayes](../Images/d3fbe85bbd5285ee92f5591fc9b15d6f.png)'
  prefs: []
  type: TYPE_IMG
- en: Bayes Theorem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Equation](../Images/3792011e5ee54c481017b1511c531e4d.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The above equation represents Bayes Theorem in which it describes the probability
    of an event occurring P(A) based on our prior knowledge of events that may be
    related to that event P(B).
  prefs: []
  type: TYPE_NORMAL
- en: 'Lets explore the parts of Bayes Theorem:'
  prefs: []
  type: TYPE_NORMAL
- en: P(A|B) - **Posterior Probability**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional probability that event A occurs given that event B has occurred.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(A) - **Prior Probability**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of event A.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(B) - **Evidence**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of event B.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(B|A) - **Likelihood**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional probability of B occurring given event A has occurred.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Now, lets explore the parts of Bayes Theorem through the eyes of someone conducting
    machine learning:*'
  prefs: []
  type: TYPE_NORMAL
- en: P(A|B) - **Posterior Probability**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional probability of the response variable (target variable) given
    the training data inputs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(A) - **Prior Probability**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of the response variable (target variable).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(B) - **Evidence**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The probability of the training data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(B|A) - **Likelihood**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The conditional probability of the training data given the response variable.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Equation](../Images/b132eb838838ec88563bb42acd6e8ded.png)'
  prefs: []
  type: TYPE_IMG
- en: P(c|x) - Posterior probability of the target/class (c) given predictors (x).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(c) - Prior probability of the class (target).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(x|c) - Probability of the predictor (x) given the class/target (c).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: P(x) - Prior probability of the predictor (x).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example of using Bayes theorem:**'
  prefs: []
  type: TYPE_NORMAL
- en: I'll be using the [tennis weather dataset](https://www.kaggle.com/pranavpandey2511/naive-bayes-classifier-from-scratch/data).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '|  | outlook | temp | humidity | windy | play |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | sunny | hot | high | False | no |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | sunny | hot | high | True | no |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | overcast | hot | high | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | rainy | mild | high | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | rainy | cool | normal | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | rainy | cool | normal | True | no |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | overcast | cool | normal | True | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | sunny | mild | high | False | no |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | sunny | cool | normal | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | rainy | mild | normal | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | sunny | mild | normal | True | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | overcast | mild | high | True | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | overcast | hot | normal | False | yes |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | rainy | mild | high | True | no |'
  prefs: []
  type: TYPE_TB
- en: 'Lets take a look at how each category looks when inside a frequency table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**What is the probability of playing tennis given it is rainy?**'
  prefs: []
  type: TYPE_NORMAL
- en: P(rain|play=yes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: frequency of (outlook=rainy) when (play=yes) / frequency of (play=yes) = 3/9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(play=yes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: frequency of (play=yes) / total(play) = 9/14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: P(outlook=rainy)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: frequency of (outlook=rainy) / total(outlook) = 5/14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Equation](../Images/d7a41a03bdc3d8062103dca6c9067ef3.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The probability of playing tennis when it is rainy is **60%.** The process is
    very simple once you obtain the frequencies for each category.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple function to help any newbies remember the parts of Bayes equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here is a simple function to calculate the posterior probability for you, but
    you must be able to find each part of bayes equation yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**Lets see another way to find the posterior probability this time using contingency
    tables in Python:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '|  | no | yes | rowtotal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| overcast | 0.000000 | 0.285714 | 0.285714 |'
  prefs: []
  type: TYPE_TB
- en: '| rainy | 0.142857 | 0.214286 | 0.357143 |'
  prefs: []
  type: TYPE_TB
- en: '| sunny | 0.214286 | 0.142857 | 0.357143 |'
  prefs: []
  type: TYPE_TB
- en: '| coltotal | 0.357143 | 0.642857 | 1.000000 |'
  prefs: []
  type: TYPE_TB
- en: To only get the column total
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '|  | no | yes | rowtotal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| overcast | 0.0 | 0.444444 | 0.285714 |'
  prefs: []
  type: TYPE_TB
- en: '| rainy | 0.4 | 0.333333 | 0.357143 |'
  prefs: []
  type: TYPE_TB
- en: '| sunny | 0.6 | 0.222222 | 0.357143 |'
  prefs: []
  type: TYPE_TB
- en: '| coltotal | 1.0 | 1.000000 | 1.000000 |'
  prefs: []
  type: TYPE_TB
- en: To only get the row total
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '|  | no | yes | rowtotal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| overcast | 0.000000 | 1.000000 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| rainy | 0.400000 | 0.600000 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| sunny | 0.600000 | 0.400000 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| coltotal | 0.357143 | 0.642857 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: 'These tables are all pandas dataframe objects. Therefore using pandas subsetting
    and the `bayesposterior` function I made, we can arrive at the same conclusion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Naive Bayes Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Naive Bayes](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
    is a supervised Machine Learning algorithm inspired by the Bayes theorem. It works
    on the principles of conditional probability. Naive Bayes is a classification
    algorithm for binary and multi-class classification. The Naive Bayes algorithm
    uses the probabilities of each attribute belonging to each class to make a prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Example**'
  prefs: []
  type: TYPE_NORMAL
- en: What is the probability of playing tennis when it is sunny, hot, highly humid
    and windy? So using the tennis dataset, we need to use the Naive Bayes method
    to predict the probability of someone playing tennis given the mentioned weather
    conditions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '| play | no | yes | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| outlook |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| overcast | 0 | 4 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| rainy | 2 | 3 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| sunny | 3 | 2 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| All | 5 | 9 | 14 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '| play | no | yes | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| temp |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| cool | 1 | 3 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| hot | 2 | 2 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| mild | 2 | 4 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| All | 5 | 9 | 14 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '| play | no | yes | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| humidity |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| high | 4 | 3 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| normal | 1 | 6 | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| All | 5 | 9 | 14 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '| play | no | yes | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| windy |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| False | 2 | 6 | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| True | 3 | 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| All | 5 | 9 | 14 |'
  prefs: []
  type: TYPE_TB
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '| col_0 | count | All |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| play |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| no | 5 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| yes | 9 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| All | 14 | 14 |'
  prefs: []
  type: TYPE_TB
- en: Now by using the above contingency tables, we will go through how the Naive
    Bayes algorithm calculates the posterior probability.
  prefs: []
  type: TYPE_NORMAL
- en: Calculate P(x|play=yes). In this case x refers to all the predictors 'outlook',
    'temp', 'humidity' and 'windy'.
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: P(sunny|play=yes)→2/9
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(hot|play=yes)→2/9
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(high|play=yes)→3/9
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(True|play=yes)→3/9
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Equation](../Images/bec5c1f801cc9c8ccf92a161c9dca547.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Calculate P(x|play=no) using the same method as above.
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: P(sunny|play=no)→3/5
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(hot|play=no)→2/5
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(high|play=no)→4/5
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(True|play=no)→3/5
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Equation](../Images/70fbd367eb381cbabb572a825d6e53c7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Calculate P(play=yes) and P(play=no)
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: P(play=yes)→9/14
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: P(play=yes)→5/14
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Calculate the probability of playing and not playing tennis given the predictors
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Equation](../Images/d596883dd6ccbaa6b96ac83242bc7a7e.png)![Equation](../Images/a434b4dc81a82288a4e9667dfd955778.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The prediction will be whichever probability is higher
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Type of Naive Bayes Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python's Scikitlearn gives the user access to the following 3 Naive Bayes models.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The gaussian NB Alogorithm assumes all contnuous features (predictors) and all
    follow a Gaussian (Normal Distribution).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Multinomial
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multinomial NB is suited for discrete data that have frequencies and counts.
    Spam Filtering and Text/Document Classification are two very well-known use cases.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bernoulli
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bernoulli is similar to Multinomial except it is for boolean/binary features.
    Like the multinomial method it can be used for spam filtering and document classification
    in which binary terms (i.e. word occurrence in a document represented with True
    or False).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Lets implement a Multinomial and Gaussian Model with Scikitlearn
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Gaussian Naive Bayes, Explained](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Naïve Bayes Algorithm: Everything You Need to Know](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[More Performance Evaluation Metrics for Classification Problems You…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
