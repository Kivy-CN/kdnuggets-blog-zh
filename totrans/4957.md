# 数据科学新手指南：面向软件工程师的入门教程系列

> 原文：[https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html](https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html)

**作者：Harris Brakmić，软件工程师。**

> **编辑注**：这是关于数据科学的新手多部分教程的概述。作者给这一系列教程起了一个不同的——带有讽刺意味的——标题；请理解这一点，并认识到该系列的方式和内容是从软件工程的角度出发，对数据科学各个方面的一个新鲜视角。

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的 IT

* * *

![PySpark 控制台](../Images/4ae095edf852180b5162a23294b12e52.png)

PySpark 控制台。

**[第 1 部分：入门](http://blog.brakmic.com/data-science-for-losers/)**

要在 Python 中进行一些严肃的统计分析，应该使用像 Continuum Analytics 提供的那种适当的发行版。当然，手动安装所有所需的包（如 Pandas、NumPy、Matplotlib 等）是可能的，但要注意复杂性和复杂的包依赖。在本文中，我们将使用 Anaconda 发行版。在 Windows 下的安装很简单，但要避免使用多个 Python 安装（例如，Python3 和 Python2 并行）。最好让 Anaconda 的 Python 二进制文件成为你的标准 Python 解释器。

**[第 2 部分：分析 Reddit 评论与查询数据库](http://blog.brakmic.com/data-science-for-losers-part-2/)**

模式无处不在，但许多模式无法立即被识别。这也是为什么我们在数据库、数据仓库以及其他存储系统中深挖的原因之一。在本文中，我们将使用 Pandas 的 DataFrame 方法并生成图表。我们还将创建数据透视表，并通过 ODBC 查询 MS SQL 数据库。在这种情况下，SqlAlchemy 将成为我们的助手，我们将看到即使像我们这样的“失败者”也可以轻松合并和筛选 SQL 表而无需接触 SQL 语法。不论任务如何，首先你总是需要一个强大的工具集。例如我们将在这里使用的 Anaconda 发行版。我们的数据源将是包含 Reddit 评论的 JSON 文件或类似 Northwind 的 SQL 数据库。许多 90 年代的孩子用 Northwind 学习 SQL。

![Reddit 评论评分](../Images/cee5b84ed2764fddb38d5668cbeb509b.png)

所有可用子版块中评价最高的评论。

**[第2部分附录：使用DataFrames进行SQL操作](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**

-   那么，我们来谈谈在上一篇文章中我忘记提及的Pandas的一些特性。

**[第3部分：Scala与Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**

-   根据其自身定义，Spark是一个用于大规模数据处理的快速通用引擎。有人可能会说：但我们已经有Hadoop了，那为什么还要使用Spark呢？对于这样的问题，我会回答说Hadoop是重新发明的EJB，我们需要更灵活、更通用、更可扩展并且……比MapReduce快得多的东西。Spark以非常快的速度处理批量和流处理。

**[第4部分：机器学习](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**

-   从我非科学家的角度来看，我会将ML定义为人工智能研究的一个子集，它开发自学习（或自我改进？）算法，试图从数据中获取知识并基于此进行预测。然而，ML不仅仅是学术界或某些“开明圈子”的专属。我们每天都在使用ML，却没有意识到它的存在和有用性。一些实际应用中的ML示例包括：垃圾邮件过滤器、语音识别软件、自动文本分析、“智能游戏角色”或即将到来的自动驾驶汽车。所有这些实体都基于一些ML算法做出决策。

![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)

-   Spark栈中的DataFrames。

**[第5部分：Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**

-   在我们开始使用DataFrames之前，我们首先需要准备好在Jupyter（以前称为“IPython”）中运行的环境。在你下载并解压Spark包之后，你会在python/pyspark目录中找到一些重要的Python库和脚本。这些文件在你启动PySpark REPL时会用到。如你所知，Spark支持Java、Scala、Python和R。基于Python的REPL，称为PySpark，提供了通过Python脚本控制Spark的一个很好的选项。

**[第6部分：Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**

-   在这篇文章中，我们将探讨微软的Azure机器学习环境，以及如何将云技术与Python和Jupyter结合使用。如你所知，我在整个文章系列中广泛使用了这些工具，因此我对数据科学友好的环境应该是什么样的有着坚定的看法。当然，并不是说其他编码环境或语言，比如R，就不合适，所以你的观点可能与我的大相径庭，这也是正常的。此外，AzureML提供了非常好的R支持！因此，欢迎根据你的需求调整这篇文章中的所有内容。在开始之前，简要介绍一下我是如何想到写关于Azure和数据科学的文章的。

**[第 7 部分：使用 Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**

在完成我的数据科学和机器学习基础课程时，我发现 Azure ML 内置支持 Jupyter 和 Python，这当然让我非常感兴趣，因为它使 Azure ML 成为实验的理想平台。他们甚至将一个工作区称为“实验”，因此可以期待良好的 Python（和 R）支持以及许多酷的现成模块。与其他技术爱好者一样，我很快决定撰写一篇文章，描述 Azure ML 的一些关键部分。

**简介： [哈里斯·布拉克米奇](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic)) 是 Advarics GmbH 的软件开发者。他使用 Ractive、React、Backbone 和 DevExtreme 编写 Web 应用程序，并使用 C# 开发基于 Azure 的后端。

**相关：**

+   [机器学习：完整详尽概述](/2016/10/machine-learning-complete-detailed-overview.html)

+   [MXNet Python API 简介]( /2017/05/intro-mxnet-python-api.html)

+   [进入数据科学：你需要知道的]( /2017/05/data-science-need-to-know.html)

### 更多相关话题

+   [Pandas 入门教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)

+   [新手强化学习](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)

+   [软件开发者与软件工程师](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)

+   [高保真合成数据，适用于数据工程师和数据科学家](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)

+   [我们不需要数据科学家，我们需要数据工程师](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)

+   [数据科学家和数据工程师如何协作？](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)
