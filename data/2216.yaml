- en: 'Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 揭示隐藏模式：层次聚类介绍
- en: 原文：[https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering](https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering](https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering)
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/80acf3364dfb9a8aa29ab8b5d8f2be6d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类介绍](../Images/80acf3364dfb9a8aa29ab8b5d8f2be6d.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: When you’re familiarizing yourself with the unsupervised learning paradigm,
    you'll learn about clustering algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当你熟悉无监督学习范式时，你将学习到聚类算法。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The goal of clustering is often to understand patterns in the given unlabeled
    dataset. Or it can be to *find* groups in the dataset—and label them—so that we
    can perform supervised learning on the now-labeled dataset. This article will
    cover the basics of hierarchical clustering.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的目标通常是理解给定未标记数据集中的模式。或者可以是*寻找*数据集中的组并对其进行标记，以便我们可以在现在标记的数据集上执行监督学习。本文将涵盖层次聚类的基础知识。
- en: What Is Hierarchical Clustering?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是层次聚类？
- en: '**Hierarchical clustering** algorithm aims at finding similarity between instances—quantified
    by a distance metric—to group them into segments called clusters.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**层次聚类**算法旨在找到实例之间的相似性——通过距离度量来量化——以将它们分组为称为簇的段。'
- en: The goal of the algorithm is to find clusters such that data points in a cluster
    are *more similar* to each other than they are to data points in other clusters.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的目标是找到簇，使得簇中的数据点彼此*更相似*，而与其他簇中的数据点的相似度较低。
- en: 'There are two common hierarchical clustering algorithms, each with its own
    approach:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种常见的层次聚类算法，每种算法都有其独特的方法：
- en: Agglomerative Clustering
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凝聚聚类
- en: Divisive Clustering
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分裂聚类
- en: Agglomerative Clustering
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 凝聚聚类
- en: 'Suppose there are n distinct data points in the dataset. Agglomerative clustering
    works as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设数据集中有n个不同的数据点。凝聚聚类的工作方式如下：
- en: Start with n clusters; each data point is a cluster in itself.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从n个簇开始；每个数据点本身就是一个簇。
- en: Group data points together based on *similarity* between them. Meaning similar
    clusters are merged depending on the distance.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据数据点之间的*相似性*将数据点组合在一起。这意味着相似的簇会根据距离进行合并。
- en: Repeat step 2 until there is *only one* cluster.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤2直到只剩下*一个*簇。
- en: Divisive Clustering
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分裂聚类
- en: 'As the name suggests, divisive clustering tries to perform the inverse of agglomerative
    clustering:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如名字所示，分裂聚类尝试执行凝聚聚类的逆过程：
- en: All the n data points are in a single cluster.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有n个数据点都在一个簇中。
- en: Divide this single large cluster into smaller groups. Note that the grouping
    together of data points in agglomerative clustering is based on similarity. But
    splitting them into different clusters is based on dissimilarity; data points
    in different clusters are dissimilar to each other.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个单一的大簇划分为更小的组。请注意，凝聚聚类中数据点的组合是基于相似性的，但将它们划分到不同的簇中是基于不相似性；不同簇中的数据点彼此不相似。
- en: Repeat until each data point is a cluster in itself.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复直到每个数据点本身都是一个簇。
- en: Distance Metrics
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 距离度量
- en: As mentioned, the *similarity* between data points is quantified using *distance*.
    [Commonly used distance metrics](/2023/03/distance-metrics-euclidean-manhattan-minkowski-oh.html)
    include the Euclidean and Manhattan distance.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，数据点之间的*相似性*是通过*距离*来量化的。[常用的距离度量](/2023/03/distance-metrics-euclidean-manhattan-minkowski-oh.html)包括欧几里得距离和曼哈顿距离。
- en: 'For any two data points in the n-dimensional feature space, the Euclidean distance
    between them given by:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 n 维特征空间中的任意两个数据点，它们之间的欧氏距离由下式给出：
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/b696770b49515a67996ec128a16a0874.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/b696770b49515a67996ec128a16a0874.png)'
- en: 'Another commonly used distance metric is the Manhattan distance given by:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常用的距离度量是曼哈顿距离，计算公式为：
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/f5f80a94b1350afe1f943d1015542869.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/f5f80a94b1350afe1f943d1015542869.png)'
- en: 'The Minkowski distance is a generalization—for a general p >= 1—of these distance
    metrics in an n-dimensional space:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 闵可夫斯基距离是对这些距离度量在 n 维空间中的一般化——适用于一般 p >= 1：
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/fbadb5f9710a995262107b914de161b4.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/fbadb5f9710a995262107b914de161b4.png)'
- en: 'Distance Between Clusters: Understanding Linkage Criteria'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类间的距离：理解连接标准
- en: Using the distance metrics, we can compute the distance between any two data
    points in the dataset. But you also need to define a distance to determine “how”
    to group together clusters at each step.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用距离度量，我们可以计算数据集中任意两个数据点之间的距离。但你还需要定义一种距离来确定每一步如何将聚类组合在一起。
- en: 'Recall that at each step in agglomerative clustering, we pick the *two closest
    groups* to merge. This is captured by the **linkage** criterion. And the commonly
    used linkage criteria include:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在每一步的凝聚型聚类中，我们选择*两个最接近的组*进行合并。这由**连接**标准来捕捉。常用的连接标准包括：
- en: Single linkage
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单链接
- en: Complete linkage
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全链接
- en: Average linkage
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均连接
- en: Ward’s linkage
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ward’s linkage
- en: Single Linkage
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单链接
- en: In **single linkage** or single-link clustering, the distance between two groups/clusters
    is taken as the *smallest* distance between all pairs of data points in the two
    clusters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在**单链接**或单链接聚类中，两组/聚类之间的距离被视为两聚类中所有数据点对之间的*最小*距离。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/d8456e47634a5f2217d4492924dfb390.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/d8456e47634a5f2217d4492924dfb390.png)'
- en: Complete Linkage
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完全链接
- en: In **complete linkage** or **complete-link clustering**, the distance between
    two clusters is chosen as the *largest* distance between all pairs of points in
    the two clusters.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在**完全链接**或**完全链接聚类**中，两聚类之间的距离被选为两聚类中所有点对之间的*最大*距离。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/b9b9d53bb114c70cd07bbe6183700a06.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/b9b9d53bb114c70cd07bbe6183700a06.png)'
- en: Average Linkage
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平均链接
- en: Sometimes **average linkage** is used which uses the average of the distances
    between all pairs of data points in the two clusters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有时使用**平均链接**，它使用两聚类中所有数据点对之间距离的平均值。
- en: Ward’s Linkage
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ward’s Linkage
- en: 'Ward''s linkage aims to *minimize the variance* within the merged clusters:
    merging clusters should minimize the overall increase in variance after merging.
    This leads to more compact and well-separated clusters.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Ward’s linkage 旨在*最小化合并后聚类内的方差*：合并聚类应尽量减少合并后的方差总增加。这会导致更紧凑且分隔良好的聚类。
- en: The distance between two clusters is calculated by considering the *increase*
    in the total sum of squared deviations (variance) from the mean of the merged
    cluster. The idea is to measure *how much* the variance of the merged cluster
    increases compared to the variance of the individual clusters before merging.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 两个聚类之间的距离通过考虑合并聚类的均值的总平方偏差（方差）*增加*来计算。其目的是测量*合并后聚类方差增加了多少*，与合并前的各个聚类的方差相比。
- en: When we code hierarchical clustering in Python, we’ll use Ward’s linkage, too.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 Python 中编写层次聚类代码时，我们也会使用 Ward’s linkage。
- en: What Is a Dendrogram?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是树状图？
- en: We can visualize the result of clustering as a **dendrogram**. It is a **hierarchical
    tree structure** that helps us understand how the data points—and subsequently
    clusters—are grouped or merged together as the algorithm proceeds.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将聚类的结果可视化为一个**树状图**。它是一个**层次树结构**，帮助我们理解数据点——以及随后形成的聚类——是如何随着算法的进行被分组或合并在一起的。
- en: In the hierarchical tree structure, the **leaves** denote the *instances* or
    the *data points* in the data set. The corresponding distances at which the merging
    or grouping occurs can be inferred from the y-axis.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在层次树结构中，**叶子**表示数据集中的*实例*或*数据点*。可以从y轴推断出合并或分组发生的相应距离。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/2ed5c7075f4f629251985296b0d78120.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类介绍](../Images/2ed5c7075f4f629251985296b0d78120.png)'
- en: Sample Dendrogram | Image by Author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 示例树状图 | 作者提供的图片
- en: Because the type of linkage determines *how* the data points are grouped together,
    different linkage criteria yield different dendrograms.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于连接类型决定了*如何*将数据点分组在一起，不同的连接准则会产生不同的树状图。
- en: Based on the distance, we can use the dendrogram—cut or slice it at a specific
    point—to get the required number of clusters.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 根据距离，我们可以使用树状图—在特定点切割或分割—以获取所需数量的簇。
- en: Unlike some clustering algorithms like K-Means clustering, hierarchical clustering
    does not require you to specify the number of clusters beforehand. However, agglomerative
    clustering can be computationally very expensive when working with large datasets.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与一些聚类算法如K-Means聚类不同，层次聚类不需要你事先指定簇的数量。然而，进行聚合聚类时，处理大型数据集可能非常耗费计算资源。
- en: Hierarchical Clustering in Python with SciPy
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SciPy进行Python中的层次聚类
- en: Next, we’ll perform hierarchical clustering on the built-in [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)—one
    step at a time. To do so, we’ll leverage the [clustering package](https://docs.scipy.org/doc/scipy/reference/cluster.html)—**scipy.cluster**—from
    SciPy.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在内置的 [酒数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html)
    上逐步进行层次聚类。为此，我们将利用 [聚类包](https://docs.scipy.org/doc/scipy/reference/cluster.html)—**scipy.cluster**—来自SciPy。
- en: Step 1 – Import Necessary Libraries
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步 – 导入必要的库
- en: 'First, let''s import the libraries and the necessary modules from the libraries
    scikit-learn and SciPy:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入必要的库和来自scikit-learn及SciPy库的模块：
- en: '[PRE0]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Step 2 – Load and Preprocess the Dataset
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步 – 加载和预处理数据集
- en: Next, we load the *wine dataset* into a pandas dataframe. It is a simple dataset
    that is part of scikit-learn’s `datasets` and is helpful in exploring hierarchical
    clustering.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将*酒数据集*加载到pandas数据框中。这是一个简单的数据集，属于scikit-learn的`datasets`的一部分，对探索层次聚类很有帮助。
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s check the first few rows of the dataframe:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看数据框的前几行：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/c0c4611ee5de3f18675a278a6db72ec9.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类介绍](../Images/c0c4611ee5de3f18675a278a6db72ec9.png)'
- en: Truncated output of wine_df.head()
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: wine_df.head()的截断输出
- en: Notice that we’ve loaded only the features—and not the output label—so that
    we can peform clustering to discover groups in the dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们仅加载了特征—而不是输出标签—以便我们可以执行聚类以发现数据集中的组。
- en: 'Let''s check the shape of the dataframe:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查数据框的形状：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'There are 178 records and 14 features:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有178条记录和14个特征：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Because the data set contains numeric values that are spread across different
    ranges, let's preprocess the dataset. We’ll use `MinMaxScaler` to transform each
    of the features to take on values in the range [0, 1].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集包含跨不同范围的数值，接下来让我们预处理数据集。我们将使用`MinMaxScaler`将每个特征转换到范围[0, 1]。
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Step 3 – Perform Hierarchical Clustering and Plot the Dendrogram
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步 – 执行层次聚类并绘制树状图
- en: Let’s compute the linkage matrix, perform clustering, and plot the dendrogram.
    We can use `linkage` from the [hierarchy](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html#module-scipy.cluster.hierarchy)
    module to calculate the linkage matrix based on Ward’s linkage (set `method` to
    'ward').
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算链接矩阵，执行聚类，并绘制树状图。我们可以使用来自 [层次](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html#module-scipy.cluster.hierarchy)
    模块的`linkage`来计算基于Ward链接法的链接矩阵（将`method`设置为'ward'）。
- en: As discussed, Ward’s linkage minimizes the variance within each cluster. We
    then plot the dendrogram to visualize the hierarchical clustering process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Ward的链接法最小化每个簇内的方差。然后我们绘制树状图以可视化层次聚类过程。
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Because we haven't (yet) truncated the dendrogram, we get to visualize how each
    of the 178 data points are grouped together into a single cluster. Though this
    is seemingly difficult to interpret, we can still see that there are *three* different
    clusters.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们还没有（尚未）截断树状图，我们可以可视化178个数据点如何被分组到一个簇中。虽然这似乎很难解释，但我们仍然可以看到有*三个*不同的簇。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/d9893a60d0db9f9489b5f1c5458b5c89.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/d9893a60d0db9f9489b5f1c5458b5c89.png)'
- en: Truncating the Dendrogram for Easier Visualization
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 截断树状图以便于可视化
- en: In practice, instead of the entire dendrogram, we can visualize a truncated
    version that's easier to interpret and understand.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可以可视化一个更容易解释和理解的截断版本，而不是整个树状图。
- en: To truncate the dendrogram, we can set `truncate_mode` to 'level' and `p = 3`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要截断树状图，我们可以将`truncate_mode`设置为'level'并将`p`设置为3。
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Doing so will truncate the dendrogram to include only those clusters which are
    *within 3 levels* from the final merge.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这样会截断树状图，只包含那些*在最终合并的3个级别内*的簇。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/2ed5c7075f4f629251985296b0d78120.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/2ed5c7075f4f629251985296b0d78120.png)'
- en: In the above dendrogram, you can see that some data points such as 158 and 159
    are represented individually. Whereas some others are mentioned within parentheses;
    these are *not* individual data points but the *number of data points* in a cluster.
    (k) denotes a cluster with k samples.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述树状图中，你可以看到一些数据点，如158和159，是单独表示的。其他一些数据点在括号中提到；这些*不是*单独的数据点，而是簇中的*数据点数量*。（k）表示一个包含k个样本的簇。
- en: Step 4 – Identify the Optimal Number of Clusters
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 确定最佳簇数
- en: The dendrogram helps us choose the optimal number of clusters.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 树状图帮助我们选择最佳的簇数。
- en: We can observe where the distance along the y-axis *increases drastically*,
    choose to truncate the dendrogram at that point—and use the distance as the threshold
    to form clusters.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到y轴上的距离*急剧增加*，选择在那个点截断树状图——并使用该距离作为形成簇的阈值。
- en: For this example, the optimal number of clusters is 3.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，最佳的簇数是3。
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/5e536cf4ad699bd40121b7c2e8853f0e.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/5e536cf4ad699bd40121b7c2e8853f0e.png)'
- en: Step 5 – Form the Clusters
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5步 – 形成簇
- en: Once we have decided on the optimal number of clusters, we can use the corresponding
    distance along the y-axis—a threshold distance. This ensures that above the threshold
    distance, the clusters are no longer merged. We choose a `threshold_distance`
    of 3.5 (as inferred from the dendrogram).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定了最佳的簇数，我们可以使用y轴上的相应距离——一个阈值距离。这确保了在阈值距离以上，簇不再合并。我们选择一个`threshold_distance`为3.5（从树状图中推断得出）。
- en: 'We then use `fcluster` with `criterion` set to ''distance'' to get the cluster
    assignment for all the data points:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用`fcluster`，将`criterion`设置为'distance'，以获取所有数据点的簇分配。
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should now be able to see the cluster labels (one of {1, 2, 3}) for all
    the data points:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该能看到所有数据点的簇标签（{1, 2, 3}中的一个）：
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Step 6 – Visualize the Clusters
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第6步 – 可视化簇
- en: 'Now that each data point has been assigned to a cluster, you can visualize
    a subset of features and their cluster assignments. Here''s the scatter plot of
    two such features along with their cluster mapping:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每个数据点都已分配到一个簇，你可以可视化特征的子集及其簇分配。以下是两个这样的特征的散点图及其簇映射：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Unveiling Hidden Patterns: An Introduction to Hierarchical Clustering](../Images/6fc4e9e449c353fb847d93e281783f9c.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![揭示隐藏模式：层次聚类简介](../Images/6fc4e9e449c353fb847d93e281783f9c.png)'
- en: Wrapping Up
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: And that's a wrap! In this tutorial, we used SciPy to perform hierarchical clustering
    just so we can cover the steps involved in greater detail. Alternatively, you
    can also use the [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)
    class from scikit-learn’s *cluster* module. Happy coding clustering!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！在本教程中，我们使用SciPy执行层次聚类，以便更详细地涵盖涉及的步骤。或者，你也可以使用来自scikit-learn的[AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)类。祝编程愉快！
- en: References
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[1] [Introduction to Machine Learning](https://mitpress.mit.edu/9780262043793/introduction-to-machine-learning/)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [机器学习导论](https://mitpress.mit.edu/9780262043793/introduction-to-machine-learning/)'
- en: '[2] [An Introduction to Statistical Learning (ISLR)](https://www.statlearning.com/)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [统计学习导论 (ISLR)](https://www.statlearning.com/)'
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a developer
    and technical writer from India. She likes working at the intersection of math,
    programming, data science, and content creation. Her areas of interest and expertise
    include DevOps, data science, and natural language processing. She enjoys reading,
    writing, coding, and coffee! Currently, she''s working on learning and sharing
    her knowledge with the developer community by authoring tutorials, how-to guides,
    opinion pieces, and more.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** 是来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇处工作。她的兴趣和专长领域包括
    DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和咖啡！目前，她正致力于学习和与开发者社区分享她的知识，通过编写教程、操作指南、观点文章等来实现。'
- en: More On This Topic
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关主题
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类解密：理解 K-Means 聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
- en: '[How to Use MultiIndex for Hierarchical Data Organization in Pandas](https://www.kdnuggets.com/how-to-use-multiindex-for-hierarchical-data-organization-in-pandas)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在 Pandas 中使用 MultiIndex 进行层次数据组织](https://www.kdnuggets.com/how-to-use-multiindex-for-hierarchical-data-organization-in-pandas)'
- en: '[Introduction to Clustering in Python with PyCaret](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyCaret 进行 Python 聚类导论](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)'
- en: '[Unveiling Midjourney 5.2: A Leap Forward in AI Image Generation](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 Midjourney 5.2：AI 图像生成的飞跃](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
- en: '[Unveiling the Potential of CTGAN: Harnessing Generative AI for…](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 CTGAN 的潜力：利用生成 AI 生成合成数据](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
- en: '[Unveiling Unsupervised Learning](https://www.kdnuggets.com/unveiling-unsupervised-learning)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示无监督学习](https://www.kdnuggets.com/unveiling-unsupervised-learning)'
