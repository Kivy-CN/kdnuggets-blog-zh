- en: Would You Survive the Titanic? A Guide to Machine Learning in Python Part 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/07/titanic-machine-learning-guide-part-2.html/2](https://www.kdnuggets.com/2016/07/titanic-machine-learning-guide-part-2.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Classification - The Fun Part**'
  prefs: []
  type: TYPE_NORMAL
- en: We will start off with a simple decision tree classifier. A decision tree examines
    one variable at a time, and splits into one of two branches based on the result
    of that value, at which point it does the same for the next variable. A fantasic
    visual explanation of how decision trees work can be found [here](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a trained decision tree for the Titanic dataset looks like, if
    we set the maximum number of levels to 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Decision tree](../Images/ba8a5a296a46ba87dcc053bdef4ff8e7.png)](/wp-content/uploads/socialcops-tree.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: The tree first splits by sex, and then by class, since it has learned during
    the training phase that these are the two most important features for determining
    survival. The dark blue boxes indicate passengers who are likely to survive, and
    the dark orange boxes represent passengers who are almost certainly doomed. Interestingly,
    after splitting by class, the main deciding factor determining the survival of
    women is the ticket fare that they paid, while the deciding factor for men is
    their age(with children being much more likely to survive).
  prefs: []
  type: TYPE_NORMAL
- en: To create this tree, first we initialize an instance of an untrained decision
    tree classifier(here we will set the maximum depth of the tree to 10). Next we
    “fit” this classifier to our training set, enabling it to learn about how different
    factors affect the survivability of a passenger. Now that the decision tree is
    ready, we can “score” it using our test data to determine how accurate it is.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*[Click here for the gist.](https://gist.github.com/triestpa/5858dc07caab1e33af10178fd1f236d5)*'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting reading, 0.7703, means that the model correctly predicted the
    survival of 77% of the test set. Not bad for our first model!
  prefs: []
  type: TYPE_NORMAL
- en: If you are being an attentive, skeptical reader(as you should be), you might
    be thinking that the accuracy of the model could vary somewhat depending on which
    rows were selected for the training and test sets. We will get around this problem
    by using a shuffle validator.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*[Click here for the gist.](https://gist.github.com/triestpa/e326db921a5400428aeb33130fb3152b)*'
  prefs: []
  type: TYPE_NORMAL
- en: This shuffle validator applies the same random 20:80 split as before, but this
    time generates 20 unique permutations of this split. By passing this shuffle validator
    as a parameter to the “cross_val_score” function, we can score our classifier
    against each of the different splits, and compute the average accuracy and standard
    deviation from the results.
  prefs: []
  type: TYPE_NORMAL
- en: The result shows that our decision tree classifier has an overall accuracy of
    77.34%, although it can go up to 80% and down to 75% depending on the training/test
    split. Using scikit-learn, we can easily test other machine learning algorithms
    using the exact same syntax.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*[Click here for the gist.](https://gist.github.com/triestpa/b6b3db3ac3424b664b59fbbf48d19859)*'
  prefs: []
  type: TYPE_NORMAL
- en: The “Random Forest” classification algorithm will create a multitude of (generally
    very poor) trees for the dataset using different random subsets of the input variables,
    and will return whichever prediction was returned by the most trees. This helps
    to avoid “overfitting”, a problem that occurs when a model is so tightly fitted
    to arbitrary correlations in the training data that it performs poorly on test
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The “Gradient Boosting” classifier will generate many weak, shallow prediction
    trees, and will combine, or “boost”, them into a strong model. This model performs
    very well on our dataset, but has the drawback of being relatively slow and difficult
    to optimize, as the model construction happens sequentially so cannot be parallelized.
  prefs: []
  type: TYPE_NORMAL
- en: A “Voting” classifier can be used to apply multiple conceptually divergent classification
    models to the same dataset, and will return the majority vote from all of the
    classifiers. For instance, if the gradient boosting classifier predicts that a
    passenger will not survive, but the decision tree and random forest classifiers
    predict that they will live, the voting classifier will chose the later.
  prefs: []
  type: TYPE_NORMAL
- en: This has been a very brief and non-technical overview of each technique, so
    I encourage you to learn more about the mathematical implementations of all of
    these algorithms to obtain a deeper understanding of their relative strengths
    and weaknesses. Many more classification algorithms are available “out-of-the-box”
    in scikit-learn and can be explored [here](http://scikit-learn.org/stable/modules/ensemble.html).
  prefs: []
  type: TYPE_NORMAL
- en: '![Patrick Triest](../Images/58fde3736bd01dbcfdf3fd2657ea5996.png)**Bio: [Patrick
    Triest](https://www.linkedin.com/in/triestpa)** is a 23 year old Android Developer
    / IoT Engineer / Data Scientist / wannabe pioneer, originally from Boston and
    now working at SocialCops. He’s addicted to learning, and sometimes after figuring
    out something particularly cool he gets really excited and writes about it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://blog.socialcops.com/engineering/machine-learning-python).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Machine Learning With Python](/2015/11/seven-steps-machine-learning-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 10 IPython Notebook Tutorials for Data Science and Machine Learning](/2016/04/top-10-ipython-nb-tutorials.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[R Learning Path: From beginner to expert in R in 7 steps](/2016/03/datacamp-r-learning-path-7-steps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Scientists Need to Specialize to Survive the Tech Winter](https://www.kdnuggets.com/2023/08/data-scientists-need-specialize-survive-tech-winter.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[If I Had To Start Learning Data Science Again, How Would I Do It?](https://www.kdnuggets.com/2020/08/start-learning-data-science-again.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[When Would Ensemble Techniques be a Good Choice?](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Interview Guide - Part 1: The Structure](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Want to Become a Data Scientist? Part 1: 10 Hard Skills You Need](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
