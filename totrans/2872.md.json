["```py\n\nfrom sklearn.metrics import f1_score\ny_true = [0, 1, 1, 0, 1, 1]\ny_pred = [0, 0, 1, 0, 0, 1]\n*f1_score(y_true, y_pred)* \n\n```", "```py\n# y_pred is an array of predictions\ndef bestThresshold(y_true,y_pred):\n    best_thresh = None\n    best_score = 0\n    for thresh in np.arange(0.1, 0.501, 0.01):\n        score = f1_score(y_true, np.array(y_pred)>thresh)\n        if score > best_score:\n            best_thresh = thresh\n            best_score = score\n    return best_score , best_thresh\n```", "```py\n\nfrom sklearn.metrics import fbeta_score\ny_true = [0, 1, 1, 0, 1, 1]\ny_pred = [0, 0, 1, 0, 0, 1]\nfbeta_score(y_true, y_pred,beta=0.5)\n\n```", "```py\n\nfrom sklearn.metrics import log_loss  \n# where y_pred are probabilities and y_true are binary class labels\nlog_loss(y_true, y_pred, eps=1e-15)\n\n```", "```py\n\nfrom sklearn.metrics import log_loss  \n# Where y_pred is a matrix of probabilities \n# with shape *=(n_samples, n_classes)* and y_true is an array of class labels\nlog_loss(y_true, y_pred, eps=1e-15)\n\n```", "```py\n\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\ny_true = np.array([0, 0, 1, 1])\ny_scores = np.array([0.1, 0.4, 0.35, 0.8])\n*print(roc_auc_score(y_true, y_scores))*\n\n```"]