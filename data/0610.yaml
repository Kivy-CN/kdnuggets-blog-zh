- en: Misconceptions About Semantic Segmentation Annotation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于语义分割注释的误解
- en: 原文：[https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)
- en: '![Misconceptions About Semantic Segmentation Annotation](../Images/191ab1b054b52ae28662451ffdbdb3cf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![关于语义分割注释的误解](../Images/191ab1b054b52ae28662451ffdbdb3cf.png)'
- en: '**Semantic segmentation** is a computer vision problem that entails putting
    related elements of an image into the same class.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**语义分割**是一个计算机视觉问题，涉及将图像中相关的元素归入同一类别。'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Three steps are involved in semantic segmentation:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割涉及三个步骤：
- en: '**Classifying:** Identifying and classifying a certain object in a picture.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类：** 识别并分类图片中的特定对象。'
- en: '**Localization:** Finding the item and putting a bounding box around.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**定位：** 查找物体并围绕其绘制边界框。'
- en: '**Segmentation:** A process of grouping pixels in a localized picture using
    a segmentation mask.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**分割：** 使用分割掩码将局部图片中的像素进行分组的过程。'
- en: 'There are several subtypes of semantic segmentation, but they all arise from
    selecting a pair of parameters from two categories: the data’s dimensionality
    and the granularity of the output annotations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割有几种子类型，但它们都源于从两个类别中选择一对参数：数据的维度和输出注释的粒度。
- en: '****Dimensionality****'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '****维度****'
- en: 'The number of dimensions in the data source is referred to as this. A normal
    camera picture is an example of a 2D object because it only has two dimensions:
    height and breadth. 3D data is a variation of 2D data with the addition of a ‘depth’
    component. Lidar and Radar scans are two kinds of sensor data. A 4D representation,
    commonly known as a movie, is created when several subsequent 3D objects are layered
    along the time axis.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源中的维度数量称为此。普通相机照片是2D对象的一个例子，因为它只有两个维度：高度和宽度。3D数据是2D数据的一种变体，增加了一个“深度”组件。Lidar和雷达扫描是两种传感器数据。当多个连续的3D对象沿时间轴层叠时，会创建一个4D表示，通常称为电影。
- en: 'We utilize a different form of semantic segmentation depending on the dimensionality
    of the data to create segmentation masks. In the case of 2D segmentation, one
    of two methods is used: pixel-based or polygon-based colouring. Because pixels
    are the smallest atomic component in this model, each one is given to one of the
    annotation classes. This leads to a point-based segmentation in 3D, where each
    3D point is labelled. A segmentation mesh can be extracted from a single object
    if enough points are provided.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据数据的维度使用不同形式的语义分割来创建分割掩码。在2D分割的情况下，使用两种方法之一：基于像素或基于多边形的着色。由于像素是此模型中最小的基本组成部分，每个像素都被分配到一个注释类别中。这导致在3D中进行基于点的分割，每个3D点都会被标记。如果提供了足够的点，可以从单个物体中提取分割网格。
- en: '**Granularity**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**粒度**'
- en: The amount of precision of the resulting annotations is referred to as granularity.
    Class-based and instance-aware segmentation are the two most common types. The
    segmentation mask for a particular class in the first example encompasses all
    areas that indicate a member of the class. In the second scenario, a distinct
    segmentation mask is constructed for each unique item of the chosen class, allowing
    different instances to be distinguished ( like separating two different cars for
    example ).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 结果标注的精确度称为粒度。基于类别和实例感知分割是最常见的两种类型。在第一个例子中，特定类别的分割掩模涵盖了所有表示该类别成员的区域。在第二种情况下，为每个选择类别的独特物体构建了不同的分割掩模，从而能够区分不同的实例（例如分开两辆不同的车）。
- en: In machine learning, which sort of semantic segmentation is more useful?
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在机器学习中，哪种语义分割更有用？
- en: In order to get the most out of [semantic segmentation](https://www.cogitotech.com/blog/what-is-semantic-image-segmentation-types),
    the instance-aware subtype should be used. Here are a few of the causes behind
    this.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大限度地发挥[语义分割](https://www.cogitotech.com/blog/what-is-semantic-image-segmentation-types)的效果，应该使用实例感知子类型。以下是一些原因。
- en: '**The format is quite adaptable**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式非常灵活**'
- en: With your data segmented, you can train and experiment with a variety of machine
    learning models, including classification, detection, and localization, picture
    creation, foreground/background separation, handwriting recognition, content alteration,
    and many others. As a result, it’s employed in a variety of industries, including
    autonomous driving, fashion, film creation and post-production, agriculture, and
    so on.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有了分割的数据，你可以训练和实验各种机器学习模型，包括分类、检测、定位、图像生成、前景/背景分离、手写识别、内容修改等。因此，它被广泛应用于各种行业，包括自动驾驶、时尚、电影制作和后期制作、农业等。
- en: '**Precision unrivalled**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度无与伦比**'
- en: Segmentation masks are the most exact since they only cover the position of
    the real item. Bounding boxes, on the other hand, frequently incorporate or connect
    with neighbouring territories. This is caused to non-rigid things being within
    or on top of other non-rigid objects.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 分割掩模最为精确，因为它们只覆盖真实物体的位置。另一方面，边界框经常包括或与邻近区域连接。这是因为非刚性物体在其他非刚性物体内或上面。
- en: '**One annotation with two annotations**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个标注两个标注**'
- en: Despite the fact that segmentation masks are more exact, bounding boxes are
    still used in many procedures. Fortunately, the surrounding bounding box can always
    be estimated using a segmentation mask. That’s how you cover all of your bases!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分割掩模更为精确，许多程序仍然使用边界框。幸运的是，可以始终通过分割掩模来估计周围的边界框。这就是你如何全面覆盖所有基础！
- en: '*Despite these benefits, there are significant drawbacks to using semantic
    segmentation as your annotation type of choice.*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*尽管有这些优点，使用语义分割作为标注类型也有显著的缺点。*'
- en: Part 1 is the most difficult
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一部分是最困难的
- en: '**1\. It’s difficult and time-consuming to annotate by hand**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 手动标注既困难又耗时**'
- en: Making semantic masks by hand is a time-consuming and difficult task. When confronted
    with irregular forms or locations where the boundary between items is not immediately
    discernible, the labeller must accurately follow the outlines of each object (see
    pictures below). Annotating a single frame without specialized tools is prone
    to mistakes, inconsistencies, and can take more than 30 minutes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 手动制作语义掩模是一项耗时且困难的任务。当面对不规则形状或物体边界不易察觉的区域时，标注者必须准确跟随每个物体的轮廓（见下图）。没有专业工具的情况下标注单帧容易出错、不一致，且可能需要超过30分钟。
- en: '**2\. Fully automated methods are incapable of delivering high-quality results**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 完全自动化的方法无法提供高质量的结果**'
- en: Wouldn’t it be great if we could just train a neural network to do semantic
    segmentation once and then have all of our annotations without having to do anything?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们可以只训练一个神经网络进行语义分割，然后获得所有标注而无需做任何事情，那不是很好吗？
- en: The reason for this is a misalignment between our perceptions of quality and
    how accuracy is assessed. The contour of an item is used to generate a segmentation
    mask, and the quality is determined by the percentage of the region that was properly
    detected.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于我们对质量的认知与准确度的评估之间存在不一致。分割掩模是通过物体轮廓生成的，质量由正确检测到的区域百分比来确定。
- en: '**3\. It takes a long time to fix mistakes**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 纠正错误需要很长时间**'
- en: Mistakes may be expensive in each of the aforementioned ways. Correcting an
    imperfect segmentation mask necessitates the correction of N additional masks,
    where N is the number of neighbouring masks (we’ll return to this later). It takes
    as long to adjust the mask as it does to create it from start. As a result, human
    adjustment of a completely automated segmentation’s output is likewise not possible.
    The only method to prevent this issue is to use specialized annotation software
    and labellers who are adequately educated.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上述每种方式中的错误可能都很昂贵。修正一个不完美的分割掩膜需要修正 N 个额外的掩膜，其中 N 是邻近掩膜的数量（稍后我们会回到这个问题）。调整掩膜所需的时间与从头创建掩膜的时间相同。因此，完全自动化的分割输出也无法通过人工调整来完成。唯一防止这个问题的方法是使用专门的标注软件和经过充分培训的标注员。
- en: '**4\. Semantic segmentation annotation costs**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 语义分割标注成本**'
- en: As you may have seen, segmentation mask creation necessitates the use of specific
    annotators, equipment, and automation. This raises the price dramatically, frequently
    by several folds above the cost of annotating basic bounding boxes, and quickly
    depletes the budget.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能看到的，创建分割掩膜需要使用特定的标注员、设备和自动化技术。这大大提高了价格，通常是标注基本边界框成本的几倍，并迅速耗尽预算。
- en: '**Gaurav Sharma** has worked in the fields of artificial intelligence and machine
    learning for over six years. Gaurav is a freelance technical writer working for
    [Cogito Tech LLC](https://www.cogitotech.com/), [Anolytics.ai](https://www.anolytics.ai/)
    and other reputed data labelling companies that provide training data to AI business.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gaurav Sharma** 在人工智能和机器学习领域工作了超过六年。Gaurav 是一名自由技术作家，为 [Cogito Tech LLC](https://www.cogitotech.com/)、[Anolytics.ai](https://www.anolytics.ai/)
    及其他提供训练数据给 AI 业务的著名数据标注公司工作。'
- en: More On This Topic
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Bounding Box Deep Learning: The Future of Video Annotation](https://www.kdnuggets.com/2022/07/bounding-box-deep-learning-future-video-annotation.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[边界框深度学习：视频标注的未来](https://www.kdnuggets.com/2022/07/bounding-box-deep-learning-future-video-annotation.html)'
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速指南：如何找到合适的标注人才](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
- en: '[Closed Source VS Open Source Image Annotation](https://www.kdnuggets.com/closed-source-vs-open-source-image-annotation)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[闭源与开源图像标注](https://www.kdnuggets.com/closed-source-vs-open-source-image-annotation)'
- en: '[The Power of a Semantic Layer: A Data Engineer''s Guide](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层的力量：数据工程师指南](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
- en: '[Semantic Layer: The Backbone of AI-powered Data Experiences](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层：AI驱动数据体验的支柱](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义向量搜索如何改变客户支持互动](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
