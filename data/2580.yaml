- en: Data Validation in Machine Learning is Imperative, Not Optional
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据验证在机器学习中是至关重要的，而非可选的
- en: 原文：[https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html](https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html](https://www.kdnuggets.com/2021/05/data-validation-machine-learning-imperative.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Aditya Aggarwal](https://www.linkedin.com/in/aditya-agarwal-2395076/),
    Data Science Practice Lead & [Arnab Bose](https://www.linkedin.com/in/arnab-bose-phd-6369531/),
    Chief Scientific Officer, Abzooba**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Aditya Aggarwal](https://www.linkedin.com/in/aditya-agarwal-2395076/)，数据科学实践负责人
    & [Arnab Bose](https://www.linkedin.com/in/arnab-bose-phd-6369531/)，首席科学官，Abzooba**'
- en: 'Operationalizing a Machine Learning (ML) model in production needs a lot more
    than just creating and validating models like in academia or research. The ML
    application in production can be a pipeline with multiple components running consecutively
    as shown in Fig 1. Before we reach model training in the pipeline, there are various
    components like Data Ingestion, Data versioning, Data validation, and Data pre-processing
    that need to be executed. Here, we will discuss the Data Validation and have arranged
    this article as below:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中运作一个机器学习（ML）模型需要远比在学术界或研究中创建和验证模型要复杂得多。生产中的ML应用程序可以是一个包含多个组件顺序运行的管道，如图
    1 所示。在我们达到管道中的模型训练之前，需要执行多个组件，如数据摄取、数据版本控制、数据验证和数据预处理。在这里，我们将讨论数据验证，并将本文安排如下：
- en: What is data validation?
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是数据验证？
- en: Why is data validation required?
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么需要数据验证？
- en: What are the challenges with data validation?
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据验证面临哪些挑战？
- en: How does the data validation component work?
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据验证组件是如何工作的？
- en: Examples of data validation components available in the market.​​​​​​​​​​​​​​
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 市场上可用的数据验证组件示例。​​​​​​​​​​​​​​
- en: '![Figure](../Images/606003bb28e7628e01050c103bd49341.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/606003bb28e7628e01050c103bd49341.png)'
- en: '**Figure 1: Components in machine learning pipelines**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1：机器学习流程中的组件**'
- en: '**1) What is data validation?**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**1) 什么是数据验证？**'
- en: ​​​​​​​Data validation means **checking the accuracy and quality of source data**
    before training a new model version. It ensures that **anomalies** that are infrequent
    or manifested in incremental data **are not silently ignored.** It focuses on
    checking that the statistics of the new data are as expected (e.g. feature distribution,
    number of categories, etc). Different types of validation can be performed depending
    on objectives and constraints. Examples of such objectives in the machine learning
    pipeline are below - ​​​​​​​
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据验证意味着**检查源数据的准确性和质量**，在训练新模型版本之前进行。它确保**稀有或增量数据中出现的异常**不会**被默默忽略。** 它侧重于检查新数据的统计数据是否符合预期（例如特征分布、类别数量等）。根据目标和约束，可以执行不同类型的验证。机器学习流程中的一些目标示例如下
    - ​​​​​​
- en: Are there any **anomalies or data errors** in the incremental data? If yes,
    raise an alert to the team for investigation.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增量数据中是否有**异常或数据错误**？如果有，请向团队发出警报进行调查。
- en: Are there any **assumptions on data** that are taken **during model training** and
    are getting violated during serving? If yes, raise an alert to the team for investigation.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型训练过程中是否有任何**数据假设**被**违反**？如果有，请向团队发出警报进行调查。
- en: Are there **significant differences** between **training** and **serving** data?
    Or, Are there differences between successive data that are getting added into
    training data? If yes, raise an alert to investigate differences in training and
    serving code stack.​​​​​​​​​​​​​​
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练**数据和**服务**数据之间是否有**显著差异**？或者，是否有连续数据的差异被添加到训练数据中？如果有，请发出警报以调查训练和服务代码堆栈中的差异。​​​​​​​​​​​​​​'
- en: Output from the data validation step should be **informative** enough that a
    data engineer can take **action** on it. Also, it needs to have **high precision**
    as too many false alarms will easily be lost credibility.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据验证步骤的输出应该是**信息丰富的**，以便数据工程师可以对其采取**行动**。此外，它还需要具有**高精度**，因为过多的假警报会轻易失去可信度。
- en: '**2) Why is data validation required?**​​​​​​​'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**2) 为什么需要数据验证？**​​​​​​​'
- en: Machine learning models are vulnerable to poor data quality as per the old adage
    "garbage in garbage out".
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型容易受到数据质量差的影响，正如古老的谚语所说“垃圾进垃圾出”。
- en: In production, the model gets re-trained with a fresh set of incremental data
    added on a periodic basis (as frequent as daily) and the updated model is pushed
    to the serving layer. The model makes predictions with new incoming data while
    serving and the same data is added with actual labels and used for retraining.
    This ensures that the newly generated model adapts to the changes in data characteristics.  ​​​​​​​
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，模型会周期性地使用新增的增量数据进行重新训练（频率可高达每日），并将更新的模型推送到服务层。模型在服务时使用新进入的数据进行预测，并且同样的数据会添加实际标签后用于重新训练。这确保了新生成的模型能够适应数据特征的变化。
- en: However, the new incoming **data in the serving layer can change **due to various
    reasons like changes in code that introduces errors in the serving data ingestion
    component or the difference between training and serving stacks. With time, the
    **erroneous ingested data​​​​​​​** will become part of the training data and this
    will start **degrading the model accuracy.** Since In each iteration, newly added
    data is generally a small fraction of overall training data, hence, the changes
    in model accuracy will be easily missed and the **errors will keep adding with
    time**. ​​​​​​​ ​​​​​​​​​​​​​​
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，服务层中新进入的**数据可能会发生变化**，原因包括引入错误的代码更改或训练和服务堆栈之间的差异。随着时间的推移，**错误的摄取数据**将成为训练数据的一部分，这将开始**降低模型的准确性**。由于每次迭代中新添加的数据通常只是总体训练数据的一小部分，因此模型准确性的变化很容易被忽视，**错误会随着时间的推移不断增加**。
- en: Thus, **catching the data errors at an early stage** is very important because it
    will reduce the cost of data error which is bound to increase as the error propagates
    further in the pipeline (as shown in fig 2). ​​​​​​​​​​​​​​​​​​​​​
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，**在早期阶段捕捉数据错误**非常重要，因为这将减少数据错误的成本，随着错误在管道中进一步传播，成本必然会增加（如图2所示）。
- en: '![Figure](../Images/daef50f86df768b4248dfe974eeda2e0.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/daef50f86df768b4248dfe974eeda2e0.png)'
- en: '**Figure 2: Cost of data error in machine learning pipelines**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2：机器学习管道中的数据错误成本**'
- en: '**3) What are the challenges with the data validation?**'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**3) 数据验证面临哪些挑战？**'
- en: There are various challenges that a data scientist faces while developing a
    data validation component, such as
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家在开发数据验证组件时面临各种挑战，例如
- en: Creating data validation rules for a dataset with few columns does sound simple.
    However, **when the number of columns in datasets increases, it becomes a humongous
    task**.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为具有少量列的数据集创建数据验证规则听起来很简单。然而，**当数据集中的列数增加时，这将变成一项庞大的任务**。
- en: Tracking and comparing metrics from the historical datasets to find **anomalies
    in historical trends for each column** needs a good amount of recurring time from
    a data scientist.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 追踪和比较历史数据集中的指标以找出**每列的历史趋势中的异常**需要数据科学家花费大量时间。
- en: Today applications are expected to run 24-by-7 and in such scenarios, **data
    validation needs to be automated.** The data validation component should be smart
    enough to refresh validation rules.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在的应用程序预计会全天候运行，在这种情况下，**数据验证需要自动化**。数据验证组件应该足够智能，能够刷新验证规则。
- en: '**4) How does the data validation component work?**'
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4) 数据验证组件如何工作？**'
- en: 'Think of the data validation component as a guard post of the ML application
    that does not let bad quality data in. It keeps a check on each and every new
    data entry that is going to add to the training data. As shown in Fig 3, the data
    validation framework can be summarised in 5 steps:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 把数据验证组件想象成ML应用程序的一个哨岗，阻止低质量数据进入。它会检查每一条即将添加到训练数据中的新数据。如图3所示，数据验证框架可以总结为5个步骤：
- en: ​​​​Calculate the statistics from the training data against a set of rules
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据一组规则计算训练数据的统计信息
- en: Calculate the statistics of the ingested data that has to be validated
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算需要验证的摄取数据的统计信息
- en: Compare the statistics of the validation data with the statistics from the training
    data
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将验证数据的统计信息与训练数据的统计信息进行比较
- en: Store the validation results and takes automated actions like removing the row,
    capping, or flooring the values
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储验证结果并采取自动化措施，如删除行、限制或调整值
- en: Sending the notification and alerts for approval​​​​​​​
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送通知和警报以供审批
- en: '[![Figure](../Images/9f0b435b38e84720969fc559e80184bd.png)](https://i.ibb.co/16Cc8G9/data-validation-imperative-3-large.png)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图](../Images/9f0b435b38e84720969fc559e80184bd.png)](https://i.ibb.co/16Cc8G9/data-validation-imperative-3-large.png)'
- en: '**Figure 3: Data validation workflow (click to enlarge)**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3：数据验证工作流程（点击放大）**'
- en: '**5) Examples of data validation components available in the market **'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5) 市场上可用的数据验证组件示例**'
- en: ​​
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ​​
- en: ​​​​​​​​​​​​Amazon Research [1] and Google Research [2] proposed a very similar
    approach to building a data validation component. Overall, both approaches follow
    the same workflow as given in Fig 2. We will discuss both approaches here.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ​​​​​​​​​​​​亚马逊研究 [1] 和谷歌研究 [2] 提出了非常相似的数据验证组件构建方法。总体而言，这两种方法遵循了图2所示的相同工作流程。我们将在这里讨论这两种方法。
- en: '**5.1) Unit-test approach for data validation by Amazon Research (Deequ)**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**5.1) 亚马逊研究（Deequ）的数据验证单元测试方法**'
- en: In software engineering, engineers write unit tests to test their code. Similarly,
    unit tests should also be defined to test the incoming data. Authors have defined
    a framework to define this component that follows the below principles -
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中，工程师编写单元测试来测试他们的代码。同样，也应该定义单元测试来测试传入的数据。作者定义了一个框架来定义这个组件，该框架遵循以下原则 -
- en: 'a) **Declare constraints**: User defines how their data should look like. It
    works by declaring checks on their data by composing constraints on various columns.
    A list of constraints is shown in Table 1 below.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: a) **声明约束**：用户定义数据应该是什么样的。通过在数据上声明检查，按不同列组合约束来实现。表1中显示了约束列表。
- en: 'b) **Compute metrics**: Based on the declared constraint, translate them to
    measurable metrics as shown in Table 2 below. These metrics can be computed and
    compared between the data in hand and the incremental data.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: b) **计算度量**：根据声明的约束，将其转换为可测量的度量，如下表2所示。这些度量可以计算并在手头数据和增量数据之间进行比较。
- en: c) **Analyze and report: **Based on the collected metrics over time, predict
    if the metric on the incremental data is an anomaly or not. As a rule, the user
    can have the system issue "a warning" if the new metric is more than three standard
    deviations away from the previous mean or throw "an error" if it is more than
    four standard deviations away. Basis the analysis, report the constraints that
    fail including the value(s) that made the constraint fail. ​​​​​​
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: c) **分析和报告：** 根据随时间收集的度量，预测增量数据中的度量是否异常。作为规则，如果新度量值比之前的均值多出三倍标准差，用户可以让系统发出“警告”；如果多出四倍标准差，则抛出“错误”。根据分析，报告失败的约束，包括导致约束失败的值(s)。​​​​​​
- en: '**Table 1: Constraints available for composing user-defined data quality checks**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1：用于编排用户定义数据质量检查的约束**'
- en: '![Figure](../Images/de29fd8f0b908476f45a8ade91a6e6d9.png)**Table 2: Computable
    metrics to based constraints on**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![图](../Images/de29fd8f0b908476f45a8ade91a6e6d9.png)**表2：基于约束的可计算度量**'
- en: '![Figure](../Images/6d22df7c707eb74a7c4ac679e76ca189.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6d22df7c707eb74a7c4ac679e76ca189.png)'
- en: '**5.2) Data schema approach for data validation by Google Research (Tensorflow
    data validation)**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**5.2) 谷歌研究（Tensorflow数据验证）的数据模式方法**'
- en: ​​​​​​Google Research has come up with a very similar technique but adopted
    "battle-tested" principles from the data management system and customized it for
    ML. This technique first codifies the expectation from correct data and then using
    these expected statistics along with user-defined validation schema performs data
    validation.​​​​​​​ This data validation framework consists of **3 sub-component**
    as also shown in Fig 4.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ​​​​​​谷歌研究提出了非常相似的技术，但采用了数据管理系统中“经过实战考验”的原则，并将其定制用于机器学习。该技术首先将对正确数据的期望进行编码，然后利用这些期望的统计数据和用户定义的验证模式进行数据验证。​​​​​​​
    该数据验证框架包含**3个子组件**，如图4所示。
- en: '**Data Analyzer** - computes a predefined set of data statistics required to
    define the data'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据分析器** - 计算定义数据所需的一组预定义数据统计信息'
- en: '**Data Validator** - checks for properties of data as specified through a schema.
    This schema is a precursor for a data validator to perform. This schema list out
    all the constraints on the features for basic checks and ML-related checks.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据验证器** - 根据通过模式指定的数据属性进行检查。此模式是数据验证器执行的前提。此模式列出了所有特征的基本检查和与机器学习相关的检查的约束。'
- en: '**Model Unit Tester** - checks for errors in training code using synthetic
    data generated through the schema'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型单元测试器** - 使用通过模式生成的合成数据检查训练代码中的错误'
- en: This framework gives the user the **ability to**
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架为用户提供了**能力**
- en: '**validate a single batch of incremental data by detecting anomalies in it**'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**通过检测数据中的异常来验证单批增量数据**'
- en: '**Detect significant changes between successive batches of incremental training
    data**. Few anomalies are not visible when checking only a single batch but manifest when
    we look at successive batches.​​​​​​​'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检测连续增量训练数据批次之间的显著变化**。一些异常在检查单个批次时不可见，但在查看连续批次时会显现。​​​​​​​'
- en: '**Find assumptions in the training code that are not reflected in the data**
    (e.g. if a feature is expected to have log() in the training code should not have
    -ve value or string values). The goal here is to cover those constraints that
    are missed to add into the schema. It happens in 2 steps'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查找训练代码中未反映在数据中的假设**（例如，如果训练代码中的特征预期应有 log()，则不应有负值或字符串值）。目标是涵盖那些未被添加到模式中的约束。此过程分为两个步骤'
- en: ​​​​​Synthetic training examples that adhere to the schema constraints are generated
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成符合模式约束的合成训练示例
- en: This generated data is iterated through the training code for checking errors
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的数据会通过训练代码进行迭代以检查错误
- en: '![Figure](../Images/2c4aaa37376bbd4ad55113aab845ccd7.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/2c4aaa37376bbd4ad55113aab845ccd7.png)'
- en: '**Figure 4: Data validation for machine learning by Google Research**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4: 谷歌研究的机器学习数据验证**'
- en: Both Amazon Research and Google Research approaches provide users with suggestions
    such as constraints in the Amazon framework and recommendations to update schema
    in the google framework. Both approaches treat data as a first-class citizen in
    ML pipelines and do data validation before putting data into the system. However,
    there are few differences worth noting.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊研究和谷歌研究的方法都为用户提供了建议，比如亚马逊框架中的约束和谷歌框架中更新模式的推荐。这两种方法都将数据视为机器学习管道中的一等公民，并在将数据输入系统之前进行数据验证。然而，仍有一些值得注意的区别。
- en: '**Table 3: Differences between data validation libraries**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**表格 3: 数据验证库的差异**'
- en: '|  | **Deequ (Amazon)** | **Tensorflow data validation (Google)** |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  | **Deequ（亚马逊）** | **Tensorflow 数据验证（谷歌）** |'
- en: '| **1** | No visualization available | Provides visualization using Google
    Facets. It summarises statistics for each feature and compares the training and
    validation data. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 无可用可视化 | 使用谷歌 Facets 提供可视化。总结了每个特征的统计数据，并比较训练数据和验证数据。 |'
- en: '| **2** | Recalculates training statistics by aggregating prior saved training
    statistics and new data statistics.   | Calculates statistics on whole training
    data in every run unless specified. This may become computationally expensive.
    |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 通过聚合之前保存的训练统计数据和新数据统计数据来重新计算训练统计数据。 | 每次运行时计算整个训练数据的统计数据，除非另有指定。这可能会变得计算开销较大。
    |'
- en: '| **3** | Provides capability to do anomaly detection based on running average
    and standard deviation in addition to the threshold or absolute/relative difference
    from training data. | Provides capability to do anomaly detection based on the
    threshold or absolute/relative difference from training data. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 除了基于阈值或相对/绝对差异进行异常检测，还提供基于运行平均值和标准差的异常检测能力。 | 提供基于阈值或相对/绝对差异的异常检测能力。
    |'
- en: '| **4** | Supports data only in SparkDataFrame. | Supports pandas dataframe,
    csv, and best works with TFRecord. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| **4** | 仅支持 SparkDataFrame 数据。 | 支持 pandas dataframe、csv，且与 TFRecord 配合最佳。
    |'
- en: '**References**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: 'S. Schelter, D. Lange, P. Schmidt, M. Celikel, F. Biessmann and A. Grafberger,
    "Automating Large-Scale Data Quality Verification" in Proceedings of the VLDB
    endowment, volume 11, Issue 12: 1781-1794, 2018\. Available: [http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf](http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf)​​​​​​​'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: S. Schelter, D. Lange, P. Schmidt, M. Celikel, F. Biessmann 和 A. Grafberger，“大规模数据质量验证的自动化”，发表于
    VLDB 基金会，卷 11，第 12 期：1781-1794，2018年。可用： [http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf](http://www.vldb.org/pvldb/vol11/p1781-schelter.pdf)​​​​​​​
- en: E. Breck, M. Zinkevich, N. Polyzotis, S. Whang and S. Roy, "Data validation
    for machine learning", in Proceedings of the 2nd SysML Conference, Palo Alto,
    CA, USA, 2019\. Available: [https://mlsys.org/Conferences/2019/doc/2019/167.pdf](https://mlsys.org/Conferences/2019/doc/2019/167.pdf)
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: E. Breck, M. Zinkevich, N. Polyzotis, S. Whang 和 S. Roy，“机器学习的数据验证”，发表于第二届 SysML
    会议，帕洛阿尔托，加州，美国，2019年。可用： [https://mlsys.org/Conferences/2019/doc/2019/167.pdf](https://mlsys.org/Conferences/2019/doc/2019/167.pdf)
- en: '[**Aditya Aggarwal**](https://www.linkedin.com/in/aditya-agarwal-2395076/) serves
    as Data Science – Practice Lead at Abzooba Inc. With more than 12+ years’ experience
    in driving business goals through data-driven solutions, Aditya specializes in
    predictive analytics, machine learning, business intelligence & business strategy
    across a range of industries. As the Advanced Analytics Practice Lead at Abzooba,
    Aditya leads a team of 50+ energetic data science professionals at Abzooba that
    are solving interesting business problems using machine learning, deep learning,
    Natural Language Processing and computer vision. He provides thought leadership
    in AI to clients to translate their business objectives into analytical problems
    and data-driven solutions. Under his leadership, several organizations have automated
    routine tasks, reduced operational cost, boosted team productivity, and improved
    top-line and bottom-line revenues. He has built solutions such as subrogation
    engine, price recommendation engine, IoT sensor predictive maintenance, and more.
    Aditya holds a Bachelor of Technology and Minor Degree in Business Management
    from Indian Institute of Technology (IIT), Delhi.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[**阿迪提亚·阿格尔瓦尔**](https://www.linkedin.com/in/aditya-agarwal-2395076/)担任Abzooba
    Inc.的数据科学实践负责人。凭借超过12年的数据驱动解决方案推动业务目标的经验，阿迪提亚专注于预测分析、机器学习、商业智能和商业战略。他是Abzooba的高级分析实践负责人，领导着一个50多人的充满活力的数据科学团队，使用机器学习、深度学习、自然语言处理和计算机视觉解决有趣的商业问题。他为客户提供人工智能方面的思想领导，将其商业目标转化为分析问题和数据驱动解决方案。在他的领导下，多个组织实现了任务自动化、降低了运营成本、提高了团队生产力，并改善了收入和利润。他开发了如代位索赔引擎、价格推荐引擎、物联网传感器预测维护等解决方案。阿迪提亚拥有印度技术学院（IIT）德里的技术学士学位和商业管理辅修学位。'
- en: '[**Dr. Arnab Bose**](https://www.linkedin.com/in/arnab-bose-phd-6369531/) is
    Chief Scientific Officer at Abzooba, a data analytics company, and an adjunct
    faculty at the University of Chicago where he teaches Machine Learning and Predictive
    Analytics, Machine Learning Operations, Time Series Analysis and Forecasting,
    and Health Analytics in the Master of Science in Analytics program. He is a 20-year
    predictive analytics industry veteran who enjoys using unstructured and structured
    data to forecast and influence behavioral outcomes in healthcare, retail, finance,
    and transportation. His current focus areas include health risk stratification
    and chronic disease management using machine learning, and production deployment
    and monitoring of machine learning models. Arnab has published book chapters and
    refereed papers in numerous Institute of Electrical and Electronics Engineers
    (IEEE) conferences & journals. He has received Best Presentation at American Control
    Conference and has given talks on data analytics at universities and companies
    in US, Australia, and India. Arnab holds MS and Ph.D. degrees in electrical engineering
    from the University of Southern California, and a B.Tech. in electrical engineering
    from the Indian Institute of Technology at Kharagpur, India.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**阿纳布·博斯博士**](https://www.linkedin.com/in/arnab-bose-phd-6369531/)是Abzooba的首席科学官，该公司是一家数据分析公司，并且是芝加哥大学的兼职教员，教授机器学习、预测分析、机器学习操作、时间序列分析与预测以及健康分析等课程。他是一位拥有20年预测分析行业经验的专家，喜欢使用结构化和非结构化数据来预测和影响医疗保健、零售、金融和交通领域的行为结果。他目前的研究重点包括使用机器学习进行健康风险分层和慢性病管理，以及机器学习模型的生产部署和监控。阿纳布在许多电气和电子工程师协会（IEEE）会议和期刊上发表了书籍章节和审稿论文。他曾获得美国控制会议最佳演讲奖，并在美国、澳大利亚和印度的大学和公司中发表过关于数据分析的讲座。阿纳布拥有南加州大学的电气工程硕士和博士学位，以及印度技术学院卡拉格普尔分校的电气工程学士学位。'
- en: '**Related:**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[MLOps – “Why is it required?” and “What it is”?](/2020/12/mlops-why-required-what-is.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps——“为什么需要它？”和“它是什么”？](/2020/12/mlops-why-required-what-is.html)'
- en: '[Data Validation and Data Verification – From Dictionary to Machine Learning](/2021/03/data-validation-data-verification-dictionary-machine-learning.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据验证和数据核实——从字典到机器学习](/2021/03/data-validation-data-verification-dictionary-machine-learning.html)'
- en: '[How to get started managing data quality with SQL and scale](/2021/05/soda-io-managing-data-quality-sql-scale.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何开始使用SQL管理数据质量并进行扩展](/2021/05/soda-io-managing-data-quality-sql-scale.html)'
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 部门'
- en: '* * *'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Data Validation for PySpark Applications using Pandera](https://www.kdnuggets.com/2023/08/data-validation-pyspark-applications-pandera.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Pandera 对 PySpark 应用进行数据验证](https://www.kdnuggets.com/2023/08/data-validation-pyspark-applications-pandera.html)'
- en: '[Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pydantic 教程：简化 Python 中的数据验证](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
- en: '[MarshMallow: The Sweetest Python Library for Data Serialization and…](https://www.kdnuggets.com/marshmallow-the-sweetest-python-library-for-data-serialization-and-validation)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MarshMallow：最甜美的 Python 数据序列化和验证库](https://www.kdnuggets.com/marshmallow-the-sweetest-python-library-for-data-serialization-and-validation)'
- en: '[Why Use k-fold Cross Validation?](https://www.kdnuggets.com/2022/07/kfold-cross-validation.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么使用 k-fold 交叉验证？](https://www.kdnuggets.com/2022/07/kfold-cross-validation.html)'
- en: '[Machine learning does not produce value for my business. Why?](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习未能为我的业务带来价值，为什么？](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)'
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同：神经元运行缓慢，……](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
