- en: 'Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门LLMOps：无缝交互的秘密秘诀
- en: 原文：[https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions](https://www.kdnuggets.com/getting-started-with-llmops-the-secret-sauce-behind-seamless-interactions)
- en: '![Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions](../Images/41bbf21ab76e836297729c8240eceddc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![入门LLMOps：无缝交互的秘密秘诀](../Images/41bbf21ab76e836297729c8240eceddc.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Large Language Models (LLMs) are a new type of artificial intelligence that
    is trained on massive amounts of text data. Their main ability is to generate
    human-like text in response to a wide range of prompts and requests.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是一种新型的人工智能，经过大量文本数据的训练。它们的主要能力是在回应各种提示和请求时生成类似人类的文本。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在的组织在IT领域'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: I bet you have already had some experience with popular LLM solutions like ChatGPT
    or Google Gemini.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我敢打赌你已经对像ChatGPT或Google Gemini这样的流行LLM解决方案有所了解。
- en: But have you ever wondered how these powerful models deliver such lightning-fast
    responses?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但你有没有想过这些强大的模型是如何提供如此迅速的响应的？
- en: The answer lies in a specialized field called LLMOps.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 答案在一个名为LLMOps的专业领域中。
- en: Before diving in, let’s try to visualize the importance of this field.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解之前，让我们先尝试可视化这个领域的重要性。
- en: Imagine you're having a conversation with a friend. The normal thing you would
    expect is that when you ask a question, they give you an answer right away, and
    the dialogue flows effortlessly.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你正在和朋友对话。你期望的正常情况是，当你提问时，他们会立刻给你回答，对话自然流畅。
- en: Right?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对吧？
- en: This smooth exchange is what users expect as well when interacting with Large
    Language Models (LLMs). Imagine chatting with ChatGPT and having to wait for a
    of couple minutes every time we send a prompt, nobody would use it at all, at
    least I wouldn’t for sure.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种流畅的交流是用户在与大型语言模型（LLMs）互动时所期望的。想象一下，如果与ChatGPT对话时，每次发送提示都要等几分钟，那几乎没人会使用它，至少我肯定不会。
- en: This is why LLMs are aiming to achieve this conversation flow and effectiveness
    in their digital solutions with the LLMOps field. This guide aims to be your companion
    in your first steps in this brand-new domain.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么LLMs旨在通过LLMOps领域在其数字解决方案中实现这种对话流畅性和有效性。本指南旨在成为你在这个全新领域的首步伴侣。
- en: What is LLMOps?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是LLMOps？
- en: LLMOps, short for Large Language Model Operations, is the behind-the-scenes
    magic that ensures LLMs function efficiently and reliably. It represents an advancement
    from the familiar MLOps, specifically designed to address the unique challenges
    posed by LLMs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps，即大型语言模型操作，是确保大型语言模型（LLMs）高效和可靠运行的幕后魔力。它代表了一种对熟悉的MLOps的进步，专门设计用于解决LLMs所带来的独特挑战。
- en: While MLOps focuses on managing the lifecycle of general machine learning models,
    LLMOps deals specifically with the LLM-specific requirements.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然MLOps专注于管理通用机器学习模型的生命周期，但LLMOps专门处理LLMs特有的需求。
- en: When using models from entities like OpenAI or Anthropic through web interfaces
    or API, LLMOps work behind the scenes, making these models accessible as services.
    However, when deploying a model for a specialized application, LLMOps responsibility
    relies on us.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过网络接口或API使用来自OpenAI或Anthropic等实体的模型时，LLMOps在幕后工作，使这些模型作为服务可用。然而，当为特定应用部署模型时，LLMOps的责任就落在我们身上。
- en: So think of it like a moderator taking care of a debate’s flow. Just like the
    moderator keeps the conversation running smoothly and aligned to the debate’s
    topic, always making sure there are no bad words and trying to avoid fake news,
    LLMOps ensures that LLMs operate at peak performance, delivering seamless user
    experiences and checking the safety of the output.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 可以把它想象成一个主持人负责讨论的流程。就像主持人保持对话的流畅和与讨论主题的一致，始终确保没有不当言辞并尽量避免假新闻，LLMOps 确保 LLM 以最佳性能运行，提供无缝的用户体验并检查输出的安全性。
- en: Why is LLMOps Important?
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么 LLMOps 重要？
- en: Creating applications with Large Language Models (LLMs) introduces challenges
    distinct from those seen with conventional machine learning. To navigate these,
    innovative management tools and methodologies have been crafted, giving rise to
    the LLMOps framework.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLMs）创建应用程序带来了不同于传统机器学习的挑战。为了解决这些问题，开发了创新的管理工具和方法，形成了 LLMOps 框架。
- en: 'Here''s why LLMOps is crucial for the success of any LLM-powered application:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么 LLMOps 对任何 LLM 驱动的应用程序的成功至关重要：
- en: '![Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions](../Images/a915ad3f3626a748263b54f309695db9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![入门 LLMOps：无缝交互的秘密配方](../Images/a915ad3f3626a748263b54f309695db9.png)'
- en: Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '**Speed is Key:** Users expect immediate responses when interacting with LLMs.
    LLMOps optimizes the process to minimize latency, ensuring you get answers within
    a reasonable timeframe.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**速度是关键：** 用户期望在与 LLM 交互时获得即时回应。LLMOps 优化了这个过程，以最小化延迟，确保你在合理的时间内得到答案。'
- en: '**Accuracy Matters:** LLMOps implements various checks and controls to guarantee
    the accuracy and relevance of the LLM''s responses.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准确性至关重要：** LLMOps 实施各种检查和控制措施，以确保 LLM 的响应准确且相关。'
- en: '**Scalability for Growth:** As your LLM application gains traction, LLMOps
    helps you scale resources efficiently to handle increasing user loads.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**增长的可扩展性：** 随着 LLM 应用的受欢迎，LLMOps 帮助你有效扩展资源，以处理不断增加的用户负载。'
- en: '**Security is Paramount:** LLMOps safeguards the integrity of the LLM system
    and protects sensitive data by enforcing robust security measures.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安全至关重要：** LLMOps 通过实施严格的安全措施，保护 LLM 系统的完整性和敏感数据。'
- en: '**Cost-effectiveness:** Operating LLMs can be financially demanding due to
    their significant resource requirements. LLMOps brings into play economical methods
    to maximize resource utilization efficiently, ensuring peak performance isn''t
    sacrificed.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本效益：** 运行 LLM 可能会因其显著的资源需求而变得财务昂贵。LLMOps 采用经济的方法来最大化资源利用效率，确保不会牺牲高性能。'
- en: 'LLMOps Workflow: Understanding the Magic'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMOps 工作流：了解魔力
- en: LLMOps makes sure your prompt is ready for the LLM and its response comes back
    to you as fast as possible. However, this is not easy at all.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps 确保你的提示准备好供 LLM 使用，并尽快返回响应。然而，这一点并不容易。
- en: This process involves several steps, mainly 4, that can be observed in the image
    below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程包括几个步骤，主要是4步，可以在下面的图像中看到。
- en: '![Getting Started with LLMOps: The Secret Sauce Behind Seamless Interactions](../Images/3a40915e3381e3711eb36893a30b7a1d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![入门 LLMOps：无缝交互的秘密配方](../Images/3a40915e3381e3711eb36893a30b7a1d.png)'
- en: Image by Author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The goal of these steps?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的目标是什么？
- en: To make the prompt clear and understandable for the model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使提示对模型清晰易懂。
- en: 'Here''s a breakdown of these steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的详细说明如下：
- en: 1\. Pre-processing
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 预处理
- en: The prompt goes through a first processing step. First, it's broken down into
    smaller pieces (tokens). Then, any typos or weird characters are cleaned up, and
    the text is formatted consistently.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提示经过第一次处理步骤。首先，它被分解为更小的片段（令牌）。然后，清理任何拼写错误或奇怪的字符，并且格式保持一致。
- en: Finally, the tokens are embedded into numerical data so the LLM understands.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，令牌被嵌入为数值数据，以便 LLM 理解。
- en: 2\. Grounding
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 基础设定
- en: Before the model processes our prompt, we need to make sure that the model understands
    the bigger picture. This might involve referencing past conversations you've had
    with the LLM or using outside information.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型处理我们的提示之前，我们需要确保模型理解整体情况。这可能涉及参考你与 LLM 进行的过去对话或使用外部信息。
- en: Additionally, the system identifies important things mentioned in the prompt
    (like names or places) to make the response even more relevant.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，系统识别提示中提到的重要内容（如名称或地点），以使响应更加相关。
- en: '3\. Safety Check:'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 安全检查：
- en: Just like having safety rules on set, LLMOps makes sure the prompt is used appropriately.
    The system checks for things like sensitive information or potentially offensive
    content.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 就像拍摄现场有安全规则一样，LLMOps 确保提示被适当地使用。系统会检查诸如敏感信息或潜在冒犯内容等问题。
- en: Only after passing these checks is the prompt ready for the main act - the LLM!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 只有通过这些检查后，提示才准备好进入主要环节——LLM！
- en: 'Now we have our prompt ready to be processed by the LLM. However, its output
    needs to be analyzed and processed as well. So before you see it, there are a
    few more adjustments performed in the fourth step:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好让提示由 LLM 处理。然而，它的输出也需要进行分析和处理。所以在你看到之前，第四步还需要做一些调整：
- en: 3\. Post-Processing
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 后处理
- en: Remember the code the prompt was converted into? The response needs to be translated
    back into human-readable text. Afterwards, the system polishes the response for
    grammar, style, and clarity.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 记得提示转换成的代码吗？响应需要被翻译回人类可读的文本。之后，系统会对响应进行语法、风格和清晰度的润色。
- en: All these steps happen seamlessly thanks to LLMOps, the invisible crew member
    ensuring a smooth LLM experience.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些步骤得以无缝进行，归功于 LLMOps，这位无形的团队成员确保了 LLM 体验的顺畅。
- en: Impressive, right?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 给人留下深刻印象，对吧？
- en: Key Components of a Robust LLMOps Infrastructure
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强健 LLMOps 基础设施的关键组成部分
- en: 'Here are some of the essential building blocks of a well-designed LLMOps setup:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个设计良好的 LLMOps 设置的一些基本构建块：
- en: '**Choosing the Right LLM:** With a vast array of LLM models available, LLMOps
    helps you select the one that best aligns with your specific needs and resources.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择合适的 LLM：** 在众多 LLM 模型中，LLMOps 帮助你选择最符合你特定需求和资源的模型。'
- en: '**Fine-Tuning for Specificity:** LLMOps empowers you to fine-tune existing
    models or train your own, customizing them for your unique use case.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对特定性进行微调：** LLMOps 使你能够微调现有模型或训练自己的模型，为你的独特用例进行定制。'
- en: '**Prompt Engineering:** LLMOps equips you with techniques to craft effective
    prompts that guide the LLM toward the desired outcome.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程：** LLMOps 提供了编写有效提示的技术，指导 LLM 达到预期结果。'
- en: '**Deployment and Monitoring:** LLMOps streamlines the deployment process and
    continuously monitors the LLM''s performance, ensuring optimal functionality.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署与监控：** LLMOps 简化了部署过程，并持续监控 LLM 的性能，确保最佳功能。'
- en: '**Security Safeguards:** LLMOps prioritizes data security by implementing robust
    measures to protect sensitive information.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全保障：** LLMOps 优先考虑数据安全，通过实施强有力的措施来保护敏感信息。'
- en: The Future of LLMs is Powered by LLMOps
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 的未来由 LLMOps 推动
- en: As LLM technology continues to evolve, LLMOps will play a critical role in the
    coming technological developments. Most part of the success of the latest popular
    solutions like ChatGPT or Google Gemini is their ability to not only answer any
    requests but also provide a good user experience.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 LLM 技术的不断发展，LLMOps 将在未来的技术进展中发挥关键作用。最新流行解决方案，如 ChatGPT 或 Google Gemini 的成功，大部分归功于它们不仅能够回应各种请求，还能提供良好的用户体验。
- en: This is why, by ensuring efficient, reliable, and secure operation, LLMOps will
    pave the way for even more innovative and transformative LLM applications across
    various industries that will arrive to even more people.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正因为如此，通过确保高效、可靠和安全的操作，LLMOps 将为更多创新和变革性的 LLM 应用铺平道路，覆盖到更多人群。
- en: With a solid understanding of LLMOps, you're well-equipped to take advantage
    of the power of these LLMs and create groundbreaking applications.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对 LLMOps 的深入理解，你将能够充分利用这些 LLM 的强大功能，创造出开创性的应用。
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)**
    是一位来自巴塞罗那的分析工程师。他毕业于物理工程专业，目前在应用于人类流动性的领域从事数据科学工作。他还是一名兼职内容创作者，专注于数据科学和技术。Josep
    书写关于人工智能的所有内容，涵盖了这一领域的持续爆炸性增长的应用。**'
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Collection of Free Courses to Learn Data Science, Data Engineering,…](https://www.kdnuggets.com/collection-of-free-courses-to-learn-data-science-data-engineering-machine-learning-mlops-and-llmops)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学、数据工程等的免费课程合集](https://www.kdnuggets.com/collection-of-free-courses-to-learn-data-science-data-engineering-machine-learning-mlops-and-llmops)'
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义向量搜索如何变革客户支持互动](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
- en: '[GPT-4: 8 Models in One; The Secret is Out](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GPT-4：一台机器中的8种模型；秘密已经揭晓](https://www.kdnuggets.com/2023/08/gpt4-8-models-one-secret.html)'
- en: '[HuggingGPT: The Secret Weapon to Solve Complex AI Tasks](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingGPT：解决复杂AI任务的秘密武器](https://www.kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html)'
- en: '[How ChatGPT Works: The Model Behind The Bot](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT的工作原理：聊天机器人的背后模型](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
- en: '[Stable Diffusion: Basic Intuition Behind Generative AI](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[稳定扩散：生成式AI的基本直觉](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)'
