- en: Scikit-Learn & More for Synthetic Dataset Generation for Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-Learn及更多用于机器学习的合成数据集生成工具
- en: 原文：[https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html](https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html](https://www.kdnuggets.com/2019/09/scikit-learn-synthetic-dataset.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: It is becoming increasingly clear that the big tech giants such as Google, Facebook,
    and Microsoft are extremely generous with their latest machine learning algorithms
    and packages (they give those away freely) because the entry barrier to the world
    of algorithms is pretty low right now. The open-source community and tools (such
    as scikit-learn) have come a long way, and [plenty of open-source initiatives
    are propelling the vehicles of data science](https://insidebigdata.com/2015/03/16/open-source-software-fuels-a-revolution-in-data-science/),
    digital analytics, and machine learning. Standing in 2018 we can safely say that, [algorithms,
    programming frameworks, and machine learning packages (or even tutorials and courses
    how to learn these techniques) are not the scarce resource but high-quality data
    is.](https://hbr.org/2015/03/data-monopolists-like-google-are-threatening-the-economy)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越明显的是，大型科技巨头如谷歌、Facebook和微软在他们最新的机器学习算法和工具方面非常慷慨（他们免费提供这些资源），因为目前进入算法世界的门槛相当低。开源社区和工具（如scikit-learn）取得了长足的进展，[大量开源项目正在推动数据科学](https://insidebigdata.com/2015/03/16/open-source-software-fuels-a-revolution-in-data-science/)、数字分析和机器学习的发展。站在2018年，我们可以安全地说，[算法、编程框架和机器学习包（甚至教程和学习这些技术的课程）并不是稀缺资源，而是高质量数据才是。](https://hbr.org/2015/03/data-monopolists-like-google-are-threatening-the-economy)
- en: This often becomes a thorny issue on the side of the practitioners in data science
    (DS) and machine learning (ML) when it comes to tweaking and fine-tuning those
    algorithms. It will also be wise to point out, at the very beginning, that the
    current article pertains to the scarcity of data for algorithmic investigation,
    pedagogical learning, and model prototyping, and not for scaling and running a
    commercial operation. It is not a discussion about how to get quality data for
    the cool travel or fashion app you are working on. That kind of consumer, social,
    or behavioral data collection presents its own issues. However, even something
    as simple as having access to quality datasets for testing out the limitations
    and vagaries of a particular algorithmic method, often turns out, not so simple.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常在数据科学（DS）和机器学习（ML）从业者面临的一个棘手问题，即调整和优化这些算法时。值得指出的是，本文涉及的是算法调查、教学学习和模型原型制作的数据稀缺性，而非扩展和运行商业操作。讨论的并非如何获取你正在开发的酷炫旅行或时尚应用的优质数据。这类消费者、社交或行为数据收集有其自身的问题。然而，即使是像获取优质数据集来测试某种算法方法的局限性和多变性这样的简单事情，也往往并不那么简单。
- en: Why Do You Need a Synthetic Dataset?
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么你需要一个合成数据集？
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you are learning from scratch, the most sound advice would be to start with
    simple, small-scale datasets which you can plot in two dimensions to understand
    the patterns visually and see for yourself the working of the ML algorithm in
    an intuitive fashion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从零开始学习，最明智的建议是从简单的小规模数据集开始，这样你可以将其绘制在二维图中，以直观地理解模式，并亲自查看机器学习算法的工作效果。
- en: As the dimensions of the data explode, however, the visual judgment must extend
    to more complicated matters – concepts like *learning and sample complexity, computational
    efficiency, class imbalance,* etc.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着数据维度的爆炸，视觉判断必须扩展到更复杂的事项——如*学习和样本复杂性、计算效率、类别不平衡*等概念。
- en: At this point, the trade-off between experimental flexibility and the nature
    of the dataset comes into play. **You can always find yourself a large real-life
    dataset to practice the algorithm on. But that is still a fixed dataset, with
    a fixed number of samples, a fixed underlying pattern, and a fixed degree of class
    separation** between positive and negative samples. You must also investigate,
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，实验灵活性和数据集性质之间的权衡开始发挥作用。**你总是可以找到一个大型真实数据集来实践算法。但那仍然是一个固定的数据集，具有固定的样本数量、固定的底层模式以及固定的类别分离程度**，在正负样本之间。你还必须调查，
- en: How the chosen fraction of test and train data affects the algorithm’s performance
    and robustness.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择的测试数据和训练数据的比例如何影响算法的性能和鲁棒性。
- en: How robust the metrics are in the face of varying degree of class imbalance.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在面对不同程度的类别不平衡时，度量指标的鲁棒性如何。
- en: What kind of bias-variance trade-offs must be made.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要进行何种偏差-方差权衡。
- en: How the algorithm performs under various noise signature in the training as
    well as test data (i.e., noise in the label as well as in the feature set).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法在训练数据和测试数据中的各种噪声特征下的表现如何（即标签中的噪声以及特征集中的噪声）。
- en: How do you experiment and tease out the weakness of your ML algorithm?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何实验并揭示你的机器学习算法的弱点？
- en: It turns out that these are quite difficult to do with a single real-life dataset
    and therefore, you must be willing to work with synthetic data which are random
    enough to capture all the vagaries of a real-life dataset but controllable enough
    to help you scientifically investigate the strength and weakness of the particular
    ML pipeline you are building.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，使用单一的真实数据集来完成这些任务是相当困难的，因此，你必须愿意使用合成数据，这些数据在足够随机的情况下捕捉到真实数据集的所有变化，但又足够可控，以帮助你科学地研究你正在构建的特定机器学习流程的优缺点。
- en: Although we won’t discuss the matter in this article, the potential benefit
    of such synthetic datasets can easily be gauged for sensitive applications – medical
    classifications or financial modeling, where getting hands on a high-quality labeled
    dataset is often expensive and prohibitive.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在本文中不会讨论这个问题，但可以很容易地评估这种合成数据集在敏感应用中的潜在好处——例如医学分类或金融建模，在这些领域，获取高质量标注数据集通常是昂贵且禁止的。
- en: Essential Features of a Synthetic Dataset for ML
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合成数据集在机器学习中的基本特征
- en: It is understood, at this point, that a synthetic dataset is generated programmatically,
    and not sourced from any kind of social or scientific experiment, business transactional
    data, sensor reading, or manual labeling of images. However, such datasets are
    definitely not completely random, and the generation and usage of synthetic data
    for ML must be guided by some overarching needs. In particular,
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 目前理解到的是，合成数据集是通过编程生成的，而不是来源于任何类型的社会或科学实验、商业交易数据、传感器读数或手动标注的图像。然而，这些数据集绝不是完全随机的，生成和使用合成数据进行机器学习必须由一些总体需求指导。特别是，
- en: It can be numeric, binary, or categorical (ordinal or non-ordinal) and the number
    of features and length of the dataset could be arbitrary.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可以是数值型、二进制型或分类型（有序或无序），特征的数量和数据集的长度可以是任意的。
- en: There must be some degree of randomness to it but, at the same time, the user
    should be able to choose a wide variety of statistical distribution to base this
    data upon, i.e., the underlying random process can be precisely controlled and
    tuned.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须存在一定程度的随机性，但同时，用户应能够选择多种统计分布作为数据的基础，即底层随机过程可以被精确控制和调整。
- en: If it is used for classification algorithms, then the degree of class separation
    should be controllable to make the learning problem easy or hard.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用于分类算法，则类别分离的程度应该是可控的，以使学习问题变得简单或困难。
- en: Random noise can be interjected in a controllable manner.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机噪声可以以可控的方式插入。
- en: Speed of generation should be quite high to enable experimentation with a large
    variety of such datasets for any particular ML algorithms, i.e., if the synthetic
    data is based on data augmentation on a real-life dataset, then the augmentation
    algorithm must be computationally efficient.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成速度应足够高，以便对各种数据集进行实验，这些数据集适用于特定的 ML 算法，即，如果合成数据是基于真实数据集的数据增强，那么增强算法必须具有计算效率。
- en: For a regression problem, a complex, non-linear generative process can be used
    for sourcing the data – real physics models may come to aid in this endeavor.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于回归问题，可以使用复杂的非线性生成过程来获取数据——实际物理模型可能会对此有所帮助。
- en: We will show, in the next section, how using some of the most popular ML libraries,
    and programmatic techniques, one is able to generate suitable datasets.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将展示如何使用一些最流行的 ML 库和编程技术来生成合适的数据集。
- en: Standard regression, classification, and clustering dataset generation using
    scikit-learn and Numpy
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 和 Numpy 生成标准的回归、分类和聚类数据集
- en: Scikit-learn is the most popular ML library in the Python-based software stack
    for data science. Apart from the well-optimized ML routines and pipeline building
    methods, it also boasts of a solid collection of utility methods for synthetic
    data generation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 是基于 Python 的数据科学软件栈中最流行的 ML 库。除了优化良好的 ML 例程和管道构建方法外，它还拥有一套强大的合成数据生成工具方法。
- en: '**Regression with scikit-learn**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 scikit-learn 进行回归**'
- en: Scikit-learn’s *dataset.make_regression* function can create random regression
    problem with arbitrary number of input features, output targets, and **controllable
    degree of informative coupling** between them.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 的 *dataset.make_regression* 函数可以创建随机回归问题，具有任意数量的输入特征、输出目标以及**可控的信息耦合程度**。
- en: '![](../Images/657ba8203365893684bc10b7db422899.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/657ba8203365893684bc10b7db422899.png)'
- en: '**Classification with Scikit-learn**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 Scikit-learn 进行分类**'
- en: Similar to the regression function above, dataset.make_classification generates
    a random multi-class classification problem with **controllable class separation
    and added noise**. You can also randomly flip any percentage of output signs to
    create a harder classification dataset if you want.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于上面的回归函数，`dataset.make_classification` 生成一个随机的多类分类问题，具有**可控的类别分离和添加的噪声**。如果需要，你也可以随机翻转任何百分比的输出标记来创建更难的分类数据集。
- en: '![](../Images/9ea8b00bc786b5565f57c111dfeac9e3.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ea8b00bc786b5565f57c111dfeac9e3.png)'
- en: '**Clustering with Scikit-learn**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 Scikit-learn 进行聚类**'
- en: A variety of clustering problems can be generated by scikit-learn utility functions.
    The most straightforward is to use the *datasets.make_blobs*, which generates
    arbitrary number of clusters with controllable distance parameters.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn 的工具函数可以生成各种聚类问题。最简单的方法是使用 *datasets.make_blobs*，它生成具有可控距离参数的任意数量的聚类。
- en: '![](../Images/292621726f680a7ab94415b03c6614d6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/292621726f680a7ab94415b03c6614d6.png)'
- en: For testing affinity-based clustering algorithm or Gaussian mixture models,
    it is useful to have clusters generated in a special shape. We can use *datasets.make_circles* function
    to accomplish that.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试基于相似度的聚类算法或高斯混合模型时，生成具有特定形状的聚类是有用的。我们可以使用 *datasets.make_circles* 函数来完成这项任务。
- en: '![](../Images/e97c95527cd22b85be131fed2dba304e.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e97c95527cd22b85be131fed2dba304e.png)'
- en: '![](../Images/fb15c4e64f19a76d77bcc3c90df44c21.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb15c4e64f19a76d77bcc3c90df44c21.png)'
- en: For testing non-linear kernel methods with **support vector machine (SVM)** algorithm,
    nearest-neighbor methods like **k-NN**, or even testing out a simple neural network,
    it is often advisable to experiment with certain shaped data. We can generate
    such data using *dataset.make_moon* function with controllable noise.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试使用**支持向量机（SVM）**算法的非线性核方法、最近邻方法如**k-NN**，或甚至测试简单神经网络时，通常建议使用特定形状的数据进行实验。我们可以使用
    *dataset.make_moon* 函数生成具有可控噪声的数据。
- en: '![](../Images/7071bf9188177f34d4eb9a2683e1c008.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7071bf9188177f34d4eb9a2683e1c008.png)'
- en: '**A gaussian mixture model with Scikit-learn**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 Scikit-learn 的高斯混合模型**'
- en: 'Gaussian mixture models (GMM) are fascinating objects to study for unsupervised
    learning and topic modeling in the text processing/NLP tasks. Here is an illustration
    of a simple function to show how easy it is to generate synthetic data for such
    a model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯混合模型（GMM）是研究无监督学习和文本处理/NLP 任务中的主题建模的迷人对象。以下是一个简单函数的示例，展示了为此类模型生成合成数据的简便性：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/10dbf89f56b673447617cbaf6bc9ea3f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10dbf89f56b673447617cbaf6bc9ea3f.png)'
- en: '![](../Images/d6a42569513170155593f3da14baf48d.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/28a084e2eeef1eed3a1d81895575456e.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/f8e0eb7264d15906f91821e7a858789d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: 'Beyond scikit-learn: Synthetic data from symbolic input'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the functions above may be sufficient for many problems, the data generated
    is truly random, and the user has less control on the actual mech
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: anics of the generation process. In many situations, one may require a controllable
    way to generate regression or classification problems based on a well-defined
    analytical function (involving linear, nonlinear, rational, or even transcendental
    terms). The following article shows how one can **combine the symbolic mathematics
    package SymPy and functions from SciPy** to generate synthetic regression and
    classification problems from given symbolic expressions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[Random regression and classification problem generation with symbolic expression](https://towardsdatascience.com/random-regression-and-classification-problem-generation-with-symbolic-expression-a4e190e37b8d)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d2ec41a8a3cd5fcdb2fb338f13c7151.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Regression dataset generated from a given symbolic expression.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3b57cc7402e8accd19850f7225bbda9.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: Classification dataset generated from a given symbolic expression.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '**Image data augmentation using scikit-image**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning systems and algorithms are voracious consumers of data. However,
    to test the limitations and robustness of a deep learning algorithm, one often
    needs to feed the algorithm with subtle variations of similar images. **Scikit-image** is
    an amazing image processing library, built on the same design principle and API
    pattern as that of scikit-learn, offering hundreds of cool functions to accomplish
    this image data augmentation task.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'The following article does a great job of providing a comprehensive overview
    of a lot of these ideas:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Augmentation | How to use Deep Learning when you have Limited Data.](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: We show some chosen examples of this augmentation process, starting with a single
    image and creating tens of variations on the same to **effectively multiply the
    dataset manifold and create a synthetic dataset of gigantic size** to train deep
    learning models in a robust manner.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '**Hue, Saturation, Value channels**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3b34127d9031309c2ca1ce6f8bb1abab.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: '**Cropping**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03b7fa3370116c332105da6c2b9dcd55.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: '**Random noise**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/461cc92ce173811ad8d5d6ab971c9cf0.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: '**Rotation**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c2b4cb1495a328907c8ac9186f9fcfbf.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: '**Swirl**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/95a563dff0ffbfbc70f721178a37346a.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: '**Random image synthesizer with segmentation**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA offers a UE4 plugin called NDDS to empower computer vision researchers
    to export high-quality synthetic images with metadata. It supports images, segmentation,
    depth, object pose, bounding box, keypoints, and custom stencils. In addition
    to the exporter, the plugin includes various components enabling the generation
    of randomized images for data augmentation and object detection algorithm training.
    The randomization utilities include lighting, objects, camera position, poses,
    textures, and distractors. Together, these components allow deep learning engineers
    to easily create randomized scenes for training their CNN. Here is the Github
    link,
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA 提供了一个名为 NDDS 的 UE4 插件，旨在帮助计算机视觉研究人员导出高质量的合成图像及其元数据。它支持图像、分割、深度、物体姿态、边界框、关键点和自定义模板。除了导出工具，插件还包含各种组件，支持生成随机图像用于数据增强和目标检测算法训练。随机化工具包括照明、物体、相机位置、姿态、纹理和干扰物。这些组件使深度学习工程师能够轻松创建随机场景以训练他们的
    CNN。以下是 Github 链接，
- en: '[NVIDIA Deep Learning Data Synthesizer](https://github.com/NVIDIA/Dataset_Synthesizer)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[NVIDIA 深度学习数据合成器](https://github.com/NVIDIA/Dataset_Synthesizer)'
- en: '**Categorical data generation using pydbgen**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 pydbgen 生成分类数据**'
- en: '*Pydbgen* is a [lightweight, pure-python library](https://github.com/tirthajyoti/pydbgen) to
    generate random useful entries (e.g. name, address, credit card number, date,
    time, company name, job title, license plate number, etc.) and save them in either
    Pandas dataframe object, or as a SQLite table in a database file, or in an MS
    Excel file. [You can read the documentation here](https://pydbgen.readthedocs.io/en/latest/).
    Here is an article describing its use and utilities,'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pydbgen*是一个[轻量级纯 Python 库](https://github.com/tirthajyoti/pydbgen)，用于生成随机有用条目（如姓名、地址、信用卡号、日期、时间、公司名称、职位名称、车牌号等），并将其保存到
    Pandas 数据框对象、SQLite 数据库文件中的表格或 MS Excel 文件中。[你可以在这里阅读文档](https://pydbgen.readthedocs.io/en/latest/)。以下是描述其用法和工具的文章，'
- en: '[Introducing pydbgen: A random dataframe/database table generator](https://towardsdatascience.com/introducing-pydbgen-a-random-dataframe-database-table-generator-b5c7bdc84be5)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[介绍 pydbgen：一个随机数据框/数据库表生成器](https://towardsdatascience.com/introducing-pydbgen-a-random-dataframe-database-table-generator-b5c7bdc84be5)'
- en: Here are a few illustrative examples,
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些说明性的示例，
- en: '![](../Images/929da64192dc0676df83ebf465f4decb.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/929da64192dc0676df83ebf465f4decb.png)'
- en: '![](../Images/d296932c57b43adf13658bccefae99d7.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d296932c57b43adf13658bccefae99d7.png)'
- en: '![](../Images/34f20a7b06934eae55bcd9b99fc3cbd7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34f20a7b06934eae55bcd9b99fc3cbd7.png)'
- en: '**Synthesizing time series dataset**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成时间序列数据集**'
- en: 'There are quite a few papers and code repositories for generating synthetic
    time-series data using special functions and patterns observed in real-life multivariate
    time series. A simple example is given in the following Github link:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多论文和代码库用于生成合成时间序列数据，这些数据使用在现实生活中的多变量时间序列中观察到的特殊函数和模式。以下 Github 链接提供了一个简单的示例：
- en: '[Synthetic Time Series](https://nbviewer.jupyter.org/github/tirthajyoti/Machine-Learning-with-Python/blob/master/Synthetic_data_generation/Synth_Time_series.ipynb)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[合成时间序列](https://nbviewer.jupyter.org/github/tirthajyoti/Machine-Learning-with-Python/blob/master/Synthetic_data_generation/Synth_Time_series.ipynb)'
- en: '![](../Images/096403f26039965b65caae44e143feb2.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/096403f26039965b65caae44e143feb2.png)'
- en: '**Synthetic audio signal dataset**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成音频信号数据集**'
- en: Audio/speech processing is a domain of particular interest for deep learning
    practitioners and ML enthusiasts. **Google’s NSynth dataset** is a synthetically
    generated (using neural autoencoders and a combination of human and heuristic
    labeling) library of short audio files sound made by musical instruments of various
    kinds. Here is the detailed description of the dataset.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 音频/语音处理是深度学习从业者和机器学习爱好者特别感兴趣的领域。**谷歌的 NSynth 数据集**是一个合成生成的（使用神经自编码器和人类及启发式标记的组合）短音频文件库，声音由各种类型的乐器发出。以下是该数据集的详细描述。
- en: '[The NSynth dataset](https://magenta.tensorflow.org/datasets/nsynth)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[NSynth 数据集](https://magenta.tensorflow.org/datasets/nsynth)'
- en: Synthetic environments for reinforcement learning
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习的合成环境
- en: '**OpenAI Gym**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenAI Gym**'
- en: The greatest repository for synthetic learning environment for reinforcement
    ML is **OpenAI Gym**. It consists of a large number of pre-programmed environments
    onto which users can implement their reinforcement learning algorithms for benchmarking
    the performance or troubleshooting hidden weakness.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 用于强化学习的合成学习环境中最伟大的资源是**OpenAI Gym**。它包含了大量的预编程环境，用户可以在这些环境中实施他们的强化学习算法，以进行性能基准测试或解决潜在的弱点。
- en: '![](../Images/e4d973a51aa33a052967f89f9ca2238d.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4d973a51aa33a052967f89f9ca2238d.png)'
- en: '**Random Grid World**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机网格世界**'
- en: For beginners in reinforcement learning, it often helps to practice and experiment
    with a simple grid world where an agent must navigate through a maze to reach
    a terminal state with given reward/penalty for each step and the terminal states.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于强化学习的初学者来说，练习和实验一个简单的网格世界通常会有所帮助，在这个网格世界中，智能体必须穿越迷宫以到达一个终端状态，每一步和终端状态都有给定的奖励/惩罚。
- en: With few simple lines of code, one can synthesize grid world environments with
    arbitrary size and complexity (with a user-specified distribution of terminal
    states and reward vectors).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几行简单的代码，就可以合成任意大小和复杂度的网格世界环境（用户指定终端状态和奖励向量的分布）。
- en: Take a look at this Github repo for ideas and code examples.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这个 Github 仓库，获取灵感和代码示例。
- en: '[https://github.com/tirthajyoti/RL_basics](https://github.com/tirthajyoti/RL_basics)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tirthajyoti/RL_basics](https://github.com/tirthajyoti/RL_basics)'
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we went over a few examples of synthetic data generation for
    machine learning. It should be clear to the reader that, by no means, these represent
    the exhaustive list of data generating techniques. In fact, many commercial apps
    other than scikit-learn are offering the same service as the need for training
    your ML model with a variety of data is increasing at a fast pace. However, if,
    as a data scientist or ML engineer, you create your programmatic method of synthetic
    data generation, it saves your organization money and resources to invest in a
    third-party app and also lets you plan the development of your ML pipeline in
    a holistic and organic fashion.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了一些用于机器学习的合成数据生成示例。读者应当明确，这些示例并不是数据生成技术的详尽列表。实际上，除了 scikit-learn 之外，许多商业应用也提供了相同的服务，因为需要用多样的数据来训练
    ML 模型的需求正在快速增长。然而，如果你作为数据科学家或 ML 工程师，创建自己的合成数据生成编程方法，这将为你的组织节省资金和资源，避免投资于第三方应用程序，同时也能让你以整体和有机的方式规划
    ML 流水线的开发。
- en: Hope you enjoyed this article and can start using some of the techniques, described
    here, in your projects soon.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这篇文章，并且可以很快在你的项目中开始使用这里描述的一些技术。
- en: '[Original](https://blog.exxactcorp.com/scikit-learn-and-more-synthetic-dataset-generation-for-ml/).
    Reposted with permission.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://blog.exxactcorp.com/scikit-learn-and-more-synthetic-dataset-generation-for-ml/)。经许可转载。'
- en: '**Related:**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[An Introduction to Scikit Learn: The Gold Standard of Python Machine Learning](https://www.kdnuggets.com/2019/02/introduction-scikit-learn-gold-standard-python-machine-learning.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Scikit Learn 入门：Python 机器学习的金标准](https://www.kdnuggets.com/2019/02/introduction-scikit-learn-gold-standard-python-machine-learning.html)'
- en: '[5 Ways to Deal with the Lack of Data in Machine Learning](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[应对机器学习中数据缺乏的 5 种方法](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)'
- en: '[Synthetic Data Generation: A must-have skill for new data scientists](https://www.kdnuggets.com/2018/12/synthetic-data-generation-must-have-skill.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[合成数据生成：新数据科学家的必备技能](https://www.kdnuggets.com/2018/12/synthetic-data-generation-must-have-skill.html)'
- en: More On This Topic
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How to Generate Synthetic Tabular Dataset](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何生成合成表格数据集](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与…的结合](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[How To Use Synthetic Data To Overcome Data Shortages For Machine…](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用合成数据来克服机器学习中的数据短缺](https://www.kdnuggets.com/2022/03/synthetic-data-overcome-data-shortages-machine-learning-model-training.html)'
- en: '[Synthetic Data for Machine Learning](https://www.kdnuggets.com/synthetic-data-for-machine-learning)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习的合成数据](https://www.kdnuggets.com/synthetic-data-for-machine-learning)'
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[假装直到成功：生成逼真的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
- en: '[A Community for Synthetic Data is Here and This is Why We Need It](https://www.kdnuggets.com/2022/04/community-synthetic-data-need.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[合成数据的社区来了，这就是我们需要它的原因](https://www.kdnuggets.com/2022/04/community-synthetic-data-need.html)'
