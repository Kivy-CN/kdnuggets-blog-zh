- en: Top 20 Recent Research Papers on Machine Learning and Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/04/top-20-papers-machine-learning.html](https://www.kdnuggets.com/2017/04/top-20-papers-machine-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning, especially its subfield of Deep Learning, had many amazing
    advances in the recent years, and important research papers may lead to breakthroughs
    in technology that get used by billio![](../Images/f4ef5aaab311b9c75155ea1f2157d558.png)ns
    of people. The research in this field is developing very quickly and to help our
    readers monitor the progress we present the list of most important recent scientific
    papers published since 2014\.
  prefs: []
  type: TYPE_NORMAL
- en: 'The criteria we used to select the 20 top papers are by using citation counts
    from three academic sources: [scholar.google.com](https://scholar.google.com);
    [academic.microsoft.com](https://academic.microsoft.com/); and  [semanticscholar.org](https://www.semanticscholar.org).
    Since the number of citations varied among sources and are estimated, we listed
    the results from [academic.microsoft.com](https://academic.microsoft.com/) which
    is slightly lower than others.'
  prefs: []
  type: TYPE_NORMAL
- en: For each paper we also give the year it was published, a Highly Influential
    Citation count (HIC) and Citation Velocity (CV) measures provided by  [semanticscholar.org](https://www.semanticscholar.org).
     HIC that presents how publications build upon and relate to each other is result
    of identifying meaningful citations. CV is the weighted average number of citations
    per year over the last 3 years. For some references, where CV is zero that means
    it was blank or not shown by [semanticscholar.org](https://www.semanticscholar.org).
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most (but not all) of these 20 papers, including the top 8, are on the topic
    of Deep Learning. However, we see strong diversity - only one author (Yoshua Bengio)
    has 2 papers, and the papers were published in many different venues: CoRR (3),
    ECCV (3), IEEE CVPR (3), NIPS (2), ACM Comp Surveys, ICML, IEEE PAMI, IEEE TKDE,
    Information Fusion, Int. J. on Computers & EE, JMLR, KDD, and Neural Networks.
    The top two papers have by far the highest citation counts than the rest. Note
    that the second paper is only published last year. Read (or re-read them) and
    learn about the latest advances.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/93c27ad5d0f40b95dbca6736b82cf9e4.png) **Dropout: a simple way
    to prevent neural networks from overfitting**](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf),
    by Hinton, G.E., Krizhevsky, A., Srivastava, N., Sutskever, I., & Salakhutdinov,
    R. (2014). Journal of Machine Learning Research, 15, 1929-1958\. (cited 2084 times,
    HIC: 142 , CV: 536).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: The key idea is to randomly drop units (along with their connections)
    from the neural network during training. This prevents units from co-adapting
    too much. This significantly reduces overfitting and gives major improvements
    over other regularization methods'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Deep Residual Learning for Image Recognition**](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf),
    by He, K., Ren, S., Sun, J., & Zhang, X. (2016). CoRR, abs/1512.03385\. (cited
    1436 times, HIC: 137 , CV: 582).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We present a residual learning framework to ease the training of deep
    neural networks that are substantially deeper than those used previously. We explicitly
    reformulate the layers as learning residual functions with reference to the layer
    inputs, instead of learning unreferenced functions. We provide comprehensive empirical
    evidence showing that these residual networks are easier to optimize, and can
    gain accuracy from considerably increased depth.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift**](http://jmlr.org/proceedings/papers/v37/ioffe15.pdf), by Sergey
    Ioffe, Christian Szegedy (2015) ICML. (cited 946 times, HIC: 56 , CV: 0).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: Training Deep Neural Networks is complicated by the fact that the
    distribution of each layer''s inputs changes during training, as the parameters
    of the previous layers change.  We refer to this phenomenon as internal covariate
    shift, and address the problem by normalizing layer inputs.  Applied to a state-of-the-art
    image classification model, Batch Normalization achieves the same accuracy with
    14 times fewer training steps, and beats the original model by a significant margin.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Large-Scale Video Classification with Convolutional Neural Networks**](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf)
    , by Fei-Fei, L., Karpathy, A., Leung, T., Shetty, S., Sukthankar, R., & Toderici,
    G. (2014). IEEE Conference on Computer Vision and Pattern Recognition (cited 865
    times, HIC: 24 , CV: 239)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: Convolutional Neural Networks (CNNs) have been established as a powerful
    class of models for image recognition problems. Encouraged by these results, we
    provide an extensive empirical evaluation of CNNs on large-scale video classification
    using a new dataset of 1 million YouTube videos belonging to 487 classes .'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Microsoft COCO: Common Objects in Context**](https://arxiv.org/pdf/1405.0312.pdf)
    , by Belongie, S.J., Dollár, P., Hays, J., Lin, T., Maire, M., Perona, P., Ramanan,
    D., & Zitnick, C.L. (2014). ECCV. (cited 830 times, HIC: 78 , CV: 279) Summary:
    We present a new dataset with the goal of advancing the state-of-the-art in object
    recognition by placing the question of object recognition in the context of the
    broader question of scene understanding. Our dataset contains photos of 91 objects
    types that would be easily recognizable by a 4 year old. Finally, we provide baseline
    performance analysis for bounding box and segmentation detection results using
    a Deformable Parts Model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Learning deep features for scene recognition using places database**](http://places.csail.mit.edu/places_NIPS14.pdf)
    , by Lapedriza, À., Oliva, A., Torralba, A., Xiao, J., & Zhou, B. (2014). NIPS. (cited
    644 times, HIC: 65 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We introduce a new scene-centric database called Places with over
    7 million labeled pictures of scenes. We propose new methods to compare the density
    and diversity of image datasets and show that Places is as dense as other scene
    datasets and has more diversity.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Generative adversarial nets**](http://datascienceassn.org/sites/default/files/Generative%20Adversarial%20Nets.pdf),
    by Bengio, Y., Courville, A.C., Goodfellow, I.J., Mirza, M., Ozair, S., Pouget-Abadie,
    J., Warde-Farley, D., & Xu, B. (2014) NIPS. (cited 463 times, HIC: 55 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We propose a new framework for estimating generative models via an
    adversarial process, in which we simultaneously train two models: a generative
    model G that captures the data distribution, and a discriminative model D that
    estimates the probability that a sample came from the training data rather than
    G.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**High-Speed Tracking with Kernelized Correlation Filters**](http://arxiv.org/pdf/1404.7584
    ), by Batista, J., Caseiro, R., Henriques, J.F., & Martins, P. (2015). CoRR, abs/1404.7584. (cited
    439 times, HIC: 43 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: In most modern trackers,  to cope with natural image changes, a classifier
    is typically trained with translated and scaled sample patches. We propose an
    analytic model for datasets of thousands of translated patches. By showing that
    the resulting data matrix is circulant, we can diagonalize it with the discrete
    Fourier transform, reducing both storage and computation by several orders of
    magnitude.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**A Review on Multi-Label Learning Algorithms**](http://doi.ieeecomputersociety.org/10.1109/TKDE.2013.39),
    by  Zhang, M., & Zhou, Z. (2014). IEEE TKDE,  (cited 436 times, HIC: 7 , CV: 91)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary:  This paper aims to provide a timely review on multi-label learning
    studies the problem where each example is represented by a single instance while
    associated with a set of labels simultaneously.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**How transferable are features in deep neural networks**](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf),
    by Bengio, Y., Clune, J., Lipson, H., & Yosinski, J. (2014) CoRR, abs/1411.1792. (cited
    402 times, HIC: 14 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We experimentally quantify the generality versus specificity of neurons
    in each layer of a deep convolutional neural network and report a few surprising
    results. Transferability is negatively affected by two distinct issues: (1) the
    specialization of higher layer neurons to their original task at the expense of
    performance on the target task, which was expected, and (2) optimization difficulties
    related to splitting networks between co-adapted neurons, which was not expected.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**[Do we need hundreds of classifiers to solve real world classification problems](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf)**,
    by Amorim, D.G., Barro, S., Cernadas, E., & Delgado, M.F. (2014).  Journal of
    Machine Learning Research (cited 387 times, HIC: 3 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We evaluate 179 classifiers arising from 17 families (discriminant
    analysis, Bayesian, neural networks, support vector machines, decision trees,
    rule-based classifiers, boosting, bagging, stacking, random forests and other
    ensembles, generalized linear models, nearest-neighbors, partial least squares
    and principal component regression, logistic and multinomial regression, multiple
    adaptive regression splines and other methods). We use 121 data sets from UCI
    data base to study the classifier behavior, not dependent on the data set collection.
    The winners are the random forest (RF) versions implemented in R and accessed
    via caret) and the SVM with Gaussian kernel implemented in C using LibSVM.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Knowledge vault: a web-scale approach to probabilistic knowledge fusion**](http://www.cs.cmu.edu/~nlao/publication/2014.kdd.pdf
    ), by Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., ...
    & Zhang, W. (2014, August). In Proceedings of the 20th ACM SIGKDD international
    conference on Knowledge discovery and data mining  ACM. (cited 334 times, HIC:
    7 , CV: 107).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We introduce Knowledge Vault, a Web-scale probabilistic knowledge
    base that combines extractions from Web content (obtained via analysis of text,
    tabular data, page structure, and human annotations) with prior knowledge derived
    from existing knowledge repositories for constructing knowledge bases. We employ
    supervised machine learning methods for fusing  distinct information sources.
    The Knowledge Vault is substantially bigger than any previously published structured
    knowledge repository, and features a probabilistic inference system that computes
    calibrated probabilities of fact correctness.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Scalable Nearest Neighbor Algorithms for High Dimensional Data**](http://ieeexplore.ieee.org/document/6809191/),
    by Lowe, D.G., & Muja, M. (2014). IEEE Trans. Pattern Anal. Mach. Intell., (cited
    324 times, HIC: 11 , CV: 69).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary: We propose new algorithms for approximate nearest neighbor matching
    and evaluate and compare them with previous algorithms.  In order to scale to
    very large data sets that would otherwise not fit in the memory of a single machine,
    we propose a distributed nearest neighbor matching framework that can be used
    with any of the algorithms described in the paper.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Trends in extreme learning machines: a review**](http://www.ntu.edu.sg/home/egbhuang/pdf/ELM-Suvey-Huang-Gao.pdf),
    by Huang, G., Huang, G., Song, S., & You, K. (2015).  Neural Networks,  (cited
    323 times, HIC: 0 , CV: 0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We aim to report the current state of the theoretical research and
    practical advances on Extreme learning machine (ELM). Apart from classification
    and regression, ELM has recently been extended for clustering, feature selection,
    representational learning and many other learning tasks.  Due to its remarkable
    efficiency, simplicity, and impressive generalization performance, ELM have been
    applied in a variety of domains, such as biomedical engineering, computer vision,
    system identification, and control and robotics.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**A survey on concept drift adaptation**](http://www.win.tue.nl/~mpechen/publications/pubs/Gama_ACMCS_AdaptationCD_accepted.pdf),
    by Bifet, A., Bouchachia, A., Gama, J., Pechenizkiy, M., & Zliobaite, I.  ACM
    Comput. Surv., 2014 , (cited 314 times, HIC: 4 , CV: 23)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: This work aims at providing a comprehensive introduction to the concept
    drift adaptation that refers to an online supervised learning scenario when the
    relation between the input data and the target variable changes over time.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Multi-scale Orderless Pooling of Deep Convolutional Activation Features**](http://slazebni.cs.illinois.edu/publications/yunchao_eccv14_mopcnn.pdf),
    by Gong, Y., Guo, R., Lazebnik, S., & Wang, L. (2014).  ECCV(cited 293 times,
    HIC: 23 , CV: 95)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary:  To improve the invariance of CNN activations without degrading their
    discriminative power, this paper presents a simple but effective scheme called
    multi-scale orderless pooling (MOP-CNN).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**Simultaneous Detection and Segmentation**](http://arxiv.org/pdf/1407.1808),
    by Arbeláez, P.A., Girshick, R.B., Hariharan, B., & Malik, J. (2014) ECCV , (cited
    286 times, HIC: 23 , CV: 94)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: We aim to detect all instances of a category in an image and, for
    each instance, mark the pixels that belong to it. We call this task Simultaneous
    Detection and Segmentation (SDS).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**A survey on feature selection methods**](http://www.serc.org.in/admin/pdffiles/2-vol3ijceit.pdf),
    by Chandrashekar, G., & Sahin, F.  Int. J. on Computers & Electrical Engineering,
    (cited 279 times, HIC: 1 , CV: 58)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: Plenty of feature selection methods are available in literature due
    to the availability of data with hundreds of variables leading to data with very
    high dimension.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**One Millisecond Face Alignment with an Ensemble of Regression Trees**](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf),
    by Kazemi, Vahid, and Josephine Sullivan, Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition 2014, (cited 277 times, HIC: 15 , CV:
    0)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: This paper addresses the problem of Face Alignment for a single image.
    We show how an ensemble of regression trees can be used to estimate the face''s
    landmark positions directly from a sparse subset of pixel intensities, achieving
    super-realtime performance with high quality predictions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[**A survey of multiple classifier systems as hybrid systems**](http://romisatriawahono.net/lecture/dm/survey/Wozniak%20-%20Multiple%20Classifier%20Systems%20-%202014.pdf)
    , by Corchado, E., Graña, M., & Wozniak, M. (2014). Information Fusion, 16, 3-17. (cited
    269 times, HIC: 1 , CV: 22)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Summary: A current focus of intense research in pattern classification is the
    combination of several classifier systems, which can be built following either
    the same or different models and/or datasets building.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
