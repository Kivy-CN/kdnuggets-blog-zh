- en: How (dis)similar are my train and test data?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的训练数据和测试数据有多（不）相似？
- en: 原文：[https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html](https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html](https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Shikhar Gupta](https://twitter.com/shik1470)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Shikhar Gupta](https://twitter.com/shik1470) 提供**'
- en: They always say that don’t compare apples to oranges. But how about if we’re
    comparing one mix of apples and oranges with another mix of apples and oranges,
    but the distribution is different. Can you still compare ? And how will you go
    about it ?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人们总是说不要拿苹果和橘子做比较。但是如果我们比较的是一组苹果和橘子的混合与另一组苹果和橘子的混合，但分布不同，那你还能比较吗？你将如何进行比较呢？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 在 IT 领域支持你的组织'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In most of the cases in the real world, you’ll come across the latter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的大多数情况下，你会遇到后一种情况。
- en: '![](../Images/7fd101b721fb668c1c84bbdb733785ce.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7fd101b721fb668c1c84bbdb733785ce.png)'
- en: This happens quite often in data science. While developing a machine learning
    model we come across a situation where our model performs well on our training
    data but it fails to match up to the same performance for the test data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这在数据科学中发生得很频繁。在开发机器学习模型时，我们会遇到一种情况，即我们的模型在训练数据上表现良好，但在测试数据上却无法达到相同的性能。
- en: I’m not referring to overfitting here. Even if I’ve picked my best model based
    on cross-validation and it still performs poorly on test data, there is some inherent
    patterns in test data that we are not capturing.< Imagine a situation where I’m
    trying to model the shopping behaviour of customers. Now if my train and test
    data looks like below then you can clearly see the issue here. ![](../Images/43e718e8ed8f3f92c83ced1e95a27790.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我这里不是在谈论过拟合。即使我根据交叉验证选择了最好的模型，并且它在测试数据上表现仍然很差，那么测试数据中存在一些我们未能捕捉到的内在模式。< 想象一个我试图建模顾客购物行为的情况。如果我的训练数据和测试数据如下图所示，你可以清楚地看到这个问题。
    ![](../Images/43e718e8ed8f3f92c83ced1e95a27790.png)
- en: The model will be trained on customers with lower average age compared to test.
    This model would have never seen age patterns like the ones in test data. If age
    is an important feature in your model, then it’ll not perform well on the test.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 模型将基于与测试数据相比平均年龄较低的客户进行训练。这个模型从未见过测试数据中那种年龄模式。如果年龄在你的模型中是一个重要特征，那么它在测试数据上表现会很差。
- en: In this post, I’ll talk about how to identify this issue and some raw ideas
    on how we can fix it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将讨论如何识别这个问题以及一些解决方案的初步想法。
- en: Covariate Shift
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协变量漂移
- en: We can define this situation more formally. **Covariate** refers to the predictor
    variables in our model. **Covariate shift** refers to a situation where predictor
    variables have different **characteristics (distribution)** in train and test
    data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以更正式地定义这种情况。**协变量**指的是我们模型中的预测变量。**协变量漂移**指的是预测变量在训练数据和测试数据中具有不同的**特征（分布）**的情况。
- en: In real world problems with many variables, covariate shift is hard to spot.
    In this post I have tried to discuss a method to identify this and also how to
    account for such shift between train and test.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有许多变量的现实世界问题中，协变量漂移很难被发现。在这篇文章中，我尝试讨论一种识别这种情况的方法，以及如何考虑训练数据和测试数据之间的这种漂移。
- en: Basic Idea
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本概念
- en: If there exist a covariate shift, then upon mixing train and test we’ll still
    be able to classify the origin of each data point (whether it is from test or
    train) with good accuracy.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果存在协变量漂移，那么在混合训练集和测试集后，我们仍然能够以较高的准确率对每个数据点的来源（是来自测试集还是训练集）进行分类。
- en: '![](../Images/5fffdd4138a36a820dde11d61ba677df.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fffdd4138a36a820dde11d61ba677df.png)'
- en: Let’s understand why. Consider the above example where age was the drifting
    feature between test and train. If we take a classifier like Random Forest and
    try to classify rows into test and train, age will be come out be very important
    feature in splitting the data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入理解一下。考虑上述例子，其中年龄是测试和训练之间的漂移特征。如果我们使用随机森林等分类器来将行分类为测试和训练，年龄将成为数据拆分中的一个非常重要的特征。
- en: '![](../Images/b84dfc6b3d7271b626a6a088a6d0dbfd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b84dfc6b3d7271b626a6a088a6d0dbfd.png)'
- en: Implementation
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施
- en: 'Now let’s try to apply this idea on a real dataset. I’m using dataset from
    this kaggle competition: [https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试将这个想法应用于实际数据集。我使用的是来自这个Kaggle竞赛的数据集：[https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data)
- en: '*Step1: Data pre-processing*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤1：数据预处理*'
- en: We have to first clean our data, impute all missing values and do label encoding
    for all the categorical variables. For this dataset, this step was not required
    so I have skipped this step.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要清理数据，填补所有缺失值，并对所有分类变量进行标签编码。对于这个数据集，这一步骤并不需要，因此我跳过了这一步。
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Step2:*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2：*'
- en: We have to add a feature **‘is_train’**in both train and test data. Value for
    this feature will be **0 for test and 1 for train**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在训练和测试数据中都添加一个特征**‘is_train’**。这个特征的值将是**测试集为0，训练集为1**。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Combining train and test*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*合并训练和测试*'
- en: Then we have to combine both the datasets. **Also since train data has the original
    ‘target’ variable which is not present in test, we have to drop that variable
    too.**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要将两个数据集合并。**此外，由于训练数据中有原始的‘target’变量，而测试数据中没有，所以我们也必须丢弃那个变量。**
- en: '**Note:** For your problem, ‘target’ will be replaced by the name of the dependent
    variable for your original problem.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 对于你的问题，‘target’将被替换为原始问题中因变量的名称。'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Step4: Building and testing a classifier*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤4：构建和测试分类器*'
- en: For classification purposes I’m using **Random Forest Classifier** to predict
    the labels for each row in the combined dataset. You can use any other classifier
    also.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分类目的，我使用**随机森林分类器**来预测合并数据集中每一行的标签。你也可以使用其他任何分类器。
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We are using stratified 4 fold to ensure that percentage for each class is preserved
    and we cover the whole data once. For each row the classifier will calculate the
    probability of it belonging to train.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用分层4折来确保每个类别的百分比得到保留，并且覆盖整个数据集。对于每一行，分类器将计算其属于训练集的概率。
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Step5: Interpreting the results*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤5：解释结果*'
- en: We’ll output the ROC-AUC metric for our classifier as an estimate how much covariate
    shift this data has.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将输出分类器的ROC-AUC指标，以估算数据的协变量偏移程度。
- en: If the classifier is able to classify the rows into train and test with good
    accuracy, our AUC score should be on the higher side (greater than 0.8). This
    implies strong covariate shift between train and test.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果分类器能够以良好的准确性将行分类为训练和测试，我们的AUC分数应该较高（大于0.8）。这意味着训练和测试之间存在强烈的协变量偏移。
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: AUC value of 0.49 implies that there is no evidence of strong covariate shift.
    This means that majority of the observations comes from a feature space which
    is not specific to test or train.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AUC值为0.49意味着没有强烈的协变量偏移证据。这意味着大多数观察结果来自一个不特定于测试或训练的特征空间。
- en: As this dataset is taken from Kaggle, this result is quite expected. As in such
    kind of competition dataset is carefully curated to ensure such shifts are not
    there.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个数据集来自Kaggle，所以这个结果是相当预期的。在这种竞赛数据集中，数据通常经过精心策划，以确保没有这样的偏移。
- en: This process can be replicated for any data science problem to check for covariate
    shift before we start modeling.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以在任何数据科学问题中复制，以检查在开始建模之前是否存在协变量偏移。
- en: Going beyond
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超越
- en: At this point we either observe covariate shift or not. So what can we possibly
    do to improve our performance on the test data ??
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此时我们要么观察到协变量偏移，要么没有。那么我们可以做些什么来提高测试数据上的性能呢？
- en: Dropping of drifting features
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃漂移特征
- en: Importance weight using Density Ratio Estimation
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用密度比估计进行重要性加权
- en: '**Dropping of drifting features:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**丢弃漂移特征：**'
- en: '**Note:** This method is applicable to the situation where you witness covariate
    shift.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 这种方法适用于你观察到协变量偏移的情况。'
- en: Extract feature importance from the random forest classifier object that we
    have built in the previous section
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从我们在上一节中构建的随机森林分类器对象中提取特征重要性
- en: The top features are the ones which are drifting and causing the shift
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶级特征是那些正在漂移并导致转移的特征。
- en: From the top features drop one variable at a time and build your model and check
    its performance. Collect all the features for which performance is not degrading
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从最重要的特征中一次删除一个变量，构建你的模型并检查其性能。收集所有那些性能没有下降的特征。
- en: Now drop all those features while building the final model
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建最终模型时，现在删除所有这些特征。
- en: '![](../Images/4f8f24d188f813f569030fe34a3240aa.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f8f24d188f813f569030fe34a3240aa.png)'
- en: The idea is to remove the features that fall in the red bucket
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个想法是去除那些落在红色桶中的特征。
- en: '**Importance weight using Density Ratio Estimation**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用密度比估计的重要性权重**'
- en: '**Note:** This method is applicable irrespective of whether there exist a covariate
    shift or not.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 该方法适用于是否存在协变量转移的情况。'
- en: Let’s look at the predictions that we have calculated in the previous section.
    For each observation, this prediction tells us the probability that it belongs
    to the training data according to our classifier.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在上一节中计算的预测结果。对于每个观察值，这个预测结果告诉我们它属于训练数据的概率。
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So for the first row our classifier thinks that it belongs to training data
    with .34 probability. Let’s call this P(train). Or we can also say that it has
    .66 probability of being from the test data. Let’s call this as P(test). Now here
    is the magic trick:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所以对于第一行，我们的分类器认为它以.34的概率属于训练数据。我们称之为P(train)。或者我们也可以说它有.66的概率来自测试数据。我们称之为P(test)。现在这里是魔法技巧：
- en: For each row of training data we calculate a coefficient **w = P(test)/P(train)**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一行训练数据，我们计算一个系数**w = P(test)/P(train)**。
- en: 'This w tells us how close is the observation from the training data to our
    test data. Here is the punchline:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个w告诉我们观察值与训练数据的接近程度。这里是重点：
- en: We can use this w as sample weights in any of our classifier to increase the
    weight of these observation which seems similar to our test data. Intuitively
    this makes sense as our model will focus more on capturing patterns from the observations
    which seems similar to our test.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以将这个w作为任何分类器中的样本权重，以增加这些与测试数据相似的观察值的权重。直观上，这很有意义，因为我们的模型将更多关注于捕捉那些与测试数据相似的观察值中的模式。
- en: These weights can be calculated using the below code.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权重可以使用以下代码计算。
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '< You can pass the weights calculated in the model fit method like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: < 你可以像这样将模型拟合方法中计算的权重传递进去：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/4781dc6afd070dbf42e7978dbc01e0f6.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4781dc6afd070dbf42e7978dbc01e0f6.png)'
- en: 'Some things to notice in the above plot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图中需要注意的一些事项：
- en: Higher the weight for the observation, more is it similar to the test data
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察值的权重越高，它与测试数据的相似性就越大。
- en: Almost 70% of training samples have sample weight of close to 1 and hence comes
    from a feature space which is not very specific to train or test high density
    region. This is in line with the AUC value that we have calculated
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎70%的训练样本的样本权重接近1，因此来自于一个对训练或测试高密度区域不是非常特定的特征空间。这与我们计算的AUC值一致。
- en: End Notes
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: I hope that now you have a better understanding about covariate shift, how you
    can identify it and treat it effectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望现在你对协变量转移有了更好的理解，知道如何识别并有效处理它。
- en: '**Bio: [Shikhar Gupta](https://twitter.com/shik1470)** is pursuing masters
    in data science at U. of San Francisco, Intern @IsaziConsulting, alumni @iitroorkee
    .'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Shikhar Gupta](https://twitter.com/shik1470)** 正在旧金山大学攻读数据科学硕士学位，实习于@IsaziConsulting，@iitroorkee
    校友。'
- en: '[Original](https://towardsdatascience.com/how-dis-similar-are-my-train-and-test-data-56af3923de9b).
    Reposted with permission.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/how-dis-similar-are-my-train-and-test-data-56af3923de9b)。转载获得许可。'
- en: '**Related:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Training Sets, Test Sets, and 10-fold Cross-validation](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[训练集、测试集和10折交叉验证](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)'
- en: '[The 6 components of Open-Source Data Science/ Machine Learning Ecosystem;
    Did Python declare victory over R?](https://www.kdnuggets.com/2018/06/ecosystem-data-science-python-victory.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开源数据科学/机器学习生态系统的6个组成部分；Python是否战胜了R？](https://www.kdnuggets.com/2018/06/ecosystem-data-science-python-victory.html)'
- en: '[The Statistics of Gang Violence](https://www.kdnuggets.com/2018/06/statistics-gang-violence.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[帮派暴力的统计数据](https://www.kdnuggets.com/2018/06/statistics-gang-violence.html)'
- en: More On This Topic
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何通过使用自动 EDA 工具在数据科学评估测试中脱颖而出](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
- en: '[Performing a T-Test in Python](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中执行 T 检验](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
- en: '[Beyond Accuracy: Evaluating & Improving a Model with the NLP Test Library](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越准确性：使用 NLP 测试库评估和改进模型](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
- en: '[How to Build and Train a Transformer Model from Scratch with…](https://www.kdnuggets.com/how-to-build-and-train-a-transformer-model-from-scratch-with-hugging-face-transformers)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何从零开始构建和训练 Transformer 模型…](https://www.kdnuggets.com/how-to-build-and-train-a-transformer-model-from-scratch-with-hugging-face-transformers)'
- en: '[Why we will always need humans to train AI — sometimes in real-time](https://www.kdnuggets.com/2021/12/why-we-need-humans-training-ai.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么我们总是需要人类来训练 AI — 有时需要实时进行](https://www.kdnuggets.com/2021/12/why-we-need-humans-training-ai.html)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
