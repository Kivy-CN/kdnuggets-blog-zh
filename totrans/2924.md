# 2019版《掌握机器学习数据准备的7个步骤》

> 原文：[https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html](https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html)

[评论](#comments)

有兴趣掌握Python的数据准备吗？

数据准备、清理、预处理、清洗、整理。无论你选择哪个术语，它们都指的是机器学习、数据挖掘和数据科学社区中的一组大致相关的预建模数据活动。

* * *

## 我们的3个推荐课程

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT工作

* * *

维基百科定义[数据清洗](https://en.wikipedia.org/wiki/Data_cleansing)为：

> …是从记录集、表格或数据库中检测和纠正（或删除）损坏或不准确记录的过程，指的是识别数据中不完整、不正确、不准确或不相关的部分，然后替换、修改或删除这些脏数据或粗糙数据。数据清洗可以通过数据处理工具进行交互式操作，也可以通过脚本进行批处理。

[数据整理](https://en.wikipedia.org/wiki/Data_wrangling)的定义与此相比，维基百科中定义为：

> …手动将数据从一种“原始”形式转换或映射到另一种格式，以便更方便地使用这些数据，借助半自动化工具。这可能包括进一步的清理、数据可视化、数据聚合、训练统计模型以及许多其他潜在用途。数据清理作为一个过程通常遵循一组通用步骤，从从数据源提取原始数据开始，使用算法（例如排序）或将数据解析成预定义的数据结构来“清理”原始数据，最后将结果内容存入数据存储区以备将来使用。

![图](../Images/2ebc5d14359a29620a0fe3466edd6938.png)

数据准备在[KDD过程](http://www2.cs.uregina.ca/~dbd/cs831/notes/kdd/1_kdd.html)（左）和[CRISP-DM模型](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)（右）中的表现。

我会说，在“将数据从一种‘原始’形式映射到另一种形式……”的背景下，数据准备是“识别数据中不完整、不正确、不准确或不相关的部分，然后替换、修改或删除这些脏数据或粗糙数据”，以及“训练统计模型”这两部分。我喜欢把数据准备理解为涵盖了“从数据源获取到模型构建前的所有内容”。这就是我们将继续使用的模糊但奇怪准确的定义。

这篇文章将[更新 2017 年的旧版本](/2017/06/7-steps-mastering-data-preparation-python.html)，以便更新一些内容。我尝试选择一两个优质的教程，并在适当的情况下附上视频，作为每个步骤中特定课程的良好代表。

请记住，文章涵盖了一组特定的数据准备技术，在特定情况下可能会使用额外或完全不同的技术，具体取决于要求。你会发现这里的处方既是正统的，又是通用的。

拿上小吃，坐下来吧，我们将学习如何用 Python 掌握数据准备。

### 第一步：准备准备工作

首先，让我们强调一下其他人已经告诉过你的：可以认为数据准备阶段并不是机器学习任务之前的初步步骤，而是一个典型机器学习任务的组成部分（甚至是主要部分）。然而，为了我们的目的，我们将数据准备与建模分开，作为一个独立的过程。

由于 Python 是我们将要深入的生态系统，以下资源是确保适当熟悉的良好起点。

+   **[10 分钟入门 Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)**

+   **[Matplotlib 初学者指南](https://matplotlib.org/users/beginner.html)**

+   **[官方 Seaborn 教程](https://seaborn.pydata.org/tutorial.html)**

数据准备可以在 CRISP-DM 模型中看到（尽管可以合理地认为“数据理解”也包含在我们的定义中）。我们还可以将数据准备等同于 KDD 过程的框架——特别是前三个主要步骤——即**选择**、**预处理**和**转换**。我们可以将这些步骤细化，但在宏观层面上，KDD 过程的这些步骤涵盖了数据处理的内容。

虽然读者应该可以在几乎不需要额外资源的情况下跟随本指南，但对于那些对 Pandas（可能是 Python 生态系统中最重要的数据准备库）有更全面兴趣的人，以下信息可能会有所帮助：

+   **[Pandas 数据结构简介](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/)**，作者 Greg Reda

+   **[现代 Pandas（7 部分）](http://tomaugspurger.github.io/modern-1-intro.html)**，作者 Tom Augspurger

最后，在继续之前，阅读关于数据准备过程的三位内部人士——Sebastian Raschka、Clare Bernard和Joe Boutros——的采访，**[数据准备技巧、窍门和工具：与内部人士的访谈](/2016/10/data-preparation-tips-tricks-tools.html)**。

### 第二步：探索性数据分析

[探索性数据分析](https://en.wikipedia.org/wiki/Exploratory_data_analysis)（EDA）是任何大型数据分析、数据科学或机器学习项目的重要组成部分。在处理数据之前理解数据不仅是一个很好的主意，如果你计划完成任何有意义的事情，它更是一个优先事项。[Andrew Andrade](https://datascienceguide.github.io/exploratory-data-analysis) 简明扼要地描述了EDA。

> EDA的目的是使用摘要统计和可视化来更好地理解数据，找出数据的趋势、质量，并制定假设和分析的假设。

基本要点是，我们需要了解数据的组成，才能有效地选择预测算法或规划数据准备的剩余步骤。随便将数据集丢给最新算法并希望获得最佳结果并不是一种策略。

为了获得一些直观的了解，请观看弗吉尼亚大学Patrick Meyer教授提供的关于EDA的概述视频。

然后阅读**[探索性数据分析](https://datascienceguide.github.io/exploratory-data-analysis)**的文章，它提供了关于如何进行EDA的额外细节，以及其实际好处。

关于EDA的基于Python的方法教程，查看Vigneshwer Dhinakaran的文章**[使用Python进行探索性数据分析（EDA）和数据可视化](https://kite.com/blog/python/data-analysis-visualization-python)**，在我看来，这实际上超越了传统的EDA，并将向你介绍一些在本文后面介绍的额外概念。

一个显著缩短进行EDA所需编写代码的库是**[Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling)**，它从Pandas DataFrames创建HTML报告。

> 从pandas `DataFrame`生成概要报告。pandas的`df.describe()`函数非常好，但对于严肃的探索性数据分析来说有些基础。`pandas_profiling`通过`df.profile_report()`扩展了pandas DataFrame，用于快速数据分析。

你可以通过一行代码在Jupyter notebooks中交互式地运行Pandas Profiling：

`df.profile_report()`

阅读项目的GitHub Readme获取更多信息，并自己尝试一下。

### 第三步：缺失值

处理缺失数据的方法有很多种，没有一种是普遍适用的。有人会说“绝不要使用包含空值的实例。”也有人会争论“绝不要用属性的均值来替代缺失值。”相反，你可能会听到更多复杂的方法被全盘接受，例如“仅在将数据集首先按已知类别进行聚类，然后使用聚类内部回归来计算缺失值是有效的。”

不要听信这些说法。“绝不要”和“仅仅”以及其他不灵活的主张在数据精细化的复杂世界中没有价值；不同类型的数据和过程建议处理缺失值的最佳实践不同。然而，由于这种知识既基于经验也基于领域，我们将重点关注可以采用的更基本的策略。

一些常用的处理缺失值的方法包括：

+   丢弃缺失值的实例

+   丢弃缺失值的属性

+   用属性的{均值 | 中位数 | 众数}填补所有缺失值

+   通过线性回归填补属性的缺失值

也可以使用组合策略：丢弃任何缺失值超过2个的实例，并用剩余实例的均值填补缺失值。显然，所采用的建模方法会对你的决策产生影响——例如，决策树不适合缺失值。此外，你可以从技术上考虑任何你能想到的统计方法来确定数据集中的缺失值，但列出的这些方法已经经过尝试、测试，并且被广泛使用。

由于我们关注的是Python生态系统，你可以通过Pandas用户指南了解更多关于**[处理缺失数据](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)**的信息，并参考**[Pandas `DataFrame` 对象的 `fillna()` 函数](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html)**的API文档。

在Pandas DataFrame中填补缺失值有很多方法。这里有一些基本示例：

你还可以观看codebasics关于使用Pandas处理缺失值的视频。

### 步骤4：异常值

这不是一个关于在建模时制定处理异常值策略的教程；在建模中包含异常值在某些情况下是合适的，在另一些情况下则不是（无论别人怎么告诉你）。这取决于具体情况，没有人可以对你的情况是否属于A列或B列做出全面的断言。

异常值可能是由于数据收集不当造成的，也可能是实际上具有真实意义的异常数据。这是两种不同的情况，必须采取不同的方法，因此没有“一刀切”的建议适用于这里，这类似于处理缺失值的方法。来自上述分析因素文章的一个特别有价值的见解如下：

> 一个选项是尝试转换。平方根和对数转换都可以收敛高值。如果离群值是因变量，这可以使假设更好地工作；如果离群值是自变量，这可以减少单个点的影响。

阅读这个讨论，**[离群值：删除还是不删除](http://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/)**，以及在Stack Exchange上的讨论**[从数据中删除离群值可以吗？](https://stats.stackexchange.com/questions/200534/is-it-ok-to-remove-outliers-from-data/200923)**，以进一步了解这个问题。

你可以查看**[使用Python通过标准差去除离群值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)**，作为使用Python去除离群值的简单示例。然后阅读这个Stack Overflow讨论，**[在Pandas DataFrame中使用百分位数去除离群值](https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles)**。

最终，是否去除离群值将取决于任务本身，推理和决策比技术方法更为重要。

### 第5步：不平衡数据

那么，如果你原本健壮的数据集由两个类别组成：一个包含95%的实例，另一个仅包含5%？或者更糟，99.8%对0.2%？

![识别和处理不平衡很重要](../Images/c9cbb484ef13d59bff657b921d1b6624.png)

如果是这样，你的数据集是不平衡的，至少在类别方面如此。这可能会引发一些问题，这些问题我相信不需要指出。但还不需要立即丢弃数据；当然有策略可以应对这个问题。

一个好的解释说明了为什么我们会遇到不平衡数据，以及为什么在某些领域这种情况比其他领域更为频繁（来自“处理不平衡数据的7种技术”，如下）：

> 这些领域使用的数据通常有不到1%的稀有但“有趣”的事件（例如，信用卡欺诈、用户点击广告或被破坏的服务器扫描其网络）。然而，大多数机器学习算法在处理不平衡数据集时效果不佳。以下七种技术可以帮助你训练分类器以检测异常类别。

请注意，虽然这可能不是真正的数据准备任务，但这样的数据集特征会在数据准备阶段早期显现（EDA的重要性），并且在这一准备阶段可以初步评估数据的有效性。

Tom Fawcett在他的文章**[从不平衡类别中学习](/2016/08/learning-from-imbalanced-classes.html)**中讨论了这个问题。阅读它可以更好地了解这个问题。

然后阅读这篇文章，**[处理不平衡数据的7种技术](/2017/06/7-techniques-handle-imbalanced-data.html)**，作者Ye Wu & Rick Radewagen，涵盖了处理类别不平衡的技术。

### 第6步：数据转换

维基百科定义的[数据转换](https://en.wikipedia.org/wiki/Data_transformation_(statistics))是：

> 在统计学中，数据转换是将一个确定性数学函数应用到数据集中的每个点——也就是说，每个数据点zi都被转换值*y[i]* = *f(z[i])*所替代，其中*f*是一个函数。转换通常是为了使数据看起来更符合将要应用的统计推断程序的假设，或者改善图表的解释性或外观。

数据转换是数据准备中最重要的方面之一，需要比其他一些方法更多的技巧。当数据中出现缺失值时，它们通常很容易找到，并可以通过上述常见方法之一来处理——或者通过在领域内长期积累的更复杂的措施来处理。然而，何时以及是否需要数据转换通常不那么容易识别，更不用说所需的转换类型。

让我们深入了解几个具体的转换，以便更好地掌握它们。

首先，这个关于**[数据预处理](http://scikit-learn.org/stable/modules/preprocessing.html)**的概述来自Scikit-learn文档，给出了一些最重要的预处理转换的理由，即标准化、归一化、二值化以及其他一些。

标准化和归一化是在机器学习项目中经常使用的一对数据转换方法。两者都是数据缩放方法：标准化是指将数据缩放到均值为0，标准差为1；归一化是指将数据值缩放到一个预定的范围，通常在0到1之间。阅读这篇文章，**[归一化与标准化——定量分析](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)**，以了解这些转换如何工作，如何在Python生态系统中执行它们，并从作者那里获得一些最佳实践的见解。

一次性编码是一种将类别特征转换为更适合分类和回归的格式的方法。观看这个关于一次性编码的视频，以更好地理解它是如何实现的，并查看如何使用Python工具完成。

对数分布转换对于将非线性模型转换为线性模型和处理偏斜数据非常有用。阅读这个Stack Exchange讨论，**[什么时候（以及为什么）你应该对分布（数字）取对数？](https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers)**，以获得直观理解。你还可以查看来自Data Science Made Simple的这个简短教程，**[pandas python中列的对数和自然对数值](http://www.datasciencemadesimple.com/log-natural-logarithmic-value-column-pandas-python-2/)**，快速了解如何使用Numpy在Python中完成转换。

这个来自安大略科技大学的简短教程，**[指数和对数函数简介](https://nool.uoit.ca/mathematics/exponential-logarithmic-functions/basics/index.php)**，采用数学方法解释对数和指数转换，以及可视化，并能帮助你更好地理解在进行这些转换时底层数据分布的变化。教程共有3页，第三页有2个视频，有助于深入理解。

根据数据和需求，还有许多其他标准数据转换方法。通过数据预处理和准备的经验应能提供在不同情况下所需转换类型的直观理解。

### 第7步：最后修饰与前进

好吧。你的数据已经“干净”了。但是你接下来该怎么做？

如果你想直接将数据输入机器学习算法以尝试建立模型，你可能需要将数据转换为更合适的表示形式。在Python生态系统中，这通常是Numpy ndarray（或矩阵）。这个Stack Overflow讨论，**[将Pandas Dataframe转换为数组并评估多元线性回归模型](https://stackoverflow.com/questions/28334091/turning-a-pandas-dataframe-to-an-array-and-evaluate-multiple-linear-regression-m)**，可以为你提供一些初步的思路。

![非常简单的数据准备过程](../Images/2b1892e803954b3888cf48f32e0c71b7.png)

*请注意，我们在前面的文本中大部分数据准备工作是在Pandas和Numpy的组合中完成的；然而，Pandas建立在Numpy之上，因此直接操作底层Numpy矩阵是一个有用的技能。[在这里了解更多](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)。*

如果你还没有准备好对数据建模，而是想将你干净的Pandas DataFrame存储以备后用？**[使用Pandas快速HDF5](https://dzone.com/articles/quick-hdf5-pandas)**由Giuseppe Vettigli展示了一种这样的方式。

一旦你有了用于Python中机器学习的干净数据和适当的表示，为什么不直接进行机器学习呢？首先，你需要阅读**[掌握基本机器学习的7个步骤 — 2019版](/2019/01/7-steps-mastering-basic-machine-learning-python.html)**，以获得Python生态系统中机器学习的初步理解。接着，阅读**[掌握中级机器学习的7个步骤 — 2019版](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)**以提升你的知识（同时也请留意“高级”版）。

对数据准备有不同观点的，请查看以下内容：

+   **[在Python中整理数据](/2017/01/tidying-data-python.html)**，作者：Jean-Nicholas Hould

+   **[数据科学实践：Kaggle实战 第3部分 — 数据清洗](/2016/06/doing-data-science-kaggle-walkthrough-data-cleaning.html)**，作者：Brett Romero

+   **[从头开始学习Python中的机器学习工作流 第1部分：数据准备](/2017/05/machine-learning-workflows-python-scratch-part-1.html)**

请注意，这整个讨论也完全且有意跳过了特征选择的提及，原因很简单：特征选择在这更广泛的讨论中值得比几句话更多的关注。请留意关于特征选择的类似指南。

**相关**：

+   [掌握基本机器学习的7个步骤 — 2019版](/2019/01/7-steps-mastering-basic-machine-learning-python.html)

+   [掌握中级机器学习的7个步骤 — 2019版](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)

+   [掌握SQL以进行数据科学的7个步骤 — 2019版](/2019/05/7-steps-mastering-sql-data-science-2019-edition.html)

### 更多相关话题

+   [成为优秀数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [每个数据科学家应该了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [是什么让Python成为创业公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)
