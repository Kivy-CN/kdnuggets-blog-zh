- en: Exploring the OpenAI API with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/exploring-the-openai-api-with-python](https://www.kdnuggets.com/exploring-the-openai-api-with-python)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Exploring the OpenAI API with Python](../Images/b571bd0ec99162294767154f74f124b7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with [Ideogram.ai](http://ideogram.ai)
  prefs: []
  type: TYPE_NORMAL
- en: Who hasn’t heard about OpenAI? The AI research laboratory has changed the world
    because of its famous product, ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: It literally changed the landscape of AI implementation, and many companies
    now rush to become the next big thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite much competition, OpenAI is still the go-to company for any Generative
    AI business needs because it has one of the best models and continuous support.
    The company provides many state-of-the-art Generative AI models with various task
    capabilities: Image generation, Text-to-Speech, and many more.'
  prefs: []
  type: TYPE_NORMAL
- en: All of the models OpenAI offers are available via API calls. With simple Python
    code, you can already use the model.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will explore how to use the OpenAI API with Python and various
    tasks you can do. I hope you learn a lot from this article.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI API Setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow this article, there are a few things you need to prepare.
  prefs: []
  type: TYPE_NORMAL
- en: The most important thing you need is the API Keys from OpenAI, as you cannot
    access the OpenAI models without the key. To acquire access, you must register
    for an OpenAI account and request the API Key on the [account page](https://platform.openai.com/api-keys).
    After you receive the key, save that somewhere you can remember, as it will not
    appear again in the OpenAI interface.
  prefs: []
  type: TYPE_NORMAL
- en: The next thing you need to set is to buy the pre-paid credit to use the OpenAI
    API. Recently, OpenAI announced changes to how [their billing works](https://help.openai.com/en/articles/8264644-what-is-prepaid-billing).
    Instead of paying at the end of the month, we need to purchase pre-paid credit
    for the API call. You can visit the [OpenAI pricing](https://openai.com/pricing)
    page to estimate the credit you need. You can also check their [model page](https://platform.openai.com/docs/models/overview)
    to understand which model you require.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, you need to install the OpenAI Python package in your environment. You
    can do that using the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, you need to set your OpenAI Key Environment variable using the code below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: With everything set, let’s start exploring the API of the OpenAI models with
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI API Text Generations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The star of OpenAI API is their Text Generations model. These Large Language
    Models family can produce text output from the text input called prompt. Prompts
    are basically instructions on what we expect from the model, such as text analysis,
    generating document drafts, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by executing a simple Text Generations API call. We would use the
    GPT-3.5-Turbo model from OpenAI as the base model. It’s not the most advanced
    model, but the cheapest are often enough to perform text-related tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*"Unleashing the power of predictive analytics to drive data-driven decisions!"*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*"Diving deep into the data ocean to uncover valuable insights."*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*"Transforming raw data into actionable intelligence through advanced algorithms."*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API Call for the Text Generation model uses the API Endpoint *chat.completions*
    to create the text response from our prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two required parameters for text Generation: model and messages.'
  prefs: []
  type: TYPE_NORMAL
- en: For the model, you can check the list of models that you can use on the related
    model page.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the messages, we pass a dictionary with two pairs: the role and the
    content. The role key specified the role sender in the conversation model. There
    are 3 different roles: system, user, and assistant.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the role in messages, we can help set the model behavior and an example
    of how the model should answer our prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s extend the previous code example with the role assistant to give guidance
    on our model. Additionally, we would explore some parameters for the Text Generation
    model to improve their result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Of course! Here are three content ideas based on the jargons provided:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Unleashing the Power of Data Wrangling: A Step-by-Step Guide for Data Scientists"
    - Create a blog post or video tutorial showcasing best practices and tools for
    data wrangling in a real-world data science project.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*"The Future of Predictive Analytics: Trends and Innovations in Data Science"
    - Write a thought leadership piece discussing emerging trends and technologies
    in predictive analytics and how they are shaping the future of data science.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*"Mastering Feature Engineering: Techniques to Boost Model Performance" - Develop
    an infographic or social media series highlighting different feature engineering
    techniques and their impact on improving the accuracy and efficiency of machine
    learning models.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The resulting output follows the example that we provided to the model. Using
    the role assistant is useful if we have a certain style or result we want the
    model to follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the parameters, here are simple explanations of each parameter that
    we used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**max_tokens**: This parameter sets the maximum number of words the model can
    generate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**temperature**: This parameter controls the unpredictability of the model''s
    output. A higher temperature results in outputs that are more varied and imaginative.
    The acceptable range is from 0 to infinity, though values above 2 are unusual.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**top_p**: Also known as nucleus sampling, this parameter helps determine the
    subset of the probability distribution from which the model draws its output.
    For instance, a top_p value of 0.1 means that the model considers only the top
    10% of the probability distribution for sampling. Its values can range from 0
    to 1, with higher values allowing for greater output diversity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**frequency_penalty**: This penalizes repeated tokens in the model''s output.
    The penalty value can range from -2 to 2, where positive values discourage the
    repetition of tokens, and negative values do the opposite, encouraging repeated
    word use. A value of 0 indicates that no penalty is applied for repetition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, you can change the model output to the JSON format with the following
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: '"jargons": ['
  prefs: []
  type: TYPE_NORMAL
- en: '"Leveraging predictive analytics to unlock valuable insights",'
  prefs: []
  type: TYPE_NORMAL
- en: '"Delving into the intricacies of advanced machine learning algorithms",'
  prefs: []
  type: TYPE_NORMAL
- en: '"Harnessing the power of big data to drive data-driven decisions"'
  prefs: []
  type: TYPE_NORMAL
- en: ']'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: The result is in JSON format and adheres to the prompt we input into the model.
  prefs: []
  type: TYPE_NORMAL
- en: For complete [Text Generation API documentation](https://platform.openai.com/docs/api-reference/chat),
    you can check them out on their dedicated page.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI Image Generations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI model is useful for text generation use cases and can also call the API
    for image generation purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Using the DALL·E model, we can generate an image as requested. The simple way
    to perform it is using the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Exploring the OpenAI API with Python](../Images/5e5a575cfd9d1d1bb026126983be456d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated with DALL·E 3
  prefs: []
  type: TYPE_NORMAL
- en: 'For the parameters, here are the explanations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**model**: The image generation model to use. Currently, the API only supports
    DALL·E 3 and DALL·E 2 models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**prompt**: This is the textual description based on which the model will generate
    an image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**size**: Determines the resolution of the generated image. There are three
    choices for the DALL·E 3 model (1024x1024, 1024x1792 or 1792x1024).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**quality**: This parameter influences the quality of the generated image.
    If computational time is needed, “standard” is faster than “hd.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**n**: Specifies the number of images to generate based on the prompt. DALL·E
    3 can only generate one image at a time. DALL·E 2 can generate up to 10 at a time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also possible to generate a variation image from the existing image, although
    it’s only available using the DALL·E 2 model. The API only accepts square PNG
    images below 4 MB as well.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The image might not be as good as the DALL·E 3 generations as it is using the
    older model.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI is a leading company that provides models that can understand image input.
    This model is called the Vision model, sometimes called GPT-4V. The model is capable
    of answering questions given the image we gave.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try out the Vision model API. In this example, I would use the white piano
    image we generate from the DALL·E 3 model and store it locally. Also, I would
    create a function that takes the image path and returns the image description
    text. Don’t forget to change the api_key variable to your API Key.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*This image features a grand piano placed on a serene beach setting. The piano
    is white, indicating a finish that is often associated with elegance. The instrument
    is situated right at the edge of the shoreline, where the gentle waves lightly
    caress the sand, creating a foam that just touches the base of the piano and the
    matching stool. The beach surroundings imply a sense of tranquility and isolation
    with clear blue skies, fluffy clouds in the distance, and a calm sea expanding
    to the horizon. Scattered around the piano on the sand are numerous seashells
    of various sizes and shapes, highlighting the natural beauty and serene atmosphere
    of the setting. The juxtaposition of a classical music instrument in a natural
    beach environment creates a surreal and visually poetic composition.*'
  prefs: []
  type: TYPE_NORMAL
- en: You can tweak the text values in the dictionary above to match your Vision model
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI Audio Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI also provides a model to generate audio based on their Text-to-Speech
    model. It’s very easy to use, although the voice narration style is limited. Also,
    the model has supported many languages, which you can see on their [language support
    page](https://github.com/openai/whisper#available-models-and-languages).
  prefs: []
  type: TYPE_NORMAL
- en: To generate the audio, you can use the below code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You should see the audio file in your directory. Try to play it and see if it’s
    up to your standard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, there are only a few parameters you can use for the Text-to-Speech
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: 'model: The Text-to-Speech model to use. Only two models are available (tts-1
    or tts-1-hd), where tts-1 optimizes speed and tts-1-hd for quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'voice: The voice style to use where all the voice is optimized to english.
    The selection is alloy, echo, fable, onyx, nova, and shimmer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'response_format: The audio format file. Currently, the supported formats are
    mp3, opus, aac, flac, wav, and pcm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'speed: The generated audio speed. You can select values between 0.25 to 4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'input: The text to create the audio. Currently, the model only supports up
    to 4096 characters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI Speech-to-Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenAI provides the models to transcribe and translate audio data. Using the
    whispers model, we can transcribe audio from the supported language to the text
    files and translate them into english.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try a simple transcription from the audio file we generated previously.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*I love data science and machine learning.*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s also possible to perform translation from the audio files to the english
    language. The model isn’t yet available to translate onto another language.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have explored several model services that OpenAI provides, from Text Generation,
    Image Generation, Audio Generation, Vision, and Text-to-Speech models. Each model
    have their API parameter and specification you need to learn before using them.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Free ChatGPT Course: Use The OpenAI API to Code 5 Projects](https://www.kdnuggets.com/2023/05/free-chatgpt-course-openai-api-code-5-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAI’s Whisper API for Transcription and Translation](https://www.kdnuggets.com/2023/06/openai-whisper-api-transcription-translation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[OpenAI API for Beginners: Your Easy-to-Follow Starter Guide](https://www.kdnuggets.com/openai-api-for-beginners-your-easy-to-follow-starter-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fine-Tuning OpenAI Language Models with Noisily Labeled Data](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[New ChatGPT and Whisper APIs from OpenAI](https://www.kdnuggets.com/2023/03/new-chatgpt-whisper-apis-openai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best Practices to Use OpenAI GPT Model](https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
