- en: 'Introduction to Deep Learning Libraries: PyTorch and Lightning AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/291f913d791d2fd9fc8513dccfb9ebc0.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Google [DeepMind](https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-depicts-the-potential-of-ai-for-society-through-3d-visualisations-it-was-created-by-novoto-studio-as-part-of-the-visua-18069496/)
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning is a branch of the machine learning model based on [neural networks](https://en.wikipedia.org/wiki/Neural_network).
    In the other machine model, the data processing to find the meaningful features
    is often done manually or relying on domain expertise; however, deep learning
    can mimic the human brain to discover the essential features, increasing the model
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: There are many applications for deep learning models, including facial recognition,
    fraud detection, speech-to-text, text generation, and many more. Deep learning
    has become a standard approach in many advanced machine learning applications,
    and we have nothing to lose by learning about them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To develop this deep learning model, there are various library frameworks we
    can rely upon rather than working from scratch. In this article, we will discuss
    two different libraries we can use to develop deep learning models: PyTorch and
    Lighting AI. Let’s get into it.'
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch is an open-source library framework to train deep-learning neural networks.
    PyTorch was developed by the Meta group in 2016 and has grown in popularity. The
    rise of popularity was thanks to the PyTorch feature that combines the GPU backend
    library from [Torch](http://torch.ch/) with Python language. This combination
    makes the package easy to follow by the user but still powerful in developing
    the deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few standout [PyTorch features](https://pytorch.org/features/) that
    are enabled by the libraries, including a nice front-end, distributed training,
    and a fast and flexible experimentation process. Because there are many PyTorch
    users, the community development and investment were also massive. That is why
    learning PyTorch would be beneficial in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch building block is a [tensor](https://en.wikipedia.org/wiki/Tensor),
    a multi-dimensional array used to encode all the input, output, and model parameters.
    You can imagine a tensor like the NumPy array but with the capability to run on
    GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try out the PyTorch library. It’s recommended to perform the tutorial
    in the cloud, such as Google Colab if you don’t have access to a GPU system (although
    it could still work with a CPU). But, If you want to start in the local, we need
    to install the library via [this page](https://pytorch.org/get-started/locally/).
    Select the appropriate system and specification you have.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the code below is for pip installation if you have a CUDA-Capable
    system.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After the installation finishes, let’s try some PyTorch capabilities to develop
    the deep learning model. We will do a simple image classification model with PyTorch
    in this tutorial based on their web tutorial. We would walk on the code and have
    an explanation of what happened within the code.
  prefs: []
  type: TYPE_NORMAL
- en: First, we would download the dataset with PyTorch. For this example, we would
    use the MNIST dataset, which is the number handwritten classification dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We download both the MNIST train and test datasets to our root folder. Let’s
    see what our dataset looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/5beec8ab85fb6221d4f0f8c808e9fe79.png)'
  prefs: []
  type: TYPE_IMG
- en: Every image is a single-digit number between zero and nine, meaning we have
    ten labels. Next, let’s develop an image classifier based on this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We need to transform the image dataset into a tensor to develop a deep learning
    model with PyTorch. As our image is a PIL object, we can use the PyTorch ToTensor
    function to perform the transformation. Additionally, we can automatically transform
    the image with the datasets function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: By passing the transformation function to the transform parameter, we can control
    what the data would be like. Next, we would wrap the data into the DataLoader
    object so the PyTorch model could access our image data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the code above, we create a DataLoader object for the train and test data.
    Each data batch iteration would return 64 features and labels in the object above.
    Additionally, the shape of our image is 28 * 28 (height * width).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we would develop the Neural Network model object.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In the object above, we create a Neural Model with few layer structure. To develop
    the Neural Model object, we use the subclassing method with the nn.module function
    and create the neural network layers within the__init__.
  prefs: []
  type: TYPE_NORMAL
- en: 'We initially convert the 2D image data into pixel values inside the layer with
    the flatten function. Then, we use the sequential function to wrap our layer into
    a sequence of layers. Inside the sequential function, we have our model layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'By sequence, what happens above is:'
  prefs: []
  type: TYPE_NORMAL
- en: First, the data input which is 28*28 features is transformed using a linear
    function in the linear layer and having 128 features as the output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ReLU is a non-linear activation function that is present between the model input
    and output to introduce non-linearity.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 128 features input to the linear layer and have 128 features output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another ReLU activation function
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 128 features as the input in the linear layer and 10 features as the output
    (our dataset label only has 10 labels).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lastly, the forward function is present for the actual input process for the
    model. Next, the model would need a loss function and optimization function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: For the next code, we just prepare the training and test preparation before
    we run the modeling activity.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now we are ready to run our model training. We would decide how many epochs
    (iterations) we want to perform with our model. For this example, let’s say we
    want it to run for five times.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/a2376135f7b6ed629ed26dea0ac08e4f.png)'
  prefs: []
  type: TYPE_IMG
- en: The model now has finished their training and able to be used for any image
    prediction activity. The result could vary, so expect different results from the
    above image.
  prefs: []
  type: TYPE_NORMAL
- en: It’s just a few things that PyTorch can do, but you can see that building a
    model with PyTorch is easy. If you are interested in the pre-trained model, PyTorch
    has a [hub](https://pytorch.org/hub/) you can access.
  prefs: []
  type: TYPE_NORMAL
- en: Lighting AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Lighting AI](https://lightning.ai/) is a company that provides various products
    to minimize the time to train the PyTorch deep learning model and simplify it.
    One of their open-source product is [PyTorch Lighting](https://lightning.ai/pytorch-lightning),
    which is a library that offers a framework to train and deploy the PyTorch model.'
  prefs: []
  type: TYPE_NORMAL
- en: Lighting offers a few features, including code flexibility, no boilerplate,
    minimal API, and improved team collaboration. Lighting also offers features such
    as multi-GPU utilization and swift, low-precision training. This made Lighting
    a good alternative to develop our PyTorch model.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try out the model development with Lighting. To start, we need to install
    the package.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: With the Lighting installed, we would also install another Lighting AI product
    called [TorchMetrics](https://lightning.ai/torchmetrics) to simplify the metric
    selection.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With all the libraries installed, we would try to develop the same model from
    our previous example using a Lighting wrapper. Below is the whole code for developing
    the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Let’s break down what happen in the code above. The difference with the PyTorch
    model we developed previously is that the NNModel class now uses subclassing from
    the LightingModule. Additionally, we assign the accuracy metrics to assess using
    the TorchMetrics. Then, we added the training and testing step within the class
    and set up the optimization function.
  prefs: []
  type: TYPE_NORMAL
- en: With all the models set, we would run the model training using the transformed
    DataLoader object to train our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Introduction to Deep Learning Libraries: PyTorch and Lightning AI](../Images/87749cd3f95ff12d202df318f44ab167.png)'
  prefs: []
  type: TYPE_IMG
- en: With the Lighting library, we can easily tweak the structure you need. For further
    reading, you could read their [documentation](https://lightning.ai/docs/pytorch/latest/).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: PyTorch is a library for developing deep learning models, and it provides an
    easy framework for us to access many advanced APIs. Lighting AI also supports
    the library, which provides a framework to simplify the model development and
    enhance the development flexibility. This article introduced us to both the library's
    features and simple code implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Lightning AI Studio For Free](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Python Libraries for Data Cleaning](https://www.kdnuggets.com/2023/03/introduction-python-libraries-data-cleaning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Practical Guide to Transfer Learning using PyTorch](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
