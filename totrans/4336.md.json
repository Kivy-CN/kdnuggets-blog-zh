["```py\n!pip install --quiet neural-structured-learning\n!pip install --quiet larq larq-zoo \n!pip install --quiet kymatio\n!pip install --quiet netcal\n!pip install --quiet baycomp\n!pip install --quiet pyeer\n!pip install --quiet pyod\n!pip install --quiet hyppo\n!pip install --quiet gradio\n!pip install --quiet jupyter_to_medium\n```", "```py\nimport tensorflow as tf\nimport neural_structured_learning as nsl\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Prepare data.\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Create a base model -- sequential, functional, or subclass.\nmodel = tf.keras.Sequential([\n    tf.keras.Input((28, 28), name='feature'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\n\n# Wrap the model with adversarial regularization.\nadv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\nadv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\n\n# Compile, train, and evaluate.\nadv_model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nadv_model.fit({'feature': x_train, 'label': y_train}, batch_size=32, epochs=5)\nadv_model.evaluate({'feature': x_test, 'label': y_test})Epoch 1/5\n\n1875/1875 [==============================] - 39s 2ms/step - loss: 0.5215 - sparse_categorical_crossentropy: 0.4292 - sparse_categorical_accuracy: 0.8781 - scaled_adversarial_loss: 0.0924\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1447 - sparse_categorical_crossentropy: 0.1171 - sparse_categorical_accuracy: 0.9663 - scaled_adversarial_loss: 0.0276\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0944 - sparse_categorical_crossentropy: 0.0758 - sparse_categorical_accuracy: 0.9770 - scaled_adversarial_loss: 0.0186\nEpoch 4/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0672 - sparse_categorical_crossentropy: 0.0536 - sparse_categorical_accuracy: 0.9840 - scaled_adversarial_loss: 0.0137\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.0532 - sparse_categorical_crossentropy: 0.0421 - sparse_categorical_accuracy: 0.9876 - scaled_adversarial_loss: 0.0111\n\n313/313 [==============================] - 1s 2ms/step - loss: 0.0940 - sparse_categorical_crossentropy: 0.0751 - sparse_categorical_accuracy: 0.9761 - scaled_adversarial_loss: 0.0189\n\n***[0.09399436414241791,\n 0.07509651780128479,\n 0.9761000275611877,\n 0.018897896632552147]***Y_pred_test=adv_model.predict({'feature': x_test, 'label': y_test})\nY_pred_test.shape***(10000, 10)***\n```", "```py\n# 1: Importsfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom kymatio.keras import Scattering2D\n# Above, we import the Scattering2D class from the kymatio.keras package.# 2: Model definitioninputs = Input(shape=(28, 28))\nx = Scattering2D(J=3, L=8)(inputs)\nx = Flatten()(x)\nx_out = Dense(10, activation='softmax')(x)\nmodel_kymatio = Model(inputs, x_out)\nprint(model_kymatio.summary())# 3: Compile and trainmodel_kymatio.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])# We then train the model_kymatio using model_kymatio.fit on a subset of the MNIST data.\nmodel_kymatio.fit(x_train[:10000], y_train[:10000], epochs=15,\n          batch_size=64, validation_split=0.2)\n# Finally, we evaluate the model_kymatio on the held-out test data.model_kymatio.evaluate(x_test, y_test)Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 28, 28)]          0         \n_________________________________________________________________\nscattering2d (Scattering2D)  (None, 217, 3, 3)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1953)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                19540     \n=================================================================\nTotal params: 19,540\nTrainable params: 19,540\nNon-trainable params: 0\n_________________________________________________________________\n\n313/313 [==============================] - 36s 114ms/step - loss: 0.6448 - accuracy: 0.9285***[0.6448228359222412, 0.9284999966621399]***\n```", "```py\nimport larq as lq\n# MODEL DEFINITION (All quantized layers except the first will use the same options)kwargs = dict(input_quantizer=\"ste_sign\",\n              kernel_quantizer=\"ste_sign\",\n              kernel_constraint=\"weight_clip\")model_bnn = tf.keras.models.Sequential()# In the first layer we only quantize the weights and not the input\nmodel_bnn.add(lq.layers.QuantConv2D(32, (3, 3),\n                                kernel_quantizer=\"ste_sign\",\n                                kernel_constraint=\"weight_clip\",\n                                use_bias=False,\n                                input_shape=(28, 28, 1)))\nmodel_bnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\nmodel_bnn.add(tf.keras.layers.BatchNormalization(scale=False))model_bnn.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\nmodel_bnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\nmodel_bnn.add(tf.keras.layers.BatchNormalization(scale=False))model_bnn.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\nmodel_bnn.add(tf.keras.layers.BatchNormalization(scale=False))\nmodel_bnn.add(tf.keras.layers.Flatten())model_bnn.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\nmodel_bnn.add(tf.keras.layers.BatchNormalization(scale=False))\nmodel_bnn.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\nmodel_bnn.add(tf.keras.layers.BatchNormalization(scale=False))\nmodel_bnn.add(tf.keras.layers.Activation(\"softmax\"))# MODEL DEFINITON AND TRAINING print(lq.models.summary(model_bnn))\nmodel_bnn.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])x_train_bnn = x_train.reshape((60000, 28, 28, 1))\nx_test_bnn = x_test.reshape((10000, 28, 28, 1))\nmodel_bnn.fit(x_train_bnn,y_train, batch_size=64, epochs=6)test_loss, test_acc = model_bnn.evaluate(x_test_bnn, y_test)\nprint(f\"Test accuracy {test_acc * 100:.2f} %\")\n+sequential_1 summary--------------------------+\n| Total params                      93.6 k     |\n| Trainable params                  93.1 k     |\n| Non-trainable params              468        |\n| Model size                        13.19 KiB  |\n| Model size (8-bit FP weights)     11.82 KiB  |\n| Float-32 Equivalent               365.45 KiB |\n| Compression Ratio of Memory       0.04       |\n| Number of MACs                    2.79 M     |\n| Ratio of MACs that are binarized  0.9303     |\n+----------------------------------------------+\n***None\n313/313 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.9831\nTest accuracy 98.31 %***Y_pred_bnn = model_bnn.predict(x_test_bnn)\ny_pred_bnn=np.argmax(Y_pred_bnn,axis=1)\n(y_pred_bnn==y_test).mean()***0.9831***import tensorflow_datasets as tfds\nimport larq_zoo as lqz\nfrom urllib.request import urlopen\nfrom PIL import Image\n#####################################img_path = \"https://raw.githubusercontent.com/larq/zoo/master/tests/fixtures/elephant.jpg\"with urlopen(img_path) as f:\n    img = Image.open(f).resize((224, 224))x = tf.keras.preprocessing.image.img_to_array(img)\nx = lqz.preprocess_input(x)\nx = np.expand_dims(x, axis=0)\nmodel = lqz.sota.QuickNet(weights=\"imagenet\")\npreds = model.predict(x)\npred_dec=lqz.decode_predictions(preds, top=5)[0]\nprint(f'Top-5 predictions: {pred_dec}')#####################################pred_dec=lqz.decode_predictions(preds, top=5)[0]\nplt.imshow(img)\nplt.title(f'Top prediction:\\n {pred_dec[0]}');***Top-5 predictions: [('n02504458', 'African_elephant', 0.7053231), ('n01871265', 'tusker', 0.2933379), ('n02504013', 'Indian_elephant', 0.001338586), ('n02408429', 'water_buffalo', 7.938418e-08), ('n01704323', 'triceratops', 7.2361296e-08)]***\n```", "```py\n# In case you also want to try the scaling-binning calibration: #!pip3 install git+https://github.com/p-lambda/verified_calibration.git # PyPi--> Kaputfrom netcal.scaling import TemperatureScaling\nimport matplotlib.pyplot as plt\n\n### Initialize and transform\n\ntemperature = TemperatureScaling()\ntemperature.fit(Y_pred_test, y_test)\ncalibrated = temperature.transform(Y_pred_test)\n### Visualization\n\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,4))\naxes[0].matshow(Y_pred_test.T,aspect='auto', cmap='jet')\naxes[0].set_title(\"Original Uncalibrated softmax\")\naxes[0].set_xlabel(\"Test image index (10k images)\")\naxes[0].set_ylabel(\"Class index\")\n# axes[0].set_xticks([])\naxes[1].matshow(calibrated.T,aspect='auto', cmap='jet')\naxes[1].set_title(\"T-scaled softmax\")\naxes[1].set_xlabel(\"Test image index (10k images)\")\n# axes[1].set_xticks([])\nplt.tight_layout()\nplt.show()\n```", "```py\ny_pred_nsl=np.argmax(Y_pred_test,axis=1)\nind_correct=np.where(y_pred_nsl==y_test)[0]\nind_wrong=np.where(y_pred_nsl!=y_test)[0]plt.figure(figsize=(10,4))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  ind_i=ind_correct[i]\n  plt.imshow(x_test[ind_i],cmap='gray_r')\n  class_pred_i=np.argmax(Y_pred_test[ind_i,:])\n  softmax_uncalib_i=str(np.round(Y_pred_test[ind_i,class_pred_i],3))\n  softmax_calib_i=str(np.round(calibrated[ind_i,class_pred_i],3))\n  plt.title(f'{class_pred_i} | {softmax_uncalib_i} | {softmax_calib_i}')\nplt.tight_layout()\nplt.suptitle('Correct predictions \\n Class | Uncalibrated |  Calibrated');\n#############################################\nplt.figure(figsize=(10,4))\nfor i in range(5):\n  plt.subplot(1,5,i+1)\n  ind_i=ind_wrong[i]\n  plt.imshow(x_test[ind_i],cmap='gray_r')\n  class_pred_i=np.argmax(Y_pred_test[ind_i,:])\n  softmax_uncalib_i=str(np.round(Y_pred_test[ind_i,class_pred_i],3))\n  softmax_calib_i=str(np.round(calibrated[ind_i,class_pred_i],3))\n  plt.title(f'{class_pred_i} | {softmax_uncalib_i} | {softmax_calib_i}')\nplt.tight_layout()\nplt.suptitle('Wrong predictions \\n Class | Uncalibrated |  Calibrated');\n```", "```py\nfrom netcal.presentation import ReliabilityDiagram\nn_bins = 10\ndiagram = ReliabilityDiagram(n_bins)\ndiagram.plot(Y_pred_test, y_test)  # visualize miscalibration of uncalibrated\n```", "```py\n# Helper function to plot the accuracies\ndef bar_plt2(acc_1,acc_2,label_1='Legacy classifier',label_2='New classifier',X_LABELS=['default'],Category_x='Dataset'):\n  # set width of bar\n\n  if(X_LABELS==['default']):\n    X_LABELS=list(string.ascii_uppercase[0:len(acc_1)])\n  barWidth = 0.25\n\n  # Set position of bar on X axis\n  r1 = np.arange(len(acc_1))\n  r2 = [x + barWidth for x in r1]\n\n  # Make the plot\n  plt.bar(r1, acc_1, color='#7f6d5f', width=barWidth, edgecolor='white', label=label_1)\n  plt.bar(r2, acc_2, color='#557f2d', width=barWidth, edgecolor='white', label=label_2)\n\n  # Add xticks on the middle of the group bars\n  plt.xlabel(Category_x, fontweight='bold')\n  plt.xticks([r + barWidth for r in range(len(acc_1))],X_LABELS)\n  plt.title('Accuracy comparison of the two classifiers') \n\n  # Create legend & Show graphic\n  plt.legend()\n  plt.show()\n  return Noneimport string\nfrom baycomp import *\n# First, let us generate two synthetic classifier accuracy vectors across 10 hypothetical datasets.\n# Accuracies obtained by a legacy classifier\nclassifier_legacy_acc=np.random.randint(80,85,size=(10))\nmean_legacy=np.mean(classifier_legacy_acc)\n# Accuracies obtained by a new-proposed classifier\nclassifier_new_acc=np.random.randint(80,87,size=(10))\nmean_new=np.mean(classifier_new_acc)\nprint(f'The mean accuracies of the two classifiers are: {mean_legacy} and {mean_new}')\n\nbar_plt2(classifier_legacy_acc,classifier_new_acc)The mean accuracies of the two classifiers are: 82.0 and 81.8\n```", "```py\nprint('$p_{left}, p_{rope},p_{right}$ using the two_on_multiple function: ')\nprint(two_on_multiple(classifier_legacy_acc, classifier_new_acc, rope=1))\n\n# With some additional arguments, the function can also plot the posterior distribution from \n# which these probabilities came.\n# Tests are packed into test classes. \n# The above call is equivalent to\n\nprint('$p_{left}, p_{rope},p_{right}$ using the SignedRankTest.probs function: ')\nprint(SignedRankTest.probs(classifier_legacy_acc, classifier_new_acc, rope=1))\n\n# and to get a plot, we call\n\nprint(SignedRankTest.plot(classifier_legacy_acc, classifier_new_acc, rope=1, names=(\"Legacy-SRT\", \"New-SRT\")))\n\n# To switch to another test, use another class:\nSignTest.probs(classifier_legacy_acc, classifier_new_acc, rope=1)\n# Finally, we can construct and query sampled posterior distributions.\n\nposterior = SignedRankTest(classifier_legacy_acc, classifier_new_acc, rope=1)\nprint(posterior.probs())\nposterior.plot(names=(\"legacy-Post\", \"new-Post\"))$p_{left}, p_{rope},p_{right}$ using the two_on_multiple function: \n(0.28222, 0.4604, 0.25738)\n$p_{left}, p_{rope},p_{right}$ using the SignedRankTest.probs function: \n\n***(0.28056, 0.46356, 0.25588)***\n######################################################\nacc_bnn=np.zeros(10)\nacc_nsl=np.zeros(10)\nfor c in range(10):\n  mask_c=y_test==c\n  acc_bnn[c]= (y_pred_bnn[mask_c]==c).mean()\n  acc_nsl[c]= (y_pred_nsl[mask_c]==c).mean()\n\nbar_plt2(acc_nsl,acc_bnn,label_1='NSL',label_2='BNN',X_LABELS=list(np.arange(10).astype(str)),Category_x='MNIST digit classes')\nposterior = SignedRankTest(acc_nsl, acc_bnn, rope=0.005)\nprint(posterior.probs())\nposterior.plot(names=(\"NSL\", \"BNN\"))\n***(0.0, 0.2846, 0.7154)***\n```", "```py\nfrom pyeer.eer_info import get_eer_stats\nfrom pyeer.report import generate_eer_report, export_error_rates\nfrom pyeer.plot import plot_eer_stats\n\n# Gather up all the 'Genuine scores' and the 'impostor scores'\n\ngscores_abod=y_test_proba_abod[y_test_ood==0,0]\niscores_abod=y_test_proba_abod[y_test_ood==1,0]\n\ngscores_knn=y_test_proba_knn[y_test_ood==0,0]\niscores_knn=y_test_proba_knn[y_test_ood==1,0]\n\n# Calculating stats for classifier A\nstats_abod = get_eer_stats(gscores_abod, iscores_abod)\n\n# Calculating stats for classifier B\nstats_knn = get_eer_stats(gscores_knn, iscores_knn)\nprint(f'EER-KNN = {stats_knn.eer}, EER-ABOD = {stats_abod.eer}')\nplot_eer_stats([stats_abod, stats_knn], ['ABOD', 'KNN'])##############################\nimport matplotlib.image as mpimg\nimg1 = mpimg.imread('DET.png')\nimg2 = mpimg.imread('ROC.png')\n\nplt.figure(figsize=(9,4))\nplt.subplot(121)\nplt.imshow(img1)\n\nplt.subplot(122)\nplt.imshow(img2)\nplt.show()EER-KNN = 0.0, EER-ABOD = 0.008333333333333333\n```", "```py\nfrom pyod.models.abod import ABOD\nfrom pyod.models.knn import KNN   # kNN detector\nfrom pyod.utils.data import generate_data\nfrom pyod.utils.data import evaluate_print\nfrom pyod.utils.example import visualize\n# Generate sample data with pyod.utils.data.generate_data():contamination = 0.4  # percentage of outliers\nn_train = 200  # number of training points\nn_test = 100  # number of testing pointsX_train_ood, y_train_ood, X_test_ood, y_test_ood = generate_data(n_train=n_train, n_test=n_test, contamination=contamination)\n##### 1: ABOD\nclf_name_1 = 'ABOD'\nclf_abod = ABOD(method=\"fast\") # initialize detector\nclf_abod.fit(X_train_ood)y_train_pred_abod = clf_abod.predict(X_train_ood) # binary labels\ny_test_pred_abod = clf_abod.predict(X_test_ood) # binary labelsy_test_scores_abod = clf_abod.decision_function(X_test_ood) # raw outlier scores\ny_test_proba_abod = clf_abod.predict_proba(X_test_ood) # outlier probabilityevaluate_print(\"ABOD\", y_test_ood, y_test_scores_abod) # performance evaluation####### 2 : KNN\nclf_knn = KNN() # initialize detector\nclf_knn.fit(X_train_ood)y_train_pred_knn = clf_knn.predict(X_train_ood) # binary labels\ny_test_pred_knn = clf_knn.predict(X_test_ood) # binary labelsy_test_scores_knn = clf_knn.decision_function(X_test_ood) # raw outlier scores\ny_test_proba_knn = clf_knn.predict_proba(X_test_ood) # outlier probabilityevaluate_print(\"KNN\", y_test_ood, y_test_scores_knn) # performance evaluationABOD ROC:0.9992, precision @ rank n:0.975\nKNN ROC:1.0, precision @ rank n:1.0\n```", "```py\n# ABOD Performance\nvisualize(\"ABOD\", X_train_ood, y_train_ood, X_test_ood, y_test_ood, y_train_pred_abod,\n          y_test_pred_abod, show_figure=True, save_figure=False)\n# KNN Performance;\nvisualize(\"KNN\", X_train_ood, y_train_ood, X_test_ood, y_test_ood, y_train_pred_knn,\n          y_test_pred_knn, show_figure=True, save_figure=False)\n```", "```py\nfrom hyppo.ksample import KSample\nsamp_in_train= X_train_ood[y_train_ood==0]\nsamp_out_train= X_train_ood[y_train_ood==1]\n\nsamp_in_test= X_test_ood[y_test_ood==0]\nsamp_out_test= X_test_ood[y_test_ood==1]\n\nstat_in_out, pvalue_in_out = KSample(\"Dcorr\").test(samp_in_train, samp_out_test)\nprint(f'In-train v/s Out-test \\n Energy test statistic: {stat_in_out}. Energy p-value: {pvalue_in_out}')\n\nstat_out_in, pvalue_out_in = KSample(\"Dcorr\").test(samp_in_test, samp_out_train)\nprint(f'In-test v/s Out-train \\n Energy test statistic: {stat_out_in}. Energy p-value: {pvalue_out_in}')\n\nstat_in_in, pvalue_in_in = KSample(\"Dcorr\").test(samp_in_train, samp_in_test)\nprint(f'In-train v/s In-test \\n Energy test statistic: {stat_in_in}. Energy p-value: {pvalue_in_in}')\n\nstat_out_out, pvalue_out_out = KSample(\"Dcorr\").test(samp_out_train, samp_out_test)\nprint(f'Out-train v/s Out-test \\n Energy test statistic: {stat_out_out}. Energy p-value: {pvalue_out_out}')In-train v/s Out-test \n Energy test statistic: 0.8626341445137959\\. Energy p-value: 4.357148137679374e-32\nIn-test v/s Out-train \n Energy test statistic: 0.7584832208162725\\. Energy p-value: 4.0495216242247524e-25\nIn-train v/s In-test \n Energy test statistic: -0.005691336487203311\\. Energy p-value: 1.0\nOut-train v/s Out-test \n Energy test statistic: 0.006631965940452427\\. Energy p-value: 0.18021672902891694\n```", "```py\nimport gradio as gr\nimport requests\ninception_net = tf.keras.applications.InceptionV3() # load the model\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  print(inp.shape)\n  inp = inp.reshape((-1, 299, 299, 3))\n  inp = tf.keras.applications.inception_v3.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  return {labels[i]: float(prediction[i]) for i in range(1000)}\n\nimage = gr.inputs.Image(shape=(299, 299, 3))\nlabel = gr.outputs.Label(num_top_classes=3)\n\ngr.Interface(fn=classify_image, inputs=image, outputs=label, capture_session=True).launch()import gradio as gr\nimport requests\n\n# EXAMPLE-1:We use the LARQ trained BNN to launch an interactive UI that facilitates a sktechpad inoput and prediction\ndef classify(image):\n  print(image.shape)\n  prediction = model_bnn.predict(image.reshape((-1,28,28,1))).tolist()[0]\n  return {str(i): prediction[i] for i in range(10)}\n\nsketchpad = gr.inputs.Sketchpad()\nlabel = gr.outputs.Label(num_top_classes=3)\ngr.Interface(fn=classify, inputs=sketchpad, outputs=label, capture_session=True).launch()# EXAMPLE-2:Image-classifcation with InceptionNet-V3inception_net = tf.keras.applications.InceptionV3() # load the model\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  print(inp.shape)\n  inp = inp.reshape((-1, 299, 299, 3))\n  inp = tf.keras.applications.inception_v3.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  return {labels[i]: float(prediction[i]) for i in range(1000)}\n\nimage = gr.inputs.Image(shape=(299, 299))\nlabel = gr.outputs.Label(num_top_classes=3)\n\ngr.Interface(fn=classify_image, inputs=image, outputs=label, capture_session=True).launch()\n```"]