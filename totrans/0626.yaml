- en: OpenAI Releases Two Transformer Models that Magically Link Language and Computer
    Vision
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/01/openai-transformer-models-link-language-computer-vision.html](https://www.kdnuggets.com/2021/01/openai-transformer-models-link-language-computer-vision.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![Figure](../Images/96196e8b2230d9c485205752ca1ef5d3.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Source: [https://www.rev.com/blog/what-is-gpt-3-the-new-openai-language-model](https://www.rev.com/blog/what-is-gpt-3-the-new-openai-language-model)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I recently started a new newsletter focus on AI education and**already has
    over 50,000 subscribers**. TheSequence is a no-BS( meaning no hype, no news etc)
    AI-focused newsletter that takes 5 minutes to read. The goal is to keep you up
    to date with machine learning projects, research papers and concepts. Please give
    it a try by subscribing below:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[![Image](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Transformers have been widely considered one of the biggest breakthroughs in
    the last decade of machine learning and OpenAI has been at the center of it. OpenAI’s
    GPT-3 is, arguably, one of the most famous and controversial machine learning
    model ever produced. Trained in billions of parameters, GPT-3 is actively used
    by hundreds of companies to automate different language tasks such as question-answering,
    text generation and others. With that level of success, it’s only natural that
    OpenAI continues exploring different flavors of GPT-3 and transformer models.
    We saw a flavor of that a few days when OpenAI released two new transformer architectures
    that combine image and language tasks in an fun and almost magical way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wait, did I just say that transformers are being used in computer vision tasks?
    Correct! Even tough natural language understanding(NLU) remains the biggest battleground
    for transformer models, there have been incredible progress adapting those architectures
    to computer vision domains. OpenAI’s debut in this area comes in the form of two
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CLIP:** Uses transformers to effectively learn visual concepts from language
    supervision.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**DALL·E:** Uses transformers to generate images from text captions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CLIP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With CLIP, OpenAI tries to address some of the most notable challenges of computer
    vision models. First of all, building training datasets for computer vision is
    very challenging an expensive. While language models can be trained in widely
    available datasets like Wikipedia, there is nothing like that for computer vision.
    Secondly, most computer vision models are highly specialized on a single task
    and can rarely adapt to a new task.
  prefs: []
  type: TYPE_NORMAL
- en: CLIP is a transformer architecture trained on an image dataset using language
    supervision. CLIP uses an image encoder and a text decoder to predict which images
    are paired with a given text in a dataset. That behavior is then used to train
    a zero-shot classifier that can be adapted to several image classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/34f4971f6252af8ebbcdc916865cb70f.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://openai.com/blog/clip/](https://openai.com/blog/clip/)
  prefs: []
  type: TYPE_NORMAL
- en: The result of a model that can learn complex visual concepts while maintaining
    a an efficient performance. The zero-shot approach allow CLIP to be adapted to
    different datasets without major changes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/b5a61f8e32459f622f8b5d646a1cc6c2.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://openai.com/blog/clip/](https://openai.com/blog/clip/)
  prefs: []
  type: TYPE_NORMAL
- en: '**DALL·E**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OpenAI’s DALL·E is a GPT-3 based model that can generate images from text descriptions.
    The concept is to combine transformers and generative models to adapt to complex
    image generation scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: DALL·E receives both text and images as an input dataset containing around 1280
    tokens(256 for the text and 1024 for the image). The model is based on a simple
    decoder architecture trained to using maximum likelihood to generate all of the
    tokens, one after another. DALL·E also includes an attention mask that allows
    to relate text and images.
  prefs: []
  type: TYPE_NORMAL
- en: The use of transformer architectures results in a generative model that can
    generate images from highly complex sentences . Take a look at some of the examples
    below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c8670d47e9a8b99abcdbee3b85d0d99f.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://openai.com/blog/dall-e/#fn1](https://openai.com/blog/dall-e/#fn1)
  prefs: []
  type: TYPE_NORMAL
- en: Both DALL·E and CLIP represent major advancements in multi-task transformer
    models and certainly important milestones for the computer vision space. We are
    likely to see major implementations of these models soon.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://jrodthoughts.medium.com/openai-releases-two-transformer-models-that-magically-link-language-and-computer-vision-d755a83843a3).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to Incorporate Tabular Data with HuggingFace Transformers](/2020/11/tabular-data-huggingface-transformers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Compute Goes Brrr: Revisiting Sutton’s Bitter Lesson for AI](/2020/11/revisiting-sutton-bitter-lesson-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Must-read NLP and Deep Learning articles for Data Scientists](/2020/08/must-read-nlp-deep-learning-articles.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fine-Tuning OpenAI Language Models with Noisily Labeled Data](https://www.kdnuggets.com/2023/04/finetuning-openai-language-models-noisily-labeled-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
