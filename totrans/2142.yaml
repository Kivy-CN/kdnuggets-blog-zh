- en: How to Make Large Language Models Play Nice with Your Software Using LangChain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/036f2f1921d5d651c1a5c147edef3126.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) like OpenAI’s GPT-3, Google’s BERT, and Meta’s
    LLaMA are revolutionizing various sectors with their ability to generate a wide
    array of text?—?from marketing copy and data science scripts to poetry.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Even though ChatGPT’s intuitive interface has managed to be in most people's
    devices today, there’s still a vast landscape of untapped potential for using
    LLMs in diverse software integrations.
  prefs: []
  type: TYPE_NORMAL
- en: The main problem?
  prefs: []
  type: TYPE_NORMAL
- en: Most applications require more fluid and native communication with LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: And this is precisely where LangChain kicks in!
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in Generative AI and LLMs, this tutorial is tailor-made
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: So… let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: What are LLMs?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just in case you have been living within a cave and haven’t gotten any news
    lately, I’ll briefly explain Large Language Models or LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: An LLM is a sophisticated artificial intelligence system built to mimic human-like
    textual understanding and generation. By training on enormous data sets, these
    models discern intricate patterns, grasp linguistic subtleties, and produce coherent
    outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wonder how to interact with these AI-powered models, there are two main
    ways to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: The most common and direct way is talking or chatting with the model. It involves
    crafting a prompt, sending it to the AI-powered model, and getting a text-based
    output as a response.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another method is converting text into numerical arrays. This process involves
    composing a prompt for the AI and receiving a numerical array in return. What
    is commonly known as an “embedding”. It has experienced a recent surge in Vector
    Databases and semantic search.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And it is precisely these two main problems that LangChain tries to address.
    If you are interested in the main problems of interacting with LLMs, you can check
    this article [here](/6-problems-of-llms-that-langchain-is-trying-to-assess).
  prefs: []
  type: TYPE_NORMAL
- en: LangChain and its basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangChain is an open-source framework built around LLMs. It brings to the table
    an arsenal of tools, components, and interfaces that streamline the architecture
    of LLM-driven applications.
  prefs: []
  type: TYPE_NORMAL
- en: With LangChain, engaging with language models, interlinking diverse components,
    and incorporating assets like APIs and databases become a breeze. This intuitive
    framework substantially simplifies the LLM application development journey.
  prefs: []
  type: TYPE_NORMAL
- en: The core idea of Long Chain is that we can connect together different components
    or modules, also known as chains, to create more sophisticated LLM-powered solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some standout features of LangChain:'
  prefs: []
  type: TYPE_NORMAL
- en: Customizable prompt templates to standardize our interactions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chain link components tailored for sophisticated use cases.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Seamless integration with leading language models, including OpenAI’s GPTs and
    those on HuggingFace Hub.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modular components for a mix-and-match approach to assess any specific problem
    or task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/6211aeddcec56539aa3c0d9df71e8a99.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is distinguished by its focus on adaptability and modular design.
  prefs: []
  type: TYPE_NORMAL
- en: The main idea behind LangChain is breaking down the natural language processing
    sequence into individual parts, allowing developers to customize workflows based
    on their requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Such versatility positions LangChain as a prime choice for building AI solutions
    in different situations and industries.
  prefs: []
  type: TYPE_NORMAL
- en: Some of its most important components are…
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/4aba22d72f234ac9cc55081a479a1e3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 1\. LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are fundamental components that leverage vast amounts of training data
    to understand and generate human-like text. They are at the core of many operations
    within LangChain, providing the necessary language processing capabilities to
    analyze, interpret, and respond to text input.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Powering chatbots, generating human-like text for various applications,
    aiding in information retrieval, and performing other language processing'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Prompt templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompts are fundamental for interacting with LLM, and when working on specific
    tasks, their structure tends to be similar. Prompt templates, which are preset
    prompts usable across chains, allow standardization of “prompts” by adding specific
    values. This enhances the adaptability and customization of any LLM.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Standardizing the process of interacting with LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Output Parsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Output parsers are components that take the raw output from a preceding stage
    in the chain and convert it into a structured format. This structured data can
    then be used more effectively in subsequent stages or delivered as a response
    to the end user.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** For instance, in a chatbot, an output parser might take the raw
    text response from a language model, extract key pieces of information, and format
    them into a structured reply.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Components and chains
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In LangChain, each component acts as a module responsible for a particular task
    in the language processing sequence. These components can be connected to form
    *chains* for customized workflows.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Generating sentiment detection and response generator chains in
    a specific chatbot.'
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Memory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory in LangChain refers to a component that provides a storage and retrieval
    mechanism for information within a workflow. This component allows for the temporary
    or persistent storage of data that can be accessed and manipulated by other components
    during the interaction with the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** This is useful in scenarios where data needs to be retained across
    different stages of processing, for example, storing conversation history in a
    chatbot to provide context-aware responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agents are autonomous components capable of taking actions based on the data
    they process. They can interact with other components, external systems, or users,
    to perform specific tasks within a LangChain workflow.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** For instance, an agent might handle user interactions, process incoming
    requests, and coordinate the flow of data through the chain to generate appropriate
    responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Indexes and Retrievers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Indexes and Retrievers play a crucial role in managing and accessing data efficiently.
    Indexes are data structures holding information and metadata from the model’s
    training data. On the other hand, retrievers are mechanisms that interact with
    these indexes to fetch relevant data based on specified criteria and allow the
    model to reply better by supplying relevant context.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** They are instrumental in quickly fetching relevant data or documents
    from a large dataset, which is essential for tasks like information retrieval
    or question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Document Transformers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In LangChain, Document Transformers are specialized components designed to process
    and transform documents in a way that makes them suitable for further analysis
    or processing. These transformations may include tasks such as text normalization,
    feature extraction, or the conversion of text into a different format.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Preparing text data for subsequent processing stages, such as analysis
    by machine learning models or indexing for efficient retrieval.'
  prefs: []
  type: TYPE_NORMAL
- en: 9\. Embedding Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: They are used to convert text data into numerical vectors in a high-dimensional
    space. These models capture semantic relationships between words and phrases,
    enabling a machine-readable representation. They form the foundation for various
    downstream Natural Language Processing (NLP) tasks within the LangChain ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Facilitating semantic searches, similarity comparisons, and other
    machine-learning tasks by providing a numerical representation of text.'
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Vector stores
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Type of database system that specializes to store and search information via
    embeddings, essentially analyzing numerical representations of text-like data.
    VectorStore serves as a storage facility for these embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Allowing efficient search based on semantic similarity.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting it up and first examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installing it using PIP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing we have to do is make sure we have LangChain installed in our
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Environment setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Utilizing LangChain typically means integrating with diverse model providers,
    data stores, APIs, among other components. And as you already know, like any integration,
    supplying the relevant and correct API keys is crucial for LangChain's operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine we want to use our OpenAI API. We can easily accomplish this in two
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up key as an environment variable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If you choose not to establish an environment variable, you have the option
    to provide the key directly through the openai_api_key named parameter when initiating
    the OpenAI LLM class:'
  prefs: []
  type: TYPE_NORMAL
- en: Directly set up the key in the relevant class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: LangChain in action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Switching between LLMs becomes straightforward
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LangChain provides an LLM class that allows us to interact with different language
    model providers, such as OpenAI and Hugging Face.
  prefs: []
  type: TYPE_NORMAL
- en: It is quite easy to get started with any LLM, as the most basic and easiest-to-implement
    functionality of any LLM is just generating text.
  prefs: []
  type: TYPE_NORMAL
- en: However, asking the very same prompt to different LLMs at once is not so easy.
  prefs: []
  type: TYPE_NORMAL
- en: This is where LangChain kicks in…
  prefs: []
  type: TYPE_NORMAL
- en: Getting back to the easiest functionality of any LLM, we can easily build an
    application with LangChain that gets a string prompt and returns the output of
    our designated LLM..
  prefs: []
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: We can simply use the same prompt and get the response of two different models
    within few lines of code!
  prefs: []
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: Impressive… right?
  prefs: []
  type: TYPE_NORMAL
- en: Giving structure to our prompts with prompt templates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A common issue with Language Models (LLMs) is their inability to escalate complex
    applications. LangChain addresses this by offering a solution to streamline the
    process of creating prompts, which is often more intricate than just defining
    a task as it requires outlining the AI's persona and ensuring factual accuracy.
    A significant part of this involves repetitive boilerplate text. LangChain alleviates
    this by offering prompt templates, which auto-include boilerplate text in new
    prompts, thus simplifying prompt creation and ensuring consistency across different
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: Getting structured responses with output parsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In chat-based interactions, the model's output is merely text. Yet, within software
    applications, having a structured output is preferable as it allows for further
    programming actions. For instance, when generating a dataset, receiving the response
    in a specific format such as CSV or JSON is desired. Assuming a prompt can be
    crafted to elicit a consistent and suitably formatted response from the AI, there's
    a need for tools to manage this output. LangChain caters to this requirement by
    offering output parser tools to handle and utilize the structured output effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Code by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can go check the whole code on my [GitHub](https://github.com/rfeers/LangChain/blob/main/1_Main_Basics_of_LangChain.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not long ago, the advanced capabilities of ChatGPT left us in awe. Yet, the
    technological environment is ever-changing, and now tools like LangChain are at
    our fingertips, allowing us to craft outstanding prototypes from our personal
    computers in just a few hours.
  prefs: []
  type: TYPE_NORMAL
- en: LangChain, a freely available Python platform, provides a means for users to
    develop applications anchored by LLMs (Language Model Models). This platform delivers
    a flexible interface to a variety of foundational models, streamlining prompt
    handling and acting as a nexus for elements like prompt templates, more LLMs,
    external information, and other resources via agents, as of the current documentation.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine chatbots, digital assistants, language translation tools, and sentiment
    analysis utilities; all these LLM-enabled applications come to life with LangChain.
    Developers utilize this platform to craft custom-tailored language model solutions
    addressing distinct requirements.
  prefs: []
  type: TYPE_NORMAL
- en: As the horizon of natural language processing expands, and its adoption deepens,
    the realm of its applications seems boundless.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[More Free Courses on Large Language Models](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn About Large Language Models](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are Large Language Models and How Do They Work?](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
