- en: 5 Simple Steps to Automate Data Cleaning with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 自动化数据清理的 5 个简单步骤
- en: 原文：[https://www.kdnuggets.com/5-simple-steps-to-automate-data-cleaning-with-python](https://www.kdnuggets.com/5-simple-steps-to-automate-data-cleaning-with-python)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/5-simple-steps-to-automate-data-cleaning-with-python](https://www.kdnuggets.com/5-simple-steps-to-automate-data-cleaning-with-python)
- en: '![A 5 Simple Steps Pipeline to Automate Data Cleaning with Python. Boxplot.](../Images/c8de18f3bbe0ef673f18b81f8365a312.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Python 自动化数据清理的 5 个简单步骤管道。箱型图。](../Images/c8de18f3bbe0ef673f18b81f8365a312.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'It is a widely spread fact among Data Scientists that data cleaning makes up
    a big proportion of our working time. However, it is one of the least exciting
    parts as well.  So this leads to a very natural question:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家普遍认为，数据清理占据了我们大量的工作时间。然而，这也是最不令人兴奋的部分之一。因此，这就引出了一个非常自然的问题：
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '*Is there a way to automate this process?*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*是否有办法自动化这个过程？*'
- en: Automating any process is always easier said than done since the steps to perform
    depend mostly on the specific project and goal. But there are always ways to automate,
    at least, some of the parts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化任何过程总是说起来容易做起来难，因为执行步骤大多依赖于具体项目和目标。但总有办法至少自动化其中的一部分。
- en: This article aims to generate a pipeline with some steps to make sure our data
    is clean and ready to be used.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在生成一个管道，包含一些步骤以确保我们的数据干净且准备好使用。
- en: Data Cleaning Process
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理过程
- en: Before proceeding to generate the pipeline, we need to understand what parts
    of the processes can be automated.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成管道之前，我们需要了解哪些部分的过程可以自动化。
- en: Since we want to build a process that can be used for almost any data science
    project, we need to first determine what steps are performed over and over again.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望构建一个几乎可以用于任何数据科学项目的过程，因此我们需要首先确定哪些步骤是反复执行的。
- en: 'So when working with a new data set, we usually ask the following questions:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在处理新的数据集时，我们通常会问以下问题：
- en: What format does the data come in?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据以什么格式存在？
- en: Does the data contain duplicates?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否包含重复项？
- en: Does the  data contain missing values?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否包含缺失值？
- en: What data types does the data contain?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据包含哪些数据类型？
- en: Does the data contain outliers?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否包含异常值？
- en: 'These 5 questions can easily be converted into 5 blocks of code to deal with
    each of the questions:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这 5 个问题可以轻松地转换为 5 个代码块来处理每一个问题：
- en: 1.Data Format
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1. 数据格式
- en: Data can come in different formats, such as JSON, CSV, or even XML. Every format
    requires its own data parser. For instance, pandas provide read_csv for CSV files,
    and read_json for JSON files.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以有不同的格式，例如 JSON、CSV，甚至 XML。每种格式都需要自己特定的数据解析器。例如，pandas 提供 read_csv 处理 CSV
    文件，以及 read_json 处理 JSON 文件。
- en: By identifying the format, you can choose the right tool to begin the cleaning
    process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过识别格式，你可以选择合适的工具来开始清理过程。
- en: We can easily identify the format of the file we are dealing with using the
    path.plaintext function from the os library. Therefore, we can create a function
    that first determines what extension we have, and then applies directly to the
    corresponding parser.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 os 库中的 path.plaintext 函数轻松识别我们处理的文件格式。因此，我们可以创建一个函数，首先确定文件扩展名，然后直接应用于相应的解析器。
- en: 2\. Duplicates
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 重复数据
- en: It happens quite often that some rows of the data contain the same exact values
    as other rows, what we know as duplicates. Duplicated data can skew results and
    lead to inaccurate analyses, which is not good at all.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的某些行往往包含与其他行完全相同的值，即我们所说的重复数据。重复数据可能会扭曲结果，导致分析不准确，这一点非常不好。
- en: This is why we always need to make sure there are no duplicates.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们总是需要确保没有重复项的原因。
- en: Pandas got us covered with the drop_duplicated() method, which erases all duplicated
    rows of a dataframe.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了 `drop_duplicated()` 方法来处理重复数据，该方法可以删除数据框中的所有重复行。
- en: We can create a straightforward function that utilizes this method to remove
    all duplicates. If necessary, we add a columns input variable that adapts the
    function to eliminate duplicates based on a specific list of column names.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个简单的函数，利用此方法来删除所有重复值。如有必要，我们添加一个列输入变量，使函数能够根据特定的列名列表删除重复项。
- en: 3\. Missing Values
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 缺失值
- en: Missing data is a common issue when working with data as well. Depending on
    the nature of your data, we can simply delete the observations containing missing
    values, or we can fill these gaps using methods like forward fill, backward fill,
    or substituting with the mean or median of the column.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据时，缺失数据是一个常见问题。根据数据的性质，我们可以简单地删除包含缺失值的观察数据，或者使用前向填充、后向填充、或用列的均值或中位数填充这些空缺。
- en: Pandas offers us the .fillna() and .dropna() methods to handle these missing
    values effectively.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了 `.fillna()` 和 `.dropna()` 方法来有效处理这些缺失值。
- en: 'The choice of how we handle missing values depends on:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值的选择取决于：
- en: The type of values that are missing
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值的类型
- en: The proportion of missing values relative to the number of total records we
    have.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值相对于我们拥有的总记录数的比例。
- en: Dealing with missing values is a quite complex task to perform - and usually
    one of the most important ones! - you can learn more about it [in the following
    article. ](https://www.kdnuggets.com/2020/06/missing-values-dataset.html)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值是一个相当复杂的任务——通常也是最重要的任务之一！——你可以在[以下文章中了解更多。](https://www.kdnuggets.com/2020/06/missing-values-dataset.html)
- en: 'For our pipeline, we will first check the total number of rows that present
    null values. If only 5% of them or less are affected, we will erase these records.
    In case more rows present missing values, we will check column by column and will
    proceed with either:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的管道，我们将首先检查所有包含空值的行的总数。如果只有 5% 或更少的行受影响，我们将删除这些记录。如果更多行存在缺失值，我们将逐列检查，然后采取以下措施：
- en: Imputing the median of the value.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充该值的中位数。
- en: Generate a warning to further investigate.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成警告以便进一步调查。
- en: In this case, we are assessing the missing values with a hybrid human validation
    process. As you already know, assessing missing values is a crucial task that
    can not be overlooked.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们通过混合人工验证过程来评估缺失值。正如你所知，评估缺失值是一个不能被忽视的重要任务。
- en: When working with regular data types we can proceed to transform the columns
    directly with the pandas .astype() function, so you could actually modify the
    code to generate regular conversations.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理常规数据类型时，我们可以直接使用 pandas 的 `.astype()` 函数来转换列，因此你可以实际修改代码以生成常规对话。
- en: Otherwise, it is usually too risky to assume that a transformation will be performed
    smoothly when working with new data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，通常假设在处理新数据时转换会顺利进行是过于冒险的。
- en: 5\. Dealing with Outliers
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 处理异常值
- en: Outliers can significantly affect the results of your data analysis. Techniques
    to handle outliers include setting thresholds, capping values, or using statistical
    methods like Z-score.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可以显著影响数据分析的结果。处理异常值的技术包括设定阈值、限制值或使用统计方法如 Z 分数。
- en: In order to determine if we have outliers in our dataset, we use a common rule
    and consider any record outside of the following range as an outlier. [Q1 — 1.5
    * IQR , Q3 + 1.5 * IQR]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定数据集中是否存在异常值，我们使用一个常见的规则，将超出以下范围的记录视为异常值。[Q1 — 1.5 * IQR , Q3 + 1.5 * IQR]
- en: Where IQR stands for the interquartile range and Q1 and Q3 are the 1st and the
    3rd quartiles. Below you can observe all the previous concepts displayed in a
    boxplot.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 IQR 代表四分位距，Q1 和 Q3 分别是第一四分位数和第三四分位数。下面你可以看到所有之前的概念在箱线图中的展示。
- en: '![XXX](../Images/ccec7a695870201416f09459b92ed277.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![XXX](../Images/ccec7a695870201416f09459b92ed277.png)'
- en: Image by Author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: To detect the presence of outliers, we can easily define a function that checks
    what columns present values that are out of the previous range and generate a
    warning.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检测异常值的存在，我们可以轻松定义一个函数，检查哪些列中的值超出了先前的范围，并生成警告。
- en: Final Thoughts
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终思考
- en: Data Cleaning is a crucial part of any data project, however, it is usually
    the most boring and time-wasting phase as well. This is why this article effectively
    distills a comprehensive approach into a practical 5-step pipeline for automating
    data cleaning using Python and.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理是任何数据项目中至关重要的一部分，但它通常也是最枯燥和浪费时间的阶段。这就是为什么本文将全面的方法提炼为一个实用的 5 步流程，以 Python
    实现数据清理自动化。
- en: The pipeline is not just about implementing code. It integrates thoughtful decision-making
    criteria that guide the user through handling different data scenarios.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流程不仅仅是实现代码。它整合了深思熟虑的决策标准，指导用户处理不同的数据场景。
- en: This blend of automation with human oversight ensures both efficiency and accuracy,
    making it a robust solution for data scientists aiming to optimize their workflow.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这种将自动化与人工监督相结合的方法确保了效率和准确性，使其成为数据科学家优化工作流程的强大解决方案。
- en: You can go check my whole code in the following [GitHub repo.](https://github.com/rfeers/data-science-portfolio/blob/main/data-analytics/automate-data-cleaning/data_cleaning_automation.ipynb)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下的 [GitHub 仓库](https://github.com/rfeers/data-science-portfolio/blob/main/data-analytics/automate-data-cleaning/data_cleaning_automation.ipynb)查看我完整的代码。
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    是一位来自巴塞罗那的分析工程师。他毕业于物理工程专业，目前在应用于人类移动的数据科学领域工作。他还是一位兼职内容创作者，专注于数据科学和技术。Josep 关注人工智能的所有事物，涵盖了该领域正在爆炸式增长的应用。'
- en: More On This Topic
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Tasks To Automate With Python](https://www.kdnuggets.com/2021/06/5-tasks-automate-python.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个使用 Python 自动化的任务](https://www.kdnuggets.com/2021/06/5-tasks-automate-python.html)'
- en: '[Automate Microsoft Excel and Word Using Python](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
- en: '[Automate the Boring Stuff with GPT-4 and Python](https://www.kdnuggets.com/2023/03/automate-boring-stuff-chatgpt-python.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 GPT-4 和 Python 自动化无聊的工作](https://www.kdnuggets.com/2023/03/automate-boring-stuff-chatgpt-python.html)'
- en: '[Automate Your Codebase with Promptr and GPT](https://www.kdnuggets.com/2023/04/automate-codebase-promptr-gpt.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Promptr 和 GPT 自动化您的代码库](https://www.kdnuggets.com/2023/04/automate-codebase-promptr-gpt.html)'
- en: '[Automate Graphic Design Activity with ChatGPT Canva Plugin](https://www.kdnuggets.com/automate-graphic-design-activity-with-chatgpt-canva-plugin)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 ChatGPT Canva 插件自动化图形设计活动](https://www.kdnuggets.com/automate-graphic-design-activity-with-chatgpt-canva-plugin)'
- en: '[AI-Automated Cybersecurity: What to Automate?](https://www.kdnuggets.com/ai-automated-cybersecurity-what-to-automate)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 自动化网络安全：自动化哪些内容？](https://www.kdnuggets.com/ai-automated-cybersecurity-what-to-automate)'
