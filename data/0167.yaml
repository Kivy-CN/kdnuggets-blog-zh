- en: Fighting AI with AI Fraud Monitoring for Deepfake Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用人工智能进行深度伪造应用的欺诈监控
- en: 原文：[https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)
- en: '![Fighting AI with AI Fraud Monitoring for Deepfake Applications](../Images/de88fdc2cd6873f6246aa1b528950f90.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用人工智能进行深度伪造应用的欺诈监控](../Images/de88fdc2cd6873f6246aa1b528950f90.png)'
- en: Photo by [Tima Miroshnichenko](https://www.pexels.com/photo/a-man-in-black-sweatshirt-with-handcuffs-holding-a-sum-of-cash-6266304/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Tima Miroshnichenko](https://www.pexels.com/photo/a-man-in-black-sweatshirt-with-handcuffs-holding-a-sum-of-cash-6266304/)
    提供
- en: Deepfakes have been a big topic of conversation in the data science community
    for some years now. Back in 2020, the MIT Technology Review [posited that deep
    fakes](/2021/04/deepfakes-mainstream-next.html) had hit their “tipping point for
    mainstream use”.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造在数据科学社区中已经讨论了好几年。早在2020年，MIT科技评论 [认为深度伪造](/2021/04/deepfakes-mainstream-next.html)
    达到了其“主流应用的临界点”。
- en: The data certainly backs that up. The *Wall Street Journal* reported that less
    than 10,000 deepfakes had been found online in 2018\. Those numbers now run into
    the millions, and there are many real-life examples of deep fakes being used both
    to confuse and misinform and to perpetuate financial fraud.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据确实支持了这一点。*华尔街日报* 报道称，2018年在线发现的深度伪造视频不到10,000个。现在这些数字已经达到了数百万，并且有很多实际案例表明，深度伪造被用来混淆和误导，以及进行金融欺诈。
- en: Deepfake techniques are altogether providing cybercriminals with many sophisticated
    options.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Deepfake 技术为网络犯罪分子提供了许多复杂的选项。
- en: They go way beyond the ability to insert the image of a celebrity into promotional
    material for an “unmissable” Bitcoin offer, which – of course – turns out to be
    a scam. Deepfake videos, in particular, are on the radar of fraudsters. They provide
    them with a way to get through automated ID and KYC checks and have proved frighteningly
    effective.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 它们远远超出了将名人形象插入到“不可错过”的比特币优惠宣传材料中的能力，后者——当然——证明是一个骗局。特别是深度伪造视频，已经成为诈骗犯的关注对象。它们为他们提供了一种通过自动化身份验证和KYC检查的方式，并且证明了其恐怖的有效性。
- en: In May 2022, *The Verge* reported that “[liveness tests](https://www.theverge.com/2022/5/18/23092964/deepfake-attack-facial-recognition-liveness-test-banks-sensity-report)”
    used by banks and other institutions to help verify users’ identities can be easily
    fooled by deep fakes. The related study found that 90% of the ID verification
    systems tested were vulnerable.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年5月，*The Verge* 报道称，“[活体检测](https://www.theverge.com/2022/5/18/23092964/deepfake-attack-facial-recognition-liveness-test-banks-sensity-report)”被银行和其他机构用来帮助验证用户身份，但深度伪造技术可以轻易欺骗这些检测。相关研究发现，90%的身份验证系统存在漏洞。
- en: So what’s the answer? Are we entering an era where cybercriminals can easily
    use deep fake technology to outwit the security measures used by financial institutions?
    Will such businesses have to ditch their automated systems and revert to manual,
    human checks?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么答案是什么呢？我们是否正进入一个网络犯罪分子可以轻易利用深度伪造技术来智取金融机构安全措施的时代？这些企业是否必须放弃自动化系统，回归人工检查？
- en: The simple answer is “probably not”. Just as criminals can make use of the surge
    in [AI advancements](/2023/03/downsides-ai-advancement.html), so too can the companies
    they target. Let’s now look at how vulnerable businesses can fight AI with AI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的答案是“可能不会”。正如罪犯可以利用 [人工智能的进步](/2023/03/downsides-ai-advancement.html) 一样，目标公司也可以。现在，让我们来看看脆弱的企业如何用人工智能来对抗人工智能。
- en: How Do Deepfakes Work?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度伪造技术是如何工作的？
- en: 'Deepfakes are produced using a range of artificial intelligence techniques,
    such as:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造是使用一系列人工智能技术生成的，例如：
- en: generative adversarial networks (GANs)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）
- en: encoder/decoder pairs
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器/解码器对
- en: first-order motion models
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一阶运动模型
- en: These techniques may, on the face of it, sound like the exclusive preserve of
    the machine learning community, complete with high barriers to entry and a need
    for expert technical knowledge. However, like other elements of AI, they have
    become considerably more accessible over time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从表面上看，这些技术可能听起来像是机器学习领域的专属，具有高门槛和需要专业技术知识的特点。然而，像人工智能的其他元素一样，随着时间的推移，它们变得更加易于获取。
- en: Low-cost, off-the-shelf tools now allow non-technical users to create deep fakes,
    just as anybody can sign up to OpenAI and test the capabilities of ChatGPT.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 低成本、现成的工具现在允许非技术用户创建深度伪造，就像任何人都可以注册OpenAI并测试ChatGPT的能力一样。
- en: As recently as 2020, the World Economic Forum reported that the cost of producing
    a “[state of the art](https://www.weforum.org/agenda/2021/04/are-we-at-a-tipping-point-on-the-use-of-deepfakes/)”
    deepfake is under $30,000\. But in 2023, Wharton School professor Ethan Mollick
    revealed, via a viral Twitter post, that he had produced a [deep fake video](https://www.oneusefulthing.org/p/a-quick-and-sobering-guide-to-cloning)
    of himself delivering a lecture in under six minutes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 早在2020年，世界经济论坛报告称，制作一个“[最先进](https://www.weforum.org/agenda/2021/04/are-we-at-a-tipping-point-on-the-use-of-deepfakes/)”的深度伪造视频的成本低于30,000美元。但在2023年，沃顿商学院教授伊桑·莫利克通过一条病毒式的Twitter帖子透露，他在不到六分钟的时间内制作了一个[深度伪造视频](https://www.oneusefulthing.org/p/a-quick-and-sobering-guide-to-cloning)，展示了他自己进行讲座的过程。
- en: Mollick’s total spend was $10.99\. He used a service called ElevenLabs to almost
    perfectly mimic his voice, for a cost of $5\. Another service called D-ID, at
    $5.99 per month, generated a video based on only a script and a single photograph.
    He even used ChatGPT to create the script itself.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 莫利克的总花费为10.99美元。他使用了一项名为ElevenLabs的服务来几乎完美地模仿他的声音，费用为5美元。另一项名为D-ID的服务，每月5.99美元，仅凭脚本和一张照片生成了视频。他甚至使用了ChatGPT来创建脚本本身。
- en: 'When deepfakes first began to emerge, a primary focus was on fake political
    videos (and fake pornography). Since then, the world has seen:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当深度伪造技术首次出现时，主要关注点是伪造的政治视频（以及伪造的色情内容）。自那时以来，世界上已经出现了：
- en: BuzzFeedVideos create a deepfake public service announcement “featuring” Barack
    Obama, impersonated by actor Jordon Peele.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BuzzFeedVideos制作了一段深度伪造的公共服务公告，“出演”巴拉克·奥巴马，由演员乔丹·皮尔假扮。
- en: A deep fake YouTube video purporting to show Donald Trump telling a story about
    a reindeer.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一段深度伪造的YouTube视频声称展示了特朗普讲述关于驯鹿的故事。
- en: A deep fake video of Hilary Clinton shown on Saturday Night Live, when she was
    in fact being impersonated by a cast member.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一段在《周六夜现场》上播放的深度伪造视频，显示希拉里·克林顿，实际上她是由一位演员扮演的。
- en: While these examples show the “fun” side of deepfakes, and perhaps provide a
    jolt of reality as to the capabilities of the technology, fraudsters haven’t wasted
    any time in using them for nefarious purposes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些例子展示了深度伪造的“趣味”侧面，并可能提供了一些关于技术能力的现实感受，但诈骗者没有浪费时间，已经将其用于恶意目的。
- en: Real-life examples of fraud, perpetuated using deepfake techniques, are many.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现实生活中使用深度伪造技术实施诈骗的例子很多。
- en: Losses due to deep fake scams range from hundreds of thousands to many millions.
    In 2021, an AI voice cloning scam was used to arrange fraudulent bank transfers
    of $35 million. This was a huge financial payoff that didn’t even *require* the
    use of video.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造诈骗造成的损失从数十万到数百万不等。2021年，一起AI声音克隆诈骗用于安排价值3500万美元的虚假银行转账。这是一笔巨大的财务收益，甚至*不需要*使用视频。
- en: The quality of AI output, especially video, can vary hugely. Some videos are
    obviously fake to humans. But, as stated above, automated systems, such as those
    used by banks and fintech, have proved easily fooled in the past.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: AI输出的质量，特别是视频，可能差异巨大。有些视频对人类来说显然是伪造的。但是，如前所述，过去银行和金融科技等自动化系统已经证明容易受骗。
- en: The balance is likely to shift further as AI capabilities continue to improve.
    A recent development is an incorporation of “counter forensics”, where “targeted
    invisible “noise” is added to deep fakes, in an attempt to fool detection mechanisms.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI能力的不断提升，平衡可能会进一步倾斜。最近的进展是“反取证”的应用，其中在深度伪造中添加“目标隐形噪声”，试图欺骗检测机制。
- en: So what can be done?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 那么可以做些什么呢？
- en: 'Fighting AI with AI: Detecting Deepfake Fraud'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用AI对抗AI：检测深度伪造诈骗
- en: Just as fraudsters seek to use the latest AI technology for financial gain,
    businesses such as tech firms are hard at work finding ways to utilize tech to
    catch criminals.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如诈骗者寻求利用最新的AI技术谋取经济利益一样，科技公司等企业也在努力寻找利用技术抓捕罪犯的方法。
- en: 'Here are a couple of examples of companies using AI to fight the AI:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些公司利用AI来对抗AI的例子：
- en: In late 2022, Intel launched an AI-based tool called “[FakeCatcher](https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-real-time-deepfake-detector.html)”.
    With Intel’s reported reliability rate of 96%, it uses a technology known as photoplethysmography
    (PPG).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 2022 年底，英特尔推出了一款名为 [FakeCatcher](https://www.intel.com/content/www/us/en/newsroom/news/intel-introduces-real-time-deepfake-detector.html)
    的基于 AI 的工具。凭借英特尔报告的96% 的可靠性率，该工具使用了一种称为光电容积描记法（PPG）的技术。
- en: 'The tech makes use of something that’s not present in artificially generated
    videos: blood flow. Trained on legitimate videos, its deep-learning algorithm
    measures the light that’s absorbed or reflected by blood vessels, which change
    color as blood moves around the body.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术利用了在人工生成的视频中不存在的东西：血液流动。经过合法视频训练，其深度学习算法测量血管吸收或反射的光线，血液在体内移动时会改变颜色。
- en: FakeCatcher, part of Intel’s Responsible AI initiative, is described as “the
    world’s first real-time deep fake detector that returns results in milliseconds.”
    It’s an innovative technology that looks for signs that the person shown in a
    video is truly human. It looks for something that’s “right”, rather than analyzing
    data to highlight something that’s “wrong”. This is how it indicates the likelihood
    of a fake.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: FakeCatcher 作为英特尔负责任 AI 项目的一部分，被描述为“全球首个实时深度伪造检测器，能够在毫秒内返回结果。”这是一项创新技术，寻找视频中显示的人是否真正为人类。它寻找的是“正确”的东西，而不是分析数据来突出“错误”的东西。这就是它指示伪造可能性的方式。
- en: 'Meanwhile, University of Buffalo (UB) computer scientists have been working
    on a deepfake detection technology of their own. It uses something that avid PC
    gamers know requires immense processing power to emulate: light.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，布法罗大学（UB）的计算机科学家们一直在开发他们自己的深度伪造检测技术。它利用了那些热衷于 PC 游戏的玩家知道需要巨大处理能力来模拟的东西：光线。
- en: Claimed by UB to be 94% effective on fake photos, the AI tool looks at how light
    reflects in the eyes of the subject. The surface of the cornea acts as a mirror,
    and generates “reflective patterns”.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: UB 宣称其 AI 工具对伪造照片的有效性达到94%，该工具观察被摄者眼睛中的光线反射。角膜的表面像镜子一样反射光线，生成“反射模式”。
- en: The scientists’ study, entitled “Exposing GAN-Generated Faces Using Inconsistent
    Corneal Specular Highlights”, indicates that “GAN synthesized faces can be exposed
    with the inconsistent corneal specular highlights between two eyes”.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家的研究题为“利用不一致的角膜镜面高光揭示 GAN 生成的面孔”，指出“GAN 合成的面孔可以通过两只眼睛之间的不一致角膜镜面高光被揭示出来”。
- en: It suggests that it would be “nontrivial” for AI systems to emulate the genuine
    highlights. PC gamers, who often invest in the latest ray-tracing graphics cards
    in order to experience realistic lighting effects, will instinctively recognize
    the challenges here.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，人工智能系统模拟真实高光将是“非平凡”的。PC 玩家通常投资最新的光线追踪显卡，以体验逼真的光效，他们会本能地认识到这里的挑战。
- en: The Challenges of AI-Based Fraud Detection
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能基础的欺诈检测挑战
- en: Perhaps the greatest fraud detection challenge is the endless “cat and mouse”
    game between fraudsters and those who work to thwart them. It’s highly likely,
    in the wake of announcements such as those above, that people are already working
    on building technologies that can sidestep and beat such detection mechanisms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最大的欺诈检测挑战是欺诈者与试图阻止他们的人员之间无休止的“猫捉老鼠”游戏。很有可能，在如上所述的公告之后，人们已经在致力于开发能够绕过和击败这种检测机制的技术。
- en: It’s also one thing that such mechanisms exist, but another to see them routinely
    integrated into the solutions that businesses use. Earlier, we referred to a statistic
    that suggested 90% of solutions can be “easily fooled”. The likelihood is that
    at least some financial institutions are still using such systems.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 存在这样的机制是一回事，但在业务使用的解决方案中常规集成这些机制则是另一回事。之前我们提到的统计数据表明，90% 的解决方案可以“轻易被欺骗”。很可能至少一些金融机构仍在使用这样的系统。
- en: A wise [fraud monitoring](https://seon.io/resources/guides/fraud-monitoring-and-fraud-alerts/)
    strategy requires companies to look beyond detecting the deep fakes themselves.
    Much can be done *before* a fraudster gets far enough into a system to participate
    in a video-based ID verification or KYC process. Precautions that find a place
    earlier in the process may also involve an element of AI and machine learning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 明智的 [欺诈监控](https://seon.io/resources/guides/fraud-monitoring-and-fraud-alerts/)
    策略要求公司在检测深度伪造本身之外有所作为。在欺诈者进入系统参与基于视频的身份验证或 KYC 过程之前，可以做很多工作。早期过程中的预防措施也可能涉及人工智能和机器学习的元素。
- en: For example, machine learning can be used for both real-time fraud monitoring
    and the creation of rulesets. These can look at historical fraud events, detecting
    patterns that could easily be missed by a human. Transactions deemed to be high
    risk can be rejected outright, or passed for manual review *before even reaching*
    a stage where there may be an ID check – and therefore an opportunity for a fraudster
    to make use of deepfake tech.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，机器学习可以用于实时欺诈监控和创建规则集。这些规则集可以查看历史欺诈事件，检测人类可能容易忽视的模式。被认为高风险的交易可以被直接拒绝，或者在*甚至达到*可能需要身份验证的阶段之前进行人工审查——因此，欺诈者利用深度伪造技术的机会就会减少。
- en: The earlier a system detects a cybercriminal, the better. There’s less chance
    that they can perpetuate a crime and less for the business to spend on further
    checks. Video-based ID checks are costly, even without the incorporation of AI
    technology to detect deep fakes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 系统越早检测到网络犯罪分子越好。这样他们实施犯罪的机会就更少，企业在进一步检查上的支出也会减少。基于视频的身份验证检查成本高，即使没有加入检测深度伪造的人工智能技术。
- en: If fraudsters can be identified before they get that far,  with techniques such
    as digital footprinting, there will be more resources left available to optimize
    the checks of more borderline cases.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能在欺诈者达到那一步之前识别出他们，利用数字足迹等技术，将有更多资源用于优化对更多边缘案件的检查。
- en: The Future of AI in Fraud Detection
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能在欺诈检测中的未来
- en: The very nature of machine learning should dictate that, over time, it becomes
    better at detecting anomalies and fighting fraud. AI-powered systems can learn
    from new patterns and potentially filter out fraudulent transactions at an early
    stage in the process.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的本质应该决定随着时间的推移，它在检测异常和打击欺诈方面会变得更好。人工智能驱动的系统可以从新的模式中学习，并有可能在过程的早期阶段筛选出欺诈交易。
- en: When it comes to deepfakes specifically, the example above gives a particular
    reason for hope. Scientists have found a way to detect the vast majority of deepfakes
    using light reflections. Developments like this represent a considerable step
    forward in fraud prevention and a considerable roadblock for cybercriminals.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 就深度伪造而言，上述例子提供了特别的希望。科学家们已经找到了一种使用光反射检测绝大多数深度伪造的方法。这类发展代表了欺诈预防的重大进展，也是对网络犯罪分子的重大障碍。
- en: In theory, it’s much easier to deploy such detection technology than it is for
    fraudsters to find a way to circumvent it – replicating the behavior of light,
    for example, at speed, and at scale. The “cat and mouse” game seems likely to
    continue eternally, but big tech and big finance have the resources and the deep
    pockets to – in theory at least – stay one small step ahead.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，部署这种检测技术要比欺诈者找到规避它的方法容易得多——例如，复制光的行为，速度快且规模大。这场“猫捉老鼠”的游戏似乎将永无休止，但大科技公司和大金融公司拥有资源和雄厚的资金——至少在理论上——可以保持领先一步。
- en: '**[Jimmy Fong](https://uk.linkedin.com/in/jimmyfong)** is the CCO of SEON and
    brings his in-depth experience of fraud-fighting to assist fraud teams everywhere.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Jimmy Fong](https://uk.linkedin.com/in/jimmyfong)** 是 SEON 的首席商务官，他带来了深厚的反欺诈经验，协助各地的反欺诈团队。'
- en: More On This Topic
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[How Data Science Fuels Fraud Prevention](https://www.kdnuggets.com/2022/09/data-science-fuels-fraud-prevention.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学如何促进欺诈预防](https://www.kdnuggets.com/2022/09/data-science-fuels-fraud-prevention.html)'
- en: '[Top 7 Diffusion-Based Applications with Demos](https://www.kdnuggets.com/2022/10/top-7-diffusionbased-applications-demos.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前 7 名扩散基础应用及演示](https://www.kdnuggets.com/2022/10/top-7-diffusionbased-applications-demos.html)'
- en: '[LangChain 101: Build Your Own GPT-Powered Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LangChain 101：构建你自己的 GPT 驱动应用](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
- en: '[Best Python Tools for Building Generative AI Applications Cheat Sheet](https://www.kdnuggets.com/2023/08/best-python-tools-generative-ai-cheat-sheet.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建生成式 AI 应用程序的最佳 Python 工具备忘单](https://www.kdnuggets.com/2023/08/best-python-tools-generative-ai-cheat-sheet.html)'
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的 5 个应用](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
- en: '[The Range of NLP Applications in the Real World: A Different…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[现实世界中 NLP 应用的范围：一种不同的…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
