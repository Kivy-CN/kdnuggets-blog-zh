- en: 'Must-Know: Why it may be better to have fewer predictors in Machine Learning
    models?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html](https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Editor''s note:** This post was originally included as an answer to a question
    posed in our [17 More Must-Know Data Science Interview Questions and Answers](/2017/02/17-data-science-interview-questions-answers.html)
    series earlier this year. The answer was thorough enough that it was deemed to
    deserve its own dedicated post.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are a few reasons why it might be a better idea to have fewer predictor
    variables rather than having many of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '**Redundancy/Irrelevance:**'
  prefs: []
  type: TYPE_NORMAL
- en: If you are dealing with many predictor variables, then the chances are high
    that there are hidden relationships between some of them, leading to redundancy.
    Unless you identify and handle this redundancy (by selecting only the non-redundant
    predictor variables) in the early phase of data analysis, it can be a huge drag
    on your succeeding steps.
  prefs: []
  type: TYPE_NORMAL
- en: It is also likely that not all predictor variables are having a considerable
    impact on the dependent variable(s). You should make sure that the set of predictor
    variables you select to work on does not have any irrelevant ones – even if you
    know that data model will take care of them by giving them lower significance.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Redundancy and Irrelevance are two different notions –a relevant feature
    can be redundant due to the presence of other relevant feature(s).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overfitting**:'
  prefs: []
  type: TYPE_NORMAL
- en: Even when you have a large number of predictor variables with no relationships
    between any of them, it would still be preferred to work with fewer predictors.
    The data models with large number of predictors (also referred to as complex models)
    often suffer from the problem of overfitting, in which case the data model performs
    great on training data, but performs poorly on test data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Productivity**:'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you have a project where there are a large number of predictors and
    all of them are relevant (i.e. have measurable impact on the dependent variable).
    So, you would obviously want to work with all of them in order to have a data
    model with very high success rate. While this approach may sound very enticing,
    practical considerations (such of amount of data available, storage and compute
    resources, time taken for completion, etc.) make it nearly impossible.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, even when you have a large number of relevant predictor variables, it
    is a good idea to work with fewer predictors (shortlisted through feature selection
    or developed through feature extraction). This is essentially similar to the Pareto
    principle, which states that for many events, roughly 80% of the effects come
    from 20% of the causes.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on those 20% most significant predictor variables will be of great
    help in building data models with considerable success rate in a reasonable time,
    without needing non-practical amount of data or other resources.
  prefs: []
  type: TYPE_NORMAL
- en: '![Training vs complexity](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Training error & test error vs model complexity (Source: Posted on [Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)
    by [Sergul Aydore](https://www.quora.com/profile/Sergül-Aydöre))'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understandability**:'
  prefs: []
  type: TYPE_NORMAL
- en: Models with fewer predictors are way easier to understand and explain. As the
    data science steps will be performed by humans and the results will be presented
    (and hopefully, used) by humans, it is important to consider the comprehensive
    ability of human brain. This is basically a trade-off – you are letting go of
    some potential benefits to your data model’s success rate, while simultaneously
    making your data model easier to understand and optimize.
  prefs: []
  type: TYPE_NORMAL
- en: This factor is particularly important if at the end of your project you need
    to present your results to someone, who is interested in not just high success
    rate, but also in understanding what is happening “under the hood”.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[17 More Must-Know Data Science Interview Questions and Answers](/2017/02/17-data-science-interview-questions-answers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Approaching (Almost) Any Machine Learning Problem](/2016/08/approaching-almost-any-machine-learning-problem.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Identifying Variables That Might Be Better Predictors](/2017/02/schmarzo-variables-better-predictors.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Why Do Machine Learning Models Die In Silence?](https://www.kdnuggets.com/2022/01/machine-learning-models-die-silence.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Does ETL Have to Do with Machine Learning?](https://www.kdnuggets.com/2022/08/etl-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A (Much) Better Approach to Evaluate Your Machine Learning Model](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 13 Skills That Every Data Scientist Should Have](https://www.kdnuggets.com/2022/03/top-13-skills-every-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21 Must-Have Cheat Sheets for Data Science Interviews: Unlocking…](https://www.kdnuggets.com/2022/06/21-cheat-sheets-data-science-interviews.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
