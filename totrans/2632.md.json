["```py\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() #cifar10 dataset\nx_train = x_train / 255.0 #normalizing images\nx_test = x_test / 255.0 \n\n```", "```py\nmodel = Sequential([\n    Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), activation='relu', name='conv_1'),\n    MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n    tf.keras.layers.BatchNormalization(),\n    Flatten(name='flatten'),\n    Dense(units=32, activation='relu', name='dense_1'),\n    tf.keras.layers.Dropout(0.5),\n    Dense(units=10, activation='softmax', name='dense_2')\n])\nmodel.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n```", "```py\nhist = model.fit(x_train,y_train,epochs=5, batch_size=512)\n\n```", "```py\nloss, acc = model.evaluate(x_test, y_test, verbose=0)\nprint(f\"test accuracy {acc*100}\")\n\n```", "```py\nmodel.save('myModel.h5')\n\n```", "```py\nnew_model = tf.keras.models.load_model('my_model.h5') #same file path\n\n```", "```py\nloss, acc = new_model.evaluate(x_test, y_test, verbose=0)\nprint(f\"test accuracy {acc*100}\")\n\n```", "```py\nnewmodel.summary()\n\n```", "```py\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #\n=================================================================\nconv_1 (Conv2D)              (None, 30, 30, 16)        448\n_________________________________________________________________\npool_1 (MaxPooling2D)        (None, 7, 7, 16)          0\n_________________________________________________________________ \nbatch_normalization (BatchNo (None, 7, 7, 16)          64         \n_________________________________________________________________ \nflatten (Flatten)            (None, 784)               0          \n_________________________________________________________________ \ndense_1 (Dense)              (None, 32)                25120      \n_________________________________________________________________ \ndropout (Dropout)            (None, 32)                0          \n_________________________________________________________________ \ndense_2 (Dense)              (None, 10)                330        \n================================================================= \nTotal params: 25,962\nTrainable params: 25,930\nNon-trainable params: 32 \n_________________________________________________________________\n\n```", "```py\nnew_model.save('newmodel')\n\n```", "```py\n!dir newmodel\n\n```", "```py\nother_model = tf.keras.models.load_model('newmodel')\n\n```", "```py\nmodel = Sequential([\n    Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), activation='relu', name='conv_1'),\n    MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n    tf.keras.layers.BatchNormalization(),\n    Flatten(name='flatten'),\n    Dense(units=32, activation='relu', name='dense_1'),\n    tf.keras.layers.Dropout(0.5),\n    Dense(units=10, activation='softmax', name='dense_2')\n])\nmodel.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n```", "```py\nmodel.fit(x_train,y_train,epochs=5, batch_size=512)\n\n```", "```py\npath = 'weights_folder/my_weights'\nmodel.save_weights(path)\n\n```", "```py\nmodel_checkpoint_path: \"my_weights\"\nall_model_checkpoint_paths: \"my_weights\"\n\n```", "```py\nmodel.load_weights(path)\n\n```", "```py\nmodel.save_weights('my_weights.h5')\n\n```"]