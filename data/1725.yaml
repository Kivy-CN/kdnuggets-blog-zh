- en: XGBoost, a Top Machine Learning Method on Kaggle, Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kaggle上的顶级机器学习方法，XGBoost解释
- en: 原文：[https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html](https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html](https://www.kdnuggets.com/2017/10/xgboost-top-machine-learning-method-kaggle-explained.html)
- en: '![XGBoost](../Images/cd6c6f40e9b8754536de6a0b3bd3a202.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![XGBoost](../Images/cd6c6f40e9b8754536de6a0b3bd3a202.png)'
- en: '*What is XGBoost?*'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*什么是XGBoost？*'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速迈入网络安全职业生涯的快车道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 在IT方面支持您的组织'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: XGBoost has become a widely used and really popular tool among Kaggle competitors
    and Data Scientists in industry, as it has been battle tested for production on
    large-scale problems. It is a highly flexible and versatile tool that can work
    through most regression, classification and ranking problems as well as user-built
    objective functions. As an open-source software, it is easily accessible and it
    may be used through different platforms and interfaces. The amazing portability
    and compatibility of the system permits its usage on all three Windows, Linux
    and OS X. It also supports training on distributed cloud platforms like AWS, Azure,
    GCE among others and it is easily connected to large-scale cloud dataflow systems
    such as Flink and Spark. Although it was built and initially used in the Command
    Line Interface (CLI) by its creator (Tianqi Chen), it can also be loaded and used
    in various languages and interfaces such as Python, C++, R, Julia, Scala and Java.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost已经成为Kaggle竞争者和工业界数据科学家中广泛使用且非常受欢迎的工具，因为它经过生产大规模问题的测试。它是一个高度灵活且通用的工具，可以解决大多数回归、分类和排序问题，以及用户构建的目标函数。作为一个开源软件，它易于访问，并且可以通过不同的平台和接口使用。该系统的惊人的可移植性和兼容性允许在Windows、Linux和OS
    X三个系统上使用。它还支持在AWS、Azure、GCE等分布式云平台上进行培训，并可以轻松连接到大规模云数据流系统，如Flink和Spark。尽管它是由创建者天琪·陈在命令行界面（CLI）中构建和使用的，但它也可以加载和在各种语言和接口中使用，如Python、C++、R、Julia、Scala和Java。
- en: Its name stands for **eXtreme Gradient Boosting**, it was developed by Tianqi
    Chen and now is part of a wider collection of open-source libraries developed
    by the Distributed Machine Learning Community (DMLC). XGBoost is a scalable and
    accurate implementation of gradient boosting machines and it has proven to push
    the limits of computing power for boosted trees algorithms as it was built and
    developed for the sole purpose of model performance and computational speed. Specifically,
    it was engineered to exploit every bit of memory and hardware resources for tree
    boosting algorithms.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 它的名称意味着**极端梯度提升**，它由天琪·陈开发，并且现在成为由分布式机器学习社区（DMLC）开发的更广泛的开源库集合的一部分。XGBoost是一种可扩展且准确的梯度提升机实现，它已经证明在提升树算法的计算能力方面推动了极限，因为它是为模型性能和计算速度而构建和开发的。具体而言，它被设计用于充分利用内存和硬件资源来进行树提升算法。
- en: The implementation of XGBoost offers several advanced features for model tuning,
    computing environments and algorithm enhancement. It is capable of performing
    the three main forms of gradient boosting (Gradient Boosting (GB), Stochastic
    GB and Regularized GB) and it is robust enough to support fine tuning and addition
    of regularization parameters. According to Tianqi Chen, the latter is what makes
    it superior and different to other libraries.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost的实现具有多种高级功能，用于模型调优、计算环境和算法增强。它能够执行三种主要形式的梯度提升（梯度提升（GB）、随机GB和正则化GB），并且具备足够强大的能力来支持精细调整和添加正则化参数。天琪·陈表示，后者是使其优越和不同于其他库的原因。
- en: “…xgboost used a more regularized model formalization to control over-fitting,
    which gives it better performance.”- Tianqi Chen on [Quora](https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting)
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “...xgboost 使用了更加正规化的模型形式化来控制过拟合，从而使其具有更好的性能。”- Tianqi Chen 在 [Quora](https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting)
- en: System-wise, the library’s portability and flexibility allow the use of a wide
    variety of computing environments like parallelization for tree construction across
    several CPU cores; distributed computing for large models; Out-of-Core computing;
    and Cache Optimization to improve hardware usage and efficiency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从系统的角度来看，该库的可移植性和灵活性允许在各种计算环境中使用，如树构建的并行化（多个 CPU 核心）、大型模型的分布式计算、外部存储器计算和缓存优化以提高硬件使用率和效率。
- en: The algorithm was developed to efficiently reduce computing time and allocate
    an optimal usage of memory resources. Important features of implementation include
    handling of missing values (Sparse Aware), Block Structure to support parallelization
    in tree construction and the ability to fit and boost on new data added to a trained
    model (Continued Training).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的开发目的是有效地减少计算时间并分配最佳的内存资源使用。实现的重要特性包括处理缺失值（Sparse Aware），块结构以支持树构建的并行化以及对训练模型中添加的新数据进行拟合和提升的能力（Continued
    Training）。
- en: '*Why use XGBoost?*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*为什么使用 XGBoost？*'
- en: As we already mentioned, the key features of this library rely on *model performance
    and execution speed*. A well-structured clear benchmark done by [Szilard Pafka](http://datascience.la/benchmarking-random-forest-implementations/),
    shows how XGBoost outperforms several other well-known implementations of gradient
    tree boosting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经提到的，该库的关键特性依赖于*模型性能和执行速度*。由[Szilard Pafka](http://datascience.la/benchmarking-random-forest-implementations/)进行的一项很好地结构化的清晰基准测试显示，XGBoost
    优于其他几种知名的梯度树提升实现。
- en: '![xgboost benchmarks](../Images/b7b2c95f91556bd75215178b20aacc52.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![xgboost 基准测试](../Images/b7b2c95f91556bd75215178b20aacc52.png)'
- en: This comparison in Figure 1 helps us grasp the power of the tool and see how
    well balanced its benefits are, i.e., it does not seem to sacrifice speed over
    accuracy or vice versa. It starts to become clear why more Kagglers are using
    it every day, it is a semi-perfect equilibrium of both performance and time-efficiency.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过图 1 中的比较，我们可以了解到这个工具的强大之处，并且看到它的益处是平衡的，即在速度和准确性之间没有偏向。这就开始清楚了为什么更多的 Kagglers
    每天都在使用它，它是性能和时间效率的半完美平衡。
- en: '*How does it work?*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*它是如何工作的？*'
- en: Before moving on to the details of the algorithm, let’s set some basic definitions
    to make our life easier and get an intuitive and complete understanding of this
    popular tool.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入算法的细节之前，让我们先设置一些基本定义，让我们的工作更加简单，并获得对这个流行工具的直观和全面的理解。
- en: First, let’s clarify the concept of boosting. This is an ensemble method that
    seeks to create a strong classifier (model) based on “weak” classifiers. In this
    context, weak and strong refer to a measure of how correlated are the learners
    to the actual target variable. By adding models on top of each other iteratively,
    the errors of the previous model are corrected by the next predictor, until the
    training data is accurately predicted or reproduced by the model. If you want
    to dig into boosting a bit more, check out information about a popular implementation
    called AdaBoost (Adaptive Boosting) [here](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们澄清 boosting 的概念。这是一种集成方法，旨在基于“弱”分类器创建一个强分类器（模型）。在这个背景下，弱和强指的是学习者与实际目标变量的相关程度。通过迭代地将模型叠加在一起，上一个模型的错误会被下一个预测器进行修正，直到将训练数据准确地预测或重现为止。如果你想更深入地了解
    boosting，请查看一个名为 AdaBoost（自适应增强）的流行实现的信息[在这里](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)。
- en: Now, gradient boosting also comprises an ensemble method that sequentially adds
    predictors and corrects previous models. However, instead of assigning different
    weights to the classifiers after every iteration, this method fits the new model
    to new residuals of the previous prediction and then minimizes the loss when adding
    the latest prediction. So, in the end, you are updating your model using gradient
    descent and hence the name, gradient boosting. This is supported for both regression
    and classification problems. XGBoost specifically, implements this algorithm for
    decision tree boosting with an additional custom regularization term in the objective
    function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，梯度提升还包括一个集成方法，该方法顺序添加预测器并纠正上一模型的错误。但是，该方法在每次迭代后不会为分类器分配不同的权重，而是将新模型拟合到先前预测的新残差上，然后在添加最新预测时最小化损失。因此，最终是通过梯度下降来更新模型，因此被称为梯度提升。该方法适用于回归和分类问题。特别是XGBoost对决策树提升实现了该算法，并在目标函数中添加了额外的自定义正则化项。
- en: '*Getting started with XGBoost*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*入门XGBoost*'
- en: You may download and install XGBoost regardless of which interface you are using.
    To learn more on how to use on each specific platform please follow the instructions
    on this link. You will also find official documentation and tutorials [here](https://xgboost.readthedocs.io/en/latest/get_started/index.html).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪个接口，都可以下载并安装XGBoost。有关如何在每个特定平台上使用的更多信息，请按照此链接上的说明进行操作。您还可以在此处找到官方文档和教程[here](https://xgboost.readthedocs.io/en/latest/get_started/index.html)。
- en: For further information on the source code and examples, you may visit this
    [DMLC repository on Github](https://github.com/dmlc/xgboost).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有关源代码和示例的更多信息，请访问此[Github上的DMLC代码库](https://github.com/dmlc/xgboost)。
- en: 'For more information on boosting and gradient boosting the following resources
    might be helpful:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于提升和梯度提升的更多信息，以下资源可能会有所帮助：
- en: The official published paper by Tianqi Chen is available for download from [Arxiv](https://arxiv.org/abs/1603.02754)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 田琪陈的官方发表的论文可以在[Arxiv](https://arxiv.org/abs/1603.02754)上下载。
- en: The official documentation [XGBoost page](http://xgboost.readthedocs.io/en/latest/model.html)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方文档[XGBoost页面](http://xgboost.readthedocs.io/en/latest/model.html)
- en: '[Here](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf) is
    a great presentation that summarizes the math in a very intuitive way'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[这里](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)是一个很好的演示，以非常直观的方式总结了数学内容'
- en: 'Some [Wikipedia Articles](https://en.wikipedia.org/wiki/Gradient_boosting)
    give a good general idea of the history and the math behind the algorithms:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些[Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)文章可以提供有关算法背后的历史和数学的良好概述：
- en: Thanks to Jason Brownlee for the inspiration of this post, more resources on
    Boosting and XGBoost are available on [his post](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Jason Brownlee对本文的灵感，有关提升和XGBoost的更多资源，请参阅[他的文章](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/)。
- en: '**Related:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关文章：**'
- en: '[Lessons Learned From Benchmarking Fast Machine Learning Algorithms](/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从基准测试快速机器学习算法中学到的教训](/2017/08/lessons-benchmarking-fast-machine-learning-algorithms.html)'
- en: '[A Simple XGBoost Tutorial Using the Iris Dataset](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用鸢尾花数据集的简单XGBoost教程](/2017/03/simple-xgboost-tutorial-iris-dataset.html)'
- en: '[XGBoost: Implementing the Winningest Kaggle Algorithm in Spark and Flink](/2016/03/xgboost-implementing-winningest-kaggle-algorithm-spark-flink.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost: 在Spark和Flink中实现最成功的Kaggle算法](/2016/03/xgboost-implementing-winningest-kaggle-algorithm-spark-flink.html)'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多关于此主题的内容
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，寻找目标以停止学习](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败案例的分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功的数据科学家的五个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 为初创企业打造的理想编程语言的特点](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
