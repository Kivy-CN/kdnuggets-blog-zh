- en: 'Making Predictions: A Beginner’s Guide to Linear Regression in Python'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测：Python中线性回归的初学者指南
- en: 原文：[https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/19b2a9deec2927d6c17364b07dce8b35.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![预测：Python中线性回归的初学者指南](../Images/19b2a9deec2927d6c17364b07dce8b35.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Linear Regression is the most popular and the first machine learning algorithm
    that a data scientist learns while starting their data science career. It is the
    most important supervised learning algorithm as it sets up the building blocks
    for all the other advanced Machine Learning algorithms. That is why we need to
    learn and understand this algorithm very clearly.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是数据科学家在开始数据科学职业生涯时学习的最受欢迎且最早的机器学习算法。它是最重要的监督学习算法，因为它为所有其他高级机器学习算法奠定了基础。这就是为什么我们需要非常清楚地学习和理解这个算法的原因。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this article, we will cover Linear Regression from scratch, its mathematical
    & geometric intuition, and its Python implementation. The only prerequisite is
    your willingness to learn and the basic knowledge of Python syntax. Let’s get
    started.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将从头开始介绍线性回归、其数学和几何直觉，以及其Python实现。唯一的前提是你有学习的愿望和基本的Python语法知识。让我们开始吧。
- en: What is Linear Regression?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是线性回归？
- en: Linear Regression is a [Supervised Machine Learning](https://www.javatpoint.com/supervised-machine-learning)
    algorithm that is used to solve Regression problems. Regression models are used
    to predict a continuous output based on some other factors. E.g., Predicting the
    next month’s stock price of an organization by considering the profit margins,
    total market cap, yearly growth, etc. Linear Regression can also be used in applications
    like predicting the weather, stock prices, sales targets, etc.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一种[监督式机器学习](https://www.javatpoint.com/supervised-machine-learning)算法，用于解决回归问题。回归模型用于根据一些其他因素预测连续输出。例如，通过考虑利润率、总市值、年度增长等来预测下个月的股票价格。线性回归还可以用于预测天气、股票价格、销售目标等应用。
- en: As the name suggests, Linear Regression, it develops a linear relationship between
    two variables. The algorithm finds the best straight line (`y=mx+c`) that can
    predict the dependent variable(y) based on the independent variables(x). The predicted
    variable is called the dependent or target variable, and the variables used to
    predict are called the independent variables or features. If only one independent
    variable is used, then it is called Univariate Linear Regression. Otherwise, it
    is called Multivariate Linear Regression.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，线性回归，它在两个变量之间建立了线性关系。该算法找到最佳的直线（`y=mx+c`），可以根据自变量(x)预测因变量(y)。被预测的变量称为因变量或目标变量，而用于预测的变量称为自变量或特征。如果只使用一个自变量，则称为单变量线性回归。否则，称为多变量线性回归。
- en: To simplify this article, we will only take one independent variable(x) so that
    we can easily visualize it on a 2D plane. In the next section, we will discuss
    its mathematical intuition.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化本文，我们将仅考虑一个自变量(x)，以便我们可以在二维平面上轻松可视化。在接下来的部分，我们将讨论它的数学直觉。
- en: Mathematical Intuition
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数学直觉
- en: Now we will understand Linear Regression’s geometry and its mathematics. Suppose
    we have a set of sample pairs of X and Y values,
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将深入理解线性回归的几何和数学。如果我们有一组 X 和 Y 值的样本对，
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/dcd0e4441bd19099e5d371bf93cd1983.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![预测指南：Python 中线性回归的初学者指南](../Images/dcd0e4441bd19099e5d371bf93cd1983.png)'
- en: We have to use these values to learn a function so that if we give it an unknown
    (x), it can predict a (y) based on the learnings. In regression, many functions
    can be used for prediction, but the linear function is the simplest among all.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须使用这些值来学习一个函数，以便如果我们给它一个未知的 (x)，它可以根据学习结果预测一个 (y)。在回归中，可以使用许多函数进行预测，但线性函数是所有函数中最简单的。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/94f7082744b5dfb894054fec9bacea2d.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![预测指南：Python 中线性回归的初学者指南](../Images/94f7082744b5dfb894054fec9bacea2d.png)'
- en: Fig.1 Sample Data Points | Image by Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1 样本数据点 | 作者提供的图片
- en: The main aim of this algorithm is to find the best-fit line among these data
    points, as indicated in the above figure, which gives the least residual error.
    The residual error is the difference between predicted and actual value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的主要目的是在这些数据点中找到最佳拟合线，如上图所示，从而得到最小的残差误差。残差误差是预测值与实际值之间的差异。
- en: Assumptions for Linear Regression
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归的假设
- en: Before moving forward, we need to discuss some assumptions of Linear Regression
    that we need to be taken care of to get accurate predictions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们需要讨论线性回归的一些假设，以确保得到准确的预测。
- en: '**Linearity:** Linearity means that the independent and dependent variables
    must follow a linear relationship. Otherwise, it will be challenging to obtain
    a straight line. Also, the data points must be independent of each other, i.e.
    the data of one observation does not depend on the data of another observation.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**线性关系：** 线性关系意味着独立变量和因变量必须遵循线性关系。否则，将难以获得一条直线。此外，数据点必须彼此独立，即一个观察的数据不依赖于另一个观察的数据。'
- en: '**Homoscedasticity:** It states that the variance of the residual errors must
    be constant. It means that the variance of the error terms should be constant
    and does not change even if the values of the independent variable change. Also,
    the errors in the model must follow a Normal Distribution.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同方差性：** 这意味着残差误差的方差必须是恒定的。这意味着误差项的方差应该是恒定的，即使独立变量的值变化也不应改变。此外，模型中的误差必须遵循正态分布。'
- en: '**No Multicollinearity:** Multicollinearity means there is a correlation between
    the independent variables. So in Linear Regression, the independent variables
    must not be correlated with each other.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无多重共线性：** 多重共线性意味着独立变量之间存在相关性。因此，在线性回归中，独立变量之间不能存在相关性。'
- en: Hypothesis Function
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设函数
- en: We will hypothesise that a linear relationship will exist between our dependent
    variable(Y) and the independent variable(X). We can represent the linear relationship
    as follows.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将假设因变量 (Y) 和独立变量 (X) 之间存在线性关系。我们可以如下表示线性关系。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/78df40dbe8fbf16f51f3c6c37aab6045.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![预测指南：Python 中线性回归的初学者指南](../Images/78df40dbe8fbf16f51f3c6c37aab6045.png)'
- en: We can observe that the straight line depends on the parameters Θ0 and Θ1\.
    So to get the best-fit line, we need to tune or adjust these parameters. These
    are also called the weights of the model. And to calculate these values, we will
    use the loss function, also known as the cost function. It calculates the [**Mean
    Squared Error**](https://en.wikipedia.org/wiki/Mean_squared_error) between the
    predicted and actual values. Our goal is to minimize this cost function. The values
    of Θ0 and Θ1, in which the cost function is minimized, will form our best-fit
    line. The cost function is represented by (J)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到，直线依赖于参数 Θ0 和 Θ1。因此，为了得到最佳拟合线，我们需要调整这些参数。这些参数也称为模型的权重。为了计算这些值，我们将使用损失函数，也称为成本函数。它计算预测值与实际值之间的[**均方误差**](https://en.wikipedia.org/wiki/Mean_squared_error)。我们的目标是最小化这个成本函数。Θ0
    和 Θ1 的值，使得成本函数最小化，将形成我们的最佳拟合线。成本函数用 (J) 表示。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/e299133c6521fedec85816679743769b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![预测指南：Python 中线性回归的初学者指南](../Images/e299133c6521fedec85816679743769b.png)'
- en: Where,
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: N is the total number of samples
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: N 是样本的总数
- en: The squared error function is chosen to handle the negative values (i.e. if
    the predicted value is less than the actual value). Also, the function is divided
    by 2 to ease the differentiation process.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 选择平方误差函数来处理负值（即预测值低于实际值）。此外，将函数除以 2 以简化微分过程。
- en: Optimizer (Gradient Descent)
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化器（梯度下降）
- en: '[Optimizer](https://www.datarobot.com/blog/introduction-to-optimizers/#:~:text=In%20simpler%20terms%2C%20optimizers%20shape,component%20of%20AI%2FML%20governance.)
    is an algorithm that minimises the MSE by iteratively updating the model''s attributes
    like weights or learning rate to achieve the best-fit line. In Linear Regression,
    the Gradient Descent algorithm is used to minimize the cost function by updating
    the values of Θ0 and Θ1.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[优化器](https://www.datarobot.com/blog/introduction-to-optimizers/#:~:text=In%20simpler%20terms%2C%20optimizers%20shape,component%20of%20AI%2FML%20governance.)
    是一种通过迭代更新模型的属性（如权重或学习率）来最小化均方误差的算法，以实现最佳拟合线。在线性回归中，使用梯度下降算法来通过更新 Θ0 和 Θ1 的值来最小化成本函数。'
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/92281635311f1ae1288145354f90dabb.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![预测制作：Python中线性回归的初学者指南](../Images/92281635311f1ae1288145354f90dabb.png)'
- en: is a hyperparameter which is called the learning rate. It determines how much
    our weights are adjusted with respect to the gradient loss. The value of the learning
    rate should be optimal, not too high or too low. If it is too high, it is difficult
    for the model to converge at the global minimum, and if it is too small, it takes
    longer to converge.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个超参数，称为学习率。它决定了我们的权重相对于梯度损失的调整幅度。学习率的值应当是最佳的，不应过高或过低。如果过高，模型难以收敛到全局最小值；如果过小，则收敛速度较慢。
- en: We will plot a graph between the Cost function and the Weights to find the optimum
    Θ0 and Θ1.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将绘制成本函数与权重之间的图表，以找到最佳的 Θ0 和 Θ1。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/1f2d0e2a7b6588b201cb9ed9bccc2d80.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![预测制作：Python中线性回归的初学者指南](../Images/1f2d0e2a7b6588b201cb9ed9bccc2d80.png)'
- en: Fig.2 Gradient Descent Curve | Image by [GeeksForGeeks](https://www.geeksforgeeks.org/ml-linear-regression/)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2 梯度下降曲线 | 图片由 [GeeksForGeeks](https://www.geeksforgeeks.org/ml-linear-regression/)
    提供
- en: Initially, we will assign random values to Θ0 and Θ1, then calculate the cost
    function and gradient. For a negative gradient(a derivative of the cost function),
    we need to move in the direction of increasing Θ1 in order to reach the minima.
    And for a positive gradient, we must move backwards to reach the global minima.
    We aim to find a point at which the gradient almost equals zero. At this point,
    the value of the cost function is minimum.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 初始时，我们将随机赋值给 Θ0 和 Θ1，然后计算成本函数和梯度。对于负梯度（即成本函数的导数），我们需要朝着增加 Θ1 的方向移动以达到最小值。而对于正梯度，我们必须向回移动以达到全局最小值。我们的目标是找到梯度几乎等于零的点。在这个点上，成本函数的值是最小的。
- en: By now, you have understood the working and mathematics of Linear Regression.
    The following section will see how to implement it from scratch using Python on
    a sample dataset.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经理解了线性回归的工作原理和数学基础。接下来的部分将展示如何在 Python 中使用样本数据集从头开始实现它。
- en: Linear Regression Python Implementation
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归 Python 实现
- en: In this section, we will learn how to implement the Linear Regression algorithm
    from scratch only using fundamental libraries like Numpy, Pandas, and Matplotlib.
    We will implement Univariate Linear Regression, which contains only one dependent
    and one independent variable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将学习如何从头开始实现线性回归算法，仅使用 Numpy、Pandas 和 Matplotlib 等基础库。我们将实现单变量线性回归，其中包含一个因变量和一个自变量。
- en: The dataset we will use contains about 700 pairs of (X, Y) in which X is the
    independent variable and Y is the dependent variable.  Ashish Jangra contributes
    this dataset, and you can download it from [here](https://github.com/AshishJangra27/Machine-Learning-with-Python-GFG/tree/main/Linear%20Regression).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集包含大约 700 对 (X, Y)，其中 X 是自变量，Y 是因变量。此数据集由 Ashish Jangra 提供，你可以从 [这里](https://github.com/AshishJangra27/Machine-Learning-with-Python-GFG/tree/main/Linear%20Regression)
    下载。
- en: Importing Libraries
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入库
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Pandas reads the CSV file and gets the dataframe, while Numpy performs basic
    mathematics and statistics operations. Matplotlib is responsible for plotting
    graphs and curves.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 读取 CSV 文件并获取数据框，而 Numpy 执行基本的数学和统计操作。Matplotlib 负责绘制图表和曲线。
- en: Loading the Dataset
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据集
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First, we will get the dataframe `df` and then drop the null values. After that,
    we will split the data into training and testing `x_train`, `y_train`, `x_test`
    and `y_test`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将获取数据框 `df`，然后删除空值。之后，我们将数据拆分为训练集和测试集 `x_train`、`y_train`、`x_test` 和 `y_test`。
- en: Building Model
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建模型
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have created a class named `LinearRegression()` in which all the required
    functions are built.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`LinearRegression()`的类，其中包含了所有必要的函数。
- en: '`__init__` : It is a constructor and will initialize the weights with random
    values when the object of this class is created.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`__init__` : 这是一个构造函数，当创建这个类的对象时，它会用随机值初始化权重。'
- en: '`forward_propogation()`: This function will find the predicted output using
    the equation of the straight line.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward_propogation()`: 这个函数将使用直线的方程找到预测的输出。'
- en: '`cost()`: This will calculate the residual error associated with the predicted
    values.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`cost()`: 这个函数将计算与预测值相关的残差误差。'
- en: '`finding_derivatives()`: This function calculates the derivative of the weights,
    which can later be used to update the weights for minimum errors.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`finding_derivatives()`: 这个函数计算权重的导数，导数可以用于之后更新权重以减少误差。'
- en: '`train()`: This function will take input from the training data, learning rate
    and the total number of iterations. It will update the weights using back-propagation
    until the specified number of iterations. At last, it will return the weights
    of the best-fit line.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`train()`: 该函数将接受训练数据、学习率和总迭代次数作为输入。它将使用反向传播来更新权重，直到达到指定的迭代次数。最后，它将返回最佳拟合线的权重。'
- en: Training the Model
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Output:**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can observe that in the 1st iteration, the loss is maximum, and in the subsequent
    iterations, this loss decreases and reaches its minimum value at the end of the
    30th iteration.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以观察到在第一次迭代中，损失最大，而在随后的迭代中，这个损失逐渐减少，并在第30次迭代结束时达到最小值。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/81b74de892ac2c4f5b78600ab589b51b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![预测：Python 中线性回归的初学者指南](../Images/81b74de892ac2c4f5b78600ab589b51b.png)'
- en: Fig.3 Finding Best-fit Line | Image by Author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图3 最佳拟合线的寻找 | 图片作者
- en: The above gif indicates how the straight line reaches its best-fit line after
    completing the 30th iteration.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的gif显示了直线如何在完成第30次迭代后达到最佳拟合线。
- en: Final Prediction
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终预测
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is the final equation of the best-fit line.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最佳拟合线的最终方程。
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/9ed8aee0bcefece00a4589665cfb84ae.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![预测：Python 中线性回归的初学者指南](../Images/9ed8aee0bcefece00a4589665cfb84ae.png)'
- en: Fig.4 Actual vs Predicted Output | Image by Author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图4 实际值与预测值的对比 | 图片作者
- en: The above plot shows the best-fit line (orange) and actual values (blue `+`)
    of the test set. You can also tune the hyperparameters, like the learning rate
    or the number of iterations, to increase the accuracy and precision.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图展示了最佳拟合线（橙色）和测试集的实际值（蓝色 `+`）。你还可以调整超参数，例如学习率或迭代次数，以提高准确性和精确度。
- en: Linear Regression (Using Sklearn Library)
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归（使用 Sklearn 库）
- en: In the previous section, we have seen how to implement Univariate Linear Regression
    from scratch. But there is also a built-in library by sklearn that can be directly
    used to implement Linear Regression. Let’s briefly discuss how we can do it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们已经学习了如何从头实现单变量线性回归。但是，sklearn 也提供了一个可以直接用来实现线性回归的内置库。我们来简要讨论一下如何实现。
- en: We will use the same dataset, but if you want, you can use a different one also.
    You need to import two extra libraries as follows.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的数据集，但如果你愿意，也可以使用不同的数据集。你需要额外导入两个库，如下所示。
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Loading Dataset
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据集
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Earlier, we had to perform the train-test split using the numpy library manually.
    But now we can use sklearn's `train_test_split()` to directly divide the data
    into the training and testing sets just by specifying the testing size.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们需要使用 numpy 库手动执行训练集和测试集的划分。但现在我们可以使用 sklearn 的 `train_test_split()` 直接通过指定测试集大小来划分数据。
- en: Model Training and Predictions
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练与预测
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, we don’t have to write the codes for forward propagation, backward propagation,
    cost function, etc. We can now directly use the `LinearRegression()` class and
    train the model on the input data. Below is the plot obtained on the test data
    from the trained model. The results are similar to when we implemented the algorithm
    on our own.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不需要为前向传播、反向传播、成本函数等编写代码。我们可以直接使用`LinearRegression()`类并在输入数据上训练模型。下面是从训练模型的测试数据中获得的图。结果与我们自己实现算法时类似。
- en: '![Making Predictions: A Beginner''s Guide to Linear Regression in Python](../Images/e1d697b491adf1c019ea0b03c5a1671f.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![预测：Python中线性回归的初学者指南](../Images/e1d697b491adf1c019ea0b03c5a1671f.png)'
- en: Fig.5 Sklearn Model Output | Image by Author
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图5 Sklearn模型输出 | 作者提供的图片
- en: References
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: GeeksForGeeks:  [ML Linear Regression](https://www.geeksforgeeks.org/ml-linear-regression/)
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'GeeksForGeeks: [ML线性回归](https://www.geeksforgeeks.org/ml-linear-regression/)'
- en: Wrapping it Up
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Google Colab Link for the Complete Code - [Linear Regression Tutorial Code](https://colab.research.google.com/drive/1MnLDoDRZPezWMAIkD-QtpviUXc5E9iRc?usp=sharing)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码的Google Colab链接 - [线性回归教程代码](https://colab.research.google.com/drive/1MnLDoDRZPezWMAIkD-QtpviUXc5E9iRc?usp=sharing)
- en: In this article, we have thoroughly discussed what Linear Regression is, its
    mathematical intuition and its Python implementation both from scratch and from
    using sklearn’s library. This algorithm is straightforward and intuitive, so it
    helps beginners to lay a solid foundation as well as helps to gain practical coding
    skills to make accurate predictions using Python.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们详细讨论了什么是线性回归，它的数学直觉以及它的Python实现，包括从零开始的实现和使用sklearn库的实现。这个算法直观且易于理解，因此有助于初学者奠定坚实的基础，并帮助获得实际的编码技能，以使用Python做出准确的预测。
- en: Thanks for reading.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
- en: '**[Aryan Garg](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)** is a B.Tech.
    Electrical Engineering student, currently in the final year of his undergrad.
    His interest lies in the field of Web Development and Machine Learning. He have
    pursued this interest and am eager to work more in these directions.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Aryan Garg](https://www.linkedin.com/in/aryan-garg-1bbb791a3/)** 是一名电气工程专业的B.Tech.学生，目前在本科最后一年。他对网页开发和机器学习领域充满兴趣。他已经追求了这一兴趣，并渴望在这些方向上继续工作。'
- en: More On This Topic
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主题更多内容
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较线性回归和逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该使用线性回归模型而不是……的3个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻 22:n12, 3月23日：最佳数据科学书籍…](https://www.kdnuggets.com/2022/n12.html)'
- en: '[Linear Regression for Data Science](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的线性回归](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
- en: '[Linear Regression from Scratch with NumPy](https://www.kdnuggets.com/linear-regression-from-scratch-with-numpy)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用NumPy从零开始进行线性回归](https://www.kdnuggets.com/linear-regression-from-scratch-with-numpy)'
