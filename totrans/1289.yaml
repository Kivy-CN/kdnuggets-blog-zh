- en: 20 Core Data Science Concepts for Beginners
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 20 个核心数据科学概念（初学者）
- en: 原文：[https://www.kdnuggets.com/2020/12/20-core-data-science-concepts-beginners.html](https://www.kdnuggets.com/2020/12/20-core-data-science-concepts-beginners.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/12/20-core-data-science-concepts-beginners.html](https://www.kdnuggets.com/2020/12/20-core-data-science-concepts-beginners.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: 1\. Dataset
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 数据集
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Just as the name implies, data science is a branch of science that applies the
    scientific method to data with the goal of studying the relationships between
    different features and drawing out meaningful conclusions based on these relationships.
    Data is, therefore, the key component in data science. A dataset is a particular
    instance of data that is used for analysis or model building at any given time.
    A dataset comes in different flavors such as numerical data, categorical data,
    text data, image data, voice data, and video data. A dataset could be static (not
    changing) or dynamic (changes with time, for example, stock prices). Moreover,
    a dataset could depend on space as well. For example, temperature data in the
    United States would differ significantly from temperature data in Africa. For
    beginning data science projects, the most popular type of dataset is a dataset
    containing numerical data that is typically stored in a comma-separated values
    (CSV) file format.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名字所示，数据科学是将科学方法应用于数据的一个分支，旨在研究不同特征之间的关系，并基于这些关系得出有意义的结论。因此，数据是数据科学的关键组成部分。数据集是用于分析或模型构建的特定数据实例。数据集有不同的类型，如数值数据、分类数据、文本数据、图像数据、语音数据和视频数据。数据集可以是静态的（不变的）或动态的（随时间变化，例如股票价格）。此外，数据集也可能依赖于空间。例如，美国的温度数据与非洲的温度数据会显著不同。对于初学者的数据科学项目，最受欢迎的数据集类型是包含数值数据的数据集，通常以逗号分隔值（CSV）文件格式存储。
- en: 2\. Data Wrangling
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 数据整理
- en: Data wrangling is the process of converting data from its raw form to a tidy
    form ready for analysis. Data wrangling is an important step in data preprocessing
    and includes several processes like data importing, data cleaning, data structuring,
    string processing, HTML parsing, handling dates and times, handling missing data,
    and text mining.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理是将数据从原始形式转换为适合分析的整洁形式的过程。数据整理是数据预处理中的重要步骤，包括数据导入、数据清洗、数据结构化、字符串处理、HTML 解析、处理日期和时间、处理缺失数据以及文本挖掘等多个过程。
- en: '![](../Images/370960a4f01129c24d0b9fe3960c77cf.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/370960a4f01129c24d0b9fe3960c77cf.png)'
- en: '***Figure 1****: Data wrangling process. Image by Benjamin O. Tayo*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '***图 1****: 数据整理过程。图片由 Benjamin O. Tayo 提供*'
- en: The process of data wrangling is a critical step for any data scientist. Very
    rarely is data easily accessible in a data science project for analysis. It is
    more likely for the data to be in a file, a database, or extracted from documents
    such as web pages, tweets, or PDFs. Knowing how to wrangle and clean data will
    enable you to derive critical insights from your data that would otherwise be
    hidden.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理过程是任何数据科学家关键的一步。在数据科学项目中，数据很少是直接可用的。数据更可能存储在文件、数据库中，或从网页、推文、PDF 等文档中提取。了解如何整理和清洗数据将使你能够从数据中获取本来会被隐藏的重要见解。
- en: 'An example of data wrangling using the college towns dataset can be found here:
    [Tutorial on Data Wrangling](https://medium.com/towards-artificial-intelligence/tutorial-on-data-wrangling-college-towns-dataset-a0e8f8dfb6ae)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大学城数据集进行数据整理的示例可以在此处找到：[数据整理教程](https://medium.com/towards-artificial-intelligence/tutorial-on-data-wrangling-college-towns-dataset-a0e8f8dfb6ae)
- en: 3\. Data Visualization
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 数据可视化
- en: 'Data Visualization is one of the most important branches of data science. It
    is one of the main tools used to analyze and study relationships between different
    variables. Data visualization (e.g., scatter plots, line graphs, bar plots, histograms,
    qqplots, smooth densities, boxplots, pair plots, heat maps, etc.) can be used
    for descriptive analytics. Data visualization is also used in machine learning
    for data preprocessing and analysis, feature selection, model building, model
    testing, and model evaluation. When preparing a data visualization, keep in mind
    that data visualization is more of an **Art** than **Science**. To produce a good
    visualization, you need to put several pieces of code together for an excellent
    end result. A tutorial on data visualization is found here: [Tutorial on data
    visualization using weather dataset](https://medium.com/towards-artificial-intelligence/tutorial-on-data-visualization-weather-data-52efa1bef183)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化是数据科学中最重要的分支之一。它是分析和研究不同变量之间关系的主要工具之一。数据可视化（例如，散点图、折线图、柱状图、直方图、qq图、平滑密度图、箱线图、配对图、热图等）可以用于描述性分析。数据可视化还用于机器学习中的数据预处理和分析、特征选择、模型构建、模型测试和模型评估。在准备数据可视化时，请记住，数据可视化更像是**艺术**而非**科学**。要产生好的可视化效果，你需要将几段代码结合在一起，以获得优秀的最终结果。有关数据可视化的教程，请参见这里：[使用天气数据集的数据可视化教程](https://medium.com/towards-artificial-intelligence/tutorial-on-data-visualization-weather-data-52efa1bef183)
- en: '![](../Images/d5a9b902cba0c4c1c34d1e15917f4670.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5a9b902cba0c4c1c34d1e15917f4670.png)'
- en: '***Figure 2****: Weather data visualization example. Image by Benjamin O. Tayo*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '***图 2****: 天气数据可视化示例。图片由**本杰明·O·泰约**提供*'
- en: 4\. Outliers
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 异常值
- en: An outlier is a data point that is very different from the rest of the dataset.
    Outliers are often just bad data, e.g., due to a malfunctioned sensor; contaminated
    experiments; or human error in recording data. Sometimes, outliers could indicate
    something real such as a malfunction in a system. Outliers are very common and
    are expected in large datasets. One common way to detect outliers in a dataset
    is by using a box plot. **Figure 3** shows a simple regression model for a dataset
    containing lots of outliers. Outliers can significantly degrade the predictive
    power of a machine learning model. A common way to deal with outliers is to simply
    omit the data points. However, removing real data outliers can be too optimistic,
    leading to non-realistic models. Advanced methods for dealing with outliers include
    the RANSAC method.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是指与数据集其他部分非常不同的数据点。异常值通常只是坏数据，例如，由于传感器故障、实验污染或记录数据时的人为错误。有时，异常值可能表明某些真实情况，例如系统中的故障。异常值非常常见，并且在大型数据集中是预期的。检测数据集中异常值的一种常见方法是使用箱线图。**图
    3** 显示了一个包含大量异常值的数据集的简单回归模型。异常值可能会显著降低机器学习模型的预测能力。处理异常值的一种常见方法是简单地省略这些数据点。然而，去除真实数据中的异常值可能过于乐观，从而导致不现实的模型。处理异常值的高级方法包括RANSAC方法。
- en: '![](../Images/e77ae7cae16d7a8038885ce202569865.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e77ae7cae16d7a8038885ce202569865.png)'
- en: '***Figure 3****: Simple regression model using a dataset with outliers. Image
    by Benjamin O. Tayo*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '***图 3****: 使用包含异常值的数据集的简单回归模型。图片由**本杰明·O·泰约**提供*'
- en: 5\. Data Imputation
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 数据插补
- en: Most datasets contain missing values. The easiest way to deal with missing data
    is simply to throw away the data point. However, the removal of samples or dropping
    of entire feature columns is simply not feasible because we might lose too much
    valuable data. In this case, we can use different interpolation techniques to
    estimate the missing values from the other training samples in our dataset. One
    of the most common interpolation techniques is **mean imputation**, where we simply
    replace the missing value with the mean value of the entire feature column. Other
    options for imputing missing values are **median** or most **frequent (mode)**,
    where the latter replaces the missing values with the most frequent values. Whatever
    imputation method you employ in your model, you have to keep in mind that imputation
    is only an approximation, and hence can produce an error in the final model. If
    the data supplied was already preprocessed, you would have to find out how missing
    values were considered. What percentage of the original data was discarded? What
    imputation method was used to estimate missing values?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据集包含缺失值。处理缺失数据的最简单方法是直接丢弃数据点。然而，删除样本或整个特征列是不切实际的，因为这可能会丢失太多有价值的数据。在这种情况下，我们可以使用不同的插值技术来估计数据集中其他训练样本中的缺失值。其中一种最常见的插值技术是**均值填补**，即用整个特征列的均值替换缺失值。其他填补缺失值的方法包括**中位数**或最**频繁值（众数）**，后者用最频繁的值来替换缺失值。无论你在模型中使用哪种填补方法，都必须记住填补仅仅是一种近似方法，因此可能会在最终模型中产生误差。如果提供的数据已经过预处理，你需要了解缺失值是如何处理的。原始数据中丢弃了多少百分比？使用了什么填补方法来估计缺失值？
- en: 6\. Data Scaling
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6\. 数据缩放
- en: Scaling your features will help improve the quality and predictive power of
    your model. For example, suppose you would like to build a model to predict a
    target variable *creditworthiness* based on predictor variables such as *income*
    and *credit score*. Because credit scores range from 0 to 850 while annual income
    could range from $25,000 to $500,000, without scaling your features, the model
    will be biased towards the *income* feature. This means the weight factor associated
    with the *income* parameter will be very small, which will cause the predictive
    model to be predicting *creditworthiness* based only on the *income* parameter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放特征有助于提高模型的质量和预测能力。例如，假设你想建立一个模型来预测目标变量*信用评分*，基于预测变量如*收入*和*信用评分*。由于信用评分的范围从0到850，而年收入可能在$25,000到$500,000之间，如果不对特征进行缩放，模型将会对*收入*特征产生偏倚。这意味着与*收入*参数相关的权重因子将非常小，这会导致预测模型仅基于*收入*参数来预测*信用评分*。
- en: In order to bring features to the same scale, we could decide to use either
    normalization or standardization of features. Most often, we assume data is normally
    distributed and default towards standardization, but that is not always the case.
    It is important that before deciding whether to use either standardization or
    normalization, you first take a look at how your features are statistically distributed.
    If the feature tends to be uniformly distributed, then we may use normalization
    (*MinMaxScale*r). If the feature is approximately Gaussian, then we can use standardization
    (*StandardScaler*). Again, note that whether you employ normalization or standardization,
    these are also approximative methods and are bound to contribute to the overall
    error of the model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将特征缩放到相同的尺度，我们可以选择使用特征的归一化或标准化。通常情况下，我们假设数据是正态分布的，并默认使用标准化，但这并不总是适用。在决定使用标准化还是归一化之前，首先需要查看特征的统计分布情况。如果特征趋向于均匀分布，则可以使用归一化（*MinMaxScaler*）。如果特征大致符合高斯分布，则可以使用标准化（*StandardScaler*）。再次提醒，无论你使用归一化还是标准化，这些方法都是近似的，并且会影响模型的总体误差。
- en: 7\. Principal Component Analysis (PCA)
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7\. 主成分分析（PCA）
- en: 'Large datasets with hundreds or thousands of features often lead to redundancy
    especially when features are correlated with each other. Training a model on a
    high-dimensional dataset having too many features can sometimes lead to overfitting
    (the model captures both real and random effects). In addition, an overly complex
    model having too many features can be hard to interpret. One way to solve the
    problem of redundancy is via feature selection and dimensionality reduction techniques
    such as PCA. Principal Component Analysis (PCA) is a statistical method that is
    used for feature extraction. PCA is used for high-dimensional and correlated data.
    The basic idea of PCA is to transform the original space of features into the
    space of the principal component. A PCA transformation achieves the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有数百或数千个特征的大型数据集通常会导致冗余，特别是当特征之间存在相关性时。在具有过多特征的高维数据集上训练模型有时会导致过拟合（模型捕捉了真实和随机效应）。此外，特征过多的过于复杂的模型可能很难解释。解决冗余问题的一种方法是通过特征选择和降维技术，例如PCA。主成分分析（PCA）是一种用于特征提取的统计方法。PCA用于高维和相关数据。PCA的基本思想是将原始特征空间转换为主成分空间。PCA变换实现了以下目标：
- en: '**a)** Reduce the number of features to be used in the final model by focusing
    only on the components accounting for the majority of the variance in the dataset.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**a)** 通过仅关注数据集中方差占多数的成分，减少最终模型中要使用的特征数量。'
- en: '**b)** Removes the correlation between features.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**b)** 消除特征之间的相关性。'
- en: 'An implementation of PCA can be found at this link: [PCA Using Iris Dataset](https://github.com/bot13956/principal_component_analysis_iris_dataset)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的实现可以在以下链接找到：[使用Iris数据集的PCA](https://github.com/bot13956/principal_component_analysis_iris_dataset)
- en: 8\. Linear Discriminant Analysis (LDA)
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8\. 线性判别分析（LDA）
- en: 'PCA and LDA are two data preprocessing linear transformation techniques that
    are often used for dimensionality reduction to select relevant features that can
    be used in the final machine learning algorithm. PCA is an unsupervised algorithm
    that is used for feature extraction in high-dimensional and correlated data. PCA
    achieves dimensionality reduction by transforming features into orthogonal component
    axes of maximum variance in a dataset. The goal of LDA is to find the feature
    subspace that optimizes class separability and reduce dimensionality (see figure
    below). Hence, LDA is a supervised algorithm. An in-depth description of PCA and
    LDA can be found in this book: Python Machine Learning by Sebastian Raschka, Chapter
    5.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: PCA和LDA是两种数据预处理线性变换技术，通常用于降维，以选择可用于最终机器学习算法的相关特征。PCA是一种无监督算法，用于高维和相关数据中的特征提取。PCA通过将特征转换为数据集中最大方差的正交成分轴来实现降维。LDA的目标是找到优化类别可分性的特征子空间并减少维度（见下图）。因此，LDA是一种有监督算法。关于PCA和LDA的详细描述可以在这本书中找到：Sebastian
    Raschka的《Python机器学习》，第5章。
- en: 'An implementation of LDA can be found at this link: [LDA Using Iris Dataset](https://github.com/bot13956/linear-discriminant-analysis-iris-dataset)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LDA的实现可以在以下链接找到：[使用Iris数据集的LDA](https://github.com/bot13956/linear-discriminant-analysis-iris-dataset)
- en: 9\. Data Partitioning
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9\. 数据划分
- en: 'In machine learning, the dataset is often partitioned into training and testing
    sets. The model is trained on the training dataset and then tested on the testing
    dataset. The testing dataset thus acts as the unseen dataset, which can be used
    to estimate a generalization error (the error expected when the model is applied
    to a real-world dataset after the model has been deployed). In scikit-learn, the
    train/test split estimator can be used to split the dataset as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，数据集通常被划分为训练集和测试集。模型在训练数据集上进行训练，然后在测试数据集上进行测试。因此，测试数据集充当未见数据集，可用于估计泛化误差（即模型部署后应用于真实数据集时的预期误差）。在scikit-learn中，可以使用train/test
    split估计器将数据集划分如下：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, X is the features matrix, and y is the target variable. In this case,
    the testing dataset is set to 30%.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，X是特征矩阵，y是目标变量。在这种情况下，测试数据集设置为30%。
- en: 10\. Supervised Learning
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10\. 有监督学习
- en: 'These are machine learning algorithms that perform learning by studying the
    relationship between the feature variables and the known target variable. Supervised
    learning has two subcategories:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是通过研究特征变量与已知目标变量之间的关系来执行学习的机器学习算法。有监督学习有两个子类别：
- en: '**a) Continuous Target Variables**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**a) 连续目标变量**'
- en: Algorithms for predicting continuous target variables include Linear Regression,
    KNeighbors regression (KNR), and Support Vector Regression (SVR).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 预测连续目标变量的算法包括线性回归、K最近邻回归（KNR）和支持向量回归（SVR）。
- en: 'A tutorial on Linear and KNeighbors Regression is found here: [Tutorial on
    Linear and KNeighbors Regression](https://medium.com/towards-artificial-intelligence/a-comparative-study-of-linear-and-knn-regression-a31955e6263d)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线性回归和K最近邻回归的教程可以在这里找到：[线性回归和KNN回归教程](https://medium.com/towards-artificial-intelligence/a-comparative-study-of-linear-and-knn-regression-a31955e6263d)
- en: '**b) Discrete Target Variables**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**b) 离散目标变量**'
- en: 'Algorithms for predicting discrete target variables include:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 预测离散目标变量的算法包括：
- en: Perceptron classifier
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知机分类器
- en: Logistic Regression classifier
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归分类器
- en: Support Vector Machines (SVM)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）
- en: Decision tree classifier
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树分类器
- en: K-nearest classifier
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K最近邻分类器
- en: Naive Bayes classifier
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器
- en: 11\. Unsupervised Learning
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11\. 无监督学习
- en: In unsupervised learning, we are dealing with unlabeled data or data of unknown
    structure. Using unsupervised learning techniques, we are able to explore the
    structure of our data to extract meaningful information without the guidance of
    a known outcome variable or reward function. K-means clustering is an example
    of an unsupervised learning algorithm.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督学习中，我们处理的是未标记的数据或结构未知的数据。使用无监督学习技术，我们能够探索数据的结构，从而在没有已知结果变量或奖励函数指导的情况下提取有意义的信息。K均值聚类是无监督学习算法的一个例子。
- en: 12\. Reinforcement Learning
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12\. 强化学习
- en: In reinforcement learning, the goal is to develop a system (agent) that improves
    its performance based on interactions with the environment. Since the information
    about the current state of the environment typically also includes a so-called
    reward signal, we can think of reinforcement learning as a field related to supervised
    learning. However, in reinforcement learning, this feedback is not the correct
    ground truth label or value but a measure of how well the action was measured
    by a reward function. Through the interaction with the environment, an agent can
    then use reinforcement learning to learn a series of actions that maximize this
    reward.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，目标是开发一个基于与环境互动来提升性能的系统（代理）。由于当前环境状态的信息通常还包括所谓的奖励信号，我们可以将强化学习视为与监督学习相关的领域。然而，在强化学习中，这种反馈不是正确的真实标签或值，而是由奖励函数衡量行动效果的一个指标。通过与环境的互动，代理可以利用强化学习来学习一系列最大化奖励的动作。
- en: 13\. Model Parameters and Hyperparameters
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13\. 模型参数和超参数
- en: 'In a machine learning model, there are two types of parameters:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习模型中，有两种类型的参数：
- en: '**a) Model Parameters:** These are the parameters in the model that must be
    determined using the training data set. These are the fitted parameters. For example,
    suppose we have a model such as *house price* = *a + b*(age) + c*(size),* to estimate
    the cost of houses based on the age of the house and its size (square foot)*,*
    then *a*, *b*, and *c* will be our model or fitted parameters.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**a) 模型参数：** 这些是在模型中必须通过训练数据集确定的参数。这些是拟合参数。例如，假设我们有一个模型如*房价* = *a + b*(年龄)
    + c*(面积)*，以根据房屋的年龄和面积（平方英尺）来估计房屋的成本，那么*a*、*b*和*c*将是我们的模型或拟合参数。'
- en: '**b) Hyperparameters:** These are adjustable parameters that must be tuned
    to obtain a model with optimal performance. An example of a hyperparameter is
    shown here:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**b) 超参数：** 这些是需要调整的参数，以获得具有最佳性能的模型。以下是一个超参数的例子：'
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It is important that during training, the hyperparameters be tuned to obtain
    the model with the best performance (with the best-fitted parameters).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，超参数的调整对于获得最佳性能（即最优拟合参数）的模型非常重要。
- en: 'A tutorial on model parameters and hyperparameters is found here: [Tutorial
    on model parameters and hyperparameters in machine learning](https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型参数和超参数的教程可以在这里找到：[机器学习中的模型参数和超参数教程](https://towardsdatascience.com/model-parameters-and-hyperparameters-in-machine-learning-what-is-the-difference-702d30970f6)
- en: 14\. Cross-validation
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14\. 交叉验证
- en: Cross-validation is a method of evaluating a machine learning model’s performance
    across random samples of the dataset. This assures that any biases in the dataset
    are captured. Cross-validation can help us to obtain reliable estimates of the
    model’s generalization error, that is, how well the model performs on unseen data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是一种评估机器学习模型在数据集随机样本上的表现的方法。这可以确保捕捉数据集中的任何偏差。交叉验证可以帮助我们获得模型泛化误差的可靠估计，即模型在未见数据上的表现。
- en: In k-fold cross-validation, the dataset is randomly partitioned into training
    and testing sets. The model is trained on the training set and evaluated on the
    testing set. The process is repeated k-times. The average training and testing
    scores are then calculated by averaging over the k-folds.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 k-折交叉验证中，数据集被随机划分为训练集和测试集。模型在训练集上训练，并在测试集上评估。这个过程重复进行 k 次。然后通过在 k 折上取平均来计算平均训练和测试分数。
- en: 'Here is the k-fold cross-validation pseudocode:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 k-折交叉验证的伪代码：
- en: '![](../Images/5e82f8dc996d1e34bde8056967e5183e.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e82f8dc996d1e34bde8056967e5183e.png)'
- en: '***Figure 4****. k-fold cross-validation pseudocode. Image by Benjamin O. Tayo*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '***图 4***。k-折交叉验证伪代码。图片由 Benjamin O. Tayo 提供。'
- en: 'An implementation of cross-validation is found here: [Hands-on cross-validation
    tutorial](https://medium.com/towards-artificial-intelligence/hands-on-k-fold-cross-validation-for-machine-learning-model-evaluation-cruise-ship-dataset-27390d58776d)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的实现可以在这里找到：[实践中的交叉验证教程](https://medium.com/towards-artificial-intelligence/hands-on-k-fold-cross-validation-for-machine-learning-model-evaluation-cruise-ship-dataset-27390d58776d)
- en: 15\. Bias-variance Tradeoff
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 15\. 偏差-方差权衡
- en: 'In statistics and machine learning, the bias-variance tradeoff is the property
    of a set of predictive models whereby models with a lower bias in parameter estimation
    have a higher variance of the parameter estimates across samples and vice versa.
    The bias-variance dilemma or problem is the conflict in trying to simultaneously
    minimize these two sources of error that prevent supervised learning algorithms
    from generalizing beyond their training set:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和机器学习中，偏差-方差权衡是预测模型集的一个特性，其中参数估计偏差较低的模型在样本之间的参数估计方差较高，反之亦然。偏差-方差困境或问题是在尝试同时最小化这两种误差来源时的冲突，这阻碍了监督学习算法在训练集之外的泛化：
- en: The *bias* is an error from erroneous assumptions in the learning algorithm.
    High bias (**overly simple**) can cause an algorithm to miss the relevant relations
    between features and target outputs (**underfitting**).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*偏差*是由于学习算法中的错误假设造成的误差。高偏差（**过于简单**）可能导致算法错过特征与目标输出之间的相关关系（**欠拟合**）。'
- en: The *variance* is an error from sensitivity to small fluctuations in the training
    set. High variance (**overly complex**) can cause an algorithm to model the random
    noise in the training data rather than the intended outputs (**overfitting**).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*方差*是由于对训练集中的小波动的敏感性所引起的误差。高方差（**过于复杂**）可能导致算法对训练数据中的随机噪声建模，而不是预期的输出（**过拟合**）。'
- en: 'It is important to find the right balance between model simplicity and complexity.
    A tutorial on bias-variance tradeoff can be found here: [Tutorial on bias-variance
    tradeoff](https://towardsdatascience.com/simplicity-vs-complexity-in-machine-learning-finding-the-right-balance-c9000d1726fb)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 找到模型简单性和复杂性之间的正确平衡是很重要的。关于偏差-方差权衡的教程可以在这里找到：[偏差-方差权衡教程](https://towardsdatascience.com/simplicity-vs-complexity-in-machine-learning-finding-the-right-balance-c9000d1726fb)
- en: '![](../Images/f2b34efff2ce08c4d9720e0cf6085230.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2b34efff2ce08c4d9720e0cf6085230.png)'
- en: '***Figure 5****. Illustration of bias-variance tradeoff. Image by Benjamin
    O. Tayo*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '***图 5***。偏差-方差权衡的示意图。图片由 Benjamin O. Tayo 提供。'
- en: 16\. Evaluation Metrics
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16\. 评估指标
- en: In machine learning (predictive analytics), there are several metrics that can
    be used for model evaluation. For example, a supervised learning (continuous target)
    model can be evaluated using metrics such as the R2 score, mean square error (MSE),
    or mean absolute error (MAE). Furthermore, a supervised learning (discrete target)
    model, also referred to as a classification model, can be evaluated using metrics
    such as accuracy, precision, recall, f1 score, and the area under ROC curve (AUC).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（预测分析）中，有几种指标可用于模型评估。例如，可以使用 R2 分数、均方误差（MSE）或平均绝对误差（MAE）来评估监督学习（连续目标）模型。此外，也称为分类模型的监督学习（离散目标）模型，可以使用准确率、精确率、召回率、F1
    分数以及 ROC 曲线下面积（AUC）等指标进行评估。
- en: 17\. Uncertainty Quantification
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 17\. 不确定性量化
- en: 'It is important to build machine learning models that will yield unbiased estimates
    of uncertainties in calculated outcomes. Due to the inherent randomness in the
    dataset and model, evaluation parameters such as the R2 score are random variables,
    and thus it is important to estimate the degree of uncertainty in the model. For
    an example of uncertainty quantification, see this article: [Random Error Quantification
    in Machine Learning](https://medium.com/towards-artificial-intelligence/random-error-quantification-in-machine-learning-846f6e78e519)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 建立能够产生无偏估计的机器学习模型非常重要。由于数据集和模型中固有的随机性，评估参数如R2分数是随机变量，因此估计模型的不确定性程度很重要。有关不确定性量化的示例，请参阅此文章：[机器学习中的随机误差量化](https://medium.com/towards-artificial-intelligence/random-error-quantification-in-machine-learning-846f6e78e519)
- en: '![](../Images/f313ebb23503c2cde858c411eae34571.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f313ebb23503c2cde858c411eae34571.png)'
- en: '***Figure 6****. Illustration of fluctuations in R2 score. Image by Benjamin
    O. Tayo*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '***图6****. R2分数波动的示意图。图片来源：Benjamin O. Tayo*'
- en: 18\. Math Concepts
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 18\. 数学概念
- en: '***a) Basic Calculus:*** Most machine learning models are built with a dataset
    having several features or predictors. Hence, familiarity with multivariable calculus
    is extremely important for building a machine learning model. Here are the topics
    you need to be familiar with:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '***a) 基础微积分：*** 大多数机器学习模型是基于具有多个特征或预测变量的数据集构建的。因此，熟悉多变量微积分对于构建机器学习模型极为重要。以下是你需要熟悉的主题：'
- en: '*Functions of several variables; Derivatives and gradients; Step function,
    Sigmoid function, Logit function, ReLU (Rectified Linear Unit) function; Cost
    function; Plotting of functions; Minimum and Maximum values of a function*'
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*多变量函数；导数和梯度；阶跃函数、Sigmoid函数、Logit函数、ReLU（整流线性单元）函数；成本函数；函数绘图；函数的最小值和最大值*'
- en: '***b) Basic Linear Algebra:*** Linear algebra is the most important math skill
    in machine learning. A data set is represented as a matrix. Linear algebra is
    used in data preprocessing, data transformation, dimensionality reduction, and
    model evaluation. Here are the topics you need to be familiar with:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '***b) 基础线性代数：*** 线性代数是机器学习中最重要的数学技能。数据集被表示为矩阵。线性代数用于数据预处理、数据转换、降维和模型评估。以下是你需要熟悉的主题：'
- en: '*Vectors; Norm of a vector; Matrices; Transpose of a matrix; The inverse of
    a matrix; The determinant of a matrix; Trace of a Matrix; Dot product; Eigenvalues;
    Eigenvectors*'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*向量；向量的范数；矩阵；矩阵的转置；矩阵的逆；矩阵的行列式；矩阵的迹；点积；特征值；特征向量*'
- en: '***c) Optimization Methods:*** Most machine learning algorithms perform predictive
    modeling by minimizing an objective function, thereby learning the weights that
    must be applied to the testing data in order to obtain the predicted labels. Here
    are the topics you need to be familiar with:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '***c) 优化方法：*** 大多数机器学习算法通过最小化目标函数来执行预测建模，从而学习应用于测试数据以获得预测标签的权重。以下是你需要熟悉的主题：'
- en: '*Cost function/Objective function; Likelihood function; Error function; Gradient
    Descent Algorithm and its variants (e.g., Stochastic Gradient Descent Algorithm)*'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*成本函数/目标函数；似然函数；误差函数；梯度下降算法及其变体（如随机梯度下降算法）*'
- en: 19\. Statistics and Probability Concepts
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 19\. 统计学和概率概念
- en: 'Statistics and Probability are used for visualization of features, data preprocessing,
    feature transformation, data imputation, dimensionality reduction, feature engineering,
    model evaluation, etc. Here are the topics you need to be familiar with:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和概率用于特征的可视化、数据预处理、特征转换、数据填补、降维、特征工程、模型评估等。以下是你需要熟悉的主题：
- en: '*Mean, Median, Mode, Standard deviation/variance, Correlation coefficient and
    the covariance matrix, Probability distributions (Binomial, Poisson, Normal),
    p-value, Bayes Theorem (Precision, Recall, Positive Predictive Value, Negative
    Predictive Value, Confusion Matrix, ROC Curve), Central Limit Theorem, R_2 score,
    Mean Square Error (MSE), A/B Testing, Monte Carlo Simulation*'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*均值、中位数、众数、标准差/方差、相关系数和协方差矩阵、概率分布（伯努利分布、泊松分布、正态分布）、p值、贝叶斯定理（精准度、召回率、正预测值、负预测值、混淆矩阵、ROC曲线）、中心极限定理、R_2分数、均方误差（MSE）、A/B测试、蒙特卡洛模拟*'
- en: 'Here are some educational resources on Central Limit Theorem and Bayes Theorem:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于中心极限定理和贝叶斯定理的一些教育资源：
- en: '[Illustration of Central Limit Theorem Using Monte-Carlo Simulation](https://towardsdatascience.com/proof-of-central-limit-theorem-using-monte-carlo-simulation-34925a7bc64a)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用蒙特卡洛模拟说明中心极限定理](https://towardsdatascience.com/proof-of-central-limit-theorem-using-monte-carlo-simulation-34925a7bc64a)'
- en: '[Bayes Theorem Explained Using Heights Dataset](https://medium.com/towards-artificial-intelligence/bayes-theorem-explained-66ebf8285fcc)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用身高数据集解释贝叶斯定理](https://medium.com/towards-artificial-intelligence/bayes-theorem-explained-66ebf8285fcc)'
- en: 20\. Productivity Tools
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20\. 生产力工具
- en: 'A typical data analysis project may involve several parts, each including several
    data files and different scripts with code. Keeping all these organized can be
    challenging. Productivity tools help you to keep projects organized and to maintain
    a record of your completed projects. Some essential productivity tools for practicing
    data scientists include tools such as Unix/Linux, git and GitHub, RStudio, and
    Jupyter Notebook. Find out more about productivity tools here: [Productivity Tools
    in Machine Learning](https://medium.com/towards-artificial-intelligence/productivity-tools-for-large-scale-data-science-projects-64810dfbb971)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的数据分析项目可能涉及多个部分，每个部分包括多个数据文件和不同的代码脚本。保持这些内容的组织性可能会很有挑战性。生产力工具可以帮助你保持项目的有序，并记录你完成的项目。一些对数据科学家来说至关重要的生产力工具包括
    Unix/Linux、git 和 GitHub、RStudio 和 Jupyter Notebook 等。了解更多关于生产力工具的信息，请访问：[机器学习中的生产力工具](https://medium.com/towards-artificial-intelligence/productivity-tools-for-large-scale-data-science-projects-64810dfbb971)
- en: '**Related:**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[15 Exciting AI Project Ideas for Beginners](https://www.kdnuggets.com/2020/11/greatlearning-ai-project-ideas-beginners.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15 个令人兴奋的初学者 AI 项目创意](https://www.kdnuggets.com/2020/11/greatlearning-ai-project-ideas-beginners.html)'
- en: '[An Introduction to AI, updated](https://www.kdnuggets.com/2020/10/introduction-ai-updated.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 简介，更新版](https://www.kdnuggets.com/2020/10/introduction-ai-updated.html)'
- en: '[Introduction to Statistics for Data Science](https://www.kdnuggets.com/2020/08/introduction-statistics-data-science.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学统计入门](https://www.kdnuggets.com/2020/08/introduction-statistics-data-science.html)'
- en: More On This Topic
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写清晰的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学，寻找目的，然后再…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为一名出色数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
