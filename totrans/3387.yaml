- en: A Quick Introduction to Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html](https://www.kdnuggets.com/2016/11/quick-introduction-neural-networks.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Ujjwal Karn.**'
  prefs: []
  type: TYPE_NORMAL
- en: An Artificial Neural Network (ANN) is a computational model that is inspired
    by the way biological neural networks in the human brain process information.
    Artificial Neural Networks have generated a lot of excitement in Machine Learning
    research and industry, thanks to many breakthrough results in speech recognition,
    computer vision and text processing. In this blog post we will try to develop
    an understanding of a particular type of Artificial Neural Network called the
    Multi Layer Perceptron.
  prefs: []
  type: TYPE_NORMAL
- en: A Single Neuron
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic unit of computation in a neural network is the **neuron**, often
    called a **node** or **unit**. It receives input from some other nodes, or from
    an external source and computes an output. Each input has an associated **weight**
    (w), which is assigned on the basis of its relative importance to other inputs.
    The node applies a function ***f*** (defined below) to the weighted sum of its
    inputs as shown in Figure 1 below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Screen Shot 2016-08-09 at 3.42.21 AM.png](../Images/087f833f5d2b288a97430ef2a13b9e1c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: a single neuron'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The above network takes numerical inputs **X1** and **X2** and has weights **w1**
    and **w2** associated with those inputs. Additionally, there is another input
    **1** with weight **b** (called the **Bias**) associated with it. We will learn
    more details about role of the bias later.
  prefs: []
  type: TYPE_NORMAL
- en: The output **Y** from the neuron is computed as shown in the Figure 1\. The
    function ***f*** is non-linear and is called the **Activation Function**. The
    purpose of the activation function is to introduce non-linearity into the output
    of a neuron. This is important because most real world data is non linear and
    we want neurons to *learn* thesenon linear representations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every activation function (or *non-linearity*) takes a single number and performs
    a certain fixed mathematical operation on it [2]. There are several activation
    functions you may encounter in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sigmoid:** takes a real-valued input and squashes it to range between 0 and
    1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: σ(x) = 1 / (1 + exp(−x))
  prefs: []
  type: TYPE_NORMAL
- en: '**tanh:** takes a real-valued input and squashes it to the range [-1, 1]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tanh(x) = 2σ(2x) − 1
  prefs: []
  type: TYPE_NORMAL
- en: '**ReLU**: ReLU stands for Rectified Linear Unit. It takes a real-valued input
    and thresholds it at zero (replaces negative values with zero)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: f(x) = max(0, x)
  prefs: []
  type: TYPE_NORMAL
- en: The below figures [2] show each of the above activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screen Shot 2016-08-08 at 11.53.41 AM](../Images/e2a53a976104ff7403495f9f57f16eef.png)Figure
    2: different activation functions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '**Importance of Bias:** The main function of Bias is to provide every node
    with a trainable constant value (in addition to the normal inputs that the node
    receives). See [this link](http://stackoverflow.com/q/2480650/3297280) to learn
    more about the role of bias in a neuron.'
  prefs: []
  type: TYPE_NORMAL
- en: Feedforward Neural Network
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The feedforward neural network was the first and simplest type of artificial
    neural network devised [3]. It contains multiple neurons (nodes) arranged in **layers**.
    Nodes from adjacent layers have **connections** or **edges** between them. All
    these connections have **weights** associated with them.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a feedforward neural network is shown in Figure 3.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screen Shot 2016-08-09 at 4.19.50 AM.png](../Images/0cf754ed44cd5d076cb69756caa4820d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: an example of feedforward neural network'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Quick Data Science Tips and Tricks to Learn SAS](https://www.kdnuggets.com/2022/05/sas-quick-data-science-tips-tricks-learn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Pandas Plotting Functions for Quick Data Visualization](https://www.kdnuggets.com/7-pandas-plotting-functions-for-quick-data-visualization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Quick Overview of Voronoi Diagrams](https://www.kdnuggets.com/2022/11/quick-overview-voronoi-diagrams.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Quick Guide to Find the Right Minds for Annotation](https://www.kdnuggets.com/2022/04/quick-guide-find-right-minds-annotation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
