- en: 'MLOps: Model Monitoring 101'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/01/mlops-model-monitoring-101.html](https://www.kdnuggets.com/2021/01/mlops-model-monitoring-101.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Pronojit Saha](https://www.linkedin.com/in/pronojitsaha/) and [Dr. Arnab
    Bose](https://www.linkedin.com/in/arnab-bose-phd-6369531/), Abzooba**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f8d9392f74429e751b9de21be042b55f.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
- en: '*Fig 1: ML Workflow (Image from [martinfowler.com](https://martinfowler.com/articles/cd4ml.html),
    2019)*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Background**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML models are driving some of the most important decisions for businesses. As
    such it is important that these models remain relevant in the context of the most
    recent data, once deployed into production. A model may go out of context if there
    is data skew i.e. data distribution may have changed in production from what was
    used during training. It may also be that a feature becomes unavailable in production
    data or that the model may no longer be relevant as the real-world environment
    might have changed (e.g. Covid19) or further and more simply, the user behavior
    may have changed. Monitoring the changes in model’s behavior and the characteristics
    of the most recent data used at inference is thus of utmost importance. This ensures
    that the model remains relevant and/or true to the desired performance as promised
    during the model training phase.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: An instance of such a model monitoring framework is illustrated in Fig 2 below.
    The objective is to track models on various metrics, the details of which we will
    get into the next sections. But first, let us understand the motivation of a model
    monitoring framework.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/73fba02de0b349ec15c7ae0b82acf5ba.png)![Figure](../Images/9f1c2f8eb4acec1eb1da64d17b4b6497.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: '*Fig 2: Model Monitoring Framework Illustrated (Image by author)*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '**Motivation**'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Feedback loops play an important role in all aspects of life as well as business.
    Feedback loops are simple to understand: you produce something, measure information
    on the production, and use that information to improve production. It’s a constant
    cycle of monitoring and improvement. Anything that has measurable information
    and room for improvement can incorporate a feedback loop and ML models can certainly
    benefit from them.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: A typical ML workflow includes steps like data ingestion, pre-processing, model
    building & evaluation, and finally deployment. However, this lacks one key aspect
    i.e. feedback. The primary motivation of any “model monitoring” framework thus
    is to create this all-important feedback loop post-deployment back to the model
    building phase (as depicted in Fig 1). This helps the ML model to constantly improve
    itself by **deciding to either update the model or continue with the existing
    model**. To enable this decision the framework should track & report various model
    metrics (details in “Metrics” section later) under two possible scenarios described
    below.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario I:** The training data is available and the framework computes the
    said model metrics both on training data and production (inference) data post-deployment
    and compares to make a decision.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Scenario II:** The training data is not available and the framework computes
    the said model metrics based only on the data that is available post-deployment.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The following table lists the inputs required by the model monitoring framework
    to generate the said metrics, under the two scenarios.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/9c65180cb2a8a1e13ca4f03220fb5695.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Based on which of the two scenarios is applicable, metrics highlighted in the
    next section are computed to decide if a model in production needs an update or
    some other interventions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '**Metrics**'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A proposed model monitoring metrics stack is given in Fig 3 below. It defines
    three broad types of metrics based on the dependency of the metric on data and/or
    ML model. A monitoring framework should ideally consist of one or two metrics
    from all three categories, but if there are tradeoff then one may build up from
    the base i.e. starting with operations metrics and then building up with the maturity
    of the model. Further, operations metrics should be monitored at a more real time
    level or at-least daily where stability and performance can be at a weekly or
    even a larger time frame depending on the domain & business scenario.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/cda4c0db87925dc7e1d256b9175a1896.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: '*Fig 3: Model Monitoring Metrics Stack (Image by author)*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Stability Metrics **— These metrics help us to capture two types of data
    distribution shifts:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: a) **Prior Probability Shift** — Captures the distribution shift of the **predicted
    outputs and/or dependent variable** between either the training data and production
    data (scenario I) or various time frames of the production data (scenario II).
    Examples of these metrics include Population Stability Index (PSI), Divergence
    Index (Concept Shift), Error Statistic (details & definition to follow in next
    article of this series)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: b) **Covariate Shift** — Captures the distribution shift of each **independent
    variable** between either the training data and production data (scenario I) or
    various time frames of the production data (scenario II), as applicable. Examples
    of these metrics include Characteristic Stability Index (CSI) & Novelty Index
    (details & definition to follow in the next article of this series)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: b) **协变量漂移** — 捕捉训练数据和生产数据（情景 I）或生产数据的不同时间框架（情景 II）之间每个**独立变量**的分布变化。这些指标的示例包括特征稳定性指数
    (CSI) 和新颖性指数（详细信息和定义将在本系列下一篇文章中介绍）
- en: '**2\. Performance Metrics **— These metrics help us to detect a **concept shift **in
    data i.e. identify whether the relation between independent & dependent variables
    has changed (e.g. post-COVID the way users purchase during festivals may have
    changed). They do so by examining how good or bad the existing deployed model
    is performing viz-a-viz when it was trained (scenario I) or during a previous
    time frame post-deployment (scenario II). Accordingly, a decision can be taken
    to re-work the deployed model or not. Examples of these metrics include,'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 性能指标** — 这些指标帮助我们检测数据中的**概念漂移**，即识别独立变量和因变量之间的关系是否发生了变化（例如，COVID 后用户在节日期间的购买方式可能发生了变化）。它们通过检查现有部署模型的表现与其训练时（情景
    I）或部署后某一时间段（情景 II）的表现来实现。因此，可以决定是否重新调整部署的模型。这些指标的示例包括：'
- en: a) **Project Metrics** like RMSE, R-Square, etc for regression and accuracy,
    AUC-ROC, etc for classification.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: a) **项目指标**，如回归中的 RMSE、R-Square 等，分类中的准确率、AUC-ROC 等。
- en: 'b) **Gini and KS -Statistics**: A statistical measure of how well the predicted
    probabilities/classes are separated (only for classification models)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: b) **Gini 和 KS 统计量**：一种统计度量，用于评估预测概率/类别的分离程度（仅适用于分类模型）
- en: '**3\. Operations Metrics **— These metrics help us to determine how the deployed
    model is performing from a usage point of view. They are as such independent of
    model type, data & don’t require any inputs as with the above two metrics. Examples
    of these metrics include,'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**3. 操作指标** — 这些指标帮助我们从使用的角度确定已部署模型的性能。它们与模型类型、数据无关，也不需要像上述两个指标那样的输入。这些指标的示例包括：'
- en: '*a. # of time ML API endpoints called in the past*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*a. 过去调用 ML API 端点的次数*'
- en: '*b. Latency when calling ML API endpoints*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*b. 调用 ML API 端点时的延迟*'
- en: '*c. IO/Memory/CPU usage when performing prediction*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*c. 预测时的 IO/内存/CPU 使用情况*'
- en: '*d. System uptime*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*d. 系统正常运行时间*'
- en: '*e. Disk utilization*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*e. 磁盘利用率*'
- en: '**Conclusion**'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Model monitoring within the realm of MLOps has become a necessity for mature
    ML systems. It is quintessential to implement such a framework to ensure consistency
    and robustness of the ML system, as without it ML systems may lose the “trust”
    of the end-user, which could be fatal. As such including and planning for it in
    the overall solution architecture of any ML use case implementation is of utmost
    importance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MLOps 领域内，模型监控已成为成熟 ML 系统的必要条件。实施这样的框架对于确保 ML 系统的一致性和鲁棒性至关重要，因为没有它，ML 系统可能会失去终端用户的“信任”，这可能是致命的。因此，在任何
    ML 用例实现的整体解决方案架构中包含和规划这一点至关重要。
- en: In the next blogs of the series, we will get into more details of the two most
    important model monitoring metric i.e. Stability & Performance metrics and we
    will see how we can use them to build our model monitoring framework.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本系列的下一篇博客中，我们将深入探讨两个最重要的模型监控指标，即稳定性和性能指标，并将了解如何利用这些指标来构建我们的模型监控框架。
- en: '**References**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: D. Sato, A. Wider, C. Windheuser, [Continuous Delivery for Machine Learning](https://martinfowler.com/articles/cd4ml.html#IntroductionAndDefinition) (2019),
    martinflower.com
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: D. Sato, A. Wider, C. Windheuser, [机器学习的持续交付](https://martinfowler.com/articles/cd4ml.html#IntroductionAndDefinition)
    (2019), martinflower.com
- en: M. Stewart, [Understanding Dataset Shift](https://towardsdatascience.com/understanding-dataset-shift-f2a5a262a766) (2019),
    towardsdatascience.com
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: M. Stewart, [理解数据集漂移](https://towardsdatascience.com/understanding-dataset-shift-f2a5a262a766)
    (2019), towardsdatascience.com
- en: '[**Pronojit Saha**](https://www.linkedin.com/in/pronojitsaha/) is an AI practitioner
    with extensive experience in solving business problems, architecting, and building
    end-to-end ML driven products & solutions by leading and facilitating cross-functional
    teams. He is currently the Advanced Analytics Practice Lead at Abzooba, wherein
    apart from project execution he also engages in leading & growing the Practice
    by nurturing talent, building thought leadership, and enabling scalable processes.
    Pronojit has worked in the retail, healthcare, and Industry 4.0 domains. Time
    series analytics and natural language processing are his expertise and he has
    applied these along with other AI methodologies for use cases like price optimization,
    readmission prediction, predictive maintenance, aspect-based sentiment analytics,
    entity recognition, topic modeling, among others.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[**Dr. Arnab Bose**](https://www.linkedin.com/in/arnab-bose-phd-6369531/) is
    Chief Scientific Officer at Abzooba, a data analytics company and an adjunct faculty
    at the University of Chicago where he teaches Machine Learning and Predictive
    Analytics, Machine Learning Operations, Time Series Analysis and Forecasting,
    and Health Analytics in the Master of Science in Analytics program. He is a 20-year
    predictive analytics industry veteran who enjoys using unstructured and structured
    data to forecast and influence behavioral outcomes in healthcare, retail, finance,
    and transportation. His current focus areas include health risk stratification
    and chronic disease management using machine learning, and production deployment
    and monitoring of machine learning models.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[MLOps – “Why is it required?” and “What it is”?](/2020/12/mlops-why-required-what-is.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Model Experiments, Tracking and Registration using MLflow on Databricks](/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Meets Devops: MLOps with Jupyter, Git, and Kubernetes](/2020/08/data-science-meets-devops-mlops-jupyter-git-kubernetes.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Fighting AI with AI Fraud Monitoring for Deepfake Applications](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Managing Model Drift in Production with MLOps](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Monitor Model Performance in the MLOps Pipeline with Python](https://www.kdnuggets.com/2023/05/monitor-model-performance-mlops-pipeline-python.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear Programming 101 for Data Scientists](https://www.kdnuggets.com/2023/02/linear-programming-101-data-scientists.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LangChain 101: Build Your Own GPT-Powered Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prompt Engineering 101: Mastering Effective LLM Communication](https://www.kdnuggets.com/prompt-engineering-101-mastering-effective-llm-communication)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
