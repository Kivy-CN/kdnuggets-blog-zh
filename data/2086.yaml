- en: How to Use Hugging Face’s Datasets Library for Efficient Data Loading
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用 Hugging Face 的数据集库进行高效的数据加载
- en: 原文：[https://www.kdnuggets.com/how-to-use-hugging-faces-datasets-library-for-efficient-data-loading](https://www.kdnuggets.com/how-to-use-hugging-faces-datasets-library-for-efficient-data-loading)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/how-to-use-hugging-faces-datasets-library-for-efficient-data-loading](https://www.kdnuggets.com/how-to-use-hugging-faces-datasets-library-for-efficient-data-loading)
- en: '![How to Use Hugging Face’s Datasets Library for Efficient Data Loading](../Images/181c3f2e2e35e4967f6a643cedcd22f7.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何使用 Hugging Face 的数据集库进行高效的数据加载](../Images/181c3f2e2e35e4967f6a643cedcd22f7.png)'
- en: Image by Editor | Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑 | Midjourney 提供
- en: This tutorial demonstrates how to use Hugging Face's Datasets library for loading
    datasets from different sources with just a few lines of code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程演示如何使用 Hugging Face 的 Datasets 库从不同来源加载数据集，仅需几行代码。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Hugging Face Datasets library simplifies the process of loading and processing
    datasets. It provides a unified interface for thousands of datasets on Hugging
    Face's hub. The library also implements various performance metrics for transformer-based
    model evaluation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Datasets 库简化了数据集的加载和处理过程。它为 Hugging Face 的中心提供了数千个数据集的统一接口。该库还实现了各种性能指标，以评估基于变换器的模型。
- en: Initial Setup
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始设置
- en: Certain Python development environments may require installing the Datasets
    library before importing it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 某些 Python 开发环境可能需要在导入之前安装 Datasets 库。
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading a Hugging Face Hub Dataset by Name
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过名称加载 Hugging Face Hub 数据集
- en: 'Hugging Face hosts a wealth of datasets in its hub. The following function
    outputs a list of these datasets by name:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 在其中心托管了大量数据集。以下函数按名称输出这些数据集的列表：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s load one of them, namely the [emotions dataset](https://huggingface.co/datasets/jeffnyman/emotions)
    for classifying emotions in tweets, by specifying its name:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载其中一个，即 [情感数据集](https://huggingface.co/datasets/jeffnyman/emotions)，以对推文中的情感进行分类，方法是指定其名称：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you wanted to load a dataset you came across while browsing Hugging Face''s
    website and are unsure what the right naming convention is, click on the "copy"
    icon beside the dataset name, as shown below:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想加载在浏览 Hugging Face 网站时遇到的数据集，并且不确定正确的命名约定是什么，请点击数据集名称旁边的“复制”图标，如下所示：
- en: '![](../Images/4bbac1454b4283697f5b6dc478ff2721.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4bbac1454b4283697f5b6dc478ff2721.png)'
- en: 'The dataset is loaded into a **DatasetDict** object that contains three subsets
    or folds: train, validation, and test.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集被加载到一个 **DatasetDict** 对象中，该对象包含三个子集或折叠：训练集、验证集和测试集。
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Each fold is in turn a **Dataset** object. Using dictionary operations, we
    can retrieve the training data fold:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 每个折叠反过来是一个 **Dataset** 对象。使用字典操作，我们可以检索训练数据折叠：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The length of this Dataset object indicates the number of training instances
    (tweets).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Dataset 对象的长度表示训练实例（推文）的数量。
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Leading to this output:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 生成以下输出：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Getting a single instance by index (e.g. the 4th one) is as easy as mimicking
    a list operation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过索引（例如，第 4 个）获取单个实例就像模仿列表操作一样简单：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'which returns a Python dictionary with the two attributes in the dataset acting
    as the keys: the input tweet **text**, and the **label** indicating the emotion
    it has been classified with.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作返回一个 Python 字典，其中数据集中的两个属性作为键：输入推文 **文本** 和 **标签**，表示它被分类的情感。
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can also get simultaneously several consecutive instances by slicing:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过切片同时获取几个连续的实例：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This operation returns a single dictionary as before, but now each key has associated
    a list of values instead of a single value.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作返回一个单一的字典，如之前一样，但现在每个键都有一个值的列表，而不是单一值。
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Last, to access a single attribute value, we specify two indexes: one for its
    position and one for the attribute name or key:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要访问单个属性值，我们指定两个索引：一个用于其位置，另一个用于属性名称或键：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Loading Your Own Data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载你自己的数据
- en: 'If instead of resorting to Hugging Face datasets hub you want to use your own
    dataset, the Datasets library also allows you to, by using the same ''load_dataset()''
    function with two arguments: the file format of the dataset to be loaded (such
    as "csv", "text", or "json") and the path or URL it is located in.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想使用 Hugging Face 数据集中心，而是想使用自己的数据集，Datasets 库也允许你这样做，通过使用相同的 `load_dataset()`
    函数，并传入两个参数：数据集的文件格式（例如“csv”、“text”或“json”）以及其所在的路径或网址。
- en: 'This example loads the Palmer Archipelago Penguins dataset from a public GitHub
    repository:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子从一个公共 GitHub 仓库加载 Palmer Archipelago Penguins 数据集：
- en: '[PRE12]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Turn Dataset Into Pandas DataFrame
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据集转换为 Pandas DataFrame
- en: Last but not least, it is sometimes convenient to convert your loaded data into
    a Pandas **DataFrame** object, which facilitates data manipulation, analysis,
    and visualization with the extensive functionality of the Pandas library.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，有时将加载的数据转换为 Pandas **DataFrame** 对象是方便的，这可以利用 Pandas 库的广泛功能来简化数据处理、分析和可视化。
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![XXX](../Images/35c613f0ce5168adfa6e8729d1699eb9.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![XXX](../Images/35c613f0ce5168adfa6e8729d1699eb9.png)'
- en: Now that you have learned how to efficiently load datasets using Hugging Face's
    dedicated library, the next step is to leverage them by using Large Language Models
    (LLMs).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何使用 Hugging Face 的专用库高效加载数据集，下一步是通过使用大语言模型（LLMs）来利用它们。
- en: '[](https://www.linkedin.com/in/ivanpc/)****[Iván Palomares Carrascosa](https://www.linkedin.com/in/ivanpc/)****
    is a leader, writer, speaker, and adviser in AI, machine learning, deep learning
    & LLMs. He trains and guides others in harnessing AI in the real world.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/ivanpc/)****[伊万·帕洛马雷斯·卡拉斯科萨](https://www.linkedin.com/in/ivanpc/)****
    是一位在人工智能、机器学习、深度学习和 LLMs 领域的领袖、作家、演讲者和顾问。他培训和指导他人将 AI 应用于现实世界。'
- en: More On This Topic
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How to Use the Hugging Face Tokenizers Library to Preprocess Text Data](https://www.kdnuggets.com/how-to-use-the-hugging-face-tokenizers-library-to-preprocess-text-data)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face Tokenizers 库进行文本数据预处理](https://www.kdnuggets.com/how-to-use-the-hugging-face-tokenizers-library-to-preprocess-text-data)'
- en: '[How to Perform Memory-Efficient Operations on Large Datasets with Pandas](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Pandas 对大数据集执行内存高效操作](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)'
- en: '[How to Use Hugging Face AutoTrain to Fine-tune LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face AutoTrain 微调 LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
- en: '[How to Use GPT for Generating Creative Content with Hugging Face…](https://www.kdnuggets.com/how-to-use-gpt-for-generating-creative-content-with-hugging-face-transformers)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 GPT 生成创意内容，通过 Hugging Face…](https://www.kdnuggets.com/how-to-use-gpt-for-generating-creative-content-with-hugging-face-transformers)'
- en: '[A community developing a Hugging Face for customer data modeling](https://www.kdnuggets.com/2022/08/objectiv-community-developing-hugging-face-customer-data-modeling.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个开发 Hugging Face 用于客户数据建模的社区](https://www.kdnuggets.com/2022/08/objectiv-community-developing-hugging-face-customer-data-modeling.html)'
- en: '[Top 10 Machine Learning Demos: Hugging Face Spaces Edition](https://www.kdnuggets.com/2022/05/top-10-machine-learning-demos-hugging-face-spaces-edition.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前10大机器学习演示：Hugging Face Spaces 版](https://www.kdnuggets.com/2022/05/top-10-machine-learning-demos-hugging-face-spaces-edition.html)'
