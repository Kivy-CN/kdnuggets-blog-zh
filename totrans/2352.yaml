- en: 'Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类指标演练：使用准确率、精确率、召回率和ROC的逻辑回归
- en: 原文：[https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/f4b3fe77b0c72d1315751064ff8166af.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演练：使用准确率、精确率、召回率和ROC的逻辑回归](../Images/f4b3fe77b0c72d1315751064ff8166af.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑提供的图像
- en: Metrics are an important element of machine learning. In regard to classification
    tasks, there are different types of metrics that allow you to assess the performance
    of machine learning models. However, it can be difficult to choose the right one
    for your task at hand.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是机器学习的重要元素。关于分类任务，有不同类型的指标可以用来评估机器学习模型的性能。然而，选择适合你任务的正确指标可能会很困难。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'In this article, I will be going through 4 common classification metrics: Accuracy,
    Precision, Recall, and ROC in relation to Logistic Regression.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍4种常见的分类指标：准确率、精确率、召回率和ROC，并与逻辑回归相关联。
- en: Let's get started…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧……
- en: What is Logistic Regression?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是逻辑回归？
- en: Logistic Regression is a form of Supervised Learning - when the algorithm learns
    on a labeled dataset and analyses the training data. Logistic Regression is typically
    used for binary classification problems based on its ‘logistic function’.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种监督学习形式——当算法在标记数据集上学习并分析训练数据时。逻辑回归通常用于基于其“逻辑函数”的二分类问题。
- en: 'Binary classification can represent their classes as either: positive/negative,
    1/0, or True/False.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类可以将其类别表示为：正/负，1/0，或真/假。
- en: The logistic function is also known as the Sigmoid function which takes any
    real-valued number and maps it to a value between 0 and 1\. It can be mathematically
    represented as:\
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数也称为Sigmoid函数，它将任何实值数映射到0和1之间的值。它可以用数学方式表示为：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/87fc0d0815eda9430d05037ee1681103.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演练：使用准确率、精确率、召回率和ROC的逻辑回归](../Images/87fc0d0815eda9430d05037ee1681103.png)'
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/bab1b7639260376b6155acf6d5282760.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演练：使用准确率、精确率、召回率和ROC的逻辑回归](../Images/bab1b7639260376b6155acf6d5282760.png)'
- en: 'Source: [Wikipedia ](https://en.wikipedia.org/wiki/Sigmoid_function)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[维基百科](https://en.wikipedia.org/wiki/Sigmoid_function)
- en: What are Classification Metrics?
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是分类指标？
- en: Classification is about predicting a label and then identifying which category
    an object belongs to based on different parameters.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是指预测一个标签，然后根据不同的参数识别一个对象属于哪个类别。
- en: In order to measure how well our classification model is doing at making these
    predictions, we use classification metrics. It measures the performance of our
    machine learning model, giving us the confidence that these outputs can be further
    used in decision-making processes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量我们的分类模型在做出这些预测时的表现，我们使用分类指标。它衡量了我们机器学习模型的性能，给我们信心，使这些输出可以进一步用于决策过程。
- en: The performance is normally presented in a range from 0 to 1, where a score
    of 1 represents perfection.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 性能通常在0到1的范围内表示，其中1代表完美。
- en: Problems with the threshold
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阈值问题
- en: If we use a range from 0 to 1 to represent the performance of our model, what
    happens when the value is 0.5? As we know from early math classes, if the probability
    is greater than 0.5, we round it up to 1 (positive) - if not, it is 0 (negative).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用0到1的范围来表示模型的性能，当值为0.5时会发生什么？正如我们从早期的数学课程中知道的那样，如果概率大于0.5，我们将其四舍五入为1（正的）-
    如果不是，它就是0（负的）。
- en: That sounds okay, but now when you are using classification models to help determine
    the output of real-life cases. We need to be 100% sure that the output has been
    correctly classified.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来还不错，但现在当你使用分类模型来帮助确定现实生活中的输出时。我们需要100%确保输出已经被正确分类。
- en: For example, logistic regression is used to detect spam emails. If the probability
    that the email is spam is based on the fact that it is above 0.5, this can be
    risky as we could potentially direct an important email into the spam folder.
    The want and need for the performance of the model to be highly accurate becomes
    more sensitive for health-related and financial tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，逻辑回归用于检测垃圾邮件。如果电子邮件是垃圾邮件的概率基于其超过0.5，这可能存在风险，因为我们可能会将重要邮件误判为垃圾邮件。对模型性能的高度准确性需求在健康相关和财务任务中变得更加敏感。
- en: Therefore, using the threshold concept of values above the threshold value tend
    to be 1, and a value below the threshold value tends to be 0 can cause challenges.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用阈值概念，其中阈值以上的值趋向于1，而阈值以下的值趋向于0，可能会带来挑战。
- en: Although there is the option to adjust the threshold value, it still raises
    the risk that we classify incorrectly. For example, having a low threshold will
    classify the majority of positive classes correctly, but within the positive will
    contain negative classes - vice versa if we had a high threshold.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以调整阈值，但这仍然会增加分类错误的风险。例如，较低的阈值会正确分类大多数正类，但正类中可能会包含负类 - 反之，如果我们使用较高的阈值。
- en: So let’s get into how these classification metrics can help us with measuring
    the performance of our logistic regression model
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们深入探讨这些分类指标如何帮助我们衡量逻辑回归模型的表现
- en: Accuracy
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确性
- en: We will start off with accuracy because it’s the one that’s typically used the
    most, especially for beginners.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从准确性开始，因为它是通常使用得最多的，尤其是对于初学者。
- en: 'Accuracy is defined as the number of correct predictions over the total predictions:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性定义为正确预测的数量除以总预测数量：
- en: '*accuracy = correct_predictions / total_predictions*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*accuracy = correct_predictions / total_predictions*'
- en: 'However, we can further expand on this using these:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以通过以下方式进一步扩展：
- en: True Positive (TP) - you predicted positive and it’s actually positive
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性（TP）- 你预测为正，实际上也是正的
- en: True Negative (TN) - you predicted negative and it’s actually negative
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阴性（TN）- 你预测为负，实际上也是负的
- en: False Positive (FP) - you predicted positive and it’s actually negative
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性（FP）- 你预测为正，但实际上是负的
- en: False Negative (FN) - you predicted negative and it’s actually positive
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性（FN）- 你预测为负，但实际上是正的
- en: 'So we can say the true predictions are TN+TP, while the false prediction is
    FP+FN. The equation can now be redefined as:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以说真正的预测是TN+TP，而错误的预测是FP+FN。这个方程现在可以重新定义为：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/6f18a08608b0a48a06b44118faba26ee.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标概述：带有准确率、精确率、召回率和ROC的逻辑回归](../Images/6f18a08608b0a48a06b44118faba26ee.png)'
- en: 'In order to find the accuracy of your model, you would do this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出模型的准确性，你可以这样做：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Or you can also use [sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 或者你也可以使用[sklearn库](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: However, using the accuracy metric to measure the performance of your model
    is usually not enough. This is where we need other metrics.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅使用准确性指标来衡量模型的性能通常是不够的。这就是我们需要其他指标的地方。
- en: Precision and Recall
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确率和召回率
- en: 'If we want to further test the “accuracy” in different classes where we want
    to ensure that when the model predicts positive, it is in fact true positive -
    we use precision. We can also call this Positive Prediction Value which can be
    defined as:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想进一步测试不同类别中的“准确性”，以确保当模型预测为正时，确实是真阳性，我们使用精确率。我们也可以称之为正预测值，其定义为：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/30bf6c68e65d84ad7c5aa91da76456c1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：带有准确率、精确度、召回率和ROC的逻辑回归](../Images/30bf6c68e65d84ad7c5aa91da76456c1.png)'
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we want to further test the “accuracy” in different classes where we want
    to ensure that when the model predicts negative, it actually is negative - we
    use recall. Recall is the same formula as sensitivity and can be defined as:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想进一步测试不同类别中的“准确性”，确保当模型预测为负时，实际也为负——我们使用召回率。召回率与敏感性相同，可以定义为：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/3b09f192f969bd7c01713467dfe52958.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：带有准确率、精确度、召回率和ROC的逻辑回归](../Images/3b09f192f969bd7c01713467dfe52958.png)'
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Using both precision and recall are useful metrics when there is an imbalance
    in the observations between the two classes. For example, there are more of one
    class (1) and only a few of the other class (0) in the dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用精度和召回率是有用的度量，尤其是在两个类别之间的观察不平衡时。例如，数据集中一个类别（1）的数量多，而另一个类别（0）的数量少。
- en: In order to increase the precision of your model, you will need to have fewer
    FP and not have to worry about the FN. Whereas, if you want to increase recall,
    you will need to have fewer FN and not have to worry about the FP.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高模型的精确度，你需要减少FP，并不必担心FN。相反，如果你想提高召回率，你需要减少FN，而不必担心FP。
- en: Raising the classification threshold reduces false positives - increasing precision.
    Raising the classification threshold reduces true positives or keeps them the
    same, whilst increasing false negatives or keeps them the same. - decreasing recall
    or keeping it constant.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 提高分类阈值会减少假阳性——从而提高精度。提高分类阈值会减少真阳性或保持不变，同时增加假阴性或保持不变——从而降低或保持召回率不变。
- en: Unfortunately, it’s not possible to have a high precision and recall value.
    If you increase precision, it will reduce recall - vice versa. This is known as
    the precision/recall tradeoff.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，不可能同时获得高精度和高召回率。如果你提高精度，召回率将会降低，反之亦然。这被称为精度/召回率权衡。
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/b2c2d8d2f21bdbccea84c1804b19a90a.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：带有准确率、精确度、召回率和ROC的逻辑回归](../Images/b2c2d8d2f21bdbccea84c1804b19a90a.png)'
- en: 'Source: [Medium](https://medium.com/@syuumak/precision-recall-tradeoff-1f5b10cc729d)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Medium](https://medium.com/@syuumak/precision-recall-tradeoff-1f5b10cc729d)
- en: ROC Curve
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ROC曲线
- en: When it comes to precision we care about lowering the FP and for recall we care
    about lowering the FN. However, there is a metric that we can use to lower both
    the FP and FN - it is called the Receiver Operating Characteristic curve, or ROC
    curve.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在精度方面，我们关心减少FP；在召回率方面，我们关心减少FN。然而，有一种度量可以同时降低FP和FN——它被称为接收者操作特征曲线，或ROC曲线。
- en: It plots the false positive rate (x-axis) against the true positive rate (y-axis).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它将假阳性率（x轴）与真阳性率（y轴）绘制在一起。
- en: True Positive Rate = TP / (TP + FN)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性率 = TP / (TP + FN)
- en: False Positive Rate = FP / (FP + TN)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性率 = FP / (FP + TN)
- en: The true positive rate is also known as sensitivity, and the false positive
    rate is also known as the inverted specificity rate.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 真阳性率也称为敏感性，而假阳性率也称为反特异性率。
- en: Specificity = TN / (TN + FP)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特异性 = TN / (TN + FP)
- en: If the values on the x-axis consist of smaller values, this indicates lower
    FP and higher TN. If the values on the y-axis consist of larger values, this indicates
    higher TP and lower FN.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果x轴上的值较小，则表示FP较少且TN较高。如果y轴上的值较大，则表示TP较高且FN较少。
- en: 'The ROC presents the performance of a classification model at all classification
    thresholds, like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ROC展示了在所有分类阈值下分类模型的表现，如下所示：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/1dfb0c57c0e2db51b60b2ed28cebefea.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：带有准确率、精确度、召回率和ROC的逻辑回归](../Images/1dfb0c57c0e2db51b60b2ed28cebefea.png)'
- en: 'Source: [Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#/media/File:Roc_curve.svg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#/media/File:Roc_curve.svg)
- en: 'Example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/9db4993d31fac363dc06fe698c47a376.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：带有准确率、精确度、召回率和ROC的逻辑回归](../Images/9db4993d31fac363dc06fe698c47a376.png)'
- en: AUC
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AUC
- en: When it comes to the ROC curve, you may have also heard Area Under the Curve
    (AUC). It’s exactly what it says it is - the area under the curve. If you want
    to know how good your curve is, you calculate the ROC AUC score. ??AUC measures
    the performance across all possible classification thresholds.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到ROC曲线时，你可能还听说过曲线下面积（AUC）。它正如其名——曲线下面积。如果你想知道你的曲线有多好，你可以计算ROC AUC得分。AUC衡量了所有可能分类阈值下的性能。
- en: The more area under the curve you have, the better - the higher the ROC AUC
    score. This is when the FN and FP are both at zero - or if we refer to the graph
    above, it’s when the true positive rate is 1 and the false positive rate is 0.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 曲线下面积越大，效果越好——ROC AUC得分越高。这是在FN和FP都为零时的情况——或者如果我们参考上面的图表，那就是当真正例率为1而假正例率为0时。
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The below image shows an ascending order of logistic regression predictions.
    If the AUC value is 0.0, we can say that the predictions are completely wrong.
    If the AUC value is 1.0, we can say that the predictions are fully correct.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了逻辑回归预测的升序排列。如果AUC值为0.0，我们可以说预测完全错误。如果AUC值为1.0，我们可以说预测完全正确。
- en: '![Classification Metrics Walkthrough: Logistic Regression with Accuracy, Precision,
    Recall, and ROC](../Images/d4df7798b75dacd4037f1a34baa164ce.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![分类指标演示：使用准确率、精确率、召回率和ROC曲线的逻辑回归](../Images/d4df7798b75dacd4037f1a34baa164ce.png)'
- en: Wrapping it up
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结一下
- en: To recap, we have gone over what is Logistic Regression, what Classification
    Metrics are, and problems with the threshold with solutions, such as Accuracy,
    Precision, Recall, and the ROC Curve.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们已经讲解了什么是逻辑回归、分类指标是什么，以及阈值问题及其解决方案，如准确率、精确率、召回率和ROC曲线。
- en: There are so many more classification metrics out there, such as confusion matrix,
    F1 score, F2 score, and more. These are all available to help you better understand
    the performance of your model.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他分类指标，如混淆矩阵、F1分数、F2分数等。这些指标都可以帮助你更好地了解模型的性能。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家和自由职业技术作家。她特别感兴趣于提供数据科学职业建议或教程，以及围绕数据科学的理论知识。她还希望探索人工智能如何及可能如何促进人类寿命的延续。作为一个渴望学习的人，她希望拓宽技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Idiot''s Guide to Precision, Recall, and Confusion Matrix](https://www.kdnuggets.com/2020/01/guide-precision-recall-confusion-matrix.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[愚蠢的精确率、召回率和混淆矩阵指南](https://www.kdnuggets.com/2020/01/guide-precision-recall-confusion-matrix.html)'
- en: '[Confusion Matrix, Precision, and Recall Explained](https://www.kdnuggets.com/2022/11/confusion-matrix-precision-recall-explained.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[混淆矩阵、精确率和召回率解释](https://www.kdnuggets.com/2022/11/confusion-matrix-precision-recall-explained.html)'
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，11月16日：LinkedIn如何使用机器学习 •…](https://www.kdnuggets.com/2022/n45.html)'
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解分类指标：评估模型准确性的指南](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
- en: '[Logistic Regression for Classification](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分类的逻辑回归](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
- en: '[Key Issues Associated with Classification Accuracy](https://www.kdnuggets.com/2023/03/key-issues-associated-classification-accuracy.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[与分类准确性相关的关键问题](https://www.kdnuggets.com/2023/03/key-issues-associated-classification-accuracy.html)'
