# 机器学习中的模型漂移——如何在大数据中处理

> 原文：[https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html](https://www.kdnuggets.com/2021/08/model-drift-machine-learning-big-data.html)

[评论](#comments)

**由 [Sai Geetha](https://www.saigeetha.in/about) 撰写，她是一位大数据工程和数据科学的专家**。

![](../Images/ac179ecb1bad142c35e7ed68f869139d.png)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

**约会架构**由 Ted Dunning 和 Ellen Friedman 在他们的《*机器学习物流*》一书中提出，是我为一个特定架构问题找到的一个很好的解决方案。我在寻找一个经过验证的设计模式或架构模式，帮助我以可维护和可支持的方式同时运行挑战者和冠军模型。约会架构在大数据领域特别有用，因为你需要处理大量数据和大型管道。

在所有数据上同时运行挑战者和冠军模型的能力是机器学习中一个非常真实的需求，因为模型性能可能会随着时间的推移而漂移，而你总是希望不断提高模型的性能。

所以，在深入探讨这种架构之前，我想澄清一些我上面使用的术语。什么是冠军模型？什么是挑战者模型？什么是模型漂移，它为什么会发生？然后，我们可以查看约会架构本身及其解决的问题。

## 模型漂移

一旦你将模型投入生产，假设它会一直表现良好是一个错误。事实上，常说 - "**你将模型投入生产的那一刻，它就开始退化**。" (*注意，在机器学习中，'**性能**'通常指统计性能——无论是准确度、精确度、召回率、敏感度、特异性还是适用于你的用例的其他度量标准*)。

为什么会发生这种情况？模型是在一些过去的数据上训练的。它对具有相同特征的数据表现出色。然而，随着时间的推移，实际数据特征可能不断变化，而模型对此完全没有意识。这会导致模型漂移，即模型性能的下降。

例如，你训练了一个模型来检测垃圾邮件和正常邮件。模型在部署时表现良好。随着时间的推移，垃圾邮件的类型不断变化，从而导致预测准确性下降。这被称为**模型漂移**。

模型漂移可能是由于**概念漂移**或**数据漂移**引起的。我今天不深入探讨这些，所以我们只需了解模型的性能不会保持不变。因此，我们需要持续监控模型的性能。通常情况下，最好是用更新的数据更频繁地重新训练模型，或者可能根据性能退化的阈值进行调整。

有时，即使重新训练模型也无法进一步提高性能。这意味着你可能需要了解问题特征的变化，并通过更合适的模型进行数据分析、特征创建和模型构建的整个过程。

如果你能在当前生产中有一个模型的同时使用 Challenger 模型，那么这个周期可以缩短。这是一个持续改进的机器学习过程，非常必要。

## Champion-Challenger 模型

通常，生产中的模型被称为**Champion**模型。任何在较小试验中表现良好并准备投入生产的模型都是**Challenger**模型。提出这些 Challenger 模型是因为我们假设它们有可能比 Champion 模型表现更好。但是我们如何证明这一点呢？

Champion 模型通常在所有进入的数据上运行以提供预测。然而，Challenger 模型在什么数据上运行？

Challenger 模型可以通过两种方式进行测试。理想的情况是将 Challenger 模型与 Champion 模型在所有数据上并行运行并比较结果。这将真正证明 Challenger 模型是否表现更好。然而，在大数据的世界里，这似乎不可行，因此 Challenger 模型总是先在一部分新数据上进行试验。一旦表现良好，它将逐渐扩展到更多的数据上，几乎就像是 alpha-beta 测试。

如你所知，在 alpha-beta 测试中，一小部分用户或进入的数据会通过新的测试或 Challenger 管道，其余的数据则通过原始的 Champion 管道。这种 alpha-beta 测试对某些应用来说是有效的，但在机器学习的世界里显然不是很令人印象深刻。你没有在相同的数据上比较模型，因此很难自信地说一个模型比另一个模型更适合全部数据。一旦全面推出，可能会出现意外情况，模型漂移可能比预期更早开始。

一个典型的 alpha-beta 管道如下：

![](../Images/815ebfe995cca0d92ee17be5ae9b10ca.png)

数据根据一些标准，如产品类别，分配到两个管道中。这种数据分割会随着对 Challenger 模型性能信心的增加而不断扩大。

从数据科学家的角度来看，这并不理想。理想的情况是能够与 Champion 模型一起并行运行**所有数据**的 Challenger 模型。正如我之前所说，这非常昂贵。

考虑最坏情况。如果你希望它们并行运行，你必须建立两个数据管道，这些管道独立完成所有步骤。

它看起来像这样：

![](../Images/79af4a7798d8a039595f6e3b3d2a5d9b.png)

这具有巨大的工程影响，因此也有市场时间的影响。随着时间的推移，成本可能会变得过高。

一些主要影响包括不断构建这些管道的时间和精力，而不确定 Challenger 模型是否真的会按预期执行。CI/CD 过程、部署、监控、认证机制等都是其中的一部分。此外，另一个成本是基础设施的双重配置。

如果这些管道是大数据管道，情况会更加重要。你很快会意识到这不是一个可扩展的模型。我们确实需要看看如何摆脱并行管道，甚至是 alpha-beta 测试方法。

作为推论，最佳情况是我们可以重复使用大量数据管道。这个想法是最小化需要重新开发和部署到生产中的部分。这也将确保基础设施使用的优化。这是优化的一种思路。

更好的是能够**插入 Challenger 模型，**其余的管道表现得像什么都没改变一样。这不是很棒吗？这正是**Rendezvous 架构**所实现的。

## Rendezvous 架构

如书中所述，Rendezvous 架构倾向于处理较小数据的机器学习。我对它进行了调整，以满足大数据世界及相关管道的需求，如下图所示：*(书籍和另一篇文章的参考文献见参考部分)*

![](../Images/64f95c58d6146d8d3da9b7dea09f8ef5.png)

现在让我逐部分解释这个架构。

**第1部分：**

这包括标准的数据管道，用于接收传入数据、清洗数据、准备数据和创建所需的特征。每个要部署的模型应仅有一个这样的管道。准备好的数据应保持一个标准接口，具有该领域所需的所有特征，而不论当前模型如何。(*我理解这并不总是可能的，可能需要随时间进行局部调整。但我们可以在需要时单独处理那部分。*)

**第2部分：**

这是一种类似于Kafka的消息基础设施，通过引入异步性来发挥作用。准备好的特征数据被发布到消息总线中。现在，每个模型都监听这个消息总线，并根据准备好的数据触发执行。这个消息总线就是使得这里实现即插即用架构的关键。

**第3部分：**

这是所有模型逐一部署的部分。新的挑战者模型可以被部署并监听消息总线，当数据流入时，它可以执行。这里可以部署任意数量的模型，而不仅仅是一个挑战者模型！此外，基础设施要求仅仅是额外模型的运行。既无需单独开发预处理模型管道，也无需单独开发后处理模型管道。

正如图中所示，只要数据科学家认为这些挑战者模型足够成熟以进行实际数据测试，就可以拥有多个挑战者模型。

另外，还有一个特殊的模型叫做诱饵模型。为了确保每个模型处理过程不被持久化负担所困扰，准备好的数据也会被所谓的**诱饵模型**读取，该模型的唯一工作就是读取准备好的数据并进行持久化。这有助于审计、追踪和在需要时进行调试。

**第4部分：**

所有这些模型再次将其预测或分数输出到另一个消息总线，从而不会在它们之间产生任何依赖关系。此外，这也在确保模型的可插拔性方面发挥了重要作用，而不会破坏管道中的其他内容。

从这里，接头过程获取分数并决定需要做什么，正如第5部分所描述的。

**第5部分：**

在这里，引入了**接头过程**的新概念，该过程有两个重要的子过程。一个即时子过程负责从接收到的多个分数中，为消费者流出正确的输出，而另一个过程是持久化所有模型的输出，以便进行进一步的比较和分析。

因此，我们在这里实现了两个目标：

1.  最佳输出提供给消费者。

1.  所有的数据都经过了所有模型，因此它们在类似情况下的性能是完全可以比较的。

如何决定应该发送哪个模型的输出？这可以基于多个标准，例如数据的一个子集应始终来自挑战者，另一个子集应始终来自冠军。这几乎像是在进行alpha-beta测试。然而，优势在于，尽管对消费者来说这听起来像是alpha-beta测试，但对数据科学家而言，所有数据都经过了这两个模型，因此他们可以比较两个输出并了解哪个表现更好。

另一个标准可能是输出应基于模型性能。在这种情况下，汇合过程会等待所有模型完成并发布到消息总线，然后它会寻找最佳性能指标并将其作为结果发送出去。

是的，另一个标准可以是时间或延迟。例如，如果我们需要在不到5秒的时间内得到结果，过程会等待所有模型的结果，最多5秒，比较这些结果并返回最佳数据。即使另一个模型在第6秒返回并且表现更好，它也会被忽略，因为它不符合延迟标准。

但这个过程如何知道对哪个数据或哪个模型遵循什么标准？这可以作为输入数据的一部分放入消息总线中。请注意，汇合过程也在监听这些消息，并了解如何处理与输入对应的输出。还有其他聪明的方式，但这是提出的其中一种方法。

## 结论

通过消息总线引入异步性，带来了一个解耦的层次，使得在原本僵化的数据管道中可以实现模型的即插即用。

通过引入汇合过程，选择不同模型输出、持久化它们、比较它们的能力都得到了引入。有了这一点，为同一数据集引入或支持任意数量的新模型似乎不再是难以完成的任务。

**总结**

汇合架构在各个层次上提供了极大的灵活性。

1.  可以使用各种标准来决定预测过程中可以发送的分数、输出或预测。这些标准可以是基于延迟的、基于模型性能的或简单的时间基准。

1.  它提供了通过汇合过程动态定义和更改这些标准的能力。你可以通过引入规则引擎将其提升到另一个层次。

1.  它提供了让所有数据通过所有管道的能力，或者仅选择子集通过多个管道。例如，如果你有超市和一般商品的预测，超市产品可以通过它们自己的冠军和挑战者模型，而通常慢销的通用商品可以有自己的管道。

1.  它还提供了同时运行多个模型的能力，而无需重新开发或重新部署大部分大数据管道。除了节省努力和时间，基础设施成本也得到了优化。

### 参考文献

1.  [机器学习物流](https://learning.oreilly.com/library/view/machine-learning-logistics/9781491997628/) 作者：Ted Dunning；Ellen Friedman - 第三章《机器学习的汇合架构》

1.  文章来自 [towardsdatascience.com](http://towardsdatascience.com/)，标题为"[数据科学生产中的相遇架构](https://towardsdatascience.com/rendezvous-architecture-for-data-science-in-production-79c4d48f12b)"，作者为 Jan Teichmann

[原文](https://www.saigeetha.in/post/machine-learning-rendezvous-architecture)。经许可重新发布。

**个人简介：** [Sai Geetha](https://www.linkedin.com/in/saigeethamn/) ([@saigeethamn](https://twitter.com/saigeethamn)) 是一位架构师，拥有创建战略路线图和基于企业需求及领先技术进行创新的经验。作为一名具有数据科学知识的大数据专家，能够弥合这两个领域之间的差距，为您的企业中的大型数据项目带来成功。

**相关：**

+   [再见，大数据。你好，海量数据！](https://www.kdnuggets.com/2020/10/sqream-massive-data.html)

+   [模型再训练的终极指南](https://www.kdnuggets.com/2019/12/ultimate-guide-model-retraining.html)

+   [AI 和大数据的隐藏风险](https://www.kdnuggets.com/2019/09/risk-ai-big-data.html)

### 更多相关内容

+   [使用 Eurybia 检测数据漂移以确保生产 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)

+   [利用 MLOps 管理生产中的模型漂移](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)

+   [KDnuggets 新闻，8月31日：完整的数据科学学习路线图……](https://www.kdnuggets.com/2022/n35.html)

+   [处理不平衡数据的 7 种技术](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)

+   [如何使用 Scikit-learn 的 Imputer 模块处理缺失数据](https://www.kdnuggets.com/how-to-handle-missing-data-with-scikit-learns-imputer-module)

+   [NumPy 中的掩码数组以处理缺失数据](https://www.kdnuggets.com/masked-arrays-in-numpy-to-handle-missing-data)
