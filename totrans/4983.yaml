- en: What I Learned Implementing a Classifier from Scratch in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我在Python中从零实现分类器的收获
- en: 原文：[https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html](https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html](https://www.kdnuggets.com/2017/02/learned-implementing-classifier-scratch-python.html)
- en: '**By Jean-Nicholas Hould, [JeanNicholasHould.com](http://JeanNicholasHould.com/?utm_source=kdnugget).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：让-尼古拉斯·侯德，[JeanNicholasHould.com](http://JeanNicholasHould.com/?utm_source=kdnugget)。**'
- en: This post is part of the author's [Learning Machine Learning](http://www.jeannicholashould.com/learning-machine-learning.html)
    series. It’s based on Chapter 1 and 2 of [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3).
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文是作者的[学习机器学习](http://www.jeannicholashould.com/learning-machine-learning.html)系列的一部分。它基于[Python机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)的第1章和第2章。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Machine learning can be intimidating for a newcomer. The concept of a machine
    learning things alone is quite abstract. How does that work in practice?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对新手来说，机器学习可能会令人感到畏惧。机器学习的概念本身相当抽象。那么它在实际中是如何运作的呢？
- en: In order to demystify some of the magic behind machine learning algorithms,
    I decided to implement a simple machine learning algorithm from scratch. I will
    not be using a library such as *scikit-learn* which already has many algorithms
    implemented. Instead, I’ll be writing all of the code in order to have a working
    binary classifier algorithm. The goal of this exercise is to understand its inner
    workings.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了揭开机器学习算法背后的神秘面纱，我决定从头开始实现一个简单的机器学习算法。我不会使用像*scikit-learn*这样的库，它已经实现了许多算法。相反，我将编写所有代码，以便拥有一个工作的二元分类器算法。这个练习的目标是理解其内部工作原理。
- en: So, what the heck is a binary classifier?
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那么，什么是二元分类器呢？
- en: A classifier is a machine-learning algorithm that determines the class of an
    input element based on a set of features. For example, a classifier could be used
    to predict the category of a beer based on its characteristics, it’s “features”.
    These features could include its alcohol content, aroma, appearance, etc. A machine
    learning classifier could potentially be used to predict that a beer with 8% alcohol
    content, 100 IBU and with strong aromas of oranges is an Indian Pale Ale.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器是一个机器学习算法，它根据一组特征确定输入元素的类别。例如，分类器可以用于根据啤酒的特征预测其类别。这些特征可能包括其酒精含量、香气、外观等。机器学习分类器可以用来预测一瓶8%酒精含量、100
    IBU、并带有强烈橙子香气的啤酒是印度淡色艾尔。
- en: 'In machine learning, there are three main types of tasks: unsupervised learning,
    supervised learning and reinforcement learning. The classifier algorithm falls
    under the supervised learning category. Supervised learning means that we know
    the right answer beforehand. The desired outputs are known. In the case of the
    beer example, we could realistically have a dataset describing beers and their
    category. We could train the classifier algorithm to predict those categories
    based on the beers features.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，主要有三种任务类型：无监督学习、监督学习和强化学习。分类器算法属于监督学习范畴。监督学习意味着我们事先知道正确答案。期望的输出是已知的。在啤酒的例子中，我们可以拥有描述啤酒及其类别的数据集。我们可以训练分类器算法，根据啤酒的特征来预测这些类别。
- en: A binary classifier classifies elements in two groups. Zero or one. True or
    false. IPA or not.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类器将元素分类为两组。零或一。真或假。IPA或不是。
- en: Building a machine learning model
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建机器学习模型
- en: There are four steps to build and use a machine learning model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和使用机器学习模型的步骤有四个。
- en: Preprocessing
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理
- en: Learning
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 学习
- en: Evaluation
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估
- en: Prediction
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测
- en: '![](../Images/ab50ecd3646752080fe903493cb7c77b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab50ecd3646752080fe903493cb7c77b.png)'
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Sebastian Raschka的[《Python机器学习》](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)。
- en: Preprocessing
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预处理
- en: The preprocessing is the first step in building a machine learning model. At
    this step, you acquire and prepare the data for future usage. You clean up the
    data, tidy it and select the features you want to use from your data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理是构建机器学习模型的第一步。在这一步，你获取并准备数据以供未来使用。你清理数据、整理数据，并选择你想从数据中使用的特征。
- en: 'The following tasks can be considered as part of the “preprocessing”:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下任务可以被视为“预处理”的一部分：
- en: Extract features from raw data
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从原始数据中提取特征
- en: Clean and format the data
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理和格式化数据
- en: Remove superfluous features (or highly correlated features)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除多余的特征（或高度相关的特征）
- en: Reduce the number of features for performance
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少特征数量以提高性能
- en: Standardize the range of feature data (also named [Feature Scaling](https://en.wikipedia.org/wiki/Feature_scaling))
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化特征数据的范围（也称为[特征缩放](https://en.wikipedia.org/wiki/Feature_scaling)）
- en: 'Split your dataset randomly: training dataset and test dataset'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机拆分数据集：训练数据集和测试数据集
- en: Learning or Training
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习或训练
- en: Once you have your datasets ready to be used, the second step is to select an
    algorithm to perform your desired task. In our case, the algorithm we selected
    is a binary classifier called Perceptron. There are many algorithms designed to
    do different tasks. They each have their strengths and weaknesses.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你准备好了数据集，第二步是选择一个算法来执行你想要的任务。在我们的案例中，我们选择的算法是一个称为感知机的二分类器。有许多算法被设计用来完成不同的任务，它们各自有优点和缺点。
- en: At this step, you can test a few algorithms, see how they perform and select
    the best performing one. There are a wide variety of metrics that can be used
    to measure the performance of a machine learning model. According to Raschka,
    “one commonly used metric is classification accuracy, which is defined as the
    proportion of correctly classified instances”. At this step, you will make adjustments
    to the parameters of your machine learning algorithm. These are named hyperparameters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，你可以测试一些算法，查看它们的表现并选择性能最好的一个。有多种指标可以用来衡量机器学习模型的性能。根据Raschka的说法，“一个常用的指标是分类准确率，它被定义为正确分类实例的比例”。在这一步，你将对机器学习算法的参数进行调整，这些参数被称为超参数。
- en: In this post, we’ll mainly focus on this part of the machine learning work flow.
    We’ll deep dive in the algorithm inner workings. If you are interested in the
    other sections of the machine learning work flow, which you should be, I’ll be
    linking to a great notebook at the end of this post.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将主要关注机器学习工作流的这一部分。我们将深入探讨算法的内部工作原理。如果你对机器学习工作流的其他部分感兴趣，应该感兴趣，我将在文章末尾链接到一个很棒的笔记本。
- en: Evaluation
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估
- en: When the model has been “trained” on the dataset it can be evaluated on new
    unseen data. The goal here is to measure the [generalization error](https://en.wikipedia.org/wiki/Generalization_error).
    This metric measures “how accurately an algorithm is able to predict outcome values
    for previously unseen data”. Once you are satisfied with the results, you can
    use your machine learning model to make predictions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型在数据集上“训练”完成后，可以在新的未见数据上进行评估。这里的目标是衡量[泛化误差](https://en.wikipedia.org/wiki/Generalization_error)。这个指标衡量的是“算法能够多准确地预测之前未见数据的结果值”。一旦你对结果感到满意，你可以使用你的机器学习模型进行预测。
- en: Introducing the Perceptron
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍感知机
- en: The algorithm that we’ll be re-implementing is a [Perceptron](https://en.wikipedia.org/wiki/Perceptron)
    which is one of the very first machine learning algorithm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新实现的算法是[感知机](https://en.wikipedia.org/wiki/Perceptron)，它是最早的机器学习算法之一。
- en: The Perceptron algorithm is simple but powerful. Given a training dataset, the
    algorithm automatically learns “the optimal weight coefficients that are then
    multiplied with the input features in order to make the decision of whether a
    neuron fires or not”.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机算法简单但强大。给定一个训练数据集，算法自动学习“最佳权重系数，这些系数与输入特征相乘以决定神经元是否被激活”。
- en: But, how does the algorithm do that?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，算法是如何做到的呢？
- en: The Algorithm
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法
- en: 'Here’s the sequence of the algorithm:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是算法的序列：
- en: First, we initialize an array with the weights equal to zero. The array length
    is equal to the number of features plus one. This additional feature is the “threshold”.
    It’s important to note that in the case of the Perceptron algorithm, the features
    must be of numerical value.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们初始化一个权重全为零的数组。数组的长度等于特征数量加一。这个额外的特征是“阈值”。值得注意的是，在感知机算法中，特征必须是数值型的。
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Secondly, we start a loop equal to the number of iterations `n_iter`. This is
    an hyperparameter defined by the data scientist.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们开始一个与迭代次数`n_iter`相等的循环。这是一个由数据科学家定义的超参数。
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thirdly, we start a loop on each training data point and it’s target. The target
    is the desired output we want the algorithm to eventually predict. Since this
    is a binary classifier, the targets are either `-1` or `1`. They are of binary
    value.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们对每一个训练数据点及其目标开始循环。目标是我们希望算法最终预测的期望输出。由于这是一个二分类器，目标值要么是`-1`，要么是`1`。它们是二进制值。
- en: 'Based on the data point features, the algorithm will predict the category:
    `1` or `-1`. The prediction calculation is a matricial multiplication of the features
    with their appropriate weights. To this multiplication we add the value of the
    threshold. If the result is above 0, the predicted category is `1`. If the result
    is below 0, the predicted category is `-1`.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据点的特征，算法将预测类别：`1` 或 `-1`。预测计算是特征与其适当权重的矩阵乘法。我们将阈值的值加到这个乘法结果中。如果结果大于0，预测的类别是`1`。如果结果小于0，预测的类别是`-1`。
- en: At each iteration on a data point, if the prediction is not accurate, the algorithm
    will adjust the weights. During the first few iterations, the predictions are
    not likely to be accurate because the weights haven’t been adjusted many times.
    They haven’t had a chance to start converging. The adjustments are made proportionally
    to the difference between the target and the predicted value. This difference
    is then multiplied by the learning rate `eta`, an hyperparameter of value between
    zero and one set by the data scientist. The higher the `eta` is, the larger the
    correction on the weights will be. If the prediction is accurate, the algorithm
    won’t adjust the weights.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次对数据点进行迭代时，如果预测不准确，算法将调整权重。在最初的几次迭代中，预测可能不准确，因为权重还没有调整很多次。它们还没有开始收敛。调整是根据目标值与预测值之间的差异按比例进行的。这个差异然后乘以学习率`eta`，这是一个数据科学家设置的在零和一之间的超参数。`eta`值越高，对权重的修正就越大。如果预测准确，算法将不会调整权重。
- en: The Perceptron will converge only if the two classes are linearly separable.
    Simply said, if you are able to draw a straight line to entirely separate the
    two classes, the algorithm will converge. Else, the algorithm will keep iterating
    and will readjust weights until it reaches the maximum number of iterations `n_iter`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机只有在两个类别线性可分时才会收敛。简单来说，如果你能够绘制一条直线完全分隔这两个类别，算法就会收敛。否则，算法将继续迭代并重新调整权重，直到达到最大迭代次数`n_iter`。
- en: '![](../Images/81a651a78516e9af6e96c47b4ee0f87f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81a651a78516e9af6e96c47b4ee0f87f.png)'
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Python 机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
- en: Complete Code
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整代码
- en: 'Source: [Python Machine Learning](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Python 机器学习](https://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1783555130&linkCode=as2&tag=nickhould-20&linkId=79334fab95b99f2021c47f06697c40c3)
    by Sebastian Raschka.'
- en: Three Learnings
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 三个学习点
- en: 1\. Learning Rate, Number of Iteration & Convergence
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 学习率、迭代次数与收敛
- en: Parameters such as `learning rate` and `number of iteration` can seem very abstract
    if you jump in straight to using an algorithm from a library like `scikit-learn`.
    It’s hard to grasp what these really do. By implementing the algorithm, it’s now
    clear for me what they represent in the context of the Perceptron.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 参数如`learning rate`（学习率）和`number of iteration`（迭代次数）如果直接跳到像`scikit-learn`这样的库中的算法，可能会显得非常抽象，很难理解它们真正的作用。通过实现算法，现在我清楚它们在感知机（Perceptron）中的含义。
- en: '**Learning Rate**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习率**'
- en: The learning rate is a ratio by which the weights are corrected when the prediction
    is not accurate. The value needs to be between zero and one. As you can see in
    the snippet below, the `fit` function will iterate on each observation, call the
    `predict` function and then adjust the weights based on the difference between
    the target and the predicted value and then multiplied by the learning rate.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是当预测不准确时，用来修正权重的比率。该值需要在零和一之间。如下面的代码片段所示，`fit`函数将对每个观察值进行迭代，调用`predict`函数，然后根据目标值和预测值之间的差异调整权重，再乘以学习率。
- en: A higher learning rate means that the algorithm will adjust the weights more
    aggressively. At each iteration, the weights will be adjusted if the predicted
    value is inaccurate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 较高的学习率意味着算法将更加积极地调整权重。在每次迭代中，如果预测值不准确，权重将会被调整。
- en: '**Number of iterations**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**迭代次数**'
- en: The number of iteration is the number of times the algorithm will run through
    the training dataset. If the number of iteration was set to one, the algorithm
    would loop through the dataset only once and update the weights one time for each
    data point. The resulting model would be more likely to be inaccurate than a model
    with a higher number of iteration. On large datasets, there is a cost to having
    a high number of iterations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代次数是算法在训练数据集上运行的次数。如果迭代次数设为一，那么算法只会循环一次数据集，并为每个数据点更新一次权重。结果模型可能会比具有更高迭代次数的模型更不准确。在大型数据集上，较高的迭代次数会带来一定的成本。
- en: The `learning rate` and `number of iteration` go hands-in-hand. They need to
    be adjusted together. For example, if you have a very low `learning rate`, which
    means that the algorithm will adjust it’s weight only marginally at each iteration,
    you will probably need a higher number of iteration.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`learning rate`（学习率）和`number of iteration`（迭代次数）是密切相关的。它们需要一起调整。例如，如果你有一个非常低的`learning
    rate`（学习率），这意味着算法在每次迭代中仅会稍微调整权重，你可能需要更多的迭代次数。'
- en: 2\. Linear Algebra
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 线性代数
- en: It’s critical to mention that the capabilities of the Perceptron algorithm are
    attributable to linear algebra. The whole algorithm can be described through linear
    algebra formulas. If you have never done linear algebra in college, the formulas
    will be cryptic. As usual, [Khan Academy](https://www.khanacademy.org/math/linear-algebra)
    is a great place to start with if you want to get familiar with linear algebra.
    It’s also a great place to get a refresher on the topic.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 需要特别提到的是，感知机算法的能力归功于线性代数。整个算法可以通过线性代数公式来描述。如果你在大学时从未学习过线性代数，那么这些公式会显得很晦涩。像[Khan
    Academy](https://www.khanacademy.org/math/linear-algebra)这样的网站是一个很好的起点，如果你想熟悉线性代数，这是一个很好的资源，也适合复习相关知识。
- en: For me, the main learning here is how fundamental linear algebra is to this
    machine learning algorithm.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对我而言，主要的学习是线性代数对这个机器学习算法的重要性。
- en: 3\. Type Everything
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 输入一切
- en: This learning is actually a concept I re-learned while going through the code
    for this post. It’s not specific to machine learning and it has nothing to do
    with the Perceptron.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种学习实际上是我在为这篇文章编写代码时重新学习的一个概念。它并不是特定于机器学习的，也与感知机无关。
- en: Back in 2012 when I was learning to code Ruby on Rails, a web application development
    framework, I realized that typing down all of the code examples from tutorials
    really helped me memorize and understand the concepts. I spent weeks writing code
    while following tutorials. No copy and paste. I typed all the code. This may sound
    stupid but it was extremely helpful to grasp the concepts. During the process,
    I inevitably made typos and spend some time figuring out what was broken. These
    moments were crucial because that’s when you usually stop and think.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 2012 年，当我在学习 Ruby on Rails，一个 Web 应用开发框架时，我意识到将教程中的所有代码示例输入到计算机中真的有助于我记忆和理解概念。我花了几周时间在跟随教程的过程中编写代码。没有复制粘贴。我输入了所有代码。这听起来可能很傻，但这对掌握概念极其有帮助。在这个过程中，我不可避免地犯了错字，并花了一些时间找出问题所在。这些时刻是关键的，因为通常会在此时停下来思考。
- en: If you are going through the Perceptron code, don’t copy and paste the code
    from the [repository](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb).
    Type it down in your own Jupyter Notebook. Type everything. Don’t read passively.
    Get involved, type it down and you’ll assimilate the concepts faster.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在查看感知器代码，请不要从 [代码库](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)
    复制粘贴代码。请在你自己的 Jupyter Notebook 中逐行输入代码。逐行输入，不要被动阅读。积极参与，输入代码，你会更快地掌握概念。
- en: Next Steps
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步
- en: In this post, my goal was to share my understanding of the algorithm and the
    learnings I’ve made while reimplementing it. However, you can do much more than
    simply reimplementing the model. You can actually use it with real data in order
    to do some simple predictions. In Python Machine Learning, Raschka uses the Perceptron
    to [predict the class of Iris flower](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)
    based on a the sepal and petal length of the flower. With actual data, you can
    then evaluate the model and make predictions on unseen data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我的目标是分享我对算法的理解以及在重新实现它时的学习经验。然而，你可以做的不仅仅是重新实现模型。你可以实际使用真实数据来进行一些简单的预测。在《Python
    机器学习》中，Raschka 使用感知器来 [预测鸢尾花的类别](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/ch02.ipynb)，根据花朵的萼片和花瓣长度。使用真实数据后，你可以评估模型并对未见数据进行预测。
- en: '**Bio: Jean-Nicholas Hould** is a [Data Scientist from Montreal, Canada](http://jeannicholashould.com/?utm_source=kdnugget).
    Author at JeanNicholasHould.com.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：Jean-Nicholas Hould** 是来自 [加拿大蒙特利尔的数据科学家](http://jeannicholashould.com/?utm_source=kdnugget)。JeanNicholasHould.com
    的作者。'
- en: '[Original](http://www.jeannicholashould.com/what-i-learned-implementing-a-classifier-from-scratch.html).
    Reposted with permission.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](http://www.jeannicholashould.com/what-i-learned-implementing-a-classifier-from-scratch.html)。已获得许可转载。'
- en: '**Related:**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Web Scraping for Dataset Curation, Part 1: Collecting Craft Beer Data](/2017/02/web-scraping-dataset-curation-part-1.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据集策划中的网络爬虫，第一部分：收集精酿啤酒数据](/2017/02/web-scraping-dataset-curation-part-1.html)'
- en: '[Tidying Data in Python](/2017/01/tidying-data-python.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中整理数据](/2017/01/tidying-data-python.html)'
- en: '[Central Limit Theorem for Data Science](/2016/08/central-limit-theorem-data-science.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的中心极限定理](/2016/08/central-limit-theorem-data-science.html)'
- en: More On This Topic
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从理论到实践：构建 k-近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
- en: '[What I Learned From Using ChatGPT for Data Science](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我从使用 ChatGPT 进行数据科学中学到的](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
- en: '[Implementing DBSCAN in Python](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中实现 DBSCAN](https://www.kdnuggets.com/2022/08/implementing-dbscan-python.html)'
- en: '[KDnuggets News, August 24: Implementing DBSCAN in Python • How to…](https://www.kdnuggets.com/2022/n34.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8 月 24 日：在 Python 中实现 DBSCAN • 如何…](https://www.kdnuggets.com/2022/n34.html)'
- en: '[Understanding and Implementing Genetic Algorithms in Python](https://www.kdnuggets.com/understanding-and-implementing-genetic-algorithms-in-python)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中理解和实现遗传算法](https://www.kdnuggets.com/understanding-and-implementing-genetic-algorithms-in-python)'
- en: '[Machine Learning from Scratch: Decision Trees](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从头开始的机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
