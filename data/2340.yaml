- en: Simple and Fast Data Streaming for Machine Learning Projects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单快速的数据流用于机器学习项目
- en: 原文：[https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/b9f199330321477dc272afb77c29bb8e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流用于机器学习项目](../Images/b9f199330321477dc272afb77c29bb8e.png)'
- en: Image Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图像作者
- en: Have you ever wondered why you have to wait for DVC to pull all the files to
    access a single file? Maybe you have created custom scripts to work around this
    problem. But what if I tell you there is a better solution for this issue?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经想过为什么你必须等待 DVC 拉取所有文件才能访问单个文件？也许你创建了自定义脚本来解决这个问题。但如果我告诉你还有更好的解决方案，你会如何想？
- en: '[Direct Data Access](https://github.com/DagsHub/client/) makes it fairly easy
    for you to load single or multiple files from the DagsHub DVC server. You can
    also upload a single file or multiple files using Upload API. It will help you
    save time, as you won’t be pulling the entire dataset to push a single file.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[直接数据访问](https://github.com/DagsHub/client/) 使你能够轻松加载来自 DagsHub DVC 服务器的单个或多个文件。你还可以使用上传
    API 上传单个文件或多个文件。这将帮助你节省时间，因为你无需拉取整个数据集来推送单个文件。'
- en: Direct Data Access works better with all kinds of Python libraries. Especially
    those that use high levels of functionalities. In the case of a training machine
    learning model, you can pull the data directly into DataLoader and start training
    or fine-tuning the model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 直接数据访问在所有类型的 Python 库中表现更好，特别是那些使用高功能级别的库。在训练机器学习模型的情况下，你可以将数据直接加载到 DataLoader
    中，开始训练或微调模型。
- en: In this tutorial, we will look deep into DagsHub's Direct Data Access and train
    simple Yoga pose classification models using FastAI-2 and Direct Data Access.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将深入研究 DagsHub 的直接数据访问，并使用 FastAI-2 和直接数据访问训练简单的瑜伽姿势分类模型。
- en: Getting Started with Direct Data Access
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用直接数据访问
- en: Direct Data Access comes with [DagsHub](https://github.com/DagsHub/client/)
    client API. Instead of using `dvc pull` to download all the data, you can access
    the files on demand from DagsHub servers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 直接数据访问附带了 [DagsHub](https://github.com/DagsHub/client/) 客户端 API。你可以根据需要从 DagsHub
    服务器访问文件，而不是使用 `dvc pull` 下载所有数据。
- en: The streamed files are indistinguishable from the local files saved on your
    disk. You can provide a local file path, and it will fetch files from DagsHub.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 流式传输的文件与保存在本地磁盘上的文件无异。你可以提供一个本地文件路径，它会从 DagsHub 拉取文件。
- en: Install the DagsHub API using GitHub URL and pip command.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 GitHub URL 和 pip 命令安装 DagsHub API。
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: <class></class>
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: <class></class>
- en: Or
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Note:** currently, the Direct Data Access is in beta version with minor issues.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 目前，直接数据访问功能处于测试版，有一些小问题。'
- en: Manual Method
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动方法
- en: The manual method lets you stream files using DagsHubFilesystem.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 手动方法允许你使用 DagsHubFilesystem 流式传输文件。
- en: '**You just have to replace:**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**你只需替换：**'
- en: '| **Python API** | **DagsHub File System** |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| **Python API** | **DagsHub 文件系统** |'
- en: '| open() | fs.open() |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| open() | fs.open() |'
- en: '| os.stat() | fs.stat() |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| os.stat() | fs.stat() |'
- en: '| os.listdir() | fs.listdir() |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| os.listdir() | fs.listdir() |'
- en: '| os.scandir() | fs.scandir() |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| os.scandir() | fs.scandir() |'
- en: If you are in a Git repository, you don’t have to provide configuration parameters.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Git 仓库中，你不需要提供配置参数。
- en: 'To override automatically detected configuration, use:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要覆盖自动检测的配置，请使用：
- en: repo_url
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: repo_url
- en: username
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: username
- en: Password
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Password
- en: If you are outside the Git repository, you can also point to the project directory
    using the `project_root` argument.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Git 仓库外部，你也可以使用 `project_root` 参数指向项目目录。
- en: In the example, we have created a DagsHubFilesystem and displayed a list of
    files and folders using listdir().
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们创建了一个 DagsHubFilesystem 并使用 listdir() 显示了文件和文件夹的列表。
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It is showing “Mobilenet-Weights” and “Saved_Models” folders that are not available
    in the local directory but on the DVC server. In short, you have access to all
    the files that you can see in the DagsHub repository without performing the `dvc
    pull` command.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示了在本地目录中不可用但在 DVC 服务器上的“Mobilenet-Weights”和“Saved_Models”文件夹。简而言之，你可以访问在 DagsHub
    仓库中看到的所有文件，而无需执行 `dvc pull` 命令。
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Automatic Method
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动方法
- en: The `install_hooks` allows Python libraries (*some exceptions apply) to access
    DVC tracked files as if they are on your system. It is simple and fast.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`install_hooks` 允许 Python 库（*某些例外情况适用*）像访问系统上的文件一样访问 DVC 跟踪的文件。它简单且快速。'
- en: In the example below, we have invoked `install_hooks()` and used PIL.Image to
    display the image of a woman in a down dog yoga pose.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们调用了`install_hooks()`并使用PIL.Image显示了一张女人做下犬瑜伽姿势的图片。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/789836de3311bdae8f95c1da58639861.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流处理，适用于机器学习项目](../Images/789836de3311bdae8f95c1da58639861.png)'
- en: I know, it is magic. It will also amaze you with faster loading time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，这就像魔法一样。它也会让你惊讶于更快的加载时间。
- en: '**Note:** While using the DagsHubFilesystem or install_hooks command you will
    be asked to generate a temporary OAuth key for additive security.'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 使用DagsHubFilesystem或install_hooks命令时，会要求你生成一个临时OAuth密钥以增加安全性。'
- en: Yoga Pose Classification Using Direct Data Access
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Direct Data Access进行瑜伽姿势分类
- en: In this tutorial, we will fine-tune the Resnet34 model on the Yoga pose [dataset](https://dagshub.com/kingabzpro/Yoga-Pose-Classification)
    using Direct Data Access. The dataset consists of 5 classes of Yoga pose images
    and the images were extracted using Bing API.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用Direct Data Access对Resnet34模型进行微调，数据集为瑜伽姿势[数据集](https://dagshub.com/kingabzpro/Yoga-Pose-Classification)。该数据集包括5类瑜伽姿势图像，图像是通过Bing
    API提取的。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/5ccfbe25f6d40cd47cc6a4c3dda2ea88.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流处理，适用于机器学习项目](../Images/5ccfbe25f6d40cd47cc6a4c3dda2ea88.png)'
- en: Image by Author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Setting Up
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置
- en: You can fork and clone my [repository](https://dagshub.com/kingabzpro/Yoga-Pose-Classification)
    and run the command below on a Google Colab or Jupyter Notebook. The command requires
    a branch name, repo name, username, and access token. You can simply replace the
    placeholders with your configurations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以fork并克隆我的[仓库](https://dagshub.com/kingabzpro/Yoga-Pose-Classification)，并在Google
    Colab或Jupyter Notebook上运行下面的命令。该命令需要一个分支名称、仓库名称、用户名和访问令牌。你可以简单地用你的配置替换占位符。
- en: '**Note:** make sure you are inside the repository to activate Streaming.'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 请确保你在仓库内部以激活流媒体功能。'
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you are facing problems with getting started, check out the [Colab notebook](https://colab.research.google.com/drive/1h-vikoiyOd5heR_-U76ScpJuov2vtzin?usp=sharing).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在开始时遇到问题，可以查看[Colab笔记本](https://colab.research.google.com/drive/1h-vikoiyOd5heR_-U76ScpJuov2vtzin?usp=sharing)。
- en: Next, we will import Pytorch, FastAI, os, and Matplotlib. The project is based
    on the FastAI framework. Read the [documentation](https://docs.fast.ai/) to learn
    more.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将导入Pytorch、FastAI、os和Matplotlib。该项目基于FastAI框架。阅读[文档](https://docs.fast.ai/)以了解更多信息。
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Data Loader
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据加载器
- en: 'After invoking install_hooks(), we can automatically access the files using:
    `ImageDataloaders`.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用install_hooks()之后，我们可以通过：`ImageDataloaders`自动访问文件。
- en: It took 6.54 seconds to load and download the 18.1 MB dataset. It is fast compared
    to 73.84 seconds with `dvc pull` + ImageDataLoaders.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 加载和下载18.1 MB数据集花费了6.54秒。这相比使用`dvc pull` + ImageDataLoaders的73.84秒要快。
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Visualization
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化
- en: Our dataset is pretty simple and consists of various Yoga poses with labels.
    We will be using it to train our model. The Resnet34 does not require large data,
    even a few hundred images can provide state-of-the-art results.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集非常简单，包括各种带标签的瑜伽姿势。我们将使用它来训练我们的模型。Resnet34不需要大量数据，即使是几百张图像也能提供最先进的结果。
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/46d4008e4fecddd9536514de05b294d1.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流处理，适用于机器学习项目](../Images/46d4008e4fecddd9536514de05b294d1.png)'
- en: Model Fine-Tuning
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型微调
- en: Before we start fine-tuning, we need to set up MLflow for experiment tracking.
    DagsHub provides a free MLflow server. You just need to set the tracking URI,
    and we are good to go. You can find URI by clicking on the green button(Remote)
    on the repo page and accessing it through the MLflow tab.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始微调之前，我们需要设置MLflow以跟踪实验。DagsHub提供了一个免费的MLflow服务器。你只需设置跟踪URI，我们就可以开始了。你可以通过点击仓库页面上的绿色按钮（Remote）并通过MLflow选项卡访问URI。
- en: The `get_experiment_id` function generates and returns experiment id.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_experiment_id`函数生成并返回实验ID。'
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After that, activate tracking using mlflow.fastai.autolog(). It will log the
    experiment and send it to the MLflow server on DagsHub.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，使用mlflow.fastai.autolog()激活跟踪功能。它将记录实验并将其发送到DagsHub上的MLflow服务器。
- en: Finally, we will build our learner with resnet34 and set metrics to accuracy
    and error_rate.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将用resnet34构建我们的学习器，并将指标设置为准确率和错误率。
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After fine-tuning for 3 epochs, we got state-of-the-art results with 95.9% accuracy
    and 0.04 loss.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 微调3个epoch后，我们获得了95.9%的准确率和0.04的损失，取得了最先进的结果。
- en: '| **epoch** | **train_loss** | **valid_loss** | **accuracy** | **error_rate**
    | **time** |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| **epoch** | **train_loss** | **valid_loss** | **accuracy** | **error_rate**
    | **time** |'
- en: '| 0 | 0.368970 | 0.154318 | 0.954315 | 0.045685 | 00:05 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.368970 | 0.154318 | 0.954315 | 0.045685 | 00:05 |'
- en: '| 1 | 0.220782 | 0.127155 | 0.964467 | 0.035533 | 00:05 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.220782 | 0.127155 | 0.964467 | 0.035533 | 00:05 |'
- en: '| 2 | 0.145330 | 0.116135 | 0.959391 | 0.040609 | 00:05 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.145330 | 0.116135 | 0.959391 | 0.040609 | 00:05 |'
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Note:** If you are using Colab to train a model, you need to set tag to link
    commit with experiment results using: `mlflow.set_tag(''mlflow.source.git.commit'',
    "<commit-id>")`'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 如果你使用 Colab 训练模型，你需要设置标签以将提交与实验结果关联，使用：`mlflow.set_tag(''mlflow.source.git.commit'',
    "<commit-id>")`'
- en: Save the model and use it for Inference and reproducibility.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 保存模型并用于推断和可重复性。
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Simple Prediction
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单预测
- en: Let’s get a random image from a training set to predict the label.  As you can
    see, we get the Downdog label with 99.99% certainty.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从训练集中获取一张随机图像来预测标签。正如你所见，我们以 99.99% 的确定性获得了 Downdog 标签。
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Evaluation
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: The model evaluation shows that the model has accurately predicted all of the
    images.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估显示模型准确地预测了所有图像。
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/84bedd1062e31a73f982431661497eba.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![简单快捷的数据流处理用于机器学习项目](../Images/84bedd1062e31a73f982431661497eba.png)'
- en: MLflow
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLflow
- en: You can review past experiments and results using the DagsHub experiment tab.
    I was first training with Keras MobilenetV3 and various other models. In the end,
    I chose FastAI and Resnet34 for simplicity and better results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 DagsHub 实验标签查看过去的实验和结果。我最初使用 Keras MobilenetV3 和其他各种模型进行训练。最后，我选择了 FastAI
    和 Resnet34，以获得更简单和更好的结果。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/ffcba172d5d27efeb1b76a45ae94f463.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![简单快捷的数据流处理用于机器学习项目](../Images/ffcba172d5d27efeb1b76a45ae94f463.png)'
- en: Image from [kingabzpro/Yoga-Pose-Classification](https://dagshub.com/kingabzpro/Yoga-Pose-Classification/experiments/#/)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [kingabzpro/Yoga-Pose-Classification](https://dagshub.com/kingabzpro/Yoga-Pose-Classification/experiments/#/)
- en: DagsHub Data Upload API
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DagsHub 数据上传 API
- en: The streaming goes both ways. You can also upload single or multiple files using
    the DagsHub Upload API.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 流式传输是双向的。你也可以使用 DagsHub 上传 API 上传单个或多个文件。
- en: To test our model on unseen data, let's download the Yoga Pose images from Google.
    We will be uploading the images and by using Streaming, we will be accessing them
    for prediction.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在未见过的数据上测试我们的模型，让我们从 Google 下载瑜伽姿势图像。我们将上传这些图像，并通过流式传输访问它们进行预测。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/1115add7eec3555469eb1c571f93d32c.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![简单快捷的数据流处理用于机器学习项目](../Images/1115add7eec3555469eb1c571f93d32c.png)'
- en: Image form Google search
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 Google 搜索
- en: We will use upload.Repo to create a repo object. It will help us directly upload
    files using a username, access token, repository name, and branch.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `upload.Repo` 创建一个 repo 对象。这将帮助我们通过用户名、访问令牌、仓库名称和分支直接上传文件。
- en: '**Note:** For uploading, you don’t even need to clone any git repository.'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 上传时，你甚至不需要克隆任何 Git 仓库。'
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Uploading Multiple Files
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传多个文件
- en: To Upload multiple files, we need to provide a folder directory. If the folder
    name does not exist, it will create one for you.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要上传多个文件，我们需要提供一个文件夹目录。如果文件夹名称不存在，它会为你创建一个。
- en: In the next step, we are using a loop to add 2 new yoga pose image files and
    committing it with message and versioning.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，我们使用循环添加 2 个新的瑜伽姿势图像文件，并使用消息和版本控制提交。
- en: By using the versioning, you can upload the files that are tracked by Git or
    DVC.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用版本控制，你可以上传由 Git 或 DVC 跟踪的文件。
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The files are successfully uploaded. Hurray!!!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 文件已成功上传。太棒了!!!
- en: It is awesome.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是太棒了。
- en: I was so happy when I uploaded the files for the first time without cloning
    the Git repository and pulling dvc data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当我第一次上传文件而不克隆 Git 仓库并拉取 DVC 数据时，我非常高兴。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/e873359bb8cdb21bb587928894987b64.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![简单快捷的数据流处理用于机器学习项目](../Images/e873359bb8cdb21bb587928894987b64.png)'
- en: Uploading Single File
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传单个文件
- en: You can also upload a file using a single line, by providing a local file and
    repository file path. With this you can upload files in any folder.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过提供本地文件和仓库文件路径来使用单行上传文件。这样，你可以将文件上传到任何文件夹中。
- en: In our case, we are uploading the third file to the Sample folder using message
    and dvc versioning.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们使用消息和 DVC 版本控制将第三个文件上传到 Sample 文件夹。
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The third image is successfully uploaded to the DagsHub repository.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 第三张图像已成功上传到 DagsHub 仓库。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/6271de110fa4911b3ed5f9a56a69d7ca.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流处理用于机器学习项目](../Images/6271de110fa4911b3ed5f9a56a69d7ca.png)'
- en: Model Prediction
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型预测
- en: Now, we will use the uploaded images to predict the Yoga Pose.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用上传的图像来预测瑜伽姿势。
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The model has accurately predicted the Warrior2 pose with 99.9% certainty.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型已以 99.9% 的准确度预测了 Warrior2 姿势。
- en: '![Simple and Fast Data Streaming for Machine Learning Projects](../Images/5d4d3cf4ab050928f77e953971ab1795.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![简单快速的数据流处理用于机器学习项目](../Images/5d4d3cf4ab050928f77e953971ab1795.png)'
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**Note:** to access recently uploaded files, you have to run `install_hooks()`
    again.'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 要访问最近上传的文件，您必须再次运行 `install_hooks()`。'
- en: Benchmark
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试
- en: Even though DagsHub's Direct Data Access is in the Beta stage, it shows promising
    results. With streaming, we have loaded the image files **11X** faster than `dvc
    pull`. There are still minor bugs that you will always see in the Beta version,
    but overall, I was impressed by the DagsHub team, who came up with an amazing
    solution.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 DagsHub 的直接数据访问仍处于 Beta 阶段，但它显示出了良好的前景。通过流式处理，我们加载图像文件的速度比 `dvc pull` 快 **11
    倍**。尽管 Beta 版本中仍有一些小的错误，但总体来说，我对 DagsHub 团队感到印象深刻，他们提出了一个令人惊叹的解决方案。
- en: '|  | **Streaming(s)** | **No-streaming(s)** |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | **流式处理(s)** | **非流式处理(s)** |'
- en: '| **Dataloader** | 6.54 | 73.84 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **数据加载器** | 6.54 | 73.84 |'
- en: '| **Training** | 74 | 72 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **培训** | 74 | 72 |'
- en: '| **Total** | **80.54** | **145.84** |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| **总计** | **80.54** | **145.84** |'
- en: In the end, I will ask everyone to give [Direct Data Access](https://github.com/DagsHub/client/)
    a try and ask questions in the [Discord](https://discord.com/invite/9gU36Y6) support
    channel, if you are facing issues.
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最后，我将请大家尝试一下 [直接数据访问](https://github.com/DagsHub/client/)，并在 [Discord](https://discord.com/invite/9gU36Y6)
    支持频道中提问，如果遇到问题。
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证数据科学专业人士，喜欢构建机器学习模型。目前，他专注于内容创作，并撰写有关机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是使用图神经网络构建一个人工智能产品，帮助那些患有心理疾病的学生。'
- en: '* * *'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过快速克里金法 (FKR) 加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[Building a Formula 1 Streaming Data Pipeline With Kafka and Risingwave](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Kafka 和 Risingwave 构建 Formula 1 流数据管道](https://www.kdnuggets.com/building-a-formula-1-streaming-data-pipeline-with-kafka-and-risingwave)'
- en: '[The Fast and Effective Way to Audit ML for Fairness](https://www.kdnuggets.com/2023/01/fast-effective-way-audit-ml-fairness.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[快速有效的机器学习公平性审计方法](https://www.kdnuggets.com/2023/01/fast-effective-way-audit-ml-fairness.html)'
- en: '[Practical Deep Learning from fast.ai is Back!](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实用深度学习课程由 fast.ai 带回来了！](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
- en: '[Python in Finance: Real Time Data Streaming within Jupyter Notebook](https://www.kdnuggets.com/python-in-finance-real-time-data-streaming-within-jupyter-notebook)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[金融中的 Python：在 Jupyter Notebook 中实时数据流](https://www.kdnuggets.com/python-in-finance-real-time-data-streaming-within-jupyter-notebook)'
- en: '[How to Build a Streaming Semi-structured Analytics Platform on Snowflake](https://www.kdnuggets.com/2023/07/build-streaming-semistructured-analytics-platform-snowflake.html)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在 Snowflake 上构建流式半结构化分析平台](https://www.kdnuggets.com/2023/07/build-streaming-semistructured-analytics-platform-snowflake.html)'
