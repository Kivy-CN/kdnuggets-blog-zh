["```py\n!pip install transformers datasets\n!pip install accelerate -U\n```", "```py\nfrom datasets import load_dataset\ndataset = load_dataset('jeffnyman/emotions')\n```", "```py\nfrom transformers import AutoTokenizer\n\ndef tokenize_function(examples):\n  return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```", "```py\nunique_labels = set(tokenized_datasets['train']['label'])\nprint(f\"Unique labels in the training set: {unique_labels}\")\n\ndef check_labels(dataset):\n  for label in dataset['train']['label']:\n    if label not in unique_labels:\n      print(f\"Found invalid label: {label}\")\n\ncheck_labels(tokenized_datasets)\n```", "```py\nfrom transformers import BertConfig\nfrom transformers import BertForSequenceClassification\n\nconfig = BertConfig(\nvocab_size=tokenizer.vocab_size,\nhidden_size=512,\nnum_hidden_layers=6,\nnum_attention_heads=8,\nintermediate_size=2048,\nmax_position_embeddings=512,\nnum_labels=len(unique_labels)\n)\n\nmodel = BertForSequenceClassification(config)\n```", "```py\nfrom transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n  output_dir='./results',\n  evaluation_strategy=\"epoch\",\n  learning_rate=2e-5,\n  per_device_train_batch_size=16,\n  per_device_eval_batch_size=16,\n  num_train_epochs=3,\n  weight_decay=0.01,\n)\n\ntrainer = Trainer(\n  model=model,\n  args=training_args,\n  train_dataset=tokenized_datasets[\"train\"],\n  eval_dataset=tokenized_datasets[\"test\"],\n)\n```", "```py\ntrainer.train()\n```", "```py\nimport os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n```", "```py\nImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\n```"]