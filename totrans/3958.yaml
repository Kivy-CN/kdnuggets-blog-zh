- en: 5 Tips for Using Regular Expressions in Data Cleaning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正则表达式进行数据清洗的 5 个技巧
- en: 原文：[https://www.kdnuggets.com/5-tips-for-using-regular-expressions-in-data-cleaning](https://www.kdnuggets.com/5-tips-for-using-regular-expressions-in-data-cleaning)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/5-tips-for-using-regular-expressions-in-data-cleaning](https://www.kdnuggets.com/5-tips-for-using-regular-expressions-in-data-cleaning)
- en: '![5 Tips for Using Regular Expressions in Data Cleaning](../Images/dd0cd3b5a960921fd88cc33160d7c5a8.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![5 Tips for Using Regular Expressions in Data Cleaning](../Images/dd0cd3b5a960921fd88cc33160d7c5a8.png)'
- en: Image by Author | Created on Canva
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片 | 使用 Canva 创建
- en: If you’re a Linux or a Mac user, you’ve probably used [grep](https://www.gnu.org/software/grep/manual/grep.html)
    at the command line to search through files by matching patterns. Regular expressions
    (regex) allow you to search, match, and manipulate text based on patterns. Which
    makes them powerful tools for text processing and data cleaning.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是 Linux 或 Mac 用户，你可能已经在命令行中使用过 [grep](https://www.gnu.org/software/grep/manual/grep.html)
    来通过匹配模式搜索文件。正则表达式（regex）允许你基于模式搜索、匹配和操作文本。这使得它们成为处理文本和清洗数据的强大工具。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: For regular expression matching operations in Python, you can use the built-in
    [re module](https://docs.python.org/3/library/re.html). In this tutorial, we’ll
    look at how you can use regular expressions to clean data.  We’ll look at removing
    unwanted characters, extracting specific patterns, finding and replacing text,
    and more.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Python 中的正则表达式匹配操作，你可以使用内置的 [re 模块](https://docs.python.org/3/library/re.html)。在本教程中，我们将探讨如何使用正则表达式来清洗数据。我们将讨论如何去除不需要的字符、提取特定模式、查找和替换文本等。
- en: 1\. Remove Unwanted Characters
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 去除不需要的字符
- en: 'Before we go ahead, let’s import the built-in re module:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们先导入内置的 re 模块：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: String fields (almost) always require extensive cleaning before you can analyze
    them. Unwanted characters—often resulting from varying formats—can make your data
    difficult to analyze. Regex can help you remove these efficiently.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串字段（几乎）总是需要广泛清洗才能进行分析。不需要的字符——通常源于不同的格式——会使你的数据难以分析。正则表达式可以帮助你高效地去除这些字符。
- en: 'You can use the `sub()` function from the re module to replace or remove all
    occurrences of a pattern or special character. Suppose you have strings with phone
    numbers that include dashes and parentheses. You can remove them as shown:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `sub()` 函数从 re 模块中替换或删除模式或特殊字符的所有出现。假设你有包含破折号和括号的电话号码字符串。你可以像下面这样去除它们：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, **re.sub(pattern, replacement, string)** replaces all occurrences of
    the pattern in the string with the replacement. We use the **r''[()-]''** pattern
    to match any occurrence of (, ), or - giving us the output:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**re.sub(pattern, replacement, string)** 将字符串中所有模式的出现替换为替换内容。我们使用 **r'[()-]'**
    模式来匹配任何出现的 (, ), 或 -，得到如下输出：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 2\. Extract Specific Patterns
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 提取特定模式
- en: Extracting email addresses, URLs, or phone numbers from text fields is a common
    task as these are relevant pieces of information. And to extract all specific
    patterns of interest, you can use the `findall()` function.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本字段中提取电子邮件地址、网址或电话号码是常见任务，因为这些都是相关的信息。为了提取所有特定的感兴趣模式，你可以使用 `findall()` 函数。
- en: 'You can extract email addresses from a text like so:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像这样从文本中提取电子邮件地址：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The **re.findall(pattern, string)** function finds and returns (as a list)
    all occurrences of the pattern in the string. We use the pattern **r''\b[\w.-]+?@\w+?\.\w+?\b''**
    to match all email addresses:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**re.findall(pattern, string)** 函数找到并返回（作为列表）字符串中所有模式的出现。我们使用模式 **r''\b[\w.-]+?@\w+?\.\w+?\b''**
    来匹配所有电子邮件地址：'
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 3\. Replace Patterns
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 替换模式
- en: We’ve already used the `sub()` function to remove unwanted special characters.
    But you can replace a pattern with another to make the field suitable for more
    consistent analysis.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of removing unwanted spaces:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The **r''\s+''** pattern matches one or more whitespace characters. The replacement
    string is a single space giving us the output:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 4\. Validate Data Formats
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Validating data formats ensures data consistency and correctness. Regex can
    validate formats like emails, phone numbers, and dates.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how you can use the `match()` function to validate email addresses:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this example, the email string is valid:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 5\. Split Strings by Patterns
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes you may want to split a string into multiple strings based on patterns
    or the occurrence of specific separators. You can use the `split()` function to
    do that.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s split the `text` string into sentences:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, **re.split(pattern, string)** splits the string at all occurrences of
    the pattern. We use the **r''[.!?]''** pattern to match periods, exclamation marks,
    or question marks:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Clean Pandas Data Frames with Regex
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Combining regex with pandas allows you to clean data frames efficiently.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'To remove non-alphabetic characters from names and validate email addresses
    in a data frame:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the above code snippet:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '`df[''names''].str.replace(pattern, replacement, regex=True)` replaces occurrences
    of the pattern in the series.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lambda x: bool(re.match(pattern, x))`: This lambda function applies the regex
    match and converts the result to a boolean.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The output is as shown:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Wrapping Up
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I hope you found this tutorial helpful. Let’s review what we’ve learned:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Use `re.sub` to remove unnecessary characters, such as dashes and parentheses
    in phone numbers and the like.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `re.findall` to extract specific patterns from text.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `re.sub` to replace patterns, such as converting multiple spaces into a
    single space.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Validate data formats with `re.match` to ensure data adheres to specific formats,
    like validating email addresses.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To split strings based on patterns, apply `re.split`.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In practice, you’ll combine regex with pandas for efficient cleaning of text
    fields in data frames. It’s also a good practice to comment your regex to explain
    their purpose, improving readability and maintainability.To learn more about data
    cleaning with pandas, read [7 Steps to Mastering Data Cleaning with Python and
    Pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    是来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇点上工作。她的兴趣和专长领域包括DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和喝咖啡！目前，她正在通过编写教程、操作指南、观点文章等方式向开发者社区学习和分享她的知识。Bala还创建了引人入胜的资源概述和编码教程。'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Mastering Regular Expressions with Python](https://www.kdnuggets.com/2023/08/mastering-regular-expressions-python.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Python掌握正则表达式](https://www.kdnuggets.com/2023/08/mastering-regular-expressions-python.html)'
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于掌握SQL、Python、数据清理、数据处理和探索性数据分析的指南集合](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
- en: '[The Importance of Data Cleaning in Data Science](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中数据清理的重要性](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)'
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费的电子书学习数据清理和预处理以进行数据科学](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
- en: '[Data Cleaning in SQL: How To Prepare Messy Data for Analysis](https://www.kdnuggets.com/data-cleaning-in-sql-how-to-prepare-messy-data-for-analysis)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL中的数据清理：如何准备混乱的数据以进行分析](https://www.kdnuggets.com/data-cleaning-in-sql-how-to-prepare-messy-data-for-analysis)'
- en: '[Getting Started Cleaning Data](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始清理数据](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
