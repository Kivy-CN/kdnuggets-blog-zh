# 使用 CatBoost 进行快速梯度提升

> 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)

[评论](#comments)

在梯度提升中，预测是通过一组弱学习器来完成的。与随机森林为每个样本创建一个决策树不同，在梯度提升中，树是一个接一个地创建的。模型中的前一棵树不会被更改。前一棵树的结果被用来改进下一棵树。在这篇文章中，我们将更深入地了解一个名为 CatBoost 的梯度提升库。

![图](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)

[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的信息技术

* * *

[CatBoost](https://github.com/catboost) 是一个由 [Yandex](https://yandex.com/company/) 开发的深度梯度提升库。它使用无意识决策树来生长平衡树。相同的特征用于每一层树的左右分裂。

![图](../Images/22cec580000a5a651f8a7b907b81bca5.png)

[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)

与经典树相比，无意识树在 CPU 上实现更高效，且更易于拟合。

### 处理分类特征

处理分类特征的常见方法是独热编码和标签编码。CatBoost 允许您在不需要预处理分类特征的情况下使用它们。

使用 CatBoost 时，我们不应使用独热编码，因为这会影响训练速度和预测质量。相反，我们只需使用 `cat_features` 参数指定分类特征。

### 使用 CatBoost 的优点

这里有几个考虑使用 CatBoost 的理由：

+   CatBoost 允许在多个 GPU 上训练数据。

+   它提供了使用默认参数的良好结果，从而减少了参数调整所需的时间。

+   由于减少了过拟合，提供了更高的准确性。

+   使用 CatBoost 的模型应用程序进行快速预测。

+   训练后的 CatBoost 模型可以导出到 Core ML 进行设备端推理（iOS）。

+   可以内部处理缺失值。

+   可以用于回归和分类问题。

### 训练参数

让我们来看看 CatBoost 中的一些常见参数：

+   `loss_function` 别名 `objective` — 用于训练的度量指标。这些是回归度量指标，例如回归的均方根误差和分类的logloss。

+   `eval_metric` — 用于检测过拟合的度量指标。

+   `iterations` — 最大树数量，默认为1000。它的别名有`num_boost_round`、`n_estimators`和`num_trees`。

+   `learning_rate` 别名 `eta` — 决定模型学习速度的学习率。默认值通常为0.03。

+   `random_seed` 别名 `random_state` — 用于训练的随机种子。

+   `l2_leaf_reg` 别名 `reg_lambda` — 成本函数L2正则化项的系数。默认值为3.0。

+   `bootstrap_type` — 确定对象权重的采样方法，例如Bayesian、Bernoulli、MVS和Poisson。

+   `depth` — 树的深度。

+   `grow_policy` — 确定贪婪搜索算法的应用方式。可以是`SymmetricTree`、`Depthwise`或`Lossguide`。`SymmetricTree`为默认选项。在`SymmetricTree`中，树按层构建，直到达到指定深度。在每一步中，前一棵树的叶子都用相同的条件进行分裂。当选择`Depthwise`时，树逐步构建，直到达到指定深度。在每一步中，上一层所有非终端叶子都会被分裂，叶子的分裂条件是导致最佳损失改善的条件。在`Lossguide`中，树逐叶构建，直到达到指定的叶子数。在每一步中，具有最佳损失改善的非终端叶子会被分裂。

+   `min_data_in_leaf` 别名 `min_child_samples` — 这是叶子中训练样本的最小数量。该参数仅在使用`Lossguide`和`Depthwise`生长策略时有效。

+   `max_leaves` 别名 `num_leaves` — 该参数仅在使用`Lossguide`策略时有效，用于确定树中的叶子数。

+   `ignored_features` — 指示在训练过程中应忽略的特征。

+   `nan_mode` — 处理缺失值的方法。选项包括`Forbidden`、`Min`和`Max`。默认值是`Min`。使用`Forbidden`时，缺失值会导致错误。使用`Min`时，缺失值被视为该特征的最小值。在`Max`中，缺失值被视为该特征的最大值。

+   `leaf_estimation_method` — 用于计算叶子中的值的方法。在分类问题中，使用10次`Newton`迭代。回归问题中使用分位数或MAE损失时使用一次`Exact`迭代。多分类使用一次`Newton`迭代。

+   `leaf_estimation_backtracking` — 梯度下降过程中使用的回溯类型。默认值是`AnyImprovement`。`AnyImprovement`会减少下降步长，直到损失函数值小于上一次迭代中的值。`Armijo`会减少下降步长，直到满足[Armijo条件](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature)。

+   `boosting_type` — 提升方案。可以是`plain`，用于经典的梯度提升方案，或`ordered`，在较小的数据集上提供更好的质量。

+   `score_function` — 用于在树构建过程中选择下一个分裂点的[评分类型](https://catboost.ai/docs/concepts/algorithm-score-functions.html)。`Cosine`是默认选项。其他可选项包括`L2`、`NewtonL2`和`NewtonCosine`。

+   `early_stopping_rounds` — 当设置为`True`时，将过拟合检测器类型设置为`Iter`，并在达到最佳指标时停止训练。

+   `classes_count` — 多分类问题中的类别数量。

+   `task_type` — 指示是否使用CPU或GPU。默认是CPU。

+   `devices` — 用于训练的GPU设备ID。

+   `cat_features` — 包含分类列的数组。

+   `text_features` — 用于在分类问题中声明文本列。

### 回归示例

CatBoost在其实现中使用了scikit-learn标准。让我们看看如何将其用于回归。

第一阶段——像往常一样——是导入回归器并实例化它。

```py
from catboost import CatBoostRegressor
cat = CatBoostRegressor()
```

在拟合模型时，CatBoost还允许通过设置`plot=true`来可视化模型：

```py
cat.fit(X_train,y_train,verbose=False, plot=True)
```

![帖子图片](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)

它还允许你进行交叉验证并可视化过程：

![帖子图片](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)

同样，你也可以执行网格搜索并可视化结果：

![帖子图片](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)

我们还可以使用CatBoost绘制树图。下面的图是第一棵树的图。可以看到，树的每一层的叶子都基于相同的条件进行分裂——例如297，值>0.5。

```py
cat.plot_tree(tree_idx=0)
```

![帖子图片](../Images/1bf072864f605a5db714f0a388c18dd4.png)

CatBoost还提供了一个包含所有模型参数的字典。我们可以通过遍历字典来打印这些参数。

```py
for key,value in cat.get_all_params().items():
 print(‘{}, {}’.format(key,value))
```

![帖子图片](../Images/33f889fb3e9caa39f98841f2938006c5.png)

### 结束语

在这部分中，我们探讨了CatBoost的优点和局限性，以及其主要训练参数。然后，我们通过scikit-learn进行了简单的回归实现。希望这能为你提供足够的信息，以便你可以进一步探索这个库。

[**CatBoost - 具有分类特征支持的最先进开源梯度提升库**](https://catboost.ai/)

CatBoost是一种用于决策树的梯度提升算法，由Yandex的研究人员和工程师开发...

[**Python 数据科学训练营**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)

学习 Python 数据科学、NumPy、Pandas、Matplotlib、Seaborn、Scikit-learn、Dask、LightGBM、XGBoost、CatBoost 等等...

**简介： [Derrick Mwiti](https://derrickmwiti.com/)** 是一名数据分析师、作家和导师。他致力于在每项任务中取得优异成绩，并且是 Lapid Leaders Africa 的导师。

[原文](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a)。经授权转载。

**相关：**

+   [LightGBM：高效的梯度提升决策树](https://www.kdnuggets.com/2020/06/lightgbm-gradient-boosting-decision-tree.html)

+   [理解梯度提升机](https://www.kdnuggets.com/2019/02/understanding-gradient-boosting-machines.html)

+   [在 Google Colaboratory 上利用免费 GPU 掌握快速梯度提升](https://www.kdnuggets.com/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)

### 了解更多相关内容

+   [CatBoost ML 给你的数据带来的 5 大优势，让数据变得更出色](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)

+   [提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)

+   [终极指南：掌握季节性和提升商业成果](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)

+   [BERT 在稀疏性下能走多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)

+   [使用快速克里金法（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)

+   [如何让 Python 代码运行得极快](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)
