- en: 8 New Tools I Learned as a Data Scientist in 2020
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2020年我作为数据科学家学习的8种新工具
- en: 原文：[https://www.kdnuggets.com/2021/01/8-new-tools-learned-data-scientist-2020.html](https://www.kdnuggets.com/2021/01/8-new-tools-learned-data-scientist-2020.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/8-new-tools-learned-data-scientist-2020.html](https://www.kdnuggets.com/2021/01/8-new-tools-learned-data-scientist-2020.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Ben Weber](https://www.linkedin.com/in/ben-weber-3b87482/), Distinguished
    Data Scientist at Zynga**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Ben Weber](https://www.linkedin.com/in/ben-weber-3b87482/)，Zynga的杰出数据科学家**'
- en: '![Figure](../Images/45ecc910201f8928de47528d7212dafc.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/45ecc910201f8928de47528d7212dafc.png)'
- en: '[Source](https://pixy.org/5939802/)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://pixy.org/5939802/)'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'While 2020 has been a challenging year, I was able to use the transition to
    remote work to explore new tools to expand my data science skill set. It was the
    year that I made the transition from data scientist to applied scientist, where
    I was responsible for not only prototyping data products, but also putting these
    systems into production and monitoring system health. I had prior experience with
    tools such as Docker for containerizing applications, but I didn’t have experience
    with deploying a container as a scalable, load balanced application. While many
    of the technologies that I learned in 2020 are more commonly associated with engineering
    rather than data science, it can be useful to learn these tools in order to learn
    to build end-to-end data products. This is especially true for data scientists
    working at startups. Here are the technologies I learned in 2020:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管2020年是一个充满挑战的年份，我还是利用远程工作的过渡期探索了新的工具，以扩展我的数据科学技能。这一年我从数据科学家转型为应用科学家，不仅负责原型设计数据产品，还要将这些系统投入生产并监控系统健康。我之前有使用Docker进行应用程序容器化的经验，但没有经验将容器部署为可扩展、负载均衡的应用程序。虽然我在2020年学到的许多技术更常与工程相关，而不是数据科学，但学习这些工具对于构建端到端的数据产品是有帮助的。这对于在初创公司工作的数据科学家尤为重要。以下是我在2020年学到的技术：
- en: MLflow
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MLflow
- en: Kubernetes
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes
- en: NoSQL
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NoSQL
- en: OpenRTB
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenRTB
- en: Java Web Frameworks
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Java Web框架
- en: HTTPS
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HTTPS
- en: Load Balancing
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负载均衡
- en: Logging
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志记录
- en: I’ll cover each of these topics in main detail below. The main motivation for
    getting hands on with all of these different tools was to build a research platform
    for programmatic advertising. I was responsible for building and maintaining a
    real-time data product, and needed to explore new tools to deliver on this project.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在下面详细介绍这些主题。使用这些不同工具的主要动机是为了建立一个程序化广告的研究平台。我负责构建和维护一个实时数据产品，需要探索新的工具来完成这个项目。
- en: MLflow
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLflow
- en: '[MLflow](https://mlflow.org/) is an open source framework for model lifecycle
    management. The goal of the project is to provide modules that support the development,
    serving, and monitoring of ML models. I starting using two of these components
    in 2020: MLflow tracking and Model Registry. The tracking module enables data
    scientists to record the performance of different model pipelines and visualize
    the results. For example, it’s possible to try out different feature scaling approaches,
    regression models, and hyperparameter combinations, and review which pipeline
    configuration produced the best results. I used this within the Databricks environment,
    which provides useful visualizations for model selection. I also started using
    the registry module in MLflow to store models, where a training notebook trains
    and stores a model, and a model application notebook retrieves and applies a model.
    One of the useful features in the model registry is the ability stage models prior
    to deployment. The registry can maintain different model versions and provides
    the ability to revert to a prior version if an issue is detected. In 2021, I plan
    on exploring more of the modules in MLFlow, including model serving.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[MLflow](https://mlflow.org/) 是一个开源框架，用于模型生命周期管理。项目的目标是提供支持机器学习模型开发、服务和监控的模块。我在2020年开始使用其中的两个组件：MLflow
    跟踪和模型注册表。跟踪模块使数据科学家能够记录不同模型管道的性能并可视化结果。例如，可以尝试不同的特征缩放方法、回归模型和超参数组合，并查看哪个管道配置产生了最佳结果。我在Databricks环境中使用了这个功能，它提供了有用的模型选择可视化工具。我还开始使用MLflow中的注册表模块来存储模型，其中一个训练笔记本训练并存储模型，而一个模型应用笔记本检索和应用模型。模型注册表中的一个有用功能是能够在部署之前对模型进行分阶段处理。注册表可以维护不同的模型版本，并提供在发现问题时回退到先前版本的能力。在2021年，我计划探索MLFlow中的更多模块，包括模型服务。'
- en: Kubernetes
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Kubernetes is an open source platform for container orchestration. It enables
    data scientists to deploy containers as scalable web applications, and provides
    a variety of configuration options for exposing services on the web. While it
    can be quite involved to set up a Kubernetes deployment from scratch, cloud platforms
    offered managed versions of Kubernetes that make it easy to get hands-on with
    this platform. My recommendation for data scientists that want to learn Kubernetes
    is to use Google Kubernetes Engine (GKE), because it provides fast cluster start
    up times and has a great developer experience.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个开源的容器编排平台。它使数据科学家能够将容器部署为可扩展的Web应用程序，并提供多种配置选项用于在Web上暴露服务。虽然从头开始设置Kubernetes部署可能相当复杂，但云平台提供了托管版本的Kubernetes，使得上手这个平台变得容易。我对希望学习Kubernetes的数据科学家的建议是使用Google
    Kubernetes Engine (GKE)，因为它提供了快速的集群启动时间，并具有出色的开发者体验。
- en: Why is Kubernetes so useful? Because it enables teams to separate application
    development and application deployment concerns. A data scientists can build a
    model serving container and then hand this off to an engineering team that exposes
    the service as a scalable web application. In GCP, it also integrates seamlessly
    with systems for load balancing and network security. However, with managed services
    such as GKE, there’s less of a barrier to using Kubernetes and data scientists
    should get hands-on experience with this platform. Doing so enables data scientists
    to build end-to-end data products.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么Kubernetes如此有用？因为它使团队能够将应用程序开发和应用程序部署问题分开。数据科学家可以构建一个模型服务容器，然后将其交给工程团队，后者将该服务暴露为可扩展的Web应用程序。在GCP中，它还与负载均衡和网络安全系统无缝集成。然而，使用托管服务如GKE，可以降低使用Kubernetes的门槛，数据科学家应当亲自体验这个平台。这样可以使数据科学家能够构建端到端的数据产品。
- en: NoSQL
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NoSQL
- en: While I’ve used a variety of databases throughout my data science career, it
    wasn’t until 2020 that I first explored NoSQL databases. NoSQL includes databases
    that implement key-value stores with low latency operations. For example, Redis
    is an in-memory database that provides sub-millisecond reads. This performance
    is useful when building real-time systems, where you need to update user profiles
    as data is received by a web service. For example, you may need to update the
    attributes of a feature vector that describes user activity, that is passed as
    input to a churn model and applied within the context of a HTTP post command.
    In order to build real-time systems, it’s essential for data scientists to get
    hands on with NoSQL databases. To learn technologies such as Redis, it’s useful
    to use [mock](https://github.com/fppt/jedis-mock) libraries to test out the API
    prior to deploying to the cloud.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我在数据科学职业生涯中使用了各种数据库，但直到2020年我才首次探索NoSQL数据库。NoSQL包括实现低延迟操作的键值存储数据库。例如，Redis是一个内存数据库，提供亚毫秒级的读取性能。这种性能在构建实时系统时非常有用，你需要在数据通过网络服务接收时更新用户档案。例如，你可能需要更新描述用户活动的特征向量的属性，该特征向量作为输入传递给流失模型，并在HTTP
    POST命令的上下文中应用。为了构建实时系统，数据科学家需要亲自使用NoSQL数据库。学习诸如Redis这样的技术时，使用[mock](https://github.com/fppt/jedis-mock)库来测试API在部署到云端之前是很有帮助的。
- en: OpenRTB
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenRTB
- en: OpenRTB is a specification for real-time ad auctions and ad serving. The specification
    is used across exchanges such as Google Ad Exchange in order to connect publishers
    selling ad inventory with buyers that want to serve advertisements. I used this
    protocol to implement a research platform for programmatic user acquisition. While
    this specification is not broadly applicable to data science, it is useful for
    data scientists learn how to build systems that can implement a standardized interface.
    In the case of OpenRTB, this involves building a web service that receives HTTP
    posts with JSON payloads and returns a JSON response with pricing details. If
    you’re interested in getting up and running with the OpenRTB specification, Google
    provides a [protobuf](https://github.com/google/openrtb) implementation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: OpenRTB是一种用于实时广告拍卖和广告投放的规范。该规范被用于如Google广告交换等交易所，以连接销售广告库存的出版商与希望投放广告的买家。我使用该协议实现了一个程序化用户获取的研究平台。虽然该规范对数据科学的广泛适用性不强，但对数据科学家学习如何构建能够实现标准化接口的系统非常有用。以OpenRTB为例，这涉及到构建一个接收带有JSON有效负载的HTTP
    POST请求并返回带有定价细节的JSON响应的网络服务。如果你有兴趣快速上手OpenRTB规范，Google提供了一个[protobuf](https://github.com/google/openrtb)实现。
- en: Java Web Frameworks
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Java Web Frameworks
- en: I decided to author the OpenRTB research platform in Java, since I have the
    most experience with this language. However, Rust and Go are both great alternatives
    to Java for building OpenRTB systems. Since I selected Java, I needed to select
    a web framework for implementing the endpoints for my application. While I used
    Jetty library over a decade ago to build simple web applications with Java, I
    decided to explore new tools based on benchmarks. I started with the [Rapidoid](https://www.rapidoid.org/) library,
    which is a lightweight and fast framework for building web applications with Java.
    However, as I started adding calls to Redis when responding to web requests, I
    found that I needed to move from the unmanaged to managed approach for serving
    requests with Rapidoid. I then tried out [Undertow](https://github.com/undertow-io/undertow) which
    supports blocking IO and found that it outperformed Rapidoid on my benchmark testing.
    While data scientists aren’t typically authoring in Java, it can be useful to
    learn how to try out different web frameworks, such choosing between gunicorn
    and uWSGI for deploying a Python web service.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定用Java编写OpenRTB研究平台，因为我对这种语言最为熟悉。然而，Rust和Go都是构建OpenRTB系统的绝佳替代选择。由于我选择了Java，我需要选择一个用于实现应用程序端点的Web框架。虽然我在十多年前使用Jetty库来构建简单的Java
    Web应用程序，但我决定根据基准测试探索新的工具。我从[Rapidoid](https://www.rapidoid.org/)库开始，它是一个用于用Java构建Web应用程序的轻量级和快速框架。然而，当我开始在响应Web请求时添加对Redis的调用时，我发现需要将Rapidoid从非托管模式转换为托管模式。我接着尝试了[Undertow](https://github.com/undertow-io/undertow)，它支持阻塞IO，并发现它在我的基准测试中表现优于Rapidoid。虽然数据科学家通常不使用Java编写代码，但学习如何尝试不同的Web框架，例如选择gunicorn和uWSGI来部署Python
    Web服务，是很有用的。
- en: '**HTTPS**'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**HTTPS**'
- en: Implementing the OpenRTB protocol now requires serving traffic over secure HTTP.
    Enabling HTTPS for a web service involves setting up web services as a named endpoint
    via DNS and using a signed certificate for establishing the identity of the endpoint.
    Securing endpoints on GCP hosted in GKE is relatively straight forward. Once the
    service is exposed using a node port and service ingress, you need to set up a
    DNS entry for the service’s IP address and then use a GCP managed certificate
    to enable HTTPS.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实施 OpenRTB 协议现在需要通过安全的 HTTP 服务流量。为 Web 服务启用 HTTPS 涉及通过 DNS 将 Web 服务设置为命名端点，并使用签名证书来建立端点的身份。确保
    GCP 上托管的 GKE 中的端点安全相对简单。一旦服务通过节点端口和服务入口暴露出来，你需要为服务的 IP 地址设置一个 DNS 条目，然后使用 GCP
    托管的证书来启用 HTTPS。
- en: It’s useful for data scientists to learn about setting up HTTPS endpoints, because
    of some of the subtleties in securing services. If end-to-end HTTPS is not required,
    as in the case of OpenRTB, where HTTP can be used internally between the load
    balancer and pods in the Kubernetes cluster, then deployment is easier. If end-to-end
    HTTPS is required, such as a web service that uses OAuth, then the Kubernetes
    configuration is a bit more complicated, because the pods may need to respond
    to health pings on a separate port from the port that serves web requests. I ended
    up submitting a [PR](https://github.com/lchapo/dash-google-auth/pull/15) to resolve
    an issue related to this for Plotly Dash applications using OAuth.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据科学家来说，学习设置 HTTPS 端点非常有用，因为这涉及到保护服务的细微差别。如果不需要端到端 HTTPS，比如在 OpenRTB 的情况下，其中
    HTTP 可以在负载均衡器和 Kubernetes 集群中的 pods 之间内部使用，那么部署就会更容易。如果需要端到端 HTTPS，比如使用 OAuth
    的 Web 服务，那么 Kubernetes 配置会稍微复杂一些，因为 pods 可能需要在与服务 Web 请求的端口不同的端口上响应健康检查。我最后提交了一个
    [PR](https://github.com/lchapo/dash-google-auth/pull/15) 来解决与此相关的 Plotly Dash
    应用程序中的一个问题。
- en: Load Balancing
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负载均衡
- en: To scale to OpenRTB volumes of web traffic, I needed to use a load balancing
    to process over 100k web request per second (QPS). Kubernetes provides the infrastructure
    to scale up the number of pods serving web requests, but it’s also necessary to
    configure the cluster in a way that evenly distributes requests across the cluster.
    Kubernetes has an [open issue](https://learnk8s.io/kubernetes-long-lived-connections) that
    causes uneven load across pods with using long-lived connections, which is a recommended
    configuration for OpenRTB systems. I used the [container native](https://cloud.google.com/kubernetes-engine/docs/how-to/container-native-load-balancing) load
    balancing feature available in GKE to alleviate this issue. Getting hands on with
    load balancing is not common for data scientists working in large organizations,
    but it’s a useful skill set to build for startups or teams that own end-to-end
    data products with high request volumes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展到 OpenRTB 量级的 Web 流量，我需要使用负载均衡来处理每秒超过 10 万个 Web 请求 (QPS)。Kubernetes 提供了扩展服务
    Web 请求的 pods 数量的基础设施，但还需要以一种均匀分配请求的方式配置集群。Kubernetes 有一个 [open issue](https://learnk8s.io/kubernetes-long-lived-connections)
    导致使用长连接时 pods 负载不均，这是 OpenRTB 系统推荐的配置。我使用了 [container native](https://cloud.google.com/kubernetes-engine/docs/how-to/container-native-load-balancing)
    的负载均衡功能来缓解这个问题。对负载均衡进行实际操作在大型组织中对数据科学家来说并不常见，但对于拥有高请求量的端到端数据产品的初创公司或团队来说，这是一个有用的技能。
- en: Logging
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 日志记录
- en: Deploying a web application also involves setting up monitoring for the system,
    to determine if any issues are occurring. When building applications with GCP,
    StackDriver provides a managed system for logging messages, reporting custom metrics,
    and setting up alerts. I was able to use this system for monitoring uptime, and
    firing alerts to Slack and SMS when incidents occurred. It’s useful for data scientists
    to get hands on with logging libraries, to make sure that systems deployed to
    the cloud are operating as expected.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 Web 应用程序还涉及到为系统设置监控，以确定是否出现任何问题。在构建 GCP 应用程序时，StackDriver 提供了一个用于日志消息、报告自定义指标和设置警报的托管系统。我能够利用这个系统来监控正常运行时间，并在发生事件时向
    Slack 和 SMS 发送警报。对数据科学家来说，实际操作日志库非常有用，以确保部署到云中的系统按预期运行。
- en: Conclusion
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: In 2020, I learned several technologies that are typically associated with engineering
    roles. As a data scientist, I learned these tools out of necessity, in order to
    build and maintain an end-to-end system. While many of these technologies are
    not broadly applicable to data science, the growing role of applied scientist
    is creating demand for data scientists with broader tech stack experience.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020年，我学习了几种通常与工程角色相关的技术。作为一名数据科学家，我出于必要学习了这些工具，以建立和维护端到端系统。虽然许多这些技术在数据科学中并不广泛适用，但应用科学家的角色日益增长，正在对拥有更广泛技术栈经验的数据科学家产生需求。
- en: '**Bio: [Ben Weber](https://www.linkedin.com/in/ben-weber-3b87482/)** is a Distinguished
    Data Scientist at Zynga and author of "[Data Science in Production](https://www.amazon.com/gp/product/B083H2YWP4)."'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [本·韦伯](https://www.linkedin.com/in/ben-weber-3b87482/)** 是Zynga的杰出数据科学家，也是《[数据科学生产](https://www.amazon.com/gp/product/B083H2YWP4)》一书的作者。'
- en: '[Original](https://towardsdatascience.com/8-new-tools-i-learned-as-a-data-scientist-in-2020-6dea2f847c32).
    Reposted with permission.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/8-new-tools-i-learned-as-a-data-scientist-in-2020-6dea2f847c32)。转载已获许可。'
- en: '**Related:**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[MLOps Is Changing How Machine Learning Models Are Developed](/2020/12/mlops-changing-machine-learning-developed.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps正在改变机器学习模型的开发方式](/2020/12/mlops-changing-machine-learning-developed.html)'
- en: '[5 Tools for Effortless Data Science](/2021/01/5-tools-effortless-data-science.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[轻松数据科学的5种工具](/2021/01/5-tools-effortless-data-science.html)'
- en: '[5 Most Useful Machine Learning Tools every lazy full-stack data scientist
    should use](/2020/11/5-useful-machine-learning-tools.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位懒散的全栈数据科学家应该使用的5种最有用的机器学习工具](/2020/11/5-useful-machine-learning-tools.html)'
- en: More On This Topic
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[What I Learned From Using ChatGPT for Data Science](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我从使用ChatGPT进行数据科学中学到了什么](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)'
- en: '[KDnuggets News, May 25: The 6 Python Machine Learning Tools Every…](https://www.kdnuggets.com/2022/n21.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，5月25日：每个数据科学家应该了解的6种Python机器学习工具…](https://www.kdnuggets.com/2022/n21.html)'
- en: '[The 6 Python Machine Learning Tools Every Data Scientist Should Know About](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应该了解的6种Python机器学习工具](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
- en: '[Tools Every Data Scientist Should Know: A Practical Guide](https://www.kdnuggets.com/tools-every-data-scientist-should-know-a-practical-guide)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家应该了解的工具：实用指南](https://www.kdnuggets.com/tools-every-data-scientist-should-know-a-practical-guide)'
- en: '[KDnuggets™ News 22:n01, Jan 5: 3 Tools to Track and Visualize…](https://www.kdnuggets.com/2022/n01.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™新闻22:n01，1月5日：跟踪和可视化的3种工具…](https://www.kdnuggets.com/2022/n01.html)'
- en: '[5 Tools Every Data Scientist Needs in Their Toolbox in 2024](https://www.kdnuggets.com/5-tools-every-data-scientist-needs-in-their-toolbox-in-2024)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2024年每位数据科学家工具箱中必备的5种工具](https://www.kdnuggets.com/5-tools-every-data-scientist-needs-in-their-toolbox-in-2024)'
