- en: 'Evaluating Data Science Projects: A Case Study Critique'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估数据科学项目：案例研究批评
- en: 原文：[https://www.kdnuggets.com/2017/09/evaluating-data-science-projects-case-study-critique.html](https://www.kdnuggets.com/2017/09/evaluating-data-science-projects-case-study-critique.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/09/evaluating-data-science-projects-case-study-critique.html](https://www.kdnuggets.com/2017/09/evaluating-data-science-projects-case-study-critique.html)
- en: '**By Tom Fawcett, [Silicon Valley Data Science](https://svds.com/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Tom Fawcett，[硅谷数据科学](https://svds.com/)。**'
- en: '![Header image](../Images/39ef661f48b52db378d2dd9fb02e5b3d.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Header image](../Images/39ef661f48b52db378d2dd9fb02e5b3d.png)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'I’ve written [two](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) [blog
    posts](https://www.svds.com/classifiers2/) on evaluation—the broccoli of machine
    learning. There are actually two closely related concerns under the rubric of
    evaluation:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我写了 [两篇](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) [博客文章](https://www.svds.com/classifiers2/)
    讨论评估——机器学习中的“西兰花”。实际上，评估下有两个密切相关的关注点：
- en: '*Model evaluation* is typically taught to data scientists and concerns the
    technical quality of a model: How well does the model perform? Can we trust the
    numbers? Are they statistically significant?'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型评估* 通常教授给数据科学家，涉及模型的技术质量：模型表现如何？我们能相信这些数字吗？它们在统计上是否显著？'
- en: '*Project evaluation* includes model evaluation, but also asks questions of
    the application context: Is the right problem being solved? Is the performance
    metric appropriate to the task? How are the data being provided and how is the
    model result used? Are the costs acceptable?'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*项目评估* 包括模型评估，但也要考虑应用背景的问题：是否解决了正确的问题？性能指标是否适合任务？数据是如何提供的，模型结果是如何使用的？成本是否可以接受？'
- en: 'Both types are important not only to data scientists but also to managers and
    executives, who must evaluate project proposals and results. To managers I would
    say: It’s not necessary to understand the inner workings of a machine learning
    project, but you should understand whether the right things have been measured
    and whether the results are suited to the business problem. You need to know whether
    to believe what data scientists are telling you.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种类型不仅对数据科学家很重要，对管理者和高管也同样重要，他们必须评估项目提案和结果。我会对管理者说：不必了解机器学习项目的内部工作原理，但你应该理解是否测量了正确的东西，结果是否适合业务问题。你需要知道是否要相信数据科学家告诉你的内容。
- en: 'To this end, here I’ll evaluate a machine learning project report. I found
    this work described as a customer success story on a [popular machine learning
    blog](https://cloud.google.com/blog/big-data/2017/03/using-machine-learning-for-insurance-pricing-optimization).
    The write-up was posted in early 2017, along with a related video presenting the
    results. Some aspects are confusing, as you’ll see, but I haven’t sought clarification
    from the authors because I wanted to critique it just as reported. This makes
    for a realistic case study: you often have to evaluate projects with missing or
    confusing details.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我将在这里评估一个机器学习项目报告。我发现这项工作被描述为在一个 [流行的机器学习博客](https://cloud.google.com/blog/big-data/2017/03/using-machine-learning-for-insurance-pricing-optimization)上的客户成功故事。这个写作发表于2017年初，同时发布了一个展示结果的相关视频。有些方面令人困惑，如你所见，但我没有向作者寻求澄清，因为我希望像报告中那样进行批评。这使得这个案例研究具有现实性：你经常需要评估缺少或令人困惑的细节的项目。
- en: As you’ll see, we’ll uncover some common application mistakes that even professional
    data scientists can make.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你将看到的，我们将揭示一些即使是专业数据科学家也可能犯的常见应用错误。
- en: The Problem
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: 'The problem is presented as this: A large insurance company wants to predict
    especially large insurance claims. Specifically, they divide their population
    into drivers who report an accident (7–10%), drivers who have no accidents (90–93%),
    and so-called *large-loss* drivers who report an accident involving damages of
    $10,000 or more (about 1% of their population). It is only the last group involved
    in large, expensive claims that they want to detect. They are facing a two-class
    problem, whose classes they call **Large Loss** and **Non-Large Loss**.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的呈现方式如下：一家大型保险公司希望预测特别大的保险索赔。具体而言，他们将其人群划分为报告事故的驾驶员（7-10%）、没有事故的驾驶员（90-93%）和所谓的*大损失*驾驶员，这些驾驶员报告涉及1万美元或更多损害的事故（约占其人群的1%）。他们只希望检测最后一组涉及大额索赔的群体。他们面临的是一个两类问题，这些类别被称为**大损失**和**非大损失**。
- en: Readers acquainted with my [prior](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) [posts](https://www.svds.com/classifiers2/) may
    recall I’ve talked about how common unbalanced classes are in real-world machine
    learning problems. Indeed, here we see a 99:1 skew where the positive (Large-Loss)
    instances are outnumbered by the uninteresting negative instances by about two
    orders of magnitude. (By the way, this would be considered very skewed by ML research
    standards, though it’s on the lighter side by real-world standards.) Because of
    this skew, we have to be careful in evaluation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉我[之前](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) [文章](https://www.svds.com/classifiers2/)的读者可能会记得我谈到过现实世界中的机器学习问题中常见的不平衡类别。确实，在这里我们看到一个99:1的偏斜，其中正类（大损失）实例的数量比不感兴趣的负类实例少了两个数量级。（顺便说一下，这在机器学习研究标准下会被认为是非常偏斜的，但在现实世界标准下则属于轻微偏斜。）由于这种偏斜，我们在评估时必须小心。
- en: The Approach
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 方法
- en: Their approach was fairly straightforward. They had a historical data sample
    of previous drivers’ records on which to train and test. They represented each
    driver’s record using 70 features, encompassing both categorical and numerical
    features, although only a few of these are shown.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的方法相当直接。他们有一个关于之前驾驶员记录的历史数据样本用于训练和测试。他们使用70个特征来表示每个驾驶员的记录，这些特征涵盖了分类特征和数值特征，尽管这里只展示了一部分。
- en: 'They state that their client had previously used a Random Forest to solve this
    problem. A Random Forest is a well known and popular technique that builds an
    ensemble of decision trees to classify instances. They hope to do better using
    a deep learning neural network. Their network design looks like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 他们表示，他们的客户之前使用了随机森林来解决这个问题。随机森林是一种广泛使用且受欢迎的技术，它通过构建一组决策树来对实例进行分类。他们希望通过使用深度学习神经网络取得更好的效果。他们的网络设计如下：
- en: '[![tensorflow-insurance-3](../Images/842cc638c45b9045837bc12c145f114f.png)](https://cloud.google.com/blog/big-data/2017/03/images/149073588641246/tensorflow-insurance-3.png)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[![tensorflow-insurance-3](../Images/842cc638c45b9045837bc12c145f114f.png)](https://cloud.google.com/blog/big-data/2017/03/images/149073588641246/tensorflow-insurance-3.png)'
- en: The model is a fully connected neural network with three hidden layers, with
    a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) as the activation
    function. They state that data from Google Compute Engine was used to train the
    model (implemented in TensorFlow), and Cloud Machine Learning Engine’s HyperTune
    feature was used to tune hyperparameters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是一个具有三层隐藏层的全连接神经网络，使用[ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))作为激活函数。他们表示使用了来自Google
    Compute Engine的数据来训练模型（使用TensorFlow实现），并使用了Cloud Machine Learning Engine的HyperTune功能来调整超参数。
- en: 'I have no reason to doubt their representation choices or network design, but
    one thing looks odd. Their output is two ReLU (rectifier) units, each emitting
    the network’s accuracy (technically: recall) on that class. I would’ve chosen
    a single [Softmax](https://en.wikipedia.org/wiki/Softmax_function) unit representing
    the probability of Large Loss driver, from which I could get a [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or [Precision-Recall](https://en.wikipedia.org/wiki/Precision_and_recall) curve.
    I could then threshold the output to get any achievable performance on the curve.
    (I explain the advantages of scoring over hard classification [in this post](https://www.svds.com/classifiers2/).)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有理由怀疑他们的表示选择或网络设计，但有一点看起来很奇怪。他们的输出是两个ReLU（整流）单元，每个单元发出该类别的网络准确率（技术上：召回率）。我会选择一个代表大损失驾驶员概率的[Softmax](https://en.wikipedia.org/wiki/Softmax_function)单元，从中我可以得到一个[ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)或[精确度-召回率](https://en.wikipedia.org/wiki/Precision_and_recall)曲线。然后我可以对输出进行阈值处理，以获得曲线上任何可实现的性能。（我在[这篇文章](https://www.svds.com/classifiers2/)中解释了评分优于硬分类的优势。）
- en: But I’m not a neural network expert, and the purpose here isn’t to critique
    their network design, just their general approach. I assume they experimented
    and are reporting the best performance they found.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但我不是神经网络专家，这里目的不是批评他们的网络设计，只是他们的一般方法。我假设他们进行了实验，并报告了他们找到的最佳性能。
- en: The Results
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果
- en: Their method of presenting test results is confusing. At the very outset, they
    report 78% accuracy—which is odd, both because [accuracy is an uninformative measure](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/) for
    this skewed domain and because simply always saying **Non-Large Loss** should
    yield 99% accuracy. These two points are not unrelated.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 他们呈现测试结果的方法令人困惑。一开始，他们报告了78%的准确率——这很奇怪，因为[准确率是这个偏斜领域的一个无信息量的指标](https://www.svds.com/the-basics-of-classifier-evaluation-part-1/)，并且因为仅仅总是说**非大损失**应该会产生99%的准确率。这两点并不无关。
- en: 'But further down they show this as their end result:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但是进一步下方他们展示了这个作为最终结果：
- en: '[![tensorflow-insurance-1](../Images/471b0e646b2ba38fc1a7a92575b3cb26.png)](https://cloud.google.com/blog/big-data/2017/03/images/149073588641246/tensorflow-insurance-1.png)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[![tensorflow-insurance-1](../Images/471b0e646b2ba38fc1a7a92575b3cb26.png)](https://cloud.google.com/blog/big-data/2017/03/images/149073588641246/tensorflow-insurance-1.png)'
- en: The graph is missing *x* and *y* markings, so it’s hard to get much out of the
    curves. The only information is at the top. They are reporting *two* accuracies,
    one for each class. This changes things—they’re not using composite classification
    accuracy (the common meaning of “accuracy”) but the recall on each class. We can
    calculate some of the information to evaluate their system. Is it enough?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图表缺少*x*和*y*标记，所以很难从曲线中获得很多信息。唯一的信息在顶部。他们报告了*两个*准确率，一个针对每个类别。这改变了情况——他们不是使用综合分类准确率（“准确率”的常见含义），而是每个类别的召回率。我们可以计算一些信息来评估他们的系统。这够吗？
- en: The **Large Loss** accuracy (recognition rate) is 0.78\. By convention, the
    rare class is usually positive, so this means the True Positive (TP) rate is 0.78,
    and the False Negative rate (1 – True Positive rate) is 0.22\. The **Non-Large
    Loss** recognition rate is 0.79, so the True Negative rate is 0.79 and the False
    Positive (FP) rate is 0.21.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**大损失**准确率（识别率）是0.78。根据惯例，稀有类别通常为正类，所以这意味着真正正例（TP）率是0.78，假阴性率（1 – 真正正例率）是0.22。**非大损失**识别率是0.79，所以真正负例率是0.79，假阳性（FP）率是0.21。'
- en: What they had previously reported as Random Forest Accuracy is 0.39\. Now we
    realize that this value is really the single-class recognition rate on the **Large
    Loss** class, so it is the Random Forest’s True Positive rate. They don’t report
    a False Positive rate (or True Negative rate, from which we could have calculated
    it). That’s a problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 他们之前报告的随机森林准确率是0.39。现在我们意识到，这个值实际上是**大损失**类别的单类识别率，因此它是随机森林的真正正例率。他们没有报告假阳性率（或真正负例率，我们可以从中计算）。这有问题。
- en: That concludes their report.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是他们报告的全部。
- en: Critique
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评价
- en: The first criticism is fairly obvious. They report only a *single* run of training
    and testing, so regardless of any other issues we really have only a single result
    to work with. We should want multiple runs using cross-validation or bootstrap
    to provide an indication of variation. As it is, we have no confidence that these
    numbers are representative. Most Machine Learning courses introduce the student
    to basic model evaluation and emphasize the need for multiple evaluations to establish
    confidence regions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个批评是相当明显的。他们仅报告了一个训练和测试的*单个*运行结果，因此无论其他问题如何，我们确实只有一个结果可用于工作。我们应该使用交叉验证或自助法进行多次运行，以提供变异的指示。如此一来，我们无法确信这些数字是否具有代表性。大多数机器学习课程都介绍了基本的模型评估，并强调需要多次评估来建立置信区间。
- en: So how good is their solution?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 那么他们的解决方案有多好？
- en: 'Bottom line: We don’t know. They haven’t given us enough information. Probably
    not as good as they think.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 底线是：我们不知道。他们没有给出足够的信息。可能没有他们认为的那么好。
- en: Here is an [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) illustrating
    the classifiers. Such diagrams allow us to see the performance as a trade-off
    between sensitivity and specificity (equivalently, between False Positives and
    True Positives).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个[ROC曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)说明分类器的图表。这样的图表允许我们看到在灵敏度和特异性之间（等效地，在假阳性和真阳性之间）的性能折衷。
- en: '![ROC plot](../Images/fe26481a60e8e069a3a158020c287190.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![ROC图](../Images/fe26481a60e8e069a3a158020c287190.png)'
- en: If these researchers had provided simultaneous values of TP rate and FP rate,
    we could draw a nice curve in ROC space, but they’ve given us only enough to draw
    a single point for the neural network, shown in blue.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些研究人员同时提供了TP率和FP率的值，我们可以在ROC空间中绘制一个漂亮的曲线，但是他们只给了我们足够绘制神经网络的单个点，显示为蓝色。
- en: Again, all we have for the Random Forest is a single True Positive rate value
    (0.39) but not the accompanying False Positive rate. This isn’t enough; by simply
    classifying *everything* as **Large Loss**, we could get a Large-Loss accuracy
    of 1.00\. We need the other coordinate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们对于随机森林只有一个真阳性率值（0.39），但没有伴随的假阳性率。这不够用；仅仅将*所有*东西分类为**大损失**，我们可以得到1.00的大损失准确率。我们需要另一个坐标点。
- en: On the ROC graph, I’ve shown RF performance by the green line at *y*=0.39\.
    The RF performance is a single point somewhere on that line. If its False Positive
    rate is less than about 0.10, Random Forest is actually better than the neural
    network. So we can’t even answer which model is better.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在ROC图上，我用绿线显示了随机森林在*y*=0.39处的性能。随机森林的性能是该线上的某一点。如果其假阳性率小于约0.10，随机森林实际上比神经网络更好。因此，我们甚至不能回答哪个模型更好。
- en: Let’s ask another question: *Is their deep learning solution usable?*
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再问一个问题：*他们的深度学习解决方案可用吗？*
- en: 'Bottom line: No, these results are probably not good enough for the insurance
    company.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 底线是：不，这些结果可能不够好，不能满足保险公司的要求。
- en: 'Here is the reasoning. In order to judge how well the Neural network is doing,
    we really need to know the costs of the errors. They aren’t provided. This is
    not uncommon: these numbers would have to be provided by the client (the insurance
    company), and in my experience most clients can’t assign exact costs to the errors.
    So we need some other way of understanding the performance. There are several
    ways to do this.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是推理。为了评估神经网络的表现，我们真正需要知道错误的成本。他们没有提供这些。这并不罕见：这些数字必须由客户（保险公司）提供，并且根据我的经验，大多数客户无法精确地为这些错误分配成本。因此，我们需要其他方法来理解性能。有几种方法可以做到这一点。
- en: 'One way is to answer the question: *How many false positives must I deal with
    for each true positive I get?* To calculate this, recall that their population
    of drivers has a 99:1 skew of **Non-Large Loss** to **Large Loss**. So they have
    a 99/1 proportion of negatives to positives. Their performance on false positives
    to true positives is 0.22/0.78\. We can answer the original question by multiplying
    these together:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是回答这个问题：*为了获得一个真阳性，我必须处理多少个假阳性？*为了计算这个，回想一下他们的司机人群具有99:1的**非大损失**到**大损失**的偏斜比例。因此，他们在假阳性到真阳性的性能比是0.22/0.78。我们可以通过将这些值相乘来回答最初的问题：
- en: '`99/1 x 0.22/0.78 ~= 28`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`99/1 x 0.22/0.78 ~= 28`'
- en: This result means that, using their Neural network, they must process 28 uninteresting **Non-Large
    Loss** customers (false alarms) for each **Large-Loss** customer they want. And
    they may only find 78% of the **Large-Loss** customers anyway.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果意味着，使用他们的神经网络，他们必须处理每个**大损失**客户的28个无趣的**非大损失**客户（误报）。而且他们可能只能找到78%的**大损失**客户。
- en: Another way to understand their performance is to convert it to precision. Given
    29 alarms, only 1 will be positive, so the precision is 1/28 or about 4%.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种理解他们表现的方式是将其转换为精度。给定29个警报，其中只有1个会是正警报，所以精度是1/28，大约为4%。
- en: Is this acceptable to the insurance company? I’m not an expert, but I would
    guess not. 4% precision is low, and 28 false alarms per real alarm is a high cost
    to tolerate. Unless the company has devoted a large workforce to this task, they
    probably can’t afford it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这对保险公司来说可以接受吗？我不是专家，但我猜不行。4%的精度很低，每个真实警报需要28个误报的成本很高。除非公司投入了大量的劳动力来处理这个任务，否则他们可能承担不起。
- en: Could these researchers do better? I think so. Since the results didn’t take
    into account the class imbalance, I assume the loss function and training regimen
    weren’t appropriate for the problem, either. [Learning on imbalanced data](https://www.svds.com/learning-imbalanced-classes/) isn’t
    a trivial undertaking, but any effort in that direction would likely yield better
    results.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些研究人员能做得更好吗？我认为可以。由于结果没有考虑类别不平衡，我假设损失函数和训练方案也不适合这个问题。[不平衡数据学习](https://www.svds.com/learning-imbalanced-classes/)并不是一项简单的工作，但朝这个方向的任何努力都可能会取得更好的结果。
- en: Evaluating the Solution as a Project
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为一个项目评估解决方案
- en: Stepping back from the technical details, we can critique this as a solution
    to a business problem. The “case” they’ve given us here doesn’t say anything really
    about what business problem they’re trying to solve. We can’t judge whether the
    solution is appropriate for solving it. The write-up simply states, “*it’s important
    for adjusters to understand which clients are at higher risk for such cases in
    order to optimize the pricing of its policies*“.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术细节中退一步，我们可以将其视为一种解决业务问题的方案。他们在这里给出的“案例”并没有真正说明他们试图解决什么业务问题。我们无法判断解决方案是否适合解决这个问题。报告中仅仅指出，“*调整员需要了解哪些客户在这些情况下风险更高，以便优化其保单的定价*”。
- en: Ignoring their model’s poor performance, is this even a good approach? “Understanding”
    often includes understanding the predictors, not just the names and account numbers
    of the high-scoring drivers. Nothing is said about how this understanding is achieved.
    Though neural networks are extremely popular right now, deep learned neural networks
    are notorious for not being comprehensible. They may not have been the ideal choice
    for this problem.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略他们模型的表现不佳，这种方法是否有效？“理解”通常包括理解预测因素，而不仅仅是高评分司机的名字和账户号码。没有说明这种理解是如何实现的。尽管神经网络现在非常流行，但深度学习神经网络以其不可理解性而臭名昭著。它们可能并不是解决这个问题的理想选择。
- en: Finally, nothing is said about how the solution would affect pricing, nor even
    what is important from the modeling to optimize pricing.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，关于解决方案如何影响定价，甚至关于优化定价所需的模型方面的重要内容，什么也没有提到。
- en: An important part about solving applications with machine learning is understanding
    how the model is going to be used in the context of the application (the larger
    process). This project simply showed a quick translation of a business problem
    into a two-class problem, then showed the technical details of the model and the
    results attained. Because the initial analysis of the insurance problem was superficial,
    we don’t even know what performance would be acceptable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 解决应用程序问题时，一个重要的部分是理解模型将在应用程序的上下文中如何使用（即更大的过程）。这个项目只是展示了一个业务问题快速转换为二分类问题的过程，然后展示了模型的技术细节和获得的结果。由于保险问题的初步分析很肤浅，我们甚至不知道什么样的性能是可接受的。
- en: Conclusion
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: I’ve been pretty merciless in critiquing this project simply because it illustrates
    a lot of mistakes data scientists make when they work on business problems. In
    other words, it was convenient, though hardly unique. In case you think only amateurs
    or beginners make these kinds of mistakes, [here is the source](https://cloud.google.com/blog/big-data/2017/03/using-machine-learning-for-insurance-pricing-optimization) of
    the case study. Note that it was one of Google’s “customer success stories” presented
    in promotion of the Google Cloud Platform.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我在批评这个项目时相当无情，因为它展示了数据科学家在处理业务问题时犯的很多错误。换句话说，这很方便，尽管几乎不具唯一性。如果你认为只有业余爱好者或初学者才会犯这些错误，[这里是来源](https://cloud.google.com/blog/big-data/2017/03/using-machine-learning-for-insurance-pricing-optimization)的案例研究。请注意，这是Google在推广Google
    Cloud Platform时展示的“客户成功故事”之一。
- en: From what I’ve seen, it’s rare for a machine learning or data science curriculum
    to cover the application issues I’ve mentioned here. Most courses concentrate
    on teaching algorithms, so they tend to simplify the data and evaluation complexities
    that come up in real-world applications. It took me many years of experience to
    understand these subtleties and know which problems to anticipate.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的观察，机器学习或数据科学课程很少涵盖我在这里提到的应用问题。大多数课程集中在教学算法，因此往往简化了在实际应用中出现的数据和评估复杂性。我要花费多年经验才能理解这些细微差别，并知道哪些问题需要预见。
- en: How about you? What was the biggest surprise you found going from academic projects
    to real-world applications? What would you do differently? What do you wish you
    had learned in school? Comment below to start a discussion.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你呢？从学术项目到实际应用中，最大的惊喜是什么？你会有什么不同的做法？你希望在学校里学到什么？请在下面评论以开始讨论。
- en: '**Bio: [Tom Fawcett](https://www.linkedin.com/in/tom-fawcett/)** is co-author
    of the popular book Data Science for Business, and brings over 20 years of experience
    applying machine learning and data mining in practical applications. He is a veteran
    of companies such as Verizon and HP Labs, and an editor of the *Machine Learning
    Journal*.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[汤姆·福塞特](https://www.linkedin.com/in/tom-fawcett/)** 是《数据科学与商业》一书的合著者，拥有超过20年的机器学习和数据挖掘实践经验。他曾在Verizon和HP
    Labs等公司工作，并且是*机器学习期刊*的编辑。'
- en: '[Original](https://www.svds.com/evaluating-data-science-projects/). Reposted
    with permission.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始来源](https://www.svds.com/evaluating-data-science-projects/)。经许可转载。'
- en: '**Related:**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine Learning vs. Statistics: The Texas Death Match of Data Science](/2017/08/machine-learning-vs-statistics.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与统计学：数据科学的德克萨斯决斗](/2017/08/machine-learning-vs-statistics.html)'
- en: '[The Value of Exploratory Data Analysis](/2017/04/value-exploratory-data-analysis.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索性数据分析的价值](/2017/04/value-exploratory-data-analysis.html)'
- en: '[A Guide to Understanding AI Toolkits](/2017/08/guide-understanding-ai-toolkits.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解AI工具包指南](/2017/08/guide-understanding-ai-toolkits.html)'
- en: More On This Topic
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Automated Machine Learning with Python: A Case Study](https://www.kdnuggets.com/2023/04/automated-machine-learning-python-case-study.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python的自动化机器学习：案例研究](https://www.kdnuggets.com/2023/04/automated-machine-learning-python-case-study.html)'
- en: '[Beyond Accuracy: Evaluating & Improving a Model with the NLP Test Library](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越准确性：使用NLP测试库评估与改进模型](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
- en: '[Evaluating Methods for Calculating Document Similarity](https://www.kdnuggets.com/evaluating-methods-for-calculating-document-similarity)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[评估文档相似性计算方法](https://www.kdnuggets.com/evaluating-methods-for-calculating-document-similarity)'
- en: '[KDnuggets News, August 31: The Complete Data Science Study Roadmap…](https://www.kdnuggets.com/2022/n35.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8月31日：完整的数据科学学习路线图…](https://www.kdnuggets.com/2022/n35.html)'
- en: '[The Complete Data Science Study Roadmap](https://www.kdnuggets.com/2022/08/complete-data-science-study-roadmap.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整的数据科学学习路线图](https://www.kdnuggets.com/2022/08/complete-data-science-study-roadmap.html)'
- en: '[Super Study Guide: A Free Algorithms and Data Structures eBook](https://www.kdnuggets.com/2022/06/super-study-guide-free-algorithms-data-structures-ebook.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超级学习指南：免费的算法和数据结构电子书](https://www.kdnuggets.com/2022/06/super-study-guide-free-algorithms-data-structures-ebook.html)'
