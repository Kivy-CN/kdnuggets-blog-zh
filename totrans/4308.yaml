- en: 11 Essential Code Blocks for Complete EDA (Exploratory Data Analysis)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/03/11-essential-code-blocks-exploratory-data-analysis.html](https://www.kdnuggets.com/2021/03/11-essential-code-blocks-exploratory-data-analysis.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Susan Maina](https://www.linkedin.com/in/suemnjeri/), Passionate about
    data, machine learning enthusiast, [writer at Medium](https://medium.com/@suemnjeri)**'
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory Data Analysis, or EDA, is one of the first steps of the [data science
    process](https://www.datasciencegraduateprograms.com/the-data-science-process/).
    It involves learning as much as possible about the data, without spending too
    much time. Here, you get an instinctive as well as a high-level practical understanding
    of the data. By the end of this process, you should have a general idea of the
    structure of the data set, some cleaning ideas, the target variable and, possible
    modeling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: There are some general strategies to quickly perform EDA in most problems. In
    this article, I will use the [Melbourne Housing snapshot dataset](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot) from
    kaggle to demonstrate the 11 blocks of code you can use to perform a satisfactory
    exploratory data analysis. The dataset includes `Address`, `Type` of Real estate, `Suburb`, `Method` of
    Selling, `Rooms`, `Price`, Real Estate Agent `(SellerG)`, `Date` of Sale and, `Distance` from
    C.B.D. You can follow along by downloading the dataset [here](https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/download).
  prefs: []
  type: TYPE_NORMAL
- en: The first step is importing the libraries required. We will need [Pandas](https://en.wikipedia.org/wiki/Pandas_(software)), [Numpy](https://towardsdatascience.com/4-fundamental-numpy-properties-every-data-scientist-must-master-c906236eb44b), [matplotlib](https://en.wikipedia.org/wiki/Matplotlib) and [seaborn](https://seaborn.pydata.org/).
    To make sure all our columns are displayed, use `pd.set_option(’display.max_columns’,
    100)` . By default, pandas displays 20 columns and hides the rest.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Panda’s `pd.read_csv(path)` reads in the csv file as a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Basic data set Exploration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**1\. Shape (dimensions) of the DataFrame**'
  prefs: []
  type: TYPE_NORMAL
- en: The `.shape` attribute of a Pandas DataFrame gives an overall structure of the
    data. It returns a [tuple](https://towardsdatascience.com/ultimate-guide-to-lists-tuples-arrays-and-dictionaries-for-beginners-8d1497f9777c) of
    length 2 that translates to how many rows of observations and columns the dataset
    has.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the dataset has 13,580 observations and 21 features, and one
    of those features is the target variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Data types of the various columns**'
  prefs: []
  type: TYPE_NORMAL
- en: The DataFrame’s `.dtypes` attribute displays the data types of the columns as
    a Panda’s [Series](https://www.geeksforgeeks.org/python-pandas-series/) (Series
    means a column of values and their indices).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We observe that our dataset has a combination of **categorical **(object) and **numeric **(float
    and int) features. At this point, I went back to the Kaggle page for an understanding
    of the columns and their meanings. Check out the table of columns and their definitions [here](https://datawrapper.dwcdn.net/hHuXG/4/) created
    with [Datawrapper](https://www.datawrapper.de/).
  prefs: []
  type: TYPE_NORMAL
- en: What to look out for;
  prefs: []
  type: TYPE_NORMAL
- en: Numeric features that should be categorical and vice versa.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a quick analysis, I did not find any mismatch for the datatypes. This makes
    sense as this dataset version is a cleaned snapshot of the original [Melbourne
    data](https://www.kaggle.com/anthonypino/melbourne-housing-market).
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Display a few rows**'
  prefs: []
  type: TYPE_NORMAL
- en: The Pandas DataFrame has very handy functions for displaying a few observations. `data.head()`displays
    the first 5 observations, `data.tail()` the last 5, and `data.sample()` an observation
    chosen randomly from the dataset. You can display 5 random observations using `data.sample(5)`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'What to look out for:'
  prefs: []
  type: TYPE_NORMAL
- en: Can you understand the column names? Do they make sense? (Check with the variable
    definitions again if needed)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do the values in these columns make sense?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there significant missing values (NaN) sighted?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What types of classes do the categorical features have?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: My insights; the `Postcode `and `Propertycount` features both changed according
    to the `Suburb` feature. Also, there were significant missing values for the `BuildingArea `and `YearBuilt`.
  prefs: []
  type: TYPE_NORMAL
- en: Distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This refers to how the values in a feature are distributed, or how often they
    occur. For numeric features, we’ll see how many times groups of numbers appear
    in a particular column, and for categorical features, the classes for each column
    and their frequency. We will use both **graphs** and actual summary **statistics**.
    The graphs enable us to get an overall idea of the distributions while the statistics
    give us factual numbers. These two strategies are both recommended as they complement
    each other.
  prefs: []
  type: TYPE_NORMAL
- en: Numeric Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**4\. Plot each numeric feature**'
  prefs: []
  type: TYPE_NORMAL
- en: We will use Pandas [histogram](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html).
    A histogram groups numbers into ranges (or bins) and the height of a bar shows
    how many numbers fall in that range. `df.hist()` plots a histogram of the data’s
    numeric features in a grid. We will also provide the `figsize` and `xrot` arguments
    to increase the grid size and rotate the x-axis by 45 degrees.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/96dad936f185d8266d880b0fd7a70289.png)'
  prefs: []
  type: TYPE_IMG
- en: Histogram by author
  prefs: []
  type: TYPE_NORMAL
- en: 'What to look out for:'
  prefs: []
  type: TYPE_NORMAL
- en: Possible outliers that cannot be explained or might be measurement errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Numeric features that should be categorical. For example, `Gender` represented
    by 1 and 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boundaries that do not make sense such as percentage values> 100.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From the histogram, I noted that `BuildingArea` and `LandSize` had potential
    outliers to the right. Our target feature `Price` was also highly skewed to the
    right. I also noted that `YearBuilt` was very skewed to the left and the boundary
    started at the year 1200 which was odd. Let’s move on to the summary statistics
    for a clearer picture.
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Summary statistics of the numerical features**'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an intuitive feel of the numeric features, we will look at
    actual statistics using `df.describe()`which displays their summary statistics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can see for each numeric feature, the *count* of values in it, the *mean* value, *std *or
    standard deviation, *minimum* value, the *25th* percentile, the *50th* percentile
    or median, the *75th* percentile, and the *maximum* value. From the count we can
    also identify the features with **missing values**; their count is not equal to
    the total number of rows of the dataset. These are `Car`, `LandSize` and `YearBuilt.`
  prefs: []
  type: TYPE_NORMAL
- en: I noted that the minimum for both the `LandSize` and `BuildingArea` is 0\. We
    also see that the `Price` ranges from 85,000 to 9,000,000 which is a big range.
    We will explore these columns in detailed analysis later in the project.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the `YearBuilt` feature, however, we note that the minimum year is
    1196\. This could be a possible data entry error that will be removed during cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: Categorical features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**6\. Summary statistics of the categorical features**'
  prefs: []
  type: TYPE_NORMAL
- en: For categorical features, it is important to show the summary statistics before
    we plot graphs because some features have a lot of unique classes (like we will
    see for the `Address`) and the classes would be unreadable if visualized on a
    countplot.
  prefs: []
  type: TYPE_NORMAL
- en: To check the summary statistics of only the categorical features, we will use `df.describe(include=’object’)`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/ecd1ed1297aea86ac40705b14a1767b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Categorical summary statistics by author
  prefs: []
  type: TYPE_NORMAL
- en: This table is a bit different from the one for numeric features. Here, we get
    the *count* of the values of each feature, the number of *unique* classes, the *top* most
    frequent class, and how *frequently* that class occurs in the data set.
  prefs: []
  type: TYPE_NORMAL
- en: We note that some classes have a lot of unique values such as `Address`, followed
    by `Suburb` and `SellerG`. From these findings, I will only plot the columns with
    10 or less unique classes. We also note that `CouncilArea` has missing values.
  prefs: []
  type: TYPE_NORMAL
- en: '**7\. Plot each categorical feature**'
  prefs: []
  type: TYPE_NORMAL
- en: Using the statistics above, we note that `Type`, `Method `and `Regionname `have
    less than 10 classes and can be effectively visualized. We will plot these features
    using the [Seaborn countplot](https://seaborn.pydata.org/generated/seaborn.countplot.html),
    which is like a histogram for categorical variables. Each bar in a countplot represents
    a unique class.
  prefs: []
  type: TYPE_NORMAL
- en: I created a [For loop](https://towardsdatascience.com/a-gentle-introduction-to-flow-control-loops-and-list-comprehensions-for-beginners-3dbaabd7cd8a).
    For each categorical feature, a countplot will be displayed to show how the classes
    are distributed for that feature. The line `df.select_dtypes(include=’object’)` selects
    the categorical columns with their values and displays them. We will also include
    an [If-statement](https://towardsdatascience.com/a-gentle-introduction-to-flow-control-loops-and-list-comprehensions-for-beginners-3dbaabd7cd8a) so
    as to pick only the three columns with 10 or fewer classes using the line `Series.nunique()
    < 10`. Read the `.nunique()` documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.nunique.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/6208f79308cff63d0955c7b208e98d23.png)'
  prefs: []
  type: TYPE_IMG
- en: Count plots by author
  prefs: []
  type: TYPE_NORMAL
- en: 'What to look out for:'
  prefs: []
  type: TYPE_NORMAL
- en: Sparse classes which have the potential to affect a model’s performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mistakes in labeling of the classes, for example 2 exact classes with minor
    spelling differences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We note that `Regionname` has some sparse classes which might need to be merged
    or re-assigned during modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping and segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Segmentation allows us to cut the data and observe the relationship between
    categorical and numeric features.
  prefs: []
  type: TYPE_NORMAL
- en: '**8\. Segment the target variable by categorical features.**'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will compare the target feature, `Price`, between the various classes
    of our main categorical features `(Type`, `Method` and `Regionname)` and see how
    the `Price` changes with the classes.
  prefs: []
  type: TYPE_NORMAL
- en: We use the [Seaborn boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) which
    plots the distribution of `Price` across the classes of categorical features. [This](https://www.geeksforgeeks.org/how-to-show-mean-on-boxplot-using-seaborn-in-python/) tutorial,
    from where I borrowed the Image below, explains the boxplot’s features clearly.
    The dots at both ends represent outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/6abcbbcd16f872b135829f01e2cd5947.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [www.geekeforgeeks.org](https://www.geeksforgeeks.org/how-to-show-mean-on-boxplot-using-seaborn-in-python/)
  prefs: []
  type: TYPE_NORMAL
- en: Again, I used a *for loop* to plot a boxplot of each categorical feature with `Price`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/6db28afbda3105515549d150ba4db0a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Box plots by author
  prefs: []
  type: TYPE_NORMAL
- en: 'What to look out for:'
  prefs: []
  type: TYPE_NORMAL
- en: which classes most affect the target variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note how the `Price` is still sparsely distributed among the 3 sparse classes
    of `Regionname` seen earlier, strengthening our case against these classes.
  prefs: []
  type: TYPE_NORMAL
- en: Also note how the `SA` class (the least frequent `Method` class) commands high
    prices, almost similar prices of the most frequently occurring class `S.`
  prefs: []
  type: TYPE_NORMAL
- en: '**9\. Group numeric features by each categorical feature.**'
  prefs: []
  type: TYPE_NORMAL
- en: Here we will see how all the other numeric features, not just `Price`, change
    with each categorical feature by summarizing the numeric features across the classes.
    We use the [Dataframe’s groupby](https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/) function
    to group the data by a category and calculate a metric (such as *mean*, *median*, *min*, *std, *etc)
    across the various numeric features.
  prefs: []
  type: TYPE_NORMAL
- en: For only the 3 categorical features with less than 10 classes, we group the
    data, then calculate the `mean` across the numeric features. We use `display()` which
    results to a cleaner table than `print()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We get to compare the `Type,` `Method` and `Regionname` classes across the numeric
    features to see how they are distributed.
  prefs: []
  type: TYPE_NORMAL
- en: Relationships between numeric features and other numeric features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**10\. Correlations matrix for the different numerical features**'
  prefs: []
  type: TYPE_NORMAL
- en: A [correlation](https://www.mathsisfun.com/data/correlation.html) is a value
    between -1 and 1 that amounts to how closely values of two separate features move
    simultaneously. A *positive* correlation means that as one feature increases the
    other one also increases, while a *negative* correlation means one feature increases
    as the other decreases. Correlations close to 0 indicate a *weak* relationship
    while closer to -1 or 1 signifies a *strong* relationship.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/88d80dd2671a58f0c17cab9179306523.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [edugyan.in](http://www.edugyan.in/2017/02/correlation-coefficient.html)
  prefs: []
  type: TYPE_NORMAL
- en: We will use `df.corr()` to calculate the [correlations](https://machinelearningmastery.com/how-to-use-correlation-to-understand-the-relationship-between-variables/) between
    the numeric features and it returns a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This might not mean much now, so let us plot a heatmap to visualize the correlations.
  prefs: []
  type: TYPE_NORMAL
- en: '**11\. Heatmap of the correlations**'
  prefs: []
  type: TYPE_NORMAL
- en: We will use a [Seaborn heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) to
    plot the grid as a rectangular color-coded matrix. We use `sns.heatmap(corrs,
    cmap=’RdBu_r’,annot=True)`.
  prefs: []
  type: TYPE_NORMAL
- en: The `cmap=‘RdBu_r’` argument tells the heatmap what colour palette to use. A
    high positive correlation appears as *dark red* and a high negative correlation
    as *dark blue*. Closer to white signifies a weak relationship. Read [this](https://medium.com/@morganjonesartist/color-guide-to-seaborn-palettes-da849406d44f) nice
    tutorial for other color palettes. `annot=True` includes the values of the correlations
    in the boxes for easier reading and interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/be9b497b0f0a6f548ea07f4e89e75e6c.png)'
  prefs: []
  type: TYPE_IMG
- en: Heatmap by author
  prefs: []
  type: TYPE_NORMAL
- en: 'What to look out for:'
  prefs: []
  type: TYPE_NORMAL
- en: Strongly correlated features; either dark red (positive) or dark blue(negative).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Target variable; If it has strong positive or negative relationships with other
    features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We note that `Rooms`, `Bedrooms2`, `Bathrooms`, and `Price` have strong positive
    relationships. On the other hand, `Price`, our target feature, has a slightly
    weak* negative* correlation with `YearBuilt` and an even weaker *negative* relationship
    with `Distance` from CBD.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we explored the Melbourne dataset and got a high-level understanding
    of the structure and its features. At this stage, we do not need to be 100% comprehensive
    because in future stages we will explore the data more elaborately. You can get
    the full code on Github [here](https://github.com/suemnjeri/medium-articles/blob/main/melbourne/EDA_melbourne_for_medium.ipynb).
    I will be uploading the dataset’s cleaning concepts soon.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Susan Maina](https://www.linkedin.com/in/suemnjeri/)** is passionate
    about data, machine learning enthusiast, [writer at Medium](https://medium.com/@suemnjeri).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/11-simple-code-blocks-for-complete-exploratory-data-analysis-eda-67c2817f56cd).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Powerful Exploratory Data Analysis in just two lines of code](/2021/02/powerful-exploratory-data-analysis-sweetviz.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pandas Profiling: One-Line Magical Code for EDA](/2021/02/pandas-profiling-one-line-magical-code-eda.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Statistical and Visual Exploratory Data Analysis with One Line of Code](/2020/09/statistical-visual-exploratory-data-analysis-one-line-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[New Ways of Sharing Code Blocks for Data Scientists](https://www.kdnuggets.com/2022/03/new-ways-sharing-code-blocks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Data Scientist’s Essential Guide to Exploratory Data Analysis](https://www.kdnuggets.com/2023/06/data-scientist-essential-guide-exploratory-data-analysis.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Exploratory Data Analysis Techniques for Unstructured Data](https://www.kdnuggets.com/2023/05/exploratory-data-analysis-techniques-unstructured-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Exploratory Data Analysis](https://www.kdnuggets.com/7-steps-to-mastering-exploratory-data-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
