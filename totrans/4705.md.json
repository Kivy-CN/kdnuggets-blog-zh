["```py\n*# Common insults against jews.*\nINSULTS = r\"\\bjew (bitch|shit|crow|fuck|rat|cockroach|ass|bast(a|e)rd)\"\n\ndef insults(tweet_text):\n    return POSITIVE if re.search(INSULTS, tweet_text) else ABSTAIN\n```", "```py\n*# If tweet author is Jewish then it's likely not anti-semitic.*\nJEWISH_AUTHOR = r\"((\\bI am jew)|(\\bas a jew)|(\\bborn a jew)\"\n\ndef jewish_author(tweet_tweet):\n    return NEGATIVE if re.search(JEWISH_AUTHOR, tweet_tweet) else ABSTAIN\n```", "```py\n*# We build a matrix of LF votes for each tweet*\nLF_matrix = make_Ls_matrix(LF_set, LFs)\n\n*# Get true labels for LF set*\nY_LF_set = np.array(LF_set['label'])\n\ndisplay(lf_summary(sparse.csr_matrix(LF_matrix), \n                   Y=Y_LF_set, \n                   lf_names=LF_names.values()))\n```", "```py\nlabel_coverage(LF_matrix)\n>> 0.8062755798090041\n```", "```py\nfrom metal.label_model.baselines import MajorityLabelVoter\n\nmv = MajorityLabelVoter()\nY_train_majority_votes = mv.predict(LF_matrix)\nprint(classification_report(Y_LFs, Y_train_majority_votes))\n```", "```py\nLs_train = make_Ls_matrix(train, LFs)\n\n*# You can tune the learning rate and class balance.*\nlabel_model = LabelModel(k=2, seed=123)\nlabel_model.train_model(Ls_train, n_epochs=2000, print_every=1000, \n                        lr=0.0001, \n                        class_balance=np.array([0.2, 0.8]))\n```", "```py\n# To use all information possible when we fit our classifier, we can # actually combine our hand-labeled LF set with our training set.\n\nY_train = label_model.predict(Ls_train) + Y_LF_set\n```", "```py\ndata_lm = TextLMDataBunch.from_df(train_df=LM_TWEETS,         valid_df=df_test, path=\"\")\n\nlearn_lm = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, drop_mult=0.5)\n```", "```py\nlearn_lm.unfreeze()\n```", "```py\nfor i in range(20):\n    learn_lm.fit_one_cycle(cyc_len=1, max_lr=1e-3, moms=(0.8, 0.7))\n    learn_lm.save('twitter_lm')\n```", "```py\nlearn_lm.predict(\"i hate jews\", n_words=10)\n>> 'i hate jews are additional for what hello you brother . xxmaj the'\nlearn_lm.predict(\"jews\", n_words=10)\n>> 'jews out there though probably okay jew back xxbos xxmaj my'\n```", "```py\n*# Classifier model data*\ndata_clas = TextClasDataBunch.from_df(path = \"\", \n                                      train_df = df_trn,\n                                      valid_df = df_val,                                         \n                                      vocab=data_lm.train_ds.vocab, \n                                      bs=32, \n                                      label_cols=0)\n\nlearn = text_classifier_learner(data_clas, drop_mult=0.5)\nlearn.freeze()\n```", "```py\nlearn.lr_find(start_lr=1e-8, end_lr=1e2)\nlearn.recorder.plot()\n```", "```py\nlearn.fit_one_cycle(cyc_len=1, max_lr=1e-3, moms=(0.8, 0.7))\nlearn.freeze_to(-2)\nlearn.fit_one_cycle(1, slice(1e-4,1e-2), moms=(0.8,0.7))\nlearn.freeze_to(-3)\nlearn.fit_one_cycle(1, slice(1e-5,5e-3), moms=(0.8,0.7))\nlearn.unfreeze()\nlearn.fit_one_cycle(4, slice(1e-5,1e-3), moms=(0.8,0.7))\n```", "```py\nlearn.predict(\"george soros controls the government\")\n>> (Category 1, tensor(1), tensor([0.4436, 0.5564]))\n\nlearn.predict(\"george soros doesn't control the government\")\n>> (Category 0, tensor(0), tensor([0.7151, 0.2849]))\n```", "```py\nlearn.predict(\"fuck jews\")\n>> (Category 1, tensor(1), tensor([0.1996, 0.8004]))\n\nlearn.predict(\"dirty jews\")\n>> (Category 1, tensor(1), tensor([0.4686, 0.5314]))\n```", "```py\nlearn.predict(\"Wow. The shocking part is you're proud of offending every serious jew, mocking a religion and openly being an anti-semite.\")\n>> (Category 0, tensor(0), tensor([0.9908, 0.0092]))\n```", "```py\nlearn.predict(\"my cousin is a russian jew from ukraine- ???????????? i'm so glad they here\")\n>> (Category 0, tensor(0), tensor([0.8076, 0.1924]))\n\nlearn.predict(\"at least the stolen election got the temple jew shooter off the drudgereport. I ran out of tears.\")\n>> (Category 0, tensor(0), tensor([0.9022, 0.0978]))\n```"]