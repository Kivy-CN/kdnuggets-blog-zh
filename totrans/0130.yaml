- en: 'Automating the Chain of Thought: How AI Can Prompt Itself to Reason'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Automating the Chain of Thought: How AI Can Prompt Itself to Reason](../Images/7aba366ad9c38f56a4801543271f5602.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by author with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Key Points
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chain-of-thought (CoT) prompting improves LM reasoning by providing step-by-step
    examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual creation of CoT demonstrations requires non-trivial human effort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This paper explores automating CoT demonstration generation using the LM itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The proposed Auto-CoT method clusters questions then samples diverse ones for
    self-prompting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiments show Auto-CoT matches manually created CoT, without human involvement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The paper "[**Automatic Chain of Thought Prompting in Large Language Models**](https://arxiv.org/abs/2210.03493)"
    explores automated ways to create effective "chain of thought" (CoT) prompts for
    large language models (LLMs) like GPT-4\. CoT prompting involves showing the LLM
    examples that demonstrate step-by-step reasoning chains mapping from a question
    to a final answer. This improves performance on complex reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best CoT prompting results, however, currently require humans to manually
    create demonstrations, with hand-crafted questions and detailed reasoning steps
    tailored to each task. The authors propose eliminating this manual effort by having
    the LLM automatically generate its own CoT demonstrations for prompting. Their
    key method, called Auto-CoT, works by first clustering the questions of a given
    task based on their semantic similarity. Auto-CoT then samples a diverse set of
    questions covering different clusters. For each sampled question, Auto-CoT uses
    the LLM itself in zero-shot mode to produce a reasoning chain from the question
    to an answer. It applies simple heuristics to select chains based on length and
    simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: The authors perform experiments evaluating Auto-CoT on 10 reasoning datasets
    spanning arithmetic, common sense, and symbolic logic problems. The results show
    that Auto-CoT matches or exceeds the performance of CoT prompting based on manually
    created demonstrations, without requiring any human effort to design demonstrations.
    A key insight is that using diversity-based sampling over similarity-based retrieval
    to select the prompting questions mitigates the impact of imperfect demonstrations
    generated by the LLM's zero-shot reasoning. Auto-CoT also substantially outperforms
    baselines like retrieving similar questions or random sampling for the demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the work provides strong evidence that LLMs can prompt themselves to
    demonstrate complex multi-step reasoning. Auto-CoT essentially composes one LLM
    that generates a diverse set of CoT examples, with another LLM that uses those
    examples for inference. The authors suggest this self-prompting approach could
    significantly extend prompting techniques and make LLMs much better few-shot learners
    on complex reasoning tasks. Limitations include potential computational costs
    and issues scaling to more unconstrained problems. But the ability to automate
    prompting reduces human effort and customization needs.
  prefs: []
  type: TYPE_NORMAL
- en: Research Q&A
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*How does Auto-CoT compare to other methods that automate prompt creation,
    like retrieval-augmented prompting?*'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval-augmented prompting retrieves related data examples to use for prompting,
    rather than having the LLM generate demonstrations. A key difference is that Auto-CoT
    doesn't require a dataset of labeled examples and instead relies on the LLM's
    own zero-shot reasoning. Retrieval may be more sample-efficient but requires data
    collection. Auto-CoT is fully automated but can suffer from imperfect demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: '*Could Auto-CoT be applied to natural language generation tasks beyond logical
    reasoning?*'
  prefs: []
  type: TYPE_NORMAL
- en: The clustering and self-prompting approach seems promising for less structured
    textual tasks where coherence is important. For example, Auto-CoT could provide
    writing planning examples for creative writing, or dialog illustrations for conversational
    bots. The key challenges would be defining appropriate clustering methods and
    training the LLM's zero-shot generation for high-quality demonstrations.
  prefs: []
  type: TYPE_NORMAL
- en: '*What is innovative about this research?*'
  prefs: []
  type: TYPE_NORMAL
- en: The key innovation is using the LLM itself to generate demonstrations for prompting,
    instead of relying on manual creation. This allows prompting to become more automated
    and task-adaptive. The clustering to select diverse questions for self-prompting
    is also innovative.
  prefs: []
  type: TYPE_NORMAL
- en: '*What are the broader implications of this research?*'
  prefs: []
  type: TYPE_NORMAL
- en: This research could significantly reduce the human effort and expertise needed
    to design effective prompts. It may allow LLMs to learn new tasks more quickly
    and from less data, enhancing their few-shot learning capabilities. The self-prompting
    approach could be applied to extend prompting techniques like in-context learning.
  prefs: []
  type: TYPE_NORMAL
- en: '*What are some potential issues or oversights with this research as presented,
    if any?*'
  prefs: []
  type: TYPE_NORMAL
- en: A potential issue is that Auto-CoT relies on clustering questions based on similarity
    features from Sentence-BERT. Performance could suffer on tasks where semantic
    similarity doesn't align well with reasoning similarity. The approach also likely
    incurs higher compute costs than standard prompting.
  prefs: []
  type: TYPE_NORMAL
- en: '*What are the logical next research steps from this research?*'
  prefs: []
  type: TYPE_NORMAL
- en: Important next steps include exploring how Auto-CoT scales to more complex and
    open-ended reasoning tasks, integrating it with retrieval of external knowledge
    sources, and studying if the approach can be learned more sample-efficiently through
    meta-learning rather than relying solely on a pre-trained LLM. Analyzing the interplay
    between cluster count, sample size, and performance is also an open question.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Auto-CoT reduces the need for hand-crafted demonstrations to prompt LMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-prompting with Auto-CoT composes one LM generating diverse examples, and
    another inferring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diversity in sampling questions is key to overcoming imperfect zero-shot reasoning
    chains
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The approach could extend prompting techniques and make LMs better few-shot
    learners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Auto-CoT demonstrates the promise of automating prompting to reduce human effort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next steps include scaling Auto-CoT to more complex reasoning tasks and larger
    LMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Matthew Mayo](https://www.linkedin.com/in/mattmayo13/)** ([**@mattmayo13**](https://twitter.com/mattmayo13))
    is a Data Scientist and the Editor-in-Chief of KDnuggets, the seminal online Data
    Science and Machine Learning resource. His interests lie in natural language processing,
    algorithm design and optimization, unsupervised learning, neural networks, and
    automated approaches to machine learning. Matthew holds a Master''s degree in
    computer science and a graduate diploma in data mining. He can be reached at editor1
    at kdnuggets[dot]com.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Exploring Tree of Thought Prompting: How AI Can Learn to Reason…](https://www.kdnuggets.com/2023/07/exploring-tree-of-thought-prompting-ai-learn-reason-through-search.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unraveling the Power of Chain-of-Thought Prompting in Large Language Models](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Parallel Processing in Prompt Engineering: The Skeleton-of-Thought…](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlocking Reliable Generations through Chain-of-Verification: A…](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Thought Propagation: An Analogical Approach to Complex Reasoning…](https://www.kdnuggets.com/thought-propagation-an-analogical-approach-to-complex-reasoning-with-large-language-models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Data Science Technologies You Need to Build Your Supply Chain Pipeline](https://www.kdnuggets.com/2022/01/6-data-science-technologies-need-build-supply-chain-pipeline.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
