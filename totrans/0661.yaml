- en: NLP and Computer Vision Integrated
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP与计算机视觉的整合
- en: 原文：[https://www.kdnuggets.com/2019/06/nlp-computer-vision-integrated.html](https://www.kdnuggets.com/2019/06/nlp-computer-vision-integrated.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/06/nlp-computer-vision-integrated.html](https://www.kdnuggets.com/2019/06/nlp-computer-vision-integrated.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Sciforce](https://sciforce.solutions)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Sciforce](https://sciforce.solutions)提供**。'
- en: '![](../Images/d61fa59424baa0cb2ac01f824879f7b1.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d61fa59424baa0cb2ac01f824879f7b1.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Integration and interdisciplinarity are the cornerstones of modern science and
    industry. One example of recent attempts to combine everything is the integration
    of computer vision and natural language processing (NLP). Both these fields are
    one of the most actively developing machine learning research areas. Yet, until
    recently, they have been treated as separate areas without many ways to benefit
    from each other. It is now, with the expansion of multimedia, researchers have
    started exploring the possibilities of applying both approaches to achieve one
    result.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 整合与跨学科性是现代科学和工业的基石。最近尝试将一切结合在一起的一个例子是计算机视觉与自然语言处理（NLP）的整合。这两个领域都是机器学习研究中最活跃的发展领域之一。然而，直到最近，它们一直被视为独立领域，彼此之间几乎没有相互受益的方式。现在，随着多媒体的扩展，研究人员开始探索将这两种方法应用于实现单一结果的可能性。
- en: '**Multimodal world and semiotics**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**多模态世界与符号学**'
- en: The most natural way for humans is to extract and analyze information from diverse
    sources. This conforms to the theory of semiotics (Greenlee 1978) — the study
    of the relations between signs and their meanings at different levels. Semiotics
    studies the relationship between signs and meaning, the formal relations between
    signs (roughly equivalent to syntax) and the way humans interpret signs depending
    on the context (pragmatics in linguistic theory). If we consider purely visual
    signs, then this leads to the conclusion that semiotics can also be approached
    by computer vision, extracting interesting signs for natural language processing
    to realize the corresponding meanings.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人类最自然的方式是从不同来源提取和分析信息。这符合符号学理论（Greenlee 1978）——研究符号及其在不同层次上意义的关系。符号学研究符号与意义之间的关系，符号之间的形式关系（大致相当于语法）以及人类根据上下文解读符号的方式（语言学理论中的语用学）。如果我们仅考虑视觉符号，那么这会得出结论，符号学也可以通过计算机视觉来处理，从中提取有趣的符号以供自然语言处理实现相应的意义。
- en: '**Computer Vision and its relation to NLP**'
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**计算机视觉及其与NLP的关系**'
- en: 'Malik summarizes Computer Vision tasks as the 3Rs (Malik et al. 2016): reconstruction,
    recognition, and reorganization.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Malik 将计算机视觉任务总结为3Rs（Malik等，2016）：重建、识别和重组。
- en: '**Reconstruction** refers to the estimation of a 3D scene that gave rise to
    a particular visual image by incorporating information from multiple views, shading,
    texture, or direct depth sensors. The process results in a 3D model, such as point
    clouds or depth images.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**重建** 指通过结合来自多个视角、阴影、纹理或直接深度传感器的信息，估计产生特定视觉图像的3D场景。该过程结果是一个3D模型，例如点云或深度图像。'
- en: '**Recognition** involves assigning labels to objects in the image. For 2D objects,
    examples of recognition are handwriting or face recognition, and 3D tasks tackle
    such problems as object recognition from point clouds which assists in robotic
    manipulation.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**识别** 涉及为图像中的对象分配标签。对于2D对象，识别的例子包括手写识别或人脸识别，而3D任务则解决从点云中识别对象等问题，这有助于机器人操作。'
- en: '**Reorganization** means bottom-up vision when raw pixels are segmented into
    groups that represent the structure of an image. Low-level vision tasks include
    edge, contour, and corner detection, while high-level tasks involve semantic segmentation,
    which partially overlaps with recognition tasks.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**重组** 指的是从底层到顶层的视觉过程，当原始像素被分割成表示图像结构的组时。低层次视觉任务包括边缘、轮廓和角点检测，而高层次任务涉及语义分割，这与识别任务部分重叠。'
- en: '![](../Images/d16b7f1e4147b82fb8aba9eefe44fe24.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d16b7f1e4147b82fb8aba9eefe44fe24.png)'
- en: It is recognition that is most closely connected to language because it has
    the output that can be interpreted as words. For example, objects can be represented
    by nouns, activities by verbs, and object attributes by adjectives. In this sense,
    vision and language are connected by means of semantic representations (Gardenfors
    2014; Gupta 2009).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 识别与语言的联系最为紧密，因为它的输出可以被解释为词语。例如，物体可以用名词表示，活动用动词表示，物体属性用形容词表示。从这个意义上说，视觉和语言通过语义表示相互连接（Gardenfors
    2014；Gupta 2009）。
- en: '**Natural Language Processing and its relation to Computer Vision**'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**自然语言处理及其与计算机视觉的关系**'
- en: NLP tasks are more diverse as compared to Computer Vision and range from syntax,
    including morphology and compositionality, semantics as a study of meaning, including
    relations between words, phrases, sentences, and discourses, to pragmatics, a
    study of shades of meaning, at the level of natural communication.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 与计算机视觉相比，NLP 任务更为多样化，包括语法（如形态学和组合性）、语义（作为意义的研究，包括词语、短语、句子和话语之间的关系）以及语用学（作为自然交流中意义的细微差别的研究）。
- en: Some complex tasks in NLP include machine translation, dialog interface, information
    extraction, and summarization.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一些复杂的 NLP 任务包括机器翻译、对话接口、信息提取和摘要。
- en: It is believed that switching from images to words is the closest to machine
    translation. Still, such “translation” between low-level pixels or contours of
    an image and a high-level description in words or sentences — the task known as
    Bridging the Semantic Gap (Zhao and Grosky 2002) — remains a wide gap to cross.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，从图像到词语的转换被认为是最接近机器翻译的。然而，这种在低层像素或图像轮廓与高层次词语或句子描述之间的“翻译”——即桥接语义差距（Zhao 和
    Grosky 2002）——依然是一个广泛的鸿沟。
- en: '**Scope of Integration of Computer Vision and NLP**'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**计算机视觉与 NLP 的整合范围**'
- en: The integration of vision and language was not going smoothly in a top-down
    deliberate manner, where researchers came up with a set of principles. Integrated
    techniques were rather developed bottom-up, as some pioneers identiﬁed certain
    rather specific and narrow problems, attempted multiple solutions, and found a
    satisfactory outcome.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉和语言的融合并不是通过自上而下的方式顺利进行的，研究人员提出了一系列原则。集成技术主要是自下而上的发展，一些先驱者识别出一些较为具体和狭窄的问题，尝试了多种解决方案，找到了令人满意的结果。
- en: The new trajectory started with an understanding that most present-day files
    are multimedia, that they contain interrelated images, videos, and natural language
    texts. For example, a typical news article contains writing by a journalist and
    a photo related to the news content. Furthermore, there may be a clip video that
    contains a reporter or a snapshot of the scene where the event in the news occurred.
    Language and visual data provide two sets of information that are combined into
    a single story, making the basis for appropriate and unambiguous communication.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 新的轨迹开始于对当前文件大多数都是多媒体的理解，即它们包含互相关联的图像、视频和自然语言文本。例如，一篇典型的新闻文章包含记者的文字和与新闻内容相关的照片。此外，可能还会有一个包含记者的剪辑视频或事件发生现场的快照。语言和视觉数据提供了两组信息，这些信息结合成一个完整的故事，为适当且明确的沟通奠定了基础。
- en: This understanding gave rise to multiple applications of an integrated approach
    to visual and textual content not only in working with multimedia files but also
    in the fields of robotics, visual translations, and distributional semantics.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种理解催生了将综合方法应用于视觉和文本内容的多个领域，不仅在处理多媒体文件时，而且在机器人技术、视觉翻译和分布式语义学领域也有应用。
- en: '**Multimedia files**'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**多媒体文件**'
- en: 'The multimedia-related tasks for NLP and computer vision fall into three main
    categories: visual properties description, visual description, and visual retrieval.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与多媒体相关的 NLP 和计算机视觉任务主要分为三个类别：视觉属性描述、视觉描述和视觉检索。
- en: '![](../Images/0f8481069a38ddebbba9b9953aa51fef.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f8481069a38ddebbba9b9953aa51fef.png)'
- en: '**Visual properties description:** A step beyond classification, the descriptive
    approach summarizes object properties by assigning attributes. Such attributes
    may be both binary values for easily recognizable properties or relative attributes
    describing a property with the help of a learning-to-rank framework. The key is
    that the attributes will provide a set of contexts as a knowledge source for recognizing
    a speciﬁc object by its properties. The attribute words become an intermediate
    representation that helps bridge the semantic gap between the visual space and
    the label space.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**视觉属性描述**：相比于分类，描述性方法通过分配属性来总结对象属性。这些属性可以是易于识别的二进制值，或通过学习排序框架描述的相对属性。关键在于，这些属性将提供一组上下文，作为识别特定对象属性的知识源。属性词成为一种中间表示，有助于弥合视觉空间和标签空间之间的语义差距。'
- en: '**Visual description**: In real life, the task of visual description is to
    provide image or video capturing. It is believed that sentences would provide
    a more informative description of an image than a bag of unordered words. To generate
    a sentence that would describe an image, a certain amount of low-level visual
    information should be extracted that would provide the basic information “who
    did what to whom, and where and how they did it.” From the part-of-speech perspective,
    the quadruplets of “Nouns, Verbs, Scenes, Prepositions” can represent meaning
    extracted from visual detectors. Visual modules extract objects that are either
    a subject or an object in the sentence. Then a Hidden Markov Model is used to
    decode the most probable sentence from a ﬁnite set of quadruplets along with some
    corpus-guided priors for verb and scene (preposition) predictions. The meaning
    is represented using objects (nouns), visual attributes (adjectives), and spatial
    relationships (prepositions). Then the sentence is generated with the help of
    the phrase fusion technique using web-scale n-grams for determining probabilities.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**视觉描述**：在现实生活中，视觉描述的任务是提供图像或视频捕捉。人们认为，句子能比一堆无序的词汇提供更具信息量的图像描述。为了生成描述图像的句子，应提取一定量的低级视觉信息，这些信息提供了基本的“谁对谁做了什么，在哪里以及如何做的”的信息。从词性角度来看，“名词、动词、场景、介词”四元组可以代表从视觉检测器提取的含义。视觉模块提取的对象可以是句子中的主语或宾语。然后使用隐马尔可夫模型从有限的四元组集合中解码出最可能的句子，并结合一些语料库指导的动词和场景（介词）预测的先验信息。含义通过对象（名词）、视觉属性（形容词）和空间关系（介词）来表示。然后，通过使用网页规模的n-grams来确定概率，借助短语融合技术生成句子。'
- en: '**Visual retrieval**: Content-based Image Retrieval (CBIR) is another ﬁeld
    in multimedia that utilizes language in the form of query strings or concepts.
    As a rule, images are indexed by low-level vision features like color, shape,
    and texture. CBIR systems try to annotate an image region with a word, similarly
    to semantic segmentation, so the keyword tags are close to human interpretation.
    CBIR systems use keywords to describe an image for image retrieval but visual
    attributes describe an image for image understanding. Nevertheless, visual attributes
    provide a suitable middle layer for CBIR with an adaptation to the target domain.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**视觉检索**：基于内容的图像检索（CBIR）是多媒体领域的另一个应用，它利用以查询字符串或概念形式的语言。通常，图像通过低级视觉特征如颜色、形状和纹理进行索引。CBIR系统尝试用词语标注图像区域，类似于语义分割，因此关键词标签接近人类的解释。CBIR系统使用关键词来描述图像以进行图像检索，而视觉属性则描述图像以进行图像理解。然而，视觉属性为CBIR提供了一个适合的中间层，并适应目标领域。'
- en: '**Robotics**'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**机器人技术**'
- en: '**Robotics Vision**: Robots need to perceive their surroundings from more than
    one way of interaction. Similar to humans processing perceptual inputs by using
    their knowledge about things in the form of words, phrases, and sentences, robots
    also need to integrate their perceived picture with the language to obtain the
    relevant knowledge about objects, scenes, actions, or events in the real world,
    make sense of them and perform a corresponding action. For example, if an object
    is far away, a human operator may verbally request an action to reach a clearer
    viewpoint. Robotics Vision tasks relate to how a robot can perform sequences of
    actions on objects to manipulate the real-world environment using hardware sensors
    like a depth camera or motion camera and having a verbalized image of their surrounds
    to respond to verbal commands.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器人视觉**：机器人需要通过多种交互方式感知其周围环境。类似于人类通过使用关于事物的知识（如单词、短语和句子）来处理感知输入，机器人也需要将感知到的图像与语言结合，以获得有关现实世界中物体、场景、动作或事件的相关知识，对其进行理解并执行相应的动作。例如，如果一个物体很远，人类操作员可能会口头请求采取行动以获得更清晰的视角。机器人视觉任务涉及如何让机器人通过对物体执行一系列操作来操控现实世界环境，使用硬件传感器（如深度摄像头或运动摄像头），并拥有周围环境的语言化图像，以响应口头指令。'
- en: '**Situated Language**: Robots use languages to describe the physical world
    and understand their environment. Moreover, spoken language and natural gestures
    are more convenient ways of interacting with a robot for a human being, if the
    robot is trained to understand this mode of interaction. From the human point
    of view, this is a more natural way to interact. Therefore, a robot should be
    able to perceive and transform the information from its contextual perception
    into a language using semantic structures. The most well-known approach to represent
    meaning is Semantic Parsing (SP), which transforms words into logic predicates.
    SP tries to map a natural language sentence to a corresponding meaning representation
    that can be a logical form like λ-calculus using Combinatorial Categorical Grammar
    (CCG) as rules to compositionally construct a parse tree.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**情境语言**：机器人使用语言来描述物理世界并理解其环境。此外，口语和自然手势是与机器人互动的更便捷方式，前提是机器人接受了理解这种互动模式的训练。从人的角度来看，这是一种更自然的互动方式。因此，机器人应该能够感知并将其环境感知的信息转化为使用语义结构的语言。最著名的表示意义的方法是语义解析（SP），它将单词转换为逻辑谓词。SP尝试将自然语言句子映射到对应的意义表示，这可以是类似λ-演算的逻辑形式，使用组合类别语法（CCG）作为规则来组合构建解析树。'
- en: '**Distributional Semantics**'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**分布式语义**'
- en: '**Early Multimodal Distributional Semantics Models**: The idea lying behind
    Distributional Semantics Models (DSM) is that words in similar contexts should
    have a similar meaning. Therefore, word meaning can be recovered from co-occurrence
    statistics between words and contexts in which they appear. This approach is believed
    to be beneficial in computer vision and natural language processing as image embedding
    and word embedding. DSMs are applied to jointly model semantics based on both
    visual features like colors, shape or texture and textual features like words.
    The common pipeline is to map visual data to words and apply distributional semantics
    models like LSA or topic models on top of them. Visual attributes can approximate
    the linguistic features for a distributional semantics model.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**早期多模态分布式语义模型**：分布式语义模型（DSM）背后的思想是相似上下文中的单词应具有相似的意义。因此，单词意义可以从单词与出现的上下文之间的共现统计中恢复。这种方法被认为对计算机视觉和自然语言处理有益，例如图像嵌入和词嵌入。DSM被应用于联合建模基于视觉特征（如颜色、形状或纹理）和文本特征（如单词）的语义。常见的流程是将视觉数据映射到单词上，并在其上应用分布式语义模型，如LSA或主题模型。视觉属性可以近似于分布式语义模型的语言特征。'
- en: '**Neural** **Multimodal Distributional Semantics Models**: Neural models have
    surpassed many traditional methods in both vision and language by learning better-distributed
    representation from the data. For instance, Multimodal Deep Boltzmann Machines
    can model joint visual and textual features better than topic models. In addition,
    neural models can model some cognitively plausible phenomena such as attention
    and memory. For attention, an image can initially give an image embedding representation
    using CNNs and RNNs. An LSTM network can be placed on top and act like a state
    machine that simultaneously generates outputs, such as image captions or looking
    at relevant regions of interest in an image one at a time. For memory, commonsense
    knowledge is integrated into visual question answering.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**神经** **多模态分布式语义模型**：神经模型通过从数据中学习更好的分布表示，已经在视觉和语言方面超越了许多传统方法。例如，多模态深度玻尔兹曼机可以比主题模型更好地建模联合视觉和文本特征。此外，神经模型可以建模一些认知上合理的现象，如注意力和记忆。对于注意力，图像可以使用CNNs和RNNs最初给出图像嵌入表示。可以在其上放置一个LSTM网络，像状态机一样同时生成输出，例如图像标题或一次查看图像中的相关区域。对于记忆，常识知识被集成到视觉问答中。'
- en: '**Future of Integration of NLP and Computer Vision**'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**自然语言处理与计算机视觉的未来整合**'
- en: 'If combined, two tasks can solve a number of long-standing problems in multiple
    fields, including:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果结合起来，这两个任务可以解决多个领域中的许多长期存在的问题，包括：
- en: 'Designing: In the sphere of designing homes, clothes, jewelry or similar items,
    the customer can explain the requirements verbally or in written form and this
    description can be automatically converted to images for better visualization.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计：在设计住宅、衣物、珠宝或类似物品时，客户可以口头或书面描述需求，这些描述可以自动转换为图像以便更好地可视化。
- en: 'Describing medical images: computer vision can be trained to identify subtler
    problems and see the image in more details compared to human specialists.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述医学图像：计算机视觉可以被训练识别更细微的问题，并比人类专家更详细地观察图像。
- en: Converting sign language to speech or text to help hearing-impaired people and
    ensure their better integration into society.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将手语转换为语音或文本，以帮助听力障碍人士，并确保他们更好地融入社会。
- en: Making a system which sees the surrounding and gives a spoken description of
    the same can be used by blind people.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作一个可以看到周围环境并给出口头描述的系统，可以供盲人使用。
- en: Making systems which can convert spoken content in the form of some image which
    may assist to an extent to people who do not possess the ability of speaking and
    hearing.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作可以将口语内容转换为图像的系统，这可能在一定程度上帮助那些不能说话和听力障碍的人。
- en: '![](../Images/1836bc42afd6a78f5da06c71aa0157c9.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1836bc42afd6a78f5da06c71aa0157c9.png)'
- en: Yet, since the integration of vision and language is a fundamentally cognitive
    problem, research in this field should take into account cognitive sciences that
    may provide insights into how humans process visual and textual content as a whole
    and create stories based on it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于视觉和语言的整合是一个根本的认知问题，因此该领域的研究应考虑认知科学，这可能提供有关人类如何整体处理视觉和文本内容并基于此创建故事的见解。
- en: '**References:**'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: 'Gärdenfors, P. 2014\. The Geometry of Meaning: Semantics Based on Conceptual
    Spaces. MIT Press.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Gärdenfors, P. 2014\. 意义的几何：基于概念空间的语义学。MIT出版社。
- en: Greenlee, D. 1978\. Semiotic and signiﬁcs. Int. Stud. Philos. 10 (1978), 251–254.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Greenlee, D. 1978\. 符号学与符号学研究。国际哲学研究。10 (1978)，251–254。
- en: Gupta, A. 2009\. Beyond nouns and verbs. (2009).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Gupta, A. 2009\. 超越名词和动词。 (2009)。
- en: 'Malik, J., Arbeláez, P., Carreira, J., Fragkiadaki, K., Girshick, R., Gkioxari,
    G., Gupta, S., Hariharan, B., Kar, A. and Tulsiani, S. 2016\. The three Rs of
    computer vision: Recognition, reconstruction and reorganization. Pattern Recogn.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Malik, J., Arbeláez, P., Carreira, J., Fragkiadaki, K., Girshick, R., Gkioxari,
    G., Gupta, S., Hariharan, B., Kar, A. 和 Tulsiani, S. 2016\. 计算机视觉的三大R：识别、重建和重组。模式识别。
- en: 'Shukla, D., Desai A.A. Integrating Computer Vision and Natural Language Processing:
    Issues and Challenges. VNSGU Journal of Science and Technology Vol. 4, №1, p.
    190–196.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Shukla, D., Desai A.A. 整合计算机视觉与自然语言处理：问题与挑战。VNSGU科学与技术期刊，第4卷，第1期，第190–196页。
- en: 'Wiriyathammabhum, P., Stay, D.S., Fermüller C., Aloimonos, Y. Computer Vision
    and Natural Language Processing: Recent Approaches in Multimedia and Robotics.
    ACM Computing Surveys. 49(4):1–44'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Wiriyathammabhum, P., Stay, D.S., Fermüller C., Aloimonos, Y. 计算机视觉与自然语言处理：多媒体和机器人领域的最新方法。ACM计算机调查。49(4):1–44
- en: '[Original](https://medium.com/sciforce/nlp-and-computer-vision-integrated-843558143e01).
    Reposted with permission.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/sciforce/nlp-and-computer-vision-integrated-843558143e01)。经许可转载。'
- en: '**Related:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Building a Computer Vision Model: Approaches and datasets](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建计算机视觉模型：方法与数据集](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)'
- en: '[How to do Everything in Computer Vision](https://www.kdnuggets.com/2019/02/everything-computer-vision.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在计算机视觉中完成一切](https://www.kdnuggets.com/2019/02/everything-computer-vision.html)'
- en: '[Your Guide to Natural Language Processing (NLP)](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理（NLP）指南](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个R语言库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
