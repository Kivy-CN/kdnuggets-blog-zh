- en: 'A Machine Learning Model Monitoring Checklist: 7 Things to Track'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/03/machine-learning-model-monitoring-checklist.html](https://www.kdnuggets.com/2021/03/machine-learning-model-monitoring-checklist.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Emeli Dral](https://twitter.com/EmeliDral), CTO and Co-founder of Evidently
    AI & [Elena Samuylova](https://twitter.com/elenasamuylova/), CEO and Co-founder
    at Evidently AI**'
  prefs: []
  type: TYPE_NORMAL
- en: It is not easy to build a machine learning model. It is even harder to deploy
    a service in production. But even if you managed to stick all the pipelines together,
    things do not stop here.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Once the model is in use, we immediately have to think about operating it smoothly.
    It is now delivering the business value, after all! Any disruption to model performance
    directly translates to the actual business loss.
  prefs: []
  type: TYPE_NORMAL
- en: We need to make sure the model delivers. Not just as a piece of software that
    returns the API response but as a machine learning system that we can trust to
    make the decisions.
  prefs: []
  type: TYPE_NORMAL
- en: It means we need to monitor our models. And there are more things to look for!
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/b29caf6d23d8985bee785a88032cd741.png)'
  prefs: []
  type: TYPE_IMG
- en: If ML in production caught you off-guard, here is a checklist of what to keep
    an eye on.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Service Health**'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning service is still a service. Your company probably has some
    established process of software monitoring that you can reuse. If the model runs
    in real-time, it needs proper alerting and responsible people on-call.
  prefs: []
  type: TYPE_NORMAL
- en: Even if you deal with batch models only, do not make an exception! We still
    need to track standard health indicators like memory utilization, CPU load, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: '*Our goal is to ensure that the service is operational and we comply with necessary
    constraints, such as the speed of response.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Grafana*](https://github.com/grafana/grafana)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Data Quality & Integrity**'
  prefs: []
  type: TYPE_NORMAL
- en: Is something wrong with a machine learning model? In a vast majority of cases,
    the [data is to blame](https://evidentlyai.com/blog/machine-learning-monitoring-what-can-go-wrong-with-your-data).
  prefs: []
  type: TYPE_NORMAL
- en: Upstream pipelines and models break. Users make an unannounced schema change.
    The data can disappear at the source, the physical sensors fail. The list goes
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Thus it is crucial to validate that the input data lives up to our expectations.
    The checks might include range compliance, data distribution, feature statistics,
    correlations, or any behavior we consider to be “normal” for our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '*Our goal is to confirm that we are feeding the data the model can handle.
    Before it returns an unreliable response.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Great Expectations*](https://github.com/great-expectations/great_expectations).'
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Data & Target Drift**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Things change. Even when we deal with very stable processes. Almost every machine
    learning model has this inconvenient trait: it will degrade with time.'
  prefs: []
  type: TYPE_NORMAL
- en: We might experience [Data Drift](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)
    when the model receives data that it has not seen in training. Imagine users coming
    from a different age group, marketing channel, or geographic area.
  prefs: []
  type: TYPE_NORMAL
- en: If the real-world patterns change, the Concept Drift kicks in. Think of something
    casual like a global pandemic affecting all customer behavior. Or a new competing
    product on the market offering a generous free tier. It changes how users respond
    to your marketing campaigns.
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate measure of both drifts is the degradation of model quality. But
    sometimes, the actual values are not yet known, and we cannot calculate it directly.
    In this case, there are leading indicators to track. We can monitor if the properties
    of the input data or target function have changed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/6efeba1798617c476e8b559d61ecbcb6.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, you can track the distributions both for the key model features
    and the model prediction. Then, trigger an alert if they significantly differ
    from a past timeframe.
  prefs: []
  type: TYPE_NORMAL
- en: '*Our goal is to get early signals that the world or the data has changed, and
    it is time to update our model.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Evidently*](https://github.com/evidentlyai/evidently).'
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Model Performance**'
  prefs: []
  type: TYPE_NORMAL
- en: The most direct way to know if your model works well is to contrast your predictions
    against the actual values. You can use the same metrics from the model training
    phase, be it Precision/Recall for classification, RMSE for regression, and so
    on. If something happens with the data quality or the real-world patterns, we
    will see the metrics creep down.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few caveats here.
  prefs: []
  type: TYPE_NORMAL
- en: '**First, the ground truth or actual labels often come with a delay.** For example,
    if you make your forecasts for a long horizon or there is a lag in data delivery.
    Sometimes you need an extra effort to label new data to check if your predictions
    are correct. In this case, it makes sense first to track data and target drift
    as an early warning.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Second, one needs to track not just the model quality but a related business
    KPI.** The decrease in ROC AUC does not directly say how much it impacts, say,
    marketing conversions. It is vital to connect model quality to the business metric
    or find some interpretable proxies.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Third, your quality metrics should fit the use case.** For example, the accuracy
    metric is far from ideal if you have unbalanced classes. With regression problems,
    you might care about the error sign. Thus, you should track not just the absolute
    values but the error distribution, too. It is also critical to distinguish between
    occasional outliers and real decay.'
  prefs: []
  type: TYPE_NORMAL
- en: So pick your metrics wisely!
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/8439a2a6935b22fb1dd1563563b1cb95.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Our goal is to track how well the model serves its purpose and how to debug
    it when things go wrong.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Evidently*](https://github.com/evidentlyai/evidently).'
  prefs: []
  type: TYPE_NORMAL
- en: '**5\. Performance by segment**'
  prefs: []
  type: TYPE_NORMAL
- en: For many models, the monitoring setup described above will be enough. But if
    you deal with more critical use cases, there are more items to check for.
  prefs: []
  type: TYPE_NORMAL
- en: For example, where does the model make more mistakes, and where does it work
    best?
  prefs: []
  type: TYPE_NORMAL
- en: 'You might already know some specific segments to track: like model accuracy
    for your premium customers versus the overall base. It would require a custom
    quality metric calculated only for the objects inside the segment you define.'
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, it would make sense to search for segments of low performance
    proactively. Imagine that your real estate pricing model consistently suggests
    higher-than-actual quotes in a particular geographic area. That is something you
    want to notice!
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the use case, we can tackle it by adding post-processing or business
    logic on top of the model output. Or by rebuilding the model to account for the
    low-performing segment.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/66ca85daea3a3aed3b32bb11d84053f1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Our goal is to go beyond aggregate performance and understand the model quality
    on specific slices of data.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**6\. Bias/fairness**'
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to finance, healthcare, education, and other areas where model
    decisions might have serious implications, we need to scrutinize our models even
    more.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the model performance might vary for different demographic groups
    based on their representation in the training data. Model creators need to be
    aware of this impact and have tools to mitigate unfairness together with regulators
    and stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: For that, we need to track suitable metrics such as parity in the accuracy rate.
    It applies both to the model validation and ongoing production monitoring. So,
    a few more metrics to the dashboard!
  prefs: []
  type: TYPE_NORMAL
- en: '*Our goal is to ensure fair treatment for all sub-groups and track compliance.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Fairlearn*](https://github.com/fairlearn/fairlearn).'
  prefs: []
  type: TYPE_NORMAL
- en: '**7\. Outliers**'
  prefs: []
  type: TYPE_NORMAL
- en: We know that models make errors. In some use cases, like ad targeting, we probably
    do not care if individual inputs appear weird or usual. As long as they do not
    constitute a meaningful segment the model fails on!
  prefs: []
  type: TYPE_NORMAL
- en: In other applications, we might want to know about each such case. To minimize
    the errors, we can design a set of rules to handle outliers. For example, send
    them for manual review instead of making an automated decision. In this case,
    we need a way to detect and flag them accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '*Our goal is to label anomalous data inputs where model predictions can be
    untrustworthy.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source tool to check: [*Seldon Alibi-Detect*](https://github.com/SeldonIO/alibi-detect)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/0bcc5f81d4c8b8260764e402db3ec31d.png)'
  prefs: []
  type: TYPE_IMG
- en: Monitoring might sound boring. But, it is essential to make machine learning
    work in the real world. Don’t wait for the model to fail to create your first
    dashboard!
  prefs: []
  type: TYPE_NORMAL
- en: '[**Emeli Dral**](https://twitter.com/EmeliDral) is a Co-founder and CTO at
    Evidently AI where she creates tools to analyze and monitor ML models. Earlier
    she co-founded an industrial AI startup and served as the Chief Data Scientist
    at Yandex Data Factory. She is a co-author of the Machine Learning and Data Analysis
    curriculum at Coursera with over 100,000 students.'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Elena Samuylova**](https://twitter.com/elenasamuylova/) is a Co-founder
    and CEO at Evidently AI. Earlier she co-founded an industrial AI startup and led
    business development at Yandex Data Factory. Since 2014, she has worked with companies
    from manufacturing to retail to deliver ML-based solutions. In 2018, Elena was
    named 50 Women in Product Europe by Product Management Festival.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Machine Learning Systems Design: A Free Stanford Course](/2021/02/machine-learning-systems-design-free-stanford-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MLOps: Model Monitoring 101](/2021/01/mlops-model-monitoring-101.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Use MLOps for an Effective AI Strategy](/2021/01/mlops-effective-ai-strategy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
