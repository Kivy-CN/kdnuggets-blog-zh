# Python数据科学中的网络爬取

> 原文：[https://www.kdnuggets.com/2017/12/baesens-web-scraping-data-science-python.html](https://www.kdnuggets.com/2017/12/baesens-web-scraping-data-science-python.html)

**由 [Seppe vanden Broucke 和 Bart Baesens](http://www.webscrapingfordatascience.com/)** 赞助发布。

> 对于那些不熟悉编程或网页深层工作原理的人来说，网络爬取通常看起来像是一门黑暗的艺术：编写一个能够自主探索互联网并收集数据的程序被视为一种神奇而令人兴奋的能力。在 [![Web Scraping for Data Science with Python](../Images/a0d81c168534c1bf8d2466965719e467.png) **《Python数据科学中的网络爬取》**](https://www.amazon.com/Web-Scraping-Data-Science-Python/dp/1979343780/ref=sr_1_6?ie=UTF8&qid=1512404325&sr=8-6)一书中，我们旨在提供一个简明但全面且现代的网络爬取指南，使用Python作为编程语言。此外，本书针对数据科学读者进行编写。
> 
> 我们自己也是数据科学家，常常发现网络爬取是一个强大的工具，因为许多数据科学项目都从获得适当的数据集开始，那么为什么不利用网络提供的信息宝库呢？本书采用“代码优先”的方法，帮助你迅速入门而不需要太多的样板文本，展示了如何处理当今的网页，包括JavaScript、cookies以及常见的网络爬取防范技术，并包括关于网络爬取的详细管理和法律讨论。我们还提供了大量进一步阅读和学习的指引，并包括十四个真实的、完全解决的例子。[有关更多细节，请点击这里](https://www.amazon.com/Web-Scraping-Data-Science-Python/dp/1979343780/ref=sr_1_6?ie=UTF8&qid=1512404325&sr=8-6)。

在这篇文章中，我们简要探讨了网络爬取在数据科学项目中的有用性。网络“爬取”（也称为“网络采集”、“网络数据提取”甚至“网络数据挖掘”）可以定义为“构建一个代理以自动下载、解析和组织来自网络的数据”。换句话说：与其让人类最终用户在其网页浏览器中点击并将有趣的部分复制粘贴到例如电子表格中，不如将这个任务交给计算机程序，该程序能够比人类更快、更准确地执行这一任务。

从互联网自动收集数据可能和互联网本身一样古老，甚至“抓取”这个术语的出现也早于网页。早在“网页抓取”这个术语流行之前，一种被称为“屏幕抓取”的做法已经作为从视觉表现中提取数据的一种方式得到了广泛应用——在计算机早期（比如 1960 年代到 80 年代），这往往是简单的基于文本的“终端”。就像今天一样，那时的人们已经对从这些终端中“抓取”大量文本并将这些数据存储以备后用感兴趣。当你使用普通的网页浏览器浏览网页时，你可能遇到过多个你考虑过收集、存储和分析页面上数据的站点。特别是对于数据科学家来说，他们的“原材料”就是数据，网络提供了许多有趣的机会。在这种情况下，使用网页抓取可能会很有用。如果你能在网页浏览器中查看到一些数据，你就能够通过程序访问和提取这些数据。如果你能通过程序访问这些数据，这些数据就可以被存储、清理，并以任何方式使用。无论你的兴趣领域是什么，总有几乎适用的数据用例可以改善或丰富你的实践。正如俗话所说，“数据是新的石油”，而网络上拥有大量的数据。

在本文中，我们的目标是构建一个 S&P 500 公司及其通过董事会成员互联的社交图谱。我们将从 [路透社 S&P 500 页面](https://www.reuters.com/finance/markets/index/.SPX) 开始，以获取符号列表：

```py

from bs4 import BeautifulSoup
import requests
import re

session = requests.Session()

sp500 = 'https://www.reuters.com/finance/markets/index/.SPX'

page = 1
regex = re.compile(r'/finance/stocks/overview/.*')
symbols = []

while True:
  print('Scraping page:', page)
  params = params={'sortBy': '', 'sortDir' :'', 'pn': page}
  html = session.get(sp500, params=params).text
  soup = BeautifulSoup(html, "html.parser")
  pagenav = soup.find(class_='pageNavigation')
  if not pagenav:
    break
  companies = pagenav.find_next('table', class_='dataTable')
  for link in companies.find_all('a', href=regex):
    symbols.append(link.get('href').split('/')[-1])
  page += 1

print(symbols)

```

一旦我们获得了一个符号列表，我们可以访问每个符号的董事会成员页面（例如 [https://www.reuters.com/finance/stocks/company-officers/MMM.N](https://www.reuters.com/finance/stocks/company-officers/MMM.N)），提取出董事会成员的表格，并将其存储为 pandas 数据框：

```py

from bs4 import BeautifulSoup
import requests
import pandas as pd

session = requests.Session()

officers = 'https://www.reuters.com/finance/stocks/company-officers/{symbol}'

symbols = ['MMM.N', [...], 'ZTS.N']
dfs = []

for symbol in symbols:
  print('Scraping symbol:', symbol)
  html = session.get(officers.format(symbol=symbol)).text
  soup = BeautifulSoup(html, "html.parser")
  officer_table = soup.find('table', {"class" : "dataTable"})
  df = pd.read_html(str(officer_table), header=0)[0]
  df.insert(0, 'symbol', symbol)
  dfs.append(df)

df = pd.concat(dfs)
df.to_pickle('data.pkl')

```

这种信息可以引出很多有趣的用例，特别是在图谱和社交网络分析领域。例如，我们可以利用收集到的信息导出图谱，并使用 Gephi 这一流行的图形可视化工具进行可视化：

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在 IT 方面

* * *

```py

import pandas as pd
import networkx as nx
from networkx.readwrite.gexf import write_gexf

df = pd.read_pickle('data.pkl')

G = nx.Graph()

for row in df.itertuples():
  G.add_node(row.symbol, type='company')
  G.add_node(row.Name,type='officer')
  G.add_edge(row.symbol, row.Name)

write_gexf(G, 'graph.gexf')

```

输出文件可以在 Gephi 中打开、过滤和修改。下图展示了 Apple、Google 和 Amazon 的 3 阶层 egonets 的快照，表明这些网络确实是相互连接的：

![Sp500 亚马逊 苹果 Google 网络](../Images/237f9e2706af8cf93501923c07c4a2f1.png)

**进一步阅读**

我们即将发布的书籍《[Web Scraping for Data Science with Python](https://www.amazon.com/Web-Scraping-Data-Science-Python/dp/1979343780/ref=sr_1_6?ie=UTF8&qid=1512404325&sr=8-6)》将面向希望在工作流程中采用网页抓取技术的数据科学家。更多信息请关注 [www.webscrapingfordatascience.com/](http://www.webscrapingfordatascience.com/)。

图形在预测设置中也可以以多种方式使用。有关更多信息，请参考：

+   [www.dataminingapps.com/dma_research/fraud-analytics/](http://www.dataminingapps.com/dma_research/fraud-analytics/)

+   Node2Vec 是一种强大的特征化技术，将图中的节点转换为特征向量：[https://snap.stanford.edu/node2vec/](https://snap.stanford.edu/node2vec/)

+   个性化的 PageRank 经常作为特征化方法用于例如客户流失和欺诈分析的背景中：[https://www.r-bloggers.com/from-random-walks-to-personalized-pagerank/](https://www.r-bloggers.com/from-random-walks-to-personalized-pagerank/)

+   Van Vlasselaer, V., Akoglu, L., Eliassi-Rad, T., Snoeck, M., Baesens, B. (2015). 通过可疑团体成员进行的“罪行与星座”：欺诈检测。第48届夏威夷国际系统科学会议论文集：已接受。HICSS-48\. 夏威夷考爱岛，2015年1月5-8日

+   Van Vlasselaer, V., Akoglu, L., Eliassi-Rad, T., Snoeck, M., Baesens, B. (2014). 在大型欺诈网络中寻找团体：理论与洞见。国际运筹学联合会大会（IFORS 2014）。西班牙巴塞罗那，2014年7月13-18日。

+   Van Vlasselaer, V., Akoglu, L., Eliassi-Rad, T., Snoeck, M., Baesens, B. (2014). Gotch'all! 检测欺诈团体的高级网络分析。PAW（预测分析世界）。英国伦敦，2014年10月29-30日

+   Van Vlasselaer, V., Van Dromme, D., Baesens, B. (2013). 社交网络分析用于检测社会安全欺诈中的蜘蛛结构：新的见解和挑战：已接受。欧洲运筹学会议。意大利罗马，2013年7月1-4日

+   Van Vlasselaer, V., Meskens, J., Van Dromme, D., Baesens, B. (2013). 利用社交网络知识检测社会安全欺诈中的蜘蛛结构。2013年 IEEE/ACM 国际社交网络分析与挖掘会议论文集。ASONAM. 加拿大尼亚加拉大瀑布，2013年8月25-28日（第813-820页）。美国新泽西州皮斯卡塔维，445 Hoes Lane, PO Box 1331, NJ 08855-1331：IEEE计算机学会

**简历：塞佩·范登·布鲁克**是比利时鲁汶大学经济与商业学院的助理教授。他的研究兴趣包括商业数据挖掘与分析、机器学习、过程管理和过程挖掘。他的工作已在知名国际期刊上发表，并在顶级会议上展示。塞佩的教学包括高级分析、大数据和信息管理课程。他还经常为工业和商业观众进行讲授。

**巴特·贝森斯**是比利时鲁汶大学（KU Leuven）的大数据与分析教授，以及英国南安普顿大学的讲师。他在大数据与分析、信用风险建模、欺诈检测和市场营销分析方面进行了广泛的研究。他已撰写了 8 本书和 200 多篇科学论文，其中一些已在知名国际期刊上发表，并在顶级国际会议上展示。他获得了各种最佳论文和最佳演讲者奖项。他的研究总结在[www.dataminingapps.com](http://www.dataminingapps.com)。

### 更多相关内容

+   [初学者的 Python 网络爬虫指南](https://www.kdnuggets.com/2022/10/beginner-guide-web-scraping-python.html)

+   [使用 Python 和 Beautiful Soup 的分步网络爬虫指南](https://www.kdnuggets.com/2023/04/stepbystep-guide-web-scraping-python-beautiful-soup.html)

+   [精通 BeautifulSoup 的网络爬虫](https://www.kdnuggets.com/mastering-web-scraping-with-beautifulsoup)

+   [Octoparse 8.5：赋能本地爬取及更多功能](https://www.kdnuggets.com/2022/02/octoparse-85-empowering-local-scraping.html)

+   [创建一个从音频中提取主题的 Python 网络应用](https://www.kdnuggets.com/2023/01/creating-web-application-extract-topics-audio-python.html)

+   [在 5 分钟内用 Python 构建网络爬虫](https://www.kdnuggets.com/2022/02/build-web-scraper-python-5-minutes.html)
