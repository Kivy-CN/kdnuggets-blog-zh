- en: Popular Machine Learning Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/05/popular-machine-learning-algorithms.html](https://www.kdnuggets.com/2022/05/popular-machine-learning-algorithms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'When starting out with Data Science, there is so much to learn it can become
    quite overwhelming. If you need more understanding of the foundations of Data
    Science, check out this article: [Best Data Science Books for Beginners](/2022/03/best-data-science-books-beginners.html)'
  prefs: []
  type: TYPE_NORMAL
- en: This guide will help aspiring data scientists and machine learning engineers
    gain better knowledge and experience. I will list different types of machine learning
    algorithms, which can be used with both Python and R.
  prefs: []
  type: TYPE_NORMAL
- en: 1. Linear Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Linear Regression](../Images/7fa80364f50cfaf834ec522ec0d16f1b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikipedia](https://en.wikipedia.org/wiki/Regression_analysis)'
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression is the simplest Machine learning algorithm that branches off
    from Supervised Learning. It is primarily used to solve regression problems and
    make predictions on continuous dependent variables with the knowledge from independent
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of Linear Regression is to find the line of best fit, which can help
    predict the output for continuous dependent variables. For example, continuous
    values are house prices, age, and salary.
  prefs: []
  type: TYPE_NORMAL
- en: Simple Linear Regression is a model that estimates the relationship between
    one single independent variable and one dependent variable using a straight line.
    Multiple Linear Regression consists of more than two independent variables.
  prefs: []
  type: TYPE_NORMAL
- en: 2. Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Logistic Regression](../Images/495e883e42b7ce0cda189f5bdd40129a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikipedia ](https://en.wikipedia.org/wiki/Sigmoid_function)'
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression is another Machine Learning algorithm that branches off
    supervised learning. It can be used for both Regression and Classification tasks,
    however, it is mainly used for Classification. If you would like to know more
    about Logistic Regression used for Classification tasks, click on the [link](/2022/04/logistic-regression-classification.html).
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression is used to predict the categorical dependent variable with
    the knowledge of independent variables. The aim is to classify outputs, which
    can only be between 0 and 1\. The weighted sum of inputs is passed through an
    activation function called Sigmoid Function which maps values between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression is based on Maximum Likelihood Estimation, a method to estimate
    the parameters of an assumed probability distribution, given some observed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is easy to get confused between the Linear and Logistic Regression, so if
    you would like a deeper explanation of the two, have a read of this article: [Linear
    vs Logistic Regression: A Succinct Explanation](/2022/03/linear-logistic-regression-succinct-explanation.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 3. Decision Tree
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Decision Tree](../Images/f3b68f21b7a55a4a00b9f4d809d23e8d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [explorium](https://www.explorium.ai/blog/the-complete-guide-to-decision-trees/)'
  prefs: []
  type: TYPE_NORMAL
- en: The Decision Tree is another machine learning algorithm that branches off supervised
    learning. The decision tree algorithm can be used for both regression and classification
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: It is a tree-like model which is used in the decision-making process by visually
    displaying decisions and their potential outcomes, consequences, and costs. The
    concept resembles the human mind; by splitting the data into parts. As we granulate
    the data as much as we can, we have split them into unique pieces.
  prefs: []
  type: TYPE_NORMAL
- en: The overall aim of a Decision Tree is to create a training model that can be
    used to predict the class of the target variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of decision trees based on the type of target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Categorical Variable: A Decision tree where the target variable is Categorical.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Continuous Variable: A Decision tree where the target variable is Continuous.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 4\. Random Forest®
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Random Forest](../Images/f5c0b335f9879e20b28138287891ccdf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikipedia ](https://en.wikipedia.org/wiki/Random_forest)'
  prefs: []
  type: TYPE_NORMAL
- en: The next machine learning algorithm is the random forest algorithm which is
    a supervised machine learning algorithm widely in classification and regression
    problems. Just like a decision tree, it is also a tree-based algorithm. However,
    the random forest algorithm uses multiple decision trees for making decisions
    - a forest of trees.
  prefs: []
  type: TYPE_NORMAL
- en: The random forest algorithm handles regression tasks using datasets that contain
    continuous variables, whilst it used categorical variables to handle classification
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The random forest algorithm is an ensemble, which means combining multiple models,
    where a collection of models are used to make predictions rather than using an
    individual model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensemble uses two types of methods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bagging: This generates additional data for the training dataset. This is done
    to decrease the variance in the predictions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Boosting: This combines weak learners and transforms them into strong learners
    by creating sequential models so that the final model has the highest accuracy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 5. Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Naive Bayes](../Images/fde81628a61290e89a229fcbea992e67.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Medium](https://medium.com/analytics-vidhya/na%C3%AFve-bayes-algorithm-5bf31e9032a2)'
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes is a classification technique based on Bayes’ Theorem. Bayes’ Theorem
    is a mathematical formula used for calculating conditional probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula above is:'
  prefs: []
  type: TYPE_NORMAL
- en: How likely does H happens given that E happens (Posterior Probability)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How likely does E happen given that H happens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How likely does H happen on its own
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How likely does E happen on its own
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It assumes that when a particular feature is present in a class, it is unrelated
    to the presence of any other feature.  It predicts the probability of different
    classes based on various attributes. The class with the highest probability is
    considered the most likely class.
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes is not a single algorithm, but multiple algorithms where all of
    them share a common principle, all based on Bayes' Theorem.
  prefs: []
  type: TYPE_NORMAL
- en: 6. k-Nearest Neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![kNN](../Images/0fd1ae1b45fda631331db0173a0e7ffd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [rapidminer](https://rapidminer.com/blog/k-nearest-neighbors-laziest-machine-learning-technique/)'
  prefs: []
  type: TYPE_NORMAL
- en: kNN, short for K-nearest neighbors, is an algorithm that branches off supervised
    machine learning which can be used to solve both classification and regression
    problems. The KNN algorithm assumes that similar things exist in close proximity.
    I remember it as the birds of a feather flock together.
  prefs: []
  type: TYPE_NORMAL
- en: kNN uses the concept of similarity between other data points using distance,
    proximity, or closeness. A mathematical approach is used to calculate the distance
    between points on a graph, where it then labels the unobserved data based on the
    nearest labeled observed data points.
  prefs: []
  type: TYPE_NORMAL
- en: In order to find the closest similar points, you will need to find the distance
    between the data points. This can be done using distance measures such as Euclidean
    distance, Hamming distance, Manhattan distance, and Minkowski distance.
  prefs: []
  type: TYPE_NORMAL
- en: The K is referred to as the number of nearest neighbors, where it is generally
    an odd number.
  prefs: []
  type: TYPE_NORMAL
- en: 7. K-Means
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![K-Means](../Images/2976669a90c0a9a44ade7c2decf73abe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Wikimedia](https://commons.wikimedia.org/wiki/File:K-means_convergence.gif)'
  prefs: []
  type: TYPE_NORMAL
- en: K-means clustering is a type of machine learning algorithm that branches off
    unsupervised learning. It is a clustering algorithm that groups similar items/data
    points in the form of clusters, where the number of groups is referred to as K.
  prefs: []
  type: TYPE_NORMAL
- en: Data points inside the cluster are considered homogeneous and heterogeneous
    to peer groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'K-means finds the similarity between these data points and groups them into
    the clusters by:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the k values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialising the centroids.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the group and find the average.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to determine the k-value, you can use two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: Elbow Method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silhouette Method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8\. Dimensionality Reduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![Dimensionality Reduction](../Images/33cacd72e9921b7e1b6c09f66b9b46f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [TDS](https://towardsdatascience.com/curse-of-dimensionality-a-curse-to-machine-learning-c122ee33bfeb#:~:text=Curse%20of%20Dimensionality%20describes%20the,first%20introduced%20by%20Richard%20E.)'
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction is a technique used to reduce the number of input variables
    in training data. In layman's terms, it is the process of reducing the dimension
    of your feature set. Let's say you have a dataset with a hundred columns, dimensionality
    reduction will reduce the number of columns down to twenty.
  prefs: []
  type: TYPE_NORMAL
- en: When the number of features increases, the model automatically becomes more
    complex, and the higher chances of overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: The curse of dimensionality is the biggest problem when it comes to working
    with data in higher dimensions, and refers to when your data has too many features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dimensionality reduction can be achieved by using the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection is used to identify and select relevant features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering manually generates new features using existing features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Methods for Dimensionality Reduction include:'
  prefs: []
  type: TYPE_NORMAL
- en: Principal Component Analysis (PCA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear Discriminant Analysis (LDA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalized Discriminant Analysis (GDA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now you have a good understanding of the popular machine learning algorithms
    used in the day-to-day lives of Data Scientists.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to know which resources to further build your knowledge,
    have a read of this article: [Machine Learning books you need to read in 2022](/2022/04/machine-learning-books-need-read-2022.html)'
  prefs: []
  type: TYPE_NORMAL
- en: RANDOM FORESTS and RANDOMFORESTS are registered marks of Minitab, LLC.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Most Popular Intro to Programming Course From Harvard is Free!](https://www.kdnuggets.com/2022/03/popular-intro-programming-course-harvard-free.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why TinyML Cases Are Becoming Popular?](https://www.kdnuggets.com/2022/10/tinyml-cases-becoming-popular.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why is DuckDB Getting Popular?](https://www.kdnuggets.com/2023/07/duckdb-getting-popular.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News March 30: The Most Popular Intro to Programming…](https://www.kdnuggets.com/2022/n13.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free Workshop on AI Quality, Back By Popular Demand](https://www.kdnuggets.com/2022/05/truera-free-workshop-ai-quality-back-popular-demand.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
