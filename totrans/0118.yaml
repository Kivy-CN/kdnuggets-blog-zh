- en: 'Introducing OpenLLM: Open Source Library for LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Introducing OpenLLM: Open Source Library for LLMs](../Images/1efb563e445901db6e7d4ada83d0ed00.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we’re all thinking the same thing. Is the world of LLMs really
    taking over? Some of you may have expected the hype to plateau, but it is still
    on the continuous rise. More resources are going into LLMs as it has shown a huge
    demand.
  prefs: []
  type: TYPE_NORMAL
- en: Not only has the performance of LLMs been successful, but also their versatility
    in being able to adapt to various NLP tasks such as translation and sentiment
    analysis. Fine-tuning pre-trained LLMs has made it much easier for specific tasks,
    making it less computationally expensive to build a model from scratch. LLMs have
    swiftly been implemented into various real-world applications, boosting the amount
    of research and development.
  prefs: []
  type: TYPE_NORMAL
- en: Open-source models have also been a big plus with LLMs, as the availability
    of open-source models has allowed researchers and organizations to continuously
    improve existing models, and how they can be safely integrated into society.
  prefs: []
  type: TYPE_NORMAL
- en: What is OpenLLM?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[OpenLLM](https://github.com/bentoml/OpenLLM) is an open platform for operating
    LLMs in production. Using OpenLLM, you can run inference on any open-source LLMs,
    fine-tune them, deploy, and build powerful AI apps with ease.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenLLM contains state-of-the-art LLMs, such as StableLM, Dolly, ChatGLM, StarCoder
    and more, which are all supported by built-in support. You also have the freedom
    to build your own AI application, as OpenLLM is not just a standalone product
    and supports LangChain, BentoML, and Hugging Face.
  prefs: []
  type: TYPE_NORMAL
- en: All these features, and it’s open-source? Sounds a bit crazy right?
  prefs: []
  type: TYPE_NORMAL
- en: And to top it, it’s easy to install and use.
  prefs: []
  type: TYPE_NORMAL
- en: How to Use OpenLLM?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To make use of LLM, you will need to have at least Python 3.8, as well as pip
    installed on your system. To prevent package conflicts, it is recommended that
    you use a virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have these ready, you can easily install OpenLLM by using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To ensure that it has been installed correctly, you can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to start an LLM server, use the following command including the model
    of your choice:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, if you’d like to start an [OPT](https://huggingface.co/docs/transformers/model_doc/opt)
    server, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Supported Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '10 models are supported in OpenLLM. You can also find the installation commands
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[chatglm](https://github.com/THUDM/ChatGLM-6B)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This model requires a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[Dolly-v2](https://github.com/databrickslabs/dolly)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This model can be used on both CPU and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[falcon](https://falconllm.tii.ae/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This model requires a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[flan-t5](https://huggingface.co/docs/transformers/model_doc/flan-t5)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This model can be used on both CPU and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[gpt-neox](https://github.com/EleutherAI/gpt-neox)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This model requires a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[mpt](https://huggingface.co/mosaicml)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This model can be used on both CPU and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[opt](https://huggingface.co/docs/transformers/model_doc/opt)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This model can be used on both CPU and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[stablelm](https://github.com/Stability-AI/StableLM)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This model can be used on both CPU and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[starcoder](https://github.com/bigcode-project/starcoder)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This model requires a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[baichuan](https://github.com/baichuan-inc/Baichuan-7B)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This model requires a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: To find out more information about runtime implementations, fine-tuning support,
    integrating a new model, and deploying to production - please have a look [here](https://github.com/bentoml/OpenLLM#runtime-implementations-experimental)
    at the one that caters to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping it up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re looking to use OpenLLM or need some assistance, you can reach out
    and join their [Discord](https://l.bentoml.com/join-openllm-discord) and [Slack
    community](https://l.bentoml.com/join-slack). You can also contribute to OpenLLM's
    codebase using their [Developer Guide](https://github.com/bentoml/OpenLLM/blob/main/DEVELOPMENT.md).
  prefs: []
  type: TYPE_NORMAL
- en: Has anybody tried it yet? If you have, let us know what you think in the comments!
  prefs: []
  type: TYPE_NORMAL
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist,
    Freelance Technical Writer and Community Manager at KDnuggets. She is particularly
    interested in providing Data Science career advice or tutorials and theory based
    knowledge around Data Science. She also wishes to explore the different ways Artificial
    Intelligence is/can benefit the longevity of human life. A keen learner, seeking
    to broaden her tech knowledge and writing skills, whilst helping guide others.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing MPT-7B: A New Open-Source LLM](https://www.kdnuggets.com/2023/05/introducing-mpt7b-new-opensource-llm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing MetaGPT''s Data Interpreter: SOTA Open Source LLM-based…](https://www.kdnuggets.com/metagpt-data-interpreter-open-source-llm-based-data-solutions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing the Testing Library for Natural Language Processing](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama Project: An Open-Source Initiative to Democratizing LLMs](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Falcon LLM: The New King of Open-Source LLMs](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
