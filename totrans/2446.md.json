["```py\nimport streamlit as st\n\nimport timeit\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tpot import TPOTClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_digits, load_iris\nfrom sklearn import metrics\nfrom stqdm import stqdm\n```", "```py\n@st.cache\ndef load_data(dataset, train_size, test_size, random_state):\n\t\"\"\"Load data\"\"\"\n\tds = ''\n\tif dataset == 'digits':\n\t\tds = load_digits()\n\t\tdf = load_digits(as_frame=True)\n\tif dataset == 'iris':\n\t\tds = load_iris()\n\t\tdf = load_iris(as_frame=True)\n\tX_train, X_test, y_train, y_test = train_test_split(ds.data, ds.target, train_size=train_size, test_size=test_size, random_state=random_state)\n\treturn X_train, X_test, y_train, y_test, df['frame']\n```", "```py\n# Set title and description\nst.title(\"AutoML Pipeline Optimization Sandbox\")\nst.write(\"Experiment with using open source automated machine learning tool TPOT for building fully-automated prediction pipelines\")\n\n# Create sidebar\nsidebar = st.sidebar\ndataset = sidebar.selectbox('Dataset', ['iris','digits'])\ntrain_display = sidebar.checkbox('Display training data', value=True)\nsearch_iters = sidebar.slider('Number of search iterations', min_value=1, max_value=5)\ngenerations = sidebar.slider('Number of generations', min_value=1, max_value=10)\npopulation_size = sidebar.select_slider('Population size', options=[10,20,30,40,50,60,70,80,90,100])\n\nrandom_state = 42\ntrain_size = 0.75\ntest_size = 1.0 - train_size\ncheckpoint_folder = './tpot_checkpoints'\noutput_folder = './tpot_output'\nverbosity = 0\nn_jobs = -1\ntimes = []\nbest_pipes = []\nscores = []\n\n# Load (and display?) data\nX_train, X_test, y_train, y_test, df = load_data(dataset)\nif train_display:\n\tst.write(df)\n```", "```py\n# Define scoring metric and model evaluation method\nscoring = 'accuracy'\ncv = ('stratified k-fold cross-validation',\n       StratifiedKFold(n_splits=10,  \n       shuffle=True,\n       random_state=random_state))\n\n# Define search\ntpot = TPOTClassifier(cv=cv[1],\n\t\t      scoring=scoring,\n\t              verbosity=verbosity,\n\t\t      random_state=random_state,\n\t\t      n_jobs=n_jobs,\n\t\t      generations=generations,\n\t\t      population_size=population_size,\n\t\t      periodic_checkpoint_folder=checkpoint_folder)\n\n# Pipeline optimization iterations\nwith st.spinner(text='Pipeline optimization in progress'):\n\tfor i in stqdm(range(search_iters)):\n\t\tstart_time = timeit.default_timer()\n\t\ttpot.fit(X_train, y_train)\n\t\telapsed = timeit.default_timer() - start_time\n\t\tscore = tpot.score(X_test, y_test)\n\t\tbest_pipes.append(tpot.fitted_pipeline_)\n\t\tst.write(f'\\n__Pipeline optimization iteration: {i}__\\n')\n\t\tst.write(f'* Elapsed time: {elapsed} seconds')\n\t\tst.write(f'* Pipeline score on test data: {score}')\n\ttpot.export(f'{output_folder}/tpot_{dataset}_pipeline_{i}.py')\n```", "```py\n# check if pipelines are the same\nresult = True\nfirst_pipe = str(best_pipes[0])\nfor pipe in best_pipes:\n\tif first_pipe != str(pipe):\n\t\tresult = False\nif (result):\n\tst.write(\"\\n__All best pipelines were the same:__\\n\")\n\tst.write(best_pipes[0])\nelse:\n\tst.write('\\nBest pipelines:\\n')\n\tst.write(*best_pipes, sep='\\n\\n')\n\nst.write('__Saved to file:__\\n')\nst.write(f'```", "```py')\n\nst.success(\"Pipeline optimization complete!\")\n```", "```py\n# Output contents of best pipe file\nwith open (f'{output_folder}/tpot_{dataset}_pipeline_{i}.py', 'r') as best_file:\n\tcode = best_file.read()\nst.write(f'```", "```py')\n```"]