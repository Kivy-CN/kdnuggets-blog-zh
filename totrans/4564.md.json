["```py\n#Independent variables\ninput_set = np.array([[0,1,0],\n                      [0,0,1],\n                      [1,0,0],\n                      [1,1,0],\n                      [1,1,1],\n                      [0,1,1],\n                      [0,1,0]])#Dependent variable\nlabels = np.array([[1,\n                    0,\n                    0,\n                    1,\n                    1,\n                    0,\n                    1]])\nlabels = labels.reshape(7,1) #to convert labels to vector\n```", "```py\nnp.random.seed(42)\nweights = np.random.rand(3,1)\nbias = np.random.rand(1)\nlr = 0.05 #learning rate\n```", "```py\ndef sigmoid(x):\n    return 1/(1+np.exp(-x))\n```", "```py\ndef sigmoid_derivative(x):\n    return sigmoid(x)*(1-sigmoid(x))\n```", "```py\nfor epoch in range(25000):\n    inputs = input_set\n    XW = np.dot(inputs, weights)+ bias\n    z = sigmoid(XW)\n    error = z - labels\n    print(error.sum())\n    dcost = error\n    dpred = sigmoid_derivative(z)\n    z_del = dcost * dpred\n    inputs = input_set.T\n    weights = weights - lr*np.dot(inputs, z_del)\n\n    for num in z_del:\n        bias = bias - lr*num\n```", "```py\ninputs = input_set\n```", "```py\nXW = np.dot(inputs, weights)+ bias\n```", "```py\nz = sigmoid(XW)\n```", "```py\nerror = z - labels\nprint(error.sum())\n```", "```py\nslope = input x dcost x dpred\n```", "```py\ndcost = error\ndpred = sigmoid_derivative(z)\nz_del = dcost * dpred\ninputs = input_set.T\nweights = weight-lr*np.dot(inputs, z_del)\n```", "```py\nfor num in z_del:\n        bias = bias - lr*num\n```", "```py\n-0.001415035616137969\n-0.0014150128584959256\n-0.0014149901015685952\n-0.0014149673453557714\n-0.0014149445898578358\n-0.00141492183507419\n-0.0014148990810050437\n-0.0014148763276499686\n-0.0014148535750089977\n-0.0014148308230825385\n-0.0014148080718707524\n-0.0014147853213728624\n-0.0014147625715897338\n-0.0014147398225201734\n-0.0014147170741648386\n-0.001414694326523502\n-0.001414671579597255\n-0.0014146488333842064\n-0.0014146260878853782\n-0.0014146033431002465\n-0.001414580599029179\n-0.0014145578556723406\n-0.0014145351130293877\n-0.0014145123710998\n-0.0014144896298846701\n-0.0014144668893831067\n-0.001414444149595611\n-0.0014144214105213174\n-0.0014143986721605849\n-0.0014143759345140276\n-0.0014143531975805163\n-0.001414330461361444\n-0.0014143077258557749\n-0.0014142849910631708\n-0.00141426225698401\n-0.0014142395236186895\n-0.0014142167909661323\n-0.001414194059027955\n-0.001414171327803089\n-0.001414148597290995\n-0.0014141258674925626\n-0.0014141031384067547\n-0.0014140804100348098\n-0.0014140576823759854\n-0.0014140349554301636\n-0.0014140122291978665\n-0.001413989503678362\n-0.001413966778871751\n-0.001413944054778446\n-0.0014139213313983257\n-0.0014138986087308195\n-0.0014138758867765552\n-0.0014138531655347973\n-0.001413830445006264\n-0.0014138077251906606\n-0.001413785006087985\n-0.0014137622876977014\n-0.0014137395700206355\n-0.0014137168530558228\n-0.0014136941368045382\n-0.0014136714212651114\n-0.0014136487064390219\n-0.0014136259923249635\n-0.001413603278923519\n-0.0014135805662344007\n-0.0014135578542581566\n-0.0014135351429944293\n-0.0014135124324428719\n-0.0014134897226037203\n-0.0014134670134771238\n-0.0014134443050626295\n-0.0014134215973605428\n-0.0014133988903706311\n```", "```py\nsingle_pt = np.array([1,0,0])\nresult = sigmoid(np.dot(single_pt, weights) + bias)\nprint(result)\n```", "```py\nsingle_pt = np.array([0,1,0])\nresult = sigmoid(np.dot(single_pt, weights) + bias)\nprint(result)\n```"]