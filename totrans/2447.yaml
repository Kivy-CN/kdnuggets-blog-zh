- en: 'Linear vs Logistic Regression: A Succinct Explanation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归与逻辑回归：简明解释
- en: 原文：[https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)
- en: They both start with the letter ‘L’ and end with Regression, so it’s quite understandable
    how people may confuse them. Linear Regression and Logistic Regression are two
    well-used Machine Learning Algorithms that both branch off from Supervised Learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都以字母‘L’开头并以回归结尾，因此人们可能会混淆它们是可以理解的。线性回归和逻辑回归是两种常用的机器学习算法，都源自于监督学习。
- en: 'To recap:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 总结：
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Supervised Learning** is when the algorithm learns on a labeled dataset and
    analyses the training data. These labeled data sets have inputs and expected outputs.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习**是指算法在标记的数据集上进行学习，并分析训练数据。这些标记的数据集具有输入和预期的输出。'
- en: '**Unsupervised Learning** learns on unlabeled data, inferring more about hidden
    structures to produce accurate and reliable outputs.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**是在未标记的数据上进行学习，推断更多关于隐藏结构的信息，以产生准确和可靠的输出。'
- en: The relation between Linear and Logistic Regression is the fact that they use
    labeled datasets to make predictions. However, the main difference between them
    is how they are being used. Linear Regression is used to solve Regression problems
    whereas Logistic Regression is used to solve Classification problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归与逻辑回归之间的关系在于它们使用标记的数据集进行预测。然而，它们之间的主要区别在于它们的使用方式。线性回归用于解决回归问题，而逻辑回归用于解决分类问题。
- en: '**Classification** is about predicting a label, by identifying which category
    an object belongs to based on different parameters.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**是关于通过识别对象所属的类别来预测标签，基于不同的参数。'
- en: '**Regression** is about predicting a continuous output, by finding the correlations
    between dependent and independent variables.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**是关于通过寻找因变量和自变量之间的相关性来预测连续的输出。'
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/dfe7d0f607596f0c73af5c8853f1daf8.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归与逻辑回归：简明解释](../Images/dfe7d0f607596f0c73af5c8853f1daf8.png)'
- en: 'Source: [Javatpoint](https://www.javatpoint.com/regression-vs-classification-in-machine-learning)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Javatpoint](https://www.javatpoint.com/regression-vs-classification-in-machine-learning)'
- en: Linear Regression
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: Linear Regression is known as one of the simplest Machine learning algorithms
    that branch from Supervised Learning and is primarily used to solve regression
    problems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归被认为是从监督学习中派生出的最简单的机器学习算法之一，主要用于解决回归问题。
- en: The use of **Linear Regression** is to make predictions on continuous dependent
    variables with the assistance and knowledge from independent variables. The overall
    goal of Linear Regression is to find the line of best fit, which can accurately
    predict the output for continuous dependent variables. Examples of continuous
    values are house prices, age, and salary.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性回归**的用途是对连续的因变量进行预测，并利用自变量的辅助和知识。线性回归的总体目标是找到最佳拟合线，能够准确预测连续因变量的输出。连续值的例子包括房价、年龄和薪水。'
- en: Simple Linear Regression is a regression model that estimates the relationship
    between one single independent variable and one dependent variable using a straight
    line. If there are more than two independent variables, we then call this Multiple
    Linear Regression.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简单线性回归是一种回归模型，用直线估计单个自变量和一个因变量之间的关系。如果有两个以上的自变量，我们称之为多重线性回归。
- en: Using the strategy of the line of best fits helps us to understand the relationship
    between the dependent and independent variable; which should be of linear nature.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最佳拟合线的策略有助于我们理解因变量和自变量之间的关系；这种关系应为线性关系。
- en: The Formula for Linear Regression
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归的公式
- en: 'If you remember high school Mathematics, you will remember the formula: ***y
    = mx + b*** and represents the slope-intercept of a straight line. ‘y’ and ‘x’
    represent variables, ‘m’ describes the slope of the line and ‘b’ describe the
    y-intercept, where the line crosses the y-axis.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得高中数学，你会记得公式：***y = mx + b***，它表示直线的斜率截距。‘y’和‘x’表示变量，‘m’描述直线的斜率，‘b’描述 y
    轴截距，即直线穿过 y 轴的位置。
- en: For Linear Regression, ‘y’ represents the dependent variable, ‘x’ represents
    the independent variable, ????0 represents the y-intercept and ????1 represents
    the slope, which describes the relationship between the independent variable and
    the dependent variable
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归，‘y’表示因变量，‘x’表示自变量，????0表示 y 轴截距，????1表示斜率，描述了自变量与因变量之间的关系。
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/e59fc95300b68f0d53ebd08222aade1d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![线性与逻辑回归的简明解释](../Images/e59fc95300b68f0d53ebd08222aade1d.png)'
- en: 'Source: [TowardsDataScience](https://towardsdatascience.com/simple-linear-regression-in-python-numpy-only-130a988c0212)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[TowardsDataScience](https://towardsdatascience.com/simple-linear-regression-in-python-numpy-only-130a988c0212)
- en: Logistic Regression
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic Regression is also a very popular Machine Learning algorithm that branches
    off Supervised Learning. Logistic Regression can be used for both Regression and
    Classification tasks, however, it is mainly used for Classification. If you would
    like to know more about Logistic Regression used for Classification tasks, click
    on this link.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归也是一种非常流行的机器学习算法，属于监督学习的分支。逻辑回归可用于回归和分类任务，但主要用于分类。如果你想了解更多关于用于分类任务的逻辑回归，请点击此链接。
- en: An example of Logistic Regression predicting whether it will rain today or not,
    by using 0 or 1, yes or no, or true and false.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的一个例子是预测今天是否会下雨，使用 0 或 1，是或否，或真和假。
- en: The use of **Logistic Regression** is to predict the categorical dependent variable
    with the assistance and knowledge of independent variables. The overall aim of
    Logistic Regression is to classify outputs, which can only be between 0 and 1.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**的用途是通过自变量的辅助和知识来预测分类因变量。逻辑回归的总体目标是对输出进行分类，输出只能在 0 和 1 之间。'
- en: In Logistic Regression the weighted sum of inputs is passed through an activation
    function called Sigmoid Function which maps values between 0 and 1.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归中，加权输入的总和会通过一个称为 Sigmoid 函数的激活函数，该函数将值映射到 0 和 1 之间。
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/b258e6d701fe7960fa34dde9514b8b22.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![线性与逻辑回归的简明解释](../Images/b258e6d701fe7960fa34dde9514b8b22.png)'
- en: 'Source: [Wikipedia ](https://en.wikipedia.org/wiki/Sigmoid_function)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[维基百科](https://en.wikipedia.org/wiki/Sigmoid_function)
- en: The Formula for Sigmoid Function
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sigmoid 函数的公式
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/80ed0a68d4665eff4cd32d814bdde821.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![线性与逻辑回归的简明解释](../Images/80ed0a68d4665eff4cd32d814bdde821.png)'
- en: Logistic Regression is based on **Maximum Likelihood Estimation**, which is
    a method of estimating the parameters of an assumed probability distribution,
    given some observed data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归基于**最大似然估计**，这是一种在给定一些观测数据的情况下估计假设概率分布参数的方法。
- en: Cost Function
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本函数
- en: A **Cost Function** is a mathematical formula used to calculate the error, it
    is a difference between our predicted value and the actual value. It simply measures
    how wrong the model is in terms of its ability to estimate the relationship between
    x and y.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本函数**是一个用于计算误差的数学公式，它是预测值与实际值之间的差异。它简单地衡量了模型在估计 x 和 y 之间关系的能力上的错误程度。'
- en: To find out more about Cost Functions, click on this link.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于成本函数的信息，请点击此链接。
- en: Linear Regression
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归
- en: The Cost Function of a Linear Regression is root mean squared error or also
    known as mean squared error (MSE).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的成本函数是均方根误差，也称为均方误差（MSE）。
- en: MSE measures the average squared difference between an observation’s actual
    and predicted values. The cost will be outputted as a single number which is associated
    with our current set of weights. The reason we use Cost Function is to improve
    the accuracy of the model; minimising MSE does this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: MSE 衡量观察值的实际值和预测值之间的平均平方差。成本将以一个单一的数字输出，这与我们当前的权重集相关。我们使用成本函数的原因是为了提高模型的准确性；最小化
    MSE 就能实现这一点。
- en: 'The formula for MSE:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: MSE 的公式：
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/dc644e002638624a6007becd4e32f56a.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归与逻辑回归：简明解释](../Images/dc644e002638624a6007becd4e32f56a.png)'
- en: Logistic Regression
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: The Cost Function of a Logistic Regression cannot use MSE because our prediction
    function is non-linear (due to sigmoid transform). Therefore we use a cost function
    called Cross-Entropy, also known as Log Loss.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的成本函数不能使用 MSE，因为我们的预测函数是非线性的（由于 sigmoid 变换）。因此，我们使用一种称为交叉熵的成本函数，也称为对数损失。
- en: Cross-entropy measures the difference between two probability distributions
    for a given random variable or set of events.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵衡量了给定随机变量或事件集的两个概率分布之间的差异。
- en: 'The formula for Cross Entropy:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵的公式：
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/f9276f5b5e3a1f671416c6cb4760d326.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归与逻辑回归：简明解释](../Images/f9276f5b5e3a1f671416c6cb4760d326.png)'
- en: Linear vs Logistic Comparison
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归与逻辑回归比较
- en: '| **Linear Regression** | **Logistic Regression** |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **线性回归** | **逻辑回归** |'
- en: '| Used to predict the continuous dependent variable using a given set of independent
    variables. | Used to predict the categorical dependent variable using a given
    set of independent variables. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 用于预测连续因变量，使用一组给定的自变量。 | 用于预测分类因变量，使用一组给定的自变量。 |'
- en: '| The outputs produced must be a continuous value, such as price and age. |
    The outputs produced must be Categorical values such as 0 or 1, Yes or No. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 产生的输出必须是连续值，如价格和年龄。 | 产生的输出必须是分类值，如0或1，是或否。 |'
- en: '| The relationship between the dependent variable and independent variable
    must be linear. | The relationship DOES NOT need to be linear between the dependent
    and independent variables. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 因变量和自变量之间的关系必须是线性的。 | 因变量和自变量之间的关系不需要是线性的。 |'
- en: '| Used for solving Regression problems. | Used for solving Classification problems.
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 用于解决回归问题。 | 用于解决分类问题。 |'
- en: '| We are finding and using the line of best fit to help us easily predict outputs.
    | We are using the S-curve (Sigmoid) to help us classify predicted outputs. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 我们找到并使用最佳拟合线来帮助我们轻松预测输出。 | 我们使用S曲线（Sigmoid）来帮助我们对预测输出进行分类。 |'
- en: '| Least square estimation method is used for the estimation of accuracy. |
    Maximum likelihood estimation method is used for the estimation of accuracy. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 最小二乘估计方法用于估计准确性。 | 最大似然估计方法用于估计准确性。 |'
- en: '| There is a possibility of collinearity between the independent variables.
    | There should not be any collinearity between the independent variable. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 自变量之间可能存在多重共线性。 | 自变量之间不应存在多重共线性。 |'
- en: '![Linear vs Logistic Regression: A Succinct Explanation](../Images/81e1998bc8155b36a9dcb92cd029857d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![线性回归与逻辑回归：简明解释](../Images/81e1998bc8155b36a9dcb92cd029857d.png)'
- en: 'Source: [javatpoint](https://www.javatpoint.com/linear-regression-vs-logistic-regression-in-machine-learning)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [javatpoint](https://www.javatpoint.com/linear-regression-vs-logistic-regression-in-machine-learning)'
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一名数据科学家和自由技术写作人。她特别关注提供数据科学职业建议或教程，并且对数据科学的理论知识充满兴趣。她还希望探索人工智能如何有助于人类寿命的延续。她是一个热衷学习者，寻求拓宽技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 22:n12, 3月23日: 最佳数据科学书籍…](https://www.kdnuggets.com/2022/n12.html)'
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归比较](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
- en: '[An Overview of Logistic Regression](https://www.kdnuggets.com/2022/02/overview-logistic-regression.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逻辑回归概述](https://www.kdnuggets.com/2022/02/overview-logistic-regression.html)'
- en: '[Logistic Regression for Classification](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分类的逻辑回归](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)'
- en: '[How Does Logistic Regression Work?](https://www.kdnuggets.com/2022/07/logistic-regression-work.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[逻辑回归是如何工作的？](https://www.kdnuggets.com/2022/07/logistic-regression-work.html)'
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类指标概述：逻辑回归与…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
