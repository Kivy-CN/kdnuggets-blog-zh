- en: 'Hands-On with Supervised Learning: Linear Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/handson-with-supervised-learning-linear-regression](https://www.kdnuggets.com/handson-with-supervised-learning-linear-regression)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Hands-On with Supervised Learning: Linear Regression](../Images/533f1a539c9dab6c2a4740198f34cf39.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Basic Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear regression is the fundamental supervised machine learning algorithm
    for predicting the continuous target variables based on the input features. As
    the name suggests it assumes that the relationship between the dependant and independent
    variable is linear. So if we try to plot the dependent variable Y against the 
    independent variable X, we will obtain a straight line. The equation of this line
    can be represented by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/5fafd0dd11eff7815530e8bc855d776c.png "Y=b_{0}+b_{1}X")'
  prefs: []
  type: TYPE_IMG
- en: Where,
  prefs: []
  type: TYPE_NORMAL
- en: '**Y**   Predicted output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**X** =  Input feature or feature matrix in multiple linear regression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**b0** = Intercept (where the line crosses the Y-axis).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**b1** =  Slope or coefficient that determines the line''s steepness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The central idea in linear regression revolves around finding the best-fit line
    for our data points so that the error between the actual and predicted values
    is minimal. It does so by estimating the values of b0 and b1\. We then utilize
    this line for making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation Using Scikit-Learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now understand the theory behind linear regression but to further solidify
    our understanding, let's build a simple linear regression model using Scikit-learn,
    a popular machine learning library in Python. Please follow along for a better
    understanding.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Import Necessary Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, you will need to import the required libraries.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Analyzing the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can find the dataset  [here](https://www.kaggle.com/datasets/andonians/random-linear-regression).
    It contains separate CSV files for training and testing. Let’s display our dataset
    and analyze it before proceeding forward.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Hands-On with Supervised Learning: Linear Regression](../Images/9f7f3acbd879c61e1734252b0b514207.png)'
  prefs: []
  type: TYPE_IMG
- en: train.head()
  prefs: []
  type: TYPE_NORMAL
- en: The dataset contains 2 variables and we want to predict y based on the value
    x.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The above output shows that we have a missing value in the training dataset
    that can be removed by the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Also, check if your dataset contains any duplicates and remove them before feeding
    it into your model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Preprocessing the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, prepare the training and testing data and target by the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can see that we have a one-dimensional array. While you could technically
    use one-dimensional arrays with some machine learning models, it's not the most
    common practice, and it may lead to unexpected behavior. So, we will reshape the
    above to (699,1) and (300,1) to explicitly specify that we have one label per
    data point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When the features are on different scales, some may dominate the model's learning
    process, leading to incorrect or suboptimal results. For this purpose, we perform
    the standardization so that our features have a mean of 0 and a standard deviation
    of 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Standardization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We are now done with the essential data preprocessing steps, and our data is
    ready for training purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Visualizing the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It''s important to first visualize the relationship between our target variable
    and feature. You can do this by making a scatter plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Hands-On with Supervised Learning: Linear Regression](../Images/65c0f8fe5cef6b40862a22bc53a20a6a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Create and Train the Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now create an instance of the Linear Regression model using Scikit
    Learn and try to fit it into our training dataset.  It finds the coefficients
    (slopes) of the linear equation that best fits your data. This line is then used
    to make the predictions. Code for this step is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 6\. Visualize the Regression Line
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can plot our regression line using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Hands-On with Supervised Learning: Linear Regression](../Images/137a116933abb033820ccc5f5e66522c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That's a wrap! You've now successfully implemented a fundamental Linear Regression
    model using Scikit-learn. The skills you've acquired here can be extended to tackle
    complex datasets with more features. It's a challenge worth exploring in your
    free time, opening doors to the exciting world of data-driven problem-solving
    and innovation.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** is an aspiring
    software developer with a keen interest in data science and applications of AI
    in medicine. Kanwal was selected as the Google Generation Scholar 2022 for the
    APAC region. Kanwal loves to share technical knowledge by writing articles on
    trending topics, and is passionate about improving the representation of women
    in tech industry.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 22: Primary Supervised Learning Algorithms…](https://www.kdnuggets.com/2022/n25.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
