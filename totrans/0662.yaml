- en: 'Building a Computer Vision Model: Approaches and datasets'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Javier Couto](https://twitter.com/JCoutoNLP), Tryolabs**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Computer vision is one of the hottest subfields of machine learning, given
    its [wide variety of applications](https://tryolabs.com/resources/introductory-guide-computer-vision/#industry-applications)
    and tremendous potential. Its goal: to replicate the powerful capacities of human
    vision. But how is this achieved with algorithms?'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a loot at the most important datasets and approaches.
  prefs: []
  type: TYPE_NORMAL
- en: '**Existing datasets**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Computer vision algorithms are no magic. They need data to work, and they can
    only be as good as the data you feed in. These are different sources to collect
    the right data, depending on the task:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most voluminous and well known dataset is **[ImageNet](http://www.image-net.org/)**,
    a readily-available dataset of 14 million images manually annotated using **[WordNet](https://wordnet.princeton.edu/)** concepts.
    Within the global dataset, 1 million images contain bounding box annotations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/47bdf49b1e7bdf044830642dc62105e9.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ImageNet images with bounding boxes. [Image source](http://www.image-net.org/bbox_fig/kit_fox.JPG)**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1de2789c0f6f512afa807174edb804a3.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ImageNet images with object attributes annotations. [Image source](http://www.image-net.org/attribute_fig/pullfigure.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: Another well-known one is the **[Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home)**,
    dataset, loaded with 328,000 images including 91 object types that would be easily
    recognizable by a 4 year old, with a total of 2.5 million labeled instances.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e60ccd5b9feab0cca16b8b7d9ebd07f8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Examples of annotated images from the COCO dataset. [Image source](https://arxiv.org/abs/1405.0312)**'
  prefs: []
  type: TYPE_NORMAL
- en: While there isn’t a plethora of available datasets, there are several suitable
    for different tasks, such as the **[CelebFaces Attributes Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)** (CelebA,
    a face attributes dataset with more than 200K celebrity images); the **[Indoor
    Scene Recognition](http://web.mit.edu/torralba/www/indoor.html)** dataset (15,620
    images of indoor scenes); and the **[Plant Image Analysis](https://www.plant-image-analysis.org/dataset)** dataset
    (1 million images of plants from 11 different species).
  prefs: []
  type: TYPE_NORMAL
- en: '**A general strategy**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**[Deep learning methods and techniques](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)** have
    profoundly transformed computer vision, along with other areas of artificial intelligence,
    to such an extent that for many tasks its use is considered standard. In particular, **[Convolutional
    Neural Networks](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)** (CNN)
    have achieved beyond state-of-the-art results utilizing traditional computer vision
    techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These four steps outline a general approach to building a computer vision model
    using CNNs:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a dataset comprised of annotated images or use an existing one. Annotations
    can be the image category (for a classification problem); pairs of bounding boxes
    and classes (for an object detection problem); or a pixel-wise segmentation of
    each object of interest present in an image (for an instance segmentation problem).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract, from each image, features pertinent to the task at hand. This is a
    key point in modeling the problem. For example, the features used to recognize
    faces, features based on facial criteria, are obviously not the same as those
    used to recognize tourist attractions or human organs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a deep learning model based on the features isolated. Training means feeding
    the machine learning model many images and it will learn, based on those features,
    how to solve the task at hand.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the model using images that weren’t used in the training phase. By
    doing so, the accuracy of the training model can be tested.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This strategy is very basic but it serves the purpose well. Such an approach,
    known as **[supervised machine learning](https://www.kdnuggets.com/2017/11/3-different-types-machine-learning.html)**,
    requires a dataset that encompasses the phenomenon the model has to learn.
  prefs: []
  type: TYPE_NORMAL
- en: '**Training an object detection model**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Viola and Jones approach**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are many ways to address object detection challenges. For years, the prevalent
    approach was one proposed by Paul Viola and Michael Jones in the paper, **[Robust
    Real-time Object Detection](http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-2001-1.pdf)**.
  prefs: []
  type: TYPE_NORMAL
- en: Although it can be trained to detect a diverse range of object classes, the
    approach was first motivated by the objective of face detection. It is so fast
    and straightforward that it was the algorithm implemented in point-and-shoot cameras,
    which allows for real-time face detection with little processing power.
  prefs: []
  type: TYPE_NORMAL
- en: The central feature of the approach is to train with a potentially large set
    of binary classifiers based on **[Haar features](https://en.wikipedia.org/wiki/Haar-like_feature)**.
    These features represent edges and lines, and are extremely simple to compute
    when scanning an image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bc6c26478e97521e0942d50b5f5a4dce.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Haar features. [Image source](https://docs.opencv.org/3.4.3/haar_features.jpg)**'
  prefs: []
  type: TYPE_NORMAL
- en: Although quite basic, in the specific case of faces these features allow for
    the capturing of important elements such as the nose, mouth, or the distance between
    the eyebrows. It is a supervised method that requires many positive and negative
    examples of the type of object to be discerned.
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting the face of the Mona Lisa**'
  prefs: []
  type: TYPE_NORMAL
- en: '**CNN-based approaches**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning has been a real game changer in machine learning, especially in
    computer vision, where deep-learning-based approaches are now cutting edge for
    many of the usual tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Among the different deep learning approaches proposed for accomplishing object
    detection, **[R-CNN](https://arxiv.org/abs/1311.2524)** (Regions with CNN features)
    is particularly simple to understand. The authors of this work propose a three
    stage process:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract possible objects using a region proposal method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify features in each region using a CNN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Classify each region utilizing **[SVMs](https://en.wikipedia.org/wiki/Support_vector_machine)**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/2be7c020983b89d8c01e3077de68f762.png)'
  prefs: []
  type: TYPE_IMG
- en: '**R-CNN Architecture. [Image source](https://arxiv.org/abs/1311.2524)**'
  prefs: []
  type: TYPE_NORMAL
- en: The region proposal method opted for in the original work was **[Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)**,
    although the R-CNN algorithm is agnostic regarding the particular region proposal
    method adopted. Step 3 is very important as it decreases the number of object
    candidates, which makes the method less computationally expensive.
  prefs: []
  type: TYPE_NORMAL
- en: The features extracted here are less intuitive than the Haar features previously
    mentioned. To summarize, a CNN is used to extract a 4096-dimensional feature vector
    from each region proposal. Given the nature of the CNN, it is necessary that the
    input always have the same dimension. This is usually one of the CNN’s weak points
    and the various approaches address this in different ways. With respect to the
    R-CNN approach, the trained CNN architecture requires inputs of a fixed area of
    227 × 227 pixels. Since the proposed regions have sizes that differ from this,
    the authors’ approach simply warps the images so that they fit the required dimension.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/528b58be52eb7121ca6d994c8c7cbcd8.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Examples of warped images matching the input dimension required by the CNN.
    [Image source](https://arxiv.org/abs/1311.2524)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'While it achieved great results, the training encountered several obstacles,
    and the approach was eventually outperformed by others. Some of those are reviewed
    in depth in the article, **[Object Detection with Deep Learning: The Definitive
    Guide](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)**.'
  prefs: []
  type: TYPE_NORMAL
- en: This article is an extract of the *Introductory Guide to Computer Vision* by
    Tryolabs, originally published [here](https://tryolabs.com/resources/introductory-guide-computer-vision/).
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio**: [Javier Couto](https://twitter.com/JCoutoNLP) is a freelance machine
    learning consultant and data scientist at Tryolabs, specialized in applying machine
    learning to solve business problems.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Think Like an Amateur, Do As an Expert: Lessons from a Career in Computer
    Vision](https://www.kdnuggets.com/2019/05/kanade-lessons-career-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Predict Age and Gender Using Convolutional Neural Network and OpenCV](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Pedestrian Detection in Aerial Images Using RetinaNet](https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
