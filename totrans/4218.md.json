["```py\n**from** flaml **import** AutoML\nautoml = AutoML()\nautoml.fit(X_train=X_train, y_train=y_train, time_budget=60, estimator_list=['lgbm'])\n\n''' retrieve best model and best configuration found'''\nprint('Best ML model:', automl.model)\nprint('Best hyperparameter config:', automl.best_config)\n```", "```py\n'''create an XGBoost learner class with a customized search space'''\n**from** flaml.model **import** XGBoostSklearnEstimator\n**from** flaml **import** tune\n\n**class** **MyXGB**(XGBoostSklearnEstimator):\n​​    '''XGBoostSklearnEstimator with a customized search space'''\n    @classmethod\n    **def** **search_space**(cls, data_size, **params):\n        upper = min(2**15, int(data_size))\n        **return** {\n            'n_estimators': {\n                'domain': tune.lograndint(lower=4, upper=upper),\n                'low_cost_init_value': 4,\n            },\n            'max_leaves': {\n                'domain': tune.lograndint(lower=4, upper=upper),\n                'low_cost_init_value': 4,\n            },\n        }\n\n'''Use CFO in FLAML to tune XGBoost'''\n**from** flaml **import** AutoML\nautoml = AutoML()\nautoml.add_learner(learner_name='my_xgboost', learner_class=MyXGB)\nautoml.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='cfo')\n```", "```py\n'''Use BlendSearch for hyperparameter search, and Ray Tune for parallelizing concurrent trials (when n_concurrent_trials > 1) in FLAML to tune XGBoost'''\n**from** flaml **import** AutoML\nautoml = AutoML()\nautoml.add_learner(learner_name='my_xgboost', learner_class=MyXGB)\nautoml.fit(X_train=X_train, y_train=y_train, time_budget=15, estimator_list=['my_xgboost'], hpo_method='bs', n_concurrent_trials=8)\n```", "```py\n**from** ray **import** tune \n**from** flaml **import** CFO, BlendSearch\n**import** time\n\n**def** **training_func**(config):\n    '''evaluate a hyperparameter configuration'''\n    # we use a toy example with 2 hyperparameters\n    metric = (round(config['x'])-85000)**2 - config['x']/config['y']\n\n    # usually the evaluation takes a non-neglible cost\n    # and the cost could be related to certain hyperparameters\n    # in this example, we assume it's proportional to x\n    time.sleep(config['x']/100000)\n    # use tune.report to report the metric to optimize    \n    tune.report(metric=metric) \n\n# provide the search space\nsearch_space = {\n        'x': tune.lograndint(lower=1, upper=100000),\n        'y': tune.randint(lower=1, upper=100000)\n    }\n\n# provide the low cost partial config\nlow_cost_partial_config={'x':1}\n\n# set up BlendSearch\nblendsearch = BlendSearch(\n    metric=\"metric\", mode=\"min\",\n    space=search_space,\n    low_cost_partial_config=low_cost_partial_config)\n\nblendsearch.set_search_properties(config={\"time_budget_s\": 60})\n\nanalysis = tune.run(\n    training_func,    # the function to evaluate a config\n    config=search_space,\n    metric='metric',    # the name of the metric used for optimization\n    mode='min',         # the optimization mode, 'min' or 'max'\n    num_samples=-1,    # the maximal number of configs to try, -1 means infinite\n    time_budget_s=60,   # the time budget in seconds\n    local_dir='logs/',  # the local directory to store logs\n    search_alg=blendsearch  # or cfo\n    )\n\nprint(analysis.best_trial.last_result)  # the best trial's result\nprint(analysis.best_config)  # the best config\n```"]