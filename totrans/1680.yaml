- en: A Beginner’s Guide to Data Engineering – Part II
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据工程入门指南 – 第二部分
- en: 原文：[https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2](https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2](https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/03/beginners-guide-data-engineering-part-2.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/03/beginners-guide-data-engineering-part-2.html?page=2#comments)'
- en: The Anatomy of an Airflow Pipeline
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Airflow 流水线的结构
- en: '![](../Images/b3883f7be24a82be7a7c39fb4e3216e7.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3883f7be24a82be7a7c39fb4e3216e7.png)'
- en: Now that we have learned about the concept of fact tables, dimension tables,
    date partitions, and what it means to do data backfilling, let’s crystalize these
    concepts and put them in an actual Airflow ETL job.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了事实表、维度表、日期分区的概念以及数据回填的含义，让我们把这些概念具体化，并将它们应用到实际的 Airflow ETL 任务中。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT 工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Defining the Directed Acyclic Graph (DAG)**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义有向无环图 (DAG)**'
- en: As we mentioned in the [earlier post](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7),
    any ETL job, at its core, is built on top of three building blocks: **E**xtract, **T**ransform,
    and **L**oad. As simple as it might sound conceptually, ETL jobs in real life
    are often complex, consisting of many combinations of E, T, and L tasks. As a
    result, it is often useful to visualize complex data flows using a graph. Visually,
    a *node* in a graph represents a task, and an *arrow* represents the dependency
    of one task on another. Given that data only needs to be computed once on a given
    task and the computation then carries forward, the graph is *directed *and *acyclic*.This
    is why Airflow jobs are commonly referred to as “DAGs” (**D**irected **A**cyclic **G**raphs).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [早期的文章](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)中提到的，任何
    ETL 任务，其核心都是建立在三个基本构件之上：**E**xtract、**T**ransform 和 **L**oad。尽管在概念上听起来很简单，但实际中的
    ETL 任务通常很复杂，由许多 E、T 和 L 任务的组合构成。因此，使用图形来可视化复杂的数据流往往是有用的。在视觉上，图中的一个 *节点* 代表一个任务，而
    *箭头* 代表一个任务对另一个任务的依赖。鉴于数据只需在给定任务上计算一次，计算结果会向前传递，因此图是 *有向* 和 *无环* 的。这就是为什么 Airflow
    任务通常被称为“DAG”（**D**irected **A**cyclic **G**raphs）的原因。
- en: '![](../Images/9c6359d1c3dedca683467b64d23bcb98.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c6359d1c3dedca683467b64d23bcb98.png)'
- en: '[Source](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166):
    A screenshot of Airbnb’s Experimentation Reporting Framework DAG'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166)：Airbnb
    实验报告框架 DAG 的截图'
- en: One of the clever designs about Airflow UI is that it allows any users to visualize
    the DAG in a [graph view](https://airflow.apache.org/ui.html#graph-view), using
    code as configuration. The author of a data pipeline must define the structure
    of dependencies among tasks in order to visualize them. This specification is
    often written in a file called the *DAG definition file, *which lays out the anatomy
    of an Airflow job.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow UI 的一个聪明设计是它允许任何用户通过 [图形视图](https://airflow.apache.org/ui.html#graph-view)
    来可视化 DAG，使用代码作为配置。数据管道的作者必须定义任务之间依赖关系的结构，以便进行可视化。这种规范通常写在一个叫做 *DAG 定义文件* 的文件中，描述了
    Airflow 任务的结构。
- en: '**Operators: Sensors, Operators, and Transfers**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作符：传感器、操作符和传输**'
- en: 'While DAGs describe *how* to run a data pipeline, operators describe *what* to
    do in a data pipeline. Typically, there are three broad categories of operators:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 DAG 描述了 *如何* 运行数据管道，操作符则描述了 *在* 数据管道中要做 *什么*。通常，操作符有三大类：
- en: '**Sensors: **waits for a certain time, external file, or upstream data source'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sensors:** 等待特定时间、外部文件或上游数据源'
- en: '**Operators: **triggers a certain action (e.g. run a bash command, execute
    a python function, or execute a Hive query, etc)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Operators:** 触发某个动作（例如，运行bash命令、执行python函数或执行Hive查询等）'
- en: '**Transfers: **moves data from one location to another'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transfers:** 将数据从一个位置移动到另一个位置'
- en: Shrewd readers can probably see how each of these operators correspond to the
    **E**xtract,
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 敏锐的读者可能会看到这些操作符如何对应于**E**xtract，
- en: '**T**ransform, and **L**oad steps that we discussed earlier.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**T**ransform和**L**oad步骤，我们之前讨论过的。'
- en: '**Sensors** unblock the data flow after a certain time has passed or when data
    from an upstream data source becomes available. At Airbnb, given that most of
    our ETL jobs involve Hive queries, we often used `[NamedHivePartitionSensors](https://github.com/apache/incubator-airflow/blob/master/airflow/sensors/named_hive_partition_sensor.py)` to
    check whether the most recent partition of a Hive table is available for downstream
    processing.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sensors** 在经过一定时间后或当来自上游数据源的数据可用时，解除数据流的阻塞。在Airbnb，由于我们大多数ETL作业涉及Hive查询，我们经常使用`[NamedHivePartitionSensors](https://github.com/apache/incubator-airflow/blob/master/airflow/sensors/named_hive_partition_sensor.py)`检查Hive表的最新分区是否可用于下游处理。'
- en: '**Operators** trigger data transformations, which corresponds to the **T**ransform
    step. Because Airflow is open-source, contributors can [extend](https://github.com/apache/incubator-airflow/tree/master/airflow/operators) `BaseOperator`class
    to create custom operators as they see fit. At Airbnb, the most common operator
    we used is `[HiveOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/hive_operator.py#L22)` (to
    execute hive queries), but we also use `[PythonOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/python_operator.py)` (e.g.
    to run a Python script) and `[BashOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/bash_operator.py)` (e.g.
    to run a bash script, or even a fancy Spark job) fairly often. The possibilities
    are endless here!'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Operators** 触发数据转换，这对应于**T**ransform步骤。由于Airflow是开源的，贡献者可以[扩展](https://github.com/apache/incubator-airflow/tree/master/airflow/operators)
    `BaseOperator`类以创建自定义操作符。在Airbnb，我们最常用的操作符是`[HiveOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/hive_operator.py#L22)`（用于执行Hive查询），但我们也经常使用`[PythonOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/python_operator.py)`（例如，运行Python脚本）和`[BashOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/bash_operator.py)`（例如，运行bash脚本或甚至一个复杂的Spark作业）。这里的可能性是无穷的！'
- en: Finally, we also have special operators that **Transfers **data from one place
    to another, which often maps to the **L**oad step in ETL. At Airbnb, we use `[MySqlToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/mysql_to_hive.py)`
    or `[S3ToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/s3_to_hive_operator.py)`
    pretty often, but this largely depends on one’s data infrastructure and where
    the data warehouse lives.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还有特殊的操作符，**Transfers** 数据从一个地方到另一个地方，这通常映射到ETL中的**L**oad步骤。在Airbnb，我们经常使用`[MySqlToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/mysql_to_hive.py)`或`[S3ToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/s3_to_hive_operator.py)`，但这在很大程度上取决于数据基础设施和数据仓库的位置。
- en: '**A Simple Example**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个简单的示例**'
- en: Below is a simple example that demonstrate how to define a DAG definition file,
    instantiate a Airflow DAG, and define the corresponding DAG structure using the
    various operators we described above.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单示例，演示如何定义DAG定义文件、实例化Airflow DAG，并使用我们上述描述的各种操作符来定义相应的DAG结构。
- en: 'When the DAG is rendered, we see the following graph view:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当DAG被渲染时，我们会看到以下图形视图：
- en: '![](../Images/8c6afb760a294b42682b86dae4f3237f.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c6afb760a294b42682b86dae4f3237f.png)'
- en: Graph View of the toy example DAG
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 玩具示例DAG的图形视图
- en: ETL Best Practices To Follow
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ETL最佳实践指南
- en: '![](../Images/2027a30a151a5a2c88b0ff1cdd567049.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2027a30a151a5a2c88b0ff1cdd567049.png)'
- en: '[Image Credit](http://www.omen-azen.com/eat-together-1/): Building your craft
    takes practice, so it’s wise to follow best practices'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](http://www.omen-azen.com/eat-together-1/)：打造你的技艺需要实践，因此遵循最佳实践是明智的。'
- en: 'Like any craft, writing Airflow jobs that are succinct, readable, and scalable
    requires practice. On my first job, ETL to me was just a series of mundane mechanical
    tasks that I had to get done. I did not see it as a craft nor did I know the best
    practices. At Airbnb, I learned a lot about best practices and I started to appreciate
    good ETLs and how beautiful they can be. Below, I list out a non-exhaustive list
    of principles that good ETL pipelines should follow:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何工艺一样，编写简洁、可读和可扩展的 Airflow 作业需要实践。在我第一次工作时，ETL 对我来说只是需要完成的一系列单调机械的任务。我没有将其视为一种工艺，也不知道最佳实践。在
    Airbnb，我学到了很多最佳实践，并开始欣赏良好的 ETL 及其美妙之处。下面，我列出了良好 ETL 管道应该遵循的一些原则：
- en: '**Partition Data Tables: **As we mentioned earlier,data partitioning can be
    especially useful when dealing with large-size tables with a long history. When
    data is partitioned using datestamps, we can leverage dynamic partitions to parallelize
    backfilling.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**划分数据表：**正如我们之前提到的，数据划分在处理历史较长的大型表时特别有用。当使用日期戳进行数据划分时，我们可以利用动态分区来并行化补全数据。'
- en: '**Load Data Incrementally: **This principle makes your ETL more modular and
    manageable, especially when building dimension tables from the fact tables. In
    each run, we only need to append the new transactions to the dimension table from
    previous date partition instead of scanning the entire fact history.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增量加载数据：**这一原则使你的 ETL 更加模块化和可管理，特别是在从事实表构建维度表时。在每次运行中，我们只需要将新交易附加到来自前一个日期分区的维度表，而不是扫描整个事实历史。'
- en: '**Enforce Idempotency: **Many data scientists rely on point-in-time snapshots
    to perform historical analysis. This means the underlying source table should
    not be mutable as time progresses, otherwise we would get a different answer.
    Pipeline should be built so that the same query, when run against the same business
    logic and time range, returns the same result. This property has a fancy name
    called Idempotency.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强制幂等性：**许多数据科学家依赖于时间点快照进行历史分析。这意味着基础源表在时间推移过程中不应该是可变的，否则我们将得到不同的答案。管道应该构建成相同的查询在相同的业务逻辑和时间范围内返回相同的结果。这个特性被称为幂等性。'
- en: '**Parameterize Workflow: **Just like how templates greatly simplified the organization
    of HTML pages, Jinja can be used in conjunction with SQL. As we mentioned earlier,
    one common usage of Jinja template is to incorporate the backfilling logic into
    a typical Hive query. [Stitch Fix](https://www.google.com/search?q=stitchfix+jinja&oq=stitchfix+jinja&aqs=chrome..69i57j69i59.3030j0j1&sourceid=chrome&ie=UTF-8) has
    a very nice post that summarized how they use this technique for their ETL.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数化工作流：**就像模板大大简化了 HTML 页面的组织一样，Jinja 可以与 SQL 配合使用。如前所述，Jinja 模板的一种常见用法是将补全逻辑融入到典型的
    Hive 查询中。[Stitch Fix](https://www.google.com/search?q=stitchfix+jinja&oq=stitchfix+jinja&aqs=chrome..69i57j69i59.3030j0j1&sourceid=chrome&ie=UTF-8)有一篇很好的文章总结了他们如何将这种技术应用于
    ETL。'
- en: '**Add Data Checks Early and Often: **When processing data, it is useful to
    write data into a staging table, check the data quality, and only then exchange
    the staging table with the final production table. At Airbnb, we call this the *stage-check-exchange* paradigm.
    Checks in this 3-step paradigm are important defensive mechanisms — they can be
    simple checks such as counting if the total number of records is greater than
    0 or something as complex as an anomaly detection system that checks for unseen
    categories or outliers.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尽早且频繁地进行数据检查：**在处理数据时，将数据写入一个暂存表中，检查数据质量，然后再将暂存表与最终生产表交换是很有用的。在 Airbnb，我们称之为*stage-check-exchange*范式。在这个三步范式中的检查是重要的防御机制——它们可以是简单的检查，比如记录总数是否大于0，或者是复杂的异常检测系统，检查未见过的类别或异常值。'
- en: A skeleton of stage-check-exchange operation (aka “Unit Test” for data pipelines)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: stage-check-exchange 操作的框架（即数据管道的“单元测试”）
- en: '**Build Useful Alerts & Monitoring System: **Since ETL jobs can often take
    a long time to run, it’s useful to add alerts and monitoring to them so we do
    not have to keep an eye on the progress of the DAG constantly. Different companies
    monitor DAGs in many creative ways — at Airbnb, we regularly use EmailOperators
    to send alert emails for jobs missing SLAs. Other teams have used alerts to flag
    experiment imbalances. Yet another [interesting example](https://www.slideshare.net/cloudera/building-robust-pipelines-with-airflow-wrangle-conference-2017) is
    from Zymergen where they report model performance metrics such as R-squared with
    a SlackOperator.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建有用的警报和监控系统：**由于 ETL 作业经常需要很长时间才能完成，因此添加警报和监控是很有用的，这样我们就不需要不断关注 DAG 的进度。不同的公司以许多创造性的方法监控
    DAG——在 Airbnb，我们定期使用 EmailOperators 发送作业未能达到 SLA 的警报邮件。其他团队使用警报来标记实验的不平衡。还有一个[有趣的例子](https://www.slideshare.net/cloudera/building-robust-pipelines-with-airflow-wrangle-conference-2017)来自
    Zymergen，他们使用 SlackOperator 报告模型性能指标，如 R 平方。'
- en: 'Many of these principles are inspired by a combination of conversations with
    seasoned data engineers, my own experience building Airflow DAGs, and readings
    from Gerard Toonstra’s [ETL Best Practices with Airflow](https://gtoonstra.github.io/etl-with-airflow/principles.html).
    For the curious readers, I highly recommend this following talk from Maxime:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则的灵感来源于与经验丰富的数据工程师的交流、我自己构建 Airflow DAG 的经历以及 Gerard Toonstra 的[ETL 最佳实践与
    Airflow](https://gtoonstra.github.io/etl-with-airflow/principles.html)的读物。对于感兴趣的读者，我强烈推荐
    Maxime 的以下讲座：
- en: '[Source](https://www.youtube.com/watch?v=dgaoqOZlvEA): Maxime, the original
    author of Airflow, talking about ETL best practices'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://www.youtube.com/watch?v=dgaoqOZlvEA)：Airflow 的原创作者 Maxime 讨论 ETL
    最佳实践'
- en: Recap of Part II
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二部分回顾
- en: In the second post of this series, we discussed star schema and data modeling
    in much more details. We learned the distinction between fact and dimension tables,
    and saw the advantages of using datestamps as partition keys, especially for backfilling.
    Furthermore, we dissected the anatomy of an Airflow job, and crystallized the
    different operators available in Airflow. We also highlighted best practices for
    building ETL, and showed how flexible Airflow jobs can be when used in conjunction
    with Jinja and SlackOperators. The possibilities are endless!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一系列的第二篇文章中，我们详细讨论了星型模式和数据建模。我们了解了事实表和维度表的区别，并看到了使用日期戳作为分区键的优势，特别是在回填时。此外，我们解剖了
    Airflow 作业的结构，并阐明了 Airflow 中各种操作符的不同。我们还强调了构建 ETL 的最佳实践，并展示了 Airflow 作业在与 Jinja
    和 SlackOperators 结合使用时的灵活性。可能性是无穷无尽的！
- en: In the last post of the series, I will discuss a few advanced data engineering
    patterns — specifically, how to go from building pipelines to building frameworks.
    I will again use a few example frameworks that we used at Airbnb as motivating
    examples.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在系列的最后一篇文章中，我将讨论一些高级数据工程模式——特别是如何从构建管道转向构建框架。我将再次使用我们在 Airbnb 使用的一些示例框架作为激励案例。
- en: If you found this post useful, please visit [**Part I**](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)and
    stay tuned for **Part III**.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章有用，请访问[**第一部分**](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)并关注
    **第三部分**。
- en: '*I want to appreciate *[*Jason Goodman*](https://medium.com/@jasonkgoodman)* and
    Michael Musson for providing invaluable feedback to me*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*我想感谢*[*Jason Goodman*](https://medium.com/@jasonkgoodman)* 和 Michael Musson
    给我的宝贵反馈*'
- en: '**Bio: [Robert Chang](https://www.linkedin.com/in/robert-chang-877b1720/)**
    is a data scientist at Airbnb working on Machine Learning, Machine Learning Infrastructure,
    and Host Growth. Prior to Airbnb, he was a data scientist at Twitter and have
    a degree in Statistics from Stanford University and a degree of Operations Research
    from UC Berkeley.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Robert Chang](https://www.linkedin.com/in/robert-chang-877b1720/)** 是
    Airbnb 的数据科学家，专注于机器学习、机器学习基础设施和房东增长。在 Airbnb 之前，他曾是 Twitter 的数据科学家，并拥有斯坦福大学的统计学学位和加州大学伯克利分校的运筹学学位。'
- en: '[Original](https://towardsdatascience.com/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71).
    Reposted with permission.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71)。经授权转载。'
- en: '**Related:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[A Beginner’s Guide to Data Engineering  –  Part I](/2018/01/beginners-guide-data-engineering-1.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据工程初学者指南——第一部分](/2018/01/beginners-guide-data-engineering-1.html)'
- en: '[Advice For New and Junior Data Scientists](/2017/11/chang-advice-new-junior-data-scientists.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手和初级数据科学家的建议](/2017/11/chang-advice-new-junior-data-scientists.html)'
- en: '[How to Build a Data Science Pipeline](/2017/07/build-data-science-pipeline.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何构建数据科学管道](/2017/07/build-data-science-pipeline.html)'
- en: More On This Topic
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关主题
- en: '[A Beginner’s Guide to Data Engineering](https://www.kdnuggets.com/2023/07/beginner-guide-data-engineering.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者数据工程指南](https://www.kdnuggets.com/2023/07/beginner-guide-data-engineering.html)'
- en: '[A Beginner''s Guide to Anomaly Detection Techniques in Data Science](https://www.kdnuggets.com/2023/05/beginner-guide-anomaly-detection-techniques-data-science.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者数据科学中的异常检测技术指南](https://www.kdnuggets.com/2023/05/beginner-guide-anomaly-detection-techniques-data-science.html)'
- en: '[Introduction to Data Science: A Beginner''s Guide](https://www.kdnuggets.com/2023/07/introduction-data-science-beginner-guide.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学简介：初学者指南](https://www.kdnuggets.com/2023/07/introduction-data-science-beginner-guide.html)'
- en: '[Beginner’s Guide to Data Cleaning with Pyjanitor](https://www.kdnuggets.com/beginners-guide-to-data-cleaning-with-pyjanitor)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Pyjanitor 进行数据清洗的初学者指南](https://www.kdnuggets.com/beginners-guide-to-data-cleaning-with-pyjanitor)'
- en: '[A Beginner''s Guide to End to End Machine Learning](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者端到端机器学习指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
- en: '[Essential Machine Learning Algorithms: A Beginner''s Guide](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[必要的机器学习算法：初学者指南](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)'
