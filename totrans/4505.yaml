- en: Generate Realistic Human Face using GAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html](https://www.kdnuggets.com/2020/03/generate-realistic-human-face-using-gan.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![Figure](../Images/c66cd91eb1e8a0a144f7300a8bfddc33.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Credits](https://www.outerplaces.com/science/item/19172-artificial-intelligence-faces-gan)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The coolest idea in deep learning in the last 20 years.” — [Yann LeCun on GANs.](https://www.linkedin.com/in/yann-lecun-0b999/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We heard the news on [**Artistic Style Transfer**](https://techcrunch.com/tag/style-transfer/) and [**face-swapping
    applications **](https://beebom.com/best-face-swap-apps/) (aka [deepfakes](https://techcrunch.com/tag/deepfakes/)), **Natural
    Voice Generation **([Google Duplex](https://www.youtube.com/watch?v=D5VN56jQMWM)), [**Music
    Synthesis**](https://openai.com/blog/musenet/), [**smart reply**](https://www.blog.google/products/gmail/save-time-with-smart-reply-in-gmail/), [**smart
    compose**](https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html)**,
    etc.**
  prefs: []
  type: TYPE_NORMAL
- en: The technology behind these kinds of AI is called a **GAN**, or **“Generative
    Adversarial Network”.** A GAN takes a different approach to learning than other
    types of neural networks. GANs algorithmic architectures that use two neural networks
    called a **Generator** and a **Discriminator**, which “compete” against one another
    to create the desired result. The Generator’s job is to create realistic-looking
    fake images, while the Discriminator’s job is to distinguish between real images
    and fake images. If both are functioning at high levels, the result is images
    that are seemingly identical real-life photos.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Networks have had a huge success since they were introduced
    in 2014 by Ian J. Goodfellow and co-authors in the article [Generative Adversarial
    Nets](https://arxiv.org/abs/1406.2661).
  prefs: []
  type: TYPE_NORMAL
- en: Why were GANs developed in the first place?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It has been noticed most of the mainstream neural nets can be easily fooled
    into misclassifying things by adding only a small amount of noise into the original
    data. Surprisingly, the model after adding noise has higher confidence in the
    wrong prediction than when it predicted correctly. The reason for such an adversary
    is that most machine learning models learn from a limited amount of data, which
    is a huge drawback, as it is prone to overfitting. Also, the mapping between the
    input and the output is almost linear. Although it may seem that the boundaries
    of separation between the various classes are linear, in reality, they are composed
    of linearities and even a small change in a point in the feature space might lead
    to misclassification of data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a0bda5e3a7d448a715b36064627855bc.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Credits](https://github.com/Puzer/stylegan-encoder/issues/1)'
  prefs: []
  type: TYPE_NORMAL
- en: How does GANs work?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GANs learn a probability distribution of a dataset by pitting two neural networks
    against each other.
  prefs: []
  type: TYPE_NORMAL
- en: One neural network, called the **Generator**, generates new data instances,
    while the other, the **Discriminator**, evaluates them for authenticity; i.e.
    the discriminator decides whether each instance of data that it reviews belongs
    to the actual training dataset or not.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, the generator is creating new, synthetic/fake images that it passes
    to the discriminator. It does so in the hopes that they, too, will be deemed authentic,
    even though they are fake. The fake image is generated from a 100-dimensional
    noise (uniform distribution between -1.0 to 1.0) using the inverse of convolution,
    called transposed convolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of the generator is to **generate** passable images: to lie without
    being caught. The goal of the **discriminator** is to identify images coming from
    the generator as fake.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps a GAN takes:'
  prefs: []
  type: TYPE_NORMAL
- en: The generator takes in random numbers and returns an image.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This generated image is fed into the discriminator alongside a stream of images
    taken from the actual, ground-truth dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discriminator takes in both real and fake images and returns probabilities,
    a number between 0 and 1, with 1 representing a prediction of authenticity and
    0 representing fake.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So you have a double feedback loop:'
  prefs: []
  type: TYPE_NORMAL
- en: The discriminator is in a feedback loop with the ground truth of the images,
    which we know.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generator is in a feedback loop with the discriminator.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure](../Images/36942c0052f4f1ea690517fca98283d1.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Credits](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
  prefs: []
  type: TYPE_NORMAL
- en: The math behind the GANs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s dig a little deeper and understand how it works mathematically. Discriminator’s
    job is to perform Binary Classification to detect between Real and Fake so its
    loss function is Binary Cross Entropy. What Generator does is Density Estimation,
    from the noise to real data, and feed it to Discriminator to fool it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The approach followed in the design is to model it as a [**MiniMax game**](https://brilliant.org/wiki/minimax/).
    Now let’s have a look at cost functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a8c31e39ff2c453cd231791c6ccab6ca.png)'
  prefs: []
  type: TYPE_IMG
- en: The first term in `J(D)` represents feeding the actual data to the discriminator,
    and the discriminator would want to maximize the log probability of predicting
    one, indicating that the data is real. The second term represents the samples
    generated by `G`. Here, the discriminator would want to maximize the log probability
    of predicting zero, indicating the data is fake. The generator, on the other hand,
    tries to minimize the log probability of the discriminator being correct. The
    solution to this problem is an equilibrium point of the game, which is a saddle
    point of the discriminator loss.
  prefs: []
  type: TYPE_NORMAL
- en: '**Objective Function**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/2a6524e8ec4c450a0cd45e4e61f4e98f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Credits](https://medium.com/sigmoid/a-brief-introduction-to-gans-and-how-to-code-them-2620ee465c30)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Architecture of GANs**'
  prefs: []
  type: TYPE_NORMAL
- en: '`D()` gives us the probability that the given sample is from training data
    X. For the Generator, we want to minimize `log(1-D(G(z))` i.e. when the value `D(G(z))` is
    high then `D` will assume that `G(z)` is nothing but X and this makes `1-D(G(z))` very
    low and we want to minimize it which this even lower. For the Discriminator, we
    want to maximize `D(X)` and `(1-D(G(z)))`. So the optimal state of D will be `P(x)=0.5`.
    However, we want to train the generator G such that it will produce the results
    for the discriminator D so that D won’t be able to distinguish between z and X.'
  prefs: []
  type: TYPE_NORMAL
- en: Now the question is why this is a minimax function? It is because the Discriminator
    tries to maximize the objective while the Generator tries to minimize it, due
    to this minimizing/maximizing we get the minimax term. They both learn together
    by alternating gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: While the idea of GAN is simple in theory, it is very difficult to build a model
    that works. In GAN, there are two deep networks coupled together making backpropagation
    of gradients twice as challenging.
  prefs: []
  type: TYPE_NORMAL
- en: '[Deep Convolutional GAN (DCGAN)](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0) is
    one of the models that demonstrated how to build a practical GAN that can learn
    by itself how to synthesize new images. DCGAN is very similar to *GAN*s but specifically
    focuses on using deep convolutional networks in place of fully-connected networks
    used in Vanilla *GAN*s.'
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional networks help in finding deep correlation within an image, that
    is they look for spatial correlation. This means DCGAN would be a better option
    for image/video data, whereas *GAN*s can be considered as a general idea on which [DCGAN](https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0) and
    many other architectures *(CGAN, CycleGAN, StarGAN and many others)* have been
    developed.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This dataset is great for training and testing models for face detection, particularly
    for recognizing facial attributes such as finding people with brown hair, are
    smiling, or wearing glasses. Images cover large pose variations, background clutter,
    diverse people, supported by a large number of images and rich annotations.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset can be downloaded from [Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset).
    Our objective is to create a model capable of generating realistic **human** **images
    that do not exist in reality.**
  prefs: []
  type: TYPE_NORMAL
- en: You heard it right!
  prefs: []
  type: TYPE_NORMAL
- en: '**Let us load the dataset and see how the input images look like:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/2b3cc85ace939295de193e1dd161b6cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Input images
  prefs: []
  type: TYPE_NORMAL
- en: '**Next step is to create a Generator:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The generator goes the other way: It is the artist who is trying to fool the
    discriminator. This network consists of 8 convolutional layers. Here first, we
    take our input, called `gen_input` and feed it into our first convolutional layer.
    Each convolutional layer performs a convolution and then performs batch normalization
    and a leaky ReLu as well. Then, we return the tanh activation function.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Next, create a Discriminator:**'
  prefs: []
  type: TYPE_NORMAL
- en: The discriminator network consists of convolutional layers the same as the generator.
    For every layer of the network, we are going to perform a convolution, then we
    are going to perform batch normalization to make the network faster and more accurate
    and finally, we are going to perform a Leaky ReLu.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Define a GAN Model:**'
  prefs: []
  type: TYPE_NORMAL
- en: Next, a GAN model can be defined that combines both the generator model and
    the discriminator model into one larger model. This larger model will be used
    to train the model weights in the generator, using the output and error calculated
    by the discriminator model. The discriminator model is trained separately, and
    as such, the model weights are marked as not trainable in this larger GAN model
    to ensure that only the weights of the generator model are updated. This change
    to the trainability of the discriminator weights only affects when training the
    combined GAN model, not when training the discriminator standalone.
  prefs: []
  type: TYPE_NORMAL
- en: This larger GAN model takes as input a point in the latent space, uses the generator
    model to generate an image, which is fed as input to the discriminator model,
    then output or classified as real or fake.
  prefs: []
  type: TYPE_NORMAL
- en: Since the output of the Discriminator is sigmoid, we use [**binary cross-entropy**](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a) for
    the loss. [**RMSProp**](https://keras.io/optimizers/) as an optimizer generates
    more realistic fake images compared to [**Adam**](https://keras.io/optimizers/) for
    this case. The learning rate is 0.0001\. Weight decay and clip value stabilize
    learning during the latter part of the training. You have to adjust the decay
    if you want to adjust the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: GANs try to replicate a probability distribution. Therefore, we should use loss
    functions that reflect the distance between the distribution of the data generated
    by the GAN and the distribution of the real data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Rather than just having a single loss function, we need to define three: The
    loss of the generator, the loss of the discriminator when using real images and
    the loss of the discriminator when using fake images. The sum of the fake image
    and real image loss is the overall discriminator loss.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Training the GAN model:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Training is the hardest part and since a GAN contains two separately trained
    networks, its training algorithm must address two complications:'
  prefs: []
  type: TYPE_NORMAL
- en: GANs must juggle two different kinds of training (generator and discriminator).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GAN convergence is hard to identify.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the generator improves with training, the discriminator performance gets
    worse because the discriminator can’t easily tell the difference between real
    and fake. If the generator succeeds perfectly, then the discriminator has a 50%
    accuracy. In effect, the discriminator flips a coin to make its prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'This progression poses a problem for convergence of the GAN as a whole: the
    discriminator feedback gets less meaningful over time. If the GAN continues training
    past the point when the discriminator is giving completely random feedback, then
    the generator starts to train on junk feedback, and its quality may collapse.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let us also make the GIF of the output images that have been generated.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Output
  prefs: []
  type: TYPE_NORMAL
- en: You can get the code in my GitHub repo.
  prefs: []
  type: TYPE_NORMAL
- en: '**[nageshsinghc4/Face-generation-GAN](https://github.com/nageshsinghc4/Face-generation-GAN)**'
  prefs: []
  type: TYPE_NORMAL
- en: We just saw how a model can generate almost a human-like face if trained sufficiently.
    Due to computation constraints, I have trained the model for 15000 epochs. You
    can try with more epochs to get even better results.
  prefs: []
  type: TYPE_NORMAL
- en: '**“GANs are Dangerous”**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As time goes on, these algorithms that exist all around us get better and better
    at what they do, meaning these generative models will likely get better at generating
    imitative objects. It is highly likely that another groundbreaking generative
    model is just on the horizon.
  prefs: []
  type: TYPE_NORMAL
- en: This technology can be used for many good things. However, the potential for
    bad is there as well. Recall the 2016 election and many subsequent international
    elections, where false news articles flooded almost all social media platforms.
    Imagine the impact these articles would have had if they had contained accompanying
    “false images” and “false audio”. Propaganda would likely spread far more easily
    in such a world. Essentially, these new generative models, **with enough time
    and data, they can generate very convincing samples from almost *any* distribution.**
  prefs: []
  type: TYPE_NORMAL
- en: You can go to[ thispersondoesnotexist.com](https://thispersondoesnotexist.com/) and
    can feel the power of GAN models, every time you refresh the website you will
    see a different human figure which doesn't even exist and has been generated via
    GAN. It's truly fascinating.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conclusion: The Future of GANs'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unsupervised learning is [the next frontier](https://www.cs.cornell.edu/content/unsupervised-learning-next-frontier-ai) in
    artificial intelligence and we are moving towards it.
  prefs: []
  type: TYPE_NORMAL
- en: GANs and generative models general are very fun and perplexing. They encapsulate
    another step towards a world where we depend more and more on artificial intelligence.
    GANs have a huge number of applications in cases such as ***Generating examples
    for Image Datasets, Generating Realistic Photographs, Image-to-Image Translation,
    Text-to-Image Translation, Semantic-Image-to-Photo Translation, Face Frontal View
    Generation, Generate New Human Poses, Face Aging, Video Prediction, 3D Object
    Generation, etc.***
  prefs: []
  type: TYPE_NORMAL
- en: Well, this concludes this article on GANs where we have discussed this cool
    domain of AI and how it is practically implemented. I hope you guys have enjoyed
    reading it, feel free to share your comments/thoughts/feedback in the comment
    section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Thanks for reading this article!!!**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/generate-realistic-human-face-using-gan-e6136876e67c).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Intro to Adversarial Machine Learning and Generative Adversarial Networks](/2019/10/adversarial-machine-learning-generative-adversarial-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Recreating Fingerprints using Convolutional Autoencoders](/2020/03/recreating-fingerprints-using-convolutional-autoencoders.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Semi-supervised learning with Generative Adversarial Networks](/2020/01/semi-supervised-learning-generative-adversarial-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3 Ways to Generate Hyper-Realistic Faces Using Stable Diffusion](https://www.kdnuggets.com/3-ways-to-generate-hyper-realistic-faces-using-stable-diffusion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4 Ways to Generate Passive Income Using ChatGPT](https://www.kdnuggets.com/2023/03/4-ways-generate-passive-income-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Generate Music From Text Using Google MusicLM](https://www.kdnuggets.com/2023/06/generate-music-text-google-musiclm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Generate Synthetic Tabular Dataset](https://www.kdnuggets.com/2022/03/generate-tabular-synthetic-dataset.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
