["```py\nvirtualenv flower_env python==python3\nsource flower_env/bin/activate\npip install flwr==0.17.0\n\n# I'm running this example on a laptop (no gpu)\n# so I am installing the cpu only version of PyTorch\n# follow the instructions at https://pytorch.org/get-started/locally/\n# if you want the gpu option\n\npip install torch==1.9.1+cpu torchvision==0.10.1+cpu \\\n    -f https://download.pytorch.org/whl/torch_stable.html\n\npip install scikit-learn==0.24.0\n```", "```py\nimport argparse\n\nimport flwr as fl\nimport torch\n\nfrom pt_client import get_data, PTMLPClient\n\ndef get_eval_fn(model):\n\n# This `evaluate` function will be called after every round\ndef evaluate(parameters: fl.common.Weights):\n\nloss, _, accuracy_dict = model.evaluate(parameters)\n\nreturn loss, accuracy_dict\n\nreturn evaluate\nif __name__ == \"__main__\":\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-r\", \"--rounds\", type=int, default=3,\\\n        help=\"number of rounds to train\")\n\nargs = parser.parse_args()\n\ntorch.random.manual_seed(42)\n\nmodel = PTMLPClient(split=\"val\")\n\nstrategy = fl.server.strategy.FedAvg( \\\n        eval_fn=get_eval_fn(model),\\\n        )\n\nfl.server.start_server(\"[::]:8080\", strategy=strategy, \\\n            config={\"num_rounds\": args.rounds})\n```", "```py\nclass PTMLPClient(fl.client.NumPyClient, nn.Module):\n\n    def __init__(self, dim_in=4, dim_h=32, \\\n            num_classes=3, lr=3e-4, split=\"alice\"):\n\n        super(PTMLPClient, self).__init__()\n\n        self.dim_in = dim_in\n        self.dim_h = dim_h\n        self.num_classes = num_classes\n        self.split = split\n\n        self.w_xh = nn.Parameter(torch.tensor(\\\n            torch.randn(self.dim_in, self.dim_h) \\\n            / np.sqrt(self.dim_in * self.dim_h))\\\n            )\n        self.w_hh = nn.Parameter(torch.tensor(\\\n            torch.randn(self.dim_h, self.dim_h) \\\n            / np.sqrt(self.dim_h * self.dim_h))\\\n            )\n        self.w_hy = nn.Parameter(torch.tensor(\\\n            torch.randn(self.dim_h, self.num_classes) \\\n            / np.sqrt(self.dim_h * self.num_classes))\\\n            )\n\n        self.lr = lr\n```", "```py\n def get_parameters(self):\n\n        my_parameters = np.append(\\\n            self.w_xh.reshape(-1).detach().numpy(), \\\n            self.w_hh.reshape(-1).detach().numpy() \\\n            )\n        my_parameters = np.append(\\\n        my_parameters, \\\n            self.w_hy.reshape(-1).detach().numpy() \\\n            )\n\n        return my_parameters\n\n    def set_parameters(self, parameters):\n\n        parameters = np.array(parameters)\n\n        total_params = reduce(lambda a,b: a*b,\\\n            np.array(parameters).shape)\n        expected_params = self.dim_in * self.dim_h \\\n            + self.dim_h**2 \\\n            + self.dim_h * self.num_classes\n\n        assert total_params == expected_params, \\\n            f\"expected {expected_params} params,\" \\\n            f\" got {total_params} params\"\n\n        start = 0\n        stop = self.dim_in * self.dim_h\n        self.w_xh = nn.Parameter(torch.tensor(\\\n                parameters[start:stop])\\\n                .reshape(self.dim_in, self.dim_h).float() \\\n                )\n\n        start = stop\n        stop += self.dim_h**2\n        self.w_hh = nn.Parameter(torch.tensor(\\\n                parameters[start:stop])\\\n                .reshape(self.dim_h, self.dim_h).float() \\\n                )\n\n        start = stop\n        stop += self.dim_h * self.num_classes\n        self.w_hy = nn.Parameter(torch.tensor(\\\n                parameters[start:stop])\\\n                .reshape(self.dim_h, self.num_classes).float()\\\n                )\n\n        self.act = torch.relu\n\n        self.optimizer = torch.optim.Adam(self.parameters())\n        self.loss_fn = nn.CrossEntropyLoss()\n```", "```py\n def forward(self, x):\n        x = self.act(torch.matmul(x, self.w_xh))\n        x = self.act(torch.matmul(x, self.w_hh))\n        x = torch.matmul(x, self.w_hy)\n\n        return x\n\n    def get_loss(self, x, y):\n\n        prediction = self.forward(x)\n        loss = self.loss_fn(prediction, y)\n\n        return loss\n```", "```py\n def fit(self, parameters, config=None, epochs=10):\n\n        self.set_parameters(parameters)\n\n        x, y = get_data(split=self.split)\n        x, y = torch.tensor(x).float(), torch.tensor(y).long()\n\n        self.train()\n        for ii in range(epochs):\n            self.optimizer.zero_grad()\n            loss = self.get_loss(x, y)\n\n            loss.backward()\n            self.optimizer.step()\n\n        loss, _, accuracy_dict = self.evaluate(self.get_parameters())\n\n        return self.get_parameters(), len(y), \\\n                {\"loss\": loss, \"accuracy\": \\\n                accuracy_dict[\"accuracy\"]}\n\n    def evaluate(self, parameters, config=None):\n\n        self.set_parameters(parameters)\n\n        val_x, val_y = get_data(split=\"val\")\n        val_x = torch.tensor(val_x).float()\n        val_y = torch.tensor(val_y).long()\n\n        self.eval()\n\n        prediction = self.forward(val_x)\n\n        loss = self.loss_fn(prediction, val_y).detach().numpy()\n\n        prediction_class = np.argmax(\\\n            prediction.detach().numpy(), axis=-1)\n        accuracy = sklearn.metrics.accuracy_score(\\\n            val_y.numpy(), prediction_class)\n\n        return float(loss), len(val_y), \\\n            {\"accuracy\":float(accuracy)}\n```", "```py\ndef get_data(split=\"all\"):\n\n    x, y = sklearn.datasets.load_iris(return_X_y=True)\n\n    np.random.seed(42); np.random.shuffle(x)\n    np.random.seed(42); np.random.shuffle(y)\n\n    val_split = int(0.2 * x.shape[0])\n    train_split = (x.shape[0] - val_split) // 2\n\n    eval_x, eval_y = x[:val_split], y[:val_split]\n\n    alice_x, alice_y = x[val_split:val_split + train_split], \\\n    y[val_split:val_split + train_split]\n    bob_x, bob_y = x[val_split + train_split:], \\\n    y[val_split + train_split:]\n\n    train_x, train_y = x[val_split:], y[val_split:]\n\n    if split == \"all\":\n        return train_x, train_y\n    elif split == \"alice\":\n        return alice_x, alice_y\n    elif split == \"bob\":\n        return bob_x, bob_y\n    elif split == \"val\":\n        return eval_x, eval_y\n    else:\n        print(\"error: split not recognized.\")\n        return None\n```", "```py\nif __name__ == \"__main__\":\n\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"-s\", \"--split\", type=str, default=\"alice\",\\\n    help=\"The training split to use, options are 'alice', 'bob', or 'all'\")\n\n    args = parser.parse_args()\n\n    torch.random.manual_seed(42)\n\n    fl.client.start_numpy_client(\"localhost:8080\", \\\n        client=PTMLPClient(split=args.split))\n```", "```py\nimport argparse\nimport numpy as np\nimport sklearn\nimport sklearn.datasets\nimport sklearn.metrics\nimport torch\nimport torch.nn as nn\nfrom functools import reduce\nimport flwr as fl\n```", "```py\npython -m pt_server -r 40\n```", "```py\npython -m pt_client -s alice\n```", "```py\npython -m pt_client -s bob\n```"]