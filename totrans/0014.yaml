- en: All About the AI Regulatory Landscape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/all-about-the-ai-regulatory-landscape](https://www.kdnuggets.com/all-about-the-ai-regulatory-landscape)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![All About the AI Regulatory Landscape](../Images/d5a70b3e996280948672c6801052a44a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Canva
  prefs: []
  type: TYPE_NORMAL
- en: AI is advancing at an accelerated pace, and while the possibilities are overwhelming,
    to say the least, so are the risks that come with it, such as bias, data privacy,
    security, etc. The ideal approach is to have ethics and responsible guidelines
    embedded into AI by design. It should be systematically built to filter the risks
    and only pass the technological benefits.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Quoting [Salesforce](https://www.salesforce.com/company/intentional-innovation/ethics-by-design/):'
  prefs: []
  type: TYPE_NORMAL
- en: “Ethics by Design is the intentional process of embedding our ethical and humane
    use guiding principles in the design and development”.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But, it is easier said than done. Even the developers find it challenging to
    decipher the complexity of AI algorithms, especially the emerging capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '"As per [deepchecks](https://deepchecks.com/exploring-the-emergent-abilities-of-large-language-models),
    “*ability in an LLM is considered emergent if it wasn’t explicitly trained for
    or expected during the model’s development but appears as the model scales up
    in size and complexity”.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given that the developers need help understanding the internals of the algorithms
    and the reason behind their behavior and predictions, expecting authorities to
    understand and keep it regulated in a short time frame is an overask.
  prefs: []
  type: TYPE_NORMAL
- en: Further, It is equally challenging for everyone to keep pace with the latest
    developments, leaving aside comprehending it timely to make the amenable guardrails.
  prefs: []
  type: TYPE_NORMAL
- en: The EU AI Act
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: That points us to discuss the European Union (EU) AI Act – a historic move that
    covers a comprehensive set of rules to promote trustworthy AI.
  prefs: []
  type: TYPE_NORMAL
- en: '![All About the AI Regulatory Landscape](../Images/bb9be4457ae5b9f0f572acd736368043.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from Canva
  prefs: []
  type: TYPE_NORMAL
- en: '[The legal framework](https://www.europarl.europa.eu/doceo/document/TA-9-2023-0236_EN.html)
    aims to “ensure a high level of protection of health, safety, fundamental rights,
    democracy and the rule of law and the environment from harmful effects of AI systems
    while supporting innovation and improving the functioning of the internal market.”'
  prefs: []
  type: TYPE_NORMAL
- en: The EU is known for leading data protection by introducing the General Data
    Protection Regulation (GDPR) previously and now for AI regulation with the AI
    Act.
  prefs: []
  type: TYPE_NORMAL
- en: The Timeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the interest of the argument as to why it takes a long time to bring regulations,
    let us take a look at the timeline of the AI Act, which was first proposed by
    the European Commission in Apr '21 and later adopted by the European Council in
    Dec’22\. The trilogue between three legislative bodies – European Commission,
    Council, and Parliament, has concluded with the EU Act in action in Mar’24 and
    is expected to be into force by May 2024.
  prefs: []
  type: TYPE_NORMAL
- en: Concerns Who?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With regards to the organizations that come under its purview, the Act applies
    not only to the developers within the EU but also to the global vendors that make
    their [AI systems available to EU users.](https://cset.georgetown.edu/article/the-eu-ai-act-a-primer/)
  prefs: []
  type: TYPE_NORMAL
- en: Risk-Grading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While all risks are not alike, the Act includes a risk-based approach that categorizes
    applications into four categories –  unacceptable, high, limited, and minimal,
    based on their impact on a person's health and safety or fundamental rights.
  prefs: []
  type: TYPE_NORMAL
- en: The risk-grading implies that the regulations become stricter and require greater
    oversight with the increasing application risk. It bans applications that carry
    unacceptable risks, such as social-scoring and biometric surveillance.
  prefs: []
  type: TYPE_NORMAL
- en: Unacceptable risks and high-risk AI systems will become enforceable six months
    and thirty-six months after the regulation comes into force.
  prefs: []
  type: TYPE_NORMAL
- en: Transparency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start with the fundamentals, it is crucial to define what constitutes an
    AI system. Keeping it too loose makes a broad spectrum of traditional software
    systems come under purview too, impacting innovation, while keeping it too tight
    can let slip-ups happen.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the general-purpose Generative AI applications or the underlying
    models must provide necessary disclosures, such as the training data, to ensure
    compliance with the Act. The increasingly powerful models will require additional
    details such as [model evaluations, assessing and mitigating systemic risks, and
    reporting on incidents.](https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law)
  prefs: []
  type: TYPE_NORMAL
- en: Amid AI-generated content and interactions, it becomes challenging for the end-user
    to understand when they see an AI-generated response. Hence, the user must be
    notified when the outcome is not human-generated or contains artificial images,
    audio, or video.
  prefs: []
  type: TYPE_NORMAL
- en: To Regulate or Not?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Technology like AI, specifically GenAI, transcends boundaries and can potentially
    transform how businesses run today. The timing of the AI Act is appropriate and
    aligns well with the onset of the Generative AI era, which tends to exacerbate
    the risks.
  prefs: []
  type: TYPE_NORMAL
- en: With the collective brain power and intelligence, nailing AI safety should be
    on every organization’s agenda. While other nations are contemplating whether
    to introduce new regulations concerning AI risks or to amend the existing ones
    to align them to handle new emerging challenges from advanced AI systems, the
    AI Act serves as the golden standard for governing AI. It sets the trail for other
    nations to follow and collaborate in putting AI to the proper use.
  prefs: []
  type: TYPE_NORMAL
- en: The regulatory landscape is challenged to lead the tech race among countries
    and is often viewed as an impediment to gaining a dominant global position.
  prefs: []
  type: TYPE_NORMAL
- en: However, if there ought to be a race, it would be great to witness one where
    we are competing to make AI safer for everyone and resorting to golden standards
    of ethics to launch the most trustworthy AI in the world.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://vidhi-chugh.medium.com/)**[Vidhi Chugh](https://vidhi-chugh.medium.com/)****
    is an AI strategist and a digital transformation leader working at the intersection
    of product, sciences, and engineering to build scalable machine learning systems.
    She is an award-winning innovation leader, an author, and an international speaker.
    She is on a mission to democratize machine learning and break the jargon for everyone
    to be a part of this transformation.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Masking: The Core of Ensuring GDPR and other Regulatory…](https://www.kdnuggets.com/2023/05/data-masking-core-ensuring-gdpr-regulatory-compliance-strategies.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8 Innovative BERT Knowledge Distillation Papers That Have Changed…](https://www.kdnuggets.com/2022/09/eight-innovative-bert-knowledge-distillation-papers-changed-nlp-landscape.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Manage Your Complex IT Landscape with AIOps](https://www.kdnuggets.com/2022/05/manage-complex-landscape-aiops.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The First ML Value Chain Landscape](https://www.kdnuggets.com/2022/10/first-ml-value-chain-landscape-sequence.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Engineering Landscape in the AI-Driven World](https://www.kdnuggets.com/2023/05/data-engineering-landscape-aidriven-world.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Evolution of the Data Landscape](https://www.kdnuggets.com/2023/06/evolution-data-landscape.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
