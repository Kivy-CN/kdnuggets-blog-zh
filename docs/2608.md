# MLOps概述

> 原文：[https://www.kdnuggets.com/2021/03/overview-mlops.html](https://www.kdnuggets.com/2021/03/overview-mlops.html)

[评论](#comments)

**由[Steve Shwartz](https://www.aiperspectives.com/)，AI作者、投资者和连续创业者**。

![](../Images/48afb2bff1fb2e3e30045c24f69e1f4c.png)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的捷径。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT

* * *

*照片：iStockPhoto / NanoStockk*

通常需要相当的 数据科学 专业知识来创建数据集并为特定应用构建模型。但构建一个好的模型通常还不够。实际上，这远远不够。正如下图所示，开发和测试模型只是第一步。

![](../Images/2c877ece7473a610986f63f263699983.png)

*机器学习模型生命周期。*

机器学习操作（MLOps）涵盖了使模型有用的所有其他要求，包括自动化开发和部署管道、监控、生命周期管理和治理等能力，如上图所示。让我们逐一探讨这些内容。

### 自动化管道

创建一个生产环境下的ML系统需要多个步骤：首先，数据必须经过一系列转换。然后，对模型进行训练。通常，这需要尝试不同的网络架构和超参数。经常需要返回数据并尝试不同的特征。接下来，模型必须通过单元测试和集成测试进行验证。它需要通过数据和模型偏差及可解释性的测试。最后，将其部署到公共云、内部环境或混合环境中。此外，过程中的某些步骤可能需要审批流程。

如果这些步骤都是手动执行的，开发过程往往会变得缓慢且脆弱。幸运的是，许多MLOps工具可以自动化从数据转换到端到端部署的这些步骤。当需要重新训练时，这将是一个自动化、可靠且可重复的过程。

### 监控

ML模型在初次部署时往往表现良好，但随着时间的推移，表现会逐渐下降。正如Forrester分析师Dr. Kjell Carlsson[所说](https://go.forrester.com/blogs/no-deploy-no-joy-leverage-modelops-to-operationalize-ai-and-machine-learning/): “AI模型就像隔离中的六岁小孩：它们需要持续关注……否则，总会出现问题。”

部署时包含各种监控类型至关重要，以便机器学习团队能够在出现问题时得到警报。性能可能因基础设施问题（例如，CPU 或内存不足）而下降。当构成模型输入的独立变量的现实世界数据开始与训练数据表现出不同特征时，也可能导致性能下降，这种现象被称为数据漂移。

同样，由于现实世界条件的变化，模型可能变得不再适用，这种现象被称为概念漂移。例如，许多客户和供应商行为的预测模型在 COVID-19 期间陷入困境。

一些公司还监控替代模型（例如，不同的网络架构或不同的超参数），以查看这些“挑战者”模型是否开始表现得比生产模型更好。

通常，围绕模型做出的决策设置保护措施是有意义的。这些保护措施是简单的规则，可以触发警报、阻止决策或将决策放入需要人工审批的工作流程中。

### 生命周期管理

当模型性能由于数据或模型漂移而开始下降时，需要进行模型重训练和可能的模型重新架构。然而，数据科学团队不应从头开始。在开发原始模型时，或许在之前的重新架构过程中，他们可能已经测试了许多架构、超参数和特征。记录所有这些先前的实验（及其结果）至关重要，以便数据科学团队无需回到起点。这对于数据科学团队成员之间的沟通和协作也至关重要。

### 治理

机器学习模型正被用于许多影响人们的应用，如银行贷款决策、医疗诊断以及招聘/解雇决策。使用机器学习模型进行决策受到批评的原因有两个：首先，这些模型容易产生偏见，特别是当训练数据导致模型在种族、肤色、民族、国籍、宗教、性别、性取向或其他受保护类别上存在歧视时。其次，这些模型通常是黑箱，无法解释其决策过程。

因此，使用基于机器学习的决策制定的组织面临着确保其模型不歧视且能够解释其决策的压力。许多 MLOps 供应商正在结合基于学术研究的工具（例如，[SHAP](https://arxiv.org/pdf/1705.07874.pdf) 和 [Grad-CAM](https://arxiv.org/pdf/1610.02391.pdf)），这些工具有助于解释模型决策，并使用各种技术来确保数据和模型不受偏见影响。此外，他们还将偏见和可解释性测试纳入监控协议，因为模型可能会随着时间的推移变得有偏见或失去解释能力。

组织还需要建立信任，并开始确保持续的性能、消除偏见和可解释性是可审计的。 这要求模型目录不仅记录所有数据、参数和架构决策，还要记录每个决策的日志并提供可追溯性，以便确定每个决策所使用的数据、模型和参数，以及模型何时重新训练或修改，谁做出了每个更改。 对审计员来说，能够重复历史交易并使用“如果”情景测试模型决策的边界也很重要。

安全性和数据隐私也是使用机器学习的组织关注的关键问题。 必须确保个人信息受到保护，基于角色的数据访问能力是必需的，尤其是在受监管行业中。

全球各国政府也在迅速推动对影响人们的机器学习决策进行监管。 欧洲联盟通过其 GDPR 和 CRD IV 法规走在前列。 在美国，包括美联储和 FDA 在内的多个监管机构已经为金融和医疗决策中的机器学习决策制定了相关法规。 最近提议的《2020 数据问责和透明法案》是一项更全面的法律，预计将在 2021 年提交国会审议。 规定可能会发展到 CEO 需要签署其机器学习模型的可解释性和无偏见性的程度。

### MLOps 领域

随着我们进入 2021 年，MLOps 市场正迅速扩张。 根据分析公司 Cognilytica 的数据，预计到 2025 年将成为一个 [$40 亿市场](https://www.cognilytica.com/2020/04/02/infographic-the-rapid-growth-of-mlops/)。

在 MLOps 领域中，既有大玩家也有小玩家。 亚马逊、谷歌、微软、IBM、Cloudera、Domino、DataRobot 和 H2O 等主要机器学习平台供应商正在将 MLOps 能力纳入他们的平台。 根据 Crunchbase 的数据，在 MLOps 领域有 35 家私人公司，这些公司已融资从 180 万美元到 10 亿美元不等，且在 LinkedIn 上的员工数量从 3 人到 2800 人不等：

|  | **融资（百万美元）** | **员工数量** |  **描述** |
| --- | --- | --- | --- |
| Cloudera | 1000 | 2803 | Cloudera 提供一个企业数据云，支持任何数据，无论是边缘计算还是 AI。 |
| Databricks | 897 | 1757 | Databricks 是一个软件平台，帮助其客户统一业务、数据科学和数据工程中的分析。 |
| DataRobot | 750 | 1105 | DataRobot 将 AI 技术和 ROI 实现服务带给全球企业。 |
| Dataiku | 246 | 556 | Dataiku 作为一个企业人工智能和机器学习平台运作。 |
| Alteryx | 163 | 1623 | Alteryx 通过统一分析、数据科学和自动化流程加速数字化转型。 |
| H2O | 151 | 257 | H2O.ai 是开源 AI 和自动机器学习领域的领导者，使命是让 AI 为所有人所用。 |
| Domino | 124 | 232 | Domino 是全球领先的企业数据科学平台，为超过 20% 的财富 100 强公司提供数据科学支持。 |
| Iguazio | 72 | 83 | Iguazio 数据科学平台使你能够大规模实时开发、部署和管理 AI 应用程序 |
| Explorium.ai | 50 | 96 | Explorium 提供一个数据科学平台，由增强的数据发现和特征工程驱动 |
| Algorithmia | 38 | 63 | Algorithmia 是一个机器学习模型部署和管理解决方案，自动化组织的 MLOps |
| Paperspace | 23 | 37 | Paperspace 提供下一代基于 GPU 的应用程序支持。 |
| Pachyderm | 21 | 32 | Pachyderm 是一个企业级数据科学平台，使可解释、可重复和可扩展的 AI/ML 成为现实。 |
| Weights and Biases | 20 | 58 | 用于实验跟踪、改进模型性能和结果协作的工具 |
| OctoML | 19 | 37 | OctoML 正在改变开发者优化和部署机器学习模型以满足 AI 需求的方式。 |
| Arthur AI | 18 | 28 | Arthur AI 是一个监控机器学习模型生产力的平台。 |
| Truera | 17 | 26 | Truera 提供一个模型智能平台，帮助企业分析机器学习。 |
| Snorkel AI | 15 | 39 | Snorkel AI 专注于通过 Snorkel Flow 实现 AI 的实际应用：面向企业 AI 的数据优先平台 |
| Seldon.io | 14 | 48 | 机器学习部署平台 |
| Fiddler Labs | 13 | 46 | Fiddler 使用户能够创建透明、可解释和易于理解的 AI 解决方案。 |
| run.ai | 13 | 26 | Run:AI 开发了一种自动化分布式训练技术，可虚拟化并加速深度学习。 |
| ClearML (Allegro) | 11 | 29 | ML / DL 实验管理器和 ML-Ops 开源解决方案，端到端产品生命周期管理企业解决方案 |
| Verta | 10 | 15 | Verta 构建软件基础设施，帮助企业数据科学和机器学习（ML）团队开发和部署 ML 模型。 |
| cnvrg.io | 8 | 38 | cnvrg.io 是一个全栈数据科学平台，帮助团队管理模型，并构建自适应机器学习管道 |
| Datatron | 8 | 19 | Datatron 提供一个统一的模型治理（管理）平台，用于生产中的所有 ML、AI 和数据科学模型 |
| Comet | 7 | 19 | Comet.ml 是一个机器学习平台，旨在帮助 AI 从业者和团队构建可靠的机器学习模型。 |
| ModelOp | 6 | 39 | 统治、监控和管理企业中的所有模型 |
| WhyLabs | 4 | 15 | WhyLabs 是 AI 观察和监控公司。 |
| Arize AI | 4 | 14 | Arize AI 提供一个解释和排查生产 AI 的平台。 |
| DarwinAI | 4 | 31 | DarwinAI 的生成合成 'AI 建造 AI' 技术实现了优化和可解释的深度学习。 |
| Mona | 4 | 11 | Mona 是一个用于数据和 AI 驱动系统的 SaaS 监控平台 |
| Valohai | 2 | 13 | 您的托管机器学习平台，允许数据科学家构建、部署和跟踪机器学习模型。 |
| Modzy | 0 | 31 | 安全的 ModelOps 平台，用于发现、部署、管理和治理大规模机器学习——更快地获得价值。 |
| Algomox | 0 | 17 | 促进您的 AI 转型 |
| Monitaur | 0 | 8 | Monitaur 是一家提供审计性、透明性和治理的软件公司，服务于使用机器学习软件的公司。 |
| Hydrosphere.io | 0 | 3 | Hydrosphere.io 是一个用于 AI/ML 操作自动化的平台 |

许多这些公司专注于 MLOps 的一个细分领域，例如自动化管道、监控、生命周期管理或治理。[有些人认为](https://www.oreilly.com/radar/why-best-of-breed-is-a-better-choice-than-all-in-one-platforms-for-data-science/) 使用多个最优的 MLOps 产品对数据科学项目比单一平台更有利。还有一些公司正在为特定垂直领域构建 MLOps 产品。例如，[Monitaur](https://monitaur.ai/) 将自己定位为一个可以与任何平台兼容的最佳治理解决方案。Monitaur 还为受监管行业（从保险开始）构建行业特定的 MLOps 治理能力。（完全披露：我在 Monitaur 中是投资者）。

也有一些开源 MLOps 项目，包括：

+   **MLFlow** 管理 ML 生命周期，包括实验、可重复性和部署，并且包含一个模型注册表

+   **DVC** 管理 ML 项目的版本控制，使其可分享和可重复

+   **Polyaxon** 具有实验、生命周期自动化、协作和部署的能力，并且包含一个模型注册表

+   **Metaflow** 是 Netflix 之前的项目，用于管理自动化管道和部署

+   **Kubeflow** 具有在 Kubernetes 容器中进行工作流自动化和部署的能力

2021 年有望成为 MLOps 的一个有趣年份。我们可能会看到快速增长、激烈竞争以及很可能的整合。

**简介：** [Steve Shwartz](https://www.linkedin.com/in/steveshwartz/) ([@sshwartz](https://twitter.com/sshwartz)) 多年前作为博士后在耶鲁大学开始他的 AI 职业生涯，是一位成功的连续创业者和投资者，并且是《邪恶机器人、杀手机器和其他神话：关于 AI 和人类未来的真相》的作者。

**相关：**

+   [机器学习模型监控检查表：7 个需要跟踪的事项](https://www.kdnuggets.com/2021/03/machine-learning-model-monitoring-checklist.html)

+   [如何使用 MLOps 实现有效的 AI 策略](https://www.kdnuggets.com/2021/01/mlops-effective-ai-strategy.html)

+   [MLOps：模型监控 101](https://www.kdnuggets.com/2021/01/mlops-model-monitoring-101.html)

### 更多相关主题

+   [MLOps 中的设计模式](https://www.kdnuggets.com/2022/02/design-patterns-machine-learning-mlops.html)

+   [MLOps 是一团糟，但这也是意料之中的](https://www.kdnuggets.com/2022/03/mlops-mess-expected.html)

+   [MLOps 完整指南](https://www.kdnuggets.com/2023/08/comprehensive-guide-mlops.html)

+   [Ploomber 与 Kubeflow：让 MLOps 更轻松](https://www.kdnuggets.com/2022/02/ploomber-kubeflow-mlops-easier.html)

+   [在纽约市 Rev 3 与数据科学社区互动，第 #1…](https://www.kdnuggets.com/2022/03/domino-connect-data-science-community-nyc-mlops-conference.html)

+   [什么是 MLOps 工程师？](https://www.kdnuggets.com/2022/03/mlops-engineer.html)
