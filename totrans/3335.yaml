- en: Software Engineering vs Machine Learning Concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件工程与机器学习概念
- en: 原文：[https://www.kdnuggets.com/2017/03/software-engineering-vs-machine-learning-concepts.html](https://www.kdnuggets.com/2017/03/software-engineering-vs-machine-learning-concepts.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/03/software-engineering-vs-machine-learning-concepts.html](https://www.kdnuggets.com/2017/03/software-engineering-vs-machine-learning-concepts.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By Paul Mineiro, Principal Research Software Developer at Microsoft.**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：保罗·米内罗，微软首席研究软件开发人员。**'
- en: '![](../Images/b25d0f0f34246cdd832d4c5a6af86fc7.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b25d0f0f34246cdd832d4c5a6af86fc7.png)'
- en: '**Divide and Conquer** - A key technique in software engineering is to break
    a problem down into simpler subproblems, solve those subproblems, and then compose
    them into a solution to the original problem. Arguably, this is the entire job,
    recursively applied until the solution can be expressed in a single line in whatever
    programming language is being used. The canonical pedagogical example is the [Tower
    of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**分而治之** - 软件工程中的一个关键技术是将问题分解为更简单的子问题，解决这些子问题，然后将它们组合成对原始问题的解决方案。可以说，这就是整个工作，递归地应用，直到解决方案可以用所使用的任何编程语言的一行代码表示。经典的教学示例是[汉诺塔](https://en.wikipedia.org/wiki/Tower_of_Hanoi)。'
- en: 'Unfortunately, in machine learning we never exactly solve a problem. At best,
    we approximately solve a problem. This is where the technique needs modification:
    in software engineering the subproblem solutions are exact, but in machine learning
    errors compound and the aggregate result can be complete rubbish. In addition
    apparently paradoxical situations can arise where a component is “improved” in
    isolation yet aggregate system performance degrades when this “improvement” is
    deployed (e.g., due to the pattern of errors now being unexpected by downstream
    components, even if they are less frequent).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在机器学习中我们从未真正解决一个问题。充其量，我们只是近似解决了一个问题。这就是技术需要改进的地方：在软件工程中，子问题的解决方案是精确的，但在机器学习中，错误会累积，最终结果可能是完全无用的。此外，可能会出现表面上矛盾的情况，即一个组件在孤立状态下被“改进”，但当这种“改进”被部署后，整体系统性能却退化（例如，由于错误模式现在被下游组件意外地处理，即使这些错误更少）。
- en: Does this mean we are doomed to think holistically (which doesn't sound scalable
    to large problems)? No, but it means you have to be defensive about subproblem
    decomposition. The best strategy, when feasible, is to train the system end-to-end,
    i.e., optimize all components (and the composition strategy) together rather than
    in isolation. Often this is not feasible, so another alternative (inspired by
    Bayesian ideas) is to have each component report some kind of confidence or variance
    along with the output in order to facilitate downstream processing and integration.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着我们注定要整体考虑（这对大型问题来说似乎不可扩展）？不是，但这意味着你必须对子问题分解持防御态度。最佳策略是（当可行时）端到端地训练系统，即优化所有组件（以及组合策略），而不是孤立地进行。通常这并不可行，因此另一种替代方案（受贝叶斯思想启发）是让每个组件在输出时报告某种置信度或方差，以促进下游处理和集成。
- en: In practice, when systems get to a particular scope, there needs to be decomposition
    in order to divide the work up amongst many people. The fact that this doesn't
    work right now in machine learning is a problem, as elegantly described by Leon
    Bottou in his [ICML 2015 invited talk](http://icml.cc/2015/invited/LeonBottouICML2015.pdf).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，当系统达到一定规模时，需要进行分解，以便将工作分配给多人。机器学习中这一点现在不能正常工作是一个问题，正如Leon Bottou在他的[ICML
    2015特邀讲座](http://icml.cc/2015/invited/LeonBottouICML2015.pdf)中优雅地描述的那样。
- en: Speaking of another concept that Leon discussed...
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 说到Leon讨论的另一个概念……
- en: '**Correctness** - In software engineering, an algorithm can be proven correct,
    in the sense that given particular assumptions about the input, certain properties
    will be true when the algorithm terminates. In (supervised) machine learning,
    the only guarantee we really have is that if the training set is an iid sample
    from a particular distribution, then performance on another iid sample from the
    same distribution will be close to that on the training set and not too far from
    optimal.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**正确性** - 在软件工程中，可以证明算法的正确性，即在给定对输入的特定假设时，算法终止时某些属性将为真。在（监督）机器学习中，我们唯一真正拥有的保证是，如果训练集是来自特定分布的独立同分布样本，那么在另一个相同分布的独立同分布样本上的表现将接近于训练集上的表现，并且不会离最优太远。'
- en: 'Consequently anyone who practice machine learning for a living has an experimental
    mindset. Often times I am asked whether option A or option B is better, and most
    of the time my answer is “I don''t know, let''s try both and see what happens.”
    Maybe the most important thing that people in machine learning know is how to
    assess a model in such a way that is predictive of generalization. Even that is
    a “feel” thing: identifying and preventing leakage between training and validation
    sets (e.g., by stratified and temporal sampling) is something you learn by screwing
    up a few times; ditto for counterfactual loops. Kaggle is great for learning about
    the former, but the latter seems to require making mistakes on a closed-loop system
    to really appreciate.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何以机器学习为职业的人都具有实验性思维。我经常被问到选项A还是选项B更好，大多数时候我的回答是“我不知道，我们试试两个选项看看会发生什么。”也许机器学习领域最重要的事情是知道如何评估一个模型，以预测其泛化能力。即便如此，这也是一种“感觉”：识别和防止训练和验证集之间的泄漏（例如，通过分层和时间采样）是通过犯错学会的；反事实循环也是如此。Kaggle对于学习前者很棒，但后者似乎需要在闭环系统中犯错误才能真正理解。
- en: 'Experimental “correctness” is much weaker than the guarantees from other software,
    and there are many ways for things to go badly. For example in my experience it
    is always temporary: models go stale, it just always seems to happen. Ergo, you
    need to plan to be continually (hence, automatically) retraining models.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 实验性的“正确性”比其他软件的保证要弱得多，并且有许多方法可能导致问题。例如，在我的经验中，这种情况总是暂时的：模型会变得陈旧，这似乎总是发生。因此，你需要计划不断（因此自动）重新训练模型。
- en: '**Reuse** - This one is interesting. Reuse is the key to leverage in traditional
    software engineering: it''s not just more productive to reuse other code, but
    every line of code you write yourself is an opportunity to inject defects. Thus,
    reuse not only allows you to move faster but also make less mistakes: in return,
    you must pay the price of learning how to operate a piece of software written
    by others (when done well, this price has been lowered through good organization,
    documentation, and community support).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**重用** - 这点很有趣。重用是传统软件工程中的关键：重用其他代码不仅更高效，而且你自己编写的每一行代码都是注入缺陷的机会。因此，重用不仅可以让你更快地移动，还可以减少错误：作为回报，你必须支付学习如何操作他人编写的软件的代价（如果做得好，这个代价通过良好的组织、文档和社区支持降低了）。'
- en: Some aspects of machine learning exhibit exactly the same tradeoff. For instance,
    if you are writing your own deep learning toolkit, recognize that you are having
    fun. There's nothing wrong with having fun, and pedagogical activities are arguably
    better than playing video games all day. However, if you are trying to get something
    done, you should absolutely attempt to reuse as much technology as you can, which
    means you should be using a standard toolkit. You will move faster and make less
    mistakes, once you learn how to operate the standard toolkit.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的某些方面展示了完全相同的权衡。例如，如果你在编写自己的深度学习工具包，请意识到你是在享受乐趣。享受乐趣本身没有问题，教育活动可能比整天玩电子游戏要好。然而，如果你想完成某项工作，你绝对应该尽可能多地重用技术，这意味着你应该使用标准工具包。一旦你学会如何操作标准工具包，你会移动得更快，犯的错误也会更少。
- en: Machine learning toolkits are “traditional software”, however, and are designed
    to be reused. What about model reuse? That can be good as well, but the caveats
    about decomposition above still apply. So maybe you use a model which produces
    features from a user profile as inputs to your model. Fine, but you should version
    the model you depend upon and not blindly upgrade without assessment or retraining.
    Reusing the internals of another model is especially dangerous as most machine
    learning models are not identifiable, i.e., have various internal symmetries which
    are not determined by the training procedure. Couple an embedding to a tree, for
    instance, and when the next version of the embedding is a rotation of the previous
    one, you can watch your performance go to crap immediately.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，机器学习工具包是“传统软件”，并设计为可重用。那模型重用呢？这也可以很好，但上述关于分解的警告仍然适用。所以也许你使用一个模型，该模型从用户配置文件中生成特征作为你模型的输入。很好，但你应该对你依赖的模型进行版本管理，而不是盲目地升级而不进行评估或重新训练。重用另一个模型的内部尤其危险，因为大多数机器学习模型是不可识别的，即具有各种内部对称性，这些对称性不是由训练过程决定的。例如，将嵌入与树结合，当下一个版本的嵌入是前一个版本的旋转时，你可以立即看到你的性能变差。
- en: Basically, model reuse creates strong coupling between components which can
    be problematic if one component is changed.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，模型重用会在组件之间创建强耦合，如果其中一个组件发生更改，可能会出现问题。
- en: '**Testing** - I find the role of software testing in machine learning to be
    the trickiest issue of all. Without a doubt testing is necessary, but the challenge
    in using something like property-based testing is that the concept that is being
    captured by the machine learning component is not easily characterized by properties
    (otherwise, you would write it using non-ml software techniques). To the extent
    there are some properties that the ml component should exhibit, you can test for
    these, but unless you incorporate these into the learning procedure itself (e.g.,
    via parameter tying or data augmentation) you are likely to have some violations
    of the property that are not necessarily indicative of defects.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试** - 我发现软件测试在机器学习中的角色是最棘手的问题。毫无疑问，测试是必要的，但使用像基于属性的测试这样的东西的挑战在于，机器学习组件所捕捉的概念不容易用属性来表征（否则，你会使用非机器学习软件技术来实现它）。在机器学习组件应该表现出一些属性的程度上，你可以测试这些属性，但除非将这些属性融入到学习过程中（例如，通过参数绑定或数据增强），否则你可能会遇到一些并不一定表示缺陷的属性违反。'
- en: 'Having a “extra-test” data set of with minimal acceptable quality is a good
    idea: this could be easy examples that “any reasonable model” should get correct.
    There''s also self-consistency: at Yahoo they used to ship models with a set of
    input-output pairs that were computed with the model when it was put together,
    and if the loaded model didn''t reproduce the pairs, the model load was cancelled.
    (That should never happen, right? Surprise! Maybe you are featurizing the inputs
    using a library with a different version or something.)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个质量最低可接受的“额外测试”数据集是个好主意：这可以是“任何合理模型”都应该正确处理的简单例子。还有自我一致性：在雅虎，他们曾用一组在模型组装时计算的输入-输出对来发货模型，如果加载的模型没有重现这些对，模型加载会被取消。（这绝不该发生，对吧？惊讶！也许你在使用不同版本的库进行特征化。）
- en: Monitoring the metrics (proxy and true) of deployed models is also good for
    detecting problems. If the proxy metric (i.e., the thing on which you actually
    trained your model and estimated generalization performance) is going south, the
    inputs to your model are changing somehow (e.g., nonstationary environment, change
    in feature extraction pipeline); but if the proxy metric is stable while the true
    metric is going south, the problem might be in how the outputs of your model are
    being leveraged.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 监控部署模型的度量指标（代理指标和真实指标）也有助于检测问题。如果代理指标（即你实际训练模型和估计泛化性能的依据）变差，模型的输入发生了变化（例如，非平稳环境，特征提取管道的变化）；但如果代理指标稳定而真实指标变差，问题可能在于模型输出的利用方式。
- en: 'Unfortunately what I find is many software systems with machine learning components
    are tested in a way that would make traditional software engineers cringe: we
    look at the output to see if it is reasonable. Crazy! As machine learning becomes
    a more pervasive part of software engineering, this state of affairs must change.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我发现许多具有机器学习组件的软件系统以一种会让传统软件工程师感到不安的方式进行测试：我们查看输出以确定其是否合理。太疯狂了！随着机器学习成为软件工程中越来越普遍的一部分，这种情况必须改变。
- en: '**Bio: [Paul Mineiro](https://www.linkedin.com/in/paulmineiro/)** is a Principal
    Research Software Developer at Microsoft. He enjoys leading moderate sized teams
    focused on prototyping, speculative development, and translation of research into
    development ("high risk, high reward" activity). He likes iterative test-driven
    development, data-driven decision making, and positive psychology oriented management.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [保罗·米内罗](https://www.linkedin.com/in/paulmineiro/)** 是微软的首席研究软件开发人员。他喜欢领导中型团队，专注于原型设计、探索性开发和将研究转化为开发（"高风险，高回报"的活动）。他喜欢迭代的测试驱动开发、数据驱动决策和积极心理学导向的管理。'
- en: '[Original](http://www.machinedlearnings.com/2017/02/software-engineering-vs-machine.html).
    Reposted with permission.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](http://www.machinedlearnings.com/2017/02/software-engineering-vs-machine.html)。经许可转载。'
- en: '**Related:**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[How to Explain Machine Learning to a Software Engineer](/2016/05/explain-machine-learning-software-engineer.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何向软件工程师解释机器学习](/2016/05/explain-machine-learning-software-engineer.html)'
- en: '[Top Data Scientist Daniel Tunkelang on Data Science Project Scope… and Reducing
    It](/2016/10/tunkelang-reduce-scope.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级数据科学家丹尼尔·图克兰关于数据科学项目范围……及其缩减](https://example.org/2016/10/tunkelang-reduce-scope.html)'
- en: '[What is the Difference Between Deep Learning and “Regular” Machine Learning?](/2016/06/difference-between-deep-learning-regular-machine-learning.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习与“常规”机器学习的区别是什么？](/2016/06/difference-between-deep-learning-regular-machine-learning.html)'
- en: '* * *'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Software Developer vs Software Engineer](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件开发者与软件工程师的区别](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
- en: '[ChatGPT as a Personalized Tutor for Learning Data Science Concepts](https://www.kdnuggets.com/2023/05/chatgpt-personalized-tutor-learning-data-science-concepts.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT作为学习数据科学概念的个性化辅导老师](https://www.kdnuggets.com/2023/05/chatgpt-personalized-tutor-learning-data-science-concepts.html)'
- en: '[5 Concepts You Should Know About Gradient Descent and Cost Function](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该了解的关于梯度下降和成本函数的5个概念](https://www.kdnuggets.com/2020/05/5-concepts-gradient-descent-cost-function.html)'
- en: '[The 8 Basic Statistics Concepts for Data Science](https://www.kdnuggets.com/2020/06/8-basic-statistics-concepts.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学的8个基本统计概念](https://www.kdnuggets.com/2020/06/8-basic-statistics-concepts.html)'
- en: '[Concepts You Should Know Before Getting Into Transformers](https://www.kdnuggets.com/2023/01/concepts-know-getting-transformer.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在进入变压器之前你应该了解的概念](https://www.kdnuggets.com/2023/01/concepts-know-getting-transformer.html)'
- en: '[The Not-so-Sexy SQL Concepts to Make You Stand Out](https://www.kdnuggets.com/2022/02/not-so-sexy-sql-concepts-stand-out.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[让你脱颖而出的不那么性感的SQL概念](https://www.kdnuggets.com/2022/02/not-so-sexy-sql-concepts-stand-out.html)'
