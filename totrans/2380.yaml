- en: 'Support Vector Machines: An Intuitive Approach'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/a42a38fb99d842ee894e558cffe74353.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [freepik ](https://img.freepik.com/free-vector/learning-concept-illustration_114360-6186.jpg?w=996&t=st=1660494575~exp=1660495175~hmac=ea22e5e0a1e466bbc0d4e9d728e693f76e49f854bc3af1a5eaf5ebfa151c258a)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machine (SVM) is one of the most popular machine learning algorithms
    especially in the pre-boosting era (before the introduction of boosting algorithms),
    which is used for both Classification and Regression use-cases.
  prefs: []
  type: TYPE_NORMAL
- en: The objective of an SVM classifier is to find the best n-1 dimensional hyperplane
    also called the decision boundary which can separate an n-dimensional space into
    the classes of interest. Notably, a hyperplane is a subspace whose dimension is
    one less than that of its ambient space.
  prefs: []
  type: TYPE_NORMAL
- en: SVM identifies the endpoints or end vectors that support this hyperplane while
    also maximizing the distance between them. This is the reason they are called
    support vectors, and thus the algorithm is called Support Vector Machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The below diagram shows two classes segregated by a hyperplane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/89bb01a5e79d1f40c204a32cc9b4d4bd.png)'
  prefs: []
  type: TYPE_IMG
- en: Source:[https://datatron.com/wp-content/uploads/2021/05/Support-Vector-Machine.png](https://datatron.com/wp-content/uploads/2021/05/Support-Vector-Machine.png)
  prefs: []
  type: TYPE_NORMAL
- en: Why is SVM so popular?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When compared to simpler algorithms for example Logistic Regression, the SVM
    identification of maximum margin makes it a robust choice when dealing with noise.
    Particularly when a sample of one class crosses over to the other side across
    the decision boundary.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression on the other hand is very vulnerable to such noisy samples
    and even a small sample of noisy observations can spoil the sport. The basic idea
    is that Logistic Regression is not trying to maximize the separation between the
    classes and just arbitrarily stops at a decision boundary that classifies the
    two categories correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/6dfd84e930153c1db570d8e4c93842be.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://kajabi-storefronts-production.kajabi-cdn.com/kajabi-storefronts-production/blogs/2147494064/images/N5bIuCEvQL6ZFNY3GCiX_LR3.png](https://kajabi-storefronts-production.kajabi-cdn.com/kajabi-storefronts-production/blogs/2147494064/images/N5bIuCEvQL6ZFNY3GCiX_LR3.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Having a soft margin also allows for a budget for misclassifications and thus
    makes SVM robust to cross-overs across classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/70d1adc573aeda183de119fc0c0406ce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://vitalflux.com/wp-content/uploads/2015/03/logistic-regression-vs-SVM.png](https://vitalflux.com/wp-content/uploads/2015/03/logistic-regression-vs-SVM.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Kernel functions are another reason why SVM is so popular. SVM classifier is
    able to separate the classes with non-linear decision boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss more on Soft margin and Kernel Trick in the upcoming sections,
    but let us first put focus on the precursor to soft margin i.e. hard margin SVM.
  prefs: []
  type: TYPE_NORMAL
- en: Hard Margin SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start our discussion with a straightforward and relatively easier-to-understand
    version of SVM called Hard Margin SVM or just Maximal Margin Classifier.
  prefs: []
  type: TYPE_NORMAL
- en: The perpendicular distance between the two support vectors when the two classes
    of interest are linearly separable is called a margin. The only thing to observe
    here is that the two classes are distinctly positioned with respect to each other
    which means not even a single sample crosses over across the margin.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go a little deeper into the mathematics of a Hard Margin Support Vector
    Machine.
  prefs: []
  type: TYPE_NORMAL
- en: In the diagram below, we have a positive class denoted by green and a negative
    denoted by red. Now to maximize the margin or the distance between the two classes
    we need to assume a perpendicular vector to our decision boundary.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/defd4baa46b37c9fd40068d094237af5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://qph.cf2.quoracdn.net/main-qimg-8264205dc003f4e1c15a3d060b9375ee-pjlq](https://qph.cf2.quoracdn.net/main-qimg-8264205dc003f4e1c15a3d060b9375ee-pjlq)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Under the following constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/8468f16aaf91293f51f52eff86c1887e.png)'
  prefs: []
  type: TYPE_IMG
- en: This is because the samples to the right of the margin should be classified
    as positive and to the left of the margin should be classified as negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also write the objective function as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/48f84753a5fac5d772ef0e2c4c538421.png)'
  prefs: []
  type: TYPE_IMG
- en: This is called Hinge Loss, which takes care of the correct classification of
    the two classes.
  prefs: []
  type: TYPE_NORMAL
- en: Soft Margin SVM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Real-world data does not follow the ideal assumption of linear separability
    as in the case with Hard Margin. The solution is to allow a tiny misclassification
    or violation of the margin in such a way that the overall margin is maximized.
    The Maximal Margin Classifier that uses a soft margin instead of a hard margin
    is called a Soft Margin Classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let the perpendicular vector be “w” and our objective is to maximize the number
    of steps in either direction from the decision boundary assuming it''s in the
    middle of both support vectors. Solving the above equation would give us the margin
    as below:'
  prefs: []
  type: TYPE_NORMAL
- en: Maximizing the above quantity alternatively means minimizing ||w|| or square
    of that, and in turn maximizing the margin of the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/eb0677221bacbd685fe3ae16f15d99f3.png)'
  prefs: []
  type: TYPE_IMG
- en: This allows an additional term to the hinge loss equation discussed in the hard
    margin case where the ||w||² terms make sure that the model balances correct classification
    with maximizing the margin. The equation given below shows the two components
    of a soft margin SVM where the second term acts as a regularize.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/3979ad783b15e066bd3e9f08c4720fcf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://miro.medium.com/max/1042/1*nFmhvEy6GyYQOYlF-L9XRw.png](https://miro.medium.com/max/1042/1*nFmhvEy6GyYQOYlF-L9XRw.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Here lambda is a hyperparameter and can be tuned to allow more or fewer misclassifications.
    A higher value of lambda means a higher allowance of misclassifications whereas
    a lower value of lambda restricts misclassifications to a minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Trick
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The world is not ideal and thus not all classification problems have linearly
    separable classes. Kernel Functions in SVM allow us to solve such cases.
  prefs: []
  type: TYPE_NORMAL
- en: Below is an example of how a polynomial kernel function (degree 2 polynomial)
    is applied to a non-linear separable case to make it linear separable.
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/2c15c5ca030ef4acddc01c6a5d2eb038.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://miro.medium.com/max/1400/1*mCwnu5kXot6buL7jeIafqQ.png](https://miro.medium.com/max/1400/1*mCwnu5kXot6buL7jeIafqQ.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the popular kernels are listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Support Vector Machines: An Intuitive Approach](../Images/1fa973d0050203a889b0d80b54be034b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [https://d3i71xaburhd42.cloudfront.net/3a92a26a66efba1849fa95c900114b9d129467ac/3-TableI-1.png](https://d3i71xaburhd42.cloudfront.net/3a92a26a66efba1849fa95c900114b9d129467ac/3-TableI-1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Kernels are amazing as they let you project the data in an additional dimension
    without adding an overhead of a dimension.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We discussed the significance of the SVM classifier and its application especially
    when the number of dimensions is very high as compared to the number of examples.
    This makes it really effective in NLP problems where a lot of times text is converted
    to really long vectors of numbers. Further, we learnt about the kernel functions
    which aid its ability to classify the new data points across non-linear decision
    boundaries. Besides, SVM models are immune to overfitting to a large extent as
    the decision boundary is only affected by support vectors and is largely immune
    to the presence of the other extreme observations.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Vidhi Chugh](https://vidhi-chugh.medium.com/)** is an award-winning AI/ML
    innovation leader and an AI Ethicist. She works at the intersection of data science,
    product, and research to deliver business value and insights. She is an advocate
    for data-centric science and a leading expert in data governance with a vision
    to build trustworthy AI solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ethics of AI: Navigating the Future of Intelligent Machines](https://www.kdnuggets.com/2023/04/ethics-ai-navigating-future-intelligent-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[AI for Ukraine is a new educational project from AI HOUSE to…](https://www.kdnuggets.com/2022/08/ai-house-ai-ukraine-new-educational-project-support-ukrainian-tech-community.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
