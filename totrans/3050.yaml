- en: Mastering The New Generation of Gradient Boosting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握新一代梯度提升
- en: 原文：[https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html](https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html](https://www.kdnuggets.com/2018/11/mastering-new-generation-gradient-boosting.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Tal Peretz](https://www.linkedin.com/in/tal-per/), Data Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Tal Peretz](https://www.linkedin.com/in/tal-per/)，数据科学家**'
- en: '![Image](../Images/6f0021d10fa8e75d1f0681617209fb04.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/6f0021d10fa8e75d1f0681617209fb04.png)'
- en: Catboost
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost
- en: '**Gradient Boosted Decision Trees** and Random Forest are my favorite ML models
    for tabular heterogeneous datasets. These models are the top performers on [Kaggle](https://www.kaggle.com/) competitions
    and in widespread use in the industry.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**梯度提升决策树**和随机森林是我最喜欢的用于异构表格数据集的机器学习模型。这些模型在*[Kaggle](https://www.kaggle.com/)*竞赛中表现最优，并在行业中广泛使用。'
- en: '**Catboost**, the new kid on the block, has been around for a little more than
    a year now, and it is already threatening *XGBoost*, *LightGBM* and *H2O*.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**Catboost**，这个新兴的模型，已经存在一年多了，并且正在威胁到*XGBoost*、*LightGBM*和*H2O*。'
- en: Why Catboost?
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择Catboost？
- en: '**Better Results**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**更好的结果**'
- en: Catboost achieves the best results on the benchmark, and that’s great, yet I
    don’t know if I would replace a working production model for only a fraction of
    a log-loss improvement alone (especially when the company who conducted the benchmark
    has a clear interest in the favor of Catboost ????).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost在基准测试中取得了最佳结果，这很好，但我不确定是否会仅因略微减少的对数损失而替换一个已在生产中的模型（尤其是当进行基准测试的公司对Catboost有明显利益时????）。
- en: Though, when you look at datasets where **categorical features play a large
    role**, such as *Amazon* and the *Internet *datasets, this improvement becomes
    significant and undeniable.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，当你查看**分类特征起重要作用**的数据集时，如*Amazon*和*Internet*数据集，这种改进变得显著且不可否认。
- en: '![](../Images/c0f56356b0efe76253f46b1b9e3e4db4.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0f56356b0efe76253f46b1b9e3e4db4.png)'
- en: GBDT Algorithms Benchmark
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: GBDT算法基准
- en: '**Faster Predictions**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**更快的预测**'
- en: While training time can take up longer than other GBDT implementations, prediction
    time is 13–16 times faster than the other libraries according to the Yandex benchmark.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管训练时间可能比其他GBDT实现更长，但根据Yandex基准，预测时间比其他库快13-16倍。
- en: '![](../Images/b878dfec55b45c7736bc70937ced22a9.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b878dfec55b45c7736bc70937ced22a9.png)'
- en: 'Left: CPU, Right: GPU'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 左：CPU，右：GPU
- en: '**Batteries Included**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**内置电池**'
- en: Catboost’s default parameters are a better starting point than in other GBDT
    algorithms. And this is good news for beginners who want a plug and play model
    to start experience tree ensembles or Kaggle competitions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost的默认参数比其他GBDT算法的起始点更好。这对希望开始体验树集成或参加Kaggle竞赛的初学者来说是个好消息。
- en: Yet, there are some very important parameters which we must address and we’ll
    talk about those in a moment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些非常重要的参数我们必须讨论，我们稍后会谈到这些。
- en: '![](../Images/1d04b9a46e27fdf79d1394772740d7c8.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d04b9a46e27fdf79d1394772740d7c8.png)'
- en: GBDT Algorithms with default parameters Benchmark
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: GBDT算法默认参数基准
- en: Some more noteworthy advancements by Catboost are the features interactions,
    object importance and the snapshot support.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost的一些更值得注意的进展包括特征交互、对象重要性和快照支持。
- en: In addition to classification and regression, Catboost supports **ranking** out
    of the box.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分类和回归，Catboost还**开箱即用地支持排名**。
- en: '**Battle Tested**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**实战验证**'
- en: '[Yandex](https://yandex.com/) is relying heavily on Catboost for ranking, forecasting
    and recommendations. This model is serving more than 70 million users each month.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yandex](https://yandex.com/)严重依赖Catboost进行排名、预测和推荐。这个模型每月服务于超过7000万用户。'
- en: CatBoost is an algorithm for **gradient boosting on decision trees**. Developed
    by Yandex researchers and engineers, it is the successor of the [**MatrixNet algorithm**](https://yandex.com/company/technologies/matrixnet/)that
    is widely used within the company for ranking tasks, forecasting and making recommendations.
    It is universal and can be applied across a wide range of areas and to a variety
    of problems.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: CatBoost是一种**基于决策树的梯度提升**算法。由Yandex的研究人员和工程师开发，是广泛用于排名任务、预测和推荐的[**MatrixNet算法**](https://yandex.com/company/technologies/matrixnet/)的继任者。它具有通用性，能够应用于广泛的领域和多种问题。
- en: '![](../Images/c5da7f5f59cc6ccf130e81e835370235.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5da7f5f59cc6ccf130e81e835370235.png)'
- en: The Algorithm
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法
- en: '**Classic Gradient Boosting**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**经典梯度提升**'
- en: '![](../Images/5c4a3ead431e03d2e430b6f2cd022cf1.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c4a3ead431e03d2e430b6f2cd022cf1.png)'
- en: Gradient Boosting on Wikipedia
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科上的梯度提升
- en: '![](../Images/d9ca34b445477fccd614b5d7fa7e7ae8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9ca34b445477fccd614b5d7fa7e7ae8.png)'
- en: Catboost Secret Sauce
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Catboost 秘密配方
- en: Catboost introduces two critical algorithmic advances - the implementation of **ordered
    boosting**, a permutation-driven alternative to the classic algorithm, and an
    innovative algorithm for **processing categorical features**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 引入了两个关键的算法进展——**有序提升**的实现，这是经典算法的一种基于排列的替代方法，以及用于**处理类别特征**的创新算法。
- en: Both techniques are using random permutations of the training examples to fight
    the *prediction shift* caused by a special kind of *target leakage* present in
    all existing implementations of gradient boosting algorithms.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术都使用训练样本的随机排列来对抗由于所有现有梯度提升算法中存在的一种特殊类型的*目标泄漏*所造成的*预测偏移*。
- en: '**Cat**egorical Feature Handling'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**类别特征处理**'
- en: '**Ordered Target Statistic**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**有序目标统计**'
- en: Most of the GBDT algorithms and Kaggle competitors are already familiar with
    the use of Target Statistic (or target mean encoding).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 GBDT 算法和 Kaggle 竞争者已经熟悉 Target Statistic（或目标均值编码）的使用。
- en: It’s a simple yet effective approach in which we encode each categorical feature
    with the estimate of the expected target y conditioned by the category.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种简单而有效的方法，我们使用根据类别条件化的期望目标 y 的估计来对每个类别特征进行编码。
- en: Well, it turns out that applying this encoding carelessly (average value of
    y over the training examples with the same category) results in a target leakage.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，随意应用这种编码（在训练示例中具有相同类别的 y 的平均值）会导致目标泄漏。
- en: To fight this *prediction shift *CatBoost uses a more effective strategy. It
    relies on the ordering principle and is inspired by online learning algorithms
    which get training examples sequentially in time. In this setting, the values
    of TS for each example rely only on the observed history.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这种*预测偏移*，CatBoost 使用了更有效的策略。它依赖于排序原则，并且受到在线学习算法的启发，这些算法按时间顺序获取训练示例。在这种情况下，每个示例的
    TS 值仅依赖于观察到的历史。
- en: To adapt this idea to a standard offline setting, Catboost introduces an artificial
    “time”— a random permutation *σ1* of the training examples.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这一思想适应于标准离线设置，Catboost 引入了一个人工的“时间”——一个训练示例的随机排列*σ1*。
- en: Then, for each example, it uses all the available “history” to compute its Target
    Statistic.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于每个示例，它使用所有可用的“历史”来计算其 Target Statistic。
- en: Note that, using only one random permutation, results in preceding examples
    with higher variance in Target Statistic than subsequent ones. To this end, CatBoost
    uses different permutations for different steps of gradient boosting.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用仅一个随机排列会导致前面的示例在 Target Statistic 上的方差大于后续示例。为此，CatBoost 在梯度提升的不同步骤中使用不同的排列。
- en: '**One Hot Encoding**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**独热编码**'
- en: Catboost uses a one-hot encoding for all the features with at most *one_hot_max_size* unique
    values. The default value is 2.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 对所有具有最多 *one_hot_max_size* 个唯一值的特征使用独热编码。默认值为 2。
- en: '![](../Images/2f8ee6fadf0aa6b7e40160287f640d95.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f8ee6fadf0aa6b7e40160287f640d95.png)'
- en: Catboost’s Secret Sauce
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 的秘密配方
- en: Orderd Boosting
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有序提升
- en: CatBoost has two modes for choosing the tree structure, Ordered and Plain. **Plain
    mode** corresponds to a combination of the standard GBDT algorithm with an ordered
    Target Statistic.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 有两种选择树结构的模式：Ordered 和 Plain。**Plain 模式**对应于将标准 GBDT 算法与有序 Target Statistic
    的组合。
- en: In **Ordered mode** boosting we perform a random permutation of the training
    examples - *σ2,* and maintain n different supporting models - *M1, . . . , Mn*
    such that the model *Mi* is trained using only the first *i* samples in the permutation.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在**有序模式**提升中，我们对训练示例进行随机排列——*σ2*，并维护 n 个不同的支持模型——*M1, . . . , Mn*，其中模型*Mi*仅使用排列中的前*i*个样本进行训练。
- en: At each step, in order to obtain the residual for *j*-th sample, we use the
    model *Mj−1*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，为了获得*j*第*个样本的残差，我们使用模型*Mj−1*。
- en: Unfortunately, this algorithm is not feasible in most practical tasks due to
    the need of maintaining n different models, which increase the complexity and
    memory requirements by n times. Catboost implements a modification of this algorithm,
    on the basis of the gradient boosting algorithm, using one tree structure shared
    by all the models to be built.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于需要维护 n 个不同的模型，这增加了复杂性和内存需求，因此这种算法在大多数实际任务中不可行。Catboost 实现了这种算法的改进，基于梯度提升算法，使用一个由所有待建立模型共享的树结构。
- en: '![](../Images/7245343ce5d8d1988a29e6935d988b25.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7245343ce5d8d1988a29e6935d988b25.png)'
- en: Catboost Ordered Boosting and Tree Building
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 有序提升和树构建
- en: In order to avoid *prediction shift*, Catboost uses permutations such that *σ1* = *σ2*.
    This guarantees that the target-*yi* is not used for training *Mi* neither for
    the Target Statistic calculation nor for the gradient estimation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免*预测偏移*，Catboost 使用排列，使得*σ1* = *σ2*。这保证了目标-*yi* 既未用于训练*Mi*，也未用于目标统计计算或梯度估计。
- en: Hands On
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实操
- en: For this section, we’ll use the [*Amazon Dataset*](https://www.kaggle.com/c/amazon-employee-access-challenge/data),
    since it’s clean and has a strong emphasize on categorical features.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，我们将使用[*Amazon Dataset*](https://www.kaggle.com/c/amazon-employee-access-challenge/data)，因为它干净且强调类别特征。
- en: '![](../Images/54f9b2df0a33b9243c0edaeb7b2614e7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54f9b2df0a33b9243c0edaeb7b2614e7.png)'
- en: Dataset in a brief
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集简述
- en: Tuning Catboost
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调整 Catboost
- en: '**Important Parameters**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要参数**'
- en: '**cat_features** — This parameter is a must in order to leverage Catboost preprocessing
    of categorical features, if you encode the categorical features yourself and don’t
    pass the columns indices as *cat_features *you are missing the essence of Catboost*.*'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**cat_features** — 为了利用 Catboost 对类别特征的预处理，这个参数是必须的。如果你自己编码类别特征却没有将列索引作为*cat_features*传递，你将错过
    Catboost 的精髓。*'
- en: '***one_hot_max_size**** — *As mentioned before,Catboost uses a one-hot encoding
    for all features with at most *one_hot_max_size* unique values. In our case, the
    categorical features have a lot of unique values, so we won’t use one hot encoding,
    but depending on the dataset it may be a good idea to adjust this parameter.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***one_hot_max_size**** — *如前所述，Catboost 对所有特征使用一个最多包含*one_hot_max_size* 个唯一值的独热编码。在我们的情况下，类别特征有很多唯一值，因此我们不会使用独热编码，但根据数据集的不同，调整此参数可能是个好主意。*'
- en: '***learning_rate* & *n_estimators*** — The smaller the learning_rate, the more
    n_estimators needed to utilize the model. Usually the approach is to start with
    a relative high *learning_rate*, tune other parameters and then decrease the *learning_rate* while
    increasing *n_estimators*.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***learning_rate* & *n_estimators*** — *学习率越小，需要的 n_estimators 越多来充分利用模型。通常的方法是从相对较高的*learning_rate*开始，调整其他参数，然后降低*learning_rate*，同时增加*n_estimators*。*'
- en: '***max_depth**** — *Depth of the base trees*, *this parameter has an high impact
    on training time*.*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***max_depth**** — *基础树的深度*，*这个参数对训练时间有很大的影响。*'
- en: '***subsample ****— *Sample rate of rows, can’t be used in a *Bayesian* boosting
    type setting.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***subsample ****— *样本率，不能用于*Bayesian*增强类型设置。*'
- en: '***colsample_bylevel ****— *Sample rate of columns.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***colsample_bylevel ****— *列的样本率。*'
- en: '***l2_leaf_reg ****— *L2 regularization coefficient.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***l2_leaf_reg ****— *L2 正则化系数。*'
- en: '***random_strength ****— *Every split gets a score and random_strength is adding
    some randomness to the score, it helps to reduce overfitting.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***random_strength ****— *每个分裂都有一个分数，random_strength 为分数添加了一些随机性，有助于减少过拟合。*'
- en: Model Exploration with Catboost
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Catboost 进行模型探索
- en: In addition to feature importance, which is quite popular for GBDT models to
    share, Catboost provides **feature interactions** and **object (row) importance**
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 除了特征重要性之外，Catboost 还提供了**特征交互**和**对象（行）重要性**
- en: '![](../Images/082c2a9b1ba4d6c8314ba8aa236e987b.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/082c2a9b1ba4d6c8314ba8aa236e987b.png)'
- en: Catboost’s Feature Importance![](../Images/56623055e6f9f321c7421840035723e3.png)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 的特征重要性![](../Images/56623055e6f9f321c7421840035723e3.png)
- en: Catboost’s Feature Interactions![](../Images/aee63f4ec198f40df446c77d26da3020.png)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 的特征交互![](../Images/aee63f4ec198f40df446c77d26da3020.png)
- en: Catboost’s Object Importance![](../Images/cc8f573706b8833248e07619ab3f075f.png)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 的对象重要性![](../Images/cc8f573706b8833248e07619ab3f075f.png)
- en: '[SHAP](https://catboost.ai/news/new-ways-to-explore-your-data) values can be
    used for other ensembles as well'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[SHAP](https://catboost.ai/news/new-ways-to-explore-your-data) 值也可以用于其他集成方法'
- en: The Full Notebook
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整的笔记本
- en: Check it out for some useful Catboost code snippets
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 查看一些有用的 Catboost 代码片段
- en: 'Catboost Playground Notebook ### Bottom Line'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 'Catboost 游乐场笔记本 ### 结论'
- en: '![](../Images/ef39987d7aca7ca0507cfb9e7cd44cb7.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef39987d7aca7ca0507cfb9e7cd44cb7.png)'
- en: Catboost vs. XGBoost (default, greedy and exhaustive parameter search)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 与 XGBoost（默认、贪婪和全面参数搜索）
- en: '![](../Images/fc9fa159d967eadf6f7a1be280d62dca.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc9fa159d967eadf6f7a1be280d62dca.png)'
- en: '**Take Away**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**'
- en: Catboost is built with a similar approach and attributes as with the “older”
    generation of GBDT models.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Catboost 采用了与“旧一代”GBDT模型类似的方法和属性。
- en: Catboost’s power lies in its **categorical features preprocessing**, **prediction
    time** and **model analysis**.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Catboost 的优势在于其 **分类特征预处理**、 **预测时间** 和 **模型分析**。
- en: Catboost’s weaknesses are its **training and optimization times**.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Catboost 的弱点在于其 **训练和优化时间**。
- en: Don’t forget to pass ***cat_features*** argument to the classifier object. You
    aren’t really utilizing the power of Catboost without it.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忘记将 ***cat_features*** 参数传递给分类器对象。没有这个参数，你并没有真正发挥 Catboost 的强大功能。
- en: Though Catboost performs well with default parameters, there are several parameters
    that drive a significant improvement in results when tuned.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管 Catboost 在默认参数下表现良好，但有几个参数在调整时能显著改善结果。
- en: '**Further Reading**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**进一步阅读**'
- en: '[Catboost Documentation](https://tech.yandex.com/catboost/doc/dg/concepts/about-docpage/)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Catboost 文档](https://tech.yandex.com/catboost/doc/dg/concepts/about-docpage/)'
- en: '[Catboost Github](https://github.com/catboost/catboost)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Catboost Github](https://github.com/catboost/catboost)'
- en: '[Catboost official website](https://catboost.ai/)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Catboost 官方网站](https://catboost.ai/)'
- en: 'I highly recommend you to dig into the [CatBoost: unbiased boosting with categorical
    features paper on arXiv](https://arxiv.org/abs/1706.09516).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '我强烈推荐你深入阅读 [CatBoost: unbiased boosting with categorical features paper on
    arXiv](https://arxiv.org/abs/1706.09516)。'
- en: '[Catboost playground notebook](https://gist.github.com/talperetz/6030f4e9997c249b09409dcf00e78f91)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Catboost 游乐场笔记本](https://gist.github.com/talperetz/6030f4e9997c249b09409dcf00e78f91)'
- en: '[SHAP Values](https://github.com/slundberg/shap)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP 值](https://github.com/slundberg/shap)'
- en: Huge thanks to Catboost Team Lead [Anna Veronika Dorogush](https://medium.com/@a.v.dorogush).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢 Catboost 团队负责人 [Anna Veronika Dorogush](https://medium.com/@a.v.dorogush)。
- en: If you enjoyed this post, feel free to hit the clap button ???????? and if you’re
    interested in posts to come, make sure to follow me on
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，可以点击点赞按钮 ????????，如果你对即将发布的文章感兴趣，请确保关注我。
- en: '**Medium: **[**https://medium.com/@talperetz24**](https://medium.com/@talperetz24)
    **Twitter:**[**https://twitter.com/talperetz24**](https://twitter.com/talperetz24)
    **LinkedIn:**[**https://www.linkedin.com/in/tal-per/**](https://www.linkedin.com/in/tal-per/)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**Medium:** [**https://medium.com/@talperetz24**](https://medium.com/@talperetz24)
    **Twitter:** [**https://twitter.com/talperetz24**](https://twitter.com/talperetz24)
    **LinkedIn:** [**https://www.linkedin.com/in/tal-per/**](https://www.linkedin.com/in/tal-per/)'
- en: Like every year, I want to mention [DataHack](https://www.datahack.org.il/)-
    the best data driven hackathon out there. This year [דור פרץ](https://medium.com/@sdorperetz) and
    I used Catboost for our project and won the 1st place ????.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 像每年一样，我想提到 [DataHack](https://www.datahack.org.il/)，这是最好的数据驱动黑客马拉松。今年 [דור פרץ](https://medium.com/@sdorperetz) 和我在项目中使用了
    Catboost，并获得了第一名 ????。
- en: '**Bio: [Tal Peretz](https://www.linkedin.com/in/tal-per/)** is a Data Scientist,
    Software Engineer, and a Continuous Learner. He is passionate about solving complex
    problems with high-value potential using data, code and algorithms. He especially
    likes building and improving models to separate the ones from the zeros. 0|1'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Tal Peretz](https://www.linkedin.com/in/tal-per/)** 是一名数据科学家、软件工程师和持续学习者。他热衷于使用数据、代码和算法解决高价值潜力的复杂问题。他特别喜欢构建和改进模型，将零和一区分开来。0|1'
- en: '[Original](https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2).
    Reposted with permission.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2)。经许可转载。'
- en: '**Related:**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Gradient Boosting in TensorFlow vs XGBoost](/2018/01/gradient-boosting-tensorflow-vs-xgboost.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 中的梯度提升与 XGBoost](/2018/01/gradient-boosting-tensorflow-vs-xgboost.html)'
- en: '[CatBoost vs. Light GBM vs. XGBoost](/2018/03/catboost-vs-light-gbm-vs-xgboost.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CatBoost 与 Light GBM 与 XGBoost](/2018/03/catboost-vs-light-gbm-vs-xgboost.html)'
- en: '[Intuitive Ensemble Learning Guide with Gradient Boosting](/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[直观的集成学习指南与梯度提升](/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html)'
- en: '* * *'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT 部门'
- en: '* * *'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Retrieval Augmented Generation: Where Information Retrieval Meets…](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检索增强生成：信息检索与文本生成的交汇](https://www.kdnuggets.com/retrieval-augmented-generation-where-information-retrieval-meets-text-generation)'
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[终极指南：掌握季节性变化并提升业务成果](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[Bark: The Ultimate Audio Generation Model](https://www.kdnuggets.com/2023/05/bark-ultimate-audio-generation-model.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Bark：终极音频生成模型](https://www.kdnuggets.com/2023/05/bark-ultimate-audio-generation-model.html)'
- en: '[The Future of AI: Exploring the Next Generation of Generative Models](https://www.kdnuggets.com/2023/05/future-ai-exploring-next-generation-generative-models.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能的未来：探索下一代生成模型](https://www.kdnuggets.com/2023/05/future-ai-exploring-next-generation-generative-models.html)'
- en: '[Unveiling Midjourney 5.2: A Leap Forward in AI Image Generation](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭示 Midjourney 5.2：AI 图像生成的飞跃](https://www.kdnuggets.com/2023/06/unveiling-midjourney-52-leap-forward.html)'
