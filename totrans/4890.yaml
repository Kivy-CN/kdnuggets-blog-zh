- en: 'Managing Machine Learning Workflows with Scikit-learn Pipelines Part 3: Multiple
    Models, Pipelines, and Grid Searches'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html](https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-3.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: First, I know that I promised we would be past the toy datasets last post, but
    for comparison purposes we will be sticking with iris for a bit longer. I think
    it's best we are able to still compare apples to apples throughout our entire
    process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '![Header image](../Images/d7c978b124395772dd8df1743b133d2b.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
- en: 'Thus far, in the previous 2 posts, we have:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Introduced Scikit-learn piplines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated their basic usage by creating and comparing some pipelines
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduced grid search
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrated how pipelines and grid search work together by using grid search
    to find optimized hyperparameters, which was then apply to an embedded pipeline
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s what we plan to do moving forward:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will be using grid search to optimize models built from a number
    of different types estimators, which we will then compare
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the follow-up post, we will pivot toward using automated machine learning
    techniques to assist in the optimization of model hyperparameters, the end result
    of which will be an automatically generated, optimized Scikit-learn pipeline script
    file, courtesy of [TPOT](https://github.com/EpistasisLab/tpot)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There won't be much to re-explain this time; I recommend that you read [the
    first post in this series](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)
    to get a gentle introduction to pipelines in Scikit-learn, and [the second post
    in this series](/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html)
    for an overview of integrating grid search into your pipelines. What we will now
    do is build a series of pipelines of different estimators, using grid search for
    hyperparameter optimization, after which we will compare these various apples
    and oranges to determine the most accurate ("best") model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: The code below is well-commented, and if you have read the first 2 installments
    should be easy to follow.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is a lot of opportunity for refactoring here. For example, each
    pipeline is defined explicitly, whereas a simple function could be used as a generator
    instead; the same goes for grid search objects. The longer form, again, hopefully
    allows for some better apples to apples comparisons in our next post.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Let's try it out.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And here''s the output:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note, importantly, that after we fit our estimators, we then tested each resulting
    model with best parameters of each of the 6 grid searches on our test dataset.
    This is not something we did last post, though we were comparing different models
    to one another, but given the introduction to other concepts the otherwise crucial
    step of comparing different models on previously unseen test data was overlooked
    until now. And our example proves why this step is necessary.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Shown above, the model which performed the "best" on our training data (highest
    training accuracy) was the support vector machine (without PCA), with the linear
    kernel and C value of 3 ([controlling the amount of regularization](http://scikit-learn.org/stable/auto_examples/svm/plot_svm_scale_c.html)),
    which learned how to accurately classify 96.7% of training instances. **However**,
    the model which performed best on the test data (the 20% of our dataset previously
    unseen to all models until after they were trained) was the random forest (without
    PCA), using the Gini criterion, minimum samples split of 2, max depth of 3, and
    minimum samples per leaf of 2, which managed to accurately classify 100% of the
    unseen data instances. Note that this model had a lower training accuracy of 94.2%.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: So, beyond seeing how we can mix and match a variety of different estimator
    types, grid search parameter combinations, and data transformations, as well as
    how to accurately compare the trained models, it should be apparent that evaluating
    different models should always include testing them on previously unseen holdout
    data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Sick of pipelines yet? Next time we'll look at an alternative approach to automating
    their construction.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[Managing Machine Learning Workflows with Scikit-learn Pipelines Part 1: A
    Gentle Introduction](/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Managing Machine Learning Workflows with Scikit-learn Pipelines Part 2: Integrating
    Grid Search](/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Genetic Algorithm for Optimizing Recurrent Neural Networks](/2018/01/genetic-algorithm-optimizing-recurrent-neural-network.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Manage Multiple Inheritance in Python](https://www.kdnuggets.com/2022/03/manage-multiple-inheritance-python.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在Python中管理多重继承](https://www.kdnuggets.com/2022/03/manage-multiple-inheritance-python.html)'
- en: '[A New Way of Managing Deep Learning Datasets](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理深度学习数据集的新方法](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
- en: '[Managing Your Reusable Python Code as a Data Scientist](https://www.kdnuggets.com/2021/06/managing-reusable-python-code-data-scientist.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[作为数据科学家管理可重用的Python代码](https://www.kdnuggets.com/2021/06/managing-reusable-python-code-data-scientist.html)'
- en: '[4 Steps for Managing a Data Science Project](https://www.kdnuggets.com/2022/05/4-steps-managing-data-science-project.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理数据科学项目的4个步骤](https://www.kdnuggets.com/2022/05/4-steps-managing-data-science-project.html)'
- en: '[Managing Model Drift in Production with MLOps](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用MLOps管理生产中的模型漂移](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)'
