# 标准模型拟合方法的简明概述

> 原文：[https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html](https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html)

为了说明不同方法在估计模型参数时的差异，让我们来看一个具体的例子：普通最小二乘（OLS）线性回归。下面的插图将作为快速提醒，以回顾简单线性回归模型的不同组成部分：

![Simple regresion](../Images/021416dd372001b2ebcefd88bc666f0c.png)

在普通最小二乘（OLS）线性回归中，我们的目标是找到最小化垂直偏差的直线（或超平面）。换句话说，我们将最佳拟合直线定义为最小化目标变量（y）与我们预测输出之间的平方误差（SSE）或均方误差（MSE）的直线，这些目标变量和预测输出遍及我们数据集中所有样本 *i* 的大小 *n*。

![SSE](../Images/fd700aecb123fddccbe1855cb4f39dc2.png)

现在，我们可以使用以下方法之一来实现一个线性回归模型，以执行普通最小二乘回归：

+   解析地求解模型参数（封闭形式方程）

+   使用优化算法（梯度下降法、随机梯度下降法、牛顿法、单纯形法等）

### 1) 正规方程（封闭形式解）

对于“小型”数据集，封闭形式解可能（应）更受青睐——如果计算（“昂贵的”）矩阵逆不成问题。对于非常大的数据集，或 XTX 的逆可能不存在的数据集（矩阵不可逆或奇异，例如在完美多重共线性的情况下），则应优先考虑 GD 或 SGD 方法。线性函数（线性回归模型）定义为：

![Linear model](../Images/18f72e806df0ea656621fbaa5fcd6263.png)

其中 *y* 是响应变量，*x* 是一个 *m* 维样本向量，*w* 是权重向量（系数向量）。请注意，*w0* 表示模型的 y 轴截距，因此 *x0=1*。使用封闭形式解（正规方程），我们可以计算模型的权重如下：

![Closed form](../Images/390bdb586f5ea1904be897034215580a.png)

### 2) 梯度下降法（GD）

使用梯度下降法（GD）优化算法，权重在每次训练轮次（= 遍历训练数据集）后逐步更新。

成本函数 *J(⋅)*，即平方误差和（SSE），可以写作：

![J](../Images/9971ba71f72a930fafe670ba77d3c459.png)

权重更新的大小和方向是通过在成本梯度的相反方向上迈进一步来计算的

![dw](../Images/2a8a0c5f09633d23aa090c7a43d83736.png)

其中 *η* 是学习率。权重在每次训练轮次后通过以下更新规则进行更新：

![w_upd](../Images/97ab06d282b695cae3a47b50bd05bbdd.png)

其中 Δw 是一个包含每个权重系数*w*的权重更新的向量，计算方法如下：

![w_upd 解释](../Images/b17273c5b1d049e3c2a73f800eb790f8.png)

本质上，我们可以将GD优化想象成一个想要从山顶（成本函数）爬下到山谷（成本最小值）的徒步旅行者（权重系数），每一步都由斜率（梯度）和旅行者的腿长（学习率）决定。考虑一个只有一个权重系数的成本函数，我们可以如下说明这一概念：

![GD优化](../Images/9ad85c8821ba0a5eef7027278d573d00.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT

* * *

### 更多相关主题

+   [使用标准差在Python中去除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)

+   [开发用于分析跟踪的开放标准](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)

+   [k-means聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)

+   [机器学习中的替代特征选择方法](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)

+   [Python字符串方法](https://www.kdnuggets.com/2022/12/python-string-methods.html)

+   [每个程序员都应该知道的11个Python魔法方法](https://www.kdnuggets.com/11-python-magic-methods-every-programmer-should-know)
