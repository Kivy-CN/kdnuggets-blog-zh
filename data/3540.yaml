- en: 7 common mistakes when doing Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行机器学习时的 7 个常见错误
- en: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html/2](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html/2](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html/2)'
- en: '**4\. Use high variance model when n<<p**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 当 n<<p 时使用高方差模型**'
- en: SVM is one of the most popular off-the-shelf modeling algorithms and one of
    its most powerful features is the ability to fit the model with different kernels.
    SVM kernels can be thought of as a way to automatically combine existing features
    to form a richer feature space. Since this power feature comes almost for free,
    most practitioners by default use kernel when training a SVM model. However, when
    the data has n<<p (number of samples << number of features) -- common in industries
    like medical data -- the richer feature space implies a much higher risk to overfit
    the data. In fact, high variance models should be avoided entirely when n<<p.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）是最流行的现成建模算法之一，其最强大的特性之一是能够使用不同的核函数来拟合模型。SVM 的核函数可以看作是自动组合现有特征以形成更丰富特征空间的一种方式。由于这种强大的功能几乎是免费的，因此大多数从业者在训练
    SVM 模型时默认使用核函数。然而，当数据的 n<<p（样本数量 << 特征数量）——在医疗数据等行业中很常见——时，更丰富的特征空间意味着更高的过拟合风险。实际上，当
    n<<p 时，高方差模型应该完全避免。
- en: '**5\. L1/L2/... regularization without standardization**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 没有标准化的 L1/L2/... 正则化**'
- en: Applying L1 or L2 to penalize large coefficients is a common way to regularize
    linear or logistic regression. However, many practitioners are not aware of the
    importance of standardizing features before applying those regularization.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对线性或逻辑回归施加 L1 或 L2 惩罚大系数是一种常见的正则化方法。然而，许多从业者没有意识到在应用这些正则化之前标准化特征的重要性。
- en: Returning to fraud detection, imagine a linear regression model with a transaction
    amount feature. Without regularization, if the unit of transaction amount is in
    dollars, the fitted coefficient is going to be around 100 times larger than the
    fitted coefficient if the unit were in cents. With regularization, as the L1 /
    L2 penalize larger coefficient more, the transaction amount will get penalized
    more if the unit is in dollars. Hence, the regularization is biased and tend to
    penalize features in smaller scales. To mitigate the problem, standardize all
    the features and put them on equal footing as a preprocessing step.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 回到欺诈检测的例子，假设有一个具有交易金额特征的线性回归模型。如果没有正则化，当交易金额的单位是美元时，拟合的系数将比单位为美分时的拟合系数大约大 100
    倍。使用正则化时，由于 L1 / L2 对较大系数的惩罚更多，因此如果单位是美元，交易金额会受到更多的惩罚。因此，正则化存在偏倚，倾向于惩罚较小规模的特征。为了解决这个问题，作为预处理步骤，标准化所有特征并使其具有相同的基础。
- en: '**6\. Use linear model without considering multi-collinear predictors**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. 使用线性模型而不考虑多重共线性预测变量**'
- en: Imagine building a linear model with two variables X1 and X2 and suppose the
    ground truth model is Y=X1+X2\. Ideally, if the data is observed with small amount
    of noise, the linear regression solution would recover the ground truth. However,
    if X1 and X2 are collinear, to most of the optimization algorithms' concerns,
    Y=2*X1, Y=3*X1-X2 or Y=100*X1-99*X2 are all as good. The problem might not be
    detrimental as it doesn't bias the estimation. However, it does make the problem
    ill-conditioned and make the coefficient weight uninterpretable.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 想象构建一个包含两个变量 X1 和 X2 的线性模型，假设真实模型是 Y=X1+X2。理想情况下，如果数据观察时噪声很小，线性回归解决方案将恢复真实模型。然而，如果
    X1 和 X2 存在共线性，则对大多数优化算法而言，Y=2*X1、Y=3*X1-X2 或 Y=100*X1-99*X2 都是同样有效的。这个问题可能不会对估计造成偏差，但确实使问题变得条件不良，并使系数权重无法解释。
- en: '**7\. Interpreting absolute value of coefficients from linear or logistic regression
    as feature importance**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. 从线性或逻辑回归中解读系数的绝对值作为特征重要性**'
- en: Because many off-the-shelf linear regressor returns p-value for each coefficient,
    many practitioners believe that for linear models, the bigger the absolute value
    of the coefficient, the more important the corresponding feature is. This is rarely
    true as (a) changing the scale of the variable changes the absolute value of the
    coefficient (b) if features are multi-collinear, coefficients can shift from one
    feature to others. Also, the more features the data set has, the more likely the
    features are multi-collinear and the less reliable to interpret the feature importance
    by coefficients.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多现成的线性回归模型返回每个系数的p值，许多从业者认为，对于线性模型来说，系数的绝对值越大，对应的特征就越重要。这种情况很少发生，因为（a）改变变量的尺度会改变系数的绝对值，（b）如果特征之间存在多重共线性，系数可能会从一个特征转移到其他特征。此外，数据集中的特征越多，特征之间存在多重共线性的可能性就越大，通过系数解释特征重要性也就越不可靠。
- en: 'So there you go: 7 common mistakes when doing ML in practice. This list is
    not meant to be exhaustive but merely to provoke the reader to consider modeling
    assumptions that may not be applicable to the data at hand. To achieve the best
    model performance, it is important to pick the modeling algorithm that makes the
    most fitting assumptions -- not just the one you’re most familiar with.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这里是：实际应用机器学习时的7个常见错误。这个列表并不是详尽无遗的，而只是为了促使读者考虑可能不适用于当前数据的建模假设。为了获得最佳的模型性能，选择最适合假设的建模算法非常重要——而不仅仅是你最熟悉的算法。
- en: 'Original: [Machine Learning Done Wrong](http://ml.posthaven.com/machine-learning-done-wrong)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 原文：[机器学习中的常见错误](http://ml.posthaven.com/machine-learning-done-wrong)
- en: '[![Cheng-Tao Chu](../Images/67e7fc5d72f45623fe838afafbe01821.png) Cheng-Tao
    Chu](https://www.linkedin.com/pub/cheng-tao-chu/4/80/783) is a Director of Analytics
    at Codecademy. Specialties: data engineering and machine learning. Formerly: Google,
    LinkedIn and Square.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Cheng-Tao Chu](../Images/67e7fc5d72f45623fe838afafbe01821.png) Cheng-Tao
    Chu](https://www.linkedin.com/pub/cheng-tao-chu/4/80/783) 是 Codecademy 的分析总监。专长：数据工程和机器学习。曾任职于：Google、LinkedIn
    和 Square。'
- en: '**Related:**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[11 Clever Methods of Overfitting and how to avoid them](/2015/01/clever-methods-overfitting-avoid.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11种聪明的过拟合方法及如何避免它们](/2015/01/clever-methods-overfitting-avoid.html)'
- en: '[Big Data accelerates medical research? Or not?](/2014/10/big-data-accelerates-medical-research-or-not.html)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大数据是否加速了医学研究？还是没有？](/2014/10/big-data-accelerates-medical-research-or-not.html)'
- en: '[10 things statistics taught us about big data analysis](/2015/02/10-things-statistics-big-data-analysis.html)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学教会我们关于大数据分析的10件事](/2015/02/10-things-statistics-big-data-analysis.html)'
- en: '* * *'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全领域的职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT领域'
- en: '* * *'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免这些每个AI新手都会犯的5个常见错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个常见的数据科学错误及如何避免](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
- en: '[How To Tackle 3 Common Machine Learning Challenges](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何应对3个常见的机器学习挑战](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Mistakes That Could Be Affecting the Accuracy of Your Data Analytics](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可能影响你数据分析准确性的3个错误](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
- en: '[Software Mistakes and Tradeoffs: New book by Tomasz Lelek and…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件错误与权衡：Tomasz Lelek等人的新书](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
