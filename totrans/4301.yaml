- en: How to Begin Your NLP Journey
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何开始你的NLP之旅
- en: 原文：[https://www.kdnuggets.com/2021/03/begin-nlp-journey.html](https://www.kdnuggets.com/2021/03/begin-nlp-journey.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/03/begin-nlp-journey.html](https://www.kdnuggets.com/2021/03/begin-nlp-journey.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/), Data Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/)，数据科学家**'
- en: '![](../Images/f528880f08e3fdfecac0452c85796b63.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f528880f08e3fdfecac0452c85796b63.png)'
- en: Photo by [PNG Design](https://unsplash.com/@_pngdesign?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[PNG Design](https://unsplash.com/@_pngdesign?utm_source=medium&utm_medium=referral)在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)提供
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Natural Language Processing (NLP) **is one of the most exciting fields in
    Artificial Intelligence. It allows machines to process and understand human language
    in a variety of ways, and it’s triggering a revolution in the way we interact
    with systems and technology.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然语言处理（NLP）**是人工智能领域中最令人兴奋的领域之一。它允许机器以多种方式处理和理解人类语言，并引发了我们与系统和技术互动方式的革命。'
- en: In a [previous post](https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1) I
    talked about NLP, its real-world applications, and some of its core concepts.
    Now I want to show you that NLP is as real as it gets, and anyone can start learning
    it. How? Let’s start with a simple text, and perform some Exploratory Data Analysis
    (EDA) around it using some NLP techniques. This way we can make sense out of data
    with simple and powerful tools before getting ourselves busy with any model or
    more complex tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在[上一篇文章](https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1)中，我讲述了NLP、它的实际应用和一些核心概念。现在我想向你展示NLP有多真实，任何人都可以开始学习它。怎么做呢？让我们从一个简单的文本开始，使用一些NLP技术进行一些探索性数据分析（EDA）。这样，我们可以使用简单而强大的工具理解数据，然后再忙于模型或更复杂的任务。
- en: Define your text
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义你的文本
- en: 'Stephen Hawking once said:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 史蒂芬·霍金曾说：
- en: “Artificial Intelligence (AI) is likely to be either the best or the worst thing
    to happen to humanity”
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “人工智能（AI）可能是人类发生的最好或最糟糕的事情”
- en: 'I couldn’t agree more with him, and time will tell what will actually happen.
    Nevertheless, this is a proper sentence to test some NLP techniques. To do that,
    let’s start by saving the phrase as a variable called “text”:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我完全同意他的观点，时间会证明实际发生的事情。然而，这句话是测试一些NLP技术的合适句子。为此，让我们首先将这句话保存为一个名为“text”的变量：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Using the **langdetect **library, we can check its language, and find out the
    probability of being written in that language:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**langdetect**库，我们可以检查其语言，并找出其用该语言写的概率：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/ced664c8874856d6715a505f8812cc2f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ced664c8874856d6715a505f8812cc2f.png)'
- en: With a certainty of more than 99,9% we can state that this phrase is written
    in English language. You should also consider using [**spelling check functionalities**](https://textblob.readthedocs.io/en/dev/quickstart.html) to
    correct any grammatical mistakes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以以超过99.9%的确定性声明，这句话是用英语写的。你还应该考虑使用[**拼写检查功能**](https://textblob.readthedocs.io/en/dev/quickstart.html)来纠正任何语法错误。
- en: What about the number of characters?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 那么字符的数量呢？
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/662ca47f2ad17ff6af58344750b3298c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/662ca47f2ad17ff6af58344750b3298c.png)'
- en: We have 102 characters, including blank spaces. And the number of distinct characters?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有102个字符，包括空格。不同字符的数量是多少？
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/a825379189ff772e1698d72c6a8aef08.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a825379189ff772e1698d72c6a8aef08.png)'
- en: 'Let’s take a look at them:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这些：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/edb7edf6d11613f5ec1f7d159abe9b03.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/edb7edf6d11613f5ec1f7d159abe9b03.png)'
- en: There’s something interesting here. We’re not only counting the non-alphanumerical
    characters like ‘(‘ and ‘.’, but also the blank spaces, and what’s even more,
    capitalized letters are considered different characters in relation to the lowercased
    ones.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些有趣的地方。我们不仅在计算像‘(’和‘.’这样的非字母数字字符，还包括空格，更重要的是，大小写字母被视为不同的字符。
- en: Tokenization
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词汇化
- en: 'Tokenization is the process of segmenting running text into sentences and words.
    In essence, it’s the task of cutting a text into pieces called *tokens. *We use
    the **NLTK** library to perform this task:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇化是将连续文本分割成句子和单词的过程。实质上，这是将文本切割成称为*tokens*的片段的任务。我们使用**NLTK**库来执行此任务：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/1ecfc8c6d66f3cd3950c478327ab10cb.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ecfc8c6d66f3cd3950c478327ab10cb.png)'
- en: 'We can see that tokenization produces a list of words:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，词汇化产生了一个词汇列表：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/61d9fdc5bca2c694e541f2b9ebc7fdae.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61d9fdc5bca2c694e541f2b9ebc7fdae.png)'
- en: Which means we can call elements within it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以调用其中的元素。
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/eddf2e0504f2b5d917589a0d1d4c76b4.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eddf2e0504f2b5d917589a0d1d4c76b4.png)'
- en: How many tokens we have?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有多少个token？
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/3a1dde1027f391f13211aa5d5445b546.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a1dde1027f391f13211aa5d5445b546.png)'
- en: And unique tokens?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 那么独特的tokens呢？
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/77e2dc39e50df31761e5a44507199202.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77e2dc39e50df31761e5a44507199202.png)'
- en: 'Now we can calculate a measure related to the *lexical richness* of the text:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算一个与文本的*词汇丰富性*相关的指标：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/979fe66bff745f3af338d3e07b14ee26.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/979fe66bff745f3af338d3e07b14ee26.png)'
- en: This shows that the number of distinct words is 85,7% of the total number of
    words.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明不同词汇的数量占总词汇数量的85.7%。
- en: Lowercase & punctuation
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小写和标点
- en: 'Now let’s lowercase the text to standardize characters and for future stopwords
    removal:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将文本转换为小写，以标准化字符，并为未来的停用词移除做准备：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/f8673a933d9289a62128043792ce60da.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8673a933d9289a62128043792ce60da.png)'
- en: 'Next, we remove non-alphanumerical characters:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们去除非字母数字字符：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/68e85988a65ac9f17530ba8e14aac90a.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68e85988a65ac9f17530ba8e14aac90a.png)'
- en: 'Let’s visualize the cumulative frequency distribution of words:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化词汇的累积频率分布：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/62ebff0e15f54dfd2196300045eac5a1.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62ebff0e15f54dfd2196300045eac5a1.png)'
- en: We can see that the words “to” and “the” appear most often, but they don’t really
    add information to the text. They are what’s known as *stopwords*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，“to”和“the”这些词出现得最频繁，但它们实际上并未向文本添加信息。它们被称为*停用词*。
- en: Stopwords removal
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 停用词移除
- en: This process includes getting rid of common language articles, pronouns and
    prepositions such as “and”, “the” or “to” in English. In this process some very
    common words that appear to provide little or no value to the NLP objective are
    filtered and excluded from the text to be processed, hence removing widespread
    and frequent terms that are not informative about the corresponding text.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程包括去除常见的语言文章、代词和介词，如英语中的“and”、“the”或“to”。在此过程中，一些非常常见的词被认为对NLP目标贡献甚微或没有价值，因此从待处理的文本中被过滤和排除，从而去除那些没有提供有用信息的广泛和频繁出现的术语。
- en: 'First, we need to create a list of stopwords and filter them our from our list
    of tokens:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个停用词列表，并将其从我们的词汇列表中过滤掉：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/8c928a8d5842671ad506ac7ae8ee63a5.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c928a8d5842671ad506ac7ae8ee63a5.png)'
- en: 'We’ll use this list from NLTK library, but bear in mind that you can create
    your own set of stop words. Let’s look for the word “the” in the list:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用NLTK库中的这个列表，但请记住，你可以创建自己的停用词集。让我们在列表中查找“the”这个词：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/9382528bc581caf9b3b88402b63e1d57.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9382528bc581caf9b3b88402b63e1d57.png)'
- en: 'Now, let’s clean our text from these stopwords:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从这些停用词中清理文本：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/c9b829e69f0f7c887cf309dc2573fe83.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9b829e69f0f7c887cf309dc2573fe83.png)'
- en: 'We can see that the words “is”, “to”, “be”, “the” and “or” were removed from
    our text. Let’s update the cumulative frequency distribution of words:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，词汇“is”、“to”、“be”、“the”和“or”已从文本中删除。让我们更新词汇的累积频率分布：
- en: '![](../Images/a46199b961de03dcd9e2161bae951c3f.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a46199b961de03dcd9e2161bae951c3f.png)'
- en: Removing stop words should be done in a very conscious way, since it can bring
    huge problems while performing other tasks like sentiment analysis. If a word’s
    context is affected (e.g. by removing the word ‘not’, which is a negation of a
    component), that action can alter the meaning of the passage.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 停用词移除应以非常谨慎的方式进行，因为它可能在执行其他任务时带来巨大问题，例如情感分析。如果一个词的上下文受到影响（例如，去除“not”这样的词，这是一种否定成分），这种操作可能会改变段落的意义。
- en: Beyond this example, it could be necessary to deal with other types of characteristics
    like [**contractions** (like the word “doesn’t”, which should be expanded](https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/)),
    or [**accents and diacritics** (like the words “cliché” or “naïve”, which should
    be normalized by removing their diacritics)](https://nlp.stanford.edu/IR-book/html/htmledition/accents-and-diacritics-1.html).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个例子，可能还需要处理其他类型的特征，例如 [**缩写**（如“doesn’t”，应展开](https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/)）或
    [**重音和变音符号**（如“cliché”或“naïve”，应通过去除变音符号来规范化）](https://nlp.stanford.edu/IR-book/html/htmledition/accents-and-diacritics-1.html)。
- en: Regular Expressions
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正则表达式
- en: '[Regular expressions](https://docs.python.org/3/howto/regex.html) (called REs,
    or RegExes) are a tiny, highly specialized programming language embedded inside
    Python and made available through the **re** module. By using them, you specify
    the rules for the set of possible strings that you want to match. You can ask
    questions such as “Does this string match the pattern?”, or “Is there a match
    for the pattern anywhere in this string?”.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[正则表达式](https://docs.python.org/3/howto/regex.html)（简称 REs 或 RegExes）是嵌入在 Python
    中的一个微小且高度专业化的编程语言，通过**re**模块提供。使用它们，你可以指定要匹配的字符串集的规则。你可以提出诸如“这个字符串是否符合模式？”或“这个字符串中是否有符合模式的匹配项？”等问题。'
- en: 'For example, let’s search for words ending with “st”:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们搜索以“st”结尾的单词：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/a0f52b5a704a95407fcc1eb4fc132e55.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0f52b5a704a95407fcc1eb4fc132e55.png)'
- en: 'Or count the number of vowels in the first word (“artificial”):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 或计算第一个单词（“artificial”）中的元音字母数量：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/87cb03271ef06cde7b57f7147edb2a9f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87cb03271ef06cde7b57f7147edb2a9f.png)'
- en: 'You can even modify texts based on conditions. For example, replace letters
    “ce” with letter “t” in the second word (“intelligence”):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以根据条件修改文本。例如，将第二个单词（“intelligence”）中的字母“ce”替换为字母“t”：
- en: '[PRE19]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/f005edc4ceacb22e5a7e2d7bb584f86a.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f005edc4ceacb22e5a7e2d7bb584f86a.png)'
- en: You can find more examples of regular expressions following [this link](https://www.w3schools.com/python/python_regex.asp).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过 [这个链接](https://www.w3schools.com/python/python_regex.asp) 找到更多正则表达式的例子。
- en: Conclusion
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: We’ve only scratched the surface of all the possible and more complex NLP techniques
    out there. And it’s not just structured texts that you may want to analyze, but
    all that data generated from conversations, declarations or even tweets, which
    are examples of unstructured data. **Unstructured data** doesn’t fit neatly into
    the traditional row and column structure of relational databases, and represent
    the vast majority of data available in the actual world. It is messy and hard
    to manipulate.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅仅触及了所有可能和更复杂的 NLP 技术的表面。你可能不仅想分析结构化文本，还要处理从对话、声明甚至推文中生成的所有数据，这些都是非结构化数据的例子。**非结构化数据**无法
    neatly 放入传统的行列结构的关系数据库中，代表了现实世界中绝大多数的数据。它是混乱的且难以操作。
- en: NLP is seriously booming thanks to the huge improvements in the access to data
    and the increase in computational power, which allow us to achieve meaningful
    results in areas like healthcare, media, finance and human resources, among others.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: NLP因数据访问的巨大改进和计算能力的提升而迅速发展，这使我们能够在医疗、媒体、金融和人力资源等领域取得有意义的成果。
- en: My suggestion is:** learn about NLP.** Try different data sources and techniques.
    Experiment, fail and improve yourself. This discipline will impact every possible
    industry, and we are likely to reach a level of advancement in the coming years
    that will blow our minds.
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的建议是：**学习 NLP。** 尝试不同的数据源和技术。实验、失败并提升自己。这一学科将影响所有可能的行业，我们很可能在未来几年达到一种令人惊叹的进展水平。
- en: '**Interested in these topics? Follow me on **[**Linkedin**](https://www.linkedin.com/in/lopezyse/)** or **[**Twitter**](https://twitter.com/lopezyse)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**对这些话题感兴趣？关注我在**[**Linkedin**](https://www.linkedin.com/in/lopezyse/)**或**[**Twitter**](https://twitter.com/lopezyse)'
- en: '**Bio: [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/)** is an experienced
    professional with a solid international background acquired in different industries
    (capital markets, biotechnology, software, consultancy, government, agriculture).
    Always a team member. Skilled in Business Management, Analytics, Finance, Risk,
    Project Management and Commercial Operations. MS in Data Science and Corporate
    Finance.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/)** 是一位经验丰富的专业人士，拥有在不同领域（资本市场、生物技术、软件、咨询、政府、农业）获得的国际背景。始终是团队成员。擅长商业管理、分析、金融、风险、项目管理和商业运营。拥有数据科学和公司金融硕士学位。'
- en: '[Original](https://towardsdatascience.com/how-to-begin-your-nlp-journey-5dc6734dfb43).
    Reposted with permission.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/how-to-begin-your-nlp-journey-5dc6734dfb43)。经许可转载。'
- en: '**Related:**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Exploratory Data Analysis on Steroids](/2020/07/exploratory-data-analysis-steroids.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[强化版探索性数据分析](/2020/07/exploratory-data-analysis-steroids.html)'
- en: '[Getting Started with 5 Essential Natural Language Processing Libraries](/2021/02/getting-started-5-essential-nlp-libraries.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用5个必备的自然语言处理库](/2021/02/getting-started-5-essential-nlp-libraries.html)'
- en: '[Natural Language Processing Pipelines, Explained](/2021/03/natural-language-processing-pipelines-explained.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理管道解析](/2021/03/natural-language-processing-pipelines-explained.html)'
- en: More On This Topic
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Kickstart Your NLP Journey with These 5 Free Courses](https://www.kdnuggets.com/kickstart-your-nlp-journey-with-these-5-free-courses)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这5个免费课程启动你的NLP之旅](https://www.kdnuggets.com/kickstart-your-nlp-journey-with-these-5-free-courses)'
- en: '[Map out your journey towards SAS Certification](https://www.kdnuggets.com/2022/11/sas-map-journey-towards-sas-certification.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[绘制通向SAS认证的路线图](https://www.kdnuggets.com/2022/11/sas-map-journey-towards-sas-certification.html)'
- en: '[Make Quantum Leaps in Your Data Science Journey](https://www.kdnuggets.com/2023/02/make-quantum-leaps-data-science-journey.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在你的数据科学之旅中取得突破性进展](https://www.kdnuggets.com/2023/02/make-quantum-leaps-data-science-journey.html)'
- en: '[Accelerate Your Machine Learning Journey with Uplimit''s Metaflow…](https://www.kdnuggets.com/2023/10/uplimit-accelerate-your-machine-learning-journey-metaflow-mastery-course)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过Uplimit的Metaflow加速你的机器学习之旅](https://www.kdnuggets.com/2023/10/uplimit-accelerate-your-machine-learning-journey-metaflow-mastery-course)'
- en: '[Supercharge Your AI Journey! Join Uplimit''s Free Building AI…](https://www.kdnuggets.com/2024/01/uplimit-supercharge-your-ai-journey-openai-course)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超级充能你的AI之旅！加入Uplimit的免费AI构建课程](https://www.kdnuggets.com/2024/01/uplimit-supercharge-your-ai-journey-openai-course)'
- en: '[How ML Model Explainability Accelerates the AI Adoption Journey for…](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型解释性如何加速AI采纳之旅](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
