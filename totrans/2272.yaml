- en: What is K-Means Clustering and How Does its Algorithm Work?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 K-Means 聚类及其算法如何工作？
- en: 原文：[https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/be51730398ddbdd8cabde734b014732e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 K-Means 聚类及其算法如何工作？](../Images/be51730398ddbdd8cabde734b014732e.png)'
- en: Image from Bing Image Creator
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 Bing 图像生成器
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Fundamentally, there are four types of machine learning algorithms; supervised
    algorithms, semi-supervised algorithms, unsupervised algorithms and reinforcement
    learning algorithms. Supervised algorithms are those that work on data that has
    labels. Semi-supervised is where part of the data is labeled and another part
    is not. Unsupervised is where the data doesn’t have labels. Reinforcement learning
    is a type of machine learning where we have an agent that works towards a certain
    goal and does it through trial and error. The agent gets rewarded when correct
    and gets penalized when wrong.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上说，机器学习算法有四种类型；监督算法、半监督算法、无监督算法和强化学习算法。监督算法是那些在具有标签的数据上工作的算法。半监督算法是数据的一部分有标签，另一部分没有标签。无监督算法是数据没有标签的情况。强化学习是一种机器学习类型，其中有一个代理通过试错来实现特定目标。当代理做对时会获得奖励，做错时会受到惩罚。
- en: Our focus is on an unsupervised machine learning algorithm, K-Means clustering
    algorithm in particular.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的重点是无监督的机器学习算法，特别是 K-Means 聚类算法。
- en: K-Means Clustering
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means 聚类
- en: K-Means is an unsupervised machine learning algorithm that assigns data points
    to one of the K clusters. Unsupervised, as mentioned before, means that the data
    doesn’t have group labels as you’d get in a supervised problem. The algorithm
    observes the patterns in the data and uses that to place each data point into
    a group with similar characteristics. Of course, there are other algorithms for
    solving clustering problems such as DBSCAN, Agglomerative clustering, KNN, and
    others, but K-Means is somewhat more popular in comparison to other approaches.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: K-Means 是一种无监督的机器学习算法，它将数据点分配到 K 个簇之一。如前所述，无监督意味着数据没有像监督学习中那样的组标签。该算法观察数据中的模式，并利用这些模式将每个数据点放入具有相似特征的组中。当然，还有其他解决聚类问题的算法，如
    DBSCAN、层次聚类、KNN 等，但与其他方法相比，K-Means 相对更受欢迎。
- en: The K refers to the distinct groupings into which the data points are placed.
    If K is 3, then the data points will be split into 3 clusters. If 5, then we’ll
    have 5 clusters.. More on this later.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: K 代表将数据点划分为的不同分组。如果 K 是 3，那么数据点将被分为 3 个簇。如果是 5，那么我们将有 5 个簇。稍后会详细介绍。
- en: Applications of K-Means
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means 的应用
- en: 'There are a myriad ways in which we can apply clustering to solve real world
    problems. Below are a few examples of the applications:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过多种方式应用聚类来解决现实世界的问题。以下是一些应用示例：
- en: '**Clustering customers**: Companies can use clustering to group their customers
    for better target marketing and understanding their customer base.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户聚类**：公司可以使用聚类来将客户分组，以便更好地进行目标营销和了解客户基础。'
- en: '**Document classification**: Group documents based on the topics or key words
    in the content.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档分类**：根据内容中的主题或关键词对文档进行分组。'
- en: '**Image segmentations**: Clustering image pixels before image recognition.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分割**：在进行图像识别之前，对图像像素进行聚类。'
- en: '**Grouping students based on their performance**: You could cluster them into
    top performers, average performers, and use that to improve learning experience.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**根据学生表现进行分组**：你可以将他们分为顶尖表现者、平均表现者，并利用这些分组来改善学习体验。'
- en: How K-Means Algorithms Work
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-Means 算法如何工作
- en: The algorithm runs an initial iteration where the data points are randomly placed
    into groups, whose central point is known as centroid is calculated. The euclidean
    distance of each data point to the centroids is calculated, and if the distance
    of a point is higher than to another centroid, the point is reassigned to the
    ‘other’ centroid. When this happens, the algorithm will run another iteration
    and the process continues until all groupings have the minimum within group variance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 算法首先进行初始迭代，其中数据点被随机分配到各组，计算出每组的中心点（称为质心）。计算每个数据点到质心的欧氏距离，如果某点到某个质心的距离大于到另一个质心的距离，则该点会被重新分配到“另一个”质心。当这种情况发生时，算法将进行另一轮迭代，直到所有分组的组内方差达到最小。
- en: What we mean by having a minimum variability within a group is that the characteristics
    of observations in a group should be as similar as possible.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所说的“组内最小变异性”是指组内观察值的特征应尽可能相似。
- en: Imagine a dataset with two variables plotted as below. The variables could be
    the height and weight of individuals. If we had a third variable like age, then
    we would have a 3-D diagram, but for now, let’s stick to the 2-D diagram below.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个包含两个变量的数据集，如下所示。这些变量可以是个人的身高和体重。如果我们有一个第三个变量，如年龄，那我们就会有一个 3-D 图，但现在我们还是用下面的
    2-D 图。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/01fcf1cf4e0542a541c874ceef490e86.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 K-Means 聚类？其算法如何工作？](../Images/01fcf1cf4e0542a541c874ceef490e86.png)'
- en: 'Step 1 : Initialization'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：初始化
- en: From the above diagram we can spot three clusters. When fitting our model, we
    can randomly assign k=3\. This simply means we are seeking to split the data points
    into three groupings.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图中我们可以看到三个簇。在拟合模型时，我们可以随机选择 k=3。这意味着我们寻求将数据点分为三个分组。
- en: In the initial iteration, the K centroids are randomly selected in the example
    below.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始迭代中，下面的示例中 K 个质心是随机选择的。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/171e76e49bfde67cdab79bb665201172.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 K-Means 聚类？其算法如何工作？](../Images/171e76e49bfde67cdab79bb665201172.png)'
- en: You can specify the number of K-Clusters that the algorithm should group the
    data points into, however, there’s a better approach to this. We’ll dive into
    how to choose K later.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以指定算法将数据点分组为的 K 个簇的数量，但还有一种更好的方法。我们稍后会详细讲解如何选择 K。
- en: 'Step 2 : Assign points to the one of the K centroids'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：将点分配给 K 个质心中的一个
- en: Once the centroids have been selected, each data point is assigned to the closest
    centroid, based on the euclidean distance of the point to the closest centroid.
    This could result in the groupings shown in the graph below.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择了质心，每个数据点将基于该点到最近质心的欧氏距离被分配到最近的质心。这可能会导致下图所示的分组。
- en: Note that other types of distance measures can be used as manhattan distance,
    spearman correlation distance, and Pearson correlations distance as an alternative
    to euclidean, but the classical ones are euclidean and manhattan.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，除了欧氏距离外，还可以使用其他类型的距离测量方法，如曼哈顿距离、斯皮尔曼相关距离和皮尔逊相关距离，但经典的距离测量方法是欧氏距离和曼哈顿距离。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/b2c29636c905add1da7cd48e797c50e9.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 K-Means 聚类？其算法如何工作？](../Images/b2c29636c905add1da7cd48e797c50e9.png)'
- en: 'Step 3 : Recompute the centroids'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：重新计算质心
- en: After the first round of groupings, new centre points are recalculated again
    and this will necessitate a re-assignment of the points. The graph below gives
    an example of how the new groupings could potentially be, and notice how some
    points have been moved into new clusters.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次分组后，新的中心点会重新计算，这会要求重新分配点。下面的图示例显示了新的分组可能是什么样的，并注意到一些点已经移动到新的簇中。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/5662ccca682a3d405e54f85d4520ac1a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 K-Means 聚类？其算法如何工作？](../Images/5662ccca682a3d405e54f85d4520ac1a.png)'
- en: Iterate
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代
- en: The process in steps 2 and 3 is repeated until we get to a point where there
    are no more reassignments of the data points or we reach the maximum number of
    iterations. The resulting final groupings are below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2 和 3 的过程会重复，直到数据点不再重新分配或达到最大迭代次数。最终的分组结果如下。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/b7bee4c9d302597620ee9b52416dcfe3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![K-Means 聚类是什么以及其算法如何工作？](../Images/b7bee4c9d302597620ee9b52416dcfe3.png)'
- en: The choice of K
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K 的选择
- en: The data you will be working on as a data scientist won’t always have distinct
    demarcations when plotted, as you’d see on iris dataset. Oftentimes, you’ll deal
    with data with higher dimensions that cannot be plotted, or even if it’s plotted,
    you won’t be able to tell the optimum number of groupings. A good example of this
    is in the graph below.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你将处理的数据在绘制图表时不会总是有明显的界限，就像你在鸢尾花数据集中看到的那样。通常，你会处理具有更高维度的数据，这些数据无法绘制，或者即使可以绘制，也无法确定最佳的分组数量。以下图表是一个很好的例子。
- en: '![What is K-Means Clustering and How Does its Algorithm Work?](../Images/f2ca9e718098204e99136e38f3c001bb.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![K-Means 聚类是什么以及其算法如何工作？](../Images/f2ca9e718098204e99136e38f3c001bb.png)'
- en: Can you tell the number of groupings? Not clearly. So, how will we find the
    optimum number of clusters into which the above data points can be grouped?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你能确定分组的数量吗？不清楚。那么，我们如何找到上述数据点可以分组的最佳集群数量呢？
- en: There are different methods used to find the optimum K, into which the data
    points of a given data set can be grouped, elbow and silhouette methods. Let’s
    briefly look at how the two approaches work.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的方法用于找到最佳的 K，将给定数据集的数据点分组，包括肘部法和轮廓系数法。让我们简要地看一下这两种方法的工作原理。
- en: Elbow method
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 肘部法
- en: This approach uses the total variations within a cluster, otherwise known as
    the WCSS (within cluster sum of squares). The aim is to have the minimal variance
    within clusters (WCSS).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法使用聚类内的总变异，通常称为 WCSS（聚类内平方和）。其目的是使聚类内的方差（WCSS）最小。
- en: 'This method works in this way:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的工作原理如下：
- en: It takes a range of K values, say 1 - 8 and calculates the WSS for each K value.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它取一系列 K 值，例如 1 - 8，并计算每个 K 值的 WSS。
- en: The resulting data will have a K value and the corresponding WSS. This data
    is then used to plot a graph of WCSS against the k values.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 得到的数据将具有一个 K 值及其对应的 WSS。然后使用这些数据绘制 WCSS 对 K 值的图表。
- en: The optimum number of K is at the elbow point, where the curve begins to accelerate.
    It is from this point that the method derives its name. Think of the elbow of
    your arm.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳的 K 数量是肘部点，即曲线开始加速的地方。这个点的名称来源于此。想象一下你手臂的肘部。
- en: Silhouette method
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 轮廓系数法
- en: 'This method measures similarity and dissimilarity. It quantifies the distance
    of a point to other members of its assigned cluster, and also the distance to
    the members in other clusters. It works in this way:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法测量相似性和不相似性。它量化了一个点与其分配的聚类中其他成员的距离，以及与其他聚类中成员的距离。它的工作原理如下：
- en: It takes a range of K values beginning with 2.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它从 K 值的范围开始，初始值为 2。
- en: For each value of K, it computes the cluster similarity, which is the average
    distance between a data point and all other group members in the same cluster.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个 K 值，它计算聚类相似度，即一个数据点与同一聚类中所有其他组成员的平均距离。
- en: Next, the cluster dissimilarity is calculated by calculating the average distance
    between a data point and all other members of the nearest cluster.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，通过计算数据点与最近聚类中所有其他成员的平均距离来计算聚类不相似度。
- en: The silhouette coefficient will be the difference between cluster similarity
    value and cluster dissimilarity value, divided by the largest of the two values.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓系数将是聚类相似度值和聚类不相似度值之间的差值，除以两个值中的较大者。
- en: The optimum K would be one with the highest coefficient. The values of this
    coefficient are bounded in the range of -1 to 1.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳的 K 值是具有最高系数的值。这个系数的值范围在 -1 到 1 之间。
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This is an introductory article to K-Means clustering algorithm where we’ve
    covered what it is, how it works, and how to choose K. In the next article, we’ll
    walk through the process on how to solve a real world clustering problems using
    Python’s scikit-learn library.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是介绍 K-Means 聚类算法的文章，我们已经涵盖了它是什么、如何工作以及如何选择 K。在下一篇文章中，我们将介绍如何使用 Python 的 scikit-learn
    库解决实际的聚类问题。
- en: '**[Clinton Oyogo](https://www.linkedin.com/in/oyogo-clinton-53359198/)** writer
    at [Saturn Cloud](https://saturncloud.io/) believes that analyzing data for actionable
    insights is a crucial part of his day-to-day work. With his skills in data visualization,
    data wrangling, and machine learning, he takes pride in his work as a data scientist.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**[克林顿·奥约戈](https://www.linkedin.com/in/oyogo-clinton-53359198/)** 是 [Saturn
    Cloud](https://saturncloud.io/) 的作家，他认为分析数据以获取可操作的洞察是他日常工作的重要部分。凭借在数据可视化、数据整理和机器学习方面的技能，他为自己作为数据科学家的工作感到自豪。'
- en: '[Original](https://saturncloud.io/blog/what-is-k-means-clustering-and-how-does-its-algorithm-work/).
    Reposted with permission.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[原创](https://saturncloud.io/blog/what-is-k-means-clustering-and-how-does-its-algorithm-work/)。经许可转载。'
- en: More On This Topic
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Clustering Unleashed: Understanding K-Means Clustering](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类大解密：理解 K-Means 聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)'
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[K-means 聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
- en: '[Hands-On with Unsupervised Learning: K-Means Clustering](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[动手实践无监督学习：K-Means 聚类](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)'
- en: '[Does AI Get its Own Batman?](https://www.kdnuggets.com/2022/05/ai-get-batman.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 会有自己的蝙蝠侠吗？](https://www.kdnuggets.com/2022/05/ai-get-batman.html)'
- en: '[Choosing the Right Clustering Algorithm for Your Dataset](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为你的数据集选择合适的聚类算法](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)'
- en: '[DBSCAN Clustering Algorithm in Machine Learning](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的 DBSCAN 聚类算法](https://www.kdnuggets.com/2020/04/dbscan-clustering-algorithm-machine-learning.html)'
