["```py\n# We create a simple AE with a single fully-connected neural layer as encoder and as decoder:\n\nimport numpy as np\nimport keras\nfrom keras import layers\nfrom keras.datasets import mnist\nimport matplotlib.pyplot as plt\n\n# This is the size of our encoded representations\nencoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n\n# This is our input image\ninput_img = keras.Input(shape=(784,))\n\n# \"encoded\" is the encoded representation of the input\nencoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = layers.Dense(784, activation='sigmoid')(encoded)\n\n# This model maps an input to its reconstruction\nautoencoder = keras.Model(input_img, decoded)\n\n# Let's also create a separate encoder model:\n# This model maps an input to its encoded representation\nencoder = keras.Model(input_img, encoded)\n\n# As well as the decoder model:\n# This is our encoded (32-dimensional) input\nencoded_input = keras.Input(shape=(encoding_dim,))\n\n# Retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n\n# Create the decoder model\ndecoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n\n# Now let's train our autoencoder to reconstruct MNIST digits.\n# First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adam optimizer:\n\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n\n#Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images).\n\n(x_train, _), (x_test, _) = mnist.load_data()\n\n# We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n# Now let's train our autoencoder for 50 epochs:\nautoencoder.fit(x_train, x_train,\n                epochs=50,\n                batch_size=256,\n                shuffle=True,\n                validation_data=(x_test, x_test))\n\n# After 50 epochs, the autoencoder seems to reach a stable train/validation loss value of about 0.09\\. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib.\n\n# Encode and decode some digits\n# Note that we take them from the *test* set\n\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)\nn = 10  # Number of digits to display\nplt.figure(figsize=(20, 4))\n\nfor i in range(n):\n    # Display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n# Display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n\n```", "```py\n# First, here's our encoder network, mapping inputs to our latent distribution parameters:\noriginal_dim = 28 * 28\nintermediate_dim = 64\nlatent_dim = 2\n\ninputs = keras.Input(shape=(original_dim,))\nh = layers.Dense(intermediate_dim, activation='relu')(inputs)\nz_mean = layers.Dense(latent_dim)(h)\nz_log_sigma = layers.Dense(latent_dim)(h)\n\n# We can use these parameters to sample new similar points from the latent space:\nfrom keras import backend as K\n\ndef sampling(args):\n    z_mean, z_log_sigma = args\n    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=0.1)\n    return z_mean + K.exp(z_log_sigma) * epsilon\n\nz = layers.Lambda(sampling)([z_mean, z_log_sigma])\n\n# Finally, we can map these sampled latent points back to reconstructed inputs:\n# Create encoder\nencoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n\n# Create decoder\nlatent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\nx = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\noutputs = layers.Dense(original_dim, activation='sigmoid')(x)\n\ndecoder = keras.Model(latent_inputs, outputs, name='decoder')\n\n# Instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\n\nvae = keras.Model(inputs, outputs, name='vae_mlp')\n\n# We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term.\n\nreconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\nreconstruction_loss *= original_dim\nkl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\nkl_loss = K.sum(kl_loss, axis=-1)\nkl_loss *= -0.5\nvae_loss = K.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)\n\nvae.compile(optimizer='adam')\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n\n# We train our VAE on MNIST digits:\nvae.fit(x_train, x_train,\n        epochs=100,\n        batch_size=32,\n        validation_data=(x_test, x_test))\n\n```", "```py\nx_test_encoded = encoder.predict(x_test, batch_size=batch_size)\nplt.figure(figsize=(6, 6))\nplt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\nplt.colorbar()\nplt.show()\n\n```", "```py\n# Display a 2D manifold of the digits\nn = 15  # figure with 15x15 digits\ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n# We will sample n points within [-15, 15] standard deviations\ngrid_x = np.linspace(-15, 15, n)\ngrid_y = np.linspace(-15, 15, n)\nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]])\n        x_decoded = decoder.predict(z_sample)\n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()\n\n```"]