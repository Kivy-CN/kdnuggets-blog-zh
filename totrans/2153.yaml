- en: Building Data Pipelines to Create Apps with Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建数据管道以创建大语言模型应用程序
- en: 原文：[https://www.kdnuggets.com/building-data-pipelines-to-create-apps-with-large-language-models](https://www.kdnuggets.com/building-data-pipelines-to-create-apps-with-large-language-models)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/building-data-pipelines-to-create-apps-with-large-language-models](https://www.kdnuggets.com/building-data-pipelines-to-create-apps-with-large-language-models)
- en: '![Building Data Pipelines to Create Apps with Large Language Models](../Images/a2f12381d3e4354246e2880210d93050.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![构建数据管道以创建大语言模型应用程序](../Images/a2f12381d3e4354246e2880210d93050.png)'
- en: Image from DALL-E 3
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 3生成的图像
- en: Enterprises currently pursue two approaches for LLM powered Apps -  **Fine tuning**
    and **Retrieval Augmented Generation (RAG).**  At a very high level, RAG takes
    an input and retrieves a set of relevant/supporting documents given a source (e.g.,
    company wiki). The documents are concatenated as context with the original input
    prompt and fed to the LLM model which produces the final response.  RAG seems
    to be the most popular approach to get LLMs to market especially in [real-time
    processing](https://github.com/pathwaycom/pathway/stargazers)  scenarios. The
    LLM architecture to support that most of the time includes building an effective
    data pipeline.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 企业目前追求两种LLM驱动应用程序的方法——**微调**和**检索增强生成（RAG）**。从很高的层面来看，RAG接受一个输入，并根据来源（例如，公司维基）检索一组相关/支持的文档。这些文档与原始输入提示一起被连接作为上下文，输入到LLM模型中，生成最终响应。RAG似乎是将LLM推向市场的最受欢迎的方法，尤其是在[实时处理](https://github.com/pathwaycom/pathway/stargazers)场景中。支持这种方法的LLM架构大多数情况下包括构建有效的数据管道。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this post, we’ll explore different stages in the LLM data pipeline to help
    developers implement production-grade systems which work with their data. Follow
    along to learn how to ingest, prepare, enrich, and serve data to power GenAI apps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨LLM数据管道中的不同阶段，以帮助开发人员实施与其数据配合的生产级系统。跟随我们，了解如何导入、准备、丰富和提供数据，以驱动GenAI应用程序。
- en: What are the Different Stages of an LLM pipeline?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大语言模型（LLM）管道的不同阶段是什么？
- en: 'These are the different stages of an LLM pipeline:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是LLM管道的不同阶段：
- en: Data ingestion of unstructured data
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据的导入
- en: Vectorization with enrichment (with metadata)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化与丰富（包含元数据）
- en: Vector indexing (with real-time syncing)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 向量索引（实时同步）
- en: AI Query Processor
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: AI查询处理器
- en: Natural Language User interaction (with Chat or APIs)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言用户交互（通过聊天或API）
- en: '![Building Data Pipelines to Create Apps with Large Language Models](../Images/ee54eacc09fc15956d2cbff854208344.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![构建数据管道以创建大语言模型应用程序](../Images/ee54eacc09fc15956d2cbff854208344.png)'
- en: Data Ingestion of unstructured data
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非结构化数据的导入
- en: The first step is gathering the right data to help with the business goals.
    If you are building a consumer facing chatbot then you have to pay special attention
    to what data is going to be used. The sources of data could range from a company
    portal (e.g. Sharepoint, Confluent, Document storage) to internal APIs.  Ideally
    you want to have a push mechanism from these sources to the index so that your
    LLM app is up to date for your end consumer.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是收集正确的数据，以帮助实现业务目标。如果你正在构建面向消费者的聊天机器人，那么你必须特别注意将使用哪些数据。数据来源可以从公司门户（例如，Sharepoint、Confluent、文档存储）到内部API。理想情况下，你希望从这些来源到索引有一个推送机制，以便你的LLM应用程序能够为最终用户提供最新的信息。
- en: Organizations should implement data governance policies and protocols when extracting
    text data for LLM in context training. Organizations can start  by auditing document
    data sources to catalog sensitivity levels, licensing terms and origin. Identify
    restricted data that needs redaction or exclusion from datasets.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 组织在提取文本数据以进行 LLM 上下文训练时，应实施数据治理政策和协议。组织可以通过审计文档数据来源，列出敏感级别、许可条款和来源来入手。识别需要修订或排除的数据。
- en: These data sources should also be assessed for quality - diversity, size, noise
    levels, redundancy. Lower quality datasets will dilute the responses from [LLM
    apps](https://github.com/pathwaycom/llm-app).  You might even need an early document
    classification mechanism to help with the right kind of storage later in the pipeline.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据源也应评估质量——多样性、大小、噪音水平、冗余。低质量数据集会稀释来自[LLM 应用](https://github.com/pathwaycom/llm-app)的响应。你甚至可能需要一个早期文档分类机制来帮助后续正确的存储。
- en: Adhering to data governance guardrails, even in fast-paced LLM development,
    reduces risks. Establishing governance upfront mitigates many issues down the
    line and enables scalable, robust extraction of text data for context learning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在快速发展的 LLM 开发中，遵循数据治理的保护措施也能降低风险。前期建立治理框架可以减轻许多后续问题，并支持可扩展、稳健的文本数据提取用于上下文学习。
- en: Pulling messages via Slack, Telegram, or Discord APIs gives access for real-time
    data is what helps RAG but raw conversational data contains noise - typos, encoding
    issues, weird characters.   Filtering out messages real-time with offensive content
    or sensitive personal details that could be PII is an important part of data cleansing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Slack、Telegram 或 Discord API 拉取消息可以实时获取数据，这有助于 RAG，但原始对话数据中包含噪音——拼写错误、编码问题和奇怪的字符。实时过滤带有攻击性内容或敏感个人信息（可能是
    PII）的消息是数据清理的重要部分。
- en: Vectorization with metadata
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带有元数据的向量化
- en: Metadata like author, date, and conversation context further enriches data.
    This embedding of external knowledge into vectors helps with smarter and targeted
    retrieval.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据如作者、日期和对话上下文进一步丰富数据。将外部知识嵌入向量中有助于更智能和有针对性的检索。
- en: Some of the metadata related to documents could lie in the portal or in the
    document’s metadata itself, however if the document is attached to a business
    object( e.g.  Case, Customer , Employee information) then you would have to fetch
    that information from a relational database.  If there are security concerns around
    data access, this is a place where you can add security metadata which also helps
    with the retrieval stage later in the pipeline.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一些与文档相关的元数据可能存在于门户或文档的元数据中，但如果文档附属于业务对象（例如案例、客户、员工信息），则需要从关系数据库中提取这些信息。如果有数据访问的安全问题，这是你可以添加安全元数据的地方，这也有助于后续检索阶段。
- en: A critical step here is to convert text and images  into vector representations
    using the LLM’s embedding models. For documents, you need to do chunking first,
    then you do encoding preferably using on-prem zero shot embedding models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 关键步骤是使用 LLM 的嵌入模型将文本和图像转换为向量表示。对于文档，你需要先进行分块，然后使用本地零样本嵌入模型进行编码。
- en: Vector indexing
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量索引
- en: Vector representations have to be stored somewhere. This is where  vector databases
    or vector indexes are used to efficiently store and index this information as
    embeddings.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 向量表示必须存储在某处。这就是使用向量数据库或向量索引高效存储和索引这些信息作为嵌入的地方。
- en: This becomes your “LLM source of truth”  and this has to be in sync with your
    data sources and documents.  [Real-time indexing](https://pathway.com/developers/tutorials/indexing-grouped-tables/)
    becomes important if your LLM app is servicing customers or generating business
    related information. You want to avoid your LLM app being out of sync with your
    data sources.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这将成为你的“LLM 真实来源”，并且必须与数据源和文档保持同步。[实时索引](https://pathway.com/developers/tutorials/indexing-grouped-tables/)变得重要，如果你的
    LLM 应用正在服务客户或生成与业务相关的信息。你要避免你的 LLM 应用与数据源不同步。
- en: Fast retrieval with a query processor
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用查询处理器进行快速检索
- en: When you have millions of enterprise documents, getting the right content based
    on the user query becomes challenging.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当你拥有数百万份企业文档时，根据用户查询获取正确内容变得具有挑战性。
- en: 'This is where the early stages of pipeline starts adding value : Cleansing
    and Data enrichment via metadata addition and most importantly Data indexing.
      This in-context addition helps with making prompt engineering stronger.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是管道早期阶段开始增加价值的地方：通过元数据添加清洗和数据丰富，最重要的是数据索引。这种上下文添加有助于增强提示工程。
- en: User interaction
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户互动
- en: In a traditional pipelining environment, you push the data to a data warehouse
    and the analytics tool will pull the reports from the warehouse.  In an LLM pipeline,
    an end user interface is usually a chat interface which at the simplest level
    takes a user query and responds to the query.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的管道环境中，你将数据推送到数据仓库，分析工具将从仓库中提取报告。在LLM管道中，最终用户界面通常是一个聊天界面，它在最简单的层面上接受用户查询并回应查询。
- en: Summary
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The challenge with this new type of pipeline is not just getting a prototype
    but getting this running in production.  This is where an enterprise grade monitoring
    solution to track your pipelines and vector stores becomes important.  The ability
    to get business data from both structured and unstructured data sources becomes
    an important architectural decision.  LLMs represent the state-of-the-art in natural
    language processing and building enterprise grade data pipelines for LLM powered
    apps keeps you at the forefront.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新型管道的挑战不仅在于获取一个原型，还在于将其投入生产。这时，企业级监控解决方案来跟踪你的管道和向量存储变得非常重要。从结构化和非结构化数据源获取业务数据的能力成为一个重要的架构决策。LLMs代表了自然语言处理的最前沿，构建企业级数据管道以支持LLM驱动的应用程序使你始终处于前沿。
- en: Here is access to a source available [real-time stream processing framework](https://github.com/pathwaycom/pathway).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里可以访问一个可用的[实时流处理框架](https://github.com/pathwaycom/pathway)。
- en: '**[](https://www.linkedin.com/in/anupsurendran/)**[Anup Surendran](https://www.linkedin.com/in/anupsurendran/)****
    is a Head of Product Marketing at Pathway who specializes in bringing AI products
    to market. He has worked with startups that have had two successful exits (to
    SAP and Kroll) and enjoys teaching others about how AI products can improve productivity
    within an organization.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/anupsurendran/)**[Anup Surendran](https://www.linkedin.com/in/anupsurendran/)****
    是Pathway的产品营销负责人，专注于将AI产品推向市场。他曾与有两个成功退出（SAP和Kroll）的初创公司合作，并喜欢教授他人如何利用AI产品提高组织内的生产力。'
- en: More On This Topic
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级开源大型语言模型](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
- en: '[More Free Courses on Large Language Models](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更多免费大型语言模型课程](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
- en: '[Learn About Large Language Models](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解大型语言模型](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[来自John Snow Labs的医疗特定大型语言模型介绍](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
- en: '[What are Large Language Models and How Do They Work?](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是大型语言模型，它们是如何工作的？](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
- en: '[AI: Large Language & Visual Models](https://www.kdnuggets.com/2023/06/ai-large-language-visual-models.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI：大型语言和视觉模型](https://www.kdnuggets.com/2023/06/ai-large-language-visual-models.html)'
