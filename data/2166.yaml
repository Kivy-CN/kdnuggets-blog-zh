- en: Understanding the Basics of Reinforcement Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解强化学习的基础
- en: 原文：[https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning](https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning](https://www.kdnuggets.com/understanding-the-basics-of-reinforcement-learning)
- en: '![Understanding the Basics of Reinforcement Learning](../Images/ae95ebb172fd241073ad13c19e1f1377.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![理解强化学习的基础](../Images/ae95ebb172fd241073ad13c19e1f1377.png)'
- en: Image by Editor | Ideogram
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：编辑 | Ideogram
- en: Reinforcement Learning is the area of AI focused on building systems that learn
    from experience or trial and error. This post uncovers the basic concepts and
    applications of this intriguing part of AI in a nontechnical and approachable
    way.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是人工智能领域专注于构建从经验或试错中学习的系统的领域。这篇文章以非技术性和易于接近的方式揭示了这一引人入胜的人工智能部分的基本概念和应用。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: What is Reinforcement Learning?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是强化学习？
- en: Reinforcement Learning (RL) is a branch of AI where an agent — typically a software
    program — gradually learns to make decisions intelligently through interaction
    with its environment.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）是人工智能的一个分支，在这个领域中，代理——通常是软件程序——通过与环境的交互逐渐学会智能决策。
- en: To better understand the rationale behind RL, a common comparison is that of
    a young kid learning to ride a bicycle. At first, the kid initially tries out
    different actions, often leading to a fall. Every time the kid falls off the bike,
    (s)he experiences pain (punishment), whereas if the kid manages to ride a few
    meters without falling, (s)he feels satisfied (reward). The kid gradually internalizes
    which actions -or sequences of actions- lead to smooth riding, applying them and
    improving their riding skills.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解RL背后的原理，一个常见的比较是小孩子学习骑自行车。一开始，孩子会尝试不同的动作，通常会导致摔倒。每次孩子摔下自行车时，(s)he 会感受到疼痛（惩罚），而如果孩子能够骑行几米而不摔倒，(s)he
    会感到满意（奖励）。孩子逐渐内化哪些动作——或动作序列——能够实现平稳骑行，应用这些动作并提高骑行技能。
- en: Similarly, in RL an agent performs actions that lead to rewards or punishments
    and iteratively adjusts its behavior to improve its performance over time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在RL中，代理执行动作以获得奖励或惩罚，并迭代地调整其行为以提高性能。
- en: Elements of an RL Algorithm
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RL算法的元素
- en: The first step to understanding the basics of RL is introducing the key elements
    of an RL algorithm. These elements are illustrated in the diagram below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 理解RL基础的第一步是介绍RL算法的关键元素。这些元素在下面的图示中展示。
- en: '![Elements of an RL algorithm](../Images/392daabd31142d084e1bffe0470668d4.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![RL算法的元素](../Images/392daabd31142d084e1bffe0470668d4.png)'
- en: '**Agent:** a software entity that makes decisions and takes actions in an environment
    to achieve a goal.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理：** 在环境中做决策并采取行动以实现目标的软件实体。'
- en: '**Environment:** The digital or physical setting the agent interacts with,
    by executing actions.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境：** 代理通过执行动作与之互动的数字或物理设置。'
- en: '**State:** The environment is composed of states, such that the agent is in
    a certain state at a given time. In other words, a state represents the current
    environment situation, being "analyzed" by the agent to make decisions.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态：** 环境由状态组成，代理在给定时间处于某一状态。换句话说，状态代表当前的环境情况，由代理“分析”以做出决策。'
- en: '**Action:** Any move or decision made by the agent in a given state, normally
    leading to a new state as a result of the action.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动作：** 在给定状态下，代理进行的任何移动或决策，通常会导致因动作而产生的新状态。'
- en: '**Reward:** A value or feedback received by the agent as a result of taking
    an action leading to a new state. It can be positive or negative (punishment),
    indicating an immediate success or failure of the action made concerning the objective
    defined. Positive rewards tend to bring the agent closer to such an objective,
    and vice versa.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**奖励：** 代理因采取某一动作导致状态变化而收到的值或反馈。它可以是正面的或负面的（惩罚），表示相对于定义的目标，动作的即时成功或失败。正面奖励往往使代理更接近该目标，反之亦然。'
- en: How Does an RL Agent Learn?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习代理如何学习？
- en: 'Our next question to answer is: how does the agent learn to choose actions
    that lead to maximum rewards, both in the short and the long term? Put another
    way, which elements does the agent utilize during the learning process to improve
    its decision-making capabilities over actions at different states? This is where
    the concepts of policy and value function come into the scene.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个需要回答的问题是：代理如何学习选择能够带来最大奖励的动作，无论是短期的还是长期的？换句话说，代理在学习过程中利用哪些元素来改善其在不同状态下的决策能力？这就是策略和价值函数的概念发挥作用的地方。
- en: A **policy** is the strategy used by the agent to decide which action to take
    at every possible state. In the simplest case, the policy can be a states-actions
    lookup table, but normally it is defined by a more complex mathematical function
    that maps states to possible actions. For example, an agent who learns to play
    a platform-based video game whose controlled character is currently standing on
    a platform (state) can walk forward, backward, or jump in either direction (actions).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**策略**是代理用来决定在每个可能状态下采取哪个动作的策略。在最简单的情况下，策略可以是一个状态-动作查找表，但通常它是由一个更复杂的数学函数定义，该函数将状态映射到可能的动作。例如，一个学习玩基于平台的视频游戏的代理，其控制的角色当前站在一个平台上（状态），可以向前、向后走或向任何方向跳跃（动作）。'
- en: Meanwhile, the **reward function** quantifies the positive or negative reward
    the agent receives upon executing an action at a given state. Mathematically,
    it maps a state-action pair to a numerical reward. In the video game example,
    if the character is on an edge and jumps forward, it may reach another platform
    opposite him (positive reward), whereas if it decides to walk forward without
    jumping, it will fall (negative reward).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，**奖励函数**量化了代理在给定状态下执行动作后获得的正面或负面奖励。从数学上讲，它将状态-动作对映射到一个数值奖励。在视频游戏的例子中，如果角色在边缘上并向前跳跃，它可能会到达对面的另一个平台（正面奖励），而如果它决定不跳跃而是直接走前面，它将会掉落（负面奖励）。
- en: When observed jointly, these elements allow the agent to gradually learn the
    best courses of action leading to maximizing a reward and eventually achieving
    the goal pursued.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当这些元素共同观察时，允许代理逐步学习最佳的行动路径，以最大化奖励并最终实现所追求的目标。
- en: Model-based vs Model-free RL Approaches
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于模型与无模型强化学习方法
- en: 'Where do the policies and reward functions come from? Does someone formulate
    this information about environment states, actions, and their rewards? The short
    answer is: it depends. This information is gathered differently depending on the
    type of RL approach used. There are two broad approaches under this perspective:
    model-based RL and model-free RL.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 策略和奖励函数来自哪里？是否有人制定了有关环境状态、行动及其奖励的信息？简短的回答是：这要看情况。这些信息的收集方式取决于所使用的强化学习方法类型。从这个角度来看，有两种广泛的方法：基于模型的强化学习和无模型强化学习。
- en: Model-based RL uses a model of the environment (often learned upon data via
    machine learning or deep learning) to assess the outcomes of actions taken, whereas
    model-free RL gradually constructs this model through direct environment interaction,
    relying on pure "trial and error" rather than predictions or estimates.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的强化学习（RL）使用环境的模型（通常通过机器学习或深度学习从数据中学习得到）来评估所采取行动的结果，而无模型强化学习则通过直接与环境互动逐步构建这个模型，依赖纯粹的“试错”而不是预测或估计。
- en: Real-World Impact and Hurdles in RL
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习的现实世界影响和障碍
- en: Applications and Latest Trends
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用与最新趋势
- en: At an experimental level, RL has historically been applied to solving games
    and problems in simulated environments. Still, its application areas have rapidly
    expanded to areas like robotics and recommender engines, where real-time decisions
    in dynamic environments are required. Latest application trends of RL include
    autonomous vehicle control, and its integration with Generative AI (for instance,
    language models), to improve content generation decisions in complex or highly
    changeable settings.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验层面，强化学习历史上主要应用于解决游戏和模拟环境中的问题。然而，其应用领域已迅速扩展到机器人技术和推荐引擎等需要实时决策的动态环境中。强化学习的最新应用趋势包括自主驾驶控制及其与生成式人工智能（例如语言模型）的集成，以提高在复杂或高度变化的环境中内容生成决策的效果。
- en: Challenges and Limitations
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 挑战与局限性
- en: One of the major challenges of RL is its high computational and data consumption
    cost, due to intensive interactions with the environment to learn effectively,
    thereby making its application in certain real-world scenarios more difficult.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的主要挑战之一是其高计算和数据消耗成本，这由于与环境的密集互动以有效学习，从而使其在某些现实场景中的应用变得更加困难。
- en: Wrap-Up
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this article, we walked through the basic concepts surrounding RL algorithms
    and their central component: agents with a goal that perform actions by interacting
    with an environment and gradually learn from the result of these actions. We also
    outlined the salient real applications and challenges of implementing RL solutions.
    While challenging, RL is currently experiencing a lot of popularity due to its
    symbiotic relationship with Gen-AI solutions, making them much more effective
    at content generation.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了围绕强化学习算法的基本概念及其核心组件：具有目标的代理，通过与环境互动执行动作并逐渐从这些动作的结果中学习。我们还概述了强化学习解决方案的显著实际应用和挑战。尽管充满挑战，强化学习目前因其与生成式人工智能解决方案的共生关系而备受关注，使得内容生成变得更加高效。
- en: '[](https://www.linkedin.com/in/ivanpc/)****[Iván Palomares Carrascosa](https://www.linkedin.com/in/ivanpc/)****
    is a leader, writer, speaker, and adviser in AI, machine learning, deep learning
    & LLMs. He trains and guides others in harnessing AI in the real world.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/ivanpc/)****[伊万·帕洛马雷斯·卡拉索萨](https://www.linkedin.com/in/ivanpc/)****
    是一位领导者、作家、演讲者和人工智能、机器学习、深度学习及大型语言模型领域的顾问。他训练和指导他人如何在实际中利用人工智能。'
- en: More On This Topic
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Back to Basics Week 3: Introduction to Machine Learning](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回到基础第3周：机器学习简介](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
- en: '[Back To Basics, Part Dos: Gradient Descent](https://www.kdnuggets.com/2023/03/back-basics-part-dos-gradient-descent.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回到基础，第2部分：梯度下降](https://www.kdnuggets.com/2023/03/back-basics-part-dos-gradient-descent.html)'
- en: '[Learn MLOps Basics with This Free eBook](https://www.kdnuggets.com/2023/08/learn-mlops-basics-free-ebook.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费电子书学习 MLOps 基础知识](https://www.kdnuggets.com/2023/08/learn-mlops-basics-free-ebook.html)'
- en: '[Python Basics: Syntax, Data Types, and Control Structures](https://www.kdnuggets.com/python-basics-syntax-data-types-and-control-structures)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 基础：语法、数据类型和控制结构](https://www.kdnuggets.com/python-basics-syntax-data-types-and-control-structures)'
- en: '[Back to Basics Week 1: Python Programming & Data Science Foundations](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回到基础第1周：Python 编程与数据科学基础](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
- en: '[Back to Basics Week 4: Advanced Topics and Deployment](https://www.kdnuggets.com/back-to-basics-week-4-advanced-topics-and-deployment)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[回到基础第4周：高级主题与部署](https://www.kdnuggets.com/back-to-basics-week-4-advanced-topics-and-deployment)'
