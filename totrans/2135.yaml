- en: A Simple Guide to Running LlaMA 2 Locally
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地运行 LLaMA 2 的简单指南
- en: 原文：[https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/883675b48c3a97d28a3e88422e51c36e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行 LLaMA 2 的简单指南](../Images/883675b48c3a97d28a3e88422e51c36e.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: New open source models like LLaMA 2 have become quite advanced and are free
    to use. You can use them commercially or fine-tune them on your own data to develop
    specialized versions. With their ease of use, you can now run them locally on
    your own device.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 像 LLaMA 2 这样的新开源模型已经变得相当先进，并且可以免费使用。你可以将其用于商业用途或在自己的数据上进行微调以开发专门的版本。由于其易用性，你现在可以在自己的设备上本地运行它们。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this post, we will learn how to download the necessary files and the LLaMA
    2 model to run the CLI program and interact with an AI assistant. The setup is
    simple enough that even non-technical users or students can get it running by
    following a few basic steps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将学习如何下载必要的文件和 LLaMA 2 模型，以运行 CLI 程序并与 AI 助手互动。设置非常简单，即使是非技术用户或学生也可以通过几个基本步骤使其运行。
- en: Downloading Llama.cpp for GPU machine
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载 GPU 机器上的 Llama.cpp
- en: To install llama.cpp locally, the simplest method is to download the pre-built
    executable from the [llama.cpp releases](https://github.com/ggerganov/llama.cpp/releases).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本地安装 llama.cpp，最简单的方法是从 [llama.cpp releases](https://github.com/ggerganov/llama.cpp/releases)
    下载预构建的可执行文件。
- en: To install it on Windows 11 with the NVIDIA GPU, we need to first download the
    `llama-master-eb542d3-bin-win-cublas-[version]-x64.zip` file. After downloading,
    extract it in the directory of your choice. It is recommended to create a new
    folder and extract all the files in it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要在带有 NVIDIA GPU 的 Windows 11 上安装它，我们首先需要下载 `llama-master-eb542d3-bin-win-cublas-[version]-x64.zip`
    文件。下载后，将其解压到你选择的目录中。建议创建一个新文件夹并将所有文件解压到其中。
- en: 'Next, we will download the cuBLAS drivers `cudart-llama-bin-win-[version]-x64.zip`
    and extract them in the main directory. For using the GPU acceleration, you have
    two options: `cuBLAS` for NVIDIA GPUs and `clBLAS` for AMD GPUs.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要下载 `cudart-llama-bin-win-[version]-x64.zip` 文件并将其解压到主目录中。要使用 GPU 加速，你有两个选择：NVIDIA
    GPU 使用 `cuBLAS`，AMD GPU 使用 `clBLAS`。
- en: '**Note:** The [version] is the version of the CUDA installed on your local
    system. You can check it by running `nvcc --version` in the terminal.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** [version] 是你本地系统上安装的 CUDA 版本。你可以通过在终端中运行 `nvcc --version` 来检查它。'
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/10cb80bf9308a540d8091469e5ded2c0.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行 LLaMA 2 的简单指南](../Images/10cb80bf9308a540d8091469e5ded2c0.png)'
- en: Downloading the Model
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载模型
- en: To begin, create a folder named “Models” in the main directory. Within the Models
    folder, create a new folder named “llama2_7b”. Next, download the LLaMA 2 model
    file from the [Hugging Face hub](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main).
    You can choose any version you prefer, but for this guide, we will be downloading
    the `llama-2-7b-chat.Q5_K_M.gguf` file. Once the download is complete, move the
    file into the “llama2_7b” folder you just created.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在主目录中创建一个名为“Models”的文件夹。在 Models 文件夹中，创建一个名为“llama2_7b”的新文件夹。接下来，从 [Hugging
    Face hub](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/tree/main) 下载 LLaMA
    2 模型文件。你可以选择任何你喜欢的版本，但为了本指南，我们将下载 `llama-2-7b-chat.Q5_K_M.gguf` 文件。下载完成后，将文件移动到刚刚创建的“llama2_7b”文件夹中。
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/179c11a6d205ee29449a4cabc9fe2ced.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行 LLaMA 2 的简单指南](../Images/179c11a6d205ee29449a4cabc9fe2ced.png)'
- en: '**Note:** To avoid any errors, please make sure to download only the `.gguf`
    model files before running the mode.'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 为避免错误，请确保在运行模型之前仅下载`.gguf`模型文件。'
- en: Initiating the AI Assistant CLI Program
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动AI助手CLI程序
- en: You can now open the terminal in the main directory. By right clicking and selecting
    “Open in Terminal” option. You can also open PowerShell and the us “cd” to change
    directory.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以在主目录中打开终端。通过右键点击并选择“在终端中打开”选项。你也可以打开PowerShell，使用“cd”命令更改目录。
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/ff829824e239b1cf01c38405a1a9a925.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行LLaMA 2的简单指南](../Images/ff829824e239b1cf01c38405a1a9a925.png)'
- en: Copy and paste the command below and press “Enter”. We are executing the `main.exe`
    file with model directory location, gpu, color, and system prompt arguments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 复制并粘贴下面的命令，然后按“Enter”。我们正在执行`main.exe`文件，传递模型目录位置、gpu、颜色和系统提示参数。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/f7fe5edbb7186863caff0fa21045a46d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行LLaMA 2的简单指南](../Images/f7fe5edbb7186863caff0fa21045a46d.png)'
- en: Our llama.ccp CLI program has been successfully initialized with the system
    prompt. It tells us it's a helpful AI assistant and shows various commands to
    use.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的llama.ccp CLI程序已经成功初始化了系统提示。它告诉我们这是一个有用的AI助手，并展示了各种命令。
- en: Using LLaMA 2 Locally in PowerShell
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在PowerShell中本地使用LLaMA 2
- en: Let’s test out the LLaMA 2 in the PowerShell by providing the prompt. We have
    asked a simple question about the age of the earth.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在PowerShell中提供提示来测试LLaMA 2。我们提出了一个关于地球年龄的简单问题。
- en: The answer is accurate. Let’s ask a follow up question about earth.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是准确的。让我们再问一个关于地球的后续问题。
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/55f3e00537fbfdb182d0bbb22badcd7f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行LLaMA 2的简单指南](../Images/55f3e00537fbfdb182d0bbb22badcd7f.png)'
- en: As you can see, the model has provided us with multiple interesting facts about
    our planet.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，模型提供了关于我们星球的多个有趣事实。
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/a9fc624c1ce0a9d85ccc6ae41ca36eaa.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行LLaMA 2的简单指南](../Images/a9fc624c1ce0a9d85ccc6ae41ca36eaa.png)'
- en: You can ask the AI assistant to generate code and an explanation in the terminal,
    which you can easily copy and use in your IDE.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以让AI助手在终端中生成代码和解释，你可以轻松地复制并在IDE中使用。
- en: '![A Simple Guide to Running LlaMA 2 Locally](../Images/204eec95e1379ed6bf6d7d9dd119ad47.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![本地运行LLaMA 2的简单指南](../Images/204eec95e1379ed6bf6d7d9dd119ad47.png)'
- en: Perfect.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 完美。
- en: Conclusion
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Running Llama 2 locally provides a powerful yet easy-to-use chatbot experience 
    that is customized to your needs. By following this simple guide, you can learn
    to build your own private chatbot set up in no time without needing to rely on
    paid services.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本地运行Llama 2提供了一个强大而易于使用的聊天机器人体验，完全根据你的需求进行定制。通过遵循这个简单的指南，你可以在短时间内学会构建自己的私人聊天机器人，而无需依赖付费服务。
- en: The main benefits of running LlaMA 2 locally are full control over your data
    and conversations as well as no usage limits. You can chat with your bot as much
    as you want and even tweak it to improve responses.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 本地运行LLaMA 2的主要好处是可以完全控制你的数据和对话，同时没有使用限制。你可以随心所欲地与机器人聊天，甚至可以调整它以改善回应。
- en: While less convenient than an instantly available cloud AI API, local setup
    brings peace of mind regarding data privacy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本地设置比即时可用的云AI API不那么方便，但它能让你对数据隐私更加放心。
- en: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) is a certified data
    scientist professional who loves building machine learning models. Currently,
    he is focusing on content creation and writing technical blogs on machine learning
    and data science technologies. Abid holds a Master''s degree in technology management
    and a bachelor''s degree in telecommunication engineering. His vision is to build
    an AI product using a graph neural network for students struggling with mental
    illness.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) 是一位认证数据科学专业人士，他喜欢构建机器学习模型。目前，他专注于内容创作并撰写关于机器学习和数据科学技术的技术博客。Abid拥有技术管理硕士学位和电信工程学士学位。他的愿景是利用图神经网络构建一个AI产品，帮助那些挣扎于心理健康问题的学生。'
- en: More On This Topic
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
- en: '[The Easiest Way of Running Llama 3 Locally](https://www.kdnuggets.com/easiest-way-of-running-llama-3-locally)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地运行 Llama 3 的最简单方法](https://www.kdnuggets.com/easiest-way-of-running-llama-3-locally)'
- en: '[Ollama Tutorial: Running LLMs Locally Made Super Simple](https://www.kdnuggets.com/ollama-tutorial-running-llms-locally-made-super-simple)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ollama 教程：本地运行 LLM 变得超级简单](https://www.kdnuggets.com/ollama-tutorial-running-llms-locally-made-super-simple)'
- en: '[Using Groq Llama 3 70B Locally: Step by Step Guide](https://www.kdnuggets.com/using-groq-llama-3-70b-locally-step-by-step-guide)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 Groq Llama 3 70B：逐步指南](https://www.kdnuggets.com/using-groq-llama-3-70b-locally-step-by-step-guide)'
- en: '[Run an LLM Locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 LM Studio 在本地运行 LLM](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
- en: '[How to Get Up and Running with SQL - A List of Free Learning Resources](https://www.kdnuggets.com/2022/10/get-running-sql-list-free-learning-resources.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何快速上手 SQL - 免费学习资源清单](https://www.kdnuggets.com/2022/10/get-running-sql-list-free-learning-resources.html)'
