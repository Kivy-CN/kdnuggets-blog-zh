- en: Getting Started with Scikit-learn in 5 Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/5-steps-getting-started-scikit-learn](https://www.kdnuggets.com/5-steps-getting-started-scikit-learn)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Getting Started with Scikit-learn in 5 Steps](../Images/1d3ecbf678f59808a4d9eb7d90d3f39b.png)'
  prefs: []
  type: TYPE_IMG
- en: Introduction to Scikit-learn
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'When learning about how to use [Scikit-learn](https://scikit-learn.org/stable/),
    we must obviously have an existing understanding of the underlying concepts of
    machine learning, as Scikit-learn is nothing more than a practical tool for implementing
    machine learning principles and related tasks. Machine learning is a subset of
    artificial intelligence that enables computers to learn and improve from experience
    without being explicitly programmed. The algorithms use training data to make
    predictions or decisions by uncovering patterns and insights. There are three
    main types of machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning - Models are trained on labeled data, learning to map inputs
    to outputs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning - Models work to uncover hidden patterns and groupings
    within unlabeled data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning - Models learn by interacting with an environment, receiving
    rewards and punishments to encourage optimal behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you are undoubtedly aware, machine learning powers many aspects of modern
    society, generating enormous amounts of data. As data availability continues to
    grow, so does the importance of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scikit-learn is a popular open source Python library for machine learning.
    Some key reasons for its widespread use include:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple and efficient tools for data analysis and modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessible to Python programmers, with focus on clarity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Built on NumPy, SciPy and matplotlib for easier integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wide range of algorithms for tasks like classification, regression, clustering,
    dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This tutorial aims to offer a step-by-step walkthrough of using Scikit-learn
    (mainly for common supervised learning tasks), focusing on getting started with
    extensive hands-on examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Getting Started with Scikit-learn'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Installation and Setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to install and use Scikit-learn, your system must have a functioning
    Python installation. We won't be covering that here, but will assume that you
    have a functioning installation at this point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scikit-learn can be installed using pip, Python''s package manager:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This will also install any required dependencies like NumPy and SciPy. Once
    installed, Scikit-learn can be imported in your Python scripts as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Testing Your Installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once installed, you can start a Python interpreter and run the import command
    above.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So long as you do not see any error messages, you are now ready to start using
    Scikit-learn!
  prefs: []
  type: TYPE_NORMAL
- en: Loading Sample Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Scikit-learn provides a variety of sample datasets that we can use for testing
    and experimentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The digits dataset contains images of handwritten digits along with their labels.
    We can start familiarizing ourselves with Scikit-learn using these sample datasets
    before moving on to real-world data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Data Preprocessing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Importance of Data Preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Real-world data is often incomplete, inconsistent, and contains errors. Data
    preprocessing transforms raw data into a usable format for machine learning, and
    is an essential step that can impact the performance of downstream models.
  prefs: []
  type: TYPE_NORMAL
- en: Many novice practitioners often overlook proper data preprocessing, instead
    jumping right into model training. However, low quality data inputs will lead
    to low quality models outputs, regardless of the sophistication of the algorithms
    used. Steps like properly handling missing data, detecting and removing outliers,
    feature encoding, and feature scaling help boost model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing accounts for a major portion of the time and effort spent
    on machine learning projects. The old computer science adage "garbage in, garbage
    out" very much applies here. High quality data inputs are a prerequisite for high
    performance machine learning. The data preprocessing steps transform the raw data
    into a refined training set that allows the machine learning algorithms to effectively
    uncover predictive patterns and insights.
  prefs: []
  type: TYPE_NORMAL
- en: So in summary, properly preprocessing the data is an indispensable step in any
    machine learning workflow, and should receive substantial focus and diligent effort.
  prefs: []
  type: TYPE_NORMAL
- en: Loading and Understanding Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s load a sample dataset using Scikit-learn for demonstration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can explore the features and target values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We should understand the meaning of the features and target before proceeding.
  prefs: []
  type: TYPE_NORMAL
- en: Data Cleaning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Real data often contains missing, corrupt or outlier values. Scikit-learn provides
    tools to handle these issues:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The imputer replaces missing values with the mean, which is a common — but not
    the only — strategy. This is just one approach for data cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Scaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Algorithms like Support Vector Machines (SVMs) and neural networks are sensitive
    to the scale of input features. Inconsistent feature scales can result in these
    algorithms giving undue importance to features with larger scales, thereby affecting
    the model's performance. Therefore, it's essential to normalize or standardize
    the features to bring them onto a similar scale before training these algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: StandardScaler standardizes features to have mean 0 and variance 1\. Other scalers
    are also available.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also visualize the data using matplotlib to gain further insights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Data visualization serves multiple critical functions in the machine learning
    workflow. It allows you to spot underlying patterns and trends in the data, identify
    outliers that may skew model performance, and gain a deeper understanding of the
    relationships between variables. By visualizing the data beforehand, you can make
    more informed decisions during the feature selection and model training phases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Model Selection and Training'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview of Scikit-learn Algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Scikit-learn provides a variety of supervised and unsupervised algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Classification: Logistic Regression, SVM, Naive Bayes, Decision Trees, Random
    Forest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regression: Linear Regression, SVR, Decision Trees, Random Forest'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clustering: k-Means, DBSCAN, Agglomerative Clustering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Along with many others.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing an Algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Choosing the most appropriate machine learning algorithm is vital for building
    high quality models. The best algorithm depends on a number of key factors:'
  prefs: []
  type: TYPE_NORMAL
- en: The size and type of data available for training. Is it a small or large dataset?
    What kinds of features does it contain - images, text, numerical?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The available computing resources. Algorithms differ in their computational
    complexity. Simple linear models train faster than deep neural networks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The specific problem we want to solve. Are we doing classification, regression,
    clustering, or something more complex?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any special requirements like the need for interpretability. Linear models are
    more interpretable than black-box methods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The desired accuracy/performance. Some algorithms simply perform better than
    others on certain tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For our particular sample problem of categorizing iris flowers, a classification
    algorithm like Logistic Regression or Support Vector Machine would be most suitable.
    These can efficiently categorize the flowers based on the provided feature measurements.
    Other simpler algorithms may not provide sufficient accuracy. At the same time,
    very complex methods like deep neural networks would be overkill for this relatively
    simple dataset.
  prefs: []
  type: TYPE_NORMAL
- en: As we train models going forward, it is crucial to always select the most appropriate
    algorithms for our specific problems at hand, based on considerations such as
    those outlined above. Reliably choosing suitable algorithms will ensure we develop
    high quality machine learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: Training a Simple Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s train a Logistic Regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: That's it! The model is trained and ready for evaluation and use.
  prefs: []
  type: TYPE_NORMAL
- en: Training a More Complex Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While simple linear models like logistic regression can often provide decent
    performance, for more complex datasets we may need to leverage more sophisticated
    algorithms. For example, ensemble methods combine multiple models together, using
    techniques like bagging and boosting, to improve overall predictive accuracy.
    As an illustration, we can train a random forest classifier, which aggregates
    many decision trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The random forest can capture non-linear relationships and complex interactions
    among the features, allowing it to produce more accurate predictions than any
    single decision tree. We can also employ algorithms like SVM, gradient boosted
    trees, and neural networks for further performance gains on challenging datasets.
    The key is to experiment with different algorithms beyond simple linear models
    to harness their strengths.
  prefs: []
  type: TYPE_NORMAL
- en: Note, however, that whether using a simple or more complex algorithm for model
    training, the Scikit-learn syntax allows for the same approach, reducing the learning
    curve dramatically. In fact, almost every task using the library can be expressed
    with the fit/transform/predict paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Model Evaluation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Importance of Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Evaluating a machine learning model's performance is an absolutely crucial step
    before final deployment into production. Comprehensively evaluating models builds
    essential trust that the system will operate reliably once deployed. It also identifies
    potential areas needing improvement to enhance the model's predictive accuracy
    and generalization ability. A model may appear highly accurate on the training
    data it was fit on, but still fail miserably on real-world data. This highlights
    the critical need to test models on held-out test sets and new data, not just
    the training data.
  prefs: []
  type: TYPE_NORMAL
- en: We must simulate how the model will perform once deployed. Rigorously evaluating
    models also provides insights into possible overfitting, where a model memorizes
    patterns in the training data but fails to learn generalizable relationships useful
    for out-of-sample prediction. Detecting overfitting prompts appropriate countermeasures
    like regularization and cross-validation. Evaluation further allows comparing
    multiple candidate models to select the best performing option. Models that do
    not provide sufficient lift over a simple benchmark model should potentially be
    re-engineered or replaced entirely.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, comprehensively evaluating machine learning models is indispensable
    for ensuring they are dependable and adding value. It is not merely an optional
    analytic exercise, but an integral part of the model development workflow that
    enables deploying truly effective systems. So machine learning practitioners should
    devote substantial effort towards properly evaluating their models across relevant
    performance metrics on representative test sets before even considering deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Train/Test Split
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We split the data to evaluate model performance on new data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: By convention, X refers to features and y refers to target variable. Please
    note that `y_test` and `iris_data.target` are different ways to refer to the same
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For classification, key metrics include:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Accuracy: Overall proportion of correct predictions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Precision: Proportion of positive predictions that are actual positives'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recall: Proportion of actual positives predicted positively'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These can be computed via Scikit-learn''s classification report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This gives us insight into model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 5: Improving Performance'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hyperparameters are model configuration settings. Tuning them can improve performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This grids over different regularization strengths to optimize model accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-Validation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cross-validation provides more reliable evaluation of hyperparameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It splits the data into 5 folds and evaluates performance on each.
  prefs: []
  type: TYPE_NORMAL
- en: Ensemble Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Combining multiple models can enhance performance. To demonstrate this, let''s
    first train a random forest model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can proceed to create an ensemble model using both our logistic regression
    and random forest models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This ensemble model combines our previously trained logistic regression model,
    referred to as `lr`, with the newly defined random forest model, referred to as
    `rf`.
  prefs: []
  type: TYPE_NORMAL
- en: Model Stacking and Blending
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More advanced ensemble techniques like stacking and blending build a meta-model
    to combine multiple base models. After training base models separately, a meta-model
    learns how best to combine them for optimal performance. This provides more flexibility
    than simple averaging or voting ensembles. The meta-learner can learn which models
    work best on different data segments. Stacking and blending ensembles with diverse
    base models often achieve state-of-the-art results across many machine learning
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This trains a random forest and SVM model separately, then trains a gradient
    boosted tree on their predictions to produce the final output. The key steps are
    generating predictions from base models on the test set, then using those predictions
    as input features to train the meta-model.
  prefs: []
  type: TYPE_NORMAL
- en: Moving Forward
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scikit-learn provides an extensive toolkit for machine learning with Python.
    In this tutorial, we covered the complete machine learning workflow using Scikit-learn
    — from installing the library and understanding its capabilities, to loading data,
    training models, evaluating model performance, tuning hyperparameters, and compiling
    ensembles. The library has become hugely popular due to its well-designed API,
    breadth of algorithms, and integration with the PyData stack. Sklearn empowers
    users to quickly and efficiently build models and generate predictions without
    getting bogged down in implementation details. With this solid foundation, you
    can now practically apply machine learning to real-world problems using Scikit-learn.
    The next step entails identifying issues that are amenable to ML techniques, and
    leveraging the skills from this tutorial to extract value.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there is always more to learn about Scikit-learn specifically and
    machine learning in general. The library implements cutting-edge algorithms like
    neural networks, manifold learning, and deep learning using its estimator API.
    You can always extend your competency by studying the theoretical workings of
    these methods. Scikit-learn also integrates with other Python libraries like Pandas
    for added data manipulation capabilities. Furthermore, a product like SageMaker
    provides a production platform for operationalizing Scikit-learn models at scale.
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial is just the starting point — Scikit-learn is a versatile toolkit
    that will continue to serve your modeling needs as you take on more advanced challenges.
    The key is to continue practicing and honing your skills through hands-on projects.
    Practical experience with the full modeling lifecycle is the best teacher. With
    diligence and creativity, Scikit-learn provides the tools to unlock deep insights
    from all kinds of data.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Matthew Mayo**](https://www.linkedin.com/in/mattmayo13/) ([**@mattmayo13**](https://twitter.com/mattmayo13))
    holds a Master''s degree in computer science and a graduate diploma in data mining.
    As Editor-in-Chief of KDnuggets, Matthew aims to make complex data science concepts
    accessible. His professional interests include natural language processing, machine
    learning algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Getting Started with Python Data Structures in 5 Steps](https://www.kdnuggets.com/5-steps-getting-started-python-data-structures)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with SQL in 5 Steps](https://www.kdnuggets.com/5-steps-getting-started-with-sql)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Google Cloud Platform in 5 Steps](https://www.kdnuggets.com/5-steps-google-cloud-platform)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with PyTorch in 5 Steps](https://www.kdnuggets.com/5-steps-getting-started-pytorch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started Cleaning Data](https://www.kdnuggets.com/2022/01/getting-started-cleaning-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
