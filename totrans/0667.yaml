- en: Comparing MobileNet Models in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html](https://www.kdnuggets.com/2019/03/comparing-mobilenet-models-tensorflow.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Harshit Dwivedi](https://harshit.app/), Android Instructor**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Header image](../Images/b19415c11ab86d4e586a957be6c5ae05.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, neural networks and deep learning have sparked tremendous progress
    in the field of [natural language processing](https://heartbeat.fritz.ai/the-7-nlp-techniques-that-will-change-how-you-communicate-in-the-future-part-i-f0114b2f0497) (NLP)
    and [computer vision](https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b).
  prefs: []
  type: TYPE_NORMAL
- en: While many of the [face](https://heartbeat.fritz.ai/building-a-real-time-face-detector-in-android-with-ml-kit-f930eb7b36d9), [object](https://heartbeat.fritz.ai/counting-items-in-real-time-on-android-with-fritz-object-detection-c450d6957448),
    landmark, logo, and [text recognition](https://heartbeat.fritz.ai/choose-the-right-on-device-text-recognition-sdk-on-android-using-deltaml-9b4b3e409b6e) and
    detection technologies are provided for Internet-connected devices, we believe
    that the [ever-increasing computational power of mobile devices](https://heartbeat.fritz.ai/hardware-acceleration-for-machine-learning-on-apple-and-android-f3e6ca85bda6) can
    enable the delivery of these technologies into the hands of users anytime, anywhere,
    regardless of Internet connection.
  prefs: []
  type: TYPE_NORMAL
- en: However, computer vision for on-device and embedded applications faces many
    challenges — models must run quickly with high accuracy in a resource-constrained
    environment, making use of limited computation, power, and space.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow offers various pre-trained models, such as drag-and-drop models,
    in order to identify approximately 1,000 default objects.
  prefs: []
  type: TYPE_NORMAL
- en: When compared with other similar models, such as the [Inception](https://github.com/tensorflow/models/tree/master/research/inception) model
    datasets, [MobileNet](https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d) works
    better with latency, size, and accuracy. In terms of output performance, there
    is a significant amount of lag with a full-fledged model.
  prefs: []
  type: TYPE_NORMAL
- en: However, the trade-off is acceptable when the model is deployable on a mobile
    device for real-time offline detection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example of how to use MobileNet. We will write a simple classifier
    to find Pikachu in an image. The following are sample pictures showing an image
    of Pikachu and an image without Pikachu:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/bf3576eec85638c94663edb9e2286300.png)'
  prefs: []
  type: TYPE_IMG
- en: Pikachu![Figure](../Images/8ed1ecdd534c72ece76faecdf43ef50b.png)
  prefs: []
  type: TYPE_NORMAL
- en: Not Pikachu, assuming there’s no Pikachu to collect in Pokémon Go…
  prefs: []
  type: TYPE_NORMAL
- en: Building the dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To build our own classifier, we need to have datasets that contain images with
    and without Pikachu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with 1,000 images on each database. You can pull such images here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**CC Search**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Creative Commons licenses provide a flexible range of protections and freedoms
    for authors, artists, and educators.*'
  prefs: []
  type: TYPE_NORMAL
- en: search.creativecommons.org](https://search.creativecommons.org/)
  prefs: []
  type: TYPE_NORMAL
- en: Next up, let’s create two folders named **pikachu** and **no-pikachu** and drop
    those images accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another handy dataset containing images for all the generation one Pokémon
    can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Pokemon Generation One**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Gotta train ''em all!*'
  prefs: []
  type: TYPE_NORMAL
- en: www.kaggle.com](https://www.kaggle.com/thedagger/pokemon-generation-one)
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have an image folder, which is structured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Retraining Images**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now start labeling our images. With TensorFlow, this job becomes easier.
    Assuming that TensorFlow [is installed](https://www.tensorflow.org/install/) on
    the training machine already, download the following retraining script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we’ll retrain the image with this Python script :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Note : If you set `validation_batch_size` to -1, it will validate the whole
    dataset. `learning_rate` = 0.0001 works well. You can adjust and try this for
    yourself.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the `architecture` flag, we choose which version of MobileNet to use, from
    versions 1.0, 0.75, 0.50, and 0.25\. The suffix number 224 represents the image
    resolution. You can specify 224, 192, 160, or 128 as well.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Model conversion from GraphDef to TFLite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: TOCO Converter is used to convert from a TensorFlow GraphDef file or SavedModel
    into either a TFLite FlatBuffer or graph visualization.
  prefs: []
  type: TYPE_NORMAL
- en: (TOCO stands for [**TensorFlow Lite Optimizing Converter**.](https://www.tensorflow.org/lite/convert/))
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to pass the data through command-line arguments. There are a few command-line
    arguments that can be passed in while converting the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now use the TOCO tool to convert the TensorFlow model into a [TensorFlow
    Lite](https://heartbeat.fritz.ai/how-tensorflow-lite-optimizes-neural-networks-for-mobile-machine-learning-e6ffa7f8ee12) model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, we can use the MobileNet model in similar applications; for example,
    in the next section, we’ll be looking at a gender model and an emotion model.
  prefs: []
  type: TYPE_NORMAL
- en: Gender Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This model uses the [IMDB WIKI dataset](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/),
    which contains 500k+ celebrity faces. It uses the MobileNet_V1_224_0.5 version
    of MobileNet.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is very rare to find public datasets with thousands of images. This dataset
    is built on top of a large collection of celebrity faces. There are two common
    places: one is IMDb and the other one is Wikipedia. More than 100K celebrities’
    details were retrieved from their profiles from both sources through scripts.'
  prefs: []
  type: TYPE_NORMAL
- en: Then it was organized by removing noise (irrelevant content). All the images
    without a timestamp were removed, assuming that images with a single photo are
    likely to show the person with correct birth date details. At the end, there were
    460,723 faces from 20,284 celebrities from IMDb, and 62,328 from Wikipedia, for
    a total of 523,051.
  prefs: []
  type: TYPE_NORMAL
- en: Emotion model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is built on the AffectNet model with more than 1 million images. It uses
    the MobileNet_V2_224_1.4 version of MobileNet.
  prefs: []
  type: TYPE_NORMAL
- en: 'The link to the data model project can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**AffectNet - Mohammad H. Mahoor, PhD**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Currently the test set is not released. We are planning to organize a challenge
    on AffectNet in near future and the…*'
  prefs: []
  type: TYPE_NORMAL
- en: mohammadmahoor.com](http://mohammadmahoor.com/affectnet/)
  prefs: []
  type: TYPE_NORMAL
- en: The AffectNet model is built by collecting and annotating facial images of more
    than 1 million faces from the Internet. The images were sourced from three search
    engines, using around 1,250 related keywords in six different languages.
  prefs: []
  type: TYPE_NORMAL
- en: Among the collected images, half of the images were manually annotated for the
    presence of seven discrete facial expressions (categorical model) and the intensity
    of valence and arousal (dimensional model).
  prefs: []
  type: TYPE_NORMAL
- en: Comparison of MobileNet Versions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In both of the above models, different versions of MobileNet models are used.
    MobileNet V2 is mostly an updated version of V1 that makes it even more efficient
    and powerful in terms of performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/555491ca9161425d40ad4aa667cf92bc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Note: Lower is better'
  prefs: []
  type: TYPE_NORMAL
- en: MACs are [multiply-accumulate operations](https://www.semanticscholar.org/topic/Multiply%E2%80%93accumulate-operation/408575),
    which measure how many calculations are needed to perform inference on a single
    224×224 RGB image.
  prefs: []
  type: TYPE_NORMAL
- en: From the number of MACs alone, V2 should be almost twice as fast as V1\. However,
    it’s not just about the number of calculations. On mobile devices, [memory access](https://heartbeat.fritz.ai/profiling-your-app-with-android-studio-7accc268cb98) is
    much slower than computation. V2 only has 80% of the parameter count that V1 has
    hence making it better than V1.
  prefs: []
  type: TYPE_NORMAL
- en: By seeing the results we can assume that V2 is almost twice as fast as V1 model.
    On a mobile device when memory access is limited, the computational capability
    of V2 works very well.
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/7986e778d85c5164a94878ca5b376c05.png)'
  prefs: []
  type: TYPE_IMG
- en: Here MobileNet V2 is slightly, if not significantly, better than V1.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MobileNets are a family of *mobile-first* computer vision models for [TensorFlow](https://www.tensorflow.org/),
    designed to effectively maximize accuracy while being mindful of the restricted
    resources for an on-device or embedded application.
  prefs: []
  type: TYPE_NORMAL
- en: MobileNets are small, low-latency, low-power models parameterized to meet the
    resource constraints of a variety of use cases. They can be built upon for classification,
    detection, embeddings, and segmentation, similar to how other popular large scale
    models, such as [Inception](https://arxiv.org/pdf/1602.07261.pdf), are used.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to go ahead and fuel your curiosity, a bunch of pre trained models
    can be found here :'
  prefs: []
  type: TYPE_NORMAL
- en: '[**tensorflow/models**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Models and examples built with TensorFlow. Contribute to tensorflow/models
    development by creating an account on…*'
  prefs: []
  type: TYPE_NORMAL
- en: github.com](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, here’s a blog post outlining how you can build a real like Pokémon classifier
    using MobileNets and TensorFlow Lite:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Building “Pokédex” in Android using TensorFlow Lite and Firebase’s ML Kit**'
  prefs: []
  type: TYPE_NORMAL
- en: heartbeat.fritz.ai](https://heartbeat.fritz.ai/building-pok%C3%A9dex-in-android-using-tensorflow-lite-and-firebase-cc780848395)
  prefs: []
  type: TYPE_NORMAL
- en: '*Thanks for reading! If you enjoyed this story, please ****click the ***????*** button******and
    share ****to help others find it! Feel free to leave a comment *????* below. Have
    feedback? Let’s connect *[*on Twitter*](https://twitter.com/daggerdwivedi)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you found this article interesting, you can explore *[*Machine Learning
    Projects for Mobile Applications*](https://www.amazon.com/Machine-Learning-Projects-Mobile-Applications/dp/1788994590)*.
    Written by Karthikeyan MG, an ML expert, *[*Machine Learning Projects for Mobile
    Applications*](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-projects-mobile-applications)* presents
    the implementation of 7 practical, real-world projects that will teach you how
    to leverage TensorFlow Lite and Core ML to perform efficient machine learning
    on a cross-platform mobile OS.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Want to start building amazing Android Apps? Check out my course on Coding
    Bocks: ***[https://online.codingblocks.com/courses/android-app-training-online](https://online.codingblocks.com/courses/android-app-training-online)'
  prefs: []
  type: TYPE_NORMAL
- en: Ready to dive into some code? Check out [Fritz on GitHub](https://github.com/fritzlabs).
    You’ll find open source, mobile-friendly implementations of the popular machine
    and deep learning models along with training scripts, project templates, and tools
    for building your own ML-powered iOS and Android apps.
  prefs: []
  type: TYPE_NORMAL
- en: Join us on [Slack](https://join.slack.com/t/heartbeat-by-fritz/shared_invite/enQtNTI4MDcxMzI1MzAwLWIyMjRmMGYxYjUwZmE3MzA0MWQ0NDk0YjA2NzE3M2FjM2Y5MjQxMWM2MmQ4ZTdjNjViYjM3NDE0OWQxOTBmZWI)
    for help with technical problems, to share what you’re working on, or just chat
    with us about mobile development and machine learning. And follow us on [Twitter](https://twitter.com/fritzlabs)
    and [LinkedIn](https://www.linkedin.com/company/fritz-labs-inc/) for the all the
    latest content, news, and more from the mobile machine learning world.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to [Austin Kodra](https://medium.com/@austin_32493?source=post_page).
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Harshit Dwivedi](https://harshit.app/)** has an *approximate* knowledge
    of many things. He''s an Android instructor at Coding Blocks, a contributing author
    for Heartbeat, by Fritz, public speaker, & Astrophysics enthusiast.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://heartbeat.fritz.ai/exploring-the-mobilenet-models-in-tensorflow-d9d21774cdab).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to do Everything in Computer Vision](/2019/02/everything-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Best Mobile Apps for Data Scientist / Data Analysts](/2018/10/10-best-mobile-apps-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[State of the art in AI and Machine Learning – highlights of papers with code](/2019/02/paperswithcode-ai-machine-learning-highlights.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PyTorch or TensorFlow? Comparing popular Machine Learning frameworks](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Comparing Natural Language Processing Techniques: RNNs, Transformers, BERT](https://www.kdnuggets.com/comparing-natural-language-processing-techniques-rnns-transformers-bert)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The "Hello World" of Tensorflow](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
