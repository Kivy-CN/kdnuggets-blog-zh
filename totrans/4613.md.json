["```py\n# pretrained models are at torchvision > models\nmodel = torchvision.models.resnet152(pretrained=False)\n```", "```py\nconda install numpy jupyter notebook\nconda install pytorch torchvision -c pytorch\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport os\nprint(os.listdir(\"../input/cell_images/cell_images/\"))\n```", "```py\n# Define your transforms for the training, validation, and testing sets\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n transforms.RandomResizedCrop(224),\n transforms.RandomVerticalFlip(),\n transforms.ToTensor(),\n transforms.Normalize([0.485, 0.456, 0.406], \n [0.229, 0.224, 0.225])])test_transforms = transforms.Compose([transforms.Resize(256),\n transforms.CenterCrop(224),\n transforms.ToTensor(),\n transforms.Normalize([0.485, 0.456, 0.406], \n [0.229, 0.224, 0.225])])validation_transforms = transforms.Compose([transforms.Resize(256),\n transforms.CenterCrop(224),\n transforms.ToTensor(),\n transforms.Normalize([0.485, 0.456, 0.406], \n [0.229, 0.224, 0.225])])\n```", "```py\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Source 4\n```", "```py\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n```", "```py\nimg_dir='../input/cell_images/cell_images/'\ntrain_data = datasets.ImageFolder(img_dir,transform=train_transforms)... # omitted\n*# convert data to a normalized torch.FloatTensor*\n... # omitted\n\n*# obtain training indices that will be used for validation*\n... # omitted\nprint(len(valid_idx), len(test_idx), len(train_idx))\n\n*# define samplers for obtaining training and validation batches*\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\ntest_sampler = SubsetRandomSampler(test_idx)\n\n*# prepare data loaders (combine dataset and sampler)*\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=64,sampler=train_sampler, num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=32, sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(train_data, batch_size=20, sampler=test_sampler, num_workers=num_workers)\n```", "```py\nfrom collections import OrderedDictclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(2048, 1024)),\n                          ('relu', nn.ReLU()),\n                          ('dropout',nn.Dropout(0.2)),\n                          ('fc2', nn.Linear(1024, 512)),\n                          ('relu', nn.ReLU()),\n                          ('dropout',nn.Dropout(0.2)),\n                          ('fc3', nn.Linear(512, 256)),\n                          ('relu', nn.ReLU()),\n                          ('dropout',nn.Dropout(0.2)),\n                          ('fc4', nn.Linear(256, 102)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))model.classifier = classifier\n```", "```py\nmodel = models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False # turn all gradient off\n\nmodel.fc = nn.Linear(2048, 2, bias=True) \n#add new fully connected layer\n\nfc_parameters = model.fc.parameters()\n\nfor param in fc_parameters:\n    param.requires_grad = True #turning last layer gradient to true\n\nmodel\n```", "```py\nDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/.torch/models/resnet50-19c8e357.pth\n100%|██████████| 102502400/102502400 [00:01<00:00, 89692748.86it/s]\n```", "```py\n(layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n```", "```py\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n... #omitted\n    ... #omitted\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace)\n    )\n  )\n  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n  (fc): Linear(in_features=2048, out_features=2, bias=True)\n)\n```", "```py\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    model = model.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(), lr=0.001 , momentum=0.9)\n```", "```py\ndef train(n_epochs, model, optimizer, criterion, use_cuda, save_path):\n    *\"\"\"returns trained model\"\"\"*\n    *# initialize tracker for minimum validation loss*\n    valid_loss_min = np.Inf\n\n    for epoch in range(1, n_epochs+1):\n        *# initialize variables to monitor training and validation loss*\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        *###################*\n        *# train the model #*\n        *###################*\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            *# move to GPU*\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            *# initialize weights to zero*\n            optimizer.zero_grad()\n\n            output = model(data)\n\n            *# calculate loss*\n            loss = criterion(output, target)\n\n            *# back prop*\n            loss.backward()\n\n            *# grad*\n            optimizer.step()\n\n            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n\n            if batch_idx % 100 == 0:\n                print('Epoch %d, Batch %d loss: %.6f' %\n                  (epoch, batch_idx + 1, train_loss))\n\n        *######################* \n        *# validate the model #*\n        *######################*\n        model.eval()\n        for batch_idx, (data, target) in enumerate(valid_loader):\n            *# move to GPU*\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            *## update the average validation loss*\n            output = model(data)\n            loss = criterion(output, target)\n            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n\n        *# print training/validation statistics* \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n\n        *## TODO: save the model if validation loss has decreased*\n        if valid_loss < valid_loss_min:\n            torch.save(model.state_dict(), save_path)\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            valid_loss_min = valid_loss\n\n    *# return trained model*\n    return model\n```", "```py\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms, models\nimport torch.nn.functional as F\nfrom collections import OrderedDict\nfrom torch import nn\nfrom torch import optim\n```", "```py\nimport torch\nimport numpy as np\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n```", "```py\nvgg16 = models.vgg16(pretrained=True)\nprint(vgg16)\n```", "```py\nVGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n...\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n...\n    (29): ReLU(inplace)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace)\n    (2): Dropout(p=0.5)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace)\n    (5): Dropout(p=0.5)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n```", "```py\ngpu_is_avail = torch.cuda.is_available()if not gpu_is_avail:\n     print('CUDA is NOT available.')\nelse:\n     print('CUDA is available. ')device = torch.device(“cuda” if torch.cuda.is_available() else “cpu”)\n```", "```py\ntorch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\nReturns the k largest elements of the given input tensor along a given dimension.\nIf dim is not given, the last dimension of the input is chosen.\nIf largest is False then the k smallest elements are returned.\n```", "```py\nimport torch.onnx\n  import torchvision\n\n  dummy_input = torch.randn(1, 3, 224, 224)\n  model = torchvision.models.alexnet(pretrained=True)\n  torch.onnx.export(model, dummy_input, \"alexnet.onnx\")\n```", "```py\nfor param in model.parameters():\n param.requires_grad = False\n```", "```py\n#define scheduler\nscheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n```", "```py\n# write and then use your custom load_checkpoint function\nmodel = load_checkpoint('checkpoint_resnet50.pth')\nprint(model)# use pytorch torch.load and load_state_dict(state_dict)\ncheckpt = torch.load(‘checkpoint_resnet50.pth’)\nmodel.load_state_dict(checkpt)#save locally, map the new class_to_idx, move to cpu\n#note down model architecturecheckpoint['class_to_idx']\nmodel.class_to_idx = image_datasets['train'].class_to_idx\nmodel.cpu()\ntorch.save({'arch': 'resnet18',\n           'state_dict': model.state_dict(),\n           'class_to_idx': model.class_to_idx},\n           'classifier.pth')\n```", "```py\nmodel.load_state_dict(torch.load('malaria_detection.pt'))\n```", "```py\ndef test(model, criterion, use_cuda):\n\n   ... #omitted\n        *# convert output probabilities to predicted class*\n        pred = output.data.max(1, keepdim=True)[1]\n        *# compare predictions to true label*\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n    .... #omitteddef load_input_image(img_path):    \n    image = Image.open(img_path)\n    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n                                     transforms.ToTensor(), \n                                     transforms.Normalize([0.485, 0.456, 0.406], \n                                                          [0.229, 0.224, 0.225])])\n\n    *# discard the transparent, alpha channel (that's the :3) and add the batch dimension*\n    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n    return imagedef predict_malaria(model, class_names, img_path):\n    *# load the image and return the predicted breed*\n    img = load_input_image(img_path)\n    model = model.cpu()\n    model.eval()\n    idx = torch.argmax(model(img))\n    return class_names[idx]\n```", "```py\n>>> import torch\n>>> import numpy as np\n>>> test = torch.tensor([[1,2,3]])\n>>> np.squeeze(test)\ntensor([1, 2, 3])\n>>> torch.tensor([1]).unsqueeze(0)\ntensor([[1]])\n```"]