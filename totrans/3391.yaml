- en: How to Rank 10% in Your First Kaggle Competition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Linghao Zhang, Fudan University**.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Kaggle](https://www.kaggle.com/) is the best place to learn from other data
    scientists. Many companies provide data and prize money to set up data science
    competitions on Kaggle. Recently I had my first shot on Kaggle and **ranked 98th
    (~ 5%) among 2125 teams**. Being my Kaggle debut, I feel quite satisfied with
    the result. Since many Kaggle beginners set 10% as their first goal, I want to
    share my two cents on how to achieve that.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '*This post is also available in [Chinese](https://dnc1994.com/2016/04/rank-10-percent-in-first-kaggle-competition/).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Updated on Oct 28th, 2016: **I made many wording changes and added several
    updates to this post. Note that Kaggle has went through some major changes since
    I published this post, especially with its ranking system. Therefore some descriptions
    here might not apply anymore.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Kaggle Profile](../Images/825b26f93f6aec236dc71f058aed8992.png)](http://7xlo8f.com1.z0.glb.clouddn.com/blog-kaggle_profile.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Most Kagglers use Python or R. I prefer Python, but R users should have no difficulty
    in understanding the ideas behind tools and languages.
  prefs: []
  type: TYPE_NORMAL
- en: First let’s go through some facts about Kaggle competitions in case you are
    not familiar with them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Different competitions have different tasks: classifications, regressions,
    recommendations… Training set and testing set will be open for download after
    the competition launches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A competition typically lasts for 2 ~ 3 months. Each team can submit for a limited
    number of times per day. Usually it’s 5 times a day.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There will be a 1st submission deadline one week before the end of the competition,
    after which you cannot merge teams or enter the competition. Therefore **be sure
    to have at least one valid submission before that.**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will get you score immediately after the submission. Different competitions
    use different scoring metrics, which are explained by the question mark on the
    leaderboard.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The score you get is calculated on a subset of testing set, which is commonly
    referred to as a **Public LB** score. Whereas the final result will use the remaining
    data in the testing set, which is referred to as a **Private LB** score.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The score you get by local cross validation is commonly referred to as a **CV** score.
    Generally speaking, CV scores are more reliable than LB scores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beginners can learn a lot from **Forum** and **Scripts**. Do not hesitate to
    ask about anything. Kagglers are in general very kind and helpful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I assume that readers are familiar with basic concepts and models of machine
    learning. Enjoy reading!
  prefs: []
  type: TYPE_NORMAL
- en: General Approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, I will walk you through the process of a Kaggle competition.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Exploration**'
  prefs: []
  type: TYPE_NORMAL
- en: What we do at this stage is called **EDA (Exploratory Data Analysis)**, which
    means analytically exploring data in order to provide some insights for subsequent
    processing and modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Usually we would load the data using **[Pandas](http://pandas.pydata.org/)** and
    make some visualizations to understand the data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Visualization**'
  prefs: []
  type: TYPE_NORMAL
- en: For plotting, **[Matplotlib](http://matplotlib.org/)** and **[Seaborn](https://stanford.edu/~mwaskom/software/seaborn/)** should
    suffice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some common practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Inspect the distribution of target variable. Depending on what scoring metric
    is used,**an [imbalanced](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5128907) distribution
    of target variable might harm the model’s performance**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For **numerical variables**, use **box plot** and **scatter plot** to inspect
    their distributions and check for outliers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For classification tasks, plot the data with points colored according to their
    labels. This can help with feature engineering.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make pairwise distribution plots and examine their correlations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be sure to read [this inspiring tutorial of exploratory visualization](https://www.kaggle.com/benhamner/d/uciml/iris/python-data-visualizations) before
    you go on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Statistical Tests**'
  prefs: []
  type: TYPE_NORMAL
- en: We can perform some statistical tests to confirm our hypotheses. Sometimes we
    can get enough intuition from visualization, but quantitative results are always
    good to have. Note that we will always encounter non-i.i.d. data in real world.
    So we have to be careful about which test to use and how we interpret the findings.
  prefs: []
  type: TYPE_NORMAL
- en: In many competitions public LB scores are not very consistent with local CV
    scores due to noise or non-i.i.d. distribution. You can use test results to **roughly
    set a threshold for determining whether an increase of score is due to genuine
    improvment or randomness**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Preprocessing**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In most cases, we need to preprocess the dataset before constructing features.
    Some common steps are:'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes several files are provided and we need to join them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deal with **[missing data](https://en.wikipedia.org/wiki/Missing_data)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deal with **[outliers](https://en.wikipedia.org/wiki/Outlier)**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encode **[categorical variables](https://en.wikipedia.org/wiki/Categorical_variable)** if
    necessary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deal with noise. For example you may have some floats derived from raw figures.
    The loss of precision during floating-point arithemics can bring much noise into
    the data: two seemingly different values might be the same before conversion.
    Sometimes noise harms model and we would want to avoid that.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How we choose to perform preprocessing largely depends on what we learn about
    the data in the previous stage. In practice, I recommend using **[Jupyter Notebook](http://ipython.org/notebook.html)** for
    data manipulation and mastering usage of frequently used Pandas operations. The
    advantage is that you get to see the results immediately and are able to modify
    or rerun code blocks. This also makes it very convenient to share your approach
    with others. After all[reproducible results](https://en.wikipedia.org/wiki/Reproducibility) are
    very important in data science.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see some examples.
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How LinkedIn Uses Machine Learning To Rank Your Feed](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[It''s alive! Build your first robots with Python and some cheap,…](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Zero to Hero: Create Your First ML Model with PyTorch](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deploying Your First Machine Learning Model](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
