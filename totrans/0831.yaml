- en: Harnessing ChatGPT for Automated Data Cleaning and Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/253506759c944a8380bc213fa5f4eaa5.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT has become a swiss-army knife that can be used for multitude of applications,
    and there’s abundant scope to integrate ChatGPT into data science workflows.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: If you’ve ever trained a machine learning model on a real-world dataset, you
    know that the steps of data cleaning and preprocessing are important for building
    robust machine learning models. In this guide, we’ll see how we can use ChatGPT
    to perform these tasks on an example dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the [bank marketing dataset from the UCI machine learning repository](https://archive.ics.uci.edu/dataset/222/bank+marketing)
    and prompt ChatGPT to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Fetch and load the dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check for missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encode categorical variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can follow along by signing in to your [OpenAI account](https://platform.openai.com/login)
    and starting a new ChatGPT session. If you prefer, you can also code along in
    [Google Colab](https://colab.research.google.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Fetching and Loading the Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a [few different versions of the dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing).
    We’ll use bank-full.csv.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Today we’ll perform data cleaning and preprocessing on a real-world
    dataset. Write the code to do the following: 1\. Fetch the bank marketing dataset
    from the UCI machine learning repository. Use libraries like requests or urllib.
    2\. Download the zip file, unzip the contents, and read in the bank-full.csv file
    into a pandas dataframe (call it data).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The code to fetch and read in the dataset is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Getting Basic Info on the Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's understand the dataset better.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/c943e5830c9d9e43f5e1034a1e06e925.png)'
  prefs: []
  type: TYPE_IMG
- en: Truncated output of data.head()
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Use pandas to get the dimension of the dataframe, descriptive statistics
    on the columns, and data types of various columns.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This step doesn’t really require prompting ChatGPT as the pandas methods are
    pretty simple.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We have over 45000 records and 16 features (as 17 is inclusive of the output
    label as well).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/cb09912fbc4731c724029ebaedb9c3dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Truncated output of data.describe()
  prefs: []
  type: TYPE_NORMAL
- en: It’s also helpful to get an overview of the data types of the various columns.
    We’ll take a closer look at them when we encode categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: So far we’ve gained an understanding of the bank marketing dataset. The output
    label denotes whether or not a customer will subscribe to a term deposit. The
    dataset contains several features such as the age, month, education, marital status,
    outcome of previous campaigns, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Checking for Missing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Prompt**: I want to know the number of missing values in each column. Please
    give me the code to do it. Use pandas.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This version of the bank marketing dataset—with over 45000 records—does not
    have any missing values. In practice, though, most real-world datasets have missing
    values. You should handle missing values using suitable imputation techniques.
  prefs: []
  type: TYPE_NORMAL
- en: As an optional exercise , you can add a step here prompting ChatGPT to drop
    a small fraction of values from a subset of columns so you can practice how to
    handle missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Encoding Categorical Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next step is to encode categorical variables in the dataset. We’ll start
    by getting the list of all categorical columns.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Give the code to get the list of all categorical columns in this
    dataset.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The categorical columns list also includes the output label **y**. But let's
    focus on the other categorical variables first.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A Closer Look at the Values of Categorical Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, let’s see the values that each categorical variable takes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: I want to understand the various values that each categorical variable
    takes. Give the pandas code to do it.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is hard to parse:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing the Values of Categorical Variables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s prompt ChatGPT to create a visualization so it’s easier to understand
    what values the categorical variables take.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: I want a plot that shows the values that each categorical variable
    takes. Exclude the output label y. Include all other categorical variables.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And here we go!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/e27c7a292f8f5588afd63b06a0a27503.png)'
  prefs: []
  type: TYPE_IMG
- en: Values of Categorical Variables
  prefs: []
  type: TYPE_NORMAL
- en: One-Hot Encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a subset of categorical columns, we can use one-hot encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Give the pandas code to perform one-hot encoding for a list of
    columns.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We use `get_dummies` from pandas to one-hot encode the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**Prompt**: I want to print out the first few rows for the newly added columns.
    Write the code to do the same.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/9bc20dfbab384edf86a1e63b3a860186.png)'
  prefs: []
  type: TYPE_IMG
- en: Truncated output of encoded_data['new_colums'].head()
  prefs: []
  type: TYPE_NORMAL
- en: Defining a Custom Mapping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For columns for variables like ‘education’ and ‘poutcome’ (previous outcome),
    rather than one-hot encoding, it would be better to use custom mapping to have
    a degree of comparison between the values.
  prefs: []
  type: TYPE_NORMAL
- en: Also, when we use one-hot encoding to encode a categorical variable that takes
    k distinct values k new columns. For a categorical column like ‘month’ this will
    be excessive without adding much information.
  prefs: []
  type: TYPE_NORMAL
- en: So for both of these cases, we will define a custom mapping and then transform
    the values. We can prompt ChatGPT to get a generic code snippet which we can then
    modify to define the mapping for the specific columns.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: I want to do a custom mapping for encoding some categorical variables.
    First give me a generic code snippet that defines a custom mapping from unique
    values in a categorical column to a different set of output values. We should
    then use this mapping to transform the values in the columns.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'For the ‘month’ column, let us transform the month strings like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s map the ‘poutcome’ and ‘education’ columns to numerical values as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Encoding the Output Label
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's also map the output labels 'yes' and 'no' to 1 and 0, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Recall that we used one-hot encoding for ‘housing’, ‘default’, and ‘loan’ columns.
    Because these columns also take ‘yes’ and ‘no’ values, you can also map ‘yes’
    and ‘no’ to 1 and 0, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the Distribution of Class Labels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s also helpful to check the distribution of class labels so that we can account
    for class imbalance when building models if needed.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: I would like to understand the distribution of class labels. Please
    give me the code to generate a suitable plot for the same.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s the code to generate a countplot in Seaborn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](../Images/3124a915de369d6eac9b0510c9911766.png)'
  prefs: []
  type: TYPE_IMG
- en: Distribution of Class Labels
  prefs: []
  type: TYPE_NORMAL
- en: We see that there is class imbalance. So if you are building a model, you should
    be sure to address class imbalance using appropriate resampling methods.
  prefs: []
  type: TYPE_NORMAL
- en: Generic Data Cleaning and Preprocessing Pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though data cleaning and preprocessing require efforts from the developer, let’s
    try to get a generic sequence of steps that works reasonably well for a simple
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt**: Can you give me a generic data cleaning and preprocessing pipeline
    based on what we’ve done so far. Get basic info on the dataset, check for and
    handle missing values, identify categorical columns, and encode categorical columns.
    Use only pandas.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'And here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Wrapping Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As seen, data science expertise in synergy with ChatGPT can help make data cleaning
    and preprocessing simpler and faster. Now that you have the preprocessed dataset
    ready, you can take this further by building a simple predictive model on this
    bank marketing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: If interested, you can also explore how to leverage [ChatGPT for data exploration](/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html).
  prefs: []
  type: TYPE_NORMAL
- en: Dataset Credits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The bank marketing dataset is licensed under a [Creative Commons Attribution
    4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/legalcode)
    license.
  prefs: []
  type: TYPE_NORMAL
- en: Moro,S., Rita,P., and Cortez,P.. (2012). Bank Marketing. UCI Machine Learning
    Repository. [https://doi.org/10.24432/C5K306](https://doi.org/10.24432/C5K306).
  prefs: []
  type: TYPE_NORMAL
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a developer
    and technical writer from India. She likes working at the intersection of math,
    programming, data science, and content creation. Her areas of interest and expertise
    include DevOps, data science, and natural language processing. She enjoys reading,
    writing, coding, and coffee! Currently, she''s working on learning and sharing
    her knowledge with the developer community by authoring tutorials, how-to guides,
    opinion pieces, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3 Steps for Harnessing the Power of Data](https://www.kdnuggets.com/2022/05/3-steps-harnessing-power-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unveiling the Potential of CTGAN: Harnessing Generative AI for…](https://www.kdnuggets.com/2023/04/unveiling-potential-ctgan-harnessing-generative-ai-synthetic-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Easy Guide To Data Preprocessing In Python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
