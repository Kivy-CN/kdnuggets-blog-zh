- en: Explainable Artificial Intelligence (Part 2) – Model Interpretation Strategies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释人工智能（第2部分）——模型解释策略
- en: 原文：[https://www.kdnuggets.com/2018/12/explainable-ai-model-interpretation-strategies.html](https://www.kdnuggets.com/2018/12/explainable-ai-model-interpretation-strategies.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/12/explainable-ai-model-interpretation-strategies.html](https://www.kdnuggets.com/2018/12/explainable-ai-model-interpretation-strategies.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/12/explainable-ai-model-interpretation-strategies.html?page=2#comments)![Figure](../Images/259329bfc9d56d238c06bba517984824.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/explainable-ai-model-interpretation-strategies.html?page=2#comments)![图](../Images/259329bfc9d56d238c06bba517984824.png)'
- en: 'Source: Pixabay'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Pixabay
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: This article is a continuation in my series of articles aimed at ***‘Explainable
    Artificial Intelligence (XAI)’***. If you haven’t checked out the first article,
    I would definitely recommend you to take a quick glance at [***‘Part I — The Importance
    of Human Interpretable Machine Learning’***](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)which
    covers the what and why of human interpretable machine learning and the need and
    importance of model interpretation along with its scope and criteria. In this
    article, we will be picking up from where we left off and expand further into
    the criteria of machine learning model interpretation methods and explore techniques
    for interpretation based on scope. The aim of this article is to give you a good
    understanding of existing, traditional model interpretation methods, their limitations
    and challenges. We will also cover the classic model accuracy vs. model interpretability
    trade-off and finally take a look at the major strategies for model interpretation.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是我系列文章的延续，旨在探讨 ***‘可解释人工智能（XAI）’***。如果你还没有查看第一篇文章，我强烈建议你快速浏览一下 [***‘第I部分——人类可解释的机器学习的重要性’***](https://towardsdatascience.com/human-interpretable-machine-learning-part-1-the-need-and-importance-of-model-interpretation-2ed758f5f476)，其中涵盖了人类可解释的机器学习的定义和重要性，以及模型解释的需求和重要性，以及其范围和标准。在本文中，我们将从中断的地方继续，并进一步扩展机器学习模型解释方法的标准，探索基于范围的解释技术。本文的目的是让你对现有的传统模型解释方法、它们的局限性和挑战有一个良好的理解。我们还将讨论经典的模型准确性与模型可解释性权衡，最后了解主要的模型解释策略。
- en: Briefly, we will be covering the following aspects in this article.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们将在本文中涵盖以下几个方面。
- en: Traditional Techniques for Model Interpretation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统模型解释技术
- en: Challenges and Limitations of Traditional Techniques
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统技术的挑战与局限
- en: The Accuracy vs. Interpretability trade-off
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确性与可解释性权衡
- en: Model Interpretation Techniques
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型解释技术
- en: This should get us set and ready for the detailed hands-on guide to model interpretation
    coming in Part 3, so stay tuned!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们即将到来的详细实践指南《模型解释》第3部分做好准备，敬请关注！
- en: Traditional Techniques for Model Interpretation
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 传统模型解释技术
- en: Model interpretation at heart, is to find out ways to understand model decision
    making policies better. This is to enable fairness, accountability and transparency
    which will give humans enough confidence to use these models in real-world problems
    which a lot of impact to business and society. Hence, there are techniques which
    have existed for a long time now, which can be used to understand and interpret
    models in a better way. These can be grouped under the following two major categories.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 模型解释的核心在于找到更好理解模型决策制定政策的方法。这是为了实现公平性、问责制和透明度，使人们对在现实世界中使用这些模型充满信心，这对商业和社会有很大影响。因此，已经存在许多技术，可以用来更好地理解和解释模型。这些技术可以分为以下两个主要类别。
- en: '**Exploratory analysis and visualization techniques** like *clustering *and *dimensionality
    reduction*.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索性分析和可视化技术** 如 *聚类* 和 *降维*。'
- en: '**Model performance evaluation metrics** like [*precision, recall, accuracy*](https://en.wikipedia.org/wiki/Confusion_matrix)*, *[*ROC
    curve and the AUC*](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) (for
    classification models) and the [*coefficient of determination (R-square)*](https://en.wikipedia.org/wiki/Coefficient_of_determination)*, *[*root
    mean-square error, mean absolute error*](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d) (for
    regression models)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能评估指标** 如[*精确度、召回率、准确率*](https://en.wikipedia.org/wiki/Confusion_matrix)*，*[*ROC曲线和AUC*](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)（用于分类模型）和[*决定系数（R平方）*](https://en.wikipedia.org/wiki/Coefficient_of_determination)*，*[*均方根误差、平均绝对误差*](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)（用于回归模型）'
- en: Let’s briefly take a more detailed look at these techniques.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要详细了解这些技术。
- en: '**Exploratory Analysis and Visualization**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性分析和可视化**'
- en: The idea of exploratory analysis is not something entirely new. For years now,
    data visualization has been one of the most effective tools for getting latent
    insights from data. Some of these techniques can help us in identifying key features
    and meaningful representations from our data which can give an indication of what
    might be influential for a model to take decisions in a human-interpretable form.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性分析的理念并非全新。多年来，数据可视化一直是从数据中获取潜在洞察的最有效工具之一。这些技术中的一些可以帮助我们识别数据中的关键特征和有意义的表示，这可能指示模型在决策时哪些因素对人类可解释形式的模型影响较大。
- en: Dimensionality reduction techniques are very useful here since often we deal
    with a very large feature space (curse of dimensionality) and reducing the feature
    space helps us visualize and see what might be influencing a model to take specific
    decisions. Some of these techniques are as follows.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 降维技术在这里非常有用，因为我们通常处理的是非常大的特征空间（维度诅咒），减少特征空间有助于我们可视化并查看哪些因素可能影响模型做出特定决策。以下是一些这些技术。
- en: '**Dimensionality reduction: **[Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis), [Self-organizing
    maps (SOM)](https://en.wikipedia.org/wiki/Self-organizing_map), [Latent Semantic
    Indexing](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维：** [主成分分析（PCA）](https://en.wikipedia.org/wiki/Principal_component_analysis)，[自组织映射（SOM）](https://en.wikipedia.org/wiki/Self-organizing_map)，[潜在语义索引](https://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html)'
- en: '[**Manifold Learning**](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)**:** t-Distributed
    Stochastic Neighbor Embedding ([t-SNE](https://distill.pub/2016/misread-tsne/))'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**流形学习**](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)**：**
    t-分布随机邻居嵌入（[t-SNE](https://distill.pub/2016/misread-tsne/)）'
- en: '**Variational autoencoders:** An automated generative approach using [variational
    autoencoders](https://arxiv.org/pdf/1606.05908.pdf) (VAE)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变分自编码器：** 一种使用[变分自编码器](https://arxiv.org/pdf/1606.05908.pdf)（VAE）的自动生成方法'
- en: '**Clustering:** [Hierarchical Clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类：** [层次聚类](https://en.wikipedia.org/wiki/Hierarchical_clustering)'
- en: An example of this in a real-world problem could be trying to visualize which
    text features could be influential in a model by checking their semantic similarity
    using word embeddings and visualizing the same using t-SNE as depicted below.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现实问题中的一个例子可能是通过检查文本特征的语义相似性来可视化哪些特征可能对模型有影响，并使用t-SNE进行可视化，如下图所示。
- en: '![Figure](../Images/a170df9d9993c6d08f152e05380b6078.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/a170df9d9993c6d08f152e05380b6078.png)'
- en: Visualizing word embeddings using t-SNE (Source: [*Understanding Feature Engineering
    (Part 4) — Deep Learning Methods for Text Data — Towards Data Science*](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa))
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用t-SNE可视化词嵌入（来源：[*理解特征工程（第4部分）— 深度学习方法用于文本数据 — 数据科学*](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)）
- en: You can also use t-SNE to visualize the famous MNIST hand-written digits dataset
    as depicted in the following figure.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用t-SNE来可视化著名的MNIST手写数字数据集，如下图所示。
- en: '![Figure](../Images/f673989b5ae5a27375f97dae683444a4.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/f673989b5ae5a27375f97dae683444a4.png)'
- en: Visualizing MNIST data using t-SNE using sklearn. Image courtesy of Pramit Choudhary
    and the Datascience.com team.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用sklearn的t-SNE可视化MNIST数据。图片由Pramit Choudhary和Datascience.com团队提供。
- en: Another example is visualizing the famous IRIS dataset by leveraging PCA for
    dimension reduction as depicted in the following figure.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个示例是通过 PCA 进行维度缩减来可视化著名的 IRIS 数据集，如下图所示。
- en: '![Figure](../Images/52b4d6050191a5f88b4b2591d6eaee84.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/52b4d6050191a5f88b4b2591d6eaee84.png)'
- en: '[Principal Component Analysis on the IRIS dataset](http://scikit-learn.org/stable/modules/decomposition.html)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[主成分分析在 IRIS 数据集上的应用](http://scikit-learn.org/stable/modules/decomposition.html)'
- en: Besides visualizing data and features, certain more intuitive and interpretable
    models like decision trees help us in visualizing how exactly it might take a
    certain decision. A sample tree is depicted below which helps us visualize the
    exact rules in a human-interpretable manner.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据和特征的可视化外，一些更直观和可解释的模型，如决策树，帮助我们可视化它是如何做出特定决策的。下图展示了一个示例树，帮助我们以人类可解释的方式可视化具体规则。
- en: '![Figure](../Images/74fc9f8e2e28cf9c70e62ababfa2c625.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/74fc9f8e2e28cf9c70e62ababfa2c625.png)'
- en: Visualizing human-interpretable rules for a decision tree model (Source: [*Practical
    Machine Learning with Python, Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python))
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化决策树模型的人类可解释规则（来源：[*Python 实用机器学习，Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python)）
- en: However, like we discussed we may not get these rules for other models which
    are not as interpretable as tree based models. Also huge decision trees always
    become very difficult to visualize and interpret.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们讨论的，我们可能无法为那些不像树模型那样可解释的其他模型获得这些规则。此外，巨大的决策树总是变得非常难以可视化和解释。
- en: '**Model Performance Evaluation Metrics**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能评估指标**'
- en: '[***Model performance evaluation***](https://www.cs.cornell.edu/courses/cs578/2003fa/performance_measures.pdf) is
    a key step in any data science lifecycle for choosing the best model. This enables
    us to see how well our models are performing, compare various performance metrics
    across models and choose the best models. This also enables us to [***tune and
    optimize hyper-parameters***](https://en.wikipedia.org/wiki/Hyperparameter_optimization)in
    a model to obtain a model which gives the best performance on the data we are
    dealing with. Typically there exist certain standard evaluation metrics based
    on the type of problem we are dealing with.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[***模型性能评估***](https://www.cs.cornell.edu/courses/cs578/2003fa/performance_measures.pdf)
    是数据科学生命周期中的关键步骤，用于选择最佳模型。这使我们能够查看模型的表现，比较各种模型的性能指标并选择最佳模型。这也使我们能够 [***调整和优化超参数***](https://en.wikipedia.org/wiki/Hyperparameter_optimization)
    以获得在我们处理的数据上表现最佳的模型。通常，基于我们所处理问题的类型存在某些标准评估指标。'
- en: '**Supervised Learning — Classification:** For classification problems, our
    main objective is to predict a discrete categorical response variable. The confusion
    matrix is extremely useful here from which we can derive a whole bunch of useful
    metrics including accuracy, precision, recall, F1-Score as depicted in the following
    example.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习——分类：** 对于分类问题，我们的主要目标是预测一个离散的分类响应变量。混淆矩阵在这里非常有用，我们可以从中推导出一整套有用的指标，包括准确率、精确率、召回率、F1
    分数，如下例所示。'
- en: '![Figure](../Images/2c8ccd191f418a6b656e14ff7bf12402.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/2c8ccd191f418a6b656e14ff7bf12402.png)'
- en: Classification Model Performance Metrics (Source: [*Practical Machine Learning
    with Python, Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python))
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型性能指标（来源：[*Python 实用机器学习，Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python)）
- en: Besides these metrics, we can also use some other techniques like the ROC curve
    and the AUC score as depicted in a wine-quality prediction system in the following
    figure.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些指标外，我们还可以使用一些其他技术，如 ROC 曲线和 AUC 分数，如下图中的葡萄酒质量预测系统所示。
- en: '![Figure](../Images/9c01adeae214aa7cbb8e63cfe26d9bd0.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/9c01adeae214aa7cbb8e63cfe26d9bd0.png)'
- en: ROC Curve and AUC scores (Source: [*Practical Machine Learning with Python,
    Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python))
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线和 AUC 分数（来源：[*Python 实用机器学习，Apress 2018*](https://github.com/dipanjanS/practical-machine-learning-with-python)）
- en: 'The area under the ROC curve is a very popular technique to objectively evaluate
    the performance of a classifier. Here we typically try to balance the True Positive
    Rate (TPR) and the False Positive Rate (FPR). The above figure tells us that the
    AUC score for a wine of class `**‘high’**` is `**0.9**` which means that the model’s
    probability of assigning a higher score to a wine of class `**‘high’**`(positive
    class) than to class `**NOT ‘high’ **`which is either `**‘medium’**` or `**‘low’**`(negative
    class) is 90%. At times, the results may be misleading and difficult to interpret
    if the ROC curves cross(Source: [*Measuring classifier performance: a coherent
    alternative to the area under the ROC curve*](https://link.springer.com/article/10.1007%2Fs10994-009-5119-5)).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线下的面积是一个非常流行的技术，用于客观评估分类器的性能。在这里，我们通常尝试平衡真实正例率（TPR）和假正例率（FPR）。上述图表告诉我们，对于类别`**‘高’**`的葡萄酒，AUC
    分数为`**0.9**`，这意味着模型将更高的分数分配给类别`**‘高’**`（正类）的概率为 90%，而不是类别`**非‘高’**`（负类），该类别可能是`**‘中’**`或`**‘低’**`。有时，如果
    ROC 曲线交叉，结果可能会误导并难以解释（来源：[*测量分类器性能：ROC 曲线下的面积的连贯替代方法*](https://link.springer.com/article/10.1007%2Fs10994-009-5119-5)）。
- en: '**Supervised Learning — Regression:** For regression problems we can use standard
    metrics like the [coefficient of determination (R-square)](https://en.wikipedia.org/wiki/Coefficient_of_determination),
    the [root mean-square error (RMSE)](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d) and
    the [mean absolute error (MAE)](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习 — 回归：** 对于回归问题，我们可以使用标准指标，如[决定系数（R平方）](https://en.wikipedia.org/wiki/Coefficient_of_determination)、[均方根误差（RMSE）](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)和[平均绝对误差（MAE）](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)。'
- en: '**Unsupervised Learning — Clustering:** For unsupervised learning problems
    based on clustering we can use metrics like the [silhouette coefficient](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html), [homogeneity,
    completeness, V-measure](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure) and
    the [Calinski-Harabaz index](http://scikit-learn.org/stable/modules/clustering.html#calinski-harabaz-index).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习 — 聚类：** 对于基于聚类的无监督学习问题，我们可以使用像[silhouette coefficient](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)、[同质性、完整性、V-measure](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure)以及[Calinski-Harabaz
    指数](http://scikit-learn.org/stable/modules/clustering.html#calinski-harabaz-index)这样的指标。'
- en: Limitations of Traditional Techniques and Motivation for Better Model Interpretation
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 传统技术的局限性及对更好模型解释的动机
- en: The techniques we discussed in the previous techniques are definitely helpful
    in trying to understand more about our data, features as well as which models
    might be effective. However, they are quite limiting in terms of trying to discern
    human-interpretable ways of how a model works. In any data science problem, we
    usually build a model on a stationary dataset and get our objective function (optimized
    loss function) which is usually deployed when it meets certain criteria based
    on model performance and business requirements. Usually we leverage the above
    techniques of exploratory analysis and evaluation metrics for deciding the overall
    model performance on our data. However, in the real-world, a model’s performance
    often decreases and plateaus over time after deployment due to variability in
    data features, added constraints and noise. This might include things like changes
    in the environment, changes in features as well as added constraints. Hence simply
    re-training a model on the same feature set will not be sufficient and we need
    to constantly check for how important features are in deciding model predictions
    and how well they might be working on new data points.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面讨论的技术在尝试更好地了解我们的数据、特征以及哪些模型可能有效方面确实是有帮助的。然而，它们在尝试揭示模型如何工作的人类可解释性方面相当有限。在任何数据科学问题中，我们通常在静态数据集上构建模型，并得到我们的目标函数（优化的损失函数），该模型通常在满足基于模型性能和业务需求的某些标准时被部署。通常，我们利用上述的探索性分析和评估指标来决定我们数据上模型的整体性能。然而，在现实世界中，模型的性能往往在部署后随着时间的推移而下降和趋于平稳，这可能是由于数据特征的变化、增加的约束和噪声。这可能包括环境变化、特征变化以及增加的约束。因此，仅仅在相同特征集上重新训练模型是不够的，我们需要不断检查特征在决定模型预测中的重要性以及它们在新数据点上的表现如何。
- en: For example, an [intrusion detection system](https://ir.library.louisville.edu/etd/2790/)(IDS),
    a cyber-security application, is prone to evasion attacks where an attacker may
    use adversarial inputs to beat the secure system (note: [adversarial inputs](https://arxiv.org/abs/1602.02697) are
    examples that are intentionally engineered by an attacker to trick the machine
    learning model to make false predictions). The model’s objective function in such
    cases may act as a weak surrogate to the real-world objectives. A better interpretation
    might be needed to identify the blind spots in the algorithms to build a secure
    and safe model by fixing the training data set prone to adversarial attacks (for
    further reading, see Moosavi-Dezfooli, et al., 2016, [*DeepFool*](https://arxiv.org/pdf/1511.04599.pdf) and
    Goodfellow, et al., 2015, [*Explaining and harnessing adversarial examples*](https://arxiv.org/abs/1412.6572)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个[入侵检测系统](https://ir.library.louisville.edu/etd/2790/)(IDS)，作为一个网络安全应用，容易受到规避攻击，其中攻击者可能利用对抗性输入来击败安全系统（注意：[对抗性输入](https://arxiv.org/abs/1602.02697)是由攻击者故意设计的样本，用以欺骗机器学习模型做出错误预测）。在这种情况下，模型的目标函数可能只是对现实世界目标的一个弱近似。可能需要更好的解释来识别算法中的盲点，以通过修复易受对抗攻击影响的训练数据集来构建安全的模型（欲了解更多，请参阅
    Moosavi-Dezfooli 等，2016年，[*DeepFool*](https://arxiv.org/pdf/1511.04599.pdf) 和
    Goodfellow 等，2015年，[*Explaining and harnessing adversarial examples*](https://arxiv.org/abs/1412.6572)）。
- en: '![Figure](../Images/1409f75c34f0565044b40b8018016d08.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/1409f75c34f0565044b40b8018016d08.png)'
- en: Source: [https://medium.com/@jrodthoughts/using-adversarial-attacks-to-make-your-deep-learning-model-look-stupid-24fb872f06fd](https://medium.com/@jrodthoughts/using-adversarial-attacks-to-make-your-deep-learning-model-look-stupid-24fb872f06fd)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://medium.com/@jrodthoughts/using-adversarial-attacks-to-make-your-deep-learning-model-look-stupid-24fb872f06fd](https://medium.com/@jrodthoughts/using-adversarial-attacks-to-make-your-deep-learning-model-look-stupid-24fb872f06fd)
- en: Besides, often bias exists in models due to the nature of data we are dealing
    with like in a rare-class prediction problem (fraud or intrusion detection). Metrics
    don’t help us justify the true story of a model’s prediction decisions. Also these
    traditional forms of model interpretation might be easy for a data scientist to
    understand but since they are inherently theoretical and often mathematical, there
    is a substantial gap in trying to explain these to (non-technical) business stakeholders
    and trying to decide the success criteria of a project based on these metrics
    alone. Just telling the business, *“I have a model with 90% accuracy”* is not
    sufficient information for them to start trusting the model when deployed in the
    real world. We need human-interpretable interpretations (HII) of a model’s decision
    policies which could be explained with proper and intuitive inputs and outputs.
    This would enable insightful information to be easily shared with peers (analysts,
    managers, data scientists, data engineers). Using such forms of explanations,
    which could be explained based on inputs and outputs, might help facilitate better
    communication and collaboration, enabling businesses to make more confident decisions
    (e.g., [risk assessment/audit risk analysis in financial institutions](https://www.journalofaccountancy.com/issues/2006/jul/assessingandrespondingtorisksinafinancialstatementaudit.html)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型中经常存在偏差，这通常与我们处理的数据特性有关，比如在稀有类别预测问题中（如欺诈或入侵检测）。指标不能帮助我们阐明模型预测决策的真实情况。此外，这些传统的模型解释形式可能对数据科学家来说容易理解，但由于其本质上是理论性和数学性的，向（非技术）业务相关者解释这些模型存在相当大的困难，并且仅依赖这些指标来决定项目的成功标准是不够的。仅告诉业务
    *“我有一个准确率为90%的模型”* 不足以让他们在实际应用中开始信任这个模型。我们需要可以通过适当和直观的输入和输出来解释的模型决策政策的人类可解释性解释（HII）。这将使有洞察力的信息可以轻松地与同事（分析师、经理、数据科学家、数据工程师）共享。利用这样的解释形式，可以基于输入和输出进行说明，可能有助于促进更好的沟通与协作，使企业能够做出更有信心的决策（例如，[金融机构的风险评估/审计风险分析](https://www.journalofaccountancy.com/issues/2006/jul/assessingandrespondingtorisksinafinancialstatementaudit.html)）。
- en: To reiterate, we define model interpretation (new approaches) as being able
    to account for ***fairness ***(unbiasedness/non-discriminative), ***accountability***(reliable
    results), and ***transparency ***(being able to query and validate predictive
    decisions) of a predictive model — currently in regard to supervised learning
    problems.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 重申一下，我们将模型解释（新方法）定义为能够考虑***公平性***（无偏见/非歧视）、***问责性***（可靠的结果）和***透明性***（能够查询和验证预测决策）——目前主要针对监督学习问题。
- en: '* * *'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Should You Become a Freelance Artificial Intelligence Engineer?](https://www.kdnuggets.com/2021/12/ucsd-become-freelance-artificial-intelligence-engineer.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你应该成为自由职业的人工智能工程师吗？](https://www.kdnuggets.com/2021/12/ucsd-become-freelance-artificial-intelligence-engineer.html)'
- en: '[Artificial Intelligence Project Ideas for 2022](https://www.kdnuggets.com/2022/01/artificial-intelligence-project-ideas-2022.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年人工智能项目创意](https://www.kdnuggets.com/2022/01/artificial-intelligence-project-ideas-2022.html)'
- en: '[Artificial Intelligence and the Metaverse](https://www.kdnuggets.com/2022/02/artificial-intelligence-metaverse.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能与元宇宙](https://www.kdnuggets.com/2022/02/artificial-intelligence-metaverse.html)'
- en: '[Uncertainty Quantification in Artificial Intelligence-based Systems](https://www.kdnuggets.com/2022/04/uncertainty-quantification-artificial-intelligencebased-systems.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能系统中的不确定性量化](https://www.kdnuggets.com/2022/04/uncertainty-quantification-artificial-intelligencebased-systems.html)'
- en: '[How Artificial Intelligence Can Transform Data Integration](https://www.kdnuggets.com/2022/04/artificial-intelligence-transform-data-integration.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能如何变革数据集成](https://www.kdnuggets.com/2022/04/artificial-intelligence-transform-data-integration.html)'
- en: '[Most In-demand Artificial Intelligence Skills To Learn In 2022](https://www.kdnuggets.com/2022/08/indemand-artificial-intelligence-skills-learn-2022.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年最受欢迎的人工智能技能](https://www.kdnuggets.com/2022/08/indemand-artificial-intelligence-skills-learn-2022.html)'
