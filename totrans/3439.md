# 你会在泰坦尼克号上幸存吗？Python中的机器学习指南第2部分

> 原文：[https://www.kdnuggets.com/2016/07/titanic-machine-learning-guide-part-2.html/2](https://www.kdnuggets.com/2016/07/titanic-machine-learning-guide-part-2.html/2)

**分类 - 有趣的部分**

我们将从一个简单的决策树分类器开始。决策树一次检查一个变量，并根据该值的结果分裂为两个分支之一，然后对下一个变量做相同的操作。一个关于决策树如何工作的出色可视化解释可以在[这里](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)找到。

这是经过训练的泰坦尼克号数据集的决策树样子，如果我们将最大层级数设置为3：

[![决策树](../Images/ba8a5a296a46ba87dcc053bdef4ff8e7.png)](/wp-content/uploads/socialcops-tree.jpg)

树首先按性别分裂，然后按等级分裂，因为在训练阶段它已经学会了这些是决定生存的两个最重要特征。深蓝色框表示可能幸存的乘客，深橙色框表示几乎肯定会遇难的乘客。有趣的是，在按等级分裂之后，决定女性生存的主要因素是她们支付的票价，而决定男性生存的因素是他们的年龄（儿童更有可能幸存）。

要创建这棵树，首先我们初始化一个未训练的决策树分类器（在这里我们将树的最大深度设置为10）。接下来，我们将这个分类器“拟合”到我们的训练集上，使其学习不同因素如何影响乘客的生存能力。现在决策树已准备好，我们可以使用测试数据对其进行“评分”，以确定它的准确性。

```py
clf_dt = tree.DecisionTreeClassifier(max_depth=10)

clf_dt.fit (X_train, y_train)
clf_dt.score (X_test, y_test)

# 0.78947368421052633

```

*[点击这里查看概要。](https://gist.github.com/triestpa/5858dc07caab1e33af10178fd1f236d5)*

得到的结果0.7703表示模型正确预测了77%的测试集生存情况。对于我们的第一个模型来说，这并不差！

如果你是一个细心的、怀疑的读者（就像你应该的那样），你可能会认为模型的准确性可能会有所不同，这取决于选择了哪些行作为训练集和测试集。我们将通过使用洗牌验证器来解决这个问题。

```py
shuffle_validator = cross_validation.ShuffleSplit(len(X), n_iter=20, test_size=0.2, random_state=0)
def test_classifier(clf):
    scores = cross_validation.cross_val_score(clf, X, y, cv=shuffle_validator)
    print("Accuracy: %0.4f (+/- %0.2f)" % (scores.mean(), scores.std()))

test_classifier(clf_dt)

# Accuracy: 0.7742 (+/- 0.02)

```

*[点击这里查看概要。](https://gist.github.com/triestpa/e326db921a5400428aeb33130fb3152b)*

这个洗牌验证器应用了之前相同的随机20:80拆分，但这次生成了20种唯一的拆分排列。通过将这个洗牌验证器作为参数传递给“cross_val_score”函数，我们可以对分类器进行不同拆分的评分，并计算结果的平均准确率和标准差。

结果显示，我们的决策树分类器总体准确率为 77.34%，尽管它可以升高至 80% 并降低至 75%，具体取决于训练/测试划分。使用 scikit-learn，我们可以使用完全相同的语法轻松测试其他机器学习算法。

```py
clf_rf = ske.RandomForestClassifier(n_estimators=50)
test_classifier(clf_rf)

# Accuracy: 0.7837 (+/- 0.02)

clf_gb = ske.GradientBoostingClassifier(n_estimators=50)
test_classifier(clf_gb)

# Accuracy: 0.8201 (+/- 0.02)

eclf = ske.VotingClassifier([('dt', clf_dt), ('rf', clf_rf), ('gb', clf_gb)])
test_classifier(eclf)

# Accuracy: 0.8036 (+/- 0.02)

```

*[点击这里获取要点。](https://gist.github.com/triestpa/b6b3db3ac3424b664b59fbbf48d19859)*

“随机森林”分类算法将使用输入变量的不同随机子集为数据集创建大量（通常很差）的树，并返回由最多树返回的预测。这有助于避免“过拟合”，即当模型过于紧密地拟合训练数据中的任意相关性时，它在测试数据上的表现很差的问题。

“梯度提升”分类器将生成许多弱的、浅层的预测树，并将它们组合或“提升”成一个强模型。该模型在我们的数据集上表现非常好，但缺点是相对较慢且难以优化，因为模型构建是顺序进行的，因此无法并行化。

“投票”分类器可以将多个概念上不同的分类模型应用于相同的数据集，并返回所有分类器中的多数票。例如，如果梯度提升分类器预测乘客不会幸存，而决策树和随机森林分类器预测他们会生存，投票分类器将选择后者。

这只是对每种技术的非常简要且非技术性的概述，因此我鼓励你深入了解所有这些算法的数学实现，以获得对它们相对优缺点的更深入理解。许多更多的分类算法在 scikit-learn 中可用，并可以在[这里](http://scikit-learn.org/stable/modules/ensemble.html)进行探索。

![Patrick Triest](../Images/58fde3736bd01dbcfdf3fd2657ea5996.png)**简历：[Patrick Triest](https://www.linkedin.com/in/triestpa)** 是一位 23 岁的 Android 开发者/物联网工程师/数据科学家/志向前卫者，来自波士顿，现在在 SocialCops 工作。他对学习上瘾，有时在搞清楚特别酷的东西后，他会非常兴奋地写下它。

[原文](http://blog.socialcops.com/engineering/machine-learning-python)。经许可转载。

**相关：**

+   [掌握 Python 机器学习的 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)

+   [数据科学和机器学习的 10 大 IPython Notebook 教程](/2016/04/top-10-ipython-nb-tutorials.html)

+   [R 学习路径：从初学者到专家的 7 个步骤](/2016/03/datacamp-r-learning-path-7-steps.html)

* * *

## 我们的 3 大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速通道进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 为你的组织提供 IT 支持

* * *

### 更多相关内容

+   [数据科学家需要专门化以度过技术寒冬](https://www.kdnuggets.com/2023/08/data-scientists-need-specialize-survive-tech-winter.html)

+   [如果我重新开始学习数据科学，我会怎么做？](https://www.kdnuggets.com/2020/08/start-learning-data-science-again.html)

+   [何时使用集成技术是一个好选择？](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)

+   [数据科学面试指南 - 第 2 部分：面试资源](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)

+   [数据科学面试指南 - 第 1 部分：结构](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)

+   [想成为数据科学家？第 1 部分：你需要掌握的 10 项硬技能](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)
