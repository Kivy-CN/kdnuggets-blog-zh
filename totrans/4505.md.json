["```py\n from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nPIC_DIR = './drive/img_align_celeba/'\nIMAGES_COUNT = 10000\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\nWIDTH = 128\nHEIGHT = 128\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), Image.ANTIALIAS)\n    images.append(np.uint8(pic)) #Normalize the images\nimages = np.array(images) / 255\nimages.shape #print first 25 images\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show() \n```", "```py\n LATENT_DIM = 32\nCHANNELS = 3\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n\n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n\n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n\n    generator = Model(gen_input, x)\n    return generator \n```", "```py\n def create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n\n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n\n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n\n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n\n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n\n    return discriminator \n```", "```py\n generator = create_generator()\ndiscriminator = create_discriminator()\ndiscriminator.trainable = False\ngan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)#Adversarial Model\noptimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy') \n```", "```py\n iters = 20000\nbatch_size = 16RES_DIR = 'res2'\nFILE_PATH = '%s/generated_%d.png'\nif not os.path.isdir(RES_DIR):\n    os.mkdir(RES_DIR)\nCONTROL_SIZE_SQRT = 6\ncontrol_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2\nstart = 0\nd_losses = []\na_losses = []\nimages_saved = 0\nfor step in range(iters):\n    start_time = time.time()\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    generated = generator.predict(latent_vectors)\n\n    real = images[start:start + batch_size]\n    combined_images = np.concatenate([generated, real])\n\n    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n    labels += .05 * np.random.random(labels.shape)\n\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    d_losses.append(d_loss)\n\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    misleading_targets = np.zeros((batch_size, 1))\n\n    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n    a_losses.append(a_loss)\n\n    start += batch_size\n    if start > images.shape[0] - batch_size:\n        start = 0\n\n    if step % 50 == 49:\n        gan.save_weights('gan.h5')\n\n        print('%d/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n\n        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n        control_generated = generator.predict(control_vectors)\n        for i in range(CONTROL_SIZE_SQRT ** 2):\n            x_off = i % CONTROL_SIZE_SQRT\n            y_off = i // CONTROL_SIZE_SQRT\n            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n        im = Image.fromarray(np.uint8(control_image * 255))\n        im.save(FILE_PATH % (RES_DIR, images_saved))\n        images_saved += 1 \n```", "```py\n import imageio\nimport shutil\nimages_to_gif = []\nfor filename in os.listdir(RES_DIR):\n    images_to_gif.append(imageio.imread(RES_DIR + '/' + filename))\nimageio.mimsave('trainnig_visual.gif', images_to_gif)\nshutil.rmtree(RES_DIR) \n```"]