# 使用 Snorkel 标注数据

> 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)

[评论](#comments)

**作者：[Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/)、[Stefan Denkovski](https://www.linkedin.com/in/stefandenkovski/)、[Michal Malyska](https://www.linkedin.com/in/malyskamichal/)、[Sally Moon](https://www.linkedin.com/in/sallysaeyoungmoon/)、[Brandon Rufino](https://www.linkedin.com/in/brandon-rufino/)、[NLP4H](https://nlp4h.com/authors/)**

![帖子图片](../Images/e16079ec47d75638df56b6c91eb5db14.png)

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织进行 IT

* * *

在本教程中，我们将介绍如何使用 Snorkel 为未标注的数据集生成标签。我们将通过引导您了解 Snorkel 的实际临床应用，提供一些基本的 Snorkel 组件示例。具体来说，我们将使用 Snorkel 来尝试提升我们在预测 [多发性硬化症 (MS) 严重程度评分](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)方面的结果。请享用！*

*查看 *[*Snorkel 入门教程*](https://www.snorkel.org/use-cases/01-spam-tutorial)* 了解垃圾邮件标注的过程。有关 Snorkel 在现实世界应用中的高性能示例，请参见 *[*Snorkel 的出版物列表*](https://www.snorkel.org/resources/)*。*

*查看我们关于 MS 严重程度分类的其他 NLP 工作 *[*这里*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*。*

### Snorkel 是什么？

Snorkel 是一个促进构建和管理训练数据集的系统，无需手动标注。Snorkel 流水线的第一个组件包括标注函数，这些函数被设计为弱启发式函数，用于在未标注的数据上预测标签。我们为 MS 严重程度评分标注开发的标注函数如下：

+   在文本中进行多个关键词搜索（使用正则表达式）。例如，在查找严重程度评分时，我们搜索了数字格式和罗马数字格式的短语。

+   训练使用术语频率-逆文档频率（或简写 tf-idf）特征的常见基线，如逻辑回归、线性判别分析和支持向量机。

+   Word2Vec 卷积神经网络（CNN）。

+   我们的 MS-BERT 分类器在[这篇博客文章](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)中进行了描述。

Snorkel 管道的第二个组件是一个生成模型，它根据所有标记函数的预测，为每个数据点输出一个单一的置信度加权训练标签。它通过学习基于标记函数的一致性和不一致性来估计标记函数的准确性和相关性来实现这一点。

### Snorkel 教程

再次强调，在这篇文章中，我们演示了 MS 严重性评分的标签生成。MS 严重性的一种常见测量方法是 EDSS 或扩展残疾状态量表。这是一个根据 MS 症状的严重程度从 0 到 10 增加的量表。我们将一般提及 EDSS 作为 MS 严重性评分，但为了让我们的细心读者了解，我们提供了这些信息。这个评分在[这里](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)有更详细的描述。

### 步骤 0：获取数据集

在我们的任务中，我们使用了一个由领先的 MS 研究医院编制的数据集，其中包含约 5000 名患者的超过 *70,000* 条 MS 咨询记录。在 70,000 条记录中，仅 *16,000* 条由专家手动标记了 MS 严重性。这意味着大约有 *54,000* 条未标记的记录。如您所知，通常拥有更大的数据集来训练模型会导致更好的模型性能。因此，我们使用 Snorkel 为我们的 *54,000* 条未标记记录生成了我们称之为“银色”标签的标签。这 *16,000* 条“黄金”标签记录用于训练我们的分类器，然后再创建其各自的标记函数。

### 步骤 1：安装 Snorkel

要将 Snorkel 安装到您的项目中，您可以运行以下命令：

### 步骤 2：添加标记函数

### 设置

标记函数允许您定义弱启发式和规则，给定未标记的数据预测标签。这些启发式方法可以源自专家知识或其他标记模型。在 MS 严重性评分预测的情况下，我们的标记函数包括：源自临床医生的关键词搜索函数、训练以预测 MS 严重性评分的基线模型（tf-idf、word2vec cnn 等）以及我们的 MS-BERT 分类器。

如下所示，您可以通过在函数上方添加“@labeling_function()”来标记标记函数。对于每个标记函数，将传入一个包含未标记数据（即一个观察/样本）的一行数据框。每个标记函数应用启发式方法或模型来获取每一行的预测。如果找不到预测，函数将选择不标记（即返回 -1）。

当所有标记函数定义完毕后，您可以使用 “PandasLFApplier” 来获得所有标记函数给出的预测矩阵。

运行以下代码后，你将获得一个（N X num_lfs）L_predictions 矩阵，其中 N 是‘df_unlabelled’中的观测数量，‘num_lfs’是‘lfs’中定义的标签函数数量。

### 标签函数示例 #1：关键词搜索

下面展示了一个使用正则表达式的关键词搜索示例，用于提取以小数形式记录的 MS 严重性评分。正则表达式函数被应用于尝试搜索以小数形式记录的 MS 严重性评分。如果找到，该函数将返回适当输出格式的评分。否则，函数将回避（即返回 -1）以表示未找到评分。

### 标签函数示例 #2：训练的分类器

上面我们看到一个使用关键词搜索的示例。要集成训练好的分类器，你必须执行一个额外的步骤。即，在创建标签函数之前，你必须训练并导出你的模型。下面是一个基于 tf-idf 特征训练逻辑回归的示例。

模型训练完成后，实现一个标签函数就像这样简单：

### 步骤 3(a)：使用 Snorkel 的多数投票

有人说 Snorkel 用来生成标签的最简单函数是‘多数投票’。多数投票，顾名思义，根据最多投票的类别做出预测。

要实现多数投票，你必须指定‘基数’（即类别数量）。

### 步骤 3(b)：使用 Snorkel 的标签模型

为了充分利用 Snorkel 的所有功能，我们使用‘标签模型’根据所有标签函数（即 L_unlabelled）获得的预测矩阵生成一个单一的置信加权标签。标签模型通过学习估计标签函数的准确性和相关性来进行预测，基于它们的同意和不同意见。

你可以定义一个标签模型并指定‘基数’。在你用 L_unlabelled 训练标签模型后，它将为未标记的数据生成单一预测。

### 步骤 4：评估工具

### LF 分析 — 覆盖率、重叠、冲突

为了更好地理解你的标签函数的工作情况，你可以使用 Snorkel 的 LFAnalysis。LF 分析报告每个标签函数的极性、覆盖率、重叠和冲突。

这些术语的定义如下，你可以参考[Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities)获取更多信息：

+   极性：根据标签矩阵中的证据推断每个 LF 的极性。

+   覆盖率：计算至少有一个标签的数据点的比例。

+   重叠：计算至少有两个（非回避）标签的数据点的比例。

+   冲突：计算每个标签函数与至少一个其他标签函数不一致的数据点的比例。

LFAnalysis 将提供关于你的标签函数相对表现的分析。

### `get_label_buckets`

Snorkel 提供了一些额外的评估工具来帮助你了解标注函数的质量。特别是，`get_label_buckets` 是一种将标签组合并进行比较的便捷方法。有关更多信息，请阅读 [Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html)。

以下代码允许你比较真实标签（y_gold）和预测标签（y_preds），以查看 Snorkel 正确或错误标注的数据点。这将帮助你找出哪些数据点难以正确标注，从而调整你的标注函数以覆盖这些边缘情况。

注意，对于此分析，我们回到创建了一个 L_train 矩阵，其中包含我们对“金标准”标注数据集的标注函数预测。

或者，你可以使用 `get_label_buckets` 来比较标注函数之间的差异。

以下代码允许你比较 L_unlabelled 中的标签预测，以观察不同标注函数如何不同地标注数据点。

### 第 5 步：部署

### 选择最佳标注模型来标注未标注数据

按照上述程序，我们基于关键词搜索、基准模型和我们的 MS-BERT 分类器开发了各种标注函数。我们尝试了各种标注函数的集成，并使用 Snorkel 的 Label Model 对保留的标注数据集进行了预测。这使我们能够确定哪种标注函数的集成最适合标注我们的未标注数据集。

如下表所示，我们观察到 MS-BERT 分类器（MSBC）单独的表现超越了所有包含它的集成模型，Macro-F1 上至少高出 0.02。添加较弱的启发式方法和分类器始终会降低集成模型的性能。此外，我们还观察到，随着较弱分类器和启发式方法的加入，MS-BERT 分类器的冲突量增加。

![图](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)

注意，基于规则（RB）指的是我们的关键词搜索。LDA 指线性判别分析。TFIDF 指所有基于 tf-idf 特征构建的模型（即逻辑回归、线性判别分析和支持向量机）。

为了理解我们的发现，我们必须提醒自己，Snorkel 的标签模型通过基于相互之间的协议和分歧来预测标签函数的准确性和相关性。因此，在存在强标签函数的情况下，比如我们的 MS-BERT 分类器，添加较弱的标签函数会导致与强标签函数之间出现更多的分歧，从而降低性能。通过这些发现，我们了解到 Snorkel 可能更适用于仅有弱启发式和规则的情况。然而，如果你已经拥有一个强标签函数，开发一个包含较弱启发式的 Snorkel 集成可能会影响性能。

因此，单独使用 MS-BERT 分类器来标注我们未标注的数据集。

### 半监督标注结果

使用 MS-BERT 分类器为我们未标注的数据集获取了“银”标签。这些“银”标签与我们的“金”标签结合，形成了银+金数据集。为了推断银标签的质量，开发了新的 MS-BERT 分类器：1) MS-BERT+（在银+金标注数据上训练）；2) MS-BERT-silver（在银标注数据上训练）。这些分类器在一个之前用于评估我们原始 MS-BERT 分类器（在金标注数据上训练）的保留测试数据集上进行了评估。MS-BERT+ 达到了 0.86238 的 Macro-F1 和 0.92569 的 Micro-F1，而 MS-BERT-silver 达到了 0.82922 的 Macro-F1 和 0.91442 的 Micro-F1。尽管它们的性能略低于我们原始的 MS-BERT 分类器（Macro-F1 为 0.88296，Micro-F1 为 0.94177），但它们仍然超越了之前最好的 MS 严重性预测基线模型。MS-BERT-silver 的强劲结果有助于展示我们 MS-BERT 分类器作为标签函数的有效性。它展示了减少专业人员需要花费的繁琐时间来阅读患者咨询笔记并手动生成 MS 严重性评分的潜力。

### 谢谢大家！

感谢大家阅读！如果你有任何问题，请随时通过 nlp4health (at gmail dot) com 联系我们。:)

### 致谢

我们要感谢圣迈克尔医院数据科学与高级分析（DSAA）部门的研究人员和工作人员，在整个项目过程中提供了持续的支持和指导。我们还要感谢 Marzyeh Ghassemi 博士和 Taylor Killan，感谢他们让我们有机会参与这个激动人心的项目。最后，我们要感谢圣迈克尔医院 MS 诊所的 Tony Antoniou 博士和 Jiwon Oh 博士，感谢他们在神经系统检查笔记方面的支持。

*最初发布于* [*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/) *。*

**简介: [作者们](https://nlp4h.com/authors/)** 是一组在多伦多大学从事医疗保健 NLP 研究的研究生。

[原始](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f)。经授权转载。

**相关内容：**

+   [人工标注是过去的事。未来是#NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)

+   [从语言到信息：斯坦福大学另一门优秀的 NLP 课程](/2020/06/languages-information-another-great-nlp-course-stanford.html)

+   [深度神经网络在自然语言处理（NLP）中的不合理进展](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)

### 更多相关话题

+   [如何使用 Python 确定最佳数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)

+   [使用 Eurybia 检测数据漂移以确保生产中的 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)

+   [黑客如何利用数据科学窃取数十亿](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)

+   [利用数据科学使清洁能源更具公平性](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)

+   [如何通过使用自动化 EDA 工具在数据科学评估测试中脱颖而出](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)

+   [使用 Matplotlib 的数据可视化介绍](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)
