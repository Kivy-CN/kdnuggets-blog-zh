- en: 'Training a Champion: Building Deep Neural Nets for Big Data Analytics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html](https://www.kdnuggets.com/2019/04/sisense-deep-neural-nets-big-data-analytics.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sponsored Post.
  prefs: []
  type: TYPE_NORMAL
- en: '**By Nir Regev, Sisense**.'
  prefs: []
  type: TYPE_NORMAL
- en: The world of data is now the world of Big Data. The genie is out of the bottle
    and there’s no going back. We produce more and more data every day and the datasets
    being generated are getting more and more complex. Traditionally, the way to handle
    this has been to scale up computing resources to handle these bigger datasets.
    That’s not feasible for the long term on a global scale, nor is it tenable in
    the near term for smaller organizations who may have limited resources to deal
    with their analytics challenges.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Further complicating matters, in order to facilitate true interactivity with
    large datasets, user queries need near-real-time response rates. This is a challenge
    even for the most powerful large-scale systems. Approximate Query Processing (AQP)
    removes the need to query the entire Big Data set and serves up usable results
    rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: Sisense Hunch™
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Sisense Hunch™](https://www.sisense.com/blog/sisense-hunch-leadership-through-radical-innovation/) is
    a new way of handling Big Data sets that uses AQP technology to construct Deep
    Neural Networks (DNNs) which are trained to learn the relationships between queries
    and their results in these huge datasets. This provides users with a fast, scalable
    inference layer above the data that they can interactively query to get actionable
    insights. Large batches of data can be approximated by the DNN which utilize concurrent
    processing in a Graphical Processing Unit (GPU). In addition, since Hunch’s DNNs
    are typically on the Mb scale, they can be easily deployed and distributed to
    thousands of users or IOT devices, putting incredibly fast Big Data analytics
    almost anywhere. Embedding Big Data analytics at the edge or anyplace that users
    can benefit from them is a huge leap forward when dealing with these immense datasets.
    Sisense Hunch balances speed, resource consumption, and accuracy and gives users
    unparalleled flexibility in where they put these insights.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Sisense Hunch](../Images/401b66816f3311820c8d3955d2570bb4.png)](https://www.sisense.com/sisense-labs/hunch/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The power of the Hunch system lies in the DNN training process, which ultimately
    yields the query approximation model. The process is divided into three phases:
    generating artificial [SQL queries](https://www.sisense.com/blog/8-ways-fine-tune-sql-queries-production-databases/),
    obtaining the labels for the training set (i.e., executing the queries on the
    database), and finally encoding the queries into numeric tensor using the on-the-fly
    generated query encoder. Once this training set is created, Hunch utilizes a supervised
    approach to learn to approximate the training set queries.'
  prefs: []
  type: TYPE_NORMAL
- en: The Training Process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Generating SQL Queries**'
  prefs: []
  type: TYPE_NORMAL
- en: To approximate the wide array of queries that could come in for a given dataset,
    Hunch self-generates a robust set of queries.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the formal query structure description:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3f40a7d5b53f1f6a7d92268f1d165d4b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An example of a Hunch-generated query is:'
  prefs: []
  type: TYPE_NORMAL
- en: “Select AVG(sales) from table where store_type in (‘online’) and computer_type
    in (‘Mac’) and hour between 20 and 23 and hdisk_tb_size between 1 AND 5”
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate goal of this phase is to generate a large representative set of
    aggregated SQL queries to cover many (user-oriented) aspects of the raw data.
    In order to do this, the system first extracts statistical values (data distribution)
    from the raw data.
  prefs: []
  type: TYPE_NORMAL
- en: For each column with continuous numeric values, the algorithm calculates quartile
    distributions (min, 25%, median, 75%, max). Then, it uses this information to
    sample values from a uniform distribution which fits to the column numeric boundaries.
    The system also executes “Group By” queries, which accelerates training set generation,
    mainly because all permutations of nominal columns’ values can be obtained in
    one path to the data. Additionally, in the query format our method supports, “WHERE”
    clause statements are connected with an “AND” operator, so the order of the statement
    does not make a difference. To ensure the DNN does not learn specific statements’
    order, our method randomly shuffles the statements before constructing the query.
    This is done intentionally to force the DNN to learn to approximate semantically
    identical queries that occur with different “WHERE” clause ordering.
  prefs: []
  type: TYPE_NORMAL
- en: '**Labeling the Training Set**'
  prefs: []
  type: TYPE_NORMAL
- en: Building a supervised data set for training the DNN requires real query results.
    For this, our method runs the set of generated queries against the dataset. Since
    the DNN requires a relatively large number of training samples, the system generates
    and executes hundreds of thousands of queries using concurrent technology to optimize
    costs. However, this process takes place only **once** for each dataset. When
    new data arrives, necessitating the generation of new queries, Hunch uses incremental
    (transfer) learning (more on that later). This approach saves time, effort, and
    costs both in the training set generation phase and in the DNN training phase.
  prefs: []
  type: TYPE_NORMAL
- en: '**Encoding Queries**'
  prefs: []
  type: TYPE_NORMAL
- en: Since the DNN can digest only numeric input, we developed an encoding model
    to encode the queries into numeric matrices. This goal is obtained by an encoder
    model which is constructed on the fly (during SQL queries generation), making
    use of vector embedding technique.
  prefs: []
  type: TYPE_NORMAL
- en: The encoder is designed to condense data sets with millions of distinct values
    into light memory footprint numeric tensors by utilizing proprietary embedding
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: '**Tackling New Data with Incremental Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: When new data is added to the dataset, Hunch needs to adapt the DNN to approximate
    queries based on new data. Building on the previous learning processes, Hunch
    utilizes transfer learning, meaning that the DNN will be trained from its last
    weights state, against a new training set which is generated using the previous
    DNN and the new data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluation and Distribution**'
  prefs: []
  type: TYPE_NORMAL
- en: Once the training is finalized, we use a set of accuracy metrics to evaluate
    the model’s approximation. We use Normalized Root Mean Squared Error (NRMSE) to
    measure the model accuracy on a hold out testing set of queries. Once the NRMSE
    is converged below a threshold, Hunch publishes a cloud API end-point around the
    DNN. Then, users or IOT devices can send query requests. The end-user benefits
    with from prompt response fixed query latency (which is independent of the raw
    data size!) and interactivity when dealing with Big Data in a wide variety of
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just because we now live in a world of Big Data does not mean we need to surrender
    our ability to interact with that data and truly understand it. [Deep neural networks](https://internetofthingsagenda.techtarget.com/blog/IoT-Agenda/Data-cognition-engines-can-save-millions-in-big-data-costs) using
    Approximate Query Processing offer users a way to work with these huge datasets,
    pull out powerful insights, and put those insights at the edge for IoT and human
    usage—all without requiring huge technological investments or costs. Nothing will
    stop the Big Data from getting even bigger, but technology like Hunch will help
    humans stay in the driver’s seat.
  prefs: []
  type: TYPE_NORMAL
- en: '**Graph A: Query Results and Predictions for a 1,000,000,000-Row, 250-Gb Dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ccbec9b2fd99cd827244b10a4da99205.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Original](https://www.sisense.com/blog/training-a-champion-building-deep-neural-nets-for-big-data-analytics/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn Deep Learning by Building 15 Neural Network Projects in 2022](https://www.kdnuggets.com/2022/01/15-neural-network-projects-build-2022.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Neural Networks and Deep Learning: A Textbook (2nd Edition)](https://www.kdnuggets.com/2023/07/aggarwal-neural-networks-deep-learning-textbook-2nd-edition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
