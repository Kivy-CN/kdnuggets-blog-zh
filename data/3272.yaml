- en: AI and Deep Learning, Explained Simply
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI和深度学习，简明解释
- en: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html/2](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html/2](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html/2)
- en: '**Faulty automation increases (rather than kill) human jobs**. 2 days after
    I published this article, suddenly my profile was blocked. Google for “LinkedIn
    account restricted” to learn this happens to many for simply too much activity,
    even if not messaging. I had only opened, for curiosity, the profiles of the hundreds
    who clicked “I like” on this article (thanks to you all). Then, a naive rule “*x* pages
    opened within time *y*” AI decided I was an AI too, of the “web bot” kind (programs
    browsing all the pages of a site to copy its contents). It blocked me without
    any “Slow down” warning, why to warn a bot?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**有缺陷的自动化增加了（而不是消灭）人类工作岗位**。在我发布这篇文章的两天后，我的个人资料突然被封锁。谷歌搜索“LinkedIn账户限制”可以了解到这种情况发生在很多人身上，仅仅因为活动过多，即使不是在发送消息。我只是出于好奇，查看了那些点击“我喜欢”这篇文章的几百个用户的个人资料（感谢大家）。然后，一个天真的规则“*x*页面在*y*时间内打开”让AI决定我也是一个AI，属于“网页机器人”类型（程序浏览网站的所有页面以复制其内容）。它没有任何“减速”警告就封锁了我，毕竟警告机器人有什么用呢？'
- en: '**I was not a bot, I swear I am human**. Counting “*x* pages opened within
    time *y*” it catches many bots, but also “false positives”: curious humans in
    activity peaks. This frustrated the LinkedIn staff too: who to trust, the AI or
    the user? I had to send my ID as proof, it took days. This rule-based “AI” created
    extra human support jobs to just handle unnecessary “AI” errors that humans alone
    would not do. Think at: “flag all emails from Nigeria as spam” or “flag all people
    with long beard as terrorists”. You can improve rules by adding parameters, past
    activity, etc., but never reaching the accuracy of humans or fine trained MLs.
    Beware of “automation” or “AI” claims: most it is still too simple rules, no any
    deep learning. Microsoft acquired LinkedIn for $26 billion, will surely upgrade
    this old piece to real ML. But until then, don’t browse LinkedIn too fast!'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**我不是机器人，我发誓我是真人**。计算“*x*页面在*y*时间内打开”会捕捉到许多机器人，但也会出现“假阳性”：活动高峰时的好奇人类。这也让LinkedIn的工作人员感到沮丧：信任AI还是用户？我不得不发送身份证明，这花费了几天时间。这种基于规则的“AI”创造了额外的人力支持工作，仅仅处理不必要的“AI”错误，而这些错误人类本来不会犯。想想：“将所有来自尼日利亚的邮件标记为垃圾邮件”或“将所有长胡子的人标记为恐怖分子”。你可以通过添加参数、过去活动等来改进规则，但永远无法达到人类或经过良好训练的机器学习的准确度。小心“自动化”或“AI”声明：大多数仍然是过于简单的规则，没有任何深度学习。微软以260亿美元收购了LinkedIn，肯定会将这块旧系统升级为真正的机器学习。但在那之前，不要浏览LinkedIn太快！'
- en: '**If no human can predict something, often the ML can’t too.** Many people
    trained MLs with years of market price changes, but these MLs **fail to predict
    the market**. The ML will guess how things will go if the learned past factors
    and trends will keep the same. But stock and economy trends change very often,
    like at random. MLs fail when the older data gets less relevant or wrong very
    soon and often. The task or rules learned must keep the same, or at most rarely
    updated, so you can re-train. For ex. learning to drive, play poker, paint in
    a style, predict a sickness given health data, translate between languages are
    jobs for MLs: old examples will keep valid for the near future.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果没有人能预测某事，机器学习通常也无法预测**。许多人用多年市场价格变化训练机器学习，但这些机器学习**无法预测市场**。机器学习会根据过去学习的因素和趋势来猜测事情的发展。然而，股票和经济趋势经常像随机一样变化。当旧数据变得不那么相关或迅速变得错误时，机器学习会失败。任务或规则必须保持不变，或最多偶尔更新，以便你可以重新训练。例如，学习驾驶、玩扑克、以某种风格绘画、根据健康数据预测疾病、翻译语言是机器学习的任务：旧的示例在近期仍然有效。'
- en: '**ML can find cause-effects on data, but it can’t find what it does not exist**.
    For ex. in the weird research “Automated inference on criminality using face images”,
    the ML was trained on labeled face photos of jailed and honest guys (some of whom,
    let me add, could be criminals who was not discovered?). Authors claimed that
    the ML learned to catch new bad guys from just a face photo, but “feeling” that
    further research will refute the validity of physiognomy (racism). Really, their
    data set is biased: some white collar criminals pose as honest guys, laughing
    about that. The ML learned the only relations it could find: happy or angry mouths,
    type of collar (neck cloth). Those smiling with white collar are classified as
    honest, those sad with dark collar are rated as crooks. The ML authors tried to
    judge the people by their faces (not science! no correlation), but failed to see
    that the ML learned to judge by clothes (social status) instead. The ML amplified
    an injustice bias: street thieves in cheap clothes (perhaps with darker skin)
    are discovered and jailed more often than corrupt politicians and top level corporate
    fraudsters. This ML will send to jail all the street guys, and not a single white
    collar, if not also told that street thieves are discovered *x*% more frequently
    than white collars. If told so, again, it would take random or no decisions, this
    is not science. A lesson is: MLs do not experienced living in our world like an
    adult human. MLs can’t can’t know what’s outside the data given, including the
    “obvious”, for ex.: the more a fire is damaging, the more fire trucks are sent
    to stop it. An ML will note: the more firefighters at a fire scene, the more damage
    the day after, so the fire trucks cause fire damage. Result: the ML will send
    to jail the firefighters for arson, cause: “95% correlation”!'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习可以在数据中发现因果关系，但无法发现不存在的东西**。例如，在奇怪的研究“使用面部图像的犯罪推断自动化”中，机器学习在标记的面部照片（其中一些可能是尚未被发现的罪犯）上进行训练。作者声称，机器学习能够仅通过面部照片捕捉到新的坏人，但“感觉”进一步研究会驳斥生理特征学的有效性（种族主义）。实际上，他们的数据集存在偏见：一些白领罪犯伪装成诚实的人，嘲笑这一点。机器学习学会了只能找到的关系：快乐或愤怒的嘴巴、领带的类型。那些微笑并穿白领衣物的人被分类为诚实，悲伤且穿黑领衣物的人被评为罪犯。机器学习作者试图通过面部来判断人们（这不是科学！没有相关性），但未能看到机器学习学会了通过衣物（社会地位）来判断。机器学习放大了不公正的偏见：穿便宜衣物的街头小偷（可能皮肤较黑）被发现和判刑的频率比腐败的政客和高层企业欺诈者更高。这个机器学习会将所有街头小偷送入监狱，而不是一个白领罪犯，如果没有说明街头小偷被发现的频率比白领高*x%多的话。如果说明了，再次，它会做出随机或没有决策，这不是科学。一个教训是：机器学习不像成人那样经历我们的世界。机器学习无法知道数据之外的东西，包括“显而易见”的事情，例如：火灾损害越严重，送去的消防车越多。机器学习会注意到：火灾现场的消防员越多，第二天的损害越大，因此消防车造成了火灾损害。结果：机器学习会因纵火罪将消防员送入监狱，原因是：“95%的相关性”！'
- en: '![](../Images/53e8919e8836c68766c74e8746fe27ca.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53e8919e8836c68766c74e8746fe27ca.png)'
- en: '*(ML can’t find correlations that do not exist, like: face with criminality.
    But this data set is biased: no smiling white collar criminals in it! ML will
    learn the bias)*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*(机器学习无法找到不存在的相关性，例如：面部与犯罪性。但是这个数据集存在偏见：没有笑容的白领罪犯！机器学习会学习这种偏见)*'
- en: '**MLs can predict what humans can’t, in some cases**. For ex. Deep Patient,
    trained from 700,000 patients data by M. Sinai Hospital in New York, it can anticipate
    the onset of schizophrenia: no one knows how! Only the ML can: humans can’t learn
    to do the same by studying the ML. This is an issue: for an investment, medical,
    judicial or military decision, you may want to **know** **how the AI reached its
    conclusions, but you can’t**. You can’t know why the ML denied your loan, advised
    a judge to jail you or gave the job to someone else. Was the ML fair or unfair?
    Unbiased or biased by race, gender or else? The ML computations are visible, but
    too many to make a human-readable summary. The ML speaks like a prophet: “You
    humans can’t understand, even if I show you the math, so have faith! You tested
    my past predictions, and these were correct!”.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习可以预测人类无法预测的情况**。例如，由纽约M. Sinai医院用70万患者数据训练的Deep Patient，可以预测精神分裂症的发生：没有人知道原因！只有机器学习能做到这一点：人类无法通过学习机器学习来做到这一点。这是一个问题：无论是投资、医疗、司法还是军事决策，你可能希望**知道**
    **人工智能如何得出结论，但你却做不到**。你无法知道为什么机器学习拒绝了你的贷款、建议法官判你入狱或将工作分配给其他人。机器学习是否公平？是否受到种族、性别等的偏见影响？机器学习的计算结果虽然可见，但数量太多，无法总结成易于理解的形式。机器学习像先知一样说：“你们人类无法理解，即使我展示给你们数学，你们也无法理解，所以要有信心！你们测试了我的过去预测，这些预测是正确的！”'
- en: '**Humans are never fully explaining their decisions too:** We give reasonable-sounding,
    but always **incomplete, over-simplified** reasons. For ex: “We invaded Iraq due
    to its weapons of mass destruction” looked right, but there were dozens more reasons.
    This looks wrong, even when the ML is right: “We bombed that village since a reputable
    ML said they was terrorists”. It only lacks explanation. People getting almost
    always right answers from MLs will start to make up fake explanations, just for
    the public to accept the MLs predictions. Some will use MLs in secret, crediting
    the ideas to themselves.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类也从未完全解释他们的决策**：我们给出听起来合理但始终**不完整、过于简化**的理由。例如：“我们入侵伊拉克是因为其拥有大规模杀伤性武器”看起来是对的，但还有几十个其他原因。这看起来很错，即使机器学习是对的：“我们轰炸了那个村庄，因为一个声誉良好的机器学习模型说他们是恐怖分子”。它只是缺乏解释。人们从机器学习中几乎总能得到正确答案后，会开始编造虚假的解释，只为公众接受机器学习的预测。一些人会秘密使用机器学习，并将创意归功于自己。'
- en: '**The ML results are only as good the data you train the ML with**. In ML you
    rarely write software, that’s provided by Google (Keras, Tensorflow), Microsoft
    etc. and the algorithms are open source. ML is an unpredictable science defined
    by experimentation, not by theory. You spend most of the time preparing the data
    to train and studying the results, then doing lots of changes, mostly by guessing,
    and retrying. ML’s fed with too few or inaccurate data will give wrong results.
    Google Images incorrectly classified African Americans as gorillas, while Microsoft’s
    Tay bot learned nazi, sex and hate speech after only hours training on Twitter.
    The issue was the data, not the software.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习结果的好坏仅取决于你用来训练机器学习的数据**。在机器学习中，你很少编写软件，这些软件由 Google（Keras、Tensorflow）、Microsoft
    等提供，算法也是开源的。机器学习是一门由实验定义的不可预测的科学，而非理论。你大部分时间都花在准备训练数据和研究结果上，然后进行大量的修改，大多是凭猜测，并重新尝试。机器学习的训练数据过少或不准确将导致错误的结果。谷歌图像错误地将非洲裔美国人分类为猩猩，而微软的Tay机器人在
    Twitter 上仅经过几小时的训练后就学会了纳粹、色情和仇恨言论。问题在于数据，而非软件。'
- en: '**Undesirable biases are implicit in human-generated data**: an ML trained
    on Google News associated “father is to doctor as mother is to nurse” reflecting
    gender bias. If used as is, it might prioritize male job applicants over female
    ones. A law enforcement ML could discriminate by skin color. During the Trump
    campaign, some ML may have reduced recommending “Mexican” restaurants, as a side
    effect of reading many negative posts about Mexican immigration, even if no one
    complained about Mexican food or restaurants specifically. You can’t simply copy
    data from the internet into your ML, and expect it to end up balanced. **To train
    a wise ML it’s expensive**: you need humans to review and “de-bias” what’s wrong
    or evil, but naturally happening in the media.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**不良偏见隐含在人类生成的数据中**：一个在 Google 新闻上训练的机器学习模型将“父亲是医生，就像母亲是护士”联系到性别偏见。如果直接使用它，可能会优先考虑男性求职者而非女性求职者。执法机器学习模型可能会基于肤色进行歧视。在特朗普竞选期间，一些机器学习模型可能减少了对“墨西哥”餐馆的推荐，这是一种副作用，因为它阅读了许多关于墨西哥移民的负面帖子，即使没有人具体抱怨墨西哥食品或餐馆。你不能简单地将互联网数据复制到你的机器学习中，并期望它最终会平衡。**训练一个明智的机器学习模型是昂贵的**：你需要人类来审查和“去偏见”那些错误或邪恶的内容，但这些内容自然存在于媒体中。'
- en: '![self-driving car](../Images/1fe4b408380fa65ec825765f72c9f9a0.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![自动驾驶汽车](../Images/1fe4b408380fa65ec825765f72c9f9a0.png)'
- en: '***(Photo: James Bridle entraps a self-driving car inside an unexpected circle)***'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '***(照片：詹姆斯·布赖德将一辆自动驾驶汽车困在一个意想不到的圈子里)***'
- en: '**ML is limited since it lacks general intelligence and prior common sense**.
    Even merging together all the specialized MLs, or training an ML on everything,
    it will still fail at general AI tasks, for ex. at understanding language. You
    can’t talk about every topic with Siri, Alexa or Cortana like with real people:
    they’re just assistants. In 2011, IBM Watson answered faster than humans at *Jeopardy!* TV
    quiz, but confused Canada with USA. ML can produce useful summaries of long texts,
    including sentiment analysis (opinions and mood identification), but not as reliable
    as human works. Chatbots fail to understand too many questions. No current AI
    can do what’s easy for every human: to guess all the times when a customer is
    frustrated or sarcastic, and to change tone accordingly. There is no any general
    AI like in the movies. But we can get small sci-fi looking AI pieces, separately,
    that win humans at narrow (specific) tasks. What’s new is that “narrow” can include
    creative or supposedly human-only tasks: paint (styles, geometries, less likely
    if symbolic or conceptual), compose, create, guess, deceive, fake emotions, etc.
    all of which, incredibly, seem not to require general AI.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习受限于缺乏通用智能和先验常识**。即使将所有专门的机器学习结合起来，或对所有内容进行训练，它在通用AI任务上仍会失败，例如理解语言。你不能像与真实的人一样与Siri、Alexa或Cortana讨论每个话题：它们只是助手。在2011年，IBM
    Watson在*危险边缘*电视问答中比人类回答得更快，但把加拿大和美国搞混了。机器学习可以生成长文本的有用摘要，包括情感分析（意见和情绪识别），但不如人类工作可靠。聊天机器人无法理解过多问题。目前没有任何AI可以完成每个人都能轻松做到的事情：在顾客感到沮丧或讽刺时猜测并相应调整语气。没有像电影中的通用AI。但我们可以获得一些看起来像科幻小说的AI模块，它们在狭义（特定）任务上战胜人类。新的地方在于，“狭义”可以包括创造性或所谓的仅有人类才能完成的任务：绘画（风格、几何，象征性或概念性的较少），作曲，创作，猜测，欺骗，虚假情感等，这些都令人难以置信地似乎不需要通用AI。'
- en: '**No one knows how to build a general AI**. This is great: we get super-human
    specialized (narrow AI) workers, but no any Terminator or Matrix will decide on
    its own to kill us anytime soon. Unfortunately, humans can train machines to kill
    us right now, for ex. a terrorist teaching self-driving trucks to hit pedestrians.
    An AI with general intelligence it would probably self-destruct, rather than obey
    to terrorist orders.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有人知道如何构建通用人工智能**。这很好：我们得到的是超人类的专门（窄域AI）工人，但不会有任何终结者或《黑客帝国》会自行决定随时消灭我们。不幸的是，人类现在可以训练机器来伤害我们，例如，一个恐怖分子教会自动驾驶卡车撞击行人。一个拥有通用智能的AI可能会自我销毁，而不是听从恐怖分子的命令。'
- en: '**AI ethics will be hacked, reprogrammed illegally**. Current ML, being not
    general or sentient AI, will always follow the orders (training data) given by
    humans: don’t expect AI conscientious objectors. Each government will have to
    write laws detailing if a self-driving car will prefer to kill either its passenger(s)
    or pedestrian(s). For ex. two kids run suddenly in front of a car with a single
    passenger, and to avoid the kids, the car can only run in a deadly option, like
    a cliff. Polls show that the majority of people would prefer to own a car that
    kills pedestrians rather than themselves. Most people don’t think yet at these
    very rare events, but will overreact and question politicians when the first case
    it will happen, even if only once per billion cars. In countries where cars will
    be instructed to kill a single passenger to save multiple pedestrians, car owners
    will ask hackers to secretly reprogram cars to always save the passenger(s). But
    within pirated AI patches, hidden AI malware and viruses will probably be installed
    too!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**AI伦理将被破解和非法重编程**。当前的机器学习，既不是通用的也不是有意识的AI，将始终遵循人类给出的命令（训练数据）：不要指望AI会有良心的反对者。每个政府都将必须制定法律，详细说明自动驾驶汽车是在优先保护乘客还是行人。例如，两个孩子突然跑到一辆只有一个乘客的汽车前面，为了避免撞到孩子，这辆车只能选择一个致命的选项，比如悬崖。民意调查显示，大多数人更愿意拥有一辆撞死人而不是伤害自己的汽车。大多数人还未考虑这些极其罕见的事件，但当第一起事件发生时，即便仅仅是每十亿辆车中一次，他们也会过度反应并质疑政治家。在那些指示汽车为了拯救多个行人而牺牲单一乘客的国家，车主会要求黑客秘密重编程汽车，以始终保护乘客。但在破解的AI补丁中，可能也会安装隐藏的AI恶意软件和病毒！'
- en: '**To teach a human it’s easy**: for most tasks, you give a dozen of examples
    and let him/her try a few times. But an ML requires thousand times more labeled
    data: only humans can learn from little data. An ML must try a million more times:
    if real world experiments are mandatory (can’t fully simulate like for chess,
    go, etc.), you’ll have to crash thousands of real cars, kill or hurt thousands
    of real human patients, etc. before to complete a training. An ML, unlike humans, **overfits**:
    it memorizes too specific detail of the training data, instead of general patterns.
    So, it fails on real tasks over never seen before data, even just a little different
    from the training data. Current ML it lacks the human general intelligence that
    models each situation and relates it to prior experience, to learn from very few
    examples or trial and errors, memorizing just what’s general, and ignoring what’s
    not relevant, avoiding to try what it can be predicted as a fail.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**教一个人很容易**：对于大多数任务，你只需给出十几个例子，让他/她尝试几次。但机器学习需要成千上万倍的标记数据：只有人类可以从少量数据中学习。机器学习必须尝试更多次：如果真实世界的实验是必需的（无法像棋类、围棋等那样完全模拟），你将不得不撞毁成千上万辆真实的汽车，伤害或致死成千上万名真实患者，等等，才能完成训练。与人类不同的是，机器学习**过拟合**：它记住了训练数据的过于具体的细节，而不是一般模式。因此，它在真实任务中对从未见过的数据（即使只是与训练数据稍有不同）表现不佳。目前的机器学习缺乏人类的普遍智能，后者会对每种情况建模，并将其与之前的经验关联，从而从极少的例子或试错中学习，记住的只是一般性内容，忽略不相关的内容，避免尝试那些可以预测为失败的情况。'
- en: '* * *'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的IT需求'
- en: '* * *'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过找到目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，深入分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写清晰的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功的数据科学家具备的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
