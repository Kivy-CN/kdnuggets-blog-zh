["```py\n*# Parallel Computing*\nimport multiprocessing as mp\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\n\n*# Data Ingestion* \nimport pandas as pd\n\n*# Text Processing* \nimport re \nfrom nltk.corpus import stopwords\nimport string\n```", "```py\nn_workers = 2 * mp.cpu_count()\n\nprint(f\"{n_workers} workers are available\")\n\n>>> 8 workers are available\n```", "```py\n%%time\nfile_name=\"../input/us-accidents/US_Accidents_Dec21_updated.csv\"\ndf = pd.read_csv(file_name)\n\nprint(f\"Shape:{df.shape}\\n\\nColumn Names:\\n{df.columns}\\n\")\n```", "```py\nShape:(2845342, 47)\n\nColumn Names:\n\nIndex(['ID', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng',\n'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Number', 'Street',\n'Side', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',\n'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)',\n'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction',\n'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity',\n'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n'Astronomical_Twilight'],\ndtype='object')\n\nCPU times: user 33.9 s, sys: 3.93 s, total: 37.9 s\nWall time: 46.9 s\n```", "```py\ndef clean_text(text): \n  *# Remove stop words*\n  stops = stopwords.words(\"english\")\n  text = \" \".join([word for word in text.split() if word not in stops])\n  *# Remove Special Characters*\n  text = text.translate(str.maketrans('', '', string.punctuation))\n  *# removing the extra spaces*\n  text = re.sub(' +',' ', text)\n  return text\n```", "```py\n%%time\ntqdm.pandas()\n\ndf['Description'] = df['Description'].progress_apply(clean_text)\n```", "```py\n100%  2845342/2845342 [09:05<00:00, 5724.25it/s]\n\nCPU times: user 8min 14s, sys: 53.6 s, total: 9min 7s\nWall time: 9min 5s\n```", "```py\n%%time\np = mp.Pool(n_workers) \n\ndf['Description'] = p.map(clean_text,tqdm(df['Description']))\n```", "```py\n100%  2845342/2845342 [02:58<00:00, 135646.12it/s]\n\nCPU times: user 5.68 s, sys: 1.56 s, total: 7.23 s\nWall time: 3min 51s\n```", "```py\ndef text_parallel_clean(array):\n  result = Parallel(n_jobs=n_workers,backend=\"multiprocessing\")(\n  delayed(clean_text)\n  (text) \n  for text in tqdm(array)\n  )\n  return result\n```", "```py\n%%time\ndf['Description'] = text_parallel_clean(df['Description'])\n```", "```py\n100%  2845342/2845342 [04:03<00:00, 10514.98it/s]\n\nCPU times: user 44.2 s, sys: 2.92 s, total: 47.1 s\nWall time: 4min 4s\n```", "```py\ndef proc_batch(batch):\n  return [\n  clean_text(text)\n  for text in batch\n  ]\n```", "```py\ndef batch_file(array,n_workers):\n  file_len = len(array)\n  batch_size = round(file_len / n_workers)\n  batches = [\n  array[ix:ix+batch_size]\n  for ix in tqdm(range(0, file_len, batch_size))\n  ]\n  return batches\n\nbatches = batch_file(df['Description'],n_workers)\n\n>>> 100%  8/8 [00:00<00:00, 280.01it/s]\n```", "```py\n%%time\nbatch_output = Parallel(n_jobs=n_workers,backend=\"multiprocessing\")(\n  delayed(proc_batch)\n  (batch) \n  for batch in tqdm(batches)\n  )\n\ndf['Description'] = [j for i in batch_output for j in i]\n```", "```py\n100%  8/8 [00:00<00:00, 2.19it/s]\n\nCPU times: user 3.39 s, sys: 1.42 s, total: 4.81 s\nWall time: 3min 56s\n```", "```py\n%%time\nfrom tqdm.contrib.concurrent import process_map\nbatch = round(len(df)/n_workers)\n\ndf[\"Description\"] = process_map(\n    clean_text, df[\"Description\"], max_workers=n_workers, chunksize=batch\n)\n```", "```py\n100%  2845342/2845342 [03:48<00:00, 1426320.93it/s]\n\nCPU times: user 7.32 s, sys: 1.97 s, total: 9.29 s\nWall time: 3min 51s\n```"]