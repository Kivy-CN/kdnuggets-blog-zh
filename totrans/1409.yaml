- en: Data Validation for Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/01/data-validation-machine-learning.html](https://www.kdnuggets.com/2020/01/data-validation-machine-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#coments)![figure-name](../Images/e306e2b39a6b142c0e4ef9a749a5f069.png)[Source](https://i.stack.imgur.com/nr41H.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Data is the sustenance that keeps machine learning going. No matter how powerful
    a machine learning and/or deep learning model is, it can never do what we want
    it to do with bad data. **Random noise (i.e. data points that make it difficult
    to see a pattern)**, **low frequency of a certain categorical variable**, **low
    frequency of the target category (if target variable is categorical)** and **incorrect
    numeric values** etc. are just some of the ways data can mess up a model. While
    the validation process cannot directly find what is wrong, the process can show
    us sometimes that there is a problem with the stability of the model.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Train/Validation/Test Split
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![figure-name](../Images/25bb23914800153c31adc3ee78148be1.png)'
  prefs: []
  type: TYPE_IMG
- en: The most basic method of validating your data (i.e. tuning your hyperparameters
    before testing the model) is when someone will perform a train/validate/test split
    on the data. A typical ratio for this might be 80/10/10 to make sure you still
    have enough training data. After training the model with the training set, the
    user will move onto validating the results and tuning the hyperparameters with
    the validation set till the user reaches a satisfactory performance metric. Once
    this stage is completed, the user would move on to testing the model with the
    test set to predict and evaluate the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Corss Validation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cross Validation is a technique to assess the performance of a statistical prediction
    model on an independent data set. The goal is to make sure the model and the data
    work well together. Cross validation is conducted during the training phase where
    the user will assess whether the model is prone to underfitting or overfitting
    to the data. The data to be used for cross validation have to be from the same
    distribution for the target variable or else we can mislead ourselves as to how
    the model will perform in real life.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different types of Cross Validation, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '***   K-fold Cross Validation**'
  prefs: []
  type: TYPE_NORMAL
- en: In the circumstance that we would like to preserve as much data as possible
    for the training stage and not risk losing valuable data to the validation set,
    k-fold cross validation can help. This technique will not require the training
    data to give up s portion for a validation set. In this instance, the dataset
    is broken into *k* number of folds wherein one fold will be used as the test set
    and the rest will be used as the training dataset and this will be repeated *n*
    number of times as specified b the user. In a regression the average of the results
    (e.g. RMSE, R-Squared, etc.) will be used as the final result. In a classification
    setting, the average of the results (i.e. Accuracy, True Positive Rate, F1, etc.)
    will be taken as the final result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure-name](../Images/f54ddfc94a93d5a96c6e33e9d386cc7e.png)'
  prefs: []
  type: TYPE_IMG
- en: .
  prefs: []
  type: TYPE_NORMAL
- en: Leave-One-Out Validation (LOOCV)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave-One-Out Validation is similar to the k-fold cross valiadtion. The iteration
    is carried out *n* specified times
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and the dataset will be split into n-1 data sets and the one that was removed
    will be the test data. performance is measured the same way as k-fold cross validation.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/176d9714fc99e9812bdff25ec0540d82.png)'
  prefs: []
  type: TYPE_IMG
- en: Validating a dataset gives reassurance to the user about the stability of their
    model. With machine learning penetrating facets of society and being used in our
    daily lives, it becomes more imperative that the models are representative of
    our society. Overfitting and underfitting are the two most common pitfalls that
    a Data Scientist can face during a model building process. Validation is the gateway
    to your model being optimized for performance and being stable for a period of
    time before needing to be retrained.
  prefs: []
  type: TYPE_NORMAL
- en: '**Related**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Common Machine Learning Obstacles](/2019/09/mathworks-common-machine-learning-obstacles.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Book to Start You on Machine Learning](/2020/01/book-start-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Reasons Why You Should Use Cross-Validation in Your Data Science Projects](/2018/10/5-reasons-cross-validation-data-science-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
