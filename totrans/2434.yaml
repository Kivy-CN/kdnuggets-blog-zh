- en: 'Naïve Bayes Algorithm: Everything You Need to Know'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法：您需要了解的一切
- en: 原文：[https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
- en: '![Figure](../Images/15178d1596b6428dba58b29de1bb24dc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/15178d1596b6428dba58b29de1bb24dc.png)'
- en: '[Image credit](https://blogs.oracle.com/datascience/introduction-to-bayesian-inference)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://blogs.oracle.com/datascience/introduction-to-bayesian-inference)'
- en: Introduction to the Naïve Bayes Algorithm
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法简介
- en: The simplest solutions are usually the most powerful ones, and [Naïve Bayes](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)
    is a good example of that. Despite the advances in Machine Learning in the last
    years, it has proven to not only be simple but also fast, accurate, and reliable.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的解决方案通常是最有效的，[朴素贝叶斯](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)就是一个很好的例子。尽管近年来机器学习取得了进展，但它不仅简单，而且快速、准确和可靠。
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织 IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: It has been successfully used for many purposes, but it works particularly well
    with natural language processing (NLP) problems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 它已经成功用于许多目的，但在自然语言处理（NLP）问题上特别有效。
- en: Naïve Bayes is a probabilistic machine learning algorithm based on the **Bayes
    Theorem**, used in a wide variety of classification tasks. In this article, we
    will understand the Naïve Bayes algorithm and all essential concepts so that there
    is no room for doubts in understanding.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是一种基于**贝叶斯定理**的概率机器学习算法，广泛应用于各种分类任务。在本文中，我们将深入理解朴素贝叶斯算法及其所有基本概念，以便彻底理解。
- en: Bayes Theorem
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: Bayes’ Theorem is a simple mathematical formula used for calculating conditional
    probabilities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是用于计算条件概率的简单数学公式。
- en: '**Conditional probability** is a measure of the probability of an event occurring
    given that another event has (by assumption, presumption, assertion, or evidence)
    occurred.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**条件概率**是指在另一个事件（通过假设、推测、断言或证据）发生的情况下，事件发生的概率的度量。'
- en: 'The formula is: —'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 公式是：—
- en: '![](../Images/38d8516f4eb2af2be4891493f2440dd7.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38d8516f4eb2af2be4891493f2440dd7.png)'
- en: 'Which tells us: how often A happens *given that B happens*, written **P(A|B) **also
    called posterior probability, When we know: how often B happens *given that A
    happens*, written **P(B|A)** and how likely A is on its own, written **P(A)** and
    how likely B is on its own, written **P(B).**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们：**P(A|B)**，即在**B发生**的情况下，**A发生的概率**，也称为后验概率。当我们知道**A发生**的情况下**B发生的概率**，写作**P(B|A)**，以及**A**单独发生的概率**P(A)**和**B**单独发生的概率**P(B)**。
- en: In simpler terms, Bayes’ Theorem is a way of finding a probability when we know
    certain other probabilities.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 简单来说，贝叶斯定理是一种在知道某些其他概率的情况下找出概率的方法。
- en: Assumptions Made by Naïve Bayes
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 朴素贝叶斯所做的假设
- en: 'The fundamental Naïve Bayes assumption is that each feature makes an:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯的基本假设是每个特征都做出一个：
- en: independent
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立
- en: equal
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相等
- en: contribution to the outcome.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对结果的贡献。
- en: Let us take an example to get some better intuition. Consider the car theft
    problem with attributes Color, Type, Origin, and the target, Stolen can be either
    Yes or No.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来获得更好的直观理解。考虑一个具有属性颜色、类型、来源的汽车盗窃问题，目标“被盗”可以是“是”或“否”。
- en: Naïve Bayes Example
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯示例
- en: The dataset is represented as below.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集表示如下。
- en: '![](../Images/f61877acf2f7db8957d71371a5dab39e.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f61877acf2f7db8957d71371a5dab39e.png)'
- en: 'Concerning our dataset, the concept of assumptions made by the algorithm can
    be understood as:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们的数据集，算法所做的假设的概念可以理解为：
- en: We assume that no pair of features are dependent. For example, the color being
    ‘Red’ has nothing to do with the Type or the Origin of the car. Hence, the features
    are assumed to be **Independent**.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们假设没有一对特征是相关的。例如，颜色为‘红色’与汽车的类型或来源无关。因此，特征被假设为**独立的**。
- en: Secondly, each feature is given the same influence(or importance). For example,
    knowing the only Color and Type alone can’t predict the outcome perfectly. So
    none of the attributes are irrelevant and assumed to be contributing **Equally** to
    the outcome.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，每个特征被赋予相同的影响（或重要性）。例如，仅知道颜色和类型无法完美预测结果。因此，没有任何属性是不相关的，假设它们对结果的贡献是**相等的**。
- en: '**Note:** The assumptions made by Naïve Bayes are generally not correct in
    real-world situations. The independence assumption is never correct but often
    works well in practice. **Hence the name ‘Naï>ve’.**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** Naïve Bayes 进行的假设在实际情况中通常不正确。独立假设从未正确，但在实践中往往有效。**因此称为‘Naïve’。**'
- en: Here in our dataset, **we need to classify whether the car is stolen, given
    the features of the car**. The columns represent these features and the rows represent
    individual entries. If we take the first row of the dataset, we can observe that
    the car is stolen if the Color is Red, the Type is Sports and Origin is Domestic.
    So we want to classify a Red Domestic SUV is getting stolen or not. Note that
    there is no example of a Red Domestic SUV in our data set.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，**我们需要根据汽车的特征来分类汽车是否被盗**。列表示这些特征，而行表示单独的条目。如果我们取数据集的第一行，可以观察到，如果颜色是红色，类型是运动型，来源是国内的，则汽车被盗。因此，我们要分类一个红色的国内SUV是否被盗。请注意，我们的数据集中没有红色国内SUV的示例。
- en: 'According to this example, Bayes theorem can be rewritten as:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此示例，贝叶斯定理可以重写为：
- en: '![](../Images/491bf150482fb467a687e989d17a48e0.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/491bf150482fb467a687e989d17a48e0.png)'
- en: The variable **y** is the class variable(stolen?), which represents if the car
    is stolen or not given the conditions. Variable **X **represents the parameters/features.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 **y** 是类变量（被盗？），表示在给定条件下汽车是否被盗。变量 **X** 表示参数/特征。
- en: '**X** is given as,'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**X** 给出如下，'
- en: '![](../Images/5098e278c044fca5b820da7d14036542.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5098e278c044fca5b820da7d14036542.png)'
- en: Here `x1, x2…, xn` represent the features, i.e they can be mapped to Color,
    Type, and Origin. By substituting for **X **and expanding using the chain rule
    we get,
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 `x1, x2…, xn` 表示特征，即它们可以映射到颜色、类型和来源。通过替代 **X** 并使用链式法则展开，我们得到，
- en: '![](../Images/05da7419b18bc6aaa32873d8bf82d70c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05da7419b18bc6aaa32873d8bf82d70c.png)'
- en: Now, you can obtain the values for each by looking at the dataset and substitute
    them into the equation. For all entries in the dataset, the denominator does not
    change, it remains static. Therefore, the denominator can be removed and proportionality
    can be injected.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过查看数据集来获得每个值并将其代入方程中。对于数据集中的所有条目，分母不变，它保持静态。因此，可以去掉分母，并引入比例。
- en: '![](../Images/aba56792a913b70e32e66da097911256.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aba56792a913b70e32e66da097911256.png)'
- en: In our case, the class variable(**y**) has only two outcomes, yes or no. There
    could be cases where the classification could be multivariate. Therefore, we have
    to find the class variable(**y)** with maximum probability.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，类变量(**y**)只有两个结果，即是或否。可能有多变量分类的情况。因此，我们需要找到具有最大概率的类变量(**y**)。
- en: '![](../Images/0dd539563839c7e2949953bac013f521.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0dd539563839c7e2949953bac013f521.png)'
- en: Using the above function, we can obtain the class, given the predictors/features.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述函数，我们可以在给定预测变量/特征的情况下获得类别。
- en: The posterior probability **P(y|X)** can be calculated by first, creating a **Frequency
    Table** for each attribute against the target. Then, molding the frequency tables
    to **Likelihood Tables** and finally, use the Naïve Bayesian equation to calculate
    the posterior probability for each class. The class with the highest posterior
    probability is the outcome of the prediction. Below are the Frequency and likelihood
    tables for all three predictors.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 后验概率 **P(y|X)** 可以通过首先为每个属性创建一个**频率表**来计算。然后，将频率表转换为**可能性表**，最后使用 Naïve Bayesian
    方程计算每个类别的后验概率。具有最高后验概率的类别是预测的结果。以下是所有三个预测变量的频率和可能性表。
- en: '![](../Images/9c4a78458a94dff92bd51ac51e0a03b1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c4a78458a94dff92bd51ac51e0a03b1.png)'
- en: Frequency and Likelihood tables of ‘Color’
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: “颜色”的频率和可能性表
- en: '![](../Images/0c047cfd6ed5737207bb0b6e33027e3b.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c047cfd6ed5737207bb0b6e33027e3b.png)'
- en: Frequency and Likelihood tables of ‘Type’
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ‘类型’的频率和可能性表
- en: '![](../Images/7ab1a4288ebc8d118b5ef013dac9b024.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ab1a4288ebc8d118b5ef013dac9b024.png)'
- en: Frequency and Likelihood tables of ‘Origin’
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ‘来源’的频率和可能性表
- en: So in our example, we have 3 predictors **X**.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在我们的例子中，我们有3个预测变量**X**。
- en: '![](../Images/9ed65c1aa22a95c968245d0c7cae56ee.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ed65c1aa22a95c968245d0c7cae56ee.png)'
- en: 'As per the equations discussed above, we can calculate the posterior probability
    P(Yes | X) as :'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述讨论的方程，我们可以计算后验概率P(Yes | X)为：
- en: '![](../Images/6a8c6366be8f30f46f0d21dce86937fa.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a8c6366be8f30f46f0d21dce86937fa.png)'
- en: 'and, P( No | X ):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '和，P( No | X ):'
- en: '![](../Images/b3ef76ae68f128b5a95d1a296e75d03f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3ef76ae68f128b5a95d1a296e75d03f.png)'
- en: Since 0.144 > 0.048, Which means given the features RED SUV and Domestic, our
    example gets classified as ’NO’ the car is not stolen.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于0.144 > 0.048，这意味着给定特征RED SUV和Domestic，我们的例子被分类为“NO”，即车辆未被盗。
- en: The Zero-Frequency Problem
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零频率问题
- en: One of the disadvantages of Naïve-Bayes is that if you have no occurrences of
    a class label and a certain attribute value together then the frequency-based
    probability estimate will be zero. And this will get a zero when all the probabilities
    are multiplied.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯的一个缺点是，如果一个类别标签和某个属性值一起没有出现，那么基于频率的概率估计将为零。当所有概率相乘时，这将得到零。
- en: An approach to overcome this ‘zero-frequency problem’ in a Bayesian environment
    is to add one to the count for every attribute value-class combination when an
    attribute value doesn’t occur with every class value.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯环境中克服‘零频率问题’的一种方法是，当一个属性值未与每个类别值一起出现时，将每个属性值-类别组合的计数加一。
- en: 'For example, say your training data looked like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你的训练数据如下：
- en: '![](../Images/b3f20887326fed468dc3fb94785fc6a2.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3f20887326fed468dc3fb94785fc6a2.png)'
- en: ????(TimeZone=????????|Spam=????????????)=10/10=1
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ????(TimeZone=????????|Spam=????????????)=10/10=1
- en: ????(TimeZone=????????|Spam=????????????)=0/10=0
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ????(TimeZone=????????|Spam=????????????)=0/10=0
- en: 'Then you should add one to every value in this table when you’re using it to
    calculate probabilities:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在使用这个表计算概率时，你应该对每个值加一：
- en: '![](../Images/8b3e31ab9e54ae8594d2327b289cf2be.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b3e31ab9e54ae8594d2327b289cf2be.png)'
- en: ????(TimeZone=????????|Spam=????????????)=11/12
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ????(TimeZone=????????|Spam=????????????)=11/12
- en: ????(TimeZone=????????|Spam=????????????)=1/12
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ????(TimeZone=????????|Spam=????????????)=1/12
- en: This is how we’ll get rid of getting a zero probability.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何避免得到零概率的方法。
- en: '![XXXXX](../Images/a99e5ff71310dc4c74783a85d0df96b2.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/a99e5ff71310dc4c74783a85d0df96b2.png)'
- en: '[Image credits](https://medium.com/@sanjeethboddi/naive-bayes-algorithm-from-scratch-715d7cc0de53)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://medium.com/@sanjeethboddi/naive-bayes-algorithm-from-scratch-715d7cc0de53)'
- en: Types of Naïve Bayes Classifiers
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器的类型
- en: '**1\. Multinomial Naïve Bayes Classifier**'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. 多项式朴素贝叶斯分类器**'
- en: Feature vectors represent the frequencies with which certain events have been
    generated by a **multinomial distribution**. This is the event model typically
    used for document classification.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量表示某些事件由**多项分布**生成的频率。这是通常用于文档分类的事件模型。
- en: '**2\. Bernoulli Naïve Bayes Classifier**:'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2\. 伯努利朴素贝叶斯分类器**：'
- en: In the multivariate Bernoulli event model, features are independent booleans
    (binary variables) describing inputs. Like the multinomial model, this model is
    popular for document classification tasks, where binary term occurrence (i.e.
    a word occurs in a document or not) features are used rather than term frequencies
    (i.e. frequency of a word in the document).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在多变量伯努利事件模型中，特征是独立的布尔值（离散变量）描述输入。与多项式模型类似，这个模型在文档分类任务中很受欢迎，其中使用的是二元术语出现（即一个词是否出现在文档中）特征，而不是术语频率（即词在文档中的频率）。
- en: '**3\. Gaussian Naïve Bayes Classifier: **'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3\. 高斯朴素贝叶斯分类器：**'
- en: 'In Gaussian Naïve Bayes, continuous values associated with each feature are
    assumed to be distributed according to a **Gaussian distribution (**[Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution)**)**.
    When plotted, it gives a bell-shaped curve which is symmetric about the mean of
    the feature values as shown below:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在高斯朴素贝叶斯中，与每个特征相关的连续值假设符合**高斯分布 (**[正态分布](https://en.wikipedia.org/wiki/Normal_distribution)**)**。当绘制时，它给出一个钟形曲线，该曲线关于特征值的均值对称，如下所示：
- en: '![](../Images/5ad7a683c8b444baa0bd2551070994ee.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ad7a683c8b444baa0bd2551070994ee.png)'
- en: 'The likelihood of the features is assumed to be Gaussian, hence, conditional
    probability is given by:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的可能性假设为高斯分布，因此，条件概率由下式给出：
- en: '![](../Images/21e23e25b324679a49299d08c41b1973.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21e23e25b324679a49299d08c41b1973.png)'
- en: Now, what if any feature contains numerical values instead of categories i.e.
    Gaussian distribution.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果某些特征包含数值而不是类别，即高斯分布，会怎样呢？
- en: One option is to transform the numerical values to their categorical counterparts
    before creating their frequency tables. The other option, as shown above, could
    be using the distribution of the numerical variable to have a good guess of the
    frequency. For example, one common method is to assume normal or gaussian distributions
    for numerical variables.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一种选择是在创建频率表之前将数值转换为其分类对应项。另一种选择，如上所示，可以使用数值变量的分布来很好地估计频率。例如，一种常见的方法是假设数值变量服从正态或高斯分布。
- en: The probability density function for the normal distribution is defined by two
    parameters (mean and standard deviation).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布的概率密度函数由两个参数（均值和标准差）定义。
- en: '![Figure](../Images/a8f7e607f21f5691c12f91cffe63eb4d.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/a8f7e607f21f5691c12f91cffe63eb4d.png)'
- en: '[Image credit](https://www.saedsayad.com/naive_bayesian.htm)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://www.saedsayad.com/naive_bayesian.htm)'
- en: Consider the problem of playing golf, here the only predictor is `Humidity` and `Play
    Golf?` is the target. Using the above formula we can calculate posterior probability
    if we know the mean and standard deviation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑高尔夫球的问题，这里唯一的预测变量是`湿度`，`是否打高尔夫？`是目标。使用上述公式，如果我们知道均值和标准差，就可以计算后验概率。
- en: '![](../Images/82b9ee1aa4c68b8e7060314dbe13bdb0.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82b9ee1aa4c68b8e7060314dbe13bdb0.png)'
- en: 'Case Study: Naïve Bayes Classifier From Scratch Using Python'
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究：从头开始使用 Python 构建朴素贝叶斯分类器
- en: An existing problem for any major website today is how to handle virulent and
    divisive content. Quora wants to tackle this problem to keep its platform a place
    where users can feel safe sharing their knowledge with the world.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当前任何主要网站面临的一个问题是如何处理恶意和分裂性内容。Quora 希望解决这个问题，使其平台成为用户可以安全分享知识的地方。
- en: '[Quora](https://www.quora.com/) is a platform that empowers people to learn
    from each other. On Quora, people can ask questions and connect with others who
    contribute unique insights and quality answers. A key challenge is to weed out
    insincere questions — those founded upon false premises, or that intend to make
    a statement rather than look for helpful answers.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[Quora](https://www.quora.com/) 是一个使人们可以相互学习的平台。在 Quora 上，人们可以提问，并与其他提供独特见解和高质量回答的人联系。一个关键挑战是筛除虚伪的问题——那些建立在虚假前提上的问题，或者那些意图陈述观点而不是寻求有用回答的问题。'
- en: The goal is to develop a Naïve Bayes classification model that identifies and
    flags insincere questions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是开发一个朴素贝叶斯分类模型，以识别和标记虚伪的问题。
- en: The dataset can be downloaded from [here](https://www.kaggle.com/c/quora-insincere-questions-classification/data).
    Once you have downloaded the train and test data, load it and check.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从[这里](https://www.kaggle.com/c/quora-insincere-questions-classification/data)下载。下载训练和测试数据后，加载并检查它。
- en: '[PRE0]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![Figure](../Images/3122d0c3be8f767d27374ffbdf4e08ba.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/3122d0c3be8f767d27374ffbdf4e08ba.png)'
- en: Training dataset
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集
- en: Let us see how are sincere questions look like.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看真实的问题是什么样的。
- en: '![Figure](../Images/9f480898c8936c834ae51541304a0480.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/9f480898c8936c834ae51541304a0480.png)'
- en: Sincere questions
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 真实问题
- en: we see how are insincere questions look like.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看虚伪的问题是什么样的。
- en: '![Figure](../Images/c956e19bcba69b1c8709e12ab7ca9520.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/c956e19bcba69b1c8709e12ab7ca9520.png)'
- en: Insincere questions
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 虚伪问题
- en: '**Text Preprocessing**'
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**文本预处理**'
- en: 'The next step is to preprocess text before splitting the dataset into a train
    and test set. The preprocessing steps involve: Removing Numbers, Removing Punctuations
    in a string, Removing Stop Words, Stemming of Words and Lemmatization of Words.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是对文本进行预处理，然后将数据集拆分为训练集和测试集。预处理步骤包括：移除数字、移除字符串中的标点符号、移除停用词、词干提取和词形还原。
- en: '**Constructing a Naive Bayes Classifier**'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**构建朴素贝叶斯分类器**'
- en: Combine all the preprocessing techniques and create a dictionary of words and
    each word’s count in training data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 结合所有预处理技术，并创建一个包含训练数据中每个词及其计数的字典。
- en: Calculate probability for each word in a text and filter the words which have
    a probability less than threshold probability. Words with probability less than
    threshold probability are irrelevant.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算文本中每个词的概率，并过滤掉概率低于阈值概率的词。概率低于阈值的词是不相关的。
- en: Then for each word in the dictionary, create a probability of that word being
    in insincere questions and its probability insincere questions. Then finding the
    conditional probability to use in naive Bayes classifier.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后对字典中的每个词，计算该词出现在不诚实问题中的概率以及它在不诚实问题中的概率。接着计算条件概率以用于朴素贝叶斯分类器。
- en: Prediction using conditional probabilities.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用条件概率进行预测。
- en: Conclusion
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Naïve Bayes algorithms are often used in sentiment analysis, spam filtering,
    recommendation systems, etc. They are quick and easy to implement but their biggest
    disadvantage is that the requirement of predictors to be independent.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法通常用于情感分析、垃圾邮件过滤、推荐系统等。它们实现起来快速简便，但最大缺点是要求预测变量必须独立。
- en: '**Thanks for Reading!**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢阅读！**'
- en: '**[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是CirrusLabs的一名大数据开发工程师。他在电信、分析、销售、数据科学等多个领域有超过4年的工作经验，专注于多个大数据组件。'
- en: '[Original](https://levelup.gitconnected.com/na%C3%AFve-bayes-algorithm-everything-you-need-to-know-9bf3104b78e5).
    Reposted with permission.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://levelup.gitconnected.com/na%C3%AFve-bayes-algorithm-everything-you-need-to-know-9bf3104b78e5)。经授权转载。'
- en: More On This Topic
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月13日：数据科学家应该知道的 Python 库…](https://www.kdnuggets.com/2022/n15.html)'
- en: '[Gaussian Naive Bayes, Explained](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯朴素贝叶斯算法解释](https://www.kdnuggets.com/2023/03/gaussian-naive-bayes-explained.html)'
- en: '[Everything You Need to Know About Tensors](https://www.kdnuggets.com/2022/05/everything-need-know-tensors.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于张量你需要知道的一切](https://www.kdnuggets.com/2022/05/everything-need-know-tensors.html)'
- en: '[Everything You Need to Know About Data Lakehouses](https://www.kdnuggets.com/2022/09/everything-need-know-data-lakehouses.html)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于数据湖屋你需要知道的一切](https://www.kdnuggets.com/2022/09/everything-need-know-data-lakehouses.html)'
- en: '[Everything You Need to Know About MLOps: A KDnuggets Tech Brief](https://www.kdnuggets.com/tech-brief-everything-you-need-to-know-about-mlops)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于 MLOps 的一切：KDnuggets 技术简报](https://www.kdnuggets.com/tech-brief-everything-you-need-to-know-about-mlops)'
- en: '[ChatGPT: Everything You Need to Know](https://www.kdnuggets.com/2023/01/chatgpt-everything-need-know.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT: 你需要知道的一切](https://www.kdnuggets.com/2023/01/chatgpt-everything-need-know.html)'
