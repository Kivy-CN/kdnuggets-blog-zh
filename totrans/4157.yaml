- en: Build a Web Scraper with Python in 5 Minutes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/02/build-web-scraper-python-5-minutes.html](https://www.kdnuggets.com/2022/02/build-web-scraper-python-5-minutes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data scientists are often expected to collect large amounts of data to derive
    business value in organizations. Unfortunately, this is a skill that is often
    overlooked, as most data science courses don’t teach you to collect external data.
    Instead, there is a lot of emphasis placed on model building and training.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will show you how to create a web scraper from scratch.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: If you aren’t already familiar with the term, a web scraper is an automated
    tool that can extract large amounts of data from sites. You can collect up to
    hundreds of thousands of data points in just a few minutes with the help of web
    scraping.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: We will scrape a site called “[Quotes to Scrape](https://quotes.toscrape.com/)”
    in this tutorial. This is a site that was specifically built to practice web scraping.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this article, you will be familiar with:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Extracting raw HTML from a website
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the BeautifulSoup library to parse this HTML and extract useful pieces
    of information from the site
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collecting data from multiple webpages at once
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing this data into a Pandas dataframe
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we start building the scraper, make sure you have the following libraries
    installed — [Pandas](https://pandas.pydata.org/docs/), [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), [requests](https://docs.python-requests.org/en/latest/).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Once that’s done, let’s take a look at the site we want to scrape, and decide
    on the data points to extract from it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/36c24272426adc420668875de0036904.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: This site consists of a list of quotes by prominent figures. There are three
    main bits of information displayed on the page — the quote, it’s author, and a
    few tags associated with it.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The site has ten pages, and we will scrape all the information available on
    it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by importing the following libraries:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, using the *requests *library, we will get the page we want to scrape
    and extract it’s HTML:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we will pass the site’s HTML text to BeautifulSoup, which will parse
    this raw data so it can be easily scraped:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: All of the site’s data is now stored in the soup object. We can easily run BeautifulSoup’s
    in-built functions on this object in order to extract the data we want.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，网站的所有数据都存储在 soup 对象中。我们可以很容易地在这个对象上运行 BeautifulSoup 的内置函数，以提取我们想要的数据。
- en: 'For example, if we wanted to extract all of the text available on the web page,
    we can easily do it with the following lines of code:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想提取网页上所有的文本，可以通过以下代码轻松完成：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You should see all of the site’s text appear on your screen.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能看到网站上的所有文本出现在你的屏幕上。
- en: 'Now, let’s start scraping by scraping the quotes listed on the site. Right
    click on any of the quotes, and select “*Inspect Element*.” The Chrome Developer
    Tools will appear on your screen:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始抓取网站上列出的引用。右键点击任何一个引用，选择 "*检查元素*"。Chrome 开发者工具将会出现在你的屏幕上：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/dbecc5467aba59a027d53cffc15711b0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/dbecc5467aba59a027d53cffc15711b0.png)'
- en: BeautifulSoup has methods like find() and findAll() that you can use to extract
    specific HTML tags from the web page.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: BeautifulSoup 具有像 find() 和 findAll() 这样的函数，你可以用它们从网页中提取特定的 HTML 标签。
- en: In this case, notice that the <span> class called *text *is highlighted. This
    is because you right-clicked on one of the quotes on the page, and all the quotes
    belong to this *text *class.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，请注意名为 *text* 的 `<span>` 类被高亮显示。这是因为你右键点击了页面上的一个引用，所有引用都属于这个 *text* 类。
- en: 'We need to extract all the data in this class:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要提取这个类中的所有数据：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once you run the code above, the following output will be produced:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你运行上述代码，将会生成以下输出：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/b883a12a11853b13a2ce2a158532a465.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/b883a12a11853b13a2ce2a158532a465.png)'
- en: There are ten quotes on the web page, and our scraper has successfully collected
    all of them. Great!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 网页上有十个引用，我们的抓取器已经成功地收集了所有这些引用。太棒了！
- en: Now, we will scrape author names using the same approach.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用相同的方法抓取作者名字。
- en: If you right click on any of the author names on the web page and click Inspect,
    you will see that they are contained within the <small> tag, and the class name
    is *author.*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你右键点击网页上的任何一个作者名字并选择检查，你会看到它们都包含在 `<small>` 标签内，且类名为 *author*。
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/800935a2cbaf6e535af7d66350f45f26.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/800935a2cbaf6e535af7d66350f45f26.png)'
- en: We will use the find() and findAll() functions to extract all the author names
    within this tag.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 find() 和 findAll() 函数来提取这个标签内的所有作者名字。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following output will be rendered:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出将被渲染：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/d1cd7739f696412e760b686fbd3e3351.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/d1cd7739f696412e760b686fbd3e3351.png)'
- en: Again, we managed to scrape all authors listed on the page. We’re almost done!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们成功地抓取了页面上列出的所有作者。我们快完成了！
- en: Finally, we will scrape the tags listed on the site.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将抓取网站上列出的标签。
- en: 'If you right click on any of the tags and click on Inspect Element, you will
    see that they are all contained within the <meta> tag and separated by a comma:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你右键点击任何一个标签并选择检查元素，你会看到它们都包含在 `<meta>` 标签内，并用逗号分隔：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/afc734bb6922cf0859f71bad101fba65.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/afc734bb6922cf0859f71bad101fba65.png)'
- en: Also, notice that the <meta> tag is wrapped by a parent <div> tag, with the
    class name *tags.*
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，请注意 `<meta>` 标签被一个父 `<div>` 标签包裹，且类名为 *tags*。
- en: 'To extract all the tags on the page, run the following lines of code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取页面上的所有标签，请运行以下代码：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output on your screen will look like this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 屏幕上的输出将如下所示：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/cf53e9316d48061b958451244b178027.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/cf53e9316d48061b958451244b178027.png)'
- en: We have now successfully scraped all the data on a single page of the site.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功地抓取了网站单页上的所有数据。
- en: But we’re not done! Remember, the site has ten pages, and we need to collect
    the same data from all of them.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们还没有完成！记住，网站有十页，我们需要从所有页面中收集相同的数据。
- en: Before we do this, let’s create three empty arrays so we can store the data
    collected.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们做这些之前，让我们创建三个空数组，以便存储收集到的数据。
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, we will create a loop that ranges from 1–10, and iterate through every
    page on the site. We will run the exact same lines of code we created earlier.
    The only difference is that instead of printing the output, we will now append
    it to an array.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个范围从 1 到 10 的循环，并遍历网站上的每一页。我们将运行之前创建的完全相同的代码行。唯一的区别是，我们现在将其附加到数组中，而不是打印输出。
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Done!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 完成！
- en: 'Finally, let’s consolidate all the data collected into a Pandas dataframe:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将所有收集到的数据汇总到一个 Pandas 数据框中：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Taking a look at the head of the final data frame, we can see that all the
    site’s scraped data has been arranged into three columns:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 查看最终数据框的开头，我们可以看到所有抓取到的数据都已被整理到三列中：
- en: '![Build a Web Scraper with Python in 5 Minutes](../Images/e2bfa793c4fc716c3e3fe8f06cb232a3.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![用 Python 在 5 分钟内构建网页抓取器](../Images/e2bfa793c4fc716c3e3fe8f06cb232a3.png)'
- en: That’s all for this tutorial!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是本教程的全部内容！
- en: We have successfully scraped a website using Python libraries, and stored the
    extracted data into a dataframe.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功使用 Python 库抓取了一个网站，并将提取的数据存储到数据框中。
- en: This data can be used for further analysis — you can build a clustering model
    to group similar quotes together, or train a model that can automatically generate
    tags based on an input quote.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据可以用于进一步分析——你可以构建一个聚类模型来将相似的引用聚集在一起，或者训练一个模型，根据输入的引用自动生成标签。
- en: If you’d like to practice the skills you learnt above, [here](http://books.toscrape.com/) is
    another relatively easy site to scrape.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想练习上述学到的技能， [这里](http://books.toscrape.com/) 是另一个相对简单的网站可以抓取。
- en: There is more to web scraping than the techniques outlined in this article.
    Real-world sites often have bot protection mechanisms in place that make it difficult
    to collect data from hundreds of pages at once. Using libraries like *requests *and *BeautifulSoup *will
    suffice when you want to pull data from static HTML webpages like the one above.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 网页抓取不仅仅是本文中提到的技术。现实中的网站通常有机器人保护机制，这使得从数百个页面中收集数据变得困难。当你想从像上述那样的静态 HTML 网页中提取数据时，使用
    *requests* 和 *BeautifulSoup* 就足够了。
- en: If you’re pulling data from a site that requires authentication, has verification
    mechanisms like captcha in place, or has JavaScript running in the browser while
    the page loads, you will have to use a browser automation tool like Selenium to
    aid with the scraping.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从需要认证的网站抓取数据，或有验证码等验证机制，或者在页面加载时有 JavaScript 运行，你将需要使用像 Selenium 这样的浏览器自动化工具来帮助抓取。
- en: If you’d like to learn Selenium for web scraping, I suggest starting out with [this](https://www.analyticsvidhya.com/blog/2020/08/web-scraping-selenium-with-python/) beginner-friendly
    tutorial.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想学习用于网页抓取的 Selenium，我建议你从 [this](https://www.analyticsvidhya.com/blog/2020/08/web-scraping-selenium-with-python/) 初学者友好的教程开始。
- en: '**[Natassha Selvaraj](https://www.natasshaselvaraj.com/)** is a self-taught
    data scientist with a passion for writing. You can connect with her on [LinkedIn](https://www.linkedin.com/in/natassha-selvaraj-33430717a/).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Natassha Selvaraj](https://www.natasshaselvaraj.com/)** 是一位自学成才的数据科学家，热衷于写作。你可以在
    [LinkedIn](https://www.linkedin.com/in/natassha-selvaraj-33430717a/) 上与她联系。'
- en: More On This Topic
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Build a Machine Learning Web App in 5 Minutes](https://www.kdnuggets.com/2022/03/build-machine-learning-web-app-5-minutes.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5分钟构建机器学习网页应用](https://www.kdnuggets.com/2022/03/build-machine-learning-web-app-5-minutes.html)'
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 2022年3月9日：用 5 分钟构建机器学习网页应用](https://www.kdnuggets.com/2022/n10.html)'
- en: '[FastAPI Tutorial: Build APIs with Python in Minutes](https://www.kdnuggets.com/fastapi-tutorial-build-apis-with-python-in-minutes)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FastAPI 教程：用 Python 分钟构建 API](https://www.kdnuggets.com/fastapi-tutorial-build-apis-with-python-in-minutes)'
- en: '[Build a Text-to-Speech Converter with Python in 5 Minutes](https://www.kdnuggets.com/2022/09/build-texttospeech-converter-python-5-minutes.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 在 5 分钟内构建文本到语音转换器](https://www.kdnuggets.com/2022/09/build-texttospeech-converter-python-5-minutes.html)'
- en: '[Build AI Chatbot in 5 Minutes with Hugging Face and Gradio](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Hugging Face 和 Gradio 在 5 分钟内构建 AI 聊天机器人](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
- en: '[Understanding Bias-Variance Trade-Off in 3 Minutes](https://www.kdnuggets.com/2020/09/understanding-bias-variance-trade-off-3-minutes.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 3 分钟内理解偏差-方差权衡](https://www.kdnuggets.com/2020/09/understanding-bias-variance-trade-off-3-minutes.html)'
