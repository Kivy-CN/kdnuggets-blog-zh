- en: Open Source Datasets for Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉的开源数据集
- en: 原文：[https://www.kdnuggets.com/2021/08/open-source-datasets-computer-vision.html](https://www.kdnuggets.com/2021/08/open-source-datasets-computer-vision.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/08/open-source-datasets-computer-vision.html](https://www.kdnuggets.com/2021/08/open-source-datasets-computer-vision.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '![](../Images/6f6289ab340e88bbc09e70945ec7cd3a.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f6289ab340e88bbc09e70945ec7cd3a.png)'
- en: '[Computer Vision](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-gpu-for-computer-vision) (CV)
    is one of the most exciting subfields within the Artificial Intelligence (AI)
    and Machine Learning (ML) domain. It is a major component for many modern AI/ML
    pipelines, and it''s transforming almost every industry, enabling organizations
    to revolutionize the way machines and business systems work.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[计算机视觉](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-gpu-for-computer-vision)（CV）是人工智能（AI）和机器学习（ML）领域中最令人兴奋的子领域之一。它是许多现代AI/ML管道中的重要组成部分，并且正在改变几乎所有行业，使组织能够彻底革新机器和业务系统的工作方式。'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT领域'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Academically, CV has been a well-established area of computer science for many
    decades, and over the years, a lot of research has gone into this field to make
    it better. However, the **use of deep neural networks has recently revolutionized
    the field** and given it new fuel for accelerated growth.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术上，计算机视觉已经是计算机科学中的一个成熟领域，多年来，这一领域经过了大量的研究以不断完善。然而，**深度神经网络的使用最近彻底革新了这一领域**，并为其加速增长注入了新的动力。
- en: 'There is a diverse array of application areas for computer vision, such as:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉有着多种应用领域，例如：
- en: Autonomous driving
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动驾驶
- en: Medical imaging analysis and diagnostics
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医学影像分析与诊断
- en: Scene detection and understanding
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 场景检测与理解
- en: Automatic image caption generation
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动图像标题生成
- en: Photo/face tagging on social media
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体上的照片/面孔标记
- en: Home security
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 家庭安全
- en: Defect identification in manufacturing industries and quality control
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制造业缺陷识别与质量控制
- en: In this article, we discuss some of the most popular and effective datasets
    used in the domain of Deep Learning (DL) to train state-of-the-art ML systems
    for CV tasks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了一些在深度学习（DL）领域中用于训练最先进的机器学习系统的流行且有效的数据集。
- en: Choose the Right Open-source Datasets Carefully
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仔细选择合适的开源数据集
- en: Training machines on image and video files is a **serious data-intensive operation**.
    A singular image file is a multi-dimensional, multi-megabytes digital entity containing
    only a tiny fraction of ‘insight’ in the context of the whole ‘intelligent image
    analysis’ task.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像和视频文件上训练机器是一项**数据密集型操作**。单一图像文件是一个多维的、多兆字节的数字实体，仅包含整个“智能图像分析”任务中的微小“洞察”部分。
- en: In contrast, a similar-sized retail sales data table can lend much more insight
    into the ML algorithm with the same expenditure on computational hardware. This
    fact is worth remembering while talking about the scale of data and computing
    required for modern CV pipelines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，一个相似规模的零售销售数据表可以在相同的计算硬件开支下为机器学习算法提供更多的洞见。在讨论现代计算机视觉管道所需的数据规模和计算时，值得记住这一点。
- en: Consequently, in almost all cases, hundreds (or even thousands) of images are
    not enough to train a high-quality ML model for CV tasks. Almost all modern CV
    systems use complex DL model architectures, and they will remain under-fitted
    if not supplied with a sufficient number of carefully selected training examples,
    i.e., labeled images. Therefore, it is becoming a highly common trend that **robust,
    generalizable, production-quality DL systems often require millions of carefully
    chosen images to train on**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在几乎所有情况下，几百张（甚至几千张）图像不足以训练高质量的机器学习模型用于计算机视觉任务。几乎所有现代计算机视觉系统使用复杂的深度学习模型架构，如果没有提供足够数量的精心选择的训练样本，即标记图像，它们将会表现不足。因此，成为一种高度常见的趋势是**稳健、具有泛化能力的生产级深度学习系统通常需要数百万张精心挑选的图像进行训练**。
- en: Also, for video analytics, the task of choosing and compiling a training dataset
    can be more complicated given the dynamic nature of the video files or frames
    obtained from a multitude of video streams.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于视频分析，选择和编制训练数据集的任务可能更加复杂，因为视频文件或从多个视频流中获得的帧具有动态特性。
- en: Here, we list some of the most popular ones (consisting of both static images
    and video clips).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们列出了一些最受欢迎的数据集（包括静态图像和视频剪辑）。
- en: Popular Open-source Datasets for Computer Vision Models
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机视觉模型的流行开源数据集
- en: 'Not all datasets are equally suitable for all kinds of CV tasks. Common CV
    tasks include:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有数据集都适用于所有类型的计算机视觉任务。常见的计算机视觉任务包括：
- en: Image classification
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类
- en: Object detection
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象检测
- en: Object segmentation
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象分割
- en: Multi-object annotation
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多对象注释
- en: Image captioning
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像描述
- en: Human pose estimation
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人体姿态估计
- en: Video frame analytics
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频帧分析
- en: We show a list of popular, open-source datasets that cover most of these categories.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了一些涵盖大部分这些类别的流行开源数据集。
- en: ImageNet (most well-known)
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ImageNet（最著名）
- en: '[ImageNet](http://www.image-net.org/) is an ongoing research effort to provide
    researchers around the world with an easily accessible image database. It is,
    perhaps, the **most well-known image dataset** out there and is quoted as the
    gold standard by researchers and learners alike.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImageNet](http://www.image-net.org/) 是一个持续的研究努力，旨在为全球研究人员提供一个易于访问的图像数据库。它或许是**最著名的图像数据集**，被研究人员和学习者一致称为金标准。'
- en: This project was inspired by an ever-growing sentiment in the image and vision
    research field–the need for more data. It is organized according to the WordNet
    hierarchy. Each meaningful concept in WordNet, possibly described by multiple
    words or word phrases, is called a "synonym set" or "synset." There are more than
    100,000 synsets in WordNet. Similarly, ImageNet aims to provide on average 1000
    images to illustrate each synset.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目的灵感来源于图像和视觉研究领域日益增长的需求——更多的数据。它按照 WordNet 层次结构进行组织。WordNet 中每个有意义的概念，可能由多个词或词组描述，称为“同义词集”或“synset”。WordNet
    中有超过 100,000 个同义词集。类似地，ImageNet 旨在提供平均 1000 张图像来说明每个同义词集。
- en: The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is a global annual
    competition that evaluates algorithms (submitted by teams from university or corporate
    research groups) for object detection and image classification at a large scale.
    One high-level motivation is to allow researchers to compare progress in detection
    across a wider variety of objects -- taking advantage of the quite expensive labeling
    effort. Another motivation is to measure the progress of computer vision for large-scale
    image indexing for retrieval and annotation.** This is one of the most talked-about
    annual competitions in the entire field of machine learning.**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 大规模视觉识别挑战赛（ILSVRC）是一个全球年度比赛，评估算法（由大学或企业研究团队提交）在大规模对象检测和图像分类方面的表现。一个主要动机是允许研究人员在更广泛的对象上比较检测进展——利用相当昂贵的标注工作。另一个动机是衡量计算机视觉在大规模图像索引、检索和注释方面的进展。**这是整个机器学习领域讨论最多的年度比赛之一。**
- en: '![](../Images/4cd19bf0a67465abdb87b749a542ee1c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cd19bf0a67465abdb87b749a542ee1c.png)'
- en: CIFAR-10 (for beginners)
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CIFAR-10（适合初学者）
- en: This is a [collection of images](https://www.cs.toronto.edu/~kriz/cifar.html) that
    are commonly used to train machine learning and computer vision algorithms by
    beginners in the field. It is also one of the most popular datasets for machine
    learning research for** quick comparison of algorithms** as it captures the weakness
    and strength of a particular architecture without placing an unreasonable computational
    burden on the training and hyperparameter tuning process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个[图像集合](https://www.cs.toronto.edu/~kriz/cifar.html)，常用于初学者训练机器学习和计算机视觉算法。它也是机器学习研究中最受欢迎的数据集之一，用于**快速比较算法**，因为它捕捉了特定架构的优缺点，而不会对训练和超参数调整过程施加不合理的计算负担。
- en: It contains 60,000, 32×32 colour images in 10 different classes. The classes
    represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and
    trucks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 它包含60,000张32×32的彩色图像，分为10个不同的类别。这些类别包括飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车。
- en: '![](../Images/c8dc50a44fc7934c601f797f50fa7d58.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8dc50a44fc7934c601f797f50fa7d58.png)'
- en: MegaFace and LFW (Face recognition)
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MegaFace 和 LFW（面部识别）
- en: '[Labeled Faces in the Wild (LFW)](http://vis-www.cs.umass.edu/lfw/) is a database
    of face photographs designed for **studying the problem of unconstrained face
    recognition**. It contains 13,233 images of 5,749 people, scraped and detected
    from the web. As an additional challenge, ML researchers can use pictures for
    1,680 people who have two or more distinct photos in the dataset. Consequently,
    it is a public benchmark for face verification, also known as pair matching (requiring
    at least two images of the same person).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[Labeled Faces in the Wild (LFW)](http://vis-www.cs.umass.edu/lfw/) 是一个旨在**研究非约束性面部识别问题**的面部照片数据库。它包含13,233张5,749个人的图像，这些图像从网络上抓取和检测而来。作为额外的挑战，机器学习研究人员可以使用数据集中有两张或更多张不同照片的1,680个人的图片。因此，它是一个公共的面部验证基准，也称为配对匹配（需要至少两张同一人的图像）。'
- en: '[MegaFace](http://megaface.cs.washington.edu/dataset/download.html) is a large-scale
    open-source face recognition training dataset that serves as one of the most important
    benchmarks for **commercial face recognition problems**. It includes 4,753,320
    faces of 672,057 identities and is highly suitable for large DL architecture training.
    All images are obtained from Flickr (Yahoo''s dataset) and licensed under Creative
    Commons.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[MegaFace](http://megaface.cs.washington.edu/dataset/download.html) 是一个大规模开源面部识别训练数据集，是**商业面部识别问题**的最重要基准之一。它包含4,753,320张面孔，涉及672,057个身份，非常适合大型深度学习架构的训练。所有图像均来自Flickr（雅虎的数据集），并且获得了创作共用许可证。'
- en: '![](../Images/fbef775032d3e602c5dc949706db7ebf.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbeb775032d3e602c5dc949706db7ebf.png)'
- en: IMDB-Wiki (gender and age identification)
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IMDB-Wiki（性别和年龄识别）
- en: IMDB-Wiki is one of the [largest and open-sourced datasets](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/) of
    face images with gender and age labels for training. In total, there are 523,051
    face images in this dataset, where 460,723 face images are obtained from 20,284
    celebrities from IMDB and 62,328 from Wikipedia.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: IMDB-Wiki是一个具有性别和年龄标签的[最大且开源的数据集](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)，用于训练面部图像。该数据集中共有523,051张面孔图像，其中460,723张来自20,284位IMDB名人，62,328张来自维基百科。
- en: '![](../Images/c9b32d79b227c1d200a31640654ff2f3.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9b32d79b227c1d200a31640654ff2f3.png)'
- en: MS Coco (object detection and segmentation)
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MS Coco（物体检测与分割）
- en: COCO or [Common Objects in COntext](https://cocodataset.org/#home) is large-scale
    object detection, segmentation, and captioning dataset. The dataset contains photos
    of 91 object types which is easily recognizable and has a total of 2.5 million
    labeled instances in 328k images. Furthermore, it **provides resources for more
    complex CV tasks such as multi-object labeling, segmentation mask annotations,
    image captioning, and key-point detection**. It is well-supported by an intuitive
    API that assists in loading, parsing, and visualizing annotations in COCO. The
    API supports multiple annotation formats.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 或 [Common Objects in COntext](https://cocodataset.org/#home) 是一个大规模的物体检测、分割和图像说明数据集。该数据集包含91种易于识别的物体类型，共有2.5百万个标注实例，分布在328,000张图像中。此外，它**提供了更多复杂的计算机视觉任务资源，如多物体标注、分割掩码注释、图像说明和关键点检测**。它由一个直观的API提供支持，帮助加载、解析和可视化COCO中的注释。该API支持多种注释格式。
- en: '![](../Images/9f68f3752e10c14629ba36fff382a5d0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f68f3752e10c14629ba36fff382a5d0.png)'
- en: MPII Human Pose (pose estimation)
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MPII Human Pose（姿态估计）
- en: '[This dataset](http://human-pose.mpi-inf.mpg.de/) is used for the evaluation
    of articulated human pose estimation. It includes around 25K images containing
    over 40K people with **annotated body joints**. Here, each image is extracted
    from a YouTube video and provided with preceding and following un-annotated frames.
    Overall the dataset covers 410 human activities, and each image is provided with
    an activity label.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[此数据集](http://human-pose.mpi-inf.mpg.de/)用于评估关节人体姿态估计。它包括约25K张图像，包含40K多人，具有**标注的身体关节**。每张图像都从YouTube视频中提取，并提供了前后未标注的帧。总体而言，数据集涵盖了410种人类活动，每张图像都附有活动标签。'
- en: '![](../Images/112c85264559966a7ff103486a0057ba.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/112c85264559966a7ff103486a0057ba.png)'
- en: Flickr-30k (image captioning)
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flickr-30k（图像字幕）
- en: It is an image caption corpus consisting of 158,915 crowd-sourced captions describing
    31,783 images. This is an extension of the previous [Flickr 8k Dataset](http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html).
    The new images and captions focus on people involved in everyday activities and
    events.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个图像字幕语料库，由158,915条众包字幕描述31,783张图像组成。这是对先前[Flickr 8k 数据集](http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html)的扩展。新图像和字幕专注于涉及日常活动和事件的人们。
- en: '![](../Images/dce929e202c4f491ea0eda1fe19de963.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dce929e202c4f491ea0eda1fe19de963.png)'
- en: 20BN-SOMETHING-SOMETHING (video clips of human action)
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20BN-SOMETHING-SOMETHING（人类动作视频剪辑）
- en: This dataset is a [large collection of densely labeled video clips](https://20bn.com/datasets/something-something/v2) that
    show **humans performing pre-defined basic actions with everyday objects**. It
    was created by a large number of crowd workers, which allows ML models to develop
    a fine-grained understanding of basic actions that occur in the physical world.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集是一个[大量密集标注的视频剪辑集合](https://20bn.com/datasets/something-something/v2)，展示了**人类使用日常物品执行预定义的基本动作**。它由大量众包工人创建，使机器学习模型能够对物理世界中发生的基本动作进行细致入微的理解。
- en: 'Here is a subset of common human activities that are captured in this dataset:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是数据集中捕获的一些常见人类活动的子集：
- en: '![](../Images/81beaa8254e491318d48cd1b83cb8eb1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81beaa8254e491318d48cd1b83cb8eb1.png)'
- en: Barkley DeepDrive (for autonomous vehicle training)
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Barkley DeepDrive（用于自动驾驶车辆训练）
- en: The [Berkeley DeepDrive dataset](https://www.bdd100k.com/) by UC Berkeley comprises
    over 100K video sequences with diverse kinds of annotations, including object
    bounding boxes, drivable areas, image-level tagging, lane markings, and full-frame
    instance segmentation. Furthermore, the dataset features **wide diversity in representing
    various geographic, environmental, and weather conditions**.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[伯克利深度驾驶数据集](https://www.bdd100k.com/)由加州大学伯克利分校提供，包括超过100K个视频序列，具有多种注释类型，包括目标边界框、可驱动区域、图像级标记、车道标记和全帧实例分割。此外，该数据集在表现各种地理、环境和天气条件方面**具有广泛的多样性**。'
- en: This is highly useful for training robust models for autonomous vehicles so
    that they are less likely to be surprised by ever-changing road and driving conditions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这对训练强健的自动驾驶模型非常有用，使其不容易被不断变化的道路和驾驶条件所惊讶。
- en: '![](../Images/6c9e3d17b942c08f5f6595f1b5ce0027.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c9e3d17b942c08f5f6595f1b5ce0027.png)'
- en: The Right Hardware & Benchmarking for These Datasets
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这些数据集的正确硬件和基准测试
- en: Needless to say, having only these datasets is not enough to build a high-quality
    ML system or business solution. A mix of the right choice of dataset, training
    hardware, and clever tuning and benchmarking strategy is required to obtain the
    optimal solution for any academic or business problem.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不用说，仅有这些数据集不足以建立高质量的机器学习系统或商业解决方案。需要正确选择数据集、训练硬件以及巧妙的调整和基准测试策略的混合，以获得任何学术或商业问题的最佳解决方案。
- en: That’s why [high-performance GPUs](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-gpu-for-computer-vision) are
    almost always paired with these datasets to deliver the desired performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么[高性能GPU](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-gpu-for-computer-vision)几乎总是与这些数据集配对使用，以提供所需的性能。
- en: GPUs were developed (primarily catering to the video gaming industry) to handle
    a **massive degree of parallel computations** using thousands of tiny computing
    cores. They also feature **large memory bandwidth** to deal with the rapid dataflow
    (processing unit to cache to the slower main memory and back) needed for these
    computations when the neural network is training through hundreds of epochs. This
    makes them the **ideal commodity hardware** to deal with the computation load
    of computer vision tasks.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: GPU的开发（主要针对视频游戏行业）是为了处理**大规模的并行计算**，使用数千个微小的计算核心。它们还具有**大容量内存带宽**，以应对神经网络训练过程中需要的快速数据流（处理单元到缓存，再到较慢的主内存及回传）。这使得它们成为处理计算机视觉任务计算负载的**理想商品硬件**。
- en: However, there are many choices for GPUs on the market, and that can certainly
    overwhelm the average user. There are some good benchmarking strategies that have
    been published over the years to guide a prospective buyer in this regard. A good
    benchmarking exercise must consider multiple varieties of (a) deep neural network
    (DNN) architecture, (b) GPU, and (c) widely used datasets (like the ones we discussed
    in the previous section).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，市场上有许多GPU选项，这确实可能让普通用户感到困惑。多年来发布了一些好的基准测试策略，以指导潜在买家。在基准测试中，必须考虑多种（a）深度神经网络（DNN）架构，（b）GPU，以及（c）广泛使用的数据集（如我们在前一部分讨论的）。
- en: 'For example, this [excellent article](https://l7.curtisnorthcutt.com/benchmarking-gpus-for-deep-learning)
    considers the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这篇[优秀的文章](https://l7.curtisnorthcutt.com/benchmarking-gpus-for-deep-learning)考虑了以下内容：
- en: Architecture: [ResNet-152, ResNet-101, ResNet-50, and ResNet-18](https://pytorch.org/hub/pytorch_vision_resnet/)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构：[ResNet-152, ResNet-101, ResNet-50, 和 ResNet-18](https://pytorch.org/hub/pytorch_vision_resnet/)
- en: GPUs: [EVGA (non-blower) RTX 2080 ti](https://www.sabrepc.com/11G-P4-2280-KR-EVGA-S2403611), [GIGABYTE
    (blower) RTX 2080 ti](https://www.sabrepc.com/GV-N208TTURBO-11GC-GIGABYTE-S2405508),
    and [NVIDIA TITAN RTX](https://www.sabrepc.com/900-1G150-2500-000-NVIDIA-S116201296)
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU：[EVGA（非风扇）RTX 2080 ti](https://www.sabrepc.com/11G-P4-2280-KR-EVGA-S2403611)、[GIGABYTE（风扇）RTX
    2080 ti](https://www.sabrepc.com/GV-N208TTURBO-11GC-GIGABYTE-S2405508)和[NVIDIA
    TITAN RTX](https://www.sabrepc.com/900-1G150-2500-000-NVIDIA-S116201296)
- en: Datasets: [ImageNet](http://www.image-net.org/), [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html),
    and [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集：[ImageNet](http://www.image-net.org/)、[CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)和[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)。
- en: Also, multiple dimensions of performance must be considered for a good benchmark.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，良好的基准测试必须考虑多个性能维度。
- en: Performance Dimensions to Consider
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 性能维度考虑
- en: 'There are three primary indices:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有三个指标：
- en: '**SECOND-BATCH-TIME**: Time to finish the second training batch. This number
    measures the performance before the GPU has run long enough to heat up. Effectively,
    no [thermal throttling](https://en.wikipedia.org/wiki/Dynamic_frequency_scaling).'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第二批次时间**：完成第二批训练的时间。这个数字衡量的是在GPU尚未长时间运行至升温前的性能。有效地说，没有[热降频](https://en.wikipedia.org/wiki/Dynamic_frequency_scaling)。'
- en: '**AVERAGE-BATCH-TIME**: Average batch time after 1 epoch in ImageNet or 15
    epochs in CIFAR. This measure takes into account [thermal throttling](https://en.wikipedia.org/wiki/Thermal_design_power).'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**平均批次时间**：在ImageNet中1个epoch或在CIFAR中15个epoch后，平均批次时间。这个测量考虑了[热降频](https://en.wikipedia.org/wiki/Thermal_design_power)。'
- en: '**SIMULTANEOUS-AVERAGE-BATCH-TIME**: Average batch time after 1 epoch in ImageNet
    or 15 epochs in CIFAR with all GPUs running simultaneously. This measures the
    effect of thermal throttling in the system due to the combined heat given off
    by all GPUs.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同时平均批次时间**：在ImageNet中1个epoch或在CIFAR中15个epoch后，所有GPU同时运行的平均批次时间。这衡量了由于所有GPU散发的综合热量对系统的热降频影响。'
- en: '[Original](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-open-source-datasets-for-computer-vision).
    Reposted with permission.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://www.sabrepc.com/blog/Deep-Learning-and-AI/best-open-source-datasets-for-computer-vision)。经允许转载。'
- en: '**Related:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Top 10 Computer Vision Papers 2020](https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2020年计算机视觉前10论文](https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html)'
- en: '[Awesome list of datasets in 100+ categories](https://www.kdnuggets.com/2021/05/awesome-list-datasets.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100+类别的数据集精彩列表](https://www.kdnuggets.com/2021/05/awesome-list-datasets.html)'
- en: '[Introducing The NLP Index](https://www.kdnuggets.com/2021/04/nlp-index.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍NLP索引](https://www.kdnuggets.com/2021/04/nlp-index.html)'
- en: More On This Topic
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标以…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，探讨](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让Python成为初创企业的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
