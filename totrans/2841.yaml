- en: 5 Ways to Apply Ethics to AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5种将伦理应用于人工智能的方法
- en: 原文：[https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html](https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html](https://www.kdnuggets.com/2019/12/5-ways-apply-ethics-ai.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Marek Rogala](https://twitter.com/marekrog), CTO at Appsilon**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Marek Rogala](https://twitter.com/marekrog)，Appsilon首席技术官**'
- en: '*In a [previous post](https://appsilon.com/dusting-under-the-bed-machine-learners-responsibility-for-the-future-of-our-society/),
    I expressed my happiness that I got to present at *[*ML in PL*](https://conference.mlinpl.org/)* in
    Warsaw. I had the opportunity to take a step back and reflect a bit on the ethics
    of what we do as practitioners of data science and builders of machine learning
    models. It’s an important topic and doesn’t receive the attention that it should.  *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*在 [上一篇文章](https://appsilon.com/dusting-under-the-bed-machine-learners-responsibility-for-the-future-of-our-society/)
    中，我表达了我有机会在 *[*ML in PL*](https://conference.mlinpl.org/)* 会议上发表演讲的快乐。我有机会退后一步，反思一下我们作为数据科学从业者和机器学习模型构建者所做工作的伦理。这是一个重要的话题，却没有得到应有的关注。*'
- en: '*The algorithms we build affect lives. *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们构建的算法会影响生活。*'
- en: '*I have researched this topic quite a lot, and during that time I have found
    a number of stories that made a huge impression on me. Here are six more lessons
    based on real life examples that I think we should all remember as people working
    in machine learning, whether you’re a researcher, engineer, or a decision-maker. *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我对这个话题进行了大量研究，在此过程中，我发现了一些对我印象深刻的故事。这里有六个基于真实生活的教训，我认为作为从事机器学习的人员，无论你是研究员、工程师还是决策者，我们都应该记住。*'
- en: It’s time to show your Cards
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 该是展示你卡片的时候了
- en: '![](../Images/68b436bd5645c3e0ec7d568a1326d583.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68b436bd5645c3e0ec7d568a1326d583.png)'
- en: It’s time for a more positive example, a practice we can follow in our daily
    work. OpenAI has finally released the full [GPT-2 model](https://openai.com/blog/better-language-models/) for
    text generation. OpenAI noticed that the model is so powerful that it could be
    used in very bad ways (from testing it personally, I can confirm that it is often
    super realistic). So in February they released a limited version, and started
    a process. They invited researchers to experiment with the model, they asked people
    to build detection systems to see the accuracy of the method to detect if something
    was created by a bot or not. They are also hiring social scientists, because as
    engineers we should know our limits and we don’t have to understand all implications
    of models we release. But we can collaborate with those who do.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候举一个更积极的例子了，这是我们在日常工作中可以遵循的做法。OpenAI最终发布了完整的 [GPT-2模型](https://openai.com/blog/better-language-models/)
    用于文本生成。OpenAI注意到该模型功能强大，可能会被用于非常不良的方式（从个人测试来看，我可以确认它通常非常逼真）。因此，他们在2月份发布了一个限制版本，并启动了一个过程。他们邀请研究人员对模型进行实验，要求人们构建检测系统，以查看检测某些内容是否由机器人生成的方法的准确性。他们还聘请了社会科学家，因为作为工程师我们应该知道自己的局限性，无法理解我们发布的模型的所有影响。但我们可以与那些理解这些的人合作。
- en: One of the tools that they used is something that we can all use in our daily
    work — **Model Cards**. This was [suggested by several people at Google](https://ai.google/research/pubs/pub48120/).
    A Model Card shows in a standardized way the intended use and the mis-use cases.
    It shows how the data was collected, so that researchers can experiment and notice
    some mistakes in the process. The Card can contain caveats and recommendations.
    Whether you’re releasing to the public or just internally, I think it’s useful
    to complete an “M-card.” I think OpenAI did this right. So that brings us to Lesson
    6.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 他们使用的工具之一是我们在日常工作中都可以使用的——**模型卡片**。这是 [谷歌的几位员工建议的](https://ai.google/research/pubs/pub48120/)。模型卡片以标准化的方式展示了预期用途和误用情况。它显示了数据是如何收集的，以便研究人员可以进行实验并发现过程中的一些错误。卡片还可以包含警告和建议。无论你是向公众发布还是仅限内部使用，我认为完成一张“M-card”是很有用的。我认为OpenAI做得很好。这就引出了第6课。
- en: '**Lesson 6: Evaluate risks. Communicate intended usage.**'
  id: totrans-11
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第6课：评估风险。沟通预期用途。**'
- en: Onward. I saw this on Twitter last week. Some researchers are showing off a
    model that will use faces to pay for entrance to the London Underground.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 前进。我上周在推特上看到了这个消息。一些研究人员展示了一种模型，这种模型将使用面部识别来支付伦敦地铁的入口费用。
- en: Facial recognition could make your commute MUCH easier [pic.twitter.com/B3SISYq0Zb](https://t.co/B3SISYq0Zb)
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 面部识别可以让你的通勤变得轻松很多 [pic.twitter.com/B3SISYq0Zb](https://t.co/B3SISYq0Zb)
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Mashable (@mashable) [November 9, 2019](https://twitter.com/mashable/status/1193088083492630528?ref_src=twsrc%5Etfw)
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: — Mashable (@mashable) [2019年11月9日](https://twitter.com/mashable/status/1193088083492630528?ref_src=twsrc%5Etfw)
- en: 'I was shocked that they didn’t mention any risks whatsoever, such as, for example,
    the potential for law enforcement abuse, privacy issues, surveillance, migrant
    rights, biases, and abuse by authoritarian states. There are huge implications.
    So, Lesson 7: it’s easy to get press for a cool model, but we shouldn’t be like
    those researchers from Bristol. We should make sure that if a video is featured
    like this, the risks are called out.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '-   我震惊于他们根本没有提到任何风险，例如执法滥用、隐私问题、监控、移民权利、偏见以及威权国家的滥用。影响巨大。所以，第7课：获得媒体关注对一个酷炫的模型很容易，但我们不应该像布里斯托尔的那些研究人员那样。如果一个视频以这种方式被展示，我们应该确保风险被指出。'
- en: '**Lesson 7: It’s easy to get media coverage. Make sure risks are communicated. **'
  id: totrans-17
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第7课：媒体报道很容易获得。确保风险被传达。**'
- en: '![](../Images/a4335775911823e04d9df26e65e79f4a.png)Here’s another positive
    example that I’d like to show you — it’s a [talk by Evan Estola](https://www.youtube.com/watch?v=MqoRzNhrTnQ) who
    is the lead machine learning engineer at [Meetup](https://www.meetup.com/). He
    gave a useful talk called “When Recommendation Systems Go Bad” about some of the
    decisions that they have made.  He reminds us of Goodhart’s law:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/a4335775911823e04d9df26e65e79f4a.png)这是我想给你展示的另一个正面例子——这是[Evan
    Estola的讲座](https://www.youtube.com/watch?v=MqoRzNhrTnQ)，他是[Meetup](https://www.meetup.com/)的首席机器学习工程师。他做了一个有用的讲座，名为“当推荐系统变坏时”，讨论了他们做出的一些决策。他提醒我们Goodhart定律：'
- en: “When a measure becomes a target, it ceases to be a good measure.”
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “当一个衡量标准变成目标时，它就不再是一个好的衡量标准。”
- en: “We have an ethical obligation not to teach our machines to be prejudiced,”
    he adds. For example, in the US, there are more men than women in tech roles.
    So should the Meetup recommendation model discourage women from attending tech
    meetups because they are mostly attended by men? Of course not. But if it is not
    intentionally designed otherwise, a model can easily infer from the data that
    women aren’t interested in tech events and then turn around and essentially maintain
    gender stereotypes. So Lesson 8…
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: “我们有道德义务不要教会我们的机器有偏见，”他补充道。例如，在美国，科技岗位中男性多于女性。那么Meetup推荐模型是否应该因为技术聚会主要由男性参加而劝阻女性参加？当然不应该。但是如果模型没有特别设计，模型可能会从数据中轻易推断出女性对技术活动不感兴趣，然后反过来维持性别刻板印象。所以第8课……
- en: '**Lesson 8: Remember that a metric is always a proxy for what we care about.**'
  id: totrans-21
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第8课：记住，一个指标始终是我们关心的事物的代理。**'
- en: And what about the issue of government regulation? The following is the most
    shocking example to me. Maybe some of you are aware that there was a genocide
    in Myanmar last year. Thousands of the Rohingya people died at the hands of the
    military, police, and other members from the majority group. Facebook finally
    admitted this year that they didn’t do enough — the platform became a way for
    people to spread violence and violent content. So basically people from the majority
    group spread hate about the ethnic minority Rohingya. They practice different
    religions so that only helped increase the violence.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么政府监管的问题呢？以下是对我来说最震惊的例子。也许你们中的一些人知道去年在缅甸发生了种族灭绝。数千名罗兴亚人在军队、警察和其他多数族群成员的手中丧生。Facebook今年终于承认，他们没有做足够的工作——这个平台成为了人们传播暴力和暴力内容的途径。所以，基本上多数族群的人传播了对少数族群罗兴亚人的仇恨。他们信仰不同的宗教，这只会加剧暴力。
- en: '![](../Images/3dc9bea082dc25213b68d96faf12025b.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dc9bea082dc25213b68d96faf12025b.png)'
- en: One of the worst things about the situation was that Facebook executives were
    warned as early as 2013\. After five years, there was a huge outburst of violence.
    In 2015, after the first warning, Facebook had only four Burmese-speaking contractors
    reviewing the content — for sure not enough. They just didn’t care enough.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 情况最糟糕的部分是，Facebook高管早在2013年就已被警告。五年后，暴力爆发。在2015年，第一次警告后，Facebook只有四名讲缅甸语的承包商审查内容——显然不够。他们只是没有足够重视。
- en: '[Rachel Thomas](https://www.youtube.com/watch?v=WC1kPtG8Iz8) compared two reactions
    from Facebook. One is for Myanmar, where Facebook boasted that they added “dozens”
    of content reviewers for Burmese. During the same year, they hired 1,500 content
    reviewers in Germany. Why is that? Because Germany threatened Facebook (and others)
    with a $50M fine if they didn’t comply with the Hate Speech law. This is an example
    of how regulations can help, because it makes managers who are mostly focused
    on profit to treat risks seriously.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[瑞秋·托马斯](https://www.youtube.com/watch?v=WC1kPtG8Iz8) 比较了 Facebook 在两个国家的反应。一个是针对缅甸，Facebook
    宣称他们为缅甸语添加了“数十个”内容审查员。在同一年，他们在德国雇用了 1,500 名内容审查员。为什么会这样？因为德国威胁 Facebook（及其他公司）如果不遵守仇恨言论法，将处以
    5000 万美元的罚款。这是一个法规如何发挥作用的例子，因为它使那些主要关注利润的管理者认真对待风险。'
- en: Here is a personal example about regulation. I have two small children, so I
    have become an expert about car seats. In the past, it was claimed by many that
    cars can’t be regulated. Drivers were blamed for safety issues. Fast forward a
    bit, and it is calculated that children are five times safer in rear-facing car
    seats as opposed to front-facing. Regulations differ in various countries. In
    Sweden, they have regulations that essentially favor the use of rear-facing car
    seats. Consequently, from 1992 to 2013, only 15 children have died in auto accidents.
    By contrast, in Poland, which does not have such a regulation, 70 to 150 children
    die **each year** in auto accidents.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关于法规的个人例子。我有两个小孩，所以我对儿童座椅变得非常熟悉。过去，很多人声称汽车不能受到监管。安全问题被归咎于驾驶员。稍微快进一下，现在的计算结果是，相比于面向前方的座椅，儿童在面向后方的座椅中安全性提高了五倍。各国的法规不同。在瑞典，他们的法规基本上支持使用面向后方的座椅。因此，从
    1992 年到 2013 年，仅有 15 名儿童在交通事故中死亡。相比之下，在没有这样的法规的波兰，每年有 70 到 150 名儿童在交通事故中死亡**。
- en: Regulation will come to AI eventually. The question is whether it will be wise
    or stupid. Technical people are often opposed to regulation because it’s often
    poorly designed and enacted. But I think it’s because we need to make it wise.
    We will eventually have regulation around AI, but it’s not determined what quality
    it’ll be and when this will happen.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 监管最终会到来 AI。问题是它是否会明智还是愚蠢。技术人员通常反对监管，因为监管往往设计和实施不佳。但我认为这是因为我们需要使其明智。我们最终会有关于
    AI 的监管，但尚不确定其质量和何时发生。
- en: '**Lesson 9: Regulation is our ally, not our enemy. Advocate for wise regulation.**'
  id: totrans-28
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第 9 课：法规是我们的盟友，而不是敌人。倡导明智的法规。**'
- en: Final example. At [Appsilon](https://appsilon.com/) we devote quite a bit of
    our time to “AI for Good” initiatives. So we work with NGOs to put AI models to
    work to study climate change, to help protect wildlife and so on, and this is
    great, I’m happy to see other companies doing that. But we should be aware of
    a phenomenon called **technologism**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的例子。在 [Appsilon](https://appsilon.com/) 我们投入了相当多的时间进行“AI for Good”倡议。因此，我们与非政府组织合作，利用
    AI 模型研究气候变化、保护野生动物等，这非常好，我很高兴看到其他公司也在这样做。但我们应该意识到一种叫做**技术主义**的现象。
- en: There’s a book by Kentaro Toyama, it’s titled “[Geek Heresy](https://geekheresy.org/).”
    Mr. Toyama is a Microsoft engineer who was sent to India to help social change
    and improve people’s lives through technology. He found that people are making
    lots of mistakes by applying the Western perspective to try to fix everything
    through technology. He shows many examples of how high hopes for fixing problems
    with technology have failed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有一本书，作者是 Kentaro Toyama，书名为 “[极客异端](https://geekheresy.org/)”。Toyama 先生是微软的工程师，他被派往印度通过技术帮助社会变革和改善人们的生活。他发现，人们在尝试用技术解决问题时，往往把西方视角应用于一切，结果犯了很多错误。他展示了许多通过技术解决问题的高期望是如何失败的例子。
- en: We should work with domain experts a lot and solve the simple problems **first** with
    the right depth, so that we build a common understanding between domain experts
    and engineers. Engineers need to learn the roots of the problems and the domain
    experts need to learn what is possible with the technology. Only then can really
    useful ideas emerge.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该与领域专家密切合作，首先解决简单问题**，以合适的深度**，以便在领域专家和工程师之间建立共同的理解。工程师需要了解问题的根源，而领域专家需要了解技术能够做什么。只有这样，真正有用的想法才能出现。
- en: '**Lesson 10: In AI 4 Good, work closely with domain experts and beware technologism. **'
  id: totrans-32
  prefs:
  - PREF_BQ
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第 10 课：在 AI for Good 中，与领域专家紧密合作，并警惕技术主义。**'
- en: '![](../Images/1988efbe7edd6da14c91ceed457a6a45.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1988efbe7edd6da14c91ceed457a6a45.png)'
- en: The algorithms we build affect lives. Via the internet and social media they
    can literally shape how you think. They affect healthcare, jobs, court cases.
    Given that less than half a percent of the population knows how to code, think
    what a tiny fraction of that number actually understands AI. So we have the awesome
    and exciting responsibility to shape the future of our society so that it is bright.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所构建的算法影响着生活。通过互联网和社交媒体，它们可以字面上塑造你的思维。它们影响医疗、就业和法庭案件。考虑到不到百分之一的人口会编码，想象一下其中有多小的一部分真正理解人工智能。所以我们肩负着塑造社会未来的**重大且令人兴奋的责任**，以确保它光明。
- en: '![You know about problems other people don''t. You are responsible for the
    shape of our society.](../Images/9b17bae0c05cc89deb22acdd4956cd5c.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![你了解其他人不知道的问题。你对我们社会的形态负有责任。](../Images/9b17bae0c05cc89deb22acdd4956cd5c.png)'
- en: You know about problems other people don’t. You are responsible for the shape
    of our society.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你了解其他人不知道的问题。你对我们社会的形态负有责任。
- en: Do you have your own “lessons”? Please add them in the comments below.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你有自己的“经验教训”吗？请在下面的评论中添加。
- en: Thanks for reading! Follow me on Twitter [@marekog](https://twitter.com/marekrog).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！在 Twitter 上关注我 [@marekog](https://twitter.com/marekrog)。
- en: '**Follow Appsilon Data Science on Social Media**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**关注Appsilon数据科学的社交媒体**'
- en: Follow[ @Appsilon](https://twitter.com/appsilon) on Twitter
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Twitter 上关注[ @Appsilon](https://twitter.com/appsilon)
- en: Follow us on[ LinkedIn](https://www.linkedin.com/company/appsilon)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[ LinkedIn](https://www.linkedin.com/company/appsilon) 上关注我们
- en: Sign up for our[ newsletter](https://appsilon.com/blog/)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册我们的[ 新闻通讯](https://appsilon.com/blog/)
- en: Try out our R Shiny[ open source](https://appsilon.com/opensource/) packages
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试我们的 R Shiny[ 开源](https://appsilon.com/opensource/) 包
- en: '**Bio: [Marek Rogala](https://twitter.com/marekrog)** is the CTO at Appsilon.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Marek Rogala](https://twitter.com/marekrog)** 是Appsilon的首席技术官。'
- en: '[Original](https://appsilon.com/5-ways-to-apply-ethics-to-ai/?nabe=4634331497365504:0).
    Reposted with permission.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://appsilon.com/5-ways-to-apply-ethics-to-ai/?nabe=4634331497365504:0)。经许可转载。'
- en: '**Related:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Dusting Under the Bed: Machine Learners’ Responsibility for the Future of
    Our Society](/2019/12/machine-learners-responsibility-future-society.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[床下的灰尘：机器学习者对我们社会未来的责任](/2019/12/machine-learners-responsibility-future-society.html)'
- en: '[5 Statistical Traps Data Scientists Should Avoid](/2019/10/statistical-traps-data-scientists-avoid.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个数据科学家应该避免的统计陷阱](/2019/10/statistical-traps-data-scientists-avoid.html)'
- en: '[Designing Ethical Algorithms](/2019/03/designing-ethical-algorithms.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[设计伦理算法](/2019/03/designing-ethical-algorithms.html)'
- en: '* * *'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[5 Ways to Apply AI to Small Data Sets](https://www.kdnuggets.com/2022/02/5-ways-apply-ai-small-data-sets.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 种将人工智能应用于小数据集的方法](https://www.kdnuggets.com/2022/02/5-ways-apply-ai-small-data-sets.html)'
- en: '[The Ethics of AI: Navigating the Future of Intelligent Machines](https://www.kdnuggets.com/2023/04/ethics-ai-navigating-future-intelligent-machines.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能伦理：导航智能机器的未来](https://www.kdnuggets.com/2023/04/ethics-ai-navigating-future-intelligent-machines.html)'
- en: '[Using the apply() Method with Pandas Dataframes](https://www.kdnuggets.com/2022/07/apply-method-pandas-dataframes.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Pandas DataFrames 的 apply() 方法](https://www.kdnuggets.com/2022/07/apply-method-pandas-dataframes.html)'
- en: '[MLOps: The Best Practices and How To Apply Them](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：最佳实践及如何应用](https://www.kdnuggets.com/2022/04/mlops-best-practices-apply.html)'
- en: '[What is Chebychev''s Theorem and How Does it Apply to Data Science?](https://www.kdnuggets.com/2022/11/chebychev-theorem-apply-data-science.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是切比雪夫定理，它如何应用于数据科学？](https://www.kdnuggets.com/2022/11/chebychev-theorem-apply-data-science.html)'
- en: '[KDnuggets News, November 30: What is Chebychev''s Theorem and How…](https://www.kdnuggets.com/2022/n46.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月30日：什么是切比雪夫定理及其如何…](https://www.kdnuggets.com/2022/n46.html)'
