- en: How to Deal with Missing Values in Your Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/06/missing-values-dataset.html](https://www.kdnuggets.com/2020/06/missing-values-dataset.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Yogita Kinha](http://www.linkedin.com/in/yogita-kinha), Consultant and
    Blogger**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/601a6d7f0a72fa9012db04fc3e3612c3.png)'
  prefs: []
  type: TYPE_IMG
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In the last [blog](https://www.edvancer.in/data-cleaning), we discussed the
    importance of the data cleaning process in a data science project and ways of
    cleaning the data to convert a raw dataset into a useable form. Here, we are going
    to talk about how to identify and treat the missing values in the data step by
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world data would certainly have missing values. This could be due to many
    reasons such as data entry errors or data collection problems. Irrespective of
    the reasons, it is important to handle missing data because any statistical results
    based on a dataset with non-random missing values could be biased. Also, many
    ML algorithms do not support data with missing values.
  prefs: []
  type: TYPE_NORMAL
- en: '**How to identify missing values?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can check for null values in a dataset using pandas function as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bbee16c73d338ae2b230e03dcd66fc6.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/b5978e130137a5f30d6f78280237a4fd.png)'
  prefs: []
  type: TYPE_IMG
- en: But, sometimes, it might not be this simple to identify missing values. One
    needs to use the domain knowledge and look at the data description to understand
    the variables. For instance, in the dataset below, isnull() does not show any
    null values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/750268e2b15735bc2ad1c53da7bb43e9.png)'
  prefs: []
  type: TYPE_IMG
- en: In this example, there are columns that have a minimum value of zero. On some
    columns, a value of zero does not make sense and indicates an invalid or missing
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 'On analysing the features carefully, the following columns have an invalid
    zero minimum value:'
  prefs: []
  type: TYPE_NORMAL
- en: Plasma glucose concentration
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Diastolic blood pressure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Triceps skinfold thickness
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2-Hour serum insulin
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Body mass index
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It becomes clear on checking the number of zeros in these columns that columns
    1,2 and 5 have few zero values, whereas columns 3 and 4 have a lot more.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9eb03f12081b98af0607fedd1a1d032c.png)'
  prefs: []
  type: TYPE_IMG
- en: Missing values in each of these columns may need different strategies. We could
    mark these zero values as NaN to highlight missing values so that they could be
    processed further.
  prefs: []
  type: TYPE_NORMAL
- en: '**Quick classification of missing data**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are three types of missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**MCAR:** Missing Completely At Random. It is the highest level of randomness.
    This means that the missing values in any features are not dependent on any other
    features values. This is the desirable scenario in case of missing data.'
  prefs: []
  type: TYPE_NORMAL
- en: '**MAR**: Missing At Random. This means that the missing values in any feature
    are dependent on the values of other features.'
  prefs: []
  type: TYPE_NORMAL
- en: '**MNAR**: Missing Not At Random. Missing not at random data is a more serious
    issue and in this case, it might be wise to check the data gathering process further
    and try to understand why the information is missing. For instance, if most of
    the people in a survey did not answer a certain question, why did they do that?
    Was the question unclear?'
  prefs: []
  type: TYPE_NORMAL
- en: '**What to do with the missing values?**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have identified the missing values in our data, next we should check
    the extent of the missing values to decide the further course of action.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ignore the missing values**'
  prefs: []
  type: TYPE_NORMAL
- en: Missing data under 10% for an individual case or observation can generally be
    ignored, except when the missing data is a MAR or MNAR.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of complete cases i.e. observation with no missing data must be sufficient
    for the selected analysis technique if the incomplete cases are not considered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Drop the missing values**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dropping a variable**'
  prefs: []
  type: TYPE_NORMAL
- en: If the data is MCAR or MAR and the number of missing values in a feature is
    very high, then that feature should be left out of the analysis. If missing data
    for a certain feature or sample is more than 5% then you probably should leave
    that feature or sample out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the cases or observations have missing values for target variables(s), it
    is advisable to delete the dependent variable(s) to avoid any artificial increase
    in relationships with independent variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Case Deletion**'
  prefs: []
  type: TYPE_NORMAL
- en: In this method, cases which have missing values for one or more features are
    deleted. If the cases having missing values are small in number, it is better
    to drop them. Though this is an easy approach, it might lead to a significant
    decrease in the sample size. Also, the data may not always be missing completely
    at random. This may lead to biased estimation of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Imputation**'
  prefs: []
  type: TYPE_NORMAL
- en: Imputation is the process of substituting the missing data by some statistical
    methods. Imputation is useful in the sense that it preserves all cases by replacing
    missing data with an estimated value based on other available information. But
    imputation methods should be used carefully as most of them introduce a large
    amount of bias and reduce variance in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Imputation by Mean/Mode/Median**'
  prefs: []
  type: TYPE_NORMAL
- en: If the missing values in a column or feature are numerical, the values can be
    imputed by the mean of the complete cases of the variable. Mean can be replaced
    by median if the feature is suspected to have outliers. For a categorical feature,
    the missing values could be replaced by the mode of the column. The major drawback
    of this method is that it reduces the variance of the imputed variables. This
    method also reduces the correlation between the imputed variables and other variables
    because the imputed values are just estimates and will not be related to other
    values inherently.
  prefs: []
  type: TYPE_NORMAL
- en: '**Regression Methods**'
  prefs: []
  type: TYPE_NORMAL
- en: The variables with missing values are treated as dependent variables and variables
    with complete cases are taken as predictors or independent variables. The independent
    variables are used to fit a linear equation for the observed values of the dependent
    variable. This equation is then used to predict values for the missing data points.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of this method is that the identified independent variables
    would have a high correlation with the dependent variable by virtue of selection.
    This would result in fitting the missing values a little too well and reducing
    the uncertainty about that value. Also, this assumes that relationship is linear
    which might not be the case in reality.
  prefs: []
  type: TYPE_NORMAL
- en: '**K-Nearest Neighbour Imputation (KNN)**'
  prefs: []
  type: TYPE_NORMAL
- en: This method uses k-nearest neighbour algorithms to estimate and replace missing
    data. The k-neighbours are chosen using some distance measure and their average
    is used as an imputation estimate. This could be used for estimating both qualitative
    attributes (the most frequent value among the k nearest neighbours) and quantitative
    attributes (the mean of the k nearest neighbours).
  prefs: []
  type: TYPE_NORMAL
- en: One should try different values of k with different distance metrics to find
    the best match. The distance metric could be chosen based on the properties of
    the data. For example, Euclidean is a good distance measure to use if the input
    variables are similar in type (e.g. all measured widths and heights). Manhattan
    distance is a good measure to use if the input variables are not similar in type
    (such as age, gender, height, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of using KNN is that it is simple to implement. But it suffers
    from the curse of dimensionality. It works well for a small number of variables
    but becomes computationally inefficient when the number of variables is large.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple Imputation**'
  prefs: []
  type: TYPE_NORMAL
- en: Multiple imputations is an iterative method in which multiple values are estimated
    for the missing data points using the distribution of the observed data. The advantage
    of this method is that it reflects the uncertainty around the true value and returns
    unbiased estimates.
  prefs: []
  type: TYPE_NORMAL
- en: 'MI involves the following three basic steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Imputation: The missing data are filled in with estimated values and a complete
    data set is created. This process of imputation is repeated m times and m datasets
    are created.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Analysis: Each of the *m* complete data sets is then analysed using a statistical
    method of interest (e.g. linear regression).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pooling: The parameter estimates (e.g. coefficients and standard errors) obtained
    from each analysed data set are then averaged to get a single point estimate.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Python’s Scikit-learn has methods — impute.SimpleImputer for univariate (single
    variable) imputations and impute.IterativeImputer for multivariate imputations.
  prefs: []
  type: TYPE_NORMAL
- en: The MICE package in R supports the multiple imputation functionality. Python
    does not directly support multiple imputations but IterativeImputer can be used
    for multiple imputations by applying it repeatedly to the same dataset with different
    random seeds when sample_posterior=True.
  prefs: []
  type: TYPE_NORMAL
- en: 'In summation, handling the missing data is crucial for a data science project.
    However, the data distribution should not be changed while handling missing data.
    Any missing data treatment method should satisfy the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: Estimation without bias — Any missing data treatment method should not change
    the data distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The relationship among the attributes should be retained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hope you enjoyed reading the blog!!
  prefs: []
  type: TYPE_NORMAL
- en: Please share your feedback and topics that you would like to know about.
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://machinelearningmastery.com/handle-missing-data-python/](https://machinelearningmastery.com/handle-missing-data-python/) [https://en.wikipedia.org/wiki/Imputation_(statistics)](https://en.wikipedia.org/wiki/Imputation_(statistics)) [https://stats.idre.ucla.edu/stata/seminars/mi_in_stata_pt1_new/](https://stats.idre.ucla.edu/stata/seminars/mi_in_stata_pt1_new/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://pdfs.semanticscholar.org/e4f8/1aa5b67132ccf875cfb61946892024996413.pdf](https://pdfs.semanticscholar.org/e4f8/1aa5b67132ccf875cfb61946892024996413.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Originally published at *[*https://www.edvancer.in*](https://www.edvancer.in/data-cleaning-missing-values-treatment)* on
    July 2, 2019.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Yogita Kinha](http://www.linkedin.com/in/yogita-kinha)** is a competent
    professional with experience in R, Python, Machine Learning and software environment
    for statistical computing and graphics, hands on experience on Hadoop ecosystem,
    and testing & reporting in software testing domain.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/limitedio/how-to-deal-with-missing-values-in-your-dataset-988696b1f450).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Transformation: Standardization vs Normalization](/2020/04/data-transformation-standardization-normalization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simplified Mixed Feature Type Preprocessing in Scikit-Learn with Pipelines](/2020/06/simplifying-mixed-feature-type-preprocessing-scikit-learn-pipelines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Great New Features in Scikit-learn 0.23](/2020/05/5-great-new-features-scikit-learn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Handling Missing Values in Time-series with SQL](https://www.kdnuggets.com/2022/09/handling-missing-values-timeseries-sql.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Deal with Missing Data Using Interpolation Techniques in Pandas](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part 4: The Neuron’s…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using SHAP Values for Model Interpretability in Machine Learning](https://www.kdnuggets.com/2023/08/shap-values-model-interpretability-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Deal with Categorical Data for Machine Learning](https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways to Deal with the Lack of Data in Machine Learning](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
