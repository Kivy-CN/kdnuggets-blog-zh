- en: 5 Ways To Use LLMs On Your Laptop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop](https://www.kdnuggets.com/5-ways-to-use-llms-on-your-laptop)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/959531228a0af4fd6fcf399f422784d8.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Accessing ChatGPT online is very simple - all you need is an internet connection
    and a good browser. However, by doing so, you may be compromising your privacy
    and data. OpenAI stores your prompt responses and other metadata to retrain the
    models. While this might not be a concern for some, others who are privacy-conscious
    may prefer to use these models locally without any external tracking.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we will discuss five ways to use large language models (LLMs)
    locally. Most of the software is compatible with all major operating systems and
    can be easily downloaded and installed for immediate use. By using LLMs on your
    laptop, you have the freedom to choose your own model. You just need to download
    the model from the HuggingFace hub and start using it. Additionally, you can grant
    these applications access to your project folder and generate context-aware responses.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. GPT4All
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[GPT4All](https://gpt4all.io/index.html) is a cutting-edge open-source software
    that enables users to download and install state-of-the-art open-source models
    with ease.'
  prefs: []
  type: TYPE_NORMAL
- en: Simply download GPT4ALL from the website and install it on your system. Next,
    choose the model from the panel that suits your needs and start using it. If you
    have CUDA (Nvidia GPU) installed, GPT4ALL will automatically start using your
    GPU to generate quick responses of up to 30 tokens per second.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/c68d67ddd46c9442bee98a695cfe0c78.png)'
  prefs: []
  type: TYPE_IMG
- en: You can provide access to multiple folders containing important documents and
    code, and GPT4ALL will generate responses using Retrieval-Augmented Generation.
    GPT4ALL is user-friendly, fast, and popular among the AI community.
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the blog about GPT4ALL to learn more about features and use cases: [The
    Ultimate Open-Source Large Language Model Ecosystem](/2023/05/ultimate-opensource-large-language-model-ecosystem.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. LM Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[LM Studio](https://lmstudio.ai/) is a new software that offers several advantages
    over GPT4ALL. The user interface is excellent, and you can install any model from
    Hugging Face Hub with a few clicks. Additionally, it provides GPU offloading and
    other options that are not available in GPT4ALL. However, LM Studio is a closed
    source, and it doesn''t have the option to generate context-aware responses by
    reading project files.'
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/4f5f0c4245979ed4d3f59ee7f7e28f52.png)'
  prefs: []
  type: TYPE_IMG
- en: LM Studio offers access to thousands of open-source LLMs, allowing you to start
    a local inference server that behaves like OpenAI's API. You can modify your LLM's
    response through the interactive user interface with multiple options.
  prefs: []
  type: TYPE_NORMAL
- en: Also, read [Run an LLM Locally with LM Studio](/run-an-llm-locally-with-lm-studio)
    to learn more about LM Studio and its key features.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Ollama
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Ollama](https://github.com/ollama/ollama) is a command-line interface (CLI)
    tool that enables speedy operation for large language models such as Llama 2,
    Mistral, and Gemma. If you are a hacker or developer, this CLI tool is a fantastic
    option. You can download and install the software and use `the llama run llama2`
    command to start using the LLaMA 2 model. You can find other model commands in
    the GitHub repository.'
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/33c8e965b3f5c20325e58d9f9749d31c.png)'
  prefs: []
  type: TYPE_IMG
- en: It also allows you to start a local HTTP server that can be integrated with
    other applications. For instance, you can use the Code GPT VSCode extension by
    providing the local server address and start using it as an AI coding assistant.
  prefs: []
  type: TYPE_NORMAL
- en: Improve your coding and data workflow with these [Top 5 AI Coding Assistants](/top-5-ai-coding-assistants-you-must-try).
  prefs: []
  type: TYPE_NORMAL
- en: 4\. LLaMA.cpp
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[LLaMA.cpp](https://github.com/ggerganov/llama.cpp) is a tool that offers both
    a CLI and a Graphical User Interface (GUI). It allows you to use any open-source
    LLMs locally without any hassle. This tool is highly customizable and provides
    fast responses to any query, as it is entirely written in pure C/C++.'
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/e9ff13b2925d46e2dde511a831ca7d36.png)'
  prefs: []
  type: TYPE_IMG
- en: LLaMA.cpp supports all types of operating systems, CPUs, and GPUs. You can also
    use multimodal models such as LLaVA, BakLLaVA, Obsidian, and ShareGPT4V.
  prefs: []
  type: TYPE_NORMAL
- en: Learn how to [Run Mixtral 8x7b On Google Colab For Free](/running-mixtral-8x7b-on-google-colab-for-free)
    using LLaMA.cpp and Google GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. NVIDIA Chat with RTX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use [NVIDIA Chat with RTX](https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/),
    you need to download and install the Windows 11 application on your laptop. This
    application is compatible with laptops that have a 30 series or 40 series RTX
    NVIDIA graphics card with at least 8GB of RAM and 50GB of free storage space.
    Additionally, your laptop should have at least 16GB of RAM to run Chat with RTX
    smoothly.
  prefs: []
  type: TYPE_NORMAL
- en: '![5 Ways To Use LLMs On Your Laptop](../Images/62b35ec13c71bd6451ed392e51013cb6.png)'
  prefs: []
  type: TYPE_IMG
- en: With Chat with RTX, you can run LLaMA and Mistral models locally on your laptop.
    It's a fast and efficient application that can even learn from documents you provide
    or YouTube videos. However, it's important to note that Chat with RTX relies on
    TensorRTX-LLM, which is only supported on 30 series GPUs or newer.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to take advantage of the latest LLMs while keeping your data safe
    and private, you can use tools like GPT4All, LM Studio, Ollama, LLaMA.cpp, or
    NVIDIA Chat with RTX. Each tool has its own unique strengths, whether it's an
    easy-to-use interface, command-line accessibility, or support for multimodal models.
    With the right setup, you can have a powerful AI assistant that generates customized
    context-aware responses.
  prefs: []
  type: TYPE_NORMAL
- en: I suggest starting with GPT4All and LM Studio as they cover most of the basic
    needs. After that, you can try Ollama and LLaMA.cpp, and finally, try Chat with
    RTX.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) is a certified data
    scientist professional who loves building machine learning models. Currently,
    he is focusing on content creation and writing technical blogs on machine learning
    and data science technologies. Abid holds a Master''s degree in technology management
    and a bachelor''s degree in telecommunication engineering. His vision is to build
    an AI product using a graph neural network for students struggling with mental
    illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Turn Your Laptop Into a Personal Analytics Engine with DuckDB and…](https://www.kdnuggets.com/turn-your-laptop-into-a-personal-analytics-engine-with-duckdb-and-motherduck)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways of Converting Unstructured Data into Structured Insights with LLMs](https://www.kdnuggets.com/5-ways-of-converting-unstructured-data-into-structured-insights-with-llms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways To Use AI For Supply Chain Management](https://www.kdnuggets.com/2022/02/5-ways-ai-supply-chain-management.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways You Can Use ChatGPT''s Code Interpreter For Data Science](https://www.kdnuggets.com/2023/08/5-ways-chatgpt-code-interpreter-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Ways You Can Use ChatGPT Vision for Data Analysis](https://www.kdnuggets.com/5-ways-you-can-use-chatgpt-vision-for-data-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
