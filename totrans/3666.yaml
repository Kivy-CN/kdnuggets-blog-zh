- en: 'RedPajama Project: An Open-Source Initiative to Democratizing LLMs'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/5d082ed99816c02306cba227165e9598.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (Generated via [Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1))
  prefs: []
  type: TYPE_NORMAL
- en: In recent times, Large Language Models or LLM have dominated the world. With
    the introduction of ChatGPT, everyone could now benefit from the text generation
    model. But, many powerful models are only available commercially, leaving much
    great research and customization behind.
  prefs: []
  type: TYPE_NORMAL
- en: There are, of course, many projects now trying to open-source many of the LLMs
    fully. Projects such as [Pythia](https://github.com/EleutherAI/pythia), [Dolly](https://github.com/databrickslabs/dolly),
    [DLite](https://huggingface.co/aisquared/dlite-v2-1_5b), and many others are some
    of examples. But why try to make LLMs open-source? It’s a sentiment of the community
    that moved all these projects to bridge the limitation that the closed model brings.
    However, are the open-source models inferior compared to the closed ones? Of course
    not. Many models could rival commercial models and show promising results in many
    areas.
  prefs: []
  type: TYPE_NORMAL
- en: To follow up with this movement, one of the open-source projects to democratize
    LLM is the RedPajama. What is this project, and how could it benefit the community?
    Let’s explore this further.
  prefs: []
  type: TYPE_NORMAL
- en: RedPajama
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[RedPajama](https://github.com/togethercomputer/RedPajama-Data) is a collaboration
    project between [Ontocord.ai](https://www.ontocord.ai/), [ETH DS3Lab](https://ds3lab.inf.ethz.ch/),
    [Stanford CRFM](https://crfm.stanford.edu/), and [Hazy Research](https://hazyresearch.stanford.edu/)
    to develop reproducible open-source LLMs. The RedPajama project contains three
    milestones, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Pre-training data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Base models
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instruction tuning data and models
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When this article was written, the RedPajama project had developed the pre-training
    data and the models, including the base, instructed, and chat versions.
  prefs: []
  type: TYPE_NORMAL
- en: RedPajama Pre-Trained Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first step, RedPajama tries replicating the semi-open model's [LLaMa](https://arxiv.org/abs/2302.13971)
    dataset. This means RedPajama tries to build pre-trained data with 1.2 trillion
    tokens and fully open-source it for the community. Currently, the full data and
    the sample data can be downloaded on the [HuggingFace](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T).
  prefs: []
  type: TYPE_NORMAL
- en: The data sources for the RedPajama dataset are summarized in the table below.
  prefs: []
  type: TYPE_NORMAL
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/bdb1b7145b1d25649e2386a7b59546cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Where each data slice is pre-processed and filtered carefully, the number of
    tokens also roughly matches the number reported in the LLaMa paper.
  prefs: []
  type: TYPE_NORMAL
- en: The next step after the dataset creation is to development of the base models.
  prefs: []
  type: TYPE_NORMAL
- en: RedPajama Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following weeks after the creation of the RedPajama dataset, the first
    model trained on the dataset was released. The base models have two versions:
    a 3 billion and a 7 Billion parameters model. The RedPajama project also releases
    two variations of each base model: instruction-tuned and chat models.'
  prefs: []
  type: TYPE_NORMAL
- en: The summary of each model can be seen in the table below.
  prefs: []
  type: TYPE_NORMAL
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/5f68338f56df1e5603ee24e0c53f30c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author (Adapted from [together.xyz](https://www.together.xyz/blog/redpajama-models-v1))
  prefs: []
  type: TYPE_NORMAL
- en: 'You can access the models above using the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Chat-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Instruct-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Base-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Chat-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-7B-v0.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[RedPajama-INCITE-Instruct-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s try out the RedPajama Base model. For example, we will try the RedPajama
    3B base model with the code adapted from [HuggingFace](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The 3B Base model's result is promising, and it might be better if we use the
    7B Base model. As the development is still ongoing, the project might have an
    even better model in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Generative AI is rising, but sadly many great models are still locked under
    the company's archive. RedPajama is one of the leading projects that try to replicate
    the semi-open LLaMA model to democratize the LLMs. By developing a similar dataset
    to the LLama, RedPajama manages to create an open-source 1.2 trillion tokens dataset
    that many open-source projects have used.
  prefs: []
  type: TYPE_NORMAL
- en: RedPajama also releases two kinds of models; 3B and 7B parameter base models,
    where each base model contains instruction-tuned and chat models.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Falcon LLM: The New King of Open-Source LLMs](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ensuring Reliable Few-Shot Prompt Selection for LLMs](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing OpenLLM: Open Source Library for LLMs](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8 Free AI and LLMs Playgrounds](https://www.kdnuggets.com/2023/05/8-free-ai-llms-playgrounds.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
