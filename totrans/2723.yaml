- en: Facebook Uses Bayesian Optimization to Conduct Better Experiments in Machine
    Learning Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Facebook 利用贝叶斯优化在机器学习模型中进行更好的实验
- en: 原文：[https://www.kdnuggets.com/2020/08/facebook-bayesian-optimization-better-experiments-machine-learning.html](https://www.kdnuggets.com/2020/08/facebook-bayesian-optimization-better-experiments-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/08/facebook-bayesian-optimization-better-experiments-machine-learning.html](https://www.kdnuggets.com/2020/08/facebook-bayesian-optimization-better-experiments-machine-learning.html)
- en: '[comments](#comments)![Figure](../Images/5a41adeaa39bd46f9876c1a54d9e5f5a.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments) ![图](../Images/5a41adeaa39bd46f9876c1a54d9e5f5a.png)'
- en: Source: [https://www.persado.com/2016/06/machine-learning-trumps-a-b-split-testing/](https://www.persado.com/2016/06/machine-learning-trumps-a-b-split-testing/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.persado.com/2016/06/machine-learning-trumps-a-b-split-testing/](https://www.persado.com/2016/06/machine-learning-trumps-a-b-split-testing/)
- en: 'I recently started a new newsletter focus on AI education. TheSequence is a
    no-BS( meaning no hype, no news etc) AI-focused newsletter that takes 5 minutes
    to read. The goal is to keep you up to date with machine learning projects, research
    papers and concepts. Please give it a try by subscribing below:'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我最近开始了一份新的关注人工智能教育的通讯。《TheSequence》是一份无废话（即没有炒作，没有新闻等）的 AI 专注通讯，阅读时间为 5 分钟。目标是让你了解最新的机器学习项目、研究论文和概念。请通过以下方式订阅试试：
- en: '[![Image](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图片](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
- en: Hyperparameter optimization is a key aspect of the lifecycle of machine learning
    applications. While methods such as grid search are incredibly effective for optimizing
    hyperparameters for specific isolated models, they are very difficult to scale
    across large permutations of models and experiments. A company like Facebook operates
    thousands of concurrent machine learning models that need to be constantly tuned.
    To achieve that, Facebook engineering teams need to regularly conduct A/B tests
    in order to determine the right hyperparameter configuration. Data in those tests
    is difficult to collect and they are typically conducted in isolation of each
    other which end up resulting in very computationally expensive exercises. One
    of the most innovative approaches in this area came from a team of AI researchers
    from Facebook who [published a paper proposing a method based on Bayesian optimization](https://projecteuclid.org/euclid.ba/1533866666) to
    adaptively design rounds of A/B tests based on the results of prior tests.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数优化是机器学习应用生命周期中的一个关键方面。尽管诸如网格搜索之类的方法在优化特定孤立模型的超参数方面极为有效，但它们很难在大规模模型和实验的排列中进行扩展。像
    Facebook 这样的公司运营着数千个并发的机器学习模型，这些模型需要不断地进行调整。为此，Facebook 工程团队需要定期进行 A/B 测试，以确定合适的超参数配置。这些测试中的数据难以收集，并且通常是孤立进行的，最终导致计算成本极高。在这一领域最具创新性的方法之一来自
    Facebook 的一个 AI 研究团队，他们[发表了一篇基于贝叶斯优化的方法来自适应设计 A/B 测试轮次的论文](https://projecteuclid.org/euclid.ba/1533866666)，该方法基于之前测试的结果。
- en: Why Bayesian Optimization?
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择贝叶斯优化？
- en: Bayesian optimization is a powerful method for solving black-box optimization
    problems that involve expensive function evaluations. Recently, Bayesian optimization
    has evolved as an important technique for optimizing hyperparameters in machine
    learning models. Conceptually, Bayesian optimization starts by evaluating a small
    number of randomly selected function values, and fitting a Gaussian process (GP)
    regression model to the results. The GP posterior provides an estimate of the
    function value at each point, as well as the uncertainty in that estimate. The
    GP works well for Bayesian optimization because it provides excellent uncertainty
    estimates and is analytically tractable. It provides an estimate of how an online
    metric varies with the parameters of interest.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化是一种强大的方法，用于解决涉及昂贵函数评估的黑箱优化问题。最近，贝叶斯优化已发展成为优化机器学习模型中的超参数的重要技术。概念上，贝叶斯优化从评估少量随机选择的函数值开始，并将高斯过程（GP）回归模型拟合到结果中。GP
    后验提供了每一点的函数值估计以及该估计的不确定性。GP 在贝叶斯优化中表现良好，因为它提供了出色的不确定性估计，并且在理论上易于处理。它提供了一个估计，说明在线度量如何随着感兴趣的参数变化。
- en: Let’s imagine an environment in which we are conducting random and regular experiments
    on machine learning models. In that scenario, Bayesian optimization can be used
    to construct a statistical model of the relationship between the parameters and
    the online outcomes of interest and uses that model to decide which experiments
    to run. The concept is well illustrated in the following figure in which each
    data marker corresponds to the outcome of an A/B test of that parameter value.
    We can use the GP to decide which parameter to test next by balancing exploration
    (high uncertainty) with exploitation (good model estimate). This is done by computing
    an acquisition function that estimates the value of running an experiment with
    any given parameter value.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设想一个环境，其中我们对机器学习模型进行随机和定期的实验。在这种情况下，贝叶斯优化可以用来构建参数与在线结果之间关系的统计模型，并使用该模型来决定运行哪些实验。这个概念在下图中得到了很好的说明，其中每个数据标记对应于该参数值的A/B测试结果。我们可以使用GP来决定下一个测试哪个参数，通过在探索（高不确定性）与利用（良好的模型估计）之间取得平衡来完成。这是通过计算一个获取函数来完成的，该函数估计运行任何给定参数值实验的价值。
- en: '![Figure](../Images/764a2ed588a06c28afc8cbad22a9d87c.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/764a2ed588a06c28afc8cbad22a9d87c.png)'
- en: Source: [https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666](https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666](https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666)
- en: The fundamental goal of Bayesian optimization when applied to hyperparameter
    optimization is to determine how valuable is an experiment for a specific hyperparameter
    configuration. Conceptually, Bayesian optimization works very efficiently for
    isolated models but its value proposition is challenged when used in scenarios
    running random experiments. The fundamental challenge is related to the noise
    introduced in the observations.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用于超参数优化时，贝叶斯优化的基本目标是确定特定超参数配置的实验价值。从概念上讲，贝叶斯优化对于孤立模型非常有效，但在运行随机实验的场景中，其价值主张面临挑战。根本挑战与观察中引入的噪声有关。
- en: Noise and Bayesian Optimization
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 噪声与贝叶斯优化
- en: Random experiments in machine learning systems introduce high levels of noise
    in the observations. Additionally, many of the constraints for a given experiment
    can be considered noisy data in and out itself which can affect the results of
    an experiment. Suppose that we are trying to evaluate the value of a function *f(x)* for
    a given observation *x*. With observation noise, we now have uncertainty not only
    in the value *f(x)*, but we also have uncertainty in which observation is the
    current best, *x**, and its value, *f(x*).*
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统中的随机实验引入了高水平的观察噪声。此外，许多特定实验的约束本身也可以视为噪声数据，这可能会影响实验结果。假设我们试图评估给定观察*x*的函数*f(x)*的值。由于观察噪声，我们不仅对值*f(x)*有不确定性，而且对当前最佳观察*x*及其值*f(x)*也存在不确定性。
- en: 'Typically, Bayesian optimization models use heuristics to handle noisy observations
    but those perform very poorly with high levels of noise. To address this challenge,
    the Facebook team came up with a clever answer: why not to factor in noise as
    part of the observations?'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，贝叶斯优化模型使用启发式方法来处理噪声观察，但这些方法在噪声水平较高时表现很差。为了解决这个问题，Facebook团队提出了一个巧妙的答案：为什么不把噪声作为观察的一部分呢？
- en: Imagine if, instead of computing the expectation of observing *f(x)* we observe *yi *= *f*(**x***i*)
    + *€i*, where *€i *is the observation noise. Mathematically, GP works similarly
    with noise observation as it does with noiseless data. Without going crazy about
    the math, in their research paper, the Facebook team showed that this type of
    approximation is very well suited for Monte Carlo optimizations which yield incredibly
    accurate results estimating the correct observation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果我们观察到的不是*f(x)*的期望，而是*yi = f(xi) + €i*，其中*€i*是观察噪声。从数学上讲，GP在处理带噪声的观察时与处理无噪声数据的方式类似。虽然数学细节较多，但在他们的研究论文中，Facebook团队展示了这种类型的近似非常适合蒙特卡洛优化，这种优化方法能准确估计正确的观察结果。
- en: '![Image for post](../Images/e8655a6e8c580d48a6fec401f7eb52e5.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/e8655a6e8c580d48a6fec401f7eb52e5.png)'
- en: Bayesian Optimization with Noisy Data in Action
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带噪声数据的贝叶斯优化实践
- en: The Facebook team tested their research in a couple of real world scenarios
    at Facebook scale. The first was to optimize 6 parameters of one of Facebook’s
    ranking systems. The second example was to optimize 7 numeric compiler flags related
    to CPU usage used in their HipHop Virtual Machine(HHVM). For that second experiment,
    the first 30 iterations were randomly created. At that point, the Bayesian optimization
    with noisy data method was able to identity CPU time as the hyperparameter configuration
    that needed to be evaluated and started running different experiments to optimize
    its value. The results are clearly illustrated in the following figure.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook 团队在几个现实世界的场景中测试了他们的研究，规模达到 Facebook 级别。第一个场景是优化 Facebook 排名系统的 6 个参数。第二个例子是优化
    7 个与 CPU 使用相关的数字编译器标志，这些标志用于他们的 HipHop 虚拟机（HHVM）。在第二个实验中，前 30 次迭代是随机生成的。此时，噪声数据下的贝叶斯优化方法能够识别出
    CPU 时间作为需要评估的超参数配置，并开始运行不同的实验以优化其值。结果在下图中清晰地展示出来。
- en: '![Figure](../Images/afda12066733a77f0cce424f606da881.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/afda12066733a77f0cce424f606da881.png)'
- en: Source: [https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666](https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666](https://projecteuclid.org/download/pdfview_1/euclid.ba/1533866666)
- en: Techniques such as Bayesian optimization with noisy data are incredibly powerful
    in large scale machine learning algorithms. While we have done a lot of work on
    optimization methods, most of those methods remain highly theoretical. Its nice
    to see Facebook pushing the boundaries of this nascent space.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声数据下的贝叶斯优化等技术在大规模机器学习算法中极具威力。虽然我们在优化方法上做了大量工作，但大多数方法仍然高度理论化。很高兴看到 Facebook
    推动了这个新兴领域的边界。
- en: '[Original](https://medium.com/dataseries/facebook-uses-bayesian-optimization-to-conduct-better-experiments-in-machine-learning-models-6f834169d005).
    Reposted with permission.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始文章](https://medium.com/dataseries/facebook-uses-bayesian-optimization-to-conduct-better-experiments-in-machine-learning-models-6f834169d005)。经许可转载。'
- en: '**Related:**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Essential Resources to Learn Bayesian Statistics](/2020/07/essential-resources-learn-bayesian-statistics.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习贝叶斯统计的必备资源](/2020/07/essential-resources-learn-bayesian-statistics.html)'
- en: '[Uber’s Ludwig is an Open Source Framework for Low-Code Machine Learning](/2020/06/uber-ludwig-open-source-framework-machine-learning.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Uber 的 Ludwig 是一个用于低代码机器学习的开源框架](/2020/06/uber-ludwig-open-source-framework-machine-learning.html)'
- en: '[Facebook Open Sources Blender, the Largest-Ever Open Domain Chatbot](/2020/05/facebook-open-sources-blender-largest-open-domain-chatbot.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Facebook 开源 Blender，最大规模的开放领域聊天机器人](/2020/05/facebook-open-sources-blender-largest-open-domain-chatbot.html)'
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How LinkedIn Uses Machine Learning To Rank Your Feed](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LinkedIn 如何使用机器学习来排序你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)'
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月16日：LinkedIn 如何使用机器学习 •…](https://www.kdnuggets.com/2022/n45.html)'
- en: '[Versioning Machine Learning Experiments vs Tracking Them](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习实验的版本控制与追踪](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
- en: '[Hydra Configs for Deep Learning Experiments](https://www.kdnuggets.com/2023/03/hydra-configs-deep-learning-experiments.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于深度学习实验的 Hydra 配置](https://www.kdnuggets.com/2023/03/hydra-configs-deep-learning-experiments.html)'
- en: '[Top Programming Languages and Their Uses](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级编程语言及其应用](https://www.kdnuggets.com/2021/05/top-programming-languages.html)'
- en: '[KDnuggets™ News 22:n04, Jan 26: The High Paying Side Hustles…](https://www.kdnuggets.com/2022/n04.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets™ 新闻 22:n04, 1月 26日: 高收入的副业…](https://www.kdnuggets.com/2022/n04.html)'
