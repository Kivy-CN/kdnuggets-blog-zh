- en: 'Phi-2: Small LMs that are Doing Big Things'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Phi-2: 小型语言模型正在做大事'
- en: 原文：[https://www.kdnuggets.com/phi-2-small-lms-that-are-doing-big-things](https://www.kdnuggets.com/phi-2-small-lms-that-are-doing-big-things)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/phi-2-small-lms-that-are-doing-big-things](https://www.kdnuggets.com/phi-2-small-lms-that-are-doing-big-things)
- en: '![Phi-2: Small LMs that are Doing Big Things](../Images/13e6e7354ab345f92ec5f0c6bdeee03d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Phi-2: 小型语言模型正在做大事](../Images/13e6e7354ab345f92ec5f0c6bdeee03d.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Before we get into the amazing things about Phi-2\. If you haven’t already
    learnt about phi-1.5, I’d advise you to have a quick skim over what Microsoft
    had in the works a few months ago [Effective Small Language Models: Microsoft’s
    1.3 Billion Parameter phi-1.5](/effective-small-language-models-microsoft-phi-15).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解Phi-2的惊人之处之前。如果你还没有了解phi-1.5，我建议你快速浏览一下微软几个月前的[有效的小型语言模型：微软的13亿参数phi-1.5](/effective-small-language-models-microsoft-phi-15)。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now you have the foundations, we can move on to learning more about Phi-2\.
    Microsoft has been working hard to release a number of small language models (SLMs)
    called ‘Phi’. This series of models has been shown to achieve remarkable performance,
    just as it was a large language model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了基础，我们可以继续学习更多关于Phi-2的内容。微软一直在努力发布一系列名为“Phi”的小型语言模型（SLMs）。这系列模型已被证明能够取得显著的性能，就像大型语言模型一样。
- en: Microsofts first model was [Phi-1](https://huggingface.co/microsoft/phi-1),
    the 1.3 billion parameter and then came [Phi-1.5](https://huggingface.co/microsoft/phi-1_5).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的第一个模型是[Phi-1](https://huggingface.co/microsoft/phi-1)，具有13亿参数，然后是[Phi-1.5](https://huggingface.co/microsoft/phi-1_5)。
- en: We’ve seen Phi-1, Phi-1.5, and now we have [Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了Phi-1、Phi-1.5，现在我们有了[Phi-2](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)。
- en: What is Phi-2?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是Phi-2？
- en: Phi-2 has become bigger and better. Bigger and better. It is a 2.7 billion-parameter
    language model that has been shown to demonstrate outstanding reasoning and language
    understanding capabilities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Phi-2变得更大、更好。更大，更好。它是一个27亿参数的语言模型，已被证明在推理和语言理解能力上表现出色。
- en: Amazing for a language model so small right?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如此小的语言模型，这真是惊人，不是吗？
- en: Phi-2 has been shown to outperform models which are 25x larger. And that’s all
    thanks to model scaling and training data curation. Small, compact, and highly
    performant. Due to its size, Phi-2 is for researchers to explore interpretability,
    fine-tuning experiments and also delve into safety improvements. It is available
    on the Azure AI Studio model catalogue.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Phi-2已被证明在性能上超越了大25倍的模型。这都归功于模型的扩展和训练数据的策划。小巧、紧凑且性能卓越。由于其规模，Phi-2适用于研究人员探索解释能力、微调实验以及深入安全改进。它可以在Azure
    AI Studio模型目录中获得。
- en: The Creation of Phi-2
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Phi-2的创建
- en: Microsfts training data is a mixture of synthetic datasets which is used to
    teach the model common sense, such as general knowledge as well as science, theory
    of mind, and daily activities.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的训练数据是合成数据集的混合，这些数据集用于教授模型常识，例如一般知识、科学、心智理论和日常活动。
- en: The training data was selected carefully to ensure that it was filtered with
    quality content that has educational value. That with the ability to scale has
    taken their 1.3 billion parameter model, Phi-1.5 to a 2.7 billion parameter Phi-2.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据经过精心挑选，以确保其经过优质内容的筛选，并具有教育价值。凭借这种可扩展性，他们将1.3亿参数的Phi-1.5模型提升到了2.7亿参数的Phi-2。
- en: '![Phi-2: Small LMs that are Doing Big Things](../Images/0c662b6c043f0225c74375a313f5d649.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![Phi-2: 小型语言模型正在做大事](../Images/0c662b6c043f0225c74375a313f5d649.png)'
- en: Image from [Microsoft Phi-2](https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[微软Phi-2](https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png)
- en: 'Microsoft put Phi-2 to the test, as they acknowledge the current challenges
    with model evaluation. Tests were done on use cases in which they compared it
    to Mistral and Llama-2\. The results showed that Phi-2 outperformed Mistral-7B
    and the 70 billion Llama-2 model outperformed Phi-2 in some cases as shown below:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 微软对Phi-2进行了测试，因为他们意识到当前模型评估的挑战。他们在测试用例中将Phi-2与Mistral和Llama-2进行了比较。结果显示，Phi-2在某些情况下超越了Mistral-7B，而70亿参数的Llama-2模型在某些情况下超越了Phi-2，如下所示：
- en: '![Phi-2: Small LMs that are Doing Big Things](../Images/b3de725465ff1a06288ca9256c9c0094.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![Phi-2: 小型语言模型的巨大潜力](../Images/b3de725465ff1a06288ca9256c9c0094.png)'
- en: Image from [Microsoft Phi-2](https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[微软Phi-2](https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png)
- en: Limitations of Phi-2
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Phi-2的局限性
- en: 'However, with that being said, Phi-2 still has its limitations. For example:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，尽管如此，Phi-2仍然有其局限性。例如：
- en: 'Inaccuracy: the model has some limitations of producing incorrect code and
    facts, which users should take with a pinch of salt and treat these outputs as
    a starting point.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不准确性：该模型在生成错误代码和事实方面存在一些局限，用户应对此保持谨慎，将这些输出视为起点。
- en: 'Limited Code Knowledge: Phi-2 training data was based on Python along with
    using common packages, therefore the generation of other languages and scripts
    will need verification.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制的代码知识：Phi-2的训练数据基于Python及常见包，因此生成其他语言和脚本的结果需要进行验证。
- en: 'Instructions: The model is yet to go through instruction fine-tuning, therefore
    it may struggle to really understand the instructions that the user provides.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令：该模型尚未经过指令微调，因此可能难以真正理解用户提供的指令。
- en: There are also other limitations of Phi-2, such as language limitations, societal
    biases, toxicity, and verbosity.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Phi-2还有其他局限性，例如语言限制、社会偏见、毒性和冗长。
- en: With that being said, every new product or service has its limitations and Phi-2
    has only been out for a week or so. Therefore, Microsoft will need phi-2 to get
    into the hands of the public to help them improve the service and overcome these
    current limitations.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，每个新产品或服务都有其局限性，而Phi-2仅发布了一周左右。因此，微软需要将Phi-2推广到公众手中，以帮助改进服务并克服当前的局限性。
- en: Wrapping it up
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Microsoft has ended the year with a small language model that could potentially
    grow to be the most talked about model of 2024\. With this being said, to close
    the year - what should we expect from the language model world for the year 2024?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 微软以一个小型语言模型结束了这一年，这个模型可能会成为2024年最受关注的模型。既然如此，我们应该对2024年的语言模型世界有什么期待呢？
- en: '[](https://www.linkedin.com/in/nisha-arya-ahmed/)****[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)****
    is a data scientist, freelance technical writer, and an editor and community manager
    for KDnuggets. She is particularly interested in providing data science career
    advice or tutorials and theory-based knowledge around data science. Nisha covers
    a wide range of topics and wishes to explore the different ways artificial intelligence
    can benefit the longevity of human life. A keen learner, Nisha seeks to broaden
    her tech knowledge and writing skills, while helping guide others.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.linkedin.com/in/nisha-arya-ahmed/)****[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)****
    是一位数据科学家、自由职业技术作家，以及KDnuggets的编辑和社区经理。她特别关注提供数据科学职业建议或教程，以及围绕数据科学的理论知识。Nisha涵盖了广泛的话题，并希望探索人工智能如何有利于人类生命的长寿。作为一个热衷学习者，Nisha寻求扩展她的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在使用神经网络之前尝试的10件简单事](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[5 Things That Set a Data Scientist Apart From Other Professions](https://www.kdnuggets.com/2021/11/5-things-set-data-scientist-apart-other-professions.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将数据科学家与其他职业区分开的5件事](https://www.kdnuggets.com/2021/11/5-things-set-data-scientist-apart-other-professions.html)'
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据管理的6件事及其重要性](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[The 5 Surprising Things You Can Do With R](https://www.kdnuggets.com/2022/08/5-surprising-things-r.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你可以用 R 做的 5 件令人惊讶的事情](https://www.kdnuggets.com/2022/08/5-surprising-things-r.html)'
- en: '[7 Things You Didn''t Know You Could do with a Low Code Tool](https://www.kdnuggets.com/2022/09/7-things-didnt-know-could-low-code-tool.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你不知道的 7 件低代码工具的用法](https://www.kdnuggets.com/2022/09/7-things-didnt-know-could-low-code-tool.html)'
- en: '[Things Aren''t Always Normal: Some of the "Other" Distributions](https://www.kdnuggets.com/2023/01/things-arent-always-normal-distributions.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[事物并非总是正常的：一些“其他”分布](https://www.kdnuggets.com/2023/01/things-arent-always-normal-distributions.html)'
