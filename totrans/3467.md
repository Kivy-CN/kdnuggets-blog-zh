# 标准模型拟合方法的简要概述

> 原文：[https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html](https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html)

为了说明估计模型参数的不同方法之间的差异，让我们看一个具体的例子：普通最小二乘法（OLS）线性回归。下面的插图将作为快速回顾，以帮助记忆简单线性回归模型的不同组成部分：

![简单回归](../Images/021416dd372001b2ebcefd88bc666f0c.png)

在普通最小二乘法（OLS）线性回归中，我们的目标是找到一条线（或超平面），使得垂直偏移最小。换句话说，我们将最佳拟合线定义为使得目标变量（y）和我们对所有样本的预测输出之间的平方误差和（SSE）或均方误差（MSE）最小的线，其中*i*表示数据集中样本的编号，*n*为样本总数。

![SSE](../Images/fd700aecb123fddccbe1855cb4f39dc2.png)

现在，我们可以使用以下方法之一实现一个线性回归模型来执行普通最小二乘法回归：

+   解析地求解模型参数（封闭形式的方程）

+   使用优化算法（梯度下降法、随机梯度下降法、牛顿法、单纯形法等）

### 1) 正规方程（封闭形式解）

对于“较小”的数据集，封闭形式的解可能（应该）更受青睐——如果计算（“昂贵的”）矩阵逆不是问题的话。对于非常大的数据集，或者逆矩阵 XTX 可能不存在的数据集（矩阵是不可逆的或奇异的，例如在完美的多重共线性情况下），应优先考虑GD或SGD方法。线性函数（线性回归模型）定义为：

![线性模型](../Images/18f72e806df0ea656621fbaa5fcd6263.png)

其中*y*是响应变量，*x*是*m*维样本向量，*w*是权重向量（系数向量）。注意，*w0*表示模型的y轴截距，因此*x0=1*。使用封闭形式解（正规方程），我们可以按如下方式计算模型的权重：

![封闭形式](../Images/390bdb586f5ea1904be897034215580a.png)

### 2) 梯度下降法（GD）

使用梯度下降法（GD）优化算法，权重在每个周期后（即遍历训练数据集）逐步更新。

成本函数 *J(⋅)*，即平方误差和（SSE），可以写作：

![J](../Images/9971ba71f72a930fafe670ba77d3c459.png)

权重更新的大小和方向是通过在成本梯度的相反方向上迈出一步来计算的

![dw](../Images/2a8a0c5f09633d23aa090c7a43d83736.png)

其中*η*是学习率。然后在每个周期后，通过以下更新规则更新权重：

![w_upd](../Images/97ab06d282b695cae3a47b50bd05bbdd.png)

其中 Δw 是一个包含每个权重系数 *w* 更新向量的向量，计算方法如下：

![w_upd 解释](../Images/b17273c5b1d049e3c2a73f800eb790f8.png)

从本质上讲，我们可以将梯度下降优化想象成一个徒步旅行者（权重系数），他希望沿着山坡（成本函数）走向山谷（成本最小值），每一步由坡度的陡峭程度（梯度）和徒步者的腿长（学习率）决定。考虑到只有一个权重系数的成本函数，我们可以如下展示这个概念：

![GD 优化](../Images/9ad85c8821ba0a5eef7027278d573d00.png)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 需求

* * *

### 相关阅读

+   [在 Python 中使用标准差移除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)

+   [开发分析追踪的开放标准](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)

+   [k-means 聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)

+   [机器学习中的替代特征选择方法](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)

+   [Python 字符串方法](https://www.kdnuggets.com/2022/12/python-string-methods.html)

+   [每位程序员都应该知道的 11 个 Python 魔法方法](https://www.kdnuggets.com/11-python-magic-methods-every-programmer-should-know)
