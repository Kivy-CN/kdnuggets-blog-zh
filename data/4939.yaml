- en: 'Machine Learning Exercises in Python: An Introductory Tutorial Series'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《Python中的机器学习练习：入门教程系列》
- en: 原文：[https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html](https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html](https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html)
- en: '**By John Wittenauer, Data Scientist.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：John Wittenauer，数据科学家。**'
- en: '**Editor''s note:** This tutorial series was started in September of 2014,
    with the 8 installments coming over the course of 2 years. I only mention this
    to put John''s first paragraph into context, and to assure readers that this informative
    series of tutorials, including all of its code, is as relevant and up-to-date
    today as it was at the time it was written. This is great material, both for anyone
    taking Andrew Ng''s MOOC and as a standalone resource.'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑说明：** 本教程系列于2014年9月开始，8期教程在2年内发布。我提及这一点是为了将约翰的第一段话置于背景中，并向读者保证，这个包括所有代码的系列教程在今天仍然与写作时一样相关和最新。这些资料非常棒，无论是对于参加Andrew
    Ng的MOOC课程的人，还是作为独立资源。'
- en: One of the pivotal moments in my professional development this year came when
    I discovered Coursera. I'd heard of the "MOOC" phenomenon but had not had the
    time to dive in and take a class. Earlier this year I finally pulled the trigger
    and signed up for Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml)
    class. I completed the whole thing from start to finish, including all of the
    programming exercises. The experience opened my eyes to the power of this type
    of education platform, and I've been hooked ever since.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 今年我职业发展中的一个关键时刻是发现了Coursera。我听说过“MOOC”现象，但一直没时间深入学习课程。今年早些时候，我终于下定决心报名参加Andrew
    Ng的[机器学习课程](https://www.coursera.org/course/ml)。我完成了整个课程，包括所有编程练习。这段经历让我认识到了这种教育平台的力量，从此我就迷上了它。
- en: '[![Python exercises](../Images/da01a56ad6eaf310800005885b464145.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python练习](../Images/da01a56ad6eaf310800005885b464145.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)'
- en: '**[Part 1 - Simple Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第1部分 - 简单线性回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)**'
- en: This blog post will be the first in a series covering the programming exercises
    from Andrew's class. One aspect of the course that I didn't particularly care
    for was the use of Octave for assignments. Although Octave/Matlab is a fine platform,
    most real-world "data science" is done in either R or Python (certainly there
    are other languages and tools being used, but these two are unquestionably at
    the top of the list). Since I'm trying to develop my Python skills, I decided
    to start working through the exercises from scratch in Python. The full source
    code is available at [my IPython repo on Github](https://github.com/jdwittenauer/ipython-notebooks).
    You'll also find the data used in these exercises and the original exercise PDFs
    in sub-folders off the root directory if you're interested.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本博客文章将是系列中的第一篇，涵盖Andrew课程中的编程练习。我不太喜欢课程中使用Octave做作业的一个方面。虽然Octave/Matlab是一个很好的平台，但大多数现实世界的“数据科学”都是用R或Python完成的（当然还有其他语言和工具在使用，但这两种毫无疑问位列前茅）。由于我正在努力提高我的Python技能，所以我决定从头开始用Python做这些练习。完整的源代码可以在[我的IPython
    Github仓库](https://github.com/jdwittenauer/ipython-notebooks)找到。如果你感兴趣，你还会在根目录的子文件夹中找到这些练习所用的数据和原始练习PDF。
- en: '**[Part 2 - Multivariate Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-2/)**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第2部分 - 多变量线性回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-2/)**'
- en: In [part 1](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)
    of my series on machine learning in Python, we covered the first part of exercise
    1 in Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml) class.
    In this post we'll wrap up exercise 1 by completing part 2 of the exercise. If
    you recall, in part 1 we implemented linear regression to predict the profits
    of a new food truck based on the population of the city that the truck would be
    placed in. For part 2 we've got a new task - predict the price that a house will
    sell for. The difference this time around is we have more than one dependent variable.
    We're given both the size of the house in square feet, and the number of bedrooms
    in the house. Can we easily extend our previous code to handle multiple linear
    regression? Let's find out!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我关于 Python 机器学习系列的[第1部分](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)中，我们介绍了安德鲁·恩的[机器学习](https://www.coursera.org/course/ml)课程第1部分的内容。在这篇文章中，我们将通过完成第2部分的练习来总结第1部分。如果你还记得，在第1部分中，我们实现了线性回归来预测新食品卡车的利润，这些卡车将被放置在某个城市中。第2部分的任务是预测房屋的销售价格。这次的不同之处在于我们有多个因变量。我们得到的输入包括房屋的平方英尺数以及卧室的数量。我们能否轻松扩展之前的代码来处理多元线性回归？让我们来看看吧！
- en: '[![Python exercises](../Images/21e90d6ac7e5c412887121b27e05b535.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python 练习](../Images/21e90d6ac7e5c412887121b27e05b535.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)'
- en: '**[Part 3 - Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第3部分 - 逻辑回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)**'
- en: In part 2 of the series we wrapped up our implementation of multivariate linear
    regression using gradient descent and applied it to a simple housing prices data
    set. In this post we’re going to switch our objective from predicting a continuous
    value (regression) to classifying a result into two or more discrete buckets (classification)
    and apply it to a student admissions problem. Suppose that you are the administrator
    of a university department and you want to determine each applicant's chance of
    admission based on their results on two exams. You have historical data from previous
    applicants that you can use as a training set. For each training example, you
    have the applicant's scores on two exams and the admissions decision. To accomplish
    this, we're going to build a classification model that estimates the probability
    of admission based on the exam scores using a somewhat confusingly-named technique
    called logistic regression.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在系列的第2部分中，我们总结了使用梯度下降法实现多元线性回归，并将其应用于一个简单的房价数据集。在这篇文章中，我们将目标从预测一个连续值（回归）转变为将结果分类为两个或更多离散类别（分类），并将其应用于学生录取问题。假设你是一个大学部门的管理员，你想根据申请人在两个考试中的成绩来确定每个申请人的录取机会。你有来自先前申请人的历史数据，可以用作训练集。对于每个训练样本，你都有申请人在两个考试中的得分以及录取决策。为此，我们将构建一个分类模型，该模型使用一种名为逻辑回归的稍微让人困惑的技术，根据考试成绩估计录取概率。
- en: '**[Part 4 - Multivariate Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/)**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第4部分 - 多元逻辑回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/)**'
- en: In part three of this series we implemented both simple and regularized logistic
    regression, completing our Python implementation of the second exercise from Andrew
    Ng's machine learning class. There's a limitation with our solution though - it
    only works for binary classification. In this post we'll extend our solution from
    the previous exercise to handle multi-class classification. In doing so, we'll
    cover the first half of exercise 3 and set ourselves up for the next big topic,
    neural networks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本系列的第三部分中，我们实现了简单和正则化逻辑回归，完成了安德鲁·恩机器学习课程第二个练习的 Python 实现。然而，我们的解决方案有一个限制——它仅适用于二分类问题。在这篇文章中，我们将扩展之前练习的解决方案，以处理多类分类问题。在此过程中，我们将涵盖第3部分的前半部分，并为下一个重要话题——神经网络做好准备。
- en: '**[Part 5 - Neural Networks](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/)**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第5部分 - 神经网络](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/)**'
- en: In part four we wrapped up our implementation of logistic regression by extending
    our solution to handle multi-class classification and testing it on the hand-written
    digits data set. Using just logistic regression we were able to hit a classification
    accuracy of about 97.5%, which is reasonably good but pretty much maxes out what
    we can achieve with a linear model. In this blog post we'll again tackle the hand-written
    digits data set, but this time using a feed-forward neural network with backpropagation.
    We'll implement un-regularized and regularized versions of the neural network
    cost function and compute gradients via the backpropagation algorithm. Finally,
    we'll run the algorithm through an optimizer and evaluate the performance of the
    network on the handwritten digits data set.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四部分中，我们通过扩展解决方案来处理多类分类，并在手写数字数据集上进行测试，从而完成了逻辑回归的实现。仅使用逻辑回归，我们就能够达到约 97.5%
    的分类准确率，这相当不错，但几乎达到了线性模型的极限。在这篇博客文章中，我们将再次处理手写数字数据集，但这次使用带有反向传播的前馈神经网络。我们将实现未正则化和正则化的神经网络成本函数版本，并通过反向传播算法计算梯度。最后，我们将通过优化器运行算法，并评估网络在手写数字数据集上的表现。
- en: '**[Part 6 - Support Vector Machines](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-6/)**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第 6 部分 - 支持向量机](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-6/)**'
- en: We're now hitting the home stretch of both the course content and this series
    of blog posts. In this exercise, we'll be using support vector machines (SVMs)
    to build a spam classifier. We'll start with SVMs on some simple 2D data sets
    to see how they work. Then we'll look at a set of email data and build a classifier
    on the processed emails using a SVM to determine if they are spam or not.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正接近课程内容和这系列博客文章的最后阶段。在这个练习中，我们将使用支持向量机（SVM）来构建一个垃圾邮件分类器。我们将从一些简单的二维数据集开始使用
    SVM 以了解其工作原理。然后我们将查看一组电子邮件数据，并利用 SVM 在处理过的邮件上构建分类器，以确定它们是否是垃圾邮件。
- en: '[![Python exercises](../Images/48e7ef6a1d68ca580cc9feb895fefe81.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python 练习](../Images/48e7ef6a1d68ca580cc9feb895fefe81.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)'
- en: '**[Part 7 - K-Means Clustering & PCA](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第 7 部分 - K 均值聚类与 PCA](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)**'
- en: 'We''re now down to the last two posts in this series! In this installment we''ll
    cover two fascinating topics: K-means clustering and principal component analysis
    (PCA). K-means and PCA are both examples of unsupervised learning techniques.
    Unsupervised learning problems do not have any label or target for us to learn
    from to make predictions, so unsupervised algorithms instead attempt to learn
    some interesting structure in the data itself. We''ll first implement K-means
    and see how it can be used it to compress an image. We''ll also experiment with
    PCA to find a low-dimensional representation of images of faces.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在只剩下这系列中的最后两篇文章了！在这一部分中，我们将讨论两个引人入胜的主题：K 均值聚类和主成分分析（PCA）。K 均值和 PCA 都是无监督学习技术的例子。无监督学习问题没有任何标签或目标供我们学习以进行预测，因此无监督算法试图从数据本身中学习一些有趣的结构。我们将首先实现
    K 均值，并看看它如何用于压缩图像。我们还将实验 PCA，以找到人脸图像的低维表示。
- en: '**[Part 8 - Anomaly Detection & Recommendation](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第 8 部分 - 异常检测与推荐](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/)**'
- en: We've now reached the last post in this series! It's been an interesting journey.
    Andrew's class was really well-done and translating it all to python has been
    a fun experience. In this final installment we'll cover the last two topics in
    the course - anomaly detection and recommendation systems. We'll implement an
    anomaly detection algorithm using a Gaussian model and apply it to detect failing
    servers on a network. We'll also see how to build a recommendation system using
    collaborative filtering and apply it to a movie recommendations data set.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经到达这一系列的最后一篇文章！这是一次有趣的旅程。安德鲁的课程做得非常出色，将其全部翻译成 Python 是一次有趣的经历。在这最后一部分中，我们将覆盖课程中的最后两个主题——异常检测和推荐系统。我们将使用高斯模型实现异常检测算法，并将其应用于检测网络上的故障服务器。我们还将看到如何使用协同过滤构建推荐系统，并将其应用于电影推荐数据集。
- en: '**Bio: [John Wittenauer](http://www.johnwittenauer.net/)** ([@jdwittenauer](https://twitter.com/jdwittenauer))
    is a data scientist, engineer, entrepreneur, and technology enthusiast.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [约翰·维滕瑙尔](http://www.johnwittenauer.net/)** ([@jdwittenauer](https://twitter.com/jdwittenauer))
    是一名数据科学家、工程师、企业家和技术爱好者。'
- en: '**Related:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[7 Steps to Mastering Machine Learning With Python](/2015/11/seven-steps-machine-learning-python.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Python 机器学习的 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)'
- en: '[Data Science for Newbies: An Introductory Tutorial Series for Software Engineers](/2017/05/data-science-tutorial-series-software-engineers.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学新手: 软件工程师入门教程系列](/2017/05/data-science-tutorial-series-software-engineers.html)'
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习: 完整详细概述](/2016/10/machine-learning-complete-detailed-overview.html)'
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT 管理'
- en: '* * *'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[入门 Pandas 教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来...](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
