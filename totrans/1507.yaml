- en: Your Guide to Natural Language Processing (NLP)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您的自然语言处理（NLP）指南
- en: 原文：[https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html](https://www.kdnuggets.com/2019/05/guide-natural-language-processing-nlp.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Diego Lopez Yse](https://twitter.com/LopezYse), Moody''s Operations LATAM**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Diego Lopez Yse](https://twitter.com/LopezYse)，穆迪拉丁美洲运营部**。'
- en: '![](../Images/fbc813c836c8dc6c3bb83c0cc408e48a.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbc813c836c8dc6c3bb83c0cc408e48a.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Everything we express (either verbally or in written) carries huge amounts of
    information. The topic we choose, our tone, our selection of words, everything
    adds some type of information that can be interpreted and value extracted from
    it. In theory, we can understand and even predict human behaviour using that information.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们表达的一切（无论是口头还是书面）都携带大量信息。我们选择的话题、语调、词汇选择，一切都添加了一些可以解释并从中提取价值的信息。从理论上讲，我们可以利用这些信息理解甚至预测人类行为。
- en: 'But there is a problem: one person may generate hundreds or thousands of words
    in a declaration, each sentence with its corresponding complexity. If you want
    to scale and analyze several hundreds, thousands or millions of people or declarations
    in a given geography, then the situation is unmanageable.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但也存在一个问题：一个人可能在声明中生成数百或数千个词，每个句子都有其相应的复杂性。如果你想在某个地理区域内扩展并分析数百、数千或数百万人的声明，那么情况将变得无法管理。
- en: Data generated from conversations, declarations or even tweets are examples
    of unstructured data. **Unstructured data** doesn’t fit neatly into the traditional
    row and column structure of relational databases, and represent the vast majority
    of data available in the actual world. It is messy and hard to manipulate. Nevertheless,
    thanks to the advances in disciplines like machine learning a big revolution is
    going on regarding this topic. Nowadays it is no longer about trying to interpret
    a text or speech based on its keywords (the old fashioned mechanical way), but
    about understanding the meaning behind those words (the cognitive way). This way
    it is possible to detect figures of speech like irony, or even perform sentiment
    analysis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从对话、声明甚至推文中生成的数据是非结构化数据的例子。**非结构化数据**无法整齐地适配关系数据库的传统行列结构，并且代表了现实世界中绝大多数的数据。这些数据混乱且难以操作。然而，感谢像机器学习这样的学科的进步，关于这一话题正在发生一场大革命。如今，不再是基于关键词（传统机械方式）来解释文本或语音，而是理解这些词背后的意义（认知方式）。这样就可以检测到比喻等修辞手法，甚至进行情感分析。
- en: '***Natural Language Processing**** or NLP is a field of Artificial Intelligence
    that gives the machines the ability to read, understand and derive meaning from
    human languages.*'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***自然语言处理***（NLP）是人工智能的一个领域，它赋予机器读取、理解和从人类语言中推导意义的能力。'
- en: It is a discipline that focuses on the interaction between data science and
    human language, and is scaling to lots of industries. Today NLP is booming thanks
    to the huge improvements in the access to data and the increase in computational
    power, which are allowing practitioners to achieve meaningful results in areas
    like healthcare, media, finance and human resources, among others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关注数据科学与人类语言互动的学科，并且正在向许多行业扩展。今天，得益于数据访问的巨大改善和计算能力的提升，NLP正在蓬勃发展，这使得从业者在医疗保健、媒体、金融和人力资源等领域取得了有意义的成果。
- en: '**Use Cases of NLP**'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**NLP的应用场景**'
- en: In simple terms, NLP represents the automatic handling of natural human language
    like speech or text, and although the concept itself is fascinating, the real
    value behind this technology comes from the use cases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，NLP 代表了自然人类语言（如语音或文本）的自动处理，尽管这一概念本身很吸引人，但真正的价值来自于实际应用。
- en: 'NLP can help you with lots of tasks and the fields of application just seem
    to increase on a daily basis. Let’s mention some examples:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: NLP 可以帮助你处理大量任务，应用领域似乎每天都在增加。让我们举几个例子：
- en: NLP enables the recognition and **prediction of diseases **based on electronic
    health records and patient’s own speech. This capability is being explored in
    health conditions that go from cardiovascular diseases to depression and even
    schizophrenia. For example, Amazon Comprehend Medical is a service that uses NLP
    to [extract disease conditions](https://www.thenewsminute.com/article/tech-giants-india-join-ai-bandwagon-focus-healthcare-93833),
    medications and treatment outcomes from patient notes, clinical trial reports
    and other electronic health records.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP 能够基于电子健康记录和患者自身的语言识别和**预测疾病**。这种能力正在用于从心血管疾病到抑郁症甚至精神分裂症的健康状况。例如，Amazon Comprehend
    Medical 是一项使用 NLP 的服务，用于[提取疾病状况](https://www.thenewsminute.com/article/tech-giants-india-join-ai-bandwagon-focus-healthcare-93833)、药物和治疗结果，从患者笔记、临床试验报告及其他电子健康记录中获取信息。
- en: Organizations can determine what customers are saying about a service or product
    by identifying and extracting information in sources like social media. This [**sentiment
    analysis**](https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17)can
    provide a lot of information about customers choices and their decision drivers.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织可以通过在社交媒体等来源中识别和提取信息，确定客户对某项服务或产品的评价。这种[**情感分析**](https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17)可以提供大量关于客户选择及其决策驱动因素的信息。
- en: '[An inventor at IBM developed a **cognitive assistant**](https://www.theatlantic.com/technology/archive/2016/01/sorry-dave-afraid-i-cant-do-that/431559/)that
    works like a personalized search engine by learning all about you and then remind
    you of a name, a song, or anything you can’t remember the moment you need it to.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IBM 的一位发明家开发了一个**认知助手**](https://www.theatlantic.com/technology/archive/2016/01/sorry-dave-afraid-i-cant-do-that/431559/)，它像个个性化的搜索引擎，通过学习关于你的所有信息，提醒你名字、歌曲或任何你在需要时无法记住的东西。'
- en: Companies like Yahoo and Google filter and classify your emails with NLP by
    analyzing text in emails that flow through their servers and **stopping spam**before
    they even enter your inbox.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 Yahoo 和 Google 这样的公司通过 NLP 对电子邮件进行过滤和分类，分析通过其服务器流动的邮件文本，并在邮件进入你的收件箱之前**阻止垃圾邮件**。
- en: To help **identifying fake news**, the [NLP Group at MIT](http://nlp.csail.mit.edu/)developed
    a new system to determine if a source is accurate or politically biased, detecting
    if a news source can be trusted or not.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了帮助**识别假新闻**，[麻省理工学院的 NLP 组](http://nlp.csail.mit.edu/)开发了一种新系统来判断一个来源是否准确或有政治偏见，检测新闻来源是否值得信赖。
- en: Amazon’s Alexa and Apple’s Siri are examples of intelligent **voice driven interfaces**that
    use NLP to respond to vocal prompts and do everything like find a particular shop,
    tell us the weather forecast, suggest the best route to the office or turn on
    the lights at home.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊的 Alexa 和苹果的 Siri 是使用 NLP 的智能**语音驱动界面**的例子，它们响应语音提示，完成诸如寻找特定商店、告诉我们天气预报、建议最佳办公路线或打开家里的灯等任务。
- en: 'Having an insight into what is happening and what people are talking about
    can be very valuable to [**financial traders**](https://news.efinancialcareers.com/nl-en/331386/charles-elkan-goldman-sachs-machine-learning).
    NLP is being used to track news, reports, comments about possible mergers between
    companies, everything can be then incorporated into a trading algorithm to generate
    massive profits. Remember: buy the rumor, sell the news.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解正在发生的事情和人们在谈论什么对[**金融交易员**](https://news.efinancialcareers.com/nl-en/331386/charles-elkan-goldman-sachs-machine-learning)来说非常有价值。NLP
    正在用于跟踪新闻、报告、关于公司之间可能合并的评论，一切都可以纳入交易算法以产生巨额利润。记住：买谣言，卖新闻。
- en: NLP is also being used in both the search and selection phases of [**talent
    recruitment**](https://www.forbes.com/sites/forbeshumanresourcescouncil/2018/09/27/how-ai-makes-recruiting-more-human/#7531fc116ba4),
    identifying the skills of potential hires and also spotting prospects before they
    become active on the job market.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP 也在 [**人才招聘**](https://www.forbes.com/sites/forbeshumanresourcescouncil/2018/09/27/how-ai-makes-recruiting-more-human/#7531fc116ba4)
    的搜索和筛选阶段中得到了应用，识别潜在雇员的技能，并在他们还未进入就业市场时就能发现他们。
- en: Powered by IBM Watson NLP technology, [LegalMation](https://www.legalmation.com/)developed
    a platform to automate routine** litigation tasks** and help legal teams save
    time, drive down costs and shift strategic focus.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由IBM Watson NLP技术驱动的 [LegalMation](https://www.legalmation.com/) 开发了一个平台，以自动化常规**诉讼任务**，帮助法律团队节省时间、降低成本，并转移战略重点。
- en: NLP is particularly booming in the **healthcare industry**. This technology
    is improving care delivery, disease diagnosis and bringing costs down while healthcare
    organizations are going through a growing adoption of electronic health records.
    The fact that clinical documentation can be improved means that patients can be
    better understood and benefited through better healthcare. The goal should be
    to optimize their experience, and several organizations are already working on
    this.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: NLP 在 **医疗行业** 特别蓬勃发展。这项技术正在改善护理服务、疾病诊断，并降低成本，同时医疗组织也在逐步采用电子健康记录。临床文档的改进意味着患者可以通过更好的医疗服务得到更好的理解和照顾。目标应是优化患者体验，许多组织已经在致力于此。
- en: '![](../Images/d488f02f8a32cceea5f6df26d4df9ef6.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d488f02f8a32cceea5f6df26d4df9ef6.png)'
- en: Number of publications containing the sentence “natural language processing”
    in PubMed in the period 1978–2018\. As of 2018, PubMed comprised more than 29
    million citations for biomedical literature
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在1978-2018年期间，PubMed中包含“自然语言处理”这一句子的出版物数量。截至2018年，PubMed包含超过2900万条生物医学文献的引用。
- en: Companies like [Winterlight Labs](https://winterlightlabs.com/) are making huge
    improvements in the treatment of Alzheimer’s disease by monitoring cognitive impairment
    through speech and they can also support clinical trials and studies for a wide
    range of central nervous system disorders. Following a similar approach, Stanford
    University developed [Woebot](https://woebot.io/), a **chatbot therapist** with
    the aim of helping people with anxiety and other disorders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 像 [Winterlight Labs](https://winterlightlabs.com/) 这样的公司通过语音监测认知障碍在阿尔茨海默病治疗方面取得了巨大进展，它们还可以支持临床试验和针对各种中枢神经系统疾病的研究。斯坦福大学也采用了类似的方法，开发了
    [Woebot](https://woebot.io/)，一个 **聊天机器人治疗师**，旨在帮助有焦虑症和其他疾病的患者。
- en: But serious [controversy](https://www.bmj.com/content/358/bmj.j3159) is around
    the subject. A couple of years ago Microsoft demonstrated that by analyzing large
    samples of search engine queries, they could [identify internet users who were
    suffering from pancreatic cancer](https://www.nytimes.com/2016/06/08/technology/online-searches-can-identify-cancer-victims-study-finds.html) even
    before they have received a diagnosis of the disease. How would users react to
    such diagnosis? And what would happen if you were tested as a false positive?
    (meaning that you can be diagnosed with the disease even though you don’t have
    it). This recalls the case of Google Flu Trends which in 2009 was announced as
    being able to predict influenza but later on vanished due to its low accuracy
    and inability to meet its projected rates.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但围绕这一主题存在严重的 [争议](https://www.bmj.com/content/358/bmj.j3159)。几年前，微软展示了通过分析大量搜索引擎查询，他们能够
    [识别出那些患有胰腺癌的互联网用户](https://www.nytimes.com/2016/06/08/technology/online-searches-can-identify-cancer-victims-study-finds.html)，即使在他们还未收到疾病诊断之前。用户对这样的诊断会有何反应？如果你被测试为假阳性（即被诊断为患有该疾病，但实际上并未患病）会发生什么？这让人想起2009年Google
    Flu Trends的案例，虽然当时宣称能够预测流感，但由于准确性低和未能达到预期水平，后来消失了。
- en: NLP may be the key to an effective clinical support in the future, but there
    are still many challenges to face in the short term.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: NLP 可能是未来有效临床支持的关键，但短期内仍面临许多挑战。
- en: '**Basic NLP to impress your non-NLP friends**'
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**基础NLP以给你的非NLP朋友留下深刻印象**'
- en: 'The main drawbacks we face these days with NLP relate to the fact that language
    is very tricky. The process of understanding and manipulating language is extremely
    complex, and for this reason it is common to use different techniques to handle
    different challenges before binding everything together. Programming languages
    like Python or R are highly used to perform these techniques, but before diving
    into code lines (that will be the topic of a different article), it’s important
    to understand the concepts beneath them. Let’s summarize and explain some of the
    most frequently used algorithms in NLP when defining the vocabulary of terms:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当前我们在自然语言处理（NLP）中面临的主要缺点与语言本身的复杂性有关。理解和处理语言的过程极其复杂，因此通常使用不同的技术来应对不同的挑战，然后再将所有内容整合在一起。像Python或R这样的编程语言被广泛用于执行这些技术，但在深入代码行之前（那将是另一篇文章的主题），理解其背后的概念非常重要。让我们总结并解释一些在NLP中定义术语词汇时最常用的算法：
- en: '**Bag of Words**'
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**词袋模型**'
- en: Is a commonly used model that allows you to count all words in a piece of text.
    Basically it creates an occurrence matrix for the sentence or document, disregarding
    grammar and word order. These word frequencies or occurrences are then used as
    features for training a classifier.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 是一种常用的模型，允许你计算文本中的所有词汇。基本上，它为句子或文档创建一个出现矩阵，不考虑语法和词序。这些词频或出现次数随后被用作训练分类器的特征。
- en: 'To bring a short example I took the first sentence of the song “Across the
    Universe” from The Beatles:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 举一个简单的例子，我取了The Beatles歌曲“Across the Universe”的第一句：
- en: '*Words are flowing out like endless rain into a paper cup,*'
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Words are flowing out like endless rain into a paper cup,*'
- en: ''
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*They slither while they pass, they slip away across the universe*'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*They slither while they pass, they slip away across the universe*'
- en: 'Now let’s count the words:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们计算这些词：
- en: '![](../Images/cda94d22ba9f20d78ed2e98df51abcaa.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cda94d22ba9f20d78ed2e98df51abcaa.png)'
- en: This approach may reflect several downsides like the absence of semantic meaning
    and context, and the facts that stop words (like “the” or “a”) add noise to the
    analysis and some words are not weighted accordingly (“universe” weights less
    than the word “they”).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能反映出几个缺点，例如缺乏语义意义和上下文，以及停用词（如“the”或“a”）给分析增加噪音，并且一些词的权重不符合实际（例如“universe”权重低于“they”）。
- en: To solve this problem, one approach is to rescale the frequency of words by
    how often they appear in all texts (not just the one we are analyzing) so that
    the scores for frequent words like “the”, that are also frequent across other
    texts, get penalized. This approach to scoring is called **“Term Frequency ****—****Inverse
    Document Frequency****”** **(TFIDF)**, and improves the bag of words by weights.
    Through TFIDF frequent terms in the text are “rewarded” (like the word “they”
    in our example), but they also get “punished” if those terms are frequent in other
    texts we include in the algorithm too. On the contrary, this method highlights
    and “rewards” unique or rare terms considering all texts. Nevertheless, this approach
    still has no context nor semantics.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是根据词在所有文本中出现的频率（而不仅仅是我们正在分析的文本）来重新缩放词频，以便像“the”这样的高频词在其他文本中也很常见，因此会受到惩罚。这种评分方法被称为**“词频——逆文档频率”**
    **(TFIDF)**，通过权重改进词袋模型。通过TFIDF，文本中的高频术语（如我们示例中的“they”）会受到“奖励”，但如果这些术语在我们包含在算法中的其他文本中也很频繁，它们也会受到“惩罚”。相反，这种方法突出了并“奖励”独特或稀有的术语，考虑到所有文本。然而，这种方法仍然没有上下文或语义。
- en: '**Tokenization**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**标记化**'
- en: 'Is the process of segmenting running text into sentences and words. In essence,
    it’s the task of cutting a text into pieces called *tokens*, and at the same time
    throwing away certain characters, such as punctuation. Following our example,
    the result of tokenization would be:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 是将连续文本划分为句子和单词的过程。本质上，它是将文本切割成称为*tokens*的片段，同时丢弃某些字符，如标点符号。以我们的示例为例，标记化的结果将是：
- en: '![](../Images/c229250b850f1aecf4712dcebddb9435.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c229250b850f1aecf4712dcebddb9435.png)'
- en: Pretty simple, right? Well, although it may seem quite basic in this case and
    also in languages like English that separate words by a blank space (called segmented
    languages) not all languages behave the same, and if you think about it, blank
    spaces alone are not sufficient enough even for English to perform proper tokenizations.
    Splitting on blank spaces may break up what should be considered as one token,
    as in the case of certain names (e.g. San Francisco or New York) or borrowed foreign
    phrases (e.g. laissez faire).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，对吧？虽然在这种情况下以及在像英语这样通过空格分隔单词的语言（称为分段语言）中这看起来很基本，但并非所有语言都表现相同。即使在英语中，仅靠空格也不足以进行正确的词元化。基于空格的分割可能会破坏应该被视为一个词的内容，例如某些名称（例如旧金山或纽约）或借用的外语短语（例如
    laissez faire）。
- en: '**Tokenization can remove punctuation too**, easing the path to a proper word
    segmentation but also triggering possible complications. In the case of periods
    that follow abbreviation (e.g. dr.), the period following that abbreviation should
    be considered as part of the same token and not be removed.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**词元化也可以去除标点符号**，简化正确的词分割路径，但也可能引发一些问题。例如，在缩写（例如 dr.）之后的句点应视为同一个词的一部分，而不是被去除。'
- en: The tokenization process can be particularly problematic when dealing with biomedical
    text domains which contain lots of hyphens, parentheses, and other punctuation
    marks.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理包含大量连字符、括号和其他标点符号的生物医学文本领域时，词元化过程可能会特别棘手。
- en: For deeper details on tokenization, you can find a great explanation in [this
    article](https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有关词元化的更详细信息，可以在 [这篇文章](https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en)中找到很好的解释。
- en: '**Stop Words Removal**'
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**停用词移除**'
- en: Includes getting rid of common language articles, pronouns and prepositions
    such as “and”, “the” or “to” in English. In this process some very common words
    that appear to provide little or no value to the NLP objective are filtered and
    excluded from the text to be processed, hence removing widespread and frequent
    terms that are not informative about the corresponding text.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 包括去除诸如“and”，“the”或“to”这样的常见语言文章、代词和介词。在这个过程中，一些非常常见的词汇因提供的价值很小或没有价值而被过滤和排除，从而去除了那些不提供关于相应文本信息的广泛和频繁的术语。
- en: Stop words can be safely ignored by carrying out a lookup in a pre-defined list
    of keywords, freeing up database space and improving processing time.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在预定义的关键词列表中进行查找，可以安全地忽略停用词，从而释放数据库空间并提高处理速度。
- en: '**There is no universal list of stop words**. These can be pre-selected or
    built from scratch. A potential approach is to begin by adopting pre-defined stop
    words and add words to the list later on. Nevertheless it seems that the general
    trend over the past time has been to go from the use of large standard stop word
    lists to the use of no lists at all.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有通用的停用词列表**。这些词可以是预先选定的，也可以从头开始建立。一种潜在的方法是首先采用预定义的停用词，然后在后续添加词汇。不过，过去一段时间的总体趋势似乎是从使用大型标准停用词列表转向完全不使用列表。'
- en: The thing is stop words removal can wipe out relevant information and modify
    the context in a given sentence. For example, if we are performing a sentiment
    analysis we might throw our algorithm off track if we remove a stop word like
    “not”. Under these conditions, you might select a minimal stop word list and add
    additional terms depending on your specific objective.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，停用词的去除可能会抹去相关信息并修改给定句子的上下文。例如，如果我们正在进行情感分析，移除像“not”这样的停用词可能会使我们的算法偏离轨道。在这种情况下，你可能需要选择一个最小的停用词列表，并根据具体目标添加额外的词汇。
- en: '**Stemming**'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**词干提取**'
- en: Refers to the process of slicing the end or the beginning of words with the
    intention of removing affixes (lexical additions to the root of the word).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 指的是对单词的开头或结尾进行切割，以去除词缀（附加在词根上的词汇）。
- en: '*Affixes that are attached at the beginning of the word are called prefixes (e.g.
    “astro” in the word “astrobiology”) and the ones attached at the end of the word
    are called suffixes (e.g. “ful” in the word “helpful”).*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*附加在单词开头的词缀称为前缀*（例如，“astrobi”中的“astro”），*而附加在单词结尾的词缀称为后缀*（例如，“helpful”中的“ful”）。'
- en: The problem is that affixes can create or expand new forms of the same word
    (called *inflectional* affixes), or even create new words themselves (called *derivational* affixes).
    In English, prefixes are always derivational (the affix creates a new word as
    in the example of the prefix “eco” in the word “ecosystem”), but suffixes can
    be derivational (the affix creates a new word as in the example of the suffix
    “ist” in the word “guitarist”) or inflectional (the affix creates a new form of
    word as in the example of the suffix “er” in the word “faster”).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是词缀可以创建或扩展同一单词的新形式（称为*屈折*词缀），甚至可以创造新词（称为*派生*词缀）。在英语中，前缀总是派生的（词缀创造了一个新词，如“ecosystem”中的前缀“eco”），但后缀可以是派生的（词缀创造了一个新词，如“guitarist”中的后缀“ist”）或屈折的（词缀创建了一个新形式的词，如“faster”中的后缀“er”）。
- en: Ok, so how can we tell the difference and chop the right bit?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那我们如何分辨差异并切割正确的部分呢？
- en: '![](../Images/1608f7938632b5f6fc5c9937e9d17b4e.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1608f7938632b5f6fc5c9937e9d17b4e.png)'
- en: A possible approach is to consider a list of common affixes and rules (Python
    and R languages have different libraries containing affixes and methods) and perform
    stemming based on them, but of course this approach presents limitations. Since
    stemmers use algorithmics approaches, the result of the stemming process may not
    be an actual word or even change the word (and sentence) meaning. To offset this
    effect you can edit those predefined methods by adding or removing affixes and
    rules, but you must consider that you might be improving the performance in one
    area while producing a degradation in another one. Always look at the whole picture
    and test your model’s performance.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的方法是考虑常见的词缀和规则列表（Python 和 R 语言有不同的库包含词缀和方法），并基于这些词缀进行词干提取，但这种方法当然存在局限性。由于词干提取器使用算法方法，词干提取的结果可能不是实际的单词，甚至可能改变单词（和句子）的含义。为了抵消这种影响，你可以通过添加或删除词缀和规则来编辑这些预定义的方法，但你必须考虑到，可能在一个领域提高了性能的同时会在另一个领域造成退化。始终关注整体情况，并测试你模型的性能。
- en: So if stemming has serious limitations, why do we use it? First of all, it can
    be used to correct spelling errors from the tokens. **Stemmers are simple to use
    and run very fast** (they perform simple operations on a string), and if speed
    and performance are important in the NLP model, then stemming is certainly the
    way to go. Remember, we use it with the objective of improving our performance,
    not as a grammar exercise.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果词干提取有严重的局限性，为什么我们还要使用它呢？首先，它可以用来纠正标记中的拼写错误。**词干提取器使用简单，运行非常快**（它们对字符串执行简单操作），如果速度和性能在自然语言处理模型中很重要，那么词干提取无疑是值得使用的。记住，我们使用它的目标是提高性能，而不是作为语法练习。
- en: '**Lemmatization**'
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**词形还原**'
- en: Has the objective of reducing a word to its base form and grouping together
    different forms of the same word. For example, verbs in past tense are changed
    into present (e.g. “went” is changed to “go”) and synonyms are unified (e.g. “best”
    is changed to “good”), hence standardizing words with similar meaning to their
    root. Although it seems closely related to the stemming process, lemmatization
    uses a different approach to reach the root forms of words.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 其目标是将单词还原为基本形式，并将同一单词的不同形式进行归类。例如，将过去时态的动词转换为现在时态（例如，“went”变为“go”），并将同义词统一（例如，“best”变为“good”），从而将具有相似含义的词标准化为其根词。虽然这与词干提取过程密切相关，但词形还原采用了不同的方法来获取词的根形式。
- en: '*Lemmatization resolves words to their dictionary form (known as **lemma**)
    for which it requires detailed dictionaries in which the algorithm can look into
    and link words to their corresponding lemmas.*'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*词形还原将单词解析为其词典形式（称为**词根**），这需要详细的词典，以便算法可以查找并将单词链接到相应的词根。*'
- en: For example, the words “*running”, “runs”* and *“ran”* are all forms of the
    word “*run”*, so “*run”* is the lemma of all the previous words.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，单词“*running*”、“*runs*”和“*ran*”都是单词“*run*”的形式，因此“*run*”是所有这些单词的词根。
- en: '![](../Images/db52d4f3acf412f2fc2968068d3a82b8.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db52d4f3acf412f2fc2968068d3a82b8.png)'
- en: Lemmatization also takes into consideration the context of the word in order
    to **solve other problems like disambiguation**, which means it can discriminate
    between identical words that have different meanings depending on the specific
    context. Think about words like “bat” (which can correspond to the animal or to
    the metal/wooden club used in baseball) or “bank” (corresponding to the financial
    institution or to the land alongside a body of water). By providing a part-of-speech
    parameter to a word ( whether it is a noun, a verb, and so on) it’s possible to
    define a role for that word in the sentence and remove disambiguation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原还考虑了单词的上下文，以**解决其他问题，如消歧义**，这意味着它可以区分在特定上下文中具有不同含义的相同单词。考虑像“bat”（可以指动物，也可以指棒球中的金属/木质棒）或“bank”（可以指金融机构，也可以指水体旁边的土地）这样的单词。通过为单词提供一个词性参数（例如，它是名词、动词等），可以为该单词在句子中定义一个角色，并消除歧义。
- en: As you might already pictured, lemmatization is a much more resource-intensive
    task than performing a stemming process. At the same time, since it requires more
    knowledge about the language structure than a stemming approach, it **demands
    more computational power **than setting up or adapting a stemming algorithm.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经想象的，词形还原（lemmatization）是一个比词干提取（stemming）过程更加资源密集的任务。与此同时，由于它比词干提取方法需要更多关于语言结构的知识，它**需要比设置或调整词干提取算法更多的计算能力**。
- en: '**Topic Modeling**'
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**主题建模**'
- en: Is as a method for uncovering hidden structures in sets of texts or documents.
    In essence it clusters texts to discover latent topics based on their contents,
    processing individual words and assigning them values based on their distribution.
    This technique is based on the assumptions that each document consists of a mixture
    of topics and that each topic consists of a set of words, which means that if
    we can spot these hidden topics we can unlock the meaning of our texts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种揭示文本或文档集隐藏结构的方法，本质上，它将文本进行聚类，以发现基于其内容的潜在主题，处理单独的单词并根据其分布赋予其值。这项技术基于这样的假设：每个文档由一组主题混合组成，每个主题由一组单词组成，这意味着如果我们能发现这些隐藏的主题，就能解锁我们文本的含义。
- en: 'From the universe of topic modelling techniques, **Latent Dirichlet Allocation
    (LDA)** is probably the most commonly used. This relatively new algorithm (invented
    less than 20 years ago) works as an unsupervised learning method that discovers
    different topics underlying a collection of documents. In **unsupervised learning **methods
    like this one, there is no output variable to guide the learning process and data
    is explored by algorithms to find patterns. To be more specific, LDA finds groups
    of related words by:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在主题建模技术的宇宙中，**潜在狄利克雷分配（LDA）**可能是最常用的。这种相对较新的算法（发明不到20年前）作为一种无监督学习方法，发现一组文档中的不同主题。在像这样的**无监督学习**方法中，没有输出变量来指导学习过程，数据由算法探索以寻找模式。更具体地说，LDA通过以下方式找到相关单词的组：
- en: Assigning each word to a random topic, where the user defines the number of
    topics it wishes to uncover. You don’t define the topics themselves (you define
    just the number of topics) and the algorithm will map all documents to the topics
    in a way that words in each document are mostly captured by those imaginary topics.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个单词分配给一个随机主题，用户定义其希望揭示的主题数量。你不定义主题本身（你只定义主题的数量），算法将以一种方式将所有文档映射到这些主题中，使得每个文档中的单词大多由这些虚拟主题捕获。
- en: The algorithm goes through each word iteratively and reassigns the word to a
    topic taking into considerations the probability that the word belongs to a topic,
    and the probability that the document will be generated by a topic. These probabilities
    are calculated multiple times, until the convergence of the algorithm.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该算法通过迭代地处理每个单词，并根据单词属于某个主题的概率以及文档由某个主题生成的概率来重新分配单词。这些概率会被计算多次，直到算法收敛为止。
- en: Unlike other clustering algorithms like [*K-means*](https://towardsdatascience.com/the-anatomy-of-k-means-c22340543397) that
    perform hard clustering (where topics are disjointed), LDA assigns each document
    to a mixture of topics, which means that each document can be described by one
    or more topics (e.g. Document 1 is described by 70% of topic A, 20% of topic B
    and 10% of topic C) and reflect more realistic results.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 与执行硬聚类（即主题是分离的）的其他聚类算法如[*K-means*](https://towardsdatascience.com/the-anatomy-of-k-means-c22340543397)不同，LDA将每个文档分配到多个主题的混合中，这意味着每个文档可以由一个或多个主题来描述（例如，文档1由70%的主题A、20%的主题B和10%的主题C来描述），并且能反映更现实的结果。
- en: '![](../Images/99eacccff44debcd7badd73879846b96.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99eacccff44debcd7badd73879846b96.png)'
- en: Topic modeling is extremely useful for classifying texts, building recommender
    systems (e.g. to recommend you books based on your past readings) or even detecting
    trends in online publications.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 主题建模对于分类文本、构建推荐系统（例如，根据你过去的阅读推荐书籍）甚至检测在线出版物中的趋势非常有用。
- en: '**How does the future look like?**'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**未来的前景如何？**'
- en: At the moment NLP is battling to detect nuances in language meaning, whether
    due to lack of context, spelling errors or dialectal differences.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，NLP正面临检测语言意义细微差别的挑战，无论是由于缺乏上下文、拼写错误还是方言差异。
- en: 'On March 2016 Microsoft launched *Tay*, an Artificial Intelligence (AI) chatbot
    released on Twitter as a NLP experiment. The idea was that as more users conversed
    with Tay, the smarter it would get. Well, the result was that after 16 hours Tay
    had to be removed due to its racist and abusive comments:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年3月，微软推出了*Tay*，这是一个在Twitter上发布的人工智能（AI）聊天机器人，作为自然语言处理（NLP）实验。其设想是随着更多用户与Tay对话，它会变得越来越聪明。然而，结果是16小时后Tay因其种族主义和侮辱性言论被迫下线：
- en: '![](../Images/47796f4589c4b9f14b3dffde8ac600fd.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47796f4589c4b9f14b3dffde8ac600fd.png)'
- en: '![](../Images/bdf3e47587ee620ca505d589bd9e3a5c.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdf3e47587ee620ca505d589bd9e3a5c.png)'
- en: Microsoft learnt from its own experience and some months later released [*Zo*](https://www.zo.ai/),
    its second generation English-language chatbot that won’t be caught making the
    same mistakes as its predecessor. Zo uses a combination of innovative approaches
    to recognize and generate conversation, and other companies are exploring with
    bots that can remember details specific to an individual conversation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 微软从自身经验中吸取了教训，几个月后推出了[*Zo*](https://www.zo.ai/)，这是其第二代英语聊天机器人，不会犯与前任相同的错误。Zo使用了一系列创新的方法来识别和生成对话，其他公司也在探索能够记住特定对话细节的聊天机器人。
- en: Although the future looks extremely challenging and full of threats for NLP,
    the discipline is developing at a very fast pace (probably like never before)
    and we are likely to reach a level of advancement in the coming years that will
    make complex applications look possible.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管未来对NLP来说充满了极大的挑战和威胁，但该领域的发展速度非常快（可能像从未有过的那样），我们有望在未来几年达到一个让复杂应用变得可能的进展水平。
- en: '[Original](https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1).
    Reposted with permission.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1)。经允许转载。'
- en: '**Bio**: [Diego Lopez Yse](https://twitter.com/LopezYse) is an experienced
    professional with a solid international background acquired in different industries
    (biotechnology, software, consultancy, government, agriculture).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**：[Diego Lopez Yse](https://twitter.com/LopezYse)是一位拥有丰富国际背景的经验丰富的专业人士，曾在生物技术、软件、咨询、政府、农业等不同领域工作。'
- en: '**Resources:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Extracting Knowledge from Knowledge Graphs Using Facebook’s Pytorch-BigGraph](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用Facebook的Pytorch-BigGraph从知识图谱中提取知识](https://www.kdnuggets.com/2019/05/extracting-knowledge-graphs-facebook-pytorch-biggraph.html)'
- en: '[A Complete Exploratory Data Analysis and Visualization for Text Data: Combine
    Visualization and NLP to Generate Insights](https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本数据的完整探索性数据分析和可视化：结合可视化和NLP以生成洞察](https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html)'
- en: '[Build Your First Chatbot Using Python & NLTK](https://www.kdnuggets.com/2019/05/build-chatbot-python-nltk.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 和 NLTK 构建你的第一个聊天机器人](https://www.kdnuggets.com/2019/05/build-chatbot-python-nltk.html)'
- en: More On This Topic
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[N-gram Language Modeling in Natural Language Processing](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[N-gram 语言建模在自然语言处理中的应用](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
- en: '[A Guide to Top Natural Language Processing Libraries](https://www.kdnuggets.com/2023/04/guide-top-natural-language-processing-libraries.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[顶级自然语言处理库指南](https://www.kdnuggets.com/2023/04/guide-top-natural-language-processing-libraries.html)'
- en: '[Natural Language Processing Key Terms, Explained](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理的关键术语解释](https://www.kdnuggets.com/2017/02/natural-language-processing-key-terms-explained.html)'
- en: '[Data Representation for Natural Language Processing Tasks](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理任务的数据表示](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像识别和自然语言处理中的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
- en: '[How to Start Using Natural Language Processing With PyTorch](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 PyTorch 开始自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
