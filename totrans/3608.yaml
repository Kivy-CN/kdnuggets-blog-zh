- en: Adventures in MLOps with Github Actions, Iterative.ai, Label Studio and NBDEV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在MLOps中探索Github Actions、Iterative.ai、Label Studio和NBDEV
- en: 原文：[https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html](https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html](https://www.kdnuggets.com/2021/09/adventures-mlops-github-actions-iterative-ai-label-studio-and-nbdev.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/) & [Will
    Kunz](https://www.linkedin.com/in/willkunz/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/) 和 [Will
    Kunz](https://www.linkedin.com/in/willkunz/)**'
- en: When designing the MLOps stack for our project, we needed a solution that allowed
    for a high degree of customization and flexibility to evolve as our experimentation
    dictated. We considered large platforms that encompassed many functions, but found
    it limiting in some key areas. Ultimately we decided on an approach where separate
    specialized tools were implemented for labeling, data versioning, and continuous
    integration. This article documents our experience building this custom MLOps
    approach.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在为我们的项目设计MLOps堆栈时，我们需要一个解决方案，允许高度的定制和灵活性，以便随着实验的需要而演变。我们考虑了包含许多功能的大型平台，但在一些关键领域感到受限。最终，我们决定采用一种方法，分别实现专用工具用于标注、数据版本控制和持续集成。本文记录了我们构建这种自定义MLOps方法的经验。
- en: '![](../Images/1de6ffdf729c70393d5fa10dec24c761.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1de6ffdf729c70393d5fa10dec24c761.png)'
- en: Photo by [Finding Dan | Dan Grinwis](https://unsplash.com/@finding_dan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/unknown?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Finding Dan | Dan Grinwis](https://unsplash.com/@finding_dan?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来自 [Unsplash](https://unsplash.com/s/photos/unknown?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: NBDEV
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NBDEV
- en: '![](../Images/c7067d28a0d19f6b72674420ae109bc3.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7067d28a0d19f6b72674420ae109bc3.png)'
- en: (Taken from [https://github.com/fastai/nbdev](https://github.com/fastai/nbdev))
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [https://github.com/fastai/nbdev](https://github.com/fastai/nbdev)）
- en: The classic problem using Jupyter for development was moving from prototype
    to production required copy/pasting code from a notebook to a python module. NBDEV
    automates the transition between notebook and module, thus enabling the Jupyter
    notebook to be an official part of a production pipeline. NBDEV allows the developer
    to state which module a notebook should create, which notebook cells to push to
    the module and which notebook cells are tests. A key capability of NBDEV is its
    approach to testing within the notebooks, and the NBDEV template even provides
    a base Github Action to implement testing in the CI/CD framework. The resulting
    Python module requires no editing by the developer, and can easily be integrated
    into other notebooks or the project at large using built-in python import functionality.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Jupyter进行开发的经典问题是，从原型到生产需要将代码从笔记本复制/粘贴到python模块中。NBDEV自动化了笔记本和模块之间的过渡，从而使Jupyter笔记本成为生产管道的官方部分。NBDEV允许开发者指定笔记本应创建哪个模块，哪些笔记本单元格应推送到模块中，以及哪些笔记本单元格是测试。NBDEV的一个关键功能是其在笔记本内测试的方法，NBDEV模板甚至提供了一个基础的Github
    Action，用于在CI/CD框架中实现测试。生成的Python模块不需要开发者编辑，可以使用内置的python导入功能轻松集成到其他笔记本或项目中。
- en: 'Iterative.ai: DVC/CML'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Iterative.ai: DVC/CML'
- en: '![](../Images/8ddbc52ba48451e1af2a6aa73e4bd4eb.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ddbc52ba48451e1af2a6aa73e4bd4eb.png)'
- en: (Taken from [https://iterative.ai/](https://iterative.ai/))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [https://iterative.ai/](https://iterative.ai/)）
- en: The files used in machine learning pipelines are often large archives of binary/compressed
    files, which are not accessible or cost prohibitive for existing version control
    solutions like git. DVC solves data versioning by representing large datasets
    as a hash of the file contents which enables DVC to track changes. It works similar
    to git (e.g. `dvc add`, `dvc push`). When you run `dvc add` on your dataset, it
    gets added to the `.gitignore` and tracked for changes by `dvc`. CML is a project
    that provides functionality for publishing model artifacts from Github Actions
    workflows into comments attached Github Issues, Pull Requests, etc... That is
    important because it helps us start to fill in the gaps in the Pull Requests accounting
    for training data changes and resulting model accuracy and effectiveness.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道中使用的文件通常是大型二进制/压缩文件的归档，这些文件对现有的版本控制解决方案如 git 来说不可访问或成本过高。DVC 通过将大型数据集表示为文件内容的哈希来解决数据版本控制问题，这使得
    DVC 能够跟踪变化。它的工作原理类似于 git（例如 `dvc add`，`dvc push`）。当你在数据集上运行 `dvc add` 时，它会被添加到
    `.gitignore` 并由 `dvc` 跟踪变化。CML 是一个项目，提供了从 Github Actions 工作流发布模型工件到 Github Issues、拉取请求等评论中的功能。这很重要，因为它帮助我们开始填补拉取请求中对训练数据变化以及模型准确性和有效性的记录缺口。
- en: Github Actions
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Github Actions
- en: '![](../Images/986a4058fc9c06b2bca4e15d272a9a31.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/986a4058fc9c06b2bca4e15d272a9a31.png)'
- en: (Taken from [https://github.com/features/actions](https://github.com/features/actions))
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [https://github.com/features/actions](https://github.com/features/actions)）
- en: We want automated code testing, including building models in the automated testing
    pipeline. Github Actions is in competition with CircleCI, Travis, Jenkins, which
    is to automate testing around code pushes, commits, pull requests, etc. Since
    we’re already using Github to host our repos, we avoid another 3rd party app by
    using Actions. In this project we need to use Github self-hosted runners to run
    jobs on an on-prem GPU cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望进行自动化代码测试，包括在自动化测试管道中构建模型。Github Actions 与 CircleCI、Travis、Jenkins 竞争，旨在自动化代码推送、提交、拉取请求等的测试。由于我们已经使用
    Github 托管我们的代码库，因此通过使用 Actions 避免了使用其他第三方应用。在这个项目中，我们需要使用 Github 自托管的运行器在本地 GPU
    集群上运行任务。
- en: Label Studio
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Label Studio
- en: '![](../Images/6fc4d94e308f6e66b77a6e2c52de00ec.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6fc4d94e308f6e66b77a6e2c52de00ec.png)'
- en: (Taken from [https://labelstud.io/](https://labelstud.io/))
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [https://labelstud.io/](https://labelstud.io/)）
- en: We did a deep dive into how we’re using Label Studio found [here](https://towardsdatascience.com/development-of-a-benchmark-dataset-with-an-interface-to-the-fastai-dataloader-using-label-studio-d3aa3c26661f).
    Label Studio is a solution for labeling data. It works well, and is flexible to
    run in a variety of environments.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入研究了如何使用 Label Studio，详细信息见 [这里](https://towardsdatascience.com/development-of-a-benchmark-dataset-with-an-interface-to-the-fastai-dataloader-using-label-studio-d3aa3c26661f)。Label
    Studio 是一个数据标注解决方案。它运行良好，并且灵活，适用于各种环境。
- en: Why use them together?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要将它们一起使用？
- en: The setup is designed to deploy models faster. That means, more data scientists
    working harmoniously in parallel, transparency in the repository and faster onboarding
    time for new people. The goal is to standardize the types of activities that data
    scientists need to do in project and provide clear instructions for them.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该设置旨在加快模型部署速度。这意味着更多的数据科学家可以和谐并行工作，代码库透明，并且新人员的入职时间更快。目标是标准化数据科学家在项目中需要执行的活动类型，并为他们提供明确的指示。
- en: 'The following is a list of tasks we want to streamline with this system design:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们希望通过此系统设计来简化的任务列表：
- en: Automate the ingest from Label Studio and provide a single point for ingesting
    that into the model training and evaluation activities.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动化从 Label Studio 的数据摄取，并提供一个单一的点来将数据摄取到模型训练和评估活动中。
- en: Automated testing on the data pipeline code, that is unit testing and re-deployment
    of containers used by the process.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据管道代码进行自动化测试，即单元测试和重新部署流程使用的容器。
- en: Automated testing on the model code, that is unit testing and re-deployment
    of containers used by the process.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对模型代码进行自动化测试，即单元测试和重新部署流程使用的容器。
- en: Enable automated testing to include model re-training and evaluation criteria.
    When the model code changes, train a model with the new code and compare it to
    the existing incumbent model.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用自动化测试，包括模型的重新训练和评估标准。当模型代码发生变化时，用新代码训练一个模型，并将其与现有的现任模型进行比较。
- en: Trigger model retraining when training data changes.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当训练数据发生变化时触发模型重新训练。
- en: Below is the description of pipeline for each task.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是每个任务的管道描述。
- en: Traditional CI/CD Pipeline
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传统 CI/CD 管道
- en: 'This pipeline implements automated testing feedback for each pull request that
    includes evaluation of syntax, unit, regression and integration tests. The outcome
    of this process is a functionally tested docker image to our private repository.
    This process maximizes the likelihood that the latest best code is in a fully
    tested image available in the repository for downstream tasks. Here’s how the
    developer lifecycle works in the context of a new feature:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道实施了对每个拉取请求的自动化测试反馈，包括语法、单元、回归和集成测试的评估。这个过程的结果是一个功能上经过测试的 Docker 镜像被放入我们的私有存储库中。这个过程最大化了最新的最佳代码在存储库中作为完全测试的镜像用于下游任务的可能性。以下是新特性的开发生命周期在这种背景下的工作方式：
- en: '![](../Images/a4761dfdadbb159032a87bf8245781ca.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4761dfdadbb159032a87bf8245781ca.png)'
- en: Here we show how the workflow function for while editing the code. Using NBDEV
    enables us to work directly from the Jupyter notebooks including writing the tests
    directly in the notebook. NBDEV requires that all the cells in the notebooks run
    without exception (unless the cell is flagged not to run). (Image by Author)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了编辑代码时工作流的功能。使用 NBDEV 使我们可以直接从 Jupyter notebooks 中工作，包括在 notebook 中直接编写测试。NBDEV
    要求 notebooks 中的所有单元格都必须无例外地运行（除非单元格标记为不运行）。 (图片来源：作者)
- en: Data pipeline
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据管道
- en: Label Studio currently lacks event hooks enabling updates on-changes to the
    label data stored. So we take a `cron` triggered approach, updating the dataset
    every hour. Additionally, while the label studio training dataset is small enough,
    the updates can be done as part of the training pipeline as well. We have the
    ability to trigger the data pipeline refresh on demand using the Github Actions
    interface.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Label Studio 目前缺乏事件钩子来启用对存储的标签数据的更改更新。因此，我们采取了 `cron` 触发的方法，每小时更新一次数据集。此外，当标签数据集足够小时，这些更新也可以作为训练管道的一部分进行。我们可以通过
    Github Actions 接口按需触发数据管道刷新。
- en: '![](../Images/576cc3526614e7f27fd041cfba29247a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/576cc3526614e7f27fd041cfba29247a.png)'
- en: The data pipeline feeds from Label Studio, and persists every version of the
    dataset and relevant inputs to the DVC cache stored in AWS S3\. (Image by Author)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道从 Label Studio 读取数据，并将数据集的每个版本及相关输入持久化到存储在 AWS S3 中的 DVC 缓存。 (图片来源：作者)
- en: Model Pipeline
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型管道
- en: The modeling pipeline integrates model training into the CI/CD pipeline for
    the repository. This enables each pull request to evaluate the syntax, unit, integration
    and regression tests configured on the codebase, but also can provide feedback
    that includes evaluating the new resulting model
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 模型管道将模型训练集成到存储库的 CI/CD 管道中。这使得每个拉取请求不仅能评估代码库中配置的语法、单元、集成和回归测试，还能提供评估新生成模型的反馈。
- en: '![](../Images/2a951bf045884ee15bffc2627b7c0e24.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a951bf045884ee15bffc2627b7c0e24.png)'
- en: The workflow in this case, run the model training experiment specified in the
    configuration file (model_params.yaml) and update the model artifact (best-model.pth)
    (Image by Author)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，工作流运行配置文件（model_params.yaml）中指定的模型训练实验，并更新模型工件（best-model.pth）。 (图片来源：作者)
- en: Benchmark Evaluation Pipeline
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准评估管道
- en: The benchmarking pipeline forms an “official submission” process to ensure all
    modeling activities are measured against the metrics of the project.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基准评估管道形成了一个“官方提交”过程，以确保所有建模活动都按照项目的度量标准进行衡量。
- en: '![](../Images/6efd84d0d1769b4a465bcff6626bcd4f.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6efd84d0d1769b4a465bcff6626bcd4f.png)'
- en: The newly trained model in best-model.pth is evaluated against the benchmark
    dataset and the results are tagged with the latest commit hash and persisted in
    AWS S3\. (Image by Author)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 新训练的模型在 best-model.pth 中与基准数据集进行评估，结果会用最新的提交哈希标记并持久化到 AWS S3 中。 (图片来源：作者)
- en: Workflow
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流
- en: Here is the DAG definition file that is used by DVC. It captures the workflow
    steps and their inputs, and allows for reproducibility across users and machines.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 DVC 使用的 DAG 定义文件。它捕获工作流步骤及其输入，并允许在不同用户和机器间进行可重现性。
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Findings
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现
- en: The Github Actions workflow `cron` trigger is not extremely reliable. It does
    not guarantee timing.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Github Actions 工作流的 `cron` 触发器不够可靠。它不能保证定时性。
- en: DVC does not work in a clear manner inside a Github Action workflow that is
    triggered on push. It will alter the trackers that are source controlled and when
    that is committed it will create another Github action.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DVC 在触发的 Github Action 工作流中表现不够清晰。它会更改源控制的跟踪器，当这些更改被提交时，会创建另一个 Github Action。
- en: The Github Actions orchestration as a mechanism to run model requires a self-hosted
    runner to use a GPU. This means connecting to a GPU instance in the cloud or on-prem,
    and this presents issues with access control. For example, we can’t open source
    the exact repo without removing that self-hosted runner configuration from the
    repo or else random people would be able to run workloads on our training server
    by pushing code to the project.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Github Actions 作为运行模型的编排机制需要一个自托管的运行器来使用 GPU。这意味着要连接到云端或本地的 GPU 实例，这会带来访问控制的问题。例如，我们不能公开源代码库而不从代码库中移除自托管运行器的配置，否则随机的人可能会通过推送代码到项目中在我们的训练服务器上运行工作负载。
- en: NBDEV built-in workflow is testing the code in the wrong place. It’s testing
    the notebook instead of the compiled package. On the one hand, it’s nice to be
    able to say that the “tests can be written right into the notebook”. On the other
    hand, testing the notebooks directly tests leaves open the possibility that the
    code package created by NBDEV fails even though the notebook ran. What we need
    is the ability to test the NBDEV-compiled package directly
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NBDEV 内置的工作流是在错误的地方测试代码。它是在笔记本中进行测试，而不是在编译后的包中测试。一方面，能够说“测试可以直接写入笔记本”是很好的。另一方面，直接测试笔记本会留下一个可能性，即
    NBDEV 创建的代码包可能会失败，即使笔记本运行正常。我们需要的是能够直接测试 NBDEV 编译后的包。
- en: NBDEV doesn’t interoperate with “traditional” Python development in the sense
    that NBDEV is a one-way street. It simply allows the project to be developed in
    the interactive Jupyter notebook style. It makes it impossible to develop the
    Python modules directly. If at any point, the project wants to be converted to
    “traditional” Python development testing would need to be accomplished another
    way.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NBDEV 与“传统” Python 开发不兼容，因为 NBDEV 是单向的。它仅允许在互动的 Jupyter 笔记本风格中开发项目。它使得直接开发 Python
    模块变得不可能。如果项目在任何时候想要转换为“传统” Python 开发，测试需要通过其他方式完成。
- en: In the beginning, we were using Weights & Biases as our experiment tracking
    dashboard, however there were issues deploying it into a Github Action. What we
    can say is that the user experience for implementing `wandb` hit its first hiccup
    in the Action Workflow. Removing Weights & Biases resolved the problem straight
    away. Before that, `wandb` stood out as the best user experience in MLOps.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 起初，我们使用 Weights & Biases 作为实验跟踪仪表盘，然而在将其部署到 Github Action 中时遇到了问题。我们可以说，实现 `wandb`
    的用户体验在 Action Workflow 中遇到了第一次障碍。移除 Weights & Biases 立即解决了问题。在那之前，`wandb` 被认为是
    MLOps 中最好的用户体验。
- en: '**Conclusions**'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: 'Ultimately, it took one week to complete the implementation of these tools
    for managing our code with Github Actions, Iterative.ai tools (DVC & CML) and
    NBDEV. This provides us with the following capabilities:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，完成这些工具的实现需要一周时间，这些工具用于使用 Github Actions、Iterative.ai 工具（DVC 和 CML）以及 NBDEV
    来管理我们的代码。这为我们提供了以下能力：
- en: Work from Jupyter notebooks as the system of record for the code. We like Jupyter.
    The main use case it accomplishes is to enable us to work directly on any hardware
    we can SSH into by hosting a Jupyter server there and forwarding it to a desktop.
    To be clear, we would be doing this even if we were not using NBDev because the
    alternative is using Vim or some such tool that we don’t like as much. Past experiments
    to connect to remote servers with VS Code or Pycharm failed. So it’s Jupyter.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Jupyter 笔记本中工作，作为代码的记录系统。我们喜欢 Jupyter。它的主要用例是让我们能够直接在任何可以通过 SSH 访问的硬件上工作，通过在那里托管
    Jupyter 服务器并将其转发到桌面上。需要明确的是，即使我们不使用 NBDev，我们也会这样做，因为替代方案是使用 Vim 或其他我们不那么喜欢的工具。过去用
    VS Code 或 Pycharm 连接到远程服务器的实验失败了。所以我们选择 Jupyter。
- en: Testing the code, and testing the model it creates. Now as part of the CI/CD
    pipeline we can evaluate whether or not the model resulting from the changes to
    the repo make the model better, worse or stay the same. This is all available
    in the pull request before it is merged into `main`.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试代码，并测试它创建的模型。现在作为 CI/CD 流水线的一部分，我们可以评估从代码库的更改中产生的模型是否变得更好、更差或保持不变。这些都可以在合并到
    `main` 之前的拉取请求中完成。
- en: Using Github Actions server as an orchestrator for training runs begins to allow
    multiple data scientists to work simultaneously in a more clear manner. Going
    forward, we will see the limitations of this setup for orchestrating the collaborative
    data science process.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Github Actions 服务器作为训练运行的编排器开始允许多个数据科学家以更清晰的方式同时工作。未来，我们将看到这种设置在编排协作数据科学过程中的局限性。
- en: '**[Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/)** has formerly
    worked as a data scientist and software engineer solving problems in finance,
    predictive maintenance and sports. He currently works as a machine learning systems
    consultant with Hoplabs working on a multi-camera computer vision application.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Aaron Soellinger](https://www.linkedin.com/in/aaronsoellinger/)** 曾作为数据科学家和软件工程师解决金融、预测维护和体育领域的问题。他目前作为
    Hoplabs 的机器学习系统顾问，致力于多摄像头计算机视觉应用的开发。'
- en: '**[Will Kunz](https://www.linkedin.com/in/willkunz/)** is a back end software
    developer, bringing a can-do attitude and dogged determination to challenges.
    It doesn''t matter if it''s tracking down an elusive bug or adapting quickly to
    a new technology. If there''s a solution, Will wants to find it.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Will Kunz](https://www.linkedin.com/in/willkunz/)** 是一名后端软件开发人员，面对挑战时总是展现出积极的态度和顽强的决心。不论是追踪难以捉摸的错误，还是快速适应新技术，Will
    都希望找到解决方案。'
- en: '[Original](https://towardsdatascience.com/machine-learning-lifecycle-with-mlops-github-actions-label-studio-iterative-ai-and-nbdev-30515f444a3e).
    Reposted with permission.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/machine-learning-lifecycle-with-mlops-github-actions-label-studio-iterative-ai-and-nbdev-30515f444a3e)。转载经许可。'
- en: '**Related:**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[MLOps Best Practices](/2021/07/mlops-best-practices.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 最佳实践](/2021/07/mlops-best-practices.html)'
- en: '[MLOps is an Engineering Discipline: A Beginner’s Overview](/2021/07/mlops-engineering-discipline.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 是一种工程学科：初学者概述](/2021/07/mlops-engineering-discipline.html)'
- en: '[MLOps And Machine Learning Roadmap](/2021/08/mlops-machine-learning-roadmap.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 和机器学习路线图](/2021/08/mlops-machine-learning-roadmap.html)'
- en: '* * *'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT 工作'
- en: '* * *'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Schedule & Run ETLs with Jupysql and GitHub Actions](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Jupysql 和 GitHub Actions 调度和运行 ETL](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
- en: '[GitHub Actions For Machine Learning Beginners](https://www.kdnuggets.com/github-actions-for-machine-learning-beginners)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习初学者的 GitHub Actions](https://www.kdnuggets.com/github-actions-for-machine-learning-beginners)'
- en: '[Multi-label NLP: An Analysis of Class Imbalance and Loss Function…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多标签 NLP：类别不平衡和损失函数分析…](https://www.kdnuggets.com/2023/03/multilabel-nlp-analysis-class-imbalance-loss-function-approaches.html)'
- en: '[How You Can Use Machine Learning to Automatically Label Data](https://www.kdnuggets.com/2022/02/machine-learning-automatically-label-data.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用机器学习自动标注数据](https://www.kdnuggets.com/2022/02/machine-learning-automatically-label-data.html)'
- en: '[Run an LLM Locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 LM Studio 运行 LLM](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
- en: '[Using Lightning AI Studio For Free](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费使用 Lightning AI Studio](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
