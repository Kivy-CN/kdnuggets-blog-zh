- en: Data Science Interview Guide
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学面试指南
- en: 原文：[https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2](https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2](https://www.kdnuggets.com/2018/04/data-science-interview-guide.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/04/data-science-interview-guide.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/04/data-science-interview-guide.html?page=2#comments)'
- en: Machine Learning Models
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习模型
- en: 'Now that we have our optimal features, it is now time to train our actual model!
    Machine Learning models fall into one of two camps: Supervised and Unsupervised.
    Supervised Learning is when the tags are available. Unsupervised Learning is when
    the tags are unavailable. Get it? SUPERVISE the tags! Pun intended. That being
    said, **DO NOT MIX UP THE DIFFERENCE BETWEEN SUPERVISED AND UNSUPERVISED LEARNING**!!!
    This mistake is enough for the interviewer to cancel the interview. Also, another
    noob mistake people make is not normalizing the features before running the model.
    While some models are resistant to this issue, a lot of models (like linear regression)
    is very sensitive to scaling. Hence. Rule of Thumb. **ALWAYS NORMALIZE THE FEATURES
    BEFORE USE!!!**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了最佳特征，是时候训练我们的实际模型了！机器学习模型分为两大类：监督学习和无监督学习。监督学习是当标签可用时。无监督学习是当标签不可用时。明白了吗？监督标签！带点双关意味。话虽如此，**千万不要混淆监督学习和无监督学习的区别**！！！这个错误足以让面试官取消面试。此外，另一个新手常犯的错误是运行模型前没有标准化特征。虽然有些模型对这个问题具有抵抗力，但很多模型（如线性回归）对尺度非常敏感。因此，经验法则是：**使用前务必标准化特征！！！**
- en: '**Linear and Logistic Regression**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性与逻辑回归**'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '![](../Images/e232e92acc891efedd7468d7fff58b80.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e232e92acc891efedd7468d7fff58b80.png)'
- en: Linear and Logistic Regression are the most basic and commonly used Machine
    Learning algorithms out there. Before doing any analysis **MAKE SURE YOU DO LINEAR/LOGISTIC
    REGRESSION FIRST AS BENCHMARK!**One common interview blooper people make is starting
    their analysis with a more complex model like Neural Network. No doubt, Neural
    Network is highly accurate. However, benchmarks are important. If your simple
    regression model already has a 98% accuracy and really close to over-fitting,
    getting a more complex model is not a smart move. That being said, linear regression
    is used for continuous targets while logistic regression is used for binary targets
    (mainly because the sigmoid curve forces the feature inputs towards either 0 or
    1).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归和逻辑回归是最基本且最常用的机器学习算法。在进行任何分析之前，**务必先进行线性/逻辑回归作为基准！**一个常见的面试失误是直接从更复杂的模型如神经网络开始分析。神经网络无疑具有很高的准确性。然而，基准测试是重要的。如果你的简单回归模型已经有98%的准确率并且非常接近过拟合，那么使用更复杂的模型并不是明智的选择。值得注意的是，线性回归用于连续目标，而逻辑回归用于二元目标（主要因为
    sigmoid 曲线将特征输入强制到0或1）。
- en: '![](../Images/20939a45745017b32c886765e55b6ea6.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20939a45745017b32c886765e55b6ea6.png)'
- en: I would recommend the derivation of both logistic and linear regression (both
    single variate and multivariate). On top of preparing for the interview, the linear
    regression model is used as the base of a whole range of other machine learning
    models out there. Hence, it is long term investment.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议同时掌握逻辑回归和线性回归（包括单变量和多变量）。除了为面试做准备，线性回归模型还被用作各种其他机器学习模型的基础。因此，这是一项长期投资。
- en: '**Decision Trees and Random Forests**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树与随机森林**'
- en: A slightly more complex model than a linear regression model is the decision
    tree. The decision tree algorithm splits at different feature based on information
    gain, until it hits a pure leaf (i.e. a set of records with only 1 label). A decision
    tree can be made to stop after a certain number of splits to stop it from getting
    pure leafs (common tactic to fix over-fitting problems).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e20328e65d199c954dfda16cf777e68.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: The Information Gain calculated to split the tree is important. **COMMON INTERVIEW
    PROBLEM! ENSURE YOU KNOW HOW INFORMATION GAIN IS CALCULATED!!!** The common Information
    Gain calculation functions are Gini and Entropy.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db440662e7b54fac21f40e19acec35f0.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: What is important in the above curve is that Entropy gives a higher value for
    Information Gain and hence cause more splitting compared to Gini.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/838a4d5884bb85b250b84510beca2142.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: When a Decision Tree isn’t complex enough, a Random Forest is generally used
    (which is nothing more than multiple Decision Trees being grown on a subset of
    the data and a final majority voting is done). Random Forest algorithms can over-fit
    if the number of trees are not determined properly. For more information on decision
    trees, random forest and tree based ensemble models, check out my other blog: [Study
    of Decision Trees and Ensembles on Scikit-Learn](https://medium.com/@sadatnazrul/study-of-decision-trees-and-ensembles-on-scikit-learn-e713a8e532b8)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '**K-Means**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: K-Means is an unsupervised learning model that classifies data points into clusters.
    The number of clusters is provided, causing the model to shift the centroid until
    it iteratively finds the optimal cluster centers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5a152b3d8648eb5af546fdd1ffe5902b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: The number of clusters are determined using an elbow curve.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6c2f2cd6d62a61cb2864eec5857b052d.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: The number of clusters may or may not be easy to find (especially if there isn’t
    a clear kink on the curve). Also, realize that the K-Means algorithm optimizes
    locally and not globally. This means that your clusters will depend on your initialization
    value. The most common initialization value is calculated in K-Means++, where
    the initial values are are far from eachother as possible. For more details on
    K-Means and other forms of unsupervised learning algorithms, check out my other
    blog: [Clustering Based Unsupervised Learning](http://clustering%20based%20unsupervised%20learning/)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Neural Network**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Neural Network is one of those buzz word algorithms that everyone is looking
    towards these days.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38e71abec65408d4423face2f02a98e1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: While it is not possible for me to cover the intricate details on this blog,
    it is important to know the basic mechanisms as well as the concept of back propagation
    and vanishing gradient. It is also important to realize that a Neural Network
    is essentially a black box. If the case study require you to build an interpretive
    model, either pick a different model or be prepared to explain how you will find
    how the weights are contributing to the final result (e.g. the visualization of
    hidden layers during image recognition).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我无法在这个博客上涵盖所有复杂的细节，但了解基本机制以及反向传播和梯度消失的概念是非常重要的。同样重要的是认识到神经网络本质上是一个黑箱。如果案例研究要求你构建一个可解释的模型，选择不同的模型或准备好解释你如何找到权重对最终结果的贡献（例如图像识别过程中隐藏层的可视化）。
- en: '**Ensemble Models**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**集成模型**'
- en: 'Finally, a single model may not accurately determine the target. Certain features
    will need special models. For such circumstances, an ensemble of multiple models
    are used. An example is given below:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，单一模型可能无法准确地确定目标。某些特征需要特殊的模型。在这种情况下，会使用多个模型的集成。以下是一个示例：
- en: '![](../Images/402119ccba64fd8ed9cd92cc0ec9f642.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/402119ccba64fd8ed9cd92cc0ec9f642.png)'
- en: Here, the models are in layers or stacks. The output of each layer is the input
    for the next layer.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，模型以层或堆栈的形式存在。每一层的输出是下一层的输入。
- en: Model Evaluation
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估
- en: '**Classification Score**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类评分**'
- en: '![](../Images/99f4745433a13371f770bfbc82d1d8fc.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99f4745433a13371f770bfbc82d1d8fc.png)'
- en: One of the most common way of evaluating model performance is by calculating
    the percentage of records whose records were predicted accurately.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型性能的最常见方法之一是计算记录被准确预测的百分比。
- en: '**Learning Curve**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习曲线**'
- en: Learning Curve is also a common method for evaluating models. Here, we are looking
    to see if our model is too complex or not complex enough.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线也是评估模型的常见方法。在这里，我们旨在查看我们的模型是否过于复杂或不够复杂。
- en: '![](../Images/f8ba954b1859f0c36fcd968320ab3998.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8ba954b1859f0c36fcd968320ab3998.png)'
- en: 'If the model is not complex enough (e.g. we decided to use a linear regression
    when the pattern is not linear), we end up with high bias and low variance. When
    our model is too complex (e.g. we decided to use a deep neural network for a simple
    problem), we end up with low bias and high variance. High variance because the
    result will VARY as we randomize the training data (i.e. the model is now very
    stable). **DO NOT MIX UP THE DIFFERENCE BETWEEN BIAS AND VARIANCE DURING THE INTERVIEW!!! **Now,
    in order to determine the model’s complexity, we use a learning curve as shown
    below:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型不够复杂（例如我们决定在模式不是线性的情况下使用线性回归），我们会遇到高偏差和低方差的问题。当我们的模型过于复杂（例如我们决定在简单问题上使用深度神经网络）时，会导致低偏差和高方差。高方差是因为结果会随着训练数据的随机化而变化（即模型现在非常不稳定）。**在面试过程中不要混淆偏差和方差的区别！！！**为了确定模型的复杂性，我们使用如下所示的学习曲线：
- en: '![](../Images/13df40a8eb07e8506f2ab0e849d29caf.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13df40a8eb07e8506f2ab0e849d29caf.png)'
- en: On the learning curve, we vary the train-test split on the x-axis and calculate
    the accuracy of the model on the training and validation datasets. If the gap
    between them is too wide, it’s too complex (i.e. over-fitting). If neither one
    of the curves is hitting the desired accuracy and the gap between the curves is
    too small, the dataset is highly biased.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习曲线上，我们在x轴上变化训练-测试分割，并计算模型在训练集和验证集上的准确性。如果它们之间的差距过大，则说明模型过于复杂（即过拟合）。如果曲线中的任何一条都没有达到期望的准确度，而且曲线之间的差距过小，则数据集偏差较大。
- en: '**ROC**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**ROC**'
- en: When dealing with fraud datasets with heavy class imbalance, a classification
    score does not make much sense. Instead, Receiver Operating Characteristic or
    ROC curves offer a better alternative.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理具有严重类别不平衡的欺诈数据集时，分类评分并没有多大意义。相反，接收者操作特征（ROC）曲线提供了更好的替代方案。
- en: '![](../Images/4252f6f09c29106d262ec793d8fb60d5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4252f6f09c29106d262ec793d8fb60d5.png)'
- en: The 45 degree line is the random line, where the Area Under the Curve or AUC
    is 0.5 . The further the curve from this line, the higher the AUC and better the
    model. The highest a model can get is an AUC of 1, where the curve forms a right
    angled triangle. The ROC curve can also help debug a model. For example, if the
    bottom left corner of the curve is closer to the random line, it implies that
    the model is misclassifying at Y=0\. Whereas, if it is random on the top right,
    it implies the errors are occurring at Y=1\. Also, if there are spikes on the
    curve (as opposed to being smooth), it implies the model is not stable. When dealing
    with fraud models, ROC is your best friend.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 45度线是随机线，其中曲线下面积（AUC）为0.5。曲线离此线越远，AUC越高，模型越好。模型的最高AUC值为1，此时曲线形成直角三角形。ROC曲线也可以帮助调试模型。例如，如果曲线的左下角接近随机线，则意味着模型在Y=0时误分类。而如果在右上角是随机的，则意味着错误发生在Y=1。此外，如果曲线有尖峰（而不是平滑），则表明模型不稳定。在处理欺诈模型时，ROC是你的最佳朋友。
- en: Additional Materials
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 额外材料
- en: '[**Stanford Machine Learning | Coursera**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[**斯坦福机器学习 | Coursera**](https://www.coursera.org/specializations/machine-learning)'
- en: '*About this course: Machine learning is the science of getting computers to
    act without being explicitly programmed. In…*www.coursera.org](https://www.coursera.org/learn/machine-learning)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*关于本课程：机器学习是让计算机在没有明确编程的情况下行动的科学。在…*www.coursera.org](https://www.coursera.org/learn/machine-learning)'
- en: '[**University of Washington Machine Learning Specialization | Coursera**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[**华盛顿大学机器学习专业化 | Coursera**](https://www.coursera.org/specializations/machine-learning)'
- en: '*This Specialization from leading researchers at the University of Washington
    introduces you to the exciting…*www.coursera.org](https://www.coursera.org/specializations/machine-learning)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个专业化课程由华盛顿大学的领先研究人员提供，将带你进入令人兴奋的…*www.coursera.org](https://www.coursera.org/specializations/machine-learning)'
- en: '[**Deep Learning Specialization | Coursera**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[**深度学习专业化 | Coursera**](https://www.coursera.org/specializations/deep-learning)'
- en: '*Deep Learning from deeplearning.ai. If you want to break into AI, this Specialization
    will help you do so. Deep…*www.coursera.org](https://www.coursera.org/specializations/deep-learning)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*来自deeplearning.ai的深度学习。如果你想进入人工智能领域，这个专业化将帮助你做到这一点。深度…*www.coursera.org](https://www.coursera.org/specializations/deep-learning)'
- en: '**Bio: [Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/)** is using
    Machine Learning to catch cyber and financial criminals by day... and writing
    cool blogs by night.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/)** 正在利用机器学习来抓捕网络和金融犯罪分子，并在夜晚写有趣的博客。'
- en: '[Original](https://towardsdatascience.com/data-science-interview-guide-4ee9f5dc778).
    Reposted with permission.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/data-science-interview-guide-4ee9f5dc778)。已获授权转载。'
- en: '**Related:**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The Two Sides of Getting a Job as a Data Scientist](/2018/03/two-sides-getting-job-data-scientist.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为数据科学家的两个方面](/2018/03/two-sides-getting-job-data-scientist.html)'
- en: '[How to Survive Your Data Science Interview](/2018/03/survive-data-science-interview.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在数据科学面试中生存](/2018/03/survive-data-science-interview.html)'
- en: '[A Guide to Hiring Data Scientists](/2018/02/guide-hiring-data-scientists.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家招聘指南](/2018/02/guide-hiring-data-scientists.html)'
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试指南 - 第2部分：面试资源](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
- en: '[Interview Kickstart Data Science Interview Course — What Makes It…](https://www.kdnuggets.com/2022/10/interview-kickstart-data-science-interview-course-makes-different.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Interview Kickstart 数据科学面试课程 — 其不同之处](https://www.kdnuggets.com/2022/10/interview-kickstart-data-science-interview-course-makes-different.html)'
- en: '[Data Science Interview Guide - Part 1: The Structure](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试指南 - 第1部分：结构](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-1-structure.html)'
- en: '[KDnuggets News, May 4: 9 Free Harvard Courses to Learn Data…](https://www.kdnuggets.com/2022/n18.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，5月4日：9门免费的哈佛课程来学习数据…](https://www.kdnuggets.com/2022/n18.html)'
- en: '[How to Answer Data Science Coding Interview Questions](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何回答数据科学编程面试问题](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
- en: '[15 Python Coding Interview Questions You Must Know For Data Science](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15个你必须知道的Python编程面试问题](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
