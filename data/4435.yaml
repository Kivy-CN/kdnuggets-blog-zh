- en: Labelling Data Using Snorkel
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Snorkel 标记数据
- en: 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/), [Stefan
    Denkovski](https://www.linkedin.com/in/stefandenkovski/), [Michal Malyska](https://www.linkedin.com/in/malyskamichal/),
    [Sally Moon](https://www.linkedin.com/in/sallysaeyoungmoon/), [Brandon Rufino](https://www.linkedin.com/in/brandon-rufino/),
    [NLP4H](https://nlp4h.com/authors/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/)、[Stefan Denkovski](https://www.linkedin.com/in/stefandenkovski/)、[Michal
    Malyska](https://www.linkedin.com/in/malyskamichal/)、[Sally Moon](https://www.linkedin.com/in/sallysaeyoungmoon/)、[Brandon
    Rufino](https://www.linkedin.com/in/brandon-rufino/)、[NLP4H](https://nlp4h.com/authors/)**
    撰写'
- en: '![Image for post](../Images/e16079ec47d75638df56b6c91eb5db14.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/e16079ec47d75638df56b6c91eb5db14.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this tutorial, we will walk through the process of using Snorkel to generate
    labels for an unlabelled dataset. We will provide you examples of basic Snorkel
    components by guiding you through a real clinical application of Snorkel. Specifically,
    we will use Snorkel to try to boost our results in predicting [Multiple Sclerosis
    (MS) severity scores](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss).
    Enjoy!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将逐步介绍如何使用 Snorkel 为未标记的数据集生成标签。我们将通过引导您完成 Snorkel 在实际临床应用中的基本组件示例，具体来说，我们将使用
    Snorkel 尝试提升预测[多发性硬化症 (MS) 严重程度评分](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)的结果。祝您使用愉快！
- en: '*Check out the *[*Snorkel Intro Tutorial*](https://www.snorkel.org/use-cases/01-spam-tutorial)* for
    a walk through on spam labelling. For more examples of high-performance in real-world
    uses of Snorkel, see *[*Snorkel’s publication list*](https://www.snorkel.org/resources/)*.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看*[*Snorkel 简介教程*](https://www.snorkel.org/use-cases/01-spam-tutorial)*，了解垃圾邮件标记的详细步骤。有关
    Snorkel 在实际应用中的高性能示例，请参阅*[*Snorkel 的出版物列表*](https://www.snorkel.org/resources/)*。*'
- en: '*Check out our other work focused on NLP for MS severity classification *[*here*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看我们其他关于 MS 严重程度分类的 NLP 相关工作*[*这里*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*。*'
- en: What is Snorkel?
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Snorkel 是什么？
- en: 'Snorkel is a system that facilitates the process of building and managing training
    datasets without manual labelling. The first component of a Snorkel pipeline includes
    labelling functions, which are designed to be weak heuristic functions that predict
    a label given unlabelled data. The labelling functions that we developed for MS
    severity score labelling were the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel 是一个简化构建和管理训练数据集过程的系统，无需手动标记。Snorkel 流水线的第一个组件包括标记功能，这些功能旨在作为弱启发式函数，根据未标记的数据预测标签。我们为
    MS 严重程度评分标记开发的标记功能如下：
- en: Multiple key-word searches (using regular expressions) within the text. For
    example, in finding a severity score we searched for the phrase in numeric format
    and in roman numeral format.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在文本中进行多个关键字搜索（使用正则表达式）。例如，在查找严重程度评分时，我们搜索了数字格式和罗马数字格式的短语。
- en: Common baselines such as logistic regression, linear discriminant analysis,
    and support vector machines which were trained using term frequency-inverse document
    frequency (or tf-idf for short) features.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见基准如逻辑回归、线性判别分析和支持向量机，这些基准使用词频-逆文档频率（或简称 tf-idf）特征进行训练。
- en: Word2Vec Convolutional Neural Network (CNN).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Word2Vec 卷积神经网络 (CNN)。
- en: Our MS-BERT classifier described [in this blog post](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的 MS-BERT 分类器在 [这篇博客文章](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)
    中进行了描述。
- en: The second component of the Snorkel pipeline is a generative model that outputs
    a single confidence weighted training label per data point given predictions from
    all the labelling functions. It does this by learning to estimate the accuracy
    and correlations of the labelling functions based on their agreements and disagreements.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel 管道的第二个组件是一个生成模型，它根据所有标注函数的预测输出每个数据点的单个置信度加权训练标签。它通过学习估计标注函数的准确性和相关性来完成此任务，基于它们的一致性和不一致性。
- en: Snorkel Tutorial
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Snorkel 教程
- en: To reiterate, in this article we demonstrate label generation for MS severity
    scores. A common measurement of MS severity is EDSS or the Expanded Disability
    Status Scale. This is a scale that increases from 0 to 10 depending on the severity
    of MS symptoms. We will refer to EDSS in general as the MS severity score but
    for our keen readers we thought we would provide this information. This score
    is further described [here](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 重申一下，在本文中，我们演示了 MS 严重性评分的标签生成。MS 严重性的一种常见测量是 EDSS 或扩展残疾状态量表。这是一个从 0 增加到 10 的量表，具体取决于
    MS 症状的严重程度。我们将 EDSS 通称为 MS 严重性评分，但为了我们的细心读者，我们提供了这些信息。这个评分的详细描述见 [这里](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)。
- en: 'Step 0: Acquire a Dataset'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '步骤 0: 获取数据集'
- en: In our task, we worked with a dataset compiled by a leading MS research hospital,
    containing over *70,000* MS consult notes for about 5000 patients. Of the 70,000
    notes only *16,000* are manually labeled by an expert for MS severity. This means
    that their are approximately *54,000* unlabelled notes. As you may or not be aware,
    having a larger dataset to train models generally lead to better model performance.
    Hence, we used Snorkel to generate what we call ‘silver’ labels for our *54,000* unlabelled
    notes. The *16,000* ‘gold’ labelled notes were used to train our classifiers before
    creating their respective labelling function.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的任务中，我们使用了由领先的 MS 研究医院编制的数据集，该数据集包含超过 *70,000* 个 MS 咨询笔记，涵盖约 5000 名患者。在这
    70,000 个笔记中，只有 *16,000* 个由专家手动标记了 MS 严重性。这意味着大约有 *54,000* 个未标记的笔记。你可能知道，拥有更大的数据集来训练模型通常会带来更好的模型性能。因此，我们使用
    Snorkel 为我们的 *54,000* 个未标记笔记生成了我们称之为“银标签”的标签。这 *16,000* 个“金标签”笔记被用来训练我们的分类器，然后再创建它们各自的标注函数。
- en: 'Step 1: Installing Snorkel'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '步骤 1: 安装 Snorkel'
- en: 'To install Snorkel to your project, you can run the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Snorkel 安装到你的项目中，你可以运行以下命令：
- en: 'Step 2: Adding the Labelling Functions'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '步骤 2: 添加标注函数'
- en: Setting up
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置
- en: 'Labelling functions allow you to define weak heuristics and rules that predict
    a label given unlabelled data. These heuristics can be derived from expert knowledge
    or other labelling models. In the case of MS severity score prediction, our labelling
    functions included: key-word search functions derived from clinicians, baseline
    models trained to predict MS severity scores (tf-idf, word2vec cnn, etc.), and
    our MS-BERT classifier.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 标注函数允许你定义弱启发式和规则，以预测给定未标记数据的标签。这些启发式可以源自专家知识或其他标注模型。在 MS 严重性评分预测的情况下，我们的标注函数包括：从临床医生那里获得的关键词搜索函数、训练预测
    MS 严重性评分的基线模型（tf-idf、word2vec cnn 等），以及我们的 MS-BERT 分类器。
- en: As you will see below, you mark labelling functions by adding “@labeling_function()”
    above the function. For each labelling function, a single row of a dataframe containing
    unlabelled data (i.e. one observation/sample) is passed in. Each labelling function
    applies heuristics or models to obtain a prediction for each row. If the prediction
    is not found, the function abstains (i.e. returns -1).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你将看到的那样，你通过在函数上方添加“@labeling_function()”来标记标注函数。对于每个标注函数，将传入包含未标记数据（即一个观察/样本）的一行数据框。每个标注函数应用启发式或模型来获取每行的预测。如果未找到预测，函数将弃权（即返回
    -1）。
- en: When all labelling functions have been defined, you can make use of the “PandasLFApplier”
    to obtain a matrix of predictions given all labelling functions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有标注函数定义完成后，你可以使用“PandasLFApplier”来获取给定所有标注函数的预测矩阵。
- en: Upon running the following code, you will obtain a (N X num_lfs) L_predictions
    matrix, where N is number of observations in ‘df_unlabelled’ and ‘num_lfs’ is
    the number of labelling functions defined in ‘lfs’.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下代码后，你将获得一个 (N X num_lfs) 的 L_predictions 矩阵，其中 N 是‘df_unlabelled’中的观察数，‘num_lfs’
    是在‘lfs’中定义的标注函数数量。
- en: 'Labelling Function Example #1: Key-Word Search'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '标注函数示例 #1：关键字搜索'
- en: Below shows an example of a key-word search (using regular expressions) used
    to extract MS severity scores recorded in decimal form. The regular expression
    functions are applied to attempt to search for the MS severity score recorded
    in decimal form. If found, the function returns the score in the appropriate output
    format. Else, the function abstains (i.e. returns -1) to indicate that the score
    is not found.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下文展示了一个关键字搜索的示例（使用正则表达式），用于提取以十进制形式记录的MS严重性评分。正则表达式函数用于尝试搜索以十进制形式记录的MS严重性评分。如果找到，函数将以适当的输出格式返回评分。否则，函数将
    abstain（即返回-1），以指示未找到评分。
- en: 'Labelling Function Example #2: Trained Classifier'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '标注函数示例 #2：训练分类器'
- en: Above we see an example using a key-word search. To integrate a trained classifier,
    you must perform one extra step. That is, you must train and export your model
    before creating your labelling function. Here is an example of how we trained
    a logistic regression that was built on top of tf-idf features.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上文展示了一个使用关键字搜索的示例。要集成一个训练好的分类器，你必须额外执行一步。即，你必须在创建标注函数之前训练并导出你的模型。这是一个基于 tf-idf
    特征的逻辑回归模型训练的示例。
- en: 'With the model trained, implementing a labelling function is as simple as this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练好模型后，实现标注函数就简单如是：
- en: 'Step 3(a): Using Snorkel’s Majority Vote'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3(a)：使用 Snorkel 的多数投票
- en: Some would say the simpliest function Snorkel uses to generate a label is ‘Majority
    Vote’. Majority Vote, as the name implies, makes a prediction based on the most
    voted for class.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有人会说，Snorkel 用于生成标签的最简单函数是‘多数投票’。正如名字所示，多数投票基于投票最多的类别做出预测。
- en: To implement Majority Vote you must specify the ‘cardinality’ (i.e. number of
    classes).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现多数投票，你必须指定‘cardinality’（即类别数量）。
- en: 'Step 3(b): Using Snorkel’s Label Model'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3(b)：使用 Snorkel 的标签模型
- en: To take advantage of Snorkel’s full functionality, we used the ‘Label Model’
    to generate a single confidence-weighted label given a matrix of predictions obtained
    from all the labelling functions (i.e. L_unlabelled). The Label Model predicts
    by learning to estimate the accuracy and correlations of the labelling functions
    based on their agreements and disagreements.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用 Snorkel 的功能，我们使用了‘标签模型’来生成一个基于所有标注函数获得的预测矩阵（即 L_unlabelled）的单一置信加权标签。标签模型通过学习估计标注函数的准确性和相关性来进行预测，基于它们的同意和分歧。
- en: You can define a Label Model and specify ‘cardinality’. After you fit the Label
    Model with L_unlabelled, it will generate single predictions for the unlabelled
    data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以定义一个标签模型并指定‘cardinality’。在用 L_unlabelled 训练标签模型后，它将为未标记数据生成单一预测。
- en: 'Step 4: Evaluation Tools'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 4：评估工具
- en: LF Analysis — Coverage, Overlaps, Conflicts
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LF 分析 — 覆盖率、重叠、冲突
- en: To better understand how your labelling functions are functioning, you can make
    use of Snorkel’s LFAnalysis. The LF analysis reports the polarity, coverage, overlap,
    and conflicts of each labelling function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解你的标注函数的功能，你可以利用 Snorkel 的 LFAnalysis。LF 分析报告每个标注函数的极性、覆盖率、重叠和冲突。
- en: 'The definition of these terms are as follows and you can refer to the [Snorkel
    documentation](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities) for
    more information:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语的定义如下，你可以参考 [Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities)
    以获取更多信息：
- en: 'Polarity: Infer the polarities of each LF based on evidence in a label matrix.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 极性：基于标签矩阵中的证据推断每个 LF 的极性。
- en: 'Coverage: Computes the fraction of data points with at least one label.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖率：计算至少有一个标签的数据点比例。
- en: 'Overlap: Computes the fraction of data points with at least two (non-abstain)
    labels.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重叠：计算至少有两个（非 abstain）标签的数据点比例。
- en: 'Conflicts: Computes the fraction of data points each labelling function disagrees
    with at least one other labelling function.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冲突：计算每个标注函数与至少一个其他标注函数意见不一致的数据点比例。
- en: LFAnalysis will provide an analysis of how your labelling functions performed
    relative to each other.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LFAnalysis 将提供关于你的标注函数在相互之间的表现分析。
- en: ‘get_label_buckets’
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`get_label_buckets`'
- en: Snorkel provides some more evaluation tools to help you understand the quality
    of your labelling functions. In particular, ‘get_label_buckets’ is a handy way
    to combine labels and make comparisons. For more information, read the [Snorkel
    documentation](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel提供了一些额外的评估工具，帮助你理解标签函数的质量。特别是，`get_label_buckets`是一个方便的方式来合并标签并进行比较。有关更多信息，请阅读[Snorkel文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html)。
- en: The following code allows you to compare the true labels (y_gold) and predicted
    labels (y_preds) to view data points that were correctly or incorrectly labelled
    by Snorkel. This will allow you to pin-point which data points are difficult to
    correctly label, so that you can fine-tune your labelling functions to cover these
    edge cases.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码允许你比较真实标签（y_gold）和预测标签（y_preds），以查看Snorkel正确或错误标记的数据点。这将帮助你找出哪些数据点难以正确标记，从而调整你的标签函数以涵盖这些边缘案例。
- en: Note, for this analysis we went back and created a L_train matrix which contains
    our labelling function predictions for our ‘gold’ labelled dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于这项分析，我们回到创建了一个包含‘黄金’标签数据集的标签函数预测的L_train矩阵。
- en: Alternatively, you can use ‘get_label_buckets’ to make comparisons between labelling
    functions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你可以使用`get_label_buckets`来比较标签函数。
- en: The following code allows you to compare the label predictions in L_unlabelled
    to observe how different labelling functions label datapoints differently.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码允许你比较L_unlabelled中的标签预测，观察不同标签函数如何以不同方式标记数据点。
- en: 'Step 5: Deployment'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第5步：部署
- en: Choosing the Best Labelling Model to Label Unlabelled Data
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择最佳标签模型以标记未标记的数据
- en: Following the procedure outlined above, we developed various labelling functions
    based on key-word searches, baseline models, and our MS-BERT classifier. We experimented
    with various ensembles of labelling functions and used Snorkel’s Label Model to
    obtain predictions for a held-out labelled dataset. This allowed us to determine
    which ensemble of labelling functions would be best to label our unlabelled dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 按照上述程序，我们基于关键字搜索、基线模型和MS-BERT分类器开发了各种标签函数。我们尝试了不同的标签函数组合，并使用Snorkel的Label Model获得了对保留标签数据集的预测。这使我们能够确定哪个标签函数组合最适合标记我们的未标记数据集。
- en: As shown in the table below, we observed that the MS-BERT classifier (MSBC)
    alone outperformed all ensembles that contain itself by at least 0.02 on Macro-F1\.
    The addition of weaker heuristics and classifiers consistently decreased the ensemble’s
    performance. Furthermore, we observed that the amount of conflict for the MS-BERT
    classifier increased as weaker classifiers and heuristics were added to the ensemble.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如下表所示，我们观察到仅MS-BERT分类器（MSBC）在Macro-F1上比所有包含它的组合表现更好至少0.02。添加较弱的启发式方法和分类器会持续降低组合的性能。此外，我们还观察到随着较弱分类器和启发式方法的添加，MS-BERT分类器的冲突量增加。
- en: '![Figure](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)'
- en: Note, Rule Based (RB) refers to our key-word searches. LDA refers to linear
    discriminant analysis. TFIDFs refer to all models built on top of tf-idf features
    (i.e. logistic regression, linear discriminant analysis, and support vector machines).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，基于规则（RB）指的是我们的关键字搜索。LDA指线性判别分析。TFIDFs指所有基于tf-idf特征构建的模型（即逻辑回归、线性判别分析和支持向量机）。
- en: To understand our findings, we have to remind ourselves that Snorkel’s label
    model learns to predict the accuracy and correlations of the labelling functions
    based on agreements and disagreements amongst each other. Therefore in the presence
    of a strong labelling function, such as our MS-BERT classifier, the addition of
    weaker labelling functions introduces more disagreements with the strong labelling
    functions and therefore decreases performance. From these findings, we learned
    that Snorkel may be more suited for situations where you *only* have weak heuristics
    and rules. However, if you already have a strong labelling function, developing
    a Snorkel ensemble with weaker heuristics may compromise performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解我们的发现，我们必须提醒自己，Snorkel 的标签模型学习根据彼此之间的一致性和分歧来预测标记函数的准确性和相关性。因此，在存在强标记函数（如我们的
    MS-BERT 分类器）的情况下，添加较弱的标记函数会引入更多与强标记函数的分歧，从而降低性能。从这些发现中，我们了解到 Snorkel 可能更适合只有*弱*启发式和规则的情况。然而，如果你已经有了一个强标记函数，开发一个带有较弱启发式的
    Snorkel 集成可能会影响性能。
- en: Therefore, the MS-BERT classifier alone was chosen to label our unlabelled dataset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，MS-BERT 分类器单独被选择用于标记我们的未标记数据集。
- en: Semi-Supervised Labelling Results
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半监督标记结果
- en: 'The MS-BERT classifier was used to obtain ‘silver’ labels for our unlabelled
    dataset. These ‘silver’ labels were combined with our ‘gold’ labels to obtain
    a silver+gold dataset. To infer the quality of the silver labels, new MS-BERT
    classifiers were developed: 1) MS-BERT+ (trained on silver+gold labelled data);
    and 2) MS-BERT-silver (trained on silver labelled data). These classifiers were
    evaluated on a held-out test dataset that was previously used to evaluate our
    original MS-BERT classifier (trained on gold labelled data). MS-BERT+ achieved
    a Macro-F1 of 0.86238 and a Micro-F1 of 0.92569, and MS-BERT-silver achieved a
    Macro-F1 of 0.82922 and a Micro-F1 of 0.91442\. Although their performance was
    slightly lower that our original MS-BERT classifier (Macro-F1 of 0.88296, Micro-F1
    of 0.94177), they still outperformed the previous best baseline models for MS
    severity prediction. The strong results of MS-BERT-silver helps show the effectiveness
    of using our MS-BERT classifier as a labelling function. It demonstrates potential
    to reduce tedious hours required by a professional to read through a patient’s
    consult note and manually generate MS severity scores.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: MS-BERT 分类器被用于为我们的未标记数据集获得“银牌”标签。这些“银牌”标签与我们的“金牌”标签结合，得到了一个银+金数据集。为了推断银牌标签的质量，开发了新的
    MS-BERT 分类器：1) MS-BERT+（在银+金标记数据上训练）；2) MS-BERT-silver（在银标记数据上训练）。这些分类器在之前用于评估我们原始
    MS-BERT 分类器（在金标记数据上训练）的持出测试数据集上进行了评估。MS-BERT+ 达到了 0.86238 的 Macro-F1 和 0.92569
    的 Micro-F1，而 MS-BERT-silver 达到了 0.82922 的 Macro-F1 和 0.91442 的 Micro-F1。尽管它们的表现略低于我们原始
    MS-BERT 分类器（Macro-F1 为 0.88296，Micro-F1 为 0.94177），但仍超越了以前最佳的 MS 严重性预测基准模型。MS-BERT-silver
    的强劲结果有助于展示使用我们的 MS-BERT 分类器作为标记函数的有效性。这表明它有潜力减少专业人员阅读患者咨询笔记并手动生成 MS 严重性评分所需的繁琐时间。
- en: Thank You!
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 感谢！
- en: Thanks for reading everyone! If you have any questions please do not hesitate
    to contact us at nlp4health (at gmail dot) com. :)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢大家的阅读！如果有任何问题，请随时通过 nlp4health (at gmail dot) com 联系我们。 :)
- en: Acknowledgements
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank the researchers and staff at the Data Science and Advanced
    Analytics (DSAA) department, St. Michael’s Hospital, for providing consistent
    support and guidance throughout this project. We would also like to thank Dr.
    Marzyeh Ghassemi, and Taylor Killan for providing us the opportunity to work on
    this exciting project. Lastly, we would like to thank Dr. Tony Antoniou and Dr.
    Jiwon Oh from the MS clinic at St. Michael’s Hospital for their support on the
    neurological examination notes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢圣迈克尔医院数据科学与高级分析（DSAA）部门的研究人员和工作人员，在整个项目过程中提供了一致的支持和指导。我们还要感谢 Marzyeh Ghassemi
    博士和 Taylor Killan，感谢他们给我们提供了参与这个令人兴奋的项目的机会。最后，我们要感谢圣迈克尔医院 MS 门诊的 Tony Antoniou
    博士和 Jiwon Oh 博士，感谢他们对神经检查笔记的支持。
- en: '*Originally published at *[*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/)*.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发布于*[*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/)*。*'
- en: '**Bio: [The authors](https://nlp4h.com/authors/)** are a group of graduate
    students at University of Toronto working on NLP for healthcare.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [作者](https://nlp4h.com/authors/)** 是一组在多伦多大学从事医疗 NLP 研究的研究生。'
- en: '[Original](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f).
    Reposted with permission.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f)。经许可转载。'
- en: '**Related:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Hand labeling is the past. The future is #NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[手工标注已成过去。未来是 #NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)'
- en: '[From Languages to Information: Another Great NLP Course from Stanford](/2020/06/languages-information-another-great-nlp-course-stanford.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从语言到信息：斯坦福大学的另一个出色 NLP 课程](/2020/06/languages-information-another-great-nlp-course-stanford.html)'
- en: '[The Unreasonable Progress of Deep Neural Networks in Natural Language Processing
    (NLP)](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络在自然语言处理（NLP）中的不合理进展](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How to Determine the Best Fitting Data Distribution Using Python](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Python 确定最佳拟合的数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Eurybia 检测数据漂移以确保生产 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[4 Ways Hackers Are Using Data Science to Steal Billions](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑客如何利用数据科学窃取数十亿资金的 4 种方式](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)'
- en: '[Using Data Science to Make Clean Energy More Equitable](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用数据科学使清洁能源更加公平](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何通过使用自动化 EDA 工具来轻松通过数据科学评估测试](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
- en: '[Introduction to Data Visualization Using Matplotlib](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Matplotlib 进行数据可视化介绍](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
