- en: Best Practices to Use OpenAI GPT Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html](https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Best Practices to Use OpenAI GPT Model](../Images/271bbda36d9d64d7bac2fb5621791567.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [rawpixel.com](https://www.freepik.com/free-photo/illustration-quality-product-warranty-assurance-laptop_18122652.htm#query=best%20practice&position=11&from_view=search&track=ais%22)
    on Freepik
  prefs: []
  type: TYPE_NORMAL
- en: Since the release of the GPT model, everyone has been using them constantly.
    From asking simple questions to developing complex coding, the GPT model can help
    the user swiftly. That’s why the model would only get bigger over time.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: To help users get the best output, OpenAI provides their [best practice](https://platform.openai.com/docs/guides/gpt-best-practices)
    for using the GPT model. This comes from the experience as many users have experimented
    with this model constantly and have found what works best.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will summarize the best practices you should know for using
    the OpenAI GPT model. What are these practices? Let’s get into it.
  prefs: []
  type: TYPE_NORMAL
- en: GPT Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GPT model output is only as good as your prompt. With definite instructions
    for what you want, it would provide the result you expected. A few tips to improve
    your GPT output include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Have a detail in the prompt to get relevant answers.** For example, instead
    of the prompt “Give me code to calculate normal distribution”, we can write “Provide
    me with the standard distribution calculation with the code example in Python.
    Place a comment in each section and explain why every code is executed that way.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Give a persona or example, plus add the length of the output.** We can bring
    a persona or example to the model for better clarity. For example, we can pass
    the system role parameter to explain something in a way that the teacher would
    explain things to the students. By providing persona, the GPT model would bring
    results in a way that we require. Here is a sample code if you want to change
    the persona.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: It’s also great to provide example results to direct how the GPT model should
    answer your questions. For example, in this code, I pass how I would explain emotion,
    and the GPT model should mimic my style.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Specify the steps to complete your tasks.** Provide detailed steps on how
    you want the output for the best output. Give a detailed breakdown of the instruction
    on how the GPT model should act. For example, we put 2-step instructions with
    prefixes and translations in this code.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Provide references, links or citations**. If we already have various references
    for our questions, we can use them as the basis for the GPT model to provide the
    output. Give the list of any references you think are relevant to your questions
    and pass them into the system role.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Give GPT time to “think”**. Provide a query allowing GPT to process the prompt
    in detail before rushing to give incorrect results. This is especially true if
    we pass the assistant role a wrong result, and we want the GPT to be able to think
    critically for themselves. For example, the code below shows how we ask the GPT
    model to be more critical of the user input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Bring GPT to use Code Execution for precise results.** For more extended
    and more complex calculations, GPT might not work as intended, as the model might
    provide inaccurate results. To alleviate this, we can ask the GPT model to write
    and run coding rather than directly calculating them. This way, GPT can rely on
    the code rather than its calculation. For example, we can provide input like below.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]code goes here[PRE5]'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The GPT model is one of the best models out there, and here are some best practices
    to improve the GPT model output:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Have a detail in the prompt to get relevant answers**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Give a persona or example, plus add the length of the output**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Specify the steps to complete your tasks**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Provide references, links or citations**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Give GPT time to “think”**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bring GPT to use Code Execution for precise results**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free ChatGPT Course: Use The OpenAI API to Code 5 Projects](https://www.kdnuggets.com/2023/05/free-chatgpt-course-openai-api-code-5-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Use GPT for Generating Creative Content with Hugging Face…](https://www.kdnuggets.com/how-to-use-gpt-for-generating-creative-content-with-hugging-face-transformers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building AI Products with OpenAI: A Free Course from CoRise](https://www.kdnuggets.com/2023/07/corise-building-ai-products-openai-free-course-corise.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Superalignment by OpenAI](https://www.kdnuggets.com/2023/08/introducing-superalignment-openai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
