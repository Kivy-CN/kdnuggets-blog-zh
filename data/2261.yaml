- en: A Practical Guide to Transfer Learning using PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的迁移学习实用指南
- en: 原文：[https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html](https://www.kdnuggets.com/2023/06/practical-guide-transfer-learning-pytorch.html)
- en: Co-authored with [Naresh](https://medium.com/u/1e659a80cffd) and [Gaurav](http://www.gaurav.ai/).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与[Naresh](https://medium.com/u/1e659a80cffd)和[Gaurav](http://www.gaurav.ai/)联合撰写。
- en: This article will cover the what, why, and how of transfer learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将涵盖迁移学习的“什么”、“为什么”和“如何”。
- en: '**What** is transfer learning'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**什么**是迁移学习'
- en: '**Why** should you use transfer learning'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为什么**应该使用迁移学习'
- en: '**How** can you use transfer learning on a real classification task'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如何**在实际分类任务中使用迁移学习'
- en: '* * *'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加速网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 部门'
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Specifically, we’ll be covering the following aspects of transfer learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将涵盖迁移学习的以下方面。
- en: The motivation behind the idea of transfer learning and its benefits.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习理念的动机及其好处。
- en: Develop an intuition for base model selection. ([notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb))
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 培养对基础模型选择的直觉。 ([notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb))
- en: Discuss different choices and the trade-offs made along the way.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论不同的选择以及在过程中做出的权衡。
- en: Implementation of an image classification task with PyTorch. ([notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb))
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PyTorch 实现图像分类任务。 ([notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb))
- en: Performance comparison of various base models.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种基础模型的性能比较。
- en: Resources to learn more about transfer learning and the current state of the
    art
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解更多关于迁移学习及其当前前沿技术的资源
- en: Transfer learning is a large and growing field and this article covers just
    a few of its aspects. However, there are many deep learning online communities
    which discuss transfer learning. For example, [here is a good article](https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)
    on how we can leverage transfer learning to reach higher benchmarks than training
    models from scratch.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一个庞大且不断发展的领域，本文仅涵盖了其中的一些方面。然而，还有许多深度学习在线社区讨论迁移学习。例如，[这里有一篇不错的文章](https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)介绍了如何利用迁移学习来实现比从头训练模型更高的基准。
- en: Intended Audience and Prerequisites
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标受众及先决条件
- en: You’re familiar with basic machine learning (ML) concepts such as defining and
    training classification models
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你已经熟悉基本的机器学习（ML）概念，例如定义和训练分类模型
- en: You’re familiar with [PyTorch](https://pytorch.org/) and [torchvision](https://pytorch.org/vision/stable/index.html)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你已经熟悉[PyTorch](https://pytorch.org/)和[torchvision](https://pytorch.org/vision/stable/index.html)
- en: In the next section, we'll formally introduce transfer learning and explain
    it with examples.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将正式介绍迁移学习并通过示例进行解释。
- en: What is transfer learning?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习是什么？
- en: From [this page](https://machinelearningmastery.com/transfer-learning-for-deep-learning/),
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从[此页面](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)获取，
- en: '*“Transfer learning is a machine learning method where a model developed for
    a task is reused as the starting point for a model on a second task.”*'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“迁移学习是一种机器学习方法，其中为一个任务开发的模型被重新用作第二个任务模型的起点。”*'
- en: A deep learning model is a network of weights whose values are optimized using
    a loss function during the training progress. The weights of the network are typically
    initialized randomly before the start of the training process. In transfer learning,
    we use a [pre-trained model](https://pytorch.org/vision/stable/models.html) that
    has been trained on a related task. This gives us a set of initial weights that
    are likely to perform better than the randomly initialized weights. We optimize
    the pre-trained weights further for our specific task.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型是一个权重网络，其权重值在训练过程中通过损失函数进行优化。网络的权重通常在训练过程开始前被随机初始化。在迁移学习中，我们使用一个[预训练模型](https://pytorch.org/vision/stable/models.html)，它已经在相关任务上进行了训练。这为我们提供了一组初始权重，这些权重很可能比随机初始化的权重表现更好。我们进一步优化这些预训练的权重以适应我们的特定任务。
- en: Jeremy Howard (from fast.ai) [says](https://www.fast.ai/posts/2020-01-13-self_supervised.html).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Jeremy Howard（来自 fast.ai）[说](https://www.fast.ai/posts/2020-01-13-self_supervised.html)。
- en: '*“Wherever possible, you should aim to start your neural network training with
    a pre-trained model and fine-tune it. You really don’t want to be starting with
    random weights, because that means that you’re starting with a model that doesn’t
    know how to do anything at all! With pretraining, you can use 1000x less data
    than starting from scratch.”*'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“在可能的情况下，你应该以一个预训练模型开始你的神经网络训练并进行微调。你真的不希望从随机权重开始，因为那意味着你从一个完全不知道如何做任何事情的模型开始！通过预训练，你可以使用比从头开始少1000倍的数据。”*'
- en: Below, we’ll see how one can think of the concept of transfer learning as it
    relates to humans.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看如何将迁移学习的概念与人类学习联系起来进行思考。
- en: Human Analogy for Transfer Learning
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习的人类类比
- en: '**Model training**: After a child is born, it takes them a while to learn to
    stand, balance, and walk. During this time, they go through the phase of building
    physical muscles, and their brain learns to understand and internalize the skills
    to stand, balance and walk. They go through several attempts, some successful
    and some failures, to reach a stage where they can stand, balance and walk with
    some consistency. This is similar to training a deep learning model which takes
    a lot of time (training epochs) to learn a generic task (such as classifying an
    image as belonging to one of the 1000 ImageNet classes) when it is trained on
    that task.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练**：在孩子出生后，他们需要一段时间来学习站立、平衡和行走。在这个过程中，他们经历了建立身体肌肉的阶段，他们的大脑也学会了理解和内化站立、平衡和行走的技能。他们经历了若干次尝试，有些成功，有些失败，最终达到能够稳定地站立、平衡和行走的阶段。这类似于训练深度学习模型的过程，模型需要经过大量的时间（训练周期）才能学习到一个通用任务（例如将图像分类为1000个ImageNet类别之一），而这在训练该任务时非常重要。'
- en: '**Transfer learning**: A child who has learned to walk finds it far easier
    to learn related advanced skills such as jumping and running. Transfer Learning
    is comparable to this aspect of human learning where a pre-trained model that
    has already learned generic skills is leveraged to efficiently train for other
    related tasks.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迁移学习**：一个已经学会走路的孩子发现学习相关的高级技能，如跳跃和跑步，要容易得多。迁移学习类似于这种人类学习的方面，其中一个已经学会了通用技能的预训练模型被用来高效地训练其他相关任务。'
- en: Now that we have built an intuitive understanding of transfer learning and an
    analogy with human learning, let’s take a look at why one would use transfer learning
    for ML models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对迁移学习有了直观的理解，并且与人类学习进行了类比，让我们看看为什么在机器学习模型中使用迁移学习是有意义的。
- en: Why should I use transfer learning?
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我应该使用迁移学习？
- en: Many vision AI tasks such as image classification, image segmentation, object
    localization, or detection differ only in the specific objects they are classifying,
    segmenting, or detecting. The models trained on these tasks have learned the features
    of the objects in their training dataset. Hence, they can be easily adapted to
    related tasks. For example, a model trained to identify the presence of a car
    in an image could be fine-tuned for identifying a cat or a dog.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 许多视觉AI任务，如图像分类、图像分割、目标定位或检测，仅在它们分类、分割或检测的具体对象上有所不同。训练这些任务的模型已经学习了训练数据集中对象的特征。因此，它们可以很容易地适应相关任务。例如，一个训练用来识别图像中是否有汽车的模型可以被微调以识别猫或狗。
- en: 'The main advantage of transfer learning is the ability to empower you to achieve
    better accuracy on your tasks. We can break down its advantages as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的主要优势是能够使你在任务上获得更好的准确性。我们可以将其优势分解如下：
- en: '**Training efficiency**: When you start with a pre-trained model that has already
    learned the general features of the data, you then only need to ***fine-tune***
    the model to your specific task, which can be done much more quickly (i.e. using
    fewer training epochs).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练效率**：当你开始使用一个已经学会数据一般特征的预训练模型时，你只需***微调***模型以适应你的具体任务，这可以更快地完成（即使用更少的训练周期）。'
- en: '**Model accuracy**: Using transfer learning can give you a [significant performance
    boost](https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)
    compared to training a model from scratch using the same amount of resources.
    Choosing the right pre-trained model for transfer-learning for your specific task
    is important though.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型准确性**：使用迁移学习可以比使用相同资源从头开始训练模型获得[显著的性能提升](https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)。然而，为你的具体任务选择合适的预训练模型很重要。'
- en: '**Training data size**: Since a pre-trained model would have already learned
    to identify many of the features that overlap with your task-specific features,
    you can train the pre-trained model with ***less domain-specific data***. This
    is useful if you don’t have as much labeled data for your specific task.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据量**：由于预训练模型已经学会识别与你的任务相关的许多特征，你可以用***较少的领域特定数据***来训练预训练模型。如果你没有足够多的标记数据用于你的具体任务，这一点非常有用。'
- en: So, how do we go about doing transfer learning in practice? The next section
    implements transfer learning in PyTorch for a flower classification task.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们在实践中如何进行迁移学习呢？下一部分将在 PyTorch 中实现一个花卉分类任务的迁移学习。
- en: Transfer Learning with PyTorch
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyTorch 进行迁移学习
- en: To perform transfer learning with PyTorch, we first need to select a dataset
    and a pre-trained vision model for image classification. This article focuses
    on using torch-vision (a domain library used with PyTorch). Let’s understand where
    to find such pre-trained models and datasets.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 PyTorch 进行迁移学习，我们首先需要选择一个数据集和一个用于图像分类的预训练视觉模型。本文集中在使用 torch-vision（一个与
    PyTorch 一起使用的领域库）。让我们了解一下在哪里可以找到这些预训练模型和数据集。
- en: Where to find pre-trained vision models for image classification?
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哪里可以找到用于图像分类的预训练视觉模型？
- en: 'There are lots of websites providing high-quality pre-trained image classification
    models. For example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多网站提供高质量的预训练图像分类模型。例如：
- en: '[Torchvision](https://pytorch.org/vision/stable/models.html)'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Torchvision](https://pytorch.org/vision/stable/models.html)'
- en: '[PyTorch Image Models](https://github.com/huggingface/pytorch-image-models)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[PyTorch 图像模型](https://github.com/huggingface/pytorch-image-models)'
- en: For the purposes of this article, we will use [pre-trained models from torchvision](https://pytorch.org/vision/stable/models.html).
    It's worth learning a bit about how these models were trained. Let's explore that
    question next!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本文的目的，我们将使用[torchvision 的预训练模型](https://pytorch.org/vision/stable/models.html)。值得了解这些模型是如何训练的。接下来我们来探讨这个问题！
- en: Which datasets are torchvision models pre-trained on?
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: torchvision 模型是预训练于哪些数据集上的？
- en: 'For vision-related tasks involving images, torchvision models are usually pre-trained
    on the [ImageNet dataset](https://www.image-net.org/download.php). The most popular
    ImageNet subset used by researchers and for model pre-training vision models contains
    about 1.2M images across 1000 classes. ImageNet classification is used as a pre-training
    task due to:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及图像的视觉相关任务，torchvision 模型通常在[ImageNet 数据集](https://www.image-net.org/download.php)上进行预训练。研究人员和模型预训练中使用的最流行的
    ImageNet 子集包含大约 120 万张图像，涵盖 1000 个类别。由于以下原因，ImageNet 分类被用作预训练任务：
- en: Its ready **availability** to the research community
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它对研究社区的**可用性**
- en: The **breadth** and variety of images it contains
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它所包含的**广度**和图像种类
- en: Its use by various researchers - making it attractive to compare results using
    a **common denominator** of Imagenet 1k classification
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 各种研究人员的使用 - 使得使用**共同的基准**进行结果比较变得有吸引力
- en: You can read more about the history of the ImageNet challenge, historical background,
    and information about the complete dataset on this [wikipedia page](https://en.wikipedia.org/wiki/ImageNet).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个[维基百科页面](https://en.wikipedia.org/wiki/ImageNet)上阅读有关 ImageNet 挑战的历史、背景信息以及完整数据集的信息。
- en: '**Legality considerations when using pre-trained models**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用预训练模型时的法律考虑**'
- en: ImageNet is released for non-commercial research purposes only ([https://image-net.org/download](https://image-net.org/download)).
    Hence, it’s not clear if one can legally use the weights from a model that was
    pre-trained on ImageNet for commercial purposes. If you plan to do so, please
    seek legal advice.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 仅用于非商业研究目的 ([https://image-net.org/download](https://image-net.org/download))。因此，目前不清楚是否可以合法地将预训练于
    ImageNet 的模型权重用于商业目的。如果你计划这样做，请寻求法律建议。
- en: Now that we know where we can find the pre-trained models we’ll be using for
    transfer learning, let’s take a look at where we can procure the dataset we wish
    to use for our custom classification task.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了可以找到用于迁移学习的预训练模型的位置，我们来看看可以在哪里获取用于自定义分类任务的数据集。
- en: 'Dataset: Oxford Flowers 102'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集：牛津花卉 102
- en: We will be using the Flowers 102 dataset to illustrate transfer learning using
    PyTorch. We will train a model to classify images in the [Flowers 102](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)
    dataset into one of the 102 categories. This is a multi-class (single-label) categorization
    problem in which predicted classes are mutually exclusive. We’ll be leveraging
    Torchvision for this task since it already [provides this dataset](https://pytorch.org/vision/stable/generated/torchvision.datasets.Flowers102.html)
    for us to use.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Flowers 102 数据集来说明如何使用 PyTorch 进行迁移学习。我们将训练一个模型，将 [Flowers 102](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)
    数据集中的图像分类为 102 个类别之一。这是一个多类（单标签）分类问题，其中预测的类别是互斥的。我们将利用 Torchvision 来完成这个任务，因为它已经
    [为我们提供了这个数据集](https://pytorch.org/vision/stable/generated/torchvision.datasets.Flowers102.html)。
- en: The Flowers 102 dataset was obtained from the [Visual Geometry Group at Oxford](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/).
    Please see the page for licensing terms for the use of the dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Flowers 102 数据集来自于 [牛津视觉几何组](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)。有关使用数据集的许可条款，请参见页面。
- en: Next, let’s take a look at the high-level steps involved in this process.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看一下这个过程中的高级步骤。
- en: How does transfer learning work?
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习是如何工作的？
- en: 'Transfer learning for image classification tasks can be viewed as a sequence
    of three steps as shown in Figure 1\. These steps are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类任务的迁移学习可以视为三个步骤的序列，如图 1 所示。这些步骤如下：
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/ca3d49ee22f436287775d519acd189ad.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyTorch 进行迁移学习的实用指南](../Images/ca3d49ee22f436287775d519acd189ad.png)'
- en: 'Figure 1: Transfer Learning using PyTorch. Source: Author(s)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：使用 PyTorch 进行迁移学习。来源：作者
- en: '**Replace classifier layer**: In this phase, we identify and replace the last
    “[classification head](https://doc.arcgis.com/en/allsource/latest/analysis/geoprocessing-tools/geoai/how-text-classification-works.htm)”
    of our pre-trained model with our own “classification head” that has the right
    number of output features (102 in this example).'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**替换分类器层**：在此阶段，我们识别并用我们自己的具有正确输出特征数量（在此示例中为 102）的“分类头”替换预训练模型的最后一个“[分类头](https://doc.arcgis.com/en/allsource/latest/analysis/geoprocessing-tools/geoai/how-text-classification-works.htm)”。'
- en: '**Feature extraction**: In this phase, we freeze (make those layers non-trainable)
    all the layers of the model except the newly added classification layer, and train
    just this newly added layer.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**特征提取**：在此阶段，我们将冻结（使这些层不可训练）模型中除了新添加的分类层之外的所有层，只训练这一新添加的层。'
- en: '**Fine tuning**: In this phase, we unfreeze some subset of the layers in the
    model  (unfreezing a layer means making it trainable). In this article, we will
    unfreeze all the layers of the model and train them as we would train any Machine
    Learning (ML) PyTorch model.'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**微调**：在此阶段，我们会解冻模型中的一些子集（解冻一层意味着使其可训练）。在本文中，我们将解冻模型的所有层，并像训练任何机器学习（ML）PyTorch
    模型一样训练它们。'
- en: Each of these phases has a lot of additional detail and nuance that we need
    to know and worry about. We’ll get into those details soon. For now, let’s deep
    dive into 2 of the key phases, namely feature extraction, and fine-tuning below.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些阶段每一个都有许多额外的细节和微妙之处，我们需要了解和关注。我们将很快深入这些细节。目前，让我们深入探讨两个关键阶段，即特征提取和微调。
- en: Feature extraction and fine-tuning
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提取和微调
- en: You can find more information about feature extraction and fine-tuning here.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到有关特征提取和微调的更多信息。
- en: '[What is the difference between feature extraction and fine-tuning in transfer
    learning?](https://ai.stackexchange.com/questions/28138/what-is-the-difference-between-feature-extraction-and-fine-tuning-in-transfer-le)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[迁移学习中的特征提取和微调有什么区别？](https://ai.stackexchange.com/questions/28138/what-is-the-difference-between-feature-extraction-and-fine-tuning-in-transfer-le)'
- en: '[Learning without forgetting](https://arxiv.org/pdf/1606.09282.pdf)'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[不遗忘学习](https://arxiv.org/pdf/1606.09282.pdf)'
- en: The diagrams below illustrate feature extraction and fine tuning visually.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示直观地展示了特征提取和微调。
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/6c3d03dfd4a4c1adcdd479febd32b4d5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyTorch 进行迁移学习的实用指南](../Images/6c3d03dfd4a4c1adcdd479febd32b4d5.png)'
- en: 'Figure 2: Visual explanation of fine tuning (b) and feature extraction (c).
    Source: [Learning without forgetting](https://arxiv.org/pdf/1606.09282.pdf)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：微调（b）和特征提取（c）的视觉解释。来源：[不遗忘学习](https://arxiv.org/pdf/1606.09282.pdf)
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/d372d5f5eccded958b1771c00b2695ce.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyTorch 进行迁移学习的实用指南](../Images/d372d5f5eccded958b1771c00b2695ce.png)'
- en: 'Figure 3: Illustration showing which layers are trainable (unfrozen) during
    the feature-extraction, and fine-tuning stages. Source: Author(s)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：图示显示了在特征提取和微调阶段哪些层是可训练的（未冻结）。来源：作者
- en: Now that we’ve developed a good understanding of the custom classification task,
    the pre-trained model we’ll be using for this task, and how transfer learning
    works, let’s look at some concrete code that performs transfer learning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对自定义分类任务、用于该任务的预训练模型以及迁移学习的工作原理有了很好的理解，让我们来看看一些执行迁移学习的具体代码。
- en: Show me the Code
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给我看代码
- en: In this section you will learn concepts like exploratory model analysis, initial
    model selection, how to define a model, implement transfer learning steps (discussed
    above), and how to prevent overfitting. We’ll discuss the train/val/test split
    for this dataset and interpret the results.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习诸如探索性模型分析、初始模型选择、如何定义模型、实现迁移学习步骤（上述讨论）以及如何防止过拟合等概念。我们将讨论数据集的训练/验证/测试划分，并解读结果。
- en: The complete code for this experiment can be found [here (Flowers102 classification
    using pre-trained models)](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb).
    The section on exploratory model analysis is in a [separate notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本实验的完整代码可以在[这里（使用预训练模型的 Flowers102 分类）](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb)找到。关于探索性模型分析的部分在[一个单独的笔记本](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb)中。
- en: Exploratory model analysis
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索性模型分析
- en: Similar to exploratory data analysis in data science, the first step in transfer-learning
    is exploratory model analysis. In this step, we explore all the pre-trained models
    available for image classification tasks, and determine how each one is structured.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于数据科学中的探索性数据分析，迁移学习的第一步是探索性模型分析。在此步骤中，我们探索所有用于图像分类任务的预训练模型，并确定每个模型的结构。
- en: In general, it’s hard to know which model will perform best for our task, so
    it’s not uncommon to try out a few models that seem promising or applicable for
    our situation. In this hypothetical scenario, let’s assume that model size isn’t
    important (we don’t want to deploy these models on mobile devices or such edge
    devices). We’ll first look at the list of available pre-trained classification
    models in torchvision.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，很难知道哪个模型对我们的任务表现最佳，因此尝试几个看起来有前途或适用的模型并不罕见。在这个假设场景中，我们假设模型的大小并不重要（我们不打算将这些模型部署到移动设备或其他边缘设备上）。我们将首先查看
    torchvision 中可用的预训练分类模型列表。
- en: '[PRE0]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Will print
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 将打印
- en: '[PRE1]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Wow! That’s a pretty large list of models to choose from! If you’re feeling
    confused, don’t worry - in the next section, we’ll look at the factors to consider
    when choosing the initial set of models for performing transfer learning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这真是一个相当庞大的模型选择列表！如果你感到困惑，不要担心——在下一节中，我们将讨论选择初始模型集进行迁移学习时需要考虑的因素。
- en: Initial model selection
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始模型选择
- en: Now that we have a list of 80 candidate models to choose from, we need to narrow
    it down to a handful of models that we can run experiments on. The choice of the
    pre-trained model backbone is a hyper-parameter, and we can (and should) explore
    multiple options by running experiments to see which one works best. Running experiments
    is costly and time consuming, and it’s unlikely that we’ll be able to try all
    the models, which is why we try to narrow down the list to 3-4 models to begin
    with.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有80个候选模型需要选择，我们需要将其缩小到几个可以进行实验的模型。预训练模型骨干网络的选择是一个超参数，我们可以（且应该）通过实验探索多个选项，以查看哪个效果最佳。运行实验成本高且耗时，而且不太可能尝试所有模型，这就是为什么我们首先尝试将列表缩小到3-4个模型的原因。
- en: We decided to go with the following pre-trained model backbones to begin with.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定首先使用以下预训练模型骨干网络。
- en: 'Vgg16: 135M parameters'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Vgg16: 135M 参数'
- en: 'ResNet50: 23M parameters'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ResNet50: 23M 参数'
- en: 'ResNet152: 58M parameters'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ResNet152: 58M 参数'
- en: Here’s how/why we chose these 3 to begin with.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们选择这三种模型的原因。
- en: We’re not constrained by model size or inference latency, so we don’t need to
    find the models that are super efficient. If you want a comparative study of various
    vision models for mobile devices, please read the paper titled “[Comparison and
    Benchmarking of AI Models and Frameworks on Mobile Devices](https://arxiv.org/pdf/2005.05085.pdf)”.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不受限于模型大小或推理延迟，因此我们不需要寻找超级高效的模型。如果你想要对各种移动设备视觉模型进行比较研究，请阅读题为“[移动设备上AI模型和框架的比较与基准测试](https://arxiv.org/pdf/2005.05085.pdf)”的论文。
- en: The models we choose are fairly popular in the vision ML community and tend
    to be good go-to choices for classification tasks. You could use the citation
    count for papers on these models as decent proxies for how effective these models
    could be. However, please be aware of a potential bias where papers on models
    such as AlexNet that have been around long will have more citations even though
    one would not use them for any serious classification task as a default choice.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们选择的模型在视觉机器学习社区中相当受欢迎，并且通常是分类任务的良好选择。你可以使用这些模型论文的引用计数作为模型有效性的一个较好指标。然而，请注意，像AlexNet这样的老旧模型的论文引用计数可能较多，但它们通常不是进行严肃分类任务的默认选择。
- en: Even within model architectures, there tend to be many flavours or sizes of
    models. For example, EfficientNet comes in trims named B0 through B7\. Please
    refer to the papers on the specific models for details on what these trims mean.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使在模型架构中，通常也有许多不同的变种或尺寸。例如，EfficientNet有从B0到B7的不同版本。有关这些版本的具体细节，请参考相关模型的论文。
- en: Citation counts of various papers on pre-trained classification models available
    in torchvision.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: torchvision中各种预训练分类模型的引用计数。
- en: 'Resnet: 165k'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Resnet: 165k'
- en: 'AlexNet: 132k'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'AlexNet: 132k'
- en: 'Vgg16: 102k'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Vgg16: 102k'
- en: 'MobileNet: 19k'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'MobileNet: 19k'
- en: 'Vision Transformers: 16k'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Vision Transformers: 16k'
- en: 'EfficientNet: 12k'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'EfficientNet: 12k'
- en: 'ShuffleNet: 6k'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ShuffleNet: 6k'
- en: 'If you’d like to read more on factors that may affect your choice of pre-trained
    model, please read the following articles:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多可能影响你选择的预训练模型的因素，请阅读以下文章：
- en: '[4 Pre-Trained CNN Models to Use for Computer Vision with Transfer Learning](https://towardsdatascience.com/4-pre-trained-cnn-models-to-use-for-computer-vision-with-transfer-learning-885cb1b2dfc)'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[4种适用于计算机视觉迁移学习的预训练CNN模型](https://towardsdatascience.com/4-pre-trained-cnn-models-to-use-for-computer-vision-with-transfer-learning-885cb1b2dfc)'
- en: '[How to choose the best pre-trained model for your Convolutional Neural Network?](https://data-science-blog.com/blog/2022/04/11/how-to-choose-the-best-pre-trained-model-for-your-convolutional-neural-network/)'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[如何选择适合你卷积神经网络的最佳预训练模型？](https://data-science-blog.com/blog/2022/04/11/how-to-choose-the-best-pre-trained-model-for-your-convolutional-neural-network/)'
- en: '[Benchmark Analysis of Representative Deep Neural Network Architectures](https://arxiv.org/pdf/1810.00736.pdf)'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[代表性深度神经网络架构的基准分析](https://arxiv.org/pdf/1810.00736.pdf)'
- en: Let’s check out the classification heads for these models.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看这些模型的分类头。
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can find the complete notebook for [exploratory model analysis here](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里找到完整的探索性模型分析笔记本](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb)。
- en: Since we’re going to be running experiments on 3 pre-trained models and performing
    transfer learning on each one of them separately, let’s define some abstractions
    and classes that will help us run and track these experiments.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将对3个预训练模型进行实验，并分别对每个模型执行转移学习，因此让我们定义一些抽象和类，以帮助我们运行和跟踪这些实验。
- en: Defining a PyTorch model to wrap pre-trained models
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义一个PyTorch模型来封装预训练模型
- en: To allow easy exploration, we will define a PyTorch model named Flowers102Classifier,
    and use that throughout this exercise. We will progressively add functionality
    to this class till we achieve our final goal. The complete notebook for [transfer
    learning for Flowers 102 classification can be found here](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便探索，我们将定义一个名为`Flowers102Classifier`的PyTorch模型，并在整个过程中使用它。我们将逐步为该类添加功能，直到实现最终目标。有关[Flowers
    102分类的转移学习的完整笔记本可以在这里找到](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)。
- en: The sections below will dive deeper into each of the mechanical steps needed
    to perform transfer learning.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的部分将深入探讨执行转移学习所需的每一个机械步骤。
- en: Replacing the old classification head with a new one
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替换旧的分类头为新的分类头
- en: The existing classification head for each of these models that is pre-trained
    on the ImageNet classification task has 1000 output features. Our custom task
    for flower classification has 102 output features. Hence, we need to replace the
    final classification head (layer) with a new one that has 102 output features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 每个在ImageNet分类任务上进行预训练的模型的现有分类头有1000个输出特征。我们自定义的花卉分类任务有102个输出特征。因此，我们需要将最终的分类头（层）替换为一个具有102个输出特征的新分类头。
- en: The constructor for our class will include code that loads the pre-trained model
    of interest from torchvision using pre-trained weights, and will replace the classification
    head with a custom classification head for 102 classes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们类的构造函数将包括加载来自`torchvision`的预训练模型的代码，并使用预训练权重，并将分类头替换为一个用于102类的自定义分类头。
- en: '[PRE4]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since we’ll be performing feature-extraction followed by fine-tuning, we’ll
    save the newly added layers into the self.new_layers list. This will help us set
    the weights of those layers as trainable or non-tainable depending on what we’re
    doing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将执行特征提取和微调，因此我们将把新添加的层保存到`self.new_layers`列表中。这将帮助我们根据操作来设置这些层的权重为可训练或不可训练。
- en: Now that we have replaced the older classification head with a new classification
    head that has randomly initialized weights, we will need to train those weights
    so that the model can perform accurate predictions. This includes feature extraction
    and fine tuning and we’ll take a look at that next.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将旧的分类头替换为具有随机初始化权重的新分类头，我们需要训练这些权重，以便模型能够进行准确的预测。这包括特征提取和微调，我们将接下来查看这一点。
- en: Transfer Learning (trainable parameters and learning rates)
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转移学习（可训练参数和学习率）
- en: Transfer learning involves running feature extraction and fine tuning in that
    specific order. Let’s take a closer look at why they need to be run in that order
    and how we can handle trainable parameters for the various transfer learning phases.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习包括按特定顺序运行特征提取和微调。让我们更详细地了解为什么需要按该顺序运行它们，以及如何处理各种转移学习阶段的可训练参数。
- en: '**Feature Extraction**: We set requires_grad to False for weights in all the
    layers in the model, and set requires_grad to True for only the newly added layers.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征提取**：我们将模型中所有层的权重的`requires_grad`设置为`False`，仅将新添加的层的`requires_grad`设置为`True`。'
- en: We train the new layer(s) for **16 epochs** with a learning rate of 1e-3\. This
    ensures that the new layer(s) are able to adjust and adapt their weights to the
    weights in the feature extractor part of the network. It’s important to freeze
    the rest of the layers in the network and train only the new layer(s) so that
    we don’t shock the network into forgetting what it has already learned. If we
    don’t freeze the earlier layers, they will end up getting re-trained on junk weights
    that were randomly initialized when we added the new classification head.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用**16个epochs**和学习率为1e-3训练新层。这确保了新层能够调整和适应其权重，以适应网络中特征提取器部分的权重。冻结网络中的其他层并仅训练新层是重要的，以免使网络忘记已经学到的内容。如果我们不冻结较早的层，它们将会在添加新分类头时被重新训练为随机初始化的垃圾权重。
- en: '**Fine Tuning**: We set requires_grad to True for weights in all the layers
    of the model. We train the entire network for **8 epochs**. However, we adopt
    a differential learning rate strategy in this case. We decay the learning rate
    (LR) so that the LR decreases as we move toward the input layers (away from the
    output classification head). We decay the learning rate as we move up the model
    towards the initial layers of the model because those initial layers have learned
    basic features about the image, which would be common for most vision AI tasks.
    Hence, the initial layers are trained with a very low LR to avoid disturbing what
    they have learned. As we move down the model towards the classification head,
    the model is learning something task specific, so it makes sense to train those
    later layers with a higher LR. One can adopt different strategies here, and in
    our case, we use 2 different strategies to illustrate the effectiveness of both
    of them.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调**：我们将所有层的权重的requires_grad设置为True。我们训练整个网络**8个周期**。然而，在这种情况下，我们采用了差异学习率策略。我们使学习率（LR）衰减，以便LR在向输入层（远离输出分类头）移动时减少。我们在向模型的初始层移动时衰减学习率，因为这些初始层已经学习了关于图像的基本特征，这对于大多数视觉AI任务都是共通的。因此，初始层用非常低的学习率进行训练，以避免干扰它们已学到的知识。当我们向分类头部的模型后层移动时，模型正在学习一些任务特定的内容，因此用更高的学习率训练这些后层是有意义的。这里可以采用不同的策略，在我们的案例中，我们使用了2种不同的策略来说明它们的有效性。'
- en: '**VGG16**: For the vgg16 network, we decay the LR **linearly** from LR=1e-4
    to LR=1e-7 (1000x lower than the LR of the classification layer). Since there
    are 44 layers in the feature extraction phase, each layer is assigned a LR that
    is (1e-7 - 1e-4)/44 = 2.3e-6 lower than the previous layer.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**VGG16**：对于vgg16网络，我们将学习率**线性**地从LR=1e-4衰减到LR=1e-7（比分类层的学习率低1000倍）。由于特征提取阶段有44层，每一层的学习率比前一层低（1e-7
    - 1e-4）/44 = 2.3e-6。'
- en: '**ResNet**: For the ResNet (50/152) network, we decay the LR exponentially
    starting from LR=1e-4\. We reduce the LR by 3x for every layer we move up.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ResNet**：对于ResNet（50/152）网络，我们从LR=1e-4开始以指数方式衰减学习率。每向上一层，我们将学习率减少3倍。'
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/43ffa221f6003b98afc4a6c4a37b2961.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![使用PyTorch进行迁移学习的实用指南](../Images/43ffa221f6003b98afc4a6c4a37b2961.png)'
- en: 'Figure 4: An example showing the learning rate (LR) decaying exponentially
    by a factor of 10 as we move up toward the layers closer to the input to the network.
    Source: Author(s).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：一个示例显示学习率（LR）以10的因子指数衰减，当我们向靠近网络输入的层移动时。来源：作者。
- en: The code for freezing layers for both feature extraction as well as fine tuning
    is shown in the function named fine_tune() below.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 用于冻结特征提取和微调的层的代码显示在下面名为fine_tune()的函数中。
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Code snippet: Freezing and unfreezing parameters using requires_grad during
    the feature-extraction (NEW_LAYERS) and fine-tuning (ALL) phase.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段：在特征提取（NEW_LAYERS）和微调（ALL）阶段使用requires_grad冻结和解冻参数。
- en: In PyTorch, the way to set differential LRs for each layer is to specify the
    weights that need that LR to the optimizer that will be used during transfer learning.
    In our notebook, we use the Adam optimizer. The get_optimizer_params() method
    below gets the optimizer parameters to pass into the Adam (or other) optimizer
    we will be using.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中，为每一层设置差异学习率的方式是将需要该学习率的权重指定给在迁移学习期间使用的优化器。在我们的笔记本中，我们使用Adam优化器。下面的get_optimizer_params()方法获取优化器参数，以传递给我们将使用的Adam（或其他）优化器。
- en: '[PRE6]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Code snippet: Differential learning rates for each layer when fine-tuning the
    model.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段：在微调模型时，每层的差异学习率。
- en: Once we have the model parameters with their own LRs, we can pass them into
    the optimizer with a single line of code. A default LR of 1e-8 is used for parameters
    whose weights are not specified in the dictionary returned by get_optimizer_params().
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了各自学习率的模型参数，就可以用一行代码将它们传递给优化器。对那些在get_optimizer_params()返回的字典中未指定权重的参数，使用默认学习率1e-8。
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Code snippet: Pass in parameters with their own LRs into the Adam optimizer.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 代码片段：将具有各自学习率的参数传递给Adam优化器。
- en: Now that we know how to perform transfer learning, let’s take a look at what
    other considerations we need to keep in mind before we fine tune our model. This
    includes steps that we need to take to prevent overfitting, and choosing the right
    train/val/test split.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何进行迁移学习，让我们来看看在微调模型之前还需要考虑哪些其他因素。这包括我们需要采取的步骤以防止过拟合，以及选择合适的训练/验证/测试集划分。
- en: Preventing overfitting
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 防止过拟合
- en: In our [notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb),
    we use the following data augmentation techniques on the training data to prevent
    overfitting and allow the model to learn the features so that it can perform predictions
    on unseen data.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的[笔记本](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)中，我们对训练数据应用了以下数据增强技术，以防止过拟合，并使模型能够学习特征，从而对未见过的数据进行预测。
- en: Color Jitter
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 色彩抖动
- en: Horizontal Flip
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 水平翻转
- en: Rotation
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 旋转
- en: Shear
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 剪切
- en: There is no data augmentation applied to the validation split.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对验证拆分没有应用数据增强。
- en: One should also explore [weight decaying](https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab),
    which is a regularization technique to prevent overfitting by reducing the complexity
    of the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 还应探讨[权重衰减](https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab)，这是一种正则化技术，通过减少模型的复杂性来防止过拟合。
- en: Train/Val/Test split
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练/验证/测试拆分
- en: The authors of the Flowers 102 dataset recommend a train/val/test split that’s
    of size 1020/ 1020/6149\. Many authors do things differently. For example,
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Flowers 102 数据集的作者推荐的训练/验证/测试拆分是1020/1020/6149。许多作者采取不同的方法。例如，
- en: In the [ResNet strikes back](https://arxiv.org/pdf/2110.00476.pdf) paper, the
    authors use the train+val (2040 images) split as the train set, and the test set
    as the test set. It isn’t clear if there’s a validation split.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[ResNet strikes back](https://arxiv.org/pdf/2110.00476.pdf)论文中，作者使用了训练+验证（2040张图像）拆分作为训练集，测试集作为测试集。是否存在验证拆分尚不明确。
- en: In this article on [classification on Flowers 102](https://towardsdatascience.com/build-train-and-deploy-a-real-world-flower-classifier-of-102-flower-types-a90f66d2092a),
    the authors use the test split of size 6149 as the train split.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[Flowers 102 分类](https://towardsdatascience.com/build-train-and-deploy-a-real-world-flower-classifier-of-102-flower-types-a90f66d2092a)这篇文章中，作者使用了6149的测试拆分作为训练拆分。
- en: In this [notebook](https://github.com/bduvenhage/pytorch_challenge/blob/master/Image_Classifier_Project_Colab.ipynb),
    the author uses a train/val/test split of size 6552, 818, and 819 respectively.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个[笔记本](https://github.com/bduvenhage/pytorch_challenge/blob/master/Image_Classifier_Project_Colab.ipynb)中，作者使用了6552、818和819的训练/验证/测试拆分。
- en: The only way to know which author is doing what is to read the papers or the
    code.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 了解哪些作者在做什么的唯一方法是阅读论文或代码。
- en: In our notebook (in this article), we use the split of size 6149 as the train
    split and the split of size 2040 as the validation split. We don’t use a test
    split, since we aren’t really trying to compete here.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的笔记本（在本文中），我们使用了6149的拆分作为训练拆分，2040的拆分作为验证拆分。我们没有使用测试拆分，因为我们并不真正尝试竞争。
- en: At this point in time, you should feel empowered to visit [this notebook](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)
    that performs all of the steps above and has their results presented for you to
    view. Please feel free to clone the notebook on Kaggle or Google Colab and run
    it yourself on a GPU. If you’re using Google Colab, you’ll need to fix up some
    of the paths where the datasets and pre-trained models are downloaded and where
    the best weights for the fine-tuned models are stored.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该感到有信心访问[这个笔记本](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)，它执行了上述所有步骤并展示了结果。请随意在Kaggle或Google
    Colab上克隆该笔记本，并在GPU上自行运行。如果你使用Google Colab，你需要修正一些路径，这些路径涉及数据集和预训练模型的下载以及微调模型最佳权重的存储。
- en: Below, we will look at the results of our transfer learning experiments!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们将查看我们的迁移学习实验的结果！
- en: Results
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: The results have some common themes that we’ll explore below.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 结果中有一些共同的主题，我们将在下面探讨。
- en: After the feature extraction step alone, almost all the networks have an accuracy
    between 91% and 94%
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单独经过特征提取步骤后，几乎所有网络的准确率都在91%到94%之间。
- en: Almost all networks do really well, achieving an accuracy of 96+% after the
    fine-tuning step. This shows that the fine tuning step really helps during transfer
    learning.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几乎所有的网络在微调步骤后都表现非常好，准确率达到96%以上。这表明微调步骤在迁移学习过程中确实很有帮助。
- en: There’s a significant difference in the number of parameters in our network,
    with vgg16 at 135M parameters, ResNet50 at 23M parameters, and ResNet152 at 58M
    parameters. This suggests that we can probably find a smaller network with comparable
    accuracy and performance.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们网络中的参数数量差异显著，vgg16 为 135M 参数，ResNet50 为 23M 参数，ResNet152 为 58M 参数。这表明我们可能可以找到一个具有类似准确率和性能的较小网络。
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/f62f4d7b6be49cdb920d90146304b94e.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyTorch 进行转移学习的实用指南](../Images/f62f4d7b6be49cdb920d90146304b94e.png)'
- en: 'Figure 5: Train/Val Loss and Accuracy over the transfer learning process. Source:
    Author(s).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：转移学习过程中的训练/验证损失和准确率。来源：作者。
- en: The vertical red line indicates the epoch when we switched from feature extraction
    (16 epochs) to fine-tuning (8 epochs). You can see that when we switched to fine-tuning,
    all the networks showed an increase in accuracy. This shows that fine-tuning after
    feature extraction is very effective.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直的红线表示我们从特征提取（16 个时期）切换到微调（8 个时期）的时间点。你可以看到，当我们切换到微调时，所有网络的准确率都有所提高。这表明在特征提取后进行微调是非常有效的。
- en: '![A Practical Guide to Transfer Learning using PyTorch](../Images/b87247c2760e4623a9c283252b70b34c.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![使用 PyTorch 进行转移学习的实用指南](../Images/b87247c2760e4623a9c283252b70b34c.png)'
- en: 'Figure 6: Validation accuracy of all the 3 pre-trained models after transfer
    learning on the flowers classification task. The validation accuracy after feature
    extraction at epoch 16 is shown along with the best validation accuracy for each
    model during the fine tuning phase. Source: author(s).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：在花卉分类任务上进行转移学习后，所有 3 个预训练模型的验证准确率。图中显示了第 16 个时期特征提取后的验证准确率以及每个模型在微调阶段的最佳验证准确率。来源：作者。
- en: Article Recap
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文章回顾
- en: Transfer learning is a thrifty and effective way to train your network by starting
    from a pre-trained network on a similar but unrelated task
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转移学习是一种节省成本且有效的训练网络的方法，通过从一个类似但不相关的任务上的预训练网络开始。
- en: Torchvision provides many models pre-trained on ImageNet for researchers to
    use during transfer learning
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Torchvision 为研究人员提供了许多在 ImageNet 上预训练的模型，以便在转移学习过程中使用。
- en: Be careful when using pre-trained models in production to ensure that you don’t
    violate any licenses or terms of use for datasets on which models were pre-trained
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预训练模型时要小心，以确保你不违反模型预训练数据集的任何许可证或使用条款。
- en: Transfer learning includes feature extraction and fine-tune, which must be performed
    in that specific order
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转移学习包括特征提取和微调，这必须按照特定顺序进行。
- en: Want to learn more?
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 想了解更多？
- en: Now that we know how to perform transfer learning for a custom task starting
    from a model that is pre-trained on a different dataset, wouldn’t it be great
    if we could avoid using a separate dataset for the pre-training (pretext task)
    and use our own dataset for this purpose? Turns out, this is becoming feasible!
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何从在不同数据集上预训练的模型开始进行定制任务的转移学习，如果我们能避免使用单独的数据集进行预训练（预文本任务），而使用我们自己的数据集，这不是更好吗？事实证明，这已经变得可行！
- en: Recently, researchers and practitioners have been using [self-supervised learning](https://www.fast.ai/posts/2020-01-13-self_supervised.html)
    as a way to perform model pre-training (learning the pretext task) which has a
    benefit of training the model on a dataset with the same distribution as the target
    dataset that the model is supposed to be consuming in production. If you are interested
    in learning more about self-supervised pre-training and hierarchical pretraining,
    please see this paper from 2021 titled [self-supervised pretraining improves self-supervised
    pretraining](https://arxiv.org/pdf/2103.12718.pdf).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，研究人员和从业者一直在使用 [自监督学习](https://www.fast.ai/posts/2020-01-13-self_supervised.html)
    作为进行模型预训练（学习预文本任务）的方式，这种方法的好处是可以在具有与目标数据集相同分布的数据集上训练模型。如果你对自监督预训练和层次化预训练感兴趣，请参阅这篇
    2021 年的论文 [自监督预训练改善自监督预训练](https://arxiv.org/pdf/2103.12718.pdf)。
- en: If you own the data for your specific task, you can use self-supervised learning
    for pre-training your model and not worry about using the ImageNet dataset for
    the pre-training step, thus staying in the clear as far as use of the ImageNet
    dataset is concerned.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你拥有特定任务的数据，你可以使用自监督学习来进行模型的预训练，而无需担心使用 ImageNet 数据集进行预训练，因此在使用 ImageNet 数据集方面不会有问题。
- en: Glossary of Terms used
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的术语词汇表
- en: '**Classification head**: In PyTorch, this is an [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)
    layer that maps numerous input features to a set of output features'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类头**：在 PyTorch 中，这是一层 [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)，将多个输入特征映射到一组输出特征。'
- en: '**Freeze weights**: Make the weights non-trainable. In PyTorch, this is done
    by setting requires_grad=False'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冻结权重**：使权重不可训练。在 PyTorch 中，通过设置 requires_grad=False 来实现。'
- en: '**Unfreeze (or thaw) weights**: Make the weights trainable. In PyTorch, this
    is done by setting requires_grad=True'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解冻（或融化）权重**：使权重可训练。在 PyTorch 中，通过设置 requires_grad=True 来实现。'
- en: '**Self-supervised learning**: A way to train an ML model so that it can be
    trained on data without any human generated labels. The labels could be automatically
    or machine generated though'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自监督学习**：一种训练 ML 模型的方法，使其可以在没有任何人为生成标签的数据上进行训练。这些标签可能是自动生成或机器生成的。'
- en: References and Further Reading
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献及进一步阅读
- en: '[Ideas on how to fine-tune a pre-trained model in PyTorch](https://medium.com/udacity-pytorch-challengers/ideas-on-how-to-fine-tune-a-pre-trained-model-in-pytorch-184c47185a20)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于如何在 PyTorch 中微调预训练模型的想法](https://medium.com/udacity-pytorch-challengers/ideas-on-how-to-fine-tune-a-pre-trained-model-in-pytorch-184c47185a20)'
- en: '[Dive into deep learning: Fine tuning](https://d2l.ai/chapter_computer-vision/fine-tuning.html)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深入了解深度学习：微调](https://d2l.ai/chapter_computer-vision/fine-tuning.html)'
- en: '[Self-supervised learning and computer vision](https://www.fast.ai/posts/2020-01-13-self_supervised.html)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自监督学习与计算机视觉](https://www.fast.ai/posts/2020-01-13-self_supervised.html)'
- en: '[A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习迁移学习的温和介绍](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)'
- en: '[Notebook: Exploratory model analysis](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本：探索性模型分析](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/torchvision-model-exploration.ipynb)'
- en: '[Notebook: Flowers 102 classification using transfer learning](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[笔记本：使用迁移学习进行花卉 102 分类](https://github.com/dhruvbird/ml-notebooks/blob/main/Flowers-102-transfer-learning/flowers102-classification-using-pre-trained-models.ipynb)'
- en: '**[Dhruv Matani](https://www.linkedin.com/in/dhruvbird/)** is a Machine Learning
    enthusiast focusing on PyTorch, CNNs, Vision, Speech, and Text AI. He is an expert
    on on-device AI, model optimization and quantization, ML and Data Infrastructure.
    Authoring a chapter on Efficient PyTorch in the Efficient Deep Learning Book at
    https://efficientdlbook.com/. His views are his own, not those of any of his employer(s);
    past, present, or future.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Dhruv Matani](https://www.linkedin.com/in/dhruvbird/)** 是一位专注于 PyTorch、CNNs、视觉、语音和文本
    AI 的机器学习爱好者。他在设备端 AI、模型优化和量化、ML 和数据基础设施方面是专家。著作《Efficient Deep Learning Book》中关于
    Efficient PyTorch 的章节可以在 https://efficientdlbook.com/ 上找到。他的观点仅代表个人，非任何雇主的观点；无论是过去、现在还是未来。'
- en: '**[Naresh](https://www.linkedin.com/in/naresh-singh-15916b17/)** is deeply
    interested in the "learning" aspect of the Neural Network. His work is focussed
    on neural network architectures and how simple topological changes enhance their
    learning capabilities. He has held engineering roles at Microsoft, Amazon, and
    Citrix in his decade-long professional career. He has been involved in the deep
    learning field for the last 6-7 years. You can find him on medium at https://medium.com/u/1e659a80cffd.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Naresh](https://www.linkedin.com/in/naresh-singh-15916b17/)** 深度关注神经网络的“学习”方面。他的工作集中于神经网络架构以及简单的拓扑变化如何增强其学习能力。在他的十年职业生涯中，他曾在
    Microsoft、Amazon 和 Citrix 担任工程职位。在过去的 6-7 年里，他一直参与深度学习领域。你可以在 https://medium.com/u/1e659a80cffd
    上找到他。'
- en: '**[Gaurav](http://www.gaurav.ai/)** is a Staff Software Engineer at Google
    Research where he leads research projects geared towards optimizing large machine
    learning models for efficient training and inference on devices ranging from tiny
    microcontrollers to Tensor Processing Unit (TPU)-based servers. His work has positively
    impacted over 1 Billion of active users across YouTube, Cloud, Ads, Chrome, etc.
    He is also an author of an upcoming book with Manning Publication on Efficient
    Machine Learning. Before Google, Gaurav worked at Facebook for 4.5 years and has
    contributed significantly to Facebook’s Search system and large-scale distributed
    databases. He has an M.S. in Computer Science from Stony Brook University.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Gaurav](http://www.gaurav.ai/)** 是谷歌研究部门的高级软件工程师，他领导的研究项目旨在优化大型机器学习模型，以实现从微型控制器到基于
    TPU 的服务器的高效训练和推理。他的工作对 YouTube、Cloud、Ads、Chrome 等超过 10 亿活跃用户产生了积极影响。他还将与 Manning
    出版社合作出版一本关于高效机器学习的书。在谷歌之前，Gaurav 在 Facebook 工作了 4.5 年，并对 Facebook 的搜索系统和大规模分布式数据库做出了重要贡献。他拥有
    Stony Brook 大学的计算机科学硕士学位。'
- en: More On This Topic
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Tools Every Data Scientist Should Know: A Practical Guide](https://www.kdnuggets.com/tools-every-data-scientist-should-know-a-practical-guide)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应了解的工具：实用指南](https://www.kdnuggets.com/tools-every-data-scientist-should-know-a-practical-guide)'
- en: '[Tools Every AI Engineer Should Know: A Practical Guide](https://www.kdnuggets.com/tools-every-ai-engineer-should-know-a-practical-guide)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个 AI 工程师都应了解的工具：实用指南](https://www.kdnuggets.com/tools-every-ai-engineer-should-know-a-practical-guide)'
- en: '[Using Transfer Learning to Boost Model Performance](https://www.kdnuggets.com/using-transfer-learning-to-boost-model-performance)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用迁移学习提升模型性能](https://www.kdnuggets.com/using-transfer-learning-to-boost-model-performance)'
- en: '[A Beginner''s Guide to PyTorch](https://www.kdnuggets.com/a-beginners-guide-to-pytorch)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 初学者指南](https://www.kdnuggets.com/a-beginners-guide-to-pytorch)'
- en: '[How to Start Using Natural Language Processing With PyTorch](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何开始使用 PyTorch 进行自然语言处理](https://www.kdnuggets.com/2022/04/start-natural-language-processing-pytorch.html)'
- en: '[Practical Deep Learning from fast.ai is Back!](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[实用深度学习课程来自 fast.ai！](https://www.kdnuggets.com/2022/07/practical-deep-learning-fastai-2022.html)'
