- en: Why are Machine Learning Projects so Hard to Manage?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/machine-learning-projects-manage.html](https://www.kdnuggets.com/2020/02/machine-learning-projects-manage.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Lukas Biewald](https://twitter.com/l2k), Founder/CEO of Weights and Biases**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: I’ve watched lots of companies attempt to deploy machine learning — some succeed
    wildly, and some fail spectacularly. One constant is that machine learning teams
    have a hard time setting goals and setting expectations. Why is this?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cea8236a453e807ed5a339d72d25f435.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: 1\. It’s really hard to tell in advance what’s hard and what’s easy.
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Is it harder to beat Kasparov at chess or pick up and physically move the chess
    pieces? Computers beat the world champion chess player over twenty years ago,
    but reliably grasping and lifting objects is still an unsolved research problem.
    Humans are not good at evaluating what will be hard for AI and what will be easy.
    Even within a domain, performance can vary wildly. What’s good accuracy for predicting
    sentiment? On movie reviews, there is a lot of text, and writers tend to be fairly
    clear about what they think and these days 90–95% accuracy is expected. On Twitter,
    two humans might only agree on the sentiment of a tweet 80% of the time. It might
    be possible to get 95% accuracy on the sentiment of tweets about certain airlines
    by just always predicting that the sentiment is going to be negative.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Metrics can also increase a lot in the early days of a project and then suddenly
    hit a wall. I once ran a Kaggle competition where thousands of people competed
    around the world to model my data. In the first week, the accuracy went from 35%
    to 65% percent, but then over the next several months it never got above 68%.
    68% accuracy was clearly the limit on the data with the best most up-to-date machine
    learning techniques. Those people competing in the Kaggle competition worked incredibly
    hard to get that 68% accuracy and I’m sure felt like it was a huge achievement.
    But for most use cases, 65% vs. 68% is totally indistinguishable. If that had
    been an internal project, I would have definitely been disappointed by the outcome.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: My friend Pete Skomoroch was recently telling me how frustrating it was to do
    engineering standups as a data scientist working on machine learning. Engineering
    projects generally move forward, but machine learning projects can completely
    stall. It’s possible, even common, for a week spent on modeling data to result
    in no improvement whatsoever.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/344aa757e20c4a4556bec5285d52dfaf.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: ‍
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Machine Learning is prone to fail in unexpected ways.
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning generally works well as long as you have lots of training data
    *and* the data you’re running on in production looks a lot like your training
    data. Humans are so good at generalizing from training data that we have terrible
    intuitions about this. I built a little robot with a camera and a vision model
    trained on the millions of images of ImageNet, which were taken off the web. I
    preprocessed the images on my robot camera to look like the images from the web
    but the accuracy was much worse than I expected. Why? Images off the web tend
    to frame the object in question. My robot wouldn’t necessarily look right at an
    object in the same way a human photographer would. Humans likely not even notice
    the difference but modern deep learning networks suffered a lot. There are ways
    to deal with this phenomenon, but I only noticed it because the degradation in
    performance was so jarring that I spent a lot of time debugging it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你有大量的训练数据*并且*生产环境中的数据与训练数据非常相似，机器学习通常能表现良好。人类在从训练数据中泛化方面非常出色，但我们对这一点的直觉非常糟糕。我用一个相机和一个基于ImageNet数百万张图像训练的视觉模型构建了一个小机器人，这些图像是从网上获取的。我在机器人相机上预处理了图像，使其看起来像来自网上的图像，但准确性远低于我预期的水平。为什么？网上的图像往往会把目标框起来。我的机器人可能不会像人类摄影师那样直接看着物体。人类可能甚至不会注意到这种差异，但现代深度学习网络却受到了很大的影响。有办法处理这种现象，但我只是因为性能下降非常明显，花了很多时间调试。
- en: Much more pernicious are the subtle differences that lead to degraded performance
    that are hard to spot. Language models trained on the New York Times don’t generalize
    well to social media texts. We might expect that. But apparently, models trained
    on text from 2017 experience degraded performance on text written in 2018\. Upstream
    distributions shift over time in lots of ways. Fraud models break down completely
    as adversaries adapt to what the model is doing.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 更棘手的是那些微妙的差异，这些差异导致性能下降且难以察觉。训练在《纽约时报》上的语言模型不适合社交媒体文本。这是我们可以预期的。然而，显然，训练于2017年文本的模型在处理2018年写的文本时性能下降。上游分布随着时间以多种方式发生变化。欺诈模型在对手适应模型行为时完全崩溃。
- en: 3\. Machine Learning requires lots and lots of relevant training data.
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 机器学习需要大量相关的训练数据。
- en: Everyone knows this, and yet it’s such a huge barrier. Computer vision can do
    amazing things, provided you are able to collect and label a massive amount of
    training data. For some use cases, the data is a free byproduct of some business
    process. This is where machine learning tends to work really well. For many other
    use cases, training data is incredibly expensive and challenging to collect. A
    lot of medical use cases seem perfect for machine learning — crucial decisions
    with lots of weak signals and clear outcomes — but the data is locked up due to
    important privacy issues or not collected consistently in the first place.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人都知道这一点，然而这依然是一个巨大的障碍。计算机视觉可以做出惊人的事情，只要你能够收集和标注大量的训练数据。对于某些使用案例，数据是某些业务过程的免费副产品。这是机器学习往往表现非常好的地方。对于许多其他使用案例，训练数据是极其昂贵且难以收集的。很多医疗使用案例看起来非常适合机器学习——做出关键决策时有许多微弱信号和明确结果——但由于重要的隐私问题，数据被锁定或最初没有被一致地收集。
- en: Many companies don’t know where to start investing in collecting training data.
    It’s a significant effort and it’s hard to predict a priori how well the model
    will work.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 很多公司不知道从哪里开始投资于收集训练数据。这是一个重大工作，而且很难预先预测模型的表现如何。
- en: What are the best practices to deal with these issues?
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理这些问题的最佳实践是什么？
- en: '**1\. Pay a lot of attention to your training data.**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 非常注意你的训练数据。**'
- en: Look at the cases where the algorithm is misclassifying data that it was trained
    on. These are almost always mislabels or strange edge cases. Either way, you really
    want to know about them. Make everyone working on building models look at the
    training data and label some of the training data themselves. For many use cases,
    it’s very unlikely that a model will do better than the rate at which two independent
    humans agree.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 查看算法错误分类了它曾训练过的数据的情况。这些几乎总是标签错误或奇怪的边缘案例。不管怎样，你真的需要了解这些情况。让所有从事模型构建的人员查看训练数据，并自己标注一些训练数据。对于许多使用案例，模型的表现很可能不会超过两个独立的人的一致率。
- en: '**2\. Get something working end-to-end right away, then improve one thing at
    a time.**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 立即使某些东西从头到尾正常工作，然后一次改进一件事。**'
- en: Start with the simplest thing that might work and get it deployed. You will
    learn a ton from doing this. Additional complexity at any stage in the process
    always improves models in research papers, but it seldom improves models in the
    real world. Justify every additional piece of complexity.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从可能有效的最简单方案开始并将其部署。你将从中学到很多。在过程中的任何阶段添加的复杂性通常在研究论文中会改善模型，但在现实世界中却很少见效。为每一项额外的复杂性提供合理的理由。
- en: Getting something into the hands of the end-user helps you get an early read
    on how well the model is likely to work and it can bring up crucial issues like
    a disagreement between what the model is optimizing and what the end-user wants.
    It also may make you reassess the kind of training data you are collecting. It’s
    much better to discover those issues quickly.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将产品交到最终用户手中可以帮助你早期了解模型的表现如何，并可能暴露出一些关键问题，例如模型优化的目标与最终用户需求之间的矛盾。这也可能促使你重新评估你所收集的训练数据。快速发现这些问题要好得多。
- en: '**3\. Look for graceful ways to handle the inevitable cases where the algorithm
    fails.**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 寻找优雅的方式来处理算法不可避免的失败情况。**'
- en: Nearly all machine learning models fail a fair amount of the time, and how this
    is handled is absolutely crucial. Models often have a reliable confidence score
    that you can use. With batch processes, you can build human-in-the-loop systems
    that send low confidence predictions to an operator to make the system work reliably
    end to end and collect high-quality training data. With other use cases, you might
    be able to present low confident predictions in a way that potential errors are
    flagged or are less annoying to the end-user.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有的机器学习模型都有一定的失败率，如何处理这些失败至关重要。模型通常有一个可靠的置信度评分可以使用。通过批处理流程，你可以建立人工干预系统，将低置信度的预测发送给操作员，从而使系统在端到端的工作中保持可靠，并收集高质量的训练数据。在其他用例中，你可能能够以某种方式展示低置信度的预测，从而标记潜在的错误或减少对最终用户的困扰。
- en: Here’s an example of a failure that wasn’t handled gracefully. Microsoft hadn’t
    predicted how quickly their Tay bot would learn bad behavior from trolls on Twitter.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个未能优雅处理的失败示例。微软未能预测到他们的Tay机器人会多快从Twitter上的恶意用户那里学到不良行为。
- en: ‍![](../Images/82515c2a691c6c6dc75ff4e3cf64a1ee.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ‍![](../Images/82515c2a691c6c6dc75ff4e3cf64a1ee.png)
- en: ‍
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ‍
- en: What’s Next?‍
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步？‍
- en: The original goal of machine learning was mostly around smart decision making,
    but more and more we are trying to put machine learning into products we use.
    As we start to rely more and more on machine learning algorithms, machine learning
    becomes an engineering discipline as much as a research topic. I’m incredibly
    excited about the opportunity to build completely new kinds of products but worried
    about the lack of tools and best practices. So much so that I started a company
    to help with this called [Weights and Biases](http://wandb.com/). If you’re interested
    in learning more, check out what we’re up to.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习最初的目标主要是智能决策，但我们越来越多地将机器学习应用于我们使用的产品中。随着我们越来越依赖机器学习算法，机器学习不仅仅是一个研究主题，它也成为了一个工程学科。我对能够构建全新类型的产品感到非常兴奋，但对缺乏工具和最佳实践感到担忧。因此，我创办了一家名为[Weights
    and Biases](http://wandb.com/)的公司来帮助解决这个问题。如果你对了解更多感兴趣，可以查看我们正在做的事情。
- en: Thanks, [Yan-David Erlich](https://medium.com/u/6e3bf872645a?source=post_page-----8e9b9cf49641----------------------), [James
    Cham](https://medium.com/u/86a8b1c606a8?source=post_page-----8e9b9cf49641----------------------), [Noga
    Leviner](https://medium.com/u/585926b0286?source=post_page-----8e9b9cf49641----------------------),
    and [Carey Phelps](https://medium.com/u/569a4293d9d2?source=post_page-----8e9b9cf49641----------------------) for
    reading early versions of this and [Peter Skomoroch](https://medium.com/u/5f3569495efc?source=post_page-----8e9b9cf49641----------------------) for
    getting me thinking about this topic.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢[Yan-David Erlich](https://medium.com/u/6e3bf872645a?source=post_page-----8e9b9cf49641----------------------)、[James
    Cham](https://medium.com/u/86a8b1c606a8?source=post_page-----8e9b9cf49641----------------------)、[Noga
    Leviner](https://medium.com/u/585926b0286?source=post_page-----8e9b9cf49641----------------------)以及[Carey
    Phelps](https://medium.com/u/569a4293d9d2?source=post_page-----8e9b9cf49641----------------------)阅读早期版本，并感谢[Peter
    Skomoroch](https://medium.com/u/5f3569495efc?source=post_page-----8e9b9cf49641----------------------)让我开始思考这个话题。
- en: '[Original](https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641).
    Reposted with permission.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@l2k/why-are-machine-learning-projects-so-hard-to-manage-8e9b9cf49641)。已获许可转载。'
- en: '**Bio:** [Lukas Biewald](https://twitter.com/l2k) is the founder of Weights
    & Biases, and previously, the founder of Figure Eight (formerly CrowdFlower).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：** [卢卡斯·比沃尔德](https://twitter.com/l2k) 是Weights & Biases的创始人，曾是Figure
    Eight（前身为CrowdFlower）的创始人。'
- en: '**Related:**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[9 Reasons why your machine learning project will fail](https://www.kdnuggets.com/2018/07/why-machine-learning-project-fail.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9个原因说明你的机器学习项目会失败](https://www.kdnuggets.com/2018/07/why-machine-learning-project-fail.html)'
- en: '[How to Turn your Data Science Projects into a Success](https://www.kdnuggets.com/2017/07/olavlaudy-turn-data-science-projects-into-success.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何将你的数据科学项目转变为成功](https://www.kdnuggets.com/2017/07/olavlaudy-turn-data-science-projects-into-success.html)'
- en: '[Top Reasons Why Big Data, Data Science, Analytics Initiatives Fail](https://www.kdnuggets.com/2016/12/top-reasons-big-data-science-analytics-fail.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大数据、数据科学、分析项目失败的主要原因](https://www.kdnuggets.com/2016/12/top-reasons-big-data-science-analytics-fail.html)'
- en: '* * *'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的IT需求'
- en: '* * *'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Hard Coding in a Data Science Project - Use Config Files Instead](https://www.kdnuggets.com/2023/06/stop-hard-coding-data-science-project-config-files-instead.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止在数据科学项目中硬编码 - 使用配置文件](https://www.kdnuggets.com/2023/06/stop-hard-coding-data-science-project-config-files-instead.html)'
- en: '[3 Hard Python Coding Interview Questions For Data Science](https://www.kdnuggets.com/2023/03/3-hard-python-coding-interview-questions-data-science.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学领域的3个难题Python编码面试问题](https://www.kdnuggets.com/2023/03/3-hard-python-coding-interview-questions-data-science.html)'
- en: '[How Hard is it to Get into FAANG Companies](https://www.kdnuggets.com/2023/05/hard-get-faang-companies.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[进入FAANG公司有多难](https://www.kdnuggets.com/2023/05/hard-get-faang-companies.html)'
- en: '[Want to Become a Data Scientist? Part 1: 10 Hard Skills You Need](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[想成为数据科学家？第一部分：你需要的10项硬技能](https://www.kdnuggets.com/want-to-become-a-data-scientist-part-1-10-hard-skills-you-need)'
- en: '[Why are More Developers Using Python for Their Machine Learning Projects?](https://www.kdnuggets.com/2022/01/developers-python-machine-learning-projects.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么越来越多的开发者使用Python进行机器学习项目？](https://www.kdnuggets.com/2022/01/developers-python-machine-learning-projects.html)'
- en: '[Top 10 MLOps Tools to Optimize & Manage Machine Learning Lifecycle](https://www.kdnuggets.com/2022/10/top-10-mlops-tools-optimize-manage-machine-learning-lifecycle.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化和管理机器学习生命周期的10大MLOps工具](https://www.kdnuggets.com/2022/10/top-10-mlops-tools-optimize-manage-machine-learning-lifecycle.html)'
