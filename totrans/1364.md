# 使用 Snorkel 标记数据

> 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)

[评论](#comments)

**由 [Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/)、[Stefan Denkovski](https://www.linkedin.com/in/stefandenkovski/)、[Michal Malyska](https://www.linkedin.com/in/malyskamichal/)、[Sally Moon](https://www.linkedin.com/in/sallysaeyoungmoon/)、[Brandon Rufino](https://www.linkedin.com/in/brandon-rufino/)、[NLP4H](https://nlp4h.com/authors/)**

![Image for post](../Images/e16079ec47d75638df56b6c91eb5db14.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速入门网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的信息技术

* * *

在本教程中，我们将深入介绍如何使用 Snorkel 为未标记的数据集生成标签。我们将通过引导您完成 Snorkel 的实际临床应用，提供基本的 Snorkel 组件示例。具体而言，我们将使用 Snorkel 尝试提升预测 [多发性硬化症 (MS) 严重程度评分](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss) 的结果。请享用！

*查看 *[*Snorkel 介绍教程*](https://www.snorkel.org/use-cases/01-spam-tutorial)* 以了解垃圾邮件标记的流程。有关 Snorkel 在实际应用中的高性能示例，请参见 *[*Snorkel 的出版列表*](https://www.snorkel.org/resources/)*。*

*查看我们其他聚焦于 NLP 的 MS 严重程度分类工作 *[*这里*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*。*

### 什么是 Snorkel？

Snorkel 是一个帮助构建和管理训练数据集的系统，无需手动标记。Snorkel 流水线的第一个组件包括标记功能，这些功能设计为弱启发式函数，用于预测给定未标记数据的标签。我们为 MS 严重程度评分标记开发的标记功能如下：

+   在文本中进行多个关键字搜索（使用正则表达式）。例如，在查找严重程度评分时，我们搜索了数字格式和罗马数字格式的短语。

+   常见基准如逻辑回归、线性判别分析和支持向量机，这些模型使用词频-逆文档频率（简称 tf-idf）特征进行训练。

+   Word2Vec 卷积神经网络 (CNN)。

+   我们的 MS-BERT 分类器在[这篇博客文章](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)中有所描述。

Snorkel 管道的第二个组成部分是一个生成模型，该模型根据所有标注函数的预测输出每个数据点的单个置信度加权训练标签。它通过学习根据标注函数的一致性和分歧来估计标注函数的准确性和相关性。

### Snorkel 教程

重申一下，在本文中我们演示了 MS 严重程度评分的标签生成。MS 严重程度的常见测量指标是 EDSS 或扩展残疾状态量表。这是一种从 0 到 10 的量表，取决于 MS 症状的严重程度。我们通常将 EDSS 称为 MS 严重程度评分，但为了让我们的读者了解更多信息，我们提供了这些信息。有关此评分的更多描述，请参见[这里](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)。

### 第 0 步：获取数据集

在我们的任务中，我们使用了由一家领先的 MS 研究医院编制的数据集，其中包含超过*70,000*份 MS 诊疗记录，涉及约 5000 名患者。在这 70,000 份记录中，只有*16,000*份是由专家手动标记的 MS 严重程度。这意味着大约有*54,000*份记录未被标记。正如您可能知道的那样，训练模型时拥有更大的数据集通常会导致更好的模型性能。因此，我们使用 Snorkel 为我们的*54,000*份未标记记录生成了所谓的“银”标签。*16,000*份“金”标签记录在创建各自的标注函数之前用于训练我们的分类器。

### 第 1 步：安装 Snorkel

要将 Snorkel 安装到您的项目中，您可以运行以下命令：

### 第 2 步：添加标注函数

### 设置

标注函数允许您定义弱启发式规则和规则，以便在给定未标记数据的情况下预测标签。这些启发式规则可以来源于专家知识或其他标注模型。在 MS 严重程度评分预测的情况下，我们的标注函数包括：来源于临床医生的关键词搜索函数、训练以预测 MS 严重程度评分的基线模型（tf-idf、word2vec cnn 等）以及我们的 MS-BERT 分类器。

如您所见，您通过在函数上方添加“@labeling_function()”来标记标注函数。对于每个标注函数，一行包含未标记数据（即一个观测/样本）的数据框将被传入。每个标注函数应用启发式规则或模型以获取每行的预测。如果未找到预测，则该函数会回避（即返回 -1）。

当所有标注函数都定义好之后，您可以利用“PandasLFApplier”来获取给定所有标注函数的预测矩阵。

运行以下代码后，你将获得一个 (N X num_lfs) L_predictions 矩阵，其中 N 是“df_unlabelled”中的观察数，“num_lfs”是“lfs”中定义的标注函数数量。

### 标注函数示例 #1：关键字搜索

下面展示了一个使用正则表达式的关键字搜索示例，用于提取以十进制形式记录的 MS 严重性分数。正则表达式函数用于尝试搜索以十进制形式记录的 MS 严重性分数。如果找到，函数将返回适当格式的分数。否则，函数会弃权（即返回 -1），表示没有找到分数。

### 标注函数示例 #2：训练分类器

上面我们看到一个使用关键字搜索的示例。要整合训练好的分类器，你必须执行一个额外的步骤。也就是说，你必须在创建标注函数之前训练和导出你的模型。这里是一个基于 tf-idf 特征训练逻辑回归的示例。

在模型训练好后，实现标注函数就简单如斯：

### 第 3(a) 步：使用 Snorkel 的多数投票

有人说 Snorkel 用于生成标签的最简单函数是“多数投票”。如其名所示，多数投票基于最多票数的类别进行预测。

要实现多数投票，你必须指定“基数”（即类别数）。

### 第 3(b) 步：使用 Snorkel 的标签模型

为了充分利用 Snorkel 的功能，我们使用“标签模型”来生成一个基于所有标注函数获得的预测矩阵（即 L_unlabelled）的单一置信度加权标签。标签模型通过学习估计标注函数的准确性和相关性来进行预测，基于它们的同意和分歧。

你可以定义一个标签模型并指定“基数”。在用 L_unlabelled 训练标签模型后，它将为未标记的数据生成单一的预测。

### 第 4 步：评估工具

### LF 分析 — 覆盖度、重叠度、冲突

为了更好地了解你的标注函数的功能，你可以利用 Snorkel 的 LFAnalysis。LF 分析报告了每个标注函数的极性、覆盖度、重叠度和冲突情况。

这些术语的定义如下，你可以参考 [Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities) 获取更多信息：

+   极性：根据标签矩阵中的证据推断每个 LF 的极性。

+   覆盖度：计算具有至少一个标签的数据点的比例。

+   重叠度：计算具有至少两个（非弃权）标签的数据点的比例。

+   冲突：计算每个标注函数与至少一个其他标注函数不一致的数据点比例。

LFAnalysis 将提供你的标注函数相互之间的表现分析。

### ‘get_label_buckets’

Snorkel 提供了一些额外的评估工具，帮助你了解标注函数的质量。特别是，‘get_label_buckets’ 是一个方便的方式来组合标签并进行比较。有关更多信息，请阅读 [Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html)。

以下代码允许你比较真实标签（`y_gold`）和预测标签（`y_preds`），以查看 Snorkel 正确或错误标记的数据点。这将帮助你精确找出哪些数据点难以正确标记，以便你可以调整标注函数来覆盖这些边缘案例。

请注意，为了进行此分析，我们回过头来创建了一个包含我们‘黄金’标注数据集的标注函数预测的 L_train 矩阵。

另外，你可以使用 ‘get_label_buckets’ 来比较标注函数之间的差异。

以下代码允许你比较 L_unlabelled 中的标签预测，以观察不同的标注函数如何以不同方式标记数据点。

### 第 5 步：部署

### 选择最佳标注模型来标记未标记的数据

按照上述程序，我们基于关键词搜索、基准模型和我们的 MS-BERT 分类器开发了各种标注函数。我们尝试了各种标注函数的集成，并使用 Snorkel 的 Label Model 来获取持出标注数据集的预测。这使我们能够确定哪种标注函数集成最适合标注我们的未标记数据集。

如下表所示，我们观察到仅使用 MS-BERT 分类器（MSBC）就比包含自身的所有集成模型在 Macro-F1 上高出至少 0.02。加入较弱的启发式方法和分类器会持续降低集成模型的表现。此外，我们观察到，随着较弱的分类器和启发式方法被加入到集成模型中，MS-BERT 分类器的冲突量增加。

![图](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)

请注意，基于规则的（RB）指的是我们的关键词搜索。LDA 指的是线性判别分析。TFIDFs 指的是所有基于 tf-idf 特征构建的模型（即逻辑回归、线性判别分析和支持向量机）。

要理解我们的发现，我们必须提醒自己，Snorkel 的标签模型通过各标注函数之间的一致性和不一致性来预测标注函数的准确性和相关性。因此，在存在强标注函数的情况下，例如我们的 MS-BERT 分类器，添加较弱的标注函数会引入更多与强标注函数的不一致，从而降低性能。从这些发现中，我们了解到 Snorkel 可能更适合仅拥有弱启发式和规则的情况。然而，如果你已经拥有强标注函数，开发具有较弱启发式的 Snorkel 集成可能会妨碍性能。

因此，MS-BERT 分类器被选中用于标注我们的未标记数据集。

### 半监督标注结果

MS-BERT 分类器用于为我们的未标记数据集获取“银色”标签。这些“银色”标签与我们的“金色”标签结合，形成银色+金色数据集。为了推断银色标签的质量，开发了新的 MS-BERT 分类器：1) MS-BERT+（在银色+金色标记数据上训练）；2) MS-BERT-silver（在银色标记数据上训练）。这些分类器在之前用于评估我们原始 MS-BERT 分类器（在金色标记数据上训练）的保留测试数据集上进行了评估。MS-BERT+ 实现了 0.86238 的 Macro-F1 和 0.92569 的 Micro-F1，而 MS-BERT-silver 实现了 0.82922 的 Macro-F1 和 0.91442 的 Micro-F1。虽然它们的性能略低于我们原始的 MS-BERT 分类器（Macro-F1 为 0.88296，Micro-F1 为 0.94177），但它们仍超越了以前的 MS 严重性预测基准模型。MS-BERT-silver 的强大结果有助于展示使用我们 MS-BERT 分类器作为标注函数的有效性。它展示了减少专业人员阅读患者咨询记录并手动生成 MS 严重性评分所需的繁琐时间的潜力。

### 谢谢！

感谢大家的阅读！如果您有任何问题，请随时通过 nlp4health (at gmail dot) com 联系我们。:)

### 致谢

我们感谢圣迈克尔医院数据科学与高级分析（DSAA）部门的研究人员和工作人员，在整个项目中提供了一贯的支持和指导。我们还要感谢 Marzyeh Ghassemi 博士和 Taylor Killan，为我们提供了参与这一激动人心项目的机会。最后，我们要感谢圣迈克尔医院 MS 门诊的 Tony Antoniou 博士和 Jiwon Oh 博士，感谢他们对神经检查记录的支持。

*最初发布于*[*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/)*.*

**作者：[The authors](https://nlp4h.com/authors/)** 是多伦多大学的研究生，专注于医疗保健中的自然语言处理。

[原文](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f)。已获许可转载。

**相关：**

+   [手动标注已经是过去。未来是#NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)

+   [从语言到信息：斯坦福大学的另一个优秀NLP课程](/2020/06/languages-information-another-great-nlp-course-stanford.html)

+   [深度神经网络在自然语言处理（NLP）中的不合理进步](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)

### 相关话题

+   [如何使用Python确定最佳拟合数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)

+   [使用Eurybia检测数据漂移以确保生产机器学习模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)

+   [黑客如何利用数据科学窃取数十亿美元的4种方式](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)

+   [利用数据科学使清洁能源更加公平](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)

+   [如何通过使用自动EDA工具来应对数据科学评估测试](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)

+   [使用Matplotlib进行数据可视化入门](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)
