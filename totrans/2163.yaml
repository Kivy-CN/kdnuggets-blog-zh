- en: Unlocking GPT-4 Summarization with Chain of Density Prompting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting](https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Unlocking GPT-4 Summarization with Chain of Density Prompting](../Images/e86e1d3b41641bee015099baa73ac43a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by Author with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chain of Density (CoD) is a novel prompt engineering technique designed for
    optimizing summarization tasks in Large Language Models like GPT-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The technique deals with controlling the information density in the generated
    summary, providing a balanced output that is neither too sparse nor too dense
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoD has practical implications for data science, especially in tasks that require
    high-quality, contextually appropriate summarizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the "right" amount of information to include in a summary is a difficult
    task.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prompt engineering is the fuel that powers advancements in the efficacy of generative
    AI. While existing prompting stalwarts such as [Chain-of-Thought](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)
    and [Skeleton-of-Thought](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)
    focus on structured and efficient output, a recent technique called Chain of Density
    (CoD) aims to optimize the quality of text summarizations. This technique addresses
    the challenge of selecting the "right" amount of information for a summary, ensuring
    it is neither too sparse nor too dense.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Chain of Density
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chain of Density is engineered to improve the summarization capabilities of
    Large Language Models like GPT-4\. It focuses on controlling the density of information
    in the generated summary. A well-balanced summary is often the key to understanding
    complex content, and CoD aims to strike that balance. It uses special prompts
    that guide the AI model to include essential points while avoiding unnecessary
    details.
  prefs: []
  type: TYPE_NORMAL
- en: '[![CoD process depicted](../Images/f8b678617d1cc3cbb6b1ee7f2cc8cecc.png)](https://www.kdnuggets.com/wp-content/uploads/chain-of-density-example-from-paper.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Figure 1**: The Chain of Density process using an example (From [Sparse to
    Dense: GPT-4 Summarization with Chain of Density Prompting](https://arxiv.org/abs/2309.04269))
    (Click to enlarge)'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Chain of Density
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Implementing CoD involves the use of a series of chained prompts that guide
    the model in generating a summary. These prompts are designed to control the model's
    focus, directing it toward essential information and away from irrelevant details.
    For example, you might start with a general prompt for summarization and then
    follow up with specific prompts to adjust the density of the generated text.
  prefs: []
  type: TYPE_NORMAL
- en: Steps of the Chain of Density Prompting Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Identify the Text for Summarization: Choose the document, article, or any piece
    of text that you wish to summarize.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Craft the Initial Prompt: Create an initial summarization prompt tailored to
    the selected text. The aim here is to guide the Large Language Model (LLM) like
    GPT-4 towards generating a basic summary.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Analyze the Initial Summary: Review the summary generated from the initial
    prompt. Identify if the summary is too sparse (missing key details) or too dense
    (containing unnecessary details).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Design Chained Prompts: Based on the initial summary''s density, construct
    additional prompts to adjust the level of detail in the summary. These are the
    "chained prompts" and are central to the Chain of Density technique.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Execute Chained Prompts: Feed these chained prompts back to the LLM. These
    prompts are designed to either increase the density by adding essential details
    or decrease it by removing non-essential information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the Adjusted Summary: Examine the new summary generated by executing
    the chained prompts. Ensure that it captures all essential points while avoiding
    unnecessary details.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Iterate if Necessary: If the summary still doesn''t meet the desired criteria
    for information density, return to step 4 and adjust the chained prompts accordingly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finalize the Summary: Once the summary meets the desired level of information
    density, it is considered finalized and ready for use.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chain of Density Prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following CoD prompt is taken directly from the paper.
  prefs: []
  type: TYPE_NORMAL
- en: 'Article: {{ ARTICLE }}'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You will generate increasingly concise, entity-dense summaries of the above
    Article.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Repeat the following 2 steps 5 times.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Step 1\. Identify 1-3 informative Entities ("; " delimited) from the Article
    which are missing from the previously generated summary.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Step 2\. Write a new, denser summary of identical length which covers every
    entity and detail from the previous summary plus the Missing Entities.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'A Missing Entity is:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Relevant: to the main story.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Specific: descriptive yet concise (5 words or fewer).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Novel: not in the previous summary.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Faithful: present in the Article.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Anywhere: located anywhere in the Article.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Guidelines:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific,
    containing little information beyond the entities marked as missing. Use overly
    verbose language and fillers (e.g., "this article discusses") to reach ~80 words.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Make every word count: rewrite the previous summary to improve flow and make
    space for additional entities.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Make space with fusion, compression, and removal of uninformative phrases
    like "the article discusses".'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- The summaries should become highly dense and concise yet self-contained,
    e.g., easily understood without the Article.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Missing entities can appear anywhere in the new summary.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- Never drop entities from the previous summary. If space cannot be made, add
    fewer new entities.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Remember, use the exact same number of words for each summary.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys
    are "Missing_Entities" and "Denser_Summary".
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chain of Density is not a one-size-fits-all solution. It requires careful crafting
    of chained prompts to suit the specific needs of a task. However, when implemented
    correctly, it can significantly improve the quality and relevance of AI-generated
    summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chain of Density offers a new avenue in prompt engineering, specifically geared
    towards improving summarization tasks. Its focus on controlling information density
    makes it an invaluable tool for generating high-quality summaries. By incorporating
    CoD into your projects, you can tap into the advanced summarization capabilities
    of next-generation language models.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Matthew Mayo**](https://www.linkedin.com/in/mattmayo13/) ([**@mattmayo13**](https://twitter.com/mattmayo13))
    holds a Master''s degree in computer science and a graduate diploma in data mining.
    As Editor-in-Chief of KDnuggets, Matthew aims to make complex data science concepts
    accessible. His professional interests include natural language processing, machine
    learning algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.linkedin.com/in/mattmayo13/)****[Matthew Mayo](https://www.kdnuggets.com/wp-content/uploads/./profile-pic.jpg)****
    ([**@mattmayo13**](https://twitter.com/mattmayo13)) holds a master''s degree in
    computer science and a graduate diploma in data mining. As managing editor of
    [KDnuggets](https://www.kdnuggets.com/) & [Statology](https://www.statology.org/),
    and contributing editor at [Machine Learning Mastery](https://machinelearningmastery.com/),
    Matthew aims to make complex data science concepts accessible. His professional
    interests include natural language processing, language models, machine learning
    algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Unraveling the Power of Chain-of-Thought Prompting in Large Language Models](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Enhancing LLM Reasoning: Unveiling Chain of Code Prompting](https://www.kdnuggets.com/enhancing-llm-reasoning-unveiling-chain-of-code-prompting)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlocking Reliable Generations through Chain-of-Verification: A…](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Approaches to Text Summarization: An Overview](https://www.kdnuggets.com/2019/01/approaches-text-summarization-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Summarization with GPT-3](https://www.kdnuggets.com/2022/04/packt-summarization-gpt3.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
