# 使用 R 学习广义线性模型（GLM）

> 原文：[https://www.kdnuggets.com/2017/10/learn-generalized-linear-models-glm-r.html](https://www.kdnuggets.com/2017/10/learn-generalized-linear-models-glm-r.html)

**由 Chaitanya Sagar 提供，Perceptive Analytics。**

> **编辑备注：** 以下讨论的数据文件可以在这里获取：
> 
> +   [**cola.csv**](https://gist.githubusercontent.com/mmmayo13/0112df82bf54961e60edfe6a69bbe22c/raw/2ceaa9131ebb40595a4d76a423ffe5c1c91ca6e3/cola.csv)
> +   
> +   [**penalty.csv**](https://gist.githubusercontent.com/mmmayo13/0e57f0b86ee3e1d58f067ecf36efc9fe/raw/6a433f74c589a68ae436ee9a358e6965dae34a63/penalty.csv)

广义线性模型（GLM）有助于将因变量表示为自变量的线性组合。简单线性回归是 GLM 的传统形式。当因变量呈正态分布时，简单线性回归效果良好。然而，在实际情况中，因变量正态分布的假设常常被违反。例如，考虑一个因变量只能取正值并且有肥尾的情况。这里，因变量是售出的咖啡数量，自变量是温度。

![R GLM header](../Images/c27e32b99685cf77c1f9961d64d36346.png)

假设我们已经建立了变量之间的线性关系。温度每增加 1 度，预期售出的咖啡数量减少 10 单位。这种模型的问题在于，它可能会给出毫无意义的结果。例如，当温度增加 1 度时，模型可能会输出负的咖啡销售数量。广义线性模型（GLM）在这种情况下非常有用。GLM 被广泛应用于建模自变量具有任意分布的情况，即除了正态分布之外的分布。GLM 的基本直觉是将因变量建模为自变量的线性组合，而不是将因变量建模为自变量的线性组合。用于转换自变量的函数称为链接函数。在上述例子中，咖啡销售数量的分布不是正态分布而是泊松分布，对变量进行对数变换（对数将作为链接函数）之后进行回归，将得到一个合理的模型。GLM 将具有任意分布的数据转换为适合的线性模型的能力使其成为一个强大的工具。

在这篇文章中，我们旨在讨论行业中广泛使用的各种广义线性模型（GLMs）。我们关注于：a）对数线性回归 b）解释对数变换和 c）二元逻辑回归。我们还回顾了基础分布和适用的链接函数。然而，我们在文章开始时简要讨论了广义线性模型的传统形式——简单线性回归。除了对上述模型的详细解释外，我们还提供了步骤和带注释的 R 脚本，以在 R 统计软件上实现建模技术。为了在 R 上进行演示，我们使用了示例数据集。希望你觉得这篇文章对你有帮助。

**线性回归**

线性回归是最基本的广义线性模型。线性回归建模了因变量与自变量之间的线性关系，无需任何变换。该模型假设变量服从正态分布。其形式为 Yi = α + βXi [方程 1]。系数使用普通最小二乘法（OLS）计算。有关线性回归和 OLS 的详细解释，请参阅我们之前的文章 [https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html](https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html)。该文章提供了线性回归的解释和示例。希望你现在对线性回归的概念感到舒适。

现在，为了展示线性回归的局限性，我们将使用一个不太完美的案例在 R 中实现线性模型。数据包括两个变量——温度和大学校园内的可口可乐销售。请点击这里下载。让我们可视化数据，并拟合一个线性模型来预测根据给定温度的可口可乐销售量。R 代码如下：

```py
## Prepare scatter plot

#Read data from .csv file
data = read.csv("Cola.csv", header = T)
head(data)

#Scatter Plot
plot(data, main = "Scatter Plot")
```

**图 1 散点图**

![图 1](../Images/6ec534da855e0214a6d21717e6d0b9bd.png)

图 1 通过可视化数据，帮助我们更好地理解温度与可口可乐销售之间的关系。我们观察到，销售量随着温度的升高而呈指数增长。

```py
## Add best-fit line to the scatter plot

#Install Package
install.packages("hydroGOF")
library("hydroGOF")

#Fit linear model using OLS
model = lm(Cola ~ Temperature, data)

#Overlay best-fit line on scatter plot
abline(model)

#Calculate RMSE
PredCola = predict(model, data)
RMSE = rmse(PredCola, data$Cola)
```

温度与可乐销售之间的关系在方程 [2] 中表示。该模型的均方根误差为 241.49，偏差较大。通过将温度代入方程中，可以得到可乐销售量的值。

![方程](../Images/67b12841cd5b8dbc8164e94de4fd67e2.png) [2]

**图 2 在散点图上叠加由简单线性回归给出的最佳拟合线**

![图 2](../Images/d3b10cad33ee77171133e808e1aa5267.png)

图 2 显示了根据简单线性回归给出的最佳拟合线。拟合效果不好，导致不合理的预测。根据模型，温度低于 10 单位时，可乐销售量将为负。应对这种情况有两种方法。第一，拟合一个非线性模型。第二，将数据转换以拟合线性模型。在下一节中，我们将讨论第二种方法。

**对数线性回归**

对数线性回归在因变量和自变量遵循指数关系时变得非常有用。这意味着Y不会随着X的单位变化线性变化，而是Y随着X单位变化按固定百分比变化。例如，在复利情况下，到期金额与时间T遵循指数关系。随着T增加一个单位，到期金额增加一定百分比，即利率。另一个例子是预期工资和教育水平。预期工资与教育水平之间并不呈线性关系，而是随着教育水平呈指数增长。这些增长模型描绘了各种现实生活中的情况，并可以使用对数线性回归进行建模。除了指数关系之外，当因变量遵循以下分布时，对因变量进行对数变换也很有用：a) 对数正态分布 - 对数正态分布是随机变量的分布，其对数服从正态分布。因此，对对数正态随机变量取对数使变量呈正态分布，适合线性回归。b) 泊松分布 - 泊松分布是来自泊松实验的随机变量的分布。例如，时间段T内的成功或失败次数遵循泊松分布。

在本文中，我们重点关注指数关系，表示为*Y=a(b)^X* [Eq. 2]。在这种情况下，对数变换将使关系线性化。我们可以将*log(Y)*表示为X的线性组合。对方程两边取对数，我们得到log *(Y)=log(a)+log⁡(b)X*。现在我们可以使用OLS估计模型。请注意，这个方程与Eq. 1非常相似，*log(a)*和*log(b)*分别等同于*α*和*β*。接下来我们将深入探讨对数线性模型的解释。*log(a)*是常数项，*log(b)*是Y随X单位变化的增长率。*log(b)*的负值表示Y在X单位增加时减少一定百分比。现在我们将在R中使用可口可乐销售数据实现模型。R代码如下。

```py
## Fitting Log-linear model

# Transform the dependent variable
data$LCola = log(data$Cola, base = exp(1))

#Scatter Plot
plot(LCola ~ Temperature, data  = data , main = "Scatter Plot")

#Fit the best line in log-linear model
model1 = lm(LCola ~ Temperature, data)
abline(model1)

#Calculate RMSE
PredCola1 = predict(model1, data)
RMSE = rmse(PredCola1, data$LCola)
```

**图3 对数线性回归给出的最佳拟合线**

![Fig 3](../Images/904c64eb887ca12a309765d48c122b41.png)

图3展示了使用对数线性回归得到的最佳拟合线。我们可以将其视为一个两步过程，即对两边取对数进行数据变换，然后对变换后的数据使用简单线性回归。计算得到的模型如下：

![Eq 3](../Images/941ecb922ca885c4364c6b798ac5daab.png) [3]

通过将温度值代入公式[3]，可以预测可乐的销售量。我们观察到，拟合效果比简单线性回归有了显著改善。转化模型的RMSE仅为0.24。请注意，日志线性回归还解决了可乐销售量出现荒谬负值的问题。对于任何温度值，我们都不会得到负的可乐销售量。简单的对数变换帮助我们处理这些荒谬情况。在接下来的部分，我们将讨论在各种情况下很有用的其他对数变换。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT工作

* * *

### 更多相关主题

+   [广义可扩展的最优稀疏决策树（GOSDT）](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)

+   [为什么你应该使用线性回归模型而不是……](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [学习机器学习的线性代数的三个免费资源](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)

+   [了解大型语言模型](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)

+   [比较线性回归与逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)

+   [线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)
