- en: How to Know if a Neural Network is Right for Your Machine Learning Initiative
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何知道神经网络是否适合您的机器学习计划
- en: 原文：[https://www.kdnuggets.com/2020/11/neural-network-right-machine-learning-initiative.html](https://www.kdnuggets.com/2020/11/neural-network-right-machine-learning-initiative.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/11/neural-network-right-machine-learning-initiative.html](https://www.kdnuggets.com/2020/11/neural-network-right-machine-learning-initiative.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By Frank Fineis, Lead Data Scientist at [Avatria](http://www.avatria.com/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Frank Fineis，Avatria 的首席数据科学家 [Avatria](http://www.avatria.com/)**'
- en: '![Image](../Images/144a940379294e3e3f816ae0f54df5a4.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/144a940379294e3e3f816ae0f54df5a4.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Deep learning models (aka neural nets) now power everything from self-driving
    cars to video recommendations on a YouTube feed, having grown very popular over
    the last couple of years. Despite their popularity, the technology is known to
    have some drawbacks, such as the deep learning “[reproducibility crisis](https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis/)”—
    as it is very common for researchers at one to be unable to recreate a set of
    results published by another, even on the same data set.  Additionally, the steep
    costs of deep learning would give any company pause, as the [FAANG](https://en.wikipedia.org/wiki/Big_Tech#FAANG) companies
    have spent [over $30,000](https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82) to
    train just a single (very) deep net.  Even the largest tech companies on the planet
    struggle with the scale, depth, and complexity of venturing into neural nets,
    while the same problems are even more pronounced for smaller data science organizations
    as neural nets  can be both time-and cost-prohibitive. Also, there is no guarantee
    that neural nets will be able to outperform benchmark models like logistic regression
    or gradient-boosted ones, as neural nets are finicky and typically require added
    data and engineering complexities.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型（即神经网络）现在驱动着从自动驾驶汽车到 YouTube 推荐视频的所有事物，在过去几年中变得非常流行。尽管它们很受欢迎，但该技术也有一些缺点，例如深度学习的“[可重复性危机](https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis/)”，因为一个研究人员很常无法重现另一研究人员发布的一组结果，即使在相同的数据集上。此外，深度学习的高昂成本会让任何公司感到迟疑，因为[FAANG](https://en.wikipedia.org/wiki/Big_Tech#FAANG)公司已花费[超过
    $30,000](https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82)来训练一个（非常）深的网络。即使是全球最大的科技公司也在神经网络的规模、深度和复杂性上遇到困难，而对较小的数据科学组织来说，这些问题更加明显，因为神经网络可能既费时又昂贵。此外，神经网络并不一定能超越基准模型，如逻辑回归或梯度提升模型，因为神经网络难以调优，通常需要额外的数据和工程复杂性。
- en: With these concerns in mind, it is important to remember that there must be
    a **business reason** for even considering neural nets and it should not be because
    the C-Suite is feeling a bad case of FOMO.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些关注点，重要的是要记住，即使考虑神经网络也必须有一个**商业原因**，而不是因为高管们感到害怕错过（FOMO）。
- en: 'When thinking about the need for neural nets, it''s useful to think about your
    data as coming in three flavors:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑神经网络的需求时，将数据视为三种类型是有用的：
- en: Continuous variables, which consist of numeric, decimal-pointed values.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连续变量，由数值和小数点值组成。
- en: Categorical variables, which offer a limited number of possible values, typically
    semantic.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类别变量，提供有限数量的可能值，通常具有语义。
- en: Text sequences, which provide unstructured semantic information.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本序列，提供非结构化的语义信息。
- en: Decision tree-based algorithms are not the most efficient method for handling
    text sequences or categorical variables with many different values, which can
    require a company to employ creative ways to encode these values into numeric
    features for their models. This can also mean *a lot* of manual feature engineering
    work, as this type of approach adds a lot of complexity to model pipelines when
    the number of potential values exceeds a handful.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 基于决策树的算法不是处理文本序列或具有多种不同值的分类变量的最有效方法，这可能要求公司采用创造性的方式将这些值编码为模型的数值特征。这也可能意味着*大量*的手动特征工程工作，因为这种方法在潜在值数量超过少量时会增加模型管道的复杂性。
- en: 'Neural networks generally have a much easier time learning so-called “sparse
    features,” which is why any organization thinking about venturing into deep learning
    might want to consider these tips before doing so:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通常更容易学习所谓的“稀疏特征”，这也是任何考虑涉足深度学习的组织在此之前可能想要考虑的建议：
- en: Try to stick with pre-built, plug-and-play solutions (at least at first), such
    as models that have been pre-assembled with [TensorFlow](https://www.tensorflow.org/).
    It's always tempting to react to an exciting new paper by attempting to pursue
    the absolute SOTA, but if the model doesn’t come from within a package with at
    least some regular users on GitHub/GitLab, it’s probably not going to work well
    out of the box for your dataset.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽量坚持使用预构建的即插即用解决方案（至少在开始时），例如已经与[TensorFlow](https://www.tensorflow.org/)预组装好的模型。尽管追求令人兴奋的新论文并尝试追求绝对的SOTA很有诱惑力，但如果模型不是来自具有一定常规用户的包（例如GitHub/GitLab上的用户），它可能无法直接适应你的数据集。
- en: Avoid implementing any algorithm that does not come with any accompanying code. [Paperswithcode.com](https://paperswithcode.com/) keeps
    up with the SOTA in deep learning/AI and conveniently links the papers describing
    neural net architectures and their implementations on GitHub. If your team is
    considering a model based on a paper that does not come with a corresponding open-sourced
    implementation (like this paper on a neural net architecture called [seq2slate](https://paperswithcode.com/paper/seq2slate-re-ranking-and-slate-optimization)
    from Google), then don’t. It will be very difficult and time consuming to recreate
    the model and match performance claims made in the paper, and likely means that
    very few people are actually using what the paper proposes.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 避免实现任何没有附带代码的算法。[Paperswithcode.com](https://paperswithcode.com/) 跟踪深度学习/AI领域的SOTA，并方便地链接描述神经网络架构及其在GitHub上的实现的论文。如果你的团队考虑基于一篇没有相应开源实现的论文（例如谷歌的[seq2slate](https://paperswithcode.com/paper/seq2slate-re-ranking-and-slate-optimization)神经网络架构论文）进行建模，那就不要尝试。这将非常困难且耗时，并且可能意味着很少有人实际使用论文所提议的内容。
- en: Don't give up if you don't see immediate results! We can't stress enough the
    value of keeping precise records of configurations and results. There may be dozens
    of hyperparameters to tune, and while some of them will have little effect on
    the outcome, some will change your results dramatically. Keep a careful eye on
    your choice of optimizer and learning rate—this combination can make all the difference
    between whether training will make zero, little, or a lot of progress. A good
    rule of thumb is to start with a very small learning rate to check for loss decrease
    during training.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你没有看到立竿见影的结果，千万不要放弃！我们无法过分强调保持配置和结果精确记录的价值。可能需要调整数十个超参数，其中一些对结果的影响很小，但一些会极大地改变结果。仔细关注你选择的优化器和学习率——这组合能决定训练是否会取得零进展、少量进展或大量进展。一个好的经验法则是从非常小的学习率开始，检查训练期间的损失是否下降。
- en: Training neural nets can take a long time to train using just CPUs, but training
    on a GPU (graphical processor unit) can speed up training by a factor of 10\.
    Get access to a free GPU on [Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb),
    which conveniently comes with the latest version of TensorFlow already installed. When
    evaluating a new model, your data science team should generally do a feature extraction
    and feature engineering on your own VPC, and then upload training sets to Google
    Drive to train models in Colab notebooks. This keeps costs down and avoids additional
    infrastructure for dev ops to maintain. Finally, using TensorFlow's tensorboard
    utility, data scientists can study model training results directly from the cloud
    and compare all of their different experiments.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用仅有的 CPU 训练神经网络可能需要很长时间，但使用 GPU（图形处理单元）可以将训练速度提高 10 倍。通过 [Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb)
    获得免费的 GPU 访问权限，它方便地预装了最新版本的 TensorFlow。在评估新模型时，你的数据科学团队通常应在自己的 VPC 上进行特征提取和特征工程，然后将训练集上传到
    Google Drive，以便在 Colab 笔记本中训练模型。这可以降低成本，并避免额外的基础设施维护。最后，使用 TensorFlow 的 tensorboard
    工具，数据科学家可以直接从云端研究模型训练结果，并比较所有不同的实验。
- en: Write reusable code. It’s much too easy to tweak one of the dozens of neural
    net hyperparameters or to subtly manipulate the training set in a way that greatly
    impacts model results in a notebook development setting and lose track of which
    settings led to which results. But maintaining central dataset creation and model
    training scripts allows you to record the best settings.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写可重用的代码。很容易调整神经网络的多个超参数，或者以微妙的方式操控训练集，这可能会极大地影响模型结果，并且在笔记本开发环境中可能会丢失导致这些结果的设置。但维护中心数据集创建和模型训练脚本可以让你记录最佳设置。
- en: '**Bio: [Frank Fineis](https://www.linkedin.com/in/frank-fineis-41770277/)**
    is the Lead Data Scientist at [Avatria](http://www.avatria.com/), a digital commerce
    firm and developer of e-commerce solutions. The company builds data-driven products
    that leverage machine learning to provide actionable insights for its B2C and
    B2B customer''s e-commerce needs.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Frank Fineis](https://www.linkedin.com/in/frank-fineis-41770277/)**
    是 [Avatria](http://www.avatria.com/) 的首席数据科学家，该公司是一家数字商务公司，专注于开发电子商务解决方案。该公司构建的数据驱动产品利用机器学习为其
    B2C 和 B2B 客户的电子商务需求提供可操作的见解。'
- en: '**Related:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Can Neural Networks Show Imagination? DeepMind Thinks They Can](/2020/09/deepmind-neural-networks-show-imagination.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络能展现想象力吗？DeepMind 认为可以](/2020/09/deepmind-neural-networks-show-imagination.html)'
- en: '[Looking Inside The Blackbox: How To Trick A Neural Network](/2020/09/inside-blackbox-trick-neural-network.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑箱内部观察：如何欺骗神经网络](/2020/09/inside-blackbox-trick-neural-network.html)'
- en: '[Top Python Libraries for Deep Learning, Natural Language Processing & Computer
    Vision](/2020/11/top-python-libraries-deep-learning-natural-language-processing-computer-vision.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习、自然语言处理和计算机视觉的顶级 Python 库](/2020/11/top-python-libraries-deep-learning-natural-language-processing-computer-vision.html)'
- en: More On This Topic
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[RedPajama Project: An Open-Source Initiative to Democratizing LLMs](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama 项目：一个开源倡议以民主化 LLMs](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)'
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
- en: '[Learn Deep Learning by Building 15 Neural Network Projects in 2022](https://www.kdnuggets.com/2022/01/15-neural-network-projects-build-2022.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过构建 15 个神经网络项目来学习深度学习（2022 年）](https://www.kdnuggets.com/2022/01/15-neural-network-projects-build-2022.html)'
- en: '[Neural Network Optimization with AIMET](https://www.kdnuggets.com/2022/04/qualcomm-neural-network-optimization-aimet.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 AIMET 进行神经网络优化](https://www.kdnuggets.com/2022/04/qualcomm-neural-network-optimization-aimet.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[The Importance of Permutation in Neural Network Predictions](https://www.kdnuggets.com/2022/12/importance-permutation-neural-network-predictions.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络预测中置换的重要性](https://www.kdnuggets.com/2022/12/importance-permutation-neural-network-predictions.html)'
