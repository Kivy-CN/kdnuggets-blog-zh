# 接收者操作特征曲线解密（Python中）

> 原文：[https://www.kdnuggets.com/2018/07/receiver-operating-characteristic-curves-demystified-python.html](https://www.kdnuggets.com/2018/07/receiver-operating-characteristic-curves-demystified-python.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**作者 [Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/)，分析科学家**

![Image](../Images/02f70f95e8cbdccd75cab6f2efaf86c9.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在IT领域

* * *

在数据科学中，评估模型性能非常重要，最常用的性能指标是分类得分。然而，当处理具有严重类别不平衡的欺诈数据集时，分类得分并没有多大意义。相反，接收者操作特征（ROC）曲线提供了更好的替代方案。ROC是信号（真正率）与噪声（假正率）的图。模型性能通过查看ROC曲线下的面积（或AUC）来确定。最佳可能的AUC是1，而最差的是0.5（45度随机线）。任何低于0.5的值意味着我们可以简单地做与模型建议相反的事情，将值提高到0.5以上。

虽然ROC曲线很常见，但并没有很多教学资源解释如何计算或推导它。在这篇博客中，我将逐步展示如何使用Python绘制ROC曲线。之后，我将解释基本ROC曲线的特征。

### 类别的概率分布

首先，让我们假设我们的假设模型为每个记录的类别预测生成了一些概率。与大多数二元欺诈模型一样，我们假设我们的类别是‘好’和‘坏’，模型生成了P(X=’bad’)的概率。为了创建这个概率分布，我们绘制了具有不同均值的高斯分布。有关高斯分布的更多信息，请阅读 [this blog](https://towardsdatascience.com/understanding-the-68-95-99-7-rule-for-a-normal-distribution-b7b7cbf760c2)。

```py

import numpy as np
import matplotlib.pyplot as plt
def pdf(x, std, mean):
    cons = 1.0 / np.sqrt(2*np.pi*(std**2))
    pdf_normal_dist = const*np.exp(-((x-mean)**2)/(2.0*(std**2)))
    return pdf_normal_dist
x = np.linspace(0, 1, num=100)
good_pdf = pdf(x,0.1,0.4)
bad_pdf = pdf(x,0.1,0.6)
```

现在我们有了分布，让我们创建一个函数来绘制这些分布。

```py
def plot_pdf(good_pdf, bad_pdf, ax):
    ax.fill(x, good_pdf, "g", alpha=0.5)
    ax.fill(x, bad_pdf,"r", alpha=0.5)
    ax.set_xlim([0,1])
    ax.set_ylim([0,5])
    ax.set_title("Probability Distribution", fontsize=14)
    ax.set_ylabel('Counts', fontsize=12)
    ax.set_xlabel('P(X="bad")', fontsize=12)
    ax.legend(["good","bad"])
```

现在让我们使用这个**plot_pdf**函数生成图：

```py
fig, ax = plt.subplots(1,1, figsize=(10,5))
plot_pdf(good, bad, ax)
```

![](../Images/7a9921ab52c894aab2fe18cf002ba628.png)

现在我们有了二元类别的概率分布，我们可以使用这个分布来推导ROC曲线。

### 导出ROC曲线

要从概率分布中导出ROC曲线，我们需要计算真正率（TPR）和假正率（FPR）。以一个简单的例子，我们假设阈值为P(X=’bad’)=0.6。

![](../Images/86ee109313664de02f85d6b4c2bb54fc.png)

真正率是阈值右侧被标记为“坏”的区域。假正率是阈值右侧被标记为“好”的区域。总正例是“坏”曲线下的总面积，而总负例是“好”曲线下的总面积。我们按图示的方式划分这些值以导出TPR和FPR。我们通过不同的阈值来导出TPR和FPR，以获取ROC曲线。利用这些知识，我们创建ROC绘图函数：

```py
def plot_roc(good_pdf, bad_pdf, ax):
    #Total
    total_bad = np.sum(bad_pdf)
    total_good = np.sum(good_pdf)
    #Cumulative sum
    cum_TP = 0
    cum_FP = 0
    #TPR and FPR list initialization
    TPR_list=[]
    FPR_list=[]
    #Iteratre through all values of x
    for i in range(len(x)):
        #We are only interested in non-zero values of bad
        if bad_pdf[i]>0:
            cum_TP+=bad_pdf[len(x)-1-i]
            cum_FP+=good_pdf[len(x)-1-i]
        FPR=cum_FP/total_good
        TPR=cum_TP/total_bad
        TPR_list.append(TPR)
        FPR_list.append(FPR)
    #Calculating AUC, taking the 100 timesteps into account
    auc=np.sum(TPR_list)/100
    #Plotting final ROC curve
    ax.plot(FPR_list, TPR_list)
    ax.plot(x,x, "--")
    ax.set_xlim([0,1])
    ax.set_ylim([0,1])
    ax.set_title("ROC Curve", fontsize=14)
    ax.set_ylabel('TPR', fontsize=12)
    ax.set_xlabel('FPR', fontsize=12)
    ax.grid()
    ax.legend(["AUC=%.3f"%auc])
```

现在让我们使用这个**plot_roc**函数来生成图表：

```py
fig, ax = plt.subplots(1,1, figsize=(10,5))
plot_roc(good_pdf, bad_pdf, ax)
```

![](../Images/3473fd9e1c1159c53781c36a04da17e5.png)

现在，将概率分布和ROC曲线并排绘制，以便进行视觉比较：

```py
fig, ax = plt.subplots(1,2, figsize=(10,5))
plot_pdf(good_pdf, bad_pdf, ax[0])
plot_roc(good_pdf, bad_pdf, ax[1])
plt.tight_layout()
```

![](../Images/02f70f95e8cbdccd75cab6f2efaf86c9.png)

### 类别分离的影响

现在我们可以导出两个图，看看ROC曲线如何随着类别分离（即模型性能）的改善而变化。我们通过改变概率分布中的高斯均值来实现这一点。

```py
x = np.linspace(0, 1, num=100)
fig, ax = plt.subplots(3,2, figsize=(10,12))
means_tuples = [(0.5,0.5),(0.4,0.6),(0.3,0.7)]
i=0
for good_mean, bad_mean in means_tuples:
    good_pdf = pdf(x,0.1,good_mean)
    bad_pdf = pdf(x,0.1,bad_mean)
    plot_pdf(good_pdf, bad_pdf, ax[i,0])
    plot_roc(good_pdf, bad_pdf, ax[i,1])
    i+=1
plt.tight_layout()
```

![](../Images/20818e7120759fbec5979733f40c7320.png)

如你所见，随着类别之间分离的增加，AUC值也在增加。

### 超越AUC

除了AUC，ROC曲线还可以帮助调试模型。通过查看ROC曲线的形状，我们可以评估模型的误分类情况。例如，如果曲线的左下角接近随机线，则表示模型在X=0时误分类。而如果它在右上方是随机的，则表示错误发生在X=1。同时，如果曲线上有尖峰（而不是平滑的），则表示模型不稳定。

**附加信息**

+   [**数据科学面试指南**](https://towardsdatascience.com/data-science-interview-guide-4ee9f5dc778) - 数据科学是一个相当大且多样化的领域。因此，成为全才确实非常困难...

+   [**极端类别不平衡下的欺诈检测**](https://towardsdatascience.com/fraud-detection-under-extreme-class-imbalance-c241854e60c) - 数据科学中的一个热门领域是欺诈分析。这可能包括信用卡/借记卡欺诈、反洗钱...

**简历：[Syed Sadat Nazrul](https://www.linkedin.com/in/snazrul1/)** 正在使用机器学习来捕捉网络和金融犯罪分子，白天...晚上则撰写有趣的博客。

[原文](https://towardsdatascience.com/receiver-operating-characteristic-curves-demystified-in-python-bd531a4364d0)。经许可转载。

**相关：**

+   [机器学习的学习曲线](/2018/01/learning-curves-machine-learning.html)

+   [选择评估机器学习模型的正确度量标准 – 第1部分](/2018/04/right-metric-evaluating-machine-learning-models-1.html)

+   [选择正确的度量标准评估机器学习模型——第 2 部分](/2018/06/right-metric-evaluating-machine-learning-models-2.html)

### 更多相关内容

+   [通过《快速 Python 数据科学》提升你的 Python 技能！](https://www.kdnuggets.com/2022/06/manning-step-python-game-fast-python-data-science.html)

+   [优化 Python 代码性能：深入了解 Python 性能分析工具](https://www.kdnuggets.com/2023/02/optimizing-python-code-performance-deep-dive-python-profilers.html)

+   [Python 枚举：如何在 Python 中构建枚举](https://www.kdnuggets.com/python-enum-how-to-build-enumerations-in-python)

+   [用 Python 和 Scikit-learn 简化决策树的可解释性](https://www.kdnuggets.com/2017/05/simplifying-decision-tree-interpretation-decision-rules-python.html)

+   [Python 中的稀疏矩阵表示](https://www.kdnuggets.com/2020/05/sparse-matrix-representation-python.html)

+   [数据科学、数据可视化和…的 38 个顶级 Python 库](https://www.kdnuggets.com/2020/11/top-python-libraries-data-science-data-visualization-machine-learning.html)
