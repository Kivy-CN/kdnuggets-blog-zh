- en: 'Machine Learning Exercises in Python: An Introductory Tutorial Series'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html](https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By John Wittenauer, Data Scientist.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Editor''s note:** This tutorial series was started in September of 2014,
    with the 8 installments coming over the course of 2 years. I only mention this
    to put John''s first paragraph into context, and to assure readers that this informative
    series of tutorials, including all of its code, is as relevant and up-to-date
    today as it was at the time it was written. This is great material, both for anyone
    taking Andrew Ng''s MOOC and as a standalone resource.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One of the pivotal moments in my professional development this year came when
    I discovered Coursera. I'd heard of the "MOOC" phenomenon but had not had the
    time to dive in and take a class. Earlier this year I finally pulled the trigger
    and signed up for Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml)
    class. I completed the whole thing from start to finish, including all of the
    programming exercises. The experience opened my eyes to the power of this type
    of education platform, and I've been hooked ever since.
  prefs: []
  type: TYPE_NORMAL
- en: '[![Python exercises](../Images/da01a56ad6eaf310800005885b464145.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 1 - Simple Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)**'
  prefs: []
  type: TYPE_NORMAL
- en: This blog post will be the first in a series covering the programming exercises
    from Andrew's class. One aspect of the course that I didn't particularly care
    for was the use of Octave for assignments. Although Octave/Matlab is a fine platform,
    most real-world "data science" is done in either R or Python (certainly there
    are other languages and tools being used, but these two are unquestionably at
    the top of the list). Since I'm trying to develop my Python skills, I decided
    to start working through the exercises from scratch in Python. The full source
    code is available at [my IPython repo on Github](https://github.com/jdwittenauer/ipython-notebooks).
    You'll also find the data used in these exercises and the original exercise PDFs
    in sub-folders off the root directory if you're interested.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2 - Multivariate Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-2/)**'
  prefs: []
  type: TYPE_NORMAL
- en: In [part 1](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)
    of my series on machine learning in Python, we covered the first part of exercise
    1 in Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml) class.
    In this post we'll wrap up exercise 1 by completing part 2 of the exercise. If
    you recall, in part 1 we implemented linear regression to predict the profits
    of a new food truck based on the population of the city that the truck would be
    placed in. For part 2 we've got a new task - predict the price that a house will
    sell for. The difference this time around is we have more than one dependent variable.
    We're given both the size of the house in square feet, and the number of bedrooms
    in the house. Can we easily extend our previous code to handle multiple linear
    regression? Let's find out!
  prefs: []
  type: TYPE_NORMAL
- en: '[![Python exercises](../Images/21e90d6ac7e5c412887121b27e05b535.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 3 - Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)**'
  prefs: []
  type: TYPE_NORMAL
- en: In part 2 of the series we wrapped up our implementation of multivariate linear
    regression using gradient descent and applied it to a simple housing prices data
    set. In this post we’re going to switch our objective from predicting a continuous
    value (regression) to classifying a result into two or more discrete buckets (classification)
    and apply it to a student admissions problem. Suppose that you are the administrator
    of a university department and you want to determine each applicant's chance of
    admission based on their results on two exams. You have historical data from previous
    applicants that you can use as a training set. For each training example, you
    have the applicant's scores on two exams and the admissions decision. To accomplish
    this, we're going to build a classification model that estimates the probability
    of admission based on the exam scores using a somewhat confusingly-named technique
    called logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 4 - Multivariate Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/)**'
  prefs: []
  type: TYPE_NORMAL
- en: In part three of this series we implemented both simple and regularized logistic
    regression, completing our Python implementation of the second exercise from Andrew
    Ng's machine learning class. There's a limitation with our solution though - it
    only works for binary classification. In this post we'll extend our solution from
    the previous exercise to handle multi-class classification. In doing so, we'll
    cover the first half of exercise 3 and set ourselves up for the next big topic,
    neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 5 - Neural Networks](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/)**'
  prefs: []
  type: TYPE_NORMAL
- en: In part four we wrapped up our implementation of logistic regression by extending
    our solution to handle multi-class classification and testing it on the hand-written
    digits data set. Using just logistic regression we were able to hit a classification
    accuracy of about 97.5%, which is reasonably good but pretty much maxes out what
    we can achieve with a linear model. In this blog post we'll again tackle the hand-written
    digits data set, but this time using a feed-forward neural network with backpropagation.
    We'll implement un-regularized and regularized versions of the neural network
    cost function and compute gradients via the backpropagation algorithm. Finally,
    we'll run the algorithm through an optimizer and evaluate the performance of the
    network on the handwritten digits data set.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 6 - Support Vector Machines](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-6/)**'
  prefs: []
  type: TYPE_NORMAL
- en: We're now hitting the home stretch of both the course content and this series
    of blog posts. In this exercise, we'll be using support vector machines (SVMs)
    to build a spam classifier. We'll start with SVMs on some simple 2D data sets
    to see how they work. Then we'll look at a set of email data and build a classifier
    on the processed emails using a SVM to determine if they are spam or not.
  prefs: []
  type: TYPE_NORMAL
- en: '[![Python exercises](../Images/48e7ef6a1d68ca580cc9feb895fefe81.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 7 - K-Means Clustering & PCA](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''re now down to the last two posts in this series! In this installment we''ll
    cover two fascinating topics: K-means clustering and principal component analysis
    (PCA). K-means and PCA are both examples of unsupervised learning techniques.
    Unsupervised learning problems do not have any label or target for us to learn
    from to make predictions, so unsupervised algorithms instead attempt to learn
    some interesting structure in the data itself. We''ll first implement K-means
    and see how it can be used it to compress an image. We''ll also experiment with
    PCA to find a low-dimensional representation of images of faces.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 8 - Anomaly Detection & Recommendation](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/)**'
  prefs: []
  type: TYPE_NORMAL
- en: We've now reached the last post in this series! It's been an interesting journey.
    Andrew's class was really well-done and translating it all to python has been
    a fun experience. In this final installment we'll cover the last two topics in
    the course - anomaly detection and recommendation systems. We'll implement an
    anomaly detection algorithm using a Gaussian model and apply it to detect failing
    servers on a network. We'll also see how to build a recommendation system using
    collaborative filtering and apply it to a movie recommendations data set.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [John Wittenauer](http://www.johnwittenauer.net/)** ([@jdwittenauer](https://twitter.com/jdwittenauer))
    is a data scientist, engineer, entrepreneur, and technology enthusiast.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[7 Steps to Mastering Machine Learning With Python](/2015/11/seven-steps-machine-learning-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science for Newbies: An Introductory Tutorial Series for Software Engineers](/2017/05/data-science-tutorial-series-software-engineers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
