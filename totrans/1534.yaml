- en: How Optimization Works
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何优化工作
- en: 原文：[https://www.kdnuggets.com/2019/04/how-optimization-works.html](https://www.kdnuggets.com/2019/04/how-optimization-works.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/04/how-optimization-works.html](https://www.kdnuggets.com/2019/04/how-optimization-works.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '[Check out the full course content for How Optimization Works](https://end-to-end-machine-learning.teachable.com/p/building-blocks-how-optimization-works/),
    including video, slides, and code.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看《如何优化工作》的完整课程内容](https://end-to-end-machine-learning.teachable.com/p/building-blocks-how-optimization-works/)，包括视频、幻灯片和代码。'
- en: Optimization is a fancy word for "finding the best way." We can see how it works
    if we take a closer look at drinking tea.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 优化是一个华丽的词汇，意思是“找到最佳方式”。如果我们仔细观察喝茶的过程，就能看到它是如何工作的。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全领域的职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您所在组织的IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: There is a best temperature for tea. If your tea is too hot, it will scald your
    tongue and you won't be able to taste anything for three days. If it’s lukewarm,
    it’s entirely unsatisfying. There is a sweet spot in the middle where it is comfortably
    hot, warming you from the inside out all the way down your throat and radiating
    through your belly. This is the ideal temperature for tea.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 茶的最佳温度是存在的。如果你的茶太热，它会烫伤你的舌头，你可能要三天才能尝到味道。如果茶温温，完全没有满足感。中间有一个最佳点，在那里它温暖舒适，从内而外温暖你的喉咙，辐射到你的腹部。这就是茶的理想温度。
- en: '![figure-name](../Images/0af83ba72f5c26285d49cca5ec57841c.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/0af83ba72f5c26285d49cca5ec57841c.png)'
- en: This happy medium is what we try to find in optimization. That’s what Goldilocks
    was looking for when she tried Papa Bear's bed and found it too hard, tried Mama
    Bear's bed and found it too soft, then tried Baby Bear's bed and found it to be
    just right.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化中，我们尝试找到这种令人满意的中间状态。这就像是《金发姑娘与三只熊》中的情节：金发姑娘尝试了爸爸熊的床，觉得太硬；尝试了妈妈熊的床，觉得太软；然后尝试了小熊的床，发现刚刚好。
- en: Finding how to get things just right turns out to be a very common problem.
    Mathematicians and computer scientist love it because it’s very specific and well
    formulated. You know when you’ve got it right, and you can compare your solution
    against others to see who got it right faster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 找到如何做到刚刚好的方法，原来是一个非常常见的问题。数学家和计算机科学家都喜欢它，因为它非常具体且描述清晰。你知道自己是否做对了，可以将你的解决方案与其他人的进行比较，看看谁更快找到了解决方案。
- en: When a computer scientist tries to find the right temperature for tea, the first
    thing they do is flip the problem upside down. Instead of trying to maximize tea
    drinking enjoyment, they try to minimize suffering while drinking tea. The result
    is the same, and the math works out in the same way. It's not that all computer
    scientists are pessimists, it's just that most optimization problems are naturally
    described in terms of costs - money, time, resources - rather than benefits. In
    math it's convenient to make all your problems look the same before you work out
    a solution, so that you can just solve it the one time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机科学家尝试找到茶的最佳温度时，他们首先会把问题颠倒过来。他们不是试图最大化喝茶的享受，而是尽量减少喝茶时的痛苦。结果是一样的，数学计算也是相同的。并不是说所有计算机科学家都是悲观主义者，而是大多数优化问题自然以成本——如金钱、时间、资源——来描述，而不是以收益来描述。在数学中，将所有问题统一成相同的形式来解决会比较方便，这样你只需要解决一次。
- en: '![figure-name](../Images/6f92a89002e54bf8d8adc545a6514ead.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/6f92a89002e54bf8d8adc545a6514ead.png)'
- en: In machine learning, this cost is often called an error function, because error
    is the undesirable thing, the suffering, that is being minimized. It can also
    be called a cost function, a loss function, or an energy function. They all mean
    pretty much the same thing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，这种代价通常被称为误差函数，因为误差是不希望出现的东西，即苦味，是被最小化的。它也可以被称为代价函数、损失函数或能量函数。它们的含义几乎是相同的。
- en: Exhaustive search
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 穷举搜索
- en: There are a handful of ways to go about finding the best temperature for serving
    tea. The most obvious is just to look at the curve and pick the lowest point.
    Unfortunately, we don't actually know what the curve is when we start out. That
    is implicit in the optimization problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 找到最佳茶温有几种方法。最明显的方法就是直接查看曲线并选择最低点。不幸的是，当我们开始时实际上并不知道曲线是什么。这在优化问题中是隐含的。
- en: '![figure-name](../Images/792e385b51973e6b64777b3e720bf61e.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/792e385b51973e6b64777b3e720bf61e.png)'
- en: But we can make use of our original idea and just measure the curve. We can
    prepare a cup of tea at a given temperature, serve it, and ask our unwitting test
    subject how they enjoyed it. Then we can repeat this process for every temperature
    across the whole range we care about. By the time we're done with this, we do
    know what the whole curve looks like, and then we can just pick temperature for
    which our tea drinker reported the most enjoyment, that is, the least suffering.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以利用我们原来的想法，直接测量曲线。我们可以在给定的温度下准备一杯茶，服务后询问我们的测试对象他们的感受。然后我们可以对整个范围内的每个温度重复这个过程。完成这个过程后，我们确实知道整个曲线的样子，然后我们可以选择茶饮者报告的最喜欢的温度，也就是最少的苦味。
- en: '![figure-name](../Images/b7444b9c41f4a36d5f81ade31cd3b263.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/b7444b9c41f4a36d5f81ade31cd3b263.png)'
- en: This way of finding the best tea temperature is called exhaustive search. It
    is straightforward and effective, but may take a while. If our time is limited,
    it's worth it to check out a few other methods.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种寻找最佳茶温的方法被称为穷举搜索。它直接且有效，但可能需要一些时间。如果我们的时间有限，值得尝试几种其他方法。
- en: Gradient descent
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降
- en: If you imagine that our tea-suffering curve is actually a physical bowl, then
    we could easily find the bottom by dropping a marble in and letting it roll until
    it stops. This is the intuition behind gradient descent - literally "going downhill".
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想象我们的茶苦味曲线实际上是一个物理碗，那么我们可以通过将一个弹珠放进去并让它滚动直到停止来轻松找到底部。这就是梯度下降的直观理解——字面意思是“下坡”。
- en: To use gradient descent we start at an arbitrary temperature. Before beginning,
    we don't know anything about our curve, so we make a random guess. We brew a cup
    of tea at that temperature and see how well our tea drinker likes it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用梯度下降，我们从一个任意的温度开始。在开始之前，我们对我们的曲线一无所知，所以我们做一个随机的猜测。我们在那个温度下冲泡一杯茶，看看我们的品茶者对它的喜欢程度。
- en: '![gradient-descent](../Images/bbef97e27c53db36be0fc88b6360293c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent](../Images/bbef97e27c53db36be0fc88b6360293c.png)'
- en: From there, the next trick is to figure out which direction is downhill and
    which is up. To figure this out, we choose a direction, and choose a new temperature
    a very small distance away. Let's say we choose a temperature to the left. Then
    we brew up another cup of tea at this slightly cooler temperature and see whether
    or not it is better than the first. We discover that it is actually inferior.
    Now we know that "downhill" is to the right - that we need to make our next cup
    warmer to make it better.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，诀窍是弄清楚哪个方向是下坡，哪个方向是上坡。要搞清楚这一点，我们选择一个方向，并选择一个非常小的温度变化。例如，我们选择左边的温度。然后我们用这个稍微凉一点的温度再冲一杯茶，看看是否比第一杯更好。我们发现其实更差了。现在我们知道“下坡”是在右边——也就是我们需要让下一杯茶更暖才能更好。
- en: '![gradient-descent2](../Images/2dc5e52721d7a4cc169936de222969b9.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent2](../Images/2dc5e52721d7a4cc169936de222969b9.png)'
- en: We take a larger step in the direction of warmer tea, brew up a new cup, and
    start the process over again.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在温暖茶的方向上迈出更大的步伐，冲泡一杯新茶，并重新开始这个过程。
- en: '![gradient-descent](../Images/97c46cb23cc11d7686f85726caa3634c.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent](../Images/97c46cb23cc11d7686f85726caa3634c.png)'
- en: We repeat this until we get to the very best temperature for tea.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复这个过程，直到找到最适合泡茶的温度。
- en: '![gradient-descent](../Images/8b0f21c06036f3a48a3fe1f9e5568bba.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent](../Images/8b0f21c06036f3a48a3fe1f9e5568bba.png)'
- en: The steeper the slope, the larger the step we can take. The shallower the slope,
    the smaller the step.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 坡度越陡，我们可以迈出的步伐就越大。坡度越浅，步伐越小。
- en: '![gradient-descent](../Images/532d7f5e4ef792b50d625b690b95760d.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent](../Images/532d7f5e4ef792b50d625b690b95760d.png)'
- en: We will know we are all done when we take a small step away and get the exact
    same level of enjoyment from our tea drinker. This can only happen at the bottom
    of the bowl, where it is flat and there is no downhill.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们退后一步并从我们的茶饮者那里得到完全相同的享受时，我们就知道一切都完成了。这只能在碗的底部发生，在那里是平的，没有下坡。
- en: There are lots of gradient descent methods. Most of them are clever ways to
    measure the slope as efficiently as possible and to get to the bottom of the bowl
    in as few steps as possible - to brew as few cups of tea as we can get away with.
    They use different tricks to avoid completely calculating the slope or to choose
    a step size that is as large as can be gotten away with, but the underlying intuition
    is the same.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多梯度下降方法。它们大多数是通过聪明的方式尽可能高效地测量斜率，以尽可能少的步骤到达碗底——尽可能少地冲泡茶水。它们使用不同的技巧来避免完全计算斜率或选择尽可能大的步长，但基本直觉是相同的。
- en: Including curvature
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 包括曲率
- en: One of the tricks to find the bottom in the bowl in fewer steps is to use not
    just slope, but also curvature, when deciding how big of a step to take. As the
    marble starts to roll down the side of the bowl, is the slope getting steeper?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找碗底的一个技巧是，在决定采取多大步时，不仅使用斜率，还使用曲率。当小球开始滚下碗的侧面时，斜率是否变得更陡？
- en: '![gradient-descent-curvature](../Images/27363264ec22da7cd127ed7b68c79a3c.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent-curvature](../Images/27363264ec22da7cd127ed7b68c79a3c.png)'
- en: If so, then the bottom is probably still far away. Take a big step.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，那么底部可能仍然很远。采取大步。
- en: '![gradient-descent-curvature](../Images/a8fa8b2d33460100b77b35e0fa5815de.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent-curvature](../Images/a8fa8b2d33460100b77b35e0fa5815de.png)'
- en: Or is the slope getting shallower and starting to bottom out?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 还是斜率变得更平缓并开始接近底部？
- en: '![gradient-descent-curvature](../Images/2ce32476efd49a69d7b4b3365f4f3af1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent-curvature](../Images/2ce32476efd49a69d7b4b3365f4f3af1.png)'
- en: If so, the bottom is probably getting closer. Take smaller steps now.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，底部可能越来越近。现在采取更小的步伐。
- en: '![gradient-descent-curvature](../Images/b2c40ca6ff839a9329d3944903fc0fa0.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![gradient-descent-curvature](../Images/b2c40ca6ff839a9329d3944903fc0fa0.png)'
- en: Curvature, this slope-of-the-slope or Hessian, to give it its rightful name,
    can be very helpful if you are trying to take as few steps as possible, however
    it can also be much more expensive to compute. This is a trade-off that comes
    up a lot in optimization. We end up choosing between the number of steps we have
    to take and how hard it is to compute where the next step should be.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 曲率，也就是斜率的斜率或赫希矩阵，准确地说，这在尽可能少走步数时非常有帮助，但计算起来也可能更加昂贵。这是在优化中经常出现的权衡。我们最终在必须采取的步骤数和计算下一个步骤应在哪里的难度之间进行选择。
- en: How gradient descent can break
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降可能会失败
- en: Like a lot of math problems, the more assumptions you’re able to make, the better
    the solution you can come up with. Unfortunately, when working with real data,
    those assumptions don’t always apply.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多数学问题一样，你能够做的假设越多，你能提出的解决方案就越好。不幸的是，在处理真实数据时，这些假设并不总是适用。
- en: There are a lot of ways that this drop-a-marble approach can fail. If there
    is more than one valley for a marble to roll into, we might miss the deepest one.
    Each of these little bowls is called a local minimum. We are interested in finding
    the global minimum, the deepest of all the bowls. Imagine that we are testing
    our tea temperatures on a hot day. It may be that once tea becomes cold enough,
    it makes a great iced tea, which is even more popular. We would never find that
    out by gradient descent alone.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这种掉小球的方法可能会失败很多次。如果有多个小山谷供小球滚入，我们可能会错过最深的一个。每一个这样的碗叫做局部最小值。我们感兴趣的是找到全局最小值，即所有碗中最深的一个。想象一下我们在炎热的日子里测试茶的温度。如果茶变得足够冷，它可能成为一种非常受欢迎的冰茶。仅靠梯度下降，我们永远无法发现这一点。
- en: '![figure-name](../Images/e64b02cacb1d9027c9f860d0dbbd3ff4.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/e64b02cacb1d9027c9f860d0dbbd3ff4.png)'
- en: If the error function is not smooth, there are lots of places a marble could
    get stuck. This could happen if our tea drinkers' enjoyment was heavily impacted
    by passing trains. The periodic occurrence of trains could introduce a wiggle
    into our data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果误差函数不平滑，可能会有许多地方让小球卡住。如果我们的茶饮者的享受受到列车通过的严重影响，就可能发生这种情况。列车的周期性出现可能会在我们的数据中引入波动。
- en: '![figure-name](../Images/e19afd4221e9035b27551b131078720a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/e19afd4221e9035b27551b131078720a.png)'
- en: If the error function you are trying to optimize makes discrete jumps, that
    presents a challenge. Marbles don't roll down stairs well. This could happen if
    our tea drinkers have to rate their enjoyment on a 10-point scale.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试优化的误差函数发生离散跳跃，这将是一个挑战。球体在楼梯上不容易滚动。如果我们的茶客需要在 10 分制上评分，他们可能会遇到这种情况。
- en: '![figure-name](../Images/903ddca73d89553328fcb814329978ca.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/903ddca73d89553328fcb814329978ca.png)'
- en: If the error function is mostly a plateau, but has a bottom that is narrow and
    deep, then the marble is unlikely to find it. Perhaps our tea drinkers absolutely
    despise all tea that is anything but perfect.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果误差函数大部分是一个平坦的区域，但有一个狭窄而深的底部，那么球体可能不容易找到它。也许我们的茶客完全厌恶任何不完美的茶。
- en: '![figure-name](../Images/49d4565f0aab828209cd4291663f7cbe.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/49d4565f0aab828209cd4291663f7cbe.png)'
- en: All of these occur in real machine learning optimization problems.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些情况都发生在真实的机器学习优化问题中。
- en: Robust methods
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稳健方法
- en: If we suspect that our tea satisfaction curve has any of these tricky characteristics,
    we can always fall back to exhaustive search. Unfortunately, exhaustive search
    takes an extremely long time for a lot of problems. Luckily for us, there is a
    middle ground. There is a set of methods that is tougher than gradient descent.
    They go by names like genetic algorithms, evolutionary algorithms, and simulated
    annealing. They take longer to compute than gradient descent, and they take more
    steps, but they don't break nearly so easily. Each has its own quirks, but one
    characteristic that most of them share is a randomness to their steps and jumps.
    This helps them discover the deepest valleys of the error function, even when
    they are difficult to find.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们怀疑我们的茶满意度曲线具有这些棘手的特性，我们可以总是回到穷举搜索。不幸的是，穷举搜索对于许多问题需要极其长的时间。幸运的是，我们有一个中间方案。有一套方法比梯度下降更强大。它们被称为遗传算法、进化算法和模拟退火。这些方法的计算时间比梯度下降更长，步骤更多，但它们不容易崩溃。每种方法都有其独特之处，但大多数方法都有一个共同特征，就是步骤和跳跃的随机性。这帮助它们发现误差函数的最深谷，即使这些谷很难找到。
- en: Optimization algorithms that rely gradient descent are like Formula One race
    cars. They are extremely fast and efficient, but require a very well behaved track
    (error function) to work well. A poorly-placed speed bump could wreck it. The
    more robust methods are like four-wheel-drive pickup trucks. They don't go nearly
    as fast, but they can handle a lot more variability in the terrain. And exhaustive
    search is like traveling on foot. You can get absolutely anywhere, but it may
    take you *really* long time. They are each invaluable in different situations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖梯度下降的优化算法就像一级方程式赛车。它们极其快速和高效，但需要一个非常规则的赛道（误差函数）才能发挥良好。一个不恰当的减速带可能会毁掉它。更稳健的方法就像四轮驱动的皮卡车。它们的速度远不如赛车，但能处理更多的地形变化。而穷举搜索就像徒步旅行。你可以到达任何地方，但可能需要*非常*长的时间。它们在不同的情况下各有其不可替代的价值。
- en: '![figure-name](../Images/3398ba44dceb2b906cae0f0f703714b1.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/3398ba44dceb2b906cae0f0f703714b1.png)'
- en: '[Original](https://brohrer.github.io/how_optimization_works_1.html). Reposted
    with permission.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://brohrer.github.io/how_optimization_works_1.html)。已获许可转载。'
- en: '**Related:**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Optimization 101 for Data Scientists](/2018/08/optimization-101-data-scientists.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的优化 101](/2018/08/optimization-101-data-scientists.html)'
- en: '[Optimization Using R](/2018/05/optimization-using-r.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 R 进行优化](/2018/05/optimization-using-r.html)'
- en: '[An Intuitive Introduction to Gradient Descent](/2018/06/intuitive-introduction-gradient-descent.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梯度下降的直观介绍](/2018/06/intuitive-introduction-gradient-descent.html)'
- en: More On This Topic
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How ChatGPT Works: The Model Behind The Bot](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT 的工作原理：机器人背后的模型](https://www.kdnuggets.com/2023/04/chatgpt-works-model-behind-bot.html)'
- en: '[The Burtch Works 2023 Data Science & AI Professionals Salary Report…](https://www.kdnuggets.com/2023/08/burtch-works-2023-data-science-ai-professionals-salary-report.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Burtch Works 2023 数据科学与人工智能专业人员薪资报告…](https://www.kdnuggets.com/2023/08/burtch-works-2023-data-science-ai-professionals-salary-report.html)'
- en: '[Machine Learning Pipeline Optimization with TPOT](https://www.kdnuggets.com/2021/05/machine-learning-pipeline-optimization-tpot.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 TPOT 进行机器学习管道优化](https://www.kdnuggets.com/2021/05/machine-learning-pipeline-optimization-tpot.html)'
- en: '[SQL Query Optimization Techniques](https://www.kdnuggets.com/2023/03/sql-query-optimization-techniques.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL 查询优化技巧](https://www.kdnuggets.com/2023/03/sql-query-optimization-techniques.html)'
- en: '[Database Optimization: Exploring Indexes in SQL](https://www.kdnuggets.com/2023/07/database-optimization-exploring-indexes-sql.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据库优化：探索 SQL 中的索引](https://www.kdnuggets.com/2023/07/database-optimization-exploring-indexes-sql.html)'
- en: '[Gradient Descent: The Mountain Trekker''s Guide to Optimization with…](https://www.kdnuggets.com/gradient-descent-the-mountain-trekker-guide-to-optimization-with-mathematics)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梯度下降：优化的山地徒步指南](https://www.kdnuggets.com/gradient-descent-the-mountain-trekker-guide-to-optimization-with-mathematics)'
