["```py\nimport pandas as pd\ndf1 = pd.read_csv('file-i-dont-have.csv') # fails\ndo_stuff(df)\n\n```", "```py\nimport pandas as pd\ndf = pd.read_csv('/path/i-dont/have/data.csv') # fails\ndo_stuff(df)\n\n# or \nimport os\nos.chdir('c:\\\\Users\\\\yourname\\\\desktop\\\\python') # fails\n\n```", "```py\n├── data.csv\n├── ingest.py\n├── other-data.csv\n├── output.png\n├── report.html\n└── run.py\n\n```", "```py\ngit add data.csv\n```", "```py\ndef process_data(data, parameter):\n    data = do_stuff(data)\n    data.to_pickle('data.pkl')\n\ndata = pd.read_csv('data.csv')\nprocess_data(data)\ndf_train = pd.read_pickle(df_train)\nmodel = sklearn.svm.SVC()\nmodel.fit(df_train.iloc[:,:-1], df_train['y'])\n\n```", "```py\nx = range(10)\navg = sum(x)/len(x); std = math.sqrt(sum((i-avg)**2 for i in x)/len(x));\nzscore = [(i-avg)/std for x]\n# should be: scipy.stats.zscore(x)\n\n# or\ngroupavg = []\nfor i in df['g'].unique():\n\tdfg = df[df[g']==i]\n\tgroupavg.append(dfg['g'].mean())\n# should be: df.groupby('g').mean()\n\n```", "```py\nassert df['id'].unique().shape[0] == len(ids) # have data for all ids?\nassert df.isna().sum()<0.9 # catch missing values\nassert df.groupby(['g','date']).size().max() ==1 # no duplicate values/date?\nassert d6tjoin.utils.PreJoin([df1,df2],['id','date']).is_all_matched() # all ids matched?\n\n```", "```py\ndef some_complicated_function(data):\n\tdata = data[data['column']!='wrong']\n\tdata = data.groupby('date').apply(lambda x: complicated_stuff(x))\n\tdata = data[data['value']<0.9]\n\treturn data\n\n```", "```py\ndef process_data(data, parameter):\n    data = do_stuff(data)\n    data.to_pickle('data.pkl')\n\ndata = pd.read_csv('data.csv')\nprocess_data(data)\ndf_train = pd.read_pickle(df_train)\n\n```"]