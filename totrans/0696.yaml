- en: Developing End-to-End Data Science Pipelines with Data Ingestion, Processing,
    and Visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/developing-end-to-end-data-science-pipelines-with-data-ingestion-processing-and-visualization](https://www.kdnuggets.com/developing-end-to-end-data-science-pipelines-with-data-ingestion-processing-and-visualization)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Developing End-to-End Data Science Pipelines with Data Ingestion, Processing,
    and Visualization](../Images/0451f63ff8c9c4f86db4caa973eda2d8.png)Image by [macrovector
    on Freepik](https://www.freepik.com/free-vector/ai-powered-content-creation-isometric-composition-with-human-characters-cute-robot-generating-art-computer-screen-3d-vector-illustration_43868976.htm#fromView=search&page=3&position=0&uuid=b4c38b5b-880f-4b62-97e8-75687fe757e3)'
  prefs: []
  type: TYPE_IMG
- en: Data science projects are not about developing and not coming back to them.
    They involve a whole process, from acquiring the dataset to maintaining it. This
    iterative process ensures that the model always provides values.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The crucial part of the data science project is not in the model but in the
    beginning. If the data quality suffers and the preprocessing is not right, the
    downstream model will not bring valuable output. Maintaining a pipeline that can
    handle end-to-end data science processes becomes important.
  prefs: []
  type: TYPE_NORMAL
- en: We will learn and focus on data ingestion, processing, and visualization during
    the end-to-end data science pipeline development.
  prefs: []
  type: TYPE_NORMAL
- en: Standard End-to-End Data Science Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When discussing end-to-end data science projects, we discuss the technical and
    business aspects. Data science projects exist to solve business problems, so every
    step needs to be remembered about the business.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, end-to-end data science projects are more or less follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Business Understanding
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data Collection and Preparation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building the Machine Learning Model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Optimization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Deployment
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model Monitoring
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each step is essential and needs to be followed in the sequence. When even one
    of the steps is missing, our data science project will not provide the optimal
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the above steps, this article will focus on the Data Collection
    and Preparation step. It would be based on data ingestion, processing, and visualization.
    We would create a simple data science end-to-end project pipeline but emphasize
    the Data Collection and preparation step.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by exploring the steps and start to build the pipeline from there.
  prefs: []
  type: TYPE_NORMAL
- en: Data Ingestion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data ingestion takes the previously collected dataset and puts it within the
    environment for the following process. How we ingest the data would be different
    depending on the data source.
  prefs: []
  type: TYPE_NORMAL
- en: Let me show you the code example. The easiest one is to ingest the data from
    a CSV or Excel file, which we can do with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can ingest the data from the data warehouse via SQL by creating the
    connection to the database.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Another popular way is to call an API request from the data source.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Depending on your needs, there are still many ways to use the data ingestion
    process. For example, you can use web scraping.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: That’s the basis for data ingestion. Let’s explore the data processing.
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After we have the data, we must process it further to accommodate the business
    requirements and tasks. We must focus on this step as the project quality usually
    depends on the data processing.
  prefs: []
  type: TYPE_NORMAL
- en: Data exploration and processing are often tied together, so deciding how to
    process the data comes after the data exploration. Here are a few examples of
    data processing.
  prefs: []
  type: TYPE_NORMAL
- en: The first data processing we would see is data cleaning. We clean the data to
    improve the dataset quality. The example below is to drop the missing data and
    data duplicate removal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Data transformation is also part of data processing, where the data is entered
    into other forms necessary for the data science project.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We could also transform the data into the scale of what we need.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Also, when we process data, we often create new features from existing ones.
    This process is called Feature Engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we can do data splitting to split the data into train and test data
    with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can still do so many things for data processing, as it depends on your project.
    Let’s get into the data visualization now.
  prefs: []
  type: TYPE_NORMAL
- en: Data Visualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data visualization might not be related to machine learning development, but
    it is essential in the data science project. By using data visualization, we can
    better understand the data insight and easily communicate any results we have.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some code examples to produce the data visualization with Python.
  prefs: []
  type: TYPE_NORMAL
- en: First, we have the correlation heatmap plot to help understand the features'
    relationship with each other.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Next, we have the pair plot, which visualizes a two-dimensional plot between
    each feature and shows the distribution of the target feature.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Then, we can visualize the importance of the feature from the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we could visualize the confusion matrix during the model evaluation
    step.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Developing the Data Science Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s combine what we have learned above into one data science pipeline incorporating
    data ingestion, processing, and visualization.
  prefs: []
  type: TYPE_NORMAL
- en: We would use the Titanic data to develop a classification model for this example.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s ingest the data using Pandas.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: After that, we would perform the data processing. Let’s use the code below to
    clean the dataset and perform data transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: After the data processing, we would develop the machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we can visualize the importance of the model feature and present it
    to the audience with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: That’s all for developing a simple end-to-end data science pipeline with data
    ingestion, processing, and visualization. Depending on your data science project,
    you can add more steps in between.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Standardizing the end-to-end data science pipeline is essential if we want to
    continuously provide value to the business. By understanding the details of each
    step, especially data ingestion, processing, and visualization, we can improve
    the quality of our project and provide the best result to solve the business problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[End-to-end privacy for model training and inference with Concrete ML](https://www.kdnuggets.com/end-to-end-privacy-for-model-training-and-inference-with-concrete-ml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Expert Insights on Developing Safe, Secure, and Trustworthy AI Frameworks](https://www.kdnuggets.com/expert-insights-on-developing-safe-secure-and-trustworthy-ai-frameworks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Full End-to-End Deployment of a Machine Learning Algorithm into a…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Best End-to-End Open Source MLOps Tools](https://www.kdnuggets.com/5-best-end-to-end-open-source-mlops-tools)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Simple to Implement End-to-End Project with HuggingFace](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 End-to-End MLOps Platforms You Must Try in 2024](https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
