- en: 'Machine Learning Model Development and Model Operations: Principles and Practices'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习模型开发和模型操作：原则与实践
- en: 原文：[https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html](https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html](https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/), Principal Solution
    Architect, DXC Technology**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Suresh Yaram](https://www.linkedin.com/in/sureshyaram/)，首席解决方案架构师，DXC技术公司**'
- en: 1\. Introduction
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 介绍
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The use of Machine Leaning (ML) has increased substantially in enterprise data
    analytics scenarios to extract valuable insights from the business data. Hence,
    it is very important to have an ecosystem to build, test, deploy, and maintain
    the enterprise grade machine learning models in production environments. The ML
    model development involves data acquisition from multiple trusted sources, data
    processing to make suitable for building the model, choose algorithm to build
    the model, build model, compute performance metrics and choose best performing
    model. The model maintenance plays critical role once the model is deployed into
    production. The maintenance of machine learning model includes keeping the model
    up to date and relevant in tune with the source data changes as there is a risk
    of model becoming outdated in course of time. Also, the configuration management
    of ML model play an important role in model management as the number of models
    grow. This article focuses on principles and industry standard practices, including
    the tools and technologies used for ML model development, deployment, and maintenance
    in an enterprise environment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业数据分析场景中，机器学习（ML）的使用大幅增加，以从业务数据中提取有价值的见解。因此，拥有一个生态系统来构建、测试、部署和维护企业级机器学习模型在生产环境中至关重要。机器学习模型开发涉及从多个受信任的来源获取数据、处理数据以便于构建模型、选择算法来构建模型、构建模型、计算性能指标并选择表现最佳的模型。模型维护在模型部署到生产环境后扮演着关键角色。机器学习模型的维护包括保持模型的最新和相关，以便与源数据变化保持一致，因为模型有可能随着时间的推移变得过时。此外，随着模型数量的增加，机器学习模型的配置管理在模型管理中也发挥着重要作用。本文着重于原则和行业标准实践，包括用于企业环境中机器学习模型开发、部署和维护的工具和技术。
- en: 2\. Model Development
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 模型开发
- en: '**Machine Learning (ML) Model Lifecycle** refers to the process that covers
    right from source data identification to model development, model deployment and
    model maintenance. At high level, the entire activities fall under two broad categories,
    such as ML Model Development and ML Model Operations.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型生命周期**指的是从源数据识别到模型开发、模型部署和模型维护的整个过程。总体而言，所有活动都属于两个广泛的类别：ML模型开发和ML模型操作。'
- en: '**Machine Learning (ML) model development** includes a series of steps as mentioned
    in the Fig. 1.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型开发**包括一系列步骤，如图1所示。'
- en: '![Figure](../Images/65ad4640976073749d0b838990e29200.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/65ad4640976073749d0b838990e29200.png)'
- en: '**Fig 1:** Machine Learning (ML) Model Development Lifecyle'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1：** 机器学习（ML）模型开发生命周期'
- en: The ML model development lifecycle steps can be broadly classified as – data
    exploration, model building, model hyperparameters tuning and model selection
    with optimum performance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型开发生命周期步骤可以大致分为数据探索、模型构建、模型超参数调优和具有最佳性能的模型选择。
- en: '**Exploratory data analysis** is an important step that starts once business
    hypothesis is ready. This step takes 40-50% of total project time as the model
    outcome depends on the quality of input data being fed to train the model. Exploratory
    data analysis involves data attributes identification, data preprocessing and
    feature engineering. Attributes’ identification involves identification of predictor/features
    variables (inputs) and target/class variable (output), along its data types (string
    or numeric or datetime) and classification of features into categorical and continuous
    variables that helps in applying appropriate treatment to be given to the variable
    by the algorithm while building the model. Data pre-processing involves identification
    of missing values and outliers and fill these gaps by computing mean or median
    for quantitative attributes and mode for qualitative attributes of data to improve
    the predictive power of model. The outliers cause increased mean and standard
    deviation, that can be eliminated by taking natural log value which reduces the
    variation caused by extreme values.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析**是一个重要的步骤，一旦商业假设准备好后就开始进行。这个步骤占据了总项目时间的40-50%，因为模型结果依赖于输入数据的质量。探索性数据分析包括数据属性识别、数据预处理和特征工程。属性识别涉及识别预测变量/特征变量（输入）和目标/分类变量（输出），以及它们的数据类型（字符串、数值或日期时间），并将特征分类为类别变量和连续变量，这有助于在构建模型时算法对变量施加适当的处理。数据预处理涉及识别缺失值和异常值，通过计算定量属性的均值或中位数以及定性属性的众数来填补这些空白，以提高模型的预测能力。异常值会导致均值和标准差的增加，可以通过取自然对数来消除，这样可以减少极端值引起的变化。'
- en: '**Feature Engineering** is the next most important step in exploratory data
    analysis where the raw dataset is processed to convert data types of string or
    datetime or numeric ones to numeric vectors for an ML algorithm to understand
    and build efficient predictive model. Also, the labelled categorical data (e.g.,
    color red, green, blue; performance → poor, fair, good, very good, excellent;
    risk → low, medium, high; status → started, in-progress, on-hold, closed; gender
    → male/female; is_loan_approved/is_claim_fraudulent → yes/no) cannot be understood
    by an ML algorithm in its true context, hence it is required to be converted into
    numeric data. Feature Encoding is the widely used technique to transform the categorical
    data into continuous (numerical) values, e.g., Encode color as 1,2,3; performance
    as 1,2,3,4,5; risk as 1,2,3; status as 1,2,3,4; gender / is_loan_approved / is_claim_fraudulent
    as 0/1 etc. It is recommended to use label encoding in case categorical variables
    have no ordered relationship (e.g., color and status), ordinal encoding in case
    categorical variables have an ordered relationship (e.g., performance, risk) and
    one hot encoding in case categorical variable data is binary in nature (e.g.,
    gender, is_loan_approved, is_claim_fraudulent). A set of libraries are available
    in R or Python to implement these encoding methods. In some cases, a set of dummy
    variables or derived variables are created, especially in handling ‘date’ data
    types. Once the categorical text data is converted into numeric data, the data
    is ready to be fed to the model; As a last step, it is required to choose the
    appropriate features that help in improving the accuracy of model, by using the
    techniques such as Univariate Selection (statistical measure), Feature Importance
    (model property) and Correlation Matrix (identifies which features are most related
    to the target variable). These methods detect Collinearity between two variables
    where they are highly correlated and contain similar information about the variance
    within a given dataset. One may find the Variance Inflation Factor (VIF) useful
    to detect Multicollinearity where highly correlated three or more variables are
    included in the model. The key points in exploratory data analysis are represented
    in Fig.2, as shown below.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**是探索性数据分析中的下一步最重要的环节，在这一环节中，原始数据集会被处理，以将字符串、日期时间或数字类型的数据转换为机器学习算法可以理解的数字向量，从而构建高效的预测模型。此外，标记的分类数据（例如，颜色：红色、绿色、蓝色；表现：差、一般、好、非常好、优秀；风险：低、中、高；状态：开始、进行中、暂停、关闭；性别：男/女；是否批准贷款/是否欺诈索赔：是/否）在机器学习算法中无法以其真实背景被理解，因此需要将其转换为数字数据。特征编码是将分类数据转换为连续（数值）值的广泛使用的技术，例如，将颜色编码为1、2、3；表现编码为1、2、3、4、5；风险编码为1、2、3；状态编码为1、2、3、4；性别/是否批准贷款/是否欺诈索赔编码为0/1等。建议在分类变量没有顺序关系（例如颜色和状态）时使用标签编码，在分类变量有顺序关系（例如表现、风险）时使用顺序编码，以及在分类变量数据是二元性质（例如性别、是否批准贷款、是否欺诈索赔）时使用独热编码。R或Python中提供了一些库来实现这些编码方法。在某些情况下，会创建一组虚拟变量或派生变量，特别是在处理“日期”数据类型时。一旦分类文本数据转换为数字数据，这些数据就可以输入到模型中；最后一步是选择适当的特征，以帮助提高模型的准确性，方法包括单变量选择（统计测量）、特征重要性（模型属性）和相关矩阵（识别哪些特征与目标变量最相关）。这些方法检测变量之间的共线性，即它们高度相关并包含关于给定数据集中的方差的相似信息。可以使用方差膨胀因子（VIF）来检测多重共线性，即在模型中包含三个或更多高度相关的变量。图
    2 展示了探索性数据分析中的关键点。'
- en: '![Figure](../Images/d185e9dfbfb0d279fbe7c621987ac415.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/d185e9dfbfb0d279fbe7c621987ac415.png)'
- en: '**Fig 2:** Exploratory Data Analysis'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2:** 探索性数据分析'
- en: '**Building an ML Model** requires splitting of data into two sets, such as
    ‘training set’ and ‘testing set’ in the ratio of 80:20 or 70:30; A set of supervised
    (for labelled data) and unsupervised (for unlabeled data) algorithms are available
    to choose from depending on the nature of input data and business outcome to predict.
    In case of labelled data, it is recommended to choose logistic regression algorithm
    if the outcome to predict is of binary (0/1) in nature; choose decision tree classifier
    (or) Random Forest® classifier (or) KNN if the outcome to predict is of multi-class
    (1/2/3/...) in nature; and choose linear regression algorithm (e.g., decision
    tree regressor, random forest regressor) if the outcome to predict is continuous
    in nature. The clustering (Unsupervised) algorithm is preferred to analyze unlabeled
    / unstructured (text) data (e.g., k-means clustering). Artificial Neural Network
    (ANN) algorithms are suggested to analyze other unstructured (image/voice) data
    types, such as Convolutional Neural Networks (CNN) for image recognition and Recurrent
    Neural Networks (RNN) for voice recognition and Natural Language Processing (NLP).
    The model is built using training dataset and make prediction using test dataset.
    Use of deep learning (neural networks) models is preferred over regression models
    (ML models) for better performance as these models introduce extra layer of non-linearity
    with the introduction of Activation Function (AF). The algorithm selection under
    various scenarios has been represented in Fig.3, as shown below.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**构建机器学习模型**需要将数据分成两个集合，例如以 80:20 或 70:30 的比例划分的“训练集”和“测试集”；根据输入数据的性质和预测的业务结果，可以选择一系列监督（针对有标签数据）和无监督（针对无标签数据）算法。如果数据是有标签的，推荐选择逻辑回归算法（当预测结果为二分类（0/1）时）；如果预测结果为多分类（1/2/3/...），可以选择决策树分类器、随机森林®
    分类器或 KNN；如果预测结果是连续的，可以选择线性回归算法（例如，决策树回归器、随机森林回归器）。无监督的聚类算法（例如，k-means 聚类）适合分析无标签/非结构化（文本）数据。人工神经网络（ANN）算法建议用于分析其他非结构化（图像/语音）数据类型，例如用于图像识别的卷积神经网络（CNN）和用于语音识别及自然语言处理（NLP）的递归神经网络（RNN）。模型使用训练数据集构建，并使用测试数据集进行预测。深度学习（神经网络）模型通常优于回归模型（机器学习模型），因为这些模型通过引入激活函数（AF）增加了额外的非线性层，从而提供了更好的性能。各种场景下的算法选择已在下图
    Fig.3 中表示。'
- en: '![Figure](../Images/fcbcb5d5eb3c35362f7a46ed449200f8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/fcbcb5d5eb3c35362f7a46ed449200f8.png)'
- en: '**Fig 3:** Choose Right Algorithm'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3:** 选择正确的算法'
- en: '**Computation of Model Performance** is next logical step to choose the right
    model. The model performance metrics will decide on final model selection, that
    include computation of accuracy, precision, recall, F1 score (weighted average
    of precision and recall) , along with confusion matrix for classification models
    and co-efficient of determination for regression models. It is not recommended
    to use accuracy as a measure to determine the performance of classification models
    that are trained with imbalanced/skewed datasets, rather precision and recall
    are recommended to be computed to choose right classification model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能的计算**是选择正确模型的下一个逻辑步骤。模型性能指标将决定最终的模型选择，这包括计算准确率、精确度、召回率、F1 分数（精确度和召回率的加权平均），以及分类模型的混淆矩阵和回归模型的决定系数。对于使用不平衡/偏斜数据集训练的分类模型，不建议使用准确率作为性能衡量标准，而推荐计算精确度和召回率来选择合适的分类模型。'
- en: '**Model Hyperparameters Tuning** is highly recommended step in the process,
    continue till the model performance reach around 80%-85%. For example, the Random
    Forest algorithm takes maximum depth, maximum number of features, number of trees
    etc., as hyperparameters which can be intuitively tuned for improving model accuracy.
    Similarly, Neural Networks algorithm takes number of layers, batch size, number
    of epochs, number of samples etc. It is recommended to use Grid-search method
    to find the optimal hyperparameters of a model which results in the most ‘accurate’
    predictions. Besides this, it is also recommended to perform cross-validation
    as sometimes improvement in model accuracy may be due to overfitting (too sensitive
    model, unable to generalize) or underfitting (very generalized model) of model,
    using k-fold cross validation technique. To avoid overfitting, increase training
    data sample size that introduces more patterns or, reduce number of features that
    avoids complexity or, perform data regularization data using Ridge and Lasso regularization
    methods that reduces error/penalty. Similarly, to avoid underfitting, increase
    model complexity such as moving from linear to non-linear or adding more hidden
    layers (epochs) to neural network or add more features that introduce hidden patterns.
    However, adding more data volume does not solve the problem of underfitting, rather
    it hampers the model performance.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型超参数调优** 是过程中的重要步骤，建议继续调优直到模型性能达到约80%-85%。例如，随机森林算法采用最大深度、最大特征数、树的数量等超参数，这些超参数可以直观地调整以提高模型准确性。同样，神经网络算法包括层数、批量大小、训练轮数、样本数量等。建议使用网格搜索方法来找到模型的最佳超参数，从而获得最‘准确’的预测。此外，还推荐进行交叉验证，因为有时模型准确性的提升可能是由于过拟合（过于敏感的模型，无法泛化）或欠拟合（过于泛化的模型），可以使用k折交叉验证技术来验证。为避免过拟合，增加训练数据样本量以引入更多模式，或者减少特征数以避免复杂性，或使用岭回归和套索回归方法进行数据正则化以减少错误/惩罚。同样，为避免欠拟合，增加模型复杂性，如从线性模型转换为非线性模型，或在神经网络中增加更多隐藏层（轮次），或添加更多特征以引入隐藏模式。然而，增加更多数据量并不能解决欠拟合问题，反而会影响模型性能。'
- en: Finally. choose the model with optimum performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，选择性能最佳的模型。
- en: '**ML Model Development Best Practices:** The recommended ML Model Development
    Best Practices are (1) Perform clear hypothesis for the identified business problem
    before attributes identification itself; (2) Build the model using a basic algorithm
    first, like a logistic regression or decision tree and compile performance metrics,
    that gives enough confidence about relevance of data before going for a fancier
    algorithms, like neural networks; (3) Keep intermediate checkpoints in building
    the model to keep track of its model hyperparameters and its associated performance
    metrics that gives an ability to train the model incrementally and make good judgement
    when it comes to performance vs training time; (4) Use real-world production data
    for training the model to improve correctness of predictions.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习模型开发最佳实践：** 推荐的机器学习模型开发最佳实践包括（1）在属性识别之前，对识别出的业务问题进行明确的假设；（2）首先使用基本算法，如逻辑回归或决策树来构建模型，并编译性能指标，这样可以在使用更复杂的算法（如神经网络）之前，对数据的相关性有足够的信心；（3）在构建模型时保持中间检查点，以跟踪模型超参数及其相关性能指标，这样可以逐步训练模型，并在性能与训练时间方面做出合理判断；（4）使用真实的生产数据来训练模型，以提高预测的准确性。'
- en: Model Operations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型操作
- en: '**Machine Leaning (ML) Model Operations** refers to implementation of processes
    to maintain the ML models in production environments. The common challenge encountered
    in a typical enterprise scenario is that the ML models worked in lab environment
    will remain stay at the proof-of-concept stage in many cases. If the model is
    rolled out into production, it becomes stale due to frequent source data changes
    that requires rebuilding of model. As the models are retrained multiple times,
    it is required to keep track for model performance and corresponding features
    and hyperparameters that are used for retraining the model. To perform all these
    operations, there should be a well-defined reproducible process in-place to implement
    the end-to-end machine learning operations (MLOps) that keeps the model current
    and accurate in production environment. The ML model operations lifecycle process
    is as shown in Fig. 4 that covers entire process of model development to model
    deployment to model performance monitoring in a seamless manner.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型操作** 指的是在生产环境中维护 ML 模型的过程实施。常见的挑战是在典型企业场景中，实验室环境中运行的 ML 模型在许多情况下会停留在概念验证阶段。如果将模型推向生产，它会因频繁的数据源变化而变得过时，需重建模型。由于模型需要多次重新训练，需要跟踪模型性能以及用于重新训练的相应特征和超参数。为执行所有这些操作，必须有一个定义明确、可重复的过程来实现端到端的机器学习操作（MLOps），以保持模型在生产环境中的当前性和准确性。ML
    模型操作生命周期过程如图 4 所示，涵盖了从模型开发到模型部署再到模型性能监控的整个过程。'
- en: '![Figure](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
- en: '**Fig 4:** Machine Learning (ML) Model Operations Lifecyle'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4:** 机器学习（ML）模型操作生命周期'
- en: The model retraining is very important at regular intervals, say fortnightly
    or monthly or quarterly or on-demand basis as it is very likely that the underlying
    source data will change over a period in the real-world scenario. A cron job is
    scheduled to retrain the model at the predefined intervals, or as and when the
    source data is changed, or as and when the model performance is degraded. There
    could be some changes to the model code due to hyperparameter tuning during model
    re-training.it is required to automate these model operations by having an automated
    model pipeline.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重新训练在定期时间间隔内非常重要，例如每两周、每月、每季度或按需进行，因为在实际场景中，基础数据可能会随时间变化。定时任务被安排在预定义的时间间隔内重新训练模型，或在数据源变化时，或在模型性能下降时进行重新训练。模型代码可能因超参数调整而发生变化，因此需要通过自动化模型管道来实现这些模型操作。
- en: The typical automated model pipeline in enterprise production environments include
    3 types of stores, such as **feature store****,** **metadata store and model registry**.
    The **feature store** contains data extracted from various source systems and
    transformed into the features as required by the model. The ML pipeline takes
    the data in batches from the feature store to train the model. The **metadata
    store** is a centralized model tracking (bookkeeping) system, maintained at the
    enterprise level, contains the model metadata at each stage of pipeline. The model
    metadata store facilitates the model stage transition, say from staging to production
    to archived. The model training is performed in one environment and deployment
    in other environments where the model inference will be performed just by specifying
    the remote model file path. The model metadata store is used for model experiments
    tracking and compare model experiments w.r.t. its performance. The model metadata
    includes training data set version, links to training runs and experiments. The
    **model registry** contains data of all trained models such as trained model version,
    model training date, model training metrics, hyperparameters used for training
    the model, predicted outcomes, and diagnostic charts (confusion matrix, ROC curves).
    The appropriate model will be picked from the model registry based on the intended
    target user’s requirement. The model metadata store & model registry can be implemented
    (custom) using a light-weight database, such as SQLite and a set of python functions;
    or a set of open-source/proprietary products, such as MLflow (community edition/managed
    service from Databricks). This tool provides an ability to manage models using
    a GUI or a set of APIs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 企业生产环境中的典型自动化模型管道包括三种类型的存储，如**特征存储**、**元数据存储和模型注册表**。**特征存储**包含从各种源系统中提取的数据，并转换为模型所需的特征。机器学习管道从特征存储中批量获取数据以训练模型。**元数据存储**是一个集中式的模型跟踪（记账）系统，企业级维护，包含管道每个阶段的模型元数据。模型元数据存储促进模型阶段的过渡，例如从暂存到生产再到归档。模型训练在一个环境中进行，部署在其他环境中进行，模型推理只需指定远程模型文件路径。模型元数据存储用于模型实验跟踪，并根据性能比较模型实验。模型元数据包括训练数据集版本、训练运行和实验的链接。**模型注册表**包含所有训练模型的数据，如训练模型版本、模型训练日期、模型训练指标、用于训练模型的超参数、预测结果和诊断图表（混淆矩阵、ROC曲线）。根据目标用户的需求，从模型注册表中选择适当的模型。模型元数据存储和模型注册表可以使用轻量级数据库（如SQLite）和一组python函数来实现（定制），也可以使用一套开源/专有产品（如MLflow社区版/Databricks的托管服务）。该工具提供了通过GUI或一组API来管理模型的功能。
- en: '**Model Deployment:** The models can be deployed in production environments
    to perform prediction either in batch inference mode or on-line inference mode.
    The batch inference can be achieved by scheduling as a job to run at a time interval
    and send the results via email to the intended users. The on-line inference can
    be achieved by exposing the model as a web service using frameworks such as python
    flask library or streamlit library to develop interactive web applications and
    invoke the model using its HTTP endpoint.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型部署：** 模型可以在生产环境中进行预测，既可以以批量推理模式也可以以在线推理模式。批量推理可以通过安排作业在特定时间间隔运行，并将结果通过电子邮件发送给指定用户来实现。在线推理可以通过使用python
    flask库或streamlit库等框架将模型公开为网络服务，开发交互式网页应用，并通过HTTP端点调用模型来实现。'
- en: '**Model Packaging/Distribution:** The trained ML model is serialized into various
    formats to be able to distribute the model for deployment into TEST/PROD environments.
    The most common formats are pickle (for machine learning or deep learning models
    developed in python), ONNX (Open Neural Network Exchange format, for deep learning
    models), and PMML(Predictive Model Markup Language XML-based format, specifically
    for models developed using logistic regression and neural networks). The model
    can be packaged as a .jar file or as a docker container image and deployed as
    a prediction service into production.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型打包/分发：** 训练好的机器学习模型会被序列化成各种格式，以便将模型分发到TEST/PROD环境中。最常见的格式有pickle（用于用python开发的机器学习或深度学习模型）、ONNX（开放神经网络交换格式，用于深度学习模型）和PMML（预测模型标记语言XML格式，专门用于使用逻辑回归和神经网络开发的模型）。模型可以打包成`.jar`文件或docker容器镜像，并作为预测服务部署到生产环境中。'
- en: '**Model Containerization** can be achieved by building a docker image, bundled
    with training and inference code, along with the necessary training and testing
    data and the model file for future predictions. Once the docker file is created
    bundled with necessary ML model, a CI/CD pipeline can be built using a tool, such
    as Jenkins. This docker container image can be exposed as a REST API, so that
    any external stakeholders can consume this ML model, either from on-premises or
    public cloud (in case of high compute requirements for building a deep learning
    model). In case of packaging and managing multiple docker containers, **Kubeflow**,
    the ML toolkit for Kubernetes can be used.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型容器化**可以通过构建一个包含训练和推理代码的 docker 镜像来实现，同时还需捆绑必要的训练和测试数据以及未来预测所需的模型文件。一旦创建了捆绑有必要机器学习模型的
    docker 文件，就可以使用像 Jenkins 这样的工具构建 CI/CD 管道。这个 docker 容器镜像可以暴露为 REST API，这样任何外部利益相关者都可以使用这个机器学习模型，无论是在本地还是在公共云上（如果构建深度学习模型需要高计算要求）。在打包和管理多个
    docker 容器的情况下，可以使用**Kubeflow**，这是 Kubernetes 的机器学习工具包。'
- en: '**Model Performance Monitoring** is an important activity where the predicted
    outcome (e.g., predicted sale price of an item) vs. actual value (actual sale
    price) is continuously monitored. And it is recommended to understand the end
    users’ reaction to the final predictions. In some scenarios, it is recommended
    to keep old model and new model running in-parallel to understand the variation
    in performance in both the models (model validation). It is mandatory to address
    performance degradation that arise due to ‘data drift’ (underlying source data
    pattern changes due to seasonality and trend, e.g., year-end sales data (or) addition
    of new categories (or) one particular attribute is not being generated by the
    upstream systems) and ‘model drift’ (statistical properties of target variable
    changes, e.g., definition of a fraudulent transaction itself changes). The most
    accurate way to measure the model drift is by measuring the F1 Score that combines
    the precision and the recall of a classifier into a single metric by taking their
    harmonic mean. The model will be retrained as an when the model drift (F1 Score)
    falls below certain threshold or at regular intervals (batch mode) or train the
    model as soon as the data is available (online training). It is very important
    to collect model logs and prediction logs by using popular logging tools such
    as elasticstack, and fluentd.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能监控**是一项重要的活动，其中预测结果（例如，某项商品的预测销售价格）与实际值（实际销售价格）会持续进行监控。建议了解最终预测对终端用户的反应。在一些情况下，建议让旧模型和新模型并行运行，以了解两个模型之间的性能变化（模型验证）。必须解决由于“数据漂移”（底层源数据模式由于季节性和趋势的变化，例如年终销售数据（或）新增类别（或）某个特定属性未由上游系统生成）和“模型漂移”（目标变量的统计属性变化，例如，欺诈交易的定义本身发生变化）引起的性能退化。测量模型漂移的最准确方法是通过测量
    F1 分数，该分数通过取分类器的精确度和召回率的调和平均值来结合这两个指标。当模型漂移（F1 分数）降到某个阈值以下时，或者在定期间隔（批处理模式）或数据一旦可用时（在线训练），将重新训练模型。使用像
    elasticstack 和 fluentd 这样的流行日志工具收集模型日志和预测日志是非常重要的。'
- en: '**Model version management** is a mandatory activity in ML model management
    as the model will be retrained at regular intervals due to changes in the underlying
    source data or as demanded by audit and compliance purposes. The source data,
    the model training scripts, model experiment, and the trained model are versioned
    together in the code repository. There are open-source tools available, such as
    Data Version Control (DVC) or AWS CodeCommit that uses Git as underlying code
    repository for model version management purposes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型版本管理**是机器学习模型管理中一个必要的活动，因为模型会因为底层源数据的变化或审计和合规要求而定期重新训练。源数据、模型训练脚本、模型实验和训练后的模型会一起在代码库中进行版本控制。市面上有开源工具，例如
    Data Version Control (DVC) 或 AWS CodeCommit，这些工具使用 Git 作为底层代码库来进行模型版本管理。'
- en: '**ML Project Development Roles:** There are various roles involved in implementing
    ML model development and operations. Data Engineer analyzes the business data
    from various sources and ensures right and up-to-date data is accessible at the
    required granularity and quality in cost effective way. Data Scientists look at
    the data, performs data pre-processing and feature engineering, model building
    and choose right model that best fits the predictive/prescriptive requirements
    of business. Usually, Data Scientists take hypothesis-based approach to choose
    the model that fits the requirements. ML Engineer makes sure that the built model
    is giving the results reliably and assess the need for re-training the model by
    monitoring its outcome. Web App Developer builds the required presentation layer
    component to invoke and present the results to the intended stakeholders. The
    ML projects also require DevOps engineers to enable continuous delivery and data
    visualization experts to produce fancy dashboards.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习项目开发角色：** 在实施机器学习模型开发和运营中涉及多种角色。数据工程师分析来自各种来源的业务数据，并确保以具有成本效益的方式提供所需粒度和质量的最新数据。数据科学家查看数据，执行数据预处理和特征工程，构建模型并选择最适合业务预测/建议需求的模型。通常，数据科学家采用基于假设的方法来选择符合要求的模型。机器学习工程师确保构建的模型提供可靠的结果，并通过监控其结果来评估是否需要重新训练模型。Web
    应用开发人员构建所需的展示层组件，以调用并向相关利益相关者展示结果。机器学习项目还需要 DevOps 工程师来实现持续交付和数据可视化专家来制作精美的仪表板。'
- en: '**ML Model Deployment Best Practices:** The recommended model deployment best
    practices are (1) Automate the steps required for ML model development and deployment,
    by leveraging DevOps tools that gives some extra time for model retraining; (2)
    Perform continuous model testing, performance monitoring and retraining after
    its production deployment to keep the model relevant/current as the source data
    changes to predict the desired outcome(s); (3) Implement logging while exposing
    ML models as APIs, that includes capturing input features/model output (to track
    model drift), application context (for debugging production errors), model version
    (if multiple re-trained models are deployed in production); (4) Manage all the
    model metadata in a single repository.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习模型部署最佳实践：** 推荐的模型部署最佳实践包括 (1) 利用 DevOps 工具自动化机器学习模型开发和部署所需的步骤，为模型重新训练腾出一些额外时间；
    (2) 在模型生产部署后进行持续的模型测试、性能监控和重新训练，以保持模型的相关性/当前状态，以应对源数据的变化，预测所需的结果； (3) 在将机器学习模型暴露为
    API 时实施日志记录，包括捕获输入特征/模型输出（以跟踪模型漂移）、应用上下文（用于调试生产错误）、模型版本（如果部署了多个重新训练的模型）； (4) 在一个存储库中管理所有模型元数据。'
- en: '**Bio: [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/)** works with
    an IT company ([DXC Technology](https://dxc.com/us/en), erstwhile CSC India Limited))
    as Principal Solution Architect. Suresh comes with 20+ years of IT experience,
    focusing on Data Architecture, Big Data Analytics, Artificial Intelligence and
    Machine Learning. He has been involved in building Data & Analytics solutions
    to his customers across various domains such as Banking, Finance, and Insurance,
    including AI/ML for various insurance industry scenarios and presented them in
    various technology forums with in DXC. Suresh has also published a [paper](https://ieeexplore.ieee.org/document/7823950)
    in an IEEE Data Science conference conducted in India.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Suresh Yaram](https://www.linkedin.com/in/sureshyaram/)** 在 IT 公司 ([DXC
    Technology](https://dxc.com/us/en), 曾用名 CSC India Limited) 担任首席解决方案架构师。Suresh
    拥有 20 多年的 IT 经验，专注于数据架构、大数据分析、人工智能和机器学习。他参与了为客户建立数据和分析解决方案，涉及银行、金融和保险等各个领域，包括保险行业的
    AI/ML 应用，并在 DXC 的多个技术论坛上进行过展示。Suresh 还在印度举办的 IEEE 数据科学会议上发表过一篇 [论文](https://ieeexplore.ieee.org/document/7823950)。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Overview of Different Approaches to Deploying Machine Learning Models in Production](/2019/06/approaches-deploying-machine-learning-production.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[不同方法在生产环境中部署机器学习模型的概述](/2019/06/approaches-deploying-machine-learning-production.html)'
- en: '[Overview of MLOps](/2021/03/overview-mlops.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 概述](/2021/03/overview-mlops.html)'
- en: '[MLOps is an Engineering Discipline: A Beginner’s Overview](/2021/07/mlops-engineering-discipline.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps 是一种工程学科：初学者概述](/2021/07/mlops-engineering-discipline.html)'
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为出色数据科学家所需的 5 项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
