- en: Top 10 Computer Vision Papers 2020
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2020年计算机视觉领域前10篇论文
- en: 原文：[https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html](https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html](https://www.kdnuggets.com/2021/01/top-10-computer-vision-papers-2020.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Louis (What''s AI) Bouchard](https://www.linkedin.com/in/whats-ai), Montrealer,
    explaining AI stuff on YouTube and Medium**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Louis (What''s AI) Bouchard](https://www.linkedin.com/in/whats-ai)，蒙特利尔人，YouTube
    和 Medium 上解释人工智能的内容**'
- en: '![Image for post](../Images/51d48d005a61c4d84e7d598064315658.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/51d48d005a61c4d84e7d598064315658.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Even with everything that happened in the world this year, we still had the
    chance to see a lot of amazing research come out. Especially in the field of artificial
    intelligence and more precisely computer vision. More, many important aspects
    were highlighted this year, like the ethical aspects, important biases, and much
    more. Artificial intelligence and our understanding of the human brain and its
    link to AI is constantly evolving, showing promising applications in the soon
    future, which I will definitely cover.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 即便今年世界发生了许多事情，我们仍然有机会看到大量令人惊叹的研究成果。特别是在人工智能领域，更准确地说是计算机视觉领域。今年突出了许多重要方面，比如伦理问题、重要偏见等。人工智能以及我们对人脑及其与人工智能关系的理解不断演变，显示出在不久的将来有着广阔的应用前景，我肯定会对此进行深入探讨。
- en: Here are my top 10 of the most interesting research papers of the year in computer
    vision, in case you missed any of them. In short, it is basically a curated list
    of the **latest breakthroughs in AI and CV **with a **clear video explanation**, **link
    to a more in-depth article**, and **code **(if applicable). Enjoy the read, and
    let me know if I missed any important papers in the comments, or by contacting
    me directly on [LinkedIn](https://www.linkedin.com/in/whats-ai/)!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我精选的年度计算机视觉领域最有趣的10篇研究论文，以防你错过了其中任何一篇。简而言之，这基本上是一个**最新突破的人工智能和计算机视觉**的精选列表，包括**清晰的视频解释**、**更深入的文章链接**，以及**代码**（如果适用）。享受阅读，如果我遗漏了任何重要论文，请在评论中告诉我，或通过[LinkedIn](https://www.linkedin.com/in/whats-ai/)直接联系我！
- en: '*The complete reference to each paper is listed at the end of this article.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*每篇论文的完整参考文献列在本文末尾。*'
- en: '[***Access the complete list in a GitHub repository***](https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[***访问GitHub仓库中的完整列表***](https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020)'
- en: '***Tag me on ***[***Twitter (@Whats_AI)***](https://twitter.com/Whats_AI)*** or ***[***LinkedIn
    (Louis (What’s AI) Bouchard)***](https://www.linkedin.com/in/whats-ai/)*** if
    you share the article!***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果你分享了这篇文章，请在***[***Twitter (@Whats_AI)***](https://twitter.com/Whats_AI)***或***[***LinkedIn
    (Louis (What’s AI) Bouchard)***](https://www.linkedin.com/in/whats-ai/)***标记我！***'
- en: Watch a complete computer vision 2020 rewind in 5 minutes
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在5分钟内观看完整的2020年计算机视觉回顾
- en: '[Sea-thru: A Method For Removing Water From Underwater Images [1]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Akkaynak_Sea-Thru_A_Method_for_Removing_Water_From_Underwater_Images_CVPR_2019_paper.pdf)'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[Sea-thru: 一种从水下图像中去除水分的方法 [1]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Akkaynak_Sea-Thru_A_Method_for_Removing_Water_From_Underwater_Images_CVPR_2019_paper.pdf)'
- en: Have you ever wondered how the ocean would look like without water Remove this
    blue-green tint of the underwater pictures, and still have the true colors of
    a coral reef? Well, using computer vision and machine learning algorithms, researchers
    from the University of Haifa were able to accomplish exactly that!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾想过没有水的海洋会是什么样子？去除水下图像中的蓝绿色调，还原珊瑚礁的真实颜色？使用计算机视觉和机器学习算法，海法大学的研究人员成功实现了这一目标！
- en: '[**This AI removes the water from underwater images!**](https://medium.com/towards-artificial-intelligence/this-ai-removes-the-water-from-underwater-images-d277281bcd0f)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这个AI从水下图像中去除水面！**](https://medium.com/towards-artificial-intelligence/this-ai-removes-the-water-from-underwater-images-d277281bcd0f)'
- en: Have you ever wondered how the ocean would look like without water? Researchers
    recently achieved that by using…
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾想过没有水的海洋会是什么样子？研究人员最近通过使用……
- en: '[Click here for the Sea-thru code](https://github.com/jgibson2/sea-thru)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里获取Sea-thru代码](https://github.com/jgibson2/sea-thru)'
- en: '[Neural circuit policies enabling auditable autonomy](https://www.nature.com/articles/s42256-020-00237-3.epdf?sharing_token=xHsXBg2SoR9l8XdbXeGSqtRgN0jAjWel9jnR3ZoTv0PbS_e49wmlSXvnXIRQ7wyir5MOFK7XBfQ8sxCtVjc7zD1lWeQB5kHoRr4BAmDEU0_1-UN5qHD5nXYVQyq5BrRV_tFa3_FZjs4LBHt-yebsG4eQcOnNsG4BenK3CmBRFLk%3D) [2]'
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[神经电路策略实现可审计的自主性](https://www.nature.com/articles/s42256-020-00237-3.epdf?sharing_token=xHsXBg2SoR9l8XdbXeGSqtRgN0jAjWel9jnR3ZoTv0PbS_e49wmlSXvnXIRQ7wyir5MOFK7XBfQ8sxCtVjc7zD1lWeQB5kHoRr4BAmDEU0_1-UN5qHD5nXYVQyq5BrRV_tFa3_FZjs4LBHt-yebsG4eQcOnNsG4BenK3CmBRFLk%3D)
    [2]'
- en: Researchers from IST Austria and MIT have successfully trained a self-driving
    car using a new artificial intelligence system based on the brains of tiny animals,
    such as threadworms. They achieved that with only a few neurons able to control
    the self-driving car, compared to the millions of neurons needed by the popular
    deep neural networks such as Inceptions, Resnets, or VGG. Their network was able
    to completely control a car using only 75 000 parameters, composed of 19 control
    neurons, rather than millions!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 来自IST奥地利和麻省理工学院的研究人员成功地使用一种基于微小动物大脑的新型人工智能系统训练了一辆自动驾驶汽车。他们仅使用了少数几个神经元来控制自动驾驶汽车，而不需要像流行的深度神经网络（如Inceptions、Resnets或VGG）那样需要数百万个神经元。他们的网络仅使用了75,000个参数，由19个控制神经元组成，而不是数百万个！
- en: '[**A New Brain-inspired Intelligent System Drives a Car Using Only 19 Control
    Neurons!**](https://medium.com/towards-artificial-intelligence/a-new-brain-inspired-intelligent-system-drives-a-car-using-only-19-control-neurons-1ed127107db9)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[**一种新的受大脑启发的智能系统仅用19个控制神经元驾驶汽车！**](https://medium.com/towards-artificial-intelligence/a-new-brain-inspired-intelligent-system-drives-a-car-using-only-19-control-neurons-1ed127107db9)'
- en: Imitating the nematode’s nervous system to process information efficiently,
    this new intelligent system is more robust…
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 模仿线虫的神经系统以高效处理信息，这种新的智能系统更具鲁棒性……
- en: '[NeRV: Neural Reflectance and Visibility Fields'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[NeRV：神经反射和可见性场'
- en: for Relighting and View Synthesis](https://people.eecs.berkeley.edu/~pratul/nerv/) [3]
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 进行重新照明和视图合成](https://people.eecs.berkeley.edu/~pratul/nerv/) [3]
- en: This new method is able to generate a complete 3-dimensional scene and has the
    ability to decide the lighting of the scene. All this with very limited computation
    costs and amazing results compared to previous approaches.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新方法能够生成一个完整的三维场景，并且能够决定场景的光照条件。所有这些都以非常有限的计算成本和与之前的方法相比惊人的结果完成。
- en: '[**Generate a Complete 3D Scene Under Arbitrary Lighting Conditions from a
    Set of Input Images**](https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[**从一组输入图像生成任意光照条件下的完整3D场景**](https://medium.com/what-is-artificial-intelligence/generate-a-complete-3d-scene-under-arbitrary-lighting-conditions-from-a-set-of-input-images-9d2fbce63243)'
- en: This new method is able to generate a complete 3-dimensional scene and has the
    ability to decide the lighting of the…
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新方法能够生成一个完整的三维场景，并且能够决定场景的光照条件……
- en: '[YOLOv4: Optimal Speed and Accuracy of Object Detection](https://arxiv.org/abs/2004.10934) [4]'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[YOLOv4：目标检测的最佳速度和准确性](https://arxiv.org/abs/2004.10934) [4]'
- en: 'This 4th version has been recently introduced in April 2020 by Alexey Bochkovsky
    et al. in the paper “YOLOv4: Optimal Speed and Accuracy of Object Detection”.
    The main goal of this algorithm was to make a super-fast object detector with
    high quality in terms of accuracy.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第4版最近于2020年4月由Alexey Bochkovsky等人在论文《YOLOv4：目标检测的最佳速度和准确性》中引入。这个算法的主要目标是制作一个超快的目标检测器，在准确性方面具有高质量。
- en: '[**The YOLOv4 algorithm | Introduction to You Only Look Once, Version 4 | Real-Time
    Object Detection**](https://medium.com/what-is-artificial-intelligence/the-yolov4-algorithm-introduction-to-you-only-look-once-version-4-real-time-object-detection-5fd8a608b0fa)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[**YOLOv4算法 | You Only Look Once 第4版简介 | 实时目标检测**](https://medium.com/what-is-artificial-intelligence/the-yolov4-algorithm-introduction-to-you-only-look-once-version-4-real-time-object-detection-5fd8a608b0fa)'
- en: I recently made a post explaining the basics of the initial You Only Look Once,
    also known as the YOLO algorithm. And…
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近发布了一篇帖子，解释了初始的 You Only Look Once，即 YOLO 算法的基础知识。然后…
- en: '[PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative
    Models](https://arxiv.org/abs/2003.03808) [5]'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[PULSE: 通过生成模型的潜在空间探索进行自监督照片超分辨率](https://arxiv.org/abs/2003.03808) [5]'
- en: This new algorithm transforms a blurry image into a high-resolution image!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新算法可以将模糊的图像转换为高分辨率图像！
- en: It can take a super low-resolution 16x16 image and turn it into a 1080p high
    definition human face! You don’t believe me? Then you can do just like me and
    try it on yourself in less than a minute! But first, let’s see how they did that.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以将超低分辨率的 16x16 图像转换为 1080p 高清人脸！你不相信我？那你可以像我一样自己试试，不到一分钟的时间！但首先，让我们看看他们是怎么做到的。
- en: '[**This AI makes blurry faces look 60 times sharper**](https://medium.com/what-is-artificial-intelligence/this-ai-makes-blurry-faces-look-60-times-sharper-7fcd3b820910)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这个 AI 让模糊的面孔清晰度提高 60 倍**](https://medium.com/what-is-artificial-intelligence/this-ai-makes-blurry-faces-look-60-times-sharper-7fcd3b820910)'
- en: This new algorithm transforms a blurry image into a high-resolution image! It
    can take a super low-resolution 16x16 image…
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新算法可以将模糊的图像转换为高分辨率图像！它可以将超低分辨率的 16x16 图像…
- en: '[Image GPT — Generative Pretraining from Pixels](https://openai.com/blog/image-gpt/) [6]'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[图像 GPT — 从像素生成预训练](https://openai.com/blog/image-gpt/) [6]'
- en: A good AI, like the one used in Gmail, can generate coherent text and finish
    your phrase. This one uses the same principles in order to complete an image!
    All done in an unsupervised training with no labels required at all!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的 AI，比如 Gmail 中使用的 AI，可以生成连贯的文本并完成你的短语。这个 AI 使用相同的原理来完成图像！这一切都在无监督训练中完成，完全不需要标签！
- en: '[**This AI Can Generate the Other Half of a Picture Using a GPT Model**](https://medium.com/towards-artificial-intelligence/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这个 AI 可以使用 GPT 模型生成图片的另一半**](https://medium.com/towards-artificial-intelligence/this-ai-can-generate-the-pixels-of-half-of-a-picture-from-nothing-using-a-nlp-model-7d7ba14b5522)'
- en: A good AI, like the one used in Gmail, can generate coherent text and finish
    your phrase. This one uses the same…
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的 AI，比如 Gmail 中使用的 AI，可以生成连贯的文本并完成你的短语。这个 AI 使用相同的…
- en: '[DeepFaceDrawing: Deep Generation of Face Images from Sketches](http://geometrylearning.com/paper/DeepFaceDrawing.pdf) [7]'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[DeepFaceDrawing: 从草图中深度生成面部图像](http://geometrylearning.com/paper/DeepFaceDrawing.pdf)
    [7]'
- en: You can now generate high-quality face images from rough or even incomplete
    sketches with zero drawing skills using this new image-to-image translation technique!
    If your drawing skills as bad as mine you can even adjust how much the eyes, mouth,
    and nose will affect the final image! Let’s see if it really works and how they
    did it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用这个新的图像到图像翻译技术，从粗略或甚至不完整的草图中生成高质量的面部图像，完全不需要绘画技巧！如果你的绘画技能和我一样糟糕，你甚至可以调整眼睛、嘴巴和鼻子对最终图像的影响！让我们看看它是否真的有效以及他们是如何做到的。
- en: '[**AI Generates Real Faces From Sketches!**](https://medium.com/what-is-artificial-intelligence/ai-generates-real-faces-from-sketches-8ccbac5d2b2e)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[**AI 从草图生成真实面孔！**](https://medium.com/what-is-artificial-intelligence/ai-generates-real-faces-from-sketches-8ccbac5d2b2e)'
- en: You can now generate high-quality face images from rough or even incomplete
    sketches with zero drawing skills using…
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用这个新的图像到图像翻译技术，从粗略或甚至不完整的草图中生成高质量的面部图像，完全不需要绘画技巧！
- en: '[PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D
    Human Digitization](https://arxiv.org/pdf/2004.00452.pdf) [8]'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[PIFuHD: 多层次像素对齐隐式函数用于高分辨率 3D 人体数字化](https://arxiv.org/pdf/2004.00452.pdf)
    [8]'
- en: This AI Generates 3D high-resolution reconstructions of people from 2D images!
    It only needs a single image of you to generate a 3D avatar that looks just like
    you, even from the back!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 AI 可以从 2D 图像中生成 3D 高分辨率的重建图像！它只需要你的一张图片就可以生成一个看起来和你一模一样的 3D 头像，甚至从背面也是如此！
- en: '[**AI Generates 3D high-resolution reconstructions of people from 2D images
    | Introduction to PIFuHD**](https://medium.com/towards-artificial-intelligence/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[**AI 从 2D 图像生成 3D 高分辨率重建 | PIFuHD 介绍**](https://medium.com/towards-artificial-intelligence/ai-generates-3d-high-resolution-reconstructions-of-people-from-2d-images-introduction-to-pifuhd-d4aa515a482a)'
- en: This AI Generates 3D high-resolution reconstructions of people from 2D images!
    It only needs a single image of you to…
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 AI 可以从 2D 图像中生成 3D 高分辨率的重建图像！它只需要你的一张图片就可以…
- en: '[RAFT: Recurrent All-Pairs Field Transforms for Optical Flow](https://arxiv.org/pdf/2003.12039.pdf) [9]'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[RAFT：用于光流的递归全对场变换](https://arxiv.org/pdf/2003.12039.pdf) [9]'
- en: ECCV 2020 Best Paper Award Goes to Princeton Team. They developed a new end-to-end
    trainable model for optical flow. Their method beats state-of-the-art architectures’
    accuracy across multiple datasets and is way more efficient. They even made the
    code available for everyone on their Github!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ECCV 2020最佳论文奖颁给了普林斯顿团队。他们开发了一种新的端到端可训练的光流模型。他们的方法在多个数据集上超越了最先进架构的准确性，并且效率更高。他们甚至将代码发布在Github上供大家使用！
- en: '[**ECCV 2020 Best Paper Award | A New Architecture For Optical Flow**](https://medium.com/towards-artificial-intelligence/eccv-2020-best-paper-award-a-new-architecture-for-optical-flow-3298c8a40dc7)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[**ECCV 2020最佳论文奖 | 一种新的光流架构**](https://medium.com/towards-artificial-intelligence/eccv-2020-best-paper-award-a-new-architecture-for-optical-flow-3298c8a40dc7)'
- en: ECCV 2020 Best Paper Award Goes to Princeton Team. They developed a new end-to-end
    trainable model for optical flow…
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ECCV 2020最佳论文奖颁给了普林斯顿团队。他们开发了一种新的端到端可训练的光流模型……
- en: '[Click here for the RAFT code](https://github.com/princeton-vl/RAFT)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里查看RAFT代码](https://github.com/princeton-vl/RAFT)'
- en: '[Learning Joint Spatial-Temporal Transformations for Video Inpainting](https://arxiv.org/abs/2007.10247) [10]'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[学习视频修补的联合时空变换](https://arxiv.org/abs/2007.10247) [10]'
- en: This AI can fill the missing pixels behind a removed moving object and reconstruct
    the whole video with way more accuracy and less blurriness than current state-of-the-art
    approaches!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个AI能够填补被移除移动物体后的缺失像素，并比当前最先进的方法更准确、更清晰地重建整个视频！
- en: '[**This AI takes a video and fills the missing pixels behind an object!**](https://medium.com/towards-artificial-intelligence/this-ai-takes-a-video-and-fills-the-missing-pixels-behind-an-object-video-inpainting-9be38e141f46)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这个AI能够从视频中填补物体后面的缺失像素！**](https://medium.com/towards-artificial-intelligence/this-ai-takes-a-video-and-fills-the-missing-pixels-behind-an-object-video-inpainting-9be38e141f46)'
- en: Video Inpainting — Microsoft Research
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 视频修补 — 微软研究院
- en: '[Click here for this Video Inpainting code](https://github.com/researchmm/STTN?utm_source=catalyzex.com)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里查看这个视频修补代码](https://github.com/researchmm/STTN?utm_source=catalyzex.com)'
- en: '[Old Photo Restoration via Deep Latent Space Translation](https://arxiv.org/pdf/2009.07047.pdf) [Bonus
    1]'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[通过深度潜在空间转换进行旧照片恢复](https://arxiv.org/pdf/2009.07047.pdf) [Bonus 1]'
- en: Imagine having the old, folded, and even torn pictures of your grandmother when
    she was 18 years old in high definition with zero artifacts. This is called old
    photo restoration and this paper just opened a whole new avenue to address this
    problem using a deep learning approach.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，将你祖母18岁时的旧照片，即使是折叠和撕裂的照片，恢复到高清晰度且没有任何伪影。这就是所谓的旧照片恢复，这篇论文刚刚开辟了一个全新的方向，使用深度学习方法来解决这个问题。
- en: '[**Old Photo Restoration using Deep Learning**](https://medium.com/towards-artificial-intelligence/old-photo-restoration-using-deep-learning-47d4ab1bdc4d)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[**使用深度学习进行旧照片恢复**](https://medium.com/towards-artificial-intelligence/old-photo-restoration-using-deep-learning-47d4ab1bdc4d)'
- en: Imagine having the old, folded, and even torn pictures of your grandmother when
    she was 18 years old in high definition…
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，将你祖母18岁时的旧照片，即使是折叠和撕裂的照片，恢复到高清晰度……
- en: '[Click here for the Old Photo Restoration code](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life?utm_source=catalyzex.com)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里查看旧照片恢复代码](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life?utm_source=catalyzex.com)'
- en: '[Is a Green Screen Really Necessary for Real-Time Portrait Matting?](https://arxiv.org/pdf/2011.11961.pdf) [Bonus
    2]'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[实时肖像抠图是否真的需要绿幕？](https://arxiv.org/pdf/2011.11961.pdf) [Bonus 2]'
- en: Human matting is an extremely interesting task where the goal is to find any
    human in a picture and remove the background from it. It is really hard to achieve
    due to the complexity of the task, having to find the person or people with the
    perfect contour. In this post, I review the best techniques used over the years
    and a novel approach published on November 29th, 2020\. Many techniques are using
    basic computer vision algorithms to achieve this task, such as the GrabCut algorithm,
    which is extremely fast, but not very precise.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 人体抠图是一项非常有趣的任务，目标是找到图片中的任何人并去除背景。由于任务复杂，需找到具有完美轮廓的人或多人，因此非常难以实现。在这篇文章中，我回顾了这些年来使用的最佳技术以及2020年11月29日发布的一种新方法。许多技术使用基本的计算机视觉算法来完成这项任务，如GrabCut算法，它极其快速，但不够精确。
- en: '[**High-Quality Background Removal Without Green Screens**](https://medium.com/datadriveninvestor/high-quality-background-removal-without-green-screens-8e61c69de63)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[**高质量背景去除，无需绿屏**](https://medium.com/datadriveninvestor/high-quality-background-removal-without-green-screens-8e61c69de63)'
- en: This new background removal technique can extract a person from a single input
    image, without the need for a green…
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新的背景去除技术可以从单张输入图像中提取一个人，无需绿屏……
- en: '[Click here for the MODNet code](https://github.com/ZHKKKe/MODNet)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里获取 MODNet 代码](https://github.com/ZHKKKe/MODNet)'
- en: '[DeOldify](https://github.com/jantic/DeOldify) [Bonus 3]'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[DeOldify](https://github.com/jantic/DeOldify) [Bonus 3]'
- en: DeOldify is a technique to colorize and restore old black and white images or
    even film footage. It was developed and is still getting updated by only one person
    Jason Antic. It is now the state of the art way to colorize black and white images,
    and everything is open-sourced, but we will get back to this in a bit.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: DeOldify 是一种为黑白图片或电影胶卷上色和修复的技术。它由 Jason Antic 开发并持续更新。它现在是为黑白图片上色的最先进方法，所有内容都是开源的，但我们稍后会回到这个话题。
- en: '[**This AI can Colorize your Black & White Photos with Full Photorealistic
    Renders! (DeOldify)**](https://medium.com/towards-artificial-intelligence/this-ai-can-colorize-your-black-white-photos-with-full-photorealistic-renders-deoldify-bf1eed5cb02a)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**这个 AI 可以将你的黑白照片色彩化，并提供全真实感的渲染！ (DeOldify)**](https://medium.com/towards-artificial-intelligence/this-ai-can-colorize-your-black-white-photos-with-full-photorealistic-renders-deoldify-bf1eed5cb02a)'
- en: This method is called DeOldify and works on pretty much any picture. If you
    don’t believe me, you can even try it…
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法称为 DeOldify，适用于几乎所有的图片。如果你不相信，可以亲自试试……
- en: '[Click here for the DeOldify code](https://github.com/jantic/DeOldify)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里获取 DeOldify 代码](https://github.com/jantic/DeOldify)'
- en: Conclusion
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: As you can see, this was an extremely insightful year for computer vision. I
    will be sure to cover the most exciting and interesting papers of 2021, and I
    would love it if you could take part in this adventure! If you like my work and
    want to stay up-to-date with AI technologies, you should definitely follow me
    on my social media channels.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，这对计算机视觉来说是一个极具洞察力的年份。我一定会涵盖2021年最激动人心和有趣的论文，如果你能参与其中我会非常高兴！如果你喜欢我的工作并希望了解最新的AI技术，你应该关注我的社交媒体频道。
- en: Subscribe to my [**YouTube channel**](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg).
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订阅我的 [**YouTube频道**](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg)。
- en: Follow my projects on [**LinkedIn**](https://www.linkedin.com/in/whats-ai/)**.**
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注我的项目 [**LinkedIn**](https://www.linkedin.com/in/whats-ai/)**。**
- en: Learn AI together, join our [**Discord community**](https://discord.gg/learnaitogether), *share
    your projects, papers, best courses, find Kaggle teammates, and much more!*
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一起学习 AI，加入我们的 [**Discord 社区**](https://discord.gg/learnaitogether)，*分享你的项目、论文、最佳课程，寻找
    Kaggle 队友，等等！*
- en: '[***Access the complete list in a GitHub repository***](https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[***访问 GitHub 仓库中的完整列表***](https://github.com/louisfb01/Top-10-Computer-Vision-Papers-2020)'
- en: '***Tag me on ***[***Twitter (@Whats_AI)***](https://twitter.com/Whats_AI)*** or ***[***LinkedIn
    (Louis (What’s AI) Bouchard)***](https://www.linkedin.com/in/whats-ai/)*** if
    you share the article!***'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果你分享了这篇文章，请在***[***Twitter (@Whats_AI)***](https://twitter.com/Whats_AI)***或***[***LinkedIn
    (Louis (What’s AI) Bouchard)***](https://www.linkedin.com/in/whats-ai/)*** 标记我！***'
- en: 'If you are interested in AI research, here is another great article for you:'
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如果你对 AI 研究感兴趣，这里有另一篇很棒的文章：
- en: '**[2020: A Year Full of Amazing AI Papers — A Review](https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b)**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**[2020: 一年精彩的 AI 论文——综述](https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b)**'
- en: A curated list of the latest breakthroughs in AI by release date with a clear
    video explanation, link to a more…
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最新 AI 突破的精心整理列表，按发布日期排序，并附有清晰的视频解释，链接到更多……
- en: '**Paper references**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**论文参考**'
- en: '[1] Akkaynak, Derya & Treibitz, Tali. (2019). Sea-Thru: A Method for Removing
    Water From Underwater Images. 1682–1691\. 10.1109/CVPR.2019.00178.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Akkaynak, Derya & Treibitz, Tali. (2019). Sea-Thru: 一种从水下图像中去除水的技术。1682–1691。10.1109/CVPR.2019.00178。'
- en: '[2] Lechner, M., Hasani, R., Amini, A. *et al.* Neural circuit policies enabling
    auditable autonomy. *Nat Mach Intell* **2, **642–652 (2020). [https://doi.org/10.1038/s42256-020-00237-3](https://doi.org/10.1038/s42256-020-00237-3)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Lechner, M., Hasani, R., Amini, A. *等* 神经电路策略实现可审计的自主性。*Nat Mach Intell*
    **2,** 642–652 (2020)。 [https://doi.org/10.1038/s42256-020-00237-3](https://doi.org/10.1038/s42256-020-00237-3)'
- en: '[3] P. P. Srinivasan, B. Deng, X. Zhang, M. Tancik, B. Mildenhall, and J. T.
    Barron, “Nerv: Neural reflectance and visibility fields for relighting and view
    synthesis,” in arXiv, 2020.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] P. P. Srinivasan, B. Deng, X. Zhang, M. Tancik, B. Mildenhall, 和 J. T.
    Barron，“Nerv: 神经反射和可见性场用于重光照和视图合成，”在arXiv，2020。'
- en: '[4] A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, Yolov4: Optimal speed and
    accuracy of object detection, 2020\. arXiv:2004.10934 [cs.CV].'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] A. Bochkovskiy, C.-Y. Wang, 和 H.-Y. M. Liao，Yolov4：目标检测的最佳速度和准确性，2020\.
    arXiv:2004.10934 [cs.CV]。'
- en: '[5] S. Menon, A. Damian, S. Hu, N. Ravi, and C. Rudin, Pulse: Self-supervised
    photo upsampling via latent space exploration of generative models, 2020\. arXiv:2003.03808
    [cs.CV].'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] S. Menon, A. Damian, S. Hu, N. Ravi, 和 C. Rudin，Pulse：通过生成模型的潜在空间探索进行自监督照片放大，2020\.
    arXiv:2003.03808 [cs.CV]。'
- en: '[6] M. Chen, A. Radford, R. Child, J. Wu, H. Jun, D. Luan, and I. Sutskever,
    “Generative pretraining from pixels,” in Proceedings of the 37th International
    Conference on Machine Learning, H. D. III and A. Singh, Eds., ser. Proceedings
    of Machine Learning Research, vol. 119, Virtual: PMLR, 13–18 Jul 2020, pp. 1691–1703\.
    [Online].'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] M. Chen, A. Radford, R. Child, J. Wu, H. Jun, D. Luan, 和 I. Sutskever，“从像素生成预训练，”在第37届国际机器学习大会论文集，H.
    D. III和A. Singh编，机器学习研究论文集，卷119，虚拟：PMLR，2020年7月13–18日，第1691–1703页。[在线]。'
- en: '[7] S.-Y. Chen, W. Su, L. Gao, S. Xia, and H. Fu, “DeepFaceDrawing: Deep generation
    of face images from sketches,” ACM Transactions on Graphics (Proceedings of ACM
    SIGGRAPH2020), vol. 39, no. 4, 72:1–72:16, 2020\. Available:http://proceedings.mlr.press/v119/chen20s.html.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] S.-Y. Chen, W. Su, L. Gao, S. Xia, 和 H. Fu，“DeepFaceDrawing：从草图中深度生成面部图像，”ACM图形学交易（ACM
    SIGGRAPH2020论文集），卷39，第4期，72:1–72:16，2020\. 可用：http://proceedings.mlr.press/v119/chen20s.html。'
- en: '[8] S. Saito, T. Simon, J. Saragih, and H. Joo, Pifuhd: Multi-level pixel-aligned
    implicit function for high-resolution 3d human digitization, 2020\. arXiv:2004.00452
    [cs.CV].'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] S. Saito, T. Simon, J. Saragih, 和 H. Joo，Pifuhd：多级像素对齐隐函数用于高分辨率3D人类数字化，2020\.
    arXiv:2004.00452 [cs.CV]。'
- en: '[9] Z. Teed and J. Deng, Raft: Recurrent all-pairs field transforms for optical
    flow, 2020\. arXiv:2003.12039 [cs.CV].'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Z. Teed 和 J. Deng，Raft：用于光流的递归全对场变换，2020\. arXiv:2003.12039 [cs.CV]。'
- en: '[10] Y. Zeng, J. Fu, and H. Chao, Learning joint spatial-temporal transformations
    for video in-painting, 2020\. arXiv:2007.10247 [cs.CV].'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Y. Zeng, J. Fu, 和 H. Chao，学习联合时空变换用于视频修复，2020\. arXiv:2007.10247 [cs.CV]。'
- en: '[Bonus 1] Z. Wan, B. Zhang, D. Chen, P. Zhang, D. Chen, J. Liao, and F. Wen,
    Old photo restoration via deep latent space translation, 2020\. arXiv:2009.07047
    [cs.CV].'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bonus 1] Z. Wan, B. Zhang, D. Chen, P. Zhang, D. Chen, J. Liao, 和 F. Wen，旧照片修复通过深度潜在空间转换，2020\.
    arXiv:2009.07047 [cs.CV]。'
- en: '[Bonus 2] Z. Ke, K. Li, Y. Zhou, Q. Wu, X. Mao, Q. Yan, and R. W. Lau, “Is
    a green screen really necessary for real-time portrait matting?” ArXiv, vol. abs/2011.11961,
    2020.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bonus 2] Z. Ke, K. Li, Y. Zhou, Q. Wu, X. Mao, Q. Yan, 和 R. W. Lau，“实时肖像抠图真的需要绿幕吗？”
    ArXiv，卷abs/2011.11961，2020。'
- en: '[Bonus 3] Jason Antic, Creator of DeOldify, [https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bonus 3] Jason Antic，DeOldify的创作者，[https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify)'
- en: '[Original](https://medium.com/towards-artificial-intelligence/top-10-computer-vision-papers-2020-aa606985f688).
    Reposted with permission.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/towards-artificial-intelligence/top-10-computer-vision-papers-2020-aa606985f688)。转载已获许可。'
- en: '**Related:**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[2020: A Year Full of Amazing AI Papers — A Review](/2020/12/2020-amazing-ai-papers.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2020：充满惊人AI论文的一年 — 回顾](/2020/12/2020-amazing-ai-papers.html)'
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning Research Main
    Developments in 2020 and Key Trends for 2021](/2020/12/predictions-ai-machine-learning-data-science-research.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI、分析、机器学习、数据科学、深度学习研究2020年的主要发展和2021年的关键趋势](/2020/12/predictions-ai-machine-learning-data-science-research.html)'
- en: '[Computer Vision at Scale With Dask And PyTorch](/2020/11/computer-vision-scale-dask-pytorch.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Dask和PyTorch的大规模计算机视觉](/2020/11/computer-vision-scale-dask-pytorch.html)'
- en: More On This Topic
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，剖析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么 Python 是初创企业的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
