- en: The Algorithms Aren’t Biased, We Are
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/01/algorithms-arent-biased-we-are.html](https://www.kdnuggets.com/2019/01/algorithms-arent-biased-we-are.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Rahul Bhargava](https://www.media.mit.edu/people/rahulb/overview/), MIT**.'
  prefs: []
  type: TYPE_NORMAL
- en: Excited about using AI to improve your organization’s operations? Curious about
    the promise of insights and predictions from computer models? I want to warn you
    about bias and how it can appear in those types of projects, share some illustrative
    examples, and translate the latest academic research on “algorithmic bias.”
  prefs: []
  type: TYPE_NORMAL
- en: First off — language matters. What we call things shapes our understanding of
    them. That’s why **I try to avoid the hype-driven term “artificial intelligence.”** Most
    projects called that are more usefully described as “machine learning.” Machine
    learning can be described as the process of training a computer to make decisions
    that you want help making. This post describes why you need to worry about the
    data in your machine learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: This matters in a lot of ways. “Algorithmic bias” is showing up all over the
    press right now. What does that term mean? Algorithms [are doling out discriminatory
    sentence ](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)recommendations
    for judges to use. Algorithms are [baking in gender stereotypes to translation
    services](http://mashable.com/2017/11/30/google-translate-sexism/). Algorithms
    are [pushing viewers towards extremist videos on YouTube](https://twitter.com/zeynep/status/917370470579822598).
    Most folks I know agree this is not the world we want. Let’s dig into why that
    is happening, and put the blame where it should be.
  prefs: []
  type: TYPE_NORMAL
- en: Your machine is learning, but who is teaching it?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Physics is hard for me. Even worse — I don’t think I’ll *ever* be good at physics.
    I attribute a lot of this to a poor high school physics teacher, who was condescending
    to me and the other students. On the other hand, while I’m not great at complicated
    math, I like trying to learn it better. I trace this continued enthusiasm to my
    junior high school math teacher, who introduced us to the topic with excitement
    and playfulness (including donut rewards for solving bonus problems!).
  prefs: []
  type: TYPE_NORMAL
- en: My point in sharing this story? Teachers matter. This is even more true in machine
    learning — machines don’t bring prior experience, contextual beliefs, and all
    the other things that make it important to meet human learners where they are
    and provide many paths into content. Machines only learn from only what you show
    them.
  prefs: []
  type: TYPE_NORMAL
- en: '**So in machine learning, the questions that matter are “what is the textbook”
    and “who is the teacher.”** The textbook in machine learning is the “training
    data” that you show to your software to teach it how to make decisions. This usually
    is some data you’ve examined and labeled with the answer you want. Often it is
    data you’ve gathered from lots of other sources that did that work already (we
    often call this a “corpus”). If you’re trying to predict how likely someone receiving
    a micro-loan is to repay it, then you might pick training data that includes previous
    payment histories of current loan recipients.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second part is about who the teacher is. The teacher decides what questions
    to ask, and tells learners what matters. In machine learning, the teacher is responsible
    for “feature selection” — deciding what pieces of the data the machine is allowed
    to use to make its decisions. Sometimes this feature selection is done for you
    by what is and isn’t included in the training sets you have. More often you use
    some statistics to have the computer pick the features most likely to be useful.
    Returning to our micro-loan example: some candidate features could be loan duration,
    total amount, whether the recipient has a cellphone, marital status, or their
    race.'
  prefs: []
  type: TYPE_NORMAL
- en: These two questions — training data and training features — are central to any
    machine learning project.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms are mirrors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s return to this question of language with this in mind.. perhaps a more
    useful term for “machine learning” would be “machine teaching.” This would put
    the responsibility where it lies, on the teacher. If you’re doing “machine learning.”
    you’re most interested in what it is learning to do. **With “machine teaching,”
    you’re most interested in what you are teaching a machine to do**. That’s a subtle
    difference in language, but a big difference in understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Putting the responsibility on the teacher helps us realize how tricky this process
    is. Remember this list of biases examples I started with? That sentencing algorithm
    is discriminatory because it was taught with sentencing data for the US court
    system, which data shows is very forgiving to everyone except black men. That
    translation algorithm that bakes in gender stereotypes was probably taught with
    data from the news or literature, which we known bakes in out-of-date gender roles
    and norms (ie. Doctors are “he,” while nurses are “she”). That algorithm that
    surfaces fake stories on your feed is taught to share what lots of other people
    share, irrespective of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: All that data is about us.
  prefs: []
  type: TYPE_NORMAL
- en: '**Those algorithms aren’t biased, we are! Algorithms are mirrors.**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07623c5d75a367f0c5d8fc2bcaa5bea5.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Algorithmic mirrors don’t fully reflect the world around us, nor the world
    we want**'
  prefs: []
  type: TYPE_NORMAL
- en: They reflect the biases in our questions and our data. These biases get baked
    into machine learning projects in both feature selection and training data. This
    is on us, not the computers.
  prefs: []
  type: TYPE_NORMAL
- en: Corrective lenses
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So how do we detect and correct this? Teachers feel a responsibility for, and
    pride in, their students’ learning. Developers of machine learning models should
    feel a similar responsibility, and perhaps should be allowed to feel a similar
    pride.
  prefs: []
  type: TYPE_NORMAL
- en: I’m heartened by examples like [Microsoft’s efforts to undo gender bias in publicly
    available language models](https://www.technologyreview.com/s/602025/how-vector-space-mathematics-reveals-the-hidden-sexism-in-language/) (trying
    to solve the “doctors are men” problem). I love my colleague Joy Buolamwini’s
    efforts to reframe this as a question of “justice” in the social and technical
    intervention she calls the “[Algorithmic Justice League](https://www.ajlunited.org/)”
    ([video](https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms)). [ProPublica’s](https://www.propublica.org/) investigative
    reporting is holding companies accountable for their discriminatory sentencing
    predictions. The amazing [Zeynep Tufekci](https://www.ted.com/talks/zeynep_tufekci_we_re_building_a_dystopia_just_to_make_people_click_on_ads) is
    leading the way in speaking and writing about the danger this poses to society
    at large. Cathy O’Neil’s [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com/) documents
    the myriad of implications for this, raising a warning flag for society at large.
    Fields [like law are debating the implications](https://scholarship.law.duke.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1315&context=dltr) of
    algorithm-driven decision making in public policy settings. [City ordinances](https://www.propublica.org/article/new-york-city-moves-to-create-accountability-for-algorithms) are
    starting to tackle the question of how to legislate against some of the effects
    I’ve described.
  prefs: []
  type: TYPE_NORMAL
- en: These efforts can hopefully serve as “corrective lenses” for these algorithmic
    mirrors — addressing the troubling aspects we see in our own reflections. The
    key here is to remember that it is up to us to do something about this. **Determining
    a decision with an algorithm doesn’t automatically make it reliable and trustworthy;
    just like quantifying something with data doesn’t automatically make it true**.
    We need to look at our own reflections in these algorithmic mirrors and make sure
    we see the future we want to see.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio**: [Rahul Bhargava](https://www.media.mit.edu/people/rahulb/overview/)
    is a researcher and technologist specializing in civic technology and data literacy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://medium.com/mit-media-lab/the-algorithms-arent-biased-we-are-a691f5f6f6f2).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Science and Ethics – Why Companies Need a new CEO (Chief Ethics Officer)](https://www.kdnuggets.com/2019/01/data-science-ethics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Exciting Ideas of 2018 in NLP](https://www.kdnuggets.com/2019/01/10-exciting-ideas-2018-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Case For Explainable AI & Machine Learning](https://www.kdnuggets.com/2018/12/explainable-ai-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Things Aren''t Always Normal: Some of the "Other" Distributions](https://www.kdnuggets.com/2023/01/things-arent-always-normal-distributions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Essential Machine Learning Algorithms: A Beginner''s Guide](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Algorithms for Classification](https://www.kdnuggets.com/2022/03/machine-learning-algorithms-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Popular Machine Learning Algorithms](https://www.kdnuggets.com/2022/05/popular-machine-learning-algorithms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free Algorithms in Python Course](https://www.kdnuggets.com/2022/09/free-algorithms-python-course.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
