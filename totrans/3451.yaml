- en: 'Support Vector Machines: A Simple Explanation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/07/support-vector-machines-simple-explanation.html](https://www.kdnuggets.com/2016/07/support-vector-machines-simple-explanation.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Noel Bambrick, AYLIEN**.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this post, we are going to introduce you to the Support Vector Machine (SVM)
    machine learning algorithm. We will follow a similar process to our recent post [Naive
    Bayes for Dummies; A Simple Explanation](http://blog.aylien.com/post/120703930533/naive-bayes-for-dummies-a-simple-explanation) by
    keeping it short and not overly-technical. The aim is to give those of you who
    are new to machine learning a basic understanding of the key concepts of this
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machines - What are they?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: A Support Vector Machine (SVM) is a supervised machine learning algorithm that
    can be employed for both classification and regression purposes. SVMs are more
    commonly used in classification problems and as such, this is what we will focus
    on in this post.
  prefs: []
  type: TYPE_NORMAL
- en: SVMs are based on the idea of finding a hyperplane that best divides a dataset
    into two classes, as shown in the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM](../Images/fa2e2d0a1043695bf64083c0efe4dbcf.png)'
  prefs: []
  type: TYPE_IMG
- en: Support Vectors
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Support vectors are the data points nearest to the hyperplane, the points of
    a data set that, if removed, would alter the position of the dividing hyperplane.
    Because of this, they can be considered the critical elements of a data set.
  prefs: []
  type: TYPE_NORMAL
- en: What is a hyperplane?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a simple example, for a classification task with only two features (like
    the image above), you can think of a hyperplane as a line that linearly separates
    and classifies a set of data.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the further from the hyperplane our data points lie, the more confident
    we are that they have been correctly classified. We therefore want our data points
    to be as far away from the hyperplane as possible, while still being on the correct
    side of it.
  prefs: []
  type: TYPE_NORMAL
- en: So when new testing data is added, whatever side of the hyperplane it lands
    will decide the class that we assign to it.
  prefs: []
  type: TYPE_NORMAL
- en: How do we find the right hyperplane?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Or, in other words, how do we best segregate the two classes within the data?
  prefs: []
  type: TYPE_NORMAL
- en: The distance between the hyperplane and the nearest data point from either set
    is known as the margin. The goal is to choose a hyperplane with the greatest possible
    margin between the hyperplane and any point within the training set, giving a
    greater chance of new data being classified correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM](../Images/850fa031b44c27acac9ce455b9e7cc95.png)'
  prefs: []
  type: TYPE_IMG
- en: But what happens when there is no clear hyperplane?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is where it can get tricky. Data is rarely ever as clean as our simple
    example above. A dataset will often look more like the jumbled balls below which
    represent a linearly non separable dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM](../Images/8f6030cd7d14f278f090e4bdb0f2f6bd.png)< In order to classify
    a dataset like the one above it’s necessary to move away from a 2d view of the
    data to a 3d view. Explaining this is easiest with another simplified example.
    Imagine that our two sets of colored balls above are sitting on a sheet and this
    sheet is lifted suddenly, launching the balls into the air. While the balls are
    up in the air, you use the sheet to separate them. This ‘lifting’ of the balls
    represents the mapping of data into a higher dimension. This is known as kernelling.
    You can read more on Kerneling [here](http://t.umblr.com/redirect?z=http%3A%2F%2Fwww.eric-kim.net%2Feric-kim-net%2Fposts%2F1%2Fkernel_trick.html&t=YWFkNDNjNzEyOTdmMzc5ZGRlNWU5YjBjZjMwOGI3MTMwMWQ1YjBkNix1cjlJVDBQcA%3D%3D).'
  prefs: []
  type: TYPE_NORMAL
- en: '![SVM](../Images/086fc32f5b768512fea953826d12bf5d.png)'
  prefs: []
  type: TYPE_IMG
- en: Because we are now in three dimensions, our hyperplane can no longer be a line.
    It must now be a plane as shown in the example above. The idea is that the data
    will continue to be mapped into higher and higher dimensions until a hyperplane
    can be formed to segregate it.
  prefs: []
  type: TYPE_NORMAL
- en: Pros & Cons of Support Vector Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Pros**'
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Works well on smaller cleaner datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can be more efficient because it uses a subset of training points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**'
  prefs: []
  type: TYPE_NORMAL
- en: Isn’t suited to larger datasets as the training time with SVMs can be high
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less effective on noisier datasets with overlapping classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SVM Uses
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SVM is used for text classification tasks such as category assignment, detecting
    spam and sentiment analysis. It is also commonly used for image recognition challenges,
    performing particularly well in aspect-based recognition and color-based classification.
    SVM also plays a vital role in many areas of handwritten digit recognition, such
    as postal automation services.
  prefs: []
  type: TYPE_NORMAL
- en: There you have it, a very high level introduction to Support Vector Machines.
    If you’d like to dive deeper into SVM we recommend checking out (need to find
    a link to a video or a more in depth blog).
  prefs: []
  type: TYPE_NORMAL
- en: '**About**: This blog was originally published on the [**AYLIEN Text Analysis
    blog**](http://t.sidekickopen57.com/e1t/c/5/f18dQhb0S7lC8dDMPbW2n0x6l2B9nMJW7t5XZs8q5vngW7fZwJ-3N1L7sVQsyTK56dFYsf8TlV-x02?t=http%3A%2F%2Fblog.aylien.com%2Fpost%2F146410178273%2Fsupport-vector-machines-for-dummies-a-simple&si=5740235936759808&pi=75c5cbd5-7b4f-411f-e28d-d4dccc46da4b).
    AYLIEN provides tools and services to help developers and data scientists make
    sense of unstructured content at scale.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://blog.aylien.com/post/146410178273/support-vector-machines-for-dummies-a-simple).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to Select Support Vector Machine Kernels](/2016/06/select-support-vector-machine-kernels.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[When Does Deep Learning Work Better Than SVMs or Random Forests?](/2016/04/deep-learning-vs-svm-random-forest.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Key Terms, Explained](/2016/05/machine-learning-key-terms-explained.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
