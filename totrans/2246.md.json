["```py\npip install lightgbm\n```", "```py\nconda install -c conda-forge lightgbm\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n```", "```py\ntitanic = sns.load_dataset('titanic')\n```", "```py\n# Drop unnecessary columns\ntitanic = titanic.drop(['deck', 'embark_town', 'alive'], axis=1)\n\n# Replace missing values with the median or mode\ntitanic['age'] = titanic['age'].fillna(titanic['age'].median())\ntitanic['fare'] = titanic['fare'].fillna(titanic['fare'].mode()[0])\ntitanic['embarked'] = titanic['embarked'].fillna(titanic['embarked'].mode()[0])\n```", "```py\n# Convert categorical variables to numerical variables\ntitanic['sex'] = pd.Categorical(titanic['sex']).codes\ntitanic['embarked'] = pd.Categorical(titanic['embarked']).codes\n\n# Split the dataset into input features and the target variable\nX = titanic.drop('survived', axis=1)\ny = titanic['survived']\n```", "```py\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```", "```py\nclass_dict = {\n\"Third\": 3,\n\"First\": 1,\n\"Second\": 2\n}\nwho_dict = {\n\"child\": 0,\n\"woman\": 1,\n\"man\": 2\n}\nX_train['class'] = X_train['class'].apply(lambda x: class_dict[x])\nX_train['who'] = X_train['who'].apply(lambda x: who_dict[x])\nX_test['class'] = X_test['class'].apply(lambda x: class_dict[x])\nX_test['who'] = X_test['who'].apply(lambda x: who_dict[x])\n```", "```py\nparams = {\n'objective': 'binary',\n'boosting_type': 'gbdt',\n'num_leaves': 31,\n'learning_rate': 0.05,\n'feature_fraction': 0.9\n}\nclf = lgb.LGBMClassifier(**params)\nclf.fit(X_train, y_train)\n```", "```py\npredictions = clf.predict(X_test)\nprint(classification_report(y_test, predictions))\n```", "```py\n precision    recall  f1-score   support\n\n           0       0.84      0.89      0.86       105\n           1       0.82      0.76      0.79        74\n\n    accuracy                           0.83       179\n   macro avg       0.83      0.82      0.82       179\nweighted avg       0.83      0.83      0.83       179\n```", "```py\nmodel = lgb.LGBMClassifier(num_leaves=31, min_data_in_leaf=20, max_depth=5)\nmodel.fit(X_train, y_train)\n```", "```py\npredictions = model.predict(X_test)\nprint(classification_report(y_test, predictions))\n```", "```py\n precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87       105\n           1       0.83      0.77      0.80        74\n\n    accuracy                           0.84       179\n   macro avg       0.84      0.83      0.83       179\nweighted avg       0.84      0.84      0.84       179\n```"]