- en: How do you check the quality of your regression model in Python?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html](https://www.kdnuggets.com/2019/07/check-quality-regression-model-python.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)![figure-name](../Images/9e4cbe6f9a615429e47f6d2663996008.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Why it is important (and why you might be missing it)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For all the talk and hair-splitting on the intricacies of the latest deep neural
    net architectures and the amazing power of [xgboost on the Kaggle competitions](https://blog.kaggle.com/tag/xgboost/),
    for a large portion of the industry, using [data-driven analytics](https://www.oreilly.com/library/view/creating-a-data-driven/9781491916902/ch01.html) and
    machine learning (ML) techniques, [regression remains the top choice](https://www.surveygizmo.com/resources/blog/regression-analysis/) for
    their daily use.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: See this KDnuggets poll result from 2018–19 (by [Matthew Mayo](https://medium.com/@mattmayo13)).
  prefs: []
  type: TYPE_NORMAL
- en: '[**Top Data Science and Machine Learning Methods Used in 2018, 2019**'
  prefs: []
  type: TYPE_NORMAL
- en: '*In the latest KDnuggets poll, readers were asked: Which Data Science / Machine
    Learning methods and algorithms did you…*www.kdnuggets.com](/2019/04/top-data-science-machine-learning-methods-2018-2019.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The technique of regression comes in many forms — linear, nonlinear, poison,
    tree-based- but the core idea remains almost same across the board and can be
    applied to a wide variety of predictive analytics problems in finance, healthcare,
    service industry, manufacturing, agriculture, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression is the fundamental technique, [which is rooted strongly in
    the time-tested theory of statistical learning and inference](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2),
    and powers all the regression-based algorithms used in modern data science pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: However, **the success of a linear regression model also depends on some fundamental
    assumptions** about the nature of the underlying data that it tries to model.
    See this article for a simple and intuitive understanding of these assumptions,
  prefs: []
  type: TYPE_NORMAL
- en: '[**Regression Model Assumptions**'
  prefs: []
  type: TYPE_NORMAL
- en: '*We make a few assumptions when we use linear regression to model the relationship
    between a response and a predictor…*www.jmp.com](https://www.jmp.com/en_us/statistics-knowledge-portal/what-is-regression/simple-linear-regression-assumptions.html)'
  prefs: []
  type: TYPE_NORMAL
- en: It is, therefore, extremely important to check the quality of your linear regression
    model, by verifying whether these assumptions were “reasonably” satisfied (generally
    visual analytics methods, which are subject to interpretation, are used to check
    the assumptions).
  prefs: []
  type: TYPE_NORMAL
- en: The problem is that checking the quality of the model is often a less prioritized
    aspect of a data science task flow where other priorities dominate — prediction,
    scaling, deployment, and model tuning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Does this assertion sound too bold? There is an easy test.
  prefs: []
  type: TYPE_NORMAL
- en: In an industry standard Python-based data science stack, how many times have
    you used **Pandas, NumPy**, **Scikit-learn**, or even **PostgreSQL** for data
    acquisition, wrangling, visualization, and finally constructing and tuning your
    ML model? Plenty of times, I suppose?
  prefs: []
  type: TYPE_NORMAL
- en: Now, how many times have you used the [**statsmodels** library](http://www.statsmodels.org/devel/index.html) to
    examine the model by running [goodness-of-fit tests](https://www.statisticshowto.datasciencecentral.com/goodness-of-fit-test/)?
  prefs: []
  type: TYPE_NORMAL
- en: It is very common in a **Python-based data science learning track**, to go like
    this,
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/cb1e308ec23bdb945d0601b004ce3e41.png)'
  prefs: []
  type: TYPE_IMG
- en: The answer to the question “Is something missing” is yes!
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/c1720435d2c50d68b6bf859f29b66f6a.png)'
  prefs: []
  type: TYPE_IMG
- en: Often, there is plenty of discussion about [regularization](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a), [bias-variance
    trade-off](http://scott.fortmann-roe.com/docs/BiasVariance.html), or scalability
    (learning and complexity curves) plots. But, is there sufficient discussion around
    the following plots and lists?
  prefs: []
  type: TYPE_NORMAL
- en: Residuals vs. predicting variables plots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fitted vs. residuals plot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histogram of the normalized residuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Q-Q plot of the normalized residuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shapiro-Wilk normality test on the residuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cook’s distance plot of the residuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance inflation factor (VIF) of the predicting features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is clear that you have to wear the [hat of a statistician](https://towardsdatascience.com/statistics-for-people-in-a-hurry-a9613c0ed0b),
    not only a data mining professional, for this part of the machine learning pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/de8063c990e653f183c1d99f45e6d855.png)'
  prefs: []
  type: TYPE_IMG
- en: The issue with Scikit-learn
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It can be safely assumed that the majority of [statisticians-turned-data scientists](https://www.unece.org/info/media/news/statistics/2017/are-official-statisticians-becoming-data-scientists/doc.html)run
    the [goodness-of-fit tests](http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/fit.pdf) regularly
    on their regression models.
  prefs: []
  type: TYPE_NORMAL
- en: But many young data scientists and analysts depend heavily, for data-driven
    modeling, on ML-focused packages like **Scikit-learn**, which, although being
    an awesome library and virtually a [silver bullet for machine learning and prediction
    tasks](https://medium.com/analytics-vidhya/scikit-learn-a-silver-bullet-for-basic-machine-learning-13c7d8b248ee),
    do not support easy and fast evaluation of model quality based on standard statistical
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is imperative that good data science pipeline, in addition to
    using an ML-focused library like Scikit-learn, include some standardized set of
    code to evaluate the quality of the model using statistical tests.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this article, we show such a standard set of evaluations for a multivariate
    linear regression problem. We will use the statsmodels library for regression
    modeling and statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/29b26bda945bc489ce754dabcd76113b.png)'
  prefs: []
  type: TYPE_IMG
- en: A brief overview of linear regression assumptions and the key visual tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The assumptions**'
  prefs: []
  type: TYPE_NORMAL
- en: The four key assumptions that need to be tested for a linear regression model
    are,
  prefs: []
  type: TYPE_NORMAL
- en: '**Linearity**: The expected value of the dependent variable is a linear function
    of each independent variable, holding the others fixed (note this does not restrict
    you to use a nonlinear transformation of the independent variables i.e. you can
    still model *f(x) = ax² + bx + c*, using both *x²* and *x* as predicting variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independence**: The errors (residuals of the fitted model) are independent
    of each other.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Homoscedasticity** **(constant variance)**: The variance of the errors is
    constant with respect to the predicting variables or the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normality**: The errors are generated from a Normal distribution (of unknown
    mean and variance, which can be estimated from the data). Note, this is not a
    necessary condition to perform linear regression unlike the top three above. However,
    without this assumption being satisfied, you cannot calculate the so-called ‘confidence’
    or ‘prediction’ intervals easily as the well-known analytical expressions corresponding
    to Gaussian distribution cannot be used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For multiple linear regression, judging **multicollinearity** is also critical
    from the statistical inference point of view. This assumption assumes minimal
    or no linear dependence between the predicting variables.
  prefs: []
  type: TYPE_NORMAL
- en: '**Outliers** can also be an issue impacting the model quality by having a disproportionate
    influence on the estimated model parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: Here is a visual recap,
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/de765e96e96c40a55b15bf3608a42821.png)'
  prefs: []
  type: TYPE_IMG
- en: '**What plots are can be checked?**'
  prefs: []
  type: TYPE_NORMAL
- en: So, error terms are pretty important.
  prefs: []
  type: TYPE_NORMAL
- en: But there is a piece of bad news. We can never know the true errors, no matter
    how much data we have. We can only estimate and draw inference about the distribution
    from which the data is generated.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Therefore, **the proxy of true errors are the residuals**, which are just the
    difference between the observed values and the fitted values.
  prefs: []
  type: TYPE_NORMAL
- en: Bottom line — we need to plot the residuals, check their random nature, variance,
    and distribution for evaluating the model quality. **This is the visual analytics
    needed for goodness-of-fit estimation of a linear model**.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from this, multicollinearity can be checked from the correlation matrix
    and heatmap, and outliers in the data (residual) can be checked by so-called **Cook’s
    distance plots**.
  prefs: []
  type: TYPE_NORMAL
- en: Example of regression model quality evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The entire code repo for this example [can be found in the author’s Github](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Regression_Diagnostics.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: We are using the [concrete compressive strength prediction](https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength) problem
    from the UCI ML portal. The concrete compressive strength is a highly complex
    function of age and ingredients. Can we predict the strength from measurement
    values of these parameters?
  prefs: []
  type: TYPE_NORMAL
- en: '**Scatterplot of variables to check for linearity**'
  prefs: []
  type: TYPE_NORMAL
- en: We can simply check the scatterplot for visual inspection of the assumption
    of linearity.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/6ab0fbb97a7803457aff72bca2caf51d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Pairwise scatter plots and correlation heatmap for checking multicollinearity**'
  prefs: []
  type: TYPE_NORMAL
- en: We can use the [**pairplot** function from the **seaborn** library](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to
    plot the pairwise scatterplots of all combinations.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/e92931cf3f7b0bd87890ecd47fbf6566.png)'
  prefs: []
  type: TYPE_IMG
- en: Furthermore, if the data is loaded in Pandas, we can easily compute the correlation
    matrix and pass that onto the [special plotting function of statsmodels](https://www.statsmodels.org/stable/generated/statsmodels.graphics.correlation.plot_corr.html#statsmodels.graphics.correlation.plot_corr)to
    visualize the correlation as a heatmap.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/ee188737403d0b7082d46984c8bc1f82.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Model fitting using statsmodel.ols() function**'
  prefs: []
  type: TYPE_NORMAL
- en: The main model fitting is done using the statsmodels.OLS method. It is an amazing
    linear model fit utility which feels very much like the powerful ‘lm’ function
    in R. Best of all, it accepts R-style formula for constructing the full or partial
    model (i.e. involving all or some of the predicting variables).
  prefs: []
  type: TYPE_NORMAL
- en: You may question, in the age of big data, why bother about creating a partial
    model and not throw all the data in? That is because confounding or hidden bias
    may be present in the data which can be addressed only by [**controlling for certain
    factors**](https://stats.stackexchange.com/questions/78816/how-do-you-control-for-a-factor-variable).
  prefs: []
  type: TYPE_NORMAL
- en: In any case, the summary of the model fitted through this model already provides
    rich statistical information about the model such as t-statistics and p-values
    corresponding to all the predicting variables, R-squared, and adjusted R-squared,
    AIC and BIC, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/33a5f6f7a0241f3f0c3bb27a0b13c417.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Residuals vs. predicting variables plots**'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we can plot the residuals versus each of the predicting variables to look
    for independence assumption. **If the residuals are distributed uniformly randomly
    around the zero x-axes and do not form specific clusters**, then the assumption
    holds true. In this particular problem, we observe some clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/5c405c5508e0063b5ce131990d60db04.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Fitted vs. residuals plot to check homoscedasticity**'
  prefs: []
  type: TYPE_NORMAL
- en: When we plot the fitted response values (as per the model) vs. the residuals,
    we clearly observe that the **variance of the residuals increases with response
    variable magnitude**. Therefore, the problem does not respect homoscedasticity
    and some kind of variable transformation may be needed to improve model quality.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/541389612dcb9a96d2c2cf463837f56a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Histogram and Q-Q plot of normalized residuals**'
  prefs: []
  type: TYPE_NORMAL
- en: To check the assumption of normality of the data generating process, we can
    simply plot the histogram and the Q-Q plot of the normalized residuals.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/b6fc7dfb1fc4c89f7101d7c473777fb8.png)'
  prefs: []
  type: TYPE_IMG
- en: Additionally, we can run the Shapiro-Wilk test on the residuals to check for
    the Normality.
  prefs: []
  type: TYPE_NORMAL
- en: '**Outlier detection using Cook’s distance plot**'
  prefs: []
  type: TYPE_NORMAL
- en: Cook’s distance essentially measures the effect of deleting a given observation.
    Points with a large Cook’s distance need to be closely examined for being potential
    outliers. We can plot the Cook’s distance using a special [outlier influence class
    from statsmodels](http://www.statsmodels.org/devel/generated/statsmodels.stats.outliers_influence.OLSInfluence.summary_frame.html).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/73db1323cc8f847f5d25911ef1dd7b37.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Variance influence factors**'
  prefs: []
  type: TYPE_NORMAL
- en: The OLS model summary for this dataset shows a warning for multicollinearity.
    But how to check which factors are causing it?
  prefs: []
  type: TYPE_NORMAL
- en: We can compute the [variance influence factors](https://en.wikipedia.org/wiki/Variance_inflation_factor) for
    each predicting variable. It is the ratio of variance in a model with multiple
    terms, divided by the variance of a model with one term alone. Again, we take
    advantage of the [special outlier influence class](https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html) in
    statsmodels.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/c84fa117d048f479d572f32db303e3b1.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Other residuals diagnostics**'
  prefs: []
  type: TYPE_NORMAL
- en: Statsmodels have a wide variety of other diagnostics tests for checking model
    quality. You can take a look at these pages.
  prefs: []
  type: TYPE_NORMAL
- en: '[Residual diagnostics tests](https://www.statsmodels.org/stable/stats.html#module-statsmodels.stats.stattools)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Goodness-of-fit tests](https://www.statsmodels.org/stable/stats.html#goodness-of-fit-tests-and-measures)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary and thoughts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we covered how one can add **essential visual analytics for
    model quality evaluation** in linear regression — various residual plots, normality
    tests, and checks for multicollinearity.
  prefs: []
  type: TYPE_NORMAL
- en: One can even think of creating a simple suite of functions capable of accepting
    a scikit-learn type estimator and generating these plots for the data scientist
    to quickly check the model quality.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, although scikit-learn does not have detailed statistical tests or
    plotting capabilities for the model quality evaluation, [Yellowbrick](https://www.scikit-yb.org/en/latest/) is
    a promising Python library which can add intuitive visualization capability on
    scikit-learn objects. We can hope that in the near future, statistical tests can
    be added to scikit-learn ML estimators directly.
  prefs: []
  type: TYPE_NORMAL
- en: Ifyou have any questions or ideas to share, please contact the author at [**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com).
    Also, you can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)**repositories **for
    other fun code snippets in Python, R, or MATLAB and machine learning resources.
    If you are, like me, passionate about machine learning/data science, please feel
    free to [add me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter.](https://twitter.com/tirthajyotiS)
  prefs: []
  type: TYPE_NORMAL
- en: '[**Tirthajyoti Sarkar - Sr. Principal Engineer - Semiconductor, AI, Machine
    Learning - ON…**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Georgia Institute of Technology Master of Science - MS, Analytics This MS
    program imparts theoretical and practical…*www.linkedin.com](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Tirthajyoti Sarkar](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)**
    is the Senior Principal Engineer at ON Semiconductor working on Deep Learning/Machine
    Learning based design automation projects.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/how-do-you-check-the-quality-of-your-regression-model-in-python-fa61759ff685).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Selecting the Best Machine Learning Algorithm for Your Regression Problem](/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Choosing the Right Metric for Evaluating Machine Learning Models  –  Part
    1](/2018/04/right-metric-evaluating-machine-learning-models-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Separating signal from noise](/2019/06/separating-signal-noise.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Quality Dimensions: Assuring Your Data Quality with Great Expectations](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Significance of Data Quality in Making a Successful Machine…](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 New Prompt Engineering Resources to Check Out](https://www.kdnuggets.com/3-new-prompt-engineering-resources)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Overcome Your Data Quality Issues with Great Expectations](https://www.kdnuggets.com/2023/01/overcome-data-quality-issues-great-expectations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear Regression Model Selection: Balancing Simplicity and Complexity](https://www.kdnuggets.com/2023/02/linear-regression-model-selection-balancing-simplicity-complexity.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
