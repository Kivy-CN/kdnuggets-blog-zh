# 如何在你的第一次Kaggle比赛中排名前10%

> 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/4](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/4)

### Home Depot搜索相关性

在这一部分，我将分享我在[Home Depot搜索相关性比赛](https://www.kaggle.com/c/home-depot-product-search-relevance)中的解决方案以及比赛后从顶级团队那里学到的经验。

本次比赛的任务是预测搜索词在Home Depot网站上的结果的相关性。相关性是三位人工评估者的平均分数，范围在1到3之间。因此这是一个回归任务。数据集包含搜索词、产品标题/描述以及一些属性，如品牌、尺寸和颜色。评估指标是[RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全领域的职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在IT方面

* * *

这与[Crowdflower搜索结果相关性](https://www.kaggle.com/c/crowdflower-search-relevance)非常相似。不同之处在于，Crowdflower比赛中使用了[二次加权Kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa#Weighted_kappa)，因此使得回归分数的最终截止点变得复杂。而且Crowdflower中没有提供属性。

**EDA**

当我加入比赛时，有几项相当不错的EDA，特别是[这个](https://www.kaggle.com/briantc/home-depot-product-search-relevance/homedepot-first-dataexploreation-k)。我了解到：

+   许多搜索词/产品出现了几次。

+   文本相似性是很好的特征。

+   许多产品没有属性特征。这会是个问题吗？

+   产品ID似乎具有强大的预测能力。然而，训练集和测试集之间的产品ID重叠并不是很高。这会导致过拟合吗？

**预处理**

你可以在[GitHub](https://github.com/dnc1994/Kaggle-Playground/blob/master/home-depot/Preprocess.ipynb)上查看我如何进行预处理和特征工程。我这里只会做一个简要总结：

1.  使用[拼写错误词典](https://www.kaggle.com/steubk/home-depot-product-search-relevance/fixing-typos)来修正搜索词中的拼写错误。

1.  计算属性。找到那些频繁且容易被利用的属性。

1.  将训练集与测试集合并。这一点很重要，因为否则你将不得不进行两次特征转换。

1.  对所有文本字段进行 **[词干提取](https://en.wikipedia.org/wiki/Stemming)** 和 **[分词](https://en.wikipedia.org/wiki/Text_segmentation#Word_segmentation)**。一些 **规范化**（包括数字和单位）以及 **同义词替换** 是手动执行的。

**特征**

+   *属性特征

    +   产品是否包含某个属性（品牌、尺寸、颜色、重量、室内/室外、能源星级认证等）

    +   是否某个属性与搜索词匹配

+   元特征

    +   每个文本字段的长度

    +   产品是否包含属性字段

    +   品牌（编码为整数）

    +   产品 ID

+   匹配

    +   搜索词是否出现在产品标题/描述/属性中

    +   搜索词在产品标题/描述/属性中的出现次数和比例

    +   *搜索词的第 i 个词是否出现在产品标题/描述/属性中

+   搜索词与产品标题/描述/属性之间的文本相似性

    +   [BOW](https://en.wikipedia.org/wiki/Bag-of-words_model) [余弦相似性](https://en.wikipedia.org/wiki/Cosine_similarity)

    +   [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 余弦相似性

    +   [Jaccard 相似性](https://en.wikipedia.org/wiki/Jaccard_index)

    +   *[编辑距离](https://en.wikipedia.org/wiki/Edit_distance)

    +   [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) 距离（我没有包含这个，因为它的表现差且计算速度慢。但似乎我使用不当。）

+   **[潜在语义索引](https://en.wikipedia.org/wiki/Latent_semantic_indexing)：通过对 BOW/TF-IDF 向量化获得的矩阵进行[SVD分解](https://en.wikipedia.org/wiki/Singular_value_decomposition)，我们得到不同搜索词/产品组的潜在表示。这使得我们的模型能够区分组别并为特征分配不同的权重，从而在一定程度上解决了相关数据和产品缺少某些特征的问题。**

请注意，以上带有 `*` 的特征是我最后添加的一批特征。问题是，使用这些特征训练的模型表现比之前的模型更差。起初我认为特征数量的增加需要重新调整模型参数。然而，在浪费了大量 CPU 时间进行网格搜索后，我仍未能超越旧模型。我认为这可能是上述提到的 **特征相关性** 问题。我实际上知道一个可能有效的解决方案，即 **通过堆叠将训练于不同版本特征的模型结合起来**。不幸的是，我没有足够的时间去尝试。**实际上，大多数顶尖团队认为用不同的预处理和特征工程管道训练的模型集成是成功的关键**。

**模型**

起初我使用`RandomForestRegressor`来构建我的模型。后来我尝试了**Xgboost**，结果发现它的速度是Sklearn的两倍多。从那时起，我每天做的基本上是在工作站上进行网格搜索，同时在我的笔记本电脑上处理特征。

本次竞赛的数据集验证起来并不简单。数据不是独立同分布的，许多记录之间是相关的。我多次使用更好的特征/参数却最终得到更差的LB分数。正如许多成功的Kaggler所反复强调的那样，在这种情况下，你必须相信自己的CV分数。因此，我决定在交叉验证中使用10折而不是5折，并在接下来的尝试中忽略LB分数。

**集成模型**

我的最终模型是由4个基础模型组成的集成模型：

+   `RandomForestRegressor`

+   `ExtraTreesRegressor`

+   `GradientBoostingRegressor`

+   `XGBRegressor`

堆叠器也是一个`XGBRegressor`。

问题是我的所有基础模型高度相关（最低相关系数为0.9）。我考虑将线性回归、SVM回归和带有线性增强器的`XGBRegressor`纳入集成模型，但这些模型的RMSE分数比我最终使用的4个模型高出0.02（这在排行榜上相当于数百名的差距）。因此，我决定不再使用更多的模型，尽管它们会带来更多的多样性。

好消息是，尽管基础模型高度相关，堆叠仍然显著提高了我的分数。**更重要的是，我的CV分数和LB分数在我开始堆叠之后完全同步。**

在竞赛的最后两天，我还做了一件事：**使用20个不同的随机种子生成集成模型，并将它们的加权平均作为最终提交**。这实际上是一种**bagging**。从理论上讲，这是有意义的，因为在堆叠中，我使用了80%的数据来训练基础模型，而100%的数据用于训练堆叠器。因此，这种方法不够干净。使用不同的种子进行多次运行确保了**每次使用不同的80%的数据**，从而降低了信息泄露的风险。然而，这样做我只获得了`0.0004`的提升，这可能只是由于随机性。

竞赛结束后，我发现我的最佳单一模型在私人排行榜上的分数是`0.46378`，而我的最佳堆叠集成模型的分数是`0.45849`。这就是174名和98名之间的差距。换句话说，特征工程和模型调优让我进入了前10%，而堆叠让我进入了前5%。

**经验教训**

从顶级团队分享的解决方案中有很多可以学习的东西：

+   产品标题中存在一个模式。例如，产品是否附带某种配件将通过标题末尾的`With/Without XXX`来表示。

+   使用外部数据。例如，使用 [WordNet](https://wordnet.princeton.edu/) 或 [Reddit 评论数据集](https://www.kaggle.com/reddit/reddit-comments-may-2015) 来训练同义词和 [超类词](https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy)。

+   一些特征是基于**字母**而不是**词**。起初我对此感到困惑。但如果你考虑一下，这就很有意义。例如，获得第三名的团队在计算文本相似度时考虑了字母匹配的数量。他们认为**较长的词更具特异性，因此更有可能被人类分配高相关性分数**。他们还使用逐字符序列比较（`difflib.SequenceMatcher`）来衡量**视觉相似度**，他们认为这对人类很重要。

+   对词进行 POS 标记，并在短语中找到**[head](https://en.wikipedia.org/wiki/Head_(linguistics))**，在计算各种距离度量时使用它们。

+   从产品标题/描述字段的 TF-IDF 中提取排名靠前的三元组，并计算这些三元组中出现的搜索词的比例。反之亦然。这就像从另一个角度计算潜在索引。

+   一些新颖的距离度量，如 [Word Movers Distance](http://jmlr.org/proceedings/papers/v37/kusnerb15.pdf)。

+   除了 SVD，一些人使用了 [NMF](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization)。

+   生成**成对多项式交互**在排名靠前的特征之间。

+   **对于交叉验证，构建训练集和测试集之间产品 ID 不重叠的拆分，以及 ID 重叠的拆分。然后，我们可以使用这些拆分及其对应的比例来近似公共/私人 LB 拆分在我们本地交叉验证中的影响。**

### 总结

**收获**

1.  **早早开始做集成学习是一个明智的决定**。事实证明，我在最后几天还在处理特征。

1.  优先级很高的是建立一个能够自动训练模型和记录最佳参数的管道。

1.  **特征最重要！** 在这次比赛中，我没有花足够的时间在特征上。

1.  如果可能，花些时间手动检查原始数据以寻找模式。

**提出的问题**

在这些竞赛中遇到的一些问题具有很高的研究价值。

1.  如何对依赖数据进行可靠的交叉验证。

1.  如何量化**多样性和准确性之间的权衡**在集成学习中。

1.  如何处理对模型性能有害的特征交互。**以及如何确定在这种情况下新特征是否有效**。

**新手提示**

1.  选择一个你感兴趣的比赛。**如果你对问题领域已有一些见解，那会更好。**

1.  遵循我的方法或他人的方法，开始探索、理解和建模数据。

1.  从论坛和脚本中学习。查看其他人如何解读数据和构建特征。

1.  **寻找之前比赛的获胜者采访或博客文章。这些资料极其有用，特别是那些与您正在进行的比赛有一些相似性的比赛。**

1.  在你达到了相当好的分数（例如 10% ~ 20%）或者你觉得新特征空间已经不大（虽然遗憾的是这通常是错误的）之后，开始进行集成学习吧。

1.  如果你认为你可能有机会赢得奖项，尝试组队！

1.  **不要在比赛结束前放弃。至少每天尝试一些新事物。**

1.  从顶级团队在比赛后的分享中学习。反思你的方法。**如果可能的话，花些时间验证你学到的东西。**

1.  休息一下吧！

### 参考文献

1.  [轻松战胜 Kaggle - 董颖](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiPxZHewLbMAhVKv5QKHb3PCGwQFggcMAA&url=http%3A%2F%2Fwww.ke.tu-darmstadt.de%2Flehre%2Farbeiten%2Fstudien%2F2015%2FDong_Ying.pdf&usg=AFQjCNE9o2BcEkqdnu_-lQ3EFD3eRAFWiw&sig2=oiU8TCEH57EYF9v9l6Scrw&bvm=bv.121070826,d.dGo)

1.  [搜索结果相关性获胜者采访：第一名，陈成龙](https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md)

1.  [(中文) 保诚人寿保险评估解决方案 - Nutastray](http://rstudio-pubs-static.s3.amazonaws.com/158725_5d2f977f4004490e9b095c0ef9357c6b.html)

![张灵昊](../Images/47effce75b02d75ca99360d2793970ea.png)**简介：[张灵昊](https://www.linkedin.com/in/linghaozh)** 是复旦大学计算机科学专业的高年级学生，同时也是 Strikingly 的数据挖掘工程师。他的兴趣包括机器学习、数据挖掘、自然语言处理、知识图谱和大数据分析。

[原文](https://dnc1994.com/2016/05/rank-10-percent-in-first-kaggle-competition-en/)。已获许可转载。

**相关内容：**

+   [接近（几乎）任何机器学习问题](/2016/08/approaching-almost-any-machine-learning-problem.html)

+   [自动化数据科学与机器学习：Auto-sklearn 团队的访谈](/2016/10/interview-auto-sklearn-automated-data-science-machine-learning-team.html)

+   [数据科学基础：集成学习者简介](/2016/11/data-science-basics-intro-ensemble-learners.html)

### 更多相关话题

+   [LinkedIn 如何使用机器学习来排序你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)

+   [如何在没有任何工作经验的情况下找到数据科学的第一份工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [它活过来了！用 Python 和一些便宜的组件构建你的第一个机器人](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)

+   [从零到英雄：使用 PyTorch 创建你的第一个 ML 模型](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)

+   [部署你的第一个机器学习模型](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)
