- en: Risk Management Framework for AI/ML Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI/ML 模型的风险管理框架
- en: 原文：[https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html](https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html](https://www.kdnuggets.com/2022/03/risk-management-framework-aiml-models.html)
- en: '![Risk Management Framework for AI/ML Models](../Images/7bd3035887aff786c512488ea06ba5fc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML 模型的风险管理框架](../Images/7bd3035887aff786c512488ea06ba5fc.png)'
- en: 'Source: Business vector created by jcomp — [www.freepik.com](https://www.freepik.com)
    (illustrating the make or break concept of managing AI Risk and producing successful
    AI models)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：商业矢量图由 jcomp 创作 — [www.freepik.com](https://www.freepik.com)（展示管理 AI 风险和生产成功
    AI 模型的关键概念）
- en: 'AI/ML models like any other mathematical and financial models come with their
    set of risks and require awareness to mitigate them beforehand. The intent of
    this article is very well summarised in the [definition of risk](https://en.wikipedia.org/wiki/Risk):'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: AI/ML 模型像其他数学和金融模型一样，具有其自身的风险，并需要事先了解以减轻这些风险。本文的意图在[风险定义](https://en.wikipedia.org/wiki/Risk)中得到了很好的总结：
- en: Risk is the possibility of something bad happening. Risk involves uncertainty
    about the effects/implications of activity with respect to something that humans
    value (such as health, well-being, wealth, property, or the environment), often
    focusing on negative, undesirable consequences.
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 风险是指可能发生不利情况的可能性。风险涉及对活动效果/影响的不确定性，这些活动涉及人类重视的东西（例如健康、福祉、财富、财产或环境），通常关注负面、不期望的后果。
- en: Risk needs to be accounted for well in advance, right at the design stage. One
    can not wait for the consequences to show up, in order to do the damage control.
    That is where “Risk Management” helps by designing a forward-looking approach,
    pulling levers to assess the worst-case scenario, and timely acting upon it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 风险需要提前充分考虑，从设计阶段开始。不能等到后果显现后再进行损害控制。这就是“风险管理”通过设计前瞻性的方法、拉动杠杆评估最坏情况，并及时采取行动的帮助所在。
- en: '![Risk Management Framework for AI/ML Models](../Images/960f56f00412ad589eef949fec84836f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML 模型的风险管理框架](../Images/960f56f00412ad589eef949fec84836f.png)'
- en: 'Source: Author'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者
- en: Key measures to manage risks include identifying the sources of risk and checking
    how they are handled in current processes. This analysis surfaces the gap where
    current checks may prove insufficient to the unforeseen risks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 管理风险的关键措施包括识别风险来源，并检查它们在当前流程中的处理方式。这种分析可以揭示当前检查可能不足以应对不可预见的风险的差距。
- en: The framework by principle involves brainstorming on what can possibly go wrong — one
    can not wait for a self-driving car to get stuck in the dilemma of whether to
    save an old man vs a child when on road. There is no one ideal answer to this
    problem but the worst-case scenario has to be thought through and should be acceptable
    before implementing the solution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从原则上讲，这一框架涉及对可能出错的情况进行头脑风暴——不能等到自动驾驶汽车在路上陷入是否拯救一个老人还是一个孩子的困境时才采取行动。对于这个问题没有一个理想的答案，但必须在实施解决方案之前考虑最坏情况，并且这个最坏情况必须是可以接受的。
- en: Risks by nature are not self-contained and have cascading effects by amplifying
    the nuisance all across. Clear metrics of how to define and measure risks are
    crucial to assure how risk is capped within acceptable limits. The metrics also
    prove the effectiveness of risk mitigation measures through pre and post-analysis.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 风险本质上是非自包含的，会通过放大所有方面的麻烦而产生连锁反应。清晰的风险定义和测量指标对确保风险被控制在可接受的范围内至关重要。这些指标还通过前后分析证明了风险缓解措施的有效性。
- en: 'The risks associated with AI are relatively unknown to measure, plan and capture
    in advance due to its recent technological advancements as against other mature
    industries like finance and medicine. There are a few lessons that can be directly
    learned and imported into the AI risk management tool:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于技术的迅猛发展，相对于金融和医学等成熟行业，AI 相关的风险在衡量、规划和预先捕捉方面仍相对未知。可以直接学习并导入到 AI 风险管理工具中的几个教训包括：
- en: Documentation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档
- en: Data Integrity
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据完整性
- en: Regulations and Compliance
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法规与合规性
- en: Explainability
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可解释性
- en: '**Documentation**'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**文档**'
- en: ML models may end up solving a revised problem than the one originally conceived.
    The project starts with a certain expectation (read magic) from the ML model.
    However, the model’s performance gets restricted due to the lack of relevant attributes
    or good quality data providing statistical signals for model learning. A number
    of experiments are performed to calibrate the features, algorithms, data, or even
    the problem statement itself to assess how the model can best suit the exact or
    tweaked business task and yet add value.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ML 模型可能最终解决的问题与最初设想的可能有所不同。项目开始时对 ML 模型有一定的期望（可理解为魔法）。然而，由于缺乏相关特征或高质量数据提供的统计信号用于模型学习，模型的性能受到限制。进行了一系列实验来校准特征、算法、数据，甚至是问题陈述本身，以评估模型如何最佳地适应确切或调整后的业务任务，并且仍能增加价值。
- en: For example, if the business requirement is to optimize resource allocation
    in a service center to attend to the bulk queries and calls received throughout
    the day. The problem can be framed as a multi-class classification where the target
    variable i.e. the expected number of calls can be divided into 3 categories — low,
    medium, and high. This implies that businesses will estimate resources as per
    the ML model’s prediction of the low, medium, or high workload (or the number
    of expected calls).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果业务需求是优化服务中心的资源分配，以处理全天接收到的大量查询和电话。可以将问题框定为多类分类，其中目标变量，即预期的电话数量，可以分为 3 类——低、中和高。这意味着企业将根据
    ML 模型对低、中或高工作量（或预期电话数量）的预测来估算资源。
- en: On the other hand, the business could be more interested in knowing the expected
    workload over the next week from the ML model and would apply its own post-processing
    logic to decide how the resources should be allocated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，企业可能更感兴趣的是从 ML 模型中获取未来一周的预期工作量，并将应用自己的后处理逻辑来决定资源应该如何分配。
- en: We have discussed two ways of framing a problem statement — regression and classification.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了两种问题陈述的框架——回归和分类。
- en: While there is no one rule that fits all — it needs to be discussed with the
    business and well-documented. The assumptions, data availability, the history
    of the data, any attributes that are only available in real-time and are not shown
    to model during the learning phase need to be captured in great detail and signed-off
    with the client before diving deep into the data modeling.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有一种规则适用于所有情况——这需要与业务讨论并进行详细文档记录。假设、数据可用性、数据历史记录、任何仅在实时中可用且在学习阶段未显示给模型的属性都需要详细记录，并与客户签署确认，然后再深入数据建模。
- en: '**Data Integrity**'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据完整性**'
- en: Covid has drastically changed the dynamics of how the world runs and rendered
    a lot of ML models becoming irrelevant. No model/AI solution provider would have
    been able to foresee it considering the black swan effect of this pandemic. But,
    there are other innumerable ways the model output can deviate from the expected
    outcome, one of the key reasons being the drift between the training data and
    inference data characteristics. Now, this is in developers' hands and can be controlled
    using various statistical methods. One such metric is the [KS statistic](https://www.statisticshowto.com/kolmogorov-smirnov-test/).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Covid 已经极大地改变了世界运作的动态，使得许多 ML 模型变得无关紧要。没有任何模型/AI 解决方案提供商能够预见到这一点，考虑到这次疫情的黑天鹅效应。但，模型输出偏离预期结果的方式还有无数种，其中一个主要原因是训练数据与推理数据特征之间的漂移。现在，这在开发者的掌控之中，可以使用各种统计方法来控制。其中一个指标是
    [KS 统计量](https://www.statisticshowto.com/kolmogorov-smirnov-test/)。
- en: If you want to learn more about how to maintain data quality to build successful
    machine learning solutions, I would recommend a prior read of this [article](/2022/03/significance-data-quality-making-successful-machine-learning-model.html).
    It explains how seamless data integration and consistency is crucial to maintaining
    data pipelines and underlines the importance of adopting data culture.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于如何维护数据质量以构建成功的机器学习解决方案的信息，我推荐你事先阅读这篇 [文章](/2022/03/significance-data-quality-making-successful-machine-learning-model.html)。文章解释了无缝数据集成和一致性对维护数据管道的重要性，并强调了采纳数据文化的重要性。
- en: '**Reputational, Regulation, and Compliance Risks**'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**声誉、法规和合规风险**'
- en: Can artificially intelligent robots gain sentience and harm human safety by
    taking over the world? Such questions predominantly occupy our thoughts and immediately
    make AI the villain of the wave of digital transformation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能机器人能否获得意识并通过接管世界来危害人类安全？这样的问题主要占据我们的思考，并立即将AI变成数字化转型潮流中的反派。
- en: But AI is just a technology that can not do harm on its own unless it is designed
    and constructed to do so. This leads to an important and often ignored concept—
    intent.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但AI只是一个技术本身不能造成伤害，除非它被设计和构建成这样。这引出了一个重要且常被忽视的概念——意图。
- en: '[Echoing Dave Waters](https://www.supplychaintoday.com/artificial-intelligence-machine-learning-quotes-top-minds/),
    “The potential benefits of artificial intelligence are huge, so are the dangers.”'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[引用Dave Waters](https://www.supplychaintoday.com/artificial-intelligence-machine-learning-quotes-top-minds/)的话，“人工智能的潜在好处巨大，危险也是如此。”'
- en: '![Risk Management Framework for AI/ML Models](../Images/077af6302e53bfcfb7f19f8944495d64.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML模型风险管理框架](../Images/077af6302e53bfcfb7f19f8944495d64.png)'
- en: 'Source: People vector created by pch.vector — [www.freepik.com](https://www.freepik.com),
    with inputs from Author on good and bad intent with examples'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：人物矢量图由pch.vector创作 — [www.freepik.com](https://www.freepik.com)，并结合作者对良好和恶意意图的例子进行输入
- en: AI has huge untapped potential to improve human lives but comes with its own
    risks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: AI有巨大的潜力来改善人类生活，但也带来了自身的风险。
- en: The moment risks enter the scene, follows the regulations. Yes, regulations
    are needed to put checks and balances in place and to make sure that they provide
    the right framework that does not deter the flight of AI benefits but controls
    the possible harms.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦风险出现，就需要遵循法规。是的，法规是必要的，以建立检查和平衡机制，并确保它们提供正确的框架，不妨碍AI利益的飞跃，同时控制可能的危害。
- en: Societal and human-friendly applications that do not compromise or misuse personal
    data and respect user privacy can only succeed and make their way to market. Regulations
    like GDPR aim at giving control and rights to individuals over how they allow
    their personal data to be used.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不妥协或滥用个人数据且尊重用户隐私的社会友好型应用才能成功并进入市场。像GDPR这样的法规旨在赋予个人控制权和权利，以决定他们允许如何使用个人数据。
- en: Timely intervention and updates of such regulation frameworks ensure that our
    society can continue to reap the benefits of good intent of AI while deterring
    the mal-intended AI products to hit the ground.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 及时干预和更新这些监管框架可以确保我们的社会继续享受AI良好意图带来的好处，同时阻止恶意AI产品的出现。
- en: '**Explainability**'
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**可解释性**'
- en: Can the AI model explain the predictions. It is imperative for the model developer
    to explain the internal working of the algorithm without trading off with the
    model accuracy. There are two ways it can be achieved — interpretable models or
    auxiliary tools.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型能否解释预测结果。模型开发者必须在不影响模型准确性的情况下解释算法的内部工作原理。这可以通过两种方式实现——可解释模型或辅助工具。
- en: '![Risk Management Framework for AI/ML Models](../Images/0c891159999ab0413218577fddfa7734.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML模型风险管理框架](../Images/0c891159999ab0413218577fddfa7734.png)'
- en: 'Source: Education vector created by freepik — [www.freepik.com](https://www.freepik.com)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：教育矢量图由freepik创作 — [www.freepik.com](https://www.freepik.com)
- en: The words interpretability and explainability are often used interchangeably.
    Models like decision trees, linear regression come under the umbrella of interpretable
    models due to their inherent nature of interpreting the predictions. While black-box
    models like deep neural networks need the help of auxiliary tools and techniques
    like LIME and SHAP framework to explain the model output.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: “可解释性”和“解释性”这两个词常被交替使用。决策树、线性回归等模型由于其固有的预测解释特性，属于可解释模型的范畴。而像深度神经网络这样的黑箱模型则需要借助LIME和SHAP框架等辅助工具和技术来解释模型输出。
- en: The illustration shown below captures the true state the data science community
    should strive to achieve where we are able to explain why a model outputs a particular
    class X and not class Y. When does the model succeed and can be trusted with a
    greater degree of confidence? What changes in the input data would have led to
    the flip in predictions etc.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了数据科学社区应努力实现的真实状态，我们能够解释为什么模型输出特定类别X而不是类别Y。模型何时成功并可以以更大的信心信任？输入数据中的哪些变化会导致预测结果的翻转等。
- en: '![Risk Management Framework for AI/ML Models](../Images/0bc4baa19aa3551af1012306a34a6147.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML模型风险管理框架](../Images/0bc4baa19aa3551af1012306a34a6147.png)'
- en: 'Source: https://[www.darpa.mil](https://www.darpa.mil/)/program/explainable-artificial-intelligence'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：https://[www.darpa.mil](https://www.darpa.mil/)/program/explainable-artificial-intelligence
- en: There are various tools that help keep the risk in check, including but not
    limited to model interpretability, bias detection, and mitigation, model monitoring,
    and maintenance.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种工具可以帮助控制风险，包括但不限于模型可解释性、偏差检测和缓解、模型监控和维护。
- en: I will elaborate more on each of these in my upcoming articles. So stay tuned.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在即将发表的文章中详细阐述这些内容。敬请关注。
- en: '**[Vidhi Chugh](https://vidhi-chugh.medium.com/)** is an award-winning AI/ML
    innovation leader and an AI Ethicist. She works at the intersection of data science,
    product, and research to deliver business value and insights. She is an advocate
    for data-centric science and a leading expert in data governance with a vision
    to build trustworthy AI solutions.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Vidhi Chugh](https://vidhi-chugh.medium.com/)** 是一位获奖的AI/ML创新领导者和AI伦理学家。她在数据科学、产品和研究的交汇点工作，以提供业务价值和见解。她提倡数据中心科学，并在数据治理方面是领先专家，致力于构建值得信赖的AI解决方案。'
- en: '* * *'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT工作'
- en: '* * *'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Introduction to Giskard: Open-Source Quality Management for AI Models](https://www.kdnuggets.com/2023/11/giskard-introduction-giskard-opensource-quality-management-ai-models)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Giskard简介：AI模型的开源质量管理](https://www.kdnuggets.com/2023/11/giskard-introduction-giskard-opensource-quality-management-ai-models)'
- en: '[Social User Authentication in Django Framework](https://www.kdnuggets.com/2023/01/social-user-authentication-django-framework.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Django框架中的社交用户认证](https://www.kdnuggets.com/2023/01/social-user-authentication-django-framework.html)'
- en: '[The Only Prompting Framework for Every Use](https://www.kdnuggets.com/the-only-prompting-framework-for-every-use)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[适用于所有用途的唯一提示框架](https://www.kdnuggets.com/the-only-prompting-framework-for-every-use)'
- en: '[Free 4 Week Data Science Course on AI Quality Management](https://www.kdnuggets.com/2022/02/truera-free-4-week-data-science-course-ai-quality-management.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费的4周AI质量管理数据科学课程](https://www.kdnuggets.com/2022/02/truera-free-4-week-data-science-course-ai-quality-management.html)'
- en: '[KDnuggets News, May 18: 5 Free Hosting Platform For Machine…](https://www.kdnuggets.com/2022/n20.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，5月18日：5个免费机器学习托管平台…](https://www.kdnuggets.com/2022/n20.html)'
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于数据管理及其重要性的6件事…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
