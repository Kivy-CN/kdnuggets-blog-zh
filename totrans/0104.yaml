- en: 'This Week in AI, August 18: OpenAI in Financial Trouble • Stability AI Announces
    StableCode'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html](https://www.kdnuggets.com/2023/08/this-week-ai-2023-08-18.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![### ALT ###](../Images/ed6e88542b41e9889a22780056e09561.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by Editor with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to this week's edition of "This Week in AI" on KDnuggets. This curated
    weekly post aims to keep you abreast of the most compelling developments in the
    rapidly advancing world of artificial intelligence. From groundbreaking headlines
    that shape our understanding of AI's role in society to thought-provoking articles,
    insightful learning resources, and spotlighted research pushing the boundaries
    of our knowledge, this post provides a comprehensive overview of AI's current
    landscape. This weekly update is designed to keep you updated and informed in
    this ever-evolving field. Stay tuned and happy reading!
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Headlines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The "Headlines" section discusses the top news and developments from the past
    week in the field of artificial intelligence. The information ranges from governmental
    AI policies to technological advancements and corporate innovations in AI.
  prefs: []
  type: TYPE_NORMAL
- en: '???? **[ChatGPT In Trouble: OpenAI may go bankrupt by 2024, AI bot costs company
    $700,000 every day](https://www.firstpost.com/tech/news-analysis/openai-may-go-bankrupt-by-2024-chatgpt-costs-company-700000-dollars-every-day-12986012.html)**'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI is facing financial trouble due to the high costs of running ChatGPT
    and other AI services. Despite rapid early growth, ChatGPT's user base has declined
    in recent months. OpenAI is struggling to effectively monetize its technology
    and generate sustainable revenue. Meanwhile, it continues to burn through cash
    at an alarming rate. With competition heating up and enterprise GPU shortages
    hindering model development, OpenAI needs to urgently find pathways to profitability.
    If it fails to do so, bankruptcy may be on the horizon for the pioneering AI startup.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Stability AI Announces StableCode, An AI Coding Assistant for Developers](https://www.maginative.com/article/stability-ai-announces-stablecode-an-ai-coding-assistant-for-developers/)**
  prefs: []
  type: TYPE_NORMAL
- en: Stability AI has released StableCode, its first generative AI product optimized
    for software development. StableCode incorporates multiple models trained on over
    500 billion tokens of code to provide intelligent autocompletion, respond to natural
    language instructions, and manage long spans of code. While conversational AI
    can already write code, StableCode is purpose-built to boost programmer productivity
    by understanding code structure and dependencies. With its specialized training
    and models that can handle long contexts, StableCode aims to enhance developer
    workflows and lower the barrier to entry for aspiring coders. The launch represents
    Stability AI's foray into AI-assisted coding tools amidst growing competition
    in the space.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Introducing Superalignment by OpenAI](https://www.kdnuggets.com/2023/08/introducing-superalignment-openai.html)**
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI is proactively working to address potential risks from superintelligent
    AI through their new Superalignment team, which is using techniques like reinforcement
    learning from human feedback to align AI systems. Key goals are developing scalable
    training methods leveraging other AI systems, validating model robustness, and
    stress testing the full alignment pipeline even with intentionally misaligned
    models. Overall, OpenAI aims to show machine learning can be conducted safely
    by pioneering approaches to responsibly steer superintelligence.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Learn as you search (and browse) using generative AI](https://blog.google/products/search/google-search-generative-ai-learning-features/)**
  prefs: []
  type: TYPE_NORMAL
- en: Google is announcing several updates to its Search Engine Generation (SGE) AI
    capabilities including hover definitions for science/history topics, color-coded
    syntax highlighting for code overviews, and an early experiment called "SGE while
    browsing" that summarizes key points and helps users explore pages when reading
    long-form content on the web. These aim to enhance understanding of complex topics,
    improve digestion of coding information, and aid navigation and learning as users
    browse. The updates represent Google's continued efforts to evolve its AI search
    experience based on user feedback, with a focus on comprehension and extracting
    key details from complex web content.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Together.ai extend Llama2 to a 32k context window](https://huggingface.co/togethercomputer/LLaMA-2-7B-32K)**
  prefs: []
  type: TYPE_NORMAL
- en: LLaMA-2-7B-32K is an open-source, long context language model developed by Together
    Computer that extends the context length of Meta's LLaMA-2 to 32K tokens. It leverages
    optimizations like FlashAttention-2 to enable more efficient inference and training.
    The model was pre-trained using a mixture of data including books, papers, and
    instructional data. Examples are provided for fine-tuning on long-form QA and
    summarization tasks. Users can access the model via Hugging Face or use the OpenChatKit
    for customized fine-tuning. Like all language models, LLaMA-2-7B-32K can generate
    biased or incorrect content, requiring caution in use.
  prefs: []
  type: TYPE_NORMAL
- en: Articles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The "Articles" section presents an array of thought-provoking pieces on artificial
    intelligence. Each article dives deep into a specific topic, offering readers
    insights into various aspects of AI, including new techniques, revolutionary approaches,
    and ground-breaking tools.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[LangChain Cheat Sheet](https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html)**
  prefs: []
  type: TYPE_NORMAL
- en: With LangChain, developers can build capable AI language-based apps without
    reinventing the wheel. Its composable structure makes it easy to mix and match
    components like LLMs, prompt templates, external tools, and memory. This accelerates
    prototyping and allows seamless integration of new capabilities over time. Whether
    you're looking to create a chatbot, QA bot, or multi-step reasoning agent, LangChain
    provides the building blocks to assemble advanced AI rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[How to Use ChatGPT to Convert Text into a PowerPoint Presentation](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)**
  prefs: []
  type: TYPE_NORMAL
- en: The article outlines a two-step process for using ChatGPT to convert text into
    a PowerPoint presentation, first summarizing the text into slide titles and content,
    then generating Python code to convert the summary to PPTX format using the python-pptx
    library. This allows rapid creation of engaging presentations from lengthy text
    documents, overcoming tedious manual efforts. Clear instruction is provided on
    crafting the ChatGPT prompts and running the code, offering an efficient automated
    solution for presentation needs.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Open challenges in LLM research](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html)**
  prefs: []
  type: TYPE_NORMAL
- en: 'The article provides an overview of 10 key research directions to improve large
    language models: reducing hallucination, optimizing context length/construction,
    incorporating multimodal data, accelerating models, designing new architectures,
    developing GPU alternatives like photonic chips, building usable agents, improving
    learning from human feedback, enhancing chat interfaces, and expanding to non-English
    languages. It cites relevant papers across these areas, noting challenges like
    representing human preferences for reinforcement learning and building models
    for low-resource languages. The author concludes that while some issues like multilinguality
    are more tractable, others like architecture will require more breakthroughs.
    Overall, both technical and non-technical expertise across researchers, companies
    and the community will be critical to steer LLMs positively.'
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Why You (Probably) Don’t Need to Fine-tune an LLM](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/)**
  prefs: []
  type: TYPE_NORMAL
- en: 'The article provides an overview of 10 key research directions to improve large
    language models: reducing hallucination, optimizing context length/construction,
    incorporating multimodal data, accelerating models, designing new architectures,
    developing GPU alternatives like photonic chips, building usable agents, improving
    learning from human feedback, enhancing chat interfaces, and expanding to non-English
    languages. It cites relevant papers across these areas, noting challenges like
    representing human preferences for reinforcement learning and building models
    for low-resource languages. The author concludes that while some issues like multilinguality
    are more tractable, others like architecture will require more breakthroughs.
    Overall, both technical and non-technical expertise across researchers, companies
    and the community will be critical to steer LLMs positively.'
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[Best Practices to Use OpenAI GPT Model](https://www.kdnuggets.com/2023/08/best-practices-openai-gpt-model.html)**
  prefs: []
  type: TYPE_NORMAL
- en: The article outlines best practices for obtaining high-quality outputs when
    using OpenAI's GPT models, drawing on community experience. It recommends providing
    detailed prompts with specifics like length and persona; multi-step instructions;
    examples to mimic; references and citations; time for critical thinking; and code
    execution for precision. Following these tips on instructing the models, such
    as specifying steps and personas, can lead to more accurate, relevant, and customizable
    results. The guidance aims to help users structure prompts effectively to get
    the most out of OpenAI's powerful generative capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: ???? **[We're All Wrong About AI](https://arnoldkling.substack.com/p/were-all-wrong-about-ai)**
  prefs: []
  type: TYPE_NORMAL
- en: The author argues that current AI capabilities are underestimated, using examples
    like creativity, search, and personalization to counter common misconceptions.
    He states that AI can be creative by recombining concepts, not merely generating
    random ideas; it is not just a supercharged search engine like Google; and it
    can develop personalized relationships, not just generic skills. While unsure
    which applications will prove most useful, the author urges an open mind rather
    than dismissiveness, emphasizing that the best way to determine AI's potential
    is by continued hands-on exploration. He concludes that our imagination around
    AI is limited and its uses likely far exceed current predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The "Tools" section lists useful apps and scripts created by the community for
    those who want to get busy with practical AI applications. Here you will find
    a range of tool types, from large comprehensive code bases to small niche scripts.
    *Note that tools are shared without endorsement, and with no guarantee of any
    sort. Do your own homework on any software prior to installation and use!*
  prefs: []
  type: TYPE_NORMAL
- en: '????️ **[MetaGPT: The Multi-Agent Framework](https://github.com/geekan/MetaGPT)**'
  prefs: []
  type: TYPE_NORMAL
- en: MetaGPT takes a one line requirement as input and outputs user stories / competitive
    analysis / requirements / data structures / APIs / documents, etc. Internally,
    MetaGPT includes product managers / architects / project managers / engineers.
    It provides the entire process of a software company along with carefully orchestrated
    SOPs.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ????️ **[GPT LLM Trainer](https://github.com/mshumer/gpt-llm-trainer)**
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this project is to explore an experimental new pipeline to train
    a high-performing task-specific model. We try to abstract away all the complexity,
    so it's as easy as possible to go from idea -> performant fully-trained model.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simply input a description of your task, and the system will generate a dataset
    from scratch, parse it into the right format, and fine-tune a LLaMA 2 model for
    you.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ????️ **[DoctorGPT](https://github.com/llSourcell/DoctorGPT)**
  prefs: []
  type: TYPE_NORMAL
- en: DoctorGPT is a Large Language Model that can pass the US Medical Licensing Exam.
    This is an open-source project with a mission to provide everyone their own private
    doctor. DoctorGPT is a version of Meta's Llama2 7 billion parameter Large Language
    Model that was fine-tuned on a Medical Dialogue Dataset, then further improved
    using Reinforcement Learning & Constitutional AI. Since the model is only 3 Gigabytes
    in size, it fits on any local device, so there is no need to pay an API to use
    it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Unveiling StableCode: A New Horizon in AI-Assisted Coding](https://www.kdnuggets.com/2023/08/unveiling-stablecode-new-horizon-ai-assisted-coding)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[This Week in AI, August 7: Generative AI Comes to Jupyter & Stack…](https://www.kdnuggets.com/2023/mm/this-week-ai-2023-08-07.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Generative AI Playground: Text-to-Image Stable Diffusion with…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-text-to-image-stable-diffusion)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8 Ways to Improve Your Search Application this Week](https://www.kdnuggets.com/2022/09/corise-8-ways-improve-search-application-week.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Basics Week 1: Python Programming & Data Science Foundations](https://www.kdnuggets.com/back-to-basics-week-1-python-programming-data-science-foundations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Back to Basics Week 3: Introduction to Machine Learning](https://www.kdnuggets.com/back-to-basics-week-3-introduction-to-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
