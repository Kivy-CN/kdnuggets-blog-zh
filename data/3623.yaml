- en: Model Experiments, Tracking and Registration using MLflow on Databricks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 在 Databricks 上进行模型实验、跟踪和注册
- en: 原文：[https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html](https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html](https://www.kdnuggets.com/2021/01/model-experiments-tracking-registration-mlflow-databricks.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Dash Desai](https://www.linkedin.com/in/dash-desai/), Director of Platform
    and Technical Evangelism at StreamSets**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Dash Desai](https://www.linkedin.com/in/dash-desai/)，StreamSets 平台和技术推广总监**'
- en: Learn how StreamSets, [a modern data integration platform for DataOps](https://streamsets.com/),
    can help expedite operations at some of the most crucial stages of Machine Learning
    Lifecycle and MLOps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 了解 [StreamSets](https://streamsets.com/) 这一个现代数据集成平台如何帮助加快机器学习生命周期和 MLOps 一些关键阶段的操作。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速迈入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Data Acquisition And Preparation
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据获取和准备
- en: Machine learning models are only as good as the quality of data and the size
    of datasets used to train the models. [Data has shown](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#282426e76f63) that
    data scientists spend around 80% of their time on preparing and managing data
    for analysis and 57% of the data scientists regard cleaning and organizing data
    as the least enjoyable part of their work. This further validates the idea of 
    MLOps and the need for collaboration between data scientists and data engineers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的质量仅与用于训练模型的数据质量和数据集大小有关。[数据表明](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#282426e76f63)数据科学家约花费
    80% 的时间用于准备和管理分析数据，57% 的数据科学家认为清理和组织数据是工作中最不愉快的部分。这进一步验证了 MLOps 的理念以及数据科学家与数据工程师之间需要合作的必要性。
- en: During this crucial phase of data acquisition and preparation, data scientists
    identify what types of (trusted) datasets are needed to train models and work
    closely with data engineers to acquire data from viable data sources.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据获取和准备的关键阶段，数据科学家识别出需要哪些类型的（受信任的）数据集来训练模型，并与数据工程师密切合作，从可行的数据源中获取数据。
- en: How Can StreamSets Help
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StreamSets 如何提供帮助
- en: 'Some of the common data sources for acquiring datasets for data science projects
    include: Amazon S3, Microsoft Azure Blob Storage, Google Cloud Storage, Kafka,
    Hadoop, on-prem and cloud data warehouses. StreamSets DataOps Platform provides
    easy-to-use GUI for building smart data pipelines for streaming and batch dataflows
    for fast data ingestion of large amounts of data from distributed systems–including
    all of the common sources mentioned above.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的数据源用于获取数据科学项目的数据集，包括：Amazon S3、Microsoft Azure Blob 存储、Google Cloud 存储、Kafka、Hadoop、本地和云数据仓库。StreamSets
    DataOps 平台提供易于使用的图形界面，用于构建智能数据管道，支持流数据和批处理数据流，从分布式系统中快速摄取大量数据——包括上述所有常见来源。
- en: Another aspect of the data ingestion process is the storage–in some cases, companies
    may already have a data lake or a data warehouse and in some cases they may need
    to build one. StreamSets DataOps Platform is capable of connecting to existing
    data lakes and data warehouses (on-prem or in the cloud) and also has built-in
    capabilities of creating new ones.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄取过程的另一个方面是存储——在某些情况下，公司可能已经拥有数据湖或数据仓库，而在某些情况下，他们可能需要建立一个。StreamSets DataOps
    平台能够连接到现有的数据湖和数据仓库（无论是本地的还是云端的），还具有创建新数据湖和数据仓库的内置功能。
- en: '![Modern Data Integration for DataOps](../Images/12bff326545c71bc6f41afffdea07c7f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![现代数据集成用于 DataOps](../Images/12bff326545c71bc6f41afffdea07c7f.png)'
- en: 'As part of building these data pipelines, data engineers can also perform some
    of the key transformations needed by data scientists. Some of the common transformations
    required during data preparation include: data type conversion for fields/columns/features,
    renaming fields/columns/features, joining datasets, merging datasets, repartitioning,
    dataset data format conversion (for example, JSON to Parquet for efficient downstream
    analysis in Apache Spark), etc. All of these transformations and many more are
    readily supported by StreamSets DataOps Platform.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建这些数据管道的过程中，数据工程师还可以执行数据科学家所需的一些关键转换。数据准备过程中一些常见的转换包括：字段/列/特征的数据类型转换、重命名字段/列/特征、连接数据集、合并数据集、重新分区、数据集数据格式转换（例如，将JSON转换为Parquet，以便在Apache
    Spark中进行高效的下游分析）等。所有这些转换及更多转换均由StreamSets DataOps平台提供支持。
- en: '*Imp Note: Extensive and thorough feature engineering tasks and in depth analysis
    of features, their correlation with the target variable, feature importances,
    etc. is best suited for and better performed on interactive tools, such as, Databricks
    Notebook, Jupyter, RStudio, and ML platforms.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*重要说明：广泛而彻底的特征工程任务及对特征、其与目标变量的相关性、特征重要性等的深入分析，最适合使用交互式工具进行，如Databricks Notebook、Jupyter、RStudio和ML平台。*'
- en: Model Experiments, Tracking, And Registration
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型实验、跟踪和注册
- en: Experimentation is a big precursor to model development where data scientists
    take sufficient subsets of trusted datasets and create several models in a rapid,
    iterative manner.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 实验是模型开发的重要前置步骤，其中数据科学家会从可信数据集中取出足够的子集，并以快速、迭代的方式创建多个模型。
- en: Without proper industry standards, data scientists have to rely on manual tracking
    of models, inputs, hyperparameters, outputs and any other such artifacts throughout
    the model experimentation and development process. This results in very long model
    deployment/release cycles, which effectively prevents organizations from adapting
    to dynamic changes, gaining competitive advantage, and in some cases staying in
    compliance with changing governance and regulations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有适当行业标准的情况下，数据科学家不得不依靠手动跟踪模型、输入、超参数、输出及其他类似工件，这导致模型部署/发布周期非常长，实际上阻碍了组织适应动态变化、获得竞争优势，并在某些情况下无法遵守不断变化的治理和法规。
- en: How Can StreamSets Help
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StreamSets如何提供帮助
- en: Using StreamSets Transformer, [a Spark ETL engine](https://streamsets.com/products/dataops-platform/transformer-etl/),
    it’s easy to integrate with [MLflow](https://mlflow.org/) using its PySpark or
    Scala APIs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用StreamSets Transformer，[一个Spark ETL引擎](https://streamsets.com/products/dataops-platform/transformer-etl/)，很容易通过其PySpark或Scala
    API与[MLflow](https://mlflow.org/)集成。
- en: This MLflow integration allows for tracking and versioning of model training
    code, data, config, hyperparameters as well as register and manage models in a
    central repository in MLflow from Transformer. This is critical for retraining
    models and/or for reproducing experiments.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种MLflow集成允许跟踪和版本化模型训练代码、数据、配置、超参数，并且可以从Transformer在MLflow的中央存储库中注册和管理模型。这对于重新训练模型和/或重现实验至关重要。
- en: When using [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html),
    this creates a powerful and seamless solution because [Transformer can run on
    Databricks](https://streamsets.com/solutions/streamsets-for-databricks/) clusters
    and Databricks comes bundled with MLflow server.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用[MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html)时，它创建了一个强大而无缝的解决方案，因为[Transformer
    can run on Databricks](https://streamsets.com/solutions/streamsets-for-databricks/)集群，而Databricks自带MLflow服务器。
- en: End-to-end Use Case
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端用例
- en: Let’s walk through an end-to-end scenario where we’ll ingest data from a cloud
    object storage (for example, Amazon S3), perform necessary transformations, and
    train a regression model. The dataset consists of a set of houses with features
    like number of bedrooms, bathrooms, square footage, etc. and the price it was
    sold at.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个端到端的场景进行演练，我们将从云对象存储（例如，Amazon S3）中获取数据，执行必要的转换，并训练一个回归模型。数据集包含一组房屋，其特征包括卧室数量、浴室数量、平方英尺等，以及其出售价格。
- en: Apart from tracking, versioning, and registering models in MLflow with every
    run we’d also like the pipeline to automatically promote models from “*staging*”
    to “*production*” provided they meet a certain set of conditions. For example,
    if *r2 >= ${r2Threshold} or rmse <= ${rmseThreshold},* then the model needs to
    be promoted to “Production” on MLflow server on Databricks. This can be one of
    the requirements and part of the specification given by the data scientists to
    the data engineering team responsible for deploying the models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了跟踪、版本控制和在 MLflow 中注册模型之外，我们还希望管道在满足特定条件时自动将模型从“*staging*”提升到“*production*”。例如，如果*r2
    >= ${r2Threshold} 或 rmse <= ${rmseThreshold},* 则该模型需要在 Databricks 上的 MLflow 服务器上提升到“生产”状态。这可以作为数据科学家向负责部署模型的数据工程团队提供的要求和规范的一部分。
- en: Pipeline Overview
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道概述
- en: The StreamSets Transformer pipeline shown below is designed to load training
    data from [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Origins/AmazonS3.html#concept_gww_1kw_shb),
    perform transformations like [remove](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/FieldRemover.html#concept_svw_dxf_fhb) row
    id, rename target column “*mdev*” to “*label*” (which is required by SparkMLlib),
    train **Gradient Boosted Regression** model using [PySpark](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) processor
    and archive the training data in [Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Destinations/AmazonS3-D.html#concept_ymh_534_d3b).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面展示的 StreamSets Transformer 管道旨在从[Amazon S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Origins/AmazonS3.html#concept_gww_1kw_shb)加载训练数据，执行像[删除](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/FieldRemover.html#concept_svw_dxf_fhb)行
    ID、将目标列“*mdev*”重命名为“*label*”（这是 SparkMLlib 所需的），使用[PySpark](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb)处理器训练**梯度提升回归**模型，并将训练数据存档到[Amazon
    S3](https://streamsets.com/documentation/transformer/latest/help/transformer/Destinations/AmazonS3-D.html#concept_ymh_534_d3b)中。
- en: More importantly, the pipeline also integrates with [MLflow on Databricks](https://docs.databricks.com/applications/mlflow/index.html) to
    track and version model training code including hyperparameters, model evaluation
    metrics, and register models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，管道还与[Databricks 上的 MLflow](https://docs.databricks.com/applications/mlflow/index.html)集成，以跟踪和版本化模型训练代码，包括超参数、模型评估指标，并注册模型。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/b18bd6ccd1ef4da94c8ad40ce57f779c.png)**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/b18bd6ccd1ef4da94c8ad40ce57f779c.png)**'
- en: '**Model Training And Experimentation**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型训练与实验**'
- en: Here’s the code snippet of interest in [PySpark Processor](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb) —
    this is part of the pipeline that trains the Gradient Boosted Regression model
    and tracks everything in MLflow including promoting models from “*staging*” to
    “*production*” based on certain conditions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是[PySpark 处理器](https://streamsets.com/documentation/transformer/latest/help/transformer/Processors/PySpark.html#concept_gqm_4hn_ygb)的代码片段——这是管道的一部分，它训练梯度提升回归模型，并在
    MLflow 中跟踪一切，包括根据某些条件将模型从“*staging*”提升到“*production*”。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Show All ▼
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 显示全部 ▼
- en: '**Model Tracking in MLflow On Databricks**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**Databricks 上的模型跟踪**'
- en: Here are the model training runs from the Transformer pipeline tracked in MLflow.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 MLflow 中跟踪的来自 Transformer 管道的模型训练运行。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/621550444f5f5e9f78ea27f94aeda536.png)**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/621550444f5f5e9f78ea27f94aeda536.png)**'
- en: '**Model Versioning in MLflow On Databricks**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Databricks 上的模型版本控制**'
- en: Here are the model versions registered from the Transformer pipeline.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是从 Transformer 管道注册的模型版本。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/71af7b1d9949d7e5d7bde0d90f25de9f.png)**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/71af7b1d9949d7e5d7bde0d90f25de9f.png)**'
- en: '**Model Comparison in MLflow On Databricks**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**Databricks 上的模型比较**'
- en: Here’s a side-by-side comparison of two selected models created from the Transformer
    pipeline.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从 Transformer 管道创建的两个选定模型的并排比较。
- en: '**![Model Experiments, Tracking and Registration using MLflow on StreamSets
    and Databricks](../Images/a9f6c3ab266eb42837024a2c6d8e62c6.png)**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/a9f6c3ab266eb42837024a2c6d8e62c6.png)**'
- en: Model Retraining
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型重新训练
- en: Now, a very common requirement is to automate the process of retraining the
    model as and when more data becomes available–especially if the model hasn’t yet
    met the evaluation criteria. For example, accuracy can be one of the metrics on
    how a particular model is evaluated. This type of automation can be implemented
    by setting up an [orchestrator pipeline](https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title) as
    shown below.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一个非常常见的需求是自动化重新训练模型的过程，当更多数据变得可用时——特别是当模型尚未满足评估标准时。例如，准确率可以是评估特定模型的指标之一。这种类型的自动化可以通过设置
    [编排管道](https://streamsets.com/documentation/datacollector/latest/help/datacollector/UserGuide/Orchestration_Pipelines/OrchestrationPipelines_Title.html#Orchestrators_Title)
    实现，如下所示。
- en: The orchestrator pipeline is designed to continuously run and “wait” for training
    dataset  files to be uploaded on Amazon S3\. As soon as a training dataset is
    uploaded, this pipeline triggers/starts the model (re)training job described earlier.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 编排管道被设计为持续运行并“等待”训练数据集文件上传到 Amazon S3。 一旦训练数据集上传，此管道会触发/启动前面描述的模型（重新）训练任务。
- en: '![Model Experiments, Tracking and Registration using MLflow on StreamSets and
    Databricks](../Images/303066fe0a00df998d4f07c69006e900.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![使用 MLflow 在 StreamSets 和 Databricks 上进行模型实验、跟踪和注册](../Images/303066fe0a00df998d4f07c69006e900.png)'
- en: Also note that there are two hyperparameters ***maxIter*** and ***numberOfCVFolds*** passed
    in the pipeline so there’s no need to hard code them, and can be dynamically passed
    into the pipeline during model retraining and experimentation. The StreamSets
    DataOps Platform also provides ways to check the status of jobs that are currently
    running so that actions can be taken based on the status as shown above in the
    pipeline.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 还需注意，管道中传递了两个超参数 ***maxIter*** 和 ***numberOfCVFolds***，因此无需硬编码它们，并且可以在模型重新训练和实验过程中动态传递到管道中。
    StreamSets DataOps 平台还提供检查当前运行的作业状态的方法，以便根据管道中所示的状态采取行动。
- en: Sample Pipelines
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例管道
- en: 'If you’re interested in additional technical details and sample pipelines,
    please reach out to me: dash at streamsets dot com or [@iamontheinet](https://twitter.com/iamontheinet).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对额外的技术细节和示例管道感兴趣，请联系我：dash at streamsets dot com 或 [@iamontheinet](https://twitter.com/iamontheinet)。
- en: Get Started With Your Own Model Experiments
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始你自己的模型实验
- en: StreamSets DataOps Platform is not a machine learning platform, but it does
    provide important capabilities and extensibility that can help and expedite operations
    at some of the most crucial stages of the ML Lifecycle and MLOps.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: StreamSets DataOps 平台不是一个机器学习平台，但它提供了重要的功能和扩展性，能够帮助并加快机器学习生命周期和 MLOps 中一些最关键阶段的操作。
- en: Learn more about [StreamSets For Databricks](https://streamsets.com/products/cloud/streamsets-for-databricks-marketplace/) available
    on AWS Marketplace and Microsoft Azure Marketplace.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多关于 [StreamSets For Databricks](https://streamsets.com/products/cloud/streamsets-for-databricks-marketplace/)
    在 AWS Marketplace 和 Microsoft Azure Marketplace 上的信息。
- en: '**Bio: [Dash Desai](https://www.linkedin.com/in/dash-desai/)** is Director
    of Platform and Technical Evangelism at StreamSets, and has 18+ years of hands-on
    software and data engineering background. With recent experience in Big Data,
    Data Science, and Machine Learning, Dash applies his technical skills to help
    build solutions that solve business problems and surface trends that shape markets
    in new ways. Dash has worked for global enterprises and tech startups in agile
    environments as an engineer and a solutions architect. As a Platform and Technical
    Evangelist, he is passionate about evaluating new ideas to help articulate how
    technology can address a given business problem. He also enjoys writing technical
    blog posts, hands-on tutorials, and conducting technical workshops.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介： [Dash Desai](https://www.linkedin.com/in/dash-desai/)** 是 StreamSets
    的平台和技术布道总监，拥有超过 18 年的软件和数据工程实践经验。凭借在大数据、数据科学和机器学习方面的最新经验，Dash 运用他的技术技能帮助构建解决方案，解决商业问题，并揭示以新方式塑造市场的趋势。Dash
    曾在全球企业和技术初创公司担任工程师和解决方案架构师。作为平台和技术布道者，他对评估新想法充满热情，以帮助阐明技术如何解决特定的商业问题。他还喜欢撰写技术博客、动手教程和主持技术研讨会。'
- en: '[Original](https://streamsets.com/blog/model-experiments-tracking-and-registration-using-mlflow-on-databricks/).
    Reposted with permission.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://streamsets.com/blog/model-experiments-tracking-and-registration-using-mlflow-on-databricks/)。经许可转载。'
- en: '**Related:**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[MLOps Is Changing How Machine Learning Models Are Developed](/2020/12/mlops-changing-machine-learning-developed.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps正在改变机器学习模型的开发方式](/2020/12/mlops-changing-machine-learning-developed.html)'
- en: '[Production Machine Learning Monitoring: Outliers, Drift, Explainers & Statistical
    Performance](/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生产机器学习监控：异常值、漂移、解释器与统计性能](/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)'
- en: '[Managing Machine Learning Cycles: Five Learnings from comparing Data Science
    Experimentation/ Collaboration Tools](/2020/01/managing-machine-learning-cycles.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理机器学习周期：从比较数据科学实验/协作工具中获得的五个经验教训](/2020/01/managing-machine-learning-cycles.html)'
- en: More On This Topic
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Versioning Machine Learning Experiments vs Tracking Them](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习实验的版本控制与追踪](https://www.kdnuggets.com/2021/12/versioning-machine-learning-experiments-tracking.html)'
- en: '[How to Package and Distribute Machine Learning Models with MLFlow](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用MLFlow打包和分发机器学习模型](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
- en: '[Developing an Open Standard for Analytics Tracking](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[制定分析追踪的开放标准](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
- en: '[7 Best Tools for Machine Learning Experiment Tracking](https://www.kdnuggets.com/2023/02/7-best-tools-machine-learning-experiment-tracking.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习实验追踪的7款最佳工具](https://www.kdnuggets.com/2023/02/7-best-tools-machine-learning-experiment-tracking.html)'
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据分析：在Databricks中集成GitHub Copilot](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
- en: '[How to Design Experiments for Data Collection](https://www.kdnuggets.com/2022/04/design-experiments-data-collection.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何设计数据收集实验](https://www.kdnuggets.com/2022/04/design-experiments-data-collection.html)'
