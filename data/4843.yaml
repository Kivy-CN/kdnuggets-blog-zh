- en: Complete Guide to Build ConvNet HTTP-Based Application using TensorFlow and
    Flask RESTful Python API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 和 Flask RESTful Python API 构建 ConvNet HTTP 基于应用程序的完整指南
- en: 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)'
- en: This tutorial takes you along the steps required to create a convolutional neural
    network (CNN/ConvNet) using TensorFlow and get it into production by allowing
    remote access via a HTTP-based application using Flask RESTful API.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将带你完成创建卷积神经网络（CNN/ConvNet）的步骤，并通过允许使用基于 HTTP 的应用程序（使用 Flask RESTful API）进行远程访问将其投入生产。
- en: In this tutorial, a CNN is to be built using TensorFlow NN (tf.nn) module. The
    CNN model architecture is created and trained and tested against the CIFAR10 dataset.
    To make the model remotely accessible, a Flask Web application is created using
    Python to receive an uploaded image and return its classification label using
    HTTP. Anaconda3 is used in addition to TensorFlow on Windows with CPU support.
    This tutorial assumes you have a basic understanding of CNN such as layers, strides,
    and padding. Also knowledge about Python is required.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将使用 TensorFlow NN（tf.nn）模块构建一个 CNN。CNN 模型架构将被创建、训练并在 CIFAR10 数据集上进行测试。为了使模型能够远程访问，使用
    Python 创建了一个 Flask Web 应用程序，接收上传的图像并使用 HTTP 返回其分类标签。除了 TensorFlow 外，本教程还使用了 Anaconda3
    和 Windows 的 CPU 支持。本教程假设你对 CNN（如层、步幅和填充）有基本了解，也需要具备 Python 知识。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The tutorial is summarized into the following steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程总结为以下步骤：
- en: Preparing the Environment by Installing Python, TensorFlow, PyCharm, and Flask
    API.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过安装 Python、TensorFlow、PyCharm 和 Flask API 来准备环境。
- en: Downloading and Preparing the CIFAR-10 Dataset.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载和准备 CIFAR-10 数据集。
- en: Building the CNN Computational Graph using TensorFlow.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 构建 CNN 计算图。
- en: Training the CNN.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练 CNN。
- en: Saving the Trained CNN Model.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存训练好的 CNN 模型。
- en: Preparing the Test Data and Restoring the Trained CNN Model.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备测试数据并恢复训练好的CNN模型。
- en: Testing the Trained CNN Model.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试训练好的 CNN 模型。
- en: Building the Flask Web Application.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建 Flask Web 应用程序。
- en: Upload an Image using HTML Form.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 HTML 表单上传图像。
- en: Creating Helper HTML, JavaScript, and CSS Files.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建辅助 HTML、JavaScript 和 CSS 文件。
- en: HTTP-Based Remote Accessing the Trained Model for Prediction.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 HTTP 远程访问训练好的模型进行预测。
- en: 1\. Installing Python, TensorFlow, PyCharm, and Flask API
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 安装 Python、TensorFlow、PyCharm 和 Flask API
- en: Before starting building the project, it is required to prepare its environment.
    Python is the first tool to start installing because the environment is fully
    dependent on it. If you already have the environment prepared, you can skip the
    first step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始构建项目之前，需要准备环境。Python 是首先需要安装的工具，因为环境完全依赖于它。如果你已经准备好了环境，可以跳过第一步。
- en: '**1.1 Anaconda/Python Installation**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.1 Anaconda/Python 安装**'
- en: It is possible to install the native Python distribution but it is recommended
    to use an all-in-one package such as Anaconda because it does some stuff for you.
    In this project, Anaconda 3 is used. For Windows, the executable file can be downloaded
    from [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows).
    It could be installed easily.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可以安装原生 Python 发行版，但建议使用诸如 Anaconda 这样的全能包，因为它为你做了些事情。在这个项目中，使用的是 Anaconda 3。对于
    Windows，安装文件可以从 [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows)
    下载。它可以很容易地安装。
- en: To ensure Anaconda3 is installed properly, the CMD command (*where python*)
    could be issued as in figure 1\. If Anaconda3 is installed properly, its installation
    path will appear in the command output.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保 Anaconda3 正确安装，可以发出 CMD 命令 (*where python*)，如图 1 所示。如果 Anaconda3 安装正确，其安装路径将出现在命令输出中。
- en: '**Figure 1**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1**'
- en: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
- en: '**1.2 TensorFlow Installation**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.2 TensorFlow 安装**'
- en: After installation Python using Anaconda3, next is to install TensorFlow (TF).
    This tutorial uses TF on Windows with CPU support. The installation instructions
    are found in this page [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows).
    This YouTube video might be helpful ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Anaconda3 安装 Python 后，接下来是安装 TensorFlow (TF)。本教程使用支持 CPU 的 Windows 版本 TF。安装说明可以在此页面找到
    [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows)。这个
    YouTube 视频可能会有帮助 ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU))。
- en: 'TF installation steps are as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TF 的安装步骤如下：
- en: '1) Creating a conda environment for TF by invoking this command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 通过执行以下命令来创建 TF 的 conda 环境：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This creates an empty folder holding the virtual environment (venv) for TF installation.
    The venv is located under Anaconda3 installation directory in this location (\Anaconda3\envs\tensorflow).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个空文件夹，用于存放 TF 安装的虚拟环境（venv）。venv 位于 Anaconda3 安装目录下的此位置（\Anaconda3\envs\tensorflow）。
- en: '2) Activating the venv for TensorFlow installation using this command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 使用此命令激活 TensorFlow 安装的 venv：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The above command tells that we are inside the venv and any library installation
    will be inside it. The command prompt is expected to be changed after this command
    to be (tensorflow)C:>. After getting into the directory, we are ready to install
    the library.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令表示我们在 venv 内部，任何库的安装都将在其中进行。执行此命令后，命令提示符应更改为 (tensorflow)C:>。进入目录后，我们准备好安装库了。
- en: '3) After activating the venv, the CPU-only version of Windows TensorFlow could
    be installed by issuing this command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 激活 venv 后，可以通过发出以下命令安装 Windows TensorFlow 的 CPU-only 版本：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To test whether TF is installed properly, we can try to import it as in figure
    2\. But remember before importing TF, its venv must be activated. Testing it from
    the CMD, we need to issue the **python** command in order to be able to interact
    with Python. Because no error occurred in the import line, TF is successfully
    installed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试 TF 是否正确安装，我们可以尝试按图 2 导入它。但请记住，在导入 TF 之前，必须激活其 venv。在 CMD 中测试时，我们需要发出 **python**
    命令，以便与 Python 互动。由于导入行没有出现错误，因此 TF 已成功安装。
- en: '**Figure 2**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2**'
- en: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
- en: '**1.3 PyCharm Python IDE Installation**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.3 PyCharm Python IDE 安装**'
- en: For this project, it is recommended to use a Python IDE rather than entering
    commands in CMD. The IDE used in this tutorial is PyCharm. Its Windows executable
    file could be downloaded from this page [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows).
    Its installation instructions are pretty simple.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，推荐使用 Python IDE，而不是在 CMD 中输入命令。此教程使用的 IDE 是 PyCharm。其 Windows 可执行文件可以从此页面下载
    [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows)。其安装说明非常简单。
- en: After downloading and installation PyCharm Python IDE, next is to link it with
    TF. This is done by setting its Python interpreter to the installed Python under
    the TF venv as in figure 3\. This is done by opening the settings of the IDE and
    choosing the Project interpreter to the **python.exe** file installed inside the
    TF venv.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并安装 PyCharm Python IDE 后，下一步是将其与 TF 连接。这是通过将其 Python 解释器设置为 TF venv 下安装的 Python
    完成的，如图 3 所示。通过打开 IDE 的设置，将项目解释器选择为安装在 TF venv 内的 **python.exe** 文件来完成这一操作。
- en: '**Figure 3**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3**'
- en: '![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)'
- en: '**1.4 Flask Installation**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.4 Flask 安装**'
- en: 'The last tool to get installed is the Flask RESTful API. It is a library to
    be installed using pip/conda installer under the TF venv using the following CMD
    command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个要安装的工具是 Flask RESTful API。它是一个库，需要通过 pip/conda 安装器在 TF venv 下使用以下 CMD 命令进行安装：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If not already installed, NumPy and SciPy should be installed inside the venv
    in order to be able to read and manipulate images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未安装，NumPy 和 SciPy 应在虚拟环境（venv）中安装，以便能够读取和操作图像。
- en: By installing Anaconda (Python), TensorFlow, PyCharm, and Flask, we are ready
    to start building the project.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过安装 Anaconda（Python）、TensorFlow、PyCharm 和 Flask，我们可以开始构建项目。
- en: 2\. Downloading and Preparing the CIFAR-10 Dataset
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 下载和准备 CIFAR-10 数据集
- en: The Python version of the 10 classes CIFAR dataset (CIFAR-10) could be downloaded
    from this page [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html).
    The dataset contains 60,000 images divided into training and testing data. There
    are five files holding the training data where each file has 10,000 images. The
    images are RGB of size 32x32x3\. The training files are named **data_batch_1**, **data_batch_2**,
    and so on. There is a single file holding the test data named **test_batch** with
    10,000 images. A metadata file named **batches.meta** is available that holds
    the dataset classes labels which are **airplane**, **automobile**, **bird**, **cat**, **deer**, **dog**, **frog**, **horse**, **ship**,
    and **truck**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR 数据集的 Python 版本（CIFAR-10）可以从此页面 [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)
    下载。数据集包含 60,000 张图像，分为训练数据和测试数据。训练数据由五个文件组成，每个文件包含 10,000 张图像。图像为 32x32x3 的 RGB。训练文件命名为
    **data_batch_1**、**data_batch_2** 等。还有一个包含 10,000 张图像的测试数据文件，命名为 **test_batch**。还有一个名为
    **batches.meta** 的元数据文件，其中包含数据集类别标签：**airplane**、**automobile**、**bird**、**cat**、**deer**、**dog**、**frog**、**horse**、**ship**
    和 **truck**。
- en: 'Because each file in the dataset is a binary file, it should be decoded in
    order to retrieve the actual image data. For such reason, a function called unpickle_patch
    is created to do such job defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集中的每个文件都是二进制文件，因此应解码以检索实际的图像数据。因此，创建了一个名为 unpickle_patch 的函数来完成此工作，其定义如下：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The method accepts the binary file name and returns a dictionary holding details
    about such file. The dictionary holds the data for all 10,000 samples within the
    file in addition to their labels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法接受二进制文件名，并返回一个包含该文件详细信息的字典。字典中包含该文件中所有 10,000 个样本的数据及其标签。
- en: In order to decode the entire training data, a new function called get_dataset_images
    is created. That function accepts the dataset path and works only on the training
    data. As a result, it filters the files under this path and returns only files
    starting with **data_batch_**. The testing data is prepared later after building
    and training the CNN.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解码整个训练数据，创建了一个名为 get_dataset_images 的新函数。该函数接受数据集路径，仅在训练数据上工作。因此，它会过滤该路径下的文件，并仅返回以
    **data_batch_** 开头的文件。测试数据在构建和训练 CNN 后准备。
- en: For each training file, it is decoded by calling the unpickle_patch function.
    Based on the dictionary returned by such function, the get_dataset_images function
    returns both the images data and their class labels. The images data is retrieved
    from the **‘data’** key and their class labels are retrieved from the **‘labels’** key.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个训练文件，通过调用 unpickle_patch 函数进行解码。基于该函数返回的字典，get_dataset_images 函数返回图像数据及其类别标签。图像数据从
    **‘data’** 键中检索，而类别标签从 **‘labels’** 键中检索。
- en: Because the images data are saved as 1D vector, it should be reshaped to be
    of 3 dimensions. This is because TensorFlow accepts the images of such shape.
    For such reason, the get_dataset_images function accepts the number of rows/columns
    in addition to the number of channels in each image as arguments.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像数据以 1D 向量保存，需要将其重塑为 3 维。这是因为 TensorFlow 接受这种形状的图像。因此，get_dataset_images
    函数接受图像的行数/列数以及每个图像的通道数作为参数。
- en: 'The implementation of such function is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的实现如下：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By preparing the training data, we can build and train the CNN model using TF.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通过准备训练数据，我们可以使用 TF 构建和训练 CNN 模型。
- en: 3\. Building the CNN Computational Graph using TensorFlow
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 使用 TensorFlow 构建 CNN 计算图
- en: The computational graph of the CNN is created inside a function called create_CNN.
    It creates a stack of convolution (conv), ReLU, max pooling, dropout, and fully
    connected (FC) layers and returns the results of the last fully connected layer.
    The output of each layer is the input to the next layer. This requires consistency
    between the sizes of outputs and inputs of neighboring layers. Note that for each
    conv, ReLU, and max pooling layers, there are some of parameters to get specified
    such as strides across each dimension and padding.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的计算图是在一个名为 create_CNN 的函数内部创建的。它创建了一个卷积（conv）、ReLU、最大池化、dropout 和全连接（FC）层的堆栈，并返回最后一个全连接层的结果。每一层的输出都是下一层的输入。这要求相邻层之间的输出和输入大小保持一致。请注意，对于每个卷积、ReLU
    和最大池化层，需要指定一些参数，如每个维度的步幅和填充。
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Because the convolution layer applies the convolution operation between the
    input data and the set of filters used, the create_CNN function accepts the input
    data as an input argument. Such data is what returned by the get_dataset_images
    function. The convolution layer is created using the create_conv_layer function.
    The create_conv_layer function accepts the input data, filter size, and number
    of filters and returns the result of convolving the input data with the set of
    filters. The set of filters have their size set according to the depth of the
    input images. The create_conv_layer is defined as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因为卷积层在输入数据和使用的滤波器集之间应用卷积操作，所以 create_CNN 函数接受输入数据作为输入参数。这些数据是由 get_dataset_images
    函数返回的。卷积层是使用 create_conv_layer 函数创建的。create_conv_layer 函数接受输入数据、滤波器大小和滤波器数量，并返回将输入数据与滤波器集卷积的结果。滤波器集的大小根据输入图像的深度进行设置。create_conv_layer
    的定义如下：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Another argument is the probability of keeping neurons in the dropout layer.
    It specifies how much neurons are dropped by the dropout layer. The dropout layer
    is implemented using the dropout_flatten_layer function as shown below. Such function
    returns a flattened array that will be the input to the fully connected layer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个参数是保持 dropout 层中的神经元的概率。它指定 dropout 层丢弃多少神经元。dropout 层是使用 dropout_flatten_layer
    函数实现的，如下所示。该函数返回一个展平的数组，将作为全连接层的输入。
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Because the last FC layer should have number of output neurons equal to the
    number of dataset classes, the number of dataset classes is used as another input
    argument to the create_CNN function. The fully connected layer is created using
    the fc_layer function. Such function accepts the flattened result of the dropout
    layer, the number of features in such flattened result, and number of output neurons
    from such FC layer. Based on number of inputs and outputs, a weights tensor is
    created which get then multiplied by the flattened layer to get the returned result
    of the FC layer.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因为最后的 FC 层应具有与数据集类别数量相等的输出神经元数量，所以数据集类别数量被用作 create_CNN 函数的另一个输入参数。全连接层是使用 fc_layer
    函数创建的。该函数接受 dropout 层的展平结果、展平结果中的特征数量和该 FC 层的输出神经元数量。根据输入和输出的数量，创建一个权重张量，然后将其与展平层相乘，以获得
    FC 层的返回结果。
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The computational graph after being visualized using TensorBoard is shown in
    figure 4.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 可视化后的计算图如图 4 所示。
- en: '**Figure 4**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4**'
- en: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并寻找目的……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个 90 亿美元的 AI 失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
