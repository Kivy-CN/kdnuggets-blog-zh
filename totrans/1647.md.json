["```py\n# Converting -f (from) latin1 (ISO-8859-1)\n# -t (to) standard UTF_8\niconv -f ISO-8859-1 -t UTF-8 < input.txt > output.txt\n```", "```py\n# Prints out first 10 lines\n\nhead filename.csv\n\n# Print first 3 lines\n\nhead -n 3 filename.csv\n```", "```py\n# Converting a tab delimited file into commas\n\ncat tab_delimited.txt | tr \"\\\\t\" \",\" comma_delimited.csv\n```", "```py\n[:alnum:] all letters and digits\n[:alpha:] all letters\n[:blank:] all horizontal whitespace\n[:cntrl:] all control characters\n[:digit:] all digits\n[:graph:] all printable characters, not including space\n[:lower:] all lower case letters\n[:print:] all printable characters, including space\n[:punct:] all punctuation characters\n[:space:] all horizontal or vertical whitespace\n[:upper:] all upper case letters\n[:xdigit:] all hexadecimal digits\n```", "```py\ncat README.md | tr \"[:punct:][:space:]\" \"\\n\" | tr \"[:upper:]\" \"[:lower:]\" | grep . | sort | uniq -c | sort -nr\n```", "```py\n# Converting all upper case letters to lower case\n\ncat filename.csv | tr '[A-Z]' '[a-z]'\n```", "```py\n# Will return number of lines in CSV\n\nwc -l gigantic_comma.csv\n```", "```py\n# We will split our CSV into new_filename every 500 line\n\nsplit -l 500 filename.csv new_filename_\n\n# filename.csv\n# ls output\n# new_filename_aaa\n# new_filename_aab\n# new_filename_aac\n```", "```py\nfind . -type f -exec mv '{}' '{}'.csv \\;\n\n# ls output\n# filename.csv.csv\n# new_filename_aaa.csv\n# new_filename_aab.csv\n# new_filename_aac.csv\n```", "```py\n# Sorting a CSV file by the second column alphabetically\n\nsort -t, -k2 filename.csv\n\n# Numerically\n\nsort -t, -k2n filename.csv\n\n# Reverse order\n\nsort -t, -k2nr filename.csv\n```", "```py\ncut -d, -f 1,3 filename.csv\n```", "```py\ncut -d, -f 2- filename.csv\n```", "```py\n# Print first 10 lines of column 1 and 3, where \"some_string_value\" is present\n\nhead filename.csv | grep \"some_string_value\" | cut -d, -f 1,3\n```", "```py\ncat filename.csv | cut -d, -f 2 | sort | uniq | wc -l\n\n# Count occurences of unique values, limiting to first 10 results\n\ncat filename.csv | cut -d, -f 2 | sort | uniq -c | head\n```", "```py\n# names.txt\nadam\njohn\nzach\n\n# jobs.txt\nlawyer\nyoutuber\ndeveloper\n\n# Join the two into a CSV\n\npaste -d ',' names.txt jobs.txt > person_data.txt\n\n# Output\nadam,lawyer\njohn,youtuber\nzach,developer\n```", "```py\n# Join the first file (-1) by the second column\n# and the second file (-2) by the first\n\njoin -t, -1 2 -2 1 first_file.txt second_file.txt\n```", "```py\n# Outer join, replace blanks with NULL in columns 1 and 2\n# -o which fields to substitute - 0 is key, 1.1 is first column, etc...\n\njoin -t, -1 2 -a 1 -a2 -e ' NULL' -o '0,1.1,2.2' first_file.txt second_file.txt\n```", "```py\n# Recursively search and list all files in directory containing 'word'\n\ngrep -lr 'word' .\n\n# List number of files containing word\n\ngrep -lr 'word' . | wc -l\n```", "```py\ngrep -c 'some_value' filename.csv\n\n# Same thing, but in all files in current directory by file name\n\ngrep -c 'some_value' *\n```", "```py\ngrep \"first_value\\|second_value\" filename.csv\n```", "```py\nbalance,name\n$1,000,john\n$2,000,jack\n```", "```py\nsed -i '' 's/\\$//g' data.txt\n\n# balance,name\n# 1,000,john\n# 2,000,jack\n```", "```py\nsed -i '' 's/\\([0-9]\\),\\([0-9]\\)/\\1\\2/g' data.txt\n\n# balance,name\n# 1000,john\n# 2000,jack\n```", "```py\nsed -i '' '/jack/d' data.txt\n\n# balance,name\n# 1000,john\n```", "```py\nawk '/word/' filename.csv\n```", "```py\nawk -F, '/word/ { print $3 \"\\t\" $4 }' filename.csv\n```", "```py\nawk -F, 'NR == 53' filename.csv\n```", "```py\nawk -F, ' $1 == \"string\" { print NR, $0 } ' filename.csv\n\n# Filter based off of numerical value in second column\n\nawk -F, ' $2 == 1000 { print NR, $0 } ' filename.csv\n```", "```py\n# Print line number and columns where column three greater\n# than 2005 and column five less than one thousand\n\nawk -F, ' $3 >= 2005 && $5 <= 1000 { print NR, $0 } ' filename.csv\n```", "```py\nawk -F, '{ x+=$3 } END { print x }' filename.csv\n```", "```py\nawk -F, '$1 == \"something\" { x+=$3 } END { print x }' filename.csv\n```", "```py\nawk -F, 'END { print NF, NR }' filename.csv\n\n# Prettier version\n\nawk -F, 'BEGIN { print \"COLUMNS\", \"ROWS\" }; END { print NF, NR }' filename.csv\n```", "```py\nawk -F, '++seen[$0] == 2' filename.csv\n```", "```py\n# Consecutive lines\nawk 'a !~ $0; {a=$0}']\n\n# Nonconsecutive lines\nawk '! a[$0]++' filename.csv\n\n# More efficient\nawk '!($0 in a) {a[$0];print}\n```", "```py\nawk '{gsub(/scarlet|ruby|puce/, \"red\"); print}'\n```", "```py\nawk 'FNR==1 && NR!=1{next;}{print}' *.csv > final_file.csv\n```", "```py\nsed '1d;$d' filename.csv | awk 'NR%NUMBER_OF_LINES==1{x=\"filename-\"++i\".csv\";}{print > x}'\n\n# Example: splitting big_data.csv into data_(n).csv every 100,000 lines\n\nsed '1d;$d' big_data.csv | awk 'NR%100000==1{x=\"data_\"++i\".csv\";}{print > x}'\n```"]