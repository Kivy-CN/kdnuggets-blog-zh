- en: How to Monitor Machine Learning Models in Real-Time
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实时监控机器学习模型
- en: 原文：[https://www.kdnuggets.com/2019/01/monitor-machine-learning-real-time.html](https://www.kdnuggets.com/2019/01/monitor-machine-learning-real-time.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/01/monitor-machine-learning-real-time.html](https://www.kdnuggets.com/2019/01/monitor-machine-learning-real-time.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Ted Dunning](https://mapr.com/blog/author/ted-dunning/), Chief Application
    Architect, MapR**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Ted Dunning](https://mapr.com/blog/author/ted-dunning/)，MapR首席应用架构师**'
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: Believe it or not, what you learn in machine learning classes isn’t what you
    need to know to put machine learning to work. Academic machine learning involves
    almost exclusively off-line evaluation of machine learning models. This halcyon
    view is also fostered by the highly publicized contests at Kaggle[^([1])](#_ftn1)
    or the Netflix challenge[^([2])](#_ftn2). In the real-world this is, somewhat
    surprisingly, often only good enough for a rough cut that eliminates the real
    dogs. For serious production work, online evaluation is often the only option
    to determine which of several final round candidates might be chosen for further
    use. As Einstein is rumored to have said, theory and practice are the same, in
    theory. In practice, they are different. So it is with models. Part of the problem
    is interaction with other models and systems. Another part has to do with variability
    of the real world, possibly adversaries at work. It may even literally be sunspots.
    One particular problem arises when models choose their own training data and thus
    they exhibit self-reinforcing behavior.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 信不信由你，在机器学习课程中学到的东西并不是你需要知道的内容来将机器学习付诸实践。学术机器学习几乎完全涉及对机器学习模型的离线评估。这种理想化的观点也由Kaggle[^([1])](#_ftn1)
    或Netflix挑战赛[^([2])](#_ftn2) 等广泛宣传的竞赛所助长。在现实世界中，这种方法令人惊讶地通常仅能作为一个粗略的初步筛选，用于剔除真正糟糕的模型。对于严肃的生产工作，在线评估通常是确定多个最终候选模型中哪个可能被选择用于进一步使用的唯一选择。正如爱因斯坦所传言的那样，理论与实践在理论上是一样的。在实践中，它们是不同的。模型也是如此。部分问题与其他模型和系统的互动有关。另一个问题则涉及现实世界的变异性，可能是对手的作用。甚至可能是太阳黑子。一个特别的问题是，当模型选择自己的训练数据时，它们会表现出自我强化的行为。
- en: In addition to these difficulties, production models almost always have service
    level agreements that have to do with how quickly they must produce results and
    how often they are allowed to fail. These operational considerations can be as
    important as the accuracy of the model … right results returned late are much
    worse than mostly right results returned in time.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些困难，生产模型几乎总是有服务水平协议，这些协议涉及它们必须多快产生结果以及它们允许失败的频率。这些操作性考虑因素可能与模型的准确性一样重要……返回的正确结果迟到比及时返回的基本正确结果要糟糕得多。
- en: This article will focus on ways to monitor machine learning systems in real-time
    or near real-time. Because of this focus, we aren’t going to talk much about getting
    down to the ground truth of whether a model is producing just the right answer
    because you often can’t determine that for a long time. For instance, if a fraud
    model says that an account has been taken over, you may not find out the truth
    for months. Even so, however, we can often find out if a model is misbehaving
    (in certain important ways) long before then.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将重点讨论如何实时或近实时地监控机器学习系统。由于这个重点，我们不会多谈论如何确定一个模型是否产生了正确答案，因为你通常很难在很长时间内确认这一点。例如，如果一个欺诈模型说某个账户已被接管，你可能要几个月才能得知真相。然而，即便如此，我们通常可以在此之前很早就发现模型是否在某些重要方面表现异常。
- en: The techniques described here will include the use of coarse functional monitors,
    non-linear latency histogramming, how to normalize user response data and how
    to compare score distributions to reference distributions and to canary models.
    These techniques may sound arcane, but behind the fancy names, each one has a
    simple heart and doesn’t really require advanced mathematics to understand, implement,
    or interpret.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的技术将包括使用粗略功能监控器、非线性延迟直方图、如何规范化用户响应数据以及如何将得分分布与参考分布和金丝雀模型进行比较。这些技术听起来可能很神秘，但在华丽的名称背后，每一种都有一个简单的核心，不需要高级数学就能理解、实施或解释。
- en: It’s a wild world
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这是一个充满挑战的世界
- en: Let’s talk about what you need to be watching for beyond what you learn in classes.
    It would absolutely be a simpler world if it worked the way it does in classes
    and contests, but it isn’t that simple by a long shot. Not only is extracting
    correct training data a large engineering effort, models running in the wild have
    to deal with some very complex real-world issues. If you are building a fraud
    model, the fraudsters will adapt their methods to evade detection by your model.
    If you are doing marketing, your competitors will always be looking for ways to
    one-up your efforts. Even with systems that don’t depend on human behavior like
    airplane engines or factories, surprises still happen. These surprises could be
    things like a two engine bird strike or like the surprise upgrade of a milling
    machine or even some contextual issue like market conditions or the weather.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈除了在课堂上学到的内容之外你需要关注的方面。如果一切像在课堂和比赛中那样简单，那将绝对是一个更简单的世界，但实际情况远非如此。不仅正确提取训练数据是一项巨大的工程工作，而且在实际运行的模型必须处理一些非常复杂的现实世界问题。如果你在构建一个欺诈模型，欺诈者会调整他们的方法以避开你的模型。如果你在做市场营销，你的竞争对手将总是寻找超越你努力的方法。即使是那些不依赖于人类行为的系统，如飞机引擎或工厂，也会发生意外。这些意外可能是像双引擎鸟击、铣床的意外升级，甚至是市场条件或天气等上下文问题。
- en: And even if the data environment doesn’t change, there can be equipment failures
    that cause the world to look strange and surprising.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据环境没有变化，也可能会发生设备故障，导致世界看起来奇怪和令人惊讶。
- en: No matter what kind of machine learning system you are building, you need to
    monitor your models to make sure that they are still working the way that you
    think they are. Let’s check out some specific techniques that help spot issues.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你构建的是哪种类型的机器学习系统，你都需要监控你的模型，以确保它们仍然按照你认为的方式工作。让我们看看一些帮助发现问题的具体技术。
- en: Watching the basics
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关注基础知识
- en: The most basic aspects of model performance is whether it is getting requests
    and how quickly it is producing results. No model will give good results if you
    don’t ask for them. And results are no good unless you actually get them in good
    time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能的最基本方面是它是否接收到请求以及它产生结果的速度。如果你不提出请求，模型不会给出好的结果。而且，结果的质量也取决于你是否能及时获得这些结果。
- en: To monitor whether requests are arriving, you need to record the arrival each
    incoming request together with the name of the machine where the request has landed
    and an accurate timestamp. It is typically a bit better to record this data to
    a persistent stream on a distributed platform because log files can disappear
    if a machine goes down. It is also better to record request arrival and completion
    as separate events so that you can distinguish failure to respond from lack of
    requests. The simplest monitor you can build is to measure the time between requests.
    One step better is to [build a simple predictor of the current request rate](https://mapr.com/practical-machine-learning-new-look-anomaly-detection/)
    based on recent request rates and use the product of the predicted rate times
    the time since the last request. Even a simple linear model will usually predict
    request rates an hour ahead of time with less than 10% error which will allow
    you to raise an alert if requests stop happening. Figure 1 shows an example of
    how accurately this can work by plotting predicted traffic for the Wikipedia page
    for “Christmas”.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要监控请求是否到达，你需要记录每一个传入请求的到达时间、请求所到达的机器名称以及准确的时间戳。通常，将这些数据记录到分布式平台上的持久流中会更好，因为如果机器宕机，日志文件可能会消失。将请求到达和完成记录为单独的事件也更好，这样你可以区分响应失败与请求缺失。你可以构建的最简单的监控方法是测量请求之间的时间。更进一步的是基于最近的请求速率[构建当前请求速率的简单预测器](https://mapr.com/practical-machine-learning-new-look-anomaly-detection/)，并使用预测速率与上次请求之间的时间的乘积。即使是简单的线性模型通常也会在一个小时前预测请求速率，误差小于10%，这将允许你在请求停止时发出警报。图1展示了通过绘制“圣诞节”维基百科页面的预测流量，预测的准确性如何。
- en: '![Christmas Prediction Figure 1](../Images/d6ba51166552433cff1059d9c4e6e5f1.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![圣诞节预测图1](../Images/d6ba51166552433cff1059d9c4e6e5f1.png)'
- en: '**Figure 1\. The actual traffic (dark line) versus predicted traffic (gray
    line) for a traffic prediction model trained on traffic in November. Even though
    the traffic right around Christmas was radically different from traffic during
    the training period, predictions were accurate enough to detect system failures
    very quickly.**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1\. 实际流量（深色线）与针对 11 月流量训练的流量预测模型预测流量（灰色线）进行对比。尽管圣诞节期间的流量与训练期间的流量大相径庭，但预测仍然足够准确，能够非常快速地检测到系统故障。**'
- en: The model used for this prediction was a linear regression that used the log
    of traffic rates for the 4 most recent hours, 24 hours ago and 48 hours ago to
    predict the log of the traffic now. This prediction can be used to detect request
    rate anomalies as shown in Figure 2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此预测的模型是一个线性回归模型，使用了最近 4 小时、24 小时前和 48 小时前的流量对流量的对数进行预测。这个预测可以用于检测请求率异常，如图
    2 所示。
- en: '![Response Model Figure 2](../Images/031296581aabd9c419b4291644f91720.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![响应模型图 2](../Images/031296581aabd9c419b4291644f91720.png)'
- en: '**Figure 2\. The architecture of a request rate anomaly detector. A threshold
     is used to determine when the rate drops below the predicted value because the
    time between events will rise to a high level. The predicted rate  is used to
    normalize this time.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2\. 请求率异常检测器的架构。使用阈值来确定何时请求率下降到预测值以下，因为事件之间的时间将上升到一个高水平。预测率用于对这个时间进行归一化。**'
- en: Once we are clear that requests are coming, we can look at whether our model
    is producing results in a timely manner. To enable this, we need to log the elapsed
    time as each request is responded to. These log entries should specify a unique
    ID for the original request, the current time, details of which model and which
    hardware used to compute the request as well as the elapsed time. As a first cut,
    we can compute the distribution of the reported elapsed times. For latencies,
    the best way to do this is by using a [non-uniform histogram](https://github.com/tdunning/t-digest/blob/master/core/src/main/java/com/tdunning/math/stats/LogHistogram.java).
    We can compute such a histogram for each, say, five minute interval. To monitor
    performance, we can accumulate a background over a fairly long period of time
    and plot the recent results against that background distribution. Figure 3 shows
    what we might see.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确认请求正在到达，我们可以查看我们的模型是否及时产生结果。为此，我们需要记录每个请求响应的时间。这些日志条目应指定原始请求的唯一 ID、当前时间、计算请求所用的模型和硬件的详细信息以及经过的时间。作为初步工作，我们可以计算报告的经过时间的分布。对于延迟，最佳方法是使用
    [非均匀直方图](https://github.com/tdunning/t-digest/blob/master/core/src/main/java/com/tdunning/math/stats/LogHistogram.java)。我们可以为每个，例如，每五分钟的时间间隔计算这样的直方图。为了监控性能，我们可以在相当长的一段时间内积累背景，并将最近的结果与该背景分布进行对比。图
    3 显示了我们可能看到的情况。
- en: '![Latency Anomaly Figure 3](../Images/d426f2ba9aab5e5e33dc03368aff7a13.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![延迟异常图 3](../Images/d426f2ba9aab5e5e33dc03368aff7a13.png)'
- en: '**Figure 3\. Normal response times in milliseconds (black line) are plotted
    against response times in which about 1% of responses are substantially delayed.
    Because of the log-scale on the vertical axis and the non-uniform bin sizes, the
    change in 99%-ile latency is clearly visible.**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3\. 以毫秒为单位的正常响应时间（黑线）与大约 1% 的响应显著延迟的响应时间进行对比。由于纵轴上的对数刻度和非均匀的区间大小，99%延迟的变化非常明显。**'
- en: These histograms can also be compared using more advanced, automated techniques
    based on comparing the counts in corresponding bins. One good way to do this is
    to use a statistical method known as the [G-test](https://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html).
    Such a test can convert each histogram into a single score that describes how
    anomalous it is versus the long term background. If the latency measurements that
    went into a histogram are tagged, then the slow and fast parts of a single histogram
    can be compared to find out which tags are more common in the slow part. If these
    tags represent hardware IDs or model versions, then this can be used to target
    your diagnostic efforts.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些直方图也可以使用基于比较对应区间计数的更高级的自动化技术进行比较。一种很好的方法是使用被称为 [G-检验](https://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html)
    的统计方法。这种测试可以将每个直方图转换为一个单一的得分，描述其与长期背景相比的异常程度。如果进入直方图的延迟测量有标签，那么可以比较单个直方图中的慢速和快速部分，以找出在慢速部分更常见的标签。如果这些标签代表硬件
    ID 或型号版本，则可以用来定向诊断工作。
- en: But is it RIGHT?!
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 但这是否正确？！
- en: All of the methods mentioned so far work no matter what the model is supposed
    to do. But that same generality also means that these techniques can’t tell us
    anything about the responses that the model is actually producing. Are the results
    any good? Are they right? We have no real idea. All we know so far is that requests
    are arriving and results are being produced at historically plausible levels and
    speeds. Speeds and feeds are nice, but we also need to have some idea when things
    are not just working, but also whether they are working correctly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止提到的所有方法都适用于模型应执行的任务。但这种普遍性也意味着这些技术不能告诉我们模型实际产生的响应情况。结果是否良好？是否正确？我们没有真正的了解。目前我们只知道请求正在到达，结果也在以历史上合理的水平和速度产生。速度和处理量很好，但我们还需要了解事情不仅仅是在运行，还要了解它们是否运行正确。
- en: In some kinds of situations, notably when working with marketing models, we
    can get preliminary feedback about whether our model has done a good job in just
    a few minutes. In doing this, though, we have to be very careful in comparing
    different models. In particular, we can’t just compare the number of conversions
    for each model because as time passes after an ad or offer is presented to a user,
    more and more conversions will be accrued giving an advantage to older impressions.
    Figure 4 shows what is going on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些情况下，特别是在处理营销模型时，我们可以在几分钟内获得有关我们模型是否表现良好的初步反馈。然而，在进行比较时，我们必须非常小心。特别是，我们不能仅仅比较每个模型的转化数量，因为随着时间的推移，广告或优惠呈现给用户后，转化数量会不断增加，这给较老的印象带来了优势。图
    4 显示了发生了什么。
- en: '![Response Rate Figure 4](../Images/e8400531ff93c23480bc9475cb13f668.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![响应率图 4](../Images/e8400531ff93c23480bc9475cb13f668.png)'
- en: '**Figure 4\. Conversions need to be normalized against the time of the original
    impression and the number of impressions. Comparisons must also be made at long
    enough after the impression to get a reliable comparison, but waiting longer than
    necessary doesn’t help. Here, the green trace seems best at first, but by 2 seconds
    after impression when only 60% of the conversions have been received, it is clear
    that black is best and red worst. Picking an appropriate delay allows quickest
    accurate evaluation of models.**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4\. 转化需要相对于原始印象的时间和印象的数量进行归一化。比较还必须在印象后经过足够长的时间以获得可靠的比较，但等待过长时间并没有帮助。在这里，绿色轨迹起初似乎最好，但在印象后2秒，当只有60%的转化被接收时，明显是黑色最佳，红色最差。选择适当的延迟可以实现模型的最快准确评估。**'
- en: The problem is that each impression of an offer or ad is independent of all
    others. If the person receiving the impression is going to respond, they will
    probably respond relatively soon after seeing the impression. Some people will
    take longer than others, though, and some may respond after a very long time.
    This means that over time, the conversion rate for any offer will creep up over
    time. The first thing you have to do, then, is to offset each conversion relative
    to the time of the corresponding impression. Similarly, some offers will get more
    impressions than others so you need to scale vertically by the number of impressions,
    as well.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，每次广告或优惠的印象都是独立于其他印象的。如果接收印象的人会做出反应，他们可能会在看到印象后的相对较短时间内做出回应。然而，有些人可能需要更长时间，有些人可能会在很长时间后才做出反应。这意味着，随着时间的推移，任何优惠的转化率都会逐渐上升。因此，首先要做的就是相对于相应印象的时间来调整每个转化率。同样，有些优惠会获得更多的印象，因此你也需要按印象的数量进行纵向缩放。
- en: When you do this, you will see that, because of statistical variation, you have
    to wait a bit before declaring which offer works best, but you don’t usually have
    to wait for more than about 60% of the final number responses. This is very important
    because waiting for 95% of all impressions can take 10x longer than waiting for
    50-60% of impressions. This trick is important as well because it allows us to
    have a near real-time measure of response rate.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你这样做时，你会发现，由于统计变异，你必须等待一段时间才能确定哪个优惠效果最好，但通常不需要等到超过最终响应数的60%。这非常重要，因为等待95%的所有印象可能比等待50-60%的印象要长10倍。这个技巧也很重要，因为它允许我们近乎实时地测量响应率。
- en: Truth may take too long
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事实可能需要很长时间
- en: As nice as real-time ground truth feedback may be, there are lots of use cases
    where this just isn’t possible. For instance, we may not know even slightly whether
    a detected fraud is really just that for days or weeks. There are still things
    that we can do to detect problems quickly, however.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管实时的真实反馈可能很有用，但在许多情况下这是不可能的。例如，我们可能几天或几周内都无法确定检测到的欺诈行为是否确实存在。然而，我们仍然可以采取一些措施快速检测问题。
- en: Lots of models produce some sort of score or set of scores. Often these represent
    some kind of probability estimate. One of the simplest things we can use as a
    monitor is to look at the score distribution produced by the model. If that distribution
    changes surprisingly, there is a good chance that there is an important change
    to the input to the model reflecting some change in the outside world or that
    the systems that the model depends on, say, for feature extraction have changed
    in some way. In either case, finding out about the change is the first step in
    figuring out what is happening.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 许多模型会产生某种分数或一组分数。这些分数通常代表某种概率估计。我们可以用来监控的最简单的方法之一是查看模型产生的分数分布。如果该分布发生意外变化，则很可能是模型输入发生了重要变化，反映了外部世界的变化，或者模型依赖的系统，例如特征提取系统，发生了某种变化。无论哪种情况，发现变化是了解发生了什么的第一步。
- en: One of the best ways to detect this kind of change is to use a system known
    as the *t*-digest. You can’t really use the logHistogram that we talked about
    using for latency distributions because scores don’t have the same kind of well
    understood characteristics as latencies do. The *t*-digest is a bit more expensive
    to use, but it can handle pretty much anything that you throw at it. The method,
    then is to store digests of the score distribution every minute or so tagged with
    model version and such. To check the score distribution, you can accumulate a
    number of these stored digests from the past to get the reference distribution
    and compare this reference to the latest digest.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 检测这种变化的最佳方法之一是使用称为*t*-digest的系统。你不能真正使用我们讨论过的用于延迟分布的logHistogram，因为分数没有延迟那样明确的特征。*t*-digest的使用成本稍高，但它几乎可以处理任何情况。方法是每分钟存储一次分数分布的摘要，并标记模型版本等。要检查分数分布，你可以从过去积累这些存储的摘要，以获得参考分布，并将该参考分布与最新的摘要进行比较。
- en: There are two popular ways to compare distributions. One is to use the deciles
    of the reference distribution as bin boundaries and then use the latest digest
    to estimate how many samples are in each bin. If the distributions are the same,
    then there should be the same number of samples in the recent data in each bin.
    This can be tested using the G-test as before to get a score that is large when
    the distributions differ interestingly.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 比较分布有两种常用方法。其一是使用参考分布的十分位数作为区间边界，然后使用最新的摘要来估计每个区间中的样本数量。如果分布相同，那么最近数据中每个区间中的样本数量应该是一样的。可以像以前一样使用G检验来测试，以获得当分布有趣地不同的时候分数较大的结果。
- en: Another approach is to use a value known as a Kolmogorov-Smirnov statistic to
    detect differences between the reference and recent distributions directly. There
    is code in the upcoming *t*-digest release to compute this statistic, but the
    important factor is that the statistic is large when the distributions differ
    significantly and smaller when they do not.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是使用称为Kolmogorov-Smirnov统计量的值直接检测参考分布与最近分布之间的差异。在即将发布的*t*-digest版本中有计算此统计量的代码，但重要的因素是，当分布显著不同的时候统计量较大，当它们不同时则较小。
- en: Nothing sings like a canary
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 没有什么能像金丝雀那样唱歌。
- en: In general, the more we know about what a model should be doing and the more
    specific we can be about comparing against reference behavior, the quicker we
    can reliably detect changes. This is the motivation behind using a canary model.
    The idea is that we send every request to the current production model as usually,
    but we also keep an older version of the model around and send every (or nearly
    every) request to that older version as well. The older model is called a canary.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，我们对模型应执行的任务了解得越多，并且在与参考行为比较时越具体，我们就能更快、可靠地检测到变化。这就是使用金丝雀模型的动机。这个想法是我们像往常一样将每个请求发送给当前的生产模型，同时保留一个较旧版本的模型，并将每个（或几乎每个）请求也发送给那个较旧版本。这个较旧的模型被称为金丝雀。
- en: Because we are sending the exact same requests to both models and because the
    canary is a model that does nearly the same thing that we want the current model
    to do, we can compare the output of the two models request by request to get a
    very specific idea about whether the new model is behaving as expected. The average
    deviation between canary and the current champion model is a very sensitive indicator
    of malfunction in the current model, particularly if we choose the canary with
    an eye to getting a very stable (even if not so incredibly accurate) model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们向两个模型发送的是完全相同的请求，并且金丝雀模型几乎做的是我们希望当前模型做的事情，我们可以逐请求比较这两个模型的输出，从而非常具体地了解新模型是否按预期运行。金丝雀模型与当前冠军模型之间的平均偏差是当前模型故障的非常敏感指标，特别是如果我们选择金丝雀时考虑到获得一个非常稳定（即使不那么准确）的模型。
- en: A canary model is also very handy when we are fielding a potential challenger
    to our current champion. If we are trying to quantify the risk of rolling out
    this new challenger to replace our current champion, we can look at the difference
    between the challenger and the champion as well as the difference between the
    challenger and the canary. In particular, once we have models that are pretty
    good and we are making incremental improvements, no new challenger should differ
    dramatically from the current champion, nor from the canary. Where there is a
    difference is both where we stand a risk of lower accuracy, but also exactly where
    the challenger has the opportunity to shine. Focusing in on these specific instances
    for manual inspection can often give us important insight into whether the challenger
    is ready to take on the champion.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们面对潜在的新挑战者要取代当前的冠军时，金丝雀模型也非常有用。如果我们试图量化推出这个新挑战者以替代当前冠军的风险，我们可以比较挑战者与冠军之间的差异，以及挑战者与金丝雀之间的差异。特别是，一旦我们拥有了相当好的模型并进行渐进改进时，任何新的挑战者都不应与当前的冠军或金丝雀有显著差异。差异存在的地方既是我们面临低准确度风险的地方，也是挑战者有机会表现出色的地方。专注于这些特定实例进行人工检查通常能给我们提供重要的见解，帮助判断挑战者是否准备好迎接冠军。
- en: Wrapping it all up
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结一下
- en: This article has walked through a range of near real-time monitoring techniques
    for machine learning models starting with monitors that look purely at the gross
    operational characteristics of request rate and response times. Those are often
    very good for detecting systems level problems in evaluating requests. From there,
    we talked about how to normalize responses for cases like search results or marketing
    impressions so that they can be compared cleanly and accuracy can be estimated
    in near real time. For cases where we don’t know exactly what our model should
    output, we talked about methods for looking for changes in score distributions
    by comparing to the past performance of the model or by comparing to a canary
    model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了一系列近实时监控机器学习模型的技术，首先是查看请求率和响应时间等总体操作特性的监控器。这些监控器通常对于检测评估请求时的系统级问题非常有效。接下来，我们讨论了如何对搜索结果或营销印象等情况的响应进行归一化，以便能够干净地进行比较，并在近实时中估计准确性。在不知道模型应该输出什么的情况下，我们讨论了通过比较过去模型的表现或比较金丝雀模型来寻找分数分布变化的方法。
- en: You probably won’t need to implement all of these methods for monitoring your
    models, but you should probably implement several of them. You never know what
    is hiding out there until you look, and you definitely need to know.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不需要实现所有这些监控方法，但你可能需要实现其中的几个。你永远不知道隐藏着什么，直到你去查看，而你肯定需要了解清楚。
- en: '[^([1])](#_ftnref1) See [https://www.kaggle.com/c/GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[^([1])](#_ftnref1) 参见 [https://www.kaggle.com/c/GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit)'
- en: '[^([2])](#_ftnref2) See [https://en.wikipedia.org/wiki/Netflix_Prize](https://en.wikipedia.org/wiki/Netflix_Prize)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[^([2])](#_ftnref2) 参见 [https://en.wikipedia.org/wiki/Netflix_Prize](https://en.wikipedia.org/wiki/Netflix_Prize)'
- en: '**Bio**: [Ted Dunning](https://mapr.com/blog/author/ted-dunning/) is Chief
    Application Architect at MapR and a member of the board of directors for the Apache
    Software Foundation. He has a long history in building successful startups where
    machine learning made a big difference in the value of the company. He is listed
    as inventor on dozens of patents and continues to develop new algorithms and architectures.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**： [Ted Dunning](https://mapr.com/blog/author/ted-dunning/) 是 MapR 的首席应用架构师，同时也是
    Apache 软件基金会的董事会成员。他在建立成功的创业公司方面有着丰富的经验，其中机器学习在公司价值上发挥了重要作用。他在数十项专利中被列为发明人，并继续开发新的算法和架构。'
- en: '**Resources:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Data Scientist’s Dilemma: The Cold Start Problem – Ten Machine Learning Examples](https://www.kdnuggets.com/2019/01/data-scientist-dilemma-cold-start-machine-learning.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的困境：冷启动问题 – 十个机器学习实例](https://www.kdnuggets.com/2019/01/data-scientist-dilemma-cold-start-machine-learning.html)'
- en: '[How to build an API for a machine learning model in 5 minutes using Flask](https://www.kdnuggets.com/2019/01/build-api-machine-learning-model-using-flask.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Flask 在 5 分钟内为机器学习模型构建 API](https://www.kdnuggets.com/2019/01/build-api-machine-learning-model-using-flask.html)'
- en: '[The 6 Most Useful Machine Learning Projects of 2018](https://www.kdnuggets.com/2019/01/6-most-useful-machine-learning-projects-2018.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2018年最有用的6个机器学习项目](https://www.kdnuggets.com/2019/01/6-most-useful-machine-learning-projects-2018.html)'
- en: '* * *'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT 工作'
- en: '* * *'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关话题
- en: '[Monitor Model Performance in the MLOps Pipeline with Python](https://www.kdnuggets.com/2023/05/monitor-model-performance-mlops-pipeline-python.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 监控 MLOps 管道中的模型性能](https://www.kdnuggets.com/2023/05/monitor-model-performance-mlops-pipeline-python.html)'
- en: '[Monitor Your File System With Python’s Watchdog](https://www.kdnuggets.com/monitor-your-file-system-with-pythons-watchdog)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 的 Watchdog 监控你的文件系统](https://www.kdnuggets.com/monitor-your-file-system-with-pythons-watchdog)'
- en: '[Why Do Machine Learning Models Die In Silence?](https://www.kdnuggets.com/2022/01/machine-learning-models-die-silence.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么机器学习模型在沉默中死去？](https://www.kdnuggets.com/2022/01/machine-learning-models-die-silence.html)'
- en: '[Working With Sparse Features In Machine Learning Models](https://www.kdnuggets.com/2021/01/sparse-features-machine-learning-models.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在机器学习模型中处理稀疏特征](https://www.kdnuggets.com/2021/01/sparse-features-machine-learning-models.html)'
- en: '[Models Are Rarely Deployed: An Industry-wide Failure in Machine…](https://www.kdnuggets.com/2022/01/models-rarely-deployed-industrywide-failure-machine-learning-leadership.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型很少被部署：机器学习领域的普遍失败](https://www.kdnuggets.com/2022/01/models-rarely-deployed-industrywide-failure-machine-learning-leadership.html)'
- en: '[How to Package and Distribute Machine Learning Models with MLFlow](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 MLFlow 打包和分发机器学习模型](https://www.kdnuggets.com/2022/08/package-distribute-machine-learning-models-mlflow.html)'
