- en: '6 Steps To Write Any Machine Learning Algorithm From Scratch: Perceptron Case
    Study'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从零开始编写任何机器学习算法的6步：感知机案例研究
- en: 原文：[https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html](https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html](https://www.kdnuggets.com/2018/09/6-steps-write-machine-learning-algorithm.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By John Sullivan,** [**DataOptimal**](https://www.dataoptimal.com/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由John Sullivan提供，** [**DataOptimal**](https://www.dataoptimal.com/)'
- en: Writing an [algorithm from scratch](https://www.dataoptimal.com/machine-learning-from-scratch/)
    is a rewarding experience, providing you with that "ah ha!" moment where it finally
    clicks, and you understand what's really going on under the hood.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[从零开始编写算法](https://www.dataoptimal.com/machine-learning-from-scratch/)是一个值得的经历，能够带给你那种“啊哈！”的时刻，让你最终明白算法的内部运作。'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Am I saying that even if you've implemented the algorithm before with [scikit-learn](http://scikit-learn.org/stable/index.html),
    it's going to be easy to write from scratch? Absolutely not.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我是说，即使你之前用[scikit-learn](http://scikit-learn.org/stable/index.html)实现过该算法，从零开始编写也会很容易吗？绝对不是。
- en: Some algorithms are just more complicated than others, so start with something
    simple, such as the single layer [Perceptron](https://en.wikipedia.org/wiki/Perceptron).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有些算法比其他算法更复杂，因此从简单的算法开始，例如单层[感知机](https://en.wikipedia.org/wiki/Perceptron)。
- en: I'll walk you through a [6-step process to write algorithms from scratch](https://www.dataoptimal.com/machine-learning-from-scratch/),
    using the Perceptron as a case-study. This methodology can easily be translated
    to other machine learning algorithms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我将带你通过一个[从零开始编写算法的6步流程](https://www.dataoptimal.com/machine-learning-from-scratch/)，以感知机为案例研究。这种方法论可以很容易地转化为其他机器学习算法。
- en: '![Machine Learning Algorithm](../Images/4b81fa33346d72d5c70e3448dbeff8f2.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/4b81fa33346d72d5c70e3448dbeff8f2.png)'
- en: '**Get a Basic Understanding of the Algorithm**'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对算法有基本理解**'
- en: 'This goes back to what I originally stated. If you don’t understand the basics,
    don’t tackle an algorithm from scratch. At the very least, you should be able
    to answer the following questions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这回到了我最初说的。如果你不理解基础知识，就不要从零开始尝试一个算法。至少，你应该能够回答以下问题：
- en: What is it?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那是什么呢？
- en: What is it typically used for?
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它通常用于什么？
- en: When CAN’T I use this?
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我什么时候不能使用它？
- en: 'For the Perceptron, let’s go ahead and answer these questions:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于感知机，我们先回答这些问题：
- en: The single layer Perceptron is the most basic neural network. It’s typically
    used for binary classification problems (1 or 0, “yes” or “no”).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单层感知机是最基本的神经网络。它通常用于二分类问题（1或0，“是”或“否”）。
- en: It’s a linear classifier, so it can only really be used when there’s a linear
    decision boundary. Some simple uses might be sentiment analysis (positive or negative
    response) or loan default prediction (“will default”, “will not default”). For
    both cases, the decision boundary would need to be linear.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个线性分类器，因此只能在存在线性决策边界时使用。一些简单的应用可能是情感分析（积极或消极反馈）或贷款违约预测（“将违约”，“不会违约”）。对于这两种情况，决策边界都需要是线性的。
- en: If the decision boundary is non-linear, you really can’t use the Perceptron.
    For those problems, you’ll need to use something different.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果决策边界是非线性的，你确实不能使用感知机。对于这些问题，你需要使用其他方法。
- en: '![Linear vs Nonlinear](../Images/0306980e0facdaf5f2331addb1d39bc3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![线性与非线性](../Images/0306980e0facdaf5f2331addb1d39bc3.png)'
- en: '**Find Some Different Learning Sources**'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**寻找一些不同的学习资源**'
- en: After you have a basic understanding of the model, it’s time to start doing
    your research. I recommend using numerous sources. Some people learn better with
    textbooks, some people learn
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在你对模型有了基本了解后，是时候开始进行研究了。我建议使用多种资源。有些人通过教科书学习效果更好，有些人则通过
- en: better with video. Personally, I like to bounce around and use various types
    of sources. For the mathematical details, textbooks do a great job, but for more
    practical examples, I prefer blog posts and YouTube videos.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 视频效果更佳。我个人喜欢跳转使用各种类型的资源。对于数学细节，教科书做得很好，但对于更多实际示例，我更喜欢博客和YouTube视频。
- en: 'For the perceptron, here''s some great resources:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于感知器，这里有一些很好的资源：
- en: 'Textbooks:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教科书：
- en: '[The Elements of Statistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf),
    Section 4.5.1'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[统计学习的元素](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)，第4.5.1节'
- en: '[Understanding Machine Learning: From Theory To Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf),
    Section 21.4'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解机器学习：从理论到算法](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf)，第21.4节'
- en: 'Blogs:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 博客：
- en: Jason Brownlee’s article on his Machine Learning Mastery blog, [How To Implement
    The Perceptron Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/)
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jason Brownlee在他的机器学习精通博客上的文章，[如何从头开始在Python中实现感知器算法](https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/)
- en: Sebastian Raschka’s blog post, [Single-Layer Neural Networks and Gradient Descent](https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastian Raschka的博客文章，[单层神经网络和梯度下降](https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)
- en: 'Videos:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频：
- en: '[Perceptron Training](https://www.youtube.com/watch?v=5g0TPrxKK6o)'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[感知器训练](https://www.youtube.com/watch?v=5g0TPrxKK6o)'
- en: '[How the Perceptron Algorithm Works](https://www.youtube.com/watch?v=1XkjVl-j8MM)'
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[感知器算法如何工作](https://www.youtube.com/watch?v=1XkjVl-j8MM)'
- en: '![Understanding Machine Learning book](../Images/db7cde17660e8739987822512d67dca2.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![理解机器学习书籍](../Images/db7cde17660e8739987822512d67dca2.png)'
- en: '**Break the algorithm into chunks**'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**将算法分解成块**'
- en: Now that we’ve gathered our sources, it’s time to start learning. Start by grabbing
    some paper and a pencil. Rather than read a chapter or blog post all the way through,
    start by skimming for section headings, and other important info. Write down bullet
    points, and try to outline the algorithm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经收集了资料，是时候开始学习了。先拿些纸和铅笔。与其整章阅读或阅读博客，不如先浏览章节标题及其他重要信息。记下要点，尝试概述算法。
- en: 'After going through the sources, I’ve broken down the Perceptron algorithm
    into the following chunks:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看了这些资源之后，我将感知器算法分解成了以下几个部分：
- en: Initialize the weights
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化权重
- en: Multiply weights by inputs and sum them up
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将权重乘以输入并加总
- en: Compare the result against the threshold to compute the output (1 or 0)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果与阈值进行比较以计算输出（1或0）
- en: Update the weights
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新权重
- en: Repeat
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复
- en: 'Breaking the algorithm up into chunks like this makes it easier to learn. Basically
    I’ve outlined the algorithm with pseudocode, and now I can go back and fill in
    the fine details. Here’s a picture of my notes for the second step, which is the
    dot product of the weights and inputs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将算法分解成块使学习更容易。基本上，我已经用伪代码概述了算法，现在可以回过头来填充详细信息。这是我对第二步的笔记的图片，即权重和输入的点积：
- en: '![Breaking the algorithm into chunks](../Images/71149fd3ff8a3c8366ee4543c134714b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![将算法分解成块](../Images/71149fd3ff8a3c8366ee4543c134714b.png)'
- en: '**Start with a simple example**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从简单示例开始**'
- en: 'After I’ve put together my notes on the algorithm, It’s time to start implementing
    it in code. Before I dive in to a complicated problem, I like to start with a
    simple example. For the Perceptron, a [NAND gate](https://en.wikipedia.org/wiki/NAND_gate)
    is a perfect simple data set. If both inputs are true (1) then the output is false
    (0), otherwise, the output is true. Here’s an example of what the data set looks
    like:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我整理完算法笔记后，是时候开始在代码中实现它了。在处理复杂问题之前，我喜欢从简单示例开始。对于感知器， [NAND门](https://en.wikipedia.org/wiki/NAND_gate)
    是一个完美的简单数据集。如果两个输入都为真（1），则输出为假（0），否则输出为真。这是数据集的一个示例：
- en: '![Simple Data Set](../Images/d493d481cc91becd452580782930498a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![简单数据集](../Images/d493d481cc91becd452580782930498a.png)'
- en: Now that I have a simple data set, I’ll start implementing the algorithm that
    I outlined in Step 3\. It’s good practice to write the algorithm in chunks and
    test it, rather than trying to write it all in one sitting. This makes it easier
    to debug when you’re first starting out. Of course at the end you can go back
    and clean it up to make it look a little nicer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我有了一个简单的数据集，我将开始实现我在第 3 步中概述的算法。将算法分块编写并测试是个好习惯，而不是尝试一次性完成。这使得在刚开始时更容易调试。当然，最后你可以回去整理一下，让它看起来更漂亮。
- en: 'Here’s an example of the Python code for the dot product part of the algorithm
    that I outlined in Step 3:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在第 3 步中概述的算法中点积部分的 Python 代码示例：
- en: '![Python code dot product](../Images/b7e7c39fd4317a23be668a6f8796ccca.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Python 代码点积](../Images/b7e7c39fd4317a23be668a6f8796ccca.png)'
- en: '**Validate with a trusted implementation**'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**与可信实现进行验证**'
- en: Now that we’ve written up our code and tested it against a small data set, it’s
    time to scale things up to a [larger dataset](https://github.com/dataoptimal/posts/tree/master/algorithms
    from scratch). To make sure that our code is working correctly on this more complicated
    dataset, it’s good to test it against a trusted implementation. For the Perceptron
    we can use the implementation from [sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经编写了代码并在一个小数据集上进行了测试，是时候将其扩展到 [更大的数据集](https://github.com/dataoptimal/posts/tree/master/algorithms%20from%20scratch)了。为了确保我们的代码在这个更复杂的数据集上正常工作，最好对其进行可信的实现测试。对于
    Perceptron，我们可以使用 [sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)
    的实现。
- en: '![Python sci-kit code](../Images/3a654185564dafe9a220fdf9aab15d56.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Python sci-kit 代码](../Images/3a654185564dafe9a220fdf9aab15d56.png)'
- en: To test [my code](https://github.com/dataoptimal/posts/tree/master/algorithms
    from scratch) I’m going to look at the weights. If I’ve implemented the algorithm
    correctly, my weights should match up with those of the sci-kit learn Perceptron.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 [我的代码](https://github.com/dataoptimal/posts/tree/master/algorithms%20from%20scratch)，我将查看权重。如果我正确实现了算法，我的权重应该与
    sci-kit learn Perceptron 的权重一致。
- en: '![Test code](../Images/5e20ea4c8902f4813b4496c38479e0b9.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![测试代码](../Images/5e20ea4c8902f4813b4496c38479e0b9.png)'
- en: At first, I didn’t get the same weights, and this is because I had to tweak
    the default settings in the scikit-learn Perceptron. I wasn’t implementing a new
    random state every time, just a fixed seed, so I had to turn this off. The same
    goes for shuffling, I also needed to turn that off. To match my learning rate,
    I changed eta0 to 0.1\. Finally, I turned off the fit_intercept option. I included
    a dummy column of 1’s in my feature dataset, so I was already automatically fitting
    the intercept (aka bias term).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我没有得到相同的权重，这是因为我必须调整 scikit-learn Perceptron 中的默认设置。我每次没有实现一个新的随机状态，只是一个固定的种子，因此我必须关闭这个设置。对于洗牌也是如此，我也需要关闭它。为了匹配我的学习率，我将
    eta0 改为 0.1。最后，我关闭了 fit_intercept 选项。我在特征数据集中包含了一列全为 1 的虚拟列，因此我已经自动拟合了截距（也称为偏置项）。
- en: This brings up another important point. When you validate against an existing
    implementation of a model, you need to be very aware of the inputs to the model.
    You should never blindly use a model, always question your assumptions, and exactly
    what each input means.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了另一个重要的点。当你对模型的现有实现进行验证时，你需要非常关注模型的输入。你绝不能盲目使用一个模型，总是要质疑你的假设，以及每个输入的确切含义。
- en: '**Write up your process**'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**撰写你的过程**'
- en: 'This last step in the process is probably the most important. You’ve just gone
    through all the work of learning, taking notes, writing the algorithm from scratch,
    and comparing it with a trusted implementation. Don’t let all that good work go
    to waste! Writing up the process is important for two reasons:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这一过程中的最后一步可能是最重要的。你刚刚完成了所有的学习工作，做了笔记，从头编写了算法，并将其与可信的实现进行了比较。不要让所有这些好工作白费！撰写过程文档很重要，原因有两个：
- en: You’ll gain an even deeper understanding because you’re teaching others what
    you just learned.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将获得更深刻的理解，因为你正在教别人你刚刚学到的知识。
- en: You can showcase it to potential employers. It’s one thing to show that you
    can implement an algorithm from a machine learning library, but it’s even more
    impressive if you can implement it yourself from scratch.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以将其展示给潜在的雇主。展示你能够实现一个机器学习库中的算法是一回事，但如果你能够从头开始自己实现它，那就更令人印象深刻了。
- en: A great way to showcase your work is with a [GitHub Pages](https://pages.github.com/)
    portfolio.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 展示你工作的一个好方法是使用 [GitHub Pages](https://pages.github.com/) 作品集。
- en: '![GitHub pages](../Images/0caf7b335e22b399e5383a40fc1c2260.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![GitHub页面](../Images/0caf7b335e22b399e5383a40fc1c2260.png)'
- en: '**Conclusion**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Writing an algorithm from scratch can be a very rewarding experience. It’s a
    great way to gain a deeper understanding of the model, while building an impressive
    portfolio project at the same time.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始编写算法可以是非常有成就感的经历。这是深入理解模型的绝佳方式，同时还能构建一个令人印象深刻的项目组合。
- en: Remember to take it slow, and start with something simple. Most importantly,
    make sure to document and share your work.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 记得慢慢来，从简单的事情开始。最重要的是，确保记录和分享你的工作。
- en: '**Bio**: John Sullivan is the founder of the data science learning blog, DataOptimal.
    You can follow him on Twitter [@DataOptimal](https://twitter.com/dataoptimal).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**：约翰·沙利文是数据科学学习博客DataOptimal的创始人。你可以在Twitter上关注他 [@DataOptimal](https://twitter.com/dataoptimal)。'
- en: '**Related:**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Top /r/MachineLearning posts, August 2018: Everybody Dance Now; Stanford class
    Machine Learning cheat sheets; Academic Torrents for sharing enormous datasets](https://www.kdnuggets.com/2018/09/top-reddit-machine-learning-august.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2018年8月/r/MachineLearning的顶级帖子：大家快跳舞；斯坦福课堂机器学习备忘单；用于共享巨大数据集的学术数据](https://www.kdnuggets.com/2018/09/top-reddit-machine-learning-august.html)'
- en: '[Key Takeaways from KDD 2018: a Deconfounder, Machine Learning at Pinterest,
    Knowledge Graph](https://www.kdnuggets.com/2018/09/kdd-2018-key-takeaways.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDD 2018的关键要点：去混淆器、Pinterest的机器学习、知识图谱](https://www.kdnuggets.com/2018/09/kdd-2018-key-takeaways.html)'
- en: '[Everything You Need to Know About AutoML and Neural Architecture Search](https://www.kdnuggets.com/2018/09/everything-need-know-about-automl-neural-architecture-search.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于AutoML和神经网络架构搜索你需要知道的一切](https://www.kdnuggets.com/2018/09/everything-need-know-about-automl-neural-architecture-search.html)'
- en: More On This Topic
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标去……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学学习统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，解析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
