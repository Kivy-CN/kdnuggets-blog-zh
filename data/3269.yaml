- en: 'Machine Learning Exercises in Python: An Introductory Tutorial Series'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的机器学习练习：一个入门教程系列
- en: 原文：[https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html](https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html](https://www.kdnuggets.com/2017/07/machine-learning-exercises-python-introductory-tutorial-series.html)
- en: '**By John Wittenauer, Data Scientist.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：John Wittenauer，数据科学家。**'
- en: '**Editor''s note:** This tutorial series was started in September of 2014,
    with the 8 installments coming over the course of 2 years. I only mention this
    to put John''s first paragraph into context, and to assure readers that this informative
    series of tutorials, including all of its code, is as relevant and up-to-date
    today as it was at the time it was written. This is great material, both for anyone
    taking Andrew Ng''s MOOC and as a standalone resource.'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑说明：** 本系列教程始于2014年9月，共有8期，历时2年才全部发布。我提到这一点是为了将John的第一段文字置于背景中，并向读者保证，这个包含所有代码的有益教程系列，今天仍然和写作时一样相关和最新。这是很棒的材料，无论是对于参加Andrew
    Ng的MOOC课程的人，还是作为独立资源。'
- en: One of the pivotal moments in my professional development this year came when
    I discovered Coursera. I'd heard of the "MOOC" phenomenon but had not had the
    time to dive in and take a class. Earlier this year I finally pulled the trigger
    and signed up for Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml)
    class. I completed the whole thing from start to finish, including all of the
    programming exercises. The experience opened my eyes to the power of this type
    of education platform, and I've been hooked ever since.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 今年我职业发展的一个关键时刻是发现了Coursera。我曾听说过“MOOC”现象，但一直没有时间深入学习一门课程。今年早些时候，我终于决定注册了Andrew
    Ng的[机器学习](https://www.coursera.org/course/ml)课程。我从头到尾完成了整个课程，包括所有编程练习。这次经历让我看到了这种教育平台的力量，从此我就对它着了迷。
- en: '[![Python exercises](../Images/da01a56ad6eaf310800005885b464145.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python练习](../Images/da01a56ad6eaf310800005885b464145.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)'
- en: '**[Part 1 - Simple Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第1部分 - 简单线性回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)**'
- en: This blog post will be the first in a series covering the programming exercises
    from Andrew's class. One aspect of the course that I didn't particularly care
    for was the use of Octave for assignments. Although Octave/Matlab is a fine platform,
    most real-world "data science" is done in either R or Python (certainly there
    are other languages and tools being used, but these two are unquestionably at
    the top of the list). Since I'm trying to develop my Python skills, I decided
    to start working through the exercises from scratch in Python. The full source
    code is available at [my IPython repo on Github](https://github.com/jdwittenauer/ipython-notebooks).
    You'll also find the data used in these exercises and the original exercise PDFs
    in sub-folders off the root directory if you're interested.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇博客文章将是一个系列中的第一篇，涵盖了Andrew课程中的编程练习。我不太喜欢课程中的一个方面是作业使用了Octave。虽然Octave/Matlab是一个不错的平台，但大多数现实世界的“数据科学”工作是在R或Python中完成的（当然，还有其他语言和工具，但这两种无疑是列表中的佼佼者）。由于我正在努力提高我的Python技能，我决定从头开始用Python完成这些练习。完整的源代码可以在[我的Github上的IPython库](https://github.com/jdwittenauer/ipython-notebooks)中找到。如果你有兴趣，你还会在根目录的子文件夹中找到这些练习使用的数据和原始练习PDF。
- en: '**[Part 2 - Multivariate Linear Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-2/)**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第2部分 - 多元线性回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-2/)**'
- en: In [part 1](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)
    of my series on machine learning in Python, we covered the first part of exercise
    1 in Andrew Ng's [Machine Learning](https://www.coursera.org/course/ml) class.
    In this post we'll wrap up exercise 1 by completing part 2 of the exercise. If
    you recall, in part 1 we implemented linear regression to predict the profits
    of a new food truck based on the population of the city that the truck would be
    placed in. For part 2 we've got a new task - predict the price that a house will
    sell for. The difference this time around is we have more than one dependent variable.
    We're given both the size of the house in square feet, and the number of bedrooms
    in the house. Can we easily extend our previous code to handle multiple linear
    regression? Let's find out!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的系列文章中，[第1部分](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-1/)中，我们介绍了安德鲁·恩的[机器学习](https://www.coursera.org/course/ml)课程中练习1的第一部分。在这篇文章中，我们将通过完成练习的第二部分来结束练习1。如果你还记得，在第1部分中，我们实现了线性回归来预测一辆新食品卡车在城市中安置的位置的利润。第2部分我们有一个新的任务——预测一栋房子的出售价格。这次的不同之处在于我们有多个因变量。我们获得了房子的平方英尺面积和卧室数量。我们能否轻松地扩展我们之前的代码来处理多重线性回归？让我们来看看！
- en: '[![Python exercises](../Images/21e90d6ac7e5c412887121b27e05b535.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python练习](../Images/21e90d6ac7e5c412887121b27e05b535.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)'
- en: '**[Part 3 - Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第3部分 - 逻辑回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-3/)**'
- en: In part 2 of the series we wrapped up our implementation of multivariate linear
    regression using gradient descent and applied it to a simple housing prices data
    set. In this post we’re going to switch our objective from predicting a continuous
    value (regression) to classifying a result into two or more discrete buckets (classification)
    and apply it to a student admissions problem. Suppose that you are the administrator
    of a university department and you want to determine each applicant's chance of
    admission based on their results on two exams. You have historical data from previous
    applicants that you can use as a training set. For each training example, you
    have the applicant's scores on two exams and the admissions decision. To accomplish
    this, we're going to build a classification model that estimates the probability
    of admission based on the exam scores using a somewhat confusingly-named technique
    called logistic regression.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在系列的第2部分中，我们完成了多变量线性回归的实现，使用梯度下降并将其应用于一个简单的房价数据集。在这篇文章中，我们将目标从预测连续值（回归）转变为将结果分类到两个或更多离散类别（分类），并将其应用于学生招生问题。假设你是一个大学部门的管理员，你想根据申请人在两次考试中的成绩来确定每个申请人的录取机会。你拥有以前申请人的历史数据，可以用作训练集。对于每个训练样本，你都有申请人在两次考试中的分数和录取决定。为此，我们将构建一个分类模型，该模型使用一种名称有些混乱的技术——逻辑回归——来估计基于考试成绩的录取概率。
- en: '**[Part 4 - Multivariate Logistic Regression](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/)**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第4部分 - 多变量逻辑回归](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-4/)**'
- en: In part three of this series we implemented both simple and regularized logistic
    regression, completing our Python implementation of the second exercise from Andrew
    Ng's machine learning class. There's a limitation with our solution though - it
    only works for binary classification. In this post we'll extend our solution from
    the previous exercise to handle multi-class classification. In doing so, we'll
    cover the first half of exercise 3 and set ourselves up for the next big topic,
    neural networks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本系列的第三部分中，我们实现了简单逻辑回归和正则化逻辑回归，完成了安德鲁·恩的机器学习课程第二个练习的Python实现。不过我们的解决方案有一个限制——它仅适用于二分类。在这篇文章中，我们将扩展之前练习的解决方案，以处理多类别分类。在此过程中，我们将涵盖第3部分的前半部分，并为下一个重要主题——神经网络——做好准备。
- en: '**[Part 5 - Neural Networks](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/)**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第5部分 - 神经网络](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-5/)**'
- en: In part four we wrapped up our implementation of logistic regression by extending
    our solution to handle multi-class classification and testing it on the hand-written
    digits data set. Using just logistic regression we were able to hit a classification
    accuracy of about 97.5%, which is reasonably good but pretty much maxes out what
    we can achieve with a linear model. In this blog post we'll again tackle the hand-written
    digits data set, but this time using a feed-forward neural network with backpropagation.
    We'll implement un-regularized and regularized versions of the neural network
    cost function and compute gradients via the backpropagation algorithm. Finally,
    we'll run the algorithm through an optimizer and evaluate the performance of the
    network on the handwritten digits data set.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四部分，我们通过扩展解决方案以处理多类别分类，并在手写数字数据集上进行测试，完成了逻辑回归的实现。仅使用逻辑回归，我们就能达到约97.5%的分类准确率，这已经相当不错，但几乎达到了线性模型的极限。在这篇博客文章中，我们将再次处理手写数字数据集，但这次使用前馈神经网络和反向传播。我们将实现未正则化和正则化版本的神经网络成本函数，并通过反向传播算法计算梯度。最后，我们将通过优化器运行算法，并评估网络在手写数字数据集上的表现。
- en: '**[Part 6 - Support Vector Machines](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-6/)**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第6部分 - 支持向量机](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-6/)**'
- en: We're now hitting the home stretch of both the course content and this series
    of blog posts. In this exercise, we'll be using support vector machines (SVMs)
    to build a spam classifier. We'll start with SVMs on some simple 2D data sets
    to see how they work. Then we'll look at a set of email data and build a classifier
    on the processed emails using a SVM to determine if they are spam or not.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正接近课程内容和这一系列博客文章的最后阶段。在本次练习中，我们将使用支持向量机（SVM）来构建一个垃圾邮件分类器。我们将从一些简单的2D数据集上的SVM开始，以了解它们的工作原理。然后，我们将查看一组电子邮件数据，并使用SVM在处理过的电子邮件上构建分类器，以确定它们是否为垃圾邮件。
- en: '[![Python exercises](../Images/48e7ef6a1d68ca580cc9feb895fefe81.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Python练习](../Images/48e7ef6a1d68ca580cc9feb895fefe81.png)](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)'
- en: '**[Part 7 - K-Means Clustering & PCA](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第7部分 - K均值聚类与PCA](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-7/)**'
- en: 'We''re now down to the last two posts in this series! In this installment we''ll
    cover two fascinating topics: K-means clustering and principal component analysis
    (PCA). K-means and PCA are both examples of unsupervised learning techniques.
    Unsupervised learning problems do not have any label or target for us to learn
    from to make predictions, so unsupervised algorithms instead attempt to learn
    some interesting structure in the data itself. We''ll first implement K-means
    and see how it can be used it to compress an image. We''ll also experiment with
    PCA to find a low-dimensional representation of images of faces.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在进入了这一系列的最后两篇文章！在本篇中，我们将探讨两个迷人的主题：K均值聚类和主成分分析（PCA）。K均值和PCA都是无监督学习技术的例子。无监督学习问题没有任何标签或目标供我们学习以进行预测，因此无监督算法尝试从数据中学习一些有趣的结构。我们将首先实现K均值，并看看它如何用于压缩图像。我们还将使用PCA实验，以找到面部图像的低维表示。
- en: '**[Part 8 - Anomaly Detection & Recommendation](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第8部分 - 异常检测与推荐](http://www.johnwittenauer.net/machine-learning-exercises-in-python-part-8/)**'
- en: We've now reached the last post in this series! It's been an interesting journey.
    Andrew's class was really well-done and translating it all to python has been
    a fun experience. In this final installment we'll cover the last two topics in
    the course - anomaly detection and recommendation systems. We'll implement an
    anomaly detection algorithm using a Gaussian model and apply it to detect failing
    servers on a network. We'll also see how to build a recommendation system using
    collaborative filtering and apply it to a movie recommendations data set.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经达到了本系列的最后一篇文章！这是一次有趣的旅程。安德鲁的课程做得非常出色，将其全部翻译成Python是一次有趣的体验。在这一最后部分，我们将覆盖课程中的最后两个主题——异常检测和推荐系统。我们将使用高斯模型实现一个异常检测算法，并将其应用于检测网络上的故障服务器。我们还将学习如何使用协同过滤构建推荐系统，并将其应用于电影推荐数据集。
- en: '**Bio: [John Wittenauer](http://www.johnwittenauer.net/)** ([@jdwittenauer](https://twitter.com/jdwittenauer))
    is a data scientist, engineer, entrepreneur, and technology enthusiast.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[John Wittenauer](http://www.johnwittenauer.net/)** ([@jdwittenauer](https://twitter.com/jdwittenauer))
    是数据科学家、工程师、企业家和技术爱好者。'
- en: '**Related:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[7 Steps to Mastering Machine Learning With Python](/2015/11/seven-steps-machine-learning-python.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Python 掌握机器学习的 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)'
- en: '[Data Science for Newbies: An Introductory Tutorial Series for Software Engineers](/2017/05/data-science-tutorial-series-software-engineers.html)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学新手：为软件工程师准备的入门教程系列](/2017/05/data-science-tutorial-series-software-engineers.html)'
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习：完整而详细的概述](/2016/10/machine-learning-complete-detailed-overview.html)'
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者 Pandas 教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个 R 语言库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，找到目标后…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
