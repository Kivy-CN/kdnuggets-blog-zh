# 使用Python的人工神经网络优化及遗传算法

> 原文：[https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html](https://www.kdnuggets.com/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/03/artificial-neural-networks-optimization-genetic-algorithm-python.html?page=2#comments)![practical-computer-vision-applications-deepl-learning](../Images/2d2eba3f4293703bd96266e9008105f8.png)

在我LinkedIn个人资料中的之前一篇教程标题为“**使用NumPy实现人工神经网络和Fruits360图像数据集分类**”，链接为[https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad](https://www.linkedin.com/pulse/artificial-neural-network-implementation-using-numpy-fruits360-gad)，该教程中创建了一个人工神经网络（ANN）来分类Fruits360图像数据集中的4个类别。本教程中使用的源代码可以在我的GitHub页面找到，链接为：[https://github.com/ahmedfgad/NumPyANN](https://github.com/ahmedfgad/NumPyANN)

本教程的简要总结是提取特征向量（360个 bin 的色调通道直方图），并通过使用标准差的滤波技术将其减少到仅102个元素。然后，从头开始使用NumPy构建ANN。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT需求

* * *

人工神经网络（ANN）并未完全创建，只完成了前向传播的准备工作，但没有进行反向传播来更新网络权重。因此，准确率非常低，未能超过45%。解决这个问题的方法是使用优化技术来更新网络权重。本教程在之前的基础上扩展，使用遗传算法（GA）来优化网络权重。

值得一提的是，之前和本教程均基于我2018年的书籍，书名为“**Ahmed Fawzy Gad《使用CNN进行深度学习的实用计算机视觉应用》。2018年12月，Apress，978-1-4842-4167-7**”。该书在Springer的链接为：[https://springer.com/us/book/9781484241660](https://springer.com/us/book/9781484241660)。您可以在书中找到所有详细信息。

本教程中使用的源代码可在我的 GitHub 页面找到，链接为：[https://github.com/ahmedfgad/NeuralGenetic](https://github.com/ahmedfgad/NeuralGenetic)

### 了解更多关于遗传算法的信息

在开始本教程之前，建议阅读有关遗传算法如何工作及其在 Python 中的实现（使用 NumPy 从零开始）的内容，相关教程可以在以下链接找到：

+   遗传算法优化介绍

    +   [https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/](https://www.linkedin.com/pulse/introduction-optimization-genetic-algorithm-ahmed-gad/)

    +   [https://www.kdnuggets.com/2018/03/introduction-optimization-with-genetic-algorithm.html](/2018/03/introduction-optimization-with-genetic-algorithm.html)

    +   [https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b](https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b)

    +   [https://www.springer.com/us/book/9781484241660](https://www.springer.com/us/book/9781484241660)

+   遗传算法（GA）优化 - 步骤示例

    +   [https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example](https://www.slideshare.net/AhmedGadFCIT/genetic-algorithm-ga-optimization-stepbystep-example)

+   遗传算法在 Python 中的实现

    +   [https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/](https://www.linkedin.com/pulse/genetic-algorithm-implementation-python-ahmed-gad/)

    +   [/2018/07/genetic-algorithm-implementation-python.html](/2018/07/genetic-algorithm-implementation-python.html)

    +   [https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6](https://towardsdatascience.com/genetic-algorithm-implementation-in-python-5ab67bb124a6)

    +   [https://github.com/ahmedfgad/GeneticAlgorithmPython](https://github.com/ahmedfgad/GeneticAlgorithmPython)

在通过数值示例和 Python 实现理解了遗传算法的工作原理后，我们可以开始使用 GA 来优化 ANN，方法是更新其权重（参数）。

### 使用遗传算法与人工神经网络

遗传算法（GA）为给定问题生成多个解，并通过多代进化这些解。每个解包含所有可能有助于提升结果的参数。对于人工神经网络（ANN），各层中的权重有助于实现高准确度。因此，GA 中的单个解将包含 ANN 中的所有权重。根据前一个教程中讨论的网络结构及下图所示，ANN 有 4 层（1 输入层、2 隐藏层和 1 输出层）。任何一层中的权重都将是同一解的一部分。这样网络的单个解将包含总数为 102x150+150x60+60x4=24,540 的权重。如果种群中有 8 个解，每个解有 24,540 个参数，则整个种群的参数总数为 24,540x8=196,320。

![artificial-neural-network](../Images/d3ee8682d9b41f4e59bad5b79e948a75.png)

从上面的图中可以看出，网络的参数是以矩阵形式存在的，因为这使得 ANN 的计算更为简便。对于每一层，都有一个关联的权重矩阵。只需将输入矩阵乘以给定层的参数矩阵即可返回该层的输出。遗传算法中的染色体是 1D 向量，因此我们需要将权重矩阵转换为 1D 向量。

由于矩阵乘法是处理 ANN 的一个好选择，我们在使用 ANN 时仍将 ANN 参数表示为矩阵形式。因此，在处理 ANN 时使用矩阵形式，而在处理 GA 时使用向量形式。这使我们需要在矩阵与向量之间进行转换。下图总结了使用的步骤。

GA 与 ANN。此图被称为**主图**。

![figure-name](../Images/57ce8711167885fdd567d24b6587d7b0.png)

### 权重矩阵转为 1D 向量

人口中的每个解将有两种表示方式。首先是用于遗传算法（GA）的 1D 向量，其次是用于人工神经网络（ANN）的矩阵。由于有 3 个权重矩阵对应 3 层（2 层隐藏层 + 1 层输出层），因此会有 3 个向量，每个矩阵对应一个。由于 GA 中的解表示为单个 1D 向量，因此这 3 个 1D 向量将被连接成一个单一的 1D 向量。每个解将表示为长度为 24,540 的向量。接下来的 Python 代码创建了一个名为**mat_to_vector()**的函数，将种群中所有解的参数从矩阵转换为向量。

```py

def mat_to_vector(mat_pop_weights):
    pop_weights_vector = []
    for sol_idx in range(mat_pop_weights.shape[0]):
        curr_vector = []
        for layer_idx in range(mat_pop_weights.shape[1]):
            vector_weights = numpy.reshape(mat_pop_weights[sol_idx, layer_idx], newshape=(mat_pop_weights[sol_idx, layer_idx].size))
            curr_vector.extend(vector_weights)
        pop_weights_vector.append(curr_vector)
    return numpy.array(pop_weights_vector)

```

该函数接受一个表示所有解种群的参数，以便循环遍历并返回其向量表示。在函数开始时，创建一个空列表变量**pop_weights_vector**来存放结果（所有解的向量）。对于矩阵形式的每个解，有一个内部循环遍历其三个矩阵。对于每个矩阵，使用**numpy.reshape()**函数将其转换为向量，该函数接受输入矩阵和要重塑的输出大小。变量**curr_vector**接受单个解的所有向量。生成所有向量后，它们会被附加到**pop_weights_vector**变量中。

请注意，我们使用**numpy.extend()**函数来处理属于同一解的向量，而**numpy.append()**函数来处理属于不同解的向量。原因是**numpy.extend()**将同一解中的 3 个向量中的数字连接在一起。换句话说，对两个列表调用此函数会返回一个新的单一列表，其中包含两个列表中的数字。这适用于为每个解创建一个 1D 染色体。但**numpy.append()**将返回每个解的三个列表。对两个列表调用时，它会返回一个新的列表，并将其拆分为两个子列表。这不是我们的目标。最后，**mat_to_vector()**函数将种群解作为 NumPy 数组返回，以便后续操作。

### 实现 GA 步骤

在将所有解从矩阵转换为向量并拼接在一起后，我们准备好进行教程中讨论的 GA 步骤，该教程标题为**"基因算法优化介绍"**。这些步骤在**主要图**中展示，并在下一个图中进行了总结。

![genetic-algorithm-steps](../Images/6ab6d32f52e77336c2e67f65d9e0058b.png)

请记住，GA 使用适应度函数来返回每个解的适应度值。适应度值越高，解越好。在**父代选择**步骤中，最佳解会作为父代返回。

对于像 ANN 这样的分类器，常见的适应度函数之一是准确率。它是正确分类样本与样本总数之间的比率。准确率按照下述方程计算。每个解的分类准确率根据**主要图**中的步骤计算。

![Equation](../Images/e8768f7eb7deeb08cb4bd8ca72e54f27.png)

每个解的单个 1D 向量被转换回 3 个矩阵，每层一个矩阵（2 个隐藏层和 1 个输出层）。转换通过一个名为**vector_to_mat()**的函数进行。其定义见下方代码。

```py

def vector_to_mat(vector_pop_weights, mat_pop_weights):

    mat_weights = []

    for sol_idx in range(mat_pop_weights.shape[0]):

        start = 0

        end = 0

        for layer_idx in range(mat_pop_weights.shape[1]):

            end = end + mat_pop_weights[sol_idx, layer_idx].size

            curr_vector = vector_pop_weights[sol_idx, start:end]

            mat_layer_weights = numpy.reshape(curr_vector, newshape=(mat_pop_weights[sol_idx, layer_idx].shape))

            mat_weights.append(mat_layer_weights)

            start = end

    return numpy.reshape(mat_weights, newshape=mat_pop_weights.shape)

```

这会逆转之前的工作。但有一个重要问题。如果给定解的向量只是一个整体，我们如何将其拆分成三个不同的部分，每部分代表一个矩阵？输入层与隐藏层之间的第一个参数矩阵的大小是 102x150。转换为向量后，其长度将为 15,300。由于这是根据**mat_to_vector()**函数插入到**curr_vector**变量中的第一个向量，因此其索引从 0 开始，到 15,299 结束。**mat_pop_weights**被用作**vector_to_mat()**函数的参数，以了解每个矩阵的大小。我们不关注使用**mat_pop_weights**变量中的权重，仅使用矩阵的大小。

对于同一解中的第二个向量，它将是将150x60的矩阵转换后的结果。因此，向量长度为9,000。这样的向量插入到**curr_vector**变量中，紧接在之前长度为15,300的向量之前。因此，它将从索引15,300开始，到索引15,300+9,000-1=24,299结束。-1的原因是Python从0开始索引。最后，从60x4的参数矩阵创建的向量长度为240。因为它在长度为9,000的前一个向量之后添加到**curr_vector**变量中，所以它的起始索引是在其之后的，即起始索引为24,300，结束索引为24,300+240-1=24,539。因此，我们可以成功地将向量恢复到原始的3个矩阵中。

返回的矩阵用于预测所用数据集中1,962个样本的类别标签，以计算准确性。这是通过**predict_outputs()**和**fitness()**两个函数来完成的，具体代码如下。

```py

def predict_outputs(weights_mat, data_inputs, data_outputs, activation="relu"):

    predictions = numpy.zeros(shape=(data_inputs.shape[0]))

    for sample_idx in range(data_inputs.shape[0]):

        r1 = data_inputs[sample_idx, :]

        for curr_weights in weights_mat:

            r1 = numpy.matmul(a=r1, b=curr_weights)

            if activation == "relu":

                r1 = relu(r1)

            elif activation == "sigmoid":

                r1 = sigmoid(r1)

        predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]

        predictions[sample_idx] = predicted_label

    correct_predictions = numpy.where(predictions == data_outputs)[0].size

    accuracy = (correct_predictions/data_outputs.size)*100

    return accuracy, predictions

def fitness(weights_mat, data_inputs, data_outputs, activation="relu"):

    accuracy = numpy.empty(shape=(weights_mat.shape[0]))

    for sol_idx in range(weights_mat.shape[0]):

        curr_sol_mat = weights_mat[sol_idx, :]

        accuracy[sol_idx], _ = predict_outputs(curr_sol_mat, data_inputs, data_outputs, activation=activation)

    return accuracy

```

**predict_outputs()**函数接受单个解的权重、输入和训练数据的输出，以及一个可选参数来指定使用哪个激活函数。它仅返回一个解的准确性，而不是种群中的所有解。为了返回种群中所有解的适应度值（即准确性），**fitness()**函数遍历每个解，将其传递给**predict_outputs()**函数，将所有解的准确性存储到**accuracy**数组中，最后返回该数组。

计算所有解的适应度值（即准确性）后，主图中的GA其余步骤按之前的方式应用。根据其准确性选择最佳父代，进入交配池。然后应用变异和交叉变体以产生后代。新一代的种群通过后代和父代一起创建。这些步骤在多代中重复进行。

### 更多相关话题

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [构建一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [是什么让Python成为初创企业理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [成为出色数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)
