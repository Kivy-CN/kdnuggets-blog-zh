- en: An Intuitive Explanation of Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的直观解释
- en: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)
- en: '**By [Ujjwal Karn](https://ujjwalkarn.me/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Ujjwal Karn](https://ujjwalkarn.me/) 编写。**'
- en: '**What are Convolutional Neural Networks and why are they important?**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络是什么，它们为何重要？**'
- en: Convolutional Neural Networks (**ConvNets** or **CNNs**) are a category of Neural
    Networks that have proven very effective in areas such as image recognition and
    classification. ConvNets have been successful in identifying faces, objects and
    traffic signs apart from powering vision in robots and self driving cars.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（**ConvNets** 或 **CNNs**）是一类神经网络，在图像识别和分类等领域已被证明非常有效。ConvNets 在识别面孔、物体和交通标志方面取得了成功，同时也为机器人和自动驾驶汽车提供了视觉支持。
- en: '![convnets use.png](../Images/7748ce554a355790e730098db0a86116.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![convnets use.png](../Images/7748ce554a355790e730098db0a86116.png)'
- en: '**Figure 1: Source [1]**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1：来源 [1]**'
- en: In **Figure 1** above, a ConvNet is able to recognize scenes and the system
    is able to suggest relevant tags such as ‘bridge’, ‘railway’ and ‘tennis’ while
    **Figure 2** shows an example of ConvNets being used for recognizing everyday
    objects, humans and animals. Lately, ConvNets have been effective in several Natural
    Language Processing tasks (such as sentence classification) as well.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **图 1** 中，ConvNet 能够识别场景，系统能够建议相关的标签，例如“桥梁”、“铁路”和“网球”，而 **图 2** 显示了 ConvNets
    被用于识别日常物品、人类和动物的示例。最近，ConvNets 在一些自然语言处理任务（如句子分类）中也表现出色。
- en: '![Screen Shot 2016-08-07 at 4.17.11 PM.png](../Images/ccc07aae6c66f4bb30726c2997a95724.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 4.17.11 PM.png](../Images/ccc07aae6c66f4bb30726c2997a95724.png)'
- en: 'Figure 2: Source [2]'
  id: totrans-9
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2：来源 [2]
- en: ConvNets, therefore, are an important tool for most machine learning practitioners
    today. However, understanding ConvNets and learning to use them for the first
    time can sometimes be an intimidating experience. The primary purpose of this
    blog post is to develop an understanding of how Convolutional Neural Networks
    work on images.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，ConvNets 是今天大多数机器学习从业者的重要工具。然而，理解 ConvNets 并第一次学习使用它们有时可能会让人感到望而却步。本文的主要目的是帮助理解卷积神经网络如何在图像上工作。
- en: If you are new to neural networks in general, I would recommend reading [this
    short tutorial on Multi Layer Perceptrons](http://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/) to
    get an idea about how they work, before proceeding. Multi Layer Perceptrons are
    referred to as “Fully Connected Layers” in this post.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对神经网络不太熟悉，我建议你先阅读 [这篇关于多层感知机的简短教程](http://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)
    来了解它们的工作原理，然后再继续。多层感知机在本文中被称为“全连接层”。
- en: The LeNet Architecture (1990s)
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LeNet 架构（1990 年代）
- en: LeNet was one of the very first convolutional neural networks which helped propel
    the field of Deep Learning. This pioneering work by Yann LeCun was named [LeNet5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) after
    many previous successful iterations since the year 1988 [3]. At that time the
    LeNet architecture was used mainly for character recognition tasks such as reading
    zip codes, digits, etc.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet 是最早的一批卷积神经网络之一，推动了深度学习领域的发展。这项由 Yann LeCun 进行的开创性工作被命名为 [LeNet5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)，这是自
    1988 年以来许多成功迭代的成果。当时，LeNet 架构主要用于字符识别任务，如读取邮政编码、数字等。
- en: Below, we will develop an intuition of how the LeNet architecture learns to
    recognize images. There have been several new architectures proposed in the recent
    years which are improvements over the LeNet, but they all use the main concepts
    from the LeNet and relatively easier to understand if you have a clear understanding
    of the former.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将直观地了解 LeNet 架构如何学习识别图像。近年来提出了几种新的架构，它们在 LeNet 的基础上进行了改进，但它们都使用了 LeNet
    的主要概念，如果你对前者有清晰的理解，它们相对更容易理解。
- en: '![Screen Shot 2016-08-07 at 4.59.29 PM.png](../Images/a8fc34dea1cebd5aeb8736caf96e53fe.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-07 at 4.59.29 PM.png](../Images/a8fc34dea1cebd5aeb8736caf96e53fe.png)'
- en: 'Figure 3: A simple ConvNet. Source [5]'
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3：一个简单的 ConvNet。来源 [5]
- en: 'The Convolutional Neural Network in **Figure 3 **is similar in architecture
    to the original LeNet and classifies an input image into four categories: dog,
    cat, boat or bird (the original LeNet was used mainly for character recognition
    tasks). As evident from the figure above, on receiving a boat image as input,
    the network correctly assigns the highest probability for boat (0.94) among all
    four categories. The sum of all probabilities in the output layer should be one
    (explained later in this post).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3**中的卷积神经网络在架构上类似于原始的LeNet，并将输入图像分类为四类：狗、猫、船或鸟（原始LeNet主要用于字符识别任务）。从上图可以看出，当输入为船图像时，网络在所有四个类别中正确地分配了船（0.94）的最高概率。输出层中所有概率的总和应为1（在本帖后面解释）。'
- en: 'There are four main operations in the ConvNet shown in **Figure 3** above:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 上面**图 3**中的ConvNet有四个主要操作：
- en: Convolution
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积
- en: Non Linearity (ReLU)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非线性（ReLU）
- en: Pooling or Sub Sampling
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 池化或子采样
- en: Classification (Fully Connected Layer)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类（全连接层）
- en: These operations are the basic building blocks of *every* Convolutional Neural
    Network, so understanding how these work is an important step to developing a
    sound understanding of ConvNets. We will try to understand the intuition behind
    each of these operations below.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些操作是*每个*卷积神经网络的基本构建块，因此理解这些操作如何工作是发展对ConvNets良好理解的重要步骤。我们将尝试理解下面每个操作的直觉。
- en: Images are a matrix of pixel values
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 图像是一个像素值矩阵
- en: Essentially, every image can be represented as a matrix of pixel values.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，每个图像都可以表示为像素值矩阵。
- en: '![8-gif.gif](../Images/95a0b5d309f5a500e50c29884bf02f1b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![8-gif.gif](../Images/95a0b5d309f5a500e50c29884bf02f1b.png)'
- en: 'Figure 4: Every image is a matrix of pixel values. Source [6]'
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4：每个图像都是一个像素值矩阵。来源 [6]
- en: '[Channel](https://en.wikipedia.org/wiki/Channel_(digital_image)) is a conventional
    term used to refer to a certain component of an image. An image from a standard
    digital camera will have three channels – red, green and blue – you can imagine
    those as three 2d-matrices stacked over each other (one for each color), each
    having pixel values in the range 0 to 255.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[通道](https://en.wikipedia.org/wiki/Channel_(digital_image))是一个传统术语，用来指代图像的某个组件。标准数字相机拍摄的图像将有三个通道——红色、绿色和蓝色——你可以将这些想象为三个叠在一起的二维矩阵（每种颜色一个），每个矩阵的像素值范围从0到255。'
- en: A [grayscale](https://en.wikipedia.org/wiki/Grayscale "Grayscale") image, on
    the other hand, has just one channel. For the purpose of this post, we will only
    consider grayscale images, so we will have a single 2d matrix representing an
    image. The value of each pixel in the matrix will range from 0 to 255 – zero indicating
    black and 255 indicating white.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[灰度](https://en.wikipedia.org/wiki/Grayscale "Grayscale")图像则只有一个通道。为了本帖的目的，我们将只考虑灰度图像，因此我们将只有一个二维矩阵来表示图像。矩阵中每个像素的值范围从0到255——0表示黑色，255表示白色。'
- en: The Convolution Step
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积步骤
- en: ConvNets derive their name from the [“convolution” operator](https://en.wikipedia.org/wiki/Convolution).
    The primary purpose of Convolution in case of a ConvNet is to extract features
    from the input image. Convolution preserves the spatial relationship between pixels
    by learning image features using small squares of input data. We will not go into
    the mathematical details of Convolution here, but will try to understand how it
    works over images.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ConvNets的名称源自[“卷积”运算符](https://en.wikipedia.org/wiki/Convolution)。在ConvNet的情况下，卷积的主要目的是从输入图像中提取特征。卷积通过使用输入数据的小方块来学习图像特征，从而保持像素之间的空间关系。我们不会在这里深入卷积的数学细节，但会尝试理解它如何在图像上工作。
- en: 'As we discussed above, every image can be considered as a matrix of pixel values.
    Consider a 5 x 5 image whose pixel values are only 0 and 1 (note that for a grayscale
    image, pixel values range from 0 to 255, the green matrix below is a special case
    where pixel values are only 0 and 1):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，每个图像可以视为一个像素值矩阵。考虑一个5 x 5图像，其像素值仅为0和1（注意对于灰度图像，像素值范围从0到255，下面的绿色矩阵是一个特例，其中像素值仅为0和1）：
- en: '![Screen Shot 2016-07-24 at 11.25.13 PM](../Images/113af8d18204fc9f1acc99c287a0da88.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-07-24 at 11.25.13 PM](../Images/113af8d18204fc9f1acc99c287a0da88.png)'
- en: 'Also, consider another 3 x 3 matrix as shown below:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，考虑下面的另一个3 x 3矩阵：
- en: '![Screen Shot 2016-07-24 at 11.25.24 PM](../Images/b7821d30b80d65701e63e230f851dff1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-07-24 at 11.25.24 PM](../Images/b7821d30b80d65701e63e230f851dff1.png)'
- en: Then, the Convolution of the 5 x 5 image and the 3 x 3 matrix can be computed
    as shown in the animation in **Figure 5** below:![Convolution_schematic](../Images/1a23e603601fbcb937a792689e209f91.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，5 x 5图像和3 x 3矩阵的卷积可以通过下图中的动画计算得到：![Convolution_schematic](../Images/1a23e603601fbcb937a792689e209f91.png)
- en: Figure 5: The Convolution operation. The output matrix is called Convolved Feature
    or **Feature Map. Source [7]**
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5：卷积操作。输出矩阵称为卷积特征或**特征图**。来源 [7]
- en: Take a moment to understand how the computation above is being done. We slide
    the orange matrix over our original image (green) by 1 pixel (also called ‘stride’)
    and for every position, we compute element wise multiplication (between the two
    matrices) and add the multiplication outputs to get the final integer which forms
    a single element of the output matrix (pink). Note that the 3×3 matrix “sees”
    only a part of the input image in each stride.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 花一点时间理解上面的计算过程。我们将橙色矩阵在原始图像（绿色）上滑动1像素（也称为‘步幅’），对于每个位置，我们进行元素逐一相乘（两个矩阵之间），然后将乘法输出相加以得到最终整数，这个整数形成输出矩阵（粉色）的一个元素。请注意，3×3矩阵在每一步只“看到”输入图像的一部分。
- en: In CNN terminology, the 3×3 matrix is called a ‘**filter**‘ or ‘kernel’ or ‘feature
    detector’ and the matrix formed by sliding the filter over the image and computing
    the dot product is called the ‘Convolved Feature’ or ‘Activation Map’ or the ‘**Feature
    Map**‘. It is important to note that filters acts as feature detectors from the
    original input image.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在CNN术语中，3×3矩阵称为‘**滤波器**’或‘内核’或‘特征检测器’，通过在图像上滑动滤波器并计算点积形成的矩阵称为‘卷积特征’或‘激活图’或‘**特征图**’。重要的是要注意，滤波器作为特征检测器从原始输入图像中提取特征。
- en: 'It is evident from the animation above that different values of the filter
    matrix will produce different Feature Maps for the same input image. As an example,
    consider the following input image:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的动画可以明显看出，滤波器矩阵的不同值会为相同的输入图像生成不同的特征图。例如，考虑以下输入图像：
- en: '![111.png](../Images/fdd2207625369b1488033a9ce74ac160.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![111.png](../Images/fdd2207625369b1488033a9ce74ac160.png)'
- en: In the table below, we can see the effects of convolution of the above image
    with different filters. As shown, we can perform operations such as Edge Detection,
    Sharpen and Blur just by changing the numeric values of our filter matrix before
    the convolution operation [8] – this means that different filters can detect different
    features from an image, for example edges, curves etc. More such examples are
    available in Section 8.2.4 [here](http://docs.gimp.org/en/plug-in-convmatrix.html).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们可以看到对上述图像应用不同滤波器的卷积效果。如图所示，我们可以通过在卷积操作之前更改滤波器矩阵的数值来执行边缘检测、锐化和模糊等操作[8]——这意味着不同的滤波器可以检测图像中的不同特征，例如边缘、曲线等。更多示例见第8.2.4节[这里](http://docs.gimp.org/en/plug-in-convmatrix.html)。
- en: '![Screen Shot 2016-08-05 at 11.03.00 PM.png](../Images/5ba80b2c13837d95579808846e8af58d.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![Screen Shot 2016-08-05 at 11.03.00 PM.png](../Images/5ba80b2c13837d95579808846e8af58d.png)'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织IT'
- en: '* * *'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多相关主题
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[直观解释协作过滤](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络的全面指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 PyTorch 构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：直观的方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
