- en: Demystifying Decision Trees for the Real World
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Decision Trees for Real World](../Images/ea4f96c2e9a77ccb1faac326d2e08a98.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees break down difficult decisions into straightforward, easily followed
    phases, thereby functioning like human brains.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In data science, these strong instruments are extensively applied to assist
    in data analysis and the direction of decision-making.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will go over how decision trees operate, give real-world
    examples, and give some tips for enhancing them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Structure of Decision Trees**'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fundamentally, decision trees are simple and clear tools. They break down difficult
    options into simpler, sequential choices, therefore reflecting human decision-making.
    Let us now explore the main elements forming a decision tree.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '**Nodes, Branches, and Leaves**'
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Three basic components define a decision tree: leaves, branches, and nodes.
    Every one of these is absolutely essential for the process of making decisions.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'Nodes: They are decision points whereby the tree decides depending on the input
    data. When representing all the data, the root node is the starting point.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Branches: They relate the result of a decision and link nodes. Every branch
    matches a potential result or value of a decision node.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Leaves: The decision tree''s ends are leaves, sometimes known as leaf nodes.
    Each leaf node offers a certain consequence or label; they reflect the last choice
    or classification.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conceptual Example**'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Suppose you are choosing whether to venture outside depending on the temperature.
    "Is it raining?" the root node would ask. If so, you might find a branch headed
    toward "Take an umbrella." This should not be the case; another branch could say,
    "Wear sunglasses."
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: These structures make decision trees easy to interpret and visualize, so they
    are popular in various fields.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '**Real-World Example: The Loan Approval Adventure**'
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Picture this: You''re a wizard at Gringotts Bank, deciding who gets a loan
    for their new broomstick.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: 'Root Node: "Is their credit score magical?"'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If yes → Branch to "Approve faster than you can say Quidditch!"
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If no → Branch to "Check their goblin gold reserves."
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If high →, "Approve, but keep an eye on them."
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If low → "Deny faster than a Nimbus 2000."
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here is the output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![Structure of Decision Trees in Machine Learning](../Images/3e9b93689e0ded4344ef485f406e1e7c.png) When
    you run this spell, you''ll see a tree appear! It''s like the Marauder''s Map
    of loan approvals:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: The root node splits on Credit_Score
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it's ≤ 675, we venture left
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If it's > 675, we journey right
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The leaves show our final decisions: "Yes" for approved, "No" for denied'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voila! You've just created a decision-making crystal ball!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'Mind Bender: If your life were a decision tree, what would be the root node
    question? "Did I have coffee this morning?" might lead to some interesting branches!'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '**Decision Trees: Behind the Branches**'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decision trees function similarly to a flowchart or tree structure, with a succession
    of decision points. They begin by dividing a dataset into smaller pieces, and
    then they build a decision tree to go along with it. The way these trees deal
    with data splitting and different variables is something we should look at.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '**Splitting Criteria: Gini Impurity and Information Gain**'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Choosing the best quality to divide the data is the primary goal of building
    a decision tree. It is possible to determine this procedure using criteria provided
    by Information Gain and Gini Impurity.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'Gini Impurity: Picture yourself in the midst of a game of guessing. How often
    would you be mistaken if you randomly selected a label? That''s what Gini Impurity
    measures. We can make better guesses and have a happier tree with a lower Gini
    coefficient.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Information gain: The "aha!" moment in a mystery story is what you may compare
    this to. How much a hint (attribute) aids in solving the case is measured by it.
    A bigger "aha!" means more gain, which means an ecstatic tree!'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To predict whether a customer would buy a product from your dataset, you can
    start with basic demographic information like age, income, and purchasing history.
    The approach takes all of these into account and finds the one that separates
    the buyers from the others.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Handling Continuous and Categorical Data**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are no types of info that our tree detectives can't look into.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: For features that are easy to change, like age or income, the tree sets up a
    speed trap. "Anyone over 30, this way!"
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to categorical data, like gender or product type, it's more of
    a lineup. "Smartphones stand on the left; laptops on the right!"
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '**Real-World Cold Case: The Customer Purchase Predictor**'
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To better understand how decision trees work, let''s look at a real-life example:
    using a customer''s age and income to guess whether they will buy a product.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: To guess what people will buy, we'll make a simple collection and a decision
    tree.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: A description of the code
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: We import libraries like pandas to work with the data, DecisionTreeClassifier
    from scikit-learn to build the tree, and matplotlib to show the results.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Create Dataset: Age, income, and buying status are used to make a sample dataset.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Get Features and Goals Ready: The goal variable (Purchased) and features (Age,
    Income) are set up.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Train the Model: The information is used to set up and train the decision tree
    classifier.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型：利用这些信息设置和训练决策树分类器。
- en: 'See the Tree: Finally, we draw the decision tree so that we can see how choices
    are made.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看决策树：最后，我们绘制决策树，以便观察决策过程。
- en: Here is the code.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码。
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here is the output.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Behind the Branches of Decision Trees in Machine Learning](../Images/7f5d804f75257f96f06d7adfdd01c418.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习中的决策树背后的秘密](../Images/7f5d804f75257f96f06d7adfdd01c418.png)'
- en: The final decision tree will show how the tree splits up based on age and income
    to figure out if a customer is likely to buy a product. Each node is a decision
    point, and the branches show different outcomes. The final decision is shown by
    the leaf nodes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最终决策树将展示如何根据年龄和收入来划分树，以确定客户是否可能购买某个产品。每个节点是一个决策点，分支显示不同的结果。最终决策由叶节点展示。
- en: Now, let's look at how interviews can be used in the real world!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看面试在现实世界中的应用吧！
- en: '**Real-World Applications**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**现实世界应用**'
- en: '![Real World Applications for Decision Trees](../Images/b89c0285925b1a8b2b25a340d3d31864.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![决策树的现实世界应用](../Images/b89c0285925b1a8b2b25a340d3d31864.png)'
- en: This project is designed as a take-home assignment for Meta (Facebook) data
    science positions. The objective is to build a classification algorithm that predicts
    whether a movie on Rotten Tomatoes is labeled 'Rotten', 'Fresh', or 'Certified
    Fresh.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目被设计为Meta（Facebook）数据科学职位的家庭作业，目标是构建一个分类算法，预测Rotten Tomatoes上的电影是否标记为“烂片”、“新鲜”或“认证新鲜”。
- en: 'Here is the link to this project: [https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction](https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该项目的链接：[https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction](https://platform.stratascratch.com/data-projects/rotten-tomatoes-movies-rating-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)
- en: Now, let’s break down the solution into codeable steps.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将解决方案拆解为可编码的步骤。
- en: '**Step-by-Step Solution**'
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**逐步解决方案**'
- en: 'Data Preparation: We will merge the two datasets on the rotten_tomatoes_link
    column. This will give us a comprehensive dataset with movie information and critic
    reviews.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备：我们将根据rotten_tomatoes_link列合并两个数据集。这将为我们提供一个包含电影信息和评论的综合数据集。
- en: 'Feature Selection and Engineering: We will select relevant features and perform
    necessary transformations. This includes converting categorical variables to numerical
    ones, handling missing values, and normalizing the feature values.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征选择与工程：我们将选择相关特征并执行必要的转换，包括将类别变量转换为数值变量、处理缺失值和标准化特征值。
- en: 'Model Training: We will train a decision tree classifier on the processed dataset
    and use cross-validation to evaluate the model''s robust performance.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型训练：我们将对处理后的数据集训练决策树分类器，并使用交叉验证评估模型的稳定性。
- en: 'Evaluation: Finally, we will evaluate the model''s performance using metrics
    like accuracy, precision, recall, and F1-score.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估：最后，我们将使用准确率、精确率、召回率和F1分数等指标来评估模型的性能。
- en: Here is the code.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码。
- en: '[PRE2]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here is the output.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Real World Applications for Decision Trees](../Images/deacf1b18f3680ce5099414ce3641d35.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![决策树的现实世界应用](../Images/deacf1b18f3680ce5099414ce3641d35.png)'
- en: The model shows high accuracy and F1 scores across the classes, indicating good
    performance. Let’s see the key takeaways.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在各类中显示出高准确率和F1分数，表明性能良好。让我们来看一下关键要点。
- en: Key Takeaways
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要点
- en: Feature selection is crucial for model performance. Content rating genres directors'
    runtime and ratings proved valuable predictors.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征选择对模型性能至关重要。内容评分、类型、导演、时长和评分被证明是有价值的预测因子。
- en: A decision tree classifier effectively captures complex relationships in movie
    data.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树分类器有效捕捉了电影数据中的复杂关系。
- en: Cross-validation ensures model reliability across different data subsets.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交叉验证确保模型在不同数据子集上的可靠性。
- en: High performance in the "Certified-Fresh" class warrants further investigation
    into potential class imbalance.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“认证新鲜”类别中表现出色的情况下，值得进一步调查可能的类别不平衡。
- en: The model shows promise for real-world application in predicting movie ratings
    and enhancing user experience on platforms like Rotten Tomatoes.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型在预测电影评分和提升如Rotten Tomatoes平台的用户体验方面显示出良好的前景。
- en: '**Enhancing Decision Trees: Turning Your Sapling into a Mighty Oak**'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**提升决策树：将你的幼苗成长为参天大树**'
- en: So, you've grown your first decision tree. Impressive! But why stop there? Let's
    turn that sapling into a forest giant that would make even Groot jealous. Ready
    to beef up your tree? Let's dive in!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经成长了第一棵决策树。令人印象深刻！但为何止步于此？让我们将这棵幼苗变成一棵森林巨人，让Groot也感到嫉妒。准备好增强你的树了吗？让我们深入了解吧！
- en: '**Pruning Techniques**'
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**剪枝技术**'
- en: Pruning is a method used to cut a decision tree's size by eliminating parts
    that have minimal ability in target variable prediction. This helps to reduce
    overfitting in particular.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 剪枝是一种通过去除对目标变量预测能力较小的部分来缩减决策树大小的方法。这有助于特别减少过拟合。
- en: 'Pre-pruning: Often referred to as early stopping, this entails stopping the
    tree''s growth right away. Before training, the model is specified parameters,
    including maximum depth (max_depth), minimum samples required to split a node
    (min_samples_split), and minimum samples required at a leaf node (min_samples_leaf).
    This keeps the tree from growing overly complicated.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前剪枝：通常称为早期停止，这涉及立即停止树的生长。在训练之前，模型会被指定参数，包括最大深度（max_depth）、分裂节点所需的最小样本数（min_samples_split）和叶节点所需的最小样本数（min_samples_leaf）。这防止了树的过度复杂化。
- en: 'Post-pruning: This method grows the tree to its maximum depth and removes nodes
    that don''t offer much power. Though more computationally taxing than pre-pruning,
    post-pruning can be more successful.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后剪枝：这种方法将树生长到最大深度，然后移除那些贡献不大的节点。虽然计算成本比前剪枝更高，但后剪枝可能更有效。
- en: '**Ensemble Methods**'
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**集成方法**'
- en: Ensemble techniques combine several models to generate performance above that
    of any one model. Two primary forms of ensemble techniques applied with decision
    trees are bagging and boosting.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 集成技术将多个模型结合以产生超过单一模型的性能。应用于决策树的两种主要集成技术是装袋法和提升法。
- en: 'Bagging (Bootstrap Aggregating): This method trains several decision trees
    on several subsets of the data (generated by sampling with replacement) and then
    averages their predictions. One often used bagging technique is Random Forest.
    It lessens variance and aids in overfit prevention. Check out "[Decision Tree
    and Random Forest Algorithm](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)"
    to deeply address everything related to the Decision Tree algorithm and its extension
    “Random Forest algorithm”.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 装袋法（Bootstrap Aggregating）：该方法在数据的多个子集（通过有放回抽样生成）上训练多个决策树，然后对它们的预测结果取平均。一个常用的装袋技术是随机森林。它减少了方差并有助于防止过拟合。查看
    "[决策树与随机森林算法](https://www.stratascratch.com/blog/decision-tree-and-random-forest-algorithm-explained/?utm_source=blog&utm_medium=click&utm_campaign=kdn+decision+trees+for+real+world)"
    深入了解决策树算法及其扩展“随机森林算法”相关的一切。
- en: 'Boosting: Boosting creates trees one after the other as each one seeks to fix
    the mistakes of the next one. Boosting techniques abound in algorithms including
    AdaBoost and Gradient Boosting. By emphasizing challenging-to-predict examples,
    these algorithms sometimes provide more exact models.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升：提升方法依次创建树，每棵树都试图修正下一棵树的错误。提升技术在算法中包括AdaBoost和梯度提升。这些算法通过强调难以预测的示例，有时能提供更精确的模型。
- en: '**Hyperparameter Tuning**'
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**超参数调优**'
- en: Hyperparameter tuning is the process of determining the optimal hyperparameter
    set for a decision tree model to raise its performance. Using methods like Grid
    Search or Random Search, whereby several combinations of hyperparameters are assessed
    to identify the best configuration, this can be accomplished.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优是确定决策树模型的最佳超参数集合以提升其性能的过程。可以通过使用如网格搜索或随机搜索等方法，评估多个超参数组合以找出最佳配置。
- en: '**Conclusion**'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: In this article, we’ve discussed the structure, working mechanism, real-world
    applications, and methods for enhancing decision tree performance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了决策树的结构、工作机制、实际应用以及提升决策树性能的方法。
- en: Practicing decision trees is crucial to mastering their use and understanding
    their nuances. Working on real-world data projects can also provide valuable experience
    and improve problem-solving skills.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 练习决策树对于掌握其使用和理解其细微差别至关重要。处理实际数据项目也可以提供宝贵的经验，提升解决问题的技能。
- en: '[](https://twitter.com/StrataScratch)****[Nate Rosidi](https://twitter.com/StrataScratch)****
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of StrataScratch, a platform helping data scientists
    prepare for their interviews with real interview questions from top companies.
    Nate writes on the latest trends in the career market, gives interview advice,
    shares data science projects, and covers everything SQL.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://twitter.com/StrataScratch)****[内特·罗西迪](https://twitter.com/StrataScratch)****
    是一名数据科学家，专注于产品策略。他还是一位兼职教授，教授分析学，并且是 StrataScratch 的创始人，该平台帮助数据科学家通过来自顶级公司的真实面试问题准备面试。内特撰写关于职业市场的最新趋势，提供面试建议，分享数据科学项目，并涵盖所有
    SQL 相关内容。'
- en: More On This Topic
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Machine Learning from Scratch: Decision Trees](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从零开始的机器学习：决策树](https://www.kdnuggets.com/2022/11/machine-learning-scratch-decision-trees.html)'
- en: '[Decision Trees vs Random Forests, Explained](https://www.kdnuggets.com/2022/08/decision-trees-random-forests-explained.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[决策树与随机森林，解释说明](https://www.kdnuggets.com/2022/08/decision-trees-random-forests-explained.html)'
- en: '[Generalized and Scalable Optimal Sparse Decision Trees(GOSDT)](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通用可扩展的最优稀疏决策树(GOSDT)](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)'
- en: '[Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的人工智能：10个 Python 库帮助解密模型决策](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)'
- en: '[Demystifying Bad Science](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解密糟糕的科学](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
- en: '[Demystifying Machine Learning](https://www.kdnuggets.com/demystifying-machine-learning)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解密机器学习](https://www.kdnuggets.com/demystifying-machine-learning)'
