# 使用K-Means聚类进行图像分割介绍

> 原文：[https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html](https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html)

[评论](#comments)![图](../Images/9b0a0b8be42317acaed68988ff8a24df.png)

图片来源：[datastuff.tech](http://www.datastuff.tech/machine-learning/k-means-clustering-unsupervised-learning-for-recommender-systems/)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业道路。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT

* * *

图像分割是图像处理中的一个重要步骤，在我们想要分析图像内部内容时几乎无处不在。例如，如果我们希望找出室内图像中是否有椅子或人，我们可能需要图像分割来分离对象，并逐个分析每个对象以检查其是什么。图像分割通常作为模式识别、特征提取和图像压缩的预处理步骤。

图像分割是将图像分类为不同组的过程。在图像分割领域，已经进行过许多研究。不同的方法中，最流行的方法之一是**K-Means 聚类算法**。

所以在这篇文章中，我们将探讨一种读取图像并对图像的不同区域进行聚类的方法。但在开始之前，我们首先讨论一下：

1.  图像分割

1.  图像分割的工作原理

1.  K-Means 聚类机器学习算法

1.  将K-Means聚类算法与图像分割结合。

1.  Canny边缘检测

### 图像分割

![图](../Images/f0e25c04eae3b9a998f05ddd691d3292.png)

图片来源：[omicsonline.org](https://www.omicsonline.org/open-access/image-segmentation-by-using-linear-spectral-clustering-2167-0919-1000143.php?aid=81482&view=mobile)

图像分割是将数字图像分割为多个不同区域的过程，每个区域包含具有相似属性的像素（像素集，也称为超像素）。

> 图像分割的目标是将图像的表示形式转换为更有意义、更易于分析的形式。

图像分割通常用于定位图像中的对象和[边界](https://en.wikipedia.org/wiki/Boundary_tracing)（线条、曲线等）。更确切地说，图像分割是将标签分配给图像中每个像素的过程，以便具有相同标签的像素共享某些特征。

当然，常见的问题是：

**为什么图像分割如此重要？**

以自主车辆为例，它们需要摄像头、雷达和激光等传感器输入设备，以使汽车能够感知周围的世界，创建数字地图。如果没有目标检测，自主驾驶甚至不可能，而目标检测本身涉及图像分类/分割。

![图示](../Images/c5478641b8db1523e1c1f3f781d15fee.png)

自主车辆的目标检测与图像分类

另一个例子是医疗行业，如果谈到癌症，即使在今天的技术进步时代，癌症如果未能在早期识别仍然可能致命。尽可能早地检测癌细胞可以潜在地拯救数百万生命。癌细胞的形状在确定癌症的严重程度方面发挥了重要作用，这可以通过图像分类算法来识别。

![图示](../Images/5cd5d39b1ed64885b7c3c1032d66b827.png)

[乳腺癌细胞](https://imgur.com/gallery/QYbhkFH)

多年来，已经开发了几种图像分割算法和技术，这些技术使用特定领域的知识来有效解决该特定应用领域的分割问题，包括[医学成像](https://en.wikipedia.org/wiki/Medical_imaging)、[目标检测](https://en.wikipedia.org/wiki/Object_detection)、[虹膜识别](https://en.wikipedia.org/wiki/Iris_recognition)、[视频监控](https://en.wikipedia.org/wiki/Closed-circuit_television)、[机器视觉](https://en.wikipedia.org/wiki/Machine_vision)等。

让我们使用python matplotlib库在三维空间中绘制图像。

下面是我们将在三维空间中绘制的图像，我们可以清晰地看到3种不同的颜色，这意味着应生成3个簇/组。

![图示](../Images/99b2323f5239141a914e6ec9ab099c33.png)

来源: [lightstalking.com](https://www.lightstalking.com/composing-with-color/)

```py
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import cv2img = cv2.imread("/Users/nageshsinghchauhan/Documents/images10.jpg")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
r, g, b = cv2.split(img)
r = r.flatten()
g = g.flatten()
b = b.flatten()#plotting 
fig = plt.figure()
ax = Axes3D(fig)
ax.scatter(r, g, b)
plt.show()
```

![图示](../Images/4465821b34acf5a136a0c9dc831c1381.png)

在三维空间中的图像绘制

从图中可以清晰地看到数据点形成了若干组——图表中的某些地方更为密集，这可以看作是图像中不同颜色的主导地位。

### 图像分割如何工作

图像分割涉及将图像转换为像素区域的集合，这些区域由掩模或标记图像表示。通过将图像分割为多个部分，你可以只处理图像中的重要部分，而不是处理整个图像。

一种常见的技术是查找像素值的急剧不连续性，这通常表示定义区域的边缘。

另一种常见的方法是检测图像区域中的相似性。一些遵循这种方法的技术包括区域生长、聚类和阈值化。

多年来，已经开发出多种其他方法来执行图像分割，利用领域特定的知识在特定应用领域有效地解决分割问题。

让我们从图像分割中的一种基于聚类的方法开始，即 K-均值聚类。

### K-均值聚类算法

首先，什么是机器学习中的聚类算法？

聚类算法是无监督算法，但与分类算法类似，只是基础不同。

在聚类中，你不知道你在寻找什么，而是尝试识别数据中的一些分段或簇。当你在数据集中使用聚类算法时，可能会突然出现一些你之前未曾想到的结构、簇和分组。

***K*-均值聚类** 算法是一种无监督算法，用于从背景中分割兴趣区域。它将给定数据基于 K-质心分成 K 个簇或部分。

当你拥有未标记的数据（即没有定义类别或组的数据）时，会使用该算法。目标是根据数据中的某种相似性找到某些组，组的数量由 K 表示。

![图](../Images/37c4f348f6a69fed5102b46d3eda1705.png)

K-均值聚类示例

在上述图中，购物中心的顾客根据他们的收入和消费评分被分成了 5 个簇。黄色点代表每个簇的质心。

K-均值聚类的目标是最小化所有点与簇中心之间的平方距离之和。

![图](../Images/2266d8cbedb64ea634a1afe60a04cfaf.png)

图片来源：[saedsayad.com](https://www.saedsayad.com/clustering_kmeans.htm)

**K-均值算法的步骤：**

1.  选择簇的数量 K。

1.  随机选择 K 个点作为质心（不一定来自你的数据集）。

1.  将每个数据点分配到最近的质心 → 这形成 K 个簇。

1.  计算并放置每个簇的新质心。

1.  将每个数据点重新分配到新的最近质心。如果发生了任何重新分配，回到第 4 步，否则模型准备好。

**如何选择 K 的最优值？**

对于某些类的聚类算法（特别是 K-均值、K[-medoids](https://en.wikipedia.org/wiki/K-medoid) 和 [期望最大化](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) 算法），有一个常被称为 K 的参数，用于指定要检测的簇的数量。其他算法如 [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN) 和 [OPTICS 算法](https://en.wikipedia.org/wiki/OPTICS_algorithm) 不需要指定该参数；[层次聚类](https://en.wikipedia.org/wiki/Hierarchical_clustering) 完全避免了这个问题，但这超出了本文的范围。

如果我们谈论K-Means，那么K的正确选择通常是模糊的，解释取决于数据集中的点的分布形状和规模以及用户所需的聚类分辨率。此外，增加K而不受惩罚将始终减少结果聚类中的错误量，在每个数据点被视为一个独立聚类（即K等于数据点数量，*n*）的极端情况下，错误量为零。直观上，*K的最佳选择将平衡使用单个聚类的最大数据压缩与将每个数据点分配到其自身聚类的最大准确性*。

如果从数据集的属性的先验知识中无法明显得出K的适当值，则必须以某种方式选择K。有几种类别的方法用于做出这个决定，**肘部法**就是其中一种方法。

### 肘部法

类似于K-Means聚类的分区方法的基本思想是定义聚类，使得总的簇内变异性，或总簇内平方和（WCSS）最小化。***总的WCSS衡量了聚类的紧凑性，我们希望它尽可能小。***

![图](../Images/c15401f28d280f1a8b9b62571528e9ac.png)

肘部法将总WCSS作为聚类数的函数：应选择一个聚类数，使得增加另一个聚类不会显著改善总WCSS。

**选择最佳聚类数K的步骤：（肘部法）**

1.  计算不同K值的K-Means聚类，通过将K从1变动到10个聚类。

1.  对于每个K，计算簇内平方和总和（WCSS）。

1.  绘制WCSS与聚类数K的曲线。

1.  图中的弯点（膝盖）的位置通常被认为是适当聚类数量的指标。

有个陷阱！！！

尽管K-Means具有许多优点，但由于质心的随机选择，它有时会失败，这被称为**随机初始化陷阱**。

为了解决这个问题，我们有一个称为[**K-Means++**](https://en.wikipedia.org/wiki/K-means%2B%2B)的K-Means初始化过程（用于选择K-Means聚类初始值的算法）。

在K-Means++中，我们随机选择一个点作为第一个质心，然后基于第一个点的距离选择下一个点，点之间的距离越远，选择的可能性越大。

然后我们有两个质心，重复过程，每个点的概率基于它到最近质心的距离。现在，***这在算法初始化中引入了额外开销，但它降低了坏初始化导致糟糕聚类结果的概率。***

**K-Means聚类的可视化表示：** 从最左边的4个点开始。

![图](../Images/73a6666e8af6262bc8673e734728b100.png)

[Source](http://shabal.in/visuals/kmeans/5.html): K-Means 聚类实战

够了理论，接下来在实际场景中实现我们讨论的内容。

在本节中，我们将探讨一种方法，通过 **K-Means 聚类算法** 和 **OpenCV** 读取图像并对图像的不同区域进行聚类。

所以基本上我们将执行颜色聚类和 Canny 边缘检测。

**颜色聚类：**

加载所有所需的库：

```py
import numpy as np
import cv2
import matplotlib.pyplot as plt
```

下一步是加载 RGB 色彩空间中的图像

```py
original_image = cv2.imread("/Users/nageshsinghchauhan/Desktop/image1.jpg")
```

原始图像：

![Figure](../Images/bbc112394504e9508aec30c6c069201d.png)

source: unsplash

我们需要将图像从 RGB 色彩空间转换为 HSV 以继续操作。

**但问题是为什么？？**

> 根据 [wikipedia](https://en.wikipedia.org/wiki/HSL_and_HSV#Use_in_image_analysis)，数字图像中物体颜色的 R、G 和 B 分量都与光线的强度相关，因此彼此相关，基于这些分量的图像描述使得物体区分变得困难。基于色调/亮度/饱和度的描述通常更为相关。

如果你不将图像转换为 HSV，图像将会是这样的：

![Figure](../Images/be1a19424260442f8af5f305c7793fb3.png)

我们原始图像的 RGB 色彩空间

```py
img=cv2.cvtColor(original_image,cv2.COLOR_BGR2RGB)
```

接下来，将 MxNx3 图像转换为 Kx3 矩阵，其中 K=MxN，每一行现在是 RGB 3-D 空间中的一个向量。

```py
vectorized = img.reshape((-1,3))
```

我们将 `unit8` 值转换为浮点型，这是 OpenCV 的 k-means 方法的要求。

```py
vectorized = np.float32(vectorized)
```

我们将使用 k=3 进行聚类，因为如果你查看上面的图像，它有 3 种颜色，绿色的草地和森林，蓝色的海洋和青绿色的海岸。

定义准则、簇的数量（K）并应用 k-means()

```py
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
```

OpenCV 提供了 [**cv2.kmeans(**](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88)**samples, nclusters(K), criteria, attempts, flags**[**)**](https://docs.opencv.org/master/d5/d38/group__core__cluster.html#ga9a34dc06c6ec9460e90860f15bcd2f88) 函数用于颜色聚类。

**1\. samples:** 应为 **np.float32** 数据类型，每个特征应放在单独的列中。

**2\. nclusters(K)**: 最终所需的簇数

**3\. criteria:** 这是迭代终止准则。当满足此准则时，算法迭代停止。实际上，它应该是一个包含 3 个参数的元组。它们是 `( type, max_iter, epsilon )`：

终止准则的类型。它有如下 3 个标志：

+   **cv.TERM_CRITERIA_EPS** — 当达到指定的精度，即*epsilon*时，停止算法迭代。

+   **cv.TERM_CRITERIA_MAX_ITER** — 在指定的迭代次数后停止算法，*max_iter*。

+   **cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER** — 当满足以上任何一个条件时，停止迭代。

**4\. 尝试次数：** 标志用于指定算法使用不同初始标记进行执行的次数。算法返回产生最佳紧凑度的标签。这个紧凑度作为输出返回。

**5\. 标志：** 此标志用于指定初始中心的选取方式。通常使用两个标志： [**cv.KMEANS_PP_CENTERS**](https://docs.opencv.org/master/d0/de1/group__core.html#gga276000efe55ee2756e0c471c7b270949a78ddd00a99cd51db10ed63c024eb1e62) 和 [**cv.KMEANS_RANDOM_CENTERS**](https://docs.opencv.org/master/d0/de1/group__core.html#gga276000efe55ee2756e0c471c7b270949adfa80a38dfc0aef0de888c3164f33faf)。

```py
K = 3
attempts=10
ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_PP_CENTERS)
```

现在转换回uint8格式。

```py
center = np.uint8(center)
```

接下来，我们需要访问标签以重新生成聚类图像。

```py
res = center[label.flatten()]
result_image = res.reshape((img.shape))
```

`result_image` 是经过K-means聚类处理的帧结果。

现在让我们可视化K=3时的输出结果

```py
figure_size = 15
plt.figure(figsize=(figure_size,figure_size))
plt.subplot(1,2,1),plt.imshow(img)
plt.title('Original Image'), plt.xticks([]), plt.yticks([])
plt.subplot(1,2,2),plt.imshow(result_image)
plt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])
plt.show()
```

![图](../Images/e122ed9b791e75f09b42e30fe5d57809.png)

K=3时的图像分割

因此，该算法已将我们的原始图像分为三种主要颜色。

让我们看看当K值变为5时会发生什么：

![图](../Images/757897619f800fa4107a94cf459ecd1a.png)

K=5时的图像分割

改变K值为7：

![图](../Images/987b393caef9ae0a152d28540c87dafd.png)

K=7时的图像分割

如你所见，随着K值的增加，图像变得更加清晰，因为K-means算法可以对更多的颜色类别/簇进行分类。

我们可以对不同的图像尝试我们的代码：

![图](../Images/95680db4234dcd426ab5cdb840dc8a90.png)

K=6时的图像分割![图](../Images/047b4c6eba9cfd996a2acb2024317bd0.png)

K=6时的图像分割

让我们进入下一部分：Canny边缘检测。

**Canny边缘检测：** 这是一种图像处理方法，用于检测图像中的边缘，同时抑制噪声。

**Canny边缘检测算法由5个步骤组成：**

1.  <噪声减少="">梯度计算</噪声>

1.  非极大值抑制

1.  双阈值

1.  通过滞后跟踪边缘

OpenCV提供了**cv2.Canny(image, threshold1,threshold2)**函数用于边缘检测。

第一个参数是我们的输入图像。第二个和第三个参数分别是最小和最大阈值。

该函数在输入图像（8位输入图像）中查找边缘，并使用Canny算法在输出图像中标记这些边缘。最小值用于边缘连接。最大值用于找到强边缘的初始段。

```py
edges = cv2.Canny(img,150,200)
plt.figure(figsize=(figure_size,figure_size))
plt.subplot(1,2,1),plt.imshow(img)
plt.title('Original Image'), plt.xticks([]), plt.yticks([])
plt.subplot(1,2,2),plt.imshow(edges,cmap = 'gray')
plt.title('Edge Image'), plt.xticks([]), plt.yticks([])
plt.show()
```

![图](../Images/343ca587398f6095595d469d8176a580.png)

结果-1：使用Canny算法进行边缘检测![图](../Images/0a649a64791babd29ae0bf62fb3e9807.png)

结果-2：使用Canny算法进行边缘检测

### 结论：未来会怎样

![图](../Images/40d187193d833bf9f63d02536b0efe73.png)

图片来源：[gehealthcare](http://newsroom.gehealthcare.com/is-the-ai-trend-why-doctors-of-the-future-may-know-code/)

由于图像处理、机器学习、人工智能及相关技术的进步，未来几十年内世界上将出现数百万台机器人，这将改变我们的日常生活方式。这些进步将涉及语音命令、预测政府的信息需求、翻译语言、识别和追踪人员及物品、诊断医疗条件、进行手术、重新编程人类 DNA 的缺陷、无人驾驶汽车等，现实生活中的应用数不胜数。

好的，这篇文章就到这里。我希望大家喜欢阅读这篇文章。请在评论区分享你的想法/评论/疑问。

你可以通过[LinkedIn](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/?source=post_page---------------------------)联系我，提出任何问题。

感谢阅读！！！

**个人简介： [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)** 是一位数据科学爱好者。对大数据、Python 和机器学习感兴趣。

[原文](https://towardsdatascience.com/introduction-to-image-segmentation-with-k-means-clustering-83fd0a9e2fc3)。经许可转载。

**相关：**

+   [使用卷积神经网络和 OpenCV 预测年龄和性别](/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)

+   [Python 中使用 Scikit-Learn 进行线性回归的初学者指南](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)

+   [从数据预处理到优化回归模型性能](/2019/07/data-pre-processing-optimizing-regression-model-performance.html)

### 更多相关内容

+   [解放聚类：理解 K 均值聚类](https://www.kdnuggets.com/2023/07/clustering-unleashed-understanding-kmeans-clustering.html)

+   [k-means 聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)

+   [什么是 K 均值聚类及其算法是如何工作的？](https://www.kdnuggets.com/2023/05/kmeans-clustering-algorithm-work.html)

+   [动手实践无监督学习：K均值聚类](https://www.kdnuggets.com/handson-with-unsupervised-learning-kmeans-clustering)

+   [使用 PyCaret 进行 Python 中的聚类简介](https://www.kdnuggets.com/2021/12/introduction-clustering-python-pycaret.html)

+   [揭示隐藏模式：层次聚类简介](https://www.kdnuggets.com/unveiling-hidden-patterns-an-introduction-to-hierarchical-clustering)
