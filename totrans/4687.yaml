- en: Which Face is Real?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪一张脸是真的？
- en: 原文：[https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html](https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html](https://www.kdnuggets.com/2019/04/which-face-real-stylegan.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)![which-face-is-real](../Images/3cb2907ee46dee9ce9e7997fd9958dd9.png)Which
    Face Is Real? ### Which Face is Real?'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments) ![which-face-is-real](../Images/3cb2907ee46dee9ce9e7997fd9958dd9.png)
    哪一张脸是真的？ ### 哪一张脸是真的？'
- en: '[Which Face Is Real?](https://www.whichfaceisreal.com/index.php) was developed
    by [Jevin West](https://www.jevinwest.org/) and [Carl Bergstrom](https://octavia.zoology.washington.edu/)
    from the [University of Washingtion](https://www.washington.edu/) as part of the
    [Calling Bullshit Project](https://callingbullshit.org/). It acts as a sort of
    game that anyone can play. Visitors to the site have a choice of two images, one
    of which is real and the other of which is a fake generated by [StyleGAN](#StyleGAN).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[哪一张脸是真的？](https://www.whichfaceisreal.com/index.php) 是由 [杰文·韦斯特](https://www.jevinwest.org/)
    和 [卡尔·伯格斯特罗姆](https://octavia.zoology.washington.edu/) 开发的，来自 [华盛顿大学](https://www.washington.edu/)，作为
    [揭穿谎言项目](https://callingbullshit.org/) 的一部分。它充当一种游戏，任何人都可以参与。网站访问者可以选择两张图像，其中一张是真的，另一张是由
    [StyleGAN](#StyleGAN) 生成的假图像。'
- en: The project was implemented by Jevin and Carl as a course that will teach its
    students how to identify misinformation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目由杰文和卡尔实施，作为一门课程，旨在教导学生如何识别虚假信息。
- en: Our aim in this course is to teach you how to think critically about the data
    and models that constitute evidence in the social and natural sciences.
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本课程的目标是教你如何对构成社会和自然科学证据的数据和模型进行批判性思考。
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The world is awash in bullshit. Politicians are unconstrained by facts. Science
    is conducted by press release. Higher education rewards bullshit over analytic
    thought. Startup culture elevates bullshit to high art. Advertisers wink conspiratorially
    and invite us to join them in seeing through all the bullshit — and take advantage
    of our lowered guard to bombard us with bullshit of the second order. The majority
    of administrative activity, whether in private business or the public sphere,
    seems to be little more than a sophisticated exercise in the combinatorial reassembly
    of bullshit.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 世界上充斥着胡言乱语。政治家不受事实约束。科学通过新闻稿进行。高等教育奖励胡说八道而非分析思维。初创文化将胡说八道提升为高雅艺术。广告商暗中挑衅，邀请我们一起看穿所有胡说八道——并利用我们放松警惕的机会向我们轰炸二级胡说八道。无论是私人企业还是公共领域，大多数行政活动似乎都只是复杂的胡说八道重组练习。
- en: ''
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We're sick of it. It's time to do something, and as educators, one constructive
    thing we know how to do is to teach people. So, the aim of this course is to help
    students navigate the bullshit-rich modern environment by identifying bullshit,
    seeing through it, and combating it with effective analysis and argument.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们对此感到厌倦。是时候采取行动了，作为教育者，我们知道的建设性方法之一就是教育人们。因此，本课程的目标是帮助学生在虚假信息充斥的现代环境中，通过识别虚假信息、看穿它，并通过有效的分析和论证来对抗它。
- en: '*-Carl T. Bergstrom and Jevin West'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*- 卡尔·T·伯格斯特罗姆 和 杰文·韦斯特'
- en: Seattle, WA.*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 西雅图，WA.*
- en: How do you tell the Difference?
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何区分？
- en: '**Water splotches**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**水斑**'
- en: The algorithm produces shiny blobs that look somewhat like water splotches on
    old photographic prints. These splotches can appear anywhere in the image, but
    often show up at the interface between the hair and the background.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法生成的光滑斑点看起来有点像老旧照片上的水斑。这些斑点可能出现在图像的任何位置，但通常在头发和背景之间的界面处出现。
- en: '![water-splotches](../Images/69553dbe85e7592cbdffa9b905132dcc.png)water splotches'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![water-splotches](../Images/69553dbe85e7592cbdffa9b905132dcc.png) 水斑'
- en: '**Background problems**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**背景问题**'
- en: The background of the image can appear in a weird state such as blurriness or
    mishaped objects. This is due to the fact that the neural net is trained on the
    face and less emphasis is given to the background of the image.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的背景可能会出现模糊或变形等奇怪状态。这是因为神经网络主要在面部进行训练，对图像背景的关注较少。
- en: '![background-problems](../Images/49af8987d14cec1d349be31cd39e3d9b.png)background
    problems'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![background-problems](../Images/49af8987d14cec1d349be31cd39e3d9b.png) 背景问题'
- en: '**Symmetry**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**对称性**'
- en: At the moment, the generator is not able to produce realistic looking eyeglasses,
    however this may not be obvious at first. A common problem is asymmetry. Look
    at the frame structure; often the frame will take one style at the left and another
    at the right, or there will be a wayfarer-style ornament on one side but not on
    the other. Other times the frame will just be crooked or jagged. In addition,
    asymmetries in facial hair, different earrings in the left and right ear, and
    different forms of collar or fabric on the left and right side can be present.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前，生成器无法生成逼真的眼镜，这可能起初不明显。一个常见问题是对称性问题。查看框架结构；通常框架左边一种风格，右边另一种，或者一边有某种风格的装饰而另一边没有。其他时候，框架可能只是歪斜或锯齿状。此外，还可能存在面部胡须的非对称性，左右耳饰不同，以及左右侧领子或面料不同等情况。
- en: '![asymmetry](../Images/1f49498ac44791186e8d45b69686c30a.png)asymmetry'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![不对称性](../Images/1f49498ac44791186e8d45b69686c30a.png)不对称性'
- en: '**Hair**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**头发**'
- en: Hair is known to be difficult for the algorithm to render properly. Disconnected
    strands, too straight, or too streaked will be common problems when generating
    hair.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 头发的渲染对算法来说非常困难。常见问题包括断裂的发丝、过于笔直或过于条纹状。
- en: '![hair](../Images/4d0ae32dcfd4386715e28c33213bcd34.png)hair'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![头发](../Images/4d0ae32dcfd4386715e28c33213bcd34.png)头发'
- en: '**Fluorescent bleed**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**荧光溢出**'
- en: Fluorescent colors can sometimes bleed into the hair or face from the background.
    People can sometimes mistake this for colored hair.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 荧光颜色有时会从背景溢出到头发或脸部，人们有时会将其误认为是染色的头发。
- en: '![fluorescent-bleed](../Images/b1358a79846111e35502a1e7cfdfe3f3.png)fluorescent
    bleed'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![荧光溢出](../Images/b1358a79846111e35502a1e7cfdfe3f3.png)荧光溢出'
- en: '**Teeth**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**牙齿**'
- en: Teeth are also hard to render and can come out as odd-shaped, asymmetric or
    for those that can identify teeth, sometimes 3 incisors can appear in the image.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 牙齿的渲染也很困难，可能呈现出奇形怪状、不对称的样子，或者对于能识别牙齿的人来说，有时图像中会出现 3 颗门牙。
- en: '![teeth](../Images/929ea9c7c869fc76c92746f72968dd90.png)teeth'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![牙齿](../Images/929ea9c7c869fc76c92746f72968dd90.png)牙齿'
- en: Trying the algorithm
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试算法
- en: All the code for the StyleGAN have been open-sourced in the [stylegan](https://github.com/NVlabs/stylegan)
    repository. It gives details on how you can run the styleGAN algorithm yourself.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: StyleGAN 的所有代码已经开源在 [stylegan](https://github.com/NVlabs/stylegan) 仓库中。它详细介绍了如何自己运行
    styleGAN 算法。
- en: '**However, there are a few barriers:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，也有一些障碍：**'
- en: System Requirements
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统要求
- en: Training time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练时间
- en: System Requirements
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统要求
- en: Both Linux and Windows are supported, but we strongly recommend Linux for performance
    and compatibility reasons.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 Linux 和 Windows，但我们强烈推荐 Linux 以获得更好的性能和兼容性。
- en: 64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or
    newer.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 64 位 Python 3.6 安装。我们推荐使用 Anaconda3 和 numpy 1.14.3 或更新版本。
- en: TensorFlow 1.10.0 or newer with GPU support.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 1.10.0 或更新版本，需支持 GPU。
- en: One or more high-end NVIDIA GPUs with at least 11GB of DRAM. We recommend NVIDIA
    DGX-1 with 8 Tesla V100 GPUs.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台或多台高端 NVIDIA GPU，至少 11GB 的 DRAM。我们推荐使用 8 个 Tesla V100 GPU 的 NVIDIA DGX-1。
- en: NVIDIA driver 391.35 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.3.1 or newer.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NVIDIA 驱动 391.35 或更新版本，CUDA 工具包 9.0 或更新版本，cuDNN 7.3.1 或更新版本。
- en: That type of compute and storage capacity is not common among individuals.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这种计算和存储能力在个人中并不常见。
- en: Training time
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练时间
- en: Below you will find NVIDIA's reported expected training times for default configuration
    of the `train.py` script (available in the stylegan repository) on a Tesla V100
    GPU for the [FFHQ dataset](https://github.com/NVlabs/ffhq-dataset) (available
    in the stylegan repository).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 NVIDIA 报告的在 Tesla V100 GPU 上使用默认配置运行 `train.py` 脚本（在 stylegan 仓库中提供）时的预期训练时间，用于
    [FFHQ 数据集](https://github.com/NVlabs/ffhq-dataset)（在 stylegan 仓库中提供）。
- en: '![figure-name](../Images/545dbbff52e4504a8dd253a9b881ad24.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图示名称](../Images/545dbbff52e4504a8dd253a9b881ad24.png)'
- en: The time taken to properly train this algorithm is far beyond the patience of
    an everyday individual.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 训练此算法所需的时间远超普通人的耐性。
- en: '### Behind the scenes'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '### 幕后花絮'
- en: The science behind the app is thanks to a team at NVIDIA and their work on Generative
    Adversarial Networks. They created the StyleGAN. To learn a little more about
    this amazing technique, I have provided some resources and concise explanations
    below.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用的背后科学来自 NVIDIA 的团队和他们在生成对抗网络方面的工作。他们创造了 StyleGAN。为了更多了解这种惊人的技术，我在下面提供了一些资源和简洁的解释。
- en: Generative Adversarial Network
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '*For those wanting a refresher on GAN''s, this playlist of tutorials on [GAN''s
    by Ahlad Kumar](https://www.youtube.com/watch?v=RRTuumxm3CE&list=PLdxQ7SoCLQAMGgQAIAcyRevM8VvygTpCu)
    is quite helpful.*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于那些想要回顾GAN的内容，这个由[Ahlad Kumar提供的GAN教程播放列表](https://www.youtube.com/watch?v=RRTuumxm3CE&list=PLdxQ7SoCLQAMGgQAIAcyRevM8VvygTpCu)非常有帮助。*'
- en: 'Generative Adversarial Networks first made the rounds in 2014 as an extension
    of generative models via an adversarial process in which we simultaneously train
    two models:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络首次在2014年作为生成模型的扩展，通过对抗性过程同时训练两个模型：
- en: A generative model that captures the data distribution (training)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获数据分布的生成模型（训练）
- en: A discriminative model that estimates the probability that a sample came from
    the
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 估计样本来源概率的判别模型
- en: training data rather than the generative model.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练数据而非生成模型。
- en: The goal of GAN's is to generate artificial/fake samples that are indistinguishable
    from authentic/real samples. A common example is generating artificial images
    that are indistinguishable from real photos of people. The human visual processing
    system would not be able to differentiate these images so easily as the images
    will look like real people at first. We will later see how this happens and how
    we can distinguish a photo of a real person and a photo generated by an algorithm.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的目标是生成与真实样本无法区分的人工/虚假样本。一个常见的例子是生成与真实人物照片无法区分的人工图像。人类视觉处理系统无法如此轻易地区分这些图像，因为这些图像乍看起来像真实的人。我们将稍后了解这如何发生，以及如何区分真实人物的照片和由算法生成的照片。
- en: StyleGAN
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StyleGAN
- en: The algorithm behind this amazing app was the brainchild of **Tero Karras, Samuli
    Laine and Timo Aila** at NVIDIA and called it ***StyleGAN***. The algorithm is
    based on earlier work by Ian Goodfellow and colleagues on General Adversarial
    Networks (GAN's). NVIDIA open sourced the code for their StyleGAN which uses GAN's
    in which two neural networks, one to generate indistinguishable artificial images
    while the other will attempt to distinguish between fake and real photographs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个令人惊叹的应用背后的算法是**Tero Karras、Samuli Laine 和 Timo Aila**在NVIDIA的杰作，称为***StyleGAN***。该算法基于Ian
    Goodfellow及其同事在对抗性网络（GAN）的早期工作。NVIDIA将其StyleGAN的代码开源，使用GAN，其中两个神经网络，一个生成难以区分的人工图像，另一个尝试区分虚假和真实的照片。
- en: But while we’ve learned to distrust user names and text more generally, pictures
    are different. You can't synthesize a picture out of nothing, we assume; a picture
    had to be of someone. Sure a scammer could appropriate someone else’s picture,
    but doing so is a risky strategy in a world with google reverse search and so
    forth. So we tend to trust pictures. A business profile with a picture obviously
    belongs to someone. A match on a dating site may turn out to be 10 pounds heavier
    or 10 years older than when a picture was taken, but if there’s a picture, the
    person obviously exists.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管我们已经学会了更普遍地怀疑用户名和文本，但图片却不同。我们假设你不能凭空合成一张图片；一张图片必须属于某个人。当然，诈骗者可以窃取他人的照片，但在有谷歌反向搜索等工具的世界里，这是一种冒险的策略。因此，我们倾向于相信照片。一个带有照片的商业档案显然属于某人。一个约会网站上的匹配可能与拍摄照片时比实际重10磅或老10岁，但如果有照片，这个人显然是存在的。
- en: ''
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: No longer. New adversarial machine learning algorithms allow people to rapidly
    generate synthetic 'photographs' of people who have never existed.
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不再如此。新的对抗性机器学习算法使人们能够迅速生成从未存在过的合成“照片”。
- en: '*- Jevin West and Carl Bergstrom*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*- Jevin West 和 Carl Bergstrom*'
- en: '***Generative models have a limitation in which it''s hard to control the characteristics
    such as facial features from photographs. NVIDIA''s StyleGAN is a fix to this
    limitation. The model allows the user to tune hyper-parameters that can control
    for the differences in the photographs.***'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '***生成模型存在一个限制，即难以控制从照片中提取的特征，如面部特征。NVIDIA的StyleGAN解决了这一限制。该模型允许用户调整超参数，从而控制照片中的差异。***'
- en: 'StyleGAN solves the variability of photos by adding *styles* to images at each
    convolution layer. These styles represent different features of a photos of a
    human, such as facial features, background color, hair, wrinkles etc. The algorithm
    generates new images starting from a low resolution (4x4) to a higher resolution
    (1024x1024). The model generates two images A and B and then combines them by
    taking low-level features from A and rest from B. At each level, different features
    (styles) are used to generate an image:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: StyleGAN 通过在每个卷积层中添加 *风格* 来解决照片的可变性。这些风格代表了人类照片的不同特征，如面部特征、背景颜色、头发、皱纹等。该算法从低分辨率（4x4）开始生成新图像，逐步提高到高分辨率（1024x1024）。模型生成两张图像
    A 和 B，然后通过从 A 中提取低级特征和从 B 中提取其余特征来组合它们。在每个层级，使用不同的特征（风格）来生成图像：
- en: Coarse styles (resolution between 4 to 8) - *pose, hair, face, shape*
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 粗糙风格（分辨率在4到8之间） - *姿势，头发，面部，形状*
- en: Middle styles (resolution between 16 to 32) - *facial features, eyes*
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中等风格（分辨率在16到32之间） - *面部特征，眼睛*
- en: Fine styles (resolution between 64 to 1024)- *color scheme*
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 细致风格（分辨率在64到1024之间） - *色彩方案*
- en: '![style-resolution](../Images/591b36c684a8ae3f4a02040a91063619.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![style-resolution](../Images/591b36c684a8ae3f4a02040a91063619.png)'
- en: Properties of the style-based generator
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于风格的生成器的特性
- en: '**Style mixing**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**风格混合**'
- en: The generator employs *mixing regularization* where a given percentage of images
    are generated using two random latent codes instead of one during training. When
    generating such an image, the user simply switches from one latent code to another
    (i.e. style mixing) at a randomly selected point in the synthesis network. In
    the below image we can see how the styles generated by one latent code (source)
    override a subset of the styles of another latent code (destination)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器采用 *混合正则化*，在训练过程中，使用两个随机潜在代码而非一个生成一定百分比的图像。生成这样的图像时，用户只需在合成网络中随机选择的点上从一个潜在代码切换到另一个（即风格混合）。在下面的图像中，我们可以看到一个潜在代码（源）生成的风格如何覆盖另一个潜在代码（目标）的风格子集。
- en: '![style-mixing](../Images/6d4d920fcbaf0228fb3c6c2bd985c582.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![style-mixing](../Images/6d4d920fcbaf0228fb3c6c2bd985c582.png)'
- en: '**Stochastic Variation**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机变化**'
- en: Many aspects of a photograph are stochastic (i.e. random) such as wrinkles,
    hair placement, stubbles, freckles, pimples. The architecture of StyleGAN adds
    per-pixel noise after each convolution layer in order for images to show these
    variations as seen in real life. As seen in the below image, noise added by the
    generator only affects the stochastic aspects of the image and leaves the higher
    level styles as they are.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片的许多方面是随机的（即随机的），如皱纹、头发位置、胡茬、雀斑、痘痘。StyleGAN 的架构在每个卷积层之后添加每像素噪声，以便图像显示出这些如现实生活中看到的变化。如下面的图像所示，生成器添加的噪声仅影响图像的随机方面，而保持更高层次的风格不变。
- en: '![stochastic-variation](../Images/6e4a07735ff32b05171a99da9df06cf6.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![stochastic-variation](../Images/6e4a07735ff32b05171a99da9df06cf6.png)'
- en: '**Separation of global effects from stochasticity**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**全局效果与随机性的分离**'
- en: Changes to the style of the image will have global effects such as changing
    pose, gender, face etc. but the noise such as freckles, wrinkles, hair placement
    will only affect the stochastic variation. In StyleGAN, global effects such as
    pose, lighting or background style can be controlled coherently and the noise
    is added independently to each pixel and is thus ideally suited for controlling
    stochastic variation.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像风格的变化会对整体效果产生影响，例如改变姿势、性别、面部等，但噪声如雀斑、皱纹、头发位置只会影响随机变化。在 StyleGAN 中，姿势、光照或背景风格等全局效果可以一致地控制，而噪声是独立地添加到每个像素上，因此非常适合控制随机变化。
- en: Helpful resources
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有用的资源
- en: '[StyleGAN](https://arxiv.org/pdf/1812.04948.pdf)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[StyleGAN](https://arxiv.org/pdf/1812.04948.pdf)'
- en: '[How to Recognize Fake AI generated Images](https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何识别伪造的 AI 生成图像](https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842)'
- en: '[NVIDIA Open-Sources Hyper-Realistic Face Generator StyleGAN](https://medium.com/syncedreview/nvidia-open-sources-hyper-realistic-face-generator-stylegan-f346e1a73826)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NVIDIA 开源超真实面部生成器 StyleGAN](https://medium.com/syncedreview/nvidia-open-sources-hyper-realistic-face-generator-stylegan-f346e1a73826)'
- en: '**Related:**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The New Neural Internet is Coming](/2018/02/new-neural-internet-coming.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新的神经网络互联网即将到来](/2018/02/new-neural-internet-coming.html)'
- en: '[Generative Adversarial Networks, an overview](/2018/01/generative-adversarial-networks-overview.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成对抗网络概述](/2018/01/generative-adversarial-networks-overview.html)'
- en: '[See NVIDIA Deep Learning In Action [Webinar Series]](/2018/09/nvidia-deep-learning-webinar-series.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[观看NVIDIA深度学习实战[网络研讨会系列]](/2018/09/nvidia-deep-learning-webinar-series.html)'
- en: '* * *'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Which is Best: Data Science Bootcamp vs Degree vs Online Course](https://www.kdnuggets.com/2022/09/best-data-science-bootcamp-degree-online-course.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[哪种最好：数据科学训练营、学位还是在线课程](https://www.kdnuggets.com/2022/09/best-data-science-bootcamp-degree-online-course.html)'
- en: '[Which Metric Should I Use? Accuracy vs. AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我应该使用哪种指标？准确率与AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)'
- en: '[ETL vs ELT: Which One is Right for Your Data Pipeline?](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL与ELT：哪一个适合你的数据管道？](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
- en: '[RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RAG与微调：哪一个是提升你的LLM应用的最佳工具？](https://www.kdnuggets.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application)'
- en: '[Degree or Certificate? Which Credential Do Employers Value More?](https://www.kdnuggets.com/degree-or-certificate-which-credential-do-employers-value-more)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学位还是证书？雇主更看重哪种资质？](https://www.kdnuggets.com/degree-or-certificate-which-credential-do-employers-value-more)'
- en: '[Real-time Translations with AI](https://www.kdnuggets.com/2022/07/realtime-translations-ai.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用AI进行实时翻译](https://www.kdnuggets.com/2022/07/realtime-translations-ai.html)'
