- en: A simple and interpretable performance measure for a binary classifier
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种简单且可解释的二分类器性能测量方法
- en: 原文：[https://www.kdnuggets.com/2020/03/interpretable-performance-measure-binary-classifier.html](https://www.kdnuggets.com/2020/03/interpretable-performance-measure-binary-classifier.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/interpretable-performance-measure-binary-classifier.html](https://www.kdnuggets.com/2020/03/interpretable-performance-measure-binary-classifier.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Mehmet Suzen](https://msuzen.github.io/), Theoretical Physicist and Research
    Scientist**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Mehmet Suzen](https://msuzen.github.io/) 提供，理论物理学家和研究科学家**。'
- en: The core application of machine learning models is a [binary classification
    task](https://en.wikipedia.org/wiki/Binary_classification). This appears in polyhedra
    of areas from medicine for [diagnostic tests](https://en.wikipedia.org/wiki/Medical_test) to [credit
    risk](https://global.oup.com/academic/product/consumer-credit-models-9780199232130?cc=us&lang=en&) decision
    making for consumers. Techniques in building classifiers vary from simple decision
    trees to logistic regression and lately super-cool deep learning models that leverage
    multilayered neural networks. However, they are mathematically different in construction
    and training methodology, when it comes to their performance measure, things get
    tricky. In this post, we propose a simple and interpretable performance measure
    for a binary classifier in practice. Some background in classification is assumed.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的核心应用是 [二分类任务](https://en.wikipedia.org/wiki/Binary_classification)。这出现在医学中的
    [诊断测试](https://en.wikipedia.org/wiki/Medical_test) 以及针对消费者的 [信用风险](https://global.oup.com/academic/product/consumer-credit-models-9780199232130?cc=us&lang=en&)
    决策等多个领域。构建分类器的技术从简单的决策树到逻辑回归，最近还有利用多层神经网络的超级酷的深度学习模型。然而，尽管这些模型在构建和训练方法上有数学上的不同，但在性能测量方面，事情变得复杂。在这篇文章中，我们提出了一种简单且可解释的二分类器性能测量方法。假设读者对分类有一定的背景知识。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Why ROC-AUC is not interpretable?
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么 ROC-AUC 不具有可解释性？
- en: '![](../Images/28e43caacaab3e2c0e52240c83b9e599.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28e43caacaab3e2c0e52240c83b9e599.png)'
- en: '*Varying threshold produces different confusion matrices (Wikipedia).*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*不同阈值产生不同的混淆矩阵（维基百科）。*'
- en: The de-facto standard in reporting classifier performance is to use the [Receiver
    Operating Characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
    (ROC) - Area Under Curve (AUC) measure. It originates from the 1940s during the
    development of [Radar](https://en.wikipedia.org/wiki/Radar) by the US Navy, in
    measuring the performance of detection.  There are at least 5 different definitions
    of what does ROC-AUC means, and *even if you have a Ph.D. in Machine Learning,
    people have an excessively difficult time explaining what AUC means as a performance
    measure*. As AUC functionality is available in almost all libraries, and it becomes
    almost like a religious ritual to report in Machine Learning papers as a classification
    performance. However, its interpretation is not easy, apart from its absurd comparison
    issues, see [hmeasure](http://www.hmeasure.net/).  AUC measures the area under
    the True Positive Rate (TPR) curve as a function of the False Positive Rate (FPR)
    that are extracted from [confusion matrices](https://en.wikipedia.org/wiki/Confusion_matrix) with
    different thresholds.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 报告分类器性能的事实标准是使用[接收器操作特性](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
    (ROC) - 曲线下面积 (AUC) 测量。它起源于1940年代美国海军在雷达的开发过程中，用于测量探测性能。 至少有5种不同的 ROC-AUC 定义，即使你拥有机器学习博士学位，人们也很难解释
    AUC 作为性能度量的意义。由于几乎所有库中都有 AUC 功能，它几乎成为机器学习论文中分类性能的宗教仪式。然而，除了其荒谬的比较问题外，解释起来并不容易，请参见[hmeasure](http://www.hmeasure.net/)。AUC
    衡量的是从[混淆矩阵](https://en.wikipedia.org/wiki/Confusion_matrix)提取的真实正率 (TPR) 曲线下的面积，作为假阳性率
    (FPR) 的函数，不同阈值下的结果。
- en: '*f(x) = y*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*f(x) = y*'
- en: '*∫ 10 f(x)dx = AUC*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*∫ 10 f(x)dx = AUC*'
- en: where *y* is TPR and *x* is FPR. Apart from a multitude of interpretations and
    being easy to have confusion, there is no clear purpose of taking the integral
    over FPR. Obviously, we would like to have perfect classification by having FPR
    zero, but the area is not mathematically clear, which means that what is it as* a
    mathematical object* is not clear.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *y* 是 TPR，*x* 是 FPR。除了有多种解释且容易产生混淆外，没有明确的目的来对 FPR 进行积分。显然，我们希望通过将 FPR 设为零来实现完美分类，但这个面积在数学上并不明确，这意味着作为*一个数学对象*
    的具体意义并不清楚。
- en: Probability of correct classification (PCC)
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正确分类概率 (PCC)
- en: 'A simple and interpretable performance measure for a binary classifier would
    be great for both highly technical data scientist and non-technical stakeholders. The
    basic tenant in this direction is that the purpose of a classifier technology
    is the ability to differentiate two classes. This boils down to a probability
    value, *Probability of correct classification (PCC).* An obvious choice is the
    so-called balanced accuracy (BA). This is usually recommended for unbalanced problems,
    even by [SAS](https://support.sas.com/resources/papers/proceedings17/0942-2017.pdf);
    though they used multiplication of probabilities. Here we will call BA as PCC
    and use addition instead, due to statistical dependence:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类器来说，一个简单且易于解释的性能度量对技术数据科学家和非技术利益相关者都非常有用。这个方向的基本原则是分类器技术的目的是能够区分两个类别。这归结为一个概率值，即*正确分类概率
    (PCC)*。显而易见的选择是所谓的平衡准确率 (BA)。即使由[SAS](https://support.sas.com/resources/papers/proceedings17/0942-2017.pdf)推荐用于不平衡问题，他们使用了概率的乘法。这里我们将
    BA 称为 PCC，并改用加法，原因是统计依赖性：
- en: '*PCC = (TPR + TNR) / 2*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*PCC = (TPR + TNR) / 2*'
- en: '*TPR = TP / (ConditionPositive) = TP / (TP + FN)*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*TPR = TP / (ConditionPositive) = TP / (TP + FN)*'
- en: '*TNR = TN / (ConditionNegative) = TN / (TN + FP).*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*TNR = TN / (ConditionNegative) = TN / (TN + FP).*'
- en: PCC tells us how good the classifier in detecting either of the class, and it
    is a probability value, [0,1]. Note that using total accuracy over both positive
    and negative cases is misleading, even if our training data is balanced in production,
    batches we measure the performance may not be balanced, so accuracy alone is not
    a good measure.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: PCC 告诉我们分类器在检测任一类别时的效果，它是一个概率值，[0,1]。请注意，即使我们的训练数据在生产中是平衡的，使用正负案例的总体准确率也是误导性的，因为我们测量性能的批次可能不平衡，因此仅用准确率作为衡量标准并不理想。
- en: Production issues
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生产问题
- en: The immediate question would be how to choose the threshold in generating a
    confusion matrix? One option would be to chose a threshold that maximizes PCC
    for production on the test set. To improve the estimation of PCC, resampling on
    the test set can be performed to get a good uncertainty.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 直接的问题是如何选择生成混淆矩阵的阈值？一种选择是选择一个能够最大化PCC的阈值，用于在测试集上进行生产。为了提高PCC的估计，可以在测试集上进行重采样，以获得良好的不确定性。
- en: Conclusion
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: We try to circumvent in reporting AUCs by introducing PCC, or balanced accuracy
    as a simple and interpretable performance measure for a binary classifier. This
    is easy to explain to a non-technical audience. An improved PCC, that takes into
    account better estimation properties can be introduced, but the main interpretation
    remains the same as the *probability of correct classification. *
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试通过引入PCC，或平衡准确率，作为二分类器的简单而可解释的性能指标，来规避报告AUC的问题。这对于非技术观众来说很容易解释。可以引入一种改进的PCC，考虑更好的估计特性，但主要的解释仍然是*正确分类的概率。*
- en: '[Original](https://memosisland.blogspot.com/2020/02/a-simple-and-interpretable-performance.html).
    Reposted with permission.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://memosisland.blogspot.com/2020/02/a-simple-and-interpretable-performance.html)。经许可转载。'
- en: '**Related:**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Do You Trust and Understand Your Predictive Models?](https://www.kdnuggets.com/2020/02/h2o-trust-understand-predictive-models.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你信任并理解你的预测模型吗？](https://www.kdnuggets.com/2020/02/h2o-trust-understand-predictive-models.html)'
- en: '[Receiver Operating Characteristic Curves Demystified (in Python)](https://www.kdnuggets.com/2018/07/receiver-operating-characteristic-curves-demystified-python.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[接收器操作特征曲线揭秘（Python版）](https://www.kdnuggets.com/2018/07/receiver-operating-characteristic-curves-demystified-python.html)'
- en: '[Choosing the Right Metric for Evaluating Machine Learning Models — Part 2](https://www.kdnuggets.com/2018/06/right-metric-evaluating-machine-learning-models-2.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择正确的指标来评估机器学习模型——第2部分](https://www.kdnuggets.com/2018/06/right-metric-evaluating-machine-learning-models-2.html)'
- en: More On This Topic
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Introduction to Binary Classification with PyCaret](https://www.kdnuggets.com/2021/12/introduction-binary-classification-pycaret.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyCaret进行二分类介绍](https://www.kdnuggets.com/2021/12/introduction-binary-classification-pycaret.html)'
- en: '[Learn how to design, measure and implement trustworthy A/B tests…](https://www.kdnuggets.com/2023/01/sphere-design-measure-implement-trustworthy-ab-tests-ronny-kohavi.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习如何设计、测量和实施可靠的A/B测试…](https://www.kdnuggets.com/2023/01/sphere-design-measure-implement-trustworthy-ab-tests-ronny-kohavi.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用PyTorch的可解释神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从理论到实践：构建k-近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
- en: '[Optimizing Your LLM for Performance and Scalability](https://www.kdnuggets.com/optimizing-your-llm-for-performance-and-scalability)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化你的LLM以提高性能和可扩展性](https://www.kdnuggets.com/optimizing-your-llm-for-performance-and-scalability)'
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化性能和成本的策略，适用于大型…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
