- en: 'Generative AI: The First Draft, Not Final'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成性 AI：初稿而非最终稿
- en: 原文：[https://www.kdnuggets.com/generative-ai-the-first-draft-not-final](https://www.kdnuggets.com/generative-ai-the-first-draft-not-final)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/generative-ai-the-first-draft-not-final](https://www.kdnuggets.com/generative-ai-the-first-draft-not-final)
- en: '**By: Numa Dhamani & Maggie Engler**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：努玛·达哈尼 & 玛吉·恩格勒**'
- en: '![Generative AI: The First Draft, Not Final](../Images/0e325d6fb9017bf797b00d207f388bdb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![生成性 AI：初稿而非最终稿](../Images/0e325d6fb9017bf797b00d207f388bdb.png)'
- en: 'It''s safe to say that AI is having a moment. Ever since OpenAI''s conversational
    agent ChatGPT went unexpectedly viral late last year, the tech industry has been
    buzzing about large language models (LLMs), the technology behind ChatGPT. Google,
    Meta, and Microsoft, in addition to well-funded startups like Anthropic and Cohere,
    have all released LLM products of their own. Companies across sectors have rushed
    to integrate LLMs into their services: OpenAI alone boasts customers ranging from
    fintechs like Stripe powering customer service chatbots, to edtechs like Duolingo
    and Khan Academy generating educational material, to video game companies such
    as Inworld leveraging LLMs to provide dialogue for NPCs (non-playable characters)
    on the fly. On the strength of these partnerships and widespread adoption, OpenAI
    is reported to be on pace to achieve more than a billion dollars in annual revenue.
    It''s easy to be impressed by the dynamism of these models: the technical report
    on GPT-4, the latest of OpenAI''s LLMs, shows that the model achieves impressive
    scores on a wide range of academic and professional benchmarks, including the
    bar exam; the SAT, LSAT, and GRE; and AP exams in subjects including art history,
    psychology, statistics, biology, and economics.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，人工智能正处于风口浪尖。自从 OpenAI 的对话代理 ChatGPT 在去年末意外走红以来，科技行业一直在热议 ChatGPT 背后的技术——大型语言模型（LLMs）。除了谷歌、Meta
    和微软之外，还有像 Anthropic 和 Cohere 这样资金充裕的初创公司也推出了自己的 LLM 产品。各个行业的公司纷纷争相将 LLM 整合进他们的服务中：仅
    OpenAI 就拥有从金融科技公司如 Stripe 提供客户服务聊天机器人，到教育科技公司如 Duolingo 和 Khan Academy 生成教育材料，再到视频游戏公司如
    Inworld 利用 LLM 为 NPC（非玩家角色）提供对话的各类客户。凭借这些合作伙伴关系和广泛的采用，据报道 OpenAI 预计年收入将超过十亿美元。很容易被这些模型的活跃性所打动：关于
    GPT-4 的技术报告显示，该模型在各种学术和专业基准测试中取得了令人印象深刻的分数，包括律师资格考试；SAT、LSAT 和 GRE；以及涉及艺术史、心理学、统计学、生物学和经济学的
    AP 考试。
- en: 'These splashy results might suggest the end of the knowledge worker, but there
    is a key difference between GPT-4 and a human expert: GPT-4 has no *understanding*.
    The responses that GPT-4 and all LLMs generate do not derive from logical reasoning
    processes but from statistical operations. Large language models are trained on
    vast quantities of data from the internet. Web crawlers –– bots that visit millions
    of web pages and download their contents –– produce datasets of text from all
    manner of sites: social media, wikis and forums, news and entertainment websites.
    These text datasets contain billions or trillions of words, which are for the
    most part arranged in natural language: words forming sentences, sentences forming
    paragraphs.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这些引人注目的结果可能暗示着知识工作者的终结，但 GPT-4 和人类专家之间存在一个关键区别：GPT-4 没有 *理解*。GPT-4 和所有 LLM 生成的回答并不是来源于逻辑推理过程，而是来自统计操作。大型语言模型是通过海量的互联网数据进行训练的。网络爬虫——访问数百万网页并下载其内容的机器人——生成了来自各种网站的文本数据集：社交媒体、维基和论坛、新闻和娱乐网站。这些文本数据集包含数十亿或数万亿个单词，这些单词大多以自然语言的形式排列：单词形成句子，句子形成段落。
- en: In order to learn how to produce coherent text, the models train themselves
    on this data on millions of text completion examples. For instance, the dataset
    for a given model might contain sentences like, "It was a dark and stormy night,"
    and "The capital of Spain is Madrid." Over and over again, the model tries to
    predict the next word after seeing "It was a dark and" or "The capital of Spain
    is," then checks to see whether it was correct or not, updating itself each time
    it's wrong. Over time, the model becomes better and better at this text completion
    task, such that for many contexts — especially ones where the next word is nearly
    always the same, like "The capital of Spain is"  — the response considered most
    likely by the model is what a human would consider the "correct" response. In
    the contexts where the next word might be several different things, like "It was
    a dark and," the model will learn to select what humans would deem to be at least
    a reasonable choice, maybe "stormy," but maybe "sinister" or "musty" instead.
    This phase of the LLM lifecycle, where the model trains itself on large text datasets,
    is referred to as *pretraining*. For some contexts, simply predicting what word
    should come next won't necessarily yield the desired results; the model might
    not be able to understand that it should respond to instructions like "Write a
    poem about a dog" with a poem rather than continuing on with the instruction.
    To produce certain behaviors like instruction-following and to improve the model's
    ability to do particular tasks, like writing code or having casual conversations
    with people, the LLMs are then trained on targeted datasets designed to include
    examples of those tasks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习如何生成连贯的文本，这些模型在数百万个文本补全示例数据上进行训练。例如，给定模型的数据集中可能包含像“这是一个黑暗而暴风雨的夜晚”和“西班牙的首都为马德里”这样的句子。模型不断尝试在看到“这是一个黑暗而暴风雨的”或“西班牙的首都为”之后预测下一个词，然后检查是否正确，并在每次错误时更新自己。随着时间的推移，模型在文本补全任务上变得越来越好，以至于在许多上下文中——尤其是那些下一个词几乎总是相同的上下文，如“西班牙的首都为”——模型认为最可能的响应是人类认为的“正确”响应。在那些下一个词可能有几个不同选择的上下文中，如“这是一个黑暗而”，模型将学习选择人类认为至少是合理的选择，也许是“暴风雨的”，但也可能是“阴险的”或“霉味的”。LLM生命周期的这一阶段，模型在大型文本数据集上进行训练，被称为*预训练*。对于某些上下文，仅仅预测下一个词并不一定能产生期望的结果；模型可能无法理解它应该如何响应诸如“写一首关于狗的诗”这样的指令，而不是继续执行指令。为了产生某些行为，如遵循指令，并提高模型完成特定任务的能力，例如编写代码或与人进行轻松对话，LLM随后会在针对这些任务设计的目标数据集上进行训练。
- en: However, the very task of LLMs being trained to generate text by predicting
    likely next words leads to a phenomenon known as *hallucinations*, a well-documented
    technical pitfall where LLMs confidently make up incorrect information and explanations
    when prompted. The ability of LLMs to predict and complete text is based on patterns
    learned during the training process, but when faced with uncertain or multiple
    possible completions, LLMs select the option that seems the most plausible, even
    if it lacks any basis in reality.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LLM（大规模语言模型）通过预测可能的下一个词来生成文本的任务，导致了一种现象，称为*幻觉*。这是一个被广泛记录的技术陷阱，在这种情况下，LLM在被提示时会自信地编造错误的信息和解释。LLM预测和完成文本的能力基于训练过程中学到的模式，但当面临不确定或多种可能的补全时，LLM选择看起来最可信的选项，即使它与现实无关。
- en: For example, when Google launched its chatbot, Bard, it made a factual error
    in its first-ever public demo. Bard [infamously stated](https://www.theverge.com/2023/2/8/23590864/google-ai-chatbot-bard-mistake-error-exoplanet-demo)
    that the James Webb Space Telescope (JWST) “took the very first pictures of a
    planet outside of our own solar system.” But in reality, the [first image of an
    exoplanet was taken in 2004](https://exoplanets.nasa.gov/resources/300/2m1207-b-first-image-of-an-exoplanet)
    by the Very Large Telescope (VLT) while [JWST wasn’t launched until 2021](https://webb.nasa.gov/content/about/launch.html).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当谷歌推出其聊天机器人Bard时，它在首次公开演示中犯了一个事实错误。Bard [臭名昭著地声明](https://www.theverge.com/2023/2/8/23590864/google-ai-chatbot-bard-mistake-error-exoplanet-demo)詹姆斯·韦布太空望远镜（JWST）“拍摄了第一张来自我们太阳系外的行星的照片。”但实际上，[第一张外行星的图像是在2004年拍摄的](https://exoplanets.nasa.gov/resources/300/2m1207-b-first-image-of-an-exoplanet)，由非常大望远镜（VLT）拍摄，而[JWST直到2021年才发射](https://webb.nasa.gov/content/about/launch.html)。
- en: Hallucinations aren’t the only shortcoming of LLMs –– training on massive amounts
    of internet data also directly results in bias and copyright issues. First, let’s
    discuss *bias*, which refers to disparate outputs from a model across attributes
    of personal identity, such as race, gender, class, or religion. Given that LLMs
    learn characteristics and patterns from internet data, they also unfortunately
    inherent human-like prejudices, historical injustice, and cultural associations.
    While humans are biased, LLMs are *even* worse as they tend to amplify the biases
    present in the training data. For LLMs, men are successful doctors, engineers,
    and CEOs, women are supportive, beautiful receptionists and nurses, and LGBTQ
    people don't exist.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉并不是大型语言模型（LLMs）唯一的缺陷——在大量互联网数据上训练还直接导致了偏见和版权问题。首先，让我们讨论一下*偏见*，它指的是模型在个人身份属性（如种族、性别、阶级或宗教）方面产生的不同输出。鉴于LLMs从互联网数据中学习特征和模式，它们也不幸地继承了类似于人类的偏见、历史不公和文化关联。虽然人类有偏见，但LLMs*更*糟糕，因为它们往往会放大训练数据中的偏见。对于LLMs来说，男性是成功的医生、工程师和首席执行官，而女性则是支持性、美丽的接待员和护士，LGBTQ人群则不存在。
- en: Training LLMs on unfathomable amounts of internet data also raises questions
    about copyright issues. *Copyrights* are exclusive rights to a piece of creative
    work, where the copyright holder is the sole entity with the authority to reproduce,
    distribute, exhibit, or perform the work for a defined duration.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在不可估量的互联网数据上训练LLMs还引发了版权问题的质疑。*版权*是对创作作品的独占权利，版权持有者是唯一有权在特定时间段内复制、分发、展览或表演该作品的实体。
- en: Right now, the primary legal concern regarding LLMs isn't centered on the copyrightability
    of their outputs, but rather on the potential infringement of existing copyrights
    from the artists and writers whose creations contribute to their training datasets.
    The [Authors Guild has called upon](https://actionnetwork.org/petitions/authors-guild-open-letter-to-generative-ai-leaders)
    OpenAI, Google, Meta, and Microsoft, amongst others, to consent, credit, and fairly
    compensate writers for the use of copyrighted materials in training LLMs. Some
    authors and publishers have also taken this matter into their own hands.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，关于LLMs的主要法律问题不在于其输出的版权性，而在于现有版权的潜在侵犯，尤其是那些贡献了他们创作作品用于训练数据集的艺术家和作家。 [作家协会呼吁](https://actionnetwork.org/petitions/authors-guild-open-letter-to-generative-ai-leaders)
    OpenAI、谷歌、Meta 和微软等公司，要求他们同意、标注并公平地补偿作家使用版权材料来训练LLMs。一些作家和出版商也已将此事提上日程。
- en: LLM developers are presently facing several lawsuits from individuals and groups
    over copyright concerns –– Sarah Silverman, a comedian and actor, [joined a class
    of authors and publishers filing a lawsuit](https://www.bloomberglaw.com/public/desktop/document/SilvermanetalvOPENAIINCetalDocketNo323cv03416NDCalJul072023CourtD?doc_id=X2K29SU053M9IPPTMOJPHDL8KSC)
    against OpenAI claiming that they never granted permission for their copyrighted
    books to be used for training LLMs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: LLM开发者目前正面临来自个人和团体的几起关于版权的诉讼——喜剧演员和演员萨拉·席弗曼 [加入了一组作家和出版商起诉](https://www.bloomberglaw.com/public/desktop/document/SilvermanetalvOPENAIINCetalDocketNo323cv03416NDCalJul072023CourtD?doc_id=X2K29SU053M9IPPTMOJPHDL8KSC)
    OpenAI 的诉讼，声称他们从未授权将他们的版权书籍用于训练LLMs。
- en: While concerns pertaining to hallucinations, bias, and copyright are among the
    most well-documented issues associated with LLMs, they are by no means the sole
    concerns. To name a few, LLMs encode sensitive information, produce undesirable
    or toxic outputs, and can be exploited by adversaries. Undoubtedly, LLMs excel
    at generating coherent and contextually relevant text and should certainly be
    leveraged to improve efficiency, among other benefits, in a multitude of tasks
    and scenarios.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与幻觉、偏见和版权相关的担忧是与LLMs相关的最有文献记录的问题之一，但这绝不是唯一的担忧。举几个例子，LLMs编码了敏感信息，产生了不良或有害的输出，并且可能被对手利用。毫无疑问，LLMs在生成连贯且上下文相关的文本方面表现出色，应该毫无疑问地被用来提高效率等众多任务和场景中的效益。
- en: 'Researchers are also working to address some of these issues, but how to best
    control model outputs remains an open research question, so existing LLMs are
    far from infallible. Their outputs should always be examined for accuracy, factuality,
    and potential biases. If you get an output that is just *too good to be true*,
    it should tingle your spider senses to exercise caution and scrutinize further.
    The responsibility lies with the users to validate and revise any text generated
    from LLMs, or as we like to say, *generative AI: it’s your first draft, not the
    final*.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员也在致力于解决这些问题，但如何最佳控制模型输出仍然是一个未解的研究问题，因此现有的大型语言模型远非万无一失。它们的输出应始终检查准确性、事实性和潜在偏见。如果你获得的输出结果*好得令人难以置信*，那就要提高警惕，仔细审查。验证和修正任何由大型语言模型生成的文本是用户的责任，或者我们喜欢说的，*生成式人工智能：这是你的初稿，而非最终稿*。
- en: '[**Maggie Engler**](https://www.linkedin.com/in/maggie-engler-717852132/) is
    an engineer and researcher currently working on safety for large language models.
    She focuses on applying data science and machine learning to abuses in the online
    ecosystem, and is a domain expert in cybersecurity and trust and safety. Maggie
    is a committed educator and communicator, teaching as an adjunct instructor at
    the University of Texas at Austin School of Information.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[**玛吉·恩格勒**](https://www.linkedin.com/in/maggie-engler-717852132/)是一位工程师和研究员，目前致力于大型语言模型的安全性。她专注于将数据科学和机器学习应用于在线生态系统中的滥用问题，是网络安全以及信任和安全领域的专家。玛吉还是一位热心的教育者和传播者，担任德克萨斯大学奥斯汀分校信息学院的兼职讲师。'
- en: '**[](https://www.linkedin.com/in/numadhamani/)**[Numa Dhamani](https://www.linkedin.com/in/numadhamani/)****
    is an engineer and researcher working at the intersection of technology and society.
    She is a natural language processing expert with domain expertise in influence
    operations, security, and privacy. Numa has developed machine learning systems
    for Fortune 500 companies and social media platforms, as well as for start-ups
    and nonprofits. She has advised companies and organizations, served as the Principal
    Investigator on the United States Department of Defense’s research programs, and
    contributed to multiple international peer-reviewed journals.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/numadhamani/)**[努玛·达马尼](https://www.linkedin.com/in/numadhamani/)****是一位在技术与社会交汇处工作的工程师和研究员。她是自然语言处理领域的专家，具有影响力操作、安全性和隐私方面的专业知识。努玛为财富500强公司、社交媒体平台、初创企业和非营利组织开发了机器学习系统。她曾为公司和组织提供咨询，担任美国国防部研究计划的首席研究员，并为多个国际同行评审期刊做出了贡献。'
- en: More On This Topic
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[5 Portfolio Projects for Final Year Data Science Students](https://www.kdnuggets.com/5-portfolio-projects-for-final-year-data-science-students)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个适合数据科学学生的作品集项目](https://www.kdnuggets.com/5-portfolio-projects-for-final-year-data-science-students)'
- en: '[My First Six Months as a Data Scientist](https://www.kdnuggets.com/2021/12/first-six-months-data-scientist.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我作为数据科学家的前六个月](https://www.kdnuggets.com/2021/12/first-six-months-data-scientist.html)'
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在没有工作经验的情况下获得第一份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
- en: '[Benefits Of Becoming A Data-First Enterprise](https://www.kdnuggets.com/2022/07/benefits-becoming-datafirst-enterprise.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为数据驱动企业的好处](https://www.kdnuggets.com/2022/07/benefits-becoming-datafirst-enterprise.html)'
- en: '[How I Got My First Job as a Data Scientist](https://www.kdnuggets.com/2023/02/got-first-job-data-scientist.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我如何获得我的第一份数据科学工作](https://www.kdnuggets.com/2023/02/got-first-job-data-scientist.html)'
- en: '[First Open Source Implementation of DeepMind’s AlphaTensor](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepMind的AlphaTensor首次开源实现](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)'
