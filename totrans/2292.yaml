- en: Machine Learning Algorithms Explained in Less Than 1 Minute Each
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/07/machine-learning-algorithms-explained-less-1-minute.html](https://www.kdnuggets.com/2022/07/machine-learning-algorithms-explained-less-1-minute.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Machine Learning Algorithms Explained in Less Than 1 Minute Each](../Images/513b4a116bd442cb812272e0c636791c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [pch.vector](https://www.freepik.com/free-vector/man-digital-era-algorithm-ai-social-system-21st-century-workforce-challenge-flat-vector-illustration-smart-business-process-human-resources-automation-artificial-intelligence-concept_22343897.htm#query=Algorithms&position=23&from_view=search&track=sph)
    on Freepik
  prefs: []
  type: TYPE_NORMAL
- en: This article will explain some of the most well known machine learning algorithms
    in less than a minute - helping everyone to understand them!
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the simplest Machine learning algorithms out there, Linear Regression
    is used to make predictions on continuous dependent variables with knowledge from
    independent variables. A dependent variable is the effect, in which its value
    depends on changes in the independent variable.
  prefs: []
  type: TYPE_NORMAL
- en: You may remember the line of best fit from school - this is what Linear Regression
    produces. A simple example is predicting one's weight depending on their height.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic Regression, similar to Linear Regression, is used to make predictions
    on categorical dependent variables with knowledge of independent variables. A
    categorical variable has two or more categories. Logistic Regression classifies
    outputs that can only be between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can use Logistic Regression to determine whether a student
    will be admitted or not to a particular college depending on their grades - either
    Yes or No, or 0 or 1.
  prefs: []
  type: TYPE_NORMAL
- en: Decision Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Decision Trees (DTs) is a probability tree-like structure model that continuously
    splits data to categorize or make predictions based on the previous set of questions
    that were answered. The model learns the features of the data and answers questions
    to help you make better decisions.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can use a decision tree using the answers Yes or No to determine
    a specific species of bird using data features such as feathers, ability to fly
    or swim, beak type, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to Decision Trees, Random Forest is also a tree-based algorithm. Where
    Decision Tree consists of one tree, Random forest uses multiple decision trees
    for making decisions - a forest of trees.
  prefs: []
  type: TYPE_NORMAL
- en: It combines multiple models to make predictions and can be used in Classification
    and Regression tasks.
  prefs: []
  type: TYPE_NORMAL
- en: K-Nearest Neighbors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: K-Nearest Neighbors uses the statistical knowledge of how close a data point
    is to another data point and determines if these data points can be grouped together.
    The closeness in the data points reflects the similarities in one another.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if we had a graph which had a group of data points that were close
    to one another called Group A and another group of data points that were in close
    proximity to one another called Group B. When we input a new data point, depending
    which group the new data point is nearer to - that will be their new classified
    group.
  prefs: []
  type: TYPE_NORMAL
- en: Support Vector Machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to Nearest Neighbor, Support Vector Machines performs classification,
    regression and outlier detection tasks. It does this by drawing a hyperplane (a
    straight line) to separate the classes. The data points that are located on one
    side of the line will be labeled as Group A, whilst the points on the other side
    will be labeled as Group B.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when a new data point is inputted, depending on which side of the
    hyperplane and its location within the margin it is - this will determine which
    group the data point belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: Naive Bayes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Naive Bayes is based on Bayes’ Theorem which is a mathematical formula used
    for calculating conditional probabilities. Conditional probability is the chance
    of an outcome occurring given that another event has also occurred.
  prefs: []
  type: TYPE_NORMAL
- en: It predicts that the probabilities for each class belongs to a particular class
    and that the class with the highest probability is considered the most likely
    class.
  prefs: []
  type: TYPE_NORMAL
- en: k-means Clustering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: K-means clustering, similar to nearest neighbors but uses the method of clustering
    to group similar items/data points in clusters. The number of groups is referred
    to as K. You do this by selecting the k value, initializing the centroids and
    then selecting the group and finding the average.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if there are 3 clusters present and a new data point is inputted,
    depending on which cluster it falls in - that is the cluster they belong to.
  prefs: []
  type: TYPE_NORMAL
- en: Bagging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bagging is also known as Bootstrap aggregating and is an ensemble learning technique.
    Bagging is used in both regression and classification models and aims to avoid
    overfitting of data and reduce the variance in the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting is when a model fits exactly against its training data - basically
    not teaching us anything and can be due to various reasons. Random Forest is an
    example of Bagging.
  prefs: []
  type: TYPE_NORMAL
- en: Boosting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The overall aim of Boosting is to convert weak learners to strong learners.
    Weak learners are found by applying base learning algorithms which then generates
    a new weak prediction rule. A  random sample of data is inputted in a model and
    then trained sequentially, aiming to train the weak learners and trying to correct
    its predecessor
  prefs: []
  type: TYPE_NORMAL
- en: XGBoost, which stands for Extreme Gradient Boosting, is used in Boosting.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality Reduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dimensionality reduction is used to reduce the number of input variables in
    the training data, by reducing the dimension of your feature set. When a model
    has a high number of features, it is naturally more complex leading to a higher
    chance of overfitting and decrease in accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you had a dataset with a hundred columns, dimensionality reduction
    will reduce the number of columns down to twenty. However, you will need Feature
    Selection to select relevant features and Feature Engineering to generate new
    features from existing features.
  prefs: []
  type: TYPE_NORMAL
- en: The Principal Component Analysis (PCA) technique is a type of Dimensionality
    Reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of this article was to help you understand Machine Learning algorithms
    in the most simplest terms. If you would like some more in depth understanding
    on each of them, have a read of this [Popular Machine Learning Algorithms](/2022/05/popular-machine-learning-algorithms.html).
  prefs: []
  type: TYPE_NORMAL
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Multi-modal deep learning in less than 15 lines of code](https://www.kdnuggets.com/2023/01/predibase-multi-modal-deep-learning-less-15-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Become a Business Intelligence Analyst in Less Than 6 Months](https://www.kdnuggets.com/become-a-business-intelligence-analyst-in-less-than-6-months)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlock the Secrets of LLMs in 60-Minute with Andrej Karpathy](https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Range of NLP Applications in the Real World: A Different…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Black Friday Deal - Master Machine Learning for Less with DataCamp](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
