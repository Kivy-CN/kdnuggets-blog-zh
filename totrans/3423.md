# 《Tensorflow的最温和介绍 – 第二部分》

> 原文：[https://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html](https://www.kdnuggets.com/2016/08/gentlest-introduction-tensorflow-part-2.html)

**作者：Soon Hin Khor，东京Tensorflow Meetup的联合组织者**。

> **编辑说明**：您可能希望在继续之前查看一下[本教程的第1部分](/2016/08/gentlest-introduction-tensorflow-part-1.html)。

### 快速回顾

在[上一篇文章](https://medium.com/@khor/the-gentlest-introduction-to-tensorflow-248dc871a224)中，我们使用Tensorflow (TF) 构建并学习了一个具有单一特征的线性回归模型，以便给定特征值（房屋大小/平方米），我们可以预测结果（房屋价格/美元）。

下面是带有插图的回顾：

1.  我们有一些房屋大小和房屋价格的数据（灰色圆点）。

1.  我们使用线性回归（红色虚线）来建模数据。

1.  我们通过训练W和b（线性回归模型的参数）来找到‘最佳’模型，以最小化‘成本’（垂直蓝线的长度总和，代表预测和实际结果之间的差异）。

1.  给定任何房屋大小，我们可以使用线性模型来预测房屋大小（带箭头的虚线蓝色线）。

![Image](../Images/db33e4c8945294c495957b1316e0b4f3.png)

*线性回归在一个图中解释*

在机器学习（ML）文献中，我们经常遇到‘训练’这个术语，让我们字面上看一下它在TF中的含义。

### 线性回归建模

```py
Linear Model (in TF notation): y = tf.matmul(x,W) + b
```

线性回归的目标是找到W和b，使得给定任何特征值(x)，我们可以通过将W、x、b值代入模型中来找到预测值(y)。

然而，要找到可以提供准确预测的W和b，我们需要使用可用的数据（实际特征(x)和实际结果(y_)的多个对），注意*下划线*。

### ‘训练’说明

为了找到最佳的W和b值，我们可以从任何W和b值开始。我们还需要定义一个成本函数，它是*预测*（y）与给定特征值(x)的*实际结果*（y_）之间的*difference*的度量。为了简单起见，我们使用最小[均方误差](https://en.wikipedia.org/wiki/Mean_squared_error)（MSE）作为我们的成本函数。

```py
Cost function (in TF notation): tf.reduce_mean(tf.square(y_ - y))
```

通过最小化成本函数，我们可以得到良好的W和b值。

我们用于训练的代码实际上非常简单，并且标记为[A, B, C, D]，我们稍后将会提到。完整的源代码在[Github](https://github.com/nethsix/gentle_tensorflow/blob/master/code/linear_regression_one_feature_using_mini_batch_with_tensorboard.py)上。

```py
# ... (snip) Variable/Constants declarations (snip) ...

# [A] TF.Graph
y = tf.matmul(x,W) + b
cost = tf.reduce_mean(tf.square(y_-y))

# [B] Train with fixed 'learn_rate'
learn_rate = 0.1
train_step =
    tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)

for i in range(steps):
  # [C] Prepare datapoints
  # ... (snip) Code to prepare datapoint as xs, and ys (snip) ...

  # [D] Feed Data at each step/epoch into 'train_step'
  feed = { x: xs, y_: ys }
  sess.run(train_step, feed_dict=feed)
```

我们的线性模型和成本函数方程[A]可以表示为TF图，如下所示：

![Image](../Images/f9f78830d98e6364ce143e3d87f069fb.png)

*创建一个包含模型和成本的TF图，并用一些值初始化W和b*

接下来，我们选择一个数据点(x, y_) [C]，并将其输入TF图以获取预测值(y)以及成本。

![Image](../Images/859098e2b745c3e05afe434678fb3f81.png)

*使用单一数据点计算预测（y）和成本*

为了更好地调整 W 和 b，我们使用 TF 的 *tf.train.GradientDescentOptimizer* [B] 进行梯度下降以减少成本。用非技术性的话说：根据当前成本以及成本如何随其他变量（即 W 和 b）变化的图形，优化器将对 W 和 b 进行小的调整（增减），使得我们的预测对 *那个单一数据点* 更加准确。

![Image](../Images/1c5d01665352d94dd475d64cd4a1d1a9.png)

*根据当前成本，确定如何调整 W 和 b 以改善预测（y）并减少成本*

训练周期的最后一步是更新 W 和 b。请注意，“周期”在 ML 文献中也被称为“轮次”。

![Image](../Images/b79b5679f1ceeb28278aaab148182ea2.png)

*在调整 W 和 b 后更新它们，并在进入下一轮训练之前*

在下一个训练轮次中，重复这些步骤，但使用不同的数据点！

![Image](../Images/ddc1f1f3b8fb9cf5fb1faee426bfea52.png)

*使用不同的数据点进行训练*

使用各种数据点可以使我们的模型更加通用，即它学习可以用于预测 *任何* 特征值的 W 和 b 值。请注意：

+   在大多数情况下，数据点越多，你的模型学习和泛化能力就越强

+   如果你训练的轮次超过了你的数据点数量，你可以重复使用数据点，这不是问题。梯度下降优化器总是使用数据点 *和* 成本（从数据点计算的，具有该轮次的 W 和 b 值）来调整 W 和 b；优化器可能之前见过那个数据点，但成本不同，因此它会学到新的东西，并以不同的方式调整 W 和 b。

你可以将模型训练固定的轮次，或直到它达到一个令人满意的成本阈值。

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行 IT 相关工作

* * *

### 更多相关内容

+   [TensorFlow 用于计算机视觉 - 转移学习变得简单](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)

+   [PyTorch 还是 TensorFlow？比较流行的机器学习框架](https://www.kdnuggets.com/2022/02/packt-pytorch-tensorflow-comparing-popular-machine-learning-frameworks.html)

+   [Tensorflow 的“Hello World”](https://www.kdnuggets.com/2022/05/hello-world-tensorflow.html)

+   [使用 Tensorflow 训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)

+   [使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [免费 TensorFlow 2.0 完整课程](https://www.kdnuggets.com/2023/02/free-tensorflow-20-complete-course.html)
