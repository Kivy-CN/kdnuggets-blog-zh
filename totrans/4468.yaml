- en: Introduction to Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络简介
- en: 原文：[https://www.kdnuggets.com/2020/06/introduction-convolutional-neural-networks.html](https://www.kdnuggets.com/2020/06/introduction-convolutional-neural-networks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/06/introduction-convolutional-neural-networks.html](https://www.kdnuggets.com/2020/06/introduction-convolutional-neural-networks.html)
- en: '[comments](#comments)![Figure](../Images/76856bd851d69a8458b5d82fd7bdb528.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图示](../Images/76856bd851d69a8458b5d82fd7bdb528.png)'
- en: '[Credits](https://nulltx.com/deep-neural-network-creates-surprisingly-accurate-simulations-of-the-universe/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[致谢](https://nulltx.com/deep-neural-network-creates-surprisingly-accurate-simulations-of-the-universe/)'
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Have you ever thought how facial recognition works on [social media](https://www.simplilearn.com/essentials-of-social-media-marketing-article),
    or how object detection helps in building self-driving cars, or how disease detection
    is done using visual imagery in healthcare? It’s all possible thanks to convolutional
    neural networks (CNN).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否想过面部识别如何在 [社交媒体](https://www.simplilearn.com/essentials-of-social-media-marketing-article)
    上工作，或者对象检测如何在自动驾驶汽车中发挥作用，或者疾病检测如何通过视觉影像在医疗保健中完成？这一切都得益于卷积神经网络（CNN）。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: Just like how a child learns to recognize objects, we need to show an algorithm,
    millions of pictures before it can generalize the input and make predictions for
    images it has never seen before.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 就像孩子学习识别对象一样，我们需要向算法展示数百万张图片，才能使其对输入进行归纳并对从未见过的图像进行预测。
- en: Computers ‘see’ in a different way than we do. Their world consists of only
    numbers. Every image can be represented as 2-dimensional arrays of numbers, known
    as pixels.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机的“视野”与我们不同。它们的世界仅由数字构成。每个图像可以表示为二维的数字数组，称为像素。
- en: '![Figure](../Images/ae907df3742070df57547ffda56509fa.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/ae907df3742070df57547ffda56509fa.png)'
- en: '[Credits](https://www.commonlounge.com/discussion/c9975025c9ff473c8f9ed2c4b1c3ea6a)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[致谢](https://www.commonlounge.com/discussion/c9975025c9ff473c8f9ed2c4b1c3ea6a)'
- en: But the fact that they perceive images differently, doesn’t mean we can’t train
    them to recognize patterns as we do. We just have to think of what an image is
    different.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们以不同的方式感知图像，并不意味着我们不能训练它们像我们一样识别模式。我们只需要考虑图像的不同之处。
- en: 'To teach an algorithm on how to recognize objects in images, we use a specific
    type of [Artificial Neural Network](https://medium.com/@daphn3cor/building-a-3-layer-neural-network-from-scratch-99239c4af5d3):
    a Convolutional Neural Network (CNN). Their name stems from one of the most important
    operations in the network called [convolution](https://en.wikipedia.org/wiki/Convolution).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要教一个算法识别图像中的对象，我们使用一种特定类型的 [人工神经网络](https://medium.com/@daphn3cor/building-a-3-layer-neural-network-from-scratch-99239c4af5d3)：卷积神经网络（CNN）。它们的名称源自网络中一种重要操作叫做
    [卷积](https://en.wikipedia.org/wiki/Convolution)。
- en: Convolutional Neural Networks
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: '**Convolutional Neural Networks(CNN or ConvNets)** are ordinary neural networks
    that assume that the inputs are image. They are used to analyze and classify images,
    cluster images by similarity, and perform object recognition within a frame. For
    example, convolutional neural networks (ConvNets or CNNs) are used to identify
    faces, individuals, street signs, tumors, platypuses, and many other aspects of
    visual data.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNN 或 ConvNets）** 是普通的神经网络，假设输入是图像。它们用于分析和分类图像，通过相似性对图像进行聚类，并在框架内执行对象识别。例如，卷积神经网络（ConvNets
    或 CNNs）用于识别面孔、个人、路标、肿瘤、鸭嘴兽以及视觉数据的许多其他方面。'
- en: Biological connection of CNN
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNN 的生物学连接
- en: When you first heard of the term convolutional neural networks, you may have
    thought of something related to neuroscience or biology, and you would be right.
    Sort of. CNN’s do take a biological inspiration from the visual cortex. The visual
    cortex has small regions of cells that are sensitive to specific regions of the
    visual field.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当你第一次听到卷积神经网络这个术语时，你可能会想到与神经科学或生物学有关的东西，你的想法是对的。某种程度上。CNN确实从视觉皮层中获得了生物学上的启发。视觉皮层有小区域的细胞对视觉场的特定区域敏感。
- en: This idea was expanded upon by a fascinating experiment by Hubel and Wiesel
    in 1962 ([Video](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)) where they showed
    that some individual neuronal cells in the brain responded (or fired) only in
    the presence of edges of a certain orientation. For example, some neurons fired
    when exposed to vertical edges and some when shown horizontal or diagonal edges.
    Hubel and Wiesel found out that all of these neurons were organized in a columnar
    architecture and that together, they were able to produce visual perception. This
    idea of specialized components inside of a system having specific tasks (the neuronal
    cells in the visual cortex looking for specific characteristics) is one that machines
    use as well and is the basis behind CNNs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法在1962年通过Hubel和Wiesel的一项引人入胜的实验得到了扩展（[视频](https://www.youtube.com/watch?v=Cw5PKV9Rj3o)），他们展示了大脑中的某些单个神经元细胞仅在特定方向的边缘存在时才会响应（或发放）。例如，一些神经元在暴露于垂直边缘时会发放，而在水平或对角边缘出现时也会发放。Hubel和Wiesel发现所有这些神经元都以柱状结构组织在一起，并且它们能够共同产生视觉感知。系统内专门组件具有特定任务的这种思想（视觉皮层中的神经细胞寻找特定特征）也是机器使用的基础，并且是CNN的基础。
- en: Before you move ahead I would strongly recommend checking the below article
    to have a basic understanding of Neural Networks if you are a beginner in deep
    learning.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在你继续之前，如果你是深度学习的初学者，我强烈建议查看下面的文章，以便对神经网络有一个基本的理解。
- en: '[**Introduction to Artificial Neural Networks**](/2019/10/introduction-artificial-neural-networks.html)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[**人工神经网络简介**](/2019/10/introduction-artificial-neural-networks.html)'
- en: How Convolutional Neural Networks learn?
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积神经网络如何学习？
- en: Images are made up of pixels. Each pixel is represented by a number between
    0 and 255\. Therefore each image has a digital representation which is how computers
    can work with images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由像素组成。每个像素由0到255之间的一个数字表示。因此，每个图像都有一个数字表示，这就是计算机能够处理图像的方式。
- en: There are 4 major operations in CNN image detection/classification.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CNN图像检测/分类中有4个主要操作。
- en: Convolution
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积
- en: Activation map
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活图
- en: Max pooling
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最大池化
- en: Flattening
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扁平化
- en: Fully connected layer
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全连接层
- en: 1.1 Convolution
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 卷积
- en: 'Convolution operation works on 2 signals in 1D and 2 images in 2D. Mathematically
    a convolution is a combined integration of two functions that shows you how one
    function modifies the other:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作在1D的两个信号和2D的两幅图像上进行。数学上，卷积是两个函数的综合积分，展示了一个函数如何修改另一个函数：
- en: '![](../Images/5cce6c4e01e0a78da5f63a2c3e2816e6.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cce6c4e01e0a78da5f63a2c3e2816e6.png)'
- en: The main purpose of a convolutional layer is to detect features or visual features
    in images such as edges, lines, color drops, etc. This is a very interesting property
    because, once it has learned a characteristic at a specific point in the image,
    it can recognize it later in any part of it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层的主要目的是检测图像中的特征或视觉特征，例如边缘、线条、颜色斑点等。这是一个非常有趣的特性，因为一旦它在图像的特定点学会了某个特征，它就能在图像的任何部分识别它。
- en: CNN’s make use of **filters **(also known as **kernels**, **feature detectors**),
    to detect features, such as edges, are present throughout an image. A filter is
    just a matrix of values, called weights, that are trained to detect specific features.
    The filter moves over each part of the image to check if the feature it is meant
    to detect is present. To provide a value representing how confident it is that
    a specific feature is present, the filter carries out a **convolution operation**,
    which is an element-wise product and sum between two matrices.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CNN使用**滤波器**（也称为**卷积核**、**特征检测器**）来检测图像中是否存在诸如边缘等特征。滤波器只是一个值矩阵，称为权重，经过训练以检测特定特征。滤波器在图像的每个部分移动，以检查是否存在其预期检测的特征。为了提供一个值，表示它对特定特征存在的信心，滤波器执行**卷积操作**，这是一种矩阵之间逐元素的乘积和求和。
- en: When the feature is present in part of an image, the convolution operation between
    the filter and that part of the image results in a real number with a high value.
    If the feature is not present, the resulting value is low.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像的某部分存在特征时，滤波器与该部分图像之间的卷积操作结果是一个高值的实数。如果特征不存在，结果值则较低。
- en: In the below image a filter that is trained for detecting plus sign is passed
    over a part of the image. Since that part of the image contains the same plus
    that the filter is looking for, the result of the convolution operation is a large
    number.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，训练用于检测加号的滤波器被应用于图像的一部分。由于该部分图像包含了滤波器所寻找的相同加号，卷积操作的结果是一个大数值。
- en: '![](../Images/6d805edc1474ceee926cbd8bb795dcb4.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d805edc1474ceee926cbd8bb795dcb4.png)'
- en: '**Convolution(element-wise product and sum)** = (50*50)+(50*50)+(50*50)+(50*50)+(50*50)+(60*60)+(60*60)+(40*50)+(40*50)+(50*50)+(50*50)+(40*50)+(50*50)+(50*50)
    = **Very large real number**'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**卷积（逐元素乘积和求和）** = (50*50)+(50*50)+(50*50)+(50*50)+(50*50)+(60*60)+(60*60)+(40*50)+(40*50)+(50*50)+(50*50)+(40*50)+(50*50)+(50*50)
    = **非常大的实数**'
- en: But when that same filter/kernel is passed over a part of the image with a considerably
    different set of edges, the convolution’s output is small, meaning that there
    was no strong presence of any plus sign and element-wise product and sum will
    result in zero or very less value.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但是当相同的滤波器/核应用于具有显著不同边缘集合的图像部分时，卷积的输出会很小，这意味着没有明显的加号存在，逐元素乘积和求和将导致零或非常小的值。
- en: So we need N number of feature detectors to detect different curves/edges of
    the image.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要N个特征检测器来检测图像的不同曲线/边缘。
- en: '![Figure](../Images/3178f437b12675aace1fa8941f1d05fc.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3178f437b12675aace1fa8941f1d05fc.png)'
- en: '[feature detection in action](https://www.analyticssteps.com/blogs/convolutional-neural-network-cnn-graphical-visualization-code-explanation)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[特征检测实例](https://www.analyticssteps.com/blogs/convolutional-neural-network-cnn-graphical-visualization-code-explanation)'
- en: 'The result of passing this filter over the entire image is an output matrix
    called **feature maps or convolved features **that stores the convolutions of
    this filter over various parts of the image. Now since we have multiple filters,
    we end up with a 3D output: one 2D feature map per filter. The filter must have
    the same number of channels as the input image so that the element-wise multiplication
    can take place.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将该滤波器应用于整个图像的结果是一个称为**特征图或卷积特征**的输出矩阵，它存储了该滤波器在图像不同部分上的卷积结果。由于我们有多个滤波器，因此我们得到一个3D输出：每个滤波器一个2D特征图。滤波器必须具有与输入图像相同的通道数，以便进行逐元素乘法。
- en: Additionally, a filter can be slid over the input image at varying intervals,
    using a **stride** value. The stride value dictates by how much the filter should
    move at each step.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以通过使用**步幅**值，在不同的间隔上滑动滤波器到输入图像上。步幅值决定了滤波器在每一步移动的距离。
- en: '![Figure](../Images/4a140f11a63e6600313c166333150695.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/4a140f11a63e6600313c166333150695.png)'
- en: '[The convolution of a filter over a 2D image](http://www.michaelfxu.com/neural%20networks%20series/neural-networks-pt3-cnn/)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[滤波器在2D图像上的卷积](http://www.michaelfxu.com/neural%20networks%20series/neural-networks-pt3-cnn/)'
- en: 'We can determine the number of output layers of a given convolutional block:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确定给定卷积块的输出层数量：
- en: '![](../Images/c3459147e68800da6344093c4d46edf5.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3459147e68800da6344093c4d46edf5.png)'
- en: 1.2 Padding
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 填充
- en: One tricky issue when applying convolutional layers is that we tend to lose
    pixels on the perimeter of our image. Since we typically use small kernels, for
    any given convolution, we might only lose a few pixels, but this can add up as
    we apply many successive convolutional layers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 应用卷积层时一个棘手的问题是我们往往会丢失图像边缘的像素。由于我们通常使用小型核，对于任何给定的卷积，我们可能只会丢失几个像素，但随着我们应用许多连续的卷积层，这种丢失会逐渐积累。
- en: '**Padding refers to the number of pixels added to an image when it is being
    processed by the kernel of a CNN.**'
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**填充是指在图像被CNN的核处理时，添加到图像上的像素数量。**'
- en: One solution to assist the kernel with processing the image, pad the image with
    zeros(zero-padding) to allow for more space for the kernel to cover the image.
    Adding padding to an image processed by a CNN allows for a more accurate analysis
    of images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个解决方案是通过在图像周围添加零（零填充）来帮助核处理图像，从而为核提供更多的覆盖图像的空间。对CNN处理的图像添加填充可以实现更准确的图像分析。
- en: '![Figure](../Images/c94145371a2c4da9a00206bd2dccf207.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/c94145371a2c4da9a00206bd2dccf207.png)'
- en: Extra zeros are added at the perimeter of the input image so that all the features
    are captured.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入图像的周围添加额外的零，以便捕获所有特征。
- en: 2.1 Activation Map
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 激活图
- en: These feature maps must be passed through a non-linear mapping. The feature
    maps are summed with a bias term and passed through a non-linear activation function: **ReLu**.
    The purpose of the activation function is to introduce non-linearity into our
    network because the images are made of different objects that are not linear to
    each other so the images are highly non-linear.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征图必须经过非线性映射。特征图与偏置项相加，并通过非线性激活函数**ReLu**。激活函数的目的是将非线性引入网络中，因为图像由彼此不线性的不同对象组成，所以图像具有高度的非线性。
- en: 2.2 Max Pooling
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 最大池化
- en: After ReLU comes to a pooling step, in which the CNN downsamples the convolved
    feature (to save on processing time), while also reducing the size of the image.
    This helps reduce overfitting, which would occur if CNN is given too much information,
    especially if that information is not relevant in classifying the image.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU之后是一个池化步骤，在该步骤中，CNN对卷积特征进行下采样（以节省处理时间），同时还减少图像的大小。这有助于减少过拟合，如果CNN接收到过多的信息，特别是当这些信息在分类图像时不相关时，过拟合会发生。
- en: There are different types of pooling, for example, max pooling and min pooling.
    In **max pooling**, a window passes over an image according to a set stride value.
    At each step, the maximum value within the window is pooled into an output matrix,
    hence the name max pooling.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的池化，例如最大池化和最小池化。在**最大池化**中，窗口按照设定的步幅值在图像上滑动。在每一步，窗口内的最大值会被池化到输出矩阵中，因此得名最大池化。
- en: These values then form a new matrix called a **pooled feature map**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值形成一个新的矩阵，称为**池化特征图**。
- en: '![](../Images/9e2d0e32383de37682ad552f630d411b.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e2d0e32383de37682ad552f630d411b.png)'
- en: An added benefit of max-pooling is that it forces the network to focus on a
    few neurons instead of all of them which has a regularizing effect on the network,
    making it less likely to overfit the training data and hopefully generalize well.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化的一个额外好处是，它迫使网络关注少数神经元，而不是所有神经元，这对网络有正则化作用，使其不易过拟合训练数据，并希望能够很好地泛化。
- en: 3.3 Flattening
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 扁平化
- en: 'After multiple convolution layers and downsampling operations, the 3D representation
    of the image is converted into a feature vector that is passed into a multi-layer
    perceptron to output probabilities. The following image describes the flattening
    operation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 经过多个卷积层和下采样操作后，图像的3D表示会转换成一个特征向量，该特征向量会传入多层感知机以输出概率。下图描述了扁平化操作：
- en: '![Figure](../Images/ae95609d85801e010b91c49570688e4e.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/ae95609d85801e010b91c49570688e4e.png)'
- en: Flattening operation
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 扁平化操作
- en: The rows are concatenated to form a long feature vector. If multiple input layers
    are present, its rows are also concatenated to form an even longer feature vector.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 行被连接起来形成一个长特征向量。如果存在多个输入层，则这些行也会连接起来形成一个更长的特征向量。
- en: 4\. Fully Connected Layer
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 全连接层
- en: In this step, the flattened feature map is passed through a neural network.
    This step is made up of the input layer, the fully connected layer, and the output
    layer. The fully connected layer is similar to the hidden layer in ANNs but in
    this case, it’s fully connected. The output layer is where we get the predicted
    classes. The information is passed through the network and the error of prediction
    is calculated. The error is then backpropagated through the system to improve
    the prediction.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，扁平化的特征图会传递给一个神经网络。这一步包括输入层、全连接层和输出层。全连接层类似于ANN中的隐藏层，但在这种情况下，它是完全连接的。输出层是我们得到预测类别的地方。信息会通过网络传递，并计算预测的误差。然后，误差会通过系统进行反向传播，以改进预测。
- en: '![Figure](../Images/9e0e7f9e2a7a39b4b64f275db136298b.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/9e0e7f9e2a7a39b4b64f275db136298b.png)'
- en: Fully connected layer
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层
- en: The final output produced by the dense layer neural network doesn’t usually
    add up to one. However, these outputs must be brought down to numbers between
    zero and one, which represent the probability of each class. This is the role
    of the Softmax function.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 密集层神经网络产生的最终输出通常不会加起来等于一。然而，这些输出必须被缩减到零到一之间的数值，这些数值代表每个类别的概率。这就是Softmax函数的作用。
- en: 'The output of this dense layer is therefore passed through the **Softmax activation
    function**, which maps all the final dense layer outputs to a vector whose elements
    sum up to one:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这一密集层的输出会传递给**Softmax激活函数**，该函数将所有最终密集层的输出映射到一个元素总和为一的向量中：
- en: '![Figure](../Images/704e94f19a5bae5956ff08428f0aba44.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/704e94f19a5bae5956ff08428f0aba44.png)'
- en: Where x denotes each element in the final layer’s outputs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 x 表示最终层输出中的每个元素。
- en: The way this fully connected layer works is that it looks at the output of the
    previous layer (which as we remember should represent the activation maps of high-level
    features) and determines which features most correlate to a particular class.
    For example, if the program is predicting that some image is a dog, it will have
    high values in the activation maps that represent high-level features like a paw
    or 4 legs, etc. Similarly, if the program is predicting that some image is a bird,
    it will have high values in the activation maps that represent high-level features
    like wings or a beak, etc. A Fully Connected layer looks at what high level features
    most strongly correlate to a particular class and has particular weights so that
    when you compute the products between the weights and the previous layer, you
    get the correct probabilities for the different classes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层的工作方式是查看前一层的输出（我们记得应该表示高层特征的激活图），并确定哪些特征与特定类别最相关。例如，如果程序预测某图像是狗，它将在表示高层特征如爪子或四条腿等的激活图中具有高值。同样，如果程序预测某图像是鸟，它将在表示高层特征如翅膀或喙等的激活图中具有高值。全连接层查看哪些高层特征最强烈地与特定类别相关，并具有特定的权重，以便当你计算权重和前一层之间的乘积时，可以得到不同类别的正确概率。
- en: 'Let’s summarize to see the entire process about how CNN recognizes:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下 CNN 如何识别的整个过程：
- en: The pixels from the image are fed to the convolutional layer that performs the
    convolution operation
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像中的像素被送入执行卷积操作的卷积层。
- en: It results in a convolved map
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它生成一个卷积映射。
- en: The convolved map is applied to a ReLU function to generate a rectified feature
    map
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积映射应用于 ReLU 函数生成一个整流特征图。
- en: The image is processed with multiple convolutions and ReLU layers for locating
    the features
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像经过多次卷积和 ReLU 层处理以定位特征。
- en: Different pooling layers with various filters are used to identify specific
    parts of the image
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同的池化层和各种滤波器来识别图像的特定部分。
- en: The pooled feature map is flattened and fed to a fully connected layer to get
    the final output
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化特征图被展平并馈送到全连接层以获得最终输出。
- en: CNN Implementation with Keras
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Keras 实现 CNN
- en: Now let’s write the code that can classify images. This code can be applied
    with most image datasets available with little modification. So once you have
    your image data, separate them into folders and give them their appropriate names,
    i.e the training set and the test set.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写能够分类图像的代码。这段代码可以在大多数图像数据集上应用，只需稍作修改。因此，一旦你拥有图像数据，将它们分开到文件夹中并命名，例如训练集和测试集。
- en: Building the CNN
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建 CNN
- en: 'In this step, the first step is to build the Convolutional Neural Network with
    below-mentioned layers:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，第一步是构建包含以下提到的层的卷积神经网络：
- en: '***Sequential*** is used to initialize the neural network.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Sequential*** 用于初始化神经网络。'
- en: '***Convolution2D***is used to make the convolutional network that deals with
    the images.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Convolution2D***用于构建处理图像的卷积网络。'
- en: '***MaxPooling2D***layer is used to add the pooling layers.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***MaxPooling2D*** 层用于添加池化层。'
- en: '***Flatten***is the function that converts the pooled feature map to a single
    column that is passed to the fully connected layer.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Flatten***是将池化特征图转换为传递到全连接层的单列的函数。'
- en: '***Dense***adds the fully connected layer to the neural network.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Dense***添加了一个全连接层到神经网络中。'
- en: Once the network is built, then compile/train the network using [Stochastic
    Gradient Descent(SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent).
    Gradient Descent works fine when we have a convex curve. But if we don’t have
    a convex curve, Gradient Descent fails. Hence, in Stochastic Gradient Descent,
    few samples are selected randomly instead of the whole data set for each iteration.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦网络建立完成，然后使用 [随机梯度下降(SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)
    来编译/训练网络。梯度下降在我们有凸曲线时效果很好。但如果我们没有凸曲线，梯度下降会失败。因此，在随机梯度下降中，每次迭代随机选择一些样本，而不是整个数据集。
- en: Now since the network is compiled, its time to train the CNN model with the
    training images.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在网络已经编译完毕，是时候用训练图像来训练 CNN 模型了。
- en: '**Fitting the CNN to the images**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**将 CNN 适配到图像上**'
- en: Perform Image Augmentation instead of training your model with lots of images
    we can train our model with fewer images and training the model with different
    angles and modifying the images. Keras has this **ImageDataGenerator** class which
    allows the users to perform image augmentation on the fly in a very easy way.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 执行图像增强，与其用大量图像训练模型，不如用较少的图像进行训练，并通过不同角度和修改图像来训练模型。Keras有一个**ImageDataGenerator**类，可以让用户以非常简单的方式动态执行图像增强。
- en: Once you have trained your CNN network with the training image dataset, its
    time to check the accuracy of your model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你用训练图像数据集训练了你的CNN网络，就该检查模型的准确性了。
- en: Conclusion
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: CNN is the best artificial neural network, it is used for modeling image but
    it is not limited to just modeling of the image but out of many of its applications.
    There are many improvised versions based on CNN architecture like [AlexNet, VGG,
    YOLO](https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5),
    and many more.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是最好的人工神经网络，它不仅用于图像建模，还有许多其他应用。基于CNN架构有很多改进版，如 [AlexNet、VGG、YOLO](https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5)
    等。
- en: Well, that’s all for this article hope you guys have enjoyed reading it and
    I’ll be glad if the article is of any help. Feel free to share your comments/thoughts/feedback
    in the comment section.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，这篇文章就到这里，希望你们喜欢阅读。如果这篇文章对你们有帮助，我会很高兴。欢迎在评论区分享你们的评论/想法/反馈。
- en: '**Thanks for reading!!!**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**感谢阅读！！！**'
- en: '**Bio: [Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    is a Big data developer at CirrusLabs. He has over 4 years of working experience
    in various sectors like Telecom, Analytics, Sales, Data Science having specialisation
    in various Big data components.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Nagesh Singh Chauhan](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)**
    是CirrusLabs的一个大数据开发人员。他在电信、分析、销售、数据科学等多个领域有超过4年的工作经验，专注于多个大数据组件。'
- en: '[Original](https://levelup.gitconnected.com/introduction-to-convolutional-neural-networks-cnn-1ee504bc20c3).
    Reposted with permission.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://levelup.gitconnected.com/introduction-to-convolutional-neural-networks-cnn-1ee504bc20c3)。经许可转载。'
- en: '**Related:**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[5 Papers on CNNs Every Data Scientist Should Read](/2020/04/5-papers-cnns-data-scientist.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家应该阅读的5篇CNN论文](/2020/04/5-papers-cnns-data-scientist.html)'
- en: '[Model Evaluation Metrics in Machine Learning](/2020/05/model-evaluation-metrics-machine-learning.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的模型评估指标](/2020/05/model-evaluation-metrics-machine-learning.html)'
- en: '[Dimensionality Reduction with Principal Component Analysis (PCA)](/2020/05/dimensionality-reduction-principal-component-analysis.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[主成分分析（PCA）的降维](/2020/05/dimensionality-reduction-principal-component-analysis.html)'
- en: More On This Topic
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络（CNNs）的图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Comprehensive Guide to Convolutional Neural Networks](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络的全面指南](https://www.kdnuggets.com/2023/06/comprehensive-guide-convolutional-neural-networks.html)'
- en: '[Building a Convolutional Neural Network with PyTorch](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用PyTorch构建卷积神经网络](https://www.kdnuggets.com/building-a-convolutional-neural-network-with-pytorch)'
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在神经网络之前尝试的10件简单事情](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用PyTorch解释性神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引导我们走向AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
