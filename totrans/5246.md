# 初学者的数据工程指南 – 第二部分

> 原文：[https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html](https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/03/beginners-guide-data-engineering-part-2.html?page=2#comments)

**作者 [Robert Chang](https://www.linkedin.com/in/robert-chang-877b1720/)，Airbnb**。

![标题图像](../Images/8eaf2321867f07225ee55fa3de019591.png)

[图片来源](https://www.archdaily.com/295502/hangar-16-inaqui-carnicero-architecture/50aa9e31b3fc4b0b54000045-hangar-16-inaqui-carnicero-architecture-image): 马德里 Hangar 16 的改造现代仓库（由 Iñaqui Carnicero Arquitectura 提供）

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 总结

在 [**初学者的数据工程指南** — **第一部分**](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)**中，**我解释了组织的分析能力是如何层层建立的。从收集原始数据和构建数据仓库到应用机器学习，我们看到了数据工程在所有这些领域中扮演的重要角色。

数据工程师最受欢迎的技能之一是设计、构建和维护数据仓库的能力。我定义了数据仓库的概念，并讨论了其三个常见构建块 — **提取**（**E**xtract）、**转换**（**T**ransform）和**加载**（**L**oad），也就是 ETL 的由来。

对于那些初涉 ETL 过程的人，我介绍了一些由 LinkedIn、Pinterest、Spotify 等公司构建的流行开源框架，并强调了 Airbnb 自有的开源工具 Airflow。最后，我认为数据科学家可以通过基于 SQL 的 ETL 模式更有效地学习数据工程。

### 第二部分 概述

第一部分的讨论有些高层次。在第二部分（本帖）中，我将分享更多关于如何构建良好数据管道的技术细节，并强调 ETL 最佳实践。主要地，我将使用 Python、Airflow 和 SQL 进行讨论。

首先，我将介绍**数据建模**的概念，这是一个设计过程，通过精确定义表模式和数据关系来捕捉业务指标和维度。我们将学习**数据分区**，这是一种可以更高效查询和填充数据的实践。完成这一部分后，读者将理解数据仓库和管道设计的基础知识。

在后续部分，我将剖析**Airflow 作业**的结构。读者将学习如何使用传感器、操作符和传输来将提取、转换和加载的概念付诸实践。我们将重点介绍**ETL 最佳实践**，并从实际生活中的例子，如 Airbnb、Stitch Fix、Zymergen 等，进行分析。

到了本文末尾，读者将欣赏到 Airflow 的多功能性以及[*配置即代码*](https://airflow.apache.org/#principles)的概念。事实上，我们将看到，Airflow 已经内置了许多这些最佳实践。

### 数据建模

![](../Images/c04d876021524a21b2bb3e3cb0414615.png)

[图片来源](https://digital-photography-school.com/lake-tekapo-stars/): 星型模式，在正确使用时，可以像实际的*天空*一样美丽

当用户与像 Medium 这样的产品互动时，她的信息，例如头像、保存的帖子和浏览次数，都会被系统捕获。为了准确及时地为用户提供服务，优化生产数据库以进行*在线事务处理*（简称 OLTP）至关重要。

当谈到构建*在线分析处理*系统（简称 OLAP）时，目标则有所不同。设计师需要专注于洞察生成，这意味着分析推理可以轻松转化为查询，统计数据可以高效计算。这种以分析为主的方式通常涉及称为**数据建模**的设计过程。

**数据建模、规范化和星型模式**

以设计决策为例，我们通常需要决定表的**规范化**程度。一般来说，规范化的表具有更简单的模式、更标准化的数据，并且冗余更少。然而，较多的小表也意味着跟踪数据关系需要更多的细心，查询模式变得更加复杂（更多`JOINs`），而且需要维护更多的ETL管道。

另一方面，从非规范化表（即宽表）中查询数据通常要容易得多，因为所有的指标和维度已经预先连接。然而，由于其较大的尺寸，宽表的数据处理速度较慢，并且涉及更多的上游依赖。这使得 ETL 管道的维护变得更加困难，因为工作单元不够模块化。

在许多尝试平衡这一权衡的设计模式中，最常用的模式之一，也是我们在 [Airbnb](https://ieondemand.com/presentations/building-airbnb-s-data-culture-insights-from-5-years-of-hypergrowth?_ga=2.230925083.5245429.1516779379-1586560381.1516779379) 使用的模式，被称为 [**星型模式**](https://en.wikipedia.org/wiki/Star_schema)。这个名字来源于星型模式下的表可以被可视化成星形图案。这种设计专注于构建规范化表，特别是事实表和维度表。当需要时，可以从这些较小的规范化表中构建非规范化表。这种设计努力在ETL可维护性和分析便捷性之间取得平衡。

![](../Images/6c703ed92b4505c125c49a049f0965c1.png)

星型模式将表组织成星形图案，以事实表为中心，周围环绕着维度表。

****事实表和维度表****

要理解如何从事实表和维度表构建非规范化表，我们需要更详细地讨论它们各自的角色：

+   **事实表** 通常包含时间点的事务数据。表中的每一行可能非常简单，通常表示为一个事务单位。由于其简单性，它们通常是从中派生业务指标的真实来源。例如，在 Airbnb，我们有各种事实表，用于跟踪类似事务的事件，如预订、预留、变更、取消等。

+   **维度表** 通常包含特定实体的缓慢变化的属性，这些属性有时可以组织成层次结构。这些属性通常被称为“维度”，并且可以与事实表连接，只要事实表中有外键。在 Airbnb，我们建立了各种维度表，如用户、房源和市场，帮助我们切分和分析数据。

以下是一个简单的示例，展示了事实表和维度表（两者都是规范化表）如何结合在一起，以回答基本的分析问题，例如过去一周每个市场发生了多少预订。聪明的用户还可以想象，如果在最终的`SELECT`子句中投影了额外的度量`m_a, m_b, m_c`和维度`dim_x, dim_y, dim_z`，则可以从这些规范化表中轻松构建一个非规范化表。

规范化表可用于回答临时问题或构建非规范化表。

### 数据分区与填补历史数据

![](../Images/d99d4c9905f720e1427ce2fa60f2b199.png)

在数据存储成本低廉且计算便宜的时代，公司现在可以负担得起将所有历史数据存储在数据仓库中，而不是将其丢弃。这种方法的优点是公司可以根据需要重新处理历史数据，以应对新的变化。

**按日期戳进行数据分区**

随着数据量的增加，运行查询和进行分析可能会随着时间的推移变得低效。除了遵循SQL最佳实践，如“提前且频繁过滤”和“仅投影所需字段”之外，提高查询性能的最有效技术之一就是数据分区。

[**数据分区**](https://en.wikipedia.org/wiki/Partition_%28database%29)的基本思想相当简单——我们将数据拆分成独立的、自包含的块，而不是将所有数据存储在一个大块中。来自同一块的数据将被分配相同的分区键，这意味着任何数据子集都可以被极其快速地查找。这项技术可以显著提高查询性能。

特别是，使用的一个常见分区键是**日期戳**（简称`ds`），这是有充分理由的。首先，在像[S3](https://aws.amazon.com/s3/)这样的数据存储系统中，原始数据通常按日期戳组织并存储在时间标记的目录中。此外，批量ETL作业的工作单位通常为一天，这意味着每次每日运行都会创建新的日期分区。最后，许多分析性问题涉及统计在指定时间范围内发生的事件，因此按日期戳查询是一种非常常见的模式。难怪日期戳是数据分区的热门选择！

一个由`ds`分区的表

**填补历史数据**

使用日期戳作为分区键的另一个重要优势是数据填补的便利性。当ETL管道被构建时，它会向前计算指标和维度，而不是向后计算。通常，我们可能希望重新访问历史趋势和动态。在这种情况下，我们需要计算过去的指标和维度——我们称这个过程为**数据填补**。

填补历史数据如此常见，以至于Hive内置了[**动态分区**](https://cwiki.apache.org/confluence/display/Hive/DynamicPartitions)功能，这是一种对多个分区执行相同SQL操作并同时执行多个插入的结构。为了说明动态分区的实用性，考虑一个任务，我们需要填补每个市场的预订数量，以供仪表板使用，从`earliest_ds`到`latest_ds`。我们可能会这样做：

上述操作相当繁琐，因为我们在不同的分区上多次运行相同的查询。如果时间范围很大，这项工作可能会变得非常重复。然而，当使用动态分区时，我们可以将这项工作大大简化为仅一个查询：

请注意`SELECT`和`GROUP BY`子句中的额外`ds`，`WHERE`子句中扩展的范围，以及我们如何将语法从`PARTITION (ds= '{{ds}}')`更改为`PARTITION (ds)`。动态分区的美在于，我们将所需的所有相同工作封装在一个`GROUP BY ds`中，并一次性将结果插入到相关的ds分区中。这种查询模式非常强大，许多Airbnb的数据管道都在使用。在后面的部分，我将演示如何编写一个包含回填逻辑的Airflow作业，使用[Jinja](http://jinja.pocoo.org/)控制流。

### 更多相关内容

+   [初学者数据工程指南](https://www.kdnuggets.com/2023/07/beginner-guide-data-engineering.html)

+   [初学者数据科学中异常检测技术指南](https://www.kdnuggets.com/2023/05/beginner-guide-anomaly-detection-techniques-data-science.html)

+   [数据科学入门：初学者指南](https://www.kdnuggets.com/2023/07/introduction-data-science-beginner-guide.html)

+   [初学者数据清洗指南：Pyjanitor](https://www.kdnuggets.com/beginners-guide-to-data-cleaning-with-pyjanitor)

+   [初学者端到端机器学习指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)

+   [基础机器学习算法：初学者指南](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)
