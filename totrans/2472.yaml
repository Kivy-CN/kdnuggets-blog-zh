- en: A (Much) Better Approach to Evaluate Your Machine Learning Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s crazy how difficult it can be for Data Scientists like myself to evaluate
    ML models using classic performance metrics properly.
  prefs: []
  type: TYPE_NORMAL
- en: Even with access to [multiple metrics and scoring methods](https://scikit-learn.org/stable/modules/model_evaluation.html),
    it is still challenging to understand the right metrics for the problems I — and
    likely many others — am facing. This is exactly why I use Snitch AI for most of
    my ML model quality evaluation. PS — I’ve been an active member of developing
    Snitch AI for the past 2 years.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '[**Machine Learning Model Validation Tool | Snitch AI**](https://snit.ch/?utm_source=blogOlivier&utm_medium=referral&utm_campaign=abetterapproach)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me explain why selecting the right metric is so important with an example:
    the generation of a model that can predict company bankruptcy using data centralized
    on the UC Irvine Machine Learning Repository. The dataset is called [Taiwanese
    Bankruptcy Prediction](https://archive-beta.ics.uci.edu/ml/datasets/taiwanese+bankruptcy+prediction) (licensed
    under CC BY 4.0) and leverages bankruptcy data from the Taiwan Economic Journal
    from 1999 to 2009.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem: Imbalanced Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first problem that you will encounter is the imbalance in the dataset. It’s
    both good news and bad news. The good news is that only 3.3% of companies went
    bankrupt! On the flip side, the bad news is that the imbalance in the dataset
    makes it more difficult to predict the “rare class” (the 3.3%), as our lazy models
    could predict the right fate for 96.7% of the companies by simply predicting no
    bankruptcies.
  prefs: []
  type: TYPE_NORMAL
- en: '![A (Much) Better Approach to Evaluate Your Machine Learning Model](../Images/ffaaeb64d6e4634e843749107e4e9977.png)'
  prefs: []
  type: TYPE_IMG
- en: Target imbalance assessment by Author
  prefs: []
  type: TYPE_NORMAL
- en: You can see that this is also a performance evaluation problem as most metrics
    are biased towards the biggest class, ultimately making them wrong. Why? predicting
    no bankruptcies makes our model 96.7% accurate in theory. Here is an example of
    the first model that was built and evaluated in Snitch AI. The tool calculates
    multiple relevant performance metrics by default. As you can see below, our first
    model gets 96% accuracy. However, when you look at the F1 score, [a better metric
    for imbalanced classes](https://peltarion.com/knowledge-center/documentation/evaluation-view/measure-performance-when-working-with-imbalanced-data),
    I get a score of barely 26%…
  prefs: []
  type: TYPE_NORMAL
- en: '![A (Much) Better Approach to Evaluate Your Machine Learning Model](../Images/4237f61e35f9cbf16c7c23e8611aa24a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image of initial quality analysis by Author
  prefs: []
  type: TYPE_NORMAL
- en: So what gives?
  prefs: []
  type: TYPE_NORMAL
- en: The Solution for Imbalanced Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When dealing with imbalanced data, a good practice is to try to get the training
    dataset more balanced as a second step. You can achieve that by either under-sampling
    the majority class (no-bankruptcy), by removing random observations, or by oversampling
    the minority class (bankruptcy).
  prefs: []
  type: TYPE_NORMAL
- en: For over-sampling, you can either copy random observations or create synthetic
    observations using proven algorithms like *Synthetic Minority Oversampling TEchnique. *SMOTE
    works by selecting examples that are close, drawing a line between the examples,
    and drawing a new sample at a point along that line.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are many techniques I can end up using to enhance my model.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Snitch, I can see a clean history of my various experiments :'
  prefs: []
  type: TYPE_NORMAL
- en: '![A (Much) Better Approach to Evaluate Your Machine Learning Model](../Images/b83e480854906fb3640884f17c5402aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Image of multiple quality analysis by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some conclusions I learned from the experiments above:'
  prefs: []
  type: TYPE_NORMAL
- en: Undersampling and oversampling techniques significantly enhance the F1 score.
    This is a good thing!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, this performance gain is at the expense of the overall quality of our
    models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our model 4 (Gradient Boosting with under-sampling) is the best model, as it
    is almost as performant as model 2, but is generally of better quality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wait! What’s this “Quality Score”?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Snitch uses about a dozen automated quality analyses to generate this Quality
    Score.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Quality Analysis produces:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Feature Contribution Score: **tocheck whether your model’s predictions
    are biased or fairly distributed between the input variables.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Random Noise Robustness Score: **to check if your model is robust to
    the introduction of noisy data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Extreme Noise Robustness Score: **to check if your model is robust to
    the introduction of worst-case scenario noisy data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![A (Much) Better Approach to Evaluate Your Machine Learning Model](../Images/0528db524afe0b7d16f4249321b55c05.png)'
  prefs: []
  type: TYPE_IMG
- en: Image from [Snitch AI quality analysis methodology](https://help.snit.ch/article/19-quality-analysis),
    2021\. Reposted with permission
  prefs: []
  type: TYPE_NORMAL
- en: Performance evaluation is hard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nothing good comes easy, and performance evaluation is no different. While tricky
    to get right, performance evaluation needs to be taken seriously while developing
    your models. It’s not because you have a good accuracy that your model is a good
    one.
  prefs: []
  type: TYPE_NORMAL
- en: The truth is, accuracy might not even be a relevant measure of performance.
    In our case, the F1 score was definitely better as our dataset was imbalanced.
    The lesson here is simple. Make sure you validate that the metrics you selected
    properly measure what you’re trying to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Although performance metrics are important (they are about measuring how well
    your model predicts the outcome after all), these metrics do not validate data
    biases or the overall robustness of your model. A good practice here is to specifically
    test for other characteristics such as biases and robustness.
  prefs: []
  type: TYPE_NORMAL
- en: We saw that some models can perform better than other models in theory but are
    in fact of poorer quality. We also saw models that are performing badly but that
    are of better quality. At the end of the day, the goal is to be able to compare
    these signals to select the best approach.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, a better approach should not only focus on estimating your model’s
    performance, it actually requires in-depth testing to make sure your system is
    robust as well so that it will actually work on new data in production… this is
    where the magic needs to happen!
  prefs: []
  type: TYPE_NORMAL
- en: '**[Olivier Blais](https://www.linkedin.com/in/olivierblais/?originalSubdomain=ca)**
    is co-founder and Head of Decision Science at Moov AI. He’s also a member of the
    Standards Council of Canada committee that is defining the ISO standards for artificial
    intelligence solutions where he leads initiatives on quality evaluation guidelines
    for AI Systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/good-approach-to-evaluate-your-machine-learning-model-e2e1fd6aa6bb).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[A Better Way To Evaluate LLMs](https://www.kdnuggets.com/a-better-way-to-evaluate-llms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Structured Approach To Building a Machine Learning Model](https://www.kdnuggets.com/2022/06/structured-approach-building-machine-learning-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Much Math Do You Need in Data Science?](https://www.kdnuggets.com/2020/06/math-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Much Do Data Scientists Make in 2022?](https://www.kdnuggets.com/2022/02/much-data-scientists-make-2022.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Practical Approach To Feature Engineering In Machine Learning](https://www.kdnuggets.com/2023/07/practical-approach-feature-engineering-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide On How To Become A Data Scientist (Step By Step Approach)](https://www.kdnuggets.com/2021/05/guide-become-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
