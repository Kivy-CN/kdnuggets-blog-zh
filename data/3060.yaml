- en: How to Define a Machine Learning Problem Like a Detective
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何像侦探一样定义机器学习问题
- en: 原文：[https://www.kdnuggets.com/2018/10/define-machine-learning-problem-detective.html](https://www.kdnuggets.com/2018/10/define-machine-learning-problem-detective.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/10/define-machine-learning-problem-detective.html](https://www.kdnuggets.com/2018/10/define-machine-learning-problem-detective.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
- en: '**By [Spencer Norris](https://www.spencernorris.xyz/), Data Scientist, Independent
    Journalist**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Spencer Norris](https://www.spencernorris.xyz/)，数据科学家，独立记者**。'
- en: '![](../Images/6b7db80ffebecc19b28072006a9b5680.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b7db80ffebecc19b28072006a9b5680.png)'
- en: This article was originally published on [OpenDataScience.com](https://OpenDataScience.com).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文最初发表在[OpenDataScience.com](https://OpenDataScience.com)。
- en: Let’s see if we can start down that direction by laying the groundwork for the
    very fundamentals of our understanding of machine learning – namely, what actually
    constitutes a machine learning problem? It’s kind of strange question that you
    might think you know the answer to, but it actually has a very formal definition
    that we’ll outline here.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看能否通过为我们对机器学习的基本理解奠定基础来开始这个方向——即，究竟什么构成了一个机器学习问题？这似乎是一个你可能认为自己知道答案的奇怪问题，但实际上它有一个非常正式的定义，我们将在这里概述。
- en: Defining the machine learning problem
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义机器学习问题
- en: 'The most important step you can take is to start by asking yourself: do I think
    there’s a pattern?'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以采取的最重要的步骤是首先问自己：我认为存在模式吗？
- en: The fundamental assumption that underlies all machine learning problems is that *there
    is a pattern*. You can’t make omelets without eggs; if there isn’t any pattern,
    then we’re already done. Ask yourself this question before you decide to embark
    on a project -; it might save you some heartbreak down the line.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所有机器学习问题的基本假设是*存在某种模式*。你不能在没有鸡蛋的情况下做煎蛋卷；如果没有任何模式，那么我们就已经完成了。在决定开始一个项目之前问问自己这个问题——这可能会为你节省一些心痛。
- en: If you still think there’s a pattern, then we can proceed. That pattern we’re
    looking for is some function *f*, which maps some input *X* onto an output *Y*.
    In the notation, this is *f:XY*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然认为存在模式，那么我们可以继续。我们寻找的模式是某个函数`f`，它将某个输入`X`映射到输出`Y`。在符号中，这就是`f:XY`。
- en: 'Of course, you don’t know *f* – you *can’t* know *f*, or you wouldn’t be reading
    this. This is the entire crux of machine learning: if I have some pattern that
    I can’t directly observe, how can I at least approximate it?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你不知道`f`——你*不能*知道`f`，否则你就不会在读这篇文章了。这是机器学习的核心：如果我有某种模式，我不能直接观察到，如何至少可以近似它？
- en: Define the problem the way a detective would
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 像侦探一样定义问题
- en: Do it like a detective. If f has left behind evidence, or observations, we can
    begin to reconstruct what f looks like. Each observation is an input **xi** =[x1,x2,…xd]
    Ɛ Rd(that is, each xi is an array of real numbers of length *d*) and an observed
    output, yi. Collectively, these observations {(x1,y1), (x2,y2)… (xn,yn)}are our
    data set, *D*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 像侦探一样做。如果`f`留下了证据或观察，我们可以开始重建`f`的样子。每个观察都是一个输入**xi**=[x1,x2,…xd] Ɛ Rd（即每个`xi`是一个长度为*d*的实数数组）和一个观察到的输出`yi`。这些观察{(x1,y1),
    (x2,y2)… (xn,yn)}统称为我们的数据集，*D*。
- en: The problem is that even with those observations, an infinite number of possibilities
    could explain them. For example, take a *D* with only the following two observations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，即使有这些观察，仍然有无限多的可能性可以解释它们。例如，取一个*D*，仅包含以下两个观察。
- en: '![](../Images/34fede020a28b73c80591562bb2826a8.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34fede020a28b73c80591562bb2826a8.png)'
- en: We have some good guesses about what kind of function f would explain these
    observations. In all likelihood, it’s a straight line – right?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对什么样的函数`f`可以解释这些观察有一些很好的猜测。很可能，它是直线——对吧？
- en: '![](../Images/fc260dbd08bc14bd0f43cbd57e402dcb.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc260dbd08bc14bd0f43cbd57e402dcb.png)'
- en: That would make the most sense. But why can’t it be a polynomial function as
    well?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那样最有意义。但是为什么它不能是一个多项式函数呢？
- en: '![](../Images/578cf61a8a8fb74eccd365e37ce77cd0.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/578cf61a8a8fb74eccd365e37ce77cd0.png)'
- en: Why can’t it be something even more complicated?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么它不能是更复杂的东西？
- en: '![](../Images/91523165a11be2d56f8615c486a308dd.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91523165a11be2d56f8615c486a308dd.png)'
- en: The fact of the matter is that there is no reason that any one of these explanations
    is completely implausible. *They are all equally valid hypotheses.*
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实际情况是，这些解释中的任何一种都没有完全不合理的理由。*它们都是同样有效的假设*。
- en: So why even bother? If there’s no way of nailing down the truth, then aren’t
    we shot from the get-go?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么还要费心呢？如果没有办法确定真相，我们不是从一开始就注定失败了吗？
- en: 'If that were true, then you probably wouldn’t be looking at this page, and
    most crimes probably wouldn’t be solved. We’ll formalize this concept later on,
    but for now, take it at face value: we’re trying to formulate our hypothesis based
    on what is *probably* the case. We’re trying to pluck some hypothesis that we
    think works best, *g*, from an infinite space of different hypotheses, *H*.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果那是真的，你可能不会查看这一页，大多数犯罪也可能不会被解决。我们稍后会形式化这个概念，但目前，请将其视为：我们尝试根据 *可能* 的情况来制定假设。我们试图从一个无限的假设空间
    *H* 中挑选出我们认为最有效的假设 *g*。
- en: How do we go about that? With our detective, of course – the algorithm, *A*.
    The algorithm will be responsible for picking through our infinitely large hypothesis
    space *H* and figuring out which one makes the most sense. The one we land on
    is *g*, and we say it approximates our real function *f* well enough that we can
    use it: *gf*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何进行呢？当然是用我们的侦探——算法 *A*。算法将负责在我们无限大的假设空间 *H* 中筛选，并找出最合适的一个。我们最终选择的那个是 *g*，我们说它足够好地近似了我们的真实函数
    *f*，以至于我们可以使用它：*gf*。
- en: This is all there really is to formalizing a machine learning problem. We have
    some unknown target function *f:XY*. We don’t know what *f* is, but we have examples
    of inputs and outputs that we call *D*. We also have an infinite number of possible
    hypotheses *H*, which we’ll slowly whittle down until we find a hypothesis that
    looks good enough, *g*. We’ll hone in on *g* by feeding *D* to *A*, which is able
    to guess which is the closest to the real thing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是将机器学习问题形式化的全部内容。我们有一些未知的目标函数 *f:XY*。我们不知道 *f* 是什么，但我们有输入和输出的示例，这些示例称为 *D*。我们还有无限多的可能假设
    *H*，我们将逐步缩小范围，直到找到一个看起来足够好的假设 *g*。我们将通过将 *D* 输入给 *A*，逐渐确定 *g*，以便找到最接近真实情况的答案。
- en: Solving the mystery
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解开谜团
- en: In our detective analogy, Agent *A* has a pile of evidence *D* to figure out
    who the killer *f* is. A will look through a massive pool of suspects, *H*, until
    he thinks he has one, *g*, that fits the profile. There’s no guarantee that *g* is *f* –
    and in machine learning, we almost never have that guarantee – but this is his
    best guess based on the evidence that is available.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的侦探类比中，代理人 *A* 拥有一堆证据 *D* 以确定凶手 *f* 是谁。*A* 将在一个庞大的嫌疑人池 *H* 中筛选，直到他认为找到了一个符合条件的
    *g*。没有保证 *g* 就是 *f* —— 在机器学习中，我们几乎从未有这样的保证 —— 但这是基于现有证据的最佳猜测。
- en: If there was more evidence available, we might arrive at a different conclusion.
    There’s a chance we’ll pin the wrong guy altogether, and that’s catastrophic.
    In practice, you’ll need to determine how much room for error you can allow for
    in your algorithm based on your requirements (something we’ll talk about later).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有更多的证据，我们可能会得出不同的结论。我们有可能完全错认嫌疑人，这将是灾难性的。在实践中，你需要根据你的要求来确定算法允许多少误差（这是我们稍后会讨论的内容）。
- en: If it were a different agent looking at the evidence, they might suggest a totally
    different set of suspects. This is what happens when we switch the algorithm we’re
    using to evaluate the data. There’s a price to pay for this too, which we’ll discuss.
    For the meantime, choose your algorithm wisely.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是不同的代理人查看证据，他们可能会建议完全不同的嫌疑人。这就是当我们切换用于评估数据的算法时发生的事情。这也有代价，我们会讨论这个问题。在此期间，明智地选择你的算法。
- en: All sorts of subtleties bubble to the surface as you spend more time delving
    into the theory. It can be a slog sometimes, but it will make you a better machine
    learning practitioner in the long run and will be vital if you ever want to use
    it in the real world.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你花更多时间深入理论时，各种细微之处会浮现出来。有时候这可能是一场艰难的战斗，但从长远来看，这将使你成为更出色的机器学习从业者，并且如果你想在现实世界中使用它，它将是至关重要的。
- en: Next time I’ll talk a bit about what it means to explore *H*, why it’s so hard
    to pick out the correct answer from this pile and why we can do it at all.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下次我会谈论一下探索 *H* 的意义，为什么从这堆数据中挑选正确答案如此困难，以及我们为何能够做到这一点。
- en: '**Bio**: [Spencer Norris](https://www.spencernorris.xyz/) is a data scientist
    and freelance journalist. He currently works as a contractor and publishes on
    his blog on [Medium](https://medium.com/@spencernorris).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介**：[斯宾塞·诺里斯](https://www.spencernorris.xyz/)是一位数据科学家和自由撰稿人。他目前以承包商身份工作，并在[Medium](https://medium.com/@spencernorris)上发表文章。'
- en: '[Original](https://opendatascience.com/how-to-define-a-machine-learning-problem-like-a-detective/).
    Reposted with permission.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://opendatascience.com/how-to-define-a-machine-learning-problem-like-a-detective/)。经许可转载。'
- en: '**Related:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine learning — Is the emperor wearing clothes?](https://www.kdnuggets.com/2018/10/machine-learning-emperor-wearing-clothes.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习——皇帝穿衣服了吗？](https://www.kdnuggets.com/2018/10/machine-learning-emperor-wearing-clothes.html)'
- en: '[What If the Data Tells You to Be Racist? When Algorithms Explicitly Penalize](https://www.kdnuggets.com/2018/09/siegel-when-algorithms-explicitly-penalize.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如果数据告诉你要种族主义怎么办？当算法明确惩罚时](https://www.kdnuggets.com/2018/09/siegel-when-algorithms-explicitly-penalize.html)'
- en: '[Why understanding of truth is important in Data Science?](https://www.kdnuggets.com/2018/01/understanding-truth-data-science.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么理解真相在数据科学中很重要？](https://www.kdnuggets.com/2018/01/understanding-truth-data-science.html)'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT 工作'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第一部分：神经元是慢的,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
- en: '[How to MLOps like a Boss: A Guide to Machine Learning without Tears](https://www.kdnuggets.com/2023/06/mlops-like-boss-guide-machine-learning-without-tears.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何像老板一样进行 MLOps：无需眼泪的机器学习指南](https://www.kdnuggets.com/2023/06/mlops-like-boss-guide-machine-learning-without-tears.html)'
- en: '[Machine Learning Is Not Like Your Brain Part Two: Perceptrons vs Neurons](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第二部分：感知器与神经元](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 3: Fundamental Architecture](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第三部分：基本架构](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 4: The Neuron’s…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第四部分：神经元的…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 5: Biological Neurons…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习不像你的大脑 第五部分：生物神经元…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
