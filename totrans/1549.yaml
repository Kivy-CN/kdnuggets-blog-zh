- en: The Pareto Principle for Data Scientists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html](https://www.kdnuggets.com/2019/03/pareto-principle-data-scientists.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Pradeep Gulipalli](https://in.linkedin.com/in/gulipalli), [Tiger Analytics](http://www.tigeranalytics.com/)**'
  prefs: []
  type: TYPE_NORMAL
- en: More than a century ago, Vifredo Pareto, a professor of Political Economy, published
    the results of his research on the distribution of wealth in society. The dramatic
    inequalities he observed, e.g. 20% of the people owned 80% of the wealth, surprised
    economists, sociologists, and political scientists. Over the last century, several
    pioneers in varied fields observed this disproportionate distribution in several
    situations, including business. The theory that a vital few inputs/causes (e.g.
    20% of inputs) directly influence a significant majority of the outputs/effects
    (e.g. 80% of outputs) came to be known as the Pareto Principle – also referred
    to as the 80-20 rule.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/57e3d193f060d94177792f2dbe5df028.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [William Lipovsky](https://due.com/blog/the-pareto-principle-the-secret-of-successful-freelancers/)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The Pareto Principle is a very simple yet extremely powerful management tool.
    Business executives have long used it for strategic planning and decision making.
    Observations such as 20% of the stores generate 80% of the revenue, 20% of software
    bugs cause 80% of the system crashes, 20% of the product features drive 80% of
    the sales etc. are popular, and analytically savvy businesses try to find such
    Paretos in their worlds. This way they are able to plan and prioritize their actions.
    In fact, today, data science plays a big role in sifting through tons of complex
    data to help identify future Paretos.
  prefs: []
  type: TYPE_NORMAL
- en: While data science is helping predict new Paretos for businesses, data science
    can benefit from taking a look internally, searching for Paretos within. Exploiting
    these can make data science significantly more efficient and effective. In this
    article, I’ll share a few ways in which we, as data scientists, can use the power
    of the Pareto Principle to guide our day-to-day activities.
  prefs: []
  type: TYPE_NORMAL
- en: '**Project Prioritization**'
  prefs: []
  type: TYPE_NORMAL
- en: If you are a data science leader/manager, you’d inevitably need to help develop
    the analytics strategy for your organization. While different business leaders
    can share their needs, you have to articulate all these organizational (or business
    unit) needs and prioritize them into an analytic roadmap. A simple approach is
    to quantify the value of solving each analytic need, and sort them in the decreasing
    order of value. You’ll often notice that the top few problems/use-cases are disproportionately
    valuable (Pareto Principle), and should be prioritized above the others. In fact,
    a better approach would be to quantify the complexity of solving/implementing
    each problem/use-case, and prioritizing them based on a trade-off between value
    and complexity (e.g. by laying them on a plot with value on the y-axis and complexity
    on the x-axis).
  prefs: []
  type: TYPE_NORMAL
- en: '**Problem Scoping**'
  prefs: []
  type: TYPE_NORMAL
- en: Business problems tend to be vague and unstructured, and a data scientist’s
    job involves identifying the right scope. Scoping often requires keeping the focus
    on the most important aspects of the problem and deprioritizing aspects that are
    of less value. To start with, looking at the distribution of outputs/effects over
    inputs/causes will help us understand if high level Paretos exist in the problem
    space. Subsequently, we can choose to look at only certain inputs/outputs or causes/effects.
    For example, if 20% of stores generate 80% of sales, we can group rest of the
    stores into a cluster and do the analysis instead of evaluating them individually.
  prefs: []
  type: TYPE_NORMAL
- en: Scoping also involves evaluating risks – deeper evaluation will often tell us
    that the top items pose significantly higher risk while the bottom ones have a
    very remote chance of occurring (the Pareto Principle). Rather than address all
    risks, we can possibly prioritize our time and efforts towards a few of the key
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Planning**'
  prefs: []
  type: TYPE_NORMAL
- en: Complex business problems require data beyond what is readily available in analytic
    data marts. We need to request access, purchase, fetch, scrape, parse, process,
    and integrate data from internal/external sources. These come in different shapes,
    sizes, health, complexity, costs etc. Waiting for the entire data plan to fall
    in place can cause project delays that are not in our control. One simple approach
    could be to categorize these data needs based on their value to the end solution,
    e.g. Absolute must have, Good to have, and Optional (the Pareto Principle). This
    will help us focus on the Absolute must haves, and not get distracted or delayed
    by the Optional items. In addition to value, considering aspects of cost, time,
    and effort of data acquisition will help us better prioritize our data planning
    exercise.
  prefs: []
  type: TYPE_NORMAL
- en: '**Analysis**'
  prefs: []
  type: TYPE_NORMAL
- en: It’s anecdotally said that a craftsman completes 80% of their work using only
    20% of their tools. This holds true for us data scientists as well. We tend to
    use few analyses and models for a significant part of our work (the Pareto Principle),
    while the other techniques get used much less frequently. Typical examples during
    exploratory analysis include, variable distributions, anomaly detection, missing
    value imputation, correlation matrices etc. Similarly, examples during the modeling
    phase include k-fold cross-validation, actual vs. predicted plots, misclassification
    tables, analyses for hyperparameter tuning etc. Building mini automations (e.g.
    libraries, code snippets, executables, UIs) to use/access/implement these analyses
    can bring significant efficiencies in the analytic process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modeling**'
  prefs: []
  type: TYPE_NORMAL
- en: During the modeling phase, it doesn’t take us long to arrive upon a reasonable
    working model early in the process. Majority of the accuracy gains have been made
    by now (the Pareto Principle). The rest of the process is about fine-tuning the
    models and pushing for the incremental accuracy gains. Sometimes, the incremental
    accuracy gains are required to make the solution viable for business. On other
    occasions, the model fine-tuning doesn’t add much value to the eventual insight/proposition.
    As data scientists, we need to be cognizant of these situations, so that we know
    where to draw the line accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business Communication**'
  prefs: []
  type: TYPE_NORMAL
- en: Today’s data science ecosystem is very multi-disciplinary. Teams include business
    analysts, machine learning scientists, big data engineers, software developers
    and multiple business stakeholders. A key driver of success of a such teams is
    communication. As someone who is working hard, you might be tempted to communicate
    all the work – challenges, analyses, models, insights etc. However, in today’s
    world of information overload, taking such an approach will not help. We will
    need to realize that there are ‘useful many but a vital few’ (the Pareto Principle)
    and use this understanding to simplify the amount of information we communicate.
    Similarly, what we present and highlight needs to be customized based on the target
    audience (business stakeholders vs. data scientists)
  prefs: []
  type: TYPE_NORMAL
- en: The Pareto Principle is a powerful tool in our arsenal. Used the right way,
    it can help us declutter and optimize our activities.
  prefs: []
  type: TYPE_NORMAL
- en: '![Pradeep Gulipalli](../Images/f8b33760f83485153b266bb08a2936aa.png)**Bio:
    [Pradeep Gulipalli](https://in.linkedin.com/in/gulipalli)** is a Co-founder of
    Tiger Analytics and currently heads the team in India. Over the last decade, he
    has worked with clients at Fortune 100 companies and start-ups alike to enable
    scientific decision making in their organizations. He has helped design analytics
    road-maps for complex business environments and architected numerous data science
    solution frameworks, which include pricing, forecasting, anomaly detection, personalization,
    optimization, behavioral simulations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[What no one will tell you about data science job applications](/2019/03/data-science-job-applications.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Do You Identify the Right Data Scientist for Your Team?](/2016/06/identify-right-data-your-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Preparing for the Unexpected](/2019/02/preparing-unexpected.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
