- en: Confusion Matrix, Precision, and Recall Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/11/confusion-matrix-precision-recall-explained.html](https://www.kdnuggets.com/2022/11/confusion-matrix-precision-recall-explained.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/3191041ede59abdf48e678202c6b93b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: A confusion matrix is a table used to summarize the performance of a classification
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In case you aren’t familiar, classification models are machine learning algorithms
    used to solve problems that have a categorical outcome, such as predicting whether
    an email is a spam or not.
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy** is the most popular metric used to evaluate classification models.'
  prefs: []
  type: TYPE_NORMAL
- en: However, it isn’t always the most reliable, which is why data scientists generate
    **confusion matrices** and use metrics like **precision** and **recall** instead.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrices are one of the most frequently tested concepts by data science
    interviewers. Hiring managers often ask candidates to interpret confusion matrices,
    or provide them with a use case and ask them to calculate a model’s precision
    and recall by hand.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this, it is important to thoroughly understand how these techniques work
    and when they should be used in place of accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, we will cover the following concepts to solidify your understanding
    of classification metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of classification accuracy
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a confusion matrix, and why is it used?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to read a confusion matrix
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are precision and recall, and how do they overcome the limitations of classification
    accuracy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to generate a confusion matrix in Python
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Limitations of Classification Accuracy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let us look at a simple example to understand where classification accuracy
    fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/7c6fefe7e8cbe00f947ac17fb4589bbe.png)'
  prefs: []
  type: TYPE_IMG
- en: The table above contains data related to 10 patients. 8 out of 10 patients do
    not have a rare disease, while 2 of them do.
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of an **imbalanced classification problem**.
  prefs: []
  type: TYPE_NORMAL
- en: If your dataset has skewed proportions, i.e. there is an over-representation
    of one class and an under-representation of another, then the dataset is imbalanced.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, even if the classification model that you build always predicts
    the majority class, the accuracy will be high.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, if the model always predicts that the patient does not have
    the disease, it will be correct 8 out of 10 times and will have an 80% accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/c2ed76eeaae54bab59e4795643302210.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a bad model as it always predicts the majority class, but its high accuracy
    can trick us into thinking that the model is performing well.
  prefs: []
  type: TYPE_NORMAL
- en: Since accuracy does not always show us the full picture, we can use a confusion
    matrix instead to tell us how well the model is actually performing.
  prefs: []
  type: TYPE_NORMAL
- en: What is a Confusion Matrix?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A confusion matrix summarizes the performance of a classifier and allows us
    to identify details that accuracy does not tell us.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand how it works, let’s build a confusion matrix based on
    the table above:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/870e01cf5b86f91a4694511470a6a22f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The above image displays the structure of a confusion matrix. Here is how it
    can be interpreted:'
  prefs: []
  type: TYPE_NORMAL
- en: The columns represent actual values, and rows represent predictions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a person actually has a disease and the model accurately predicts that they
    have the disease, then it is called a **true** **positive**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a person does not have the disease and the model predicts “no,” then this
    is a **true** **negative**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True positives and true negatives form a diagonal in the confusion matrix.
    We can calculate a model’s accuracy with the following formula:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/dc0ef3a8055a6ad71edaae53c356e54d.png)'
  prefs: []
  type: TYPE_IMG
- en: If a person has the disease (yes) but the model predicts “no,” this is a **false
    negative**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, if a person does not have the disease (no) but the model predicts “yes”,
    then this is a **false positive**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let’s fill out the confusion matrix based on the disease prediction data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/c2ed76eeaae54bab59e4795643302210.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 1: True Positives'
  prefs: []
  type: TYPE_NORMAL
- en: Recall that this means the number of people accurately predicted to have the
    disease. Since the model has predicted “No” for every patient, there are **0 true
    positives** in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: True Negatives'
  prefs: []
  type: TYPE_NORMAL
- en: There are 8 patients who do not have the disease, and the model managed to identify
    all of them. So there are **8 true negatives**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/938021662a87d1a62510db6580767620.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 3: False Positives'
  prefs: []
  type: TYPE_NORMAL
- en: These are the people who do not have the disease, but the model predicted “Yes.”
    Since our model has never predicted “Yes,” there are **0 false positives**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: False Negatives'
  prefs: []
  type: TYPE_NORMAL
- en: These are people who do have the disease, but the model predicted “No.” There
    are **2 false negatives** in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/fa6205492ec172812cc642f61817d590.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, although we know that this model has an 80% accuracy, we can tell that
    there is something wrong with it by just looking at its confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entire “*Predicted: Yes*” column of the confusion matrix has zeros in it,
    which tells us that the model has not predicted that even one person has the disease.'
  prefs: []
  type: TYPE_NORMAL
- en: The model is only predicting the majority class “*No”*, indicating that it’s
    doing a poor job at disease classification and must be refined.
  prefs: []
  type: TYPE_NORMAL
- en: Precision and Recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you understand how a confusion matrix works, let’s dive into two more
    metrics that can be computed from it.
  prefs: []
  type: TYPE_NORMAL
- en: Precision and recall are two popular classification metrics that data scientists
    use to optimize model performance. They give us insight into model performance
    that accuracy does not tell us.
  prefs: []
  type: TYPE_NORMAL
- en: Precision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Precision is a metric that tells us about the quality of positive predictions.
    Out of everyone predicted to have the disease, how many of them actually have
    it?
  prefs: []
  type: TYPE_NORMAL
- en: 'It is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/18680bee59e4a78359b75f0b0c205201.png)![Confusion
    Matrix, Precision, and Recall Explained](../Images/b84268472f0746a193a1353034b37dbe.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, we only look at the left hand side of the confusion matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The number of **true positives** is 0.
  prefs: []
  type: TYPE_NORMAL
- en: All predicted positives include the sum of **true positives** and **false positives**,
    which is also 0.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the model’s precision is 0/0+0 = 0.
  prefs: []
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall tells us about how well the model identifies true positives. Out of all
    the patients who have the disease, how many were correctly identified?
  prefs: []
  type: TYPE_NORMAL
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/453b672f985a50e7161da55f25757e9d.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Confusion Matrix, Precision, and Recall Explained](../Images/172006f01c0fe6e56c37087b44dae8ad.png)'
  prefs: []
  type: TYPE_IMG
- en: In this case, the number of true positives is 0\. The number of false negatives
    is 2.
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the model’s recall is 0/2+0 = 0.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that both precision and recall are zero in this example. This is because
    the model has no true positives, marking the classifier as useless as it was unable
    to make even one correct positive prediction.
  prefs: []
  type: TYPE_NORMAL
- en: What is a “good” classification model?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A good classifier should have high accuracy, precision, and recall.
  prefs: []
  type: TYPE_NORMAL
- en: In some use-cases, data scientists optimize their model to have higher precision
    or recall depending on the scenario.
  prefs: []
  type: TYPE_NORMAL
- en: A model with higher recall than precision often makes more positive predictions.
    A model like this comes with higher false positives and low false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: In scenarios like disease prediction, models should always be optimized for
    recall. False positives are better than false negatives in the healthcare industry.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, a model with higher precision will have fewer false positives
    and more false negatives. If you were to build a bot detection machine learning
    model for an online store, you may want to optimize for higher precision, since
    banning legitimate users from the website will lead to a decline in sales.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to properly understand this concept, as data science interviewers
    often present use-cases like the ones above and ask candidates whether to optimize
    for precision or recall.
  prefs: []
  type: TYPE_NORMAL
- en: How to Build a Confusion Matrix in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can run the following lines of code to build a confusion matrix using Scikit-Learn
    in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**[Natassha Selvaraj](https://www.natasshaselvaraj.com/)** is a self-taught
    data scientist with a passion for writing. You can connect with her on [LinkedIn](https://www.linkedin.com/in/natassha-selvaraj-33430717a/).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, November 16: How LinkedIn Uses Machine Learning •…](https://www.kdnuggets.com/2022/n45.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Idiot''s Guide to Precision, Recall, and Confusion Matrix](https://www.kdnuggets.com/2020/01/guide-precision-recall-confusion-matrix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Visualizing Your Confusion Matrix in Scikit-learn](https://www.kdnuggets.com/2022/09/visualizing-confusion-matrix-scikitlearn.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Vector and Matrix Norms with NumPy Linalg Norm](https://www.kdnuggets.com/2023/05/vector-matrix-norms-numpy-linalg-norm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sparse Matrix Representation in Python](https://www.kdnuggets.com/2020/05/sparse-matrix-representation-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
