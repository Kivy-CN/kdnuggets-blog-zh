# 掌握Python机器学习的7个额外步骤

> 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)

所以，你一直在考虑学习机器学习，但由于网络上的混乱状态，你不知道从哪里开始？或者也许你已经完成了[前7步](/2015/11/seven-steps-machine-learning-python.html)，现在在寻找一些进一步的材料，超越基础介绍？

![机器学习算法](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)

机器学习算法。

本文是[掌握Python机器学习的7个步骤](/2015/11/seven-steps-machine-learning-python.html)系列的第二部分（既然有两部分，我想现在可以算作一个系列）。如果你已经从[原始文章](/2015/11/seven-steps-machine-learning-python.html)开始，你应该已经在技能上有了满意的进展。如果没有，你可能需要先回顾那篇文章，这可能需要一些时间，具体取决于你当前的理解水平；不过，我保证这样做会值得你付出的努力。

在快速回顾和几种新视角的选项之后，这篇文章将更具分类地关注几组相关的机器学习任务。由于这次我们可以安全地跳过基础模块——Python基础、机器学习基础等——我们将直接进入各种机器学习算法。这次我们也可以更好地按功能线分类我们的教程。

我再次声明，本材料中包含的所有内容均可在网络上免费获取，所有权利和对作品的认可归原作者所有。如果有任何内容未被正确归属，请随时[告诉我](https://twitter.com/mattmayo13)。

### 第一步：机器学习基础回顾及新视角

只是为了回顾，这些是[原始文章](/2015/11/seven-steps-machine-learning-python.html)中涵盖的步骤：

1.  基础Python技能

1.  机器学习基础技能

1.  科学Python包概述

1.  使用Python进行机器学习入门：介绍及模型评估

1.  使用Python的机器学习主题：k-means聚类、决策树、线性回归与逻辑回归

1.  使用Python的高级机器学习主题：支持向量机、随机森林、PCA降维

1.  Python中的深度学习

如上所述，如果你打算从头开始，我建议回到第一篇文章并按顺序进行。我还要指出，适当的*入门*材料，包括所有安装说明，均包含在前一篇文章中。

不过，如果你真的很陌生，我建议从以下内容入手，涵盖最基本的知识：

+   [机器学习关键术语解释](/2016/05/machine-learning-key-terms-explained.html)，作者：马修·梅奥

+   [维基百科上的统计分类](https://en.wikipedia.org/wiki/Statistical_classification)

+   [机器学习：全面而详细的概述](/2016/10/machine-learning-complete-detailed-overview.html)，作者：亚历克斯·卡斯特罗尼斯

如果你正在寻找学习机器学习基础的替代或补充方法，我最近一直在享受 Shai Ben-David 的视频讲座和与 Shai Shalev-Shwartz 共同编写的免费教材。你可以在这里找到它们：

+   [Shai Ben-David 的机器学习入门视频讲座](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm)，滑铁卢大学

+   [理解机器学习：从理论到算法](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html)，作者：Shai Ben-David 和 Shai Shalev-Shwartz

请记住，在继续进行其余步骤时（无论是在此帖子中还是原始帖子中），并不需要完全消化所有的介绍材料。在使用反射机器学习算法实施模型时，或在后续步骤中实际应用相关概念时，可以查阅视频讲座、文本和其他资源。请自行判断。

### 第2步：更多分类

我们将通过首先增强我们的分类知识，并引入一些额外的算法来开始新材料。虽然我们帖子的第1部分涵盖了决策树、支持向量机和逻辑回归——以及集成分类器随机森林——我们将加入 k-最近邻、朴素贝叶斯分类器和多层感知器。

![Scikit-learn 分类器](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)

Scikit-learn 分类器。

**k-最近邻（kNN）** 是一个简单的分类器，也是一个懒惰学习者的例子，其中所有计算都在分类时进行（与在训练步骤中提前进行计算相对）。kNN 是 [非参数](https://en.wikipedia.org/wiki/Nonparametric_statistics)的，通过在做决策时比较数据实例与 *k* 个最近的实例来运作。

+   [使用 Python 进行 K-最近邻分类](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)

**朴素贝叶斯** 是基于 [贝叶斯定理](https://en.wikipedia.org/wiki/Bayes'_theorem) 的分类器。它假设特征之间是独立的，并且一个类中特征的存在与同一类中其他特征的存在无关。

+   [使用 scikit-learn 进行文档分类](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html)，作者：扎克·斯图尔特

**多层感知器（MLP）** 是一种简单的 [前馈](https://en.wikipedia.org/wiki/Feedforward_neural_network) 神经网络，由多个层的节点组成，每一层与其后续层完全连接。MLP 在 Scikit-learn 版本 0.18 中引入。

首先阅读 Scikit-learn 文档中关于 MLP 分类器的概述，然后通过教程进行实践。

+   [神经网络模型（监督学习）](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)，Scikit-learn 文档

+   [Python 和 SciKit Learn 0.18 的初学者指南!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html)，由 Jose Portilla 编写

### 第 3 步：更多聚类

我们现在转向聚类，一种无监督学习的形式。在第一篇文章中，我们介绍了 k-means 算法；在此我们将介绍 DBSCAN 和期望最大化（EM）。

![Scikit-learn 聚类算法](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)

Scikit-learn 聚类算法。

首先阅读这些介绍性的帖子；第一个是 k-means 和 EM 聚类技术的快速比较，是进入新聚类形式的良好过渡，第二个是 Scikit-learn 中可用聚类技术的概述：

+   [聚类技术比较：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)，由 Matthew Mayo 编写

+   [在玩具数据集上比较不同的聚类算法](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)，Scikit-learn 文档

**期望最大化（EM）**是一种概率聚类算法，因此涉及确定实例属于特定簇的概率。EM “接近统计模型中参数的最大似然或最大后验估计”（Han, Kamber & Pei）。EM 过程从一组参数开始，迭代直到在 *k* 个簇下最大化聚类效果。

首先阅读有关 EM 算法的教程。接着，查看相关的 Scikit-learn 文档。最后，跟随教程使用 Python 实现 EM 聚类。

+   [期望最大化（EM）算法教程](/2016/08/tutorial-expectation-maximization-algorithm.html)，由 Elena Sharova 编写

+   [高斯混合模型](http://scikit-learn.org/stable/modules/mixture.html)，Scikit-learn 文档

+   [使用 Python 进行高斯混合模型的快速介绍](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/)，Tiago Ramalho 编写

如果 "[高斯混合模型](https://en.wikipedia.org/wiki/Mixture_model)" 一开始让人感到困惑，Scikit-learn 文档中的相关部分应该可以减轻任何不必要的担忧：

> `GaussianMixture` 对象实现了用于拟合高斯混合模型的期望最大化（EM）算法。

**基于密度的空间聚类算法（DBSCAN）** 通过将密集的数据点分组在一起，并将低密度的数据点指定为异常值来运行。

首先阅读并遵循 Scikit-learn 文档中的 DBSCAN 示例实现，然后跟随一个简明的教程：

+   [DBSCAN 聚类算法演示](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)，Scikit-learn 文档

+   [基于密度的聚类算法（DBSCAN）及其实现](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在 IT 领域

* * *

### 更多相关主题

+   [使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [建立一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [是什么让 Python 成为初创企业的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，然后找到目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
