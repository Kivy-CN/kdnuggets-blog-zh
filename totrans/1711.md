# 使用R进行过程挖掘：介绍

> 原文：[https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html](https://www.kdnuggets.com/2017/11/process-mining-r-introduction.html)

**作者：Seppe vanden Broucke, KU Leuven**

今天的组织机构采用了各种信息支持系统来支持他们的业务流程。这些支持系统记录并记录了大量的数据，包含各种*事件*，这些事件可以与源业务流程中任务发生的时刻关联起来。而[*过程挖掘*](http://www.dataminingapps.com/dma_research/process-analytics/)以这些事件日志作为分析的基石，旨在从中获取知识，对操作流程进行建模、改进和扩展以“实时”地发生在组织机构中。因此，过程挖掘可以被视为业务流程管理（BPM）和数据挖掘领域的交叉点。

* * *

## 我们的前3个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速迈向网络安全的职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 在IT领域支持您的组织

* * *

在过程挖掘领域中最著名的任务被称为*过程发现*（有时也被称为过程识别），分析师的目标是从记录在过程感知信息支持系统中的数据中推导出一个现状流程模型，而不是从一个描述性模型开始，然后尽力使实际数据与此模型对齐。过程挖掘建立在现有方法的基础上，尽管事件数据带来的特定环境和需求导致了各种特定工具和算法的创建。与传统的数据挖掘相比，数据挖掘最初是使用一个平坦的实例表的方式进行的，而过程挖掘则从一个*层次化的和内在有序*的数据集开始。层次化是指事件日志由多个记录一个过程实例的迹组成，而一个过程实例本身由多个事件组成。这些事件基于它们的执行顺序进行排序。因此，过程挖掘的一个主要用例是将这个复杂的数据集抽象成一个可视化的表示，即一个过程模型，突出显示频繁的行为、瓶颈或任何其他可能对最终用户感兴趣的数据维度。

传统的数据挖掘工具如R、SAS或Python非常强大，可以过滤、查询和分析平面表格，但由于事件日志的非典型特性，尚未被过程挖掘社区广泛采用来实现前述任务。相反，出现了一系列独立的工具生态系统，包括但不限于：Disco，Minit，ProcessGold，Celonis Discovery，ProM等。在本文中，我们想要通过使用更传统的数据科学编程语言R，快速介绍如何创建丰富的过程地图。当上述工具可能无法使用时，这将很有帮助，并且还提供了有关如何通过或更容易地结合在此环境中执行的与数据挖掘相关的其他任务来增强典型的过程挖掘任务的提示。此外，直接处理数据的实践方法将显示，开始进行过程发现非常容易。我们选择R作为我们的“工作语言”，因为现代R的流畅性（即“整洁宇宙”包，特别是“dplyr”）使得相对可读且简明的方法成为可能，虽然没有理由认为其他工具如Python也能同样完美地运行。

我们将使用Disco提供的“[示例事件日志](http://www.dataminingapps.com/dma_research/process-analytics/)”作为运行示例。首先，我们加载一些我们需要的库，并定义一些辅助函数并加载事件日志：

```py

# Load in libraries
library(tidyverse)
library(igraph)
library(subprocess)
library(png)
library(grid)
library(humanFormat)

# Returns the max/min of given sequence or a default value in case the sequence
# is empty

max.na <- function(..., def=NA, na.rm=FALSE)

if(!is.infinite(x<-suppressWarnings(max(..., na.rm=na.rm)))) x else def

min.na <- function(..., def=NA, na.rm=FALSE)

if(!is.infinite(x<-suppressWarnings(min(..., na.rm=na.rm)))) x else def

eventlog <- read.csv('c:/users/seppe/desktop/sandbox.csv', sep=';')

eventlog$Start <- as.POSIXct(strptime(eventlog$Start.Timestamp, 
                                 "%Y/%m/%d %H:%M:%OS"))

eventlog$Complete <- as.POSIXct(strptime(eventlog$Complete.Timestamp, 
                                   "%Y/%m/%d %H:%M:%OS"))

```

接下来是分析过程的关键步骤：对于事件日志中的每一行事件，我们希望找出（i）前一活动，即在同一案例中在此活动开始之前最近停止的活动，并且（ii）后续活动，即在同一案例中在此活动完成后最快开始的活动。为此，我们首先为每个事件分配一个递增的行号，并使用它来构建两个新列，以引用事件日志中的后续事件和前一个事件：

```py
eventlog %<>%

mutate(RowNum=row_number()) %>%

arrange(Start, RowNum) %>%

mutate(RowNum=row_number()) %>%

rowwise %>%

mutate(NextNum=min.na(.$RowNum[.$Case.ID == Case.ID & RowNum < .$RowNum & 
                                                 .$Start >= Complete])) %>%

mutate(PrevNum=max.na(.$RowNum[.$Case.ID == Case.ID & RowNum > .$RowNum &
                                                   .$Complete <= Start])) %>%

ungroup

```

使用这种准备好的事件日志数据集，我们已经可以获得许多有趣的描述性统计和见解。例如，以下代码块提供了事件日志中不同变体（路径）的概述：

```py
eventlog %>%

arrange(Start.Timestamp) %>%

group_by(Case.ID) %>%

summarize(Variant=paste(Activity, collapse='->', sep='')) %>%

ggplot(aes(x=reorder(Variant, -table(Variant)[Variant]) )) +

theme_minimal() +

theme(axis.text.x=element_blank(),

axis.ticks.x=element_blank()) +

xlab('Variants') +

geom_bar()

```

与许多过程相同，有几个变体构成了过程实例的最大部分，其后是“长尾行为”：

![](../Images/e8a0c33bdf2881846042dc9a1b798f31.png)

接下来，我们构建包含活动和边缘的两个数据帧，仅包含我们在可视化过程地图中所需的列。我们还将计算事件持续时间：

```py
activities.basic <- eventlog %>%

select(Case.ID, RowNum, Start, Complete, act=Activity) %>%

mutate(Duration=Complete-Start)

edges.basic <- bind_rows(

eventlog %>% select(Case.ID, a=RowNum, b=NextNum),

eventlog %>% select(Case.ID, a=PrevNum, b=RowNum)) %>%

filter(!is.na(a), !is.na(b)) %>%

distinct %>%

left_join(eventlog, by=c("a" = "RowNum"), copy=T, suffix=c("", ".prev")) %>%

left_join(eventlog, by=c("b" = "RowNum"), copy=T, suffix=c("", ".next")) %>%

select(Case.ID, a, b,

a.act=Activity, b.act=Activity.next,

a.start=Start, b.start=Start.next,

a.complete=Complete, b.complete=Complete.next) %>%

mutate(Duration=b.start-a.complete)

```

后者需要一些周到的思考。尽管一个明确的（活动A-活动B）对列表足以构建流程图，但我们需要考虑弧线出现的次数以计算频率和其他指标。因此，我们首先将（Case Identifier，RowNum，NextNum）列表与（Case Identifier，PrevNum，RowNum）合并，并过滤出端点等于NA的所有条目。然后，我们应用“distinct”操作符以确保获得唯一列表，尽管在行号级别上而不是活动名称级别上。这样可以确保我们的频率计数保持正确。然后，我们可以通过在事件日志上两次连接自身来找出每个弧线的活动级端点。然后，我们选择每个弧线的案例标识符，端点行号（“a”和“b”），端点的活动名称，端点的活动开始和完成时间，以及基于端点的弧线持续时间，即弧线的等待时间。

这是我们开始构建流程图所需的所有信息。我们将使用优秀的“igraph”包来可视化流程图。然而，在R中直接绘制它会得到默认的不吸引人的结果。不幸的是，igraph和大多数图形工具一样，都建立在图形可以非常无结构的假设之上（想象一下社交网络图），因此面向过程的图形的布局看起来并不吸引人。幸运的是，igraph带有强大的导出功能，我们可以利用这个功能。在这里，我们将将图形导出为dot文件格式，并使用“Graphviz”执行实际的布局和生成结果图像。

让我们尝试创建一个流程图，其中包含对活动和弧线的中位持续时间的注释。首先，我们将定义两个活动和边缘的颜色渐变，以及另一个小的辅助函数，然后使用持续时间信息构建两个新的活动和边缘数据框：

```py
col.box.red <- colorRampPalette(c('#FEF0D9', '#B30000'))(20)

col.arc.red <- colorRampPalette(c('#938D8D', '#B30000'))(20)

linMap <- function(x, from, to) (x - min(x)) / max(x - min(x)) * (to - from) + from

activities.counts <- activities.basic %>%

group_by(act) %>%

summarize(metric=formatSeconds(as.numeric(median(Duration))),

metric.s=as.numeric(median(Duration))) %>%

ungroup %>%

mutate(metric=ifelse(metric.s == 0, 'instant', metric),

color=col.box.red[floor(linMap(metric.s, 1,20))])

edges.counts <- edges.basic %>%

group_by(a.act, b.act) %>%

summarize(metric=formatSeconds(as.numeric(median(Duration))),

metric.s=as.numeric(median(Duration))) %>%

ungroup %>%

mutate(metric=ifelse(metric.s == 0, 'instant', metric),

color=col.arc.red[floor(linMap(metric.s, 1, 20))],

penwidth=floor(linMap(metric.s, 1, 5)))

```

### 更多关于这个话题的内容

+   [如何在几秒钟内处理数百万行的 DataFrame](https://www.kdnuggets.com/2022/01/process-dataframe-millions-rows-seconds.html)

+   [机器学习过程的框架](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)

+   [使用 Python 处理 CSV 文件的 3 种方法](https://www.kdnuggets.com/2022/10/3-ways-process-csv-files-python.html)

+   [自然语言处理简介](https://www.kdnuggets.com/2022/06/gentle-introduction-natural-language-processing.html)

+   [人工智能中的爬山算法介绍](https://www.kdnuggets.com/2022/07/introduction-hill-climbing-algorithm-ai.html)

+   [SMOTE 简介](https://www.kdnuggets.com/2022/11/introduction-smote.html)
