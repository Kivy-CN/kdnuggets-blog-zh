["```py\npip install shap\n```", "```py\nconda install -c conda-forge shap\n```", "```py\nimport pandas as pd\n\nmobile = pd.read_csv(\"train.csv\")\nmobile.head()\n```", "```py\nfrom sklearn.model_selection import train_test_split\n\nX = mobile.drop('price_range', axis=1)\ny = mobile.pop('price_range')\n\n# Train and test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Model fitting\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\n\n# Prediction\ny_pred = rf.predict(X_test)\n\n# Model evaluation\nprint(classification_report(y_pred, y_test))\n```", "```py\n precision    recall  f1-score   support\n\n           0       0.95      0.91      0.93       141\n           1       0.83      0.81      0.82       153\n           2       0.80      0.85      0.83       158\n           3       0.93      0.93      0.93       148\n\n    accuracy                           0.87       600\n   macro avg       0.88      0.87      0.88       600\nweighted avg       0.87      0.87      0.87       600\n```", "```py\nimport shap\nshap.initjs()\n\n# Calculate SHAP values\nexplainer = shap.TreeExplainer(rf)\nshap_values = explainer.shap_values(X_test)\n```", "```py\n# Summarize the effects of features\nshap.summary_plot(shap_values, X_test)\n```", "```py\nshap.summary_plot(shap_values[0], X_test)\n```", "```py\nshap.dependence_plot(\"battery_power\", shap_values[0], X_test,interaction_index=\"ram\")\n```", "```py\nshap.plots.force(explainer.expected_value[0], shap_values[0][12,:], X_test.iloc[12, :], matplotlib = True)\n```", "```py\nshap.plots.force(explainer.expected_value[1], shap_values[1][12, :], X_test.iloc[12, :],matplotlib = True)\n```", "```py\ny_test.iloc[12]\n>>> 1 \n```", "```py\nshap.decision_plot(explainer.expected_value[1], shap_values[1][12,:], X_test.columns)\n```"]