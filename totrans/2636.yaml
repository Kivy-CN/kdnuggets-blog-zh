- en: Popular Machine Learning Interview Questions, part 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的机器学习面试问题，第 2 部分
- en: 原文：[https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Mo Daoud](https://mohamed-daoud214.medium.com/), Works in technology,
    AI enthusiast**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Mo Daoud](https://mohamed-daoud214.medium.com/)，从事技术工作，AI 爱好者**。'
- en: This article is part 2 of my [Popular Machine Learning Interview questions](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是我 [流行的机器学习面试问题](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html)
    的第二部分。
- en: Here I feature more questions I usually see asked during interviews. I shall
    note that this isn’t an interview prep guide nor a conclusive list of all questions.
    Rather, you should use this article as a refresher for your Machine Learning knowledge.
    I suggest reading the question then try to answer it yourself before reading the
    answer. This way, you will validate your knowledge and learn where are your skill
    gaps. Let’s get started.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我展示了在面试中我通常看到的更多问题。我必须说明，这不是一份面试准备指南，也不是所有问题的完整列表。相反，你应该将这篇文章作为复习你机器学习知识的材料。我建议你在阅读答案之前先阅读问题，并尝试自己回答。这样，你可以验证你的知识，并发现技能上的差距。让我们开始吧。
- en: '![](../Images/004475fc96ce5b397df59868fa7d8d31.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/004475fc96ce5b397df59868fa7d8d31.png)'
- en: '*Photo by [Gabrielle Henderson](https://unsplash.com/@gabriellefaithhenderson?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*图片由 [Gabrielle Henderson](https://unsplash.com/@gabriellefaithhenderson?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。*'
- en: '*Q1\. What’s the difference between ANN, CNN, and RNN?*'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q1. 人工神经网络 (ANN)、卷积神经网络 (CNN) 和递归神经网络 (RNN) 之间有什么区别？*'
- en: 'ANN stands for **Artificial Neural Networks** , which is the basis of deep
    learning. In ANN, we have layers, neurons, activation functions, weights, and
    backpropagation. You should be familiar with all these terms. If not, then read [Neurons,
    Activation Functions, Back-Propagation, Epoch, Gradient Descent: What are these?](https://towardsdatascience.com/neurons-activation-functions-back-propagation-epoch-gradient-descent-what-are-these-c80349c6c452)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ANN 代表 **人工神经网络**，这是深度学习的基础。在 ANN 中，我们有层、神经元、激活函数、权重和反向传播。你应该对这些术语都很熟悉。如果不熟悉，可以阅读
    [神经元、激活函数、反向传播、时期、梯度下降：这些是什么？](https://towardsdatascience.com/neurons-activation-functions-back-propagation-epoch-gradient-descent-what-are-these-c80349c6c452)
- en: I usually find good candidates drawing during interviews to illustrate their
    ideas and confirm their knowledge. Drawing the below diagram will help you further
    explain ANN and how it learns.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常发现候选人在面试时通过绘图来说明他们的想法并确认他们的知识。绘制以下图表将帮助你进一步解释 ANN 以及它是如何学习的。
- en: '![](../Images/8658016cf94fa6a946df2fe411aed9e3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8658016cf94fa6a946df2fe411aed9e3.png)'
- en: '*Artificial Neural Network: Learning Steps. Image by Author.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工神经网络：学习步骤。图片作者。*'
- en: CNN is a **Convolution Neural Network ****with** its main application in computer
    vision and video analytics in general. CNN deals with the issue of how to enter
    an image in an ANN, how to capture the important features of an image and convert
    it into a format that can be fed in the neural network.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 是一个 **卷积神经网络**，主要应用于计算机视觉和视频分析。CNN 处理如何将图像输入到人工神经网络中，如何捕捉图像的重要特征并将其转换为可以输入神经网络的格式。
- en: CNN takes an image and passes it through the below steps
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 处理图像并经过以下步骤
- en: '**1 - Convolution**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**1 - 卷积**'
- en: The image is converted into 0’s and 1’s and then multiplied by a feature detector
    to produce a feature map. The main reason for this step is to reduce the size
    of the input image. Some information might get lost, but the main features of
    the image will get captured. Usually, the image is multiplied by multiple feature
    detectors to produce multiple feature maps. These feature maps go through a function,
    usually, ReLU, to ensure non-linearity in the image.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图像被转换为 0 和 1，然后乘以特征检测器以生成特征图。此步骤的主要原因是为了减少输入图像的大小。可能会丢失一些信息，但图像的主要特征将被捕捉到。通常，图像会被多个特征检测器处理，生成多个特征图。这些特征图会经过一个函数，通常是
    ReLU，以确保图像中的非线性。
- en: '**2 - Pooling**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**2 - 池化**'
- en: There are several pooling operations, but the most common is max pooling. It
    teaches the network spatial variance. In simple words, the ability to recognize
    the image features even if the image is upside down, tilted, or the image is taken
    from far or close, etc. The output of this operation is a pooled feature map.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种池化操作，但最常见的是最大池化。它教会网络空间变异性。简单来说，就是即使图像被颠倒、倾斜，或从远处或近处拍摄，网络也能识别图像特征。这种操作的输出是一个池化特征图。
- en: '**3 - Flattening**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**3 - 展平**'
- en: The purpose of this operation is to be able to input the pooled feature map
    into the neural network.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作的目的是能够将池化特征图输入到神经网络中。
- en: The below image shows the entire CNN operation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示展示了整个卷积神经网络（CNN）操作。
- en: '![](../Images/a5e8416db925a357745b392bf1249f00.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5e8416db925a357745b392bf1249f00.png)'
- en: '*Convolution Neural Network. Image by Author.*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积神经网络。图片由作者提供。*'
- en: As you can see, the flattened output of the CNN has the image features and is
    in a format that can be input to the ANN.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，CNN 的展平输出包含了图像特征，并且以可以输入到人工神经网络（ANN）的格式呈现。
- en: RNN is **Recurrent Neural Networks** that is mainly used for time series problems
    like stock market forecasting. They are famous for **LSTM** (Long Short-Term Memory).
    Similar to ANN, there are input and output layers along with multiple layers of
    neurons in between, but the main difference is that RNN neurons have a sort of
    short-term memory. This short-term memory provides the neurons with the possibility
    to remember what was in this neuron previously. This is the reason RNN is good
    for time series problems and translation since the network will need to know the
    previous translated word in order to create a coherent sentence rather than just
    translate each word on its own.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 是 **递归神经网络**，主要用于时间序列问题，如股票市场预测。它们以 **LSTM**（长短期记忆）而闻名。与人工神经网络（ANN）类似，RNN
    也有输入层和输出层以及多个中间层的神经元，但主要区别在于 RNN 神经元具有某种短期记忆。这种短期记忆使得神经元能够记住之前在该神经元中的内容。这就是为什么
    RNN 适用于时间序列问题和翻译的原因，因为网络需要了解之前翻译的词汇，以便生成连贯的句子，而不仅仅是逐词翻译。
- en: This question is one of my all-time favorites because it shows a general overview
    understanding of the main concept of neural networks.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题是我最喜欢的问题之一，因为它展示了对神经网络主要概念的总体理解。
- en: '*Q2\. What’s the difference between AI, ML, and DL?*'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q2. AI、ML 和 DL 之间的区别是什么？*'
- en: This is a simple one, yet many people get it wrong. The main thing to know is
    that AI is the general term, then give some examples.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的问题，但许多人却答错了。主要是要知道人工智能是一个通用术语，然后给出一些例子。
- en: '**Artificial Intelligence** is the science of making computers behave like
    humans in terms of making decisions, text processing, translation, etc. AI is
    a big umbrella with Machine Learning and Deep Learning under it.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能** 是让计算机在决策、文本处理、翻译等方面像人类一样行为的科学。人工智能是一个大的伞，机器学习和深度学习都在它之下。'
- en: '***Every Machine Learning algorithm is considered AI but not every AI algorithm
    is considered Machine Learning.***'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '***每个机器学习算法都被认为是人工智能（AI），但不是所有的人工智能算法都被认为是机器学习。***'
- en: '![](../Images/b129ee5b601aa70a97d9e9f53de9352a.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b129ee5b601aa70a97d9e9f53de9352a.png)'
- en: '*The relation between AI, ML, and DL. Image by Author.*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI、ML 和 DL 之间的关系。图片由作者提供。*'
- en: '**Machine Learning**: You select the model to train and ***manually*** perform
    feature extraction for the model to learn.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**：你选择模型进行训练，并且 ***手动*** 执行特征提取，以便模型进行学习。'
- en: '**Deep Learning**: You design the architecture of the Neural Network, and features
    are ***automatically*** extracted from the fed labeled training data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习**：你设计神经网络的架构，特征从提供的标记训练数据中被 ***自动*** 提取。'
- en: '![](../Images/090d0482e9f390f2e1dcec82640743c6.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/090d0482e9f390f2e1dcec82640743c6.png)'
- en: '*Difference between ML and DL. Image by Author.*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习与深度学习之间的区别。图片由作者提供。*'
- en: '*Q3\. What are factorization machine algorithms, and what are they used for?*'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q3. 什么是矩阵分解机器算法，它们用于什么？*'
- en: Factorization Machines can be used for classification or regression and are
    much more computationally efficient on **large sparse data sets** than traditional
    algorithms like linear regression. This property is why Factorization Machines
    are widely used for recommendation. Factorization Machines are supervised learning
    algorithms, and their main use is handling spare data. However, they don’t perform
    dimensionality reduction. An example of Factorization Machines use is ad click
    prediction and item recommendation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解机可以用于分类或回归，并且在处理**大规模稀疏数据集**时，比传统算法如线性回归更加高效。这种特性使得因式分解机在推荐系统中被广泛应用。因式分解机是监督学习算法，主要用于处理稀疏数据。然而，它们不进行降维。因式分解机的一个应用例子是广告点击预测和商品推荐。
- en: '*Q4\. How can you create a model with a very unbalanced dataset? For example,
    working with credit card fraud data and there are very few real fraud cases while
    the majority of the cases are non-fraudulent.*'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q4. 如何使用非常不平衡的数据集创建模型？例如，处理信用卡欺诈数据时，真实欺诈案例非常少，而大多数案例都是非欺诈性的。*'
- en: Creating a model with an unbalanced dataset will yield bad results in terms
    of favoring more training data, in our case, the non-fraudulent transactions.
    You should never create a model with an unbalanced dataset. The answer should
    be around trying to gather more balanced data and, if not possible, then oversample
    your data using **SMOTE (Synthetic Minority Over Sampling) **or** Random Over
    Sampling (ROS)**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不平衡数据集创建模型会导致结果不佳，尤其是对更多训练数据（在我们这个例子中是非欺诈性交易）有偏向。你绝不应使用不平衡数据集来创建模型。解决方案是尽量收集更多平衡的数据，如果不可能，则可以使用**SMOTE（合成少数类过采样）**或**随机过采样（ROS）**对数据进行过采样。
- en: '![](../Images/b3e7ada95649d93ce2ba6ccd232cc99f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3e7ada95649d93ce2ba6ccd232cc99f.png)'
- en: '*SMOTE Techniques to Balance Datasets. Image by Author.*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*SMOTE技术用于平衡数据集。图片来源：作者。*'
- en: The **SMOTE** technique creates new observations of the underrepresented class,
    in this case, the fraudulent observations. These synthetic observations are almost
    identical to the original fraudulent observations. This technique is expeditious,
    but the types of synthetic observations it produces are not as useful as the unique
    observations created by other oversampling techniques.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**SMOTE**技术会生成新的少数类观察值，在这个例子中是欺诈性观察值。这些合成观察值几乎与原始欺诈性观察值相同。该技术迅速有效，但其生成的合成观察值类型不如其他过采样技术创造的独特观察值有用。'
- en: '*Q5\. What’s regularization, and what’s the difference between L1 and L2 regularization?*'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q5. 什么是正则化，L1和L2正则化有什么区别？*'
- en: Regularization in machine learning is the process of regularizing the parameters
    that constrain, regularizes, or shrinks the coefficient estimates towards zero.
    In other words, this technique discourages learning of a more complex or flexible
    model, avoiding the risk of overfitting. Regularization basically adds the penalty
    as model complexity increases, which can help avoid overfitting.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，正则化是对参数进行约束、规整或使系数估计向零收缩的过程。换句话说，这种技术会抑制学习更复杂或更灵活的模型，从而避免过拟合的风险。正则化基本上是随着模型复杂性的增加而增加惩罚，这有助于避免过拟合。
- en: '**L1 effectively removes features** that are unimportant, and doing this too
    aggressively can lead to underfitting. **L2 weighs each feature** instead of removing
    them entirely, which can lead to better accuracy. Briefly, L1 removes features
    while L2 doesn’t, and L2 regulates their weights instead.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**L1有效地去除不重要的特征**，过于激进的去除可能导致欠拟合。**L2则对每个特征进行加权**，而不是完全去除它们，这可能带来更好的准确性。简而言之，L1去除特征，而L2则不去除，而是对其权重进行规整。'
- en: '*Q6\. What’s transfer learning? How it’s useful?*'
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q6. 什么是迁移学习？它有什么用？*'
- en: '**Transfer Learning** allows you to start with an existing trained model, usually
    off the shelf from a source like GitHub. You take the existing trained model and
    apply it to your different but closely aligned observations. This saves you time
    deploying and operationalizing your machine learning solution since you are starting
    from a pre-trained model.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习**允许你从现有的训练模型开始，通常是从像GitHub这样的来源获取现成的模型。你将现有的训练模型应用于你不同但紧密相关的观察数据。这节省了你部署和操作机器学习解决方案的时间，因为你是从一个预训练的模型开始的。'
- en: In Transfer Learning, the network is initialized with pre-trained weights, and
    just the top fully connected layer is initialized with random weights. Then, the
    whole network is fine-tuned with new data. In this mode, training can be achieved
    even with a smaller dataset. This is because the network is already trained and
    therefore, can be used in cases without sufficient training data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移学习中，网络初始化为预训练的权重，仅将顶层全连接层初始化为随机权重。然后，整个网络会根据新数据进行微调。在这种模式下，即使数据集较小，也可以进行训练。这是因为网络已经过训练，因此可以在没有足够训练数据的情况下使用。
- en: '![](../Images/135e1449807cc5af6751270c60629db0.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/135e1449807cc5af6751270c60629db0.png)'
- en: '*Full Learning vs. Transfer Learning. Image by Author.*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*全学习 vs. 迁移学习。图像来源于作者。*'
- en: '*Q7\. What’s the LDA algorithm? Give an example.*'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q7\. LDA 算法是什么？举一个例子。*'
- en: '**LDA (Latent Dirichlet Allocation)** algorithm is an unsupervised learning
    algorithm that attempts to describe a set of observations as a mixture of distinct
    categories. LDA is most commonly used to discover a user-specified number of topics
    shared by documents within a text corpus, i.e., topic modeling.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**LDA（潜在狄利克雷分配）** 算法是一种无监督学习算法，尝试将一组观察结果描述为不同类别的混合。LDA 最常用于发现文档集中的用户指定数量的主题，即主题建模。'
- en: '*Q8\. What’s the difference between Linear Regression and Logistic Regression?*'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q8\. 线性回归和逻辑回归有什么区别？*'
- en: '**Linear Regression** is used to predict a continuous variable and is mainly
    used to solve regression problems. Linear regression finds the best fit line by
    which the numerical output value can be predicted.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性回归** 用于预测连续变量，主要用于解决回归问题。线性回归通过寻找最佳拟合线来预测数值输出。'
- en: '**Logistic Regression** is used to predict categorical values and is mainly
    used in classification problems. Logistic regression produces an S curve that
    classifies, and the output is binary or categories.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归** 用于预测分类值，主要用于分类问题。逻辑回归产生一个 S 曲线进行分类，输出是二元或类别值。'
- en: '*Q9\. What’s Bag of Words used for?*'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q9\. Bag of Words 用于什么？*'
- en: Bag-of-Words is an NLP (Natural Language Processing) algorithm that creates
    tokens of the input document text and outputs a statistical depiction of the text.
    The statistical depiction, such as a histogram, shows the count of each word in
    the document.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Bag-of-Words 是一种 NLP（自然语言处理）算法，它创建输入文档文本的标记，并输出文本的统计表示。这种统计表示，例如直方图，显示文档中每个词的计数。
- en: '*Q10\. How can you identify a high bias model? How can you fix it?*'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q10\. 如何识别高偏差模型？如何修复？*'
- en: 'A High Bias model is due to a simple model and can be easily identified when
    you see:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 高偏差模型是由于模型简单而产生的，通常在你看到以下情况时容易识别：
- en: High training error
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高训练误差
- en: Validation error or test error is the same as training error
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证误差或测试误差与训练误差相同
- en: 'To fix a High Bias model, you can:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要修复高偏差模型，你可以：
- en: Add more input features
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加更多输入特征
- en: Add more complexity by introducing polynomial features
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过引入多项式特征增加复杂性
- en: Decrease the regularization term
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少正则化项
- en: '*Q11\. How to identify a high variance model? How do you fix it?*'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q11\. 如何识别高方差模型？如何修复？*'
- en: 'A High Variance model is due to a complex model and can be easily identified
    when you see:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 高方差模型是由于模型复杂而产生的，通常在你看到以下情况时容易识别：
- en: Low training error
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 低训练误差
- en: High validation error or high test error
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高验证误差或高测试误差
- en: 'To fix a high variance model, you can:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要修复高方差模型，你可以：
- en: Get more training data
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取更多训练数据
- en: Reduce input features
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少输入特征
- en: Increase the regularization term
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加正则化项
- en: '*Q12\. What are some common tools to evaluate regression models?*'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q12\. 评估回归模型的一些常见工具是什么？*'
- en: The first thing that comes to my mind when I hear regression model evaluation
    is **RMSE (Root Mean Square Error)** because it’s the most simple and common metric
    for regression evaluation. RMSE can easily tell if the model is overestimating
    or underestimating.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当我听到回归模型评估时，第一个想到的就是 **RMSE（均方根误差）**，因为它是回归评估中最简单和最常见的指标。RMSE 可以轻松地告诉你模型是否过高估计或低估。
- en: RMSE is the gap between the predicted numerical target and the true numerical
    answer (i.e., true numerical value). The smaller the value of RMSE, the better
    the prediction accuracy of the model. If the model’s prediction is correct, its
    RMSE will be 0.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE 是预测数值目标与真实数值答案之间的差距（即真实数值）。RMSE 值越小，模型的预测精度越好。如果模型的预测正确，其 RMSE 将为 0。
- en: '*Q13\. What’s ROC and AUC? What are they used for?*'
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q13\. 什么是 ROC 和 AUC？它们用于什么？*'
- en: A **ROC (Receiver Operating Characteristic)** curve, or ROC curve, is a graphical
    plot that illustrates the diagnostic ability of a binary classifier system as
    its discrimination threshold is varied.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**ROC（接收操作特征）**曲线，或ROC曲线，是一种图形绘制，展示了二元分类系统在其区分阈值变化时的诊断能力。'
- en: '![](../Images/e5f6090e3d150b6db5423705319c675d.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5f6090e3d150b6db5423705319c675d.png)'
- en: '*ROC Curve. [Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc).*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*ROC曲线。[来源](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)。*'
- en: 'This curve plots two parameters:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该曲线绘制了两个参数：
- en: True Positive Rate
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真正率
- en: False Positive Rate
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假正率
- en: ROC curve plots True Positive Rate vs. False Positive Rate at different classification
    thresholds. Lowering the classification threshold classifies more items as positive,
    thus increasing both False Positives and True Positives.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ROC曲线在不同分类阈值下绘制真正率与假正率。降低分类阈值将更多项分类为正，从而增加假正例和真正例。
- en: '**Area Under the ROC Curve (AUC) **measures the entire two-dimensional area
    underneath the ROC curve. AUC is used to compare/evaluate machine learning classification
    models against each other and measures the entire two-dimensional area underneath
    the entire ROC curve.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**ROC曲线下的面积（AUC）**衡量ROC曲线下方的整个二维面积。AUC用于相互比较/评估机器学习分类模型，并测量整个ROC曲线下的二维面积。'
- en: '![](../Images/2cbc28b5174e287f36cf89099d41fd39.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cbc28b5174e287f36cf89099d41fd39.png)'
- en: '*AUC. [Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc).*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*AUC. [来源](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)。*'
- en: AUC provides an aggregate measure of performance across all possible classification
    thresholds. One way of interpreting AUC is the probability that the model ranks
    a random positive example more highly than a random negative example.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: AUC提供了所有可能分类阈值下的性能总衡量。一种解释AUC的方法是模型将随机正例的排名高于随机负例的概率。
- en: Good luck with any upcoming interview you may have. There are a lot of Machine
    Learning and AI information online, and there are many sources you can gain knowledge
    from. I encourage you to utilize free sources, courses, and articles like this
    to learn more about Machine Learning. ML and AI will affect your job no matter
    what line of work you’re in, so arm yourself with the required knowledge.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你好运，无论你即将参加哪个面试。网上有大量的机器学习和人工智能信息，你可以从许多来源获取知识。我鼓励你利用免费资源、课程和类似的文章来深入了解机器学习。无论你从事哪个行业，机器学习和人工智能都会影响你的工作，因此请为自己装备所需的知识。
- en: '[Original](https://towardsdatascience.com/popular-machine-learning-interview-questions-part-2-d484874c21fe).
    Reposted with permission.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/popular-machine-learning-interview-questions-part-2-d484874c21fe)。经许可转载。'
- en: '**Related:**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Popular Machine Learning Interview Questions](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[流行的机器学习面试问题](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html)'
- en: '[The Ultimate Guide to Data Engineer Interviews](https://www.kdnuggets.com/2020/12/ultimate-guide-data-engineer-interviews.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据工程师面试终极指南](https://www.kdnuggets.com/2020/12/ultimate-guide-data-engineer-interviews.html)'
- en: '[How to Explain Key Machine Learning Algorithms at an Interview](https://www.kdnuggets.com/2020/10/explain-machine-learning-algorithms-interview.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在面试中解释关键的机器学习算法](https://www.kdnuggets.com/2020/10/explain-machine-learning-algorithms-interview.html)'
- en: '* * *'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Data Science Interview Guide - Part 2: Interview Resources](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试指南 - 第二部分：面试资源](https://www.kdnuggets.com/2022/04/data-science-interview-guide-part-2-interview-resources.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20个问题（附答案）检测虚假数据科学家：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20个问题（附答案）检测虚假数据科学家：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
- en: '[SQL Interview Questions for Experienced Professionals](https://www.kdnuggets.com/2022/01/sql-interview-questions-experienced-professionals.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[经验丰富的专业人士 SQL 面试问题](https://www.kdnuggets.com/2022/01/sql-interview-questions-experienced-professionals.html)'
- en: '[How to Answer Data Science Coding Interview Questions](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何回答数据科学编程面试问题](https://www.kdnuggets.com/2022/01/answer-data-science-coding-interview-questions.html)'
- en: '[15 Python Coding Interview Questions You Must Know For Data Science](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15个你必须了解的 Python 编程面试问题（适用于数据科学）](https://www.kdnuggets.com/2022/04/15-python-coding-interview-questions-must-know-data-science.html)'
