- en: 'Federated Learning: Collaborative Machine Learning with a Tutorial on How to
    Get Started'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Federated-Learning-Collaborative-Machine-Learning-blog.jpg](../Images/723734f5fd799f64ecea45bd199a6824.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Federated Learning: Privacy, Security, and Data Sovereignty in the Lab and
    in the Wild (with Tutorial)**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning, also known as collaborative learning, allows [training models](https://www.exxactcorp.com/Deep-Learning-NVIDIA-GPU-Workstations) at
    scale on data that remains distributed on the devices where they are generated.
    Sensitive data remains with the owners of said data, where training is conducted,
    and a centralized training orchestrator of training only sees the contribution
    of each client through model updates.
  prefs: []
  type: TYPE_NORMAL
- en: Federated learning doesn’t guarantee privacy on its own (we'll touch on breaking
    and repairing privacy in federated learning systems later on), but it does make
    privacy possible.
  prefs: []
  type: TYPE_NORMAL
- en: '**Use cases for federated learning:**'
  prefs: []
  type: TYPE_NORMAL
- en: Next word prediction for mobile phone keyboards (*e.g. *[McMahan *et al.* 2017](https://arxiv.org/abs/1811.03604), [Hard *et
    al. *2019](https://arxiv.org/abs/1602.05629))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health research (*e.g.* [Kaissis* et al. *2020](https://www.nature.com/articles/s42256-020-0186-1/), [Sadilek *et
    al.* 2021](https://www.nature.com/articles/s41746-021-00489-2))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous vehicles (*e.g. *[Zeng* et al. *2021](https://arxiv.org/abs/2102.03401), [OpenMined
    blog post](https://blog.openmined.org/making-autonomous-vehicles-robust-active-learning-federated-learning-v2x/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Smart home” systems (*e.g.* [Matchi* et al.* 2019](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8844592), [Wu* et
    al. *2020](https://arxiv.org/abs/2012.07450))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: … and anywhere else where machine learning predictions would be useful, but
    individuals would rather not give up their personal data if given the choice.
    That covers pretty much every scenario where predictions are made at a resolution
    of the individual.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the public and policy-makers becoming more aware of the data economy, demand
    for privacy-preserving machine learning is on the rise. As a result, data practices
    have been garnering increased scrutiny, and research on privacy-respecting tools
    like federated learning is increasingly active. Ideally, federated learning aims
    to preserve individual and institutional privacy while potentially making collaborations
    between data stakeholders possible where they would normally be impossible due
    to trade secrecy, private health information, or the increased risk of data breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Government regulations like the European Union’s[ General Data Protection Regulation](https://en.wikipedia.org/wiki/GDPR) or
    the[ California Consumer Privacy Act](https://www.oag.ca.gov/privacy/ccpa) (among
    others) make privacy preserving strategies like federated learning become a useful
    tool for enterprises that want to remain in legal operation. At the same time,
    attaining a desired degree of privacy and security while maintaining model performance
    and efficiency presents plenty of technical challenges in their own right.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, from the everyday perspective of the individual data-producer (such
    as, in all likelihood, yourself, dear reader), it’s nice to know that, at least
    in theory, there’s something that can be placed between your private health and
    financial data and the kind of hodgepodge ecosystem of data brokers that track
    everything else you do online, typically *sans* both moral backbone and security
    competency.
  prefs: []
  type: TYPE_NORMAL
- en: If any of these issues strike a chord with you, then read on to learn more about
    the intricacies of federated learning and what it can do for machine learning
    on sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: '****Federated Learning in a Nutshell****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Federated learning aims to train a single model from multiple data sources,
    under the constraint that data stays at the source and is not exchanged by the
    data sources (a.k.a. nodes, clients, or workers) nor by the central server orchestrating
    training, if present.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/05695c8aff2696c10ecf1e18dd7473c0.png)'
  prefs: []
  type: TYPE_IMG
- en: '*In a typical federated learning scheme, a central server sends model parameters
    to a population of nodes (also known as clients or workers). The nodes train the
    initial model for some number of updates on local data and send the newly trained
    weights back to the central server, which averages the new model parameters (often
    with respect to the amount of training performed on each node). In this scenario
    the data at any one node is never directly seen by the central server or the other
    nodes, and additional techniques, such as secure aggregation, can further enhance
    privacy.*'
  prefs: []
  type: TYPE_NORMAL
- en: There are many variations within this framework. For example, we’re mainly concerned
    in this article with federated learning schemes managed by a central server that
    orchestrates training on multiple devices of the same type, each training on their
    own local data and uploading the results to the central server. This is the basic
    scheme described by[ McMahan et al. in 2017](https://arxiv.org/abs/1602.05629).
    However, it’s possible to do away with centralized control of training, and in
    some situations it may be desirable to do so. When individual nodes distribute
    the role of the central manager it becomes decentralized federated learning, an
    attractive approach for[ training](https://www.semanticscholar.org/paper/BrainTorrent%3A-A-Peer-to-Peer-Environment-for-Roy-Siddiqui/aad543a5b7f231f085764ce0258fe8914a15006f) collaborative
    models on[ privileged medical data](https://www.semanticscholar.org/paper/Decentralized-Federated-Learning-for-Electronic-Lu-Zhang/c838937405bce0365b6d4b1dc80f91c22cfa7b31).
  prefs: []
  type: TYPE_NORMAL
- en: While a typical federated learning scenario might involve a population of mobile
    phones, for example, all with roughly similar computational capabilities and training
    the same model architecture, some schemes, such as a[ HeteroFL](https://arxiv.org/abs/2010.01264) by
    Diao *et al. *2021*, *allow for training a single inference model on a variety
    of devices with vastly different communication and computation capabilities, even
    going so far as to train local models with different architectures and numbers
    of parameters, before aggregating the trained parameters to a global inference
    model.
  prefs: []
  type: TYPE_NORMAL
- en: The primary advantages of federated learning stem from the fact that data stays
    on the device where it’s generated, and includes, for example, the fact that a
    training dataset is usually substantially larger than the model being trained,
    and sending the latter instead of the former can save on bandwidth. Paramount
    among these advantages is the possibility of privacy, yet it is still possible
    to infer something about the contents of a private dataset from a model parameter
    update alone.
  prefs: []
  type: TYPE_NORMAL
- en: The simple example used in McMahan *et al.* 2017 to explain the vulnerability
    is a language model trained with a “bag-of-words” input vector, where each input
    vector corresponds specifically to a single word in a large vocabulary. Each non-zero
    gradient update for a corresponding word would give eavesdroppers a clue to the
    presence (and conversely the absence) of the word in the private dataset. More[ sophisticated
    attacks](https://inpher.io/journal-blog/the-privacy-risk-right-under-our-nose-in-federated-learning-part-1/) have
    also been demonstrated. As a result there is a wide spectrum of privacy-enhancing
    techniques that can be incorporated into federated learning, ranging from[ secure
    aggregation](https://dl.acm.org/doi/10.1145/3133956.3133982) of updates to training
    with[ fully homomorphic encryption](https://www.usenix.org/conference/atc20/presentation/zhang-chengliang).
    We’ll briefly touch on the most prominent threats to privacy in federated learning
    and their mitigation in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: '****The Ongoing Origin Story of Federated Learning****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: State regulation of data privacy is an emergent area of policy, gaining momentum
    about 10 to 20 years after it would have matched the development of large segments
    of the global economy based on personal data collection and analysis. The most
    prominent regulation of personal data belonging to members of the public is the
    European[ General Data Protection Regulation](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation) enacted
    in 2016, more commonly known as GDPR.
  prefs: []
  type: TYPE_NORMAL
- en: It may come as some surprise, given that similar protections limiting corporate
    surveillance and data collection in the USA are nascent or lacking, but the US
    White House published an extensive report outlining similar principles in 2012
    ([pdf](https://obamawhitehouse.archives.gov/sites/default/files/privacy-final.pdf)),
    including focused collection, data security and transparency, control over which
    data are collected, and an expectation that data collected for one purpose would
    not be used for wildly unrelated purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The[ California Consumer Privacy Act](https://www.oag.ca.gov/privacy/ccpa) followed
    the EU’s GDPR into law two years later in 2018\. As a state law, the CCPA is significantly
    limited in geographic scope by comparison to GDPR, while the act itself has similar
    aims but a somewhat narrower definition of personal information. Federated learning
    is one machine learning tool that can be used to give privacy a chance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The term *federated learning* was introduced in a[ 2017 paper](https://arxiv.org/abs/1602.05629) by
    McMahan *et al.* to describe the training of a model on decentralized data. The
    authors framed the design strategy for their system under the 2012 White House
    report on consumer data privacy described above. They suggested two primary use
    cases for federated learning: image classification, and language models for voice
    recognition or next word/phrase prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: It wasn’t long before the potential attack surfaces associated with distributed
    training were demonstrated. Work by [Phong *et al.* 2017](https://ieeexplore.ieee.org/document/8241854) and [Bhowmick
    et al. 2018](https://arxiv.org/abs/1812.00984) among others demonstrated that
    even with access only to the gradient updates or partially trained models returned
    from a federated learning client to the server, some details describing private
    data can be inferred. A summary of privacy concerns and their mitigation can be
    had in [this blog post](https://inpher.io/journal-blog/the-privacy-risk-right-under-our-nose-in-federated-learning-part-1/) at
    inpher.io.
  prefs: []
  type: TYPE_NORMAL
- en: The balance between privacy, effectiveness, and efficiency in federated learning
    spans a broad spectrum. Communications between the server and clients (or solely
    between decentralized clients) can be encrypted in transport and at rest, but
    there’s an even more robust option where data and models remain encrypted during
    training as well. [Homomorphic encryption](https://en.wikipedia.org/wiki/Homomorphic_encryption) can
    be used to perform computations on encrypted data, so that (ideally) the outputs
    can only be decrypted by the stakeholder with the key. Libraries like OpenMined’s [PySyft](https://github.com/OpenMined/PySyft),
    Microsoft’s [SEAL](https://github.com/Microsoft/SEAL), or [TensorFlow Encrypted](https://github.com/tf-encrypted/tf-encrypted) provide
    tools for encrypted deep learning that can be applied to federated learning systems.
  prefs: []
  type: TYPE_NORMAL
- en: That’s enough discussion about federated learning, next we'll set up a simple
    federated learning demonstration in the tutorial section.
  prefs: []
  type: TYPE_NORMAL
- en: '****Federated ML Tutorial: Federated Learning on the Iris Dataset with the
    Flower Library****'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '***If you run into any trouble getting the code to run for this tutorial and
    would like to see a working example, try running it in from your browser at ***[***this
    mybinder link***](https://mybinder.org/v2/gh/riveSunder/fed_ml_flower_demo/201057130524d2e2770afe297faf9fc7a961ab98)*** and
    follow the instructions in the ***[***readme***](https://github.com/riveSunder/fed_ml_flower_demo/commit/201057130524d2e2770afe297faf9fc7a961ab98)*** to
    launch the federated learning demo.***'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have an idea of where and why we might want to use federated learning,
    let’s take a hands-on look at how we might do so.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of federated learning libraries to choose from, from the
    more mainstream[ Tensorflow Federated](https://www.tensorflow.org/federated) with
    over 1700 stars on GitHub to the popular and privacy-focused[ PySyft](https://github.com/OpenMined/PySyft) to
    the research oriented[ FedJAX](https://github.com/google/fedjax). Table 1 contains
    a reference list of popular federated learning repositories.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Repository** | **License/Stars** | **Focus** |'
  prefs: []
  type: TYPE_TB
- en: '| TF Federated | [https://github.com/tensorflow/federated](https://github.com/tensorflow/federated)
    | [Apache 2.0 ](https://github.com/tensorflow/federated)/ 1.7k | R&D |'
  prefs: []
  type: TYPE_TB
- en: '| FedJAX | [https://github.com/google/fedjax](https://github.com/google/fedjax)
    | [Apache 2.0](https://github.com/tensorflow/federated/blob/main/LICENSE) / 130
    | Research |'
  prefs: []
  type: TYPE_TB
- en: '| Flower | [https://github.com/adap/flower](https://github.com/adap/flower)
    | [Apache 2.0](https://github.com/adap/flower/blob/main/LICENSE) / 529 | Usability
    |'
  prefs: []
  type: TYPE_TB
- en: '| FedML | [https://github.com/FedML-AI/FedML](https://github.com/FedML-AI/FedML)
    | [Apache 2.0](https://github.com/FedML-AI/FedML/blob/master/LICENSE) / 839 |
    Research |'
  prefs: []
  type: TYPE_TB
- en: '| PySyft | [https://github.com/openmined/pysyft](https://github.com/openmined/pysyft)
    | [Apache 2.0](https://github.com/OpenMined/PySyft/blob/main/packages/syft/LICENSE) /
    7.7k | Privacy / R&D |'
  prefs: []
  type: TYPE_TB
- en: '| IBM federated-learning-lib | [https://github.com/IBM/federated-learning-lib](https://github.com/IBM/federated-learning-lib)
    | [Custom](https://github.com/IBM/federated-learning-lib/blob/main/LICENSE) /
    244 | Enterprise |'
  prefs: []
  type: TYPE_TB
- en: '***Table 1: **Libraries for federated learning.*'
  prefs: []
  type: TYPE_NORMAL
- en: For our tutorial we'll use the[ Flower library](https://github.com/adap/flower).
    We chose this library in part because it exemplifies basic federated learning
    concepts in an accessible way and it is framework agnostic, and in part because
    we will be using the “iris” dataset included in SciKit-Learn (and the names match).
  prefs: []
  type: TYPE_NORMAL
- en: As Flower is agnostic to the deep learning toolkit used to build models (they
    have examples for[ TensorFlow](https://flower.dev/docs/quickstart_tensorflow.html),[ PyTorch](https://flower.dev/docs/quickstart_pytorch.html),[ MXNet](https://flower.dev/docs/quickstart_mxnet.html),
    and[ SciKit-Learn](https://github.com/adap/flower/tree/main/examples/sklearn-logreg-mnist) in
    the documentation), we’ll use PyTorch. From a high-level perspective, we need
    to set up a server and a client, the latter of which we’ll call twice with different
    training datasets. Setting up the server is by far the simpler of the tasks at
    hand, so we’ll start there.
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up our server, all we need to do is define an evaluation strategy and
    pass it to the default configuration server in Flower. But first let’s make sure
    we have a virtual environment set up that has all the dependencies we’ll need.
    On the Unix command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: With our virtual environment up and running, we can write a module for spinning
    up a Flower server to handle federated learning. In the code below we've included
    argparse to make it easier to experiment with different numbers of training rounds
    when calling the server module from the command line. We also define a function
    that generates an evaluation function, which is the only other thing we add to
    the strategy used by the default configuration of the Flower server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contents of our server module file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Take notice of the `PTMLPClient` called in the code above. This is used by the
    server module to define the evaluation function, and this class is also the model
    class used for training and doubles as a federated learning client. We'll define
    the `PTMLPClient` next, sub-classing from both Flower's `NumPyClient` class and
    the `torch.nn.Module` class that you’ll already be familiar with if you work with
    PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: The `NumPyClient` class handles communication with the server and requires use
    to implement the abstract functions `set_parameters`, `get_parameters`, `fit`,
    and `evaluate`. The `torch.nn.Module` class gives us all the convenient functionality
    of a PyTorch model, mainly the ability to train with the PyTorch Adam optimizer.
    Our `PTMLPClient` class will be just over 100 lines of code, so we’ll go through
    each class function in turn, starting with `__init__`.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we are inheriting from two ancestor classes. Inheriting from nn.Module
    means that we have to make sure to call `__init__` from nn.Module using the super
    command, but Python will let you know right away if you forget to do so. Other
    than that we initialize three dense layers as matrices (`torch.tensor` data types)
    and store some of the information about the training split and model dimensions
    as class variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next we'll define the `get_parameters` and `set_parameters` functions of the `PTMLPClient` class.
    These functions concatenate all model parameters as a flattened numpy array, which
    is the data type that Flower's NumPyClient class is expected to return and receive.
    This fits into the federated learning scheme as the server will send initial parameters
    to each client (using `set_parameters`) and expects a set of partially trained
    weights to be returned (from `get_parameters`). This pattern occurs once per round.
    We also initialize the optimizer and loss function in `set_parameters`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Next we'll define our forward pass and a convenience function for getting a
    loss scalar.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The last few functions that our client needs are `fit` and `evaluate`. For each
    round, each client initializes its parameters with those supplied to the fit method
    before training for a few epochs (default is 10 in this case). The `evaluate` function
    also sets its parameters before calculating the loss and accuracy on the validation
    split of the training data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Both `fit` and `evaluate` in our client class call a function get_data which
    is just a wrapper for the SciKit-Learn iris dataset. It also splits the data into
    training and validation sets, and further splits the training dataset in twain
    (which we call ‘alice’ and ‘bob’) to simulate federated learning with clients
    that each have their own data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we just need to populate an `if __name__ ==` "`__main__`": method at the
    bottom of our file so that we can run our client code as a module from the command
    line.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Finally, make sure to import everything needed at the top of the client module.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: That's actually all we have to implement to run a federated training demo with
    Flower!
  prefs: []
  type: TYPE_NORMAL
- en: To start a federated training run, first launch the server in its own command
    line terminal. We saved our server as pt_server.py and our client module as pt_client.py,
    both in the root of the directory we're working in, so to launch a server and
    tell it to train for 40 rounds of federated learning we used the following command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next open up a fresh terminal to launch your first client with the “alice”
    training split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '... and a second terminal for your next client with the “bob” training split.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If everything works you should see training start up and a scroll of info in
    the terminal running the server process.
  prefs: []
  type: TYPE_NORMAL
- en: '![fed-learning.jpg](../Images/c6c94bae6f2cea3b0ae107931843d1ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In our hands this demo achieved just over 96% accuracy in 20 rounds of training.
    The loss and accuracy curves for the training run look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![fed-learning-loss-of-accuracy.png](../Images/933df64b77c96cabf88ed197d71cfc91.png)'
  prefs: []
  type: TYPE_IMG
- en: That’s it! Now you can put “Flower library” on your federated learning resume.
  prefs: []
  type: TYPE_NORMAL
- en: '**Looking to the Future of Federated Learning**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A casual observer of the modern world might be persuaded to believe that there
    “[is no such thing](https://www.washingtonpost.com/posteverything/wp/2014/07/28/theres-no-such-thing-as-privacy-on-the-internet-anymore/) as [privacy](https://www.fastcompany.com/40561281/survey-most-facebook-users-dont-expect-much-privacy)”
    anymore. These declarations have been primarily directed at the internet (and
    such declarations have been made since [at least 1999](https://www.wired.com/1999/01/sun-on-privacy-get-over-it/))
    but with the rapid adoption of smart home devices and nosy home robots the reasonable
    expectation of privacy, even [within your own home](https://archive.is/0sDwX),
    may be in danger of catastrophic erosion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pay attention to who is making these declarations and you’ll find that many
    of them have a vested financial interest in the easy pilfering of your data, or
    may be beholden to those who do. This sort of “no privacy” defeatist attitude
    is not only wrong, but can be dangerous: loss of privacy allows individuals and
    groups to be subtly manipulated in ways they may not notice or admit, and people
    who know they are being watched [behave differently](https://en.wikipedia.org/wiki/Panopticon).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact
    Corp blog and works with many of its talented authors who write about different
    aspects of Deep Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/federated-learning-training-models).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[How to Implement a Federated Learning Project with Healthcare Data](https://www.kdnuggets.com/2023/02/implement-federated-learning-project-healthcare-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Open Assistant: Explore the Possibilities of Open and Collaborative…](https://www.kdnuggets.com/2023/04/open-assistant-explore-possibilities-open-collaborative-chatbot-development.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Beginner-Friendly Projects to Get You Started with ChatGPT](https://www.kdnuggets.com/2023/08/7-beginnerfriendly-projects-get-started-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Free Must-Take Data Science Courses to Get Started](https://www.kdnuggets.com/10-free-must-take-data-science-courses-to-get-started)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Upskilling in Data Vis Matters (& How to Get Started)](https://www.kdnuggets.com/2022/07/sphere-upskilling-data-vis-matters.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
