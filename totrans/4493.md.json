["```py\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('data/train.csv', nrows=10000)\nX = data.drop(['ID_code', 'target'], axis=1)\ny = data['target']\n(X_train, X_valid, \ny_train, y_valid )= train_test_split(X, y, test_size=0.2, random_state=1234)\n\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n\nparams = {'objective': 'binary',\n          'metric': 'auc',\n          'learning_rate': 0.4,\n          'max_depth': 15,\n          'num_leaves': 20,\n          'feature_fraction': 0.8,\n          'subsample': 0.2}\n\nmodel = lgb.train(params, train_data,\n                  num_boost_round=300,\n                  early_stopping_rounds=30,\n                  valid_sets=[valid_data],\n                  valid_names=['valid'])\n\nscore = model.best_score['valid']['auc']\nprint('validation AUC:', score)\n\n```", "```py\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nSEARCH_PARAMS = {'learning_rate': 0.4,\n                 'max_depth': 15,\n                 'num_leaves': 20,\n                 'feature_fraction': 0.8,\n                 'subsample': 0.2}\n\ndata = pd.read_csv('../data/train.csv', nrows=10000)\nX = data.drop(['ID_code', 'target'], axis=1)\ny = data['target']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1234)\n\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n\nparams = {'objective': 'binary',\n          'metric': 'auc',\n          **SEARCH_PARAMS}\n\nmodel = lgb.train(params, train_data,\n                  num_boost_round=300,\n                  early_stopping_rounds=30,\n                  valid_sets=[valid_data],\n                  valid_names=['valid'])\n\nscore = model.best_score['valid']['auc']\nprint('validation AUC:', score) \n\n```", "```py\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nSEARCH_PARAMS = {'learning_rate': 0.4,\n                 'max_depth': 15,\n                 'num_leaves': 20,\n                 'feature_fraction': 0.8,\n                 'subsample': 0.2}\n\ndef train_evaluate(search_params):\n    data = pd.read_csv('../data/train.csv', nrows=10000)\n    X = data.drop(['ID_code', 'target'], axis=1)\n    y = data['target']\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1234)\n\n    train_data = lgb.Dataset(X_train, label=y_train)\n    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n\n    params = {'objective': 'binary',\n              'metric': 'auc',\n              **search_params}\n\n    model = lgb.train(params, train_data,\n                      num_boost_round=300,\n                      early_stopping_rounds=30,\n                      valid_sets=[valid_data],\n                      valid_names=['valid'])\n\n    score = model.best_score['valid']['auc']\n    return score\n\nif __name__ == '__main__':\n    score = train_evaluate(SEARCH_PARAMS)\n    print('validation AUC:', score)\n\n```", "```py\nimport skopt\n\nfrom script_step2 import train_evaluate\n\nSPACE = [\n    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\n    skopt.space.Integer(1, 30, name='max_depth'),\n    skopt.space.Integer(2, 100, name='num_leaves'),\n    skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),\n    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')]\n\n@skopt.utils.use_named_args(SPACE)\ndef objective(**params):\n    return -1.0 * train_evaluate(params)\n\nresults = skopt.forest_minimize(objective, SPACE, n_calls=30, n_random_starts=10)\nbest_auc = -1.0 * results.fun\nbest_params = results.x\n\nprint('best result: ', best_auc)\nprint('best parameters: ', best_params)\n\n```", "```py\nimport neptune\nimport neptunecontrib.monitoring.skopt as sk_utils\nimport skopt\n\nfrom script_step2 import train_evaluate\n\nneptune.init('jakub-czakon/blog-hpo')\nneptune.create_experiment('hpo-on-any-script', upload_source_files=['*.py'])\n\nSPACE = [\n    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\n    skopt.space.Integer(1, 30, name='max_depth'),\n    skopt.space.Integer(2, 100, name='num_leaves'),\n    skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),\n    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')]\n\n@skopt.utils.use_named_args(SPACE)\ndef objective(**params):\n    return -1.0 * train_evaluate(params)\n\nmonitor = sk_utils.NeptuneMonitor()\nresults = skopt.forest_minimize(objective, SPACE, n_calls=100, n_random_starts=10, callback=[monitor])\nsk_utils.log_results(results)\n\nneptune.stop()\n\n```"]