- en: How (dis)similar are my train and test data?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的训练数据和测试数据有多么（不）相似？
- en: 原文：[https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html](https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html](https://www.kdnuggets.com/2018/06/how-dissimilar-train-test-data.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Shikhar Gupta](https://twitter.com/shik1470)**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Shikhar Gupta](https://twitter.com/shik1470) 撰写**。'
- en: They always say that don’t compare apples to oranges. But how about if we’re
    comparing one mix of apples and oranges with another mix of apples and oranges,
    but the distribution is different. Can you still compare ? And how will you go
    about it ?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人们总是说不要拿苹果和橙子做比较。但是如果我们比较一种苹果和橙子的混合与另一种苹果和橙子的混合，但分布不同，情况会如何？你还能比较吗？你会怎么做？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加入网络安全职业的快车道'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In most of the cases in the real world, you’ll come across the latter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，大多数情况下你会遇到后者。
- en: '![](../Images/7fd101b721fb668c1c84bbdb733785ce.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7fd101b721fb668c1c84bbdb733785ce.png)'
- en: This happens quite often in data science. While developing a machine learning
    model we come across a situation where our model performs well on our training
    data but it fails to match up to the same performance for the test data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这在数据科学中非常常见。在开发机器学习模型时，我们会遇到一种情况，即我们的模型在训练数据上表现良好，但在测试数据上的表现却无法达到相同的水平。
- en: I’m not referring to overfitting here. Even if I’ve picked my best model based
    on cross-validation and it still performs poorly on test data, there is some inherent
    patterns in test data that we are not capturing.< Imagine a situation where I’m
    trying to model the shopping behaviour of customers. Now if my train and test
    data looks like below then you can clearly see the issue here. ![](../Images/43e718e8ed8f3f92c83ced1e95a27790.png)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我这里不是在讨论过拟合。即使我基于交叉验证挑选了最佳模型，但它在测试数据上的表现仍然很差，这表明测试数据中存在一些我们未能捕捉到的固有模式。< 想象一下我在尝试建模客户的购物行为。如果我的训练数据和测试数据如下所示，那么你可以清楚地看到这里的问题。
    ![](../Images/43e718e8ed8f3f92c83ced1e95a27790.png)
- en: The model will be trained on customers with lower average age compared to test.
    This model would have never seen age patterns like the ones in test data. If age
    is an important feature in your model, then it’ll not perform well on the test.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该模型将基于年龄较低的客户进行训练，而测试数据中的客户年龄模式则从未见过。如果年龄是你模型中的一个重要特征，那么它在测试数据上的表现可能会不好。
- en: In this post, I’ll talk about how to identify this issue and some raw ideas
    on how we can fix it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将讨论如何识别这个问题以及一些解决办法的初步想法。
- en: Covariate Shift
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 协变量偏移
- en: We can define this situation more formally. **Covariate** refers to the predictor
    variables in our model. **Covariate shift** refers to a situation where predictor
    variables have different **characteristics (distribution)** in train and test
    data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以更正式地定义这种情况。**协变量**指的是我们模型中的预测变量。**协变量偏移**指的是预测变量在训练数据和测试数据中具有不同的**特征（分布）**的情况。
- en: In real world problems with many variables, covariate shift is hard to spot.
    In this post I have tried to discuss a method to identify this and also how to
    account for such shift between train and test.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及许多变量的实际问题中，协变量偏移很难被发现。在这篇文章中，我尝试讨论一种识别此问题的方法以及如何解决训练数据和测试数据之间的这种偏移。
- en: Basic Idea
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本概念
- en: If there exist a covariate shift, then upon mixing train and test we’ll still
    be able to classify the origin of each data point (whether it is from test or
    train) with good accuracy.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果存在协变量偏移，那么在混合训练和测试数据时，我们仍然能够以较高的准确率分类每个数据点的来源（是来自测试数据还是训练数据）。
- en: '![](../Images/5fffdd4138a36a820dde11d61ba677df.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fffdd4138a36a820dde11d61ba677df.png)'
- en: Let’s understand why. Consider the above example where age was the drifting
    feature between test and train. If we take a classifier like Random Forest and
    try to classify rows into test and train, age will be come out be very important
    feature in splitting the data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解一下原因。考虑上面的例子，其中年龄是测试和训练之间的滚动特征。如果我们使用像随机森林这样的分类器来将行分类为测试和训练，年龄将成为数据分割中非常重要的特征。
- en: '![](../Images/b84dfc6b3d7271b626a6a088a6d0dbfd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b84dfc6b3d7271b626a6a088a6d0dbfd.png)'
- en: Implementation
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现
- en: 'Now let’s try to apply this idea on a real dataset. I’m using dataset from
    this kaggle competition: [https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试将这个想法应用到实际数据集上。我使用来自这个 Kaggle 竞赛的数据集：[https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data)
- en: '*Step1: Data pre-processing*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 1：数据预处理*'
- en: We have to first clean our data, impute all missing values and do label encoding
    for all the categorical variables. For this dataset, this step was not required
    so I have skipped this step.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要清理数据，填补所有缺失值，并对所有分类变量进行标签编码。对于这个数据集，这一步骤并不需要，因此我跳过了这一步。
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Step2:*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 2：*'
- en: We have to add a feature **‘is_train’**in both train and test data. Value for
    this feature will be **0 for test and 1 for train**.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在训练和测试数据中添加一个特征**‘is_train’**。这个特征的值将是**测试为 0，训练为 1**。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Combining train and test*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*合并训练集和测试集*'
- en: Then we have to combine both the datasets. **Also since train data has the original
    ‘target’ variable which is not present in test, we have to drop that variable
    too.**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要合并两个数据集。**此外，由于训练数据中包含原始的“目标”变量，而测试数据中不存在，因此我们也需要删除该变量。**
- en: '**Note:** For your problem, ‘target’ will be replaced by the name of the dependent
    variable for your original problem.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 对于你的问题，“目标”将被替换为你原始问题中因变量的名称。'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Step4: Building and testing a classifier*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 4：构建和测试分类器*'
- en: For classification purposes I’m using **Random Forest Classifier** to predict
    the labels for each row in the combined dataset. You can use any other classifier
    also.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类目的，我使用**随机森林分类器**来预测合并数据集中每一行的标签。你也可以使用其他分类器。
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We are using stratified 4 fold to ensure that percentage for each class is preserved
    and we cover the whole data once. For each row the classifier will calculate the
    probability of it belonging to train.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用分层 4 折来确保每个类别的比例得以保留，并且我们覆盖了整个数据集。对于每一行，分类器将计算它属于训练集的概率。
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Step5: Interpreting the results*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 5：解释结果*'
- en: We’ll output the ROC-AUC metric for our classifier as an estimate how much covariate
    shift this data has.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将输出分类器的 ROC-AUC 指标，以估计数据中存在多少协变量偏移。
- en: If the classifier is able to classify the rows into train and test with good
    accuracy, our AUC score should be on the higher side (greater than 0.8). This
    implies strong covariate shift between train and test.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果分类器能够以良好的准确性将行分类为训练集和测试集，那么我们的 AUC 分数应在较高的一侧（大于 0.8）。这意味着训练集和测试集之间存在强协变量偏移。
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: AUC value of 0.49 implies that there is no evidence of strong covariate shift.
    This means that majority of the observations comes from a feature space which
    is not specific to test or train.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AUC 值为 0.49 表明没有强协变量偏移的证据。这意味着大多数观察值来自一个对测试或训练数据都不特定的特征空间。
- en: As this dataset is taken from Kaggle, this result is quite expected. As in such
    kind of competition dataset is carefully curated to ensure such shifts are not
    there.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个数据集来自 Kaggle，这个结果是相当预期的。在这种竞赛数据集中，数据经过精心策划以确保不存在这种偏移。
- en: This process can be replicated for any data science problem to check for covariate
    shift before we start modeling.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以复制到任何数据科学问题中，以在开始建模之前检查协变量偏移。
- en: Going beyond
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步探索
- en: At this point we either observe covariate shift or not. So what can we possibly
    do to improve our performance on the test data ??
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此时我们可以观察到协变量偏移，也可能没有。那么我们可以做些什么来提高测试数据上的表现呢？
- en: Dropping of drifting features
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动特征的删除
- en: Importance weight using Density Ratio Estimation
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用密度比估计的权重重要性
- en: '**Dropping of drifting features:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**滚动特征的删除：**'
- en: '**Note:** This method is applicable to the situation where you witness covariate
    shift.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 该方法适用于观察到协变量偏移的情况。'
- en: Extract feature importance from the random forest classifier object that we
    have built in the previous section
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从我们在上一节构建的随机森林分类器对象中提取特征重要性
- en: The top features are the ones which are drifting and causing the shift
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶级特征是那些漂移并导致变化的特征
- en: From the top features drop one variable at a time and build your model and check
    its performance. Collect all the features for which performance is not degrading
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从顶部特征中一次删除一个变量，构建你的模型并检查其性能。收集所有性能没有下降的特征
- en: Now drop all those features while building the final model
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在在构建最终模型时删除所有这些特征
- en: '![](../Images/4f8f24d188f813f569030fe34a3240aa.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f8f24d188f813f569030fe34a3240aa.png)'
- en: The idea is to remove the features that fall in the red bucket
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个想法是去除那些落入红色桶中的特征
- en: '**Importance weight using Density Ratio Estimation**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用密度比估计的权重**'
- en: '**Note:** This method is applicable irrespective of whether there exist a covariate
    shift or not.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 无论是否存在协变量转移，此方法均适用。'
- en: Let’s look at the predictions that we have calculated in the previous section.
    For each observation, this prediction tells us the probability that it belongs
    to the training data according to our classifier.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在上一节计算的预测。对于每个观察值，这个预测告诉我们根据我们的分类器，它属于训练数据的概率。
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So for the first row our classifier thinks that it belongs to training data
    with .34 probability. Let’s call this P(train). Or we can also say that it has
    .66 probability of being from the test data. Let’s call this as P(test). Now here
    is the magic trick:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一行，我们的分类器认为它属于训练数据的概率是.34。我们称之为P(train)。或者我们也可以说它有.66的概率来自测试数据。我们称之为P(test)。现在这是魔法的妙处：
- en: For each row of training data we calculate a coefficient **w = P(test)/P(train)**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一行训练数据，我们计算一个系数 **w = P(test)/P(train)**。
- en: 'This w tells us how close is the observation from the training data to our
    test data. Here is the punchline:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个w告诉我们观察值与训练数据的接近程度。这里是重点：
- en: We can use this w as sample weights in any of our classifier to increase the
    weight of these observation which seems similar to our test data. Intuitively
    this makes sense as our model will focus more on capturing patterns from the observations
    which seems similar to our test.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以将这个w作为任何分类器中的样本权重，以增加这些看似与我们的测试数据相似的观察值的权重。从直观上看，这很有意义，因为我们的模型将更多地关注捕捉那些与测试数据相似的观察模式。
- en: These weights can be calculated using the below code.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权重可以使用以下代码计算。
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '< You can pass the weights calculated in the model fit method like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: < 你可以像这样传递在模型拟合方法中计算的权重：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/4781dc6afd070dbf42e7978dbc01e0f6.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4781dc6afd070dbf42e7978dbc01e0f6.png)'
- en: 'Some things to notice in the above plot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图中需要注意的一些事项：
- en: Higher the weight for the observation, more is it similar to the test data
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察值的权重越高，它与测试数据的相似度就越大
- en: Almost 70% of training samples have sample weight of close to 1 and hence comes
    from a feature space which is not very specific to train or test high density
    region. This is in line with the AUC value that we have calculated
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近70%的训练样本的样本权重接近1，因此来自一个不特别针对训练或测试高密度区域的特征空间。这与我们计算的AUC值一致
- en: End Notes
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: I hope that now you have a better understanding about covariate shift, how you
    can identify it and treat it effectively.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你现在对协变量转移有了更好的理解，了解如何有效地识别和处理它。
- en: '**Bio: [Shikhar Gupta](https://twitter.com/shik1470)** is pursuing masters
    in data science at U. of San Francisco, Intern @IsaziConsulting, alumni @iitroorkee
    .'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Shikhar Gupta](https://twitter.com/shik1470)** 正在旧金山大学攻读数据科学硕士，实习生 @IsaziConsulting，校友
    @iitroorkee。'
- en: '[Original](https://towardsdatascience.com/how-dis-similar-are-my-train-and-test-data-56af3923de9b).
    Reposted with permission.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/how-dis-similar-are-my-train-and-test-data-56af3923de9b)。已获许可转载。'
- en: '**Related:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Training Sets, Test Sets, and 10-fold Cross-validation](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[训练集、测试集和10折交叉验证](https://www.kdnuggets.com/2018/01/training-test-sets-cross-validation.html)'
- en: '[The 6 components of Open-Source Data Science/ Machine Learning Ecosystem;
    Did Python declare victory over R?](https://www.kdnuggets.com/2018/06/ecosystem-data-science-python-victory.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开源数据科学/机器学习生态系统的6个组成部分；Python是否战胜了R？](https://www.kdnuggets.com/2018/06/ecosystem-data-science-python-victory.html)'
- en: '[The Statistics of Gang Violence](https://www.kdnuggets.com/2018/06/statistics-gang-violence.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[帮派暴力的统计数据](https://www.kdnuggets.com/2018/06/statistics-gang-violence.html)'
- en: More On This Topic
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何通过使用自动 EDA 工具来通过数据科学评估测试](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
- en: '[Performing a T-Test in Python](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 中执行 T 检验](https://www.kdnuggets.com/2023/01/performing-ttest-python.html)'
- en: '[Beyond Accuracy: Evaluating & Improving a Model with the NLP Test Library](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越准确性：使用 NLP 测试库评估和改进模型](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)'
- en: '[How to Build and Train a Transformer Model from Scratch with…](https://www.kdnuggets.com/how-to-build-and-train-a-transformer-model-from-scratch-with-hugging-face-transformers)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何从头开始构建和训练一个 Transformer 模型…](https://www.kdnuggets.com/how-to-build-and-train-a-transformer-model-from-scratch-with-hugging-face-transformers)'
- en: '[Why we will always need humans to train AI — sometimes in real-time](https://www.kdnuggets.com/2021/12/why-we-need-humans-training-ai.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为什么我们总是需要人类来训练 AI——有时甚至是实时的](https://www.kdnuggets.com/2021/12/why-we-need-humans-training-ai.html)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
