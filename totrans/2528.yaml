- en: How Machine Learning Leverages Linear Algebra to Solve Data Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html](https://www.kdnuggets.com/2021/09/machine-learning-leverages-linear-algebra-solve-data-problems.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bfd423cfaf9f4d27734f99ac1249cbe6.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  prefs: []
  type: TYPE_NORMAL
- en: Machines or your computers only understand numbers and these numbers need to
    be represented and processed in a way that enables these machines to solve problems
    by learning from data instead of predefined instruction as in the case of programming.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: All types of programming use mathematics at some level and machine learning
    is programming data to learn the function that best describes the data.
  prefs: []
  type: TYPE_NORMAL
- en: The problem(or process) of finding the best parameters of a function using data
    is called **model training **in ML.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in a nutshell, machine learning is programming to optimize for the
    best possible solution and we need math to understand how that problem is solved.
  prefs: []
  type: TYPE_NORMAL
- en: The first step towards learning Math for ML is Linear algebra.
  prefs: []
  type: TYPE_NORMAL
- en: '**Linear Algebra is that mathematical foundation that solves the problem of
    representing data as well as computations in machine learning models.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**It is the math of arrays** — technically referred to as vectors, matrices,
    and tensors.'
  prefs: []
  type: TYPE_NORMAL
- en: Common Areas of Application — Linear Algebra in Action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/2cc6846103ced3c7a63de659bf1bb505.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  prefs: []
  type: TYPE_NORMAL
- en: In the ML context, all major phases of developing a model have linear algebra
    running behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Important areas of application that are enabled by linear algebra are:'
  prefs: []
  type: TYPE_NORMAL
- en: data & learned model representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: word embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Representation — **The fuel of ML models, a.k.a. **data**, needs to
    be converted into arrays before feeding into your models, the computations performed
    on these arrays include operations like matrix multiplication(dot product) which
    further returns the output that is also represented as a transformed matrix/tensor
    of numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6980b736abcfe8843b2ea518afd11ac8.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Word embeddings — **don’t worry about the terminology here, it is just about
    representing large-dimensional data(think of a huge number of variables in your
    data) with a smaller dimensional vector.'
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing(NLP) deals with textual data. Dealing with text
    means comprehending the meaning of a large corpus of words and each word represents
    a different meaning which might be similar to another word, vector embeddings
    in linear algebra allow us to represent these words more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '**Eigenvectors(SVD)** — Finally, concepts like eigenvectors allow us to reduce
    the number of features or dimensions of the data while keeping the essence of
    all of them using something called **principal component analysis.**'
  prefs: []
  type: TYPE_NORMAL
- en: From data to Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/f1802792a52cf9c312866fe9bf7e62fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  prefs: []
  type: TYPE_NORMAL
- en: Linear algebra basically deals with vectors & matrices(different shapes of arrays)
    and operations on these arrays. In NumPy, vectors are basically a 1-Dimensional
    array of numbers but geometrically, this has both magnitude and direction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c55f7691097e60acd80378bf65d936e4.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  prefs: []
  type: TYPE_NORMAL
- en: Our data can be represented using a vector. In the figure above, one row in
    this data is represented by a feature vector that has 3 elements or components
    representing 3 different dimensions. N-entries in a vector make it n-dimensional
    vector space and in this case, we can see 3-dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning — Tensors flowing through a neural network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Linear algebra can be seen in action across all the major applications today,
    be it sentiment analysis on a LinkedIn or a Twitter post(embeddings), be it detecting
    a type of lung infection from X-ray images(computer vision), or any speech to
    text bot(NLP).
  prefs: []
  type: TYPE_NORMAL
- en: All of these data types are represented by numbers in tensors and we run vectorized
    operations to learn patterns from them using a neural network which then outputs
    processed tensor which in turn is decoded to produce the final inference of the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality Reduction — Vector space transformation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/dff6198b90f92fb1cc8be1a17893ad21.png)'
  prefs: []
  type: TYPE_IMG
- en: Source: [https://www.wiplane.com/p/foundations-for-data-science-ml](https://www.wiplane.com/p/foundations-for-data-science-ml)
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to embeddings, you can basically think of an n-dimensional vector
    being replaced with another vector that belongs to a lower-dimensional space which
    is more meaningful and the one that overcomes computational complexities.
  prefs: []
  type: TYPE_NORMAL
- en: For example, here is a 3-dimensional vector that is replaced by a 2-dimensional
    space but you can extrapolate it to a real-world scenario where you have a very
    large number of dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing dimensions doesn’t mean dropping features from the data but finding
    new features that are linear functions of the original features and preserves
    the variance of the original features.
  prefs: []
  type: TYPE_NORMAL
- en: Finding these new variables(features) translates to finding the principal components(PCs)
    which converge to solving eigenvectors and eigenvalues problems.
  prefs: []
  type: TYPE_NORMAL
- en: Recommendation Engines — Making use of embeddings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can think of Embedding as a 2D plane being embedded in a 3D space and that’s
    where this term comes from. You can think of the ground you are standing on as
    a 2D plane that is embedded into this space in which we live.
  prefs: []
  type: TYPE_NORMAL
- en: Just to give you a real-world use case to relate to all of this discussion on
    vector embeddings, all applications that are giving you personalized recommendations
    are using vector embedding in some form.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/62fa0dcf8d7b91e435b1e2f2fcef1a39.png)'
  prefs: []
  type: TYPE_IMG
- en: For example, here is a graphic from Google’s course on recommendation systems
    where we are given this data on different users and their preferred movies. Some
    users are kids and others are adults, some movies were are all-time classics while
    others are more artistic. Some movies are targeted towards a younger audience
    while movies like memento are preferred by adults.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we not only need to represent this information in numbers but also need
    to find new smaller dimensional vector representations that capture all these
    features well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28af5bb2a270796195f820a72973e946.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: Google’s Machine Learning Course on recommendation systems'
  prefs: []
  type: TYPE_NORMAL
- en: A very quick way to understand how we can pull this task is by understanding
    something called Matrix Factorization which allows us to break a large matrix
    down into smaller matrices.
  prefs: []
  type: TYPE_NORMAL
- en: Ignore the numbers and colors for now and just try to understand how we have
    broken down one big matrix into two smaller ones.
  prefs: []
  type: TYPE_NORMAL
- en: For example, here this matrix of 4X5, 4 rows, and 5 features were broken down
    into two matrices, one of the shape 4X2 and the other of shape 2X5\. We basically
    have new smaller dimensional vectors for users and movies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/93d13f18bbdb51854a94c4f4aee7cdee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And this allows us to plot this on a 2D vector space, and here you’ll see that
    user #1 and the movie Harry Potter are closer and user #3 and the movie Shrek
    are closer.'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of **dot product(matrix multiplication)** of vectors tells us more
    about the similarity of two vectors. And it has applications in correlation/covariance
    calculation, linear regression, logistic regression, PCA, convolutions, PageRank,
    and numerous other algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Industries where you see LA being used heavily
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By now, I hope you are convinced that Linear algebra is driving the ML initiatives
    in a host of areas today. If not, here is a list to name a few:'
  prefs: []
  type: TYPE_NORMAL
- en: Statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chemical Physics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Genomics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Word Embeddings — neural networks/deep learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robotics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image Processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantum Physics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much should you know to get started with ML / DL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, the important question is how can you learn to program these concepts of
    linear algebra. So, the answer is you don’t have to reinvent the wheel, you just
    need to understand the basics of vector algebra computationally and you then learn
    to program those concepts using NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy is a scientific computation package that gives us access to all the underlying
    concepts of linear algebra. It is fast as it runs compiled C code and it has a
    large number of mathematical and scientific functions that we can use.
  prefs: []
  type: TYPE_NORMAL
- en: Recommended resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[**Playlist on Linear Algebra by 3Blue1Brown**](https://www.youtube.com/watch?v=kjBOesZCoqc&list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B)—
    very engaging visualizations that explain the essence of linear algebra and its
    applications. Might be a little too hard for beginners.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Book on Deep Learning by Ian Goodfellow & Yoshua Bengio**](https://www.deeplearningbook.org/)** —** a
    fantastic resource for learning ML and applied math. Give it a read, few folks
    may find it too technical and notation-heavy, to begin with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Foundations of Data Science & ML —**](https://www.wiplane.com/p/foundations-for-data-science-ml) I
    have created a course that gives you enough understanding of Programming, Math(Basic
    Algebra, Linear Algebra & Calculus), and Statistics. A complete package for the
    first steps to learning DS/ML. Learn more [**here**](https://www.wiplane.com/p/foundations-for-data-science-ml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ???? You can use the code `TDS10` to get 10% off.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the course outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Harshit Tyagi](https://www.linkedin.com/in/tyagiharshit/)** is an engineer
    with amalgamated experience in web technologies and data science(aka full-stack
    data science). He has mentored over 1000 AI/Web/Data Science aspirants, and is
    designing data science and ML engineering learning tracks. Previously, Harshit
    developed data processing algorithms with research scientists at Yale, MIT, and
    UCLA.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://dswharshit.medium.com/how-machine-learning-leverages-linear-algebra-to-solve-data-problems-4e210a644508).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Science Learning Roadmap for 2021](/2021/02/data-science-learning-roadmap-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear Algebra for Natural Language Processing](/2021/08/linear-algebra-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Antifragility and Machine Learning](/2021/09/antifragility-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Projects That Can Help You Solve Real World Problems](https://www.kdnuggets.com/2022/11/data-science-projects-help-solve-real-world-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 3 Free Resources to Learn Linear Algebra for Machine Learning](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 13: Linear Algebra for Data Science; 10 Modern…](https://www.kdnuggets.com/2022/n28.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Linear Algebra for Data Science](https://www.kdnuggets.com/2022/07/linear-algebra-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Free Courses to Master Linear Algebra](https://www.kdnuggets.com/2022/10/5-free-courses-master-linear-algebra.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
