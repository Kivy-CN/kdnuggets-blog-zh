- en: Data Catalogs Are Dead; Long Live Data Discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/12/data-catalogs-dead-long-live-data-discovery.html](https://www.kdnuggets.com/2020/12/data-catalogs-dead-long-live-data-discovery.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By Debashis Saha & Barr Moses**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f00b83f39667b7cb334ee9d770bef0b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Image courtesy of [Andrey_Kuzmin](https://www.shutterstock.com/g/akz) on [Shutterstock](http://www.shutterstock.com/)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '*As companies increasingly leverage data to power digital products, drive decision
    making, and fuel innovation, understanding the health and reliability of these
    most critical assets is fundamental. For decades, organizations have relied on
    data catalogs to power data governance. But is that enough?*'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Debashis Saha*](https://www.linkedin.com/in/debashis1saha)*, VP of Engineering
    at AppZen, formerly at eBay and Intuit, and *[*Barr Moses*](https://www.linkedin.com/in/barrmoses)*,
    CEO and Co-founder of Monte Carlo, discuss why data catalogs aren’t meeting the
    needs of the modern data stack, and how a new approach — data discovery — is needed
    to better facilitate metadata management and data reliability.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s no secret: knowing where your data lives and who has access to it is fundamental
    to understanding its impact on your business. In fact, when it comes to building [**a
    successful data platform**](https://www.montecarlodata.com/how-to-build-your-data-platform-like-a-product/),
    it’s critical that your data is both organized and centralized, while also easily
    discoverable.'
  prefs: []
  type: TYPE_NORMAL
- en: Analogous to a physical library catalog, [data catalogs](https://cloud.google.com/data-catalog) serve
    as an inventory of metadata and give users the information necessary to evaluate
    data accessibility, health, and location. In our age of [self-service business
    intelligence](https://searchbusinessanalytics.techtarget.com/definition/self-service-business-intelligence-BI),
    data catalogs have also emerged as a powerful tool for data management and data
    governance.
  prefs: []
  type: TYPE_NORMAL
- en: Not surprisingly, for most data leaders, one of their first imperatives is to
    build a data catalog.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the bare minimum, a data catalog should answer:'
  prefs: []
  type: TYPE_NORMAL
- en: Where should I look for my data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this data matter?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What does this data represent?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is this data relevant and important?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I use this data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Still, as data operations mature and data pipelines become increasingly complex,
    traditional data catalogs often fall short of meeting these requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**Here’s why some of the best data engineering teams are innovating their approach
    to metadata management — and what they’re doing instead:**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Where data catalogs fall short
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While data catalogs have the ability to document data, the fundamental challenge
    of allowing users to “discover” and glean meaningful, real-time insights about
    the health of your data has largely remained unsolved.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data catalogs as we know them are unable to keep pace with this new reality
    for three primary reasons: (1) lack of automation, (2) inability to scale with
    the growth and diversity of your data stack, and (3) their undistributed format.'
  prefs: []
  type: TYPE_NORMAL
- en: Increased need for automation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Traditional data catalogs and governance methodologies typically rely on data
    teams to do the heavy lifting of manual data entry, holding them responsible for
    updating the catalog as data assets evolve. This approach is not only time-intensive,
    but requires significant manual toil that could otherwise be automated, freeing
    time up for data engineers and analysts to focus on projects that actually move
    the needle.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a data professional, understanding the state of your data is a constant
    battle and speaks to the need for greater, more customized automation. Perhaps
    this scenario rings a bell:'
  prefs: []
  type: TYPE_NORMAL
- en: Before stakeholder meetings, do you often find yourself frantically pinging
    Slack channels to figure out what data sets feed a specific report or model you
    are using — and why on earth the data stopped arriving last week? To cope with
    this, do you and your team huddle together in a room and start whiteboarding all
    of the various connections upstream and downstream for a specific key report?
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll spare you the gory details, but it probably looked something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/f4ad709b9580d751ac55b76f7928ba87.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Does your data lineage look like a storm of lines and arrows? That makes two
    (hundred) of us. Image courtesy of *[EgudinKa](https://www.shutterstock.com/g/EgudinKa) on [*Shutterstock*](http://www.shutterstock.com/)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: If this hits home, you’re not alone. Many companies that need to solve this
    dependency jigsaw puzzle embark on a multi-year process to manually map out all
    their data assets. Some are able to dedicate resources to build short-term hacks
    or even in-house tools that allow them to search and explore their data. Even
    if it gets you to the end goal, this poses a heavy burden on the data organization,
    costing your data engineering team time and money that could have been spent on
    other things, like product development or actually using the data.
  prefs: []
  type: TYPE_NORMAL
- en: Ability to scale as data changes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data catalogs work well when data is structured, but in 2020, that’s not always
    the case. As machine-generated data increases and companies invest in ML initiatives,
    unstructured data is becoming more and more common, accounting for [over 90 percent
    of all new data produced](https://www.cio.com/article/3406806/ai-unleashes-the-power-of-unstructured-data.html).
  prefs: []
  type: TYPE_NORMAL
- en: '[Typically stored in data lakes](https://towardsdatascience.com/how-to-build-your-data-platform-choosing-a-cloud-data-warehouse-3de66862f41c),
    unstructured data does not have a predefined model and must go through multiple
    transformations to be usable and useful. Unstructured data is very dynamic, with
    its shape, source, and meaning changing all the time as it goes through various
    phases of processing, including transformation, modeling, and aggregation. What
    we do with this unstructured data (i.e., transform, model, aggregate, and visualize
    it), makes it much more difficult to catalog in its “desired state.”'
  prefs: []
  type: TYPE_NORMAL
- en: On top of this, rather than simply *describing* the data that consumers access
    and use, there’s a growing need to also *understand* the data based on its intention
    and purpose. How a producer of data might describe an asset would be very different
    from how a consumer of this data understands its function, and even between one
    consumer of data to another there might be a vast difference in terms of understanding
    the meaning ascribed to the data.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, a data set pulled from Salesforce has a completely different meaning
    to a data engineer than it would to someone on the sales team. While the engineer
    would understand what “DW_7_V3” means, the sales team would be scratching their
    heads, trying to determine if said data set correlated to their “Revenue Forecasts
    2021” dashboard in Salesforce. And the list goes on.
  prefs: []
  type: TYPE_NORMAL
- en: Static data descriptions are limited by nature. In 2021, we must accept and
    adapt to these new and evolving dynamics to truly understand the data.
  prefs: []
  type: TYPE_NORMAL
- en: Data is distributed; catalogs are not
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite the distribution of the modern data architecture (see: [the data mesh](https://towardsdatascience.com/what-is-a-data-mesh-and-how-not-to-mesh-it-up-210710bb41e0))
    and the move towards embracing semi-structured and unstructured data as the norm,
    most data catalogs still treat data like a one-dimensional entity. As data is
    aggregated and transformed, it flows through different elements of the data stack,
    making it nearly impossible to document.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/57690c59f9bd39ab68fff0deed226ee0.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Traditional data catalogs manage metadata (data about your data) at the ingest
    state, but data is constantly changing, making it hard to understand the health
    of your data as it evolves in the pipeline. Image courtesy of Barr Moses.*'
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, data tends to be [self-describing](https://www.gartner.com/en/information-technology/glossary/self-describing-messages#:~:text=A%20message%20that%20contains%20data,consists%20of%20tag%2Fvalue%20pairs.),
    containing both the data and the metadata that describes the format and meaning
    of that data in a single package.
  prefs: []
  type: TYPE_NORMAL
- en: Since traditional data catalogs are not distributed, it’s near to impossible
    to use as a central source of truth about your data. This problem will only grow
    as data becomes more accessible to a wider variety of users, from BI analysts
    to operations teams, and the pipelines powering ML, operations, and analytics
    become increasingly complex.
  prefs: []
  type: TYPE_NORMAL
- en: A modern data catalog needs to federate the meaning of data across these domains.
    Data teams need to be able to understand how these data domains relate to each
    other and what aspects of the aggregate view are important. They need a centralized
    way to answer these distributed questions as a whole — in other words, a distributed,
    federated data catalog.
  prefs: []
  type: TYPE_NORMAL
- en: Investing in the right approach to building a data catalog from the outset will
    allow you to build a better data platform that helps your team democratize and
    easily explore data, allowing you to keep tabs on important data assets and harness
    their full potential.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data Catalog 2.0 = Data Discovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data catalogs work well when you have rigid models, but as data pipelines grow
    increasingly complex and unstructured data becomes the golden standard, our understanding
    of this data (what it does, who uses it, how it’s used, etc.) does not reflect
    reality.
  prefs: []
  type: TYPE_NORMAL
- en: We believe that next generation catalogs will have the capabilities to learn,
    understand, and infer the data, enabling users to leverage its insights in a self-service
    manner. But how do we get there?
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/14319ae5849e5da6618a3bbd39f631c3.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Data discovery can replace the modern data catalog by providing distributed,
    real-time insights about data across different domains, all while abiding by a
    central set of governance standards. Image courtesy of Barr Moses.*'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to cataloging data, metadata and data management strategies must
    also incorporate data discovery, a new approach to understanding the health of
    your distributed data assets in real-time. Borrowing from the distributed domain-oriented
    architecture proposed by Zhamak Deghani and Thoughtworks’ [**data mesh model**](https://martinfowler.com/articles/data-monolith-to-mesh.html),
    data discovery posits that different data owners are held accountable for their
    data as products, as well as for facilitating communication between distributed
    data across different locations. Once data has been served to and transformed
    by a given domain, the domain data owners can leverage the data for their operational
    or analytic needs.
  prefs: []
  type: TYPE_NORMAL
- en: Data discovery replaces the need for a data catalog by providing a domain-specific,
    dynamic understanding of your data based on how it’s being ingested, stored, aggregated,
    and used by a set of specific consumers. As with a data catalog, governance standards
    and tooling are federated across these domains (allowing for greater accessibility
    and interoperability), but unlike a data catalog, data discovery surfaces a real-time
    understanding of the data’s current state as opposed to it’s ideal or “cataloged”
    state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data discovery can answer these questions not just for the data’s ideal state
    but for the current state of the data across each domain:'
  prefs: []
  type: TYPE_NORMAL
- en: What data set is most recent? Which data sets can be deprecated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When was the last time this table was updated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the meaning of a given field in my domain?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who has access to this data? When was the last time this data was used? By who?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the upstream and downstream dependencies of this data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is this production-quality data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data matters for my domain’s business requirements?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are my assumptions about this data, and are they being met?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We believe that the next generation data catalog, in other words, data discovery,
    will have the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Self-service discovery and automation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data teams should be able to easily leverage their data catalog without a dedicated
    support team. Self-service, automation, and workflow orchestration for your data
    tooling removes silos between stages of the data pipeline, and in the process,
    making it easier to understand and access data. Greater accessibility naturally
    leads to increased data adoption, reducing the load for your data engineering
    team.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability as data evolves
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As companies ingest more and more data and unstructured data becomes the norm,
    the ability to scale to meet these demands will be critical for the success of
    your data initiatives. Data discovery leverages machine learning to gain a bird’s
    eye view of your data assets as they scale, ensuring that your understanding adapts
    as your data evolves. This way, data consumers are set up to make more intelligent
    and informed decisions instead of relying on outdated documentation (aka data
    about data that becomes stale, how meta!) or worse — gut-based decision making.
  prefs: []
  type: TYPE_NORMAL
- en: '[Data lineage](https://en.wikipedia.org/wiki/Data_lineage) for distributed
    discovery'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data discovery relies heavily on automated table and field-level lineage to
    map upstream and downstream dependencies between data assets. Lineage helps surface
    the right information at the right time (a core functionality of data discovery)
    and draw connections between data assets so you can better troubleshoot when data
    pipelines do break, which is becoming an increasingly common problem as the [modern
    data stack evolves](https://www.montecarlodata.com/data-observability-how-to-prevent-your-data-pipelines-from-breaking/) to
    accommodate more complex use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Data reliability to ensure the gold standard of data — at all times
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The truth is — in one way or another — your team is probably already investing
    in data discovery. Whether it’s through manual work your team is doing to verify
    data, custom validation rules your engineers are writing, or simply the cost of
    decisions made based on broken data or silent errors that went unnoticed. Modern
    data teams have started leveraging automated approaches to ensuring highly trustworthy
    data at every stage of the pipeline, from data quality monitoring to more robust,
    end-to-end [data observability platforms](https://towardsdatascience.com/how-do-you-prevent-broken-data-pipelines-326f3c6d239e) that
    monitor and alert for issues in your data pipelines. Such solutions notify you
    when data breaks so you can identify the root cause quickly for fast resolution
    and [prevent future downtime](https://www.montecarlodata.com/the-rise-of-data-downtime/).
  prefs: []
  type: TYPE_NORMAL
- en: Data discovery empowers data teams to trust that their assumptions about data
    match reality, enabling dynamic discovery and a high degree of reliability across
    your data infrastructure, regardless of domain.
  prefs: []
  type: TYPE_NORMAL
- en: What’s next?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If bad data is worse than no data, a data catalog without data discovery is
    worse than not having a data catalog at all. To achieve truly discoverable data,
    it’s important that your data is not just “cataloged,” but also accurate, clean,
    and fully observable for ingestion to consumption — in other words: reliable.'
  prefs: []
  type: TYPE_NORMAL
- en: A strong approach to data discovery relies on automated and scalable data management,
    which works with the newly distributed nature of data systems. Therefore, to truly
    enable data discovery in an organization, we need to rethink how we are approaching
    the data catalog.
  prefs: []
  type: TYPE_NORMAL
- en: Only by understanding your data, the state of your data, and how it’s being
    used — at all stages of its lifecycle, across domains — can we even begin to trust
    it.
  prefs: []
  type: TYPE_NORMAL
- en: '***Want to learn more about ***[***building better data catalogs***](http://www.montecarlodata.com/)***?
    Reach out to ***[***Debashis Saha***](https://www.linkedin.com/in/debashis1saha)*** or ***[***Barr
    Moses***](https://www.linkedin.com/in/barrmoses)*** and the ***[***Monte Carlo
    team***](http://www.montecarlodata.com/)***.***'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Debashis Saha](https://www.linkedin.com/in/debashis1saha/)** is the VP of
    Engineering at AppZen. Prior, he served as VP of Data Platforms at Intuit and
    eBay.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Barr Moses](https://www.linkedin.com/in/barrmoses/)** is the CEO and Co-founder
    of Monte Carlo, a data observability company. Prior, she served as a VP of Operations
    at Gainsight.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/data-catalogs-are-dead-long-live-data-discovery-a0dc8d02bd34?source=friends_link&sk=3140d4e8c1e40c35ec7a29967f81a453).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Science and Machine Learning: The Free eBook](/2020/12/data-science-machine-learning-free-ebook.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8 Places for Data Professionals to Find Datasets](/2020/12/8-places-data-professionals-find-datasets.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Tour of End-to-End Machine Learning Platforms](/2020/07/tour-end-to-end-machine-learning-platforms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Is OLAP Dead?](https://www.kdnuggets.com/2022/10/olap-dead.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Long Does It Take to Learn Data Science Fundamentals?](https://www.kdnuggets.com/2022/03/long-take-learn-data-science-fundamentals.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Classifying Long Text Documents Using BERT](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Full End-to-End Deployment of a Machine Learning Algorithm into a…](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Last call: Stefan Krawcyzk’s ''Mastering MLOps'' Live Cohort](https://www.kdnuggets.com/2022/08/sphere-last-call-stefan-krawcyzk-mastering-mlops.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unlock DataOps Success with DataOps.live - Featured in Gartner…](https://www.kdnuggets.com/2023/07/dataopslive-unlock-dataops-success-featured-gartner-market-guide.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
