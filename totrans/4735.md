# 快速轻松解决任何图像分类问题

> 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)

### 6\. 示例

在这个示例中，我们将看到**如何将这些分类器中的每一个应用到图像分类的迁移学习解决方案中**。根据 Rawat 和 Wang (2017) 的说法，‘*在深度卷积神经网络基础上比较不同分类器的性能仍需进一步研究，因此这是一个有趣的研究方向*’。因此，观察每个分类器在标准图像分类问题中的表现将很有趣。

你可以在 [我的 GitHub 页面](https://github.com/pmarcelino/blog/blob/master/dogs_cats/dogs_cats.ipynb)上找到这个示例的完整代码。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

**6.1\. 准备数据**

在这个示例中，我们将使用原始数据集的较小版本。这将使我们能更快地运行模型，这对计算能力有限的人（像我）来说非常好。

为了构建数据集的较小版本，我们可以采用 Chollet (2017) 提供的代码，如代码 1 所示。

代码 1\. 为狗与猫创建一个较小的数据集。

**6.2\. 从卷积基础中提取特征**

卷积基础将用于提取特征。这些特征将输入到我们希望训练的分类器中，以便识别图像中是否有狗或猫。

再次修改了 Chollet (2017) 提供的代码。代码 2 展示了使用的代码。

代码 2\. 从卷积基础中提取特征。

**6.3\. 分类器**

**6.3.1\. 全连接层**

我们展示的第一个解决方案基于全连接层。这个分类器添加了一堆全连接层，这些层由从卷积基础中提取的特征提供输入。

为了保持简单（且快速），我们将使用 Chollet (2018) 提出的解决方案，并进行一些小的修改。特别是，我们将使用 Adam 优化器而不是 RMSProp，因为 [斯坦福说这样](http://cs231n.github.io/neural-networks-3/#adam) （多么美妙的*权威论证*）。

代码 3 展示了使用的代码，而图 5 和 6 展示了学习曲线。

代码 3\. 全连接层解决方案.![](../Images/37a3b1336eb12b75a2b53aea7edf9958.png)

图 5\. 全连接层解决方案的准确率.![](../Images/a624ba4e5278d22f95690936d9dab636.png)

图 6\. 全连接层解决方案的损失。

**结果的简要讨论：**

1.  验证准确率约为 0.85，考虑到数据集的大小，这是令人鼓舞的。

1.  模型严重过拟合。训练曲线和验证曲线之间存在很大差距。

1.  由于我们已经使用了 dropout，我们应该增加数据集的大小以改善结果。

**6.3.2\. 全局平均池化**

本案例与前一个案例的区别在于，我们没有添加一堆全连接层，而是添加了一个全局平均池化层，并将其输出送入一个 sigmoid 激活层。

请注意，我们使用的是 sigmoid 激活层，而不是 Lin 等人（2013）推荐的 softmax 激活层。我们更改为 sigmoid 激活是因为在 Keras 中，为了进行二分类，应该使用*sigmoid*激活和*binary_crossentropy*作为损失（Chollet 2017）。因此，需要对 Lin 等人（2013）的原始提案进行这个小修改。

代码 4 显示了构建分类器的代码。图 7 和图 8 显示了结果学习曲线。

代码 4\. 全局平均池化解决方案.![](../Images/10de3d9dcec03af404861a8879c0accb.png)

图 7\. 全局平均池化解决方案的准确率.![](../Images/a5d7d4e1dfd9f9804655064ae61f6cb7.png)

图 8\. 全局平均池化解决方案的损失。

**结果的简要讨论：**

1.  验证准确率与全连接层解决方案的结果相似。

1.  该模型没有像前一个案例那样过拟合。

1.  当模型停止训练时，损失函数仍在下降。可能通过增加训练周期数可以进一步改善模型。

**6.3.3 线性支持向量机**

在这个案例中，我们将在卷积基提取的特征上训练一个线性支持向量机（SVM）分类器。

要训练这个分类器，传统的机器学习方法更为合适。因此，我们将使用 k 折交叉验证来估计分类器的错误。由于将使用 k 折交叉验证，我们可以将训练集和验证集合并以扩大我们的训练数据（我们保持测试集不变，就像在之前的情况下）。代码 5 显示了数据是如何拼接的。

代码 5\. 数据拼接。

最后，我们必须注意到 SVM 分类器有一个超参数。这个超参数是误差项的惩罚参数 C。为了优化这个超参数的选择，我们将使用穷举网格搜索。代码 6 展示了构建这个分类器的代码，而图 9 则展示了学习曲线。

代码 6\. 线性支持向量机解决方案.![](../Images/1636b5411bb359e6864f8a0c3784e7b9.png)

图 9\. 线性支持向量机解决方案的准确率。

**结果简要讨论：**

1.  模型的准确率约为0.86，这与之前解决方案的准确率相似。

1.  过拟合就在眼前。此外，训练准确率总是1.0，这不寻常，可以被解读为过拟合的迹象。

1.  模型的准确率应随着训练样本的增加而提高。然而，这似乎没有发生。这可能是由于过拟合。看看数据集增加时模型的反应会很有趣。

### 7\. 总结

在本文中，我们：

+   介绍了迁移学习、卷积神经网络和预训练模型的概念。

+   定义了将预训练模型重新用于其他任务的基本微调策略。

+   描述了一种结构化的方法，以决定应使用哪种微调策略，基于数据集的大小和相似性。

+   介绍了三种可以在卷积基础上提取的特征上使用的不同分类器。

+   提供了这篇文章中介绍的每个分类器的端到端图像分类示例。

我希望你感到有动力开始在计算机视觉领域开发深度学习项目。这是一个伟大的研究领域，每天都有新的令人兴奋的发现。

我很乐意帮助你，所以如果你有任何问题或改进建议，请告诉我！

### 8\. 参考文献

1\. Bengio, Y., 2009\. 为人工智能学习深度架构。机器学习基础与趋势，2(1)，第1–127页。

2\. Canziani, A., Paszke, A. 和 Culurciello, E., 2016\. 深度神经网络模型在实际应用中的分析。arXiv 预印本 arXiv:1605.07678。

[3\. Chollet, F., 2015\. Keras.](https://keras.io/)

4\. [Chollet, F., 2017\. 用 Python 进行深度学习。Manning Publications Co..](https://amzn.to/2CeEySF)

5\. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K. 和 Fei-Fei, L., 2009年6月。Imagenet：大规模层次图像数据库。见计算机视觉与模式识别，2009年。CVPR 2009。IEEE会议（第248–255页）。Ieee。

6\. He, K., Zhang, X., Ren, S. 和 Sun, J., 2016\. 用于图像识别的深度残差学习。见 IEEE 计算机视觉与模式识别会议论文集（第770–778页）。

7\. Krizhevsky, A., Sutskever, I. 和 Hinton, G.E., 2012\. 用深度卷积神经网络进行Imagenet分类。见神经信息处理系统进展（第1097–1105页）。

8\. LeCun, Y., Bengio, Y. 和 Hinton, G., 2015\. 深度学习。自然，521(7553)，第436页。

9\. Lin, M., Chen, Q. 和 Yan, S., 2013\. 网络中的网络。arXiv 预印本 arXiv:1312.4400。

10\. Pan, S.J. 和 Yang, Q., 2010\. 关于迁移学习的调查。IEEE 知识与数据工程学报，22(10)，第1345–1359页。

11\. Rawat, W. 和 Wang, Z., 2017\. 用于图像分类的深度卷积神经网络：全面回顾。神经计算，29(9)，第2352–2449页。

12. Simonyan, K. 和 Zisserman, A., 2014年。用于大规模图像识别的非常深的卷积网络。arXiv预印本 arXiv:1409.1556。

13. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. 和 Wojna, Z., 2016年。重新思考计算机视觉的Inception架构。发表于《IEEE计算机视觉与模式识别会议论文集》（第2818–2826页）。

14. Tang, Y., 2013年。使用线性支持向量机的深度学习。arXiv预印本 arXiv:1306.0239。

15. Voulodimos, A., Doulamis, N., Doulamis, A. 和 Protopapadakis, E., 2018年。计算机视觉中的深度学习：简要综述。计算智能与神经科学，2018年。

16. Yosinski, J., Clune, J., Bengio, Y. 和 Lipson, H., 2014年。深度神经网络中的特征可转移性如何？发表于《神经信息处理系统进展》（第3320–3328页）。

17. Zeiler, M.D. 和 Fergus, R., 2014年9月。可视化和理解卷积网络。发表于《欧洲计算机视觉会议》（第818–833页）。Springer, Cham。

### 致谢

感谢 [João Coelho](https://www.linkedin.com/in/joaopcoelho/) 阅读草稿。

*你可以在* [*pmarcelino.com*](http://www.pmarcelino.com/) *找到更多关于我和我的项目的信息。此外，你还可以注册我的* [*新闻通讯*](http://pmarcelino.com/subscribe) *，以获取我在“人类、机器和科学”方面的最新更新。*

**个人简介： [Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)** 对机器学习和数据分析的各个方面感兴趣。他专注于数据挖掘与质量、探索性分析与可视化，以及预测性/处方性分析，同时也包括在实际问题中测试和评估不同的机器学习方法。

[原文](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)。经授权转载。

**相关内容：**

+   [计算机视觉技术与应用的最新趋势](/2018/11/trends-computer-vision-technology-applications.html)

+   [在Raspberry Pi上构建一个图像分类器](/2018/10/building-image-classifier-running-raspberry-pi.html)

+   [使用Tensorflow对象检测和OpenCV分析足球（足球）比赛](/2018/07/analyze-soccer-game-using-tensorflow-object-detection-opencv.html)

### 更多关于此主题的信息

+   [NExT-GPT简介：任意对任意的多模态大语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)

+   [机器学习不像你的大脑第6部分：...的意义](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)

+   [用无编码方式轻松抓取网站上的图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)

+   [通过openplayground轻松探索LLM](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)

+   [轻松将LLMs集成到您的Scikit-learn工作流程中，使用Scikit-LLM](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)

+   [使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
