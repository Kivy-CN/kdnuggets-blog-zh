["```py\npip install openai\n```", "```py\nimport os\n\nos.environ['OPENAI_API_KEY'] = 'YOUR API KEY'\n```", "```py\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Generate me 3 Jargons that I can use for my Social Media content as a Data Scientist content creator\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n```", "```py\ncompletion = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Generate me 3 jargons that I can use for my Social Media content as a Data Scientist content creator.\"},\n        {\"role\": \"assistant\", \"content\": \"Sure, here are three jargons: Data Wrangling is the key, Predictive Analytics is the future, and Feature Engineering help your model.\"},\n        {\"role\": \"user\", \"content\": \"Great, can you also provide me with 3 content ideas based on these jargons?\"}\n    ],\n    max_tokens=150,\n    temperature=0.7,\n    top_p=1,\n    frequency_penalty=0\n)\n\nprint(completion.choices[0].message.content)\n```", "```py\ncompletion = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  response_format={ \"type\": \"json_object\" },\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON..\"},\n    {\"role\": \"user\", \"content\": \"Generate me 3 Jargons that I can use for my Social Media content as a Data Scientist content creator\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n```", "```py\nfrom openai import OpenAI\nfrom IPython.display import Image\n\nclient = OpenAI()\n\nresponse = client.images.generate(\n  model=\"dall-e-3\",\n  prompt=\"White Piano on the Beach\",\n  size=\"1792x1024\",\n  quality=\"hd\",\n  n=1,\n)\n\nimage_url = response.data[0].url\nImage(url=image_url)\n```", "```py\nfrom openai import OpenAI\nfrom IPython.display import Image\n\nclient = OpenAI()\n\nresponse = client.images.create_variation(\n  image=open(\"white_piano_ori.png\", \"rb\"),\n  n=2,\n  size=\"1024x1024\"\n)\n\nimage_url = response.data[0].url\n\nImage(url=image_url)\n```", "```py\nfrom openai import OpenAI\nimport base64\nimport requests\ndef provide_image_description(img_path):\n\n    client = OpenAI()\n\n    api_key = 'YOUR-API-KEY'\n    # Function to encode the image\n    def encode_image(image_path):\n      with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\n    # Path to your image\n    image_path = img_path\n\n    # Getting the base64 string\n    base64_image = encode_image(image_path)\n\n    headers = {\n      \"Content-Type\": \"application/json\",\n      \"Authorization\": f\"Bearer {api_key}\"\n    }\n\n    payload = {\n      \"model\": \"gpt-4-vision-preview\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": [\n            {\n              \"type\": \"text\",\n              \"text\": \"\"\"Can you describe this image? \"\"\"\n            },\n            {\n              \"type\": \"image_url\",\n              \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n              }\n            }\n          ]\n        }\n      ],\n      \"max_tokens\": 300\n    }\n\n    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n\n    return response.json()['choices'][0]['message']['content']\n```", "```py\nfrom openai import OpenAI\nclient = OpenAI()\n\nspeech_file_path = \"speech.mp3\"\nresponse = client.audio.speech.create(\n  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"I love data science and machine learning\"\n)\n\nresponse.stream_to_file(speech_file_path)\n```", "```py\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file= open(\"speech.mp3\", \"rb\")\ntranscription = client.audio.transcriptions.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\n\nprint(transcription.text)\n```", "```py\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file = open(\"speech.mp3\", \"rb\")\ntranslate = client.audio.translations.create(\n  model=\"whisper-1\",\n  file=audio_file\n)\n```"]