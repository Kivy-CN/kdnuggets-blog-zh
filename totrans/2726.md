# 在边缘设备上实施 MLOps

> 原文：[https://www.kdnuggets.com/2020/08/implementing-mlops-edge-device.html](https://www.kdnuggets.com/2020/08/implementing-mlops-edge-device.html)

[评论](#comments)

**由 [Felix Baum](https://developer.qualcomm.com/blogs/fbaum)，高通科技**

传统软件的生命周期可以说相当简单。最简单的形式是，你开发、测试和部署软件，然后根据需要发布新版本，添加功能、更新和/或修复。为此，传统的软件开发通常依赖于 [DevOps](https://en.wikipedia.org/wiki/DevOps)，它包括 [持续集成](https://en.wikipedia.org/wiki/Continuous_integration) (CI)、[持续交付](https://en.wikipedia.org/wiki/Continuous_delivery) (CD) 和 [持续测试](https://en.wikipedia.org/wiki/Continuous_testing) (CT)，以减少开发时间，同时不断交付新版本并保持质量。

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

关于机器学习（ML）建模，人们很容易认为 ML 工作流程遵循类似的模式。毕竟，它应该只是创建和训练 ML 模型，部署它，并根据需要发布新版本。但 ML 系统操作的环境使事情变得复杂。首先，ML 系统本身由于其数据驱动的、非确定性的行为，本质上与传统软件不同。而最近的全球事件也强调了我们的世界不断变化，因此 ML 从业者必须预见到生产模型¹ 推断的真实世界数据也会不可避免地发生变化。

结果是，一种特殊的 ML DevOps 被称为*MLOps*（即“机器学习与运维”的缩写）应运而生，以帮助管理这种不断变化及其随之而来的模型重新部署需求。MLOps 拥抱 DevOps 的持续集成和持续交付，但将持续测试阶段替换为*持续训练*。这种新的模型的持续训练，包括这些新模型的重新部署及所有相关的技术工作，旨在解决 ML 项目的三个显著方面：

+   需要对模型如何及为何做出某些预测进行“可解释性”说明。这对于审计目的尤其重要，以满足法规和/或某些预测性能水平的要求。

+   模型衰退是指由于模型遇到的新变化的实际数据，生产模型的预测性能随时间减少。

+   由业务需求驱动的模型的持续开发和改进。

持续训练，实际上也包括 MLOps，一般都接受模型会不断且不可避免地变化的理念，这意味着组织在实施 MLOps 策略和战术时会有不同程度的体现。

随着 MLOps 的发展，许多组织提出了最佳实践框架。一个显著的例子是 [Google 的 MLOps](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#mlops_level_2_cicd_pipeline_automation) 指南，它描述了组织采用的三种 MLOps 实施级别：

+   **MLOps 0 级：手动过程**：模型训练和部署的需求被正式认可，但通常通过脚本和交互过程以临时的方式手动完成。这个层级一般缺乏持续集成和持续交付。

+   **MLOps 1 级：ML 流水线自动化**：这一层级引入了用于持续训练的流水线。数据和模型验证被自动化，并且设有触发器，以便在模型性能下降时用新数据重新训练模型。

+   **MLOps 2 级：CI/CD 流水线自动化**：ML 工作流已经自动化到数据科学家能够更新模型和流水线，而开发人员的干预减少。

实施了 MLOps 2 级或 MLOps 3 级的组织甚至可能使用所谓的“影子模型”，这些模型在生产模型运行时会并行训练，每个模型使用不同的训练数据集。当需要新的生产模型时，可以快速选择和部署一个影子模型。

[![图示](../Images/22938573f024a01b728b506138623974.png)](https://developer.qualcomm.com/sites/default/files/attachments/mlops-01_0.png)

*图 1 - 影子模型在不同数据集上并行训练的可视化展示。每个模型都是成为新生产模型的潜在候选者。*

为了更好地理解这些不同级别的 MLOps 如何以及何时实施，请考虑以下示例。

**示例 1：包装机器人**

一个简单的例子是，在装配线末端的机器人，利用 ML 支持的计算机视觉来分析和包装产品。ML 模型可能已经训练成识别一定范围的方形和矩形盒子。然而，业务现在会引入新的包装形状和尺寸，因此创建并部署了新的 ML 模型。在这种情况下，MLOps 0 级的开发团队将手动创建、训练和部署新模型，在新类型的包装开始下线之前进行预先准备。考虑到机器人的能力范围有限，这种 MLOps 层级可能已经足够。

**示例 2：语音识别**

考虑一个可以根据人们说话的方式感知或识别上下文（例如，语调或情感）的语音识别移动应用程序。随着时间的推移，新短语和俚语的出现，以及人们谈话风格的变化，机器学习模型可能会在长时间内出现模型衰退。

这是一个可能从 MLOps 1 级的指导方针中受益的例子。在 MLOps 1 级下，系统可以在设备上运行，以监控模型的预测性能。如果性能接近或低于阈值，系统会触发警报，提醒团队需要使用新数据训练一个新模型，并将其部署以替代生产模型。

**示例 3：股市中的突发异常值**

今年早些时候，油价进入了负值区域。如果一个机器学习模型是基于油价进行预测的，但只用过正油价进行训练，那么当它突然遇到负油价时，表现会如何？在这种情况下，团队成员需要立即被警告到这个问题，并且必须能够快速训练和重新部署一个新模型。

在这里，实现 MLOps 2 级可能会有所帮助。在这个级别，大部分训练和部署新模型的管道已经自动化，因此数据科学家应该能够在没有开发人员协助的情况下处理大部分或全部管道。此外，自动化的程度应该允许他们尽快且可靠地专注于更新、训练和部署新模型。

**为边缘设备实施 MLOps**

许多今天的高端边缘设备非常适合 MLOps。它们不仅能够托管大型模型，而且通常配备了专门优化运行推断的向量处理器。例如，[Hexagon](https://developer.qualcomm.com/software/hexagon-dsp-sdk/dsp-processor) 数字信号处理器（DSP）就存在于高通® [Snapdragon](https://www.qualcomm.com/snapdragon)™ 系列的移动平台上，它为[今天许多高端设备提供动力](https://en.wikipedia.org/wiki/Devices_using_Qualcomm_Snapdragon_systems-on-chip)²。此外，这些处理器通常配备了丰富的人工智能（AI）SDK 和工具集，开发人员可以使用它们来优化和加载模型到设备上。这些 SDK 和工具可以集成到 MLOps 管道中，以促进模型部署过程。

在 ML 工作流的上下文中，使用 SDK 的一般过程如下：

1.  机器学习模型是使用如 [TensorFlow](https://www.tensorflow.org/) 这样的框架设计和训练的。

1.  [Qualcomm 神经处理 SDK](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk) 中的转换工具用于将模型转换为专有格式，优化以在 Snapdragon 上执行。

1.  从 Qualcomm 神经处理 SDK 的 API 调用被添加到应用程序中，以将数据加载到 Qualcomm® Hexagon™ 处理器上并进行推理。

1.  一旦加载完成并且应用程序运行中，模型就会被部署到边缘进行实际数据的推理。

[![图像](../Images/4fc6183c11b6ba52714bfa3a5b8bba45.png)](https://developer.qualcomm.com/sites/default/files/attachments/mlops-02.png)

*图 2 - 在边缘设备上集成和执行机器学习模型的基本工作流程。*

在 MLOps 的背景下，上述第 1、2 和 4 步骤会在产品生命周期内重复执行，随着模型更新的需求而不断进行。根据实施的 MLOps 级别，开发人员可能会构建一些额外的实体，例如在边缘设备上运行的监控工具，用于评估模型的预测性能。他们还可能构建某种警报和/或触发器，以启动机器学习工作流程的新迭代。

**深入了解 MLOps 管道**

进一步来看，将有许多工具和阶段需要集成到 MLOps 管道模型部署脚本中。以下展示了一个基于 Qualcomm 神经处理 SDK 构建的示例管道：

[![图像](../Images/52ae9f34f0b50b1a7484756abbd57a08.png)](https://developer.qualcomm.com/sites/default/files/attachments/mlops-03.jpg)

*图 3 – 边缘设备 SDK 在机器学习工作流程中的角色的更详细视图。*

在工作流程的上半部分，ML 模型在机器学习框架中进行训练。在工作流程的下半部分，使用 SDK 工具将模型转换为边缘设备的专有格式，并可以选择性地优化模型以适应边缘设备。在 MLOps 的背景下，这些工具会被手动调用或作为自动构建脚本的一部分调用。

开发人员还可以实现不同的方法将新模型重新加载到运行中的边缘设备应用程序中。一种方法是在设备上运行服务，自动下载新模型并用新模型重启应用程序（甚至重启整个设备），但这可能会在重启过程中中断服务。另一种方法是应用程序本身在运行时监视新模型文件的存在，并重新调用必要的 API 来加载新模型。还有另一种选择是使用*推送*方法，通过服务器发起的空中更新将新模型推送到设备。

根据应用程序的架构，这些选项中的每一个可能会在模型部署和应用程序切换到使用新模型时产生不同程度的停机。因此，开发人员需要权衡实施每种技术的复杂性与部署新模型所需的潜在停机时间。

**结论**

ML 系统本质上与传统软件不同，因为它们是非确定性的，并在一个不断发展的、不断变化的数据世界中运行。但由于像 MLOps 这样的正式方法，开发人员拥有了策略和实施强大 ML 解决方案所需的工具。

随着机器学习在当今众多设备上的边缘计算中获得如此重要的地位，看到这些硬件与其 SDK 和工具结合，如何支持有效的 MLOps 流水线，令人兴奋。

1.  *生产模型* 是指已经部署用于在真实数据上进行推理的机器学习模型。

1.  [https://www.statista.com/statistics/233415/global-market-share-of-applications-processor-suppliers/](https://www.statista.com/statistics/233415/global-market-share-of-applications-processor-suppliers/)

**简介: [Felix Baum](https://developer.qualcomm.com/blogs/fbaum)** 负责管理 Qualcomm Technologies 的数字信号处理器 (DSP) 软件产品，并在支持 Hexagon DSP 在连接、音频、语音、传感器融合、计算机视觉和机器学习用例方面发挥了重要作用。

[原文](https://developer.qualcomm.com/blog/implementing-machine-learning-and-operations-mlops )。转载获许可。

**相关:**

+   [驾驭 MLOps 的复杂性](/2020/05/taming-complexity-mlops.html)

+   [揭开 AI 基础设施栈的面纱](/2020/05/demystifying-ai-infrastructure-stack.html)

+   [端到端机器学习平台的巡礼](/2020/07/tour-end-to-end-machine-learning-platforms.html)

### 更多相关话题

+   [带开发者准备好的软件堆栈的设备内 AI](https://www.kdnuggets.com/2022/03/qualcomm-ondevice-ai-developer-ready-software-stacks.html)

+   [了解如何在您的设备上仅需几步运行 Alpaca-LoRA](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)

+   [边缘机器学习](https://www.kdnuggets.com/2022/10/machine-learning-edge.html)

+   [最大化边缘 AI 应用中的性能](https://www.kdnuggets.com/maximize-performance-in-edge-ai-applications)

+   [Snapdragon 上的 Windows 将混合 AI 带入边缘应用](https://www.kdnuggets.com/qualcomm-windows-on-snapdragon-brings-hybrid-ai-to-apps-at-the-edge)

+   [介绍 TPU v4: Google 的前沿超级计算机用于大型…](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)
