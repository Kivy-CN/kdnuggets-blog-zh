["```py\nctx = ssl.create_default_context()\nctx.check_hostname = False\nctx.verify_mode = ssl.CERT_NONE\n\n# Read the HTML from the URL and pass on to BeautifulSoup\nurl = 'https://www.cia.gov/library/publications/the-world-factbook/'\nprint(\"Opening the file connection...\")\nuh= urllib.request.urlopen(url, context=ctx)\nprint(\"HTTP status\",uh.getcode())\nhtml =uh.read().decode()\nprint(f\"Reading done. Total {len(html)} characters read.\")\n```", "```py\nsoup = BeautifulSoup(html, 'html.parser')\ncountry_codes=[]\ncountry_names=[]\n\nfor tag in soup.find_all('option'):\n    country_codes.append(tag.get('value')[5:7])\n    country_names.append(tag.text)\n\ntemp=country_codes.pop(0) # *To remove the first entry 'World'*\ntemp=country_names.pop(0) # *To remove the first entry 'World'*\n```", "```py\n# Base URL\nurlbase = 'https://www.cia.gov/library/publications/the-world-factbook/geos/'\n# Empty data dictionary\ntext_data=dict()\n\n# Iterate over every country\nfor i in range(1,len(country_names)-1):\n    country_html=country_codes[i]+'.html'\n    url_to_get=urlbase+country_html\n    # Read the HTML from the URL and pass on to BeautifulSoup\n    html = urllib.request.urlopen(url_to_get, context=ctx).read()\n    soup = BeautifulSoup(html, 'html.parser')\n    txt=soup.get_text()\n    text_data[country_names[i]]=txt\n    print(f\"Finished loading data for {country_names[i]}\")\n\nprint (\"\\n**Finished downloading all text data!**\")\n```", "```py\nimport pickle\npickle.dump(text_data,open(\"text_data_CIA_Factobook.p\", \"wb\"))\n\n# Unpickle and read the data from local storage next time\ntext_data = pickle.load(open(\"text_data_CIA_Factobook.p\", \"rb\"))\n```", "```py\n# 'b' to catch 'billions', 't' to catch 'trillions'\nstart = re.search('\\$',string)\nend = re.search('[b,t]',string)\nif (start!=None and end!=None):\n    start=start.start()\n    end=end.start()\n    a=string[start+1:start+end-1]\n    a = convert_float(a)\n    if (string[end]=='t'):\n    # If the GDP was in trillions, multiply it by 1000\n        a=1000*a\n```", "```py\n# Initialize dictionary for holding the data\nGDP_PPP = {}\n# Iterate over every country\nfor i in range(1,len(country_names)-1):\n    country= country_names[i]\n    txt=text_data[country]       \n    pos = txt.find('GDP - per capita (PPP):')\n    if pos!=-1: #If the wording/phrase is not present\n        pos= pos+len('GDP - per capita (PPP):')\n        string = txt[pos+1:pos+11]\n        start = re.search('\\$',string)\n        end = re.search('\\S',string)\n        if (start!=None and end!=None): #If search fails somehow\n            start=start.start()\n            end=end.start()\n            a=string[start+1:start+end-1]\n            #print(a)\n            a = convert_float(a)\n            if (a!=-1.0): #If the float conversion fails somehow\n                print(f\"GDP/capita (PPP) of {country}: {a} dollars\")\n                # Insert the data in the dictionary\n                GDP_PPP[country]=a\n            else:\n                print(\"**Could not find GDP/capita data!**\")\n        else:\n            print(\"**Could not find GDP/capita data!**\")\n    else:\n        print(\"**Could not find GDP/capita data!**\")\n\nprint (\"\\nFinished finding all GDP/capita data\")\n```", "```py\ndf_combined = df_demo.join(df_GDP, how='left')\ndf_combined.dropna(inplace=True)\n```", "```py\n# Create a filtered data frame and x and y arrays\nfilter_gdp = df_combined['Total GDP (PPP)'] > 50\nfilter_low_income=df_combined['GDP (PPP)']>5000\nfilter_high_income=df_combined['GDP (PPP)']<25000\n\ndf_filtered = df_combined[filter_gdp][filter_low_income][filter_high_income]\n```"]