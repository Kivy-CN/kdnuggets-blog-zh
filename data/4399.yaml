- en: Your Guide to Linear Regression Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归模型指南
- en: 原文：[https://www.kdnuggets.com/2020/10/guide-linear-regression-models.html](https://www.kdnuggets.com/2020/10/guide-linear-regression-models.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/10/guide-linear-regression-models.html](https://www.kdnuggets.com/2020/10/guide-linear-regression-models.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/), Data Scientist**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/), 数据科学家**'
- en: '![Figure](../Images/fcbc5e05af9fcf5b53dc7a06990b9997.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/fcbc5e05af9fcf5b53dc7a06990b9997.png)'
- en: Photo by [Drew Beamer](https://unsplash.com/@drew_beamer?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Drew Beamer](https://unsplash.com/@drew_beamer?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加速你的网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Interpretability is one of the biggest challenges in machine learning. A model
    has more interpretability than another one if its decisions are easier for a human
    to comprehend. Some models are so complex and are internally structured in such
    a way that it’s almost impossible to understand how they reached their final results.
    These black boxes seem to break the association between raw data and final output,
    since several processes happen in between.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性是机器学习中的一个重大挑战。如果一个模型的决策对人类更易于理解，那么它的可解释性就高于其他模型。一些模型复杂到几乎无法理解它们如何得出最终结果。这些黑箱似乎打破了原始数据与最终输出之间的联系，因为中间发生了多个过程。
- en: But in the universe of machine learning algorithms, some models are more transparent
    than others. [Decision Trees](https://towardsdatascience.com/modelling-classification-trees-3607ad43a123) are
    definitely one of them, and Linear Regression models are another one. Their simplicity
    and straightforward approach turns them into an ideal tool to approach different
    problems. Let’s see how.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习算法的宇宙中，有些模型比其他模型更透明。[决策树](https://towardsdatascience.com/modelling-classification-trees-3607ad43a123)无疑是其中之一，线性回归模型也是另一个。它们的简单性和直接的方法使它们成为处理不同问题的理想工具。让我们来看看。
- en: You can use Linear Regression models to analyze how salaries in a given place
    depend on features like experience, level of education, role, city they work in,
    and so on. Similarly, you can analyze if real estate prices depend on factors
    such as their areas, numbers of bedrooms, or distances to the city center.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用线性回归模型来分析某地的薪资如何依赖于如经验、教育水平、角色、所在城市等特征。同样，你也可以分析房地产价格是否依赖于如面积、卧室数量或距离市中心的因素。
- en: In this post, I’ll focus on Linear Regression models that examine the linear
    relationship between a **dependent variable **and one (Simple Linear Regression)
    or more (Multiple Linear Regression) **independent variables**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将重点讨论线性回归模型，这些模型检查 **因变量** 和一个（简单线性回归）或多个（多重线性回归） **自变量** 之间的线性关系。
- en: Simple Linear Regression (SLR)
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简单线性回归（SLR）
- en: 'Is the simplest form of Linear Regression used when there is a single input
    variable (predictor) for the output variable (target):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当输出变量（目标）只有一个输入变量（预测变量）时，使用最简单形式的线性回归：
- en: The **input** or **predictor variable** is the variable that helps predict the
    value of the output variable. It is commonly referred to as ***X***.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入** 或 **预测变量** 是帮助预测输出变量值的变量。它通常被称为 ***X***。'
- en: The **output **or** target variable** is the variable that we want to predict.
    It is commonly referred to as ***y***.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出** 或 **目标变量** 是我们想要预测的变量。它通常被称为 ***y***。'
- en: '![Image for post](../Images/8cda7a5444b3f7af8be443524877724f.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![文章图片](../Images/8cda7a5444b3f7af8be443524877724f.png)'
- en: The value of **β0, also called the intercept**, shows the point where the estimated
    regression line crosses the ***y*** axis, while the value of **β1** **determines
    the slope** of the estimated regression line. The **random error** describes the
    random component of the linear relationship between the dependent and independent
    variable (the disturbance of the model, the part of ***y*** that ***X ***is unable
    to explain). The true regression model is usually never known (since we are not
    able to capture all the effects that impact the dependent variable), and therefore
    the value of the random error term corresponding to observed data points remains
    unknown. However, the regression model can be estimated by calculating the parameters
    of the model for an observed data set.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**β0，亦称截距**的值显示了估计回归线与***y***轴交点的位置，而**β1**的值**确定了估计回归线的斜率**。**随机误差**描述了因变量与自变量之间线性关系的随机成分（模型的干扰，即***X***无法解释的***y***部分）。真实的回归模型通常是未知的（因为我们无法捕捉所有影响因变量的因素），因此，实际数据点对应的随机误差项的值仍然未知。然而，通过计算观察数据集的模型参数，可以估计回归模型。'
- en: The idea behind regression is to estimate the parameters **β0** and **β1** from
    a sample. If we are able to determine the optimum values of these two parameters,
    then we will have the **line of best fit** that we can use to predict the values
    of ***y***, given the value of ***X***. In other words, we try to fit a line to
    observe a relationship between the input and output variables and then further
    use it to predict the output of unseen inputs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 回归的思想是从样本中估计参数**β0**和**β1**。如果我们能够确定这两个参数的最优值，那么我们将得到**最佳拟合线**，可以用来预测***y***的值，给定***X***的值。换句话说，我们尝试拟合一条线，以观察输入和输出变量之间的关系，然后进一步用它来预测未见输入的输出。
- en: '![Image for post](../Images/79e28b3a31c2a1ca51aa7b22db888416.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![用于帖子](../Images/79e28b3a31c2a1ca51aa7b22db888416.png)'
- en: How do we estimate **β0**and **β1**? We can use a method called **Ordinary Least
    Squares (OLS)**.The goal behind this is to minimize the distance from the black
    dots to the red line as close to zero as possible, which is done by minimizing
    the squared differences between actual and predicted outcomes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何估计**β0**和**β1**？我们可以使用一种叫做**普通最小二乘法（OLS）**的方法。其目标是尽可能将黑点到红线的距离减小到接近零，这通过最小化实际结果和预测结果之间的平方差来实现。
- en: The difference between actual and predicted values is called **residual (e)**and
    can be negative or positive depending on whether the model overpredicted or underpredicted
    the outcome. Hence, to calculate the net error, adding all the residuals directly
    can lead to the cancellations of terms and reduction of the net effect. To avoid
    this, we take the sum of squares of these error terms, which is called the ***Residual
    Sum of Squares (RSS).***
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实际值和预测值之间的差异称为**残差（e）**，它可以是负的或正的，具体取决于模型是否过度预测或低估了结果。因此，为了计算净误差，直接将所有残差相加可能会导致项的相互抵消和净效果的减少。为避免这种情况，我们取这些误差项的平方和，这被称为***残差平方和（RSS）***。
- en: '![Image for post](../Images/bda915173cacc02353a9dc556511929c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![用于帖子](../Images/bda915173cacc02353a9dc556511929c.png)'
- en: The **Ordinary Least Squares (OLS) method minimizes the residual sum of squares**,
    and its objective is to fit a regression line that would minimize the distance
    (measured in quadratic values) from the observed values to the predicted ones
    (the regression line).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**普通最小二乘法（OLS）最小化残差平方和**，其目标是拟合一条回归线，以最小化观察值与预测值（回归线）之间的距离（以平方值计）。'
- en: Multiple Linear Regression (MLR)
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多元线性回归（MLR）
- en: 'Is the formof Linear Regression used when there are two or more predictors
    or input variables. Similar to the SLR model described before, it includes additional
    predictors:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当有两个或更多预测变量或输入变量时使用的线性回归形式。类似于之前描述的SLR模型，它包括额外的预测变量：
- en: '![Image for post](../Images/b6650093faec8342f178de664db892e4.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![用于帖子](../Images/b6650093faec8342f178de664db892e4.png)'
- en: Notice that the equation is just an extension of the Simple Linear Regression
    one, in which each input/ predictor has its corresponding slope coefficient **(β*)***.
    The first **β**term **(β0)** is the intercept constant and is the value of ***y*** in
    absence of all predictors (i.e when all ***X*** terms are 0).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这个方程只是简单线性回归方程的扩展，其中每个输入/预测变量都有其相应的斜率系数**(β*)**。第一个**β**项**(β0)**是截距常数，是在没有所有预测变量的情况下***y***的值（即当所有***X***项为0时）。
- en: As the number of features grows, the complexity of our model increases and it
    becomes more difficult to visualize, or even comprehend, our data. Because there
    are more parameters in these models compared to SLR ones, more care is needed.
    when working with them. Adding more terms will inherently improve the fit to the
    data, but the new terms may not have any real significance. This is dangerous
    because it can lead to a model that fits that data but doesn’t actually mean anything
    useful.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 随着特征数量的增加，我们模型的复杂性也增加，数据的可视化和理解变得更加困难。由于这些模型中参数更多，相较于SLR模型，需要更多的注意。增加更多的项本质上会改善对数据的拟合，但这些新项可能没有实际意义。这是危险的，因为它可能导致一个适应数据但实际上没有任何有用意义的模型。
- en: An example
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个示例
- en: 'The advertising dataset consists of the sales of a product in 200 different
    markets, along with advertising budgets for three different media: TV, radio,
    and newspaper. We’ll use the dataset to predict the amount of sales (dependent
    variable), based on the TV, radio and newspaper advertising budgets (independent
    variables).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 广告数据集包含了在200个不同市场中某产品的销售情况，以及对三种不同媒体（电视、广播和报纸）的广告预算。我们将使用这个数据集来预测销售量（因变量），基于电视、广播和报纸广告预算（自变量）。
- en: 'Mathematically, the formula we’ll try solve is:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度看，我们尝试解决的公式是：
- en: '![Image for post](../Images/20b1ee1581d96839e194aa57d99bb15d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/20b1ee1581d96839e194aa57d99bb15d.png)'
- en: Finding the values of these constants **(β)** is what regression model does
    by minimizing the error function and fitting the best line or hyperplane (depending
    on the number of input variables). Let’s code.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 找到这些常数**(β)**的值是回归模型通过最小化误差函数和拟合最佳线或超平面（取决于输入变量的数量）来完成的。让我们开始编码。
- en: Load data and describe dataset
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据并描述数据集
- en: 'You can download the dataset under [this link](https://github.com/dlopezyse/Medium).
    Before loading the data, we’ll import the necessary libraries:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[this link](https://github.com/dlopezyse/Medium)下载数据集。在加载数据之前，我们将导入必要的库：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now we load the dataset:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们加载数据集：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s understand the dataset and describe it:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解数据集并描述它：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Image for post](../Images/ed9096f717b3417a46d185b66c037cf5.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/ed9096f717b3417a46d185b66c037cf5.png)'
- en: 'We’ll drop the first column (“Unnamed”) since we don’t need it:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将删除第一列（“Unnamed”），因为我们不需要它：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Image for post](../Images/f26b29dfb125222633b20c292e7af496.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/f26b29dfb125222633b20c292e7af496.png)'
- en: Our dataset now contains 4 columns (including the target variable “sales”),
    200 registers and no missing values. Let’s visualize the relationship between
    the independent and target variables.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集现在包含4列（包括目标变量“销售”）、200个记录和没有缺失值。让我们可视化自变量和目标变量之间的关系。
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Image for post](../Images/72d9a6f285aea4fce58f76dee299ada4.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/72d9a6f285aea4fce58f76dee299ada4.png)'
- en: 'The relationship between TV and sales seems to be pretty strong, and while
    there seems to be some trend between radio and sales, the relationship between
    newspaper and sales seems to be nonexistent. We can verify that also numerically
    through a correlation map:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 电视与销售之间的关系似乎相当强，而广播与销售之间似乎有一些趋势，但报纸与销售之间的关系似乎不存在。我们还可以通过相关性图来数值验证这一点：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Image for post](../Images/d75991c12d1f5bd10e21e436f11113fa.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/d75991c12d1f5bd10e21e436f11113fa.png)'
- en: As we expected, the strongest positive correlation happens between sales and
    TV, while the relationship between sales and newspaper is close to 0.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们预期的那样，销售与电视之间的正相关最强，而销售与报纸之间的关系接近于0。
- en: Select features and target variable
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择特征和目标变量
- en: 'Next, we divide the variables into two sets: dependent (or target variable
    “y”) and independents (or feature variables “X”)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将变量分为两组：因变量（或目标变量“y”）和自变量（或特征变量“X”）
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Split the dataset
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拆分数据集
- en: To understand model performance, dividing the dataset into a training set and
    a test set is a good strategy. By splitting the dataset into two separate sets,
    we can train using one set and test the model performance using unseen data on
    the other one.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解模型的表现，将数据集分为训练集和测试集是一种良好的策略。通过将数据集分为两个独立的集合，我们可以使用一个集合进行训练，使用另一个集合上的未见数据测试模型的表现。
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We split our dataset into 70% train and 30% test. The random_state parameter
    is used for initializing the internal random number generator, which will decide
    the splitting of data into train and test indices in your case. I set random state
    = 0 so that you can compare your output over multiple runs of the code using the
    same parameter.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据集拆分为70%的训练集和30%的测试集。random_state 参数用于初始化内部随机数生成器，它将决定数据拆分为训练和测试索引。我将 random_state
    设置为0，以便你可以使用相同的参数比较多次运行的输出。
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Image for post](../Images/23b9729cd234ee782860ede5c523f967.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/23b9729cd234ee782860ede5c523f967.png)'
- en: 'By printing the shape of the splitted sets, we see that we created:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通过打印拆分集的形状，我们可以看到我们创建了：
- en: 2 datasets of 140 registers each (70% of total registers), one with 3 independent
    variables and one with just the target variable, that will be used for **training** and
    producing the linear regression model.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 个数据集，每个数据集包含 140 条记录（总记录的 70%），一个有 3 个独立变量，一个只有目标变量，将用于 **训练** 和生成线性回归模型。
- en: 2 datasets of 60 registers each (30% of total registers), one with 3 independent
    variables and one with just the target variable, that will be used for **testing** the
    performance of the linear regression model.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 个数据集，每个数据集包含 60 条记录（总记录的 30%），一个有 3 个独立变量，一个只有目标变量，将用于 **测试** 线性回归模型的性能。
- en: Build model
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建模型
- en: 'Building the model is as simple as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 构建模型是如此简单：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Train model
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'Fitting your model to the training data represents the training part of the
    modelling process. After it is trained, the model can be used to make predictions,
    with a predict method call:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据上代表了建模过程中的训练部分。训练后，模型可以用来进行预测，通过调用 predict 方法：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let’s see the output of the model after being trained, and take a look at the
    value of **β0** (the intercept):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模型训练后的输出，并查看 **β0**（截距）的值：
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Image for post](../Images/adb451920cd51229c2da62c7786301ef.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/adb451920cd51229c2da62c7786301ef.png)'
- en: 'We can also print the values of the coefficients **(β)**:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以打印系数的值 **(β)**：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Image for post](../Images/c162f63a4b2dff8db2fe9b5c61e2b0a4.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/c162f63a4b2dff8db2fe9b5c61e2b0a4.png)'
- en: 'This way we can now estimate the value of “sales” based on different budget
    values for TV, radio and newspaper:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这样我们现在可以根据不同的电视、广播和报纸预算值来估计“销售” 的值：
- en: '![Image for post](../Images/4ed913943f9bde535868ae7c0e7fbbb4.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/4ed913943f9bde535868ae7c0e7fbbb4.png)'
- en: 'For example, if we determine a budget value of 50 for TV, 30 for radio and
    10 for newspaper, the estimated value of “sales” will be:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们为电视确定了 50 的预算，为广播 30，为报纸 10，则“销售” 的估计值将是：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Image for post](../Images/ad0baa7d2144b796f5e062b704dd24b0.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/ad0baa7d2144b796f5e062b704dd24b0.png)'
- en: Test model
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试模型
- en: 'A test dataset is a dataset that is independent of the training dataset. This
    test dataset is the unseen data set for your model which will help you have a
    better view of its ability to generalize:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集是与训练数据集独立的数据集。这个测试数据集是模型未见过的数据，这将帮助你更好地了解模型的泛化能力：
- en: '[PRE14]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Evaluate Performance**'
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**评估性能**'
- en: 'The quality of a model is related to how well its predictions match up against
    the actual values of the testing dataset:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的质量与其预测值与测试数据集的实际值匹配的程度有关：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Image for post](../Images/a6a0f1654a011201c1be4a9d5a6be571.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/a6a0f1654a011201c1be4a9d5a6be571.png)'
- en: After validating our model against the testing set, we get an R² of 0.86 which
    seems like a pretty decent performance score. But although a higher R² indicates
    a better fit for the model, it’s not always the case that a high measure is a
    positive thing. We’ll see below some ways to interpret and improve our regression
    models.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在用测试集验证我们的模型后，我们得到的 R² 值为 0.86，这似乎是一个相当不错的性能得分。但虽然更高的 R² 表示模型拟合得更好，但高的测量值不总是正面的。我们将在下文中看到一些解读和改进回归模型的方法。
- en: '**How to interpret and improve your model?**'
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**如何解读和改进你的模型？**'
- en: 'OK, we created our model, and now what? Let’s take a look at the model statistics
    over the training data to get some answers:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，我们创建了模型，接下来呢？让我们查看训练数据上的模型统计数据，以获得一些答案：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Image for post](../Images/5f929c9267d99aabcc912d796e037fce.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![Image for post](../Images/5f929c9267d99aabcc912d796e037fce.png)'
- en: Let’s see below what these numbers mean.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些数字的含义。
- en: '**Hypothesis Test**'
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**假设检验**'
- en: One of the fundamental questions you should answer while running a MLR model
    is, whether or not, [at least one of the predictors is useful in predicting the
    output](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b).
    What if the relationship between the independent variables and target is just
    by chance and there is no actual impact on sales due to any of the predictors?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行多元线性回归模型时，您应该回答的基本问题之一是，[至少一个预测变量是否对预测输出有用](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)。如果自变量与目标之间的关系只是偶然的，并且任何预测变量对销售没有实际影响，该怎么办？
- en: 'We need to perform a Hypothesis Test to answer this question and check our
    assumptions. It all starts by forming a **Null Hypothesis (H0)**, which states
    that all the coefficients are equal to zero, and there’s no relationship between
    predictors and target (meaning that a model with no independent variables fits
    the data as well as your model):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要进行假设检验来回答这个问题并检查我们的假设。首先形成**原假设 (H0)**，即所有系数等于零，预测变量与目标之间没有关系（意味着一个没有自变量的模型与您的模型一样好）：
- en: '![Figure](../Images/bcf3f2bd870635a2ff7a97cd7643ce0b.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bcf3f2bd870635a2ff7a97cd7643ce0b.png)'
- en: Multiple Linear Regression. Source: [Towards Data Science](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '多元线性回归。来源: [Towards Data Science](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)'
- en: 'On the other hand, we need to define an **Alternative Hypothesis (Ha)**, which
    states that at least one of the coefficients is not zero, and there is a relationship
    between predictors and target (meaning that your model fits the data better than
    the intercept-only model):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们需要定义**备择假设 (Ha)**，即至少一个系数不为零，且预测变量与目标之间存在关系（意味着您的模型比仅有截距的模型更好地拟合数据）：
- en: '![Figure](../Images/bb164e3b5e96385c541b00e831671324.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bb164e3b5e96385c541b00e831671324.png)'
- en: Multiple Linear Regression. Source: [Towards Data Science](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '多元线性回归。来源: [Towards Data Science](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)'
- en: If we want to reject the Null Hypothesis and have confidence in our regression
    model, we need to find strong statistical evidence. To do this we perform a hypothesis
    test, for which we use the **F-Statistic**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要拒绝原假设并对我们的回归模型有信心，我们需要找到强有力的统计证据。为此，我们进行假设检验，其中使用**F统计量**。
- en: '*If the value of F-statistic is equal to or very close to 1, then the results
    are in favor of the Null Hypothesis and we fail to reject it.*'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果F统计量的值等于或非常接近1，则结果支持原假设，我们无法拒绝它。*'
- en: As we can see in the table above (marked in yellow), the F-statistic is 439.9,
    thus providing strong evidence against the Null Hypothesis (that all coefficients
    are zero). Next, we also need to check the **probability of occurrence of the
    F-statistic** (also marked in yellow) under the assumption that the null hypothesis
    is true, which is 8.76e-70, an exceedingly small number lower than 1%. This means
    that there is much less than 1% probability that the F-statistic of 439.9 could
    have occurred by chance under the assumption of a valid Null hypothesis.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如上表所示（标记为黄色），F统计量为439.9，因此提供了强有力的证据来反驳原假设（即所有系数为零）。接下来，我们还需要检查在原假设为真的情况下**F统计量出现的概率**（也标记为黄色），其值为8.76e-70，这是一个远小于1%的极小数字。这意味着在假设原假设有效的情况下，F统计量439.9出现的概率远低于1%。
- en: Having said this, we can reject the Null Hypothesis and be confident that at
    least one predictor is useful in predicting the output.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我们可以拒绝原假设，并确信至少一个预测变量对预测输出是有用的。
- en: Generate models
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成模型
- en: 'Running a Linear Regression model with many variables including irrelevant
    ones will lead to a needlessly complex model. Which of the predictors are important?
    Are all of them significant to our model? To find that out, we need to perform
    a process called **feature selection**.The 2 main methods for feature selection
    are:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 运行包含许多变量（包括无关变量）的线性回归模型会导致模型过于复杂。哪些预测变量是重要的？它们都对我们的模型重要吗？要找出这一点，我们需要进行一个叫做**特征选择**的过程。特征选择的两种主要方法是：
- en: '**Forward Selection: **where predictors are added one at a time beginning with
    the predictor with the highest correlation with the dependent variable. Then,
    variables of greater theoretical importance are incorporated to the model sequentially,
    until a stopping rule is reached.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**前向选择：** 从与因变量相关性最高的预测变量开始，逐个添加预测变量。然后，按照理论重要性将变量顺序地纳入模型，直到达到停止规则。'
- en: '**Backward Elimination:** where you start with all variables in the model,
    and remove the variables that have the least statistically significant (greater
    p-value), until a stopping rule is reached.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**后向淘汰：** 从模型中包含所有变量开始，移除那些统计显著性最低（p 值较大）的变量，直到达到停止规则。'
- en: Although both methods can be used, unless the number of predictors is larger
    than the sample size (or number of events), it’s usually preferred to use a backward
    elimination approach.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以使用这两种方法，但除非预测变量的数量大于样本量（或事件数量），否则通常更倾向于使用后向淘汰方法。
- en: You can find a full example and implementation of these methods in [this link](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [this link](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)找到这些方法的完整示例和实现。
- en: '**Compare models**'
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**比较模型**'
- en: Every time you add an independent variable to a model, the R² increases, even
    if the independent variable is insignificant. In our model, are all predictors
    contributing to an increase in sales? And if so, are they all doing it in the
    same extent?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你向模型中添加一个自变量时，R² 都会增加，即使该自变量并不显著。在我们的模型中，所有预测变量是否都在增加销售额？如果是，它们的贡献程度是否相同？
- en: As opposed to R²,** Adjusted R² **is a measure that increases only when the
    independent variable is significant and affects the dependent variable. So,if
    your R² score increases but the Adjusted R² score decreases as you add variables
    to the model, then you know that some features are not useful and you should remove
    them.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与 R² 相对，**调整后的 R²** 是一个只有在自变量显著且影响因变量时才会增加的指标。因此，如果你的 R² 分数增加但调整后的 R² 分数下降，那么说明一些特征没有用处，你应该将其移除。
- en: An interesting finding in the table above is that the **p-value** for newspaper
    is super high (0.789, marked in red). Finding the p-value for each coefficient
    will tell if the variable is statistically significant to predict the target or
    not.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 上表中的一个有趣发现是，**p 值** 对于报纸的值非常高（0.789，标记为红色）。找出每个系数的 p 值将告诉你该变量是否对预测目标具有统计学意义。
- en: As a general rule of thumb, if the p-value for a given variable is less than
    0.05 then there is a strong relationship between that variable and the target.
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一般来说，如果某个变量的 p 值小于 0.05，那么该变量与目标之间有很强的关系。
- en: This way, including the variable newspaper doesn’t seem to be appropriate to
    reach a robust model, and removing it may improve the performance and generalization
    of the model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的话，包含报纸变量似乎不适合达到一个稳健的模型，移除它可能会提高模型的表现和泛化能力。
- en: 'Besides Adjusted R² score you can use other criteria to compare different regression
    models:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 除了调整后的 R² 分数，你还可以使用其他标准来比较不同的回归模型：
- en: '**Akaike Information Criterion (AIC):** is a technique used to estimate the
    likelihood of a model to predict/estimate the future values. It rewards models
    that achieve a high goodness-of-fit score and penalizes them if they become overly
    complex. A good model is the one that has minimum AIC among all the other models.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**赤池信息准则 (AIC)：** 是一种用于估计模型预测/估计未来值可能性的技术。它奖励那些拟合度高的模型，并对过于复杂的模型进行惩罚。一个好的模型是所有模型中
    AIC 最小的模型。'
- en: '**Bayesian Information Criterion (BIC):** is another criteria for model selection
    that measures the trade-off between model fit and complexity, penalizing overly
    complex models even more than AIC.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯信息准则 (BIC)：** 是另一种模型选择标准，衡量模型拟合度与复杂性之间的权衡，对过于复杂的模型进行更多惩罚。'
- en: Assumptions
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 假设
- en: Because Linear Regression models are an approximation of the long-term sequence
    of any event, they require some assumptions to be made about the data they represent
    in order to remain appropriate. Most statistical tests rely upon certain assumptions
    about the variables used in the analysis, and when these assumptions are not met,
    the results may not be trustworthy (e.g. resulting in Type I or Type II errors).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 因为线性回归模型是对任何事件的长期序列的近似，因此它们需要对其代表的数据做出一些假设，以保持适用性。大多数统计测试依赖于对分析中使用的变量的某些假设，当这些假设不成立时，结果可能不可靠（例如，导致
    I 型或 II 型错误）。
- en: 'Linear Regression models are linear in the sense that the output is a linear
    combination of the input variables, and only suited for modeling linearly separable
    data. Linear Regression models work under various assumptions that must be present
    in order to produce a proper estimation and not to depend solely on accuracy scores:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型在输出是输入变量的线性组合的意义上是线性的，并且仅适用于建模线性可分的数据。线性回归模型在各种假设下工作，这些假设必须存在以生成适当的估计，并且不能仅仅依赖于准确性评分：
- en: '**Linearity**: the relationship between the features and target must be linear.
    One way to check the linear relationships is to visually inspect scatter plots
    for linearity. If the relationship displayed in the scatter plot is not linear,
    then we’d need to run a non-linear regression or transform the data.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性关系**：特征与目标之间的关系必须是线性的。检查线性关系的一种方法是通过可视化散点图来观察线性。如果散点图中显示的关系不是线性的，则需要进行非线性回归或转换数据。'
- en: '**Homoscedasticity**: the variance of the residual must be the same for any
    value of x. Multiple linear regression assumes that the amount of error in the
    residuals is similar at each point of the linear model. This scenario is known
    as homoscedasticity. Scatter plots are a good way to check whether the data are
    homoscedastic, and also several tests exist to validate the assumption numerically
    (e.g. Goldfeld-Quandt, Breusch-Pagan, White)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同方差性**：残差的方差在任何 x 值下都必须相同。多元线性回归假设残差中的误差量在每个线性模型点处是类似的。这种情况称为同方差性。散点图是一种检查数据是否同方差性的方法，还有几种测试可以在数值上验证这一假设（例如
    Goldfeld-Quandt 测试、Breusch-Pagan 测试、White 测试）。'
- en: '![Figure](../Images/42ff07e76b715b1bc499932a4ba38514.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/42ff07e76b715b1bc499932a4ba38514.png)'
- en: Assumptions of Linear Regression algorithm. Source: [Towards Data Science](https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归算法的假设。来源：[Towards Data Science](https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1)
- en: '**No multicollinearity:** data should not show multicollinearity, which occurs
    when the independent variables (explanatory variables) are highly correlated to
    one another. If this happens, there will be problems in figuring out the specific
    variable that contributes to the variance in the dependent/target variable. This
    assumption can be tested with the Variance Inflation Factor (VIF) method, or through
    a correlation matrix. Alternatives to solve this issue may be centering the data
    (deducting the mean score), or conducting a factor analysis and rotating the factors
    to insure independence of the factors in the linear regression analysis.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无多重共线性**：数据不应显示多重共线性，即当自变量（解释变量）之间高度相关时发生。如果发生这种情况，将会在确定哪个特定变量对因变量的方差有贡献时出现问题。可以通过方差膨胀因子（VIF）方法或相关矩阵来测试这一假设。解决此问题的替代方案包括对数据进行中心化（减去均值），或进行因子分析并旋转因子以确保线性回归分析中的因子独立性。'
- en: '**No autocorrelation**: the value of the residuals should be independent of
    one another. The presence of correlation in residuals drastically reduces model’s
    accuracy. If the error terms are correlated, the estimated standard errors tend
    to underestimate the true standard error. To test for this assumption, you can
    use the Durbin-Watson statistic.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无自相关性**：残差的值应彼此独立。残差中的相关性会显著降低模型的准确性。如果误差项相关，估计的标准误差往往会低估真实的标准误差。可以使用 Durbin-Watson
    统计量来检验这一假设。'
- en: '**Normality of residuals**: residuals must be normally distributed. Normality
    can be checked with a goodness of fit test (e.g. Kolmogorov-Smirnov or Shapiro-Wilk
    tests), and if data is not normally distributed, a non-linear transformation (e.g.
    log transformation) might fix the issue.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残差的正态性**：残差必须呈正态分布。可以通过拟合优度检验（例如 Kolmogorov-Smirnov 检验或 Shapiro-Wilk 检验）来检查正态性，如果数据不呈正态分布，可以通过非线性变换（例如对数变换）来解决此问题。'
- en: '![Figure](../Images/6d4419689d91613d692892fbd0305884.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/6d4419689d91613d692892fbd0305884.png)'
- en: Assumptions of Linear Regression algorithm. Source: [Towards Data Science](https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归算法的假设。来源：[数据科学探索](https://towardsdatascience.com/assumptions-of-linear-regression-algorithm-ed9ea32224e1)
- en: Assumptions are critical because if they are not valid, then the analytical
    process can be considered unreliable, unpredictable, and out of control. Failing
    to meet the assumptions can lead to draw conclusions that are not valid or scientifically
    unsupported by the data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 假设是关键的，因为如果它们不成立，那么分析过程可以被认为是不可靠、不可预测和失控的。未能满足假设可能导致得出无效或科学上未得到数据支持的结论。
- en: You can find a full testing of the assumptions in [this link](https://www.kaggle.com/shrutimechlearn/step-by-step-assumptions-linear-regression).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[this link](https://www.kaggle.com/shrutimechlearn/step-by-step-assumptions-linear-regression)找到假设的全面测试。
- en: Final thoughts
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的想法
- en: Although MLR models extend the scope of SLR models, they are still linear models,
    meaning that the terms included in the model are incapable of showing any non-linear
    relationships between each other or representing any sort of non-linear trend.
    You should also be careful when predicting a point outside the observed range
    of features since the relationship among variables may change as you move outside
    the observed range (a fact that you can’t know because you don’t have the data).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管MLR模型扩展了SLR模型的范围，但它们仍然是线性模型，这意味着模型中包含的项无法显示彼此之间的任何非线性关系或表示任何非线性趋势。你在预测观察范围之外的点时也应该小心，因为随着你移动到观察范围之外，变量之间的关系可能会发生变化（这是你无法知道的，因为你没有数据）。
- en: The observed relationship may be locally linear, but there may be unobserved
    non-linear relationships on the outside range of your data.
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 观察到的关系可能在局部是线性的，但在数据的外部范围可能存在未观察到的非线性关系。
- en: '**Linear models can also model curvatures** by including non-linear variables
    such as polynomials and transforming exponential functions. The linear regression
    equation is *linear in the *[*parameters*](https://statisticsbyjim.com/glossary/parameter/),
    meaning you can raise an independent variable by an exponent to fit a curve, and
    still remain in the “linear world”. Linear Regression models can contain log terms
    and inverse terms to follow different kinds of curves and yet continue to be linear
    in the parameters.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性模型也可以通过包括非线性变量如多项式和变换指数函数来建模曲率**。线性回归方程在[*参数*](https://statisticsbyjim.com/glossary/parameter/)上是*线性的*，这意味着你可以通过指数提高自变量来拟合曲线，仍然保持在“线性世界”中。线性回归模型可以包含对数项和倒数项来跟随不同类型的曲线，并且仍然在参数上保持线性。'
- en: '![Figure](../Images/c7ae3a17f20dd0573fff1bb9a0f62e80.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/c7ae3a17f20dd0573fff1bb9a0f62e80.png)'
- en: While the independent variable is squared, the model is still linear in the
    parameters
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当自变量被平方时，模型仍然在参数上是线性的。
- en: Regressions like [**Polynomial Regression**](https://towardsdatascience.com/machine-learning-with-python-easy-and-robust-method-to-fit-nonlinear-data-19e8a1ddbd49) can
    model *non-linear relationships*, and while a linear equation has one basic form,
    non-linear equations can take many different forms. The reason you might consider
    using [**Non-linear Regression Models**](https://towardsdatascience.com/how-to-choose-between-a-linear-or-nonlinear-regression-for-your-dataset-e58a568e2a15) is
    that, while linear regression can model curves, it might not be able to model
    the specific curve that exists in your data.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 像[**多项式回归**](https://towardsdatascience.com/machine-learning-with-python-easy-and-robust-method-to-fit-nonlinear-data-19e8a1ddbd49)这样的回归可以建模*非线性关系*，而线性方程有一个基本形式，非线性方程可以采取许多不同的形式。你可能会考虑使用[**非线性回归模型**](https://towardsdatascience.com/how-to-choose-between-a-linear-or-nonlinear-regression-for-your-dataset-e58a568e2a15)，因为虽然线性回归可以建模曲线，但它可能无法建模数据中存在的特定曲线。
- en: You should also know that OLS is not the only method to fit your Linear Regression
    model, and other optimization methods like [**Gradient Descent**](https://towardsdatascience.com/linear-regression-simplified-ordinary-least-square-vs-gradient-descent-48145de2cf76) are
    more adequate to fit large datasets. Applying OLS to complex and non-linear algorithms
    might not be scalable, and Gradient Descent can be computationally cheaper (faster)
    for finding the solution. *Gradient Descent is an algorithm that minimizes functions*,
    and given a function defined by a set of parameters, the algorithm starts with
    an initial set of parameter values and iteratively moves toward a set of parameter
    values that minimize the function. This **iterative minimization** is achieved
    using derivatives, taking steps in the negative direction of the function gradient.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该知道，最小二乘法（OLS）并不是拟合线性回归模型的唯一方法，其他优化方法如[**梯度下降**](https://towardsdatascience.com/linear-regression-simplified-ordinary-least-square-vs-gradient-descent-48145de2cf76)更适合拟合大数据集。将OLS应用于复杂和非线性算法可能不具备可扩展性，而梯度下降在找到解时可能计算成本更低（更快）。*梯度下降是一种最小化函数的算法*，在给定一组参数定义的函数时，算法从一组初始参数值开始，迭代地朝向最小化函数的参数值移动。这种**迭代最小化**是通过使用导数来实现的，沿函数梯度的负方向采取步骤。
- en: '![Figure](../Images/cc0df61e5024e01589a2df3a8f32b933.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/cc0df61e5024e01589a2df3a8f32b933.png)'
- en: Linear Regression using Gradient Descent. Source: [Towards Data Science](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用梯度下降的线性回归。来源：[数据科学之路](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931)
- en: Another key thing to take into account is that **outliers can have a dramatic
    effect on regression lines **and the correlation coefficient. In order to identify
    them it’s essential to perform [Exploratory Data Analysis (EDA)](https://towardsdatascience.com/the-basics-of-data-prep-7bb5f3af77ac),
    examining the data to detect unusual observations, since they can impact the results
    of our analysis and statistical modeling in a drastic way. In case you recognize
    any, outliers can be imputed (e.g. with mean / median / mode), capped (replacing
    those outside certain limits), or replaced by missing values and predicted.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的关键点是**离群值可能对回归线**和相关系数产生重大影响。为了识别它们，必须进行[探索性数据分析（EDA）](https://towardsdatascience.com/the-basics-of-data-prep-7bb5f3af77ac)，检查数据以检测异常观察，因为它们可能会对我们的分析和统计建模结果产生极大的影响。如果识别出任何离群值，可以对其进行插补（例如用均值/中位数/众数）、截断（替换超出某些限制的值），或用缺失值和预测值替代。
- en: 'Finally, some [limitations of Linear Regression models](https://www.imf.org/external/pubs/ft/fandd/2006/03/basics.htm) are:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一些[线性回归模型的局限性](https://www.imf.org/external/pubs/ft/fandd/2006/03/basics.htm)包括：
- en: '**Omitted variables**. It is necessary to have a good theoretical model to
    suggest variables that explain the dependent variable. In the case of a simple
    two-variable regression, one has to think of other factors that might explain
    the dependent variable, since there may be other “unobserved” variables that explain
    the output.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗漏变量**。需要有一个良好的理论模型来建议解释因变量的变量。在简单的双变量回归中，必须考虑其他可能解释因变量的因素，因为可能存在其他“未观察到”的变量来解释输出。'
- en: '**Reverse causality**. Many theoretical models predict bidirectional causality
    — that is, a dependent variable can cause changes in one or more explanatory variables.
    For instance, higher earnings may enable people to invest more in their own education,
    which, in turn, raises their earnings. This complicates the way regressions should
    be estimated, calling for special techniques.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向因果关系**。许多理论模型预测双向因果关系——即一个因变量可以引起一个或多个解释变量的变化。例如，较高的收入可能使人们能够在自己的教育上投资更多，这反过来又提高了他们的收入。这使得回归的估计方式变得复杂，需采用特殊技术。'
- en: '**Mismeasurement**. Factors might be measured incorrectly. For example, aptitude
    is difficult to measure, and there are well-known problems with IQ tests. As a
    result, the regression using IQ might not properly control for aptitude, leading
    to inaccurate or biased correlations between variables like education and earnings.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测量误差**。因素可能被错误测量。例如，能力很难测量，而IQ测试存在已知的问题。因此，使用IQ的回归可能无法正确控制能力，从而导致教育和收入等变量之间的相关性不准确或有偏。'
- en: '**Too limited a focus**. A regression coefficient provides information only
    about how small changes — not large changes — in one variable relate to changes
    in another. It will show how a small change in education is likely to affect earnings
    but it will not allow the researcher to generalize about the effect of large changes.
    If everyone became college educated at the same time, a newly minted college graduate
    would be unlikely to earn a great deal more because the total supply of college
    graduates would have increased dramatically.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关注点过于有限**。回归系数仅提供有关一个变量的微小变化如何与另一个变量的变化相关的信息——而非大变化。它会显示教育的小变化如何可能影响收入，但不会使研究者对大变化的影响做出概括。如果每个人同时接受大学教育，新毕业的大学生不太可能赚到更多，因为大学毕业生的总供应量将大幅增加。'
- en: Interested in these topics? Follow me on [Linkedin](https://www.linkedin.com/in/lopezyse/) or [Twitter](https://twitter.com/lopezyse)
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对这些话题感兴趣？关注我在[Linkedin](https://www.linkedin.com/in/lopezyse/)或[Twitter](https://twitter.com/lopezyse)
- en: '**Bio: [Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/)** is an experienced
    professional with a solid international background acquired in different industries
    (capital markets, biotechnology, software, consultancy, government, agriculture).
    Always a team member. Skilled in Business Management, Analytics, Finance, Risk,
    Project Management and Commercial Operations. MS in Data Science and Corporate
    Finance.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Diego Lopez Yse](https://www.linkedin.com/in/lopezyse/)**是一位经验丰富的专业人士，在不同的行业（资本市场、生物技术、软件、咨询、政府、农业）中积累了扎实的国际背景。始终是团队的一员。擅长商业管理、分析、金融、风险、项目管理和商业运营。拥有数据科学和企业金融硕士学位。'
- en: '[Original](https://towardsdatascience.com/your-guide-to-linear-regression-models-df1d847185db).
    Reposted with permission.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/your-guide-to-linear-regression-models-df1d847185db)。经许可转载。'
- en: '**Related:**'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Which methods should be used for solving linear regression?](/2020/09/solving-linear-regression.html)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解决线性回归应使用哪些方法？](/2020/09/solving-linear-regression.html)'
- en: '[Before Probability Distributions](/2020/07/before-probability-distributions.html)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[概率分布之前](/2020/07/before-probability-distributions.html)'
- en: '[Time Complexity: How to measure the efficiency of algorithms](/2020/06/time-complexity-measure-efficiency-algorithms.html)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[时间复杂度：如何衡量算法的效率](/2020/06/time-complexity-measure-efficiency-algorithms.html)'
- en: More On This Topic
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题更多内容
- en: '[3 Reasons Why You Should Use Linear Regression Models Instead of…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用线性回归模型而非…的3个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)'
- en: '[Making Predictions: A Beginner''s Guide to Linear Regression in Python](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[预测：Python中线性回归的初学者指南](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)'
- en: '[Comparing Linear and Logistic Regression](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归的比较](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)'
- en: '[Linear vs Logistic Regression: A Succinct Explanation](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)'
- en: '[KDnuggets News 22:n12, March 23: Best Data Science Books for…](https://www.kdnuggets.com/2022/n12.html)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻 22:n12，3月23日：最佳数据科学书籍…](https://www.kdnuggets.com/2022/n12.html)'
- en: '[Linear Regression for Data Science](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中的线性回归](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)'
