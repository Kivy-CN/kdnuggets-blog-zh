["```py\n#loading test and train data\ntrain = pd.read_csv(‘train.csv’,low_memory=True)\ntest = pd.read_csv(‘test.csv’,low_memory=True)\n```", "```py\n#adding a column to identify whether a row comes from train or not\ntest[‘is_train’] = 0\ntrain[‘is_train’] = 1 \n```", "```py\n#combining test and train data\ndf_combine = pd.concat([train, test], axis=0, ignore_index=True)\n#dropping ‘target’ column as it is not present in the test\ndf_combine = df_combine.drop(‘target’, axis =1)\n```", "```py\ny = df_combine['is_train'].values #labels\nx = df_combine.drop('is_train', axis=1).values #covariates or our independent variables\n```", "```py\ntst, trn = test.values, train.values\n```", "```py\nm = RandomForestClassifier(n_jobs=-1, max_depth=5, min_samples_leaf = 5)\npredictions = np.zeros(y.shape) #creating an empty prediction array\n```", "```py\nskf = SKF(n_splits=20, shuffle=True, random_state=100)\nfor fold, (train_idx, test_idx) in enumerate(skf.split(x, y)):\n X_train, X_test = x[train_idx], x[test_idx]\n y_train, y_test = y[train_idx], y[test_idx]\n\n m.fit(X_train, y_train)\n probs = m.predict_proba(X_test)[:, 1] #calculating the probability\n predictions[test_idx] = probs\n```", "```py\nprint(‘ROC-AUC for train and test distributions:’, AUC(y, predictions))\n```", "```py\n# ROC-AUC for train and test distributions: 0.49944573868\n```", "```py\npredictions[:10]\n----output-----\n```", "```py\narray([ 0.34593171])\n```", "```py\nplt.figure(figsize=(20,5))\npredictions_train = predictions[len(tst):] #filtering the actual training rows\nweights = (1./predictions_train) — 1\\. \nweights /= np.mean(weights) # Normalizing the weights\n```", "```py\nplt.xlabel(‘Computed sample weight’)\nplt.ylabel(‘# Samples’)\nsns.distplot(weights, kde=False)\n```", "```py\nm = RandomForestClassifier(n_jobs=-1,max_depth=5)\n```", "```py\nm.fit(X_train, y_train, *sample_weight=weights*)\n```"]