# 如何在第一次 Kaggle 竞赛中排名前10%

> 原文：[https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3](https://www.kdnuggets.com/2016/11/rank-ten-precent-first-kaggle-competition.html/3)

**模型训练**

我们可以通过调整模型的参数来提升模型的性能。一个模型通常有很多参数，但其中只有少数几个对其性能有显著影响。例如，随机森林最重要的参数是森林中树的数量以及在每棵树的构建中使用的最大特征数量。**我们需要了解模型的工作原理以及每个参数对模型性能的影响，无论是准确性、鲁棒性还是速度。**

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT 需求

* * *

通常我们会通过一种叫做**[网格搜索](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html))**的过程找到最佳参数集。实际上，它的工作原理是通过遍历所有可能的组合来找到最佳的一个。

顺便提一下，当`max_features`设置为特征总数的平方根时，随机森林通常会达到最佳效果。

在这里，我想强调一些关于调整 XGB 的要点。这些参数通常被认为对其性能有实际影响：

+   `eta`：用于更新权重的步长。较低的`eta`意味着训练较慢但收敛效果更好。

+   `num_round`：总的迭代次数。

+   `subsample`：每次迭代中使用的训练数据比例。这是为了防止过拟合。

+   `colsample_bytree`：每次迭代中使用的特征比例。这类似于`RandomForestClassifier`中的`max_features`。

+   `max_depth`：每棵树的最大深度。与随机森林不同，**梯度提升如果不限制其深度最终会出现过拟合**。

+   `early_stopping_rounds`：如果在给定次数的迭代中没有看到验证分数的提高，算法将提前停止。这也是为了防止过拟合。

通常的调整步骤：

1.  将一部分训练集保留为验证集。

1.  将`eta`设置为相对较高的值（例如0.05 ~ 0.1），将`num_round`设置为300 ~ 500。

1.  使用网格搜索找到其他参数的最佳组合。

1.  逐渐降低`eta`直到达到最佳值。

1.  **使用验证集作为`watch_list`重新训练模型，并使用最佳参数。观察每次迭代中验证集上的得分变化。找到`early_stopping_rounds`的最佳值。**

最后，请注意，所有具有随机性的模型都有一个像`seed`或`random_state`这样的参数来控制随机种子。**在获得好的模型时，你必须记录这个参数**及所有其他参数。否则你将无法重现它。

**交叉验证**

**[交叉验证](https://en.wikipedia.org/wiki/Cross-validation_(statistics))**是在模型训练中的一个重要步骤。它告诉我们模型是否有较高的过拟合风险。在许多竞赛中，公共LB得分并不可靠。经常在我们改进模型并获得更好的本地CV得分时，LB得分反而变差。**在这种情况下，人们普遍认为我们应该相信我们的CV得分。**理想情况下，我们希望**不同方法获得的CV得分与LB得分同步提高**，但这并不总是可能的。

通常**5折交叉验证**已经足够好。如果使用更多折数，CV得分会变得更可靠，但训练也需要更长时间。然而，如果我们的训练数据有限，就不应该使用过多的折数，否则每折中的样本数量过少，无法保证统计显著性。

如何正确进行交叉验证并非小事。这需要不断的实验和逐案讨论。许多Kaggler在竞赛后分享他们的CV方法（如[这个](https://www.kaggle.com/c/telstra-recruiting-network/forums/t/19277/what-is-your-cross-validation-method)），因为他们觉得可靠的CV并不容易。

**集成生成**

[集成学习](https://en.wikipedia.org/wiki/Ensemble_learning)指的是将不同模型组合在一起的技术。它**降低了最终模型的偏差和方差**（你可以在[这里](http://link.springer.com/chapter/10.1007%2F3-540-33019-4_19)找到证明），从而**提高了得分并减少了过拟合的风险**。最近，没有使用集成方法几乎不可能在Kaggle竞赛中获胜。

常见的集成学习方法包括：

+   **装袋**：使用训练数据的不同随机子集训练每个基础模型。然后，所有基础模型投票生成最终预测。这就是随机森林的工作原理。

+   **提升**：迭代地训练基础模型，根据上一轮的结果调整训练样本的权重。这就是梯度提升树的工作原理。（实际上，这并不是全部。除了提升，GBT还尝试学习早期迭代的残差。）它的表现优于装袋，但更容易过拟合。

+   **混合**：使用非重叠的数据训练不同的基础模型，并对它们取加权平均以获得最终预测。这种方法实现简单，但使用的数据较少。

+   **堆叠**：将在接下来的内容中讨论。

从理论上讲，为了使集成表现良好，两个因素很重要：

+   **基础模型应该尽可能不相关**。这就是为什么我们倾向于在集成中包含非树模型，即使它们的表现不如树模型。数学上说，最终集成的多样性越大，偏差越小。

+   **基础模型的性能不应差异过大。**

实际上，我们在这里有一个**权衡**。在实践中，我们可能会得到性能相当的高度相关模型。然而，我们仍然将它们进行集成，因为这通常会提高整体性能。

**堆叠**

与混合方法相比，堆叠方法更好地利用了训练数据。以下是它如何工作的示意图：

[![堆叠](../Images/fb2fd03a6a8cf5851969a1254b354966.png)](http://7xlo8f.com1.z0.glb.clouddn.com/blog-diagram-stacking.jpg)

*(摘自 [Faron](https://www.kaggle.com/mmueller)。非常感谢！)*

这很像交叉验证。以5折堆叠为例。首先，我们将训练数据分成5个折。接下来我们将进行5次迭代。在每次迭代中，训练每个基础模型在4个折上，并在保留折上进行预测。**你还需要保持对测试数据的预测。**这样，在每次迭代中，每个基础模型都会对训练数据的1个折和所有的测试数据进行预测。经过5次迭代后，我们将得到一个形状为`#(训练数据中的样本数) X #(基础模型)`的矩阵。然后将这个矩阵传递给第二层的堆叠器（这只是另一个模型）。堆叠器拟合后，使用基础模型对测试数据的预测（**每个基础模型被训练了5次，因此我们必须取平均值以获得相同形状的矩阵**）作为堆叠器的输入，从而获得最终预测结果。

也许直接展示代码更好：

奖品获得者通常有更大、更复杂的集成。对于初学者来说，实现一个正确的5折堆叠已经足够了。

***管道***

我们可以看到，Kaggle竞赛的工作流程非常复杂，特别是在模型选择和集成方面。理想情况下，我们需要一个高度自动化的流程，能够：

+   **模块化特征转换**。我们只需编写几行代码（或者更好，使用规则/DSLs），新特征就会被添加到训练集中。

+   **自动化网格搜索**。我们只需要设置模型和参数网格，搜索将被执行，最佳参数将被记录。

+   **自动化的集成选择**。当我们将另一个基础模型添加到池中时，使用K个最佳模型进行集成训练。

对于初学者来说，第一个并不是很重要，因为特征数量是相对可管理的；第三个也不重要，因为通常我们只在竞赛结束时进行几次集成。但第二个很有用，因为**手动记录每个模型的性能和参数既耗时又容易出错**。

[陈成龙](https://www.kaggle.com/chenglongchen)，[Crowdflower 搜索结果相关性](https://www.kaggle.com/c/crowdflower-search-relevance)的获胜者，曾在[GitHub](https://github.com/ChenglongChen/Kaggle_CrowdFlower)上发布了他的管道。它非常完整且高效。但理解并提取他的所有逻辑来构建通用框架非常困难。这是你在有充足时间时可能想要做的事情。

### 更多相关内容

+   [LinkedIn 如何使用机器学习来排序你的动态](https://www.kdnuggets.com/2022/11/linkedin-uses-machine-learning-rank-feed.html)

+   [如何在没有任何工作经验的情况下获得你的第一个数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [使用 TensorFlow 和 Keras 构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [它活过来了！用 Python 和一些便宜的……构建你的第一个机器人](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)

+   [从零到英雄：使用 PyTorch 创建你的第一个 ML 模型](https://www.kdnuggets.com/from-zero-to-hero-create-your-first-ml-model-with-pytorch)

+   [部署你的第一个机器学习模型](https://www.kdnuggets.com/deploying-your-first-machine-learning-model)
