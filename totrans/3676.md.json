["```py\n!openai api fine_tunes.create -t \"train_prepared.jsonl\" -v \"test_prepared.jsonl\" --compute_classification_metrics --classification_n_classes 3 -m davinci \n--suffix \"baseline\"\n\n>>> Created fine-tune: ft-9800F2gcVNzyMdTLKcMqAtJ5\n```", "```py\n!openai api fine_tunes.results -i ft-9800F2gcVNzyMdTLKcMqAtJ5 > baseline.csv\n\ndf = pd.read_csv('baseline.csv')\nbaseline_acc = df.iloc[-1]['classification/accuracy']\n\n>>> Fine-tuning Accuracy: 0.6312500238418579\n```", "```py\n# Get embeddings from OpenAI.\nfrom openai.embeddings_utils import get_embedding\n\nembedding_model = \"text-similarity-davinci-001\"\ntrain[\"embedding\"] = train.prompt.apply(lambda x: get_embedding(x, engine=embedding_model))\nembeddings = train[\"embedding\"].values\n\n# Get out-of-sample predicted class probabilities via cross-validation.\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nlabels = train[\"completion\"].values\npred_probs = cross_val_predict(estimator=model, X=embeddings, y=labels, \t\t                   cv=10, method=\"predict_proba\")\n```", "```py\nfrom cleanlab.filter import find_label_issues\n\n# Get indices of examples estimated to have label issues:\nissue_idx = find_label_issues(labels, pred_probs,\n            return_indices_ranked_by='self_confidence')  # sort indices by likelihood of label error \n```", "```py\n# Remove data flagged with potential label error. \ntrain_cl = train.drop(issue_idx).reset_index(drop=True)\nformat_data(train_cl, \"train_cl.jsonl\")\n\n# Train a more robust classifier with less erroneous data.\n!openai api fine_tunes.create -t \"train_cl_prepared.jsonl\" -v \"test_prepared.jsonl\" --compute_classification_metrics --classification_n_classes 3 -m davinci --suffix \"dropped\"\n\n# Evaluate model on test data.\n!openai api fine_tunes.results -i ft-InhTRQGu11gIDlVJUt0LYbEx > autofiltered.csv\ndf = pd.read_csv('autofiltered.csv')\ndropped_acc = df.iloc[-1]['classification/accuracy']\n\n>>> 0.6604166626930237\n```", "```py\n# Load in and format data with the manually fixed labels.\ntrain_studio = pd.read_csv('train_corrected.csv')\nformat_data(train_studio, \"train_corrected.jsonl\")\n\n# Train a more robust classifier with the fixed data.\n!openai api fine_tunes.create -t \"train_corrected_prepared.jsonl\" -v \"test_prepared.jsonl\" \n--compute_classification_metrics --classification_n_classes 3 -m davinci --suffix \"corrected\"\n\n# Evaluate model on test data.\n!openai api fine_tunes.results -i ft-MQbaduYd8UGD2EWBmfpoQpkQ > corrected .csv\ndf = pd.read_csv('corrected.csv')\ncorrected_acc = df.iloc[-1]['classification/accuracy']\n>>> 0.7729166746139526\n```"]