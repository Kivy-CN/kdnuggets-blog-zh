["```py\n$ curl -fsSL https://ollama.com/install.sh | sh\n```", "```py\n$ ollama pull gemma:2b\n```", "```py\n$ ollama run gemma:2b\n```", "```py\n>>> /set system For all questions asked answer in plain English avoiding technical jargon as much as possible\nSet system message.\n>>> /save ipe\nCreated new model 'ipe'\n>>> /bye\n```", "```py\n$ ollama run ipe\n```", "```py\n$ pip install ollama\n```", "```py\nimport ollama\n\nresponse = ollama.generate(model='gemma:2b',\nprompt='what is a qubit?')\nprint(response['response'])\n```", "```py\n$ pip install langchain\n```", "```py\nfrom langchain_community.llms import Ollama\n\nllm = Ollama(model=\"llama2\")\n\nllm.invoke(\"tell me about partial functions in python\")\n```"]