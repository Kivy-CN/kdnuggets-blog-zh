- en: A Concise Overview of Standard Model-fitting Methods
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html](https://www.kdnuggets.com/2016/05/concise-overview-model-fitting-methods.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In order to explain the differences between alternative approaches to estimating
    the parameters of a model, let''s take a look at a concrete example: Ordinary
    Least Squares (OLS) Linear Regression. The illustration below shall serve as a
    quick reminder to recall the different components of a simple linear regression
    model:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Simple regresion](../Images/021416dd372001b2ebcefd88bc666f0c.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: In Ordinary Least Squares (OLS) Linear Regression, our goal is to find the line
    (or hyperplane) that minimizes the vertical offsets. Or, in other words, we define
    the best-fitting line as the line that minimizes the sum of squared errors (SSE)
    or mean squared error (MSE) between our target variable (y) and our predicted
    output over all samples *i* in our dataset of size *n*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![SSE](../Images/fd700aecb123fddccbe1855cb4f39dc2.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can implement a linear regression model for performing ordinary least
    squares regression using one of the following approaches:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Solving the model parameters analytically (closed-form equations)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent,
    Newton's Method, Simplex Method, etc.)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1) Normal Equations (closed-form solution)
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The closed-form solution may (should) be preferred for "smaller" datasets --
    if computing (a "costly") matrix inverse is not a concern. For very large datasets,
    or datasets where the inverse of XTX may not exist (the matrix is non-invertible
    or singular, e.g., in case of perfect multicollinearity), the GD or SGD approaches
    are to be preferred. The linear function (linear regression model) is defined
    as:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear model](../Images/18f72e806df0ea656621fbaa5fcd6263.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: 'where *y* is the response variable, *x* is an *m*-dimensional sample vector,
    and *w* is the weight vector (vector of coefficients). Note that *w0* represents
    the y-axis intercept of the model and therefore *x0=1*. Using the closed-form
    solution (normal equation), we compute the weights of the model as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![Closed form](../Images/390bdb586f5ea1904be897034215580a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: 2) Gradient Descent (GD)
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the Gradient Decent (GD) optimization algorithm, the weights are updated
    incrementally after each epoch (= pass over the training dataset).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'The cost function *J(⋅)*, the sum of squared errors (SSE), can be written as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![J](../Images/9971ba71f72a930fafe670ba77d3c459.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: The magnitude and direction of the weight update is computed by taking a step
    in the opposite direction of the cost gradient
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![dw](../Images/2a8a0c5f09633d23aa090c7a43d83736.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: 'where *η* is the learning rate. The weights are then updated after each epoch
    via the following update rule:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![w_upd](../Images/97ab06d282b695cae3a47b50bd05bbdd.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: 'where Δw is a vector that contains the weight updates of each weight coefficient *w*,
    which are computed as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 Δw 是一个包含每个权重系数*w*的权重更新的向量，计算方法如下：
- en: '![w_upd explained](../Images/b17273c5b1d049e3c2a73f800eb790f8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![w_upd 解释](../Images/b17273c5b1d049e3c2a73f800eb790f8.png)'
- en: 'Essentially, we can picture GD optimization as a hiker (the weight coefficient)
    who wants to climb down a mountain (cost function) into a valley (cost minimum),
    and each step is determined by the steepness of the slope (gradient) and the leg
    length of the hiker (learning rate). Considering a cost function with only a single
    weight coefficient, we can illustrate this concept as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们可以将GD优化想象成一个想要从山顶（成本函数）爬下到山谷（成本最小值）的徒步旅行者（权重系数），每一步都由斜率（梯度）和旅行者的腿长（学习率）决定。考虑一个只有一个权重系数的成本函数，我们可以如下说明这一概念：
- en: '![GD optimization](../Images/9ad85c8821ba0a5eef7027278d573d00.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![GD优化](../Images/9ad85c8821ba0a5eef7027278d573d00.png)'
- en: '* * *'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Removing Outliers Using Standard Deviation in Python](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用标准差在Python中去除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)'
- en: '[Developing an Open Standard for Analytics Tracking](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开发用于分析跟踪的开放标准](https://www.kdnuggets.com/2022/07/developing-open-standard-analytics-tracking.html)'
- en: '[Centroid Initialization Methods for k-means Clustering](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[k-means聚类的质心初始化方法](https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html)'
- en: '[Alternative Feature Selection Methods in Machine Learning](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的替代特征选择方法](https://www.kdnuggets.com/2021/12/alternative-feature-selection-methods-machine-learning.html)'
- en: '[Python String Methods](https://www.kdnuggets.com/2022/12/python-string-methods.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python字符串方法](https://www.kdnuggets.com/2022/12/python-string-methods.html)'
- en: '[11 Python Magic Methods Every Programmer Should Know](https://www.kdnuggets.com/11-python-magic-methods-every-programmer-should-know)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个程序员都应该知道的11个Python魔法方法](https://www.kdnuggets.com/11-python-magic-methods-every-programmer-should-know)'
