- en: 7 More Steps to Mastering Machine Learning With Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握Python机器学习的7个额外步骤
- en: 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)
- en: So, you have been thinking about picking up machine learning, but given the
    confusing state of the web you don't know where to begin? Or maybe you have finished
    [the first 7 steps](/2015/11/seven-steps-machine-learning-python.html) and are
    looking for some follow-up material, beyond the introductory?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，你一直在考虑学习机器学习，但由于网络上的混乱状态，你不知道从哪里开始？或者也许你已经完成了[前7步](/2015/11/seven-steps-machine-learning-python.html)，现在在寻找一些进一步的材料，超越基础介绍？
- en: '![Machine learning algorithms](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![机器学习算法](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)'
- en: Machine learning algorithms.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法。
- en: This post is the second installment of the [7 Steps to Mastering Machine Learning
    in Python](/2015/11/seven-steps-machine-learning-python.html) series (since there
    are 2 parts, I guess it now qualifies as a series). If you have started with the
    [original post](/2015/11/seven-steps-machine-learning-python.html), you should
    already be satisfactorily up to speed, skill-wise. If not, you may want to review
    that post first, which may take some time, depending on your current level of
    understanding; however, I assure you that doing so will be worth your effort.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是[掌握Python机器学习的7个步骤](/2015/11/seven-steps-machine-learning-python.html)系列的第二部分（既然有两部分，我想现在可以算作一个系列）。如果你已经从[原始文章](/2015/11/seven-steps-machine-learning-python.html)开始，你应该已经在技能上有了满意的进展。如果没有，你可能需要先回顾那篇文章，这可能需要一些时间，具体取决于你当前的理解水平；不过，我保证这样做会值得你付出的努力。
- en: After a quick review -- and a few options for a fresh perspective -- this post
    will focus more categorically on several sets of related machine learning tasks.
    Since we can safely skip the foundational modules this time around -- Python basics,
    machine learning basics, etc. -- we will jump right into the various machine learning
    algorithms. We can also categorize our tutorials better along functional lines
    this time.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速回顾和几种新视角的选项之后，这篇文章将更具分类地关注几组相关的机器学习任务。由于这次我们可以安全地跳过基础模块——Python基础、机器学习基础等——我们将直接进入各种机器学习算法。这次我们也可以更好地按功能线分类我们的教程。
- en: I will, once again, state that the material contained herein is all freely available
    on the web, and all rights and recognition for the works belong to their original
    authors. If something has not been properly attributed, please feel free to [let
    me know](https://twitter.com/mattmayo13).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我再次声明，本材料中包含的所有内容均可在网络上免费获取，所有权利和对作品的认可归原作者所有。如果有任何内容未被正确归属，请随时[告诉我](https://twitter.com/mattmayo13)。
- en: 'Step 1: Machine Learning Basics Review & A Fresh Perspective'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：机器学习基础回顾及新视角
- en: 'Just to review, these are the steps covered in the [original post](/2015/11/seven-steps-machine-learning-python.html):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 只是为了回顾，这些是[原始文章](/2015/11/seven-steps-machine-learning-python.html)中涵盖的步骤：
- en: Basic Python Skills
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础Python技能
- en: Foundational Machine Learning Skills
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器学习基础技能
- en: Scientific Python Packages Overview
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 科学Python包概述
- en: 'Getting Started with Machine Learning in Python: Introduction & model evaluation'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python进行机器学习入门：介绍及模型评估
- en: 'Machine Learning Topics with Python: k-means clustering, decision trees, linear
    regression & logistic regression'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python的机器学习主题：k-means聚类、决策树、线性回归与逻辑回归
- en: 'Advanced Machine Learning Topics with Python: Support vector machines, random
    forests, dimension reduction with PCA'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python的高级机器学习主题：支持向量机、随机森林、PCA降维
- en: Deep Learning in Python
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python中的深度学习
- en: As stated above, if you are looking to start from square one, I would suggest
    going back to the first article and proceeding accordingly. I will also note that
    the appropriate *getting started* material, including any and all installation
    instructions, are including in the previous article.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，如果你打算从头开始，我建议回到第一篇文章并按顺序进行。我还要指出，适当的*入门*材料，包括所有安装说明，均包含在前一篇文章中。
- en: 'If, however, you are really green, I would start with the following, covering
    the absolute basics:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，如果你真的很陌生，我建议从以下内容入手，涵盖最基本的知识：
- en: '[Machine Learning Key Terms, Explained](/2016/05/machine-learning-key-terms-explained.html),
    by Matthew Mayo'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Statistical Classification on Wikipedia](https://en.wikipedia.org/wiki/Statistical_classification)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html),
    by Alex Castrounis'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are looking for some alternative or complementary approaches to learning
    the basics of machine learning, I have recently been enjoying Shai Ben-David''s
    video lectures and freely available textbook written with Shai Shalev-Shwartz.
    Find them both here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[Shai Ben-David''s introductory machine learning video lectures](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm),
    University of Waterloo'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html),
    by Shai Ben-David & Shai Shalev-Shwartz'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, the introductory material does not all need to be digested before
    moving forward with the rest of the steps (in either this post or the original).
    Video lectures, texts, and other resources can be consulted when implementing
    models using the reflected machine learning algorithms, or when applicable concepts
    are being used practically in subsequent steps. Use your judgment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: More Classification'
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We begin with the new material by first strengthening our classification know-how
    and introducing a few additional algorithms. While part 1 of our post covered
    decision trees, support vector machines, and logistic regression -- as well as
    the ensemble classifier Random Forests -- we will add k-nearest neighbors, the
    Naive Bayes classier, and a multilayer perceptron into the mix.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '![Scikit-learn classifiers](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
- en: Scikit-learn classifiers.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**k-nearest neighbors (kNN)** is a simple classifier and an example of a lazy
    learner, in which all computation occurs at classification time (as opposed to
    occurring during a training step ahead of time). kNN is [non-parametric](https://en.wikipedia.org/wiki/Nonparametric_statistics),
    and functions by comparing a data instance with the *k* closest instances when
    making decisions about how it should be classified.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[K-Nearest Neighbor classification using python](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Naive Bayes** is a classifier based on [Bayes'' Theorem](https://en.wikipedia.org/wiki/Bayes''_theorem).
    It assumes that there is independence among features, and that the presence of
    any particular feature in one class is not related to any other feature''s presence
    in the same class.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[Document Classification with scikit-learn](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html),
    by Zac Stewart'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **multilayer perceptron (MLP)** is a simple [feedforward](https://en.wikipedia.org/wiki/Feedforward_neural_network)
    neural network, consisting of multiple layers of nodes, where each layer is fully
    connected with the layer which comes after it. The MLP was introduced in Scikit-learn
    version 0.18.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**多层感知器（MLP）** 是一种简单的 [前馈](https://en.wikipedia.org/wiki/Feedforward_neural_network)
    神经网络，由多个层的节点组成，每一层与其后续层完全连接。MLP 在 Scikit-learn 版本 0.18 中引入。'
- en: First read an overview of the MLP classifier from the Scikit-learn documentation,
    and then practice implementation with a tutorial.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读 Scikit-learn 文档中关于 MLP 分类器的概述，然后通过教程进行实践。
- en: '[Neural network models (supervised)](http://scikit-learn.org/stable/modules/neural_networks_supervised.html),
    Scikit-learn documentation'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[神经网络模型（监督学习）](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)，Scikit-learn
    文档'
- en: '[A Beginner’s Guide to Neural Networks with Python and SciKit Learn 0.18!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html),
    by Jose Portilla'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 和 SciKit Learn 0.18 的初学者指南!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html)，由
    Jose Portilla 编写'
- en: 'Step 3: More Clustering'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步：更多聚类
- en: We now move on to clustering, a form of unsupervised learning. In the first
    post we covered the k-means algorithm; we will introduce DBSCAN and Expectation-maximization
    (EM) herein.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在转向聚类，一种无监督学习的形式。在第一篇文章中，我们介绍了 k-means 算法；在此我们将介绍 DBSCAN 和期望最大化（EM）。
- en: '![Scikit-learn clustering algorithms](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![Scikit-learn 聚类算法](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)'
- en: Scikit-learn clustering algorithms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 聚类算法。
- en: 'First off, read these introductory posts; the first is a quick comparison of
    k-means and EM clustering techniques, a nice segue into new forms of clustering,
    and the second is an overview of clustering techniques available in Scikit-learn:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读这些介绍性的帖子；第一个是 k-means 和 EM 聚类技术的快速比较，是进入新聚类形式的良好过渡，第二个是 Scikit-learn 中可用聚类技术的概述：
- en: '[Comparing Clustering Techniques: A Concise Technical Overview](/2016/09/comparing-clustering-techniques-concise-technical-overview.html),
    by Matthew Mayo'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[聚类技术比较：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)，由
    Matthew Mayo 编写'
- en: '[Comparing different clustering algorithms on toy datasets](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html),
    Scikit-learn documentation'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在玩具数据集上比较不同的聚类算法](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)，Scikit-learn
    文档'
- en: '**Expectation-maximization (EM)** is a probabilistic clustering algorithm,
    and, as such, involves determining the probabilities that instances belong to
    particular clusters. EM ”approaches maximum likelihood or maximum a posteriori
    estimates of parameters in statistical models” (Han, Kamber & Pei). The EM process
    begins with a set of parameters, iterating until clustering is maximized, with
    respect to *k* clusters.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**期望最大化（EM）**是一种概率聚类算法，因此涉及确定实例属于特定簇的概率。EM “接近统计模型中参数的最大似然或最大后验估计”（Han, Kamber
    & Pei）。EM 过程从一组参数开始，迭代直到在 *k* 个簇下最大化聚类效果。'
- en: First read a tutorial on the EM algorithm. Next, have a look at the relevant
    Scikit-learn documentation. Finally, follow a tutorial and implement EM clustering
    yourself with Python.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读有关 EM 算法的教程。接着，查看相关的 Scikit-learn 文档。最后，跟随教程使用 Python 实现 EM 聚类。
- en: '[A Tutorial on the Expectation Maximization (EM) Algorithm](/2016/08/tutorial-expectation-maximization-algorithm.html),
    by Elena Sharova'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[期望最大化（EM）算法教程](/2016/08/tutorial-expectation-maximization-algorithm.html)，由
    Elena Sharova 编写'
- en: '[Gaussian mixture models](http://scikit-learn.org/stable/modules/mixture.html),
    Scikit-learn documentation'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高斯混合模型](http://scikit-learn.org/stable/modules/mixture.html)，Scikit-learn
    文档'
- en: '[Quick introduction to gaussian mixture models with Python](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/),
    by Tiago Ramalho'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 进行高斯混合模型的快速介绍](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/)，Tiago
    Ramalho 编写'
- en: 'If "[Gaussian mixture models](https://en.wikipedia.org/wiki/Mixture_model)"
    is confusing at first glance, this relevant section from the Scikit-learn documentation
    should alleviate any unnecessary worries:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 "[高斯混合模型](https://en.wikipedia.org/wiki/Mixture_model)" 一开始让人感到困惑，Scikit-learn
    文档中的相关部分应该可以减轻任何不必要的担忧：
- en: The `GaussianMixture` object implements the expectation-maximization (EM) algorithm
    for fitting mixture-of-Gaussian models.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`GaussianMixture` 对象实现了用于拟合高斯混合模型的期望最大化（EM）算法。'
- en: '**Density-based spatial clustering of applications with noise (DBSCAN)** operates
    by grouping densely-packed data points together, and designating low-density data
    points as outliers.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于密度的空间聚类算法（DBSCAN）** 通过将密集的数据点分组在一起，并将低密度的数据点指定为异常值来运行。'
- en: 'First read and follow an example implementation of DBSCAN from Scikit-learn''s
    documentation, and then follow a concise tutorial:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先阅读并遵循 Scikit-learn 文档中的 DBSCAN 示例实现，然后跟随一个简明的教程：
- en: '[Demo of DBSCAN clustering algorithm](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html),
    Scikit-learn documentation'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DBSCAN 聚类算法演示](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)，Scikit-learn
    文档'
- en: '[Density-based clustering algorithm (DBSCAN) and Implementation](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于密度的聚类算法（DBSCAN）及其实现](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 领域'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创企业的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，然后找到目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
