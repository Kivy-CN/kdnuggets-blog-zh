# 机器学习以88%的准确率发现“假新闻”

> 原文：[https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html](https://www.kdnuggets.com/2017/04/machine-learning-fake-news-accuracy.html)

**乔治·麦金太尔，数据科学撰稿人，ODSC**

![特朗普](../Images/c4c806c5213c7410a605b76b4daa4706.png)

> ### “谎言在真相来得及穿上裤子之前已经绕了半个地球。”
> ### 
> * * *
> 
> ## 我们的前三大课程推荐
> ## 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道
> 
> ![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能
> 
> ![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT需求
> 
> * * *
> 
> – 温斯顿·丘吉尔

自2016年总统选举以来，政治话语中主导的话题之一是“假新闻”问题。许多政治评论员声称，显著偏见和/或不真实新闻的兴起影响了选举，尽管[斯坦福大学和纽约大学的研究者](http://thehill.com/homenews/media/317646-fake-news-did-not-change-result-of-2016-election-study)得出了不同的结论。尽管如此，虚假新闻帖子已经利用Facebook用户的动态在互联网上传播。

****“什么是假新闻？”****

显然，有意误导的故事是“假新闻”，但最近喧嚣的社交媒体话语正在改变其定义。有些人现在用这个术语来驳斥与他们偏好观点相反的事实，最显著的例子是[特朗普总统](https://twitter.com/search?q=fake%20news%20from%3Arealdonaldtrump&src=typd)。这样的模糊定义的术语容易受到愤世嫉俗的操控。

数据科学社区已回应，通过[采取行动解决问题](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/)。有一个类似Kaggle的比赛叫做“[假新闻挑战](http://www.fakenewschallenge.org/)”，而[Facebook正在使用人工智能](https://techcrunch.com/2016/11/14/facebook-fake-news/)来过滤用户动态中的虚假新闻。对抗虚假新闻是一个经典的文本分类项目，提出了一个直接的问题：***你能否建立一个模型来区分“真实”新闻与“虚假”新闻？***

这正是我在这个项目中所尝试做的。我组建了一个包含虚假和真实新闻的数据集，并使用了[朴素贝叶斯](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)分类器，以创建一个模型，根据文章的词汇和短语将其分类为虚假或真实。

### 数据收集/整理

数据获取过程分为两个部分：获取“假新闻”和获取真实新闻。第一部分很快完成，Kaggle 发布了一个 [假新闻数据集](https://www.kaggle.com/mrisdal/fake-news)，包括13000篇在2016年选举周期内发布的文章。

第二部分就…困难得多。为了获取数据集中的真实新闻部分，我转向了 [All Sides](http://www.allsides.com/)，一个致力于发布来自不同政治立场的新闻和意见文章的网站。网站上的文章按主题（环境、经济、堕胎等）和政治倾向（左、中、右）进行分类。我使用 All Sides 是因为这是从众多媒体渠道中抓取数千篇文章的最佳方法。此外，它允许我下载文章的完整文本，而这是纽约时报和 NPR API 无法做到的。在经过漫长而艰难的过程后，我最终抓取了 **5279 篇文章**。我的真实新闻数据集中的文章来自于纽约时报、华尔街日报、彭博社、NPR 和卫报等媒体组织，并且这些文章的发布时间为2015年或2016年。

我决定将我的完整数据集构建为假新闻和真实新闻各占一半，从而使我的模型的无效准确率为50%。我随机从假新闻数据集中选择了5279篇文章用于我的完整数据集，其余的文章则保留作为模型完成后的测试集。

我的最终数据集包含了总共10558篇文章，包括它们的标题、全文和标签（真实与虚假）。这些数据可以在这个 [github repo](https://github.com/GeorgeMcIntire/fake_real_news_dataset) 中找到。

### 目的与期望

当我刚开始这个项目时，我承认这不会是一个完美的项目。这个项目的目的是看看我能在创建假新闻分类模型上取得多大进展，以及从中能获得什么见解，然后用这些见解改进模型。我的计划是将这个项目当作一个常规的垃圾邮件检测项目来处理。

基于计数向量化器（使用词频）或 tfidf 矩阵（词频相对于在数据集中其他文章中的使用频率）构建模型只能达到一定程度。这些方法并未考虑重要的特性，如词序和上下文。两个在词频上类似的文章可能在意义上完全不同。我并不期望我的模型能够很好地处理词语和短语重叠的假新闻和真实新闻。不过，我期待从这个项目中获得一些有价值的见解。

### 建模

由于这是一个文本分类项目，我仅使用了朴素贝叶斯分类器，这在基于文本的数据科学项目中是标准做法。

制定模型的真正工作是文本转换（`count vectorizer`与`tfidf vectorizer`）和选择使用哪种类型的文本（标题与全文）。这给了我四对重新配置的数据集来处理。

下一步是确定`countvectorizer`或`tfidf-vectorizer`的最优参数。对于那些不熟悉文本机器学习的人，这意味着使用最常见的`n`个单词，使用单词和/或短语，是否转换为小写，去除停用词（例如“the”、“when”和“there”等常见词），以及仅使用在文本语料库中出现至少给定次数的单词（语料库是文本数据集或文本集合的术语）。

为了测试多个参数及其各种组合的性能，我利用了Sci-kit Learn的GridSearch功能来高效地执行此任务。要了解如何优化算法参数，请查看[这个教程](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)。

在网格搜索交叉验证过程之后，我发现我的模型在`count vectorizer`上表现最佳，而不是在`tfidf`上，并且在训练于文章全文时比在标题上得分更高。`count vectorizer`的最优参数是：不转换为小写，使用双词短语而不是单词，并且只使用在语料库中出现至少三次的单词。

根据我在这篇文章中之前概述的期望，我对我的模型所产生的高分感到惊讶甚至困惑。我的模型的交叉验证准确率为91.7%，召回率（真正阳性率）为92.6%，AUC评分为95%。

这是我模型的ROC曲线。

[![ROC 曲线](../Images/b0c30a0271a9fcb5833e5eb51493fb96.png)](https://opendatascience.com/wp-content/uploads/2017/02/roccurve.png)

如果我根据这个图表为模型选择一个阈值，我会选择一个在0.08左右产生假阳性率（FPR）和0.90左右产生真正阳性率（TPR）的阈值，因为在图表的那个点上，假阳性和真正阳性的权衡是相等的。

### 结果与结论

对我的模型质量的真正考验将是看看它能否准确分类测试集中（那些未用于创建我的模型的）假新闻文章。

**在5234篇其他假新闻数据集中，我的模型能够正确识别88.2%的假新闻。** 这比我的交叉验证准确率低了3.5个百分点，但在我看来，这是对我的模型相当不错的评估。

结果证明我预测模型在分类新闻文章时会遇到困难的假设是错误的。我原以为准确率在60多岁或70多岁就已经很出色，但我成功地超越了这个预期。

尽管我创建了一个在任务复杂性面前看起来相当不错的模型，但我并不完全相信它看起来那么好，原因如下。

为了更好地理解为什么会发生这种情况，我们来看一下数据中“最虚假”和“最真实”的词汇——我会解释我所说的含义。

使用我从Data School的Kevin Markham那里借用的一种技术，以下是我如何得出语料库中的“最虚假”和“最真实”词汇的。首先，我创建了一个两列宽、10558行长的表格（这是语料库中的词汇数量）。第一列表示某个词在被分类为“虚假”的文章中出现的次数，第二列则是该词在“真实”文章中出现的次数。接着，我将虚假列的数值除以我模型分类的虚假文章总数，真实列也是如此。然后，我在数据中的每个值上加了1，因为我创建了一个新的“虚假:真实”比率列，并且不希望因为除以零而出现错误。这个“虚假:真实”比率是一个相当不错但并非完美的指标，用来衡量一个词汇的“虚假”或“真实”程度。逻辑很简单，如果一个词汇在“虚假”文章中频繁出现，而在“真实”文章中很少出现，那么它的虚假对真实比率得分将会很高。

下面是我的数据集中前20个“最虚假”和“最真实”的词汇。

[![最虚假](../Images/b612bacbe492de1d0b4462ef3be8c9eb.png)](https://opendatascience.com/wp-content/uploads/2017/02/fakestwords.png)

[![最真实](../Images/d2c2c7786cb06420a522ead6632c9b0d.png)](https://opendatascience.com/wp-content/uploads/2017/02/realwords.png)

这两个图表展示了一些令人困惑的结果。“虚假”图表中的词汇是一混合包，包括一些典型的互联网术语，如PLEASE、Share、Posted、html和Widget，以及一些甚至不是词汇的字符组合，如tzrwu。然而，我看到infowars被提及，或者像“Sheeple”或“UFO”这样的词汇进入前20个“最虚假”词汇并不感到惊讶。Infowars是一个由亚历克斯·琼斯领导的右翼阴谋论媒体，推广有关化学喷剂和9/11的阴谋论。

“真实”图表被名字和政治人物主导，这些词汇在政治文章中频繁出现，占图表条形的60%。二十个术语中有七个，包括前六名中的四个，是政治人物的名字。这引发了一个问题：关于政治人物的文章更可能真实吗？当然不是，如果有的话，你会期望有很多关于政治人物的虚假新闻文章传播虚假信息。如果我得出结论认为提到政治人物的文章更有可能是真实的，那将是一个巨大的错误。

本项目的一个重大假设是，每类文章所覆盖的主题之间存在相当大的重叠。正如我们上面所见，仅仅因为某个词在“真实”新闻中出现的频率比在“虚假”新闻中高，并不意味着包含这些词的文章一定是“真实”的，而可能只是因为这些词用于真实新闻数据集中更常见的话题，反之亦然。

我和另一方在塑造这个数据集方面有着相当大的影响。我决定了哪些文章用于“真实”数据集。“虚假”数据集中的文章则由[一个名为“BS Detector”的 Chrome 扩展](https://github.com/selfagency/bs-detector)确定，该扩展由 Daniel Sieradski 制作。确定什么是“虚假新闻”存在显著的主观性。政治人物名字被评为“真实”如此之高，很可能是因为语料库的一半不成比例地来自政治新闻。此外，我确实找到了一些我认为是可信新闻来源的文章。其中一篇来自《拦截者》，这是一个具有高标准新闻报道的新闻机构。是的，我的模型确实将这篇所谓的“虚假新闻”文章标记为真实。

更复杂的是，我们必须决定如何为我们的模型设置阈值概率。如果我是 Facebook 的数据科学家，负责实施一个将真实新闻和虚假新闻从用户的动态中分类的模型，我将面临在选择一个阻挡所有或大多数虚假新闻和一些真实新闻的模型，还是选择一个允许所有或大多数真实新闻和一些虚假新闻的模型之间的困境。但在做出决定之前，我需要搞清楚，未能防止虚假新闻与阻挡真实新闻的成本分别是多少？如何尝试回答这样一个抽象的问题？除非我们能训练出一个100%真正率和0%假正率的模型，否则我们将陷入这个困境。

总之，虽然我认为一个标准的朴素贝叶斯文本分类模型可以为解决这个问题提供一些见解，但在专业环境中应使用更强大的深度学习工具来对抗虚假新闻。

对“虚假新闻”的分类给数据科学界带来了全新的挑战。在许多机器学习项目中，你要预测的不同类别之间的区别很明确，而在这种情况下则模糊得多。这个项目验证了数据科学中的一个观点，即对数据的直觉和熟悉度与任何模型或工具同样重要，甚至更为重要。

**简介：[乔治·麦金泰尔](https://opendatascience.com/author/george-mcintire/)** 是一位从记者转行的数据科学家/记者混合体。寻求数据科学和/或新闻学的机会。对学习新事物充满好奇和热情。在完成Metis数据科学训练营之前，他曾在旧金山为Vice、Salon、SF Weekly、旧金山杂志等担任自由记者。

[原文](https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/)。经许可转载。

**相关：**

+   [这里变热了：数据科学与虚假新闻](/2017/03/getting-hot-here-data-science-vs-fake-news.html)

+   [昨晚在瑞典发生了什么：数据科学与虚假新闻](/2017/03/last-night-sweden-data-science-vs-fake-news.html)

+   [警惕两种数据混淆策略](/2017/04/beware-two-data-obfuscation-tactics.html)

### 更多相关主题

+   [虚假到成功：生成真实的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)

+   [20个问题（附答案）以识别虚假数据科学家：ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)

+   [20个问题（附答案）以识别虚假数据科学家：ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)

+   [我应该使用哪个指标？准确度与AUC](https://www.kdnuggets.com/2022/10/metric-accuracy-auc.html)

+   [分类指标逐步解析：带有…的逻辑回归](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)

+   [天空是极限：了解JetBlue如何使用Monte Carlo和Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)
