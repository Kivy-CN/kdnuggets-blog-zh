# 掌握 Python 机器学习的 7 个步骤

> 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html/2](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html/2)

### 第 4 步：更多集成方法

第一篇文章仅涉及一种集成方法：随机森林（RF）。多年来，RF 作为一种顶级分类器取得了巨大成功，但它绝不是唯一的集成分类器。我们将探讨装袋、提升和投票。

![提升](../Images/658f99083c93080b92c1f86c7f94ecf7.png)

给我一个提升。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能。

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT。

* * *

首先，阅读这些集成学习者的概述，第一篇是一般性的，第二篇是与 Scikit-learn 相关的：

+   [集成学习者简介](/2016/11/data-science-basics-intro-ensemble-learners.html)，作者：Matthew Mayo

+   [Scikit-learn 中的集成方法](http://scikit-learn.org/stable/modules/ensemble.html)，Scikit-learn 文档

然后，在继续了解新的集成方法之前，通过这里的最新教程重新学习随机森林：

+   [Python 中的随机森林](/2016/12/random-forests-python.html)，作者：Yhat

装袋、提升和投票都是不同形式的集成分类器。它们都涉及构建多个模型；然而，这些模型是从什么**算法**构建的、模型使用的**数据**以及结果如何最终**结合**在不同方案之间有所不同。

+   **装袋**从相同的分类算法构建多个模型，同时使用训练集中的不同（独立）数据样本——Scikit-learn 实现了 BaggingClassifier。

+   **提升**从相同的分类算法构建多个模型，将模型一个接一个地链式排列，以提升每个后续模型的学习——Scikit-learn 实现了 AdaBoost。

+   **投票**通过不同的分类算法构建多个模型，并使用标准来确定如何最好地结合这些模型——Scikit-learn 实现了 VotingClassifier。

那么，为什么要结合模型？从一个具体的角度来看，这里是一个关于 [偏差-方差权衡](/2016/08/bias-variance-tradeoff-overview.html) 的概述，特别是与提升相关，来自 Scikit-learn 文档：

+   [单一估计器与袋装法：偏差-方差分解](http://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html)，Scikit-learn 文档

现在你已经阅读了一些关于集成学习者的一般介绍，并对一些特定的集成分类器有了基本了解，请按照来自 Machine Learning Mastery 的教程介绍，在 Python 中使用 Scikit-learn 实现集成分类器：

+   [使用 scikit-learn 的 Python 集成机器学习算法](http://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)，作者 Jason Brownlee

### 第 5 步：梯度提升

我们的下一步将继续探讨集成分类器领域，专注于一种最受欢迎的现代机器学习算法。梯度提升在最近的机器学习领域中产生了显著影响，成为（值得注意的是）Kaggle 竞赛中最常用且成功的算法之一。

![梯度提升](../Images/8a508ad2c2ca40aaed56f1ad7dfa9128.png)

给我一个梯度提升。

首先，阅读关于梯度提升的概述：

+   [维基百科上的梯度提升](https://en.wikipedia.org/wiki/Gradient_boosting)

接下来，了解为何梯度提升是 Kaggle 竞赛中“最获胜”的方法：

+   [为什么梯度提升对许多 Kaggle 问题效果如此好？在 Quora 上](https://www.quora.com/Why-does-Gradient-boosting-work-so-well-for-so-many-Kaggle-problems)

+   [Kaggle 大师讲解梯度提升](https://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)，作者 Ben Gorman

尽管 Scikit-learn 也有自己的梯度提升实现，但我们会稍作偏离，使用 [XGBoost 库](https://github.com/dmlc/xgboost)，它 [被指出](http://www.jmlr.org/proceedings/papers/v42/chen14.pdf) 是一种更快的实现。

以下链接提供了关于 XGBoost 库及梯度提升的一些额外信息（出于必要性）：

+   [XGBoost 在维基百科](https://en.wikipedia.org/wiki/Xgboost)

+   [XGBoost 库在 GitHub](https://github.com/dmlc/xgboost)

+   [XGBoost 文档](https://xgboost.readthedocs.io/en/latest/model.html)

现在，请按照这个将所有内容整合在一起的教程进行操作：

+   [在 Python 中使用 XGBoost 的梯度提升树指南](https://jessesw.com/XG-Boost/)，作者 Jesse Steinweg-Woods

你还可以参考这些更简洁的例子来加强理解：

+   [Kaggle 上的 XGBoost 示例（Python）](https://www.kaggle.com/cbrogan/titanic/xgboost-example-python)

+   [Iris 数据集与 XGBoost 简单教程](http://ieva.rocks/2016/08/25/iris_dataset_and_xgboost_simple_tutorial/)，作者 Ieva Zarina

### 第 6 步：更多降维

[降维](https://en.wikipedia.org/wiki/Dimensionality_reduction)是指通过利用处理过程将模型构建所用的变量从最初数量减少到较少数量的行为，以获得一组**主要变量**。

降维有两种主要形式：

1.  [特征选择](https://en.wikipedia.org/wiki/Feature_selection) - 选择相关特征的子集

1.  [特征提取](https://en.wikipedia.org/wiki/Feature_extraction) - 构建一个信息丰富且不冗余的衍生特征值集

以下是对一对常见特征提取方法的介绍。

![LDA Iris 数据集](../Images/64b868a81463c323186ccc586b238ac0.png)

LDA Iris 数据集。

> [**主成分分析 (PCA)**](https://en.wikipedia.org/wiki/Principal_component_analysis) 是一种统计程序，通过正交变换将可能相关的变量的观测值集转换为一组线性不相关的变量，这些变量称为主成分。主成分的数量小于或等于原始变量的数量。这种变换的定义使得第一个主成分具有最大的可能方差（即尽可能多地解释数据的变异性）[.]

上述定义来自于 [PCA 维基百科条目](https://en.wikipedia.org/wiki/Principal_component_analysis)，如果有兴趣，可以进一步阅读。然而，以下概述教程非常全面：

+   [主成分分析的 3 个简单步骤](http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html)，作者：Sebastian Raschka

> [**线性判别分析 (LDA)**](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) 是 Fisher 线性判别分析的推广，这是一种用于统计学、模式识别和机器学习的方法，用于寻找特征的线性组合，这种组合能够表征或分离两个或更多类的对象或事件。结果的组合可以用作线性分类器，或者更常见的是，在后续分类前进行降维。
> 
> LDA 与方差分析 (ANOVA) 和回归分析密切相关，后者也尝试将一个因变量表达为其他特征或测量的线性组合。然而，ANOVA 使用分类自变量和连续因变量，而判别分析具有连续自变量和分类因变量（即类别标签）

上述定义也来自维基百科。再一次，以下读物非常详尽：

+   [线性判别分析 – 一步步解读](http://sebastianraschka.com/Articles/2014_python_lda.html)，作者：Sebastian Raschka

你是否对 PCA 和 LDA 在降维上的实际差异感到困惑？[Sebastian Raschka 进行了阐明](http://sebastianraschka.com/Articles/2014_python_lda.html)：

> 线性判别分析（LDA）和主成分分析（PCA）都是常用于降维的线性变换技术。PCA可以被描述为一种“无监督”的算法，因为它“忽略”类标签，其目标是找到最大化数据集方差的方向（即所谓的主成分）。与PCA相比，LDA是“有监督”的，它计算出将表示最大化多个类之间分离的方向（即“线性判别”的方向）。

关于这个主题的简明阐述，请阅读以下内容：

+   [LDA和PCA在降维上的区别是什么？](https://sebastianraschka.com/faq/docs/lda-vs-pca.html)，作者：Sebastian Raschka

### 第7步：更多深度学习

原始的7步骤...文章提供了进入神经网络和深度学习的入口。如果你已经顺利到达这里并希望巩固对神经网络的理解，并练习实现一些常见的神经网络模型，那么没有理由不继续下去。

![深度学习](../Images/35cca5c97cb4d4033c23fdadcb5820b8.png)

深度神经网络的多个层次。

首先，查看一些深度学习基础材料：

+   [深度学习关键术语解析](/2016/10/deep-learning-key-terms-explained.html)，作者：Matthew Mayo

+   [理解深度学习的7个步骤](/2016/01/seven-steps-deep-learning.html)，作者：Matthew Mayo

接下来，尝试几个关于[TensorFlow](https://www.tensorflow.org/)的入门概述或教程，这是Google的“开源机器智能软件库”，实际上是一个深度学习框架，并且几乎是*事实上的*当代神经网络工具：

+   [最温和的Tensorflow介绍 – 第1部分](/2016/08/gentlest-introduction-tensorflow-part-1.html)，作者：Soon Hin Khor

+   [最温和的Tensorflow介绍 – 第2部分](/2016/08/gentlest-introduction-tensorflow-part-2.html)，作者：Soon Hin Khor

+   [最温和的Tensorflow介绍 – 第3部分](/2017/02/gentlest-introduction-tensorflow-part-3.html)，作者：Soon Hin Khor

+   [最温和的Tensorflow介绍 – 第4部分](/2017/02/gentlest-introduction-tensorflow-part-4.html)，作者：Soon Hin Khor

最后，试试这些来自TensorFlow网站的教程，它们实现了一些最流行和常见的神经网络模型：

+   [递归神经网络](https://www.tensorflow.org/tutorials/recurrent)，Google TensorFlow教程

+   [卷积神经网络](https://www.tensorflow.org/tutorials/deep_cnn)，Google TensorFlow教程

此外，一篇关于深度学习的7步骤...文章目前正在制作中，将着重于使用高层次API，这些API位于TensorFlow之上，以增加从业者实现模型的便捷性和灵活性。完成后我也会在这里添加一个链接。

**相关内容**：

+   [进入机器学习职业前阅读的5本电子书](/2016/10/5-free-ebooks-machine-learning-career.html)

+   [理解深度学习的7个步骤](/2016/01/seven-steps-deep-learning.html)

+   [机器学习关键术语解释](/2016/05/machine-learning-key-terms-explained.html)

### 更多相关主题

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [建立一个稳固的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [是什么让Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，并通过找到目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
