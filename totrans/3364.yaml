- en: 'Machine Learning & Artificial Intelligence: Main Developments in 2016 and Key
    Trends in 2017'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html](https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: At KDnuggets, we try to keep our finger on the pulse of main events and developments
    in industry, academia, and technology. We also do our best to look forward to
    key trends on the horizon.
  prefs: []
  type: TYPE_NORMAL
- en: We recently asked some of the leading experts in Big Data, Data Science, Artificial
    Intelligence, and Machine Learning for their opinion on the most important developments
    of 2016 and key trends they 2017.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get up to speed on our first 2 posts published outlining expert opinions,
    see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Big Data: Main Developments in 2016 and Key Trends in 2017](/2016/12/big-data-main-developments-2016-key-trends-2017.html)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Data Science & Predictive Analytics: Main Developments in 2016 and Key Trends
    in 2017](/2016/12/data-science-predictive-analytics-main-developments-trends.html)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the final post of the series, we bring you the collected responses to the
    question:'
  prefs: []
  type: TYPE_NORMAL
- en: '**"What were the main Artificial Intelligence/Machine Learning related events
    in 2016 and what key trends do you see in 2017?"**'
  prefs: []
  type: TYPE_NORMAL
- en: Common themes include the triumphs of deep neural networks, reinforcement learning's
    successes, AlphaGo as exemplar of the power of both of these phenomena in unison,
    the application of machine learning to the Internet of Things, self-driving vehicles,
    and automation, among others.
  prefs: []
  type: TYPE_NORMAL
- en: We generally asked participants to keep their responses to within 100 words
    or so, but were amenable to longer answers if the situation warranted. Without
    further delay, here is what we found.
  prefs: []
  type: TYPE_NORMAL
- en: '![AI/ML experts](../Images/421d900ae8f712837a374838a8b89e49.png)'
  prefs: []
  type: TYPE_IMG
- en: '**[Yaser Abu-Mostafa](https://work.caltech.edu/)**, Caltech (in consultation
    with Professor Hsuan-Tien Lin and Professor Malik Magdon-Ismail)'
  prefs: []
  type: TYPE_NORMAL
- en: 2016 and 2017 are an exciting time for [**Machine Learning**](/tag/machine-learning).
    There are two trends that have been accelerating. First, the showcases that prove
    ML to be an extraordinarily powerful technology. The recent successes of [AlphaGo](/tag/alphago)
    and [inhuman encryption](https://techcrunch.com/2016/10/28/googles-ai-creates-its-own-inhuman-encryption/)
    are compelling examples. Second, the expanding reach of ML applications. More
    complex tasks, more domains, and more acceptance of ML as the way to exploit data
    everywhere. The Google/Microsoft/Facebook/IBM AI partnerships are there for a
    reason.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Xavier Amatriain](https://www.quora.com/topic/Xavier-Amatriain-1)**, VP
    Engineering at Quora'
  prefs: []
  type: TYPE_NORMAL
- en: 2016 may very well go down in history as the year of “the Machine Learning [**hype**](/tag/hype)”.
    Everyone now seems to be doing machine learning, and if they are not, they are
    thinking of buying a startup to claim they do.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, to be fair, there are reasons for much of that “hype”. Can you believe
    that it has been only a year since [Google announced](https://research.googleblog.com/2015/11/tensorflow-googles-latest-machine_9.html)
    they were open sourcing [**Tensor Flow**](/tag/tensorflow)? TF is already a very
    active project that is being used for anything ranging from drug discovery to
    [generating music](https://github.com/tensorflow/magenta). Google has not been
    the only company open sourcing their ML software though, many followed lead. [Microsoft
    open sourced CNTK](http://blogs.microsoft.com/next/2016/01/25/microsoft-releases-cntk-its-open-source-deep-learning-toolkit-on-github),
    [Baidu announced the release of PaddlePaddle](http://www.theverge.com/2016/9/1/12725804/baidu-machine-learning-open-source-paddle),
    and Amazon just recently announced that they [will back MXNet](http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html)
    in their new AWS ML platform. Facebook, on the other hand, are basically supporting
    the development of not one, but two Deep Learning frameworks: [Torch](http://torch.ch/)
    and [Caffe](http://caffe.berkeleyvision.org/). On the other hand, Google is also
    supporting the highly successful [Keras](https://github.com/fchollet/keras), so
    things are at least even between Facebook and Google on that front.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Besides the “hype” and the outpour of support from companies to machine learning
    open source projects, 2016 has also seen a great deal of applications of machine
    learning that were almost unimaginable a few months back. I was particularly impressed
    by the quality of [Wavenet](https://arxiv.org/pdf/1609.03499.pdf)’s audio generation.
    Having worked on similar problems in the past I can appreciate those results.
    I would also highlight some of the [recent results in lip reading](https://arxiv.org/pdf/1611.05358.pdf),
    a great application of video recognition that is likely to be very useful (and
    maybe scary) in the near future. I should also mention Google’s impressive [advances
    in machine translation](https://arxiv.org/pdf/1609.08144.pdf). It is amazing to
    see how much this area has improved in a year.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'As a matter of fact, machine translation is not the only interesting advance
    we have seen in machine learning for language technologies this past year. I think
    it is very interesting to see some of the recent approaches to combine deep sequential
    networks with side-information in order to produce richer language models. In
    “[A Neural Knowledge Language Model](https://arxiv.org/pdf/1608.00318.pdf)”, Bengio’s
    team combines knowledge graphs with RNNs, and in “[Contextual LSTM models for
    Large scale NLP Tasks](https://arxiv.org/pdf/1602.06291.pdf)”, the DeepMind folks
    incorporate topics into the LSTM model. We have also seen a lot of interesting
    work in modeling attention and memory for language models. As an example, I would
    recommend “[Ask Me Anything: Dynamic Memory Networks for NLP](https://arxiv.org/pdf/1602.06291.pdf)”,
    presented in this year’s ICML.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I could not finish this review of 2016 without some mention of advances in
    my main area of expertise: [**Recommender Systems**](/tag/recommender-systems).
    Of course Deep Learning has also impacted this area. While I would still not recommend
    DL as the default approach to recommender systems, it is interesting to see how
    it is already being used in practice, and in large scale, by products like [Youtube](http://dl.acm.org/citation.cfm?id=2959190).
    That said, there has been interesting research in the area that is not related
    to Deep Learning. The best paper award in this year’s ACM Recsys went to “[Local
    Item-Item Models For Top-N Recommendation](http://dl.acm.org/citation.cfm?id=2959185&CFID=672508488&CFTOKEN=91227145)”,
    an interesting extension to Sparse Linear Methods (i.e. [SLIM](https://www.researchgate.net/profile/George_Karypis/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems/links/549ee9ac0cf257a635fe7010.pdf))
    using an initial unsupervised clustering step. Also, “[Field-aware Factorization
    Machines for CTR Prediction](http://dl.acm.org/citation.cfm?id=2959134)”, which
    describes the winning approach to the [Criteo CTR Prediction Kaggle Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge/details/winners)
    is a good reminder that Factorization Machines are still a good tool to have in
    your ML toolkit.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I could probably go on for a couple of pages just listing impactful advances
    in machine learning in the last 12 months. Note that I haven’t even listed any
    of the breakthroughs related to image recognition or deep reinforcement learning,
    or obvious applications such as self-driving cars or game playing, which all saw
    huge advances in 2016\. Not to mention all the controversy around how machine
    learning is having or could have negative effects on society and the rise of discussions
    around [algorithmic bias and fairness](https://www.wired.com/2016/11/humans-can-force-machines-play-fair?mbid=social_twitter).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'So, what should we expect for 2017? It is hard to say given how fast things
    are moving in the area. I am sure we will have a hard time just digesting what
    we will see in the [NIPS conference](https://nips.cc/Conferences/2016/Schedule)
    in a few days. I am definitely looking forward to many machine learning advances
    in the areas that I care the most about: personalization/recommendations, and
    natural language processing. I am sure, for example, that in the next few months
    we will see how ML can tackle the problem of fake news. But, of course, I also
    hope to see more self driving cars on the roads and machine learning being put
    to good use for health-related applications or for creating a better informed
    and more just society.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Yoshua Bengio](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html)**,
    Professor, Department of Computer Science and Operations Research, Université
    de Montréal‎, Canada Research Chair in Statistical Learning Algorithms, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: The main events of 2016 from my point of view have been in the areas of deep
    [**reinforcement learning**](/tag/reinforcement-learning), [**generative models**](/tag/generative-models),
    and neural machine translation. First we had AlphaGo (DeepMind's network which
    beat the Go world champion using deep RL). Over the whole year we have seen a
    series of papers showing the success of generative adversarial networks (for unsupervised
    learning of generative models). Also in the area of unsupervised learning, we
    have seen the unexpected success of auto-correlation neural networks (like the
    WaveNet paper from DeepMind). Finally, just about a month ago we have seen the
    crowning of neural machine translation (which was initiated in part by my lab
    since 2014) with Google bringing this technology to the scale of Google Translate
    and obtaining really amazing results (approaching very significantly human-level
    performance).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I believe these are good indicators for the progress to be expected in 2017:
    more advances in [**unsupervised learning**](/tag/unsupervised-learning) (which
    remains a major challenge, we are very far from human abilities in that respect)
    and in the ability of computers to understand and generate natural language, probably
    first with chatbots and other dialogue systems. Another likely trend is the increase
    in research and results of applying deep learning in the healthcare domain, on
    a variety of types of data, including medical images, clinical data, genomic data,
    etc. Progress in computer vision will continue as we see more applications, including
    of course self-driving cars but I have the impression that in general the community
    is under-estimating the challenges ahead before reaching true autonomy.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Self-driving car](../Images/72488205ebf5d06b9957e142c07a565a.png)'
  prefs: []
  type: TYPE_IMG
- en: '**[Pedro Domingos](http://homes.cs.washington.edu/~pedrod/)**, Professor of
    computer science at UW and author of ''[The Master Algorithm](https://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708/)'''
  prefs: []
  type: TYPE_NORMAL
- en: The main event of 2016 was AlphaGo's win. Two areas where we might see substantial
    progress in 2017 are [**chatbots**](/tag/chatbot) and [**self-driving cars**](/tag/self-driving-car),
    just because so many major companies are investing heavily in them. On the more
    fundamental side, one thing we'll probably see is increasing hybridization of
    deep learning with other ML/AI techniques, as is  typical for a maturing technology.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**Oren Etzioni**](http://allenai.org/team/orene/), CEO of the Allen Institute
    for Artificial Intelligence. He was a Professor at U. Washington, founder/co-founder
    of several companies including Farecast and Decide, and the author of over 100
    technical papers.'
  prefs: []
  type: TYPE_NORMAL
- en: The tremendous success of AlphaGo is the crowning achievement for an exciting
    2016\. In 2017, we will see more reinforcement learning in [**neural networks**](/tag/neural-networks),
    more research on neural networks in NLP & vision. However, the challenges of neural
    networks with limited labeled data, exemplified by systems like [Semantic Scholar](https://www.semanticscholar.org/),
    remain formidable and will occupy us for years to come. These are still early
    days for [**Deep Learning**](/tag/deep-learning) and more broadly for Machine
    Learning.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**Ajit Jaokar**](https://twitter.com/AjitJaokar), #Datascience, #IoT, #MachineLearning,
    #BigData, Mobile,#Smartcities, #edtech (@feynlabs + @countdowncode) Teaching (@forumoxford
    + @citysciences)'
  prefs: []
  type: TYPE_NORMAL
- en: 2017 will be a big year for both [**IoT**](/tag/IoT) and [**AI**](/tag/artificial-intelligence).
    As per my recent [KDnuggets post](/2016/11/continuous-improvement-iot-ai-learning.html),
    AI will be a core competency for Enterprises. For IoT, this would mean the ability
    to build and deploy models across platforms (Cloud, Edge, Streaming). This ties
    continuous learning to the vision of continuous improvement through AI. It also
    needs to new competencies as AI and devops converge.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Neil Lawrence](http://inverseprobability.com/)**, Professor of Machine Learning
    at the University of Sheffield'
  prefs: []
  type: TYPE_NORMAL
- en: I think things are progressing much as we might expect at the moment. [**Deep
    learning**](/tag/deep-learning) methods are being intelligently deployed on very
    large data sets. For smaller data sets I think we'll see some interesting directions
    on model repurposing, i.e the reuse of pre-trained deep learning models. There
    are some interesting open questions around how best to do this. A further trend
    has been the increasing press focus on the field. Including mainstream articles
    on papers placed on [**Arxiv**](/tag/arxiv) that have not yet been reviewed. This
    appetite for advance was also present last year but I think this year we've seen
    it accelerate. In response I think academics should probably become a lot more
    careful about how they choose to promote their work (for example on social media),
    particularly when it is unreviewed.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Randal Olson](http://www.randalolson.com/)**, Senior Data Scientist at the
    University of Pennsylvania Institute for Biomedical Informatics'
  prefs: []
  type: TYPE_NORMAL
- en: '[Automated Machine Learning (AutoML) systems](/2016/11/autoamted-machine-learning-interview-randy-olson-tpot.html)
    started becoming competitive with human machine learning experts in 2016\. Earlier
    this year, an MIT group created a [Data Science Machine](http://people.csail.mit.edu/kalyan/dsm/)
    that beat hundreds of teams in the popular KDD Cup and IJCAI machine learning
    competitions. Just this month, our in-house AutoML system, [TPOT](https://github.com/rhiever/tpot),
    started ranking in the 90th percentile on several [Kaggle](https://www.kaggle.com/)
    competitions. Needless to say, I am confident that AutoML systems will start replacing
    human experts for standard machine learning analyses in 2017.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Colorful neural networks](../Images/02b2b6e13a9bcc46c937d2817304b9f4.png)'
  prefs: []
  type: TYPE_IMG
- en: '**[Charles Martin](https://www.linkedin.com/in/charlesmartin14)**, Data Scientist
    & Machine Learning Expert'
  prefs: []
  type: TYPE_NORMAL
- en: 2016 has been the watershed year for [**Deep learning**](/tag/deep-learning).
    We have had a year with [**Google Tensorflow**](/tag/tensorflow), and the applications
    keep pouring in. Combined with say Keras, Jupyter Notebooks, and GPU-enabled AWS
    nodes, [**Data Science teams**](/tag/data-science-team) have the infrastructure
    on-demand to start building truly innovative learning applications and start generating
    revenue fast. But they may not have the talent? It is not about coding. It is
    not an infrastructure play. It is very different from traditional analytics, and
    no one really understands Why Deep Learning Works. Still, let's face it, it is
    all Google and Facebook talk about! And the C-suite is listening. In 2017, companies
    will be looking to bring best-of-breed Deep Learning technologies in house to
    improve the bottom line.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Matthew Mayo](/author/matt-mayo)**, Data Scientist, Deputy Editor of KDnuggets'
  prefs: []
  type: TYPE_NORMAL
- en: The big story of 2016 has to be the accelerated returns we are seeing from deep
    learning. The (not solely) neural network-based "conquering" of Go is likely the
    most prominent example, but there are others. Looking forward to 2017, I would
    expect that the continued advancements in [**neural networks**](/tag/neural-networks)
    will remain the big story. However, [**automated machine learning**](/tag/automated-data-science)
    will quietly become an important event in its own right. Perhaps not as sexy to
    outsiders as deep neural networks, automated machine learning will begin to have
    far-reaching consequences in ML, AI, and data science, and 2017 will likely be
    the year this becomes apparent.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Brandon Rohrer](https://www.linkedin.com/in/brohrer)**, Data Scientist at
    Facebook'
  prefs: []
  type: TYPE_NORMAL
- en: In 2016 machines read lips more accurately than humans ([arxiv.org/pdf/1611.05358.pdf](https://arxiv.org/pdf/1611.05358.pdf)),
    type from dictation faster than humans ([arxiv.org/abs/1608.07323](https://arxiv.org/abs/1608.07323))
    and create eerily realistic human speech ([arxiv.org/pdf/1609.03499.pdf](https://arxiv.org/pdf/1609.03499.pdf)).
    These are the results of exploring novel architectures and [**algorithms**](/tag/algorithms).
    [**Convolutional Neural Networks**](/tag/convolutional-neural-networks) are being
    modified beyond recognition and combined with reinforcement learners and time-aware
    methods to open up new application areas. In 2017 I expect a few more human level
    benchmarks to fall, particularly those that are vision-based and thus amenable
    to CNNs. I also expect (and hope!) that our community forays into the nearby territories
    of decision making, non-vision feature creation and time-aware methods will become
    more frequent and fruitful. Together these make intelligent robots possible. If
    we are really lucky, 2017 will bring us a machine that can beat humans at making
    a cup of coffee.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Daniel Tunkelang](https://www.linkedin.com/in/dtunkelang)**, Data science,
    Engineering, and Leadership'
  prefs: []
  type: TYPE_NORMAL
- en: The biggest story of 2016 was [**AlphaGo**](/tag/alphago) defeating Lee Sedol,
    the human world champion of Go. It was a surprise even to the AI community, and
    it will be remembered as the tipping point in the rise of deep learning. 2016
    was the year of deep learning and AI. Chatbots, self-driving cars, and computer-aided
    diagnosis have unlocked the possibilities of what we can do by throwing enough
    GPUs at the right training data. 2017 will bring us successes and disillusionments.
    Technologies like TensorFlow will commodify deep learning, and AI will be something
    we take for granted in consumer products. But we'll hit the limits of what we
    can model and optimize. We'll have to confront the biases in our data. And we'll
    grow up and realize that we're nowhere close to general AI or the [**singularity**](/tag/singularity).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Big Data: Main Developments in 2016 and Key Trends in 2017](/2016/12/big-data-main-developments-2016-key-trends-2017.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science & Predictive Analytics: Main Developments in 2016 and Key Trends
    in 2017](/2016/12/data-science-predictive-analytics-main-developments-trends.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Predictions for Deep Learning in 2017](/2016/12/ibm-predictions-deep-learning-2017.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Main 2021 Developments and Key 2022 Trends in AI, Data Science,…](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science & Analytics Industry Main Developments in 2021 and Key…](https://www.kdnuggets.com/2021/12/developments-predictions-data-science-analytics-industry.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
