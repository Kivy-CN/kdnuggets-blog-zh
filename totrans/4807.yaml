- en: Intuitive Ensemble Learning Guide with Gradient Boosting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直观的集成学习指南与梯度提升
- en: 原文：[https://www.kdnuggets.com/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html](https://www.kdnuggets.com/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html](https://www.kdnuggets.com/2018/07/intuitive-ensemble-learning-guide-gradient-boosting.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: Using a single machine learning model may not always fit the data. Optimizing
    its parameters also may not help. One solution is to combine multiple models together
    to fit the data. This tutorial discusses the importance of ensemble learning with
    gradient boosting as a study case.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单一的机器学习模型可能并不总是能拟合数据。优化其参数也可能无济于事。一个解决方案是将多个模型结合起来拟合数据。本教程讨论了集成学习的重要性，以梯度提升为研究案例。
- en: '**Introduction**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: One critical step in the machine learning (ML) pipeline is to select the best
    algorithm that fits the data. Based on some statistics and visualizations from
    the data, the ML engineer will select the best algorithm. Let us apply that on
    a regression example with its data shown in figure 1.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）管道中的一个关键步骤是选择最适合数据的算法。根据数据中的一些统计信息和可视化，ML工程师将选择最佳算法。让我们以图1中的回归示例来应用这一点。
- en: '**Figure 1**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**'
- en: '![](../Images/cd452bb8c00bc8e5697c7c1efff89210.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd452bb8c00bc8e5697c7c1efff89210.png)'
- en: By visualizing the data according to figure 2, it seems that a linear regression
    model will be suitable.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图2可视化数据，似乎线性回归模型将是合适的。
- en: '**Figure 2**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2**'
- en: '![](../Images/d8fa607e02e4ca34f856ecc1af2ddc85.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8fa607e02e4ca34f856ecc1af2ddc85.png)'
- en: A regression model with just one input and one output will be formulated according
    to the equation in figure 3.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个只有一个输入和一个输出的回归模型将根据图3中的方程进行制定。
- en: '**Figure 3**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3**'
- en: '![](../Images/8cc21deb9b95317fddebfed354641791.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cc21deb9b95317fddebfed354641791.png)'
- en: Where a and b are the parameters of the equation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中a和b是方程的参数。
- en: Because we do not know the optimal parameters that will fit the data, we can
    start with initial values. We can set a to 1.0 and b to 0.0 and visualize the
    model as in figure 4.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不知道最优的参数来拟合数据，我们可以从初始值开始。我们可以将a设置为1.0，b设置为0.0，并如图4所示可视化模型。
- en: '**Figure 4**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4**'
- en: '![](../Images/582d31456edef8d913fa3c9747aeca66.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/582d31456edef8d913fa3c9747aeca66.png)'
- en: It seems that the model does not fit the data based on the initial values for
    the parameters.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 基于初始值的模型似乎并没有拟合数据。
- en: It is expected that everything might not work from the first trial. The question
    is how to enhance the results in such cases? In other words, how to maximize the
    classification accuracy or minimize the regression error? There are different
    ways of doing that.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 预计第一次试验可能无法奏效。问题在于如何在这种情况下提升结果？换句话说，如何最大化分类准确性或最小化回归误差？有多种方法可以实现这一目标。
- en: One simple way is to try to change the previously selected parameters. After
    a number of trials, the model will know that the optimal parameters are a=2 and
    b=1\. The model will fit the data in such case as shown in figure 5\. Very good.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单的方法是尝试更改之前选择的参数。经过若干次试验，模型将知道最优的参数是a=2和b=1。模型将在这种情况下拟合数据，如图5所示。非常好。
- en: '**Figure 5**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**图5**'
- en: '![](../Images/be32c3a96d8a9942b2a5a25b6dd797d6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be32c3a96d8a9942b2a5a25b6dd797d6.png)'
- en: But there are some cases in which changing the model parameters will not make
    the model fit the data. There will be some false predictions. Suppose that the
    data has a new point (x=2, y=2). According to figure 6, it is impossible to find
    parameters that make the model completely fits every data point.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但在某些情况下，改变模型参数并不能使模型更好地拟合数据。会出现一些错误预测。假设数据中有一个新点（x=2，y=2）。根据图 6，无法找到使模型完全拟合每个数据点的参数。
- en: '**Figure 6**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 6**'
- en: '![](../Images/9ed3f14b772824c56d96a5faff54b516.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ed3f14b772824c56d96a5faff54b516.png)'
- en: One might say that fitting 4 points and missing one is acceptable. But what
    if there are more points that the line can not fit as in figure 7? Thus the model
    will make more false predictions than the correct ones. There is no single line
    to fit the entire data. The model is strong in its predictions to the points on
    the line but weak for other points.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会说，拟合 4 个点而漏掉一个是可以接受的。但是如果有更多的点线无法拟合，如图 7 所示呢？这样模型的错误预测会比正确预测更多。没有单一的直线能够拟合整个数据。模型对直线上的点预测较强，但对其他点预测较弱。
- en: '**Figure 7**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 7**'
- en: '![](../Images/762589b52f4c7a84eeab9bdc7a20de2d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/762589b52f4c7a84eeab9bdc7a20de2d.png)'
- en: '**Ensemble Learning**'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**集成学习**'
- en: Because a single regression model will not fit the entire data, an alternative
    solution is to use multiple regression models. Each regression model will be able
    to strongly fit a part of the data. The combination of all models will reduce
    the total error across the entire data and produce a generally strong model. Using
    multiple models in a problem is called ensemble learning. Importance of using
    multiple models is depicted in figure 8\. Figure 8(a) shows that the error is
    high when predicting the outcome of the sample. According to figure 8(b), when
    there are multiple models (e.g. three models), the average of their outcomes will
    be able to make a more accurate prediction than before.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因为单一的回归模型无法拟合整个数据，一个替代方案是使用多个回归模型。每个回归模型可以强烈地拟合数据的一部分。所有模型的组合将减少整个数据的总误差，并产生一个通常较强的模型。在问题中使用多个模型称为集成学习。使用多个模型的重要性在图
    8 中有所展示。图 8(a) 显示在预测样本结果时误差较高。根据图 8(b)，当有多个模型（例如，三个模型）时，它们结果的平均值能够比以前做出更准确的预测。
- en: '**Figure 8**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 8**'
- en: '![](../Images/5749554a805253a1b1564d107189fe41.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5749554a805253a1b1564d107189fe41.png)'
- en: When being applied to the previous problem in figure 7, the ensemble of 4 regression
    models fitting the data is shown in figure 9.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 应用到图 7 中的先前问题时，图 9 展示了 4 个回归模型拟合数据的集成结果。
- en: '**Figure 9**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 9**'
- en: '![](../Images/bae40240b28680b575171720d328b7a3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bae40240b28680b575171720d328b7a3.png)'
- en: This leaves another question. If there are multiple models to fit the data,
    how to get a single prediction? There are two ways to combine multiple regression
    models to return a single outcome. They are bagging and boosting (which is the
    focus of this tutorial).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了另一个问题。如果有多个模型来拟合数据，如何得到单一预测？有两种方法可以将多个回归模型组合以返回单一结果。它们是自助法和提升法（本教程的重点）。
- en: In bagging, each model will return its outcome and the final outcome will be
    returned by summarizing all of such outcomes. One way is by averaging all outcomes.
    Bagging is parallel as all models are working at the same time.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在自助法（bagging）中，每个模型都会返回其结果，最终结果通过汇总所有这些结果来获得。一个方法是对所有结果进行平均。自助法是并行的，因为所有模型同时工作。
- en: In contrast, boosting is regarded sequential as the outcome of one model is
    the input to the next model. The idea of boosting is to use a weak learner to
    fit the data. Because it is weak, it will not be able to fit the data correctly.
    The weaknesses in such a learner will be fixed by another weak learner. If some
    weaknesses still exist, then another weak learner will be used to fix them. The
    chain got extended until finally producing a strong learner from multiple weak
    learners.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，提升法被视为顺序的，因为一个模型的结果是下一个模型的输入。提升法的理念是使用一个弱学习器来拟合数据。由于它很弱，它将无法正确拟合数据。一个弱学习器的不足将被另一个弱学习器修正。如果一些不足仍然存在，那么将使用另一个弱学习器来修正它们。这条链会延续，直到最终从多个弱学习器中产生一个强学习器。
- en: Next is to go through the explanation of how gradient boosting works.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是讲解梯度提升的工作原理。
- en: '**Gradient Boosting (GB)**'
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**梯度提升 (GB)**'
- en: 'Here is how gradient boosting works based on a simple example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是梯度提升在一个简单示例中的工作原理：
- en: Suppose that a regression model is to be built and the data has a single output,
    where the first sample has an output 15\. It is depicted as in figure 10\. The
    goal is to build a regression model that correctly predict the output of such
    a sample.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 假设要建立一个回归模型，数据有一个输出，其中第一个样本的输出为15。它如图 10 所示。目标是建立一个能够正确预测这种样本输出的回归模型。
- en: '**Figure 10**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 10**'
- en: '![](../Images/ca0f50adb19096d37b8a0195f700b88c.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca0f50adb19096d37b8a0195f700b88c.png)'
- en: The first weak model predicted the output of the first sample to be 9 rather
    than 15 as shown in figure 11.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个弱模型预测第一个样本的输出为9，而不是15，如图 11 所示。
- en: '**Figure 11**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 11**'
- en: '![](../Images/3e7d934838de8899e3bb763e00476635.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e7d934838de8899e3bb763e00476635.png)'
- en: 'To measure the amount of loss in the prediction, its residual is calculated.
    Residual is the difference between the desired and predicted outputs. It is calculated
    according to the following equation:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测量预测中的损失量，需要计算其残差。残差是期望输出与预测输出之间的差异。它按照以下方程计算：
- en: '**desired – predicted1 = residual1**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**desired – predicted1 = residual1**'
- en: Where **predicted1** and **residual1** are the predicted output and the residual
    of the first weak model, respectively.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**predicted1**和**residual1**分别是第一个弱模型的预测输出和残差。
- en: 'By substituting by the values of the desired and predicted outputs, the residual
    will be 6:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过代入期望输出和预测输出的值，残差将为6：
- en: '**15 – 9 = 6**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**15 – 9 = 6**'
- en: 'For **residual1**=6 between the predicted and the desired outputs, we could
    create a second weak model where its target is to predict an output equal to the
    residual of the first model. Thus the second model will fix the weakness of the
    first model. The summation of the outputs from the two models will be equal to
    the desired output according to the next equation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**residual1**=6，在预测和期望输出之间，我们可以创建一个第二个弱模型，其目标是预测一个等于第一个模型残差的输出。因此，第二个模型将修正第一个模型的不足。两个模型的输出总和将等于期望输出，按照以下方程：
- en: '**desired = predicted1 + predicted2(residual1)**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**desired = predicted1 + predicted2(residual1)**'
- en: 'If the second weak model was able to predict the **residual1** correctly, then
    the desired output will equal the predictions of all weak models as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第二个弱模型能够正确预测**residual1**，则期望输出将等于所有弱模型的预测值，如下所示：
- en: '**desired = predicted1 + predicted2(residual1) = 9 + 6 = 15**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**desired = predicted1 + predicted2(residual1) = 9 + 6 = 15**'
- en: 'But if the second weak model failed to correctly predict the value of **residual1** and
    just returned 3 for example, then the second weak learner will also have a non-zero
    residual calculated as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果第二个弱模型未能正确预测**residual1**的值，例如返回了3，则第二个弱学习器也会有一个非零残差，计算如下：
- en: '**residual2 = predicted1 - predicted2 = 6 - 3 = 3**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**residual2 = predicted1 - predicted2 = 6 - 3 = 3**'
- en: This is depicted in figure 12.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 12 所示。
- en: '**Figure 12**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 12**'
- en: '![](../Images/01af35abbd568828c1eecc3687c726f5.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01af35abbd568828c1eecc3687c726f5.png)'
- en: 'To fix the weakness of the second weak model, a third weak model will be created.
    Its goal is to predict the residual of the second weak model. Thus its target
    is 3\. Thus the desired output of our sample will be equal to the predictions
    of all weak models as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了修正第二个弱模型的不足，将创建第三个弱模型。其目标是预测第二个弱模型的残差。因此，其目标是3。我们样本的期望输出将等于所有弱模型的预测值，如下所示：
- en: '**desired = predicted1 + predicted2(residual1) + predicted3(residual2)**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**desired = predicted1 + predicted2(residual1) + predicted3(residual2)**'
- en: 'If the third weak model prediction is 2, i.e. it is unable to predict the residual
    of the second weak model, then there will be a residual for such third model equal
    to as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第三个弱模型的预测值是2，即它无法预测第二个弱模型的残差，则第三个模型将有一个等于如下的残差：
- en: '**residual3 = predicted2 – predicted3 = 3 - 2 = 1**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**residual3 = predicted2 – predicted3 = 3 - 2 = 1**'
- en: This is depicted in figure 13.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 13 所示。
- en: '**Figure 13**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 13**'
- en: '![](../Images/ac903b318ace39264e89d2603faf1a38.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac903b318ace39264e89d2603faf1a38.png)'
- en: 'As a result, a fourth weak model will be created to predict the residual of
    the third weak model which equals to 1\. The desired output will be equal to the
    predictions of all weak models as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，将创建第四个弱模型来预测第三个弱模型的残差，该残差等于1。期望输出将等于所有弱模型的预测值，如下所示：
- en: '**desired = predicted1 + predicted2(residual1) + predicted3(residual2) + predicted4(residual3)**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**desired = predicted1 + predicted2(residual1) + predicted3(residual2) + predicted4(residual3)**'
- en: If the fourth weak model predicted its target correctly (i.e. residual3), then
    the desired output of 15 has been reached using a total of four weak models as
    shown in figure 14.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第四个弱模型正确预测了其目标（即 residual3），那么图 14 所示，通过总共四个弱模型已经达到了期望的输出 15。
- en: '**Figure 14**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 14**'
- en: '![](../Images/d9c8542828319814727f44251f3379df.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9c8542828319814727f44251f3379df.png)'
- en: This is the core idea of the gradient boosting algorithm. Use the residuals
    of the previous model as the target of the next model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这是梯度提升算法的核心思想。使用前一个模型的残差作为下一个模型的目标。
- en: '**Summary of GB**'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**GB 摘要**'
- en: As a summary, gradient boosting starts with a weak model for making predictions.
    The target of such a model is the desired output of the problem. After training
    such model, its residuals are calculated. If the residuals are not equal to zero,
    then another weak model is created to fix the weakness of the previous one. But
    the target of such new model will not be the desired outputs but the residuals
    of the previous model. That is if the desired output for a given sample is T,
    then the target of the first model is T. After training it, there might be a residual
    of R for such sample. The new model to be created will have its target set to
    R, not T. This is because the new model fills the gaps of the previous models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，梯度提升从一个弱模型开始进行预测。该模型的目标是问题的期望输出。在训练该模型后，计算其残差。如果残差不为零，则创建另一个弱模型来修正前一个模型的不足。然而，新模型的目标将不是期望输出，而是前一个模型的残差。也就是说，如果给定样本的期望输出是
    T，则第一个模型的目标是 T。训练后，该样本可能会有一个残差 R。新模型的目标将设置为 R，而不是 T。这是因为新模型填补了前一个模型的空白。
- en: Gradient boosting is similar to lifting a heavy metal a number of stairs by
    multiple weak persons. No one of the weak persons is able to lift the metal all
    stairs. Each one can only lift it a single step. The first weak person will lift
    the metal one step and get tired after that. Another weak person will lift the
    metal another step, and so on until getting the metal lifted all stairs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提升类似于多个弱者将重金属搬上几层楼梯。没有一个弱者能够将金属搬上所有的楼梯。每个人只能搬上一个台阶。第一个弱者将金属搬上一个台阶后就会感到疲惫。另一个弱者将金属再搬上一个台阶，依此类推，直到将金属搬上所有的楼梯。
- en: '**Bio: [Ahmed Gad](https://www.linkedin.com/in/ahmedfgad/)** received his B.Sc.
    degree with excellent with honors in information technology from the Faculty of
    Computers and Information (FCI), Menoufia University, Egypt, in July 2015\. For
    being ranked first in his faculty, he was recommended to work as a teaching assistant
    in one of the Egyptian institutes in 2015 and then in 2016 to work as a teaching
    assistant and a researcher in his faculty. His current research interests include
    deep learning, machine learning, artificial intelligence, digital signal processing,
    and computer vision.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Ahmed Gad](https://www.linkedin.com/in/ahmedfgad/)** 于 2015 年 7 月获得埃及梅努非亚大学计算机与信息学院的信息技术学士学位，并获得优异荣誉。因在学院中排名第一，他于
    2015 年被推荐在埃及的一所学院担任助教，随后于 2016 年继续担任助教和研究员。他目前的研究兴趣包括深度学习、机器学习、人工智能、数字信号处理和计算机视觉。'
- en: '[Original](https://www.linkedin.com/pulse/intuitive-ensemble-learning-guide-gradient-boosting-study-ahmed-gad/).
    Reposted with permission.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.linkedin.com/pulse/intuitive-ensemble-learning-guide-gradient-boosting-study-ahmed-gad/)。经许可转载。'
- en: '**Related:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Introduction to Python Ensembles](/2018/02/introduction-python-ensembles.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 集成学习介绍](/2018/02/introduction-python-ensembles.html)'
- en: '[Building Convolutional Neural Network using NumPy from Scratch](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从头开始使用 NumPy 构建卷积神经网络](/2018/04/building-convolutional-neural-network-numpy-scratch.html)'
- en: '[Ensemble Learning to Improve Machine Learning Results](/2017/09/ensemble-learning-improve-machine-learning-results.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[集成学习以提高机器学习结果](/2017/09/ensemble-learning-improve-machine-learning-results.html)'
- en: More On This Topic
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握季节性和提升业务成果的终极指南](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：直观方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[An Intuitive Explanation of Collaborative Filtering](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[协同过滤的直观解释](https://www.kdnuggets.com/2022/09/intuitive-explanation-collaborative-filtering.html)'
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[Ensemble Learning with Examples](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带例子的集成学习](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
- en: '[Ensemble Learning Techniques: A Walkthrough with Random Forests in Python](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[集成学习技术：Python中随机森林的实践指南](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
