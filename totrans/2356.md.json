["```py\nimport pandas as pd\n\ndf = pd.read_csv('winequality-red.csv')\ndf.head()\n```", "```py\nimport numpy as np\n\ndf['target'] = np.where(df['quality']>5, 1, 0)\n\n```", "```py\ndf2 = df.drop(['quality'],axis=1)\nX = df2.drop(['target'],axis=1)\ny = df2[['target']]\n\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\n\n```", "```py\ngrid_space={'max_depth':[3,5,10,None],\n              'n_estimators':[10,100,200],\n              'max_features':[1,3,5,7],\n              'min_samples_leaf':[1,2,3],\n              'min_samples_split':[1,2,3]\n           }\n\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')\nmodel_grid = grid.fit(X,y)\n\n```", "```py\nprint('Best hyperparameters are: '+str(model_grid.best_params_))\nprint('Best score is: '+str(model_grid.best_score_))\n\n```", "```py\nfrom scipy.stats import randint\n\nrs_space={'max_depth':list(np.arange(10, 100, step=10)) + [None],\n              'n_estimators':np.arange(10, 500, step=50),\n              'max_features':randint(1,7),\n              'criterion':['gini','entropy'],\n              'min_samples_leaf':randint(1,4),\n              'min_samples_split':np.arange(2, 10, step=2)\n         }\n\n```", "```py\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf = RandomForestClassifier()\nrf_random = RandomizedSearchCV(rf, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=3)\nmodel_random = rf_random.fit(X,y)\n\n```", "```py\nprint('Best hyperparameters are: '+str(model_random.best_params_))\nprint('Best score is: '+str(model_random.best_score_))\n\n```", "```py\n# imports\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import randint\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# reading the dataset \n\ndf = pd.read_csv('winequality-red.csv')\n\n# preprocessing \ndf['target'] = np.where(df['quality']>5, 1, 0)\ndf2 = df.drop(['quality'],axis=1)\nX = df2.drop(['target'],axis=1)\ny = df2[['target']]\n\n# initializing random forest\nrf = RandomForestClassifier()\n\n# grid search cv\ngrid_space={'max_depth':[3,5,10,None],\n              'n_estimators':[10,100,200],\n              'max_features':[1,3,5,7],\n              'min_samples_leaf':[1,2,3],\n              'min_samples_split':[1,2,3]\n           }\n\ngrid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')\nmodel_grid = grid.fit(X,y)\n\n# grid search results\nprint('Best grid search hyperparameters are: '+str(model_grid.best_params_))\nprint('Best grid search score is: '+str(model_grid.best_score_))\n\n# random search cv\nrs_space={'max_depth':list(np.arange(10, 100, step=10)) + [None],\n              'n_estimators':np.arange(10, 500, step=50),\n              'max_features':randint(1,7),\n              'criterion':['gini','entropy'],\n              'min_samples_leaf':randint(1,4),\n              'min_samples_split':np.arange(2, 10, step=2)\n          }\n\nrf = RandomForestClassifier()\n\nrf_random = RandomizedSearchCV(rf, rs_space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=3)\nmodel_random = rf_random.fit(X,y)\n\n# random random search results\nprint('Best random search hyperparameters are: '+str(model_random.best_params_))\nprint('Best random search score is: '+str(model_random.best_score_))\n\n```"]