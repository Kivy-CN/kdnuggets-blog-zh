- en: 'Data Science for Newbies: An Introductory Tutorial Series for Software Engineers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html](https://www.kdnuggets.com/2017/05/data-science-tutorial-series-software-engineers.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Harris Brakmić, Software Engineer.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**Editor''s note**: This is an overview of a multi-part tutorial on data science
    for newbies. The author has given the series a different -- tongue-in-cheek --
    title; take it in stride and recognize that the series'' approach and content
    is a fresh look at getting started with various aspects of data science from a
    software engineering perspective.'
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![PySpark console](../Images/4ae095edf852180b5162a23294b12e52.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: The PySpark console.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 1: Getting Started](http://blog.brakmic.com/data-science-for-losers/)**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: To do some serious statistics with Python one should use a proper distribution
    like the one provided by Continuum Analytics. Of course, a manual installation
    of all the needed packages (Pandas, NumPy, Matplotlib etc.) is possible but beware
    the complexities and convoluted package dependencies. In this article we’ll use
    the Anaconda Distribution. The installation under Windows is straightforward but
    avoid the usage of multiple Python installations (for example, Python3 and Python2
    in parallel). It’s best to let Anaconda’s Python binary be your standard Python
    interpreter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**[Part 2: Analyzing Reddit Comments & Querying Databases](http://blog.brakmic.com/data-science-for-losers-part-2/)**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Patterns are everywhere but many of them can’t be immediately recognized. This
    is one of the reasons why we’re digging deep holes in our databases, data warehouses,
    and other silos. In this article we’ll use a few more methods from Pandas’ DataFrames
    and generate plots. We’ll also create pivot tables and query an MS SQL database
    via ODBC. SqlAlchemy will be our helper in this case and we’ll see that even Losers
    like us can easily merge and filter SQL tables without touching the SQL syntax.
    No matter the task you always need a powerful tool-set in the first place. Like
    the Anaconda Distribution which we’ll be using here. Our data sources will be
    things like JSON files containing reddit comments or SQL-databases like Northwind.
    Many 90’es kids used Northwind to learn SQL.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![Reddit comment ratings](../Images/cee5b84ed2764fddb38d5668cbeb509b.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: Highest rated comments for all available sub-reddits.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可用子版块中评价最高的评论。
- en: '**[Part 2 Addendum: Playing SQL with DataFrames](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第2部分附录：使用DataFrames进行SQL操作](http://blog.brakmic.com/data-science-for-losers-part-2-addendum/)**'
- en: So, let’s talk about a few features from Pandas I’ve forgot to mention in the
    last two articles.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '-   那么，我们来谈谈在上一篇文章中我忘记提及的Pandas的一些特性。'
- en: '**[Part 3: Scala & Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第3部分：Scala与Apache Spark](http://blog.brakmic.com/data-science-for-losers-part-3-scala-apache-spark/)**'
- en: 'By its own definition Spark is a fast, general engine for large-scale data
    processing. Well, someone would say: but we already have Hadoop, so why should
    we use Spark? Such a question I’d answer with a remark that Hadoop is EJB reinvented
    and that we need something more flexible, more general, more expandable and…much
    faster than MapReduce. Spark handles both batch and streaming processing at a
    very fast rate.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '-   根据其自身定义，Spark是一个用于大规模数据处理的快速通用引擎。有人可能会说：但我们已经有Hadoop了，那为什么还要使用Spark呢？对于这样的问题，我会回答说Hadoop是重新发明的EJB，我们需要更灵活、更通用、更可扩展并且……比MapReduce快得多的东西。Spark以非常快的速度处理批量和流处理。'
- en: '**[Part 4: Machine Learning](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第4部分：机器学习](http://blog.brakmic.com/data-science-for-losers-part-4-machine-learning/)**'
- en: 'From my non-scientist perspective I’d define ML as a subset of the Artificial
    Intelligence research which develops self-learning (or self-improving?) algorithms
    that try to gain knowledge from data and make predictions based on it. However,
    ML is not only reserved for academia or some “enlightened circles”. We use ML
    every day without being aware of its existence and usefulness. A few examples
    of ML in the wild would be: spam filters, speech-recognition software, automatic
    text-analysis, “intelligent game characters”, or the upcoming self-driving cars.
    All these entities make decisions based on some ML algorithms.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '-   从我非科学家的角度来看，我会将ML定义为人工智能研究的一个子集，它开发自学习（或自我改进？）算法，试图从数据中获取知识并基于此进行预测。然而，ML不仅仅是学术界或某些“开明圈子”的专属。我们每天都在使用ML，却没有意识到它的存在和有用性。一些实际应用中的ML示例包括：垃圾邮件过滤器、语音识别软件、自动文本分析、“智能游戏角色”或即将到来的自动驾驶汽车。所有这些实体都基于一些ML算法做出决策。'
- en: '![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![PySpark](../Images/65b89b9396498da22b3e6822b9a735ae.png)'
- en: DataFrames in the Spark stack.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '-   Spark栈中的DataFrames。'
- en: '**[Part 5: Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第5部分：Spark DataFrames](http://blog.brakmic.com/data-science-for-losers-part-5-spark-dataframes/)**'
- en: Before we start using DataFrames we first have to prepare our environment which
    will run in Jupyter (formerly known as “IPython”). After you’ve downloaded and
    unpacked the Spark Package you’ll find some important Python libraries and scripts
    inside the python/pyspark directory. These files are used, for example, when you
    start the PySpark REPL in the console. As you may know, Spark supports Java, Scala,
    Python and R. Python-based REPL called PySpark offers a nice option to control
    Spark via Python scripts
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '-   在我们开始使用DataFrames之前，我们首先需要准备好在Jupyter（以前称为“IPython”）中运行的环境。在你下载并解压Spark包之后，你会在python/pyspark目录中找到一些重要的Python库和脚本。这些文件在你启动PySpark
    REPL时会用到。如你所知，Spark支持Java、Scala、Python和R。基于Python的REPL，称为PySpark，提供了通过Python脚本控制Spark的一个很好的选项。'
- en: '**[Part 6: Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第6部分：Azure ML](http://blog.brakmic.com/data-science-for-losers-part-6-azure-ml/)**'
- en: In this article we’ll explore Microsoft’s Azure Machine Learning environment
    and how to combine Cloud technologies with Python and Jupyter. As you may know
    I’ve been extensively using them throughout this article series so I have a strong
    opinion on how a Data Science-friendly environment should look like. Of course,
    there’s nothing against other coding environments or languages, for example R,
    so your opinion may greatly differ from mine and this is fine. Also AzureML offers
    a very good R-support! So, feel free to adapt everything from this article to
    your needs. And before we begin, a few words about how I came to the idea to write
    about Azure and Data Science.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '-   在这篇文章中，我们将探讨微软的Azure机器学习环境，以及如何将云技术与Python和Jupyter结合使用。如你所知，我在整个文章系列中广泛使用了这些工具，因此我对数据科学友好的环境应该是什么样的有着坚定的看法。当然，并不是说其他编码环境或语言，比如R，就不合适，所以你的观点可能与我的大相径庭，这也是正常的。此外，AzureML提供了非常好的R支持！因此，欢迎根据你的需求调整这篇文章中的所有内容。在开始之前，简要介绍一下我是如何想到写关于Azure和数据科学的文章的。'
- en: '**[Part 7: Using Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**[第 7 部分：使用 Azure ML](http://blog.brakmic.com/data-science-for-losers-part-7-using-azure-ml/)**'
- en: While finishing my Data Science and ML Essentials course, I discovered that
    Azure ML has a built-in support for Jupyter and Python which, of course, made
    it very interesting to me because it makes Azure ML an ideal ground for experimentation.
    They even call one of their working areas “Experiments” so one can expect good
    Python (and R) support and many cool off-the-shelf modules. Being no different
    than other tech-enthusiasts I quickly decided to write an article describing some
    of the key parts of Azure ML.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成我的数据科学和机器学习基础课程时，我发现 Azure ML 内置支持 Jupyter 和 Python，这当然让我非常感兴趣，因为它使 Azure
    ML 成为实验的理想平台。他们甚至将一个工作区称为“实验”，因此可以期待良好的 Python（和 R）支持以及许多酷的现成模块。与其他技术爱好者一样，我很快决定撰写一篇文章，描述
    Azure ML 的一些关键部分。
- en: '**Bio: [Harris Brakmić](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic))
    is a Software Developer at Advarics GmbH. He writes WebApps with Ractive, React,
    Backbone & DevExtreme, and Azure-based backends with C#.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [哈里斯·布拉克米奇](http://blog.brakmic.com/)** ([@brakmic](https://twitter.com/brakmic))
    是 Advarics GmbH 的软件开发者。他使用 Ractive、React、Backbone 和 DevExtreme 编写 Web 应用程序，并使用
    C# 开发基于 Azure 的后端。'
- en: '**Related:**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Machine Learning: A Complete and Detailed Overview](/2016/10/machine-learning-complete-detailed-overview.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习：完整详尽概述](/2016/10/machine-learning-complete-detailed-overview.html)'
- en: '[An Introduction to the MXNet Python API ](/2017/05/intro-mxnet-python-api.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MXNet Python API 简介]( /2017/05/intro-mxnet-python-api.html)'
- en: '[Getting Into Data Science: What You Need to Know](/2017/05/data-science-need-to-know.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[进入数据科学：你需要知道的]( /2017/05/data-science-need-to-know.html)'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas 入门教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
- en: '[Reinforcement Learning for Newbies](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手强化学习](https://www.kdnuggets.com/2022/05/reinforcement-learning-newbies.html)'
- en: '[Software Developer vs Software Engineer](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[软件开发者与软件工程师](https://www.kdnuggets.com/2022/05/software-developer-software-engineer.html)'
- en: '[High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高保真合成数据，适用于数据工程师和数据科学家](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
- en: '[We Don''t Need Data Scientists, We Need Data Engineers](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们不需要数据科学家，我们需要数据工程师](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
- en: '[How Do Data Scientists and Data Engineers Work Together?](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家和数据工程师如何协作？](https://www.kdnuggets.com/2022/08/data-scientists-data-engineers-work-together.html)'
