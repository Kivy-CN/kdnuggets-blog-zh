- en: A 2019 Guide to Semantic Segmentation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2019年语义分割指南
- en: 原文：[https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html?page=2#comments)![Figure](../Images/07f5a30cb23b66cb64bace083c9f4c55.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](https://www.kdnuggets.com/2019/08/2019-guide-semantic-segmentation.html?page=2#comments)![图](../Images/07f5a30cb23b66cb64bace083c9f4c55.png)'
- en: '[Image Source](https://pixabay.com/photos/traffic-locomotion-roadway-mobility-3612474/)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://pixabay.com/photos/traffic-locomotion-roadway-mobility-3612474/)'
- en: Semantic segmentation refers to the process of linking each pixel in an image
    to a class label. These labels could include a person, car, flower, piece of furniture,
    etc., just to mention a few.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割指的是将图像中的每个像素链接到一个类标签的过程。这些标签可以包括人、车、花、家具等，仅举几例。
- en: We can think of semantic segmentation as [image classification](https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864) at
    a pixel level. For example, in an image that has many cars, segmentation will
    label all the objects as car objects. However, a separate class of models known
    as instance segmentation is able to label the separate instances where an object
    appears in an image. This kind of segmentation can be very useful in applications
    that are used to count the number of objects, such as counting the amount of foot
    traffic in a mall.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将语义分割视为[图像分类](https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864)在像素级别的应用。例如，在一张包含多辆汽车的图像中，分割会将所有对象标记为汽车对象。然而，一种被称为实例分割的模型类别可以标记图像中对象出现的不同实例。这种分割在用于计算对象数量的应用中非常有用，比如计算商场中的人流量。
- en: Some of its primary applications are in autonomous vehicles, human-computer
    interaction, robotics, and [photo editing/creativity tools](https://heartbeat.fritz.ai/momento-animating-memories-with-immersive-gifs-powered-by-mobile-machine-learning-81ff52806ae3).
    For example, semantic segmentation is very crucial in self-driving cars and robotics
    because it is important for the models to understand the context in the environment
    in which they’re operating.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 它的一些主要应用包括自动驾驶汽车、人机交互、机器人以及[照片编辑/创意工具](https://heartbeat.fritz.ai/momento-animating-memories-with-immersive-gifs-powered-by-mobile-machine-learning-81ff52806ae3)。例如，语义分割在自动驾驶汽车和机器人中非常关键，因为模型需要理解它们操作环境的上下文。
- en: '![Figure](../Images/0789908d1ccda658ce70c44dd3d29c92.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/0789908d1ccda658ce70c44dd3d29c92.png)'
- en: '[source](http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf)'
- en: 'We’ll now look at a number of research papers on covering state-of-the-art
    approaches to building semantic segmentation models, namely:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探讨一些研究论文，涵盖了构建语义分割模型的最先进方法，即：
- en: '[Weakly- and Semi-Supervised Learning of a Deep Convolutional Network for Semantic
    Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#7efa)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[弱监督和半监督学习的深度卷积网络用于语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#7efa)'
- en: '[Fully Convolutional Networks for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#9141)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于语义分割的全卷积网络](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#9141)'
- en: '[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#6ad7)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[U-Net：用于生物医学图像分割的卷积网络](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#6ad7)'
- en: '[The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#3e4b)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一百层提拉米苏：用于语义分割的全卷积DenseNets](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#3e4b)'
- en: '[Multi-Scale Context Aggregation by Dilated Convolutions](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#851f)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过膨胀卷积进行多尺度上下文聚合](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#851f)'
- en: '[DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully Connected CRFs](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#60e4)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DeepLab: 使用深度卷积网络、膨胀卷积和全连接CRFs进行语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#60e4)'
- en: '[Rethinking Atrous Convolution for Semantic Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#a1f6)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[重新思考空洞卷积用于语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#a1f6)'
- en: '[Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#1fc4)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带有空洞可分离卷积的编码器-解码器用于语义图像分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#1fc4)'
- en: '[FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#f083)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FastFCN: 重新思考主干网络中的膨胀卷积用于语义分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#f083)'
- en: '[Improving Semantic Segmentation via Video Propagation and Label Relaxation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#ec16)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过视频传播和标签松弛改进语义分割](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#ec16)'
- en: '[Gated-SCNN: Gated Shape CNNs for Semantic Segmentation](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#b3f5)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gated-SCNN: 用于语义分割的门控形状 CNN](https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc#b3f5)'
- en: Passionate about machine learning? Same! We’re curating each week’s biggest
    stories, best tutorials, and latest research so you don’t have to. [Sign up for
    weekly updates delivered to your inbox](https://www.deeplearningweekly.com/newsletter?utm_campaign=dlweekly-newsletter-timesaver4&utm_source=heartbeat).
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对机器学习充满热情？我也是！我们每周整理最重要的新闻、最佳教程和最新研究，让你无需费心。 [注册每周更新，直接送到你的邮箱](https://www.deeplearningweekly.com/newsletter?utm_campaign=dlweekly-newsletter-timesaver4&utm_source=heartbeat)。
- en: Weakly- and Semi-Supervised Learning of a Deep Convolutional Network for Semantic
    Image Segmentation (ICCV, 2015)
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 弱监督和半监督学习深度卷积网络用于语义图像分割（ICCV，2015）
- en: This paper proposes a solution to the challenge of dealing with weakly-labeled
    data in deep convolutional neural networks (CNNs), as well as a combination of
    data that’s well-labeled and data that’s not properly labeled.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种解决在深度卷积神经网络（CNN）中处理弱标签数据的挑战的方法，以及对良好标注数据和标注不充分的数据的组合。
- en: In the paper, a combination of deep CNNs with a fully-connected conditional [random
    field](https://en.wikipedia.org/wiki/Conditional_random_field) is applied.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中应用了深度 CNN 与完全连接的条件 [随机场](https://en.wikipedia.org/wiki/Conditional_random_field) 的组合。
- en: '**[Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation](https://arxiv.org/abs/1502.02734?source=post_page---------------------------)**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**[弱监督和半监督学习用于语义图像分割](https://arxiv.org/abs/1502.02734?source=post_page---------------------------)**'
- en: '*Deep convolutional neural networks (DCNNs) trained on a large number of images
    with strong pixel-level annotations have...*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*在大量强像素级注释图像上训练的深度卷积神经网络（DCNNs）...*'
- en: On the PASCAL VOC segmentation benchmark, this model gives a [mean intersection-over-union
    (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) score
    above 70%. One of the major challenges faced with this kind of model is that it
    requires images that are annotated at the pixel level during training.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PASCAL VOC 分割基准上，该模型的 [平均交并比 (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) 得分超过
    70%。这种模型面临的主要挑战之一是训练时需要像素级注释的图像。
- en: '![Figure](../Images/1020f5e46e86498cb31e25b77c7fcc11.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/1020f5e46e86498cb31e25b77c7fcc11.png)'
- en: '[source](https://arxiv.org/pdf/1502.02734.pdf)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1502.02734.pdf)'
- en: 'The main contributions of this paper are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的主要贡献包括：
- en: Introduction of Expectation-Maximization algorithms for bounding box or image-level
    training that can be applied to both weakly-supervised and semi-supervised settings.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍了适用于弱监督和半监督设置的边界框或图像级训练的期望最大化算法。
- en: Proves that combining weak and strong annotations improves performance. The
    writers of this paper reach 73.9% IOU performance on PASCAL VOC 2012 after merging
    annotations from the MS-COCO datasets and PASCAL datasets.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明了结合弱注释和强注释能提高性能。本文作者通过合并 MS-COCO 数据集和 PASCAL 数据集的注释，在 PASCAL VOC 2012 上达到了
    73.9% 的 IOU 性能。
- en: Proves that their approach achieves higher performance by merging a small number
    of pixel-level annotated images and a large number of bounding-box or image-level
    annotated images.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明了通过合并少量像素级注释图像和大量边界框或图像级注释图像，其方法能够实现更高的性能。
- en: '![Figure](../Images/70e1751ad5aa724af01578f46e6e8623.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/70e1751ad5aa724af01578f46e6e8623.png)'
- en: '[source](https://arxiv.org/pdf/1502.02734.pdf)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/pdf/1502.02734.pdf)'
- en: Fully Convolutional Networks for Semantic Segmentation (PAMI, 2016)
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用于语义分割的全卷积网络（PAMI，2016）
- en: The model proposed in this paper achieves a performance of 67.2% mean IU on
    PASCAL VOC 2012.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出的模型在PASCAL VOC 2012上达到了67.2%的平均交并比（mean IU）性能。
- en: '**[Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211?source=post_page---------------------------)**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[用于语义分割的全卷积网络](https://arxiv.org/abs/1605.06211?source=post_page---------------------------)**'
- en: '*Convolutional networks are powerful visual models that yield hierarchies of
    features. We show that convolutional...*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*卷积网络是强大的视觉模型，可以产生特征层次。我们展示了卷积网络...*'
- en: Fully-connected networks take an image of any size and generate an output of
    the corresponding spatial dimensions. In this model, [ILSVRC classifiers](http://image-net.org/challenges/LSVRC/)are
    cast into fully-connected networks and augmented for dense prediction using pixel-wise
    loss and in-network up-sampling. Training for segmentation is then done by fine-tuning.
    Fine-tuning is done by back-propagation on the entire network.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接网络接收任意大小的图像，并生成相应空间尺寸的输出。在该模型中，[ILSVRC分类器](http://image-net.org/challenges/LSVRC/)被转换为全连接网络，并通过像素级损失和网络内上采样进行密集预测的增强。然后通过微调进行分割训练。微调通过对整个网络进行反向传播完成。
- en: '![Figure](../Images/3ae028eb91479ce7bc8825f79bb2b4a4.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3ae028eb91479ce7bc8825f79bb2b4a4.png)'
- en: '[source](https://arxiv.org/pdf/1605.06211.pdf)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/pdf/1605.06211.pdf)'
- en: 'U-Net: Convolutional Networks for Biomedical Image Segmentation (MICCAI, 2015)'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: U-Net：用于生物医学图像分割的卷积网络（MICCAI，2015）
- en: In biomedical image processing, it’s very crucial to get a class label for every
    cell in the image. The biggest challenge in biomedical tasks is that thousands
    of images for training are not easily accessible.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物医学图像处理中，为图像中的每个细胞获得类别标签是非常关键的。生物医学任务中的最大挑战是很难获得成千上万的训练图像。
- en: '[**U-Net: Convolutional Networks for Biomedical Image Segmentation**](https://arxiv.org/abs/1505.04597?source=post_page---------------------------)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[**U-Net：用于生物医学图像分割的卷积网络**](https://arxiv.org/abs/1505.04597?source=post_page---------------------------)'
- en: '*There is large consent that successful training of deep networks requires
    many thousand annotated training samples. In...*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*有广泛共识认为，成功训练深度网络需要成千上万的标注训练样本。 在...*'
- en: This paper builds upon the fully convolutional layer and modifies it to work
    on a few training images and yield more precise segmentation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本文基于全卷积层，并对其进行修改以便在少量训练图像上工作，从而实现更精确的分割。
- en: '![Figure](../Images/31f03b8b104d2569ff4f424247711c4f.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/31f03b8b104d2569ff4f424247711c4f.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/abs/1505.04597)'
- en: Since very little training data is available, this model uses data augmentation
    by applying elastic deformations on the available data. As illustrated in figure
    1 above, the network architecture is made up of a contracting path on the left
    and an expansive path on the right.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可用的训练数据非常有限，因此该模型通过对现有数据应用弹性变形来进行数据增强。如上图1所示，网络架构由左侧的收缩路径和右侧的扩展路径组成。
- en: The contracting path is made up of two 3x3 convolutions. Each of the convolutions
    is followed by a rectified linear unit and a 2x2 max pooling operation for downsampling.
    Every downsampling stage doubles the number of feature channels. The expansive
    path steps include an upsampling of the feature channels. This is followed by
    2x2 up-convolution that halves the number of feature channels. The final layer
    is a 1x1 convolution that is used to map the component feature vectors to the
    required number of classes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩路径由两个3x3卷积层组成。每个卷积层后面跟随一个修正线性单元和一个2x2最大池化操作进行下采样。每个下采样阶段都会使特征通道数量翻倍。扩展路径的步骤包括特征通道的上采样。随后是2x2的上卷积，将特征通道数量减半。最后一层是1x1卷积，用于将组件特征向量映射到所需的类别数量。
- en: '![Figure](../Images/695df8cbe9fd49e377be06a203db4c6b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/695df8cbe9fd49e377be06a203db4c6b.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[源文](https://arxiv.org/abs/1505.04597)'
- en: In this model, training is done using the input images, their segmentation maps,
    and a stochastic gradient descent implementation of Caffe. Data augmentation is
    used to teach the network the required robustness and invariance when very little
    training data is used. This model achieved a [mean intersection-over-union (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) score
    of 92% on one of the experiments.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，训练使用输入图像、其分割图以及 Caffe 的随机梯度下降实现。数据增强被用来教会网络在使用非常少的训练数据时所需的鲁棒性和不变性。该模型在实验中的一个测试上达到了[平均交并比
    (IOU)](https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)
    92% 的得分。
- en: '![Figure](../Images/819be25a915d06b500daccd66923bf07.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/819be25a915d06b500daccd66923bf07.png)'
- en: '[source](https://arxiv.org/abs/1505.04597)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/abs/1505.04597)'
- en: 'The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation (2017)'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 《一百层 Tiramisu：用于语义分割的全卷积 DenseNets》（2017）
- en: The idea behind DenseNets is that having each layer connected to every layer
    in a feed-forward manner makes the network easier to train and more accurate.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: DenseNets 的核心思想是让每一层以前馈方式连接到每一层，这样可以使网络更容易训练且更准确。
- en: '[**The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic
    Segmentation**](https://arxiv.org/abs/1611.09326?source=post_page---------------------------)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[**一百层 Tiramisu：用于语义分割的全卷积 DenseNets**](https://arxiv.org/abs/1611.09326?source=post_page---------------------------)'
- en: '*State-of-the-art approaches for semantic image segmentation are built on Convolutional
    Neural Networks (CNNs). The...*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*最先进的语义图像分割方法建立在卷积神经网络 (CNNs) 的基础上。...*'
- en: The model’s architecture is built in dense blocks of downsampling and upsampling
    paths. The downsampling path has 2 Transitions Down (TD) while the upsampling
    path has 2 Transitions Up (TU). The circle and arrows represent connectivity patterns
    within the network.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的架构由下采样和上采样路径的密集块构成。下采样路径有 2 个过渡下采样（TD），而上采样路径有 2 个过渡上采样（TU）。圆圈和箭头表示网络内部的连接模式。
- en: '![Figure](../Images/f81b34a6f31353f1cf4225530d1d1699.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/f81b34a6f31353f1cf4225530d1d1699.png)'
- en: '[source](https://arxiv.org/pdf/1611.09326.pdf)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1611.09326.pdf)'
- en: 'The main contributions of this paper are:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文的主要贡献有：
- en: Extends the DenseNet architecture to fully convolutional networks for use in
    semantic segmentation.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展了 DenseNet 架构到全卷积网络，用于语义分割。
- en: Proposes upsampling paths from dense networks that perform better than other
    upsampling paths.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出了从密集网络中进行上采样路径，这些路径的表现优于其他上采样路径。
- en: Proves that the network can produce state-of-the-art results on standard benchmarks.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明了该网络可以在标准基准上产生最先进的结果。
- en: This model achieves a global accuracy of 88% on the [CamVid dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在 [CamVid 数据集](http://mi.eng.cam.ac.uk/research/projects/VideoRec/) 上达到了
    88% 的全球准确率。
- en: '![](../Images/8c59a5ac4ebeee0242d1b5d5324ae9b5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c59a5ac4ebeee0242d1b5d5324ae9b5.png)'
- en: '![Figure](../Images/d072fcb801ed0438b4ba74eb68b392fe.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/d072fcb801ed0438b4ba74eb68b392fe.png)'
- en: '[source](https://arxiv.org/pdf/1611.09326.pdf)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://arxiv.org/pdf/1611.09326.pdf)'
- en: '* * *'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Misconceptions About Semantic Segmentation Annotation](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[关于语义分割注释的误解](https://www.kdnuggets.com/2022/01/misconceptions-semantic-segmentation-annotation.html)'
- en: '[The Power of a Semantic Layer: A Data Engineer''s Guide](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层的力量：数据工程师指南](https://www.kdnuggets.com/2023/10/cube-power-of-a-semantic-layer-a-data-engineers-guide)'
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义向量搜索如何改变客户支持互动](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
- en: '[Semantic Search with Vector Databases](https://www.kdnuggets.com/semantic-search-with-vector-databases)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用向量数据库进行语义搜索](https://www.kdnuggets.com/semantic-search-with-vector-databases)'
- en: '[Semantic Layer: The Backbone of AI-powered Data Experiences](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义层：AI驱动的数据体验的支柱](https://www.kdnuggets.com/2023/10/cube-semantic-layer-backbone-aipowered-data-experiences)'
- en: '[6 Reasons Why a Universal Semantic Layer is Beneficial to Your Data Stack](https://www.kdnuggets.com/2024/01/cube-6-reasons-why-a-universal-semantic-layer-is-beneficial)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通用语义层对你的数据栈的6个好处](https://www.kdnuggets.com/2024/01/cube-6-reasons-why-a-universal-semantic-layer-is-beneficial)'
