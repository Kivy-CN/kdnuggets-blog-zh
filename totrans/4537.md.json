["```py\nimport nltk\nimport random\nimport string\nimport re, string, unicodedata\nfrom nltk.corpus import wordnet as wn\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport wikipedia as wk\nfrom collections import defaultdict\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnltk.download('punkt') \nnltk.download('wordnet')\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n```", "```py\ndata = open('/../../chatbot/HR.txt','r',errors = 'ignore')\nraw = data.read()\nraw = raw.lower()\n```", "```py\nraw[:1000]\n'human resource management is the process of recruiting, selecting, inducting employees, providing orientation, imparting training and development, appraising the performance of employees, deciding compensation and providing benefits, motivating employees, maintaining proper relations with employees and their trade unions, ensuring employees safety, welfare and healthy measures in compliance with labour laws of the land.\\nhuman resource management involves management functions like planning, organizing, directing and controlling\\nit involves procurement, development, maintenance of human resource\\nit helps to achieve individual, organizational and social objectives\\nhuman resource management is a multidisciplinary subject. it includes the study of management, psychology, communication, economics and sociology.\\nit involves team spirit and team work.\\nit is a continuous process.\\nhuman resource management as a department in an organisation handles all aspects of employees and has various functi'\n```", "```py\nsent_tokens = nltk.sent_tokenize(raw)\n```", "```py\ndef Normalize(text):\n    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n    #word tokenization\n    word_token = nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n\n    #remove ascii\n    new_words = []\n    for word in word_token:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n\n    #Remove tags\n    rmv = []\n    for w in new_words:\n        text=re.sub(\"&lt;/?.*?&gt;\",\"&lt;&gt;\",w)\n        rmv.append(text)\n\n    #pos tagging and lemmatization\n    tag_map = defaultdict(lambda : wn.NOUN)\n    tag_map['J'] = wn.ADJ\n    tag_map['V'] = wn.VERB\n    tag_map['R'] = wn.ADV\n    lmtzr = WordNetLemmatizer()\n    lemma_list = []\n    rmv = [i for i in rmv if i]\n    for token, tag in nltk.pos_tag(rmv):\n        lemma = lmtzr.lemmatize(token, tag_map[tag[0]])\n        lemma_list.append(lemma)\n    return lemma_list\n```", "```py\nwelcome_input = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nwelcome_response = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef welcome(user_response):\n    for word in user_response.split():\n        if word.lower() in welcome_input:\n            return random.choice(welcome_response)\n```", "```py\ndef generateResponse(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=Normalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    #vals = cosine_similarity(tfidf[-1], tfidf)\n    vals = linear_kernel(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0) or \"tell me about\" in user_response:\n        print(\"Checking Wikipedia\")\n        if user_response:\n            robo_response = wikipedia_data(user_response)\n            return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response#wikipedia search\ndef wikipedia_data(input):\n    reg_ex = re.search('tell me about (.*)', input)\n    try:\n        if reg_ex:\n            topic = reg_ex.group(1)\n            wiki = wk.summary(topic, sentences = 3)\n            return wiki\n    except Exception as e:\n            print(\"No content has been found\")\n```", "```py\nflag=True\nprint(\"My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response not in ['bye','shutdown','exit', 'quit']):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"Chatterbot : You are welcome..\")\n        else:\n            if(welcome(user_response)!=None):\n                print(\"Chatterbot : \"+welcome(user_response))\n            else:\n                print(\"Chatterbot : \",end=\"\")\n                print(generateResponse(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"Chatterbot : Bye!!! \")\n```"]