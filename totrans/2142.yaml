- en: How to Make Large Language Models Play Nice with Your Software Using LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/036f2f1921d5d651c1a5c147edef3126.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) like OpenAI’s GPT-3, Google’s BERT, and Meta’s
    LLaMA are revolutionizing various sectors with their ability to generate a wide
    array of text?—?from marketing copy and data science scripts to poetry.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Even though ChatGPT’s intuitive interface has managed to be in most people's
    devices today, there’s still a vast landscape of untapped potential for using
    LLMs in diverse software integrations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The main problem?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Most applications require more fluid and native communication with LLMs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: And this is precisely where LangChain kicks in!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in Generative AI and LLMs, this tutorial is tailor-made
    for you.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: So… let’s start!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: What are LLMs?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Just in case you have been living within a cave and haven’t gotten any news
    lately, I’ll briefly explain Large Language Models or LLMs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: An LLM is a sophisticated artificial intelligence system built to mimic human-like
    textual understanding and generation. By training on enormous data sets, these
    models discern intricate patterns, grasp linguistic subtleties, and produce coherent
    outputs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wonder how to interact with these AI-powered models, there are two main
    ways to do so:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The most common and direct way is talking or chatting with the model. It involves
    crafting a prompt, sending it to the AI-powered model, and getting a text-based
    output as a response.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another method is converting text into numerical arrays. This process involves
    composing a prompt for the AI and receiving a numerical array in return. What
    is commonly known as an “embedding”. It has experienced a recent surge in Vector
    Databases and semantic search.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And it is precisely these two main problems that LangChain tries to address.
    If you are interested in the main problems of interacting with LLMs, you can check
    this article [here](/6-problems-of-llms-that-langchain-is-trying-to-assess).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: LangChain and its basics
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LangChain is an open-source framework built around LLMs. It brings to the table
    an arsenal of tools, components, and interfaces that streamline the architecture
    of LLM-driven applications.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: With LangChain, engaging with language models, interlinking diverse components,
    and incorporating assets like APIs and databases become a breeze. This intuitive
    framework substantially simplifies the LLM application development journey.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: The core idea of Long Chain is that we can connect together different components
    or modules, also known as chains, to create more sophisticated LLM-powered solutions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some standout features of LangChain:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Customizable prompt templates to standardize our interactions.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chain link components tailored for sophisticated use cases.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Seamless integration with leading language models, including OpenAI’s GPTs and
    those on HuggingFace Hub.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Modular components for a mix-and-match approach to assess any specific problem
    or task.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/6211aeddcec56539aa3c0d9df71e8a99.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is distinguished by its focus on adaptability and modular design.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The main idea behind LangChain is breaking down the natural language processing
    sequence into individual parts, allowing developers to customize workflows based
    on their requirements.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Such versatility positions LangChain as a prime choice for building AI solutions
    in different situations and industries.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Some of its most important components are…
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Make Large Language Models Play Nice with Your Software using LangChain](../Images/4aba22d72f234ac9cc55081a479a1e3c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 1\. LLMs
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are fundamental components that leverage vast amounts of training data
    to understand and generate human-like text. They are at the core of many operations
    within LangChain, providing the necessary language processing capabilities to
    analyze, interpret, and respond to text input.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Powering chatbots, generating human-like text for various applications,
    aiding in information retrieval, and performing other language processing'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Prompt templates
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompts are fundamental for interacting with LLM, and when working on specific
    tasks, their structure tends to be similar. Prompt templates, which are preset
    prompts usable across chains, allow standardization of “prompts” by adding specific
    values. This enhances the adaptability and customization of any LLM.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Standardizing the process of interacting with LLMs.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Output Parsers
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Output parsers are components that take the raw output from a preceding stage
    in the chain and convert it into a structured format. This structured data can
    then be used more effectively in subsequent stages or delivered as a response
    to the end user.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** For instance, in a chatbot, an output parser might take the raw
    text response from a language model, extract key pieces of information, and format
    them into a structured reply.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Components and chains
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In LangChain, each component acts as a module responsible for a particular task
    in the language processing sequence. These components can be connected to form
    *chains* for customized workflows.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Generating sentiment detection and response generator chains in
    a specific chatbot.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Memory
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory in LangChain refers to a component that provides a storage and retrieval
    mechanism for information within a workflow. This component allows for the temporary
    or persistent storage of data that can be accessed and manipulated by other components
    during the interaction with the LLM.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** This is useful in scenarios where data needs to be retained across
    different stages of processing, for example, storing conversation history in a
    chatbot to provide context-aware responses.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Agents
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agents are autonomous components capable of taking actions based on the data
    they process. They can interact with other components, external systems, or users,
    to perform specific tasks within a LangChain workflow.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** For instance, an agent might handle user interactions, process incoming
    requests, and coordinate the flow of data through the chain to generate appropriate
    responses.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Indexes and Retrievers
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Indexes and Retrievers play a crucial role in managing and accessing data efficiently.
    Indexes are data structures holding information and metadata from the model’s
    training data. On the other hand, retrievers are mechanisms that interact with
    these indexes to fetch relevant data based on specified criteria and allow the
    model to reply better by supplying relevant context.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** They are instrumental in quickly fetching relevant data or documents
    from a large dataset, which is essential for tasks like information retrieval
    or question answering.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Document Transformers
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In LangChain, Document Transformers are specialized components designed to process
    and transform documents in a way that makes them suitable for further analysis
    or processing. These transformations may include tasks such as text normalization,
    feature extraction, or the conversion of text into a different format.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Preparing text data for subsequent processing stages, such as analysis
    by machine learning models or indexing for efficient retrieval.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 9\. Embedding Models
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: They are used to convert text data into numerical vectors in a high-dimensional
    space. These models capture semantic relationships between words and phrases,
    enabling a machine-readable representation. They form the foundation for various
    downstream Natural Language Processing (NLP) tasks within the LangChain ecosystem.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Facilitating semantic searches, similarity comparisons, and other
    machine-learning tasks by providing a numerical representation of text.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Vector stores
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Type of database system that specializes to store and search information via
    embeddings, essentially analyzing numerical representations of text-like data.
    VectorStore serves as a storage facility for these embeddings.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '**Usage:** Allowing efficient search based on semantic similarity.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**用法：** 允许基于语义相似性进行高效搜索。'
- en: Setting it up and first examples
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和第一个示例
- en: Installing it using PIP
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PIP 安装
- en: The first thing we have to do is make sure we have LangChain installed in our
    environment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要确保环境中已安装 LangChain。
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Environment setup
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 环境设置
- en: Utilizing LangChain typically means integrating with diverse model providers,
    data stores, APIs, among other components. And as you already know, like any integration,
    supplying the relevant and correct API keys is crucial for LangChain's operation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LangChain 通常意味着与多种模型提供者、数据存储、API 以及其他组件进行集成。正如你已经知道的那样，与任何集成一样，提供相关且正确的 API
    密钥对 LangChain 的操作至关重要。
- en: 'Imagine we want to use our OpenAI API. We can easily accomplish this in two
    ways:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下我们要使用我们的 OpenAI API。我们可以通过两种方式轻松实现这一点：
- en: Setting up key as an environment variable
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将密钥设置为环境变量
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: or
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you choose not to establish an environment variable, you have the option
    to provide the key directly through the openai_api_key named parameter when initiating
    the OpenAI LLM class:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择不建立环境变量，你可以在初始化 OpenAI LLM 类时通过名为 openai_api_key 的参数直接提供密钥：
- en: Directly set up the key in the relevant class.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接在相关类中设置密钥。
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: LangChain in action
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 的实际应用
- en: Switching between LLMs becomes straightforward
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 LLM 之间切换变得非常简单
- en: LangChain provides an LLM class that allows us to interact with different language
    model providers, such as OpenAI and Hugging Face.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 提供了一个 LLM 类，使我们可以与不同的语言模型提供者（如 OpenAI 和 Hugging Face）进行交互。
- en: It is quite easy to get started with any LLM, as the most basic and easiest-to-implement
    functionality of any LLM is just generating text.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用任何 LLM 都相当容易，因为任何 LLM 最基本、最容易实现的功能就是生成文本。
- en: However, asking the very same prompt to different LLMs at once is not so easy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，同时向不同的 LLM 提问相同的提示并不是那么容易。
- en: This is where LangChain kicks in…
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 LangChain 发挥作用的地方……
- en: Getting back to the easiest functionality of any LLM, we can easily build an
    application with LangChain that gets a string prompt and returns the output of
    our designated LLM..
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 回到任何 LLM 最简单的功能，我们可以轻松地使用 LangChain 构建一个应用程序，该应用程序获取一个字符串提示，并返回我们指定 LLM 的输出。
- en: Code by Author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: We can simply use the same prompt and get the response of two different models
    within few lines of code!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以仅用几行代码，使用相同的提示并获取两个不同模型的响应！
- en: Code by Author
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: Impressive… right?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 令人印象深刻……对吧？
- en: Giving structure to our prompts with prompt templates
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示模板为我们的提示赋予结构
- en: A common issue with Language Models (LLMs) is their inability to escalate complex
    applications. LangChain addresses this by offering a solution to streamline the
    process of creating prompts, which is often more intricate than just defining
    a task as it requires outlining the AI's persona and ensuring factual accuracy.
    A significant part of this involves repetitive boilerplate text. LangChain alleviates
    this by offering prompt templates, which auto-include boilerplate text in new
    prompts, thus simplifying prompt creation and ensuring consistency across different
    tasks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型（LLMs）常见的问题是它们无法升级复杂的应用程序。LangChain 通过提供简化创建提示过程的解决方案来解决这一问题，这通常比定义任务更为复杂，因为它需要概述
    AI 的角色并确保事实准确性。这一过程的一个重要部分涉及重复的模板文本。LangChain 通过提供提示模板来缓解这一点，提示模板自动包含模板文本，从而简化提示创建，并确保不同任务之间的一致性。
- en: Code by Author
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: Getting structured responses with output parsers
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用输出解析器获取结构化响应
- en: In chat-based interactions, the model's output is merely text. Yet, within software
    applications, having a structured output is preferable as it allows for further
    programming actions. For instance, when generating a dataset, receiving the response
    in a specific format such as CSV or JSON is desired. Assuming a prompt can be
    crafted to elicit a consistent and suitably formatted response from the AI, there's
    a need for tools to manage this output. LangChain caters to this requirement by
    offering output parser tools to handle and utilize the structured output effectively.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于聊天的互动中，模型的输出仅仅是文本。然而，在软件应用中，拥有结构化的输出更为理想，因为这允许进一步的编程操作。例如，在生成数据集时，希望以 CSV
    或 JSON 等特定格式接收响应。假设可以设计一个提示以引导 AI 提供一致且格式合适的响应，那么就需要工具来管理这种输出。LangChain 通过提供输出解析器工具来满足这一需求，从而有效处理和利用结构化输出。
- en: Code by Author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 代码由作者提供
- en: You can go check the whole code on my [GitHub](https://github.com/rfeers/LangChain/blob/main/1_Main_Basics_of_LangChain.ipynb).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Not long ago, the advanced capabilities of ChatGPT left us in awe. Yet, the
    technological environment is ever-changing, and now tools like LangChain are at
    our fingertips, allowing us to craft outstanding prototypes from our personal
    computers in just a few hours.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: LangChain, a freely available Python platform, provides a means for users to
    develop applications anchored by LLMs (Language Model Models). This platform delivers
    a flexible interface to a variety of foundational models, streamlining prompt
    handling and acting as a nexus for elements like prompt templates, more LLMs,
    external information, and other resources via agents, as of the current documentation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Imagine chatbots, digital assistants, language translation tools, and sentiment
    analysis utilities; all these LLM-enabled applications come to life with LangChain.
    Developers utilize this platform to craft custom-tailored language model solutions
    addressing distinct requirements.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: As the horizon of natural language processing expands, and its adoption deepens,
    the realm of its applications seems boundless.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Open Source Large Language Models](https://www.kdnuggets.com/2022/09/john-snow-top-open-source-large-language-models.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[More Free Courses on Large Language Models](https://www.kdnuggets.com/2023/06/free-courses-large-language-models.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn About Large Language Models](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing Healthcare-Specific Large Language Models from John Snow Labs](https://www.kdnuggets.com/2023/04/john-snow-introducing-healthcare-specific-large-language-models-john-snow-labs.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What are Large Language Models and How Do They Work?](https://www.kdnuggets.com/2023/05/large-language-models-work.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
