- en: Real Time Image Segmentation Using 5 Lines of Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/10/real-time-image-segmentation-5-lines-code.html](https://www.kdnuggets.com/2021/10/real-time-image-segmentation-5-lines-code.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/),
    Machine Learning Engineer**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Demand for Real Time Image Segmentation Applications**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Image segmentation is an aspect of computer vision that deals with segmenting
    the contents of objects visualized by a computer into different categories for
    better analysis. The contributions of image segmentation in solving a lot of computer
    vision problems such as analysis of medical images, background editing, vision
    in self driving cars and analysis of satellite images make it an invaluable field
    in computer vision. One of the greatest challenges in computer vision is keeping
    the space between accuracy and speed performance for real time applications. In
    the field of computer vision there is this dilemma of a computer vision solution
    either being more accurate and slow or less accurate and faster.
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib Library is a library created to allow easy integration of object segmentation
    in images and videos using few lines of python code. The previous version of PixelLib
    uses Tensorflow deep learning as its backend which employs Mask R-CNN to perform
    instance segmentation. Mask R-CNN is a great object segmentation architecture,
    but it fails to balance between the accuracy and speed performance for real time
    applications.  PixelLib provides support for PyTorch backend to perform faster,
    more accurate segmentation and extraction of objects in images and videos using ***PointRend ***segmentation
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: '***PointRend*** by [Alexander Kirillov et al](https://arxiv.org/abs/1912.08193) is
    used to replace Mask R-CNN for performing instance segmentation of objects. ***PointRend*** is
    an excellent state of the art neural network for implementing object segmentation.
    It generates accurate segmentation masks and run at high inference speed that
    matches the increasing demand for an accurate and real time computer vision applications.
    I integrated PixelLib with the python implementation of PointRend by Detectron2
    which supports only Linux OS. I made modifications to the original Detectron2
    PointRend implementation to support Windows OS. PointRend implementation used
    for PixelLib supports both Linux and Windows OS.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** This article is based on performing instance segmentation using PyTorch
    and ***PointRend.*** If you want to learn how to perform instance segmentation
    with Tensorflow and Mask R-CNN read this [article](https://towardsdatascience.com/image-segmentation-with-six-lines-0f-code-acb870a462e8).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/22bc7c780b4afe84799ac42f72f0cfd6.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Original Image Source](https://unsplash.com/photos/6UWqw25wfLI) (left:MASK
    R-CNN, right:PointRend)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/cb489b9285153f06bae3e2511f8f1e0f.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Original Image Source](https://unsplash.com/photos/rrI02QQ9GSQ) (left:MASK
    R-CNN, right:PointRend)'
  prefs: []
  type: TYPE_NORMAL
- en: The images labelled **PointRend** are obviously better segmentation results
    than **Mask R-CNN**.
  prefs: []
  type: TYPE_NORMAL
- en: Download & Installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Download Python**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib PyTorch supports python version 3.7 and above. Download a compatible
    [python version](https://www.python.org/).
  prefs: []
  type: TYPE_NORMAL
- en: '**Install PixelLib and its dependencies**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Install PyTorch**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib PyTorch version supports these versions of PyTorch(***1.6.0,1.7.1,1.8.0***
    and ***1.90)***. PyTorch ***1.7.0*** is not supported and do not use any PyTorch
    version less than 1.6.0\. Install a compatible [PyTorch version](https://PyTorch.org/).
  prefs: []
  type: TYPE_NORMAL
- en: '**Install Pycocotools**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '**Install PixelLib**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**If installed, upgrade to the latest version using:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '**Image Segmentation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PixelLib uses five lines of python code for performing object segmentation in
    images and videos with PointRend model. Download the [PointRend model](https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet50.pkl).
    This is the code for image segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '**Line 1-4:** PixelLib package was imported and we also imported the class
    ***instanceSegmentation*** from the module ***pixellib.torchbackend.instance***
    (importing instance segmentation class from PyTorch support). We created an instance
    of the class and finally loaded the ***PointRend*** model we have downloaded.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 5:** We called the function ***segmentImage*** to perform segmentation
    of objects in images and added the following parameters to the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Image_path:*** This is the path to the image to be segmented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Show_bbox:*** This is an optional parameter to show the segmented results
    with bounding boxes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Output_image_name:*** This is the name of the saved segmented image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sample Image for Segmentation**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/a8a8466af953d96d9291e39b63072e43.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Original Image Source](https://commons.wikimedia.org/wiki/File:Carspotters.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**Image After Segmentation**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/03a6cceedbc5db33a5d577d457ae424b.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This log above may appear if you are running the segmentation code. It is not
    an error and the code will work fine.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The segmentation results return a dictionary with values associated with the
    objects segmented in the image. The results printed will be in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**Detection Threshold**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib makes it possible to determine the detection threshold of object segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '**confidence:** This is a new parameter introduced in the ***load_model***
    function and it is set to ***0.3*** to threshold the detections by ***30%.***
    The default value I set for detection threshold is ***0.5*** and it can be increased
    or decreased using the ***confidence*** parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speed Records**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib makes it possible to perform real time object segmentation and added
    the ability to adjust the inference speed to suit real time predictions.  The
    default inference speed for processing a single image using Nvidia GPU with 4GB
    capacity is about ***0.26 seconds***.
  prefs: []
  type: TYPE_NORMAL
- en: '**Speed Adjustments**'
  prefs: []
  type: TYPE_NORMAL
- en: 'PixelLib supports speed adjustments and there are two types of speed adjustment
    modes which are ***fast*** and ***rapid*** modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Fast Mode**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the ***load_model*** function, we added the parameter ***detection_speed***
    and set the value to ***fast***. The fast mode achieves ***0.20 seconds*** for
    processing a single image.
  prefs: []
  type: TYPE_NORMAL
- en: '**Full Code for Fast Mode Detection**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**2\. Rapid Mode**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the ***load_model*** function, we added the parameter ***detection_speed***
    and set the value to ***rapid***. The **rapid** mode achieves ***0.15 seconds***
    for processing a single image.
  prefs: []
  type: TYPE_NORMAL
- en: '**Full Code for Rapid Mode Detection**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '**PointRend Models**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two types of PointRend models used for object segmentation and they
    are of ***resnet50 variant*** and ***resnet101 variant***. The ***resnet50 variant***
    is used throughout this article because it is faster and of good accuracy. The
    ***resnet101 variant*** is more accurate but it is slower than ***resnet50 variant***.
    According to the [official reports](https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend)
    of the models on Detectron2 the ***resnet50 variant*** achieves ***38.3 mAP***
    on COCO and ***resnet101 variant*** achieves ***40.1 mAP*** on COCO.
  prefs: []
  type: TYPE_NORMAL
- en: '**Speed Records for Resnet101:** The default speed for segmentation is ***0.5
    seconds***, fast mode is ***0.3 seconds*** while the rapid mode is ***0.25 seconds***.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code for Resnet101 variant**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The code for performing inference with the resnet101 model is the same, except
    we loaded the ***PointRend resnet101 model*** in the ***load_model*** function.
    Download the resnet101 model from [here](https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet101.pkl).
    We added an extra parameter ***network_backbone*** in the ***load_model*** function
    and set the value to ***resnet101***.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** If you want to achieve high inference speed and good accuracy, use
    **PointRend** ***resnet50 variant***, but if you are more concerned about accuracy,
    use the **PointRend** ***resnet101 variant***. All these inference reports are
    based on using Nvidia GPU with 4GB capacity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Custom Object Detection in Image Segmentation**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PointRend model used is a pretrained COCO model which supports 80 classes
    of objects. PixelLib supports custom object detection which makes it possible
    to filter detections and ensure segmentation of target objects. We can choose
    out of the 80 classes of objects supported to match our target goal. These are
    the 80 classes of objects supported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**Code for Segmentation of Target Classes**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The function ***select_target_classes*** was called to select the target objects
    to be segmented. The function ***segmentImage*** got a new parameter ***segment_target_classes***
    to choose from the target classes and filter the detections based on them. We
    filter the detections to detect only person in the image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/03a6cceedbc5db33a5d577d457ae424b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Object Extractions in Images**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PixelLib makes it possible to extract and analyse objects segmented in an image.
  prefs: []
  type: TYPE_NORMAL
- en: '**Code for Object Extraction**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The code for image segmentation is the same, except we added extra parameters
    ***extract_segmented_objects*** and ***save_extracted_objects*** to extract segmented
    object and save the extracted objects respectively.  Each of the segmented objects
    will be saved as ***segmented_object_index*** e.g ***segmented_object_1***. The
    objects are saved based in the order in which they are extracted.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/8b1a301199f1b4ca6df20a01cd384dcc.png)'
  prefs: []
  type: TYPE_IMG
- en: Note:  All the objects in the image are extracted and I chose to display only
    three of them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Extraction of Object from Bounding Box Coordinates**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We introduced a new parameter ***extract_from_box*** to extract the objects
    segmented from their bounding boxes coordinates. Each of the extracted objects
    will be saved as ***object_extract_index*** e.g ***object_extract_1***. The objects
    are saved in the order in which they are extracted.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/948881319af9a109839b6ad02bbf7278.png)'
  prefs: []
  type: TYPE_IMG
- en: Extracts from Bounding Box Coordinates
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Segmentation Output Visualization**'
  prefs: []
  type: TYPE_NORMAL
- en: PixelLib makes it possible to regulate the visualization of images according
    to their resolutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure](../Images/2eff7a7adc25c50baf6aac1db642d3ee.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Original Image Source](https://unsplash.com/photos/UiVe5QvOhao)'
  prefs: []
  type: TYPE_NORMAL
- en: The visualization wasn’t visible because the ***text size***, and ***box thickness***
    are too slim. We can regulate the ***text size***, ***text thickness***, and ***box
    thickness*** to regulate the visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Modifications for Better Visualization**.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The segmentImage function accepted new parameters that regulate the thickness
    of texts and bounding boxes.
  prefs: []
  type: TYPE_NORMAL
- en: '***text_size:*** The default text size is ***0.6*** and it is okay with images
    with moderate resolutions. It will be too samll for images with high resolutions.
    I increased it to 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***text_thickness:*** The default text thickness is 1\. I increased it to 4
    to match the image resolution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***box_thickness:*** The default box thickness is 2 and I changed it to 10
    to match the image resolution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output Image with A Better Visualization**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/0841dec48cb891e893d87abb233a4a2d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Note:** Regulate the parameters according to the resolutions of your images.
    The values I used for this sample image whose resolution is ***5760 x 3840*** might
    be too large if your image resolution is lower. You can increase the values of
    the parameters beyond the ones I set in this sample code if you have images whose
    resolutions are very high.***text_thickness*** and ***box_thickness*** parameters’
    values must be in integers and do not express their values in floating point numbers. ***text_size*** value
    can be expressed in both integers and floating point numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: We discussed in detail in this article how to perform accurate and fast image
    segmentation and extraction of objects in images. We also described the upgrade
    added to PixelLib using PointRend that makes it possible for the library to match
    the increasing demand to balance between accuracy and speed performance in computer
    vision.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** [Read the full tutorial](https://towardsdatascience.com/real-time-image-segmentation-using-5-lines-of-code-7c480abdb835)
    that includes how to perform object segmentation on a batch of images, videos
    and live camera feeds using PixelLib.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/)**
    is a self-taught programmer, technical writer, and a deep learning practitioner.
    Ayoola has developed two open source computer vision projects that are used by
    many developers across the globe, and presently works as a Machine Learning Engineer
    at DeepQuest AI building and deploying machine learning applications in the cloud.
    Ayoola''s areas of expertise are in computer vision and machine learning. She
    has experience working on machine learning systems, using deep learning libraries
    like PyTorch and Tensorflow to build and deploy machine learning models in production
    on cloud computing platforms like Azure using DevOp tools such as Docker, Pulumi
    and Kubernetes. Ayoola also works on deploying machine learning models on edge
    devices like Nvidia Jetson Nano and Raspberry PI devices using efficient frameworks
    like PyTorchMobile, TensorflowLite and ONNX Runtime.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Extraction of Objects In Images and Videos Using 5 Lines of Code](/2021/03/extraction-objects-images-videos-5-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Change the Background of Any Image with 5 Lines of Code](/2020/11/change-background-image-5-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Change the Background of Any Video with 5 Lines of Code](/2020/12/change-background-video-5-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Multi-modal deep learning in less than 15 lines of code](https://www.kdnuggets.com/2023/01/predibase-multi-modal-deep-learning-less-15-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Build a Real-Time Recommendation Engine Using Graph Databases](https://www.kdnuggets.com/2023/08/build-realtime-recommendation-engine-graph-databases.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Segment Anything Model: Foundation Model for Image Segmentation](https://www.kdnuggets.com/2023/07/segment-anything-model-foundation-model-image-segmentation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Feature Stores for Real-time AI & Machine Learning](https://www.kdnuggets.com/2022/03/feature-stores-realtime-ai-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Real-time Translations with AI](https://www.kdnuggets.com/2022/07/realtime-translations-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Big Data Is Saving Lives in Real Time: IoV Data Analytics Helps…](https://www.kdnuggets.com/how-big-data-is-saving-lives-in-real-time-iov-data-analytics-helps-prevent-accidents)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
