- en: Handling Imbalanced Datasets in Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理深度学习中的不平衡数据集
- en: 原文：[https://www.kdnuggets.com/2018/12/handling-imbalanced-datasets-deep-learning.html](https://www.kdnuggets.com/2018/12/handling-imbalanced-datasets-deep-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/12/handling-imbalanced-datasets-deep-learning.html](https://www.kdnuggets.com/2018/12/handling-imbalanced-datasets-deep-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)![Figure](../Images/8c454a33c119cce44bea47f4a8b874a5.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)![图示](../Images/8c454a33c119cce44bea47f4a8b874a5.png)'
- en: Bring balance to your datasets like Thanos
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 像**灭霸**一样为你的数据集带来平衡
- en: Not all data is perfect. In fact, you’ll be extremely lucky if you ever get
    a perfectly balanced real-world dataset. Most of the time, your data will have
    some level of class imbalance, which is when each of your classes have a different
    number of examples.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 并不是所有数据都是完美的。实际上，如果你能获得一个完美平衡的现实世界数据集，你将非常幸运。大多数情况下，你的数据会有某种程度的类别不平衡，即每个类别的示例数量不同。
- en: Why do we want our data to be balanced?
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么我们希望数据平衡？
- en: Before committing time to any potentially lengthy task in a Deep Learning project,
    it’s important to understand *why* we should do it so that we can be sure it’s
    a valuable investment. Class balancing techniques are only really necessary when
    we *actually care* about the minority classes.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在投入时间进行任何可能漫长的深度学习项目之前，理解*为什么*我们应该这样做是很重要的，以确保这是一个有价值的投资。类别平衡技术只有在我们*真正关心*少数类时才是必要的。
- en: For example, let’s say we are trying to predict whether or not we should buy
    a house based on the current state of the market, the house’s attributes, and
    our budget. In this case it’s very important that if we buy then it is the right
    decision since it’s such a huge investment. At the same time it’s not a really
    big deal if our model says not to buy when we should have. There will always be
    other houses to buy if we miss out on one, but making the wrong investment on
    such a huge asset would be really bad.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，假设我们要预测是否应该根据市场的当前状况、房子的属性和我们的预算来购买一栋房子。在这种情况下，如果我们决定买房，那么这个决定是否正确是非常重要的，因为这是一个巨大的投资。同时，如果我们的模型说不买而实际上应该买，这也不是大问题。即使错过了某一栋房子，仍然会有其他房子可供选择，但对如此大的资产做出错误投资会很糟糕。
- en: In that example, we absolutely **need** our minority “buy” class to be extremely
    accurate, while for our “don’t buy” class it’s not such a big deal. Yet in a practical
    case, since buying will be far more rare than not buying in our data, our model
    will be biased to learning the “don’t buy” class very well since it has the most
    data and might perform poorly on the “buy” class. That calls for balancing our
    data so that we can put more weight on the “buy” predictions being correct!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们绝对**需要**我们的少数“买”类别非常准确，而对于“不要买”类别则不是那么重要。然而在实际情况中，由于在数据中购买会比不购买少得多，我们的模型会倾向于非常好地学习“不要买”类别，因为它有最多的数据，并可能在“买”类别上表现不佳。这就需要平衡数据，以便我们可以更重视“买”预测的正确性！
- en: 'Now what about if we don’t really care about the minority classes? For example,
    let’s say we are doing image classification and your class distribution looks
    something like this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如果我们不太关心少数类呢？例如，假设我们正在做图像分类，并且你的类别分布如下：
- en: '![](../Images/946564fe1ca35c62b88084b3dea2e344.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/946564fe1ca35c62b88084b3dea2e344.png)'
- en: At first glance it may seem like balancing our data would help. But maybe we’re
    not very interested in those minority classes. Perhaps our main goal is to get
    the **highest possible percentage accuracy**. In that case it doesn’t really make
    sense to do any balancing since most of our percentage accuracy will come from
    the classes with more training examples. Secondly, categorical crossentropy losses
    tend to perform quite well when aiming for the highest percentage accuracy even
    when the dataset is imbalanced. All in all our minority classes don’t contribute
    much to achieving our main goal, so balancing isn’t necessary.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，平衡数据似乎有帮助。但也许我们对那些少数类不太感兴趣。也许我们的主要目标是获得**最高可能的百分比准确度**。在这种情况下，进行任何平衡并没有太大意义，因为我们的百分比准确度大部分来自于训练示例更多的类别。其次，即使数据集不平衡，分类交叉熵损失在追求最高百分比准确度时也往往表现良好。总的来说，我们的少数类对实现主要目标贡献不大，因此平衡并不是必要的。
- en: With all of that being said, when we do encounter a case where we want to balance
    our data there are two techniques that we can use to help us out.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这里，当我们遇到需要平衡数据的情况时，我们可以使用两种技术来帮助我们。
- en: (1) Weight balancing
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (1) 权重平衡
- en: Weight balancing balances our data by altering the *weight* that each training
    example carries when computing the loss. Normally, each example and class in our
    loss function will carry equal weight i.e 1.0\. But sometimes we might want certain
    classes or certain training examples to hold more weight if they are more important.
    Referring again to our example of buying a house, since the accuracy of the “buy”
    class is most important to us, training examples within that class should have
    significant effect on the loss function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 权重平衡通过调整每个训练样本在计算损失时所承载的*权重*来平衡我们的数据。通常，我们的损失函数中的每个样本和类别将承担相等的权重，即1.0。但是有时我们可能希望某些类别或某些训练样本承载更多的权重，如果它们更为重要。再次以我们买房的例子为例，由于“买入”类别的准确性对我们最为重要，因此该类别中的训练样本应该对损失函数有显著影响。
- en: 'We can give weight to the classes simply by multiplying the loss of each example
    by a certain factor depending on their class. In Keras we can do something like
    this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过根据类别的不同，将每个样本的损失乘以某个因子来给类别赋权。在Keras中，我们可以这样做：
- en: We created a dictionary that basically says our “buy” class should hold 75%
    of the weight for the loss function since it is more important that the “don’t
    buy” class which we accordingly set to 25%. Of course these values can easily
    be tweaked to find the most optimal settings for your application. We can also
    use this method of balancing if one of our classes has significantly more examples
    than the other. Instead of spending time and resources trying to collect more
    for the minority class, we can try to use weight balancing to make all classes
    contribute equally to our loss.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个字典，其中基本上规定了我们的“买入”类别应在损失函数中占据75%的权重，因为“买入”类别比“不要买”类别更为重要，而“不要买”类别的权重则相应设置为25%。当然，这些值可以很容易地调整，以找到最适合您应用的设置。如果我们的某个类别的样本显著多于其他类别，我们也可以使用这种权重平衡的方法。与其花费时间和资源去收集更多的少数类样本，不如尝试使用权重平衡，使所有类别对我们的损失函数的贡献相等。
- en: 'Another method which we can use to balance the weighting of our training examples
    is the [*Focal Loss*](https://arxiv.org/pdf/1708.02002.pdf)shown below. Here’s
    the main idea: in our dataset, we will naturally have some training examples that
    are easier to classify than others. During training, these examples will be classified
    with 99% accuracy, while other more challenging ones may still exhibit poor performance.
    The problem is that those easily classified training examples are *still contributing
    to the loss. *Why are we still giving them equal weight when there are other more
    challenging data points that if correctly classified can contribute much more
    to our overall accuracy?!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种平衡训练样本权重的方法是[*焦点损失*](https://arxiv.org/pdf/1708.02002.pdf)。其主要思想是：在我们的数据集中，某些训练样本自然比其他样本更容易分类。在训练过程中，这些样本将以99%的准确率被分类，而其他更具挑战性的样本可能仍表现较差。问题在于，那些容易分类的训练样本*仍然在贡献损失*。为什么我们还要对它们给予相同的权重，而在其他更具挑战性的数据点上，如果正确分类，能对我们的整体准确率贡献更多？！
- en: '![](../Images/28f4f6d0c57b2949d600d821e61cf85f.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28f4f6d0c57b2949d600d821e61cf85f.png)'
- en: 'And that’s exactly the problem that the focal loss can address! Instead of
    giving equal weighting to all training examples, focal loss *down-weights the
    well-classified examples*. This has the net effect of putting more training emphasis
    on that data that is hard to classify! In a practical setting where we have a
    data imbalance, our majority class will quickly become well-classified since we
    have much more data for it. Thus, in order to insure that we also achieve high
    accuracy on our minority class, we can use the focal loss to give those minority
    class examples more relative weight during training. The focal loss can easily
    be implemented in Keras as a custom loss function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是焦点损失可以解决的问题！焦点损失*降低了对已分类样本的权重*，而不是对所有训练样本给予相等的权重。这有助于将更多的训练重点放在那些难以分类的数据上！在数据不平衡的实际设置中，由于我们拥有更多的数据，我们的多数类很快就会被良好分类。因此，为了确保我们在少数类上也能实现高准确率，我们可以使用焦点损失在训练过程中给予这些少数类样本更多的相对权重。焦点损失可以很容易地在Keras中作为自定义损失函数实现：
- en: (2) Over and under sampling
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: (2) 过采样与欠采样
- en: Selecting the proper class weights can sometimes be complicated. Doing a simple
    inverse-frequency might not always work very well. Focal loss can help, but even
    that will down-weight all well-classified examples of *each class equally*. Thus,
    another way to balance our data is by doing so *directly*, via sampling. Check
    out the image below for an illustration.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的类别权重有时可能会很复杂。简单的逆频率方法可能效果不好。焦点损失可以提供帮助，但即便如此，它也会平等地减少*每个类别*的所有良好分类示例的权重。因此，平衡数据的另一种方式是通过*直接*采样。请查看下面的图示。
- en: '![Figure](../Images/2d7a64fc17b95c412da66c90a535224b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2d7a64fc17b95c412da66c90a535224b.png)'
- en: Under and and Over Sampling
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样和过采样
- en: In both the left and right side of the image above, our blue class has far more
    samples than the orange class. In this case, we have 2 pre-processing options
    which can help in the training of our Machine Learning models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图的左侧和右侧，我们的蓝色类别样本远多于橙色类别。在这种情况下，我们有两个预处理选项可以帮助训练我们的机器学习模型。
- en: Undersampling means we will select only *some* of the data from the majority
    class, only using as many examples as the minority class has. This selection should
    be done to maintain the probability distribution of the class. That was easy!
    We just evened out our dataset by just taking less samples!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样意味着我们只会从多数类中选择*一部分*数据，只使用与少数类相同数量的样本。这种选择应保持类别的概率分布。这样很简单！我们通过减少样本数量平衡了数据集！
- en: Oversampling means that we will *create copies *of our minority class in order
    to have the same number of examples as the majority class has. The copies will
    be made such that the distribution of the minority class is maintained. We just
    evened out our dataset without getting any more data! Sampling can be a good alternative
    to class balancing if you find that the class weights are difficult to set effectively.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 过采样意味着我们会*创建副本*以使少数类的样本数量与多数类相同。这些副本的生成会保持少数类的分布。我们没有获取更多数据，但依然平衡了数据集！如果发现类别权重难以有效设置，采样可以是平衡类别的一个好替代方案。
- en: Like to learn?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想学习更多吗？
- en: Follow me on[ twitter](https://twitter.com/GeorgeSeif94) where I post all about
    the latest and greatest AI, Technology, and Science!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关注我的[推特](https://twitter.com/GeorgeSeif94)，我会发布最新最前沿的AI、技术和科学内容！
- en: '**Bio: [George Seif](https://towardsdatascience.com/@george.seif94)** is a
    Certified Nerd and AI / Machine Learning Engineer.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [George Seif](https://towardsdatascience.com/@george.seif94)** 是一名认证极客及AI/机器学习工程师。'
- en: '[Original](https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758).
    Reposted with permission.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758).
    经许可转载。'
- en: '**Related:**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容:**'
- en: '[The 5 Clustering Algorithms Data Scientists Need to Know](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家必知的5种聚类算法](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
- en: '[Three techniques to improve machine learning model performance with imbalanced
    datasets](/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[三种提高不平衡数据集上机器学习模型性能的技术](/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)'
- en: '[Get a 2–6x Speed-up on Your Data Pre-processing with Python](/2018/10/get-speed-up-data-pre-processing-python.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Python提升数据预处理速度2-6倍](/2018/10/get-speed-up-data-pre-processing-python.html)'
- en: '* * *'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织IT工作'
- en: '* * *'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Handling Missing Values in Time-series with SQL](https://www.kdnuggets.com/2022/09/handling-missing-values-timeseries-sql.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用SQL处理时间序列中的缺失值](https://www.kdnuggets.com/2022/09/handling-missing-values-timeseries-sql.html)'
- en: '[Unsupervised Disentangled Representation Learning in Class…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在类别不平衡数据集上进行无监督的解耦表示学习…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)'
- en: '[7 Techniques to Handle Imbalanced Data](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理不平衡数据的7种技术](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)'
- en: '[Overcoming Imbalanced Data Challenges in Real-World Scenarios](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克服现实世界场景中的不平衡数据挑战](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)'
- en: '[KDnuggets News, August 31: The Complete Data Science Study Roadmap…](https://www.kdnuggets.com/2022/n35.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，8月31日：完整的数据科学学习路线图…](https://www.kdnuggets.com/2022/n35.html)'
- en: '[A New Way of Managing Deep Learning Datasets](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理深度学习数据集的新方法](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
