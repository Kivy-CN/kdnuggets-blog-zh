- en: How I Redesigned over 100 ETL into ELT Data Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何将100多个ETL重新设计为ELT数据管道
- en: 原文：[https://www.kdnuggets.com/2021/11/redesigned-over-100-etl-elt-data-pipelines.html](https://www.kdnuggets.com/2021/11/redesigned-over-100-etl-elt-data-pipelines.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/11/redesigned-over-100-etl-elt-data-pipelines.html](https://www.kdnuggets.com/2021/11/redesigned-over-100-etl-elt-data-pipelines.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Nicholas Leong](https://www.linkedin.com/in/nickefy/), Data Engineer,
    Writer**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Nicholas Leong](https://www.linkedin.com/in/nickefy/)，数据工程师，作家**'
- en: '![](../Images/5a64ce73f49a562a81fa5893ec7d42df.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a64ce73f49a562a81fa5893ec7d42df.png)'
- en: Image by Author
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 在IT领域支持你的组织'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '> Everyone: What do Data Engineers do?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '> 大家：数据工程师做什么？'
- en: 'Me: We build pipelines.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我：我们构建管道。
- en: 'Everyone: You mean like a plumber?'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大家：你是说像水管工那样？
- en: Something like that, but instead of water flowing through pipes, **data flows
    through our pipelines.**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有点像，但不是水通过管道流动，而是**数据通过我们的管道流动**。
- en: Data Scientists build models and Data Analysts communicate data to stakeholders.
    So, what do we need Data Engineers for?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家构建模型，数据分析师将数据传达给利益相关者。那么，我们为什么需要数据工程师？
- en: Little do they know, without Data Engineers, models won’t even exist. There
    won’t be any data to be communicated. Data Engineers build warehouses and pipelines
    to allow data to flow through the organization. We connect the dots.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 他们几乎不知道，没有数据工程师，模型甚至不会存在。不会有任何数据可以传递。数据工程师构建仓库和管道，使数据能够在组织内流动。我们连接这些点。
- en: '[**Should You Become a Data Engineer in 2021?**](https://towardsdatascience.com/should-you-become-a-data-engineer-in-2021-4db57b6cce35)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[**你应该在2021年成为数据工程师吗？**](https://towardsdatascience.com/should-you-become-a-data-engineer-in-2021-4db57b6cce35)'
- en: Data Engineer is the fastest-growing job in 2019, **growing by 50% YoY**, which
    is higher than the job growth of Data Scientist, amounting to **32% YoY**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师是2019年增长最快的工作，**年增长率为50%**，高于数据科学家**32%的年增长率**。
- en: Hence, I’m here to shed some light on some of the day-to-day tasks a Data Engineer
    gets. Data Pipelines is just one of them.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我在这里为大家介绍一些数据工程师的日常任务。数据管道只是其中之一。
- en: ETL/ELT Pipelines
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ETL/ELT管道
- en: ETL — Extract, Transform, Load
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ETL — 提取、转换、加载
- en: ELT — Extract, Load, Transform
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ELT — 提取、加载、转换
- en: What do these mean and how are they different from each other?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是什么意思，它们之间有什么不同？
- en: In the data pipeline world, there is a **source **and a **destination**. In
    the simplest form, the source is where Data Engineers get the data from and the
    destination is where they want the data to be loaded into.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据管道的世界里，有一个**源头**和一个**目的地**。最简单的形式是，源头是数据工程师获取数据的地方，而目的地是他们希望将数据加载到的地方。
- en: More often than not, there will need to be some **processing **of data somewhere
    in between. This can be due to numerous reasons which include but are not limited
    to —
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，数据处理过程中往往需要进行一些**处理**。这可能是由于许多原因，包括但不限于—
- en: The difference in types of Data Storage
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储类型的差异
- en: Purpose of data
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的目的
- en: Data governance/quality
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据治理/质量
- en: Data Engineers label the processing of data as transformations. This is where
    they perform their magic to transform all kinds of data into the form they intend
    it to be.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师将数据处理标记为转换。这是他们施展魔法的地方，将各种数据转化为他们希望的形式。
- en: In **ETL Data Pipelines**, Data Engineers perform transformations before loading
    data into the destination. If there are relational transformations between tables,
    these happen within the source itself. In my case, the source was a Postgres Database.
    Hence, we performed relational joins in the source to obtain the data required,
    then load it into the destination.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在**ETL 数据管道**中，数据工程师在将数据加载到目标之前执行转换。如果表之间存在关系转换，这些转换发生在源数据库本身。在我的情况下，源是一个 Postgres
    数据库。因此，我们在源中执行关系联接以获取所需的数据，然后将其加载到目标中。
- en: In **ELT Data Pipelines**, Data Engineers load data into the destination raw.
    They then perform any relational transformations within the destination itself.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在**ELT 数据管道**中，数据工程师将数据原始地加载到目标中。然后，他们在目标本身内执行任何关系转换。
- en: In this article, we will be talking about how I transformed over 100+ ETL Pipelines
    in my organization into ELT Pipelines, we will also go through the reasons I did
    it.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将讨论我如何将组织中的 100 多个 ETL 管道转换为 ELT 管道，我们还将探讨我这样做的原因。
- en: How I Did It
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我是怎么做到的
- en: Initially, the pipelines were ran using Linux cron jobs. Cron jobs are like
    your traditional task schedulers, they initialize using the Linux terminal. They
    are the most basic way of scheduling programs without any functionalities like
    —
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，管道是使用 Linux cron 作业运行的。Cron 作业类似于传统的任务调度程序，它们通过 Linux 终端初始化。它们是调度程序的最基本方式，没有任何功能，例如
    —
- en: Setting dependencies
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置依赖关系
- en: Setting Dynamic Variables
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置动态变量
- en: Building Connections
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建连接
- en: '![](../Images/97fc8c807073933c0797cd585086ef7c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97fc8c807073933c0797cd585086ef7c.png)'
- en: Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: This was the first thing to go as it was causing way too many issues. We needed
    to scale. To do that, we had to set up a proper Workflow Management System.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是首先需要改变的，因为它造成了太多问题。我们需要扩展。为此，我们必须建立一个适当的工作流管理系统。
- en: We chose **Apache Airflow**. I wrote all about it here.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了**Apache Airflow**。我在这里详细写了关于它的所有内容。
- en: '[**Data Engineering — Basics of Apache Airflow — Build Your First Pipeline**](https://towardsdatascience.com/data-engineering-basics-of-apache-airflow-build-your-first-pipeline-eefecb7f1bb9)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[**数据工程 — Apache Airflow 基础 — 构建你的第一个管道**](https://towardsdatascience.com/data-engineering-basics-of-apache-airflow-build-your-first-pipeline-eefecb7f1bb9)'
- en: Airflow was originally built by the guys at **Airbnb**, made open source. It
    is also used by popular companies like **Twitter **as their Pipeline management
    system. You can read all about the benefits of Airflow above.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow 最初是由**Airbnb**的团队开发的，并开放源代码。它还被像**Twitter**这样的大公司作为它们的管道管理系统使用。你可以阅读上面关于
    Airflow 好处的所有内容。
- en: After that’s sorted out, we had to change the way we are extracting data. The
    team suggested **redesigning our ETL pipelines into ELT pipelines.** More on why
    did we do it later.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决这个问题后，我们必须改变提取数据的方式。团队建议**将我们的 ETL 管道重新设计为 ELT 管道**。稍后会详细讲解我们这样做的原因。
- en: '![](../Images/15658012ec0844894f7de86408543162.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15658012ec0844894f7de86408543162.png)'
- en: Image by Author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Here’s an example of the pipeline before it was redesigned. The source we were
    dealing with was a Postgres Database. Hence, to obtain data in the form intended,
    we had to perform joins in the source database.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在重新设计之前的管道示例。我们处理的源是一个 Postgres 数据库。因此，为了以预期的形式获取数据，我们必须在源数据库中执行联接操作。
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is the query ran in the source database. Of course, I’ve simplified the
    examples to their dumbest form, the actual queries were over 400 lines of SQL.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在源数据库中运行的查询。当然，我简化了示例，实际的查询超过了 400 行 SQL。
- en: The query results were saved in a CSV file and then uploaded to the destination,
    which is a **Google Bigquery database** in our case. Here’s how it looked like
    in Apache Airflow —
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 查询结果被保存到 CSV 文件中，然后上传到目标，即**Google Bigquery 数据库**。在 Apache Airflow 中，它是这样的 —
- en: This is a simple example of an ETL pipeline. It was working as intended, but
    the team had realized the **benefits** of redesigning this into an ELT pipeline.
    More on that later.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 ETL 管道的简单示例。它按预期工作，但团队意识到将其重新设计为 ELT 管道的**好处**。稍后会详细介绍。
- en: '![](../Images/36c7974a56ab4e7173aec07e1358e3b6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36c7974a56ab4e7173aec07e1358e3b6.png)'
- en: Image by Author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Here’s an example of the pipeline after it was redesigned. Observed how the
    tables are brought into the destination** as it is**. After all the tables have
    been successfully extracted, we perform relational transformations in the destination.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在重新设计之后的管道示例。观察一下表格是如何**保持原样**地带入目标的。在所有表格成功提取后，我们在目标中执行关系转换。
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is the query ran in the source database. Most of the extractions are using
    ‘Select *’ statements **without any joins**. For appending jobs, we include **where
    conditions** to properly segregate the data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在源数据库中运行的查询。大多数提取使用的是‘Select *’语句**没有任何联接**。对于追加任务，我们包括**where 条件**以正确分隔数据。
- en: Similarly, the query results were saved in a CSV file and then uploaded into
    the Google Bigquery database. We then made a separate dag for transformation jobs
    by **setting dependencies within Apache Airflow.** This is to ensure that all
    the extraction jobs have been completed before running transformation jobs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，查询结果被保存到一个 CSV 文件中，然后上传到 Google BigQuery 数据库。我们随后为转换任务制作了一个单独的 dag，通过**在
    Apache Airflow 中设置依赖关系**来实现。这是为了确保所有提取任务在运行转换任务之前都已完成。
- en: We set dependencies using **Airflow Sensors.** You can read about them [here](https://towardsdatascience.com/data-engineering-how-to-set-dependencies-between-data-pipelines-in-apache-airflow-using-sensors-fc34cfa55fba).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用**Airflow Sensors**设置依赖关系。你可以在[这里](https://towardsdatascience.com/data-engineering-how-to-set-dependencies-between-data-pipelines-in-apache-airflow-using-sensors-fc34cfa55fba)了解它们。
- en: '[**Data Engineering — How to Set Dependencies Between Data Pipelines in Apache
    Airflow**](https://towardsdatascience.com/data-engineering-how-to-set-dependencies-between-data-pipelines-in-apache-airflow-using-sensors-fc34cfa55fba)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[**数据工程 — 如何在 Apache Airflow 中设置数据管道之间的依赖关系**](https://towardsdatascience.com/data-engineering-how-to-set-dependencies-between-data-pipelines-in-apache-airflow-using-sensors-fc34cfa55fba)'
- en: Why I Did it
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我这么做
- en: '![](../Images/29a9cdb5ff4f6a2b66b1819e49f13a39.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29a9cdb5ff4f6a2b66b1819e49f13a39.png)'
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Now that you understand how I did it, we move onto the **why** — Why exactly
    did we re-wrote all our ETL into ELT pipelines?
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你了解了我是怎么做的，我们来讨论一下**为什么**——我们究竟为何将所有 ETL 重新编写为 ELT 管道？
- en: Cost
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本
- en: Running with our old Pipeline had cost our team **resources**, specifically
    time, effort, and money.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们旧的数据管道花费了团队**资源**，特别是时间、精力和金钱。
- en: To understand the cost aspect of things, you have to understand that our source
    database (Postgres) was an ancient machine set up back in 2008\. It was hosted
    on-prem. It was also running an old version of Postgres which makes things even
    complicated.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解成本方面的情况，你需要知道我们的源数据库（Postgres）是2008年设置的古老机器。它托管在本地，也运行着旧版本的 Postgres，这使事情变得更加复杂。
- en: It wasn’t until recent years when the organization realize the** need** for
    a centralized data warehouse for Data Scientists and Analysts. This is when they
    started to build the old pipelines on cron jobs. As the number of jobs increase,
    it had drained resources on the machine.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近几年，组织才意识到对数据科学家和分析师来说需要一个集中的数据仓库。于是他们开始将旧的管道迁移到定时任务上。随着任务数量的增加，这消耗了机器上的资源。
- en: The SQL joins written by the previous Data Analysts were also all over the place.
    There were over **20 joins** in a single query in some pipelines, and we were
    approaching 100+ pipelines. Our tasks began running during midnight, it usually
    finished about 1–2 p.m., which amounted to about **12+ hours,** which is absolutely
    unacceptable.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的数据分析师编写的 SQL 联接也非常混乱。在某些数据管道中，一个查询中有超过**20 个联接**，而我们的数据管道接近 100 个。我们的任务通常在午夜开始运行，通常在下午
    1 到 2 点结束，总共大约需要**12 个小时以上**，这绝对不可接受。
- en: For those of you who don’t know, SQL joins are one of the **most resource-intensive
    commands** to run. It’ll increase the query’s runtime exponentially as the number
    of joins increases.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不知道的人来说，SQL 联接是**最耗费资源的命令之一**。随着联接数量的增加，它将使查询的运行时间呈指数级增长。
- en: '![](../Images/31cd342fe86942f3c1f3a7daedfdc14b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31cd342fe86942f3c1f3a7daedfdc14b.png)'
- en: Image by Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Since we were moving onto Google Cloud, the team understood that Google Bigquery
    is** lightning fast** in computing SQL queries. You can read all about it [**here**](https://cloud.google.com/blog/products/bigquery/anatomy-of-a-bigquery-query).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们迁移到 Google Cloud，团队理解到 Google BigQuery 在计算 SQL 查询方面**非常快速**。你可以在[**这里**](https://cloud.google.com/blog/products/bigquery/anatomy-of-a-bigquery-query)阅读有关内容。
- en: '[**How fast is BigQuery? | Google Cloud Blog**](https://cloud.google.com/blog/products/bigquery/anatomy-of-a-bigquery-query)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**BigQuery 速度有多快？| Google Cloud 博客**](https://cloud.google.com/blog/products/bigquery/anatomy-of-a-bigquery-query)'
- en: Hence, the whole point is to only run simple ‘Select *’ statements in the source
    and perform all the joins on Google Cloud.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关键是只在源中运行简单的‘Select *’语句，并在 Google Cloud 上执行所有连接。
- en: This had more than **doubled the** **efficiency and speed** of our Data Pipelines.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这**使我们数据管道的** **效率和速度** **增加了两倍以上**。
- en: Scalability
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性
- en: '![](../Images/995369f87b81e5cf6bb9e7439b0b2a3e.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/995369f87b81e5cf6bb9e7439b0b2a3e.png)'
- en: Photo by [Quinten de Graaf](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Quinten de Graaf](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral)
    提供的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: As businesses scale, so do their tools and technologies.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 随着业务的扩展，它们的工具和技术也在扩展。
- en: By moving onto Google Cloud, we can easily scale our machines and pipelines
    without worrying much.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通过迁移到 Google Cloud，我们可以轻松扩展我们的机器和管道，而无需过多担心。
- en: Google Cloud utilizes **Cloud Monitoring **which is a tool that collects metrics,
    events, and metadata of your Google Cloud Technologies like Google Cloud Composer,
    Dataflow, Bigquery, and many more. You can monitor all sorts of data points which
    includes but are not limited to —
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 利用**Cloud Monitoring**，这是一个收集 Google Cloud 技术（如 Google Cloud Composer、Dataflow、Bigquery
    等）的指标、事件和元数据的工具。你可以监控各种数据点，包括但不限于 —
- en: Cost of Virtual Machines
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机的成本
- en: The cost of each query ran in Google Bigquery
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个在 Google Bigquery 中运行的查询的成本
- en: The size of each query ran in Google Bigquery
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个在 Google Bigquery 中运行的查询的大小
- en: Duration of Data Pipelines
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据管道的持续时间
- en: This had made monitoring a breeze for us. Hence, by performing all transformations
    on Google Bigquery, we are able to accurately monitor our query size, duration,
    and cost as we scale.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得监控对我们来说变得轻松。因此，通过在 Google Bigquery 上执行所有转换，我们能够准确监控我们的查询大小、持续时间和成本，随着扩展而进行调整。
- en: Even as we **increase **our machine sizes, data warehouses, data pipelines,
    etc, we completely **understand the costs and benefits** that come with it and
    have full control of turning it on and off if needed.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们**增加**我们的机器规模、数据仓库、数据管道等，我们也完全**理解随之而来的成本和利益**，并能完全控制是否需要开启或关闭。
- en: This had and will save us from a lot of headaches.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经并将为我们省去很多麻烦。
- en: Conclusion
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: '![](../Images/7d220a315695610328a8d88fc84123d7.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d220a315695610328a8d88fc84123d7.png)'
- en: Photo by [Fernando Brasil](https://unsplash.com/@nandovish?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Fernando Brasil](https://unsplash.com/@nandovish?utm_source=medium&utm_medium=referral)
    提供的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: If you’ve read until this point, you must really have a thing for data.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你读到这里，你肯定对数据非常感兴趣。
- en: You should!
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该这样做！
- en: We’ve already made ETLs and ELTs. Who knows what kind of pipelines we will be
    building in the **future**?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经做了 ETLs 和 ELTs。谁知道我们将来会构建什么样的管道呢？
- en: In this article, we talked about —
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了 —
- en: What are ELT/ETL Data Pipelines?
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 ELT/ETL 数据管道？
- en: How I redesigned ETL to ELT Pipelines
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是如何将 ETL 重新设计为 ELT 管道的
- en: Why I did it
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我为什么这样做
- en: As usual, I end with a quote.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我以一句名言结尾。
- en: Data is the new science. Big Data holds the answers
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据是新的科学。大数据持有答案
- en: —Pet Gelsinger
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: — 佩特·盖尔辛格
- en: '[Subscribe to my newsletter to stay in touch.](https://www.nicholas-leong.com/sign-up-here)'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[订阅我的新闻通讯以保持联系。](https://www.nicholas-leong.com/sign-up-here)'
- en: You can also support me by signing up for a medium membership through [**my
    link**](https://nickefy.medium.com/membership). You will be able to read an unlimited
    amount of stories from me and other incredible writers!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过 [**我的链接**](https://nickefy.medium.com/membership) 支持我。你将能阅读我和其他优秀作家的无限故事！
- en: I am working on more stories, writings, and guides in the data industry. You
    can absolutely expect more posts like this. In the meantime, feel free to check
    out my other [**articles**](https://nickefy.medium.com/) to temporarily fill your
    hunger for data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在数据行业中创作更多故事、文章和指南。你可以期待更多类似的帖子。在此期间，随时查看我其他的 [**文章**](https://nickefy.medium.com/)
    来暂时满足你对数据的渴望。
- en: '***Thanks**** for reading! If you want to get in touch with me, feel free to
    reach me at nickmydata@gmail.com or my *[*LinkedIn Profile*](https://www.linkedin.com/in/nickefy/)*.
    You can also view the code for previous write-ups in my *[*Github*](https://github.com/nickefy)*.*'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '***感谢*** 阅读！如果你想与我联系，请随时通过 nickmydata@gmail.com 或我的 *[*LinkedIn 个人资料*](https://www.linkedin.com/in/nickefy/)*
    联系我。你还可以查看我以前文章的代码，位于我的 *[*Github*](https://github.com/nickefy)*。*'
- en: '**Bio: [Nicholas Leong](https://www.linkedin.com/in/nickefy/)** is a data engineer,
    currently working in an online classifieds tech company. In his years of experience,
    Nicholas has fully designed batch and streaming pipelines, improved data warehousing
    solutions, and performed machine learning projects for the organization. During
    his free time, Nicholas likes to work on his own projects to improve his skills.
    He also write about his work, projects, and experiences to share them with the
    world. [Visit my site to check out my work](https://nickefy.github.io/porfoliosite/)!'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历：[Nicholas Leong](https://www.linkedin.com/in/nickefy/)** 是一名数据工程师，目前在一家在线分类广告技术公司工作。在他的多年经验中，Nicholas
    完全设计了批处理和流处理管道，改进了数据仓库解决方案，并为组织执行了机器学习项目。在空闲时间，Nicholas 喜欢从事自己的项目以提高技能。他还撰写关于自己工作、项目和经验的文章，以与世界分享。[访问我的网站查看我的工作](https://nickefy.github.io/porfoliosite/)！'
- en: '[Original](https://towardsdatascience.com/how-i-redesigned-over-100-etl-into-elt-data-pipelines-c58d3a3cb3c).
    Reposted with permission.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/how-i-redesigned-over-100-etl-into-elt-data-pipelines-c58d3a3cb3c)。经许可转载。'
- en: '**Related:**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Prefect: How to Write and Schedule Your First ETL Pipeline with Python](/2021/08/prefect-write-schedule-etl-pipeline-python.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Prefect：如何使用Python编写和调度你的第一个ETL管道](/2021/08/prefect-write-schedule-etl-pipeline-python.html)'
- en: '[Design Patterns for Machine Learning Pipelines](/2021/11/design-patterns-machine-learning-pipelines.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习管道的设计模式](/2021/11/design-patterns-machine-learning-pipelines.html)'
- en: '[ETL and ELT: A Guide and Market Analysis](/2021/10/etl-elt-guide-market-analysis.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL与ELT：指南与市场分析](/2021/10/etl-elt-guide-market-analysis.html)'
- en: More On This Topic
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[ETL vs ELT: Which One is Right for Your Data Pipeline?](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL与ELT：哪种更适合你的数据管道？](https://www.kdnuggets.com/2023/03/etl-elt-one-right-data-pipeline.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[ETL vs ELT: Data Integration Showdown](https://www.kdnuggets.com/2022/08/etl-elt-data-integration-showdown.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ETL与ELT：数据集成对决](https://www.kdnuggets.com/2022/08/etl-elt-data-integration-showdown.html)'
- en: '[SQL and Data Integration: ETL and ELT](https://www.kdnuggets.com/2023/01/sql-data-integration-etl-elt.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL与数据集成：ETL和ELT](https://www.kdnuggets.com/2023/01/sql-data-integration-etl-elt.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
