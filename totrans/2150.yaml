- en: 'Between Dreams and Reality: Generative Text and Hallucinations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations](https://www.kdnuggets.com/between-dreams-and-reality-generative-text-and-hallucinations)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Between Dreams and Reality: Generative Text and Hallucinations](../Images/d011127f45ac4793b31892199f686d31.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: In the digital age, the marvels of artificial intelligence have transformed
    the way we interact, work, and even think.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: From voice assistants that curate our playlists to predictive algorithms that
    forecast market trends, AI has seamlessly integrated into our daily lives.
  prefs: []
  type: TYPE_NORMAL
- en: But as with any technological advancement, it’s not without its twists.
  prefs: []
  type: TYPE_NORMAL
- en: A large language model or LLM is a trained machine learning model that generates
    text based on the prompt you provided. In order to generate good responses, the
    models take advantage of all the knowledge retained during its training phase.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, LLMs have shown impressive and increasing capabilities, including
    generating convincing responses to any type of user prompts.
  prefs: []
  type: TYPE_NORMAL
- en: However, even though LLMs have an incredible ability to generate text, it is
    hard to tell if this generation is accurate or not.
  prefs: []
  type: TYPE_NORMAL
- en: And this is precisely what is commonly known as hallucinations.
  prefs: []
  type: TYPE_NORMAL
- en: But what are these hallucinations, and how do they impact the reliability and
    utility of AI?
  prefs: []
  type: TYPE_NORMAL
- en: The Enigma of LLM Hallucinations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: LLMs are masterminds when it comes to text generation, translations, creative
    content, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite being potent tools, LLM do present some significant shortcomings:'
  prefs: []
  type: TYPE_NORMAL
- en: The decoding techniques employed can yield outputs that are either uninspiring,
    lacking coherence, or prone to falling into monotonous repetitions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Their knowledge foundation is “static” in nature, presenting challenges in seamless
    updates.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A common issue is the generation of text that is either nonsensical or inaccurate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The last point is referred to as hallucination, which is an AI-extended concept
    from humans.
  prefs: []
  type: TYPE_NORMAL
- en: For humans, hallucinations represent experiences perceived as real despite being
    imaginary. This concept extends to AI models, where the hallucinated text appears
    accurate even though it's false.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of LLMs, “hallucination” refers to a phenomenon where the model
    generates text that is incorrect, nonsensical, or not real.
  prefs: []
  type: TYPE_NORMAL
- en: '![Between Dreams and Reality: Generative Text and Hallucinations](../Images/5dea512a548361642bfd1d0dfd757848.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Dall-E
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are not designed like databases or search engines, so they don’t reference
    specific sources or knowledge in their answers.
  prefs: []
  type: TYPE_NORMAL
- en: I bet most of you might be wondering… How can it be possible?
  prefs: []
  type: TYPE_NORMAL
- en: Well… these models produce text by building upon the given prompt. The generated
    response isn’t always directly backed by specific training data, but is crafted
    to align with the context of the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'In simpler terms:'
  prefs: []
  type: TYPE_NORMAL
- en: They can confidently spew out information that’s factually incorrect or simply
    doesn’t make sense.
  prefs: []
  type: TYPE_NORMAL
- en: Deciphering the Types of Hallucinations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Identifying hallucinations in humans has always posed a significant challenge.
    This task becomes even more complex given our limited ability to access a reliable
    baseline for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: While detailed insights like output probability distributions from Large Language
    Models can aid in this process, such data is not always available, adding another
    layer of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: The issue of hallucination detection remains unsolved and is a subject of ongoing
    research.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Blatant Untruths:** LLMs might conjure up events or figures that never
    existed.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The Overly Accurate:** They might overshare, potentially leading to the spread
    of sensitive information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The Nonsensical:** Sometimes, the output might just be pure gibberish.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why Do These Hallucinations Occur?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why Do These Hallucinations Occur?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The root cause lies in the training data. LLMs learn from vast datasets, which
    can sometimes be incomplete, outdated, or even contradictory. This ambiguity can
    lead them astray, making them associate certain words or phrases with inaccurate
    concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the sheer volume of data means that LLMs might not have a clear “source
    of truth” to verify the information they generate.
  prefs: []
  type: TYPE_NORMAL
- en: Using Hallucinations to Your Advantage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interestingly, these hallucinations can be a boon in disguise. If you’re seeking
    creativity, you’d want LLMs like ChatGPT to hallucinate.
  prefs: []
  type: TYPE_NORMAL
- en: '![Between Dreams and Reality: Generative Text and Hallucinations](../Images/d98eb6c897e67ca33027f0e53ff85b7c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image generated by DALL-E
  prefs: []
  type: TYPE_NORMAL
- en: Imagine asking for a unique fantasy story plot, you’d want a fresh narrative,
    not a replica of an existing one.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, when brainstorming, hallucinations can offer a plethora of diverse
    ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigating the Mirage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Awareness is the first step towards addressing these hallucinations. Here are
    some strategies to keep them in check:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Consistency Checks:** Generate multiple responses to the same prompt and
    compare.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Semantic Similarity Checks:** Use tools like BERTScore to measure the semantic
    similarity between generated texts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training on Updated Data:** Regularly update the training data to ensure
    relevancy. You can even fine-tune the GPT model to improve its performance in
    some specific fields.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User Awareness:** Educate users about potential hallucinations and the importance
    of cross-referencing information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And the final one, but not least… EXPLORE!
  prefs: []
  type: TYPE_NORMAL
- en: This article has laid the groundwork regarding LLM hallucinations, yet the implications
    for you and your application might diverge considerably.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, your interpretation of these phenomena may not precisely correspond
    with actuality. The key to fully grasping and valuing the impact of LLM hallucinations
    on your endeavors is through an in-depth exploration of LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: In Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The journey of AI, especially LLMs, is akin to sailing in uncharted waters.
    While the vast ocean of possibilities is exciting, it’s essential to be wary of
    the mirages that might lead us astray.
  prefs: []
  type: TYPE_NORMAL
- en: By understanding the nature of these hallucinations and implementing strategies
    to mitigate them, we can continue to harness the transformative power of AI, ensuring
    its accuracy and reliability in our ever-evolving digital landscape.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/josep-ferrer-sanchez/)**[Josep Ferrer](https://www.linkedin.com/in/josep-ferrer-sanchez)****
    is an analytics engineer from Barcelona. He graduated in physics engineering and
    is currently working in the data science field applied to human mobility. He is
    a part-time content creator focused on data science and technology. Josep writes
    on all things AI, covering the application of the ongoing explosion in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Orchestration: The Dividing Line Between Generative AI Success…](https://www.kdnuggets.com/2024/07/astronomer/data-orchestration-the-dividing-line-between-generative-ai-success-and-failure)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Fiction to Reality: ChatGPT and the Sci-Fi Dream of True AI…](https://www.kdnuggets.com/from-fiction-to-reality-chatgpt-and-the-sci-fi-dream-of-true-ai-conversation)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Career: 7 Expectations vs Reality](https://www.kdnuggets.com/2022/06/data-science-career-7-expectations-reality.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science: Reality vs Expectations](https://www.kdnuggets.com/2022/03/data-science-reality-expectations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Efficiency Spells the Difference Between Biological Neurons and…](https://www.kdnuggets.com/2022/11/efficiency-spells-difference-biological-neurons-artificial-counterparts.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
