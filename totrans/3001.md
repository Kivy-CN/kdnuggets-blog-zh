# 逻辑回归：简明技术概述

> 原文：[https://www.kdnuggets.com/2019/01/logistic-regression-concise-technical-overview.html](https://www.kdnuggets.com/2019/01/logistic-regression-concise-technical-overview.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

我们都听说过线性回归。这是我们在统计学第一学期学习的内容。当我们有连续的结果变量时，它是我们的默认技术。有关线性回归的复习可以在[这里](/2016/11/linear-regression-least-squares-matrix-multiplication-concise-technical-overview.html)找到。但有时我们有**类别结果**。*逻辑回归解决了线性回归中结果变量（***y***) 必须是连续的限制。*

**逻辑回归**是一种回归技术，适用于具有类别结果（2个或更多类别）的情况。此技术可用于分析和预测‘**离散**’，‘**名义**’和‘**有序**’的变量。逻辑回归是数据科学家组合中最易于解释的分类技术之一。

与线性回归不同，逻辑回归不对正态性、线性和方差齐性做任何假设。这是逻辑回归可能更强大的原因之一，因为这些假设在现实世界中很少或几乎从未得到满足。

![图](../Images/852f8c8152e5a18b86c5d7b012c77737.png)

来源：[Scikit-learn 文档](https://scikit-learn.org/stable/auto_examples/linear_model/plot_logistic.html#sphx-glr-auto-examples-linear-model-plot-logistic-py)

> 线性回归和逻辑回归之间的一个简单区别是，在线性回归中，人们可以预测学生的考试成绩（连续目标）。而在逻辑回归中，人们可以将学生的成绩分类为‘通过’、‘失败’，并预测学生是否通过了考试。

### 逻辑回归的类型

+   二项

+   多项式

+   序数

**二项逻辑回归**

最基本的逻辑回归类型是二项逻辑回归，其中只有 2 个类别结果。

![图](../Images/a5ed8aca467faeb620b2e9b63e3f10c6.png)

+   Logit 函数（3）用于获得目标结果的正概率值。它表示为成功与失败的对数赔率。

    +   ***π***（2）是成功的概率。

    +   1-***π*** 指的是失败的概率。

+   解释变量（4）可以是类别型或数值型，并以目标结果的对数赔率变化的形式表示。

其解释方式如下：

*连续解释变量*

+   ***x[i]*** 的赔率增加 1 将使成功的赔率增加/减少 ***e^(β[i])***，假设所有其他变量保持不变。

*类别解释变量*

+   在水平***x[i]***，赔率将比参考水平增加/减少***e^(β[1])***，其他所有变量保持不变。

**多项式逻辑回归**

虽然二元逻辑回归允许我们分析二元类别作为目标变量，但有时你会看到目标变量有超过2个类别。

例如：

+   苹果、橙子、葡萄、香蕉

+   心脏病、糖尿病、癌症

多项式回归用于计算相对于**指定基线**的目标类别的赔率。

在以下方程中：

+   ***p***指的是一个变量/特征/列

+   ***j***指的是目标变量的类别水平。

![图](../Images/06e2711e1aa88573c6940c564808ee08.png)

+   基线模型对数逻辑回归（5 & 6）显示，预测概率值是相对于所选基线对数概率（***log(π[1])***）的对数赔率（***log(π[j])***）的对数值。

+   每个类别水平‘***j***’将有其自身的截距（8）和解释变量（7）。

+   每个解释变量（7）将有其自己的β系数（9）。

它的解释方式如下：

****j^(th)***水平的截距（***β[j⁰]***）

+   当所有解释变量为零时，***j^(th)***水平的赔率为***e^(β[j0])***，其他所有变量保持不变。

*连续解释变量*

+   当***x[p]***增加1单位时，相对于***π[1]***的***π[j]***的赔率变化为***e^(β[jp])***，其他所有变量保持不变。

*类别解释变量*

+   在水平***x[p]***，相对于***π[i]***的***π[j]***的赔率将比参考水平增加/减少***e^(β[jp])***，其他所有变量保持不变。

**有序逻辑回归**

有序回归可以被视为多项式回归的扩展。有序回归还可以处理具有两个以上目标水平的回归问题，并且**目标水平具有自然顺序**。

例如：

+   排名尺度（1,2,3,4,5）

+   高、低、中

![图](../Images/2661968a0e56acb83e922219847ad236.png)

+   每个目标水平都有其自身的截距‘***β[j0]***’。

+   解释变量在每个截距之间共享。

+   **正如我们在（12）和（13）中看到的，有序回归可以用于计算累计概率，而不仅仅是单个目标的概率。**

它的解释方式如下：

****j^(th)***水平的截距（***β[j0]***）*

+   当所有解释变量为零时，***j^(th)***水平的赔率为***e^(β[j0])***，其他所有变量保持不变。

*连续解释变量*

+   当***x[p]***增加1单位时，相对于（13）的（12）的赔率变化为***e^(β[p])***，其他所有变量保持不变。

*类别解释变量*

+   在水平***x[p]***，相对于（13）的（12）的赔率将比参考水平增加/减少***e^(β[p])***，其他所有变量保持不变。

对于有序回归，***P(Y <= j)*** 将指代用户期望的目标水平，而 ***1 - P(Y <= j)*** 指代剩余的类别水平。

### 结论

逻辑回归是机器学习中一些最简单但最强大的技术。逻辑回归的不同形式可以用来建模许多现实世界的场景，结果相对容易解释。这不是一个黑箱过程，这增加了它被使用的吸引力。许多人认为逻辑回归只用于二分类结果，但如我们所见，事实并非如此。

深入理解逻辑回归的一个重要理由是它[有助于理解神经网络](https://stats.stackexchange.com/questions/43538/difference-between-logistic-regression-and-neural-networks)。机器学习本质上是计算机做决策的方法，许多决策是类别/离散的。学习逻辑回归可以成为理解神经网络的途径。

本文中的大部分信息可以通过[这里](http://www.chrisbilder.com/categorical/)的相应R代码找到。

**相关**:

+   [5个理由说明逻辑回归应该是你成为数据科学家时学习的首要内容](/2018/05/5-reasons-logistic-regression-first-data-scientist.html)

+   [逻辑回归基础 – 第一部分](/2016/08/primer-logistic-regression-part-1.html)

+   [逻辑回归中的正则化：更好的拟合和更好的泛化？](/2016/06/regularization-logistic-regression.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT

* * *

### 了解更多主题

+   [逻辑回归概述](https://www.kdnuggets.com/2022/02/overview-logistic-regression.html)

+   [比较线性回归和逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)

+   [线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)

+   [KDnuggets 新闻 22:n12，3月23日：最佳数据科学书籍…](https://www.kdnuggets.com/2022/n12.html)

+   [逻辑回归用于分类](https://www.kdnuggets.com/2022/04/logistic-regression-classification.html)

+   [逻辑回归是如何工作的？](https://www.kdnuggets.com/2022/07/logistic-regression-work.html)
