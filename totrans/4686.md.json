["```py\nimport pafy\n\nurl = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\nvPafy = pafy.new(url)\nprint vPafy.title\nprint vPafy.rating\nprint vPafy.viewcount\nprint vPafy.author\nprint vPafy.length\nprint vPafy.description\n```", "```py\nTesting file uploads with Postman (multipart/form-data)\n4.87096786499\n11478\nValentin Despa\n1688\n➡️➡️➡️ ???? Check my online course on Postman. Get it for only $10 (limited supply):\nhttps://www.udemy.com/postman-the-complete-guide/?couponCode=YOUTUBE10\n\nI will show you how to debug an upload script and demonstrate it with a tool that can make requests encoded as \"multipart/form-data\" so that you can send also a file.\n\nAfter this, we will go even further and write tests and begin automating the process.\n\nHere is the Git repository containing the files used for this tutorial:\nhttps://github.com/vdespa/postman-testing-file-uploads\n```", "```py\nimport cv2\nimport numpy as np\nimport pafy\n\n#url of the video to predict Age and gender\nurl = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\nvPafy = pafy.new(url)\nplay = vPafy.getbest(preftype=\"mp4\")\n\ncap = cv2.VideoCapture(play.url)\n\ncap.set(3, 480) #set width of the frame\ncap.set(4, 640) #set height of the frame\n\nMODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n\nage_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n\ngender_list = ['Male', 'Female']\n\ndef load_caffe_models():\n\n age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n\ngender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n\nreturn(age_net, gender_net)\n\ndef video_detector(age_net, gender_net):\n  font = cv2.FONT_HERSHEY_SIMPLEX\n\nwhile True:\n\n  ret, image = cap.read()\n\n  face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n\n  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n  faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n\nif(len(faces)>0):\n   print(\"Found {} faces\".format(str(len(faces))))\n\nfor (x, y, w, h )in faces:\n   cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n\n#Get Face \n   face_img = image[y:y+h, h:h+w].copy()\n   blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n\n#Predict Gender\n   gender_net.setInput(blob)\n   gender_preds = gender_net.forward()\n   gender = gender_list[gender_preds[0].argmax()]\n   print(\"Gender : \" + gender)\n\n#Predict Age\n   age_net.setInput(blob)\n   age_preds = age_net.forward()\n   age = age_list[age_preds[0].argmax()]\n   print(\"Age Range: \" + age)\n\noverlay_text = \"%s %s\" % (gender, age)\n   cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n\ncv2.imshow('frame', image)  \n#0xFF is a hexadecimal constant which is 11111111 in binary.\nif cv2.waitKey(1) & 0xFF == ord('q'): \n   break\n\nif __name__ == \"__main__\":\nage_net, gender_net = load_caffe_models()\n\nvideo_detector(age_net, gender_net)\n```", "```py\nimport cv2\nimport numpy as np\nimport pafy\n```", "```py\nurl = 'https://www.youtube.com/watch?v=c07IsbSNqfI&feature=youtu.be'\nvPafy = pafy.new(url)\nplay = vPafy.getbest(preftype=\"mp4\")\n```", "```py\ncap = cv2.VideoCapture(0) #if you are using webcam\n```", "```py\ncap = cv2.VideoCapture(play.url)\n```", "```py\ncap.set(3, 480) #set width of the frame\ncap.set(4, 640) #set height of the frame\n```", "```py\nMODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\nage_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\ngender_list = ['Male', 'Female']\n```", "```py\ndef load_caffe_models():\n\n age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n\ngender_net = cv2.dnn.readNetFromCaffe('deploy_gender.prototxt', 'gender_net.caffemodel')\n\nreturn(age_net, gender_net)\n```", "```py\nif __name__ == \"__main__\":\nage_net, gender_net = load_caffe_models()\n\nvideo_detector(age_net, gender_net)\n```", "```py\nret, image = cap.read()\n```", "```py\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n```", "```py\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n```", "```py\ndetectMultiScale(image, scaleFactor, minNeighbors)\n```", "```py\nfaces = face_cascade.detectMultiScale(gray, 1.1, 5)\n```", "```py\nfor (x, y, w, h )in faces:\n   cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n\n# Get Face \n   face_img = image[y:y+h, h:h+w].copy()\n```", "```py\nblob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size, mean, swapRB=True)\n```", "```py\nblob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n```", "```py\n#Predict Gender\ngender_net.setInput(blob)\ngender_preds = gender_net.forward()\ngender = gender_list[gender_preds[0].argmax()]\n```", "```py\n#Predict Age\nage_net.setInput(blob)\nage_preds = age_net.forward()\nage = age_list[age_preds[0].argmax()]\n```", "```py\noverlay_text = \"%s %s\" % (gender, age)\ncv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n```", "```py\ncv2.imshow('frame', image)\n```", "```py\nif cv2.waitKey(1) & 0xFF == ord('q'):\n   break\n```"]