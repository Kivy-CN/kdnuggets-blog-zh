# 你从未学过的基本统计学知识…因为它们从未被教授

> 原文：[`www.kdnuggets.com/2017/08/vital-statistics-never-learned-never-taught.html`](https://www.kdnuggets.com/2017/08/vital-statistics-never-learned-never-taught.html)

![c](img/3d9c022da2d331bb56691a9617b91b90.png) 评论

![Header](img/85c910744831014464778dcbc6d8c9f3.png)

**KG: 从头开始，什么是统计学，它是如何产生的？你能给我们一个简短的定义和该学科的历史吗？**

* * *

## 我们的前三名课程推荐

![](img/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](img/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](img/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在 IT 领域

* * *

**FH:** 这是一个复杂的问题，最好通过参考我们统计学史上伟大人物之一 Stephen Stigler 的众多著作来回答（例如，参见[`en.wikipedia.org/wiki/History_of_statistics`](https://en.wikipedia.org/wiki/History_of_statistics)）。

简言之，统计学起初是为了理解国家的运作、生产力、预期寿命、农业产量等，并从样本中进行估计（后者的一个统计学例子可以追溯到公元前 5 世纪的雅典）。大致而言，统计学已经发展为几个广泛的领域：

+   描述性（例如，通常的棒球统计数据）

+   推论性（例如，棒球击球手在主场比赛时是否有不同的成功概率？）

+   估计性（例如，从一个因子实验中，如果我们保持面粉和糖的量不变，改变烘焙温度的效果）和

+   预测性（例如，金融预测或预测病人多久会复发一次）

关于统计学的定义，它是一个自成体系的学科，并且对所有其他领域和日常生活都大有裨益。统计学的独特之处在于它提供了在面对不确定性时做出决策的有效工具，理解变异和偏差的来源，以及最重要的，统计思维。统计思维是一种不同的思维方式，它既像侦探一样具有怀疑精神，又涉及对问题的不同看法。统计学包括测量改进、实验设计、数据分析、推断和趋势及证据的解释。

**KG: 决策者在有效利用统计学进行决策时需要了解哪些最基本的内容？**

**FH:** 总是最重要的问题是理解测量的意义和可靠性，以及理解数据解释与实验设计之间的联系。随着数据量的增加，普通数据分析师对设计的要求变得更加宽松，因此我们看到许多数据解释的失败案例（参见[`youtu.be/TGGGDpb04Yc`](https://youtu.be/TGGGDpb04Yc)获取一个很好的例子）。当没有设计（如随意数据收集）或使用的设计与项目目标不一致（前瞻性与回顾性设计；随机与观察性设计等）时，统计分析很少能有所补救。现代统计学创始人之一 R. A. Fisher 的名言很好地总结了这个问题：

> “在实验结束后咨询统计学家，往往只是让他进行事后检查。他也许只能说实验的死因。”

关于测量，我看到很多统计学家忘记了“质疑一切”的格言，信任客户对测量的选择或计算。例如，漂亮的连续测量数据通常会被分类，从而导致信息、效能、精确度和普遍性的巨大损失。或者一个研究者可能会使用归一化程序来导出响应变量，这种情况下建模会更好，而不是用来创建比率。鉴于良好的设计和适当的测量，统计分析的方法需要基于良好的统计原则，正如我在[`www.fharrell.com/2017/01/fundamental-principles-of-statistics.html`](http://www.fharrell.com/2017/01/fundamental-principles-of-statistics.html)中尝试概述的那样。

然后结果需要能够被行动化，通过估计对客户有用的尺度（例如，相对治疗效果、预测风险、预期寿命、贝叶斯后验概率）。一个非常常见的问题是随着机器学习的兴起（见下文）对分类的误用；分类对客户做出了过多假设，并且没有提供灰色区域。我在[`www.fharrell.com/2017/01/classification-vs-prediction.html`](http://www.fharrell.com/2017/01/classification-vs-prediction.html)中详细讨论了这一点。

**KG: 统计学中的主要领域或分支有哪些？它们有什么区别？**

**FH:** 有三种思潮：

最常用的是**频率学统计学**，涉及估计、显著性检验、置信区间和假设检验，基于对研究的想象重复（抽样分布）的情景。由于需要考虑抽样分布和“样本空间”，频率学方法可能变得相当复杂，需要为每个抽样方案定制解决方案，例如，当进行顺序检验并希望在有足够证据支持效果时停止。频率学结果的统计陈述已被证明对于非统计学家（以及一些统计学家）来说很难解读。

接下来是**贝叶斯**统计学派，实际上早于频率学派一个多世纪，因为贝叶斯和拉普拉斯的工作。直到强大的计算机被统计学家使用之前，它并没有被广泛使用。贝叶斯方法要求指定一个锚点/起始点（“先验分布”），这可能需要大量思考，但也可以只是指定对数据的怀疑程度。经过这一步骤的好处是显著的——不需要为复杂的设计/抽样方案创建一次性解决方案，而且贝叶斯方法提供直接可操作的概率——例如，效果为正的概率，而不是频率学派的 p 值，后者是对效果为正的假设的概率，而实际上效果可能为零。

最后是**似然**学派，它类似于贝叶斯学派，但没有先验分布。似然方法像贝叶斯方法一样避免样本空间，因此更为简洁，但主要提供相对证据而非绝对证据，并且无法处理包含大量参数的模型。除了这三大学派，每个学派内还有不同的工具，特别是在频率学派中——例如自助法、非参数方法和缺失数据插补方法。

**KG: 在你看来，机器学习和数据科学是否与统计学不同？**

**FH:** 是的。为了简化来说，我会说数据科学是应用统计学 + 计算机科学，更少关注统计理论和假设检验，而更多关注估计和预测。机器学习是一种极为经验主义的统计建模方法，不太关心能否分离变量的效应。许多机器学习从业者在统计学方面有扎实的基础，但也有不少人没有。后一组人似乎在不断重新发明轮子，使用统计学几十年前已经表明无效的方法。

好的统计学家的一个标志是知道如何量化估计和预测的准确性。后一组机器学习从业者从未学习过预测准确性的度量背后的原理和理论（包括适当的概率准确度评分），并且在问题需要预测或最优贝叶斯决策时，持续开发“分类器”。这些分类器存在许多问题，包括无法对新样本进行泛化，特别是当结果频率差异较大时，详细讨论请见[`www.fharrell.com/2017/03/damage-caused-by-classification.html`](http://www.fharrell.com/2017/03/damage-caused-by-classification.html)。

> 机器学习从业者似乎也对**特征选择**情有独钟，却没有意识到折磨数据以试图确定“重要”预测因子与从所有预测因子中获取最大信息的目标相悖，后者涉及到最大化预测区分度。

**KG：你质疑了许多常见的统计实践，并且在批评中往往非常直言。实践者最常犯的错误是什么？**

**FH：** 首先，我从算术开始。令人惊讶的是，很多人不知道除非比率代表的是互斥事件的比例，否则你不能直接相加比率。一般来说，比率是相乘的。我经常看到一些论文分析比率时没有取对数，或者分析基线的百分比变化时没有注意到数学不适用。比如一个从 1.0 开始的对象增加到 2.0，这是 100%的增长。然后考虑一个从 2.0 开始减少到 1.0 的对象，这是一种 50%的减少。100%和-50%的平均值是+25%，而实际上这两个值应该抵消，得到的平均值是 0%。百分比变化是一种不对称的度量，除非在特殊限制下，否则不能用于统计分析。

关于比率的不当加法，许多医学论文在应该加对数的时候加了比值比或风险比。一个简单的例子说明了原因。当开发风险评分时，假设两个风险因素在逻辑回归模型中的回归系数分别为 1 和-1。两个比值比是 2.72 和 0.37。将这两个比值相加假装两个风险因素都是有害的，而实际上第二个风险因素是保护性的。基线变化有许多其他问题，如我的博客中所述。我们应该分析原始响应变量作为因变量，并对原始基线变量进行协变量调整。统计学家和其他数据分析师需要仔细批评他们合作者使用的数学！

在统计模型中，有许多常见的陷阱，包括

+   尝试从样本量所允许的范围内学习过多内容（使用特征选择或估计过多参数），导致过拟合/过度解释。

+   做出不太可能成立的非线性假设；

+   尝试多种转换并假装最终的转换是预先指定的，破坏了结果的统计推断特性（与使用样条函数相对）；

+   使用不准确的评分标准；

+   在信号：噪声比不大的情况下使用分类而非预测；

+   对因变量进行不同的转换或受该变量的离群值影响，而不是使用稳健的半参数有序回归模型。

然后是逐步回归——别让我开始说了……

**二分法**是对数据的最大犯罪之一。这是一种丢失信息的、任意的做法，并假设了自然界中不存在的非连续关系。对连续的因变量或自变量进行分类几乎从来不是一个好主意。

我们每天看到许多其他问题，包括使用无效的图形，如饼图和条形图。

**KG：最后，统计学正在迅速发展，新方法不断涌现。你认为统计学在 10 到 15 年后会是什么样的？**

**FH：** 哎呀——又是一个难题！我确信我们将看到贝叶斯模型被更频繁地使用，因为它们提供了我们真正需要的输出（前向时间、前向信息流概率），并允许我们正式地结合外部信息，即使这些信息，比如说某个治疗的不良事件比率不可能大于 10。我们还将看到更多可解释的、灵活的和鲁棒的预测方法，更直观和强大的统计软件及图形，以及更多不假设正态性或依赖大样本理论的统计方法。

**谢谢你，Frank！**

**[Kevin Gray](https://www.linkedin.com/in/cannongray)** 是 [Cannon Gray](http://cannongray.com/home) 的总裁，这是一家市场科学和分析咨询公司。

[**Frank Harrell**](http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell) 是范德比尔特大学医学院生物统计学教授及生物统计学系创始主任。他还在 FDA 药物评价与研究中心生物统计办公室担任专家统计顾问。他著有多篇论文、影响力巨大的《回归建模策略》一书以及 R 包 rms 和 Hmisc。他可以在他的博客[**统计思维**](http://www.fharrell.com/)中找到。

[原文](https://www.linkedin.com/pulse/vital-statistics-you-never-learnedbecause-theyre-taught-kevin-gray)。经授权转载。

*这篇文章首次发表于 2017 年 8 月的 Greenbook。*

**相关：**

+   因果关系：为何在何处

+   统计建模：入门

+   时间序列分析：入门

### 相关话题

+   [什么是大型语言模型，它们是如何工作的？](https://www.kdnuggets.com/2023/05/large-language-models-work.html)

+   [什么是基础模型，它们是如何工作的？](https://www.kdnuggets.com/2023/05/foundation-models-work.html)

+   [什么是向量数据库，它们为何对 LLMs 重要？](https://www.kdnuggets.com/2023/06/vector-databases-important-llms.html)

+   [你的特征重要吗？这并不意味着它们是好的](https://www.kdnuggets.com/your-features-are-important-it-doesnt-mean-they-are-good)

+   [我从使用 ChatGPT 进行数据科学中学到了什么](https://www.kdnuggets.com/what-i-learned-from-using-chatgpt-for-data-science)

+   [机器学习中的统计学：成为认证专家需要了解的知识](https://www.kdnuggets.com/2024/03/sas-statistics-machine-learning-need-know-become-certified-expert)
