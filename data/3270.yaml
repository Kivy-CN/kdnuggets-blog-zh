- en: AI and Deep Learning, Explained Simply
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能和深度学习，简单解释
- en: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html](https://www.kdnuggets.com/2017/07/ai-deep-learning-explained-simply.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png)[comments](2017/07/ai-deep-learning-explained-simply.html/3#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png)[评论](2017/07/ai-deep-learning-explained-simply.html/3#comments)'
- en: '![AI and Deep Learning](../Images/c7647d29fcffe28c724b24f417ff1a6c.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![AI和深度学习](../Images/c7647d29fcffe28c724b24f417ff1a6c.png)'
- en: 'Sci-fi level **Artificial Intelligence (AI)** like HAL 9000 was promised since
    1960s, but PCs and robots were dumb until recently. Now, tech giants and startups
    are announcing the AI revolution: self-driving cars, robo doctors, robo investors,
    etc. PwC just said that AI will contribute **$15.7 trillion** to the world economy
    by 2030\. “AI” it’s the 2017 buzzword, like “dot com” was in 1999, and everyone
    claims to be into AI. Don’t be confused by the AI hype. Is this a bubble or for
    real? What’s new from older AI flops?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 科幻级**人工智能（AI）**如HAL 9000自1960年代以来就被承诺，但个人电脑和机器人直到最近才智能化。现在，科技巨头和初创公司正宣布人工智能革命：自动驾驶汽车、机器人医生、机器人投资者等。普华永道刚刚表示，到2030年人工智能将为世界经济贡献**15.7万亿美元**。“人工智能”是2017年的流行词，就像“点com”在1999年一样，每个人都声称自己涉足人工智能。不要被人工智能炒作所困惑。这是泡沫还是现实？与旧的人工智能失败相比，有什么新进展？
- en: '**AI is not easy or fast to apply**. The most exciting AI examples come from
    universities or the tech giants. Self-appointed AI experts who promise to revolutionize
    any company with the latest AI in short time are doing **AI misinformation**,
    some just rebranding old tech as AI. Everyone is already using the latest AI through
    Google, Microsoft, Amazon etc. services. But “deep learning” will not soon be
    mastered by the majority of businesses for custom in-house projects. Most have
    insufficient relevant digital data, not enough to train an AI reliably. As a result,
    AI will not kill all jobs, especially because it will require humans to train
    and test each AI.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能的应用并不简单或快速**。最令人兴奋的人工智能实例来自大学或科技巨头。那些自称人工智能专家，承诺用最新的人工智能在短时间内彻底改变任何公司的，正在进行**人工智能误导**，有些只是将旧技术重新包装为人工智能。每个人已经通过Google、Microsoft、Amazon等服务在使用最新的人工智能。但是，“深度学习”不会很快被大多数企业掌握用于定制的内部项目。大多数企业缺乏足够的相关数字数据，无法可靠地训练人工智能。因此，人工智能不会消灭所有工作，尤其是因为它需要人类来训练和测试每个人工智能。'
- en: '**AI now can “see”**, and master vision jobs, for ex. **identify cancer** or
    other diseases from medical images, statistically better than human radiologists,
    ophthalmologists, dermatologists, etc. AI can drive cars, read lips, etc. AI can **paint **in
    any style learned from samples (for ex., Picasso or yours), and apply the style
    to photos. And the inverse: guess a realistic photo from a painting, hallucinating
    the missing details. AIs looking at screenshots of web pages or apps, can write
    code producing similar pages or apps.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能现在可以“看”**，并掌握视觉工作，例如**识别癌症**或其他疾病从医学图像中，比人类放射科医师、眼科医生、皮肤科医生等统计学上更准确。人工智能可以驾驶汽车，阅读唇语等。人工智能可以**以任何从样本中学到的风格绘画**（例如，毕加索风格或你的风格），并将风格应用到照片上。反向操作：从画作中猜测出逼真的照片，幻觉出缺失的细节。观察网页或应用程序截图的人工智能，可以编写生成类似页面或应用程序的代码。'
- en: '![AI and Deep Learning](../Images/c649b75b63b727a4073ef28d679bb39b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![AI和深度学习](../Images/c649b75b63b727a4073ef28d679bb39b.png)'
- en: '***Fig. (Style transfer: learn from a photo, apply to another. Credits: Andrej
    Karpathy)***'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '***图（风格转移：从一张照片中学习，应用到另一张。来源：Andrej Karpathy）***'
- en: '**AI now can “hear”**, not only to understand your voice: it can compose music
    in style of the Beatles or yours, imitate the voice of any person it hears for
    a while, and so on. The average person can’t say what painting or music is composed
    by humans or machines, or what voices are spoken by the human or AI impersonator.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能现在可以“听”**，不仅可以理解你的声音：它可以以披头士的风格或你的风格创作音乐，模仿任何它听到的人的声音，等等。普通人无法分辨什么画作或音乐是由人类还是机器创作的，或者什么声音是由人类还是人工智能伪装者发出的。'
- en: AI trained to win at poker games **learned to bluff**, handling missing and
    potentially fake, misleading information. Bots trained to negotiate and find compromises,
    learned to **deceive **too, guessing when you’re not telling them the truth, and
    lying as needed. A Google translate AI trained on Japanese-English and Korean-English
    examples only, translated Korean-Japanese too, a language pair **it was not trained
    on**. It seems it built an intermediate language on its own, representing any
    sentence regardless of language.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 训练以赢得扑克游戏的AI**学会了诈唬**，处理丢失和潜在虚假、误导的信息。训练用于谈判和寻找妥协的机器人也学会了**欺骗**，能够猜测你是否没有告诉它们真相，并在需要时撒谎。一个只在日英和韩英示例上训练的Google翻译AI，也翻译了韩日语言对，这是一个**它没有训练过的**语言对。看起来它自行构建了一种中间语言，可以表示任何句子，无论语言如何。
- en: '**Machine learning (ML)**, a subset of AI, make machines **learn** from experience,
    from examples of the real world: the more the data, the more it learns. A machine
    is said to learn from experience with respect to a task, if its performance at
    doing the task improves with experience. Most AIs are still made of fixed rules,
    and do not learn. I will use “ML” to refer “AI that learns from data” from now
    on, to underline the difference.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）**，作为AI的一个子集，使机器**从经验中学习**，从现实世界的例子中学习：数据越多，它学到的东西就越多。一个机器被认为是从经验中学习的，如果它在完成任务时的表现随着经验的积累而改善。大多数AI仍然由固定规则组成，无法学习。从现在开始，我将使用“ML”来指代“从数据中学习的AI”，以强调区别。'
- en: '**Artificial Neural Networks (ANN) **is only one approach to ML, others (not
    ANN) include decision trees, support vector machines, etc. **Deep learning** is
    an ANN with many levels of abstraction. Despite the “deep” hype, many ML methods
    are “shallow”. Winning MLs are often a mix – a **ensemble** of methods, for example
    trees + deep learning + other, independently trained and then combined together.
    Each method might make different errors, so averaging their results can win, at
    times, over single methods.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANN）**只是机器学习（ML）的一种方法，其他方法（非ANN）包括决策树、支持向量机等。**深度学习**是具有多个抽象层次的ANN。尽管有“深度”宣传，许多机器学习方法实际上是“浅层”的。成功的机器学习通常是混合的——例如树
    + 深度学习 + 其他方法，独立训练后再结合在一起。每种方法可能会产生不同的错误，因此有时将它们的结果平均起来会胜过单一方法。'
- en: '**The old AI was not learning**. It was rule-based, several “if this then that”
    written by humans: this can be AI since it solves problems, but not ML since it
    does not learn from data. Most of current AI and automation systems still are
    rule-based code. ML is known since the 1960s, but like the human brain, it needs
    billions of computations over lots of data. To train an ML in 1980s PCs it required
    months, and digital data was rare. Handcrafted rule-based code was solving most
    problems fast, so ML was forgotten. But with today’s hardware (NVIDIA GPUs, Google
    TPUs etc.) you can train an ML in minutes, optimal parameters are known, and more
    digital data is available. Then, after 2010 one AI field after another (vision,
    speech, language translation, game playing etc.) it was mastered by MLs, winning
    over rules-based AIs, and often over humans too.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**旧AI并没有学习**。它是基于规则的，由人类编写的多个“如果这样则那样”：这可以被认为是AI，因为它解决了问题，但不算是机器学习，因为它没有从数据中学习。大多数当前的AI和自动化系统仍然是基于规则的代码。机器学习自1960年代以来就已经存在，但就像人脑一样，它需要在大量数据上进行数十亿次计算。要在1980年代的个人电脑上训练一个机器学习系统需要几个月时间，而且数字数据非常稀少。手工编写的基于规则的代码能够快速解决大多数问题，因此机器学习被遗忘了。但借助今天的硬件（NVIDIA
    GPU、Google TPU等），你可以在几分钟内训练一个机器学习系统，最优参数已经知道，数字数据也更多了。然后，自2010年以后，一个接一个的AI领域（视觉、语音、语言翻译、游戏等）都被机器学习掌握，击败了基于规则的AI，并且经常也超过了人类。'
- en: '**Why AI beat humans in Chess in 1997, but only in 2016 in Go**: for problems
    that can be mastered by humans as a limited, well defined rule-set, for ex. beat
    Kasparov (then world champion) at chess, it’s enough (and best) to write a rule-based
    code the old way. The possible next dozen moves in Chess (8 x 8 grid with limits)
    are just billions: in 1997, computers simply became fast enough to try all the
    moves. But in Go (19 x 19 grid, free) there are more moves than atoms in the universe:
    no machine can try them all in billion years. It’s like trying all random letter
    combinations to get this article as result, or trying random paint strokes until
    getting a Picasso: it will never happen. The only known hope is to train an ML
    on the task. But ML is approximate, not exact, to be used only for intuitive tasks
    you can’t reduce to “if this then that” deterministic logic in reasonably few
    loops. ML is “stochastic”: for patterns you can analyse statistically, but you
    can’t predict precisely.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么人工智能在1997年击败了人类的棋盘游戏，但在2016年才击败围棋**：对于人类可以掌握的有限且定义明确的规则集的问题，例如在棋盘上击败卡斯帕罗夫（当时的世界冠军），编写基于规则的代码就足够了（且最好）。在棋盘上的下一步可能有数十亿种：在1997年，计算机速度足够快，能够尝试所有的移动。但在围棋（19
    x 19的棋盘，自由度更高）中，可能的移动数比宇宙中的原子还多：没有机器能在亿年内尝试所有可能性。这就像尝试所有随机的字母组合以获得这篇文章的结果，或者尝试随机的画笔笔触直到得到一幅毕加索作品：这种事永远不会发生。唯一已知的希望是训练机器学习来完成任务。但机器学习是近似的，不是精确的，只能用于你无法简化为“如果这样，那么那样”的确定性逻辑的直观任务。机器学习是“随机的”：对于可以统计分析的模式，但无法精准预测。'
- en: '**ML automates automation**, as long as you prepared correctly the data to
    train from. That’s unlike manual automation where humans come up with rules to
    automate a task, a lot of “if this then that” describing for ex. what e-mail is
    likely to be spam or not, or if a medical photo represents a cancer or not. In
    ML instead we only feed data samples of the problem to solve: lots (thousands
    or more) of spam and no spam emails, cancer and no cancer photos etc., all first
    sorted, polished, and labeled by humans. The ML then figures out (learns) the
    rules by itself, magically, but it does not explains these rules. You show a photo
    of a cat, the ML says this is a cat, but no indication why.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习自动化了自动化**，只要你正确准备了训练数据。这不同于手动自动化，人类通过“如果这样，那么那样”的规则来自动化任务，例如判断电子邮件是否可能是垃圾邮件，或医疗照片是否显示癌症。在机器学习中，我们只需输入解决问题的数据样本：大量（数千或更多）垃圾邮件和非垃圾邮件、癌症和非癌症照片等，所有这些都需先由人类排序、清理和标记。机器学习然后自己“学习”规则，像魔法一样，但它不能解释这些规则。你展示一张猫的照片，机器学习系统说这是猫，但没有说明理由。'
- en: '![Bi-Directional Image Transformations with Deep Learning](../Images/c5f267a4fa4de9aff08af53db2b1e49c.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![双向图像转换与深度学习](../Images/c5f267a4fa4de9aff08af53db2b1e49c.png)'
- en: '*(bidirectional AI transforms: Horse to Zebra, Zebra to Horse, Summer from/to
    Winter, Photo from/to Monet etc. credits: Jun-Yan Zhu, Taesung Park et all.)*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*(双向AI转换：马到斑马，斑马到马，夏天到冬天，照片到莫奈风格等，致谢：Jun-Yan Zhu, Taesung Park 等人。)*'
- en: Most ML is **Supervised Learning**, where the examples for training are given
    to ML along with labels, a description or transcription of each example. You first
    need a human to divide the photos of cats from those of dogs, or spam from legitimate
    emails, etc. If you label the data incorrectly, the ML results will be incorrect,
    this is very important as will be discussed later. Throwing unlabeled data to
    ML it’s **Unsupervised Learning**, where the ML discovers patterns and clusters
    on data, useful for exploration, but unlikely enough alone to solve your problems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习是**监督学习**，其中训练示例会被提供给机器学习系统，并附带标签、描述或每个示例的转录。你首先需要人工将猫的照片与狗的照片区分开，或者将垃圾邮件与合法邮件区分开等。如果你错误地标记数据，机器学习结果将会不准确，这一点非常重要，后面会进一步讨论。将未标记的数据投入到机器学习中则是**无监督学习**，在这种情况下，机器学习会发现数据中的模式和聚类，适用于探索，但单独使用不太可能解决你的问题。
- en: In **Anomaly Detection** you identify unusual things that differ from the norm,
    for ex. frauds or cyber intrusions. An ML trained only on old frauds it would
    miss the always new fraud ideas. Then, you can teach the normal activity, asking
    the ML to warn on any suspicious difference. Governments already rely on ML to
    detect tax evasion.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在**异常检测**中，你识别出与正常情况不同的异常事物，例如欺诈或网络入侵。一个仅在旧的欺诈案例上训练的机器学习系统会错过总是新的欺诈想法。然后，你可以教会机器学习正常活动，要求其对任何可疑差异发出警告。政府已经依赖机器学习来检测税收逃漏。
- en: '**Reinforcement Learning** is shown in the 1983 movie War Games, where a computer
    decides not to start World War III by playing out every scenario at light speed,
    finding out that all would cause world destruction. The AI discovers through millions
    of trial and error, within rules of a game or an environment, which actions yield
    the greatest rewards. AlphaGo was trained this way: it played against itself millions
    of times, reaching super-human skills. It made surprising moves, never seen before,
    that humans would consider as mistakes. But later, these was proven as brilliantly
    innovative tactics. The ML became more **creative** than humans at the Go game.
    At Poker or other games with hidden cards, the MLs learns to bluff and deceive
    too: it does what’s best to win.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习** 在1983年的电影《战争游戏》中有所体现，其中一台计算机通过以光速模拟每种情境来决定不发动第三次世界大战，发现所有情境都会导致世界毁灭。人工智能通过数百万次的试错发现，在游戏或环境的规则下，哪些行动带来最大的奖励。AlphaGo就是通过这种方式训练的：它与自己对弈了数百万次，达到了超人类的技能。它做出了令人惊讶的举动，这些举动以前从未见过，人类会认为这些是错误。但后来，这些被证明是极具创新的战术。机器学习在围棋游戏中变得比人类更**创造性**。在扑克或其他有隐藏牌的游戏中，机器学习也学会了虚张声势和欺骗：它会做出最有利于获胜的决策。'
- en: '**The “AI effect” is when people argue that an AI it is not real intelligence**.
    Humans subconsciously need to believe to have a magical spirit and unique role
    in the universe. Every time a machine outperforms humans on a new piece of intelligence,
    such as play chess, recognize images, translate etc., always people say: “That’s
    just brute force computation, not intelligence”. Lots of AI is included in many
    apps, but once widely used, it’s not labeled “intelligence” anymore. If “intelligence”
    it is only what’s not done yet by AI (what’s still unique to the brain), then
    dictionaries should be updated every year, like: “math it was considered intelligence
    until 1950s, but now no more, since computers can do it”, it’s quite strange.
    About “brute force”, a human brain got 100 trillion of neuronal connections, lots
    more than any computer on earth. ML can’t do “brute force”: trying all the combinations
    it would take billion years. ML do “educated guesses” using less computations
    than a brain. So it should be the “smaller” AI to claim that the human brain as
    not real intelligence, but only brute force computation.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**“人工智能效应”指的是人们争辩说人工智能不是真正的智能**。人类潜意识里需要相信自己在宇宙中有一种神秘的精神和独特的角色。每当机器在新的智能领域超越人类，比如下棋、识别图像、翻译等，人们总是会说：“这只是纯粹的计算，不是真正的智能。”很多人工智能已经被应用到许多应用程序中，但一旦广泛使用，它们就不再被标记为“智能”。如果“智能”仅仅是指人工智能尚未做到的（仍然是大脑特有的），那么词典应该每年更新，比如：“数学在1950年代被认为是智能，但现在不再是，因为计算机可以完成”，这相当奇怪。关于“纯粹计算”，人脑有100万亿个神经连接，比地球上任何计算机都多。机器学习无法进行“纯粹计算”：尝试所有组合需要数十亿年。机器学习通过比大脑更少的计算来进行“有根据的猜测”。所以，应该是“较小的”人工智能声称人脑不是现实的智能，而只是纯粹计算。'
- en: '**ML is not a human brain simulator**: real neurons are very different. ML
    it’s an alternative way to reach brain-like results, similar to a brain like a
    horse is similar to a car. It matters that both car and horse can transport you
    from point A to point B: the car do it faster, consuming more energy and lacking
    most horse features. Both the brain and ML run statistics (probability) to approximate
    complex functions: they give result only a bit wrong, but usable. MLs and brains
    give different results on same task, as they approximate in different way. Everyone
    knows that while the brain forgets things and is limited in doing explicit math,
    the machines are perfect for memory and math. But the old idea that machines either
    give exact results or are broken is wrong, outdated. Humans do many mistakes,
    but instead of: “this brain is broken!”, you hear: “study more!”. MLs doing mistakes
    are not “broken” either, they must study more data, or different data. MLs trained
    with biased (human generated) data will end up racist, sexist, unfair: human in
    the worst way. AI should not be compared only with our brain, AI it is different,
    and that’s an opportunity. We train MLs with our data, to imitate the human jobs,
    activity and brain only. But the same MLs, if trained in other galaxies, could
    imitate different (perhaps better) alien brains. Let’s try to think in alien ways
    too.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习不是人脑的模拟器**：真实的神经元差别很大。机器学习是一种达到类似大脑结果的替代方式，类似于汽车与马匹的关系。重要的是，汽车和马匹都可以将你从A点运输到B点：汽车做得更快，消耗更多的能量且缺乏大多数马的特性。大脑和机器学习都运行统计（概率）来近似复杂的函数：它们给出的结果只有一点点错误，但仍然可以使用。机器学习和大脑在相同任务上给出的结果不同，因为它们的近似方式不同。每个人都知道，虽然大脑会遗忘事物且在进行显式数学运算时有限，但机器在记忆和数学方面表现完美。但认为机器要么给出精确结果，要么就坏了的旧观念是错误且过时的。人类犯很多错误，但不是：“这个大脑坏了！”，而是：“多学习点！”机器学习犯错也并不是“坏了”，它们需要更多的数据或不同的数据。使用有偏见（由人类生成）的数据训练的机器学习模型会变得种族歧视、性别歧视、不公平：以最糟糕的人类方式。人工智能不应仅与我们的大脑进行比较，人工智能是不同的，这也是一个机会。我们用我们的数据训练机器学习模型，以模仿人类的工作、活动和大脑。但相同的机器学习模型，如果在其他星系中训练，可能会模仿不同（或许更好）的外星大脑。让我们也试着用外星人的方式思考。'
- en: '**AI is getting as mysterious as humans**. The idea that computers can’t be
    creative, liars, wrong or human-like comes from old rule-based AI, indeed predictable,
    but that seems changed with ML. The arguments to reduce each new capability mastered
    by AI as “not real intelligence” are ending. The real issue left is: general versus
    narrow AI.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能变得与人类一样神秘**。认为计算机不能创造、撒谎、犯错或像人类的观点来自于旧有的规则驱动型人工智能，这些人工智能确实可预测，但这似乎随着机器学习而改变。将人工智能掌握的每一个新能力归结为“非真正智能”的论点正在结束。剩下的真正问题是：一般人工智能与狭义人工智能。'
- en: '![AI in the movies](../Images/09bfcaf72ce6441fb4bf4944111f0099.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![电影中的人工智能](../Images/09bfcaf72ce6441fb4bf4944111f0099.png)'
- en: '*(Please forget the general AI seen in movies. But the “narrow AI” is smart
    too!)*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*(请忘记电影中的一般人工智能。但是“狭义人工智能”也很聪明！)*'
- en: '**Unlike some other sciences, you can’t verify if an ML is correct using a
    logical theory**. To judge if an ML it is correct or not, you can only test its
    results (errors) on unseen new data. The ML is not a black box: you can see the
    “if this then that” list it produces and runs, but it’s often too big and complex
    for any human to follow. ML it’s a practical science trying to reproduce the real
    world’s chaos and human intuition, without giving a simple or theoretical explanation.
    It gives the too big to understand linear algebra producing the results. It’s
    like when you have an idea which works, but **you can’t explain exactly how you
    came up with the idea**: for the brain that’s called inspiration, intuition, subconscious,
    while in computers it’s called ML. If you could get the complete list of neuron
    signals that caused a decision in a human brain, could you understand why and
    how really the brain took that decision? Maybe, but it’s complex.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**与其他一些科学不同，你无法通过逻辑理论验证一个机器学习模型是否正确**。要判断一个机器学习模型是否正确，你只能测试它在未见过的新数据上的结果（错误）。机器学习并不是一个黑箱：你可以看到它产生并运行的“如果这样，那么那样”的列表，但通常这些列表太大且复杂，任何人都很难跟随。机器学习是一种实践科学，试图重现现实世界的混乱和人类直觉，而没有给出简单或理论性的解释。它产生的线性代数过于庞大以至于难以理解。就像你有一个有效的想法，但**你无法准确解释你是如何产生这个想法的**：对大脑来说，这被称为灵感、直觉、潜意识，而在计算机中则称为机器学习。如果你能够获得导致人脑决策的完整神经信号列表，你能理解大脑为什么以及如何做出那个决策吗？也许能，但这很复杂。'
- en: '**Everyone can intuitively imagine** (some even draw) the face of a person,
    in original and in Picasso style. Or imagine (some even play) sounds or music
    styles. But no one can describe, with a complete and working formula, the face,
    sound or style change. **Humans can visualize only up to 3 dimensions**: even
    Einstein it could not conceive, consciously, ML-like math with let’s say 500 dimensions.
    Such 500D math is solved by our brains all the time, intuitively, like magic.
    Why it is not solved consciously? Imagine if for each idea, the brain also gave
    us the formulas used, with thousands of variables. That extra info would confuse
    and slow us down a lot, and for what? No human could use pages-long math, we’re
    not evolved with an USB cable on the head.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**每个人都可以直观地想象**（有些人甚至绘制）一个人的面孔，无论是原始的还是毕加索风格的。或者想象（有些人甚至演奏）声音或音乐风格。但是没有人能够用完整而有效的公式描述面孔、声音或风格的变化。**人类只能可视化最多3维**：即使是爱因斯坦也无法意识到像500维这样的机器学习数学。这种500维的数学被我们的脑袋一直以直观的方式解决，像魔法一样。为什么它不能被有意识地解决？想象一下，如果大脑对每个想法还给我们使用的公式，包含成千上万的变量。那额外的信息会使我们非常困惑和缓慢，而且有什么用呢？没有人能够使用数页长的数学公式，我们不是进化成头上带着USB线的样子。'
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目的，并寻找目的以…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，详细分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[建立一个坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
