- en: When to Retrain an Machine Learning Model? Run these 5 checks to decide on the
    schedule
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么时候重新训练机器学习模型？进行这5个检查来决定计划
- en: 原文：[https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html](https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html](https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By** [**Emeli Dral**](https://twitter.com/EmeliDral)**, CTO and Co-founder
    of Evidently AI &** [**Elena Samuylova**](https://twitter.com/elenasamuylova/)**,
    CEO and Co-founder at Evidently AI**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由** [**Emeli Dral**](https://twitter.com/EmeliDral)**，Evidently AI 的首席技术官和联合创始人
    &** [**Elena Samuylova**](https://twitter.com/elenasamuylova/)**，Evidently AI
    的首席执行官和联合创始人**'
- en: The world and data are not static. But most machine learning models are. Once
    they are in production, they become less relevant with time. The [data distributions
    evolve, the behavioral patterns change](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift),
    and models need updates to keep up with new reality.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 世界和数据是不断变化的。但大多数机器学习模型是静态的。一旦投入生产，它们会随着时间的推移变得不那么相关。[数据分布会变化，行为模式也会改变](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)，模型需要更新以跟上新的现实。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The usual process is to retrain the models at defined intervals. It looks quite
    straightforward: take the new data, the old training pipeline, and fit the model
    again.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的过程是在定义的时间间隔内重新训练模型。这看起来相当简单：获取新数据、旧的训练管道，并再次拟合模型。
- en: But how often should we do it? Should it be done daily, weekly, or monthly?
    Or every time you get a new batch of data?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们应该多久进行一次？是每天、每周还是每月？或者每次获得一批新数据时？
- en: '![Image](../Images/6633c2014ec57d3088ba2179d982447e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/6633c2014ec57d3088ba2179d982447e.png)'
- en: Too often, the answer is based on a gut feeling or convenience. Someone picks
    a reasonable interval and schedules a regular retraining job.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 过于频繁地，答案是基于直觉或方便性。有人选择一个合理的时间间隔并安排定期再训练任务。
- en: Instead, we can approach it in a more data-driven way. To be more precise when
    planning the model maintenance, we can run a few checks in advance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以以更具数据驱动的方式进行。为了更准确地规划模型维护，我们可以提前进行一些检查。
- en: Depending on how critical the model is, you might go through all of them or
    only some.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型的重要性，你可能会通过所有检查或仅部分检查。
- en: 'Check #1\. Is the model already good enough?'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #1\. 模型是否已经足够好？'
- en: Before we make our retraining plans, it helps to check if we are done with training!
    Maybe, the model hasn’t reached its peak performance yet?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在制定再训练计划之前，检查我们是否完成了训练是有帮助的！也许，模型还没有达到最佳性能？
- en: The simple way to do that is to look at good old learning curves.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的方法是查看老旧的学习曲线。
- en: '![Image](../Images/f0988021c2e694e56e03bef78e14da42.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/f0988021c2e694e56e03bef78e14da42.png)'
- en: How to proceed? We can fix the test set which we use to evaluate the model performance.
    Then, run a set of experiments by training the model on different parts of the
    training data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如何继续？我们可以固定测试集来评估模型性能。然后，通过在不同部分的训练数据上训练模型，进行一系列实验。
- en: We can use the random split method and iterate by changing the train size. This
    way, we focus on how the data volume impacts the performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用随机拆分方法，并通过改变训练规模进行迭代。这样，我们可以专注于数据量如何影响性能。
- en: '![Image](../Images/1353e1f20c4313d1a9f55092a6d2800a.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1353e1f20c4313d1a9f55092a6d2800a.png)'
- en: 'There are two things we can learn as a result: 1) how much data we need to
    reach the peak performance 2) whether the model reaches this plateau with the
    available training data.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 结果我们可以学到两件事：1）我们需要多少数据才能达到峰值性能 2）模型是否在可用的训练数据下达到了这个平台。
- en: '**Sometimes we’d learn that the model doesn’t need all the data we have.**
    For example, we have multiple years of sales data, but using just one year of
    training data gets the same quality.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**有时我们会发现模型不需要我们所有的数据。** 例如，我们有多年的销售数据，但使用仅一年的训练数据可以获得相同的质量。'
- en: We might drop the extra data to make the model more lightweight.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会去掉多余的数据，使模型更轻量化。
- en: '**In other cases, we could see that the model quality keeps going up and up**.
    The model is hungry for more data! There are more steps to be made to bring the
    model to its top shape.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，我们可能会看到模型质量不断提高**。模型渴望更多数据！还有更多步骤需要完成，以将模型调整到最佳状态。'
- en: '![Image](../Images/7d75b4bc993a559419e6f57d29fb3c70.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/7d75b4bc993a559419e6f57d29fb3c70.png)'
- en: Rather than think about model retraining to maintain its quality, we should
    plan for continuous improvement. As soon as we get enough new data, we can use
    it to reach better performance.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与其考虑重新训练模型以维持其质量，我们应该计划持续改进。一旦我们获得足够的新数据，就可以利用它达到更好的性能。
- en: This first test also gives a sense of scale and “density” of signal in the data.
    Do we need 10, 100, or 1000 observations to see a meaningful impact on the model
    performance? Would it take us a day or a month to collect that amount of new data?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个初步测试还提供了数据中信号的规模和“密度”的感觉。我们需要10个、100个还是1000个观察来观察模型性能的有意义影响？收集这么多新数据需要一天还是一个月？
- en: That’s a helpful thing to know!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一件有用的事情！
- en: 'Check #2\. How quickly do things change?'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #2\. 事情变化的速度有多快？'
- en: When we create our machine learning models, we assume there is some stability
    in the real-world process. Otherwise, it would make little sense to learn from
    the past!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建机器学习模型时，我们假设现实世界过程有一定的稳定性。否则，从过去中学习就毫无意义了！
- en: We also know that things change. When working with a dynamic process, we can
    also assume that there is a certain speed at which these new patterns accumulate.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也知道事情会变化。在处理动态过程时，我们还可以假设这些新模式的积累有一定的速度。
- en: We can then try to calculate this!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以尝试计算这个！
- en: Let’s take our model and see how long it “lasts” if we simulate its application
    in the past.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拿出我们的模型，看看如果我们模拟它在过去的应用，它能“持续”多久。
- en: '![Image](../Images/f57dc5e2baea3ed6c05cdd2eefc14927.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/f57dc5e2baea3ed6c05cdd2eefc14927.png)'
- en: We can train a model using some older part of the data and then “apply” it to
    the later periods. Just like we do with a hold-out set, but here we simply take
    several consecutive ones.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用数据中的一些较早部分来训练模型，然后将其“应用”到后来的时期。就像我们用保留集一样，只不过这里我们只是取几个连续的部分。
- en: We can start with a single-point estimate and see how fast the performance degrades.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从一个单点估计开始，看看性能下降的速度有多快。
- en: '![Image](../Images/886251abc0b3af2682dc5aedba2e68cd.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/886251abc0b3af2682dc5aedba2e68cd.png)'
- en: If we have enough historical data, we can repeat this check several times and
    then average the results. Just keep an eye on potential outliers and rare events!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有足够的历史数据，我们可以多次重复这个检查，然后取平均值。只需注意潜在的异常值和稀有事件！
- en: '![Image](../Images/4187c122c80bd37ca886503946959293.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/4187c122c80bd37ca886503946959293.png)'
- en: '**Sometimes we’d learn that an “old” model performs as good as new.** Some
    prefer to retrain the models often to keep them “fresh,” but it is not always
    justified.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**有时我们会发现“旧”模型的表现和新模型一样好。** 一些人喜欢经常重新训练模型以保持其“新鲜”，但这并不总是有必要的。'
- en: Don’t fix what’s not broken!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不要修复未损坏的东西！
- en: If frequent retraining is not needed, you might go away with a lighter service
    architecture. You can also decrease the risks of technical errors that come with
    any change. The same goes for the organizational overhead, especially when new
    models require an approval process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不需要频繁重新训练，你可能会选择一个更轻量的服务架构。你还可以降低由于任何更改带来的技术错误风险。组织开销也是如此，特别是当新模型需要审批流程时。
- en: '![Image](../Images/7cf2c1d846f0a3770216da28a8ebe87a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/7cf2c1d846f0a3770216da28a8ebe87a.png)'
- en: '**In other cases, you can learn that the model ages very fast!** That is good
    to know in advance to set up proper monitoring and prepare the infrastructure.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，你会发现模型衰老得非常快！** 提前了解这一点有助于设置适当的监控和准备基础设施。'
- en: You might decide to reconsider your training approach to make the model more
    stable. For example, change feature engineering or model architecture to make
    it a bit less performant on the test set but more stable in the long run. In other
    cases, you might train the model using a shorter training period but perform frequent
    calibration or consider active learning.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能决定重新考虑你的训练方法，以使模型更稳定。例如，改变特征工程或模型架构，使其在测试集上的表现稍微逊色，但在长期内更稳定。在其他情况下，你可能会使用较短的训练期来训练模型，但进行频繁的校准或考虑主动学习。
- en: We might also face constraints in our ability to retrain the model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能还会面临重新训练模型能力的限制。
- en: That brings us to the next check.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将引出下一个检查。
- en: 'Check #3\. When do we get the new data?'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #3。我们什么时候获得新数据？'
- en: '![Image](../Images/ad4cb68a76433b6c053208581142e7d7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/ad4cb68a76433b6c053208581142e7d7.png)'
- en: Here, we look at the business process rather than the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们关注的是业务流程而不是数据。
- en: Sometimes, we get real-world feedback almost immediately. For example, you recommend
    an article to read, and you quickly know if the user clicked on a link.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们几乎立即获得现实世界的反馈。例如，你推荐了一篇文章，且你很快知道用户是否点击了链接。
- en: In other cases, the new data that you can use to retrain your model comes with
    a delay.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，你可以用来重新训练模型的新数据会有延迟到达。
- en: If you have a long prediction horizon, you have to wait to know if your prediction
    was correct. With other tasks, you need a separate labeling process. Sometimes,
    the limitations come from how the data is moved or generated. For example, manual
    data entry is done once per month.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个较长的预测期，你必须等待才能知道你的预测是否正确。对于其他任务，你需要一个单独的标注过程。有时，限制来自于数据的移动或生成方式。例如，手动数据录入每月进行一次。
- en: '![Image](../Images/4d963f1ef664d1112a0b9573247d2a02.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/4d963f1ef664d1112a0b9573247d2a02.png)'
- en: We can find ourselves in one of the two situations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会面临这两种情况之一。
- en: '**In some cases, the model degrades before the new data arrives.** It becomes
    a limitation.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**在某些情况下，模型在新数据到达之前就已经衰退。** 这就成了一个限制。'
- en: If we do not get the data in time to retrain the model, we might need to reconsider
    the approach again. For example, create an ensemble of models with different retraining
    horizons or combine machine learning with rules or human-in-the-loop. As a last
    resort, we can also adjust our performance expectations and prepare to deal with
    a lowered model quality.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有及时获得数据来重新训练模型，我们可能需要重新考虑方法。例如，创建具有不同重新训练周期的模型集成，或将机器学习与规则或人工干预结合起来。作为最后的手段，我们还可以调整我们的性能期望，并准备应对降低的模型质量。
- en: '**In other cases, the new data starts accumulating before the model decay.**
    In this case, we have the luxury of choice.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，新数据开始积累之前，模型已经开始衰退。** 在这种情况下，我们有选择的余地。'
- en: We can, of course, simply initiate the retraining at any point after the data
    comes. If we want to be more precise, there is a way to do that.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以在数据到来后的任何时候启动重新训练。如果我们想更精确一些，有一种方法可以做到这一点。
- en: Read on!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 继续阅读！
- en: 'Check #4\. How much data do we need to see the improvement?'
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #4。我们需要多少数据才能看到改进？'
- en: Say the new data arrives daily, but the model degrades only after 30 days. What
    would be the optimal action? Should we retrain daily, weekly, or once per month?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 假设新数据每天到达，但模型只有在30天后才衰退。最优的行动是什么？我们应该每天、每周还是每月重新训练？
- en: '![Image](../Images/93da0c9a4e5c92b0642fc2c37d89f2a3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/93da0c9a4e5c92b0642fc2c37d89f2a3.png)'
- en: We can make a more precise judgment by checking if the new bucket of data brings
    the improvement we want.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查新数据桶是否带来了我们想要的改进来做出更精确的判断。
- en: The thing is, sometimes adding a small set of new data points does not change
    anything. There is some minimal required data size that has a visible impact on
    the performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，有时添加一小部分新数据点不会改变任何东西。有一个最小的数据量对性能有明显的影响。
- en: We can evaluate this.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对此进行评估。
- en: 'To do that, we choose a test set from a period of the known decay. We know
    when the performance goes down: we can then check if retraining on the new data
    improves it.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们从已知衰退的期间中选择一个测试集。我们知道何时性能下降：然后我们可以检查是否在新数据上重新训练能够改进性能。
- en: '![Image](../Images/36e21e33e0b86cf04f120b86ea13917b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/36e21e33e0b86cf04f120b86ea13917b.png)'
- en: We can add data in small increments as it comes. Then, we see how it affects
    the test performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在数据到来时逐渐添加数据。然后，观察其对测试性能的影响。
- en: What often happens is that we have to wait a bit to collect a “useful” amount
    of data—for example, at least a week of it to capture the relevant seasonal patterns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的情况是我们需要等待一段时间以收集“有用”的数据——例如，至少一周的数据来捕捉相关的季节性模式。
- en: As a result, our actual choice of retraining window might be more narrow than
    it seemed! On the side, it is limited by the speed of data provision. On the other
    side, by the need to collect enough data for retraining to bring effect.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，我们实际选择的再训练窗口可能比预想的要窄！一方面，它受到数据提供速度的限制。另一方面，则受到收集足够数据以产生效果的需求限制。
- en: '![Image](../Images/0c8d71d262bc407a56865915a599e208.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/0c8d71d262bc407a56865915a599e208.png)'
- en: Within this time frame, you can pick the period based on what’s practical and
    makes more sense for the use case.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时间框架内，你可以根据实际情况和用例的合理性选择时间段。
- en: 'Check #5\. Should we keep the older data?'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #5。我们应该保留旧数据吗？'
- en: There is one more question that often comes up. How should we retrain the model?
    Should we add some new data and drop some old? Should we continuously increase
    the training set?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个常见问题。我们应该如何再训练模型？我们应该添加一些新数据并丢弃一些旧数据吗？我们是否应该持续增加训练集？
- en: This is a bonus check we can run.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个额外的检查项。
- en: We can imitate model retraining at the chosen interval and then check how things
    change if we start dropping the old data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在选定的间隔进行模型再训练，然后检查如果我们开始丢弃旧数据，情况会如何变化。
- en: '![Image](../Images/2433693530f83ace89e16563af95b574.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/2433693530f83ace89e16563af95b574.png)'
- en: We can often see that leaving out the old data makes no difference. Then, it
    is probably a sane thing to do to keep the training more lightweight.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常会发现，排除旧数据没有任何区别。那么，保留训练数据以保持训练更轻量可能是明智的做法。
- en: What’s more, sometimes it makes the model better! Keeping the old irrelevant
    data might cause the performance to go down if you have a dynamic use case. That
    is good to know in advance.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，有时这会让模型变得更好！如果你有一个动态的用例，保留旧的无关数据可能会导致性能下降。这一点提前了解是很有帮助的。
- en: Of course, we might also see that it makes sense to keep all you have for the
    time being. You can probably repeat the check later on.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可能会看到，暂时保留所有数据是有意义的。你可以稍后再重复检查。
- en: What’s next?
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 接下来是什么？
- en: With these checks, you can come prepared for the model maintenance. You can
    set up your retraining pipelines to get ready for the updates at a chosen interval.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些检查，你可以为模型维护做好准备。你可以设置再训练管道以便在选定的间隔进行更新。
- en: Still, we cannot simply rely on our schedule. We also need a reality check.
    This means, monitoring our models once they go live.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们不能仅仅依赖我们的计划。我们还需要现实检查。这意味着，模型上线后要进行监控。
- en: To get the visibility, we can build a [monitoring dashboard](https://github.com/evidentlyai/evidently)
    or schedule regular checks to calculate the actual model performance (if we have
    the ground truth) or otherwise monitor the input data for statistical distribution
    drifts and outliers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得可视性，我们可以构建一个[监控仪表板](https://github.com/evidentlyai/evidently)，或者安排定期检查以计算实际模型性能（如果我们有真实数据），或者监控输入数据的统计分布漂移和异常值。
- en: '![Image](../Images/19db7390f4ca668c6a5a3a66023ce064.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/19db7390f4ca668c6a5a3a66023ce064.png)'
- en: Even stable models can face [data and concept drift](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)
    or certain rare events. In this case, we might then need to intervene earlier
    than planned.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是稳定的模型也可能面临[数据和概念漂移](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)或某些稀有事件。在这种情况下，我们可能需要比计划更早进行干预。
- en: On the other side, if things look steady, and we can skip an update for longer
    than planned.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果情况稳定，我们可以跳过比计划更长时间的更新。
- en: Planning for regular retraining and complementing this with continuous monitoring
    is usually an optimal strategy to make the model live up to its promised performance!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 规划定期再训练并结合持续监控通常是让模型达到其承诺性能的**最佳**策略！
- en: '**Links**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**链接**'
- en: You can find an extended version of this article [here](https://evidentlyai.com/blog/retrain-or-not-retrain).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://evidentlyai.com/blog/retrain-or-not-retrain)找到这篇文章的扩展版本。
- en: '[Machine learning monitoring checklist](/2021/03/machine-learning-model-monitoring-checklist.html)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[机器学习监控清单](/2021/03/machine-learning-model-monitoring-checklist.html)'
- en: '**Emeli Dral** is a Co-founder and CTO at Evidently AI where she creates tools
    to analyze and monitor ML models. Earlier she co-founded an industrial AI startup
    and served as the Chief Data Scientist at Yandex Data Factory. She is a co-author
    of the Machine Learning and Data Analysis curriculum at Coursera with over 100,000
    students.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Emeli Dral** 是 Evidently AI 的联合创始人兼首席技术官，她在这里创建了分析和监控机器学习模型的工具。她曾共同创立了一家工业
    AI 初创公司，并在 Yandex Data Factory 担任首席数据科学家。她还是 Coursera 上机器学习和数据分析课程的共同作者，该课程有超过100,000名学生。'
- en: '[https://twitter.com/EmeliDral](https://twitter.com/EmeliDral)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/EmeliDral](https://twitter.com/EmeliDral)'
- en: '**Elena Samuylova** is a Co-founder and CEO at Evidently AI. Earlier she co-founded
    an industrial AI startup and led business development at Yandex Data Factory.
    Since 2014, she has worked with companies from manufacturing to retail to deliver
    ML-based solutions. In 2018, Elena was named 50 Women in Product Europe by Product
    Management Festival.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Elena Samuylova** 是 Evidently AI 的联合创始人兼首席执行官。她曾共同创立了一家工业 AI 初创公司，并在 Yandex
    Data Factory 负责业务发展。自2014年以来，她一直与从制造业到零售业的公司合作，提供基于机器学习的解决方案。2018年，Elena 被 Product
    Management Festival 评选为欧洲50位杰出产品女性之一。'
- en: '[https://twitter.com/elenasamuylova/](https://twitter.com/elenasamuylova/)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/elenasamuylova/](https://twitter.com/elenasamuylova/)'
- en: '**Related:**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Learning from machine learning mistakes](/2021/03/learning-from-machine-learning-mistakes.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从机器学习错误中学习](/2021/03/learning-from-machine-learning-mistakes.html)'
- en: '[A Machine Learning Model Monitoring Checklist: 7 Things to Track](/2021/03/machine-learning-model-monitoring-checklist.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型监控检查清单：7 个需要跟踪的事项](/2021/03/machine-learning-model-monitoring-checklist.html)'
- en: '[MLOps: Model Monitoring 101](/2021/01/mlops-model-monitoring-101.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：模型监控 101](/2021/01/mlops-model-monitoring-101.html)'
- en: More On This Topic
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Schedule & Run ETLs with Jupysql and GitHub Actions](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Jupysql 和 GitHub Actions 计划和运行 ETL](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
- en: '[Deep Learning For Compliance Checks: What''s New?](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[合规检查中的深度学习：有什么新变化？](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
- en: '[7 Essential Data Quality Checks with Pandas](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Pandas 进行 7 项数据质量检查](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)'
- en: '[Learn Machine Learning From These GitHub Repositories](https://www.kdnuggets.com/2023/01/learn-machine-learning-github-repositories.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这些 GitHub 仓库学习机器学习](https://www.kdnuggets.com/2023/01/learn-machine-learning-github-repositories.html)'
- en: '[Learn How to Run Alpaca-LoRA on Your Device in Just a Few Steps](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解如何在您的设备上仅需几个步骤运行 Alpaca-LoRA](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)'
- en: '[Run an LLM Locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 LM Studio 运行 LLM](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
