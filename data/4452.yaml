- en: Getting Started with TensorFlow 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 2 入门
- en: 原文：[https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html](https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html](https://www.kdnuggets.com/2020/07/getting-started-tensorflow2.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: But wait… What is Tensorflow?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等……什么是 TensorFlow？
- en: Tensorflow is a Deep Learning Framework by Google, which released its 2nd version
    in 2019\. It is one of the world's most famous Deep Learning frameworks widely
    used by Industry Specialists and Researchers.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是 Google 的一个深度学习框架，于2019年发布了第二版。它是全球最著名的深度学习框架之一，广泛应用于工业专家和研究人员。
- en: '![](../Images/27d7d21c1f39e5d239bfde9d58901f9c.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27d7d21c1f39e5d239bfde9d58901f9c.png)'
- en: Tensorflow v1 was difficult to use and understand as it was less Pythonic, but
    with v2 released with Keras now fully synchronized with Tensorflow.keras, it is
    easy to use, easy to learn, and simple to understand.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow v1 使用起来很困难，因为它不够 Pythonic，但 v2 发布后与 Keras 完全同步，现在使用起来简单易学，理解起来也很直观。
- en: Remember, this is not a post on Deep Learning so I expect you to be aware of
    Deep Learning terms and the basic ideas behind it.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这不是一篇关于深度学习的文章，所以我希望你对深度学习的术语和基本概念有一定了解。
- en: We will explore the world of Deep Learning with a very famous data set known
    as the IRIS data set.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个非常著名的数据集——IRIS 数据集，来探索深度学习的世界。
- en: Let’s jump straight into code to understand what is happening.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接跳入代码，了解发生了什么。
- en: Importing and understanding the dataset
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入并理解数据集
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now this *iris *is a dictionary. We can see it’s keys using
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这个*iris*是一个字典。我们可以使用以下方法查看它的键
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So our data is in *data *key, *target *is in *target *key, and so on. If you
    want to see details of this dataset, you can use *iris['DESCR']*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们的数据在*data*键中，*target*在*target*键中，等等。如果你想查看这个数据集的详细信息，你可以使用*iris['DESCR']*。
- en: Now we have to import other important libraries which will help us in creating
    our neural network.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要导入其他重要的库，这将帮助我们创建神经网络。
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here we have imported 2 main things from *tensorflow*, which are *Dense *and *Sequential*.
    Dense as we have imported it from *tensorflow.keras.layers* is a type of layer
    which is densely connected. The densely connected layer means that all nodes of
    previous layers are connected to all nodes of the current layers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们从*tensorflow*导入了两个主要的东西，分别是*Dense*和*Sequential*。Dense是从*tensorflow.keras.layers*导入的，它是一种密集连接的层。密集连接层意味着前一层的所有节点都连接到当前层的所有节点。
- en: '*Sequential *is an API from Keras commonly known as Sequential API that we
    will use to make our neural network.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*Sequential* 是 Keras 提供的一个 API，通常称为 Sequential API，我们将用它来构建我们的神经网络。'
- en: To understand the data better, we can convert it into a data frame. Let’s do
    it.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解数据，我们可以将其转换为数据框。让我们来做吧。
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/1a17ff1a41c152e622471e6fd6c98472.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a17ff1a41c152e622471e6fd6c98472.png)'
- en: '*X.head()*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*X.head()*'
- en: Note that here we have set *columns = iris.feature_names* where *feature_names* is
    a key with the name of all 4 features.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里我们设置了*columns = iris.feature_names*，其中*feature_names*是包含所有4个特征名称的键。
- en: Similarly for targets,
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 同样对于目标，
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/0eac9b8469dbf8748e065646effff790.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0eac9b8469dbf8748e065646effff790.png)'
- en: '*y.head()*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*y.head()*'
- en: To explore number of classes in our target set, we can use
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要探索目标集中的类别数量，我们可以使用
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/0560867fbbaed129cfdede35d6c8aa1d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0560867fbbaed129cfdede35d6c8aa1d.png)'
- en: Here we can see that we have 3 classes, each with labels 0,1, and 2\. To see
    the label name, we can use
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到有3个类别，每个类别的标签是0、1和2。要查看标签名称，我们可以使用
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/b91e865e6854978c5a5257f86f22cdc8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b91e865e6854978c5a5257f86f22cdc8.png)'
- en: These are the names of the classes which we have to predict.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们需要预测的类别名称。
- en: Data preprocessing for machine learning
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习的数据预处理
- en: Now, the first step for machine learning is data preprocessing. The main steps
    in data preprocessing are
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，机器学习的第一步是数据预处理。数据预处理的主要步骤包括
- en: Filling missing values
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填补缺失值
- en: Splitting of data into training and validation sets
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分割为训练集和验证集
- en: Normalization of data
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Conversion of categorical data into one-hot vector
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将分类数据转换为独热向量
- en: Missing values
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺失值
- en: To check if we have any missing values, we can use *pandas.DataFrame.info()* method
    to check.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查是否有缺失值，我们可以使用*pandas.DataFrame.info()*方法进行检查。
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/fe8d25e4564ba83ca6e87ad6976cc8e8.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe8d25e4564ba83ca6e87ad6976cc8e8.png)'
- en: Here we can see that we have no missing value (luckily) and all our features
    are in *float64*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到没有缺失值（幸运的是），并且我们所有的特征都是*float64*类型。
- en: Splitting into train and test sets
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拆分为训练集和测试集
- en: To split the data into the training and test sets, we can use *train_test_split* from *sklearn.model_selection* previously
    imported.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据拆分为训练集和测试集，我们可以使用先前导入的 *train_test_split* 来实现。
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: where *test_size* is the argument that tells us that we want our test data to
    be 10% of the whole data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *test_size* 是一个参数，告诉我们我们希望测试数据占整个数据的 10%。
- en: Normalization of data
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Typically, we normalize the data when we have a high amount of variance in it.
    To check the variance, we can use *var()* function from *panadas.DataFrame* to
    check var of all columns.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当数据具有较高的方差时，我们会对其进行归一化处理。为了检查方差，我们可以使用 *var()* 函数从 *panadas.DataFrame* 来检查所有列的方差。
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/7fdeaec43949d8c7924abe329fcc3d20.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7fdeaec43949d8c7924abe329fcc3d20.png)'
- en: Here we can see that both *X_train* and *X_test *have very low variance, so
    no need to normalize the data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到，*X_train* 和 *X_test* 的方差都非常低，因此无需对数据进行归一化处理。
- en: Categorical data into one-hot vector
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 类别数据转换为独热编码向量
- en: As we know that our output data is one of 3 classes already checked using *iris.target_names*,
    the good thing is that when we loaded the targets, they were already in 0, 1,
    2 format where 0=1st class, 1=2nd class, and so on.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们知道我们的输出数据已经是通过 *iris.target_names* 检查过的3个类别中的一个，好的地方是，当我们加载目标时，它们已经是 0、1、2
    格式，其中 0=第一个类别，1=第二个类别，以此类推。
- en: The problem with this representation is that our model might give higher numbers
    more priority, which can lead to results that are biased. So to tackle this, we
    are going to use one-hot representation. You can learn more about one-hot vectors [here](https://towardsdatascience.com/tagged/one-hot-encoder).
    We can either use the Keras built-in *to_categorical* or use *OneHotEncoder *from *sklearn*.
    We will use *to_categorical*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示法的问题是我们的模型可能会优先考虑较高的数字，这可能会导致结果偏差。因此，为了应对这一点，我们将使用独热编码表示。你可以在 [这里](https://towardsdatascience.com/tagged/one-hot-encoder)
    了解更多关于独热编码向量的信息。我们可以使用 Keras 内置的 *to_categorical* 或使用 *OneHotEncoder* 从 *sklearn*。我们将使用
    *to_categorical*。
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We will review the first 5 rows only to check if it has converted it correctly
    or not.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将只查看前5行，以检查它是否正确转换。
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/d3ed2e9fbc7510745ddd4041088ff1a3.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3ed2e9fbc7510745ddd4041088ff1a3.png)'
- en: And yes, we have converted it into a one-hot representation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们已经将其转换为独热编码表示。
- en: One last thing
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后一件事
- en: One last thing we can do is to convert our data back to *numpy* arrays so that
    we can use some extra functions that will help us later in our model. To do this
    we can use
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以做的一件事是将数据转换回 *numpy* 数组，以便我们可以使用一些额外的函数，这些函数将帮助我们在模型中。为此我们可以使用
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s see what the result of the 1st training example.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看第一个训练样本的结果。
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/04d96ffa5100df2a7b9e4703fd801307.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04d96ffa5100df2a7b9e4703fd801307.png)'
- en: Here we can see the value of 4 features in the 1st training example, and its
    shape is (4,)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到第一个训练样本的4个特征的值，其形状为 (4,)
- en: Our target labels were already in array format when we used *to_categorical *on
    them.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对目标标签使用 *to_categorical* 时，它们已经是数组格式。
- en: Machine learning model
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习模型
- en: Now finally, we are ready to create our model and train it. We will start from
    a simple model, and then we will go to complex model structures where we will
    cover different tips and techniques in Keras.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于准备好创建我们的模型并进行训练了。我们将从一个简单的模型开始，然后转向复杂的模型结构，在此过程中我们将介绍 Keras 中的不同技巧和技术。
- en: Lets code our basic model
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写基本模型的代码
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, we have to create a Sequential Object. Now, to create a model, all we
    have to do is to add different types of layers as per our choice. We will make
    a 10 Dense layers model so that we can observe over-fitting, and reduce it later
    by different Regularization techniques.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须创建一个顺序对象。现在，要创建一个模型，我们所要做的就是根据我们的选择添加不同类型的层。我们将创建一个包含10个全连接层的模型，以便观察过拟合，并通过不同的正则化技术来减少它。
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice that in our first layer, we have used an extra argument of *input_shape.*
    This argument specifies the dimension of the first layer. We do not care about
    the number of training examples in this case. Instead, we only care about the
    number of features. So we pass in the shape of any training example, in our case,
    it was *(4,)* inside *input_shape*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们的第一层中，我们使用了一个额外的参数 *input_shape*。这个参数指定了第一层的维度。在这种情况下，我们不关心训练样本的数量。我们只关心特征的数量。因此，我们将任何训练样本的形状传递给
    *input_shape*，在我们的例子中，它是 *(4,)*。
- en: Notice that we have used *softmax *the activation function in our output layer
    because it is a multi-class classification problem. If it was a binary classification
    problem, we would have used *sigmoid *the activation function instead.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在输出层使用了*softmax*激活函数，因为这是一个多分类问题。如果是二分类问题，我们会使用*sigmoid*激活函数。
- en: We can pass in any activation function we want such as *sigmoid *or *linear *or *tanh*,
    but it is proved via experiments that *relu *performs best in these kinds of models.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以传入任何我们想要的激活函数，如*sigmoid*、*linear*或*tanh*，但实验表明*relu*在这些模型中表现最佳。
- en: Now when we have defined the shape of our model, the next step is to specify
    it’s *loss*, *optimizer*, and *metrics*. We specify these using *compile *method
    in Keras.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们定义了模型的形状后，下一步是指定它的*损失*、*优化器*和*度量标准*。我们使用 Keras 中的*compile*方法来指定这些。
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here we can use any *optimizer *such as Stochastic Gradient Descent, RMSProp,
    etc., but we will use Adam.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以使用任何*优化器*，如随机梯度下降、RMSProp 等，但我们将使用 Adam。
- en: We are using* categorical_crossentropy* here because we have a multi-class classification
    problem, if we have a binary class classification problem, we would have used *binary_crossentropy* instead.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用*categorical_crossentropy*，因为我们有一个多分类问题，如果我们有一个二分类问题，我们会使用*binary_crossentropy*。
- en: Metrics are important to evaluate one’s model. There are different metrics on
    the basis of which we can evaluate our model. For classification problems, the
    most important metric is accuracy, which tells how accurate our predictions are.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 度量标准对评估模型非常重要。根据不同的度量标准，我们可以评估模型的表现。对于分类问题，最重要的度量标准是准确率，它表示我们的预测有多准确。
- en: The last step in our model is to *fit *it on training data and training labels.
    Let's code it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的最后一步是*fit*它在训练数据和训练标签上。让我们开始编码吧。
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*fit *returns a callback that has all the history of our training, which we
    can use to do different useful tasks such as plotting etc.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*fit*返回一个包含我们训练所有历史记录的回调，我们可以用来执行各种有用的任务，如绘图等。'
- en: History callback has an attribute named as *history *that we can access as *history.histor*y, which
    is a dictionary having all the history of losses and metrics, i.e., in our case,
    it has a history of *loss*, *acc*, *val_loss*, and *val_acc *and we can access
    every single one as *history.history.loss* or *history.history['val_acc']* etc.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: History 回调有一个名为*history*的属性，我们可以通过*history.history*访问，它是一个包含所有损失和度量标准历史的字典，也就是说，在我们的案例中，它包含了*loss*、*acc*、*val_loss*
    和*val_acc*的历史，我们可以像*history.history.loss*或*history.history['val_acc']*这样访问每一个。
- en: We have a specified number of epochs to 800, batch size to 40, and validation
    split to 0.1, meaning that we have now 10% validation data which we will use to
    analyze our training. Using 800 epochs will overfit the data, which means it will
    perform very well on training data, but not on testing data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练周期指定为800，批量大小为40，验证拆分为0.1，这意味着我们现在有10%的验证数据，用于分析我们的训练。使用800个周期会导致数据过拟合，这意味着它在训练数据上表现很好，但在测试数据上表现不好。
- en: While the model is training, we can see our loss and accuracy both on the training
    and validation set.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型训练时，我们可以看到训练集和验证集上的损失和准确率。
- en: '![](../Images/c7de26eaff37ce5a7ae933093179dd0f.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7de26eaff37ce5a7ae933093179dd0f.png)'
- en: Here we can see that our training accuracy is 100% and validation accuracy is
    67% which is pretty good for such a model. Let’s plot it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的训练准确率是100%，验证准确率是67%，这对于这样一个模型来说相当不错。让我们绘制一下。
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/f2b06dab8c76bc54892942f9cef732a1.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2b06dab8c76bc54892942f9cef732a1.png)'
- en: We can clearly see that accuracy for the training set is much higher than the
    accuracy for the validation set.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以清楚地看到训练集的准确率远高于验证集的准确率。
- en: Similarly, we can plot Loss as
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以绘制损失图。
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/c0346f3004ad5b809b658278d9ddc2d6.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0346f3004ad5b809b658278d9ddc2d6.png)'
- en: Here, we can clearly see that our Validation Loss is much higher than our Training
    Loss, which is because we have overfitted the data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以清楚地看到我们的验证损失远高于训练损失，这表明我们对数据进行了过拟合。
- en: To check the model performance, we can use *model.evaluate* to check the performance
    of the model. We need to pass data and labels in evaluate method.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查模型性能，我们可以使用*model.evaluate*来检查模型的性能。我们需要在evaluate方法中传入数据和标签。
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/b9696ef0ade7616e2f860f2e0e08106c.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9696ef0ade7616e2f860f2e0e08106c.png)'
- en: Here, we can see that our model is giving 88% accuracy, which is pretty good
    for an overfitted model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到我们的模型提供了88%的准确率，这对于一个过拟合的模型来说相当不错。
- en: Regularization
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 正则化
- en: Let’s make it better by adding regularization into our model. Regularization
    will reduce overfitting from our model and will improve our model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在模型中添加正则化来改进它。正则化将减少模型的过拟合，并改善我们的模型。
- en: We will add L2 regularization in our model. Learn more about L2 regularization [here](https://towardsdatascience.com/concept-of-regularization-28f593cf9f8c#:~:text=The%20idea%20behind%20L1%20regularization,absolute%20value%20of%20the%20coefficients.).
    To add L2 regularization in our model, we have to specify the layers, in which
    we want to add regularization and give an additional parameter which is *kernel_regularizer*,
    and pass *tf.keras.regularizers.l2()*.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在模型中添加L2正则化。了解更多关于L2正则化的内容，请查看 [这里](https://towardsdatascience.com/concept-of-regularization-28f593cf9f8c#:~:text=The%20idea%20behind%20L1%20regularization,absolute%20value%20of%20the%20coefficients.)。要在模型中添加L2正则化，我们需要指定要添加正则化的层，并提供一个额外的参数，即*kernel_regularizer*，并传递*tf.keras.regularizers.l2()*。
- en: We will also implement some dropout in our model, which will help us reduce
    the overfitting better, and hence a better performing model. To read more about
    the theory and motivation behind dropout, refer to [this](https://medium.com/towards-artificial-intelligence/an-introduction-to-dropout-for-regularizing-deep-neural-networks-4e0826c10395) article.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将在模型中实现一些dropout，这将帮助我们更好地减少过拟合，从而提高模型的表现。要了解有关dropout的理论和动机，请参考 [this](https://medium.com/towards-artificial-intelligence/an-introduction-to-dropout-for-regularizing-deep-neural-networks-4e0826c10395) 文章。
- en: Let’s remake the model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新制作模型。
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If you notice closely, we have all the layers and parameters the same except
    we have added 2 dropout layers and regularization in each dense layer.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，我们所有的层和参数都相同，只是我们添加了2个dropout层和每个全连接层中的正则化。
- en: We will keep all other things (loss, optimizer, epochs, etc.) the same.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将保持其他所有内容（损失、优化器、周期等）不变。
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Let’s now evaluate the model.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们评估模型。
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/896442fe9c63adaa29f8e114f2540f5e.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/896442fe9c63adaa29f8e114f2540f5e.png)'
- en: And guess what? We improved our accuracy from 88% to 94% just by adding regularization
    and dropout. If we add batch normalization to it, it will improve further.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你猜怎么着？我们仅通过添加正则化和dropout，将准确率从88%提高到了94%。如果再加入批量归一化，效果会更好。
- en: Let’s plot it.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制它。
- en: Accuracy
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准确性
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/34d8f3d812ad25df126fa15aa6a85cf8.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34d8f3d812ad25df126fa15aa6a85cf8.png)'
- en: '[PRE25]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/30516b12b65b5845fa8587a5b27685c4.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30516b12b65b5845fa8587a5b27685c4.png)'
- en: Insights
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 见解
- en: Here we can see that we have successfully removed the overfitting from over
    model, and improve our model by almost 6%, which is a good improvement for such
    a small dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们成功地从模型中过滤掉了过拟合，模型提升了近6%，对于如此小的数据集这是一个很好的改进。
- en: '**Related:**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[TensorFlow 2.0 Tutorial: Optimizing Training Time Performance](https://www.kdnuggets.com/2020/03/tensorflow-optimizing-training-time-performance.html)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 2.0教程：优化训练时间性能](https://www.kdnuggets.com/2020/03/tensorflow-optimizing-training-time-performance.html)'
- en: '[TensorFlow 2.0: Dynamic, Readable, and Highly Extended](https://www.kdnuggets.com/2019/08/tensorflow-20.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow 2.0：动态、可读且高度扩展](https://www.kdnuggets.com/2019/08/tensorflow-20.html)'
- en: '[Avoid Overfitting with Regularization](https://www.kdnuggets.com/2018/02/avoid-overfitting-regularization.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过正则化避免过拟合](https://www.kdnuggets.com/2018/02/avoid-overfitting-regularization.html)'
- en: '* * *'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT方面'
- en: '* * *'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应掌握的6个预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标去…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的人工智能失败，分析中](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个可靠的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
