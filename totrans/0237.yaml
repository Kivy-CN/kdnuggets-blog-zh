- en: 'Machine Learning Is Not Like Your Brain Part Two: Perceptrons vs Neurons'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习并不像你的大脑 第二部分：感知机与神经元
- en: 原文：[https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)
- en: While today’s artificial intelligence (AI) is able to do some extraordinary
    things, its functionality has very little to do with the way in which a human
    brain works to achieve the same tasks. AI – and specifically machine learning
    (ML) – works by analyzing massive data sets, looking for patterns and correlations
    without understanding the data it is processing. As a result, an ML system requiring
    thousands of tagged samples is fundamentally different from the mind of a child,
    which can learn from just a few experiences of untagged data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然今天的人工智能（AI）能够完成一些非凡的任务，但其功能与人脑实现相同任务的方式几乎没有关系。AI——特别是机器学习（ML）——通过分析大量数据集，寻找模式和相关性，而不理解其处理的数据。因此，需要数千个标记样本的ML系统与一个可以通过少量未标记数据经验学习的儿童的大脑在本质上是不同的。
- en: For today’s AI to overcome such inherent limitations and evolve into its next
    phase (artificial general intelligence), we should examine the differences between
    the brain, which already implements general intelligence and its artificial counterparts.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使今天的人工智能克服这些固有的限制，并进化到下一阶段（人工通用智能），我们应当检查大脑（已经实现了通用智能）与其人工对应物之间的差异。
- en: With that in mind, this nine-part series examines in progressively greater detail
    the capabilities and limitations of biological neurons and how these relate to
    ML. In Part One, we examined how a neuron’s slowness makes its approach to learning
    through thousands of training samples implausible. In Part Two, we’ll take a look
    at the fundamental algorithm of the perceptron and how it differs from any model
    of a biological neuron which involves spikes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于此，这个九部分系列将逐步深入探讨生物神经元的能力和局限性，以及这些如何与机器学习（ML）相关联。在第一部分，我们探讨了神经元的慢速如何使得通过数千个训练样本的学习方法显得不切实际。在第二部分，我们将审视感知机的基本算法及其与涉及脉冲的生物神经元模型的不同之处。
- en: The perceptron underlying most ML algorithms is fundamentally different from
    any model of a biological neuron. The perceptron has a value calculated as a function
    of the sum of incoming signals via synapses, each of which is the product of the
    synapse weight and the value of the perceptron from which it comes. In contrast,
    the biological neuron accumulates charge over time until a threshold is reached,
    giving it a modicum of memory.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法所依赖的感知机在本质上与任何生物神经元模型都不同。感知机的值是通过突触传递的信号总和的函数计算得出的，每个突触的值是突触权重和感知机值的乘积。相比之下，生物神经元随着时间的推移累积电荷，直到达到一个阈值，这赋予了它一定的记忆。
- en: Similarly, while the perceptron has an analog value, the neuron simply emits
    spikes. The perceptron has no intrinsic memory, while the neuron does. And while
    many say the perceptron’s value is analogous to the spiking rate of the neuron,
    this analogy breaks down because the perceptron ignores the relative spike timing
    or the phase of an incoming signal and considers only the frequency. As a result,
    the biological neuron can respond differently based on the order of spike arrival,
    while the perceptron cannot.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，虽然感知机有一个模拟值，神经元则简单地发出脉冲。感知机没有内在的记忆，而神经元有。而且，虽然许多人认为感知机的值类似于神经元的脉冲频率，但这种类比是有缺陷的，因为感知机忽略了脉冲的相对时序或传入信号的相位，仅考虑频率。因此，生物神经元可以根据脉冲到达的顺序作出不同的反应，而感知机则不能。
- en: To provide an illustration, synapses with positive weights contribute to the
    internal charge of a neuron and stimulate it to fire when the accumulated charge
    exceeds a threshold level (defined as 1), while negatively weighted synapses inhibit
    firing. Consider a neuron stimulated by two inputs weighted .5 and -.5\. If the
    input sequence is .5, -.5, .5, -.5, the neuron will never fire because each positive
    input is followed by a negative input which zeros out the accumulated charge.
    If the inputs fire in the sequence of .5, .5, -.5, -.5, the neuron will fire after
    the second positively-weighted spike.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，具有正权重的突触会对神经元的内部电荷产生贡献，并在累积电荷超过阈值水平（定义为1）时刺激神经元发放脉冲，而负权重的突触则抑制发放。如果一个神经元由两个权重分别为.5和-.5的输入刺激。如果输入序列为.5,
    -.5, .5, -.5，该神经元将永远不会发放脉冲，因为每个正输入后面都有一个负输入，导致累积电荷归零。如果输入按.5, .5, -.5, -.5的顺序发放，神经元将在第二个正权重脉冲之后发放脉冲。
- en: '![Illustrating how a neuron (Out) stimulated with a weight of .25 will accumulate
    charge and fire every 4th input spike of the input neuron (In)](../Images/96855caae85113d6c9ece0f307c799f0.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![展示了一个以.25权重刺激的神经元如何累积电荷，并在每第四个输入脉冲（来自输入神经元In）的脉冲后发放](../Images/96855caae85113d6c9ece0f307c799f0.png)'
- en: Illustrating how a neuron (Out) stimulated with a weight of .25 will accumulate
    charge and fire every 4th input spike of the input neuron (In).![With In1 and
    In2 stimulateing with weights of .5 and -.5 respectively Out will never fire.
    ](../Images/bc42a0211eef87928c13f82171395d9e.png)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 展示了一个以.25权重刺激的神经元如何累积电荷，并在每第四个输入脉冲（来自输入神经元In）的脉冲后发放。![当In1和In2分别以.5和-.5的权重刺激时，Out将永远不会发放脉冲。](../Images/bc42a0211eef87928c13f82171395d9e.png)
- en: With In1 and In2 stimulateing with weights of .5 and -.5 respectively Out will
    never fire.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当In1和In2分别以.5和-.5的权重刺激时，Out将永远不会发放脉冲。
- en: '![But changing the timing of the incoming spikes lets Out fire. The perceptron
    model doesn’t support this function because it ignores the timing/phase of incoming
    signals.](../Images/9ff4ce6830b2cacd3411df2425e8e0b7.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![但改变进入脉冲的时序可以使Out发放。感知器模型不支持这个功能，因为它忽略了进入信号的时序/相位。](../Images/9ff4ce6830b2cacd3411df2425e8e0b7.png)'
- en: But changing the timing of the incoming spikes lets Out fire. The perceptron
    model doesn’t support this function because it ignores the timing/phase of incoming
    signals.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但改变进入脉冲的时序可以使Out发放。感知器模型不支持这个功能，因为它忽略了进入信号的时序/相位。
- en: In both cases, the average input frequency is .5 (half the maximum firing rate).
    The perceptron model will give the same output, 0, in either case, because the
    summation of weighted inputs or .5*.5 + .5*-.5 will always equal 0 regardless
    of the input timing. This means that the perceptron model cannot be reliably implemented
    in biological neurons and vice versa.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，平均输入频率为.5（最大发放率的一半）。感知器模型将给出相同的输出0，因为加权输入的总和或.5*.5 + .5*-.5始终等于0，无论输入的时序如何。这意味着感知器模型无法在生物神经元中可靠实现，反之亦然。
- en: This is such an essential difference between the neural network and the biological
    neuron that I will devote a separate article to exploring it, along with the other
    biological factors which make today’s AI different from the brain’s function at
    a very fundamental level.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是神经网络与生物神经元之间如此根本的区别，我将撰写一篇单独的文章来深入探讨它，以及其他生物因素，使得今天的人工智能在一个非常基础的层面上与大脑的功能有所不同。
- en: The biological neuron models allow for single spikes to have meaning. The overwhelming
    majority of the brain’s neurons spike only rarely, so it is likely that many neurons
    *do* have specific meanings. For example, since you understand what a ball is,
    it is likely that your brain contains a “ball neuron” (or perhaps many) that fires
    if you see a ball or hear the word. In a biological model, that neuron might fire
    only once when a ball is recognized. The perceptron model of firing rates doesn’t
    allow this, however, because the firing rate of a single spike isn’t defined.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 生物神经元模型允许单个脉冲具有意义。大多数大脑神经元很少发放脉冲，因此许多神经元*确实*具有特定的意义。例如，由于你理解什么是球，因此你的大脑中可能包含一个“球神经元”（或多个）当你看到球或听到这个词时会发放脉冲。在生物模型中，这个神经元可能在识别到球时只发放一次脉冲。然而，感知器模型的发放率并不允许这种情况，因为单个脉冲的发放率没有定义。
- en: In the next article, I’ll discuss how the connections in the brain are not organized
    in the orderly layers of ML, and how this requires some modification to the basic
    perceptron algorithm which may prevent backpropagation from working at all.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一篇文章中，我将讨论大脑中的连接是如何不像机器学习中的有序层次那样组织的，以及这如何需要对基本感知机算法进行一些修改，这可能会导致反向传播完全不起作用。
- en: '**Next up**: Fundamental Architecture'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**接下来**：基本架构'
- en: '**[Charles Simon](https://futureai.guru/Founder.aspx)** is a nationally recognized
    entrepreneur and software developer, and the CEO of FutureAI. Simon is the author
    of Will the Computers Revolt?: Preparing for the Future of Artificial Intelligence,
    and the developer of Brain Simulator II, an AGI research software platform. For
    more information, [visit here](https://futureai.guru/Founder.aspx).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**[查尔斯·西蒙](https://futureai.guru/Founder.aspx)** 是一位全国知名的企业家和软件开发者，也是FutureAI的首席执行官。西蒙是《计算机会叛乱吗？：为人工智能的未来做准备》的作者，也是Brain
    Simulator II的开发者，这是一个AGI研究软件平台。欲了解更多信息，[请访问这里](https://futureai.guru/Founder.aspx)。'
- en: More On This Topic
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第一次：神经元很慢,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 5: Biological Neurons…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第五次：生物神经元…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
- en: '[Machine Learning is Not Like Your Brain Part Seven: What Neurons…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第七次：神经元的功能…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 3: Fundamental Architecture](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第三次：基本架构](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 4: The Neuron’s…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第四次：神经元的…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
- en: '[Machine Learning Is Not Like Your Brain Part 6: The Importance of…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习与大脑的不同 第六次：精准突触权重的重要性…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
