- en: 'Boosting Machine Learning Algorithms: An Overview'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升机器学习算法：概述
- en: 原文：[https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)
- en: '![Boosting Machine Learning Algorithms: An Overview](../Images/33700d14b7b9b61945cb7546be324715.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![提升机器学习算法：概述](../Images/33700d14b7b9b61945cb7546be324715.png)'
- en: Combing various machine learning algorithms while solving a problem usually
    results in better results. The individual algorithms are referred to as weak learners.
    Their combination results in a strong learner. A weak learner is a model that
    gives better results than a random prediction in a classification problem or the
    mean in a regression problem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决问题时，结合各种机器学习算法通常会得到更好的结果。这些单独的算法被称为弱学习器。它们的组合形成了一个强学习器。弱学习器是指在分类问题中比随机预测或回归问题中的均值更有效的模型。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The final result from these algorithms is obtained by fitting them on the training
    data and combining their predictions. In classification, the combination is done
    by voting, while in regression, it’s done via averaging.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法的最终结果通过在训练数据上拟合它们并结合它们的预测来获得。在分类中，结合是通过投票完成的，而在回归中则是通过平均来完成的。
- en: The combination of several machine learning algorithms is referred to as **ensemble
    learning**. There are several ensemble learning techniques. In this article, we
    will focus on boosting.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 几个机器学习算法的组合被称为**集成学习**。集成学习有多种技术。在本文中，我们将重点介绍提升。
- en: '*Let’s start learning––pun intended!*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*让我们开始学习——玩笑话！*'
- en: What is Boosting?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是提升？
- en: Boosting is an ensemble learning technique that sequentially fits weaker learners
    to a dataset. Every subsequent weak learner that is fitted aims at reducing the
    errors resulting from the previous one.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提升是一种集成学习技术，它依次将较弱的学习器拟合到数据集中。每个后续的弱学习器都旨在减少前一个学习器产生的错误。
- en: How does boosting work?
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升（Boosting）是如何工作的？
- en: 'Generally, boosting works as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，提升的工作原理如下：
- en: Create the initial weak learner.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建初始的弱学习器。
- en: Use the weak learner to make predictions on the entire dataset.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用弱学习器对整个数据集进行预测。
- en: Compute the prediction errors.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算预测误差。
- en: Incorrect predictions are assigned more weight.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误预测会被赋予更多的权重。
- en: Build another weak learner aimed at fixing the errors of the previous learner.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建另一个弱学习器，旨在修正前一个学习器的错误。
- en: Make predictions on the whole dataset using the new learner.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用新的学习器对整个数据集进行预测。
- en: Repeat this process until the optimal results are obtained.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复这个过程直到获得最佳结果。
- en: The final model is obtained by weighting the mean of all weak learners.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终模型通过加权所有弱学习器的均值来获得。
- en: Boosting Algorithms
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升算法
- en: Let’s look at some algorithms that are based on the boosting framework that
    we have just discussed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一些基于刚才讨论的提升框架的算法。
- en: AdaBoost
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AdaBoost
- en: AdaBoost works by fitting one weak learner after the other. In subsequent fits,
    it gives more weight to incorrect predictions and less weight to correct predictions.
    In this way, the models learn to make predictions for the difficult classes. The
    final predictions are obtained by weighing the majority class or sum. The learning
    rate controls the contribution of each weak learner to the final prediction. 
    AdaBoost can be used for both [classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)
    and [regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor)
    problems.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBoost 通过逐个拟合弱学习器来工作。在随后的拟合中，它对错误预测给予更多权重，对正确预测给予较少权重。通过这种方式，模型学会了对难分类的样本进行预测。最终的预测是通过对多数类进行加权或求和得到的。学习率控制每个弱学习器对最终预测的贡献。AdaBoost
    可以用于 [分类](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)
    和 [回归](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor)
    问题。
- en: Scikit-learn provides an [AdaBoost implementation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)
    that you can start using immediately. By default, the algorithm uses [decision
    trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
    as the base estimator. In this case, a `DecisionTreeClassifier` will be fitted
    on the entire dataset first. In subsequent iterations, the fit will be done with
    incorrectly predicted instances given more weight.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 提供了一个 [AdaBoost 实现](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)，你可以立即开始使用。默认情况下，算法使用
    [决策树](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
    作为基础估计器。在这种情况下，将首先在整个数据集上拟合一个 `DecisionTreeClassifier`。在随后的迭代中，将对错误预测的实例给予更多权重进行拟合。
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To improve the performance of the model, the number of estimators, the parameters
    of the base estimator, and the learning rate should be tuned. For example, you
    can tune the maximum depth of the decision tree classifier.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高模型的性能，应调整估计器的数量、基础估计器的参数以及学习率。例如，可以调整决策树分类器的最大深度。
- en: Once training is complete, the impurity-based feature importances are obtained
    via the `feature_importances_` attribute.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，通过 `feature_importances_` 属性可以获得基于不纯度的特征重要性。
- en: Gradient tree boosting
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度树提升
- en: Gradient tree boosting is an additive ensemble learning approach that uses decision
    trees as weak learners. Additive means that the trees are added one after the
    other. Previous trees remain unchanged. When adding subsequent trees, [gradient
    descent](https://scikit-learn.org/stable/modules/sgd.html) is used to minimize
    the loss.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度树提升是一种加法集成学习方法，它使用决策树作为弱学习器。加法意味着树一个接一个地添加。之前的树保持不变。在添加后续树时，使用 [梯度下降](https://scikit-learn.org/stable/modules/sgd.html)
    来最小化损失。
- en: The quickest way to build a gradient boosting model is to use [Scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 构建梯度提升模型的最快方法是使用 [Scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting)。
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The algorithm can be used for [regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)
    and [classification](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
    problems.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法可以用于 [回归](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)
    和 [分类](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
    问题。
- en: eXtreme Gradient Boosting - XGBoost
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 极端梯度提升 - XGBoost
- en: '[XGBoost](https://xgboost.readthedocs.io/en/latest/) is a popular gradient
    boosting algorithm. It uses weak regression trees as weak learners. The algorithm
    also does cross-validation and computes the feature importance.  Furthermore,
    it accepts sparse input data.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[XGBoost](https://xgboost.readthedocs.io/en/latest/) 是一种流行的梯度提升算法。它使用弱回归树作为弱学习器。该算法还进行交叉验证并计算特征重要性。此外，它接受稀疏输入数据。'
- en: XGBoost offers the [DMatrix](https://xgboost.readthedocs.io/en/latest/search.html?q=DMatrix&check_keywords=yes&area=default)
    data structure that improves its performance and efficiency. XGBoost can be used
    in [R](https://www.r-project.org/), [Java](https://www.java.com/), [C++,](https://www.cplusplus.com/)
    and [Julia](https://julialang.org/).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost提供了[ DMatrix](https://xgboost.readthedocs.io/en/latest/search.html?q=DMatrix&check_keywords=yes&area=default)数据结构，提高了其性能和效率。XGBoost可用于[R](https://www.r-project.org/)、[Java](https://www.java.com/)、[C++](https://www.cplusplus.com/)和[Julia](https://julialang.org/)。
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: XGBoost offers the feature importance via the `plot_importance()` function.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost通过`plot_importance()`函数提供特征重要性。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: LightGBM
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LightGBM
- en: LightGBM is a tree-based gradient boosting algorithm that uses leaf-wise tree
    growth and not depth-wise growth.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM是基于树的梯度提升算法，采用叶子-wise 树生长，而非深度-wise 生长。
- en: '![LightGBM](../Images/d55af5779baecced0915cb366849095d.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![LightGBM](../Images/d55af5779baecced0915cb366849095d.png)'
- en: '[Leaf-wise tree growth. ](https://lightgbm.readthedocs.io/en/latest/Features.html?highlight=dart#leaf-wise-best-first-tree-growth)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[叶子-wise 树生长。](https://lightgbm.readthedocs.io/en/latest/Features.html?highlight=dart#leaf-wise-best-first-tree-growth)'
- en: The algorithm can be used for classification and regression problems. LightGBM
    supports categorical features via the `categorical_feature` argument. One-hot
    encoding is not needed after specifying the categorical columns.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法可用于分类和回归问题。LightGBM通过`categorical_feature`参数支持分类特征。指定分类列后，无需进行独热编码。
- en: The LightGBM algorithm also has the capacity to deal with null values. This
    feature can be disabled by setting `use_missing=false`. It uses NA to represent
    null values. To use zeros set `zero_as_missing=true.`
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM算法也能处理空值。通过设置`use_missing=false`可以禁用此功能。它使用NA表示空值。要使用零值，请设置`zero_as_missing=true`。
- en: The objective parameter is used to dictate the type of problem. For example,
    `binary` for binary classification, `regression` for regression and `multiclass`
    for multiclass problems.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 目标参数用于决定问题的类型。例如，`binary`用于二分类问题，`regression`用于回归问题，`multiclass`用于多分类问题。
- en: When using LightGM, you’ll usually first convert the data into the [LightGBM
    Daset](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Dataset.html?highlight=lgb.Dataset)
    format.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LightGBM时，你通常会先将数据转换为[LightGBM Dataset](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Dataset.html?highlight=lgb.Dataset)格式。
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: LightGBM also allows you to specify the boosting type. Available options include
    random forests and traditional gradient boosting decision trees.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM还允许你指定提升类型。可用选项包括随机森林和传统的梯度提升决策树。
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: CatBoost
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CatBoost
- en: '[CatBoost](https://catboost.ai/) is a depth-wise gradient boosting library
    developed by [Yandex](https://yandex.com/). In CatBoost, a balanced tree is grown
    using oblivious trees. In these types of trees the same feature is used when making
    right and left splits at each level of the tree.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[CatBoost](https://catboost.ai/)是由[ Yandex](https://yandex.com/)开发的深度梯度提升库。在CatBoost中，使用不可知树生长平衡树。在这些类型的树中，进行左右分裂时使用相同的特征。'
- en: '![CatBoost](../Images/beea2b8e36a2d499fa8aa5115efdd9a7.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![CatBoost](../Images/beea2b8e36a2d499fa8aa5115efdd9a7.png)'
- en: '[Using the same feature to make left and right splits. ](https://medium.com/p/38779b0d5d9a)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用相同特征进行左右分裂。](https://medium.com/p/38779b0d5d9a)'
- en: Like LightGBM, CatBoost supports categorical features, training on GPUs, and
    handling of null values. CatBoost can be used for [regression](https://catboost.ai/en/docs/concepts/python-reference_catboostregressor)
    and [classification](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier)
    problems.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 与LightGBM类似，CatBoost支持分类特征、GPU训练和处理空值。CatBoost可用于[回归](https://catboost.ai/en/docs/concepts/python-reference_catboostregressor)和[分类](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier)问题。
- en: Setting `plot=true` while training visualizes the training process.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练时设置`plot=true`可以可视化训练过程。
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Final Thoughts
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: 'In this article we have coved boosting algorithms and how you can apply them
    in machine learning. Specifically, we have talked about:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们涵盖了提升算法以及如何在机器学习中应用它们。具体来说，我们讨论了：
- en: What is boosting?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是提升？
- en: How boosting works.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升是如何工作的。
- en: Different boosting algorithms.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的提升算法。
- en: How different boosting algorithms work.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的提升算法是如何工作的。
- en: Happy boosting!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 祝你提升愉快！
- en: Resources
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: '[Ensemble learning guide ](https://scikit-learn.org/stable/modules/ensemble.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[集成学习指南](https://scikit-learn.org/stable/modules/ensemble.html)'
- en: '[Kaggle ensembling guide](https://web.archive.org/web/20150613065532/https://mlwave.com/kaggle-ensembling-guide/)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle集成指南](https://web.archive.org/web/20150613065532/https://mlwave.com/kaggle-ensembling-guide/)'
- en: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** is experienced
    in data science, machine learning, and deep learning with a keen eye for building
    machine learning communities.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Derrick Mwiti](https://www.linkedin.com/in/mwitiderrick/)** 在数据科学、机器学习和深度学习方面经验丰富，并且对构建机器学习社区有着敏锐的洞察力。'
- en: More On This Topic
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Linear Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[线性机器学习算法：概述](https://www.kdnuggets.com/2022/07/linear-machine-learning-algorithms-overview.html)'
- en: '[Understanding Machine Learning Algorithms: An In-Depth Overview](https://www.kdnuggets.com/understanding-machine-learning-algorithms-an-indepth-overview)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解机器学习算法：深入概述](https://www.kdnuggets.com/understanding-machine-learning-algorithms-an-indepth-overview)'
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[终极指南：掌握季节性并提升业务成果](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[Data Labeling for Machine Learning: Market Overview, Approaches, and Tools](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习数据标注：市场概述、方法和工具](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)'
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习评估指标：理论与概述](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
- en: '[Primary Supervised Learning Algorithms Used in Machine Learning](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中使用的主要监督学习算法](https://www.kdnuggets.com/2022/06/primary-supervised-learning-algorithms-used-machine-learning.html)'
