- en: A Playbook to Scale MLOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/06/playbook-scale-mlops.html](https://www.kdnuggets.com/2023/06/playbook-scale-mlops.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By Mike Caravetta & Brendan Kelly
  prefs: []
  type: TYPE_NORMAL
- en: Scaling MLOps for Your Teams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: MLOps teams are pressured to advance their capabilities to scale AI. In 2022,
    we saw an explosion of buzz around AI and MLOps inside and outside of organizations.
    2023 promises more hype with the success of ChatGPT and the traction of models
    inside enterprises.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps teams look to expand their capabilities while meeting the pressing needs
    of the business. These teams start 2023 with a long list of resolutions and initiatives
    to improve how they [industrialize AI](https://www2.deloitte.com/content/dam/insights/articles/7022_TT-MLOps-industrialized-AI/DI_2021-TT-MLOps-industrialized-AI.pdf).
    How are we going to scale the components of MLOps (deployment, monitoring, and
    governance)? What are the top priorities for our team?
  prefs: []
  type: TYPE_NORMAL
- en: '[AlignAI](http://getalignai.com) teamed up with Ford Motors to write this playbook
    to guide MLOps teams based on what we have seen be successful to scale.'
  prefs: []
  type: TYPE_NORMAL
- en: What Does MLOps Mean?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To start, we need a working definition of MLOps. MLOps is an organization’s
    transition from delivering a few AI models to delivering algorithms reliably at
    scale. This transition requires a repeatable and predictable process. MLOps means
    more AI and the associated return on investment. Teams win at MLOps when they
    focus on orchestrating the process, the team, and the tools.
  prefs: []
  type: TYPE_NORMAL
- en: '**Foundational components of MLOps to scale**'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through each area with examples from Ford Motors and ideas to help
    get you started.
  prefs: []
  type: TYPE_NORMAL
- en: '**Measurement and Impact**: how teams track and measure progress.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment & Infrastructure**: how teams scale model deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring**: maintaining the quality and performance of models in production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance**: creating controls and visibility around models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evangelizing MLOps**: educating the business and other technical teams on
    why and how to utilize MLOps methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![A Playbook to Scale MLOps](../Images/f944bd2e67cfae365720e1ec160f76e4.png)'
  prefs: []
  type: TYPE_IMG
- en: Measurement and Impact
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One day, a business executive walked into Ford’s MLOps command center. We reviewed
    the usage metrics of a model and had a productive conversation about why usage
    had dropped. This visibility of the impact and adoption of models is crucial to
    building trust and reacting to the needs of the business.
  prefs: []
  type: TYPE_NORMAL
- en: A fundamental question for teams leveraging AI and investing in MLOps capabilities
    is how do we know if we are progressing?
  prefs: []
  type: TYPE_NORMAL
- en: The key is to align our team on how we provide value to our customers and business
    stakeholders. Teams focus on quantifying performance in the business impact they
    provide and the operational metrics enabling it. Measuring impact captures the
    picture of how we generate.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Playbook to Scale MLOps](../Images/de2208bcaf22c556ff36d74f8c7665ea.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Ideas to get started:**'
  prefs: []
  type: TYPE_NORMAL
- en: How do you measure the value of models in development or production today? How
    do you track the usage and engagement of your business stakeholders?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the operational or engineering metrics for your models in production
    today? Who owns the improvement of these metrics? How do you give people access
    to see these metrics?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do people know if there is a change in user behavior or solution usage?
    Who responds to these issues?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deployment & Infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first hurdle the team faces in MLOps is deploying models into production.
    As the number of models grows, teams must create a standardized process and shared
    platform to handle the increased volume. Managing 20 models deployed using 20
    different patterns can make things cumbersome. Enterprise teams typically create
    centralized infrastructure resources around X models. Choosing the right architecture
    and infrastructure across models and teams can be an uphill battle. However, once
    it is established, it provides a strong foundation to build the capabilities around
    monitoring and governance.
  prefs: []
  type: TYPE_NORMAL
- en: At Ford, we created a standard deployment function using Kubernetes, Google
    Cloud Platform, and a team to support them.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Lucid Link**](https://lucid.app/lucidchart/0ebe6cd4-cacf-4080-8e6f-1885e510b666/edit?invitationId=inv_67a19c1e-5868-4ad1-b659-cc09e0606270&page=0_0#)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ideas for your team:**'
  prefs: []
  type: TYPE_NORMAL
- en: How will you centralize the deployment of models? Can you create or designate
    a centralized team and resources to manage the deployments?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What deployment patterns (REST, batch, streaming, etc.)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are you going to define and share those with other teams?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the most time-consuming or difficult aspects for your modeling teams
    to overcome to get a model in production? How can the centralized deployment system
    be designed to mitigate these issues?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A unique and challenging aspect of machine learning is the ability of [models
    to drift and change](https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)
    in production. Monitoring is critical in creating trust with stakeholders to use
    the models. [Google’s Rules of Machine Learning](https://developers.google.com/machine-learning/guides/rules-of-ml)
    says to “practice good alerting hygiene, such as making alerts actionable.” This
    requires teams to define the areas to monitor and how to generate these alerts.
    A challenging piece becomes making these alerts actionable. There needs to be
    a process established to investigate and mitigate issues in production.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Playbook to Scale MLOps](../Images/9fa8a44610690a4dc5908fb6d59a3330.png)'
  prefs: []
  type: TYPE_IMG
- en: At Ford, the Model Operations Center is the centralized location with screens
    full of information and data to understand if the models are getting what we expect
    in near real-time.
  prefs: []
  type: TYPE_NORMAL
- en: Here is a simplified example of a dashboard looking for usage or record counts
    dropping below a set threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitoring Metrics**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are monitoring metrics to consider for your models:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency**: Time to return predictions (e.g., batch processing time for 100
    records).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Statistical Performance**: the ability of a model to make correct or close
    predictions given a test data set (e.g., Mean Squared Error, F2, etc.).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Quality**: quantification of the completeness, accuracy, validity, and
    timeliness of the prediction or training data. (e.g., % of prediction records
    missing a feature).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Drift**: changes to the distribution of data over time (e.g., lighting
    changes for a computer vision model).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model Usage:**how often the model predictions are used to solve business
    or user problems (e.g., # of predictions for model deployed as a REST endpoint).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ideas for your team:**'
  prefs: []
  type: TYPE_NORMAL
- en: How should all models be monitored?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What metrics need to be included with each model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is there a standard tool or framework to generate the metrics?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are we going to manage the monitoring alerts and issues?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Innovation inherently creates risk, especially in the enterprise environment.
    Therefore, successfully leading innovation requires designing controls into the
    systems to mitigate risk. Being proactive can save a lot of headaches and time.
    MLOps teams should proactively anticipate and educate stakeholders on the risks
    and how to mitigate them.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a proactive approach to governance helps avoid reacting to the needs
    of the business. Two key pieces of the strategy are controlling access to sensitive
    data and capturing lineage and metadata for visibility and audit.
  prefs: []
  type: TYPE_NORMAL
- en: Governance provides great opportunities for automation as teams scale. Waiting
    for data is a constant momentum killer on data science projects. At Ford, a model
    automatically determines if there is personally identifiable information in a
    data set with 97% accuracy. Machine learning models also help with access requests
    and have reduced the processing time from weeks to minutes in 90% of the cases.
  prefs: []
  type: TYPE_NORMAL
- en: The other piece is tracking meta-data throughout the model’s life cycle. Scaling
    machine learning requires scaling trust in the models themselves. MLOps at scale
    require built-in quality, security, and control to avoid issues and bias in production.
  prefs: []
  type: TYPE_NORMAL
- en: Teams can get caught up in the theory and opinions around governance. The best
    course of action is to start with clear access and controls around user access.
  prefs: []
  type: TYPE_NORMAL
- en: From there, meta-data capture and automation are key. The table below outlines
    the areas to collect meta-data. Wherever possible, leverage pipelines or other
    automation systems to capture this information automatically to avoid manual processing
    and inconsistencies.
  prefs: []
  type: TYPE_NORMAL
- en: '**Meta-data to Collect**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the items to collect for each model:'
  prefs: []
  type: TYPE_NORMAL
- en: Version/ Trained Model Artifact:Unique identifier of the trained model artifact.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training Data- Data used to create the trained model artifact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training Code- Git hash or link to the source code for inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependencies- Libraries used in training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction Code- Git hash or link to the source code for inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historical Predictions- Store inferences for audit purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ideas for your team:**'
  prefs: []
  type: TYPE_NORMAL
- en: What issues have we encountered across projects?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What problems are our business stakeholders experiencing or concerned about?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we manage access requests for data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Who approves them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there automation opportunities?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What vulnerabilities do our model pipelines or deployments create?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What pieces of meta-data do we need to capture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How is it stored and made available?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evangelizing MLOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many technical teams fall into the pitfall of thinking: “if we build it, they
    will come.” There’s more to solving the problem. It also involves sharing and
    advocating for the solution to increase organizational impact. MLOps teams need
    to share the best practices and how to solve the unique problems of your organization’s
    tools, data, models, and stakeholders.'
  prefs: []
  type: TYPE_NORMAL
- en: Anybody in the MLOps team can be an evangelist by partnering with the business
    stakeholders to showcase their success stories. Showcasing examples from your
    organization can illustrate the benefits and opportunities clearly.
  prefs: []
  type: TYPE_NORMAL
- en: People across the organization looking to industrialize AI need education, documentation,
    and other support. Lunch and Learns, onboarding, and mentorship programs are great
    places to start. As your organization scales, more formalized learning and onboarding
    programs with supporting documentation can accelerate your organization’s transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ideas for your team:**'
  prefs: []
  type: TYPE_NORMAL
- en: How can you create a community or recurring learnings and best practices for
    MLOps?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the new roles and capabilities we need to establish and share?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What problems have we solved that can be shared?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are you providing training or documentation to share best practices and
    success stories with other teams?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we create learning programs or checklists for data scientists, data
    engineers, and business stakeholders to learn how to work with AI models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLOps teams and leaders face a mountain of opportunities while balancing the
    pressing needs of industrializing models. Each organization faces different challenges,
    given its data, models, and technologies. If MLOps were easy, we probably would
    not like working on the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**The challenge is always prioritization.**'
  prefs: []
  type: TYPE_NORMAL
- en: We hope this playbook helped generate new ideas and areas for your team to explore.
    The first step is to generate a big list of opportunities for your team in 2023\.
    Then prioritize them ruthlessly based on what will have the largest impact on
    your customers. Teams can also define and measure their maturity progress against
    emerging benchmarks. [This guide from Google](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
    can provide a framework and maturity milestones for your team.
  prefs: []
  type: TYPE_NORMAL
- en: '**Ideas for your team:**'
  prefs: []
  type: TYPE_NORMAL
- en: What are the largest opportunities to advance our maturity or sophistication
    with MLOps?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we capture and track our progress on the projects that advance maturity?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a list of tasks for this guide and your team. Prioritize based on the
    time to implement and the expected benefit. Create a roadmap.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[https://www2.deloitte.com/content/dam/insights/articles/7022_TT-MLOps-industrialized-AI/DI_2021-TT-MLOps-industrialized-AI.pdf](https://www2.deloitte.com/content/dam/insights/articles/7022_TT-MLOps-industrialized-AI/DI_2021-TT-MLOps-industrialized-AI.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://developers.google.com/machine-learning/guides/rules-of-ml](https://developers.google.com/machine-learning/guides/rules-of-ml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Mike Caravetta](https://www.linkedin.com/in/michael-cavaretta-795a965/)**
    has delivered hundreds of millions of dollars in business value using analytics.He
    currently leads the charge to scale MLOps in manufacturing and complexity reduction
    at Ford.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Brendan Kelly](https://www.linkedin.com/in/brendan-kelly-5b79135a/)**, Co-Founder
    of AlignAI, has helped dozens of organizations accelerate MLOps across the banking,
    financial services, manufacturing, and insurance industries.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[The Ultimate AI Strategy Playbook](https://www.kdnuggets.com/the-ultimate-ai-strategy-playbook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Digital Transformation Playbook for Modern Businesses](https://www.kdnuggets.com/digital-transformation-playbook-for-modern-businesses)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Efficiently Scale Data Science Projects with Cloud Computing](https://www.kdnuggets.com/2023/05/efficiently-scale-data-science-projects-cloud-computing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[From Google Colab to a Ploomber Pipeline: ML at Scale with GPUs](https://www.kdnuggets.com/2022/03/google-colab-ploomber-pipeline-ml-scale-gpus.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[With Data Privacy learn to implement technical privacy solutions…](https://www.kdnuggets.com/2022/04/manning-data-privacy-learn-implement-technical-privacy-solutions-tools-scale.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Design Patterns in Machine Learning for MLOps](https://www.kdnuggets.com/2022/02/design-patterns-machine-learning-mlops.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
