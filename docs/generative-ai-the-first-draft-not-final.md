# 生成性 AI：初稿而非最终稿

> 原文：[https://www.kdnuggets.com/generative-ai-the-first-draft-not-final](https://www.kdnuggets.com/generative-ai-the-first-draft-not-final)

**作者：努玛·达哈尼 & 玛吉·恩格勒**

![生成性 AI：初稿而非最终稿](../Images/0e325d6fb9017bf797b00d207f388bdb.png)

可以说，人工智能正处于风口浪尖。自从 OpenAI 的对话代理 ChatGPT 在去年末意外走红以来，科技行业一直在热议 ChatGPT 背后的技术——大型语言模型（LLMs）。除了谷歌、Meta 和微软之外，还有像 Anthropic 和 Cohere 这样资金充裕的初创公司也推出了自己的 LLM 产品。各个行业的公司纷纷争相将 LLM 整合进他们的服务中：仅 OpenAI 就拥有从金融科技公司如 Stripe 提供客户服务聊天机器人，到教育科技公司如 Duolingo 和 Khan Academy 生成教育材料，再到视频游戏公司如 Inworld 利用 LLM 为 NPC（非玩家角色）提供对话的各类客户。凭借这些合作伙伴关系和广泛的采用，据报道 OpenAI 预计年收入将超过十亿美元。很容易被这些模型的活跃性所打动：关于 GPT-4 的技术报告显示，该模型在各种学术和专业基准测试中取得了令人印象深刻的分数，包括律师资格考试；SAT、LSAT 和 GRE；以及涉及艺术史、心理学、统计学、生物学和经济学的 AP 考试。

这些引人注目的结果可能暗示着知识工作者的终结，但 GPT-4 和人类专家之间存在一个关键区别：GPT-4 没有 *理解*。GPT-4 和所有 LLM 生成的回答并不是来源于逻辑推理过程，而是来自统计操作。大型语言模型是通过海量的互联网数据进行训练的。网络爬虫——访问数百万网页并下载其内容的机器人——生成了来自各种网站的文本数据集：社交媒体、维基和论坛、新闻和娱乐网站。这些文本数据集包含数十亿或数万亿个单词，这些单词大多以自然语言的形式排列：单词形成句子，句子形成段落。

为了学习如何生成连贯的文本，这些模型在数百万个文本补全示例数据上进行训练。例如，给定模型的数据集中可能包含像“这是一个黑暗而暴风雨的夜晚”和“西班牙的首都为马德里”这样的句子。模型不断尝试在看到“这是一个黑暗而暴风雨的”或“西班牙的首都为”之后预测下一个词，然后检查是否正确，并在每次错误时更新自己。随着时间的推移，模型在文本补全任务上变得越来越好，以至于在许多上下文中——尤其是那些下一个词几乎总是相同的上下文，如“西班牙的首都为”——模型认为最可能的响应是人类认为的“正确”响应。在那些下一个词可能有几个不同选择的上下文中，如“这是一个黑暗而”，模型将学习选择人类认为至少是合理的选择，也许是“暴风雨的”，但也可能是“阴险的”或“霉味的”。LLM生命周期的这一阶段，模型在大型文本数据集上进行训练，被称为*预训练*。对于某些上下文，仅仅预测下一个词并不一定能产生期望的结果；模型可能无法理解它应该如何响应诸如“写一首关于狗的诗”这样的指令，而不是继续执行指令。为了产生某些行为，如遵循指令，并提高模型完成特定任务的能力，例如编写代码或与人进行轻松对话，LLM随后会在针对这些任务设计的目标数据集上进行训练。

然而，LLM（大规模语言模型）通过预测可能的下一个词来生成文本的任务，导致了一种现象，称为*幻觉*。这是一个被广泛记录的技术陷阱，在这种情况下，LLM在被提示时会自信地编造错误的信息和解释。LLM预测和完成文本的能力基于训练过程中学到的模式，但当面临不确定或多种可能的补全时，LLM选择看起来最可信的选项，即使它与现实无关。

例如，当谷歌推出其聊天机器人Bard时，它在首次公开演示中犯了一个事实错误。Bard [臭名昭著地声明](https://www.theverge.com/2023/2/8/23590864/google-ai-chatbot-bard-mistake-error-exoplanet-demo)詹姆斯·韦布太空望远镜（JWST）“拍摄了第一张来自我们太阳系外的行星的照片。”但实际上，[第一张外行星的图像是在2004年拍摄的](https://exoplanets.nasa.gov/resources/300/2m1207-b-first-image-of-an-exoplanet)，由非常大望远镜（VLT）拍摄，而[JWST直到2021年才发射](https://webb.nasa.gov/content/about/launch.html)。

幻觉并不是大型语言模型（LLMs）唯一的缺陷——在大量互联网数据上训练还直接导致了偏见和版权问题。首先，让我们讨论一下*偏见*，它指的是模型在个人身份属性（如种族、性别、阶级或宗教）方面产生的不同输出。鉴于LLMs从互联网数据中学习特征和模式，它们也不幸地继承了类似于人类的偏见、历史不公和文化关联。虽然人类有偏见，但LLMs*更*糟糕，因为它们往往会放大训练数据中的偏见。对于LLMs来说，男性是成功的医生、工程师和首席执行官，而女性则是支持性、美丽的接待员和护士，LGBTQ人群则不存在。

在不可估量的互联网数据上训练LLMs还引发了版权问题的质疑。*版权*是对创作作品的独占权利，版权持有者是唯一有权在特定时间段内复制、分发、展览或表演该作品的实体。

目前，关于LLMs的主要法律问题不在于其输出的版权性，而在于现有版权的潜在侵犯，尤其是那些贡献了他们创作作品用于训练数据集的艺术家和作家。 [作家协会呼吁](https://actionnetwork.org/petitions/authors-guild-open-letter-to-generative-ai-leaders) OpenAI、谷歌、Meta 和微软等公司，要求他们同意、标注并公平地补偿作家使用版权材料来训练LLMs。一些作家和出版商也已将此事提上日程。

LLM开发者目前正面临来自个人和团体的几起关于版权的诉讼——喜剧演员和演员萨拉·席弗曼 [加入了一组作家和出版商起诉](https://www.bloomberglaw.com/public/desktop/document/SilvermanetalvOPENAIINCetalDocketNo323cv03416NDCalJul072023CourtD?doc_id=X2K29SU053M9IPPTMOJPHDL8KSC) OpenAI 的诉讼，声称他们从未授权将他们的版权书籍用于训练LLMs。

尽管与幻觉、偏见和版权相关的担忧是与LLMs相关的最有文献记录的问题之一，但这绝不是唯一的担忧。举几个例子，LLMs编码了敏感信息，产生了不良或有害的输出，并且可能被对手利用。毫无疑问，LLMs在生成连贯且上下文相关的文本方面表现出色，应该毫无疑问地被用来提高效率等众多任务和场景中的效益。

研究人员也在致力于解决这些问题，但如何最佳控制模型输出仍然是一个未解的研究问题，因此现有的大型语言模型远非万无一失。它们的输出应始终检查准确性、事实性和潜在偏见。如果你获得的输出结果*好得令人难以置信*，那就要提高警惕，仔细审查。验证和修正任何由大型语言模型生成的文本是用户的责任，或者我们喜欢说的，*生成式人工智能：这是你的初稿，而非最终稿*。

[**玛吉·恩格勒**](https://www.linkedin.com/in/maggie-engler-717852132/)是一位工程师和研究员，目前致力于大型语言模型的安全性。她专注于将数据科学和机器学习应用于在线生态系统中的滥用问题，是网络安全以及信任和安全领域的专家。玛吉还是一位热心的教育者和传播者，担任德克萨斯大学奥斯汀分校信息学院的兼职讲师。

**[](https://www.linkedin.com/in/numadhamani/)**[努玛·达马尼](https://www.linkedin.com/in/numadhamani/)****是一位在技术与社会交汇处工作的工程师和研究员。她是自然语言处理领域的专家，具有影响力操作、安全性和隐私方面的专业知识。努玛为财富500强公司、社交媒体平台、初创企业和非营利组织开发了机器学习系统。她曾为公司和组织提供咨询，担任美国国防部研究计划的首席研究员，并为多个国际同行评审期刊做出了贡献。

### 更多相关主题

+   [5个适合数据科学学生的作品集项目](https://www.kdnuggets.com/5-portfolio-projects-for-final-year-data-science-students)

+   [我作为数据科学家的前六个月](https://www.kdnuggets.com/2021/12/first-six-months-data-scientist.html)

+   [如何在没有工作经验的情况下获得第一份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [成为数据驱动企业的好处](https://www.kdnuggets.com/2022/07/benefits-becoming-datafirst-enterprise.html)

+   [我如何获得我的第一份数据科学工作](https://www.kdnuggets.com/2023/02/got-first-job-data-scientist.html)

+   [DeepMind的AlphaTensor首次开源实现](https://www.kdnuggets.com/2023/03/first-open-source-implementation-deepmind-alphatensor.html)
