# 生产机器学习监控：异常、漂移、解释器与统计性能

> 原文：[https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html](https://www.kdnuggets.com/2020/12/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance.html)

[评论](#comments)

**作者 [Alejandro Saucedo](https://www.linkedin.com/in/axsaucedo/)，Seldon 工程总监**

![图](../Images/5adde1d0c003e4c846241add464f5b86.png)

作者图片

> “机器学习模型的生命周期只有在投入生产后才真正开始”

在本文中，我们展示了一个端到端的示例，展示了有关生产中机器学习模型监控的最佳实践、原则、模式和技术。我们将展示如何将标准微服务监控技术适应于部署的机器学习模型，以及包括概念漂移、异常检测和 AI 解释性在内的更高级范式。

我们将从头开始训练一个图像分类机器学习模型，将其作为微服务部署在 Kubernetes 中，并介绍一系列高级监控组件。这些监控组件包括异常检测器、漂移检测器、AI 解释器和指标服务器——我们将涵盖每个组件所使用的底层架构模式，这些模式都是为了规模考虑而开发的，并设计为在数百或数千个异构机器学习模型之间高效工作。

你还可以以视频形式查看这篇博客文章，该视频作为 PyCon Hong Kong 2020 的主题演讲进行呈现——主要的不同之处在于，这次讲座使用了 Iris Sklearn 模型作为 e2e 示例，而不是 CIFAR10 Tensorflow 模型。

### 端到端机器学习监控示例

在本文中，我们展示了一个端到端的实践示例，涵盖了下面各节中概述的每个高级概念。

1.  复杂 ML 系统监控简介

1.  CIFAR10 Tensorflow Renset32 模型训练

1.  模型打包与部署

1.  性能监控

1.  监控事件基础设施

1.  统计监控

1.  异常检测监控

1.  概念漂移监控

1.  解释性监控

在本教程中，我们将使用以下开源框架：

+   [**Tensorflow**](https://github.com/tensorflow/tensorflow) — 广泛使用的机器学习框架。

+   [**Alibi Explain**](https://github.com/SeldonIO/alibi) — 白盒和黑盒机器学习模型解释库。

+   [**Albi Detect**](https://github.com/SeldonIO/alibi-detect) — 用于概念漂移、异常检测和对抗检测的高级机器学习监控算法。

+   [**Seldon Core**](https://github.com/SeldonIO/seldon-core/) — 机器学习模型及其监控组件的部署与编排。

你可以在 [提供的 jupyter notebook](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb) 中找到本文的完整代码，这将允许你运行模型监控生命周期中的所有相关步骤。

让我们开始吧。

### 1\. 复杂机器学习系统的监控介绍

生产机器学习的监控是困难的，并且当模型和高级监控组件的数量增加时，它的复杂性会呈指数级增长。这部分是由于生产机器学习系统与传统的软件微服务系统之间的不同——以下概述了一些这些关键差异。

![图示](../Images/0c0298d101c1be5bc129ca939d2ccf2c.png)

作者提供的图像

+   **专用硬件**——优化的机器学习算法实现通常需要访问 GPU、大量 RAM、专用 TPU/FPGAs 以及其他动态变化的要求。这就需要特定的配置，以确保这些专用硬件可以生成准确的使用指标，更重要的是，这些指标可以与各自的基础算法关联起来。

+   **复杂的依赖图**——工具和基础数据涉及复杂的依赖关系，这些关系可能跨越复杂的图结构。这意味着处理单个数据点可能需要在多个步骤中进行状态度量评估，可能引入额外的领域特定抽象层，这些层可能需要考虑，以便可靠地解释监控状态。

+   **合规要求**——生产系统，尤其是在高度监管的环境中，可能涉及关于审计、数据要求以及在每个执行阶段收集资源和工件的复杂政策。有时，展示和分析的指标必须限制给相关个人，这取决于指定的政策，这些政策在不同用例之间可能具有不同的复杂性。

+   **可重复性**——在这些复杂的技术要求之上，还有一个关于组件可重复性的关键要求，确保运行的组件可以在另一个时间点以相同的结果执行。当涉及到监控时，重要的是系统需要以此为前提构建，以便可以重新运行特定的机器学习执行来再现特定的指标，无论是用于监控还是审计目的。

生产机器学习的结构涉及广泛的复杂性，这些复杂性涵盖了模型生命周期的多个阶段。这包括实验、评分、超参数调优、服务、离线批处理、流处理等。每个阶段可能涉及不同的系统和多种异构工具。这就是为什么关键在于确保我们不仅学习如何引入模型特定的指标进行监控，还要识别可以用来在大规模下有效监控已部署模型的高级架构模式。我们将在以下每个部分中涵盖这些内容。

### 2\. CIFAR10 Tensorflow Renset32模型训练

![Figure](../Images/e0fc7f608ee02bb318b6d800cfffeb2a.png)

图片来自开源的[CIFAR10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)

我们将使用直观的[**CIFAR10数据集**](https://www.cs.toronto.edu/~kriz/cifar.html)。该数据集由可以被分类为10个类别之一的图像组成。模型将以形状为32x32x3的数组作为输入，并以一个包含10个概率的数组作为输出，表示图像属于哪个类别。

我们可以从Tensorflow数据集中加载数据，即：

这10个类别包括：`cifar_classes = [“airplane”, “automobile”, “bird”, “cat”, “deer”, “dog”, “frog”, “horse”, “ship”, “truck”]`。

为了训练和部署我们的机器学习模型，我们将遵循下面图示的传统机器学习工作流程。我们将训练一个模型，然后将其导出和部署。

![Image for post](../Images/dc4efbfe55db9179d41c9b3cd37bb2ba.png)

我们将使用Tensorflow来训练这个模型，利用[**残差网络**](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)，它可以说是最具突破性的架构之一，因为它使得训练多达几百甚至几千层成为可能且表现良好。在这个教程中，我们将使用Resnet32实现，幸运的是，我们可以通过Alibi Detect包提供的工具来使用它。

使用我的GPU，这个模型大约训练了5小时，幸运的是，我们将能够使用一个预训练的模型，这可以通过Alibi Detect的`fetch_tf_model`工具进行检索。

如果你仍然想训练CIFAR10 resnet32 Tensorflow模型，你可以使用Alibi Detect包提供的辅助工具，如下所示，或者直接导入原始网络并自行训练。

我们现在可以在“未见数据”上测试训练好的模型。我们可以使用一个被分类为卡车的CIFAR10数据点来测试它。我们可以通过使用Matplotlib绘制数据点来查看它。

![Image for post](../Images/c13d881447de9a1cb03b023f153b0927.png)

我们现在可以通过模型处理那个数据点，正如你所想的，它应该被预测为“卡车”。

我们可以通过找到概率最高的索引来找到预测的类别，在这种情况下是 `index 9`，其概率高达 99%。从类别名称（例如 `cifar_classes[ np.argmax( X_curr_pred )]`）中可以看到，类别 9 是“卡车”。

### 3. 打包并部署模型

我们将使用 Seldon Core 将模型部署到 Kubernetes，这提供了多种选项将我们的模型转换为完整的微服务，暴露 REST、GRPC 和 Kafka 接口。

我们在 Seldon Core 中部署模型的选项包括 1) [语言包装器](https://docs.seldon.io/projects/seldon-core/en/latest/wrappers/language_wrappers.html) 以部署我们的 Python、Java、R 等代码类，或 2) [预包装模型服务器](https://docs.seldon.io/projects/seldon-core/en/latest/servers/overview.html) 直接部署模型工件。在本教程中，我们将使用 [Tensorflow 预包装模型](https://docs.seldon.io/projects/seldon-core/en/latest/servers/tensorflow.html) 服务器来部署我们之前使用的 Resnet32 模型。

这种方法将使我们能够利用 Kubernetes 的云原生架构，通过水平可扩展的基础设施来支持大规模微服务系统。我们将在本教程中学习和利用机器学习中采用的云原生和微服务模式。

下图总结了可用的选项，用于部署模型工件或代码本身，以及我们能够部署单个模型或构建复杂推理图的能力。

![帖子图片](../Images/a78e2d4a97e0799410efad8c75bdd0b3.png)

> 作为附注，你可以使用类似 [KIND (Kubernetes in Docker)](https://github.com/kubernetes-sigs/kind) 或 [Minikube](https://github.com/kubernetes/minikube) 的开发环境设置 Kubernetes，然后按照 [这个示例的 Notebook](https://github.com/axsaucedo/seldon_experiments/blob/master/monitoring-talk/cifar10_example.ipynb) 或 [Seldon 文档](https://docs.seldon.io/projects/seldon-core/en/latest/workflow/install.html) 中的说明进行操作。你需要确保安装 Seldon 并配置相应的 ingress 提供者，如 Istio 或 Ambassador，以便可以发送 REST 请求。

为了简化教程，我们已经上传了训练好的 Tensorflow Resnet32 模型，可以在这个公共 Google 桶中找到：`gs://seldon-models/tfserving/cifar10/resnet32`。如果你训练了自己的模型，你可以将其上传到你选择的桶中，可以是 Google Bucket、Azure、S3 或本地 Minio。特别是对于 Google，你可以使用 `gsutil` 命令行工具和以下命令来完成上传：

我们可以使用 Seldon 通过自定义资源定义配置文件来部署我们的模型。下面是将模型工件转换为完整微服务的脚本。

我们现在可以看到模型已被部署并正在运行。

```py
$ kubectl get pods | grep cifarcifar10-default-0-resnet32-6dc5f5777-sq765   2/2     Running   0          4m50s
```

现在我们可以通过发送相同的卡车图像来测试我们部署的模型，看看是否仍然有相同的预测结果。

![图示](../Images/c13d881447de9a1cb03b023f153b0927.png)

用`plt.imshow(X_curr[0])`显示的数据点

我们将通过如下所示的REST请求来完成这项工作，然后打印结果。

上述代码的输出是对Seldon Core通过[入口](https://docs.seldon.io/projects/seldon-core/en/latest/ingress/istio.html)提供的URL进行POST请求的JSON响应。我们可以看到预测正确地结果为“卡车”类别。

```py
{'predictions': [[1.26448288e-06, 4.88144e-09, 1.51532642e-09, 8.49054249e-09, 5.51306611e-10, 1.16171261e-09, 5.77286274e-10, 2.88394716e-07, 0.00061489339, 0.999383569]]}

Prediction: truck
```

### 4. 性能监控

我们将讨论的第一个监控支柱是老旧的性能监控，这是你在微服务和基础设施领域中会发现的传统和标准监控功能。当然，在我们的情况下，我们将其应用于已部署的机器学习模型。

机器学习监控的一些高级原则包括：

+   **监控运行中ML服务的性能**

+   **识别潜在的瓶颈或运行时警告**

+   **调试和诊断ML服务的意外性能**

为此，我们将介绍两个在生产系统中常用的核心框架：

+   Elasticsearch用于日志——一个常用的文档键值存储，用于存储来自容器的日志，然后可以通过堆栈跟踪或信息日志进行错误诊断。在机器学习的情况下，我们不仅用它来存储日志，还用它来存储机器学习模型的预处理输入和输出，以便进一步处理。

+   Prometheus用于指标——一个常用的时间序列存储，用于存储实时指标数据，然后可以通过Grafana等工具进行可视化。

Seldon Core为任何已部署的模型提供了开箱即用的Prometheus和Elasticsearch集成。在本教程中，我们将参考Elasticsearch，但为了简化对几个高级监控概念的直观理解，我们将主要使用Prometheus进行指标监控，使用Grafana进行可视化。

在下面的图示中，你可以看到导出的微服务如何使任何容器化模型能够导出指标和日志。指标由Prometheus抓取，日志则通过模型转发到Elasticsearch（这是通过我们在下一部分中介绍的事件基础设施完成的。为了明确起见，值得提到的是，Seldon Core还支持使用Jaeger的Open Tracing指标，这显示了Seldon Core模型图中所有微服务跳跃的延迟）。

![图示](../Images/c143b6a1cd7220fe395eb48ec970de53.png)

作者提供的图片

Seldon Core模型暴露的一些性能监控指标示例，也可以通过进一步的集成添加，包括：

+   **每秒请求数**

+   **每个请求的延迟**

+   **CPU/内存/数据利用率**

+   **自定义应用程序指标**

对于本教程，你可以通过使用 [**Seldon Core Analytics 包**](https://docs.seldon.io/projects/seldon-core/en/latest/examples/metrics.html#Install-Seldon-Analytics) 来设置 Prometheus 和 Grafana，这个包会为实时收集指标并在仪表板上进行可视化设置一切。

我们现在可以可视化已部署模型相对于其特定基础设施的利用率。当使用 Seldon 部署模型时，你将有多个属性需要考虑，以确保模型的最佳处理。这包括为应用程序分配的 CPU、内存和文件系统存储，还包括相对于分配的资源和预期请求的运行进程和线程的相应配置。

![图](../Images/d0cc2829de8a477556017a2a4e626f43.png)

图片由作者提供

同样，我们还能够监控模型本身的使用情况——每个 Seldon 模型都会暴露模型使用指标，如每秒请求数、每个请求的延迟、模型的成功/错误代码等。这些指标很重要，因为它们能够映射到底层机器学习模型的更高级/专业化的概念。大延迟的激增可以根据模型的底层要求进行诊断和解释。同样，模型显示的错误被抽象成简单的 HTTP 错误代码，这使得高级 ML 组件可以标准化成微服务模式，从而便于 DevOps / IT 管理员在大规模环境中进行管理。

![图](../Images/07c8b6943074a75ba76ace141563087f.png)

图片由作者提供

### 5\. 用于监控的事件基础设施

为了能够利用更高级的监控技术，我们将首先简要介绍事件基础设施，这使得 Seldon 可以在异步和可扩展的架构中使用高级 ML 算法进行数据监控。

Seldon Core 利用 [KNative Eventing](https://knative.dev/docs/eventing/) 来使机器学习模型能够将模型的输入和输出转发到更高级的机器学习监控组件，如异常检测器、概念漂移检测器等。

![文章图片](../Images/a57c4af6face082e2133f577a4bef0a1.png)

我们不会详细介绍 KNative 引入的事件基础设施，但如果你感兴趣，Seldon Core 文档中有多个实际示例，涉及它如何利用 KNative 事件基础设施来 [将有效负载转发到进一步的组件](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/log_level.html) ，如 Elasticsearch，以及如何将 Seldon 模型连接到 [处理事件](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html)。

对于本教程，我们需要使我们的模型能够将模型处理的所有负载输入和输出转发到 KNative Eventing 中介，这将使所有其他高级监控组件能够订阅这些事件。

以下代码为部署配置添加了一个“logger”属性，指定了中介的位置。

### 6. 统计监控

性能指标对于微服务的总体监控非常有用，但对于机器学习的专业领域，有许多广泛认可和使用的指标在模型的生命周期中至关重要，超出了训练阶段。更常见的指标包括准确率、精确率、召回率，但也包括像 [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)、[KL 散度](https://en.wikipedia.org/wiki/Relative_entropy) 以及许多其他指标。

本文的核心主题不仅仅是指定这些指标如何计算，因为通过一些 Flask-wrapper 魔法使单个微服务暴露这些指标并不是一项艰巨的任务。关键在于识别可以在数百或数千个模型中引入的可扩展架构模式。这意味着我们需要在将模型映射到其相关基础设施所需的接口和模式上达到一定的标准化水平。

一些围绕更专业化机器学习指标的高层次原则如下：

+   **针对统计 ML 性能的监控**

+   **基准测试多个不同模型或不同版本**

+   **专为数据类型和输入/输出格式设计**

+   **有状态的异步“反馈”提供（例如“注释”或“修正”）**

鉴于这些需求，Seldon Core 引入了一套架构模式，允许我们引入“可扩展度量服务器”的概念。这些度量服务器包含开箱即用的数据处理方式，通过订阅相应的事件主题，最终暴露诸如：

+   **原始指标：真正例、假正例、真负例、假负例**

+   **基本指标：准确率、精确率、召回率、特异性**

+   **专业化指标：KL 散度、RMSE 等**

+   **按类别、特征和其他元数据进行的细分**

![图示](../Images/30cca19ad85dee2babd4ed75c402ce5f.png)

图片由作者提供

从架构角度来看，这可以在上面的图示中更直观地展示。这展示了如何通过模型提交一个数据点，然后由任何相应的度量服务器处理。度量服务器还可以在提供后处理“正确/注释”标签，这些标签可以与 Seldon Core 在每个请求上添加的唯一预测 ID 关联。通过从 Elasticsearch 存储中获取相关数据来计算和暴露专业化指标。

目前，Seldon Core 提供了一组开箱即用的指标服务器：

+   BinaryClassification — 以二分类（例如 0 或 1）的形式处理数据，暴露原始指标以显示基本统计指标（准确性、精确度、召回率和特异性）。

+   MultiClassOneHot — 以独热编码预测的形式处理数据用于分类任务（例如 [0, 0, 1] 或 [0, 0.2, 0.8]），然后暴露原始指标以显示基本统计指标。

+   MultiClassNumeric — 以数值数据点的形式处理数据用于分类任务（例如 1 或 [1]），然后暴露原始指标以显示基本统计指标。

对于这个示例，我们将能够部署一种“MulticlassOneHot”类型的指标服务器 — 你可以在下面总结的代码中看到使用的参数，但你可以在jupyter notebook中找到完整的YAML。

一旦我们部署了我们的指标服务器，我们现在只需通过相同的微服务端点发送请求和反馈给我们的CIFAR10模型。为了简化工作流程，我们不会发送异步反馈（这将与elasticsearch数据进行比较），而是发送“自包含”的反馈请求，这些请求包含推理的“响应”和推理的“真实值”。

以下函数提供了一种方法来发送一堆反馈请求，以达到我们的用例的近似准确率（正确预测与错误预测的比例）。

现在我们可以首先发送反馈以获得 90% 的准确率，然后为了确保我们的图表看起来漂亮，我们可以发送另一批请求，这将导致 40% 的准确率。

这现在基本上使我们能够实时可视化指标服务器计算的指标。

![图](../Images/331608e4580c21ee4dc09de8b432720f.png)

作者提供的图片

从上述仪表板中，我们可以对通过这种架构模式获得的指标类型有一个高层次的直觉。特别是，上述有状态统计指标需要额外的元数据异步提供，尽管这些指标本身可能有非常不同的计算方式，但我们可以看到基础设施和架构要求可以被抽象和标准化，以便以更具可扩展的方式进行处理。

我们将在深入了解更高级的统计监控技术时继续看到这种模式。

### 7\. 异常检测监控

对于更高级的监控技术，我们将利用 Alibi Detect 库，特别是它提供的一些高级异常检测算法。Seldon Core 为我们提供了一种将异常检测器作为架构模式进行部署的方式，同时还为我们提供了一个优化的预打包服务器，用于服务 Alibi Detect 异常检测模型。

异常检测的一些关键原则包括：

+   检测数据实例中的异常

+   当出现异常时进行标记/警报

+   识别可能有助于诊断异常值的元数据

+   启用对已识别的异常值的深入分析

+   启用检测器的连续/自动化再训练

对于异常值检测器来说，尤其重要的是允许将计算与模型分开执行，因为这些计算通常更复杂，可能需要更多专业的组件。已部署的异常值检测器可能会遇到与机器学习模型类似的复杂性，因此覆盖这些高级组件时需要考虑相同的合规性、治理和数据血统概念。

下图展示了模型如何通过事件基础设施转发请求。异常值检测器然后处理数据点以计算它是否是异常值。组件可以异步地将异常值数据存储在相应的请求条目中，或者将指标暴露给Prometheus，这是我们将在本节中可视化的内容。

![图示](../Images/c8cff05e54c48ecdbb2c4093776237fd.png)

图片由作者提供

在这个例子中，我们将使用[Alibi Detect Variational Auto Encoder](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/od_vae_cifar10.html)异常值检测技术。异常值检测器在一批未标记但正常（内点）数据上进行训练。VAE检测器尝试重建接收到的输入，如果输入数据无法很好地重建，则被标记为异常值。

**Alibi Detect** 提供了允许我们从头开始导出异常值检测器的工具。我们可以通过`fetch_detector`函数获取它。

如果你想训练异常值检测器，你可以通过使用`OutlierVAE`类以及相应的编码器和解码器来实现。

为了测试异常值检测器，我们可以拍摄同一张卡车的图片，看看当噪声逐渐添加到图像中时，异常值检测器的表现如何。我们还可以使用Alibi Detect可视化函数`plot_feature_outlier_image`进行绘图。

我们可以创建一组修改过的图像，并使用下面的代码通过异常值检测器进行检测。

我们现在在变量`all_X_mask`中有一组修改过的样本，每个样本都有越来越多的噪声。现在我们可以将这10个样本都通过异常值检测器。

查看结果时，我们可以看到前3个没有被标记为异常值，而其余的被标记为异常值——我们可以通过打印值`print(od_preds[“data”][“is_outlier”])`来查看。这将显示如下数组，其中0表示非异常值，1表示异常值。

```py
array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])
```

我们现在可以可视化异常值实例级别的分数如何与阈值映射，这反映了上面数组中的结果。

![帖子图片](../Images/e223f2ae51a8eef73b4d5f7c5d778253.png)

同样，我们可以更深入地了解离群点检测器评分通道的直观表现，以及重构图像，这些应能清晰地展示其内部运作方式。

![帖子用图像](../Images/2354074d9c4f8cd0c9d6d6b73aa0dc2e.png)

我们将能够将离群点检测器投入生产。我们将利用类似于度量服务器的架构模式，即 Alibi Detect Seldon Core 服务器，它将监听数据的推断输入/输出。每个经过模型的数据点，相应的离群点检测器将能够处理。

首要步骤是确保我们之前训练的离群点检测器已经上传到像 Google bucket 这样的对象存储中。我们已经将其上传到`gs://seldon-models/alibi-detect/od/OutlierVAE/cifar10,`，但如果你愿意，你可以上传并使用自己的模型。

一旦我们部署了离群点检测器，我们将能够发送一系列请求，其中许多会是离群点，而其他则不会。

我们现在可以在仪表板上可视化一些离群点——对于每个数据点，将会有一个新的条目，并包括是否为离群点的标记。

![图像](../Images/22fab564c5d242a7368693f631b1c0d1.png)

作者提供的图像

### 8\. 漂移监控

随着时间的推移，现实生活中的生产环境数据可能会发生变化。尽管这种变化不是剧烈的，但可以通过数据本身分布的漂移，特别是与模型预测输出相关的漂移来识别。

漂移检测的关键原则包括：

+   识别数据分布的漂移，以及模型输入和输出数据之间关系的漂移

+   标记找到的漂移以及识别到漂移的相关数据点

+   允许深入挖掘用于计算漂移的数据

在漂移检测的概念中，与离群点检测用例相比，我们面临着更多的复杂性。主要区别在于需要对每一个漂移预测进行批量输入处理，而不是单个数据点。下面的图示展示了与离群点检测模式相似的工作流程，主要区别在于它保持了一个滚动或滑动的数据窗口，以进行处理。

![图像](../Images/ff4154ac5d02e9d857b37971c4855fb7.png)

作者提供的图像

对于这个例子，我们将再次使用 Alibi Detect 库，它提供了[Kolmogorov-Smirnov 数据漂移检测器在 CIFAR-10 上的应用](https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html)。

对于这种技术，我们将能够使用`KSDrift`类来创建和训练漂移检测器，该类还需要一个使用“未训练的自编码器（UAE）”的预处理步骤。

为了测试异常检测器，我们将生成一组带有损坏数据的检测器。Alibi Detect提供了一套很好的工具，我们可以用来以递增的方式生成图像中的损坏/噪声。在这种情况下，我们将使用以下噪声：`[‘gaussian_noise’, ‘motion_blur’, ‘brightness’, ‘pixelate’]`。这些将通过下面的代码生成。

以下是来自创建的损坏数据集的一个数据点，其中包含不同类型的逐渐增加的损坏图像。

![帖子图片](../Images/c2995ccd6c4acf96339a6c0835fbe4ac.png)

我们现在可以尝试运行几个数据点来计算是否检测到漂移。初始批次将包含来自原始数据集的数据点。

这会输出：`Drift? No!`

同样，我们可以在损坏的数据集上运行它。

我们可以看到它们都按预期标记为漂移：

```py
Corruption type: gaussian_noise
Drift? Yes!

Corruption type: motion_blur
Drift? Yes!

Corruption type: brightness
Drift? Yes!

Corruption type: pixelate
Drift? Yes!
```

### 部署漂移检测器

现在我们可以按照上述提供的架构模式部署我们的漂移检测器。类似于异常检测器，我们首先要确保我们训练的漂移检测器可以上传到对象存储。我们目前将使用我们准备好的Google bucket，位于`gs://seldon-models/alibi-detect/cd/ks/drift`，来进行部署。

这将具有类似的结构，主要的区别是我们还将指定用于Alibi Detect服务器的所需批量大小，以作为运行模型之前的缓冲区。在这种情况下，我们选择批量大小为1000。

现在我们已经部署了我们的异常检测器，首先尝试从正常数据集发送1000个请求。

接下来，我们可以发送损坏的数据，这将导致在发送了10k数据点后检测到漂移。

我们可以在Grafana仪表板中可视化检测到的每一个漂移点。

![图示](../Images/895a3bbbb20901101dfc4bd59edbb935.png)

作者提供的图片

### 9. 可解释性监控

AI 可解释性技术对于理解复杂黑箱机器学习模型的行为至关重要。有广泛的内容探讨了可以在不同背景下使用的不同算法技术。我们当前的重点是提供一个直观的理解和一个实际示例，说明可以让解释器组件大规模部署的架构模式。一些模型可解释性的关键原则包括：

+   **模型行为的人类可解释洞察**

+   **引入特定用例的可解释性能力**

+   **识别关键指标，如信任分数或统计性能阈值**

+   **启用使用更复杂的机器学习技术**

关于可解释性有许多不同的技术，但了解不同类型解释器的高层主题很重要。这些包括：

+   **范围（局部 vs 全局）**

+   **模型类型（黑箱 vs 白箱）**

+   **任务（分类、回归等）**

+   **数据类型（表格、图像、文本等）**

+   **洞察（特征归因、反事实、影响训练实例等）**

对于作为接口的解释器，它们在数据流模式上有相似之处。也就是说，它们中的许多需要与模型处理的数据交互，以及与模型本身交互的能力——对于黑箱技术，这包括输入/输出，而对于白箱技术，这包括模型本身的内部。

![图示](../Images/81d115b32de0b5399e611f38e790c06d.png)

作者提供的图像

从架构角度来看，这主要涉及一个独立的微服务，这个微服务不仅接收推断请求，还能够与相关模型交互，并通过发送相关数据“反向工程”模型。图示如上，但一旦我们深入示例，这将变得更直观。

在示例中，我们将使用 Alibi Explain 框架，并使用[Anchor Explanation](https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_image_imagenet.html)技术。这种本地解释技术告诉我们在特定数据点中具有最高预测能力的特征。

我们可以通过指定数据集的结构和一个允许解释器与模型的预测功能交互的`lambda`，简单地创建我们的 Anchor 解释器。

我们能够识别出模型中用于预测卡车图像的锚点。

![用于帖子图像](../Images/c13d881447de9a1cb03b023f153b0927.png)

我们可以通过显示解释本身的输出锚点来可视化这些锚点。

我们可以看到图像的锚点包括挡风玻璃和卡车的车轮。

![用于帖子图像](../Images/902de571fd0d5b33d84174f68044924c.png)

在这里你可以看到解释器与我们部署的模型交互。部署解释器时，我们将遵循相同的原则，但这次将使用一个调用远程模型微服务的函数，而不是一个在本地运行模型的`lambda`。

我们将遵循类似的方法，只需将上面的图像上传到对象存储桶中。与之前的示例类似，我们提供了一个桶，路径为`gs://seldon-models/tfserving/cifar10/explainer-py36–0.5.2`。现在我们将能够部署一个解释器，该解释器可以作为 Seldon 部署的 CRD 部分进行部署。

我们可以通过`kubectl get pods | grep cifar`检查解释器是否正在运行，这应该会输出两个运行中的 pod：

```py
cifar10-default-0-resnet32-6dc5f5777-sq765   2/2     Running   0          18m
cifar10-default-explainer-56cd6c76cd-mwjcp   1/1     Running   0          5m3s
```

类似于我们如何向模型发送请求，我们也可以向解释器路径发送请求。这是解释器将与模型本身交互并打印反向工程解释的地方。

我们可以看到解释的输出与我们之前看到的相同。

![用于帖子图像](../Images/902de571fd0d5b33d84174f68044924c.png)

最后，我们还可以看到一些来自解释器本身的度量相关组件，这些组件可以通过仪表板进行可视化。

```py
Coverage: 0.2475
Precision: 1.0
```

类似于其他基于微服务的机器学习组件，解释器也可以暴露这些以及其他更专业的性能或高级监控指标。

### 结语

在总结之前，需要指出的是，将这些高级机器学习概念抽象为标准化架构模式的重要性。这样做的主要原因是为了使机器学习系统能够扩展，同时也允许跨堆栈的组件进行高级集成。

上述涵盖的所有高级架构不仅适用于每个高级组件，而且还可以启用我们所称的“集成模式”——即，将高级组件连接到其他高级组件的输出。

![图像](../Images/0ea18befddfeb5c06aa892b9de841118.png)

图片由作者提供

确保有结构化和标准化的架构模式也很重要，以使开发人员能够提供监控组件，这些组件也是高级机器学习模型，必须具备相同级别的治理、合规性和数据血统，以便有效管理风险。

这些模式正通过 Seldon Core 项目不断得到改进和演进，针对异常检测、概念漂移、可解释性等的先进前沿算法也在不断改进——如果你对进一步讨论感兴趣，请随时联系。该教程中的所有示例都是开源的，因此非常欢迎提出建议。

如果你对机器学习模型的可扩展部署策略的更多实际示例感兴趣，可以查看：

+   [使用 Argo 工作流的批处理](https://docs.seldon.io/projects/seldon-core/en/latest/examples/argo_workflows_batch.html)

+   [使用 Knative 的无服务器事件处理](https://docs.seldon.io/projects/seldon-core/en/latest/streaming/knative_eventing.html)

+   [AI 可解释性模式与 Alibi](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/explainers.html)

+   [Seldon 模型容器化笔记本](https://docs.seldon.io/projects/seldon-core/en/latest/examples/sklearn_spacy_text_classifier_example.html)

+   [Kafka Seldon Core 流处理部署笔记本](https://github.com/SeldonIO/seldon-core/blob/master/examples/kafka/sklearn_spacy/README.ipynb)

**个人简介：[Alejandro Saucedo](https://www.linkedin.com/in/axsaucedo/)** 是 Seldon 的工程总监、The Institute for Ethical AI 的首席科学家，以及 ACM 执委会成员。

[原文](https://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158)。经许可转载。

**相关：**

+   [可解释性、解释性和机器学习——数据科学家需要知道什么](/2020/11/interpretability-explainability-machine-learning.html)

+   [使用 TensorFlow Serving 部署训练好的模型到生产环境](/2020/11/serving-tensorflow-models.html)

+   [人工智能不仅仅是模型：实现完整工作流成功的四个步骤](/2020/11/mathworks-ai-four-steps-workflow.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速入门网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的 IT 工作

* * *

### 更多相关话题

+   [使用 Eurybia 检测数据漂移以确保生产机器学习模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)

+   [利用 MLOps 管理生产中的模型漂移](https://www.kdnuggets.com/2023/05/managing-model-drift-production-mlops.html)

+   [用 AI 对抗 AI：深度伪造应用中的欺诈监控](https://www.kdnuggets.com/2023/05/fighting-ai-ai-fraud-monitoring-deepfake-applications.html)

+   [使用 Python 中的标准差去除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)

+   [如何使用 Pandas 处理数据集中的异常值](https://www.kdnuggets.com/how-to-handle-outliers-in-dataset-with-pandas)

+   [将机器学习算法全面部署到实际生产环境中的完整过程](https://www.kdnuggets.com/2021/12/deployment-machine-learning-algorithm-live-production-environment.html)
