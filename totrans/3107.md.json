["```py\nfor j, (train_idx, valid_idx) in enumerate(folds):\n\n                X_train = X[train_idx]\n                Y_train = y[train_idx]\n                X_valid = X[valid_idx]\n                Y_valid = y[valid_idx]\n\n                clf.fit(X_train, Y_train)\n\n                valid_pred = clf.predict(X_valid)\n                recall  = recall_score(Y_valid, valid_pred, average='macro')\n                f1 = f1_score(Y_valid, valid_pred, average='macro')\n\n                recall_scores[i][j] = recall\n                f1_scores[i][j] = f1\n\n                train_pred[valid_idx, i] = valid_pred\n                test_pred[:, test_col] = clf.predict(T)\n                test_col += 1\n\n                ## Probabilities\n                valid_proba = clf.predict_proba(X_valid)\n                train_proba[valid_idx, :] = valid_proba\n                test_proba  += clf.predict_proba(T)\n\n            test_proba /= self.n_splits\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nclass_weight = dict({1:1.9, 2:35, 3:180})\n\nrdf = RandomForestClassifier(bootstrap=True,\n            class_weight=class_weight, \n            criterion='gini',\n            max_depth=8, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=4, min_samples_split=10,\n            min_weight_fraction_leaf=0.0, n_estimators=300,\n            oob_score=False,\n            random_state=random_state,\n            verbose=0, warm_start=False)\n```"]