# 使用R学习广义线性模型（GLM）

> 原文：[https://www.kdnuggets.com/2017/10/learn-generalized-linear-models-glm-r.html](https://www.kdnuggets.com/2017/10/learn-generalized-linear-models-glm-r.html)

**由Chaitanya Sagar，Perceptive Analytics。**

> **编辑注：** 下面讨论的数据文件可以在此处获取：
> 
> +   [**cola.csv**](https://gist.githubusercontent.com/mmmayo13/0112df82bf54961e60edfe6a69bbe22c/raw/2ceaa9131ebb40595a4d76a423ffe5c1c91ca6e3/cola.csv)
> +   
> +   [**penalty.csv**](https://gist.githubusercontent.com/mmmayo13/0e57f0b86ee3e1d58f067ecf36efc9fe/raw/6a433f74c589a68ae436ee9a358e6965dae34a63/penalty.csv)

广义线性模型（GLM）帮助将因变量表示为自变量的线性组合。简单线性回归是GLM的传统形式。当因变量呈正态分布时，简单线性回归效果良好。在实际情况中，因变量通常不满足正态分布的假设。例如，考虑一种情况，其中因变量只能取正值且具有厚尾。因变量是咖啡销售量，自变量是温度。

![R GLM header](../Images/c27e32b99685cf77c1f9961d64d36346.png)

假设我们已经建模了变量之间的线性关系。随着温度每升高1度，预计咖啡销售量减少10个单位。此类模型的问题在于它可能会给出无意义的结果。例如，当温度上升1度时，模型可能会输出负值的咖啡销售量。在这些情况下，GLM显得非常有用。GLM广泛应用于建模自变量具有任意分布（即非正态分布）的情况。GLM的基本直觉是将因变量建模为自变量的线性组合，而不是将因变量的函数建模为因变量的线性组合。用于变换自变量的函数称为链接函数。在上述例子中，咖啡销售量的分布将不是正态分布而是泊松分布，回归前对变量进行对数变换（在这种情况下，对数将是链接函数）将导致一个合理的模型。GLM将任意分布的数据转化为适合的线性模型的能力使其成为一个强大的工具。

在本文中，我们旨在讨论各种广义线性模型（GLM），这些模型在行业中被广泛使用。我们重点关注：a）对数线性回归 b）解释对数变换 c）二项逻辑回归。我们还回顾了相关的分布及适用的连接函数。然而，我们首先简要讨论了GLM的传统形式，即简单线性回归。除了详细解释上述模型外，我们还提供了在R统计软件上实现建模技术的步骤和注释的R脚本。为了在R中进行演示，我们使用了示例数据集。希望你觉得这篇文章有用。

**线性回归**

线性回归是广义线性模型（GLM）中最基本的形式。线性回归建模了因变量与自变量之间的线性关系，且没有任何变换。该模型假设变量服从正态分布。其表示形式为Yi= α+ βXi [Eq. 1]。系数通过普通最小二乘法（OLS）计算。有关线性回归和OLS的详细解释，请参阅我们早期的文章 [https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html](https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html)。该文章提供了线性回归的解释和示例。希望现在你对线性回归的概念已经感到熟悉。

现在，为了展示线性回归的局限性，我们将在R中使用一个不那么完美的案例来实现线性模型。数据包括两个变量——大学校园内的温度和可口可乐销售额。请点击这里下载。让我们可视化数据并拟合一个线性模型，以根据给定的温度预测可乐销售。以下是R代码：

```py
## Prepare scatter plot

#Read data from .csv file
data = read.csv("Cola.csv", header = T)
head(data)

#Scatter Plot
plot(data, main = "Scatter Plot")
```

**图 1 散点图**

![图 1](../Images/6ec534da855e0214a6d21717e6d0b9bd.png)

图 1 可视化了数据，以便更好地理解温度与可口可乐销售之间的关系。我们观察到，销售额随着温度的升高而呈指数增长。

```py
## Add best-fit line to the scatter plot

#Install Package
install.packages("hydroGOF")
library("hydroGOF")

#Fit linear model using OLS
model = lm(Cola ~ Temperature, data)

#Overlay best-fit line on scatter plot
abline(model)

#Calculate RMSE
PredCola = predict(model, data)
RMSE = rmse(PredCola, data$Cola)
```

温度与可乐销售之间的关系在方程[2]中表示。该模型的均方根误差相当高，达到241.49。可以通过将温度代入方程中来获得可乐销售的值。

![Eq](../Images/67b12841cd5b8dbc8164e94de4fd67e2.png) [2]

**图 2 使用简单线性回归给出的最佳拟合线叠加在散点图上**

![图 2](../Images/d3b10cad33ee77171133e808e1aa5267.png)

图 2 显示了根据简单线性回归得到的最佳拟合线。拟合效果较差，导致了荒谬的预测。根据该模型，当温度低于10个单位时，可乐销售将为负值。有两种方法可以处理这种情况。首先，拟合一个非线性模型。其次，转换数据以适配线性模型。在下一节中，我们将讨论第二种方法。

**对数线性回归**

对数线性回归在因变量和自变量呈指数关系时变得非常有用。这意味着 Y 并不会随着 X 的单位变化而线性变化，而是随着 X 的单位变化 Y 会以一个固定的百分比变化。例如，复利情况下到期金额与时间 T 呈指数关系。随着 T 增加一个单位，到期金额会以一定百分比增加，即利率。另一个例子是预期薪资和教育水平。预期薪资与教育水平之间并不呈线性关系，而是随着教育水平的提高而呈指数增长。这类增长模型描绘了多种现实生活中的情况，并可以通过对数线性回归进行建模。除了指数关系外，当因变量遵循以下分布时，也会使用对数变换：a) 对数正态分布 - 对数正态分布是指随机变量的对数遵循正态分布。因此，对对数正态随机变量取对数，使得变量呈正态分布，并适合进行线性回归。b) 泊松分布 - 泊松分布是指由泊松实验产生的随机变量分布。例如，时间段 T 内的成功或失败次数遵循泊松分布。

在本文中，我们重点关注指数关系，其表达式为 *Y=a(b)^X* [方程 2]。在这种情况下，对数变换会使关系变为线性。我们可以将 *log(Y)* 表示为 X 的线性组合。对方程两边取对数，我们得到 log *(Y)=log(a)+log⁡(b)X*。现在我们可以使用普通最小二乘法（OLS）来估计模型。请注意，这个方程与方程 1 非常相似，*log(a)* 和 *log(b)* 分别等同于 *α* 和 *β*。现在我们将探讨对数线性模型的解释。*log(a)* 是常数项，*log(b)* 是 Y 随 X 单位变化而增长的增长率。*log(b)* 的负值表明 Y 会因为 X 的单位增加而以一定百分比减少。接下来，我们将使用可口可乐销售数据在 R 中实现该模型。R 代码如下。

```py
## Fitting Log-linear model

# Transform the dependent variable
data$LCola = log(data$Cola, base = exp(1))

#Scatter Plot
plot(LCola ~ Temperature, data  = data , main = "Scatter Plot")

#Fit the best line in log-linear model
model1 = lm(LCola ~ Temperature, data)
abline(model1)

#Calculate RMSE
PredCola1 = predict(model1, data)
RMSE = rmse(PredCola1, data$LCola)
```

**图 3 对数线性回归给出的最佳拟合线**

![图 3](../Images/904c64eb887ca12a309765d48c122b41.png)

图 3 显示了使用对数线性回归的最佳拟合线。我们可以将其视为一个两步过程，即对数据进行变换（对两边取对数），然后对变换后的数据进行简单线性回归。计算出的模型如下：

![方程 3](../Images/941ecb922ca885c4364c6b798ac5daab.png) [3]

可乐销售量可以通过将温度值代入方程[3]来预测。我们观察到与简单线性回归相比，拟合效果有了很大改善。变换后的模型的RMSE仅为0.24。请注意，日志线性回归也解决了可乐销售量出现荒谬负值的问题。对于任何温度值，我们都不会得到负的可乐销售量。简单的对数变换帮助我们处理了这种荒谬情况。在下一部分，我们将讨论其他在各种情况下非常有用的对数变换。

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力。

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT需求。

* * *

### 更多相关话题

+   [通用和可扩展的最优稀疏决策树(GOSDT)](https://www.kdnuggets.com/2023/02/generalized-scalable-optimal-sparse-decision-treesgosdt.html)

+   [使用线性回归模型的三大理由而不是…](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [机器学习中学习线性代数的三大免费资源](https://www.kdnuggets.com/2022/03/top-3-free-resources-learn-linear-algebra-machine-learning.html)

+   [了解大语言模型](https://www.kdnuggets.com/2023/03/learn-large-language-models.html)

+   [比较线性回归与逻辑回归](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)

+   [线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)
