- en: Scaling Data Management Through Apache Gobblin
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Apache Gobblin扩展数据管理
- en: 原文：[https://www.kdnuggets.com/2023/01/scaling-data-management-apache-gobblin.html](https://www.kdnuggets.com/2023/01/scaling-data-management-apache-gobblin.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/01/scaling-data-management-apache-gobblin.html](https://www.kdnuggets.com/2023/01/scaling-data-management-apache-gobblin.html)
- en: Challenges of Big Data Management
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据管理的挑战
- en: '* * *'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的IT组织'
- en: '* * *'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In the modern world, most businesses rely on the power of big data and analytics
    to fuel their growth, strategic investments, and customer engagement. Big data
    is the underlying constant in the targeted advertisement, personalized marketing,
    product recommendations, insights generation, price optimizations, sentiment analysis,
    predictive analytics, and much more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代世界，大多数企业依赖大数据和分析的力量来推动其增长、战略投资和客户参与。大数据是目标广告、个性化营销、产品推荐、洞察生成、价格优化、情感分析、预测分析等的基础。
- en: 'Data is often collected from multiple sources, transformed, stored, and processed
    on data lakes on-prem or on-cloud. While the initial ingest of data is relatively
    trivial and can be achieved through custom scripts developed in-house or traditional
    ETL (Extract Transform Load) tools, the problem quickly becomes prohibitively
    complex and expensive to solve as the companies have to:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常从多个来源收集，经过转换、存储，并在本地或云端的数据湖中处理。虽然数据的初步摄取相对简单，可以通过内部开发的自定义脚本或传统的ETL（提取、转换、加载）工具实现，但问题很快会变得复杂且昂贵，公司必须：
- en: Manage full data lifecycle - for housekeeping and compliance purposes
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理整个数据生命周期 - 以满足清理和合规要求
- en: Optimize storage - to reduce associated costs
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化存储 - 以减少相关成本
- en: Simplify Architecture - through the reuse of computing infrastructure
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 简化架构 - 通过重用计算基础设施
- en: Incrementally process data - through powerful state management
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增量处理数据 - 通过强大的状态管理
- en: Apply the same policies on batch and stream data - without duplication of effort
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在批量和流数据上应用相同的政策 - 避免重复劳动
- en: Migrate between On-prem and Cloud - with the least effort
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地和云端之间迁移 - 以最小的努力
- en: It is where [Apache Gobblin](https://gobblin.apache.org/), an open-source data
    management, and integration system comes in. Apache Gobblin provides unparalleled
    capabilities which can be used in whole or parts depending on the needs of the
    business.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是[Apache Gobblin](https://gobblin.apache.org/)，一个开源的数据管理和集成系统的用武之地。Apache
    Gobblin 提供了无与伦比的功能，可以根据业务需求选择整体或部分使用。
- en: Streamlining Big Data Management with Gobblin
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Gobblin简化大数据管理
- en: In this section, we will delve into the various capabilities of Apache Gobblin
    that aid in addressing the challenges outlined previously.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨Apache Gobblin的各种功能，帮助解决之前概述的挑战。
- en: Managing full data lifecycle
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理整个数据生命周期
- en: Apache Gobblin provides a gamut of capabilities to construct data pipelines
    that support the full suite of data lifecycle operations on datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Gobblin 提供了一系列功能来构建数据管道，支持对数据集的所有生命周期操作。
- en: Ingest data - from multiple sources to sinks ranging from Databases, Rest APIs,
    FTP/SFTP servers, Filers, CRMs like Salesforce and Dynamics, and more.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据摄取 - 从多个来源到各种目的地，包括数据库、Rest API、FTP/SFTP 服务器、文件存储、如Salesforce和Dynamics等CRM系统，等等。
- en: Replicate data - between multiple data lakes with specialized capabilities for
    Hadoop Distributed File System via Distcp-NG.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制数据 - 在多个数据湖之间，通过Distcp-NG为Hadoop分布式文件系统提供专门的功能。
- en: Purge Data - using retention policies like Time-based, Newest K, Versioned,
    or a combination of policies.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理数据 - 使用基于时间的、新近K、版本化或组合政策等保留政策。
- en: Gobblin's logical pipeline consists of a 'Source' that determines the distribution
    of work and creates 'Workunits.' These 'Workunits' are then picked up for execution
    as 'Tasks,' which include extraction, conversion, quality checking, and writing
    of data to the destination. The final step, 'Data Publish,' validates the successful
    execution of the pipeline and atomically commits the output data, if the destination
    supports it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Gobblin 的逻辑管道包括一个确定工作分配并创建“工作单元”（'Workunits'）的“源”（'Source'）。这些“工作单元”随后被提取执行为“任务”（'Tasks'），任务包括数据提取、转换、质量检查和写入目标。最后一步，“数据发布”（'Data
    Publish'），验证管道的成功执行，并在目标支持的情况下原子性地提交输出数据。
- en: '![Scaling Data Management through Apache Gobblin](../Images/fdd99756c9ff07b7c680eeb056407d6e.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![通过 Apache Gobblin 扩展数据管理](../Images/fdd99756c9ff07b7c680eeb056407d6e.png)'
- en: Image by Author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Optimize Storage
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化存储
- en: Apache Gobblin can help reduce the amount of storage needed for data through
    post-processing data after ingestion or replication through compaction or format
    conversion.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Gobblin 可以通过在数据摄取或复制后进行后处理（例如压缩或格式转换），帮助减少所需的存储量。
- en: Compaction - post-processing data to deduplicate based on all the fields or
    key fields of the records, trimming the data to keep only one record with the
    latest timestamp with the same key.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 压缩 - 对数据进行后处理，以基于所有字段或关键字段去重，修剪数据以保留具有最新时间戳的唯一记录。
- en: Avro to ORC - as a specialized format conversion mechanism to convert the popular
    row-based Avro format to a hyper-optimized column-based ORC format.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Avro 到 ORC - 作为一种专用格式转换机制，将流行的行基 Avro 格式转换为超优化的列基 ORC 格式。
- en: '![Scaling Data Management through Apache Gobblin](../Images/67b3172daa08d833c985c8c523075c80.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![通过 Apache Gobblin 扩展数据管理](../Images/67b3172daa08d833c985c8c523075c80.png)'
- en: Image by Author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Simplify Architecture
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简化架构
- en: Depending on the stage of the company (startup to enterprise), scale requirements,
    and their respective architecture, companies prefer to set up or evolve their
    data infrastructure. Apache Gobblin is very flexible and supports multiple execution
    models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 根据公司的阶段（从初创公司到企业）、规模需求及其各自的架构，公司倾向于建立或发展他们的数据基础设施。Apache Gobblin 非常灵活，支持多种执行模型。
- en: Standalone Mode - to run as a standalone process on a bare metal box, i.e.,
    single host for simple use cases and low-demanding situations.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 独立模式 - 作为单独进程在裸金属主机上运行，即单个主机，适用于简单用例和低需求情况。
- en: MapReduce Mode - to run as a MapReduce job on Hadoop infrastructure for big
    data cases to handle datasets ranging in Petabytes scale.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MapReduce 模式 - 作为一个 MapReduce 作业在 Hadoop 基础设施上运行，用于处理范围为 PB 规模的大数据集。
- en: 'Cluster Mode: Standalone - to run as a cluster backed by Apache Helix and Apache
    Zookeeper on a set of bare metal machines or hosts to handle large scale independent
    of the Hadoop MR framework.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式：独立 - 作为一个集群运行，由 Apache Helix 和 Apache Zookeeper 支持，部署在一组裸金属机器或主机上，以处理大规模独立于
    Hadoop MR 框架的工作负载。
- en: 'Cluster Mode: Yarn - to run as a cluster on native Yarn without the Hadoop
    MR framework.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式：Yarn - 作为一个集群在原生 Yarn 上运行，无需 Hadoop MR 框架。
- en: 'Cluster Mode: AWS - to run as a cluster on Amazon’s public cloud offering,
    ie. AWS for infrastructures hosted on AWS.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群模式：AWS - 作为一个集群在亚马逊公共云服务（即 AWS）上运行，用于托管在 AWS 上的基础设施。
- en: '![Scaling Data Management through Apache Gobblin](../Images/8903a92240d375900d52550cf692048e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![通过 Apache Gobblin 扩展数据管理](../Images/8903a92240d375900d52550cf692048e.png)'
- en: Image by Author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Incrementally process data
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增量处理数据
- en: At a significant scale with multiple data pipelines and high volume, data needs
    to be processed in batches and over time. Therefore, it necessitates checkpointing
    so the data pipelines can resume from where they left off last time and continue
    onwards. Apache Gobblin supports low and high watermarks and supports robust state
    management semantics via State Store on HDFS, AWS S3, MySQL and more transparently.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有多个数据管道和高数据量的大规模环境下，数据需要批量处理并随时间处理。因此，需要进行检查点，以便数据管道能够从上次中断的地方恢复并继续进行。Apache
    Gobblin 支持低水位和高水位，并通过 HDFS、AWS S3、MySQL 等提供强大的状态管理语义。
- en: '![Scaling Data Management through Apache Gobblin](../Images/6de2f6a5cd0857955293f0a2c37b4063.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![通过 Apache Gobblin 扩展数据管理](../Images/6de2f6a5cd0857955293f0a2c37b4063.png)'
- en: Image by Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Same policies on batch and stream data
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批处理和流数据的相同策略
- en: Most data pipelines today have to be written twice, once for batch data and
    again for near-line or streaming data. It doubles the effort and introduces inconsistencies
    in policies and algorithms applied to different types of pipelines. Apache Gobblin
    solves this by allowing users to author a pipeline once and run it on both batch
    and stream data if used in Gobblin Cluster mode, Gobblin on AWS mode, or Gobblin
    on Yarn mode.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数数据管道需要编写两次，一次用于批量数据，一次用于近线或流数据。这会加倍工作量，并在应用于不同类型管道的策略和算法中引入不一致。**Apache
    Gobblin** 通过允许用户编写一次管道并在批量和流数据上运行来解决这个问题，如果在 Gobblin 集群模式、AWS 模式或 Yarn 模式中使用 Gobblin。
- en: Migrate between On-prem and Cloud
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在本地和云之间迁移
- en: Due to its versatile modes that can run on-prem on a single box, a cluster of
    nodes, or the cloud - Apache Gobblin can be deployed and used on-prem and on the
    cloud. Therefore, allowing users to write their data pipelines once and migrate
    them along with Gobblin deployments easily between on-prem and cloud, based on
    specific needs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其多功能模式可以在单台机器、节点集群或云上运行，**Apache Gobblin** 可以在本地和云上部署和使用。因此，用户可以根据具体需求，仅需编写一次数据管道，并与
    Gobblin 部署一起轻松迁移本地和云之间。
- en: Due to its highly flexible architecture, powerful features, and the extreme
    scale of data volumes that it can support and process, Apache Gobblin is used
    in the production infrastructure of [major technology companies](https://gobblin.apache.org/powers/)
    and is a must-have for any big data infrastructure deployment today.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其高度灵活的架构、强大的功能以及支持和处理极大数据量的能力，**Apache Gobblin** 被[主要技术公司](https://gobblin.apache.org/powers/)
    用于生产基础设施，并且是今天任何大数据基础设施部署的必备工具。
- en: More details on Apache Gobblin and how to use it can be found at [https://gobblin.apache.org](https://gobblin.apache.org/)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Apache Gobblin 及其使用方式的更多细节可以在 [https://gobblin.apache.org](https://gobblin.apache.org/)
    找到。
- en: '**[Abhishek Tiwari](https://www.linkedin.com/in/findabti/)** is a Senior Manager
    at LinkedIn, leading the company''s Big Data Pipelines organization. He is also
    the Vice President of Apache Gobblin at the Apache Software Foundation and a Fellow
    of the British Computer Society.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abhishek Tiwari](https://www.linkedin.com/in/findabti/)** 是 LinkedIn 的高级经理，负责领导公司的大数据管道组织。他还是
    Apache 软件基金会的 Apache Gobblin 副总裁以及英国计算机学会的会员。'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Data Scaling with Python](https://www.kdnuggets.com/2023/07/data-scaling-python.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 扩展数据规模](https://www.kdnuggets.com/2023/07/data-scaling-python.html)'
- en: '[Things You Should Know When Scaling Your Web Data-Driven Product](https://www.kdnuggets.com/2023/08/things-know-scaling-web-datadriven-product.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[扩展 Web 数据驱动产品时应了解的事项](https://www.kdnuggets.com/2023/08/things-know-scaling-web-datadriven-product.html)'
- en: '[Data storytelling - the art of telling stories through data](https://www.kdnuggets.com/2023/07/manning-data-storytelling-the-art-telling-stories-data.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据讲故事——通过数据讲述故事的艺术](https://www.kdnuggets.com/2023/07/manning-data-storytelling-the-art-telling-stories-data.html)'
- en: '[Exploring Tree of Thought Prompting: How AI Can Learn to Reason…](https://www.kdnuggets.com/2023/07/exploring-tree-of-thought-prompting-ai-learn-reason-through-search.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索思维树提示：AI 如何通过搜索学习推理…](https://www.kdnuggets.com/2023/07/exploring-tree-of-thought-prompting-ai-learn-reason-through-search.html)'
- en: '[Unlocking Reliable Generations through Chain-of-Verification: A…](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过验证链解锁可靠生成：一个…](https://www.kdnuggets.com/unlocking-reliable-generations-through-chain-of-verification)'
- en: '[How to Build a Scalable Data Architecture with Apache Kafka](https://www.kdnuggets.com/2023/04/build-scalable-data-architecture-apache-kafka.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Apache Kafka 构建可扩展的数据架构](https://www.kdnuggets.com/2023/04/build-scalable-data-architecture-apache-kafka.html)'
