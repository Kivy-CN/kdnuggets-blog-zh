["```py\npython -m venv venv\nsource venv/bin/activate\n```", "```py\n# requirements.txt\naccelerate  # For distributed loading\nbitsandbytes\t# For Quantization\ntorch   # Used by HuggingFace\ntransformers\t# To load pipelines and models\nPillow  # Basic Loading and Image Processing\nrequests\t# Downloading image from URL \n```", "```py\npip install -r requirements.txt\n```", "```py\nfrom transformers import BitsAndBytesConfig\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n  \t# Original model support BFloat16\n    bnb_4bit_compute_dtype=torch.bfloat16,\n) \n```", "```py\nfrom transformers import LlavaNextForConditionalGeneration, LlavaNextProcessor\nprocessor = LlavaNextProcessor.from_pretrained(\n\t\"tiiuae/falcon-11B-vlm\",\n\ttokenizer_class='PreTrainedTokenizerFast'\n)\nmodel = LlavaNextForConditionalGeneration.from_pretrained(\n\t\"tiiuae/falcon-11B-vlm\",\n\tquantization_config=quantization_config,\n\tdevice_map=\"auto\"\n) \n```", "```py\nfrom Pillow import Image\nimport requests\n\nurl = \"https://static.theprint.in/wp-content/uploads/2020/07/football.jpg\"\nimg = Image.open(requests.get(url, stream=True).raw)\n```", "```py\ninstruction = \"Write a long paragraph about this picture.\"\nprompt = f\"\"\"User:<image>\\n{instruction} Falcon:\"\"\"\n```", "```py\ninputs = processor(\n\tprompt,\n\timages=img,\n\treturn_tensors=\"pt\",\n\tpadding=True\n).to('cuda:0') \n```", "```py\noutput = model.generate(**inputs, max_new_tokens=256)\ngenerated_captions = processor.decode(output[0], skip_special_tokens=True).strip()\n```"]