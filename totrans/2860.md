# 机器学习三种类型的初学者指南

> 原文：[https://www.kdnuggets.com/2019/11/beginners-guide-three-types-machine-learning.html](https://www.kdnuggets.com/2019/11/beginners-guide-three-types-machine-learning.html)

[评论](#comments)

**作者：[Rebecca Vickery](https://www.linkedin.com/in/rebecca-vickery-20b94133/)，数据科学家**

![Figure](../Images/97361e3877e513bd6978ee0085f57086.png)

使用[Yellowbrick](https://www.scikit-yb.org/en/latest/)可视化KMeans性能

机器学习问题通常可以分为三种类型。分类和回归被称为监督学习，而无监督学习在机器学习应用的背景下通常指的是聚类。

在接下来的文章中，我将简要介绍这三种问题中的每一种，并包含在流行的Python库[scikit-learn](https://scikit-learn.org/stable/index.html)中的演示。

在开始之前，我将简要解释监督学习和无监督学习这两个术语的含义。

**监督学习：** *在监督学习中，你有一组已知的输入（特征）和一组已知的输出（标签）。这些通常被称为X和y。算法的目标是学习将输入映射到输出的映射函数。这样，当给出新的X示例时，机器可以正确预测相应的y标签。*

**无监督学习：** *在无监督学习中，你只有一组输入（X）而没有对应的标签（y）。算法的目标是发现数据中以前未知的模式。这些算法经常用于寻找类似样本X的有意义的聚类，从而在实际中找到数据的内在类别。*

### 分类

在分类中，输出（y）是类别。这些可以是二分类，例如，如果我们在分类垃圾邮件与非垃圾邮件。也可以是多类别，例如分类[花卉](https://archive.ics.uci.edu/ml/datasets/iris)，这被称为多类分类。

让我们通过一个使用scikit-learn的简单分类示例来演示。如果你尚未安装，可以通过pip或conda按照[这里](https://scikit-learn.org/stable/install.html)的说明进行安装。

Scikit-learn有许多可以通过库直接访问的数据集。为了方便起见，本文将使用这些示例数据集。为了说明分类，我将使用酒数据集，这是一个多类分类问题。在数据集中，输入（X）由与每种葡萄酒类型相关的13个特征组成。已知的输出（y）是葡萄酒类型，在数据集中被标记为0、1或2。

本文中所有代码所使用的导入如下所示。

[PRE0]

在下面的代码中，我正在下载数据并将其转换为pandas数据框。

[PRE1]

监督学习问题的下一阶段是将数据拆分为测试集和训练集。训练集可以被算法用来学习输入和输出之间的映射，然后保留的测试集可以用来评估模型学习这种映射的效果。在下面的代码中，我使用了scikit-learn的model_selection函数`train_test_split`来实现这一点。

[PRE2]

在下一步中，我们需要选择最适合学习你选择的数据集中的映射的算法。在scikit-learn中有许多不同的算法可供选择，这些算法使用不同的函数和方法来学习映射，你可以在[这里](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)查看完整列表。

为了确定最佳模型，我正在运行以下代码。我使用一系列算法训练模型，并获取每种算法的F1得分。F1得分是分类器整体准确性的良好指标。我在[这里](https://towardsdatascience.com/understanding-the-confusion-matrix-and-its-business-applications-c4e8aaf37f42)写了详细的描述，介绍了可以用于评估分类器的各种指标。

[PRE3]

![](../Images/b228fa9a0ee7af8de72a061aabe63c88.png)

完美的F1得分是1.0，因此，得分越接近1.0，模型性能越好。上述结果表明，随机森林分类器是此数据集的最佳模型。

### 回归

在回归中，输出（y）是连续值，而不是类别。回归的一个例子是预测商店下个月可能的销售额，或预测你房子的未来价格。

为了进一步说明回归，我将使用一个来自scikit-learn的数据集，称为波士顿住房数据集。该数据集包含13个特征（X），这些特征是房子的各种属性，如房间数量、年龄和犯罪率。输出（y）是房价。

我正在使用下面的代码加载数据，并使用与处理葡萄酒数据集相同的方法将数据拆分为测试集和训练集。

[PRE4]

我们可以使用这个[备忘单](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)来查看scikit-learn中适用于回归问题的可用算法。我们将使用类似于分类问题的代码，循环遍历选择并打印每个算法的分数。

评估回归模型使用了许多不同的指标。这些指标本质上都是误差指标，衡量模型实际值和预测值之间的差异。我使用了均方根误差（RMSE）。对于这个指标，值越接近零，模型性能越好。这个[文章](https://www.dataquest.io/blog/understanding-regression-error-metrics/)对回归问题的误差指标进行了非常好的解释。

[PRE5]

![](../Images/112c20479514357f35a9a727672f387f.png)

RMSE 分数表明线性回归和岭回归算法在这个数据集上表现最佳。

### 无监督学习

有多种不同类型的无监督学习，但为了简便，我将专注于[聚类方法](https://en.wikipedia.org/wiki/Cluster_analysis)。聚类有许多不同的算法，每种算法都使用稍微不同的技术来寻找输入的簇。

可能最广泛使用的方法之一是 Kmeans。这个算法执行一个迭代过程，其中会启动指定数量的随机生成的均值。计算每个数据点到质心的距离度量，[欧几里得](https://en.wikipedia.org/wiki/Euclidean_distance)距离，从而创建相似值的簇。每个簇的质心随后成为新的均值，这个过程会重复直到达到最佳结果。

让我们使用在分类任务中使用的葡萄酒数据集（去掉 y 标签），看看 k-means 算法能从输入中识别出酒的类型的效果如何。

由于我们只使用输入来构建这个模型，我将数据分为测试集和训练集，使用稍微不同的方法。

[PRE6]

由于 Kmeans 依赖于距离度量来确定簇，因此在训练模型之前通常需要进行特征缩放（确保所有特征具有相同的尺度）。在下面的代码中，我使用了 MinMaxScaler 来缩放特征，使所有值都落在 0 和 1 之间。

[PRE7]

使用 K-means 时，你必须指定算法应使用的簇数。因此，首先需要确定最佳的簇数。这是通过迭代多个 k 值并将结果绘制在图表上来实现的。这被称为肘部法，因为它通常会产生一个看起来有点像你肘部曲线的图。yellowbrick [库](https://www.scikit-yb.org/en/latest/quickstart.html)（这是一个很棒的可视化 scikit-learn 模型的库，可以通过 pip 安装）有一个非常好的图。下面的代码生成了这个可视化。

[PRE8]

![](../Images/a4ff56635ba4125cf527a067392ceba7.png)

通常情况下，我们不会知道数据集中有多少个类别来使用聚类技术。然而，在这种情况下，我们知道数据中有三种酒——曲线已经正确选择了三个作为模型中使用的最佳簇数。

下一步是初始化 K-means 算法，并将模型拟合到训练数据上，评估算法对数据的聚类效果。

用于此目的的一种方法被称为 [轮廓系数](https://en.wikipedia.org/wiki/Silhouette_(clustering))。它衡量簇内值的一致性。换句话说，它衡量每个簇内值的相似程度以及簇之间的分离度。轮廓系数针对每个值进行计算，范围从-1到+1。这些值随后被绘制成轮廓图。再次，yellowbrick 提供了一种简单的方法来构建这种图形。下面的代码为酒类数据集创建了这种可视化效果。

[PRE9]

![](../Images/97361e3877e513bd6978ee0085f57086.png)

轮廓图可以按如下方式解读：

+   平均得分（即上图中的红色虚线）越接近 +1，簇内数据点匹配度越好。

+   得分为0的数据点非常接近另一个簇的决策边界（因此分离度低）。

+   负值表示数据点可能被分配到了错误的簇。

+   如果每个簇的宽度不够均匀，则可能使用了不正确的k值。

上面的酒类数据集图表显示，簇0可能没有其他簇一致，因为大多数数据点低于平均分数，并且一些数据点的得分低于0。

轮廓系数在比较不同算法或不同k值时特别有用。

在这篇文章中，我想简要介绍一下三种机器学习的类型。这些过程涉及许多其他步骤，包括特征工程、数据处理和超参数优化，以确定最佳的数据预处理技术和模型。

感谢阅读！

**个人简介：[Rebecca Vickery](https://www.linkedin.com/in/rebecca-vickery-20b94133/)** 通过自学学习数据科学。Holiday Extras 数据科学家。alGo 联合创始人。

[原文](https://towardsdatascience.com/beginners-guide-to-the-three-types-of-machine-learning-3141730ef45d)。已获许可转载。

**相关：**

+   [机器学习分类：基于数据集的图解](/2018/11/machine-learning-classification-dataset-based-pictorial.html)

+   [可解释机器学习的 Python 库](/2019/09/python-libraries-interpretable-machine-learning.html)

+   [数据科学的五个命令行工具](/2019/07/five-command-line-tools-data-science.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你组织的 IT 工作

* * *

### 相关主题

+   [每个数据科学家都应该知道的三大 R 语言库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [Python 基础：语法、数据类型和控制结构](https://www.kdnuggets.com/python-basics-syntax-data-types-and-control-structures)

+   [优化数据存储：探索 SQL 中的数据类型和规范化](https://www.kdnuggets.com/optimizing-data-storage-exploring-data-types-and-normalization-in-sql)

+   [可视化框架的类型](https://www.kdnuggets.com/types-of-visualization-frameworks)

+   [KDnuggets 新闻，12月14日：3 门免费的机器学习课程…](https://www.kdnuggets.com/2022/n48.html)

+   [OpenAI API 初学者指南：易于跟随的入门指南](https://www.kdnuggets.com/openai-api-for-beginners-your-easy-to-follow-starter-guide)
