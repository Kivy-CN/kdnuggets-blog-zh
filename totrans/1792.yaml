- en: 17 More Must-Know Data Science Interview Questions and Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html/2)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Q4\. Why might it be preferable to include fewer predictors over many?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**[Anmol Rajpurohit](https://twitter.com/hey_anmol) answers:**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few reasons why it might be a better idea to have fewer predictor
    variables rather than having many of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '**Redundancy/Irrelevance:**'
  prefs: []
  type: TYPE_NORMAL
- en: If you are dealing with many predictor variables, then the chances are high
    that there are hidden relationships between some of them, leading to redundancy.
    Unless you identify and handle this redundancy (by selecting only the non-redundant
    predictor variables) in the early phase of data analysis, it can be a huge drag
    on your succeeding steps.
  prefs: []
  type: TYPE_NORMAL
- en: It is also likely that not all predictor variables are having a considerable
    impact on the dependent variable(s). You should make sure that the set of predictor
    variables you select to work on does not have any irrelevant ones – even if you
    know that data model will take care of them by giving them lower significance.
  prefs: []
  type: TYPE_NORMAL
- en: '*Note: Redundancy and Irrelevance are two different notions –a relevant feature
    can be redundant due to the presence of other relevant feature(s).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Overfitting**:'
  prefs: []
  type: TYPE_NORMAL
- en: Even when you have a large number of predictor variables with no relationships
    between any of them, it would still be preferred to work with fewer predictors.
    The data models with large number of predictors (also referred to as complex models)
    often suffer from the problem of overfitting, in which case the data model performs
    great on training data, but performs poorly on test data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Productivity**:'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you have a project where there are a large number of predictors and
    all of them are relevant (i.e. have measurable impact on the dependent variable).
    So, you would obviously want to work with all of them in order to have a data
    model with very high success rate. While this approach may sound very enticing,
    practical considerations (such of amount of data available, storage and compute
    resources, time taken for completion, etc.) make it nearly impossible.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, even when you have a large number of relevant predictor variables, it
    is a good idea to work with fewer predictors (shortlisted through feature selection
    or developed through feature extraction). This is essentially similar to the Pareto
    principle, which states that for many events, roughly 80% of the effects come
    from 20% of the causes.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on those 20% most significant predictor variables will be of great
    help in building data models with considerable success rate in a reasonable time,
    without needing non-practical amount of data or other resources.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b30a107ef5009d61aa270f2047eb9950.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Training error & test error vs model complexity (Source: Posted on [Quora](https://www.quora.com/Why-might-it-be-preferable-to-include-fewer-predictors-over-many/answer/Sergül-Aydöre)
    by [Sergul Aydore](https://www.quora.com/profile/Sergül-Aydöre))*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understandability**:'
  prefs: []
  type: TYPE_NORMAL
- en: Models with fewer predictors are way easier to understand and explain. As the
    data science steps will be performed by humans and the results will be presented
    (and hopefully, used) by humans, it is important to consider the comprehensive
    ability of human brain. This is basically a trade-off – you are letting go of
    some potential benefits to your data model’s success rate, while simultaneously
    making your data model easier to understand and optimize.
  prefs: []
  type: TYPE_NORMAL
- en: This factor is particularly important if at the end of your project you need
    to present your results to someone, who is interested in not just high success
    rate, but also in understanding what is happening “under the hood”.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Q5\. What error metric would you use to evaluate how good a binary classifier
    is? What if the classes are imbalanced? What if there are more than 2 groups?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[**Prasad Pore**](/author/prasad-pore) **answers:**'
  prefs: []
  type: TYPE_NORMAL
- en: Binary classification involves classifying the data into two groups, e.g. whether
    or not a customer buys a particular product or not (Yes/No), based on independent
    variables such as gender, age, location etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the target variable is not continuous, binary classification model predicts
    the probability of a target variable to be Yes/No. To evaluate such a model, a
    metric called the confusion matrix is used, also called the classification or
    co-incidence matrix. With the help of a confusion matrix, we can calculate important
    performance measures:'
  prefs: []
  type: TYPE_NORMAL
- en: True Positive Rate (TPR) or Hit Rate or Recall or Sensitivity = TP / (TP + FN)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False Positive Rate(FPR) or False Alarm Rate = 1 - Specificity = 1 - (TN / (TN
    + FP))
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accuracy = (TP + TN) / (TP + TN + FP + FN)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Error Rate = 1 – accuracy or (FP + FN) / (TP + TN + FP + FN)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Precision = TP / (TP + FP)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'F-measure: 2 / ( (1 / Precision) + (1 / Recall) )'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ROC (Receiver Operating Characteristics) = plot of FPR vs TPR
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AUC (Area Under the Curve)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kappa statistics
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can find more details about these measures here: [The Best Metric to Measure
    Accuracy of Classification Models](/2016/12/best-metric-measure-accuracy-classification-models.html).'
  prefs: []
  type: TYPE_NORMAL
- en: All of these measures should be used with domain skills and balanced, as, for
    example, if you only get a higher TPR in predicting patients who don’t have cancer,
    it will not help at all in diagnosing cancer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the same example of cancer diagnosis data, if only 2% or less of the patients
    have cancer, then this would be a case of class imbalance, as the percentage of
    cancer patients is very small compared to rest of the population. There are main
    2 approaches to handle this issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use of a cost function**: In this approach, a cost associated with misclassifying
    data is evaluated with the help of a cost matrix (similar to the confusion matrix,
    but more concerned with False Positives and False Negatives). The main aim is
    to reduce the cost of misclassifying. The cost of a False Negative is always more
    than the cost of a False Positive. e.g. wrongly predicting a cancer patient to
    be cancer-free is more dangerous than wrongly predicting a cancer-free patient
    to have cancer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Total Cost = Cost of FN * Count of FN + Cost of FP * Count of FP
  prefs: []
  type: TYPE_NORMAL
- en: '**Use of different sampling methods**: In this approach, you can use over-sampling,
    under-sampling, or hybrid sampling. In over-sampling, minority class observations
    are replicated to balance the data. Replication of observations leading to overfitting,
    causing good accuracy in training but less accuracy in unseen data. In under-sampling,
    the majority class observations are removed causing loss of information. It is
    helpful in reducing processing time and storage, but only useful if you have a
    large data set.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find more about class imbalance [here](/2016/08/learning-from-imbalanced-classes.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'If there are multiple classes in the target variable, then a confusion matrix
    of dimensions equal to the number of classes is formed, and all performance measures
    can be calculated for each of the classes. This is called a multiclass confusion
    matrix. e.g. there are 3 classes X, Y, Z in the response variable, so recall for
    each class will be calculated as below:'
  prefs: []
  type: TYPE_NORMAL
- en: Recall_X = TP_X/(TP_X+FN_X)
  prefs: []
  type: TYPE_NORMAL
- en: Recall_Y = TP_Y/(TP_Y+FN_Y)
  prefs: []
  type: TYPE_NORMAL
- en: Recall_Z = TP_Z/(TP_Z+FN_Z)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Q6\. What are some ways I can make my model more robust to outliers?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[**Thuy Pham**](/author/thuy-pham) **answers:**'
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to make a model more robust to outliers, from different
    points of view (data preparation or model building). **An outlier** in the question
    and answer is assumed being unwanted, unexpected, or a must-be-wrong value to
    the human’s knowledge so far (e.g. no one is 200 years old) rather than a rare
    event which is possible but rare.
  prefs: []
  type: TYPE_NORMAL
- en: Outliers are usually defined in relation to the distribution. Thus outliers
    could be removed in the pre-processing step (before any learning step), by using
    standard deviations (for normality) or interquartile ranges (for not normal/unknown)
    as threshold levels.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5cb6f2fe1fb2779c49fcc7574c92c98.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Outliers.** [Image source](https://www.neuraldesigner.com/blog/3_methods_to_deal_with_outliers)'
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, **data transformation** (e.g. log transformation) may help if data
    have a noticeable tail. When outliers related to the sensitivity of the collecting
    instrument which may not precisely record small values, **Winsorization** may
    be useful. This type of transformation (named after Charles P. Winsor (1895–1951))
    has the same effect as clipping signals (i.e. replaces extreme data values with
    less extreme values).  Another option to reduce the influence of outliers is using
    **mean absolute difference** rather mean squared error.
  prefs: []
  type: TYPE_NORMAL
- en: For model building, some models are resistant to outliers (e.g. [tree-based
    approaches](https://www.quora.com/Why-are-tree-based-models-robust-to-outliers))
    or non-parametric tests. Similar to the median effect, tree models divide each
    node into two in each split. Thus, at each split, all data points in a bucket
    could be equally treated regardless of extreme values they may have. The study
    [Pham 2016] proposed a detection model that incorporates interquartile information
    of data to predict outliers of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Pham 2016] T. T. Pham, C. Thamrin, P. D. Robinson, and P. H. W. Leong. Respiratory
    artefact removal in forced oscillation measurements: A machine learning approach.
    IEEE Transactions on Biomedical Engineering, 2016.'
  prefs: []
  type: TYPE_NORMAL
- en: '[This Quora answer](https://www.quora.com/What-are-methods-to-make-a-predictive-model-more-robust-to-outliers)
    contains further information.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Here is [part 2](/2017/02/17-data-science-interview-questions-answers-part-2.html)
    and [part 3](/2017/03/17-data-science-interview-questions-answers-part-3.html)
    with more answers.
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Data Analytics Interview Questions & Answers](https://www.kdnuggets.com/2022/09/7-data-analytics-interview-questions-answers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Python Interview Questions & Answers](https://www.kdnuggets.com/2022/09/5-python-interview-questions-answers.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/01/20-questions-detect-fake-data-scientists-chatgpt-1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20 Questions (with Answers) to Detect Fake Data Scientists: ChatGPT…](https://www.kdnuggets.com/2023/02/20-questions-detect-fake-data-scientists-chatgpt-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
