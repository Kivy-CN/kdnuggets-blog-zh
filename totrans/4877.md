# 数据工程初学者指南 – 第二部分

> 原文：[https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2](https://www.kdnuggets.com/2018/03/beginners-guide-data-engineering-part-2.html/2)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/03/beginners-guide-data-engineering-part-2.html?page=2#comments)

### Airflow 管道的结构

![](../Images/b3883f7be24a82be7a7c39fb4e3216e7.png)

现在我们已经了解了事实表、维度表、日期分区的概念以及数据回填的含义，让我们把这些概念具体化，并应用到实际的 Airflow ETL 作业中。

* * *

## 我们的前 3 个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持您组织的 IT

* * *

**定义有向无环图 (DAG)**

正如我们在[之前的文章](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)中提到的，任何 ETL 工作的核心都建立在三个基本组成部分上：**提取**、**转换**和**加载**。尽管概念上听起来很简单，但现实中的 ETL 工作往往很复杂，包含了许多 E、T 和 L 任务的组合。因此，使用图形来可视化复杂的数据流往往很有用。从视觉上看，图中的一个*节点*表示一个任务，而*箭头*表示一个任务对另一个任务的依赖。鉴于数据只需要在给定任务上计算一次，然后计算结果继续传递，因此图是*有向*和*无环*的。这就是为什么 Airflow 作业通常被称为“DAGs”（**有向无环图**）。

![](../Images/9c6359d1c3dedca683467b64d23bcb98.png)

[来源](https://medium.com/airbnb-engineering/https-medium-com-jonathan-parks-scaling-erf-23fd17c91166)：Airbnb 实验报告框架 DAG 的截图

Airflow UI 的一个巧妙设计是它允许任何用户通过[图形视图](https://airflow.apache.org/ui.html#graph-view)来可视化 DAG，使用代码作为配置。数据管道的作者必须定义任务之间依赖关系的结构，以便可视化它们。这些规范通常写在一个称为*DAG 定义文件*的文件中，该文件展示了 Airflow 作业的结构。

**操作符：传感器、操作符和传输**

虽然 DAGs 描述了*如何*运行数据管道，但操作符描述了*在数据管道中做什么*。通常，操作符有三大类：

+   **Sensors: **等待一定时间、外部文件或上游数据源

+   **Operators: **触发特定操作（例如，运行 bash 命令、执行 Python 函数或执行 Hive 查询等）

+   **Transfers: **将数据从一个位置移动到另一个位置

精明的读者可能可以看到这些操作符如何对应到 **E**xtract，

**T**ransform 和 **L**oad 步骤，我们之前讨论过的。

**Sensors** 在一定时间后或当来自上游数据源的数据可用时解除数据流的阻塞。在 Airbnb，由于我们的 ETL 作业大多数涉及 Hive 查询，我们通常使用 `[NamedHivePartitionSensors](https://github.com/apache/incubator-airflow/blob/master/airflow/sensors/named_hive_partition_sensor.py)` 来检查 Hive 表的最新分区是否可用于下游处理。

**Operators** 触发数据转换，这对应于 **T**ransform 步骤。由于 Airflow 是开源的，贡献者可以 [扩展](https://github.com/apache/incubator-airflow/tree/master/airflow/operators) `BaseOperator` 类，以创建自定义操作符。在 Airbnb，我们使用得最频繁的操作符是 `[HiveOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/hive_operator.py#L22)`（用于执行 Hive 查询），但我们也经常使用 `[PythonOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/python_operator.py)`（例如，运行 Python 脚本）和 `[BashOperator](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/bash_operator.py)`（例如，运行 bash 脚本，或甚至是复杂的 Spark 作业）。这里的可能性是无穷的！

最后，我们还具有将数据从一个地方转移到另一个地方的特殊操作符，这通常映射到 ETL 中的 **L**oad 步骤。在 Airbnb，我们经常使用 `[MySqlToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/mysql_to_hive.py)` 或 `[S3ToHiveTransfer](https://github.com/apache/incubator-airflow/blob/master/airflow/operators/s3_to_hive_operator.py)`，但这在很大程度上取决于数据基础设施及数据仓库的位置。

**一个简单的示例**

下面是一个简单的示例，演示了如何定义一个 DAG 定义文件、实例化一个 Airflow DAG，并使用我们上面描述的各种操作符来定义相应的 DAG 结构。

当 DAG 被渲染时，我们可以看到以下图形视图：

![](../Images/8c6afb760a294b42682b86dae4f3237f.png)

玩具示例 DAG 的图形视图

### ETL 最佳实践指南

![](../Images/2027a30a151a5a2c88b0ff1cdd567049.png)

[图片来源](http://www.omen-azen.com/eat-together-1/): 打造你的工艺需要实践，因此遵循最佳实践是明智的

就像任何工艺一样，编写简洁、可读且可扩展的 Airflow 任务需要实践。在我第一次工作时，ETL 对我来说只是需要完成的一系列单调的机械任务。我没有将其视为一种工艺，也不知道最佳实践。在 Airbnb，我学到了很多最佳实践，开始欣赏好的 ETL 及其美丽之处。以下是我列出的一个非详尽的良好 ETL 管道应遵循的原则列表：

+   **分区数据表：**正如我们之前提到的，当处理具有长历史的大型表时，数据分区特别有用。当数据使用日期戳进行分区时，我们可以利用动态分区来并行回填。

+   **增量加载数据：**这一原则使得 ETL 更加模块化和可管理，尤其是在从事实表构建维度表时。在每次运行中，我们只需将新事务附加到前一个日期分区的维度表，而不是扫描整个事实历史。

+   **强制幂等性：**许多数据科学家依赖于时间点快照进行历史分析。这意味着随着时间的推移，基础源表不应可变，否则我们会得到不同的答案。管道应构建为相同的查询在相同的业务逻辑和时间范围内运行时返回相同的结果。这种属性有一个很酷的名字，叫做幂等性。

+   **参数化工作流：**就像模板大大简化了 HTML 页面组织一样，Jinja 也可以与 SQL 配合使用。正如我们之前提到的，Jinja 模板的一个常见用法是将回填逻辑纳入典型的 Hive 查询中。[Stitch Fix](https://www.google.com/search?q=stitchfix+jinja&oq=stitchfix+jinja&aqs=chrome..69i57j69i59.3030j0j1&sourceid=chrome&ie=UTF-8) 有一篇很好的文章总结了他们如何在 ETL 中使用这种技术。

+   **尽早并频繁地添加数据检查：**在处理数据时，将数据写入临时表，检查数据质量，然后再用最终生产表交换临时表是很有用的。在 Airbnb，我们称之为*阶段检查交换*范式。这个 3 步范式中的检查是重要的防御机制——它们可以是简单的检查，比如统计记录总数是否大于 0，或者像异常检测系统那样复杂，检查未见的类别或异常值。

阶段检查交换操作的框架（也称为数据管道的“单元测试”）

+   **构建有用的警报和监控系统：** 由于ETL作业通常需要很长时间才能运行，因此添加警报和监控非常有用，以便我们不必不断关注DAG的进度。不同公司以多种创造性方式监控DAG——在Airbnb，我们定期使用EmailOperators发送作业缺失SLA的警报邮件。其他团队还使用警报来标记实验不平衡。还有一个[有趣的例子](https://www.slideshare.net/cloudera/building-robust-pipelines-with-airflow-wrangle-conference-2017)来自Zymergen，他们通过SlackOperator报告模型性能指标，如R平方。

这些原则中的许多都受到与经验丰富的数据工程师交谈、我自己构建Airflow DAGs的经验以及Gerard Toonstra的[ETL最佳实践与Airflow](https://gtoonstra.github.io/etl-with-airflow/principles.html)的阅读启发。对于好奇的读者，我强烈推荐以下Maxime的讲座：

[来源](https://www.youtube.com/watch?v=dgaoqOZlvEA)：Airflow的原始作者Maxime谈论ETL最佳实践

### 第二部分回顾

在本系列的第二篇文章中，我们详细讨论了星型模式和数据建模。我们了解了事实表和维度表的区别，并观察了使用日期戳作为分区键的优势，尤其是在回填时。此外，我们剖析了Airflow作业的结构，并明确了Airflow中可用的不同操作符。我们还强调了构建ETL的最佳实践，并展示了当Airflow作业与Jinja和SlackOperators结合使用时的灵活性。可能性是无穷的！

在本系列的最后一篇文章中，我将讨论一些高级数据工程模式——具体来说，即如何从构建管道转向构建框架。我将再次使用我们在Airbnb使用的几个示例框架作为动机示例。

如果你觉得这篇文章有用，请访问[**第一部分**](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7)并关注**第三部分**。

*我想感谢*[*Jason Goodman*](https://medium.com/@jasonkgoodman)*和Michael Musson提供的宝贵反馈*

**简历： [Robert Chang](https://www.linkedin.com/in/robert-chang-877b1720/)** 是Airbnb的一名数据科学家，专注于机器学习、机器学习基础设施和主持人增长。在Airbnb之前，他曾在Twitter担任数据科学家，并拥有斯坦福大学的统计学学位和加州大学伯克利分校的运筹学学位。

[原文](https://towardsdatascience.com/a-beginners-guide-to-data-engineering-part-ii-47c4e7cbda71)。经授权转载。

**相关：**

+   [数据工程初学者指南 — 第一部分](/2018/01/beginners-guide-data-engineering-1.html)

+   [新手和初级数据科学家的建议](/2017/11/chang-advice-new-junior-data-scientists.html)

+   [如何构建数据科学管道](/2017/07/build-data-science-pipeline.html)

### 更多相关内容

+   [初学者数据工程指南](https://www.kdnuggets.com/2023/07/beginner-guide-data-engineering.html)

+   [数据科学中异常检测技术的初学者指南](https://www.kdnuggets.com/2023/05/beginner-guide-anomaly-detection-techniques-data-science.html)

+   [数据科学简介：初学者指南](https://www.kdnuggets.com/2023/07/introduction-data-science-beginner-guide.html)

+   [使用 Pyjanitor 的数据清理初学者指南](https://www.kdnuggets.com/beginners-guide-to-data-cleaning-with-pyjanitor)

+   [初学者端到端机器学习指南](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)

+   [必备机器学习算法：初学者指南](https://www.kdnuggets.com/2021/05/essential-machine-learning-algorithms-beginners.html)
