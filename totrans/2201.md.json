["```py\nimport pandas as pd\nimport urllib\n\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/iphere.data\"\ndata = urllib.request.urlopen(url)\ndf = pd.read_csv(data, header=None)\n```", "```py\n# Display the first few rows of the DataFrame\ndf.head()\n```", "```py\n# Get information about the dataset\nprint(df.info())\n```", "```py\n# Get descriptive statistics of the dataset\nprint(df.describe())\n```", "```py\ncolumn_names = [\n\"attribute_1\", \"attribute_2\", \"attribute_3\", \"attribute_4\", \"attribute_5\",\n\"attribute_6\", \"attribute_7\", \"attribute_8\", \"attribute_9\", \"attribute_10\",\n\"attribute_11\", \"attribute_12\", \"attribute_13\", \"attribute_14\", \"attribute_15\",\n\"attribute_16\", \"attribute_17\", \"attribute_18\", \"attribute_19\", \"attribute_20\",\n\"attribute_21\", \"attribute_22\", \"attribute_23\", \"attribute_24\", \"attribute_25\",\n\"attribute_26\", \"attribute_27\", \"attribute_28\", \"attribute_29\", \"attribute_30\",\n\"attribute_31\", \"attribute_32\", \"attribute_33\", \"attribute_34\", \"class_label\"\n]\ndf.columns = column_names\n```", "```py\n# Display the first few rows of the DataFrame\ndf.head()\n```", "```py\n# Convert the class labels from 'g' and 'b' to 1 and 0, respectively\ndf[\"class_label\"] = df[\"class_label\"].replace({'g': 1, 'b': 0})\n```", "```py\nimport matplotlib.pyplot as plt\n\n# Count the number of data points in each class\nclass_counts = df['class_label'].value_counts()\n\n# Create a bar plot to visualize the class distribution\nplt.bar(class_counts.index, class_counts.values)\nplt.xlabel('Class Label')\nplt.ylabel('Count')\nplt.xticks(class_counts.index)\nplt.title('Class Distribution')\nplt.show()\n```", "```py\nX = df.drop('class_label', axis=1)  # Input features\ny = df['class_label']               # Target variable\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Get the indices of the numerical features\nnumerical_feature_indices = list(range(34))  # Assuming the numerical features are in columns 0 to 33\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Normalize the numerical features in the training set\nX_train.iloc[:, numerical_feature_indices] = scaler.fit_transform(X_train.iloc[:, numerical_feature_indices])\n\n# Normalize the numerical features in the test set using the trained scaler from the training set\nX_test.iloc[:, numerical_feature_indices] = scaler.transform(X_test.iloc[:, numerical_feature_indices])\n```", "```py\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(class_weight='balanced')\nmodel.fit(X_train, y_train)\n```", "```py\nfrom sklearn.metrics import accuracy_score, classification_report\n\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\nclassification_rep = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", classification_rep)\n```"]