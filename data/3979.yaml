- en: How to Perform Memory-Efficient Operations on Large Datasets with Pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在大型数据集上使用Pandas执行内存高效的操作
- en: 原文：[https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)
- en: '![How to Perform Memory-Efficient Operations on Large Datasets with Pandas](../Images/2d5df1e34d710f034fb115f832b43dcb.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何在大型数据集上执行内存高效的操作](../Images/2d5df1e34d710f034fb115f832b43dcb.png)'
- en: Image by Editor | Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑提供 | Midjourney
- en: Let’s learn how to perform operation in Pandas with Large datasets.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何在Pandas中对大型数据集进行操作。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Preparation
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: As we are talking about the Pandas package, you should have one installed. Additionally,
    we would use the Numpy package as well. So, install them both.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在讨论Pandas包，你应该已经安装了它。此外，我们还会使用Numpy包。所以，请同时安装这两个包。
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, let’s get into the central part of the tutorial.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们进入教程的核心部分。
- en: Perform Memory-Efficients Operations with Pandas
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Pandas执行内存高效的操作
- en: Pandas are typically not known to process large datasets as memory-intensive
    operations with the Pandas package can take too much time or even swallow your
    whole RAM. However, there are ways to improve efficiency in panda operations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas通常不以处理大型数据集而闻名，因为Pandas包的内存密集型操作可能会耗费大量时间甚至占满整个RAM。然而，有一些方法可以提高Pandas操作的效率。
- en: In this tutorial, we will walk you through ways to enhance your experience with
    large Datasets in Pandas.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将向你展示如何提升在Pandas中处理大型数据集的体验。
- en: First, try loading the dataset with a memory optimization parameter. Also, try
    changing the data type, especially to a memory-friendly type, and drop any unnecessary
    columns.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，尝试使用内存优化参数加载数据集。还要尝试更改数据类型，尤其是更改为内存友好的类型，并删除任何不必要的列。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Converting the integer and float with the smallest type would help reduce the
    memory footprint. Using category type to the categorical column with a small number
    of unique values would also help. Smaller columns also help with memory efficiency.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 将整数和浮点数转换为最小类型可以帮助减少内存占用。将具有少量唯一值的类别列转换为类别类型也有帮助。更小的列也有助于提高内存效率。
- en: Next, we can use the chunk process to avoid using all the memory. It would be
    more efficient if process it iteratively. For example, we want to get the column
    mean, but the dataset is too big. We can process 100,000 data at a time and get
    the total result.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用分块处理来避免使用全部内存。如果迭代处理会更高效。例如，我们想要计算列的均值，但数据集太大了。我们可以每次处理100,000条数据，最后得到总结果。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Additionally, avoid using the apply method with lambda functions; it could be
    memory intensive. Alternatively, it’s better to use vectorized operations or the
    `.apply` method with normal function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，避免使用带有lambda函数的apply方法，因为这可能会占用大量内存。更好的做法是使用矢量化操作或带有普通函数的`.apply`方法。
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For conditional operations in Pandas, it’s also faster to use `np.where`rather
    than directly using the Lambda function with `.apply`
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Pandas中的条件操作，使用`np.where`通常比直接使用带有`.apply`的Lambda函数要快。
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, using `inplace=True`in many Pandas operations is much more memory-efficient
    than assigning them back to their DataFrame. It’s much more efficient because
    assigning them back would create a separate DataFrame before we put them into
    the same variable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在许多Pandas操作中使用`inplace=True`比将其分配回DataFrame要节省更多内存。这种方法更高效，因为将其分配回DataFrame会在将它们放回同一个变量之前创建一个单独的DataFrame。
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Lastly, filter the data early before any operations, if possible. This will
    limit the amount of data we process.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果可能的话，尽早筛选数据。这将限制我们处理的数据量。
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Try to master these tips to improve your Pandas experience in large datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试掌握这些技巧以改善你在大型数据集中的 Pandas 使用体验。
- en: Additional Resources
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外资源
- en: '[How to Remove Duplicates in Large Datasets](https://www.kdnuggets.com/2016/04/clevertap-remove-duplicates-large-datasets.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在大型数据集中移除重复项](https://www.kdnuggets.com/2016/04/clevertap-remove-duplicates-large-datasets.html)'
- en: '[7 Ways to Handle Large Data Files for Machine Learning](https://machinelearningmastery.com/large-data-files-machine-learning)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理大型数据文件以进行机器学习的 7 种方法](https://machinelearningmastery.com/large-data-files-machine-learning)'
- en: '[How to Load Large Datasets From Directories for Deep Learning in Keras](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何从目录中加载大型数据集以进行 Keras 深度学习](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/)'
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** 是一名数据科学助理经理和数据撰稿人。在全职工作于
    Allianz Indonesia 的同时，他喜欢通过社交媒体和写作分享 Python 和数据技巧。Cornellius 在多个人工智能和机器学习主题上撰写文章。'
- en: More On This Topic
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How to Perform Matrix Operations with NumPy](https://www.kdnuggets.com/how-to-perform-matrix-operations-with-numpy)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 NumPy 执行矩阵操作](https://www.kdnuggets.com/how-to-perform-matrix-operations-with-numpy)'
- en: '[How to Merge Large DataFrames Efficiently with Pandas](https://www.kdnuggets.com/how-to-merge-large-dataframes-efficiently-with-pandas)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何高效合并大型 DataFrame](https://www.kdnuggets.com/how-to-merge-large-dataframes-efficiently-with-pandas)'
- en: '[Elevate Math Efficiency: Navigating Numpy Array Operations](https://www.kdnuggets.com/elevate-math-efficiency-navigating-numpy-array-operations)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升数学效率：导航 NumPy 数组操作](https://www.kdnuggets.com/elevate-math-efficiency-navigating-numpy-array-operations)'
- en: '[Fake It Till You Make It: Generating Realistic Synthetic Customer Datasets](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[假装直到成功：生成真实的合成客户数据集](https://www.kdnuggets.com/2022/01/fake-realistic-synthetic-customer-datasets-projects.html)'
- en: '[A New Way of Managing Deep Learning Datasets](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管理深度学习数据集的新方法](https://www.kdnuggets.com/2022/03/new-way-managing-deep-learning-datasets.html)'
- en: '[How to Identify Missing Data in Time-Series Datasets](https://www.kdnuggets.com/how-to-identify-missing-data-in-timeseries-datasets)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何识别时间序列数据集中的缺失数据](https://www.kdnuggets.com/how-to-identify-missing-data-in-timeseries-datasets)'
