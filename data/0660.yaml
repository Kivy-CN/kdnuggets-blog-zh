- en: An Overview of Human Pose Estimation with Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习的人体姿势估计概述
- en: 原文：[https://www.kdnuggets.com/2019/06/human-pose-estimation-deep-learning.html](https://www.kdnuggets.com/2019/06/human-pose-estimation-deep-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/06/human-pose-estimation-deep-learning.html](https://www.kdnuggets.com/2019/06/human-pose-estimation-deep-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Bharath Raj](https://www.linkedin.com/in/bharathrajn/), Associate Engineer,
    and [Yoni Osin](https://www.linkedin.com/in/yoni-osin-41791aa5/), VP of R&D at
    BeyondMinds**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Bharath Raj](https://www.linkedin.com/in/bharathrajn/)，助理工程师，以及[Yoni
    Osin](https://www.linkedin.com/in/yoni-osin-41791aa5/)，BeyondMinds研发副总裁**'
- en: A Human Pose Skeleton represents the orientation of a person in a graphical
    format. Essentially, it is a set of coordinates that can be connected to describe
    the pose of the person. Each coordinate in the skeleton is known as a part (or
    a joint, or a keypoint). A valid connection between two parts is known as a pair
    (or a limb). Note that, not all part combinations give rise to valid pairs. A
    sample human pose skeleton is shown below.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人体姿势骨架以图形格式表示一个人的朝向。实际上，它是一组可以连接的坐标，用来描述一个人的姿势。骨架中的每个坐标称为一个部分（或关节，或关键点）。两个部分之间的有效连接称为一对（或肢体）。请注意，并非所有部分组合都会形成有效的对。下方展示了一个示例人体姿势骨架。
- en: '![COCO keypoint format for human pose skeletons](../Images/52ae5cc813101fc0517fb7973a34d2a4.png)
    Left: COCO keypoint format for human pose skeletons. Right: Rendered human pose
    skeletons. ([Source](https://github.com/CMU-Perceptual-Computing-Lab/openpose))'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![COCO关键点格式的人体姿势骨架](../Images/52ae5cc813101fc0517fb7973a34d2a4.png) 左：COCO关键点格式的人体姿势骨架。右：渲染的人体姿势骨架。
    ([来源](https://github.com/CMU-Perceptual-Computing-Lab/openpose))'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的轨道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Knowing the orientation of a person opens avenues for several real-life applications,
    some of which are discussed towards the end of this blog. Several approaches to
    Human Pose Estimation were introduced over the years. The earliest (and slowest)
    methods typically estimating the pose of a single person in an image which only
    had one person to begin with. These methods often identify the individual parts
    first, followed by forming connections between them to create the pose.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 了解一个人的朝向为多个现实生活中的应用打开了大门，其中一些在本博客的末尾讨论。多年来，提出了几种人体姿势估计的方法。最早（也是最慢）的方法通常估计图像中一个人的姿势，而图像中最初只有一个人。这些方法通常首先识别单独的部分，然后通过形成它们之间的连接来创建姿势。
- en: Naturally, these methods are not particularly useful in many real-life scenarios
    where images contain multiple people.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这些方法在现实生活中的许多场景中并不是特别有用，因为这些图像包含多个个体。
- en: Multi-Person Pose Estimation
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多人姿势估计
- en: 'Multi-Person pose estimation is more difficult than the single person case
    as the location and the number of people in an image are unknown. Typically, we
    can tackle the above issue using one of two approaches:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 多人姿势估计比单人情况更复杂，因为图像中的人物位置和数量未知。通常，我们可以使用两种方法之一来解决上述问题：
- en: The simple approach is to incorporate a person detector first, followed by estimating
    the parts and then calculating the pose for each person. This method is known
    as the **top-down** approach.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的方法是首先整合一个人员检测器，然后估计每个人的部分，最后计算每个人的姿势。这种方法称为**自上而下**方法。
- en: Another approach is to detect all parts in the image (i.e. parts of every person),
    followed by associating/grouping parts belonging to distinct persons. This method
    is known as the **bottom-up** approach.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种方法是检测图像中的所有部分（即每个人的部分），然后将属于不同人的部分进行关联/分组。这种方法称为**自下而上**方法。
- en: '![Typical Top-Down approach](../Images/0e4922934a541b2d3062b04952051ab8.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![典型的自上而下方法](../Images/0e4922934a541b2d3062b04952051ab8.png)'
- en: 'Top: Typical Top-Down approach. Bottom: Typical Bottom-Up approach. ([Image
    Source](https://unsplash.com/photos/XuN44TajBGo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上：典型的自上而下方法。下：典型的自下而上方法。 ([图片来源](https://unsplash.com/photos/XuN44TajBGo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
- en: Typically, the top-down approach is easier to implement than the bottom-up approach
    as adding a person detector is much simpler than adding associating/grouping algorithms.
    It is hard to judge which approach has better performance overall as it really
    comes down to which among the person detector and associating/grouping algorithms
    is better.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，自上而下的方法比自下而上方法更易于实现，因为添加一个人体检测器比添加关联/分组算法要简单得多。很难判断哪种方法的整体性能更好，因为这实际上取决于人体检测器和关联/分组算法中的哪个更好。
- en: In this blog, we will focus on multi-person human pose estimation using deep
    learning techniques. In the next section, we will review some of the popular top-down
    and bottom-up approaches for the same.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将重点讨论使用深度学习技术进行多人的人体姿态估计。在接下来的部分，我们将回顾一些流行的自上而下和自下而上的方法。
- en: Deep Learning Methods
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习方法
- en: '**1\. OpenPose**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. OpenPose**'
- en: '[OpenPose](https://arxiv.org/pdf/1812.08008.pdf) is one of the most popular
    bottom-up approaches for multi-person human pose estimation, partly because of
    their well documented [GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose) implementation.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenPose](https://arxiv.org/pdf/1812.08008.pdf) 是最受欢迎的自下而上的多人体姿态估计方法之一，部分原因在于他们的[GitHub](https://github.com/CMU-Perceptual-Computing-Lab/openpose)
    实现文档详细。'
- en: As with many bottom-up approaches, OpenPose first detects parts (key points)
    belonging to every person in the image, followed by assigning parts to distinct
    individuals. Shown below is the architecture of the OpenPose model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多自下而上的方法一样，OpenPose 首先检测图像中每个人的部件（关键点），然后将这些部件分配给不同的个体。下图显示了OpenPose模型的架构。
- en: '![Flowchart of the OpenPose architecture](../Images/c75cef9a2fe93fc363d86ad3f3b60b3a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![OpenPose架构的流程图](../Images/c75cef9a2fe93fc363d86ad3f3b60b3a.png)'
- en: Flowchart of the OpenPose architecture. ([Source](https://arxiv.org/pdf/1611.08050.pdf))
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: OpenPose架构的流程图。 ([来源](https://arxiv.org/pdf/1611.08050.pdf))
- en: The OpenPose network first extracts features from an image using the first few
    layers (VGG-19 in the above flowchart). The features are then fed into two parallel
    branches of convolutional layers. The first branch predicts a set of 18 confidence
    maps, with each map representing a particular part of the human pose skeleton.
    The second branch predicts a set of 38 Part Affinity Fields (PAFs) which represents
    the degree of association between parts.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: OpenPose网络首先使用前几层（上述流程图中的VGG-19）从图像中提取特征。然后，这些特征被输入到两个并行的卷积层分支中。第一个分支预测一组18个置信度图，每个图表示人体姿态骨架的某个特定部位。第二个分支预测一组38个部件关联字段（PAFs），表示部件之间的关联程度。
- en: '![Steps involved in human pose estimation using OpenPose](../Images/d8d2fa450aa073d722e4ec7e348a2d18.png)
    Steps involved in human pose estimation using OpenPose. ([Source](https://arxiv.org/pdf/1812.08008.pdf))'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![使用OpenPose进行人体姿态估计的步骤](../Images/d8d2fa450aa073d722e4ec7e348a2d18.png) 使用OpenPose进行人体姿态估计的步骤。
    ([来源](https://arxiv.org/pdf/1812.08008.pdf))'
- en: Successive stages are used to refine the predictions made by each branch. Using
    the part confidence maps, bipartite graphs are formed between pairs of parts (as
    shown in the above image). Using the PAF values, weaker links in the bipartite
    graphs are pruned. Through the above steps, human pose skeletons can be estimated
    and assigned to every person in the image. For a more thorough explanation of
    the algorithm, you may refer to their [paper](https://arxiv.org/pdf/1812.08008.pdf) and
    to this [blog post](https://arvrjourney.com/human-pose-estimation-using-openpose-with-tensorflow-part-2-e78ab9104fc8).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用后续阶段来细化每个分支的预测。使用部件置信度图，在部件对之间形成二分图（如上图所示）。使用PAF值，剪除二分图中较弱的链接。通过这些步骤，可以估计人体姿态骨架并分配给图像中的每个人。有关算法的更详细解释，请参考他们的[论文](https://arxiv.org/pdf/1812.08008.pdf)以及这篇[博客文章](https://arvrjourney.com/human-pose-estimation-using-openpose-with-tensorflow-part-2-e78ab9104fc8)。
- en: '**2\. DeepCut**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. DeepCut**'
- en: '[DeepCut](https://arxiv.org/abs/1511.06645) is a bottom-up approach for multi-person
    human pose estimation. The authors approached the task by defining the following
    problems:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[DeepCut](https://arxiv.org/abs/1511.06645) 是一种自下而上的多人体姿态估计方法。作者通过定义以下问题来解决这一任务：'
- en: Produce a set of `**D**`body part candidates. This set represents all possible
    locations of body parts for every person in the image. Select a subset of body
    parts from the above set of body part candidates.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一组`**D**`身体部位候选。这个集合代表图像中每个人的所有可能的身体部位位置。从上述身体部位候选集合中选择一个子集。
- en: Label each selected body part with one of `**C**` body part classes. The body
    part classes represent the types of parts, such as “arm”, “leg”, “torso” etc.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用`**C**`个身体部位类别中的一个标记每个选定的身体部位。身体部位类别代表部位类型，如“手臂”、“腿”、“躯干”等。
- en: Partition body parts that belong to the same person.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将属于同一人的身体部位进行分割。
- en: '![olympics](../Images/bb9e0130b0f4a1b0a5ac8ab8e8c6cab5.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/bb9e0130b0f4a1b0a5ac8ab8e8c6cab5.png)'
- en: Pictorial representation of the approach. ([Source](https://arxiv.org/pdf/1511.06645.pdf))
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 方法的图示表示。([来源](https://arxiv.org/pdf/1511.06645.pdf))
- en: The above problems were jointly solved by modeling it into an [Integer Linear
    Programming](https://en.wikipedia.org/wiki/Integer_programming) (ILP) problem.
    It is modeled by considering triples `**(x, y, z)**` of binary random variables
    with domains as stated in the images below.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述问题通过将其建模为一个[整数线性规划](https://en.wikipedia.org/wiki/Integer_programming)（ILP）问题来共同解决。该模型通过考虑下图中所述的二元随机变量三元组`**(x,
    y, z)**`来建立。
- en: '![olympics](../Images/b2facd07488ec7b17de6071620afb7d9.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/b2facd07488ec7b17de6071620afb7d9.png)'
- en: Domains of the binary random variables. ([Source](https://arxiv.org/pdf/1511.06645.pdf))
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 二元随机变量的域。([来源](https://arxiv.org/pdf/1511.06645.pdf))
- en: Consider two body part candidates `d` and `d'` from the set of body part candidates `D` and
    classes `c` and `c'` from the set of classes `C`. The body part candidates were
    obtained through a [Faster RCNN](https://arxiv.org/abs/1506.01497) or a Dense
    CNN. Now, we can develop the following set of statements.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑来自身体部位候选集合`D`的两个身体部位候选`d`和`d'`，以及来自类别集合`C`的类别`c`和`c'`。这些身体部位候选通过[Faster RCNN](https://arxiv.org/abs/1506.01497)或密集卷积神经网络获得。现在，我们可以开发以下一组语句。
- en: If `x(d,c) = 1` then it means that body part candidate `d` belongs to class `c`.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`x(d,c) = 1`，则表示身体部位候选`d`属于类别`c`。
- en: Also, `y(d,d') = 1 `indicates that body part candidates `d` and `d'`belong to
    the same person.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，`y(d,d') = 1`表示身体部位候选`d`和`d'`属于同一个人。
- en: They also define `z(d,d’,c,c’) = x(d,c) * x(d’,c’) * y(d,d’)`. If the above
    value is 1, then it means that body part candidate `d` belongs to class `c`, body
    part candidate `d'` belongs to class `c'`, and finally body part candidates `d,d’` belong
    to the same person.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们还定义了`z(d,d’,c,c’) = x(d,c) * x(d’,c’) * y(d,d’)`。如果上述值为1，则表示身体部位候选`d`属于类别`c`，身体部位候选`d'`属于类别`c'`，并且身体部位候选`d,d’`属于同一个人。
- en: The last statement can be used to partition pose belonging to different people.
    Clearly, the above statements can be formulated in terms of linear equations as
    functions of `(x,y,z)`. In this way, the Integer Linear Program (ILP) is set up,
    and the pose of multiple persons can be estimated. For the exact set of equations
    and much more detailed analysis, you can check out their paper [here](https://arxiv.org/pdf/1511.06645.pdf).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条语句可以用来将属于不同人的姿态进行分割。显然，上述语句可以用`(x,y,z)`的线性方程来表示。通过这种方式，设置了整数线性规划（ILP），可以估计多个人的姿态。有关确切的方程组和更详细的分析，请查看他们的论文[这里](https://arxiv.org/pdf/1511.06645.pdf)。
- en: '**3\. RMPE (AlphaPose)**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. RMPE (AlphaPose)**'
- en: '[RMPE](https://arxiv.org/abs/1612.00137) is a popular top-down method of Pose
    Estimation. The authors posit that top-down methods are usually dependent on the
    accuracy of the person detector, as pose estimation is performed on the region
    where the person is located. Hence, errors in localization and duplicate bounding
    box predictions can cause the pose extraction algorithm to perform sub-optimally.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[RMPE](https://arxiv.org/abs/1612.00137)是一个流行的自上而下的姿态估计方法。作者认为，自上而下的方法通常依赖于人体检测器的准确性，因为姿态估计是在人体所在的区域进行的。因此，定位误差和重复的边界框预测可能导致姿态提取算法表现不佳。'
- en: '![Effect of duplicate predictions](../Images/17cbc644352043aa4a34d155dcf4a851.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![重复预测的效果](../Images/17cbc644352043aa4a34d155dcf4a851.png)'
- en: Effect of duplicate predictions (left) and low confidence bounding boxes (right).
    ([Source](https://arxiv.org/pdf/1612.00137.pdf))
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 重复预测的效果（左）和低置信度边界框（右）。([来源](https://arxiv.org/pdf/1612.00137.pdf))
- en: To resolve this issue, the authors proposed the usage of Symmetric Spatial Transformer
    Network (SSTN) to extract a high-quality single person region from an inaccurate
    bounding box. A Single Person Pose Estimator (SPPE) is used in this extracted
    region to estimate the human pose skeleton for that person. A Spatial De-Transformer
    Network (SDTN) is used to remap the estimated human pose back to the original
    image coordinate system. Finally, a parametric pose Non-Maximum Suppression (NMS)
    technique is used to handle the issue of redundant pose deductions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，作者提出使用对称空间变换网络 (SSTN) 从不准确的边界框中提取高质量的单人区域。一个单人姿态估计器 (SPPE) 被用在这个提取的区域中，以估计该人的姿态骨架。一个空间去变换网络
    (SDTN) 被用来将估计的人体姿态重新映射到原始图像坐标系统。最后，使用一种参数化姿态非极大值抑制 (NMS) 技术来处理冗余姿态推断的问题。
- en: Furthermore, the authors introduce a Pose Guided Proposals Generator to augment
    training samples that can better help train the SPPE and SSTN networks. The salient
    feature of RMPE is that this technique can be extended to any combination of a
    person detection algorithm and an SPPE.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，作者引入了一种姿态引导提议生成器，以增强训练样本，从而更好地训练 SPPE 和 SSTN 网络。RMPE 的显著特点是该技术可以扩展到任何组合的人体检测算法和
    SPPE。
- en: '**4\. Mask RCNN**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. Mask RCNN**'
- en: '[Mask RCNN](https://arxiv.org/abs/1703.06870) is a popular architecture for
    performing semantic and instance segmentation. The model parallelly predicts both
    the bounding box locations of the various objects in the image and a mask that
    semantically segments the object. The basic architecture can be quite easily extended
    for human pose estimation.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mask RCNN](https://arxiv.org/abs/1703.06870) 是一种用于执行语义和实例分割的流行架构。该模型并行预测图像中各种对象的边界框位置以及语义分割的掩码。基本架构可以很容易地扩展到人体姿态估计。'
- en: '![olympics](../Images/61cd3ed8667b8e8a16477684669409d4.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![olympics](../Images/61cd3ed8667b8e8a16477684669409d4.png)'
- en: Flowchart describing the Mask RCNN Architecture. ([Source](https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272))
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 描述 Mask RCNN 架构的流程图。 ([来源](https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272))
- en: The basic architecture first extracts feature maps from an image using a CNN.
    These feature maps are used by a Region Proposal Network (RPN) to get bounding
    box candidates for the presence of objects. The bounding box candidates select
    an area (region) from the feature map extracted by the CNN. Since the bounding
    box candidates can be of various sizes, a layer called RoIAlign is used to reduce
    the size of the extracted feature such that they are all of the uniform size.
    Now, this extracted feature is passed into the parallel branches of CNNs for final
    prediction of the bounding boxes and the segmentation masks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 基本架构首先使用 CNN 从图像中提取特征图。这些特征图被区域提议网络 (RPN) 用来获取对象存在的边界框候选。边界框候选从 CNN 提取的特征图中选择一个区域（区域）。由于边界框候选可能有各种尺寸，因此使用称为
    RoIAlign 的层来减少提取特征的大小，使其都具有统一的尺寸。现在，这个提取的特征被传入 CNN 的并行分支，以最终预测边界框和分割掩码。
- en: Let us focus on the branch that performs segmentation. Suppose an object in
    our image can belong to one among K classes. The segmentation branch outputs `**K**` binary
    masks of size `**m x m**`, where each binary mask represents all objects belonging
    to that class alone. We can extract key points belonging to every person in the
    image by modeling each type of keypoint as a distinct class and treating this
    like a segmentation problem.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于执行分割的分支。假设我们图像中的一个对象可以属于 K 类中的一个。分割分支输出`**K**`个大小为`**m x m**`的二进制掩码，其中每个二进制掩码仅表示属于该类的所有对象。通过将每种关键点建模为一个独特的类别，并将其视为一个分割问题，我们可以提取图像中每个人的关键点。
- en: Parallely, the objection detection algorithm can be trained to identify the
    location of the persons. By combining the information of the location of the person
    as well as their set of keypoints, we obtain the human pose skeleton for every
    person in the image.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，目标检测算法可以被训练来识别人员的位置。通过结合人员的位置以及其关键点集，我们获得图像中每个人的姿态骨架。
- en: This method nearly resembles the top-down approach, but the person detection
    stage is performed in parallel to the part detection stage. In other words, the
    keypoint detection stage and person detection stage are independent of each other.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法几乎类似于自上而下的方法，但人员检测阶段与部件检测阶段是并行执行的。换句话说，关键点检测阶段和人员检测阶段是相互独立的。
- en: '**5\. Other Methods**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 其他方法**'
- en: 'Multi-Person Human Pose Estimation is a vast field with a plethora of approaches
    to tackle the problem. For brevity, only a select few approaches are explained
    here. For a more exhaustive list of approaches, you may check out the following
    links:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 多人类姿态估计是一个庞大的领域，拥有大量的解决方法。为了简洁起见，这里仅解释了一些方法。要了解更详尽的方法列表，您可以查看以下链接：
- en: '[Awesome Human Pose Estimation](https://github.com/cbsudux/awesome-human-pose-estimation)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[绝妙的人体姿态估计](https://github.com/cbsudux/awesome-human-pose-estimation)'
- en: '[Papers with Code](https://paperswithcode.com/sota/multi-person-pose-estimation-on-mpii-multi)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带代码的论文](https://paperswithcode.com/sota/multi-person-pose-estimation-on-mpii-multi)'
- en: Applications
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用
- en: Pose Estimation has applications in myriad fields, some of which are listed
    below.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 姿态估计在众多领域中都有应用，以下列出了一些。
- en: '**1\. Activity Recognition**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 活动识别**'
- en: 'Tracking the variations in the pose of a person over a period of time can also
    be used for activity, gesture and gait recognition. There are several use cases
    for the same, including:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪一个人姿态的变化也可以用于活动、手势和步态识别。这些有很多应用场景，包括：
- en: Applications to detect if a person has fallen down or is sick.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测一个人是否跌倒或生病的应用。
- en: Applications that can autonomously teach proper workout regimes, sport techniques
    and dance activities.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以自主教授正确锻炼方案、运动技巧和舞蹈活动的应用。
- en: 'Applications that can understand full-body sign language. (Ex: Airport runway
    signals, traffic policemen signals, etc.).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以理解全身手语的应用程序。（例如：机场跑道信号，交通警察信号等）。
- en: Applications that can enhance security and surveillance.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以增强安全和监控的应用程序。
- en: '![Tracking the gait of the person](../Images/2b0bf07ba2418cbda034bd3eeaf77e42.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![追踪人的步态](../Images/2b0bf07ba2418cbda034bd3eeaf77e42.png)'
- en: Tracking the gait of the person is useful for security and surveillance purposes.
    ([Image source](http://www.ee.oulu.fi/~gyzhao/research/gait_recognition.htm))
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 追踪人的步态对于安全和监控目的很有用。（[图片来源](http://www.ee.oulu.fi/~gyzhao/research/gait_recognition.htm)）
- en: '**2\. Motion Capture and Augmented Reality**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 动作捕捉与增强现实**'
- en: An interesting application of human pose estimation is for CGI applications.
    Graphics, styles, fancy enhancements, equipment and artwork can be superimposed
    on the person if their human pose can be estimated. By tracking the variations
    of this human pose, the rendered graphics can “naturally fit” the person as they
    move.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 人体姿态估计的一个有趣应用是 CGI 应用。可以在人的身上叠加图形、风格、精美效果、设备和艺术品，如果能够估计他们的人体姿态。通过跟踪这些姿态的变化，渲染的图形可以“自然地适应”随着人的动作。
- en: '![Example of CGI Rendering](../Images/d82f726c995dc636cf3c91ae1ac01f8b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![CGI 渲染示例](../Images/d82f726c995dc636cf3c91ae1ac01f8b.png)'
- en: Example of CGI Rendering. ([Source](https://i.kym-cdn.com/photos/images/facebook/001/012/571/0a4.jpg))
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: CGI 渲染示例。（[来源](https://i.kym-cdn.com/photos/images/facebook/001/012/571/0a4.jpg)）
- en: A good visual example of what is possible can be seen through [Animoji](https://www.wired.com/story/all-the-face-tracking-tech-behind-apples-animoji/).
    Even though the above only tracks the structure of a face, the idea can be extrapolated
    for the key points of a person. The same concepts can be leveraged to render Augmented
    Reality (AR) elements that can mimic the movements of a person.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一个良好的视觉示例可以通过 [Animoji](https://www.wired.com/story/all-the-face-tracking-tech-behind-apples-animoji/)
    来看到。尽管上述技术仅追踪了面部结构，但这个想法可以推导到人的关键点上。相同的概念可以用来渲染可以模仿一个人动作的增强现实 (AR) 元素。
- en: '**3\. Training Robots**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 训练机器人**'
- en: Instead of manually programming robots to follow trajectories, robots can be
    made to follow the trajectories of a human pose skeleton that is performing an
    action. A human instructor can effectively teach the robot certain actions by
    just demonstrating the same. The robot can then calculate how to move its articulators
    to perform the same action.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人可以通过跟随执行动作的人体姿态骨架的轨迹来代替手动编程来跟随轨迹。人类教练只需演示相同动作，就可以有效地教机器人某些动作。机器人随后可以计算如何移动其关节来执行相同的动作。
- en: '**4\. Motion Tracking for Consoles**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 控制台的动作追踪**'
- en: An interesting application of pose estimation is for tracking the motion of
    human subjects for interactive gaming. Popularly, Kinect used 3D pose estimation
    (using IR sensor data) to track the motion of the human players and to use it
    to render the actions of the virtual characters.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 姿态估计的一个有趣应用是跟踪人类对象的运动以进行互动游戏。Kinect 通常使用 3D 姿态估计（使用红外传感器数据）来跟踪人类玩家的动作，并利用这些数据渲染虚拟角色的动作。
- en: '![olympics](../Images/aa55d13a78c9ec2f044803018daf1825.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![奥运会](../Images/aa55d13a78c9ec2f044803018daf1825.png)'
- en: The Kinect sensor in action. ([Source](https://appleinsider.com/articles/14/07/11/apples-secret-plans-for-primesense-3d-tech-hinted-at-by-new-itseez3d-ipad-app))
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Kinect 传感器在工作中。（[来源](https://appleinsider.com/articles/14/07/11/apples-secret-plans-for-primesense-3d-tech-hinted-at-by-new-itseez3d-ipad-app)）
- en: Conclusion
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: Great strides have been made in the field of human pose estimation, which enables
    us to better serve the myriad applications that are possible with it. Moreover,
    research in related fields such as Pose Tracking can greatly enhance its productive
    utilization in several fields. The concepts listed in this blog are not exhaustive
    but rather strives to introduce some popular variants of these algorithms and
    their real-life applications.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类姿态估计领域取得了巨大进展，这使我们能够更好地服务于其可能应用的各种场景。此外，诸如姿态跟踪等相关领域的研究可以大大提升其在多个领域的生产性应用。本文博客中列出的概念并不详尽，而是力图介绍这些算法的一些流行变体及其实际应用。
- en: '[Bharath Raj](https://www.linkedin.com/in/bharathrajn/) is an associate engineer
    at Siemens PLM Software. He loves to experiment with Machine Learning and Computer
    Vision concepts. You can check out his projects [here](https://thatbrguy.github.io).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bharath Raj](https://www.linkedin.com/in/bharathrajn/) 是 Siemens PLM Software
    的一名助理工程师。他喜欢尝试机器学习和计算机视觉概念。你可以在 [这里](https://thatbrguy.github.io) 查看他的项目。'
- en: '[Yoni Osin](https://www.linkedin.com/in/yoni-osin-41791aa5/) is the VP of R&D
    at BeyondMinds'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoni Osin](https://www.linkedin.com/in/yoni-osin-41791aa5/) 是 BeyondMinds
    的研发副总裁'
- en: '[Original](https://medium.com/beyondminds/an-overview-of-human-pose-estimation-with-deep-learning-d49eb656739b).
    Reposted with permission.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/beyondminds/an-overview-of-human-pose-estimation-with-deep-learning-d49eb656739b)。经许可转载。'
- en: '**Related:**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to do Everything in Computer Vision](/2019/02/everything-computer-vision.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在计算机视觉中实现一切](/2019/02/everything-computer-vision.html)'
- en: '[Using Tensorflow Object Detection to do Pixel Wise Classification](/2018/03/tensorflow-object-detection-pixel-wise-classification.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Tensorflow 对象检测进行像素级分类](/2018/03/tensorflow-object-detection-pixel-wise-classification.html)'
- en: '[Implementing a CNN for Human Activity Recognition in Tensorflow](/2016/11/implementing-cnn-human-activity-recognition-tensorflow.html)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Tensorflow 中实现 CNN 进行人类活动识别](/2016/11/implementing-cnn-human-activity-recognition-tensorflow.html)'
- en: More On This Topic
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[The Gap Between Deep Learning and Human Cognitive Abilities](https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习与人类认知能力之间的差距](https://www.kdnuggets.com/2022/10/gap-deep-learning-human-cognitive-abilities.html)'
- en: '[Closing the Gap Between Human Understanding and Machine Learning:…](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[缩小人类理解与机器学习之间的差距：……](https://www.kdnuggets.com/2023/06/closing-gap-human-understanding-machine-learning-explainable-ai-solution.html)'
- en: '[R vs Python (Again): A Human Factor Perspective](https://www.kdnuggets.com/2022/01/r-python-human-factor-perspective.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[R 与 Python（再论）：从人因角度看](https://www.kdnuggets.com/2022/01/r-python-human-factor-perspective.html)'
- en: '[Beyond Human Boundaries: The Rise of SuperIntelligence](https://www.kdnuggets.com/beyond-human-boundaries-the-rise-of-superintelligence)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越人类界限：超级智能的崛起](https://www.kdnuggets.com/beyond-human-boundaries-the-rise-of-superintelligence)'
- en: '[Natural Language Processing: Bridging Human Communication with AI](https://www.kdnuggets.com/natural-language-processing-bridging-human-communication-with-ai)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理：用AI架起人类沟通的桥梁](https://www.kdnuggets.com/natural-language-processing-bridging-human-communication-with-ai)'
- en: '[Beyond Coding: Why The Human Touch Matters](https://www.kdnuggets.com/beyond-coding-why-the-human-touch-matters)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越编码：人类触感为何重要](https://www.kdnuggets.com/beyond-coding-why-the-human-touch-matters)'
