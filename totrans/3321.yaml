- en: 'AI & Machine Learning Black Boxes: The Need for Transparency and Accountability'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI和机器学习黑箱：对透明度和问责制的需求
- en: 原文：[https://www.kdnuggets.com/2017/04/ai-machine-learning-black-boxes-transparency-accountability.html](https://www.kdnuggets.com/2017/04/ai-machine-learning-black-boxes-transparency-accountability.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/04/ai-machine-learning-black-boxes-transparency-accountability.html](https://www.kdnuggets.com/2017/04/ai-machine-learning-black-boxes-transparency-accountability.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By Colin Lewis (Robotenomics) and Dagmar Monett (Berlin School of Economics
    and Law).**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由Colin Lewis（Robotenomics）和Dagmar Monett（柏林经济与法律学院）撰写。**'
- en: The black box in aviation, otherwise known as a flight data recorder, is an
    extremely secure device designed to provide researchers or investigators with
    highly factual information about any anomalies that may have led to incidents
    or mishaps during a flight.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 航空中的黑箱，也称为飞行数据记录器，是一种极其安全的设备，旨在向研究人员或调查员提供关于任何可能导致飞行事件或事故的异常情况的高度真实的信息。
- en: The black box in Artificial Intelligence (AI) or Machine Learning programs¹
    has taken on the opposite meaning. The latest approach in Machine Learning, where
    there have been ‘important empirical successes,’² is Deep Learning, yet there
    are significant concerns about transparency.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）或机器学习程序中的黑箱¹已经变成了相反的意义。最新的机器学习方法，即已取得“重要实证成功”的深度学习²，但关于透明度的重大问题仍然存在。
- en: Developers acknowledge that the inner working of these ‘self-learning machines’
    adds an additional layer of complexity and opaqueness concerning machine behavior.
    Once a Machine Learning algorithm is trained, it can be difficult to understand³
    why it gives a particular response to a set of data inputs. This, as we describe
    below, can be a disadvantage when these algorithms are used in mission-critical
    tasks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员承认，这些“自学习机器”的内部工作增加了关于机器行为的复杂性和不透明性。一旦机器学习算法训练完成，理解³为何它对一组数据输入给出特定响应可能变得困难。这，如下所述，当这些算法用于任务关键时，可能是一种劣势。
- en: Furthermore, the fact that Machine Learning algorithms can act in ways unforeseen
    by their designer raises issues about the ‘autonomy,’ ‘decision-making,’ and ‘responsibility’
    capacities of AI. When something goes wrong, as it inevitably does, it can be
    a daunting task discovering the behavior that caused an event that is locked away
    inside a black box where discoverability is virtually impossible.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，机器学习算法可以以其设计者未曾预见的方式行动，这引发了关于AI的“自治”、“决策”和“责任”能力的问题。当出现问题时，正如必然会发生的那样，发现导致事件的行为可能是一项艰巨的任务，因为这些行为被锁定在几乎无法发现的黑箱中。
- en: '![Black box](../Images/99fc6f58785746d59b0567f0aa960761.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![黑箱](../Images/99fc6f58785746d59b0567f0aa960761.png)'
- en: '**As Machine Learning algorithms get smarter, they are also becoming more incomprehensible.**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**随着机器学习算法变得更加智能，它们也变得更加不可理解。**'
- en: 'Machine Learning algorithms are essentially systems that learn patterns of
    behavior from collected data to support prediction and informed decision-making.
    These Machine Learning systems typically process data in two explicit areas as
    described by Rayid Ghani, Director of the Data Science for Social Good Fellowship,
    who indicated that⁴: “the power of data science is typically harnessed in a spectrum
    with the following two extremes:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法本质上是从收集的数据中学习行为模式以支持预测和知情决策的系统。这些机器学习系统通常在两个明确的领域中处理数据，如数据科学社会公益奖学金主任Rayid
    Ghani所描述，他指出⁴：“数据科学的力量通常在以下两个极端的范围内发挥作用：
- en: Helping humans in discovering new knowledge that can be used to inform decision
    making,
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 帮助人类发现可以用于决策的信息，新知识，
- en: Through automated predictive models that are plugged into operational systems
    and operate autonomously.”
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过自动化预测模型，这些模型被插入到操作系统中并自主运行。”
- en: 'To reflect these two extremes of knowledge gathering and automated decision-making,
    Machine Learning systems typically cluster into two types:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了反映知识获取和自动决策的这两个极端，机器学习系统通常分为两种类型：
- en: Type A applications -- in which model predictions are used to support consequential
    decisions that can have a profound effect on people’s lives such as medical diagnosis,
    loan applications, self-driving cars, and policing and prison sentencing; and
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A类应用——其中模型预测用于支持可能对人们生活产生深远影响的决策，例如医学诊断、贷款申请、自动驾驶汽车、执法和刑罚；以及
- en: Type B applications -- in which model predictions are used in settings of lower
    consequence and large scale, such as which streaming video to watch, the news
    that gets shown at the top of a news-feed, and search queries.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B类应用——在较低后果和大规模的环境中使用模型预测，例如选择观看哪个流媒体视频、新闻提要顶部显示的新闻以及搜索查询。
- en: However, it has been well documented⁵ that the design and build of these Machine
    Learning black boxes can lead to bias, unfairness, and discrimination through
    programmer and data choices. “The irony is that the more we design Artificial
    Intelligence technology that successfully mimics humans, the more that AI is learning
    in a way that we do, with all of our biases and limitations.”⁶
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，已经有充分的文献记录表明，这些机器学习黑箱的设计和构建可能会通过程序员和数据选择导致偏见、不公平和歧视。“讽刺的是，我们越是设计成功模拟人类的人工智能技术，人工智能就越是以我们拥有的所有偏见和局限性进行学习。”⁶
- en: 'While there are other issues such as concerns about the quality of the data
    and its processing, or about the quality of the algorithms'' outcome and its ethical
    implications, to name a few, managers should be aware of two core elements where
    potential problems frequently occur in Machine Learning systems and which we feel
    executives should be concerned with and take action to remedy: 1) *Transparency*,
    and 2) *Leadership and Governance*.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然还有其他问题，如数据质量及其处理的担忧，或算法结果的质量及其伦理影响等，但经理们应该意识到机器学习系统中经常出现潜在问题的两个核心要素，我们认为高管们应该关注并采取行动加以解决：1）*透明性*，2）*领导力和治理*。
- en: '**1\. Transparency**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 透明性**'
- en: For people to use the predictions of an analytics model in their decision-making,
    they must trust the model. To trust a model, they must understand how it makes
    its predictions, i.e., the model should be interpretable. Most current Machine
    Learning systems operating which are based on deep neural network principles are
    not easily interpretable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让人们在决策中使用分析模型的预测，他们必须信任该模型。要信任一个模型，他们必须了解它如何做出预测，即模型应该是可解释的。目前大多数基于深度神经网络原理的机器学习系统并不容易解释。
- en: This can potentially be very damaging for the organization that is relying on
    the AI system. Researchers Taylor et al⁷. (2016) have shown that “there are many
    possible hard-to-detect ways a system’s behavior could differ from the intended
    behavior of the designer, and at least some of these differences are undesirable.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这对依赖人工智能系统的组织可能造成很大的损害。研究人员Taylor等人（2016）已经表明，“系统行为与设计者的预期行为之间存在许多可能难以察觉的差异，而这些差异中至少有一些是不
    desirable的。”
- en: 'Monitoring the behavior of a Machine Learning system may prove difficult without
    careful design. Executives should strive to ensure that their Machine Learning
    systems are more transparent, in order to aid an informed overseer by allowing
    them to evaluate a system’s internal reasons for decisions. As Professor Pedro
    Domingos writes⁸: “when a new technology is as pervasive and game-changing as
    machine learning, it’s not wise to let it remain a black box. Opacity opens the
    door to error and misuse.”'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有精心设计，监控机器学习系统的行为可能会很困难。高管们应当努力确保他们的机器学习系统更具透明性，以帮助知情监督者评估系统在做出决策时的内部原因。正如Pedro
    Domingos教授所写的⁸：“当一种新技术如机器学习如此普及且改变游戏规则时，让它保持黑箱状态并不明智。隐蔽性为错误和滥用打开了大门。”
- en: '**2\. Leadership and Governance**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**2. 领导力和治理**'
- en: Leaders should seek to enforce strict governance over Machine Learning algorithms
    ensuring a “value alignment” and “good behavior’’ in these new machine intelligence
    systems especially as they are frequently being utilized in a general capacity
    for making effective decisions toward a business objective.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 领导者应当寻求对机器学习算法实施严格的治理，确保这些新型机器智能系统具有“价值对齐”和“良好行为”，特别是当它们经常被用来在业务目标方面做出有效决策时。
- en: Governance of the systems should incorporate systematic ways to formalize hidden
    assumptions (inside a black box) and ensure accountability, auditability, and
    transparency of internal Machine Learning system workings. Furthermore, a greater
    emphasis on introducing stricter checks on the selection and robustness of open
    source Machine Learning algorithms and training data should be uppermost in developers
    and management's mind.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的治理应包括系统化的方式来形式化隐藏的假设（在黑箱内部），并确保机器学习系统内部工作的问责制、可审计性和透明度。此外，对开源机器学习算法和训练数据的选择及其鲁棒性引入更严格的检查应成为开发者和管理者的首要任务。
- en: Any decision-making Machine Learning system optimizing itself for an objective,
    which may be misaligned with an organization’s interests, could have significant
    and permanent effects. Recognizing the limitations⁹ of Machine Learning and AI
    algorithms is the first step to managing them better.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一个为了优化目标而自行调整的决策机器学习系统，如果其目标与组织的利益不一致，可能会产生显著且永久的影响。认识到机器学习和AI算法的局限性是更好地管理它们的第一步。
- en: Ultimately we need to be sure we are not putting machines in charge of decisions
    that they do not have the intelligence to make.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们需要确保我们不会把不具备足够智能的机器置于决策之中。
- en: '**Footnotes**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**脚注**'
- en: The authors use the terms Machine Learning systems, programs, and algorithms
    interchangeably throughout this article.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作者在本文中将机器学习系统、程序和算法这些术语交替使用。
- en: 'Bengio, Yoshua (2013). Deep Learning of Representations: Looking Forward. In
    A. Dediu, C. Martín-Vide, R. Mitkov, and B. Truthe (eds.), *Statistical Language
    and Speech Processing: First International Conference* (pp. 1-137), Berlin Heidelberg:
    Springer.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bengio, Yoshua (2013年)。表征的深度学习：展望未来。见 A. Dediu, C. Martín-Vide, R. Mitkov, 和
    B. Truthe (编)，*统计语言与语音处理：第一次国际会议*（第1-137页），柏林海德堡：施普林格。
- en: 'Mittelstadt, Brent Daniel; Allo, Patrick; Taddeo, Mariarosaria; Wachter, Sandra;
    and Floridi, Luciano (2016, in press). The Ethics of Algorithms: Mapping the Debate.
    *Big Data & Society*.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Mittelstadt, Brent Daniel; Allo, Patrick; Taddeo, Mariarosaria; Wachter, Sandra;
    和 Floridi, Luciano (2016年，待出版)。算法伦理：辩论的映射。*大数据与社会*。
- en: Shan, Carl (2015). *How data science can be used for social good*. Retrieved
    from [http://www.carlshan.com/2015/01/08/data-science-social-good.html](http://www.carlshan.com/2015/01/08/data-science-social-good.html).
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shan, Carl (2015年)。*数据科学如何用于社会公益*。来源：[http://www.carlshan.com/2015/01/08/data-science-social-good.html](http://www.carlshan.com/2015/01/08/data-science-social-good.html)。
- en: 'Peña Gangadharan, Seeta; Eubanks, Virginia; and Barocas, Solon (2014). *Data
    and Discrimination: Collected Essays*. New America: Open Technology Institute.
    Retrieved from [https://na-production.s3.amazonaws.com/documents/data-and-discrimination.pdf](https://na-production.s3.amazonaws.com/documents/data-and-discrimination.pdf).'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Peña Gangadharan, Seeta; Eubanks, Virginia; 和 Barocas, Solon (2014年)。*数据与歧视：论文集*。新美国：开放技术研究所。来源：[https://na-production.s3.amazonaws.com/documents/data-and-discrimination.pdf](https://na-production.s3.amazonaws.com/documents/data-and-discrimination.pdf)。
- en: '*Programming and Prejudice: UTAH computer scientists discover how to find bias
    in algorithms* (2015, August). UNews, University of UTAH. Retrieved from [http://unews.utah.edu/programming-and-prejudice/](https://unews.utah.edu/programming-and-prejudice/).'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*编程与偏见：犹他大学计算机科学家发现如何在算法中识别偏见* (2015年8月)。UNews, 犹他大学。来源：[http://unews.utah.edu/programming-and-prejudice/](https://unews.utah.edu/programming-and-prejudice/)。'
- en: Taylor, Jessica; Yudkowsky, Eliezer; LaVictoire, Patrick; and Critch, Andrew
    (2016). *Alignment for advanced machine learning systems*. Retrieved from [https://intelligence.org/files/AlignmentMachineLearning.pdf](https://intelligence.org/files/AlignmentMachineLearning.pdf).
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Taylor, Jessica; Yudkowsky, Eliezer; LaVictoire, Patrick; 和 Critch, Andrew (2016年)。*高级机器学习系统的对齐*。来源：[https://intelligence.org/files/AlignmentMachineLearning.pdf](https://intelligence.org/files/AlignmentMachineLearning.pdf)。
- en: Domingos, Pedro (2016, May). *Why you need to understand machine learning*.
    World Economic Forum. Retrieved from [https://www.weforum.org/agenda/2016/05/why-you-need-to-understand-machine-learning/](https://www.weforum.org/agenda/2016/05/why-you-need-to-understand-machine-learning/).
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Domingos, Pedro (2016年5月)。*为什么你需要理解机器学习*。世界经济论坛。来源：[https://www.weforum.org/agenda/2016/05/why-you-need-to-understand-machine-learning/](https://www.weforum.org/agenda/2016/05/why-you-need-to-understand-machine-learning/)。
- en: Luca, Michael; Kleinberg, Jon; and Mullainathan, Sendhil (2016, January-February).
    *Algorithms Need Managers, Too*. Harvard Business Review. Retrieved from [https://hbr.org/2016/01/algorithms-need-managers-too](https://hbr.org/2016/01/algorithms-need-managers-too).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卢卡，迈克尔；克莱因伯格，乔恩；穆拉纳坦，森迪尔（2016年1月-2月）。*算法也需要管理者*。哈佛商业评论。取自 [https://hbr.org/2016/01/algorithms-need-managers-too](https://hbr.org/2016/01/algorithms-need-managers-too)。
- en: '**[Colin Lewis](http://robotenomics.com/)** is a Behavioral Economist and Data
    Scientist who provides research and advisory services in automation, robotics
    and artificial intelligence ([www.robotenomics.com](http://robotenomics.com/)).
    His work on robotics and automation has been featured by The Financial Times,
    Bloomberg, Harvard Business Review, and others.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**[科林·刘易斯](http://robotenomics.com/)** 是一位行为经济学家和数据科学家，提供自动化、机器人技术和人工智能的研究和咨询服务
    ([www.robotenomics.com](http://robotenomics.com/))。他的机器人和自动化工作曾被《金融时报》，彭博社，哈佛商业评论等媒体报道。'
- en: '**[Dagmar Monett](http://www.monettdiaz.com)** is Professor of Computer Science
    at the Berlin School of Economics and Law, Germany. She received a *Dr. rer nat.*
    in Computer Science from the Humboldt University of Berlin in 2005\. Her main
    research and teaching interests include different areas in Artificial Intelligence
    and Software Engineering ([www.monettdiaz.com](http://www.monettdiaz.com)).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[达格玛·莫内特](http://www.monettdiaz.com)** 是德国柏林经济与法律学院的计算机科学教授。她于2005年获得柏林洪堡大学计算机科学的*Dr.
    rer nat.*学位。她的主要研究和教学兴趣包括人工智能和软件工程的不同领域 ([www.monettdiaz.com](http://www.monettdiaz.com))。'
- en: '**Related:**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Big Data Desperately Needs Transparency](/2017/03/big-data-needs-transparency.html)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大数据迫切需要透明度](/2017/03/big-data-needs-transparency.html)'
- en: '[A Brief History of Artificial Intelligence](/2017/04/brief-history-artificial-intelligence.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能简史](/2017/04/brief-history-artificial-intelligence.html)'
- en: '[What is AI? Ingredients for Intelligence](/2017/04/grakn-artificial-intelligence-ingredients-intelligence.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是人工智能？智能的组成部分](/2017/04/grakn-artificial-intelligence-ingredients-intelligence.html)'
- en: '* * *'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How Metadata Improves Security, Quality, and Transparency](https://www.kdnuggets.com/2022/04/metadata-improves-security-quality-transparency.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[元数据如何提高安全性、质量和透明度](https://www.kdnuggets.com/2022/04/metadata-improves-security-quality-transparency.html)'
- en: '[Black Friday Deal - Master Machine Learning for Less with DataCamp](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑色星期五优惠 - 用DataCamp以更低价格掌握机器学习](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
- en: '[The Quest for Model Confidence: Can You Trust a Black Box?](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对模型信心的探索：你能相信一个黑箱吗？](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
- en: '[We Don''t Need Data Scientists, We Need Data Engineers](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们不需要数据科学家，我们需要数据工程师](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)'
- en: '[Machine Learning Books You Need To Read In 2022](https://www.kdnuggets.com/2022/04/machine-learning-books-need-read-2022.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022年你需要阅读的机器学习书籍](https://www.kdnuggets.com/2022/04/machine-learning-books-need-read-2022.html)'
- en: '[KDnuggets News, April 27: A Brief Introduction to Papers With Code;…](https://www.kdnuggets.com/2022/n17.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，4月27日：关于带代码的论文简要介绍；…](https://www.kdnuggets.com/2022/n17.html)'
