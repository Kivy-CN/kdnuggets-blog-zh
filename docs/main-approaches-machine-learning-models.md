# 机器学习模型的三种主要方法

> 原文：[https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html](https://www.kdnuggets.com/2019/06/main-approaches-machine-learning-models.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

在2018年9月，我发布了一篇关于我的[即将出版的《数据科学的数学基础》一书](https://www.kdnuggets.com/2018/09/learning-mathematics-machine-learning.html)的博客。我们讨论的核心问题是：***我们如何弥合人工智能（深度学习和机器学习）所需的数学与高中所教授的数学（至17/18岁）之间的差距？***

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业领域。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 为你的组织提供 IT 支持

* * *

在这篇文章中，我们介绍了这本书中的一章，名为“机器学习模型的分类”。这本书现在已经发布，并以章节形式提供早鸟折扣。如果你有兴趣获得早期折扣版，请联系 ajit.jaokar at feynlabs.ai。

### 1\. 机器学习模型的分类

没有简单的方法来分类机器学习算法。在这一部分，我们呈现了从*彼得·弗拉赫*的《机器学习》一书中改编的机器学习模型分类法。虽然分类算法的结构基于该书，但下面的解释是我们创建的。

对于给定问题，所有可能结果的集合表示**样本空间或实例空间**。

创建算法分类法的基本理念是通过以下三种方式之一划分实例空间：

+   使用逻辑表达式。

+   使用实例空间的几何。

+   使用概率来分类实例空间。

使用上述技术转换实例空间的机器学习算法的结果应该是详尽的（涵盖所有可能的结果）和互斥的（不重叠）。

### 2\. 逻辑模型

#### 2.1 逻辑模型 - 树模型和规则模型

**逻辑模型**使用逻辑表达式将实例空间划分为多个段，从而构建分组模型。**逻辑表达式**是返回布尔值的表达式，即True或False结果。一旦使用逻辑表达式对数据进行分组，数据将被划分为解决问题的同质分组。例如，对于分类问题，组中的所有实例都属于同一类。

逻辑模型主要有两种类型：**树模型**和**规则模型**。

规则模型由一组蕴涵或IF-THEN规则组成。对于树模型，“if部分”定义了一个段，“then部分”定义了该段的模型行为。规则模型遵循相同的推理。

树模型可以看作是规则模型的一种特殊类型，其中规则的if部分以树结构组织。树模型和规则模型都采用相同的监督学习方法。该方法可以总结为两种策略：我们可以首先找到覆盖足够同质实例的规则主体（概念），然后找到代表该主体的标签。或者，我们可以从另一个方向入手，即首先选择一个我们想要学习的类别，然后找到覆盖该类别实例的规则。

下图展示了一个简单的树模型。树模型显示了泰坦尼克号乘客的生存数量（“sibsp”是船上配偶或兄弟姐妹的数量）。叶子下的值显示了生存的概率以及叶子的观察百分比。该模型可以总结为：如果你是（i）女性，或（ii）年龄小于9.5岁且兄弟姐妹少于2.5个的男性，那么你的生存机会很好。

![](../Images/85e50c23e3bb1eb1dcaef01fa2dbb9aa.png)

([图片来源](https://en.wikipedia.org/wiki/Decision_tree_learning#/media/File:CART_tree_titanic_survivors.png).)

#### 2.2 逻辑模型与概念学习

要进一步理解逻辑模型，我们需要了解**概念学习**的概念。概念学习涉及从实例中学习逻辑表达式或概念。概念学习的思想与机器学习的理念非常契合，即从具体的训练实例中推断出一般函数。概念学习是树模型和规则模型的基础。更正式地说，概念学习包括从给定的一组正负训练实例中获得一般类别的定义。概念学习的正式定义是“***从输入和输出的训练实例中推断一个布尔值函数。***”在概念学习中，我们仅为正类学习描述，并将所有不满足该描述的标记为负类。

以下示例详细解释了这一思想。

![](../Images/d828ab1972e27be4bb02766ea6cb01ca.png)

一个 [概念学习](https://web.cs.hacettepe.edu.tr/~ilyas/Courses/BIL712/lec01-conceptLearning.pdf) 任务，称为“享受运动”，如上所示，由一些示例日期的数据集定义。每个数据由六个属性描述。任务是学习基于属性值预测“享受运动”的值。问题可以用 **一系列假设** 来表示。每个假设由对属性的约束的结合描述。训练数据代表目标函数的正例和负例。在上面的例子中，每个假设是一个包含六个约束的向量，指定了六个属性的值——天空、空气温度、湿度、风、水和预报。训练阶段涉及学习一组日期（作为属性的结合），其中“享受运动”= 是。

因此，问题可以表述为：

+   给定实例 X，表示所有可能的日期集合，每个日期由以下属性描述：

    +   天空 – （值：晴天，多云，雨天），

    +   空气温度 – （值：温暖，寒冷），

    +   湿度 – （值：正常，高），

    +   风 – （值：强，弱），

    +   水 – （值：温暖，寒冷），

    +   预报 – （值：相同，变化）。

尝试识别一个可以预测目标变量“享受运动”是“是”/“否”，即 1 或 0 的函数。

#### 2.3 概念学习作为搜索问题和归纳学习

我们也可以将概念学习表述为 **搜索问题**。我们可以将概念学习看作是在预定义的潜在假设空间中搜索，以识别最符合训练示例的假设。概念学习也是 **归纳学习** 的一个例子。归纳学习，也称为发现学习，是一种通过观察示例发现规则的过程。归纳学习不同于演绎学习，演绎学习是学生获得规则后需要应用的。归纳学习基于 **归纳学习假设**。归纳学习假设认为：任何在足够大的训练示例集上能很好近似目标函数的假设，预计在其他未观察到的示例上也能很好近似目标函数。这一思想是归纳学习的基本假设。

总结一下，在本节中，我们看到了第一类算法，在这些算法中，我们基于逻辑表达式划分了实例空间。我们还讨论了逻辑模型如何基于概念学习理论——而概念学习理论又可以表述为归纳学习或搜索问题。

### 3. 几何模型

在前一节中，我们看到使用逻辑模型，如决策树，使用逻辑表达式来划分实例空间。当两个实例最终落在相同的逻辑片段中时，它们是相似的。在本节中，我们考虑通过考虑实例空间的几何来定义相似性的模型。在几何模型中，特征可以描述为二维（*x-* 和 *y* 轴）或三维空间（*x*、*y* 和 *z*）。即使特征本质上不是几何的，也可以以几何方式建模（例如，时间函数的温度可以在两个轴上建模）。在几何模型中，我们可以通过两种方式强加相似性。

+   我们可以使用几何概念，如**直线或平面进行分割（分类）**实例空间。这些称为**线性模型**。

+   或者，我们可以使用几何上的距离概念来表示相似性。在这种情况下，如果两个点接近，它们在特征上具有相似的值，因此可以被归类为相似。我们称这种模型为**基于距离的模型**。

#### 3.1 线性模型

线性模型相对简单。在这种情况下，函数被表示为其输入的线性组合。因此，如果 *x*[1] 和 *x*[2] 是两个相同维度的标量或向量，*a* 和 *b* 是任意标量，那么 *ax*[1] + *bx*[2] 表示 *x*[1] 和 *x*[2] 的线性组合。在最简单的情况下，当 *f*(*x*) 表示一条直线时，我们有一个形式为 *f*(*x*) = *mx* + *c* 的方程，其中 *c* 代表截距，*m* 代表斜率。

![](../Images/5d556dcaa6505f6f20801865dff203e4.png)

([图片来源](https://en.wikipedia.org/wiki/Linear_regression).)

线性模型是**参数化的**，这意味着它们有一个固定的形式，具有少量需要从数据中学习的数值参数。例如，在 *f* (*x*) = *mx* + *c* 中，*m* 和 *c* 是我们试图从数据中学习的参数。这种技术不同于树或规则模型，其中模型的结构（例如，树中使用哪些特征以及位置）[不是预先固定的](https://www.quora.com/Why-is-a-decision-tree-considered-a-non-parametric-model)。

线性模型是**稳定**的，即训练数据的微小变化对学习到的模型的影响有限。相比之下，**树模型通常会随着训练数据的变化而变化更多**，因为树的根部选择不同的分割通常意味着树的其余部分也会不同。 由于参数相对较少，线性模型具有**低方差和高偏差**。这意味着**线性模型比其他一些模型更不容易过拟合训练数据**。然而，它们更容易欠拟合。例如，如果我们想根据标记数据学习国家之间的边界，那么线性模型可能不会给出一个好的近似。

在这一部分，我们还可以使用包括**核方法**的算法，例如支持向量机（SVM）。核方法使用核函数将数据转换到另一个维度，在该维度上可以更容易地进行数据分离，例如使用超平面进行SVM。

#### 3.2 基于距离的模型

**基于距离的模型**是几何模型的第二类。与线性模型一样，基于距离的模型基于数据的几何。顾名思义，基于距离的模型依赖于距离的概念。在机器学习的背景下，距离的概念不仅仅是两点之间的物理距离。我们可以考虑两点之间的**运输方式**。通过飞机旅行的城市之间的距离在物理上比火车旅行的距离要少，因为飞机没有限制。类似地，在国际象棋中，距离的概念依赖于使用的棋子——例如，象可以对角移动。因此，根据实体和旅行方式，距离的概念可以有不同的体验。常用的距离度量包括**欧几里得**、**闵可夫斯基**、**曼哈顿**和**马氏**。

![](../Images/26c20eb8d04972bcdaf9fd0b32166a34.png)

([图片来源](http://www.ieee.ma/uaesb/pdf/distances-in-classification.pdf).)

距离通过**邻居和样本**的概念应用。邻居是相对于通过样本表示的距离度量的邻近点。样本是找到根据所选距离度量的质量中心的**中心点**或找到最中央数据点的**代表元**。最常用的中心点是算术均值，它最小化了与所有其他点的平方欧几里得距离。

备注：

+   **中心点**代表平面图形的几何中心，即图形中所有点相对于中心点的算术平均位置。这个定义扩展到任意*n*维空间中的对象：其中心点是所有点的平均位置。

+   **代表元**在概念上类似于均值或中心点。代表元通常用于无法定义均值或中心点的数据场景。它们在中心点无法代表数据集的情况下使用，例如在图像数据中。

基于距离的模型的例子包括**最近邻**模型，它们使用训练数据作为样本，例如在分类中。**K均值聚类**算法也使用样本来创建相似数据点的簇。

### 4\. 概率模型

机器学习算法的第三类是概率模型。我们之前已经看到，k-近邻算法使用距离（例如，欧几里得距离）的理念来分类实体，而逻辑模型使用逻辑表达式来划分实例空间。在本节中，我们将看到**概率模型如何使用概率的概念来分类新实体**。

概率模型将特征和目标变量视为随机变量。建模过程表示和**操控这些变量的不确定性**。概率模型有两种类型：**预测型和生成型**。预测型概率模型使用**条件概率**分布 *P* (*Y* |*X*) 从中可以从 *X* 预测 *Y*。生成型模型估计**联合分布** *P* (*Y*, *X*)。一旦我们知道生成模型的联合分布，我们可以推导出涉及相同变量的任何条件或边际分布。因此，生成模型能够创建新的数据点及其标签，知道联合概率分布。联合分布寻找两个变量之间的关系。一旦推断出这种关系，就可以推断出新的数据点。

**朴素贝叶斯** 是一种概率分类器的例子。

任何概率分类器的目标是，给定一组特征（*x*_0 到 *x*_n）和一组类别（*c*_0 到 *c*_k），我们旨在确定特征在每个类别中出现的概率，并返回最可能的类别。因此，对于每个类别，我们需要计算 *P*(*c*_i | x_0, …, x_n)。

我们可以使用**贝叶斯规则**来实现这一点

![](../Images/b93638ae72ebb1dfd9def2e9dfb5165f.png)

朴素贝叶斯算法基于**条件概率**的理念。条件概率是基于找到**某事发生的**概率，*前提是其他事情* 已经发生。算法的任务是查看证据并确定特定类别的可能性，并相应地为每个实体分配标签。

### 结论

上述讨论提供了一种基于数学基础的分类算法的方法。虽然讨论简化了，但它提供了一种从基本原理深入探讨算法的全面方式。**如果你对获得早期折扣副本感兴趣，请联系 ajit.jaokar at feynlabs.ai。**

**相关：**

+   [决策树——直观介绍](https://www.kdnuggets.com/2019/02/decision-trees-introduction.html)

+   [使用 Scikit-Learn 的 Python 线性回归入门指南](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html)

+   [仅使用 Python 从头实现朴素贝叶斯——无复杂框架](https://www.kdnuggets.com/2018/10/naive-bayes-from-scratch-python.html)

### 更多相关主题

+   [人工智能、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)

+   [机器学习的数据标注：市场概况、方法与工具](https://www.kdnuggets.com/2021/12/data-labeling-ml-overview-and-tools.html)

+   [机器学习的甜蜜点：自然语言处理与文档分析中的纯方法](https://www.kdnuggets.com/2022/05/machine-learning-sweet-spot-pure-approaches-nlp-document-analysis.html)

+   [使用Python的自动化机器学习：不同方法的比较…](https://www.kdnuggets.com/2023/03/automated-machine-learning-python-comparison-different-approaches.html)

+   [2021年的主要发展及2022年的关键趋势：人工智能、数据科学…](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)

+   [文本总结的方法：概述](https://www.kdnuggets.com/2019/01/approaches-text-summarization-overview.html)
