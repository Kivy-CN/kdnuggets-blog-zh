- en: (Deep Learning’s Deep Flaws)’s Deep Flaws
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: (深度学习的深层缺陷)的深层缺陷
- en: 原文：[https://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html](https://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html](https://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: A few well-publicized recent papers have tempered the hype surrounding deep
    learning. The papers identify both that images can be subtly altered to induce
    misclassification and that seemingly random garbage images can easily be generated
    which receive high confidence classifications. A wave of press has sensationalized
    the message. Several blog posts, a YouTube video, and others have amplified and
    occasionally distorted the results, professing the gullibility of deep networks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一些近期广泛报道的论文已经缓解了围绕深度学习的炒作。这些论文指出，图像可以被微妙地修改以引起错误分类，并且可以轻易生成看似随机的垃圾图像，这些图像会得到高度的信心分类。新闻界对这一消息进行了
    sensationalized 的报道。几个博客帖子、一个 YouTube 视频以及其他媒体都放大并偶尔扭曲了结果，宣称深度网络的轻信性。
- en: Given the hoopla, it's appropriate to examine these findings. While some are
    intriguing, others are less surprising. Some are nearly universal problems with
    machine learning in adversarial settings. Further, after examining these findings,
    it seems clear that they are only shocking given an unrealistic conception of
    what deep networks actually do, i.e., an unrealistic expectation that modern feed-forward
    neural networks exhibit human-like cognition.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些炒作，审视这些发现是合适的。虽然一些发现很吸引人，但其他的却不那么令人惊讶。有些是机器学习在对抗性环境中的几乎普遍存在的问题。此外，经过审视这些发现后，似乎很清楚，它们之所以令人震惊，完全是因为对深度网络实际做什么的非现实预期，即对现代前馈神经网络具有类似人类认知的非现实期望。
- en: The criticisms are two-fold, stemming from two separate papers. The first, ["Intriguing
    Properties of Neural Networks"](http://cs.nyu.edu/~zaremba/docs/understanding.pdf),
    is a paper published last year by Google's Christian Szegedy and others. In it,
    they reveal that one can subtly alter images in ways imperceptible to humans and
    yet induce misclassification by a trained convolutional neural network (CNN).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这些批评有两个方面，源于两篇独立的论文。第一篇，[“神经网络的有趣特性”](http://cs.nyu.edu/~zaremba/docs/understanding.pdf)，是由谷歌的
    Christian Szegedy 等人去年发表的论文。在其中，他们揭示了可以以对人类不可察觉的方式微妙地改变图像，从而导致经过训练的卷积神经网络 (CNN)
    的错误分类。
- en: To be clear, this paper is well-written, well-conceived, and presents modest
    but insightful claims. The authors present two results. The main result shows
    that random linear combinations of the hidden units in the final layer of a neural
    network are semantically indistinguishable from the units themselves. They suggest
    that the space spanned by these hidden units is actually what is important and
    not which specific basis spans that space.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 需要明确的是，这篇论文写得很好，构思周密，提出了适度但有洞察力的主张。作者展示了两个结果。主要结果显示，神经网络最后一层的隐藏单元的随机线性组合在语义上与单元本身不可区分。他们建议这些隐藏单元所跨越的空间才是重要的，而不是哪个特定的基底跨越了这个空间。
- en: The second, more widely covered claim regards the altering of images. The authors
    non-randomly alter a set of pixels so as to induce misclassification. The result
    is a seemingly identical but misclassified image. This finding raises interesting
    questions about the applications of deep learning to adversarial situations. The
    authors also point out that this challenges the smoothness assumption, i.e., that
    examples very close to each other should have the same classification with high
    probability.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个、更广泛报道的主张涉及图像的修改。作者非随机地改变了一组像素，以引起错误分类。结果是一个看似相同但被错误分类的图像。这个发现引发了关于深度学习在对抗性情境中的应用的有趣问题。作者还指出，这挑战了平滑假设，即相互非常接近的示例应有很高概率得到相同分类。
- en: The adversarial case is definitely worth thinking about. Still, optimizing images
    for misclassification requires access to the model. This scenario may not always
    be realistic. A spammer, for example may be able to send out emails and see which
    emails are classified as spam by Google's filter, but they're unlikely to gain
    the opportunity to access Google's spam-filtering algorithm so as to optimize
    maximally spam-like emails which are nevertheless not filtered. Similarly, to
    fool deep learning face detection software, one would need access to the underlying
    convolutional neural net in order to precisely doctor the image.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗案例确实值得深思。然而，优化图像以实现错误分类需要访问模型。这种情况可能并不总是现实的。例如，垃圾邮件发送者可能能够发送电子邮件并查看哪些电子邮件被谷歌的过滤器分类为垃圾邮件，但他们不太可能获得访问谷歌垃圾邮件过滤算法的机会，以便最大限度地优化垃圾邮件类型的电子邮件，这些电子邮件却未被过滤。同样，要欺骗深度学习面部检测软件，需要访问底层的卷积神经网络，以便准确地伪造图像。
- en: It's worth noting that nearly all machine learning algorithms are susceptible
    to adversarial chosen examples. Consider a logistic regression classifier with
    thousands of features, many of which have non-zero weight. If one such feature
    is numerical, the value of that feature could be set very high or very low to
    induce misclassification, without altering any of the other thousands of features.
    To a human who could only perceive a small subset of the features at a time, this
    alteration might not be perceptible. Alternatively, if any features had very high
    weight in the model, they might only need to have their values shifted a small
    amount to induce misclassification. Similarly, for decision trees, a single binary
    feature might be switched to direct an example into the wrong partition at the
    final layer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，几乎所有的机器学习算法都容易受到对抗性选择示例的影响。考虑一个具有数千个特征的逻辑回归分类器，其中许多特征具有非零权重。如果其中一个特征是数值型的，可以将该特征的值设置得非常高或非常低，以诱导错误分类，而不改变其他数千个特征。对于只能感知特征子集的人类而言，这种改变可能不会被察觉。或者，如果模型中任何特征的权重非常高，则可能只需要将其值稍微调整一下，就能诱导错误分类。类似地，对于决策树，一个二进制特征可能被切换，以将示例引导到最终层的错误分区中。
- en: This pathological case for neural networks is different in some ways. One crucial
    difference is that the values taken by pixels are constrained. Still, given nearly
    any machine learning model with many features and many degrees of freedom, it
    is easy to engineer pathological adversarial examples. This is true even for much
    simpler models that are better understood and come with theoretical guarantees.
    Perhaps, we should not be surprised that deep learning too is susceptible to adversarially
    chosen examples.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于神经网络而言，这种病态案例在某些方面是不同的。其中一个关键区别是像素的取值是受到约束的。然而，鉴于几乎任何具有许多特征和自由度的机器学习模型，都容易工程化病态的对抗示例。这对于那些更简单、理解更透彻并且有理论保证的模型也是真的。也许，我们不应该对深度学习也易受对抗性选择示例的影响感到惊讶。
- en: The second paper, ["Deep Networks are Easily Fooled"](http://arxiv.org/pdf/1412.1897v2.pdf)
    by Anh Nguyen of the University of Wyoming, appears to make a bolder proclamation.
    Citing the work of Szegedy et. al., they set out to examine the reverse problem,
    i.e., how to fabricate a seemingly nonsensical example, which despite its apparent
    lack of content nonetheless receives a high confidence classification. The authors
    use gradient ascent to train gibberish images (unrecognizable to the human eye)
    which are classified strongly into some clearly incorrect object class.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第二篇论文，来自怀俄明大学的Anh Nguyen所著的《["深度网络容易被欺骗"](http://arxiv.org/pdf/1412.1897v2.pdf)》，似乎做出了更大胆的声明。引用了Szegedy等人的工作，他们着手研究反向问题，即如何制造一个看似无意义的例子，尽管它明显缺乏内容，但仍然获得了高置信度的分类。作者使用梯度上升法来训练一些无法被人眼识别的胡言乱语图像，这些图像被强烈分类到一些明显错误的对象类别中。
- en: '![Second layer of convolutional neural network visualized](../Images/8c12470a515a5f24014c9325e7204a14.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络的第二层可视化](../Images/8c12470a515a5f24014c9325e7204a14.png)'
- en: From a standpoint of mathematical intuition, this is what we should expect.
    In the previous case, the altered images were constrained to be indistinguishable
    from some source image. Here, the images are constrained only not to look like
    anything! In the whole space of possible images, actual recognizable images are
    a minuscule subset of images, leaving nearly the entire vector space open. Further,
    here it is very easy to find a corresponding problem in virtually every other
    machine learning method. Given any linear classifier, one could find some spot
    that is both far from the decision boundary and also far away from any other data
    point that has ever been seen. Given a topic model, one could create a nonsensical
    mishmash of randomly ordered words which appears to get the same inferred topic
    distribution as some chosen real document.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学直觉的角度来看，这正是我们应该预期的。在之前的情况中，修改后的图像被限制为与某个源图像不可区分。在这里，图像的限制只是不能看起来像任何东西！在所有可能的图像空间中，实际可识别的图像只是一个微小的子集，几乎整个向量空间都是开放的。此外，在几乎所有其他机器学习方法中，都很容易找到相应的问题。给定任何线性分类器，都可以找到一个既远离决策边界又远离任何曾见过的数据点的位置。给定一个主题模型，可以创建一个毫无意义的随机词序列，它似乎获得了与某个选定的真实文档相同的推断主题分布。
- en: The primary sense in which this result might be surprising is that convolutional
    neural networks' have come to rival human abilities when it comes to the task
    of object detection. In this sense, it may be important to distinguish the capabilities
    of CNNs from human abilities. The authors make this point from the outset, and
    the argument is reasonable.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果可能令人惊讶的主要原因是卷积神经网络在物体检测任务中的表现已经能够与人类能力相媲美。在这种意义上，区分CNN的能力和人类能力可能是重要的。作者从一开始就提出了这一点，这个论点是合理的。
- en: As both Michael I. Jordan and Geoff Hinton have recently discussed, deep learning's
    great successes have attracted a wave of hype. The recent wave of negative publicity
    illustrates that this hype cuts both ways. The success of deep learning has rightfully
    tempted many to examine its shortcomings. However, it's worth keeping in mind
    that many of the problems are ubiquitous in most machine learning contexts. Perhaps
    more widespread interest in algorithms robust to adversarial examples could benefit
    the entire machine learning community.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Michael I. Jordan和Geoff Hinton最近讨论的那样，深度学习的巨大成功吸引了一波炒作。最近的负面宣传表明这种炒作有两面性。深度学习的成功确实使许多人愿意审视其缺陷。然而，值得记住的是，许多问题在大多数机器学习环境中都是普遍存在的。或许对对抗性示例鲁棒的算法的更广泛兴趣可以使整个机器学习社区受益。
- en: '![Zachary Chase Lipton](../Images/240b273c667af1a53a99fd93d1fd39ce.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![Zachary Chase Lipton](../Images/240b273c667af1a53a99fd93d1fd39ce.png)'
- en: '**[Zachary Chase Lipton](http://zacklipton.com)** is a PhD student in the Computer
    Science Engineering department at the University of California, San Diego. Funded
    by the [Division of Biomedical Informatics](http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx),
    he is interested in both theoretical foundations and applications of machine learning.
    In addition to his work at UCSD, he has interned at Microsoft Research Labs.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Zachary Chase Lipton](http://zacklipton.com)** 是加州大学圣地亚哥分校计算机科学工程系的博士生。在[生物医学信息学部门](http://healthsciences.ucsd.edu/som/medicine/divisions/dbmi/pages/default.aspx)资助下，他对机器学习的理论基础和应用都感兴趣。除了在UCSD的工作，他还曾在微软研究院实习。'
- en: '**Related:**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Geoff Hinton AMA: Neural Networks, the Brain, and Machine Learning](/2014/12/geoff-hinton-ama-neural-networks-brain-machine-learning.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Geoff Hinton AMA：神经网络、大脑和机器学习](/2014/12/geoff-hinton-ama-neural-networks-brain-machine-learning.html)'
- en: '[Does Deep Learning Have Deep Flaws?](/2014/06/deep-learning-deep-flaws.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习是否存在深层缺陷？](/2014/06/deep-learning-deep-flaws.html)'
- en: '[Deep Learning can be easily fooled](/2015/01/deep-learning-can-be-easily-fooled.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习可以轻易被愚弄](/2015/01/deep-learning-can-be-easily-fooled.html)'
- en: '[Differential Privacy: How to make Privacy and Data Mining Compatible](/2015/01/differential-privacy-data-mining-compatible.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[差分隐私：如何使隐私与数据挖掘兼容](/2015/01/differential-privacy-data-mining-compatible.html)'
- en: '* * *'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 方面'
- en: '* * *'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多主题
- en: '[A Solid Plan for Learning Data Science, Machine Learning, and Deep Learning](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学、机器学习和深度学习的扎实计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)'
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
- en: '[15 Free Machine Learning and Deep Learning Books](https://www.kdnuggets.com/2022/10/15-free-machine-learning-deep-learning-books.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15 本免费的机器学习和深度学习书籍](https://www.kdnuggets.com/2022/10/15-free-machine-learning-deep-learning-books.html)'
- en: '[KDnuggets News, November 2: The Current State of Data Science…](https://www.kdnuggets.com/2022/n43.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，11月2日：数据科学的现状…](https://www.kdnuggets.com/2022/n43.html)'
- en: '[15 More Free Machine Learning and Deep Learning Books](https://www.kdnuggets.com/2022/11/15-free-machine-learning-deep-learning-books.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15 本免费的机器学习和深度学习书籍](https://www.kdnuggets.com/2022/11/15-free-machine-learning-deep-learning-books.html)'
- en: '[Using Datawig, an AWS Deep Learning Library for Missing Value Imputation](https://www.kdnuggets.com/2021/12/datawig-aws-deep-learning-library-missing-value-imputation.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Datawig，AWS 的深度学习库进行缺失值插补](https://www.kdnuggets.com/2021/12/datawig-aws-deep-learning-library-missing-value-imputation.html)'
