- en: 'Data Ingestion with Pandas: A Beginner Tutorial'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据导入与 Pandas：初学者教程
- en: 原文：[https://www.kdnuggets.com/2022/04/data-ingestion-pandas-beginner-tutorial.html](https://www.kdnuggets.com/2022/04/data-ingestion-pandas-beginner-tutorial.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/04/data-ingestion-pandas-beginner-tutorial.html](https://www.kdnuggets.com/2022/04/data-ingestion-pandas-beginner-tutorial.html)
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/1ee6bcf1b4fdde28bdbc82763da6ffd9.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![数据导入与 Pandas：初学者教程](../Images/1ee6bcf1b4fdde28bdbc82763da6ffd9.png)'
- en: Image by author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) is easy to
    use, open-source data analysis tool which is widely used by data analytics, data
    engineering, data science, and machine learning engineers. It comes with powerful
    functions such as data cleaning & manipulations, supporting popular data formats,
    and data visualization using matplotlib. Most data science students only learn
    to import CSV, but at work, you have to deal with multiple data formats, and things
    can get complicated if you are doing it for the first time. In this guide, we
    will be focusing on importing CSV, Excel, SQL, HTML, and JSON datasets.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) 是一个易于使用的开源数据分析工具，广泛用于数据分析、数据工程、数据科学和机器学习工程。它具有强大的功能，如数据清理与操作、支持流行的数据格式以及使用
    matplotlib 的数据可视化。大多数数据科学学生只学习导入 CSV，但在工作中，你必须处理多种数据格式，如果这是你第一次做，事情可能会变得复杂。在本指南中，我们将重点介绍导入
    CSV、Excel、SQL、HTML 和 JSON 数据集。'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: SQL
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SQL
- en: For running SQL queries, we need to download SQLite database for Kaggle [Mental
    Health in the Tech Industry](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry)
    under the License [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/).
    The database contains three tables; Questions, Answer, and Survey.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行 SQL 查询，我们需要下载用于 Kaggle [科技行业心理健康](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry)
    的 SQLite 数据库，许可证为 [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)。该数据库包含三个表：Questions、Answer
    和 Survey。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/fcc3a630e7e5303231d299d03ec017af.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![数据导入与 Pandas：初学者教程](../Images/fcc3a630e7e5303231d299d03ec017af.png)'
- en: SQL Schema | [Kaggle](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: SQL Schema | [Kaggle](https://www.kaggle.com/anth7310/mental-health-in-the-tech-industry)
- en: 'To import data from any SQL server, we need to create a connection (SQLAlchemy
    connectable / sqlite3), write SQL query, and use Pandas’s **read_sql_query()**
    function to convert output to dataframe. In our case, we will first connect *mental_health.sqlite*
    by using sqlite3 package and then pass the object into the **read_sql_query()**
    function. The last step is to write a query to import all columns from the *Question*
    table. If you are new to SQL, I will suggest you learn the basics by taking a
    free course: [Learn SQL | Codecademy](https://www.codecademy.com/learn/learn-sql).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要从任何 SQL 服务器导入数据，我们需要创建连接（SQLAlchemy 可连接对象 / sqlite3），编写 SQL 查询，并使用 Pandas 的
    **read_sql_query()** 函数将输出转换为数据框。在我们的案例中，我们将首先使用 sqlite3 包连接 *mental_health.sqlite*，然后将对象传递给
    **read_sql_query()** 函数。最后一步是编写查询以从 *Question* 表中导入所有列。如果你是 SQL 新手，我建议你通过参加一个免费的课程来学习基础知识：[Learn
    SQL | Codecademy](https://www.codecademy.com/learn/learn-sql)。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We have successfully converted SQL query into Pandas dataframe. It’s that easy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功将 SQL 查询转换为 Pandas 数据框。就是这么简单。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/c5ba35f1464ccb7fe1bfe0724bf589ab.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![数据导入与 Pandas：初学者教程](../Images/c5ba35f1464ccb7fe1bfe0724bf589ab.png)'
- en: HTML
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTML
- en: Web scraping is a complicated and time-consuming job in the tech world. You
    will be using [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/),
    [Selenium](https://www.selenium.dev/), and [Scrapy](https://scrapy.org/) to extract
    and clean your HTML data. Using Pandas **read_html()**, you can skip all the steps
    and directly import table data from the website into a dataframe. **It’s that
    easy**. In our case, we will be scraping the [COVID-19 Vaccination Tracker](https://www.pharmaceutical-technology.com/covid-19-vaccination-tracker/)
    website to extract tables containing COVID19 vaccination data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 网络抓取在技术世界中是一项复杂且耗时的工作。你将使用 [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/)，
    [Selenium](https://www.selenium.dev/)，和 [Scrapy](https://scrapy.org/) 来提取和清理HTML数据。使用Pandas
    **read_html()**，你可以跳过所有步骤，直接将网站上的表格数据导入数据框。**这就是简单**。在我们的案例中，我们将抓取 [COVID-19 疫苗接种追踪器](https://www.pharmaceutical-technology.com/covid-19-vaccination-tracker/)
    网站，以提取包含COVID19疫苗接种数据的表格。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/5a7258252c504ceb3c88b7340462c8eb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![使用Pandas的数据导入：初学者教程](../Images/5a7258252c504ceb3c88b7340462c8eb.png)'
- en: COVID19 Vaccination Data | [Pharmaceutical Technology](https://www.pharmaceutical-technology.com/covid-19-vaccination-tracker/)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: COVID19 疫苗接种数据 | [制药技术](https://www.pharmaceutical-technology.com/covid-19-vaccination-tracker/)
- en: Just by using **pd.read_html()** we were able to extract the data from the website.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用**pd.read_html()**我们就能够从网站中提取数据。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Our initial output was list and to convert list into a dataframe we have use
    **[0]** at the end. This will only display the first value in the list.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初始输出是列表，若要将列表转换为数据框，我们在末尾使用了**[0]**。这只会显示列表中的第一个值。
- en: '**Note:** You need to experiment with your initial result to get the perfect
    result.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 你需要对初始结果进行实验，以获得最终的结果。'
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/34bebd7afd402c10af4a31cdcfd053d2.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![使用Pandas的数据导入：初学者教程](../Images/34bebd7afd402c10af4a31cdcfd053d2.png)'
- en: CSV
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CSV
- en: 'CSV is the most common file format in data science. It is simple and can be
    accessed by multiple Python packages. The first thing you will learn in a data
    science course is to import a CSV file. In our case, we are using Kaggle’s [Bike
    Sharing Dataset](https://www.kaggle.com/yasserh/bike-sharing-dataset) under [CC0:
    Public Domain](https://creativecommons.org/publicdomain/zero/1.0/) license. The
    values in CSV are separated by commas as shown below.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 'CSV 是数据科学中最常见的文件格式。它简单易用，可被多个Python包访问。你在数据科学课程中学到的第一件事就是导入CSV文件。在我们的案例中，我们使用的是Kaggle的
    [共享单车数据集](https://www.kaggle.com/yasserh/bike-sharing-dataset)，其遵循 [CC0: 公共领域](https://creativecommons.org/publicdomain/zero/1.0/)
    许可证。CSV中的值由逗号分隔，如下所示。'
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/b84155762108f436c8280b8294bdbd73.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![使用Pandas的数据导入：初学者教程](../Images/b84155762108f436c8280b8294bdbd73.png)'
- en: Image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: We will use the **read_csv()** function to import the dataset into Pandas dataframe.
    This function is quite powerful as we can parse dates, remove missing values and
    do a lot of data cleaning with just one line of code.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**read_csv()**函数将数据集导入Pandas数据框。这个函数非常强大，因为我们可以解析日期、删除缺失值，并且只用一行代码就能进行大量数据清理。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have successfully loaded the CSV file and displayed the first five rows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功加载了CSV文件并显示了前五行。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/19ba1f5d0bb8d671b6cc8f61cc4e6eb8.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![使用Pandas的数据导入：初学者教程](../Images/19ba1f5d0bb8d671b6cc8f61cc4e6eb8.png)'
- en: Excel
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Excel
- en: Excel sheets are still popular among data and business analytics professionals.
    In our case we will be converting the [U.S. Presidents and Debt](https://data.world/kevinnayar/us-presidents-and-debt)
    dataset by kevinnayar under [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/)
    license into **.xlsx** format by using Microsoft Excel. Our Excel file contains
    two sheets but Pandas dataframe is a flat table, we will use **sheet_name** to
    import selected sheets into Pandas dataframe.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Excel表格在数据和业务分析专业人员中仍然很受欢迎。在我们的案例中，我们将使用Microsoft Excel将 [美国总统与债务](https://data.world/kevinnayar/us-presidents-and-debt)
    数据集（由kevinnayar提供，遵循 [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/)
    许可证）转换为**.xlsx**格式。我们的Excel文件包含两个工作表，但Pandas数据框是一个平面表，我们将使用**sheet_name**将选定的工作表导入Pandas数据框。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/821a0b955235e2d4cbe7152a69d2f3fe.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用Pandas的数据导入：初学者教程](../Images/821a0b955235e2d4cbe7152a69d2f3fe.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'We will be using **read_excel()** to import our dataset:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**read_excel()**导入数据集：
- en: The first parameter is file path.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数是文件路径。
- en: 'The second is sheet_name: in our case we are importing the second sheet. The
    sheet numbers start from 0.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二是 sheet_name：在我们的案例中，我们正在导入第二个工作表。工作表编号从 0 开始。
- en: 'Third is index_col: as our dataset contains index columns, to avoid duplication,
    we will provide **index_col=<column_name>.**'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三是 index_col：由于我们的数据集包含索引列，为了避免重复，我们将提供**index_col=<column_name>**。
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/1418e9de94d6d65f9bc3ddc20a8eb4c5.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据导入：初学者教程](../Images/1418e9de94d6d65f9bc3ddc20a8eb4c5.png)'
- en: JSON
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JSON
- en: 'Reading JSON files is quite tricky as there are multiple formats that you need
    to understand. Sometimes, Pandas fails to import nested JSON files so we need
    to perform manual steps to import the file perfectly. JSON is the most common
    file format for the tech industry. It is preferred by web developers to data engineers.
    In our case, we are going to download the [Spotify Recommendation](https://www.kaggle.com/bricevergnou/spotify-recommendation)
    dataset under [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)
    license. The dataset contains good songs and bad songs JSON files. For this example,
    we will only use the *good.json* file. As we can observe, we are dealing with
    a nested dataset.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '读取 JSON 文件相当棘手，因为有多种格式需要理解。有时，Pandas 无法导入嵌套 JSON 文件，因此我们需要执行手动步骤以完美导入文件。JSON
    是科技行业最常见的文件格式。它受到网页开发者和数据工程师的青睐。在我们的案例中，我们将下载[Spotify 推荐](https://www.kaggle.com/bricevergnou/spotify-recommendation)数据集，许可证为[CC0:
    公共领域](https://creativecommons.org/publicdomain/zero/1.0/)。该数据集包含好歌曲和坏歌曲的 JSON
    文件。对于这个例子，我们将只使用*good.json* 文件。正如我们所见，我们正在处理一个嵌套的数据集。'
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/7ab0d0abb065bac0dd87d52b6f0af72e.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据导入：初学者教程](../Images/7ab0d0abb065bac0dd87d52b6f0af72e.png)'
- en: Image by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Before doing any data processing let’s import the dataset without parameters
    by using the **read_json()** function.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何数据处理之前，让我们使用**read_json()**函数在不带参数的情况下导入数据集。
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we can observe, the dataframe contains only one column, and it's all over
    the place. To debug this issue, we need to import the raw dataset and then parse
    it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，数据框只包含一列，而且数据杂乱无章。要调试此问题，我们需要导入原始数据集，然后进行解析。
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/2a3a237fa062aecb33d1cf6604080de6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据导入：初学者教程](../Images/2a3a237fa062aecb33d1cf6604080de6.png)'
- en: First, we will be importing raw JSON files using the **json** package and only
    selecting the *audio_features* subset. Finally, we will convert the JSON to Pandas
    dataframe by using the **json_normalize()** function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用**json**包导入原始 JSON 文件，并仅选择*audio_features*子集。最后，我们将通过使用**json_normalize()**函数将
    JSON 转换为 Pandas 数据框。
- en: It’s a success and we have finally parsed the JSON into a dataframe. If you
    are dealing with a multi-layer nested JSON file, try to import the raw data and
    then process the data so that the final output is a flat table.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是成功的，我们终于将 JSON 解析为数据框。如果你处理的是多层嵌套 JSON 文件，尝试先导入原始数据，然后处理数据，以便最终输出为平面表格。
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Data Ingestion with Pandas: A Beginner Tutorial](../Images/8506a1eb58677611a614320fa5e275ff.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据导入：初学者教程](../Images/8506a1eb58677611a614320fa5e275ff.png)'
- en: The code and all datasets are available at [**Deepnote**](https://deepnote.com/@abid/Data-Ingestion-with-Pandas-04Jajb5RSDWQY_RbkaJxjA)**.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 代码和所有数据集可以在 [**Deepnote**](https://deepnote.com/@abid/Data-Ingestion-with-Pandas-04Jajb5RSDWQY_RbkaJxjA)**.**
- en: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    is a certified data scientist professional who loves building machine learning
    models. Currently, he is focusing on content creation and writing technical blogs
    on machine learning and data science technologies. Abid holds a Master''s degree
    in Technology Management and a bachelor''s degree in Telecommunication Engineering.
    His vision is to build an AI product using a graph neural network for students
    struggling with mental illness.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Abid Ali Awan](https://www.polywork.com/kingabzpro)** ([@1abidaliawan](https://twitter.com/1abidaliawan))
    是一位认证的数据科学专业人士，喜欢构建机器学习模型。目前，他专注于内容创作，并撰写关于机器学习和数据科学技术的技术博客。Abid 拥有技术管理硕士学位和电信工程学士学位。他的愿景是使用图神经网络构建一个
    AI 产品，帮助那些在精神健康方面遇到困难的学生。'
- en: More On This Topic
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Introductory Pandas Tutorial](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者 Pandas 教程](https://www.kdnuggets.com/2022/03/introductory-pandas-tutorial.html)'
- en: '[A Beginner''s Guide to Pandas Melt Function](https://www.kdnuggets.com/2023/03/beginner-guide-pandas-melt-function.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者的 Pandas Melt 函数指南](https://www.kdnuggets.com/2023/03/beginner-guide-pandas-melt-function.html)'
- en: '[Docker Tutorial for Data Scientists](https://www.kdnuggets.com/2023/07/docker-tutorial-data-scientists.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的 Docker 教程](https://www.kdnuggets.com/2023/07/docker-tutorial-data-scientists.html)'
- en: '[Pydantic Tutorial: Data Validation in Python Made Simple](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pydantic 教程：简化 Python 数据验证](https://www.kdnuggets.com/pydantic-tutorial-data-validation-in-python-made-simple)'
- en: '[Federated Learning: Collaborative Machine Learning with a Tutorial…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[联邦学习：协作机器学习教程…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)'
- en: '[YOLOv5 PyTorch Tutorial](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv5 PyTorch 教程](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)'
