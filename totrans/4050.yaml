- en: Mastering the Art of Data Cleaning in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握 Python 数据清理的艺术
- en: 原文：[https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python](https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python](https://www.kdnuggets.com/mastering-the-art-of-data-cleaning-in-python)
- en: '![Mastering the Art of Data Cleaning in Python](../Images/8962cd78b382626bafaea7ad8d538500.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/8962cd78b382626bafaea7ad8d538500.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Data cleaning is a critical part of any data analysis process. It's the step
    where you remove errors, handle missing data, and make sure that your data is
    in a format that you can work with. Without a well-cleaned dataset, any subsequent
    analyses can be skewed or incorrect.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理是任何数据分析过程中的关键部分。这一步骤中你会去除错误，处理缺失数据，并确保数据以可处理的格式存在。没有经过良好清理的数据集，任何后续分析都可能会产生偏差或错误。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的捷径'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的 IT 部门'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This article introduces you to several key techniques for data cleaning in Python,
    using powerful libraries like pandas, numpy, seaborn, and matplotlib.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了几种在 Python 中进行数据清理的关键技术，使用了 pandas、numpy、seaborn 和 matplotlib 等强大库。
- en: Understanding the Importance of Data Cleaning
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据清理的重要性
- en: Before diving into the mechanics of data cleaning, let's understand its importance.
    Real-world data is often messy. It can contain duplicate entries, incorrect or
    inconsistent data types, missing values, irrelevant features, and outliers. All
    these factors can lead to misleading conclusions when analyzing data. This makes
    data cleaning an indispensable part of the data science lifecycle.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入数据清理的机制之前，让我们了解其重要性。现实世界中的数据通常是混乱的。它可能包含重复条目、错误或不一致的数据类型、缺失值、无关特征和异常值。所有这些因素都可能导致分析数据时得出误导性结论。这使得数据清理成为数据科学生命周期中不可或缺的一部分。
- en: We’ll cover the following data cleaning tasks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下数据清理任务。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/9705a754315fcc1b9d070e034988a2f3.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/9705a754315fcc1b9d070e034988a2f3.png)'
- en: Image by Author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Setup for Data Cleaning in Python
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 数据清理的设置
- en: Before getting started, let's import the necessary libraries. We'll be using
    pandas for data manipulation, and seaborn and matplotlib for visualizations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，让我们导入必要的库。我们将使用 pandas 进行数据处理，使用 seaborn 和 matplotlib 进行可视化。
- en: We’ll also import the datetime Python module for manipulating the dates.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将导入 datetime Python 模块以便处理日期。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading and Inspecting Your Data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载和检查您的数据
- en: First, we'll need to load our data. In this example, we're going to load a CSV
    file using pandas. We also add the delimiter argument.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要加载数据。在这个例子中，我们将使用 pandas 加载一个 CSV 文件。我们还添加了分隔符参数。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, it's important to inspect the data to understand its structure, what kind
    of variables we're working with, and whether there are any missing values. Since
    the data we imported is not huge, let’s have a look at the whole dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，检查数据以了解其结构、我们正在处理的变量类型以及是否有缺失值是很重要的。由于我们导入的数据量不大，让我们查看整个数据集。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here’s how the dataset looks.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的样子如下。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/14b819ad4461b06f0037afbd0fb31cc0.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/14b819ad4461b06f0037afbd0fb31cc0.png)'
- en: You can immediately see there are some missing values. Also, the date formats
    are inconsistent.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以立即看到有一些缺失值。此外，日期格式不一致。
- en: Now, let’s take a look at the DataFrame summary using the info() method.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 info() 方法查看 DataFrame 概况。
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here’s the code output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码输出。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/e02bf810733535c1ba1e9252f7922309.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/e02bf810733535c1ba1e9252f7922309.png)'
- en: We can see that only the column square_feet doesn’t have any NULL values, so
    we’ll somehow have to handle this. Also, the columns advertisement_date, and sale_date
    are the object data type, even though this should be a date.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，只有列 square_feet 没有任何 NULL 值，因此我们需要处理这一点。此外，列 advertisement_date 和 sale_date
    的数据类型是对象类型，尽管它们应该是日期。
- en: The column location is completely empty. Do we need it?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列的位置完全为空。我们需要它吗？
- en: We’ll show you how to handle these issues. We’ll start by learning how to delete
    unnecessary columns.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向你展示如何处理这些问题。我们首先学习如何删除不必要的列。
- en: Deleting Unnecessary Columns
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除不必要的列
- en: There are two columns in the dataset that we don’t need in our data analysis,
    so we’ll remove them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有两列在数据分析中不需要，因此我们将删除它们。
- en: The first column is buyer. We don’t need it, as the buyer’s name doesn’t impact
    the analysis.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 第一列是 buyer。我们不需要它，因为买方的名字不会影响分析。
- en: We’re using the drop() method with the specified column name. We set the axis
    to 1 to specify that we want to delete a column. Also, the inplace argument is
    set to True so that we modify the existing DataFrame, and not create a new DataFrame
    without the removed column.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了 `drop()` 方法，并指定了列名。我们将 `axis` 设置为 1，以指定要删除的是列。另外，将 `inplace` 参数设置为 True，以便我们修改现有的
    DataFrame，而不是创建一个没有被删除列的新 DataFrame。
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The second column we want to remove is location. While it might be useful to
    have this information, this is a completely empty column, so let’s just remove
    it.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要删除的第二列是 location。虽然这些信息可能有用，但这是一列完全为空的列，所以我们直接删除它。
- en: We take the same approach as with the first column.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用与第一列相同的方法。
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of course, you can remove these two columns simultaneously.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以同时删除这两列。
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Both approaches return the following dataframe.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法都返回了以下数据框。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/d4b19f806cfe3564dd619a9df95ffe74.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/d4b19f806cfe3564dd619a9df95ffe74.png)'
- en: Handling Duplicate Data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理重复数据
- en: Duplicate data can occur in your dataset for various reasons and can skew your
    analysis.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的重复数据可能由于各种原因发生，并且可能会影响你的分析。
- en: Let’s detect the duplicates in our dataset. Here’s how to do it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检测数据集中的重复项。以下是如何操作。
- en: The below code uses the method **duplicated()** to consider duplicates in the
    whole dataset. Its default setting is to consider the first occurrence of a value
    as unique and the subsequent occurrences as duplicates. You can modify this behavior
    using the **keep** parameter. For instance, df.duplicated(keep=False) would mark
    all duplicates as True, including the first occurrence.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用了 **duplicated()** 方法来检查整个数据集中的重复项。默认情况下，它将值的第一次出现视为唯一，之后的出现视为重复。你可以使用
    **keep** 参数来修改这一行为。例如，df.duplicated(keep=False) 会将所有重复项标记为 True，包括第一次出现。
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here’s the output.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/d4fe70038e3767a4460653a2ef241088.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/d4fe70038e3767a4460653a2ef241088.png)'
- en: The row with index 3 has been marked as duplicate because row 2 with the same
    values is its first occurrence.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 索引为 3 的行被标记为重复，因为值相同的第 2 行是它的第一次出现。
- en: Now we need to remove duplicates, which we do with the following code.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要去除重复项，这里使用了以下代码。
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The **drop_duplicates()** function considers all columns while identifying
    duplicates. If you want to consider only certain columns, you can pass them as
    a list to this function like this: df.drop_duplicates(subset=[''column1'', ''column2'']).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**drop_duplicates()** 函数在识别重复项时会考虑所有列。如果你只想考虑某些列，可以将它们作为列表传递给此函数，例如：df.drop_duplicates(subset=[''column1'',
    ''column2''])。'
- en: '![Mastering the Art of Data Cleaning in Python](../Images/0c802373e36ec7124b65ee9e9cb0cc8b.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/0c802373e36ec7124b65ee9e9cb0cc8b.png)'
- en: As you can see, the duplicate row has been dropped. However, the indexing stayed
    the same, with index 3 missing. We’ll tidy this up by resetting indices.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，重复的行已经被删除。然而，索引保持不变，索引 3 丢失了。我们将通过重置索引来整理这一点。
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This task is performed by using the **reset_index()** function.  The drop=True
    argument is used to discard the original index. If you do not include this argument,
    the old index will be added as a new column in your DataFrame. By setting drop=True,
    you are telling pandas to forget the old index and reset it to the default integer
    index.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务是通过使用**reset_index()**函数来完成的。`drop=True`参数用于丢弃原始索引。如果不包括此参数，旧索引将作为新列添加到你的DataFrame中。通过设置`drop=True`，你告诉pandas忘记旧索引并将其重置为默认的整数索引。
- en: For practice, try to [remove duplicates from this Microsoft dataset](https://platform.stratascratch.com/coding/9849-find-the-duplicate-records-in-the-dataset?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 练习一下，尝试从这个[Microsoft数据集中删除重复项](https://platform.stratascratch.com/coding/9849-find-the-duplicate-records-in-the-dataset?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)。
- en: Data Type Conversion
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型转换
- en: Sometimes, data types might be incorrectly set. For example, a date column might
    be interpreted as strings. You need to convert these to their appropriate types.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据类型可能设置不正确。例如，日期列可能被解释为字符串。你需要将其转换为适当的类型。
- en: In our dataset, we’ll do that for the columns advertisement_date and sale_date,
    as they are shown as the object data type. Also, the date dates are formatted
    differently across the rows. We need to make it consistent, along with converting
    it to date.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的数据集中，我们将对`advertisement_date`和`sale_date`列进行此操作，因为它们显示为对象数据类型。此外，日期格式在各行之间不同。我们需要使其一致，同时转换为日期。
- en: The easiest way is to use the **to_datetime()** method. Again, you can do that
    column by column, as shown below.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是使用**to_datetime()**方法。你可以像下面所示，一列一列地进行转换。
- en: When doing that, we set the dayfirst argument to True because some dates start
    with the day first.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样做时，我们将`dayfirst`参数设置为True，因为某些日期以天为首。
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can also convert both columns at the same time by using the **apply()**
    method with **to_datetime()**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用**apply()**方法结合**to_datetime()**同时转换两列。
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Both approaches give you the same result.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法都会给你相同的结果。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/19dc91cbaf4dbb488a3593d95ad7a444.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![掌握Python数据清洗的艺术](../Images/19dc91cbaf4dbb488a3593d95ad7a444.png)'
- en: Now the dates are in a consistent format. We see that not all data has been
    converted. There’s one NaT value in advertisement_date and two in sale_date. This
    means the date is missing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在日期格式一致了。我们看到并非所有数据都已转换。`advertisement_date`中有一个NaT值，`sale_date`中有两个。这意味着日期缺失了。
- en: Let’s check if the columns are converted to dates by using the **info()** method.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用**info()**方法检查列是否已转换为日期。
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Mastering the Art of Data Cleaning in Python](../Images/e6ec0eb9378e4f56d55550dcb47a8a4d.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![掌握Python数据清洗的艺术](../Images/e6ec0eb9378e4f56d55550dcb47a8a4d.png)'
- en: As you can see, both columns are not in datetime64[ns] format.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，两列都不是datetime64[ns]格式。
- en: Now, try to convert the data from TEXT to NUMERIC in this [Airbnb dataset](https://platform.stratascratch.com/coding/9634-host-response-rates-with-cleaning-fees?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尝试在这个[Airbnb数据集中将数据从文本转换为数字](https://platform.stratascratch.com/coding/9634-host-response-rates-with-cleaning-fees?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)。
- en: Handling Missing Data
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: Real-world datasets often have missing values. Handling missing data is vital,
    as certain algorithms cannot handle such values.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的数据集通常会有缺失值。处理缺失数据是至关重要的，因为某些算法不能处理这些值。
- en: Our example also has some missing values, so let’s take a look at the two most
    usual approaches to handling missing data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例中也有一些缺失值，所以我们来看一下处理缺失数据的两种最常见的方法。
- en: Deleting Rows With Missing Values
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除缺失值的行
- en: If the number of rows with missing data is insignificant compared to the total
    number of observations, you might consider deleting these rows.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺失数据的行数与总观察数相比不重要，你可以考虑删除这些行。
- en: In our example, the last row has no values except the square feet and advertisement
    date. We can’t use such data, so let’s remove this row.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，最后一行除了平方英尺和广告日期外没有值。我们不能使用这些数据，所以我们来删除这一行。
- en: Here’s the code where we indicate the row’s index.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们指明行索引的代码。
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The DataFrame now looks like this.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame现在看起来是这样的。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/9f2a0e5598824db43db0c0347be9f221.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![掌握Python数据清洗的艺术](../Images/9f2a0e5598824db43db0c0347be9f221.png)'
- en: The last row has been deleted, and our DataFrame now looks better. However,
    there are still some missing data which we’ll handle using another approach.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行已经被删除，我们的DataFrame现在看起来更好了。不过，仍然有一些缺失的数据，我们将使用另一种方法处理这些数据。
- en: Imputing Missing Values
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插补缺失值
- en: If you have significant missing data, a better strategy than deleting could
    be imputation. This process involves filling in missing values based on other
    data. For numerical data, common imputation methods involve using a measure of
    central tendency (mean, median, mode).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有显著缺失的数据，除了删除，另一种更好的策略是插补。这个过程涉及根据其他数据填充缺失值。对于数值数据，常见的插补方法包括使用集中趋势的度量（均值、中位数、众数）。
- en: In our already changed DataFrame, we have NaT (Not a Time) values in the columns
    advertisement_date and sale_date. We’ll impute these missing values using the
    **mean()** method.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们已经更改的DataFrame中，advertisement_date和sale_date列中有NaT（非时间）值。我们将使用**mean()**方法插补这些缺失值。
- en: The code uses the **fillna()** method to find and fill the null values with
    the mean value.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用**fillna()**方法查找并用均值填充空值。
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You can also do the same thing in one line of code. We use the **apply()** to
    apply the function defined using **lambda**. Same as above, this function uses
    the **fillna()** and **mean()** methods to fill in the missing values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以用一行代码完成相同的操作。我们使用**apply()**来应用用**lambda**定义的函数。与上述相同，这个函数使用**fillna()**和**mean()**方法填充缺失值。
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The output in both cases looks like this.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 两种情况下的输出如下所示。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/96cc85a9edbd5b5dc67ab39ab9774fab.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 中的数据清理艺术](../Images/96cc85a9edbd5b5dc67ab39ab9774fab.png)'
- en: Our sale_date column now has times which we don’t need. Let’s remove them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的sale_date列现在有一些我们不需要的时间。让我们把它们移除。
- en: We’ll use the **strftime()** method, which converts the dates to their string
    representation and a specific format.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用**strftime()**方法，它将日期转换为其字符串表示形式和特定格式。
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Mastering the Art of Data Cleaning in Python](../Images/e2b413dcdf2794b2dfce981d3964e274.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 中的数据清理艺术](../Images/e2b413dcdf2794b2dfce981d3964e274.png)'
- en: The dates now look all tidy.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在日期看起来都很整齐了。
- en: If you need to use **strftime()** on multiple columns, you can again use **lambda**
    the following way.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要在多个列上使用**strftime()**，你可以再次使用**lambda**，方法如下。
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, let’s see how we can impute missing categorical values.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何插补缺失的分类值。
- en: Categorical data is a type of data that is used to group information with similar
    characteristics. Each of these groups is a category. Categorical data can take
    on numerical values (such as "1" indicating "male" and "2" indicating "female"),
    but those numbers do not have mathematical meaning. You can't add them together,
    for instance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据是一种用于将信息分组的类型，每个组是一个类别。分类数据可以取数值（例如“1”表示“男”和“2”表示“女”），但这些数字没有数学意义。例如，你不能将它们相加。
- en: 'Categorical data is typically divided into two categories:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据通常分为两类：
- en: '**Nominal data:** This is when the categories are only labeled and cannot be
    arranged in any particular order. Examples include gender (male, female), blood
    type (A, B, AB, O), or color (red, green, blue).'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**名义数据：** 这是指类别仅仅被标记，不能按特定顺序排列。例如性别（男、女）、血型（A、B、AB、O）或颜色（红、绿、蓝）。'
- en: '**Ordinal data:** This is when the categories can be ordered or ranked. While
    the intervals between the categories are not equally spaced, the order of the
    categories has a meaning. Examples include rating scales (1 to 5 rating of a movie),
    an education level (high school, undergraduate, graduate), or stages of cancer
    (Stage I, Stage II, Stage III).'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**顺序数据：** 这是指类别可以被排序或排名。虽然类别之间的间隔不均等，但类别的顺序具有意义。例如评分尺度（电影的1到5评分）、教育水平（高中、本科、研究生）或癌症阶段（I期、II期、III期）。'
- en: For imputing missing categorical data, the mode is typically used. In our example,
    the column property_category is categorical (nominal) data, and there’s data missing
    in two rows.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于插补缺失的分类数据，通常使用众数。在我们的例子中，property_category列是分类（名义）数据，并且有两个行数据缺失。
- en: Let’s replace the missing values with mode.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用众数替换缺失值。
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This code uses the **fillna()** function to replace all the NaN values in the
    property_category column. It replaces it with mode.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用**fillna()**函数来替换property_category列中的所有NaN值。它用众数替代这些值。
- en: Additionally, the [0] part is used to extract the first value from this Series.
    If there are multiple modes, this will select the first one. If there's only one
    mode, it still works fine.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，[0] 部分用于从此系列中提取第一个值。如果存在多个众数，它将选择第一个。如果只有一个众数，它也会正常工作。
- en: Here’s the output.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/d5a4dc6cfbcae664ee2ba044bfc1cf82.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 中的数据清洗艺术](../Images/d5a4dc6cfbcae664ee2ba044bfc1cf82.png)'
- en: The data now looks pretty good. The only thing that’s remaining is to see if
    there are outliers.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据看起来相当不错。剩下的唯一任务是检查是否有异常值。
- en: You can practice dealing with nulls on this [Meta interview question](https://platform.stratascratch.com/coding/9790-find-the-number-of-processed-and-not-processed-complaints-of-each-type?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning),
    where you’ll have to replace NULLs with zeros.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个 [Meta 面试问题](https://platform.stratascratch.com/coding/9790-find-the-number-of-processed-and-not-processed-complaints-of-each-type?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)
    上练习处理空值，其中你需要将 NULL 替换为零。
- en: Dealing with Outliers
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理异常值
- en: Outliers are data points in a dataset that are distinctly different from the
    other observations. They may lie exceptionally far from the other values in the
    data set, residing outside an overall pattern. They're considered unusual due
    to their values either being significantly higher or lower compared to the rest
    of the data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是数据集中明显不同于其他观察值的数据点。它们可能远离数据集中其他值，位于整体模式之外。由于其值显著高于或低于其他数据点，它们被认为是不寻常的。
- en: 'Outliers can arise due to various reasons such as:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可能由于各种原因产生，例如：
- en: Measurement or input errors
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量或输入错误
- en: Data corruption
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据损坏
- en: True statistical anomalies
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实的统计异常
- en: Outliers can significantly impact the results of your data analysis and statistical
    modeling. They can lead to a skewed distribution, bias, or invalidate the underlying
    statistical assumptions, distort the estimated model fit, reduce the predictive
    accuracy of predictive models, and lead to incorrect conclusions.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可能会显著影响数据分析和统计建模的结果。它们可能导致分布偏斜、偏差，或使基本的统计假设无效，扭曲估计的模型拟合，降低预测模型的预测准确性，并导致不正确的结论。
- en: Some commonly used methods to detect outliers are Z-score, IQR (Interquartile
    Range), box plots, scatter plots, and data visualization techniques. In some advanced
    cases, machine learning methods are used as well.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常用的检测异常值的方法包括 Z-score、IQR（四分位距）、箱线图、散点图和数据可视化技术。在一些高级情况下，也会使用机器学习方法。
- en: Visualizing data can help identify outliers. Seaborn's boxplot is handy for
    this.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化可以帮助识别异常值。Seaborn 的箱线图在这方面很有用。
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We use the plt.figure() to set the width and height of the figure in inches.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 plt.figure() 设置图形的宽度和高度（以英寸为单位）。
- en: Then we create the boxplot for the columns advertised_price and sale_price,
    which looks like this.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们为广告价格和销售价格列创建箱线图，如下所示。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/eab301802d2a19402b4de84b5a41005f.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 中的数据清洗艺术](../Images/eab301802d2a19402b4de84b5a41005f.png)'
- en: The plot can be improved for easier use by adding this to the above code.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将此添加到上述代码来改进图表，以便更容易使用。
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We use the above code to set the labels for both axes. We also notice that the
    values on the y-axis are in the scientific notation, and we can’t use that for
    the price values. So we change this to plain style using the plt.ticklabel_format()
    function.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上述代码设置两个轴的标签。我们还注意到 y 轴上的值以科学记数法显示，而我们不能用这种方式显示价格值。因此，我们使用 plt.ticklabel_format()
    函数将其更改为普通样式。
- en: Then we create the formatter that will show the values on the y-axis with commas
    as thousand separators and decimal dots. The last code line applies this to the
    axis.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建格式化器，将 y 轴上的值显示为用逗号分隔的千位数和小数点。最后一行代码将其应用到轴上。
- en: The output now looks like this.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在输出结果如下。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/484a574270a0fdf86aa68c9650010659.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 中的数据清洗艺术](../Images/484a574270a0fdf86aa68c9650010659.png)'
- en: Now, how do we identify and remove the outlier?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何识别和去除异常值呢？
- en: One of the ways is to use the IQR method.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一种方法是使用 IQR 方法。
- en: IQR, or Interquartile Range, is a statistical method used to measure variability
    by dividing a data set into quartiles. Quartiles divide a rank-ordered data set
    into four equal parts, and values within the range of the first quartile (25th
    percentile) and the third quartile (75th percentile) make up the interquartile
    range.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: IQR，即四分位距，是一种统计方法，用于通过将数据集划分为四分位数来测量变异性。四分位数将按顺序排列的数据集分为四个相等的部分，第一个四分位数（25百分位数）和第三个四分位数（75百分位数）之间的值构成了四分位距。
- en: 'The interquartile range is used to identify outliers in the data. Here''s how
    it works:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 四分位距用于识别数据中的异常值。其工作原理如下：
- en: First, calculate the first quartile (Q1), the third quartile (Q3), and then
    determine the IQR. The IQR is computed as Q3 - Q1.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，计算第一个四分位数（Q1），第三个四分位数（Q3），然后确定IQR。IQR的计算公式是Q3 - Q1。
- en: Any value below Q1 - 1.5IQR or above Q3 + 1.5IQR is considered an outlier.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任何低于Q1 - 1.5IQR或高于Q3 + 1.5IQR的值都被视为异常值。
- en: On our boxplot, the box actually represents the IQR. The line inside the box
    is the median (or second quartile). The 'whiskers' of the boxplot represent the
    range within 1.5*IQR from Q1 and Q3.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的箱线图上，箱体实际上代表了IQR。箱体内的线是中位数（或第二四分位数）。箱线图的“胡须”表示距离Q1和Q3的1.5*IQR范围内的范围。
- en: Any data points outside these whiskers can be considered outliers. In our case,
    it’s the value of $12,000,000\. If you look at the boxplot, you’ll see how clearly
    this is represented, which shows why data visualization is important in detecting
    outliers.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 任何超出这些“胡须”的数据点都可以被视为异常值。在我们的案例中，就是$12,000,000的值。如果你查看箱线图，你会清楚地看到这一点，这显示了数据可视化在检测异常值中的重要性。
- en: Now, let’s remove the outliers by using the IQR method in Python code. First,
    we’ll remove the advertised price outliers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用Python代码中的IQR方法来去除异常值。首先，我们将去除advertised price的异常值。
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We first calculate the first quartile (or the 25th percentile) using the **quantile()**
    function. We do the same for the third quartile or the 75th percentile.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用**quantile()**函数计算第一个四分位数（即第25百分位数）。对第三个四分位数或第75百分位数也进行相同操作。
- en: They show the values below which 25% and 75% of the data fall, respectively.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 它们显示了25%和75%的数据分别落在的值。
- en: Then we calculate the difference between the quartiles. Everything so far is
    just translating the IQR steps into Python code.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算四分位数之间的差异。到目前为止，一切都是将IQR步骤转化为Python代码。
- en: As a final step, we remove the outliers. In other words, all data less than
    Q1 - 1.5 * IQR or more than Q3 + 1.5 * IQR.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，我们去除异常值。换句话说，去除所有小于Q1 - 1.5 * IQR或大于Q3 + 1.5 * IQR的数据。
- en: The '~' operator negates the condition, so we are left with only the data that
    are not outliers.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '''~''运算符否定条件，因此我们只保留不是异常值的数据。'
- en: Then we can do the same with the sale price.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以对sale price做同样的处理。
- en: '[PRE22]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Of course, you can do it in a more succinct way using the **for loop**.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你可以使用**for loop**以更简洁的方式实现。
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The loop iterates of the two columns. For each column, it calculates the IQR
    and then removes the rows in the DataFrame.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 循环遍历两列。对于每一列，它计算IQR，然后从数据框中删除相应的行。
- en: Please note that this operation is done sequentially, first for advertised_price
    and then for sale_price. As a result, the DataFrame is modified in-place for each
    column, and rows can be removed due to being an outlier in either column. Therefore,
    this operation might result in fewer rows than if outliers for advertised_price
    and sale_price were removed independently and the results were combined afterward.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这一操作是顺序进行的，首先处理advertised_price，然后处理sale_price。因此，数据框在每一列中都会就地修改，行可能会因为在任一列中是异常值而被删除。因此，这一操作可能导致行数少于分别去除advertised_price和sale_price中的异常值后再合并结果的行数。
- en: In our example, the output will be the same in both cases. To see how the box
    plot changed, we need to plot it again using the same code as earlier.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，两种情况的输出将是相同的。要查看箱线图的变化，我们需要使用之前相同的代码再次绘制。
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here’s the output.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果。
- en: '![Mastering the Art of Data Cleaning in Python](../Images/02a67feb20614804d7f213806b8ba6c4.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![掌握 Python 数据清理的艺术](../Images/02a67feb20614804d7f213806b8ba6c4.png)'
- en: You can practice calculating percentiles in Python by solving the [General Assembly
    interview question](https://platform.stratascratch.com/coding/9611-find-the-80th-percentile-of-hours-studied?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过解决[General Assembly 面试题](https://platform.stratascratch.com/coding/9611-find-the-80th-percentile-of-hours-studied?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)来练习在Python中计算百分位数。
- en: Conclusion
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Data cleaning is a crucial step in the data analysis process. Though it can
    be time-consuming, it's essential to ensure the accuracy of your findings.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理是数据分析过程中的一个关键步骤。尽管这可能很耗时，但确保发现的准确性至关重要。
- en: Fortunately, Python's rich ecosystem of libraries makes this process more manageable.
    We learned how to remove unnecessary rows and columns, reformat data, and deal
    with missing values and outliers. These are the usual steps that have to be performed
    on most any data. However, you’ll also sometimes need to [combine two columns
    into one](https://platform.stratascratch.com/coding/9834-combine-the-first-and-last-names-of-workers?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning),
    [verify the existing data](https://platform.stratascratch.com/coding/9737-verify-that-the-first-4-digits-are-equal-to-1415-for-all-phone-numbers?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning),
    [assign labels to it](https://platform.stratascratch.com/coding/9628-reviews-bins-on-reviews-number?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning),
    or [get rid of the white spaces](https://platform.stratascratch.com/coding/9818-file-contents-shuffle?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Python 丰富的库生态系统使这一过程更加可控。我们学习了如何删除不必要的行和列，重新格式化数据，并处理缺失值和异常值。这些是对大多数数据必须执行的常规步骤。然而，有时你还需要[将两列合并为一列](https://platform.stratascratch.com/coding/9834-combine-the-first-and-last-names-of-workers?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)、[验证现有数据](https://platform.stratascratch.com/coding/9737-verify-that-the-first-4-digits-are-equal-to-1415-for-all-phone-numbers?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)、[给数据分配标签](https://platform.stratascratch.com/coding/9628-reviews-bins-on-reviews-number?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)或[去除空白字符](https://platform.stratascratch.com/coding/9818-file-contents-shuffle?code_type=2&utm_source=blog&utm_medium=click&utm_campaign=kdn+data+cleaning)。
- en: All this is data cleaning, as it allows you to turn messy, real-world data into
    a well-structured dataset that you can analyze with confidence. Just compare the
    dataset we started with to the one we ended up with.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是数据清理，因为它使你能够将混乱的现实世界数据转化为一个结构良好的数据集，从而可以自信地进行分析。只需比较我们开始时的数据集和最终的数据集。
- en: If you don’t see the satisfaction in this result and the clean data doesn’t
    make you strangely excited, what in the world are you doing in data science!?
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这个结果不满意，干净的数据没有让你感到异常兴奋，那你在数据科学领域到底在做什么！？
- en: '[](https://twitter.com/StrataScratch)****[Nate Rosidi](https://twitter.com/StrataScratch)****
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of StrataScratch, a platform helping data scientists
    prepare for their interviews with real interview questions from top companies.
    Nate writes on the latest trends in the career market, gives interview advice,
    shares data science projects, and covers everything SQL.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://twitter.com/StrataScratch)****[内特·罗西迪](https://twitter.com/StrataScratch)****
    是一位数据科学家，专注于产品战略。他还是一名兼职教授，教授分析学，并且是 StrataScratch 的创始人，该平台帮助数据科学家通过顶级公司提供的真实面试问题准备面试。内特撰写有关职业市场的最新趋势，提供面试建议，分享数据科学项目，并涵盖所有
    SQL 相关内容。'
- en: More On This Topic
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Mastering the Art of Data Storytelling: A Guide for Data Scientists](https://www.kdnuggets.com/2023/06/mastering-art-data-storytelling-guide-data-scientists.html)'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据讲述的艺术：数据科学家的指南](https://www.kdnuggets.com/2023/06/mastering-art-data-storytelling-guide-data-scientists.html)'
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 SQL、Python、数据清理、数据整理与探索性数据分析的指南集合](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
- en: '[7 Steps to Mastering Data Cleaning with Python and Pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Python 和 Pandas 的数据清理的 7 个步骤](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Data storytelling - the art of telling stories through data](https://www.kdnuggets.com/2023/07/manning-data-storytelling-the-art-telling-stories-data.html)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据讲述 - 通过数据讲故事的艺术](https://www.kdnuggets.com/2023/07/manning-data-storytelling-the-art-telling-stories-data.html)'
- en: '[7 Steps to Master the Art of Data Storytelling](https://www.kdnuggets.com/7-steps-to-master-the-art-of-data-storytelling)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据故事讲述艺术的7个步骤](https://www.kdnuggets.com/7-steps-to-master-the-art-of-data-storytelling)'
