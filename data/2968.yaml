- en: Interpolation in Autoencoders via an Adversarial Regularizer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过对抗正则化器进行自编码器插值
- en: 原文：[https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html](https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html](https://www.kdnuggets.com/2019/03/interpolation-autoencoders-adversarial-regularizer.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By Taraneh Khazaei (Edited by Mahsa Rahimi & Serena McDonnell)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Taraneh Khazaei（编辑：Mahsa Rahimi & Serena McDonnell）**'
- en: '**A**dversarially **C**onstrained **A**utoencoder **I**nterpolation (ACAI; [Berthelot
    et al., 2018](https://arxiv.org/abs/1807.07543)) is a regularization procedure
    that uses an adversarial strategy to create high-quality interpolations of the
    learned representations in autoencoders. This paper makes three main contributions:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**对抗约束自编码器插值**（ACAI； [Berthelot et al., 2018](https://arxiv.org/abs/1807.07543)）是一种正则化程序，使用对抗策略来创建自编码器学习表示的高质量插值。本文做出了三项主要贡献：'
- en: Proposed ACAI to generate semantically meaningful autoencoder interpolations.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出了 ACAI 以生成语义上有意义的自编码器插值。
- en: Developed a synthetic benchmark to quantify the quality of interpolations.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发了一个合成基准来量化插值的质量。
- en: Examined the performance of ACAI learned representations on downstream tasks.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查了 ACAI 学习表示在下游任务中的表现。
- en: AISC recently presented and discussed this paper led by Mahsa Rahimi. The details
    of the event can be found on the [AISC website](https://aisc.a-i.science/events/2019-02-07/),
    and the full presentation can be viewed on [YouTube](https://www.youtube.com/watch?v=FdeHlC4QiqA&t=2871s).
    Here, we present an overview of the paper, along with the discussion points raised
    at the AISC session.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: AISC 最近介绍并讨论了由 Mahsa Rahimi 主导的这篇论文。事件的详细信息可以在 [AISC 网站](https://aisc.a-i.science/events/2019-02-07/)上找到，完整的演讲可以在 [YouTube](https://www.youtube.com/watch?v=FdeHlC4QiqA&t=2871s)上观看。这里，我们提供了对论文的概述，以及在
    AISC 会议上提出的讨论要点。
- en: '**Interpolations in Autoencoders**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**自编码器中的插值**'
- en: 'Autoencoders are a class of neural nets that attempt to output an approximate
    reconstruction of an input xx with minimal information loss. As an autoencoder
    is trained, it learns to encode the input data into a latent space, capturing
    all the information needed to reconstruct the output. An autoencoder consists
    of two parts, an encoder and a decoder, which can be described as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一类神经网络，试图输出一个输入 xx 的近似重建，尽量减少信息损失。随着自编码器的训练，它学习将输入数据编码到一个潜在空间中，捕捉重建输出所需的所有信息。自编码器由两个部分组成，编码器和解码器，描述如下：
- en: The encoder receives the input data ![Equation](../Images/08a1766df96545e32fa0502988b63a06.png)
    and generates a latent code ![Equation](../Images/452c25829bc32c9923984ddf8eb43fc5.png).
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器接收输入数据 ![Equation](../Images/08a1766df96545e32fa0502988b63a06.png) 并生成一个潜在代码 ![Equation](../Images/452c25829bc32c9923984ddf8eb43fc5.png)。
- en: The decoder receives the latent code ![Equation](../Images/ef86bd01daa526febbb16ae8422410f5.png) and
    attempts to reconstruct the input data as ![Equation](../Images/2fa129febcdcc7e0604d61daab66c3d8.png).
    The latent space is often of a lower dimension than the data (*m < n*).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器接收潜在代码 ![Equation](../Images/ef86bd01daa526febbb16ae8422410f5.png) 并尝试重建输入数据为 ![Equation](../Images/2fa129febcdcc7e0604d61daab66c3d8.png)。潜在空间通常维度低于数据（*m
    < n*）。
- en: '![](../Images/797a16d1970e8ea5e7caa7b8fd29343e.png)*The architecture of a standard
    autoencoder*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/797a16d1970e8ea5e7caa7b8fd29343e.png)*标准自编码器的架构*'
- en: Standard autoencoders focus on the reconstruction of the input x and barely
    learn the probabilistic features of the underlying dataset. As a result, they
    have very limited generative power. One approach that allows standard autoencoders
    to generate synthetic data is to facilitate interpolation by mixing the latent
    codes. However, the latent space learned by a regular autoencoder might not be
    continuous and may have large gaps between clusters of latent codes. Simply mixing
    the previously learned latent codes may result in interpolations that fall into
    regions that the decoder has never seen before, which may result in the creation
    of unrealistic data points. To mitigate this, the interpolation process needs
    to be integrated into the autoencoder architecture and its training, allowing
    the autoencoder to learn the underlying data manifold and to create meaningful
    interpolations. By borrowing ideas from Generative Adversarial Networks ([Goodfellow
    et al., 2014](https://papers.nips.cc/paper/5423-generative-adversarial-nets)),
    ACAI effectively integrates the interpolation process into the autoencoder architecture. [Berthelot
    et al. (2018](https://arxiv.org/abs/1807.07543)) propose a method that can create
    high-quality interpolations that are both indistinguishable from real data, and
    are a semantically meaningful combination of the inputs. We explain the ACAI approach
    in detail below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 标准自编码器关注于输入x的重建，并且几乎没有学习潜在数据集的概率特征。因此，它们的生成能力非常有限。一个允许标准自编码器生成合成数据的方法是通过混合潜在编码来促进插值。然而，常规自编码器学到的潜在空间可能不连续，并且潜在编码的簇之间可能存在较大的间隙。简单地混合先前学到的潜在编码可能会导致插值落入解码器从未见过的区域，从而产生不现实的数据点。为了解决这个问题，需要将插值过程集成到自编码器架构及其训练中，使自编码器能够学习潜在的数据流形并创建有意义的插值。通过借鉴生成对抗网络的理念（[Goodfellow
    et al., 2014](https://papers.nips.cc/paper/5423-generative-adversarial-nets)），ACAI有效地将插值过程集成到自编码器架构中。
    [Berthelot et al. (2018)](https://arxiv.org/abs/1807.07543) 提出了一种方法，能够创建高质量的插值，这些插值不仅与真实数据无差异，而且是输入的语义上有意义的组合。我们将在下面详细解释ACAI方法。
- en: '![alt_text](../Images/70ed176d4a1a36cad0b2397f356e39d9.png)*A visualization
    of the latent codes on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset
    showing the discontinuity of the latent space.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![alt_text](../Images/70ed176d4a1a36cad0b2397f356e39d9.png)*潜在编码在[MNIST](http://yann.lecun.com/exdb/mnist/)数据集上的可视化，展示了潜在空间的不连续性。*'
- en: '*To read more on the continuity of the latent space you can read this [blog
    post](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf).*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*要了解更多关于潜在空间连续性的内容，你可以阅读这篇[博客文章](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)。*'
- en: '**Adversarially Constrained Autoencoder Interpolation (ACAI)**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**对抗约束自编码器插值（ACAI）**'
- en: 'To interpolate two inputs ![Equation](../Images/b1c048a322cdd946dd237ec663a89591.png) and ![Equation](../Images/74990a2016e1ee9d8bbda70beada905e.png),
    ACAI performs the following steps:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要插值两个输入 ![Equation](../Images/b1c048a322cdd946dd237ec663a89591.png) 和 ![Equation](../Images/74990a2016e1ee9d8bbda70beada905e.png)，ACAI
    执行以下步骤：
- en: Using two encoders, ![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png) and ![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)​ are
    first encoded into the corresponding latent codes ![Equation](../Images/b46e009f9938818ff1afc4d7a6fd45da.png)​ and ![Equation](../Images/58026cfc461745fdde6a8f91a04d58dc.png)​ where ![Equation](../Images/8cf3e7845f3984dc469a57c79175e1b5.png) and ![Equation](../Images/11803a4badb4bcc13a9cf3d15e9ec1c7.png).
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用两个编码器， ![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png) 和 ![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)
    首先被编码为相应的潜在编码 ![Equation](../Images/b46e009f9938818ff1afc4d7a6fd45da.png) 和 ![Equation](../Images/58026cfc461745fdde6a8f91a04d58dc.png)，其中
    ![Equation](../Images/8cf3e7845f3984dc469a57c79175e1b5.png) 和 ![Equation](../Images/11803a4badb4bcc13a9cf3d15e9ec1c7.png)。
- en: The two latent codes are then interpolated via a convex combination ![Equation](../Images/d07e9dffa1acc972c7c4d01927acefc1.png)
    ​for some ![Equation](../Images/39a12604c9cccd8b5ab9e2e4c42b13af.png).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过凸组合 ![Equation](../Images/d07e9dffa1acc972c7c4d01927acefc1.png) 对两个潜在编码进行插值，某些
    ![Equation](../Images/39a12604c9cccd8b5ab9e2e4c42b13af.png)。
- en: The convex combination ![Equation](../Images/96e5cf2e6344fbc505bf80fe17c4865d.png) is
    then passed through a decoder to generate the interpolated data point, where ![Equation](../Images/27347138f718c2bdbe33ba946c7b53d6.png).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 凸组合 ![Equation](../Images/96e5cf2e6344fbc505bf80fe17c4865d.png) 然后通过解码器生成插值数据点，其中
    ![Equation](../Images/27347138f718c2bdbe33ba946c7b53d6.png)。
- en: Finally, to ensure that interpolations are realistic, the decoded interpolation ![Equation](../Images/543b8d9d742e7610cfb57c36c2719dea.png)​ is
    passed through a critic network. The goal of the critic network is to predict
    the mixing coefficient α from the interpolated data point ![Equation](../Images/543b8d9d742e7610cfb57c36c2719dea.png)​.
    The autoencoder is then trained to fool the critic network into thinking that ![Equation](../Images/43e99db5ec6f22a289330e918c378936.png) is
    always 0, meaning that it attempts to fool the critic network into thinking the
    interpolated data is actually non-interpolated.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，为了确保插值的真实性，解码后的插值 ![方程](../Images/543b8d9d742e7610cfb57c36c2719dea.png)​ 会通过一个判别器网络。判别器网络的目标是从插值数据点 ![方程](../Images/543b8d9d742e7610cfb57c36c2719dea.png)​中预测混合系数 α。然后，自动编码器被训练以欺骗判别器网络，使其认为 ![方程](../Images/43e99db5ec6f22a289330e918c378936.png) 始终为0，即尝试欺骗判别器网络，使其认为插值数据实际上是非插值的。
- en: 'Fooling the critic network is achieved by adding a term to the autoencoder''s
    loss function. In ACAI, the encoders and the decoder are trained to minimize the
    following loss function:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向自动编码器的损失函数添加一项来实现欺骗判别器网络。在ACAI中，编码器和解码器被训练以最小化以下损失函数：
- en: '![Equation](../Images/d547dc6d6a4588c7763d028028ef4cdf.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![方程](../Images/d547dc6d6a4588c7763d028028ef4cdf.png)'
- en: 'where λ is a scalar hyperparameter that can be used to control the weight of
    the regularization term on the right, and ![Equation](../Images/f8743f0ceed8189e9ae6c840b7674466.png) is
    the critic network parametrized by ![Equation](../Images/60af46ed1b6f6b52591c7c61f7e33396.png).
    The first term of the loss function attempts to reconstruct the input, and the
    second term tries to make the critic network output 0 at all times. The critic
    network is trained to optimize the following loss function:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 λ 是一个标量超参数，可以用来控制右侧正则化项的权重，而 ![方程](../Images/f8743f0ceed8189e9ae6c840b7674466.png) 是由 ![方程](../Images/60af46ed1b6f6b52591c7c61f7e33396.png) 参数化的判别器网络。损失函数的第一个项试图重建输入，第二项则试图使判别器网络始终输出0。判别器网络被训练以优化以下损失函数：
- en: '![Equation](../Images/b670d0df49217a7b220d7629c47ef497.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![方程](../Images/b670d0df49217a7b220d7629c47ef497.png)'
- en: where ![Equation](../Images/3ed6fc16fb7ad00b363f9819c310dc0b.png) is a scalar
    hyperparameter. The first term of the loss function attempts to recover ![Equation](../Images/43e99db5ec6f22a289330e918c378936.png).
    The second term is a regularization term that is not crucial for creating high-quality
    interpolations but helps with the adversarial learning process in two ways. First,
    it enforces the critic to consistently output 0 for non-interpolated data; and
    second, it ensures that the critic is exposed to realistic data even when the
    autoencoder reconstructions are of poor quality.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![方程](../Images/3ed6fc16fb7ad00b363f9819c310dc0b.png) 是一个标量超参数。损失函数的第一个项试图恢复 ![方程](../Images/43e99db5ec6f22a289330e918c378936.png)。第二项是正则化项，对于创建高质量插值并非至关重要，但在对抗学习过程中有两方面的帮助。首先，它强制判别器对非插值数据始终输出0；其次，即使自动编码器的重建质量较差，它也确保判别器接触到真实的数据。
- en: When the algorithm converges, the interpolated points are expected to be indistinguishable
    from real data. Empirically, the authors show that the learned interpolations
    are semantically smooth interpolations of the two inputs ![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)​ and ![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)​.
    Evaluation results on a set of clustering and classification tasks show that the
    ACAI learned representations are more effective on downstream tasks than non-ACAI
    learned representations. Given the improved performance on the downstream tasks,
    the authors note that there may be a connection between interpolation and representation
    learning.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法收敛时，期望插值点与真实数据难以区分。经验上，作者展示了学到的插值是两个输入 ![方程](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)​ 和 ![方程](../Images/1796c6ec8e88657dc036f34bea536f8d.png)​的语义平滑插值。在一组聚类和分类任务上的评估结果表明，ACAI学到的表示在下游任务上比非-ACAI学到的表示更有效。鉴于下游任务的性能提升，作者指出插值和表示学习之间可能存在联系。
- en: '![alt_text](../Images/6ff82a3742c8abff8495756ea7e843df.png)*The ACAI Architecture*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![alt_text](../Images/6ff82a3742c8abff8495756ea7e843df.png)*ACAI架构*'
- en: '**Benchmark Development**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**基准开发**'
- en: 'The concept of semantic similarity is ambiguous, ill-defined, and difficult
    to quantify. Another contribution of this paper is to define a benchmark to quantitatively
    evaluate the quality of interpolations. Their benchmark is focused on the task
    of autoencoding ![Equation](../Images/9d3aa90567a62dd42e196dc3205ef57b.png) greyscale
    images of lines. The lines are 1616-pixels long, beginning from the center of
    the image and extending outward at an angle ![Equation](../Images/2d7dacbe34efdfa4efa9ea4e17489a21.png),
    with a single line per image. Using this data, a valid interpolation between ![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)​ and ![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)​ is
    an image of a line that smoothly and linearly adjusts ![Equation](../Images/1f3886f59db4be974a13b9d9bafda729.png) from
    the angle of the line in ![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)​ to
    the angle of the line in ![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)​ while
    traversing the shortest path. Using these images, the following two criteria can
    be easily calculated and are used to evaluate the interpolation capability of
    different autoencoders:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 语义相似性的概念模糊、不明确且难以量化。本文的另一项贡献是定义一个基准来定量评估插值的质量。他们的基准集中在自编码![Equation](../Images/9d3aa90567a62dd42e196dc3205ef57b.png)灰度图像的任务上。这些线条长为1616像素，从图像中心开始，向外延伸，角度为![Equation](../Images/2d7dacbe34efdfa4efa9ea4e17489a21.png)，每张图像上有一条线。利用这些数据，一个有效的插值应是从![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)到![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)的图像，平滑且线性地调整![Equation](../Images/1f3886f59db4be974a13b9d9bafda729.png)从![Equation](../Images/0ed13cb405f614a66e1f5d11a70fe343.png)中的线条角度到![Equation](../Images/1796c6ec8e88657dc036f34bea536f8d.png)中的线条角度，同时沿最短路径遍历。使用这些图像，可以轻松计算以下两个标准，并用于评估不同自编码器的插值能力：
- en: 'Mean distance: measures the average distance between the interpolated points
    and real data points.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平均距离：衡量插值点与真实数据点之间的平均距离。
- en: 'Smoothness: measures whether the angles of the interpolated lines follow a
    linear trajectory between the start and endpoint.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平滑度：衡量插值线的角度是否在起点和终点之间遵循线性轨迹。
- en: An ideal interpolation would achieve 0 for both scores. An example of an ideal
    interpolation between \piπ and 00 is shown below.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的插值应使两项评分都达到0。以下是\piπ与00之间理想插值的示例。
- en: '![alt_text](../Images/1e9a50982e67d482bb91e7917e096a3f.png)*A perfect interpolation
    from ![Equation](../Images/bd8436edea644bce071fabf769a0fbf7.png) to 0*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![alt_text](../Images/1e9a50982e67d482bb91e7917e096a3f.png)*从![Equation](../Images/bd8436edea644bce071fabf769a0fbf7.png)到0的完美插值*'
- en: Using this benchmark, it is shown that ACAI substantially outperforms common
    autoencoder models (e.g., denoising and variational autoencoders) for the task
    of generating realistic and semantically meaningful interpolations.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个基准，结果显示ACAI在生成现实且具有语义意义的插值任务中显著优于常见的自编码器模型（如去噪自编码器和变分自编码器）。
- en: '**AISC Discussions**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**AISC讨论**'
- en: In the AISC session, a set of [discussion points](https://youtu.be/Tu3FqCD7-BY?t=3513) were
    raised, which can be used as pointers for future work and experimentation on autoencoder
    interpolation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在AISC会议中，提出了一系列[讨论点](https://youtu.be/Tu3FqCD7-BY?t=3513)，可以作为未来工作和自编码器插值实验的参考。
- en: First, the classification and clustering evaluations of ACAI representations
    are conducted on three different datasets: [MNIST](http://yann.lecun.com/exdb/mnist/), [SVHN](http://ufldl.stanford.edu/housenumbers/),
    and [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). While the results
    for both clustering and classification tasks are reasonable for the two simpler
    datasets (i.e., MNIST and SVHN), the classification improvement on CIFAR is not
    nearly as significant, and the CIFAR clustering outcome is poor for all of the
    autoencoders, including ACAI. AISC brought up the idea of extending ACAI to be
    more effective on complicated datasets.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，对三种不同数据集上的ACAI表示进行了分类和聚类评估：[MNIST](http://yann.lecun.com/exdb/mnist/)、[SVHN](http://ufldl.stanford.edu/housenumbers/)和[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)。虽然对于两个较简单的数据集（即MNIST和SVHN），分类和聚类任务的结果都比较合理，但在CIFAR上的分类改进并不显著，而且所有自编码器（包括ACAI）在CIFAR上的聚类结果都很差。AISC提出了将ACAI扩展以在复杂数据集上更有效的想法。
- en: Second, the ACAI paper primarily focuses on computer vision tasks and even defines
    high-quality interpolations based on visual attributes of images. It would be
    extremely valuable to explore how ACAI and the benchmark could be extended to
    benefit non-visual tasks such as text interpolation. Finally, in this paper, the
    regularization procedure is applied to a vanilla autoencoder. It would be worth
    exploring the effects of using a similar regularization mechanism on other types
    of autoencoders. In particular, the possibility of improving the generative power
    of [variational autoencoders using the same idea was discussed in the AISC session](https://youtu.be/Tu3FqCD7-BY?t=3574).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，ACAI 论文主要关注计算机视觉任务，甚至根据图像的视觉属性定义了高质量的插值。探索 ACAI 和基准如何扩展以惠及非视觉任务如文本插值，将极具价值。最后，本文将正则化过程应用于普通自编码器。值得探索使用类似正则化机制对其他类型自编码器的影响。特别是，[使用相同思想改进变分自编码器的生成能力在
    AISC 会议中进行了讨论](https://youtu.be/Tu3FqCD7-BY?t=3574)。
- en: '**Additional Resources:**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**附加资源:**'
- en: The datasets they evaluated ACAI on are [MNIST](http://yann.lecun.com/exdb/mnist/), [SVHN](http://ufldl.stanford.edu/housenumbers/),
    and [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), all of which are
    publicly available.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们评估 ACAI 的数据集包括 [MNIST](http://yann.lecun.com/exdb/mnist/)、[SVHN](http://ufldl.stanford.edu/housenumbers/)
    和 [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)，这些数据集都是公开可用的。
- en: An implementation of ACAI in Tensoflow is available on [GitHub](https://github.com/brain-research/acai).
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACAI 在 TensorFlow 的实现可以在 [GitHub](https://github.com/brain-research/acai) 上找到。
- en: '[Original](https://aisc.a-i.science/blog/2019/acai-interpolation-autoencoders-adversarial-regularizer/).
    Reposted with permission.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://aisc.a-i.science/blog/2019/acai-interpolation-autoencoders-adversarial-regularizer/)。经许可转载。'
- en: '**Related:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[GANs Need Some Attention, Too](/2019/03/gans-need-some-attention-too.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GAN 也需要一些关注](/2019/03/gans-need-some-attention-too.html)'
- en: '[Variational Autoencoders Explained in Detail](/2018/11/variational-autoencoders-explained.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[变分自编码器详解](/2018/11/variational-autoencoders-explained.html)'
- en: '[Breaking neural networks with adversarial attacks](/2019/03/breaking-neural-networks-adversarial-attacks.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用对抗攻击突破神经网络](/2019/03/breaking-neural-networks-adversarial-attacks.html)'
- en: '* * *'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的信息技术工作'
- en: '* * *'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How to Deal with Missing Data Using Interpolation Techniques in Pandas](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Pandas 中的插值技术处理缺失数据](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)'
- en: '[What is Adversarial Machine Learning?](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是对抗机器学习？](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
