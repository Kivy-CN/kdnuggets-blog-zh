- en: 'Not Only for Deep Learning: How GPUs Accelerate Data Science & Data Analytics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/07/deep-learning-gpu-accelerate-data-science-data-analytics.html](https://www.kdnuggets.com/2021/07/deep-learning-gpu-accelerate-data-science-data-analytics.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![blog-gpu-powered-data-sci.jpg](../Images/07154ebf2b03cd01e5098fa0563117c2.png)'
  prefs: []
  type: TYPE_IMG
- en: How GPUs Accelerate Data Science & Data Analytics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '[Artificial intelligence (AI)](https://www.exxactcorp.com/Deep-Learning-AI-Workstations) is
    set to transform global productivity, working patterns, and lifestyles and create
    enormous wealth. Research firm Gartner expects the global AI economy to increase
    from about $1.2 trillion last year to about [$3.9 Trillion by 2022](https://www.forbes.com/sites/alexknapp/2018/04/25/gartner-estimates-ai-business-value-to-reach-nearly-4-trillion-by-2022/#3eb979af33f9),
    while McKinsey sees it delivering global economic activity of around [$13 trillion
    by 2030](https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy).
    In many ways, at its core, this transformation is fueled by powerful Machine Learning
    (ML) tools and techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: It is now well established that the modern AI/ML systems’ success has been critically
    dependent on their ability to **process massive amounts of raw data in a parallel
    fashion using task-optimized hardware**. Therefore, use of specialized hardware
    like Graphics Processing Units (GPUs) played a significant role in this early
    success. Since then, a lot of emphasis has been given on building highly optimized
    software tools and customized mathematical processing engines (both hardware and
    software) to leverage the power and architecture of GPUs and parallel computing.
  prefs: []
  type: TYPE_NORMAL
- en: While the use of GPUs and distributed computing is widely discussed in the academic
    and business circles for core AI/ML tasks (e.g. running a 100-layer deep neural
    network for image classification or billion-parameter BERT speech synthesis model),
    they find less coverage when it comes to their utility for regular data science
    and data engineering tasks. These **data-related tasks are the essential precursor
    to any ML workload in an AI pipeline** and they often constitute a majority percentage
    of the time and intellectual effort spent by a data scientist or even a ML engineer.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, recently, the famous AI pioneer Andrew Ng talked about **moving from
    a model-centric to a data-centric approach for AI** tools development. This means
    spending much more time with the raw data and preprocessing it before an actual
    AI workload executes on your pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can watch Andrew’s interview here: [https://www.youtube.com/watch?v=06-AZXmwHjo](https://www.youtube.com/watch?v=06-AZXmwHjo)'
  prefs: []
  type: TYPE_NORMAL
- en: '[![Andrew Ng](../Images/7235770bd4f35c50a0d74c8cec143ab6.png)](https://www.youtube.com/watch?v=06-AZXmwHjo)'
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to an important question...
  prefs: []
  type: TYPE_NORMAL
- en: '***Can we leverage the power of GPU and distributed computing for regular data
    processing jobs too***?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The answer is not trivial, and needs some special consideration and knowledge
    sharing. In this article, we will try to show some of the tools and platforms
    that can be used for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e31b35c45a2a4555907cbaa70e2c216d.png)'
  prefs: []
  type: TYPE_IMG
- en: '[***Image source***](https://pixabay.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'RAPIDS: Leverage GPU for Data Science'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The [RAPIDS](https://www.nvidia.com/en-us/deep-learning-ai/software/rapids/) suite
    of open source software libraries and APIs gives you the ability to execute end-to-end
    data science and analytics pipelines entirely on GPUs. NVIDIA incubated this project
    and built tools to take advantage of CUDA primitives for low-level compute optimization.
    It specifically focuses on **exposing GPU parallelism and high-bandwidth memory
    speed features through the friendly Python language** popular with all the data
    scientists and analytics professionals.
  prefs: []
  type: TYPE_NORMAL
- en: '**Common data preparation and wrangling tasks** are highly valued in the RAPIDS
    ecosystem as they take up a significant amount of time in a typical data science
    pipeline. A familiar **dataframe-like API** has been developed with a lot of optimization
    and robustness built-in. It has also been customized to integrate with a variety
    of ML algorithms for end-to-end pipeline accelerations with incurring serialization
    costs.'
  prefs: []
  type: TYPE_NORMAL
- en: RAPIDS also includes a significant amount of internal **support for multi-node,
    multi-GPU deployment and distributed processing**. It integrates with other libraries
    which make **out-of-memory** (i.e. dataset size larger than individual computer
    RAM) data processing easy and accessible for individual data scientists.
  prefs: []
  type: TYPE_NORMAL
- en: Here are the most prominent libraries that are included in the RAPIDS ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: CuPy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A CUDA-powered array library that looks and feels like Numpy, the foundation
    of all numerical computing and ML with Python. It uses CUDA-related libraries
    including cuBLAS, cuDNN, cuRand, cuSolver, cuSPARSE, cuFFT and NCCL to make full
    use of the GPU architecture with the goal of providing GPU-accelerated computing
    with Python.
  prefs: []
  type: TYPE_NORMAL
- en: CuPy’s interface is highly similar to that of NumPy and can be used as a simple
    drop-in replacement for most use cases. Here is the module-level detailed list
    of API compatibility between CuPy and NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: '**View the **[**CuPy Comparison Table**](https://docs.cupy.dev/en/stable/reference/comparison.html).'
  prefs: []
  type: TYPE_NORMAL
- en: The speedup over NumPy can be mind-boggling depending on the data type and use
    case. Here is a speedup comparison between CuPy and NumPy for two different array
    sizes and for various common numerical operations - FFT, slicing, sum and standard
    deviation, matrix multiplication, SVD - that are widely used by almost all ML
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7cafdff12da11b520bcd5d0c7dda62dd.png)'
  prefs: []
  type: TYPE_IMG
- en: '*CuPy speeds compared to NumPy, [**Image source**](https://cupy.dev/)*'
  prefs: []
  type: TYPE_NORMAL
- en: CuDF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Built based on the Apache Arrow columnar memory format, cuDF is a GPU DataFrame
    library for loading, joining, aggregating, filtering, and otherwise manipulating
    data. It provides a **pandas-like API** that will be familiar to almost all data
    engineers & data scientists, so they can use it to easily accelerate their workflows
    using powerful GPUs without going into the details of CUDA programming.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, cuDF is supported only on Linux, and with Python versions 3.7 and
    later. Other requirements are,
  prefs: []
  type: TYPE_NORMAL
- en: CUDA 11.0+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NVIDIA driver 450.80.02+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pascal architecture or better (Compute Capability >=6.0)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**View more about this powerful library in the **[**API docs for CuDF**](https://docs.rapids.ai/api/cudf/stable/10min.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, **data scientists and analysts (i.e. those who do not necessarily use **[**deep
    learning**](https://www.exxactcorp.com/Deep-Learning-Solutions)** in any of their
    daily tasks) can rejoice and use powerful AI-workstations** like the following
    to enhance their productivity.
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/c55732dbec760a86470752b9ea89de6b.png)](https://www.exxactcorp.com/NVIDIA-Data-Science-Workstations)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data science workstation from Exxact Corporation, [**Image source**](https://www.exxactcorp.com/NVIDIA-Data-Science-Workstations)*'
  prefs: []
  type: TYPE_NORMAL
- en: CuML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: cuML enables data scientists, analysts, and researchers to run traditional/
    classical ML algorithmic tasks with (mostly) tabular datasets on GPUs without
    going into the details of CUDA programming. In most cases, cuML's Python API matches
    that of the popular Python library Scikit-learn to make the transition to GPU
    hardware fast and painless.
  prefs: []
  type: TYPE_NORMAL
- en: '**View the **[**GitHub repo for CuML**](https://github.com/rapidsai/cuml)** documentation
    to learn more**.'
  prefs: []
  type: TYPE_NORMAL
- en: CuML also integrates with [**Dask**](https://docs.dask.org/en/latest/), wherever
    it can, to offer **multi-GPU and multi-node-GPU support** for an ever-increasing
    set of algorithms that takes advantage of such distributed processing.
  prefs: []
  type: TYPE_NORMAL
- en: CuGraph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CuGraph is a collection of GPU accelerated graph algorithms that process data
    found in [GPU DataFrames](https://github.com/rapidsai/cudf). The vision of cuGraph
    is to make graph analysis ubiquitous to the point that users just think in terms
    of analysis and not technologies or frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Data scientists familiar with Python will quickly pick up how cuGraph integrates
    with the Pandas-like API of cuDF. Likewise, users familiar with NetworkX will
    quickly recognize the NetworkX-like API provided in cuGraph, with the goal to
    allow existing code to be ported with minimal effort into RAPIDS.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, it supports all kinds of graph analytics algorithms,
  prefs: []
  type: TYPE_NORMAL
- en: Centrality
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Link analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Link prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traversal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many scientific and business analytics tasks involve use of extensive graph
    algorithms on large datasets. Libraries like cuGraph **lend the assurance of higher
    productivity to those engineers when they invest in GPU-powered workstations**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ecbba5c74b20d8bed538c95264f9a2aa.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Empower social graph analytics using GPU-accelerated computing, [Image source](https://pixabay.com/vectors/social-media-connections-networking-3846597/)*'
  prefs: []
  type: TYPE_NORMAL
- en: The Overall Pipeline for GPU Data Science
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RAPIDS envisions a whole pipeline for GPU-powered data science task flow as
    follows. Note that **deep learning, which has traditionally been the primary focus
    of GPU-based computing, is only a sub-component of this system**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70d3d196012e7424b8b486f890b4597e.png)'
  prefs: []
  type: TYPE_IMG
- en: '*The GPU Data Science Pipeline, [**Image source**](https://github.com/rapidsai/cuml/blob/branch-21.06/img/rapids_arrow.png)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dask: Distributed Analytics With Python'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we observed, modern data processing pipelines can often benefit from distributed
    processing of large data chunks. **This is slightly different from the parallelism
    offered by the thousands of cores in a single GPU**. This is more about how to
    split up a mundane data processing (which may occur much before the dataset is
    ready for ML algorithms) into chunks and process in using multiple compute nodes.
  prefs: []
  type: TYPE_NORMAL
- en: These computing nodes can be GPU cores or they can even be simple logical/ virtual
    cores of CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'By design, **most widely popular data science libraries like Pandas, Numpy,
    and Scikit-learn cannot take advantage of truly distributed processing easily**.
    Dask tries to solve this problem by bringing the features of intelligent task
    scheduling and big data chunk handling into regular Python code. Naturally, it
    is composed of two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamic task scheduling** optimized for computation. This is similar to Airflow,
    Luigi, Celery, or Make, but optimized for interactive computational workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**“Big Data” collections** like parallel arrays, dataframes, and lists that
    extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory
    or distributed environments. These parallel collections run on top of the aforementioned
    dynamic task schedulers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here is an illustrative diagram of a typical Dask task-flow.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f4a371fd406b4b55329d1715b20c402d.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Official Dask Flow Documentation, [**Image source**](https://docs.dask.org/en/latest/)*'
  prefs: []
  type: TYPE_NORMAL
- en: Easy to Convert Existing Codebase
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Familiarity is at the core of the Dask design, so that a typical data scientist
    can **just pick up his/her existing Pandas/Numpy based codebase and convert it
    to Dask code** following a minimal learning curve. Here are some of the canonical
    examples from their official documentation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fb3e45f22b1f3905e38348c90c93b831.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Dask Documentation comparing Pandas and NumPy, [**Image source**](https://docs.dask.org/en/latest/)*'
  prefs: []
  type: TYPE_NORMAL
- en: Dask-ML for Scalability Challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are different kinds of scalability challenges for ML engineers. The following
    figure illustrates them. The machine learning library Dask-ML offers something
    for each of these scenarios. Therefore, one can focus on either model-centric
    exploration or data-centric development based on the unique business or research
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, focus on familiarity again plays a role here and the DASK-ML
    API is designed to mimic that of the widely popular Scikit-learn API.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b60d07be82d1c73fd76738e4b038ff1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Dask Documentation for XGBRegressor, [**Image source**](https://docs.dask.org/en/latest/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/39a657db5d7acaaacc326946cddc9a36.png)'
  prefs: []
  type: TYPE_IMG
- en: Dask Benefits from Multi-Core CPU Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is to be noted that the primary attractiveness of Dask comes from its role
    as a high-level, efficient task scheduler that can work with any Python code or
    data structure. Consequently, it is not dependent on a GPU to boost existing data
    science workloads with distributed processing.
  prefs: []
  type: TYPE_NORMAL
- en: Even multi-core CPU systems can take full advantage of Dask if the code is written
    to focus on that. Major changes in the code are not required.
  prefs: []
  type: TYPE_NORMAL
- en: You can distribute your convex optimization routine or hyperparameter search
    among many cores of your laptop using Dask. Or, you can just process different
    parts of a simple DataFrame based on some filtering criteria using the full multi-core
    parallelism. This opens up the possibility of boosting the productivity of all
    the data scientists and analysts who do not need to buy expensive graphics cards
    for their machine but can just invest in a [workstation](https://www.exxactcorp.com/NVIDIA-Data-Science-Workstations) with
    16 or 24 CPU cores.
  prefs: []
  type: TYPE_NORMAL
- en: Summary of Distributed Data Science Powered by GPUs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this article, we discussed some exciting new developments in the Python data
    science ecosystem which enables common data scientists, analysts, science researchers,
    academics, to use GPU-powered hardware systems for a much wider variety of data
    related tasks than just what is related to image classification and natural language
    processing. This will surely broaden the appeal of such hardware systems to these
    large sections of users and democratize the data science user base even more.
  prefs: []
  type: TYPE_NORMAL
- en: We also touched upon the possibilities of distributed analytics with the Dask
    library which can leverage multi-core CPU workstations.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, this kind of convergence of powerful hardware and modern software
    stack will open up endless possibilities for highly efficient data science workflows.
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/using-gpus-for-data-science).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[How to Use NVIDIA GPU Accelerated Libraries](/2021/07/nvidia-gpu-accelerated-libraries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Good-bye Big Data. Hello, Massive Data!](/2020/10/sqream-massive-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Abstraction and Data Science: Not a great combination](/2021/07/abstraction-data-science-not-great-combination.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
