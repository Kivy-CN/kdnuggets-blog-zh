- en: Beginner’s Guide to Machine Learning Testing With DeepChecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/beginners-guide-to-machine-learning-testing-with-deepchecks](https://www.kdnuggets.com/beginners-guide-to-machine-learning-testing-with-deepchecks)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Beginner’s Guide to Machine Learning Testing With DeepChecks cover image](../Images/4044f479fcdea590b166dc7a2be4d384.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author | Canva
  prefs: []
  type: TYPE_NORMAL
- en: '[DeepChecks](https://github.com/deepchecks/deepchecks) is a Python package
    that provides a wide variety of built-in checks to test for issues with model
    performance, data distribution, data integrity, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we will learn about DeepChecks and use it to validate the
    dataset and test the trained machine learning model to generate a comprehensive
    report. We will also learn to test models on specific tests instead of generating
    full reports.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need Machine Learning Testing?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning testing is essential for ensuring the reliability, fairness,
    and security of AI models. It helps verify model performance, detect biases, enhance
    security against adversarial attacks especially in Large Language Models (LLMs),
    ensure regulatory compliance, and enable continuous improvement. Tools like Deepchecks
    provide a comprehensive testing solution that addresses all aspects of AI and
    ML validation from research to production, making them invaluable for developing
    robust, trustworthy AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with DeepChecks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this getting started guide, we will load the dataset and perform a data integrity
    test. This critical step ensures that our dataset is reliable and accurate, paving
    the way for successful model training.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by installing the DeepChecks Python package using the `pip` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Import essential Python packages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the dataset using the pandas library, which consists of 569 samples and
    30 features. The [Cancer classification](https://www.kaggle.com/datasets/sahilnbajaj/cancer-classification)
    dataset is derived from digitized images of fine needle aspirates (FNAs) of breast
    masses, where each feature represents a characteristic of the cell nuclei present
    in the image. These features enable us to predict whether the cancer is benign
    or malignant.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the dataset into training and testing using the target column 'benign_0__mal_1'.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Create the DeepChecks dataset by providing additional metadata. Since our dataset
    has no categorical features, we leave the argument empty.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Run the data integrity test on the train dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It will take a few second to generate the report.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data integrity report contains test results on:'
  prefs: []
  type: TYPE_NORMAL
- en: Feature-Feature Correlation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature-Label Correlation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single Value in Column
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Special Characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mixed Nulls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mixed Data Types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String Mismatch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Duplicates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String Length Out Of Bounds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conflicting Labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outlier Sample Detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![data validation report](../Images/865a79fad12a02046b532cd134f5486a.png)'
  prefs: []
  type: TYPE_IMG
- en: Machine Learning Model Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s train our model and then run a model evaluation suite to learn more about
    model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Load the essential Python packages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build three machine learning models (Logistic Regression, Random Forest Classifier,
    and Gaussian NB).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensemble them using the voting classifier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit the ensemble model on the training dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Once the training phase is completed, run the DeepChecks model evaluation suite
    using the training and testing datasets and the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The model evaluation report contains the test results on:'
  prefs: []
  type: TYPE_NORMAL
- en: Unused Features - Train Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unused Features - Test Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train Test Performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prediction Drift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple Model Comparison
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model Inference Time - Train Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model Inference Time - Test Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confusion Matrix Report - Train Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Confusion Matrix Report - Test Dataset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are other tests available in the suite that didn't run due to the ensemble
    type of model. If you ran a simple model like logistic regression, you might have
    gotten a full report.
  prefs: []
  type: TYPE_NORMAL
- en: '![model evaluation report DeepChecks](../Images/5b6a1a9ca455e76fd75b13a22e6c1846.png)'
  prefs: []
  type: TYPE_IMG
- en: If you want to use a model evaluation report in a structured format, you can
    always use the `.to_json()` function to convert your report into the JSON format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![model evaluation report to JSON output](../Images/3d1b4ff48dbcd417baa9dfa18ad74e45.png)'
  prefs: []
  type: TYPE_IMG
- en: Moreover, you can also save this interactive report as a web page using the
    `.save_as_html()` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running the Single Check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you don't want to run the entire suite of model evaluation tests, you can
    also test your model on a single check.
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can check label drift by providing the training and testing
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As a result, you will get a distribution plot and drift score.
  prefs: []
  type: TYPE_NORMAL
- en: '![Running the Single Check: Label drift](../Images/d5088bd7523c4e7de1f282d1ab4089ec.png)'
  prefs: []
  type: TYPE_IMG
- en: You can even extract the value and methodology of the drift score.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next step in your learning journey is to automate the machine learning testing
    process and track performance. You can do that with GitHub Actions by following
    the [Deepchecks In CI/CD](https://docs.deepchecks.com/stable/general/usage/ci_cd.html#using-deepchecks-ci-cd)
    guide.
  prefs: []
  type: TYPE_NORMAL
- en: In this beginner-friendly, we have learned to generate data validation and machine
    learning evaluation reports using DeepChecks. If you are having trouble running
    the code, I suggest you have a look at the [Machine Learning Testing With DeepChecks](https://www.kaggle.com/code/kingabzpro/machine-learning-testing-with-deepchecks?scriptVersionId=180206809)
    Kaggle Notebook and run it yourself.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://www.polywork.com/kingabzpro)****[Abid Ali Awan](https://www.polywork.com/kingabzpro)****
    ([@1abidaliawan](https://www.linkedin.com/in/1abidaliawan)) is a certified data
    scientist professional who loves building machine learning models. Currently,
    he is focusing on content creation and writing technical blogs on machine learning
    and data science technologies. Abid holds a Master''s degree in technology management
    and a bachelor''s degree in telecommunication engineering. His vision is to build
    an AI product using a graph neural network for students struggling with mental
    illness.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Hypothesis Testing and A/B Testing](https://www.kdnuggets.com/hypothesis-testing-and-ab-testing)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A/B Testing: A Comprehensive Guide](https://www.kdnuggets.com/ab-testing-a-comprehensive-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Testing Like a Pro: A Step-by-Step Guide to Python''s Mock Library](https://www.kdnuggets.com/testing-like-a-pro-a-step-by-step-guide-to-pythons-mock-library)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Effective Testing for Machine Learning](https://www.kdnuggets.com/2022/01/effective-testing-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Difference Between Training and Testing Data in Machine Learning](https://www.kdnuggets.com/2022/08/difference-training-testing-data-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Beginner''s Guide to End to End Machine Learning](https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
