["```py\nimport os\nimport re\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook, tnrange\nfrom sklearn.utils import shuffle\nimport pickle\nimport math\nimport torch\nimport torch.nn.functional as F\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n```", "```py\ntorch.manual_seed(3007)model = T5ForConditionalGeneration.from_pretrained('./outputs/model_files')\ntokenizer = T5Tokenizer.from_pretrained('./outputs/model_files')\n```", "```py\ntext = \"generate plot for genre: horror\"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\")\ngreedyOp = model.generate(input_ids, max_length=100)\ntokenizer.decode(greedyOp[0], skip_special_tokens=True)\n```", "```py\ndef generateStoryLine(text, seq_len, seq_num):\n\t\t\t\t'''\n\t\t\t\targs:\n\t\t\t\t\ttext: input text eg. generate plot for: {genre} or generate plot for: {director}\n\t\t\t\t\tseq_len: Max sequence length for the generated text\n\t\t\t\t\tseq_num: Number of sequences to generate\n\t\t\t\t'''\n        outputDict = dict()\n        outputDict[\"plots\"] = {}\n        input_ids = tokenizer.encode(text, return_tensors = \"pt\")\n        beamOp = model.generate(\n            input_ids,\n            max_length = seq_len,\n            do_sample = True,\n            top_k = 100,\n            top_p = 0.95,\n            num_return_sequences = seq_num\n        )        for ix, sample_op in enumerate(beamOp):\n            outputDict[\"plots\"][ix] = self.tokenizer.decode(sample_op, skip_special_tokens = True)\n\n        return outputDict\n```", "```py\npip install flask flask_cors tqdm rich gunicorn\n```", "```py\n# app.pyfrom flask import Flask, request, jsonify\nimport json\nfrom flask_cors import CORS\nimport uuidfrom predict import PredictionModelObjectapp = Flask(__name__)\nCORS(app)print(\"Loading Model Object\")\npredictionObject = PredictionModelObject()\nprint(\"Loaded Model Object\")\n```", "```py\n@app.route('/api/generatePlot', methods=['POST'])\ndef gen_plot():    req = request.get_json()\n    genre = req['genre']\n    director = req['director'] if 'director' in req else None\n    cast = req['cast'] if 'cast' in req else None\n    ethnicity = req['ethnicity'] if 'ethnicity' in req else None\n    num_plots = req['num_plots'] if 'num_plots' in req else 1\n    seq_len = req['seq_len'] if 'seq_len' in req else 200    if not isinstance(num_plots, int) or not isinstance(seq_len, int):\n        return jsonify({\n            \"message\": \"Number of words in plot and Number of plots must be integers\",\n            \"status\": \"Fail\"\n        })\n\n    try:\n        plot, status = predictionObject.returnPlot(\n            genre = genre, \n            director = director,\n            cast = cast,\n            ethnicity = ethnicity,\n            seq_len = seq_len,\n            seq_num = num_plots\n        )        if status == 'Pass':\n\n            plot[\"message\"] = \"Success!\"\n            plot[\"status\"] = \"Pass\"\n            return jsonify(plot)\n\n        else:            return jsonify({\"message\": plot, \"status\": status})\n\n    except Exception as e:        return jsonify({\"message\": \"Error getting plot for the given input\", \"status\": \"Fail\"})\n```", "```py\nif __name__ == \"__main__\":\n    app.run(debug=True, port = 5000)\n```", "```py\n# predict.py\nimport os\nimport re\nimport random\nimport torch\nimport torch.nn as nn\nfrom rich.console import Console\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom collections import defaultdictconsole = Console(record = True)torch.cuda.manual_seed(3007)\ntorch.manual_seed(3007)\n```", "```py\n# predict.py\nclass PredictionModelObject(object):    def __init__(self):console.log(\"Model Loading\")\n        self.model = T5ForConditionalGeneration.from_pretrained('./outputs/model_files')\n        self.tokenizer = T5Tokenizer.from_pretrained('./outputs/model_files')\n        console.log(\"Model Loaded\")\n\n    def beamSearch(self, text, seq_len, seq_num):        outputDict = dict()\n        outputDict[\"plots\"] = {}\n        input_ids = self.tokenizer.encode(text, return_tensors = \"pt\")\n        beamOp = self.model.generate(\n            input_ids,\n            max_length = seq_len,\n            do_sample = True,\n            top_k = 100,\n            top_p = 0.95,\n            num_return_sequences = seq_num\n        )        for ix, sample_op in enumerate(beamOp):\n            outputDict[\"plots\"][ix] = self.tokenizer.decode(sample_op, skip_special_tokens = True)\n\n        return outputDict    def genreToPlot(self, genre, seq_len, seq_num):        text = f\"generate plot for genre: {genre}\"        return self.beamSearch(text, seq_len, seq_num)    def genreDirectorToPlot(self, genre, director, seq_len, seq_num):        text = f\"generate plot for genre: {genre} and director: {director}\"\n\n        return self.beamSearch(text, seq_len, seq_num)    def genreDirectorCastToPlot(self, genre, director, cast, seq_len, seq_num):        text = f\"generate plot for genre: {genre} director: {director} cast: {cast}\"        return self.beamSearch(text, seq_len, seq_num)    def genreDirectorCastEthnicityToPlot(self, genre, director, cast, ethnicity, seq_len, seq_num):        text = f\"generate plot for genre: {genre} director: {director} cast: {cast} and ethnicity: {ethnicity}\"        return self.beamSearch(text, seq_len, seq_num)\n\n    def genreCastToPlot(self, genre, cast, seq_len, seq_num):        text = f\"genreate plot for genre: {genre} and cast: {cast}\"        return self.beamSearch(text, seq_len, seq_num)    def genreEthnicityToPlot(self, genre, ethnicity, seq_len, seq_num):        text = f\"generate plot for genre: {genre} and ethnicity: {ethnicity}\"        return self.beamSearch(text, seq_len, seq_num)    def returnPlot(self, genre, director, cast, ethnicity, seq_len, seq_num):\n        console.log('Got genre: ', genre, 'director: ', director, 'cast: ', cast, 'seq_len: ', seq_len, 'seq_num: ', seq_num, 'ethnicity: ',ethnicity)\n\n        seq_len = 200 if not seq_len else int(seq_len)\n\n        seq_num = 1 if not seq_num else int(seq_num)\n\n        if not director and not cast and not ethnicity:            return self.genreToPlot(genre, seq_len, seq_num), \"Pass\"\n\n        elif genre and director and not cast and not ethnicity:            return self.genreDirectorToPlot(genre, director, seq_len, seq_num), \"Pass\"        elif genre and director and cast and not ethnicity:            return self.genreDirectorCastToPlot(genre, director, cast, seq_len, seq_num), \"Pass\"        elif genre and director and cast and ethnicity:            return self.genreDirectorCastEthnicityToPlot(genre, director, cast, ethnicity, seq_len, seq_num), \"Pass\"        elif genre and cast and not director and not ethnicity:            return self.genreCastToPlot(genre, cast, seq_len, seq_num), \"Pass\"\n\n        elif genre and ethnicity and not director and not cast:            return self.genreEthnicityToPlot(genre, ethnicity, seq_len, seq_num), \"Pass\"        else:            return \"Genre cannot be empty\", \"Fail\"\n```", "```py\npython app.py\n```", "```py\n# test_api.py\nimport requests\nimport osurl = \"<http://localhost:5000/api/generatePlot>\"\njson = {\n    \"genre\": str(input(\"Genre: \")),\n    \"director\": str(input(\"Director: \")),\n    \"cast\": str(input(\"Cast: \")),\n    \"ethnicity\": str(input(\"Ethnicity: \")),\n    \"num_plots\": int(input(\"Num Plots: \")),\n    \"seq_len\": int(input(\"Sequence Length: \")),\n}r = requests.post(url, json = json)\nprint(r.json())\n```", "```py\ngunicorn -k gthread -w 2 -t 40000 --threads 3 -b:5000 app:app\n```"]