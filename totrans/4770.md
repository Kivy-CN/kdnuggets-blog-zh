# 在 Python 和 R 中评估预测模型的业务价值

> 原文：[https://www.kdnuggets.com/2018/10/evaluating-business-value-predictive-models-modelplotpy.html](https://www.kdnuggets.com/2018/10/evaluating-business-value-predictive-models-modelplotpy.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**作者 [Jurriaan Nagelkerke](https://www.linkedin.com/in/jnagelkerke/)，数据科学顾问，以及 [Pieter Marcus](https://www.linkedin.com/in/pieter-marcus/)，数据科学家**

### 为什么 ROC 曲线在向业务人员解释你的模型时是个坏主意

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

### 总结

在本博客中，我们解释了评估预测模型业务价值的四种最有价值的评估图。这些图包括累计收益图、累计提升图、响应图和累计响应图。由于这些可视化图表未包含在大多数流行的模型构建软件包或 R 和 Python 模块中，我们展示了如何使用我们的 modelplotpy Python 模块和我们的 [modelplotr R 包（更喜欢 R 吗？在这里阅读有关 modelplotr 的所有信息！）](https://modelplot.github.io/intro_modelplotr.html) 轻松创建这些图表。这将帮助你用通俗的语言向非技术人员解释模型的业务价值。

### 介绍

![ ](../Images/83c84da9830ba3d49ae3aba258c106a6.png)

> ‘…正如我们在这个 ROC 图中清楚看到的，当 0.2 的特异性减去 1 的值时，模型的敏感性相当高！对吧？…’

如果你的商业同事在你介绍你的奇妙预测模型时还没离开，当你开始这样讲解时，他们肯定会彻底离开。为什么？因为 ROC 曲线不容易快速解释，也难以转换成你的观众提出的业务问题的答案。而这些业务问题正是你构建模型的初衷！

业务问题是什么？我们构建各种监督分类问题。例如，预测模型用于在数据集中选择最佳记录，这些记录可以是客户、潜在客户、项目、事件……例如：你想知道哪些活跃客户有最高的流失概率；你需要选择那些最有可能响应优惠的潜在客户；你必须识别出有较高欺诈风险的交易。因此，在你的演示中，听众主要关注的问题是*你的模型能否帮助我们找到目标受众？使用你的模型我们能提高多少？我们的活动预期回应会如何？*

在我们的模型构建过程中，我们应该已经专注于验证模型的表现如何。通常，我们通过在选择的记录子集上训练模型参数，并在留出集或外部验证集上测试性能来做到这一点。我们查看一组性能衡量标准，如 ROC 曲线和 AUC 值。这些图表和统计数据在模型构建和优化过程中非常有帮助，可以检查模型是否存在过拟合或欠拟合，以及哪些参数组合在测试数据上表现最佳。然而，这些统计数据在评估你所开发模型的商业价值方面并不那么有用。

ROC 曲线在解释模型的商业价值方面不是特别有用的一个原因是，因为很难向商业人员解释“曲线下面积”、“特异性”或“敏感性”的含义。另一个重要原因是，这些统计数据和图表在商务会议中没有帮助，因为它们不能帮助确定如何应用你的预测模型：我们应该根据模型选择多少记录？是否只选择最好的 10%？还是在 30% 时停止？或者继续选择直到 70%？……这需要你和你的商业同事*共同*决定，以最好地匹配他们需要达成的商业计划和活动目标。我们接下来要介绍的四种图表——累计增益、累计提升、响应和累计响应——在我们看来是最适合这一目的的图表。

### 使 modelplotpy 在你的计算机上运行

让我们从安装**modelplotpy**模块开始本教程。Modelplotpy 已经可以从[Github](https://github.com/modelplot/modelplotpy)上获取，但目前无法通过[Python 包索引（PyPI）存储库](https://pypi.org/)进行安装。

对于某些用户，我们发现需要先在你的计算机上安装 GitHub。如果你的计算机上还没有安装 GitHub，可以从[这里](https://desktop.github.com/)下载。安装 GitHub 后，最好重启计算机，然后继续进行本教程。

Modelplotpy需要通过命令行安装。在macOS或Linux操作的机器上，打开终端；在Windows机器上，搜索cmd.exe并按回车键。复制并粘贴以下命令，然后按回车键。

```py
pip install git+https://github.com/modelplot/modelplotpy.git

```

一旦您成功安装了modelplotpy，就可以打开Python并将其加载到工作目录中，继续这个教程！这个教程是用Python 3.6.4编写的，可能在Python 2.x中无法完全运行。

```py
import modelplotpy as mp

```

现在我们准备使用modelplotpy。在另一篇文章中，我们将详细介绍我们的modelplot包在R和Python中的所有功能。在这里，我们将专注于如何使用modelplotpy进行业务示例。

### 示例：来自*sklearn*的预测模型在*银行营销数据集*上

让我们开始吧！在介绍图表时，我们将向您展示如何使用它们进行业务示例。这个示例基于一个公开可用的数据集，称为银行营销数据集。它是最受欢迎的数据集之一，发布在[UCI机器学习库](https://archive.ics.uci.edu/ml/index.php)。该数据集来自一家葡萄牙银行，涉及一个经常提出的营销问题：客户是否购买了定期存款这一金融产品。共有4个数据集可用，**bank-additional-full.csv** 是我们使用的。它包含41,188名客户的信息和21列数据。

为了说明如何使用modelplotpy，假设我们在这家银行工作，我们的市场营销同事要求我们帮助选择最有可能响应定期存款优惠的客户。为此，我们将开发一个预测模型并创建图表，与市场营销同事讨论结果。由于我们想展示如何构建图表，而不是如何构建一个完美的模型，我们将在示例中使用这六个列。以下是我们使用的数据的简要描述：

1.  **y**: 客户是否订阅了定期存款？

1.  **duration**: 最后一次联系的持续时间，单位为秒（数字）

1.  **campaign**: 在此活动中为此客户执行的联系次数

1.  **pdays**: 客户在上一轮活动后被联系的天数

1.  **previous**: 在此活动之前为此客户执行的联系次数（数字）

1.  **euribor3m**: euribor 3个月利率

让我们加载数据并快速查看一下：

```py
import io
import os
import requests
import zipfile
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

#r = requests.get("https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip")
# we encountered that the source at uci.edu is not always available, therefore we made a copy to our repos.
r = requests.get('https://modelplot.github.io/img/bank-additional.zip')
z = zipfile.ZipFile(io.BytesIO(r.content))
# You can change the path, currently the data is written to the working directory
path = os.getcwd()
z.extractall(path)
bank = pd.read_csv(path + "/bank-additional/bank-additional-full.csv", sep = ';')

# select the 6 columns
bank = bank[['y', 'duration', 'campaign', 'pdays', 'previous', 'euribor3m']]
# rename target class value 'yes' for better interpretation
bank.y[bank.y == 'yes'] = 'term deposit'

# dimensions of the data
print(bank.shape)

# show the first rows of the dataset
print(bank.head())

```

```py
(41188, 6)
    y  duration  campaign  pdays  previous  euribor3m
0  no       261         1    999         0      4.857
1  no       149         1    999         0      4.857
2  no       226         1    999         0      4.857
3  no       151         1    999         0      4.857
4  no       307         1    999         0      4.857

```

在这些数据上，我们应用了一些来自[**sklearn模块**](http://scikit-learn.org/)的预测建模技术。这个广为人知的模块是许多预测建模技术的封装器，例如逻辑回归、随机森林等等。让我们训练几个模型并用图表评估它们。

```py
# to create predictive models
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# define target vector y
y = bank.y
# define feature matrix X
X = bank.drop('y', axis = 1)

# Create the necessary datasets to build models
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2018)

# Instantiate a few classification models
clf_rf = RandomForestClassifier().fit(X_train, y_train)
clf_mult = LogisticRegression(multi_class = 'multinomial', solver = 'newton-cg').fit(X_train, y_train)

```

```py
C:\Users\nagelk000\PycharmProjects\testen_matplotpy\venv\lib\site-packages\sklearn\ensemble\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.
  from numpy.core.umath_tests import inner1d

```

在另一篇文章中，我们将详细介绍我们在 R 和 Python 中的 modelplot 包及其所有功能。目前，我们重点解释给我们的营销同事，我们的预测模型如何帮助他们选择客户进行定期存款活动。

```py
obj = mp.modelplotpy(feature_data = [X_train, X_test]
                     , label_data = [y_train, y_test]
                     , dataset_labels = ['train data', 'test data']
                     , models = [clf_rf, clf_mult]
                     , model_labels = ['random forest', 'multinomial logit']
                     )

# transform data generated with prepare_scores_and_deciles into aggregated data for chosen plotting scope 
ps = obj.plotting_scope(select_model_label = ['random forest'], select_dataset_label = ['test data'])

```

```py
No comparison specified! Single evaluation line will be plotted
The label with smallest class is ['term deposit']
Target value term deposit plotted for dataset test data and model random forest.

```

刚刚发生了什么？在 **modelplotpy** 中实例化了一个类，**plotting_scope** 函数指定了你想要显示的图表范围。一般来说，可以应用于 modelplotpy 类的 3 个方法（函数），但你不需要指定它们，因为它们是链式调用的。这些函数是：

+   **prepare_scores_and_deciles**：对训练数据集和测试数据集中的客户进行评分，预测他们获取定期存款的概率

+   **aggregate_over_deciles**：将所有评分汇总到十分位数，并计算显示的信息。

+   **plotting_scope** 允许你指定分析的范围。

在第二行代码中，我们指定了分析的范围。我们没有指定 "scope" 参数，因此选择了默认值 - *不进行比较*。正如输出所述，你可以使用 modelplotpy 从多个角度评估你的模型：

+   仅解释一个模型（默认情况）

+   比较不同数据集中的模型性能

+   比较不同模型的性能

+   比较不同目标类别的性能

在这里，我们将简单评估 - 从商业角度 - 选定的模型在选定数据集中的表现情况，针对一个目标类别。我们确实为一些参数指定了值，重点关注 **随机森林** 模型在 **测试数据** 上。目标类别的默认值是 **定期存款**；由于我们要关注的是选择定期存款的客户，这个默认值是完美的。

### 让我们介绍一下收益、提升和（累积）响应图。

在给你更多代码和输出之前，让我们先让你熟悉我们强烈建议用于评估预测模型商业价值的图表。虽然每个图表从不同角度揭示模型的商业价值，但它们都使用相同的数据：

+   目标类别的预测概率

+   基于预测概率的同样大小的组

+   这些组中观察到的实际目标类别观察数

常见做法是将数据分成 10 个大小相等的组，并称这些组为十分位数。属于某个数据集中前 10% 高模型概率的观察值在该集合的第一十分位数；下一个 10% 高模型概率的组是第二十分位数，最后 10% 目标类别模型概率最低的观察值属于第十十分位数。

我们的四个图表中的每一个都将十分位数放在 x 轴上，另一个度量放在 y 轴上。十分位数从左到右绘制，因此模型概率最高的观察值在图表的左侧。这会产生这样的图表：

![ ](../Images/f0d5193245d460e1640096864514008c.png)

现在我们清楚了每个图的横轴上是什么，我们可以更详细地探讨每个图在纵轴上的度量。对于每个图，我们将从业务角度简要解释你能从图中获得的洞察。之后，我们将其应用于我们的银行数据，并展示modelplotpy的一些巧妙功能，以帮助你向他人解释你出色预测模型的价值。

**1. 累计收益图**

累计收益图——通常称为“收益图”——帮助你回答以下问题：

***当我们应用模型并选择最佳的X个十位数时，我们可以预期选择到多少实际目标类别观察的百分比？***

因此，累计收益图可视化了如果你决定选择直到第X个十位数，你选择到的目标类别成员的百分比。这是一个非常重要的业务问题，因为在大多数情况下，你希望使用预测模型来针对**子集**的观察——客户、潜在客户、案件……—而不是针对所有案例。由于我们不会总是构建完美的模型，我们会错过一些潜在的情况。这完全没问题，因为如果我们不愿意接受这一点，我们根本不应该使用模型。或者构建一个完美的模型，以100%的概率评分所有实际目标类别成员，并以0%的概率评分所有不属于目标类别的案例。然而，如果你是这样的高手，你根本不需要这些图，或者你应该仔细检查你的模型——也许你在作弊？....

因此，我们必须接受我们会丢失一些。*你在给定十位数下，模型实际选择的目标类别成员的百分比*，就是累计收益图所告诉你的。该图附带两条参考线，告诉你模型的表现好坏：*随机模型线* 和 *理想模型线*。随机模型线告诉你在完全不使用模型的情况下，你会期望选择到的目标类别的比例。这条垂直线从原点（0%的情况下，你只能选择到0%的实际目标类别成员）延伸到右上角（100%的情况下，你会选择到100%的目标类别成员）。这是模型表现的最低底线；如果接近这个水平，则说明你的模型不比掷硬币好多少。理想模型是模型能达到的上限。它从原点开始，以尽可能陡的角度上升至100%。如果少于10%的所有案例属于目标类别，这意味着它从原点陡升至第一个十位数的值和100%的累计收益，并在所有其他十位数中保持不变，因为这是一个累积度量。你的模型总是会在这两条参考线之间移动——越接近理想模型越好——并且看起来是这样的：

![ ](../Images/773c69670ffd4dd5c2dcc0fa00a8cb38.png)

回到我们的业务示例。我们能从预测模型的前20%中选择多少定期存款购买者？让我们来找出答案！要生成累积收益图表，我们可以简单地调用函数**plot_cumgains()**：

```py
# plot the cumulative gains plot
mp.plot_cumgains(ps)

```

```py
The cumulative gains plot is saved in C:\Users\nagelk000\AppData\Local\Temp\intro_modelplotpy.ipynb/Cumulative gains plot.png

```

![](../Images/1d22b8efa88d457540009a4782eb926f.png)

```py
<Figure size 432x288 with 0 Axes>
```

```py
<matplotlib.axes._subplots.AxesSubplot at 0x1ca44358>
```

我们只需要指定绘图范围的输入。尽管如此，还有几个参数可以自定义图表。如果我们想要突出显示某一点的模型性能，我们可以在图表上添加高亮和在图表下方添加一些解释文本。虽然这两者都是可选的：

```py
# plot the cumulative gains plot and annotate the plot at decile = 2
mp.plot_cumgains(ps, highlight_decile = 2)

```

```py
When we select 20% with the highest probability according to model random forest, this selection holds 80% of all term deposit cases in dataset test data.
The cumulative gains plot is saved in C:\Users\nagelk000\AppData\Local\Temp\intro_modelplotpy.ipynb/Cumulative gains plot.png

```

![](../Images/6aa9908c17e07b026f90b89554194d05.png)

```py
<Figure size 432x288 with 0 Axes>
```

```py
<matplotlib.axes._subplots.AxesSubplot at 0x20596198>
```

我们的'**highlight_decile**'参数在第2分位数处为图表添加了一些指导元素，并在图表下方添加了一个文本框，其中用文字解释了第2分位数处图表的含义。这一解释也会打印到控制台上。我们的简单模型 - 仅使用了6个预测变量 - 似乎在选择对定期存款感兴趣的客户方面表现良好。*当我们根据随机森林选择前20%的高概率客户时，这一选择在测试数据中占所有定期存款案例的79%。*如果模型完美，我们将选择100%，因为测试集中不到20%的客户购买定期存款。随机选择仅会包含20%的定期存款客户。我们表现得比随机选择好多少，这将带我们到图表2！

### 相关主题

+   [超越准确性：使用NLP测试库评估和改进模型](https://www.kdnuggets.com/2023/04/john-snow-beyond-accuracy-nlp-test-library.html)

+   [评估计算文档相似性的方法](https://www.kdnuggets.com/evaluating-methods-for-calculating-document-similarity)

+   [机器学习没有为我的业务创造价值。为什么？](https://www.kdnuggets.com/2021/12/machine-learning-produce-value-business.html)

+   [KDnuggets™ 新闻 22:n01, 1月5日：3个跟踪和可视化工具…](https://www.kdnuggets.com/2022/n01.html)

+   [构建预测模型：Python中的逻辑回归](https://www.kdnuggets.com/building-predictive-models-logistic-regression-in-python)

+   [结合数据管理和数据讲述生成价值](https://www.kdnuggets.com/combining-data-management-and-data-storytelling-to-generate-value)
