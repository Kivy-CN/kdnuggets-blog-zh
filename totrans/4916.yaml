- en: Tips for Getting Started with Text Mining in R and Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 R 和 Python 进行文本挖掘的提示
- en: 原文：[https://www.kdnuggets.com/2017/11/getting-started-text-mining-r-python.html](https://www.kdnuggets.com/2017/11/getting-started-text-mining-r-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/11/getting-started-text-mining-r-python.html](https://www.kdnuggets.com/2017/11/getting-started-text-mining-r-python.html)
- en: '**By Chaitanya Sagar, [Perceptive Analytics](http://www.perceptive-analytics.com/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Chaitanya Sagar，[Perceptive Analytics](http://www.perceptive-analytics.com/)。**'
- en: '**It All Starts With The Text**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**一切从文本开始**'
- en: There is so much of information lying in the text posts made by you and me and
    all others about all the trending topics today. Being in our respective firms,
    big or small, each of us collect some data related to our respective businesses
    and store it to analyze for various projects. At the same time, we all need this
    ‘unstructured data’ to know and understand more about our clients, customers and
    the state of our company in the world today. However, working with this data is
    not easy. The data is not structured, every piece does not have all the information
    and each part is unique. This is how textual data is. It needs to be processed
    first and converted in a form that is suitable for analysis. This is very similar
    to our own databases which we create except that they cannot be used directly
    and the amount of data is very large. This article opens up the world of text
    mining in a simple and intuitive way and provides great tips to get started with
    text mining.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你我以及所有人关于当今热门话题的文本帖子中蕴藏着大量信息。无论我们在大公司还是小公司工作，我们都收集与各自业务相关的数据，并将其存储以便用于各种项目。同时，我们都需要这些‘非结构化数据’来了解和理解更多关于我们的客户、顾客以及公司在当今世界的状态。然而，处理这些数据并不容易。数据是非结构化的，每一部分都不包含全部信息，每部分都是独特的。这就是文本数据的特点。它需要首先处理并转换为适合分析的形式。这与我们创建的数据库非常相似，只是这些数据库不能直接使用，而且数据量非常大。本文以简单直观的方式打开了文本挖掘的世界，并提供了开始文本挖掘的绝佳提示。
- en: '![](../Images/4a09fc15ca3b602f36a8a527949e76c8.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a09fc15ca3b602f36a8a527949e76c8.png)'
- en: '**Tip #1: Think First**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #1：先思考**'
- en: The mammoth of text mining can become a simple task if you work on it with a
    plan in mind. Think what you need to do with text before going all out on it.
    What is your objective behind text mining? What sources of data do you want to
    use? How much data do you need for it to be sufficient? How do you plan to present
    your results from the data? It is all about getting curious about your problem
    and break it into small fragments. Thinking through the problem also opens up
    your mind towards the various situations you may encounter and ways to tackle
    those situations. You can then chart out a workflow and start pursuing the task.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有计划地进行文本挖掘，它可以变得很简单。在全面投入之前，先想想你需要对文本做什么。你进行文本挖掘的目标是什么？你想使用哪些数据来源？你需要多少数据才足够？你计划如何展示数据结果？这一切都在于对问题保持好奇，并将其分解成小部分。思考问题还会让你对可能遇到的各种情况及应对方式有更多了解。然后，你可以制定工作流程并开始执行任务。
- en: '**Tip #2: R or Python.. Or Something Else?**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #2：R 还是 Python？还是其他？**'
- en: There is no gold standard procedure for text mining. You have to choose the
    method which is most convenient for text mining. This is where factors such as
    efficiency,effectiveness type of problem and other factors come into play and
    helps you decide the best candidate for your problem. After having decided your
    chosen path, you need to build your knowledge and skills in developing skills
    in that language. I find the text mining techniques more intuitive in Python than
    in R but R has some handy functions to do tasks such as word counting and is richer
    in terms of packages available for text mining.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种金标准程序用于文本挖掘。你必须选择最方便的文本挖掘方法。在这里，效率、效果、问题类型等因素发挥作用，帮助你决定最适合你问题的方案。在决定了你的选择路径之后，你需要在该语言中建立知识和技能。我发现
    Python 中的文本挖掘技术比 R 更直观，但 R 具有一些便利的功能，例如词频统计，并且在文本挖掘的包方面更丰富。
- en: '**Tip #3: Start Early and Collect Your Data**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #3：早点开始并收集数据**'
- en: 'The usual process of text mining involves the following steps:'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本挖掘的常规过程包括以下步骤：
- en: Collect data; either from social media such as twitter or other websites. Write
    your code that can adjust to the specific type of text you collect and store it
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据；无论是来自社交媒体如 Twitter 还是其他网站。编写可以适应你收集的特定类型文本的代码并存储它
- en: Convert your data into readable text
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据转换为可读文本
- en: Remove special characters from the text (such as hashtags). You can add a hashtag
    count feature if that is required
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本中删除特殊字符（例如井号）。如果需要，可以添加一个井号计数功能。
- en: Removing numbers from the text data (unless the problem requires numbers)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文本数据中删除数字（除非问题需要数字）。
- en: Deciding whether to keep all the data or remove some of it such as all non-English
    text
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定是否保留所有数据或删除其中的一部分，例如所有非英语文本。
- en: Converting all the text to uppercase or lowercase only to ease analysis
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有文本转换为大写或小写以简化分析。
- en: Removing stop words.. Words that have no use in your analysis. This includes
    articles, conjunctions, etc.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除停用词。这些词在你的分析中没有用处，包括冠词、连词等。
- en: Using word stemming and grouping similar words such as ‘keep’ and ‘keeping’
    are same words used in different tense form.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用词干提取和将类似词汇（如‘keep’和‘keeping’）分组，这些词在不同的时态形式中使用的是相同的词。
- en: Final analysis of the processed stemmed words and visualize results
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对处理后的词干词进行最终分析并可视化结果。
- en: The steps are short and simple but they all depend on the first step executed
    well. You need to collect your data so that text mining can be performed on it.
    There are many ways to collect data. One of the most popular sources to collect
    data from is Twitter. Twitter has exposed some APIs so that tweets can be mined
    using both R and Python. Besides twitter, one can capture data from any website
    today including e-commerce websites, movie websites, song websites, etc. Some
    websites also contain preformatted repositories of text data such as project gutenberg,
    corpora, etc. Google trends and yahoo also offer some analysis online.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤简短而简单，但都依赖于第一步的顺利执行。你需要收集数据以便进行文本挖掘。有许多方式可以收集数据，其中最受欢迎的来源之一是Twitter。Twitter提供了一些API，可以使用R和Python挖掘推文。除了Twitter，现在你还可以从任何网站捕获数据，包括电子商务网站、电影网站、歌曲网站等。一些网站还包含预格式化的文本数据库，如Project
    Gutenberg、语料库等。Google趋势和Yahoo也提供一些在线分析。
- en: '**Tip #4: Find and Use The Best Way to Convert Text to Data**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #4: 找到并使用最佳的文本到数据转换方法**'
- en: Based on the tools and your project objective, you may use a different approach
    to convert your collected text to data. If you are using R, packages such as twitteR,
    tm and stringr are what you may be using for most of the preprocessing. The nltk
    library and Tweepy package are the equivalent packages in Python. Whichever language
    and package you use, make sure that you have enough resources and memory to handle
    the data. Text mining can be cumbersome just because of the irrelavant text lying
    around in your data even after removing stop words. Using a good method to prepare
    data will give you a lot of useful information when you apply modelling techniques
    on the data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据工具和项目目标，你可能会使用不同的方法将收集的文本转换为数据。如果你使用R，可能会用到如twitteR、tm和stringr等包进行大部分预处理。在Python中，相应的包是nltk库和Tweepy包。无论使用哪种语言和包，都要确保你有足够的资源和内存来处理数据。文本挖掘可能会很麻烦，因为即使在去除停用词后，数据中仍然可能存在无关文本。使用良好的数据准备方法会在应用建模技术时提供很多有用的信息。
- en: '**Tip #5: Explore and Play Around**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #5: 探索和尝试**'
- en: You need to know your data before preprocessing it. Without the knowledge of
    how your data looks like, you might carelessly remove text which might have been
    useful in your analysis. There are many standard methods and dictionaries of removing
    stopwords and assigning importance to words but they may or may not apply to your
    data. For example, data about the government may include a lot of words such as
    ‘rule’, ‘govern’ and ‘politics’ which you may deem unnecessary and want to remove.
    Reviews may include lots of ‘hi’ in the beginning but may not be useful for a
    review dataset. It is always a good step to look at the source of data and go
    through some of the text to know how the process you defined for analysis is working
    to transform it correctly into useful information. Other ways specific to exploring
    text data is by creating a document term matrix. A document term matrix is a m*n
    matrix where the number of columns denote the total number of unique words in
    the entire dataset and the number of rows denote the total data points. Each cell
    thus represents the count of the particular word in that datapoint. This is a
    very large matrix and is later collapsed into term-frequency. From this document
    term matrix, one can count the total occurrences of each word in the dataset and
    that is exactly what term-frequency matrix stores. Other uses of document term
    matrix include knowing correlation between words, drawing a word cloud using term-frequency
    or predicting patterns using modelling techniques. This exploration will further
    give you confidence on the best way to move forward with textual data analysis.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在对数据进行预处理之前，你需要了解你的数据。不了解数据的具体情况，你可能会不小心删除掉那些在分析中可能有用的文本。有许多标准方法和词典用于去除停用词和给单词分配重要性，但这些方法可能适用于你的数据，也可能不适用。例如，关于政府的数据可能包含许多像“rule”（规则）、“govern”（治理）和“politics”（政治）这样的词汇，这些词汇你可能会认为是不必要的而想要删除。评论中可能在开头包含很多“hi”，但对于评论数据集来说可能没有用处。查看数据源并阅读一些文本，了解你为分析定义的过程是否能够正确地将数据转化为有用的信息，是一个很好的步骤。探索文本数据的另一种方式是创建文档词项矩阵。文档词项矩阵是一个
    m*n 矩阵，其中列的数量表示整个数据集中唯一单词的总数，行的数量表示数据点的总数。因此，每个单元格表示该数据点中某个特定单词的计数。这是一个非常大的矩阵，随后会被压缩成词频矩阵。从这个文档词项矩阵中，可以计算数据集中每个单词的总出现次数，这正是词频矩阵所储存的内容。文档词项矩阵的其他用途包括了解单词之间的关联、使用词频绘制词云，或通过建模技术预测模式。这种探索将进一步增强你对如何进行文本数据分析的信心。
- en: '**Tip #6: Dive Deep and Get Your Hands Dirty**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #6：深入挖掘并亲自实践**'
- en: The primary objective or every machine learning and data science project is
    to find patterns in the data that are otherwise hard to find. You need to look
    for those interesting patterns and are not a true data scientist if you’re scared
    of this step. It can be as simple as fitting a simple classifier to classify data
    points and see its performance. This will set a benchmark while giving you an
    idea of the predicting ability of the data. At times, the data may be biased or
    have a poor predictive power and data quality checks can help define this. For
    example, If I am collecting twitter data on the basis of hashtags, I can divide
    my collected data into train and test datasets keeping the hashtags as the dependent
    feature. If my prediction performance is not up to the mark, I need to go back
    a few steps and find out the cause of this low performance and then check how
    I am collecting data or how I am cleaning my data as the case may be. Other ways
    of getting patterns involve associations. For example, some data points may be
    related to each other while others may have a similar or opposite pattern. If
    tweets are being used for text mining, there can be duplicate tweets because of
    retweeting or debates going for or against a remark. Working with data also exposes
    problems such as dealing with sarcasm or comments that convey mixed expressions.
    Without brushing through the data, it will be difficult to know how much of your
    data is affected by these problems and whether you should drop such data or use
    some technique to handle the situation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个机器学习和数据科学项目的主要目标是发现数据中那些难以发现的模式。你需要寻找这些有趣的模式，如果你害怕这一步，那你就不是真正的数据科学家。这个过程可以简单到只需将一个简单的分类器应用于数据点，并查看其性能。这将设定一个基准，同时给你一个数据预测能力的概念。有时，数据可能存在偏差或预测能力差，数据质量检查可以帮助定义这一点。例如，如果我基于标签收集Twitter数据，我可以将收集的数据分为训练集和测试集，将标签作为依赖特征。如果我的预测性能不理想，我需要回到几步前，找出低性能的原因，然后检查我如何收集数据或清理数据，具体情况而定。获得模式的其他方法包括关联。例如，某些数据点可能彼此相关，而其他数据点可能具有相似或相反的模式。如果用于文本挖掘的推文中可能会有重复推文，因为转发或对评论的辩论。处理数据也会暴露出诸如处理讽刺或传达混合表达的评论等问题。如果不仔细检查数据，很难知道你的数据有多少受到这些问题的影响，以及是否应该删除这些数据或使用某种技术来处理这种情况。
- en: '**Tip #7: Rework and Repeat**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #7: 重新工作和重复**'
- en: The problem you are trying to solve may or may not be the first text mining
    problem in your company but it is certainly not the first text mining problem
    in the world today. There are several data scientists out there who have worked
    on either the same or similar problem as the one you are working on and knowing
    what methods they followed and what they did differently will help you take your
    problem solving to the next level. Though not as frequent as other domains, there
    are several analysis and projects being done on text mining which include finding
    the trending topics, sentiment analysis on the trending topics, identifying remarks
    about your firm or product, identifying grievances and appreciations and the like.
    With the same data, there can be more than one problem that can be solved. Complex
    problems which can be explored also include NLP and topic modelling. I read about
    a fairly recent project in which some students predicted the next topic which
    a group of people will discuss based on the current conversation. There can be
    many such new projects which can be thought of and pursued in the area of text
    mining but since it is a new and hot field to work on, always refer other similar
    data and resources to further compliment your analysis and come up with strong
    insights.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你尝试解决的问题可能不是你公司中的第一个文本挖掘问题，但肯定不是今天世界上第一个文本挖掘问题。很多数据科学家曾处理过与您正在处理的相同或类似的问题，了解他们采用的方法以及他们所做的不同之处，将有助于你将问题解决提升到新的水平。虽然不像其他领域那样频繁，但在文本挖掘领域也有很多分析和项目，包括发现趋势话题、对趋势话题的情感分析、识别对公司或产品的评论、识别抱怨和赞赏等。相同的数据可以解决多个问题。可以探索的复杂问题还包括自然语言处理（NLP）和主题建模。我读到一个相对较新的项目，其中一些学生根据当前对话预测了一组人将讨论的下一个话题。在文本挖掘领域，可能会有许多这样的新项目可以构思和追求，但由于这是一个新兴且热门的领域，请始终参考其他类似的数据和资源，以进一步补充你的分析并得出有力的见解。
- en: '**Tip #8: Presenting Text Visually**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示 #8: 以视觉方式呈现文本**'
- en: As mentioned earlier, there can be a lot of problems which can be pursued using
    text mining and more than one problem can be solved from the same data. With so
    much to present, it is a good practice to come up with ways to present the results
    in a way that would seem attractive to people. This is why most of the text mining
    results are already visualized in the form of word clouds, sentiment studies and
    figures. There are a packages and libraries for each such task which include wordcloud,
    ggplot2, igraph, text2vec, networkD3 and plotly in R and Networkx, matplotlib,
    plotly in Python. You can also use other sophisticated tools just for visualization
    such as Tableau or Power BI which can help visualize your data in many more ways.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，文本挖掘可以解决许多问题，并且可以从同一数据中解决多个问题。面对如此多的内容，提出以吸引人的方式展示结果是一种良好的实践。这也是为什么大多数文本挖掘结果已被可视化为词云、情感研究和图形的原因。每项任务都有相应的包和库，包括R中的wordcloud、ggplot2、igraph、text2vec、networkD3和plotly，以及Python中的Networkx、matplotlib、plotly。你还可以使用其他先进的可视化工具，如Tableau或Power
    BI，以更多的方式展示数据。
- en: '**Conclusion: A Roadmap**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**结论：路线图**'
- en: Visualizing results is not the end step in text mining projects. Since text
    is captured from online sources, it is constantly changing and so is the data
    that is captured. With the changing data comes changing insights and hence, when
    the project is completed and accepted, it should be continuously updated with
    new data and new insights. These insights can be further enriched with the rate
    of change. With time, the change can also be captured and used as a metric of
    progression. This becomes another longitudinal problem to be solved. Apart from
    the problems which can be pursued with text data, text mining is no easy feat.
    When you create a roadmap of collecting, cleaning and analyzing data, there may
    be several obstacles that will come your way. They can be situations when you
    have to decide whether to work with a single word frequency in document term matrix
    or use groups of words (known as n-grams) or building your own visualization method
    to present your results or memory management. At the same time, new projects are
    coming up in the area of text mining. The best way to learn is to face the problem
    hands on and learn from the experience of working on the problem. Hope this article
    provides motivation to head to the world of text and start mining insightful nuggets
    of information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可视化并不是文本挖掘项目的最终步骤。由于文本来自在线来源，因此它不断变化，捕获的数据也在变化。随着数据的变化，见解也在变化，因此，当项目完成并被接受时，应不断更新新的数据和见解。这些见解可以随着变化的速度进一步丰富。随着时间的推移，变化也可以作为进展的度量来捕捉。这成为另一个需要解决的纵向问题。除了可以用文本数据解决的问题，文本挖掘并非易事。当你创建一个数据收集、清洗和分析的路线图时，可能会遇到一些障碍。这些障碍可能包括决定是处理单个词频还是使用词组（即n-grams），或创建自己的可视化方法来展示结果，或管理内存。同时，文本挖掘领域也在不断出现新的项目。最好的学习方式是亲自面对问题，从解决问题的经验中学习。希望这篇文章能激励你进入文本世界，开始挖掘有价值的信息。
- en: '**Bio: [Chaitanya Sagar](https://www.linkedin.com/in/chaitanyasagar/)** is
    the Founder and CEO of [Perceptive Analytics](http://www.perceptive-analytics.com/).
    Perceptive Analytics has been chosen as one of the top 10 analytics companies
    to watch out for by Analytics India Magazine. It works on Marketing Analytics
    for e-commerce, Retail and Pharma companies.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Chaitanya Sagar](https://www.linkedin.com/in/chaitanyasagar/)** 是[Perceptive
    Analytics](http://www.perceptive-analytics.com/)的创始人兼首席执行官。Perceptive Analytics被Analytics
    India Magazine评选为值得关注的十大分析公司之一。该公司致力于电子商务、零售和制药公司的市场分析。'
- en: '**Related:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Top 10 Machine Learning with R Videos](/2017/10/top-10-machine-learning-r-videos.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前10名R语言机器学习视频](/2017/10/top-10-machine-learning-r-videos.html)'
- en: '[Learn Generalized Linear Models (GLM) using R](/2017/10/learn-generalized-linear-models-glm-r.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用R学习广义线性模型（GLM）](/2017/10/learn-generalized-linear-models-glm-r.html)'
- en: '[A Solution to Missing Data: Imputation Using R](/2017/09/missing-data-imputation-using-r.html)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[缺失数据解决方案：使用R进行插补](/2017/09/missing-data-imputation-using-r.html)'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Getting Started with Automated Text Summarization](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用自动化文本总结入门](https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html)'
- en: '[5 Tips for Getting Started with Language Models](https://www.kdnuggets.com/5-tips-for-getting-started-with-language-models)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用语言模型的5个技巧](https://www.kdnuggets.com/5-tips-for-getting-started-with-language-models)'
- en: '[Getting Started with PyTest: Effortlessly Write and Run Tests in Python](https://www.kdnuggets.com/getting-started-with-pytest-effortlessly-write-and-run-tests-in-python)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用PyTest入门：轻松编写和运行Python测试](https://www.kdnuggets.com/getting-started-with-pytest-effortlessly-write-and-run-tests-in-python)'
- en: '[Getting Started with Python Generators](https://www.kdnuggets.com/2023/02/getting-started-python-generators.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用Python生成器入门](https://www.kdnuggets.com/2023/02/getting-started-python-generators.html)'
- en: '[Getting Started with Python Data Structures in 5 Steps](https://www.kdnuggets.com/5-steps-getting-started-python-data-structures)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用5个步骤开始学习Python数据结构](https://www.kdnuggets.com/5-steps-getting-started-python-data-structures)'
- en: '[Getting Started with Python for Data Science](https://www.kdnuggets.com/getting-started-with-python-for-data-science)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用Python进行数据科学入门](https://www.kdnuggets.com/getting-started-with-python-for-data-science)'
