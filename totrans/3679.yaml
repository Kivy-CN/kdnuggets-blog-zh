- en: Dealing With Noisy Labels in Text Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理文本数据中的噪声标签
- en: 原文：[https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)
- en: '![Dealing With Noisy Labels in Text Data](../Images/15973e5270fd138ec4bc5d0349e92906.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![处理文本数据中的噪声标签](../Images/15973e5270fd138ec4bc5d0349e92906.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑器提供的图像
- en: With the rising interest in natural language processing, more and more practitioners
    are hitting the wall not because they can’t build or fine-tune LLMs, but because
    their data is messy!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自然语言处理的兴趣上升，越来越多的从业者遇到了瓶颈，这不是因为他们不能构建或微调 LLM，而是因为他们的数据很混乱！
- en: 'We will show simple, yet very effective coding procedures for fixing noisy
    labels in text data. We will deal with 2 common scenarios in real-world text data:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示简单但非常有效的编码程序，以修复文本数据中的噪声标签。我们将处理现实世界文本数据中的两个常见场景：
- en: Having a category that contains mixed examples from a few other categories.
    I love to call this kind of category a meta category.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拥有一个包含来自其他几个类别的混合示例的类别。我喜欢将这种类别称为元类别。
- en: Having 2 or more categories that should be merged into 1 category because texts
    belonging to them refer to the same topic.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拥有两个或更多应该合并成一个类别的类别，因为它们的文本指向相同的话题。
- en: 'We will use ITSM (IT Service Management) dataset created for this tutorial
    (CCO license). It’s available on Kaggle from the link below:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用为本教程创建的 ITSM（IT 服务管理）数据集（CCO 许可）。它可以在下面的 Kaggle 链接中找到：
- en: '[https://www.kaggle.com/datasets/nikolagreb/small-itsm-dataset](https://www.kaggle.com/datasets/nikolagreb/small-itsm-dataset)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/datasets/nikolagreb/small-itsm-dataset](https://www.kaggle.com/datasets/nikolagreb/small-itsm-dataset)'
- en: It’s time to start with the import of all libraries needed and basic data examination.
    Brace yourself, code is coming!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候开始导入所有需要的库和基本数据检查了。做好准备，代码来了！
- en: Import and Data Examination
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入和数据检查
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Each row represents one entry in the ITSM database. We will try to predict the
    category of the ticket based on the text of the ticket written by a user. Let’s
    examine deeper the most important fields for described business use cases.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行代表 ITSM 数据库中的一个条目。我们将尝试根据用户编写的工单文本来预测工单的类别。让我们更深入地探讨描述的业务用例中最重要的字段。
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we take a look at the first two tickets, although one ticket is in German,
    we can see that described problems refer to the same software?—?Asana, but they
    carry different labels. This is starting distribution of our categories:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看前两个工单，虽然一个工单是德文的，但我们可以看到描述的问题指的是相同的软件？—？Asana，但它们带有不同的标签。这是我们类别的初步分布：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The help needed looks suspicious, like the category that can contain tickets
    from multiple other categories. Also, categories Outlook and Mail sound similar,
    maybe they should be merged into one category. Before diving deeper into mentioned
    categories, we will get rid of missing values in columns of our interest.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 需要帮助的类别看起来可疑，像是一个可以包含来自多个其他类别的工单的类别。此外，Outlook 和 Mail 听起来相似，也许它们应该合并为一个类别。在深入研究这些类别之前，我们将清理我们关注列中的缺失值。
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Assigning Tickets to the Proper Category
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将工单分配到正确的类别
- en: 'There isn’t a valid substitute for the examination of data with the bare eye.
    The fancy function to do so in pandas is .sample(), so we will do exactly that
    once more, now for the suspicious category:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据进行目视检查没有有效的替代方法。在 pandas 中执行此操作的高级函数是 .sample()，因此我们将再次执行此操作，这次针对可疑类别：
- en: '[PRE7]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Obviously, we have tickets talking about Discord, Asana, and CRM. So the name
    of the category should be changed from “Help Needed” to existing, more specific
    categories. For the first step of the reassignment process, we will create the
    new column “Keywords” that gives the information if the ticket has the word from
    the list of categories in the “Text” column.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们有关于 Discord、Asana 和 CRM 的工单。因此，类别名称应该从“Help Needed”更改为现有的、更具体的类别。在重新分配过程的第一步，我们将创建一个新的列“Keywords”，该列提供工单是否包含“Text”列中类别列表中的单词的信息。
- en: '[PRE9]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Also, note that using "if word in str(words_categories)" instead of "if word
    in words_categories" would catch words from categories with more than 1 word (Internet
    Browser in our case), but would also require more data preprocessing. To keep
    things simple and straight to the point, we will go with the code for categories
    made of just one word. This is how our dataset looks now:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，使用“if word in str(words_categories)”而不是“if word in words_categories”将捕捉到来自多词类别（在我们的例子中是Internet
    Browser）的词，但也需要更多的数据预处理。为了保持简单和直接，我们将使用仅包含一个词的类别的代码。这是我们数据集现在的样子：
- en: '[PRE10]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'output as image:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以图像输出：
- en: '![XXXXX](../Images/7f8932ac292c1f768b45f3d6520af4f8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![XXXXX](../Images/7f8932ac292c1f768b45f3d6520af4f8.png)'
- en: 'After extracting the keywords column, we will assume the quality of the tickets.
    Our hypothesis:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 提取关键词列后，我们将评估票据的质量。我们的假设是：
- en: Ticket with just 1 keyword in the Text field that is the same as the category
    to the which ticket belongs would be easy to classify.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文本字段中只有一个与票据所属类别相同的关键词的票据将容易分类。
- en: Ticket with multiple keywords in the Text field, where at least one of the keywords
    is the same as the category to the which ticket belongs would be easy to classify
    in the majority of cases.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文本字段中有多个关键词的票据，其中至少一个关键词与票据所属类别相同，大多数情况下将容易分类。
- en: The ticket that has keywords, but none of them is equal to the name of the category
    to the which ticket belongs is probably a noisy label case.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 含有关键词的票据，但其中没有一个与票据所属类别的名称相同的，可能是噪声标签的情况。
- en: Other tickets are neutral based on keywords.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其他票据基于关键词是中性的。
- en: '[PRE11]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We made our new distribution and now is the time to examine tickets classified
    as a potential problem. In practice, the following step would require much more
    sampling and look at the larger chunks of data with the bare eye, but the rationale
    would be the same. You are supposed to find problematic tickets and decide if
    you can improve their quality or if you should drop them from the dataset. When
    you are facing a large dataset stay calm, and don't forget that data examination
    and data preparation usually take much more time than building ML algorithms!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了新的分布，现在是时候检查分类为潜在问题的票据了。在实际操作中，下一步将需要更多的采样并用肉眼查看更大块的数据，但基本原理是一样的。你需要找出有问题的票据，并决定是否可以提高其质量或是否应将其从数据集中剔除。当你面对一个大数据集时，保持冷静，别忘了数据检查和数据准备通常比构建机器学习算法需要更多的时间！
- en: '[PRE13]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We understand that tickets from Outlook and Mail categories are related to the
    same problem, so we will merge these 2 categories and improve the results of our
    future ML classification algorithm.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到来自Outlook和Mail类别的票据与相同的问题相关，因此我们将合并这两个类别并改进我们未来机器学习分类算法的结果。
- en: Merging into the Cluster
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合并到集群
- en: '[PRE15]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Last, but not least, we want to relabel some tickets from the meta category
    “Help Needed” to the proper category.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们希望将一些来自“需要帮助”元类别的票据重新标记为适当的类别。
- en: '[PRE17]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We did our data relabeling and cleaning but we shouldn't call ourselves data
    scientists if we don't do at least one scientific experiment and test the impact
    of our work on the final classification. We will do so by implementing The Complement
    Naive Bayes classifier in sklearn. Feel free to try other, more complex algorithms.
    Also, be aware that further data cleaning could be done - for example, we could
    also drop all tickets left in the "Help Needed" category.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行了数据重新标记和清理，但如果我们不做至少一个科学实验来测试我们工作的最终分类影响，我们不应自称为数据科学家。我们将通过在sklearn中实现互补朴素贝叶斯分类器来完成这一点。你可以尝试其他更复杂的算法。此外，还要注意，进一步的数据清理可能会进行，例如，我们还可以删除所有仍留在“需要帮助”类别中的票据。
- en: Testing the Impact of Data Munging
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试数据处理的影响
- en: '[PRE19]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Pretty impressive, right? The dataset we used is small (on purpose, so you can
    easily see what happens in each step) so different random seeds might produce
    different results, but in the vast majority of cases, the model will perform significantly
    better on the dataset after cleaning compared to the original dataset. We did
    a good job!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相当令人印象深刻，对吧？我们使用的数据集很小（故意如此，以便你可以轻松看到每一步的结果），因此不同的随机种子可能会产生不同的结果，但在绝大多数情况下，模型在清理后的数据集上表现会显著优于原始数据集。我们做得很好！
- en: '**[Nikola Greb](https://www.linkedin.com/in/ngreb/)** been coding for more
    than four years, and for the past two years he specialized in NLP. Before turning
    to data science, he was successful in sales, HR, writing and chess.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**[尼古拉·格雷布](https://www.linkedin.com/in/ngreb/)** 编程已有四年多，在过去的两年里，他专注于自然语言处理。在转向数据科学之前，他在销售、人力资源、写作和国际象棋方面取得了成功。'
- en: '* * *'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Dealing with Position Bias in Recommendations and Search](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理推荐系统和搜索中的位置偏差](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)'
- en: '[Transforming AI with LangChain: A Text Data Game Changer](https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 LangChain 转变 AI：文本数据的游戏规则改变者](https://www.kdnuggets.com/2023/08/transforming-ai-langchain-text-data-game-changer.html)'
- en: '[How to Use the Hugging Face Tokenizers Library to Preprocess Text Data](https://www.kdnuggets.com/how-to-use-the-hugging-face-tokenizers-library-to-preprocess-text-data)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face Tokenizers 库来预处理文本数据](https://www.kdnuggets.com/how-to-use-the-hugging-face-tokenizers-library-to-preprocess-text-data)'
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清洗和预处理文本数据以用于 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[Classifying Long Text Documents Using BERT](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 BERT 对长文本文档进行分类](https://www.kdnuggets.com/2022/02/classifying-long-text-documents-bert.html)'
- en: '[How to Use ChatGPT to Convert Text into a PowerPoint Presentation](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 ChatGPT 将文本转换为 PowerPoint 演示文稿](https://www.kdnuggets.com/2023/08/chatgpt-convert-text-powerpoint-presentation.html)'
