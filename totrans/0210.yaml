- en: What To Expect for AI Quality Trends In 2023
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/11/expect-ai-quality-trends-2023.html](https://www.kdnuggets.com/2022/11/expect-ai-quality-trends-2023.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![What To Expect for AI Quality Trends In 2023](../Images/6f68a096e130d3e980818feac3c5ddcc.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Pavel Danilyuk](https://www.pexels.com/photo/elderly-man-thinking-while-looking-at-a-chessboard-8438918/)
  prefs: []
  type: TYPE_NORMAL
- en: 2022 was a watershed year in AI, as quality-related issues came to the forefront.
    Regulation marched along in the EU, Asia, and the U.S., and we saw companies like
    Zillow hobbled by AI model quality [snafus](https://insidebigdata.com/2021/12/13/the-500mm-debacle-at-zillow-offers-what-went-wrong-with-the-ai-models/).
  prefs: []
  type: TYPE_NORMAL
- en: Based on my recent discussions with dozens of Fortune 500 data science teams,
    I expect to see a continued spotlight on AI model quality in 2023\. Here are six
    areas I’m keeping an eye on.
  prefs: []
  type: TYPE_NORMAL
- en: A Movement Towards more Formal Testing and Monitoring Programs for AI models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Similar to software development 20 years ago, it wasn’t until testing and monitoring
    became common that enterprise software use really took off. AI is at a similar
    inflection point. AI and Machine Learning technologies are being adopted at a
    rapid pace, but quality varies. Often, the data scientists developing the models
    are also the ones manually testing them, and that can lead to blind spots. Testing
    is manual and slow. Monitoring is nascent and ad hoc. And AI model quality is
    highly variable, becoming a gating factor for the successful adoption of AI. Automated
    testing and monitoring provide quality assurance and lowers uncertainty and risk.
  prefs: []
  type: TYPE_NORMAL
- en: AI Model Explainability stays Hot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As AI becomes increasingly important in the lives of everyday people, more people
    want to know exactly how the models work. This is being driven by internal stakeholders
    who need to trust the models they are using, consumers who are impacted by model
    decisions, and regulators who want to make sure that consumers are being treated
    fairly.
  prefs: []
  type: TYPE_NORMAL
- en: More Debate about AI and Bias. Is AI a Friend or Foe to Fairness?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2021 and 2022, people were concerned that AI was causing bias, due to factors
    such as bad training data. In 2023, I think we’ll see a growing realization that
    AI can help eliminate bias by bypassing the historical points where bias came
    into play. People are often more biased than machines - we’re starting to see
    ways that AI can reduce bias rather than to introduce it.
  prefs: []
  type: TYPE_NORMAL
- en: More Zillow-like Debacles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until testing and monitoring is standard practice, enterprises will continue
    to struggle with quality-related issues like the ones [Zillow](https://insidebigdata.com/2021/12/13/the-500mm-debacle-at-zillow-offers-what-went-wrong-with-the-ai-models/)
    faced in its home-buying division (outdated models cause the company to overbuy
    at inflated prices, ultimately leading to the closure of the division and massive
    losses and layoffs). I expect more PR disasters in 2023 that could have been avoided
    with better AI model quality approaches.
  prefs: []
  type: TYPE_NORMAL
- en: A New Vulnerability in the Data Science Ranks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the past several years, there has been a severe shortage of data scientists,
    and companies lucky enough to have them treated them like gold. But as trends
    continue regarding the difficulty of demonstrating ROI on AI efforts, and as the
    economy softens, enterprises are taking a harder line on results. It’s common
    today for only 1 in 10 models developed to ever move into production use. Data
    science teams that aren’t able to get models into production at a faster pace
    will face pressure. Those jobs may not be secure forever.
  prefs: []
  type: TYPE_NORMAL
- en: Formal Regulation of AI uses in the U.S.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: U.S. regulatory agencies have been studying the challenges and impacts of AI,
    but have yet to make a significant move, unlike the European Commission.  I expect
    that to change in 2023, with the U.S. finally drafting its own rules at the federal
    level, similar to those already in effect in the EU and Asia. Guardrails are good
    for everyone in this market, and will ultimately help build trust in AI. U.S.
    regulations are not far off, and businesses should get ready. The recent White
    House [Blueprint for an AI Bill of Rights](https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf),
    released in October 2022, is a step in the right direction, providing a framework
    for the responsible development and use of AI.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI remains one of the fastest-moving areas of technology – but in many ways,
    its promise has yet to be realized. A stronger focus on quality will drive AI
    adoption and help companies achieve a return on their growing AI investments.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Anupam Datta](https://www.linkedin.com/in/anupamdatta/)** is Co-Founder,
    President and Chief Scientist at [TruEra](https://truera.com/). (previously called
    AILens). He was on the faculty at Carnegie Mellon University for 15 years, most
    recently as Professor and Director of the Accountable Systems Lab. His focus is
    on accountable data-driven systems that employ machine learning and other statistical
    and artificial intelligence methods. Datta''s work touches on several other aspects
    of privacy, fairness, compliance and security. Datta obtained Ph.D. (2005) and
    M.S. (2002) degrees from Stanford University and a B.Tech. (2000) from IIT Kharagpur,
    all in Computer Science.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[2023 AI Index Report: AI Trends We Can Expect in the Future](https://www.kdnuggets.com/2023/06/2023-ai-index-report-ai-trends-expect-future.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Quality Dimensions: Assuring Your Data Quality with Great Expectations](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What to Expect From Your Career Path as a Data Scientist](https://www.kdnuggets.com/2022/01/expect-career-path-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Data Scientists Expect Flawed Advice From Google Bard](https://www.kdnuggets.com/2023/02/data-scientists-expect-flawed-advice-google-bard.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Can We Expect From GPT-5?](https://www.kdnuggets.com/2023/06/expect-gpt5.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[H1 2023 Analytics & Data Science Spend & Trends Report](https://www.kdnuggets.com/2023/07/h1-2023-analytics-data-science-spend-trends-report.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
