# 机器学习正在变得实时

> 原文：[https://www.kdnuggets.com/2021/01/machine-learning-real-time.html](https://www.kdnuggets.com/2021/01/machine-learning-real-time.html)

[评论](#comments)

**[Chip Huyen](https://huyenchip.com/)**, Snorkel AI的ML生产，斯坦福大学的讲师。

![实时](../Images/58a4de630b7ab8bbc230e0e05f8d8a0a.png)

在与美国、欧洲和中国主要互联网公司的机器学习和基础设施工程师交谈后，我注意到两类公司。一类公司在基础设施上投入了大量资金（数亿美元），以实现实时机器学习，并已看到投资回报。另一类公司仍在怀疑实时机器学习是否有价值。

关于实时机器学习的定义似乎没有共识，并且在业界关于如何实现实时机器学习的讨论不多。在这篇文章中，我想分享我与大约十几家公司交谈后所学到的。

在这篇文章中，我将讨论实时机器学习的两个级别。

+   Level 1: 你的机器学习系统实时进行预测（在线预测）。

+   Level 2: 你的系统可以实时接收新数据并更新模型（在线学习）。

我使用“模型”来指代机器学习模型，用“系统”来指代围绕它的基础设施，包括数据管道和监控系统。

### Level 1: 在线预测 - 你的系统可以实时进行预测

> ***实时**在这里被定义为毫秒到秒的范围内。*

**用例**

延迟很重要，特别是对于面向用户的应用程序。在2009年，谷歌的实验表明，[将网页搜索延迟增加100到400毫秒会使每个用户的每日搜索次数减少0.2%到0.6%](https://services.google.com/fh/files/blogs/google_delayexp.pdf)。在2019年，[Booking.com发现延迟增加30%会使转化率减少约0.5%——“这是对我们业务的相关成本。”](https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/)

无论你的机器学习模型多么出色，如果它们在进行预测时只慢了几毫秒，用户就会点击其他内容。

**批量预测的问题**

一个非解决方案是避免在线进行预测。你可以在离线批量生成预测，存储它们（例如，在SQL表中），并在需要时提取预先计算的预测。

当输入空间是有限的时，这种方法可以工作——你确切知道要为多少个可能的输入进行预测。例如，当你需要为用户生成电影推荐时，你确切知道有多少用户。因此，你会定期为每个用户预测一组推荐，例如每隔几个小时。

为了使用户输入空间有限，许多应用程序让用户从类别中选择，而不是输入任意查询。例如，如果你去 TripAdvisor，你首先必须选择一个预定义的大都市区域，而不是可以输入任何地点。

这种方法有很多限制。TripAdvisor 的结果在其预定义的类别中，如**“餐馆”**在**“旧金山”**，是可以接受的，但当你尝试输入诸如**“海斯谷的高评分泰国餐馆”**这样的查询时，效果就很差。

![](../Images/23367ba14d3d6d5bcc84a86eddbc7ce9.png)

即使在像 Netflix 这样技术先进的公司中，批量预测也会造成限制。比如你最近看了很多恐怖片，所以当你首次登录 Netflix 时，恐怖片会主导推荐列表。但今天你心情很好，于是搜索了“喜剧”并开始浏览喜剧类别。Netflix 应该会学习并在你的推荐列表中显示更多喜剧内容，对吧？但它无法在下次批量推荐生成之前更新列表。

在上述两个例子中，批量预测会导致用户体验下降（这与用户参与度/保留率紧密相关），而不是灾难性的失败。其他例子包括广告排名、Twitter 的热门话题排名、Facebook 的新闻推送排名、到达时间估算等。

还有许多应用，如果没有在线预测，就会导致灾难性的失败或根本无法工作。例如高频交易、自动驾驶汽车、语音助手、通过面部/指纹解锁手机、老年人跌倒检测、欺诈检测等。能够检测到3小时前发生的欺诈交易仍然比完全无法检测要好，但实时检测可以防止交易完成。

从批量预测转向实时预测可以让你利用动态特征做出更相关的预测。静态特征是那些变化缓慢或很少变化的信息——如年龄、性别、职业、邻里等。动态特征是基于当前发生的事情的特征——如你正在观看的内容、你刚刚点赞的内容等。了解用户当前的兴趣将使你的系统能够做出更符合他们需求的推荐。

![](../Images/d4becf5482ba17f49624c25d3a5cf789.png)

**解决方案**

为了使系统能够进行在线预测，它必须具有两个组件：

1.  快速推理：一种可以在毫秒级别内做出预测的模型。

1.  实时管道：一种可以实时处理数据、将其输入模型并返回预测的管道。

+   **快速推理**

当一个模型过大且预测时间过长时，有三种方法可以解决：

1.  **加快模型速度（推理优化）**

例如，融合操作、分配计算、内存占用优化、编写针对特定硬件的高性能内核等。

1.  **缩小模型（模型压缩）**

最初，这些技术的目的是将模型缩小以适应边缘设备。缩小模型通常会使其运行更快。模型压缩的最常见、通用技术是量化，例如，使用16位浮点数（半精度）或8位整数（定点）来表示模型权重，而不是32位浮点数（全精度）。在极端情况下，一些人尝试了1位表示（二进制权重神经网络），例如，[BinaryConnect](https://arxiv.org/abs/1511.00363)和[Xnor-Net](https://arxiv.org/abs/1603.05279)。Xnor-Net的作者创办了Xnor.ai，这是一家专注于模型压缩的初创公司，后来被[苹果以2亿美元的价格收购](https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/)。

另一种流行技术是[知识蒸馏](https://arxiv.org/abs/1503.02531)——一个小模型（学生）被训练来模仿一个更大的模型或模型集（老师）。尽管学生通常是在一个预训练的老师指导下进行训练，但两者也可以同时训练。一个在生产中使用的蒸馏网络的例子是[DistilBERT](https://arxiv.org/abs/1910.01108)，它将BERT模型的大小减少了40%，同时保留了97%的语言理解能力，并且速度提升了60%。

其他技术包括剪枝（找出对预测最无用的参数并将其设置为0）和低秩分解（用紧凑块替换过度参数化的卷积滤波器，以减少参数数量并提高速度）。有关详细分析，请参见[A Survey of Model Compression and Acceleration for Deep Neural Networks](https://arxiv.org/abs/1710.09282)（Cheng et al. 2017）。

关于模型压缩的研究论文数量在增长。现成的工具也在增加。Awesome Open Source列出了[前40个模型压缩开源项目](https://awesomeopensource.com/projects/model-compression)。

1.  **提升硬件速度**

这是另一个蓬勃发展的研究领域。大公司和初创公司都在竞相开发能够加快大型ML模型推理速度的硬件，包括云端和设备上的训练。IDC预测，到2020年，边缘和移动设备的推理总量将达到[37亿台，另外还有1.16亿台用于训练](https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513)。

+   **实时管道**

假设你有一个共享出行应用，想要检测欺诈交易，例如，使用盗取的信用卡进行支付。当真正的信用卡持有人发现未经授权的支付时，他们会与银行争议，你将不得不退还费用。为了最大化利润，欺诈者可能会连续打车或从多个账户中打车。2019年，商家估计欺诈交易占其年在线销售额的平均[27%](https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf)。你检测到盗用信用卡的时间越长，你损失的钱就越多。

要检测交易是否欺诈，仅仅查看该交易是不够的。你至少需要查看涉及该交易的用户的近期历史记录、他们在应用中的近期行程和活动、信用卡的近期交易，以及其他同时发生的交易。

为了快速访问这些信息，你希望尽可能将它们保存在内存中。每次发生你关心的事件——用户选择位置、预订行程、联系司机、取消行程、添加信用卡、删除信用卡等——该事件的信息都会存入你的内存存储中。这些信息会在有用的时间内保留（通常是几天），然后要么转入永久存储（例如S3），要么被丢弃。最常用的工具是[Apache Kafka](https://github.com/apache/kafka)，还有像Amazon Kinesis这样的替代品。Kafka是一种流存储：它在数据流动时存储数据。

流数据与静态数据不同——静态数据是指已经存在的完整数据，例如CSV文件。当从CSV文件中读取时，你知道任务何时完成。而数据流是不断进行的。

一旦你有了管理流数据的方法，你就会想要提取特征以输入到你的机器学习模型中。除了流数据的特征，你可能还需要静态数据的特征（例如，该账户何时创建，用户的评分等）。你需要一个工具，它允许你处理流数据和静态数据，并将它们从各种数据源中结合起来。

**流处理与批处理**

人们通常使用“批处理”来指代静态数据处理，因为你可以批量处理这些数据。这与“流处理”相对，流处理是在每个事件到达时进行处理。批处理是**高效的**——你可以利用像 MapReduce 这样的工具处理大量数据。流处理是**快速的**，因为你可以在数据到达时立即处理它。Apache Flink 的 PMC 成员 Robert Metzger 争辩说，流处理不可能像批处理一样高效，因为[批处理是流处理的一种特殊情况](https://www.ververica.com/blog/batch-is-a-special-case-of-streaming)。

处理流数据更为困难，因为数据量是无限的，并且数据以不稳定的速率和速度到达。让流处理器进行批处理要比让批处理器进行流处理容易。

Apache Kafka 具有一定的流处理能力，一些公司在其 Kafka 流存储之上使用了这种能力，但 Kafka 流处理在处理各种数据源的能力上有限。已有努力扩展 SQL，这种流行的查询语言旨在处理静态数据表，以处理数据流 [[1](http://cs.brown.edu/~ugur/streamsql.pdf), [2](https://en.wikipedia.org/wiki/StreamSQL)]。然而，最受欢迎的流处理工具是[Apache Flink](https://github.com/apache/flink)，它原生支持批处理。

在机器学习生产的早期阶段，许多公司将他们的机器学习系统建立在现有的 MapReduce/Spark/Hadoop 数据管道之上。当这些公司希望进行实时推理时，他们需要建立一个独立的流数据管道。

拥有两个不同的管道来处理数据是机器学习生产中常见的错误来源，例如，一个管道中的变化未能正确地复制到另一个管道，导致两个管道提取了不同的特征集。如果这两个管道由两个不同的团队维护，则尤其常见，例如，开发团队维护用于训练的批处理管道，而部署团队维护用于推理的流处理管道。包括[Uber](https://www.infoq.com/presentations/sql-streaming-apache-flink/)和[微博](https://www.youtube.com/watch?v=WQ520rWgd9A&ab_channel=FlinkForward)在内的公司已经进行了重大基础设施改造，以使用 Flink 统一它们的批处理和流处理管道。

**事件驱动 vs. 请求驱动**

在过去十年中，软件世界已经转向微服务。这个概念是将业务逻辑拆分成小组件——每个组件都是一个独立的服务——可以独立维护。每个组件的所有者可以快速更新和测试该组件，而不必咨询系统的其他部分。

微服务通常与 REST 一起使用，REST 是一组方法，用于让这些微服务进行通信。REST API 是请求驱动的。客户端（服务）通过 POST 和 GET 等方法向服务器发送请求，指示服务器执行特定操作，服务器则以结果响应。服务器必须监听请求才能使请求注册。

由于在请求驱动的世界中，数据通过向不同服务发出的请求进行处理，没有人能够概览数据如何流经整个系统。考虑一个包含 3 个服务的简单系统：

+   A 管理司机可用性

+   B 管理乘车需求

+   C 预测每次客户请求乘车时的最佳价格

由于价格依赖于可用性和需求，服务 C 的输出依赖于服务 A 和 B 的输出。首先，该系统需要服务间通信：C 需要向 A 和 B 请求预测，A 需要向 B 请求以了解是否需要调动更多司机，并向 C 请求以了解应给予司机什么价格激励。其次，监控 A 或 B 逻辑的变化如何影响服务 C 的性能，或者映射数据流以调试服务 C 性能突然下降的问题，将变得非常困难。

仅仅是 3 个服务，事情已经变得复杂。想象一下拥有数百个，甚至上千个服务的情况，就像大型互联网公司那样。服务间通信将会爆炸。以 JSON 数据块通过 HTTP 发送数据——这是 REST 请求的常见方式——也很慢。服务间数据传输可能成为瓶颈，减缓整个系统的速度。

如果不让 20 个服务向服务 A 请求数据，而是每当服务 A 内发生事件时，这个事件被广播到一个流中，而任何需要 A 数据的服务可以订阅这个流并提取所需的内容，这会怎样？如果所有服务都可以广播它们的事件并订阅一个流，这种模型被称为 pub/sub：发布 & 订阅。这就是像 Kafka 这样的解决方案所允许的。由于所有数据都通过流进行传输，你可以设置一个仪表板来监控数据及其在系统中的变化。由于它基于服务广播的事件，这种架构是事件驱动的。

![](../Images/4ceecb97d4d7ef3d243f242fa13277c7.png)

*[超越微服务：流、状态与可扩展性](https://www.infoq.com/presentations/microservices-streams-state-scalability/) (Gwen Shapira, QCon 2019)。*

请求驱动的架构适用于依赖于逻辑而非数据的系统。事件驱动的架构更适合数据密集型的系统。

**挑战**

许多公司正在从批处理转向流处理，从请求驱动架构转向事件驱动架构。我与美国和中国主要互联网公司交流后的印象是，美国的这种变化仍然较慢，而中国的速度要快得多。流处理架构的采用与Kafka和Flink的流行程度密切相关。罗伯特·梅茨格告诉我，他观察到亚洲的Flink机器学习工作负载比美国更多。Google Trends中“Apache Flink”的数据与这一观察结果一致。

![](../Images/57fdf04eedadbcf1c20c288a28d4c694.png)

流处理不够流行有很多原因。

1.  **公司看不到流处理的好处**

    +   他们的系统规模尚未达到服务间通信成为瓶颈的程度。

    +   他们没有从在线预测中受益的应用程序。

    +   他们有可能从在线预测中受益的应用程序，但由于他们之前从未进行过在线预测，因此尚未意识到这一点。

1.  **高初期基础设施投资**

    基础设施更新成本高昂，可能会危及现有应用程序。经理们可能不愿意投资升级基础设施以支持在线预测。

1.  **心理转变**

    从批处理切换到流处理需要心理转变。使用批处理，你知道一个任务什么时候完成。使用流处理，它永远不会完成。你可以制定规则，比如获取过去2分钟内所有数据点的平均值，但如果发生在2分钟前的事件被延迟了，还没有进入流中呢？使用批处理，你可以有定义明确的表并将其连接起来，但在流处理中没有表可以连接，那么对两个流进行连接操作意味着什么？

1.  **Python不兼容**

    Python是机器学习的通用语言，而Kafka和Flink运行在Java和Scala上。引入流处理可能会在工作流程中造成语言不兼容。Apache Beam在Flink之上提供了一个Python接口用于与流进行通信，但你仍然需要能够使用Java/Scala的人。

1.  **更高的处理成本**

    批处理意味着你可以更有效地利用计算资源。如果你的硬件能够一次处理1000个数据点，那么仅处理1个数据点就是浪费。

### 第二级：在线学习 - 你的系统可以实时整合新数据并进行更新

> ***实时**在这里定义为以分钟为单位*

**定义“在线学习”**

我使用“在线学习”而不是“在线训练”，因为后者的定义有争议。根据定义，在线训练意味着从每个进入的数据点中学习。实际上，极少有公司做到这一点，因为：

+   这种方法遭遇灾难性遗忘——神经网络在学习新信息时会突然忘记先前学到的信息。

+   在仅用一个数据点进行学习的步骤可能比批量处理更昂贵（这可以通过拥有足够强大的硬件来处理恰好一个数据点来缓解）。

即使一个模型在每次接收到数据点时都在学习，也不意味着每个数据点后都会部署新的权重。由于我们目前对机器学习算法的理解有限，更新的模型需要先进行评估，以查看其效果如何。

对于大多数进行所谓在线训练的公司，它们的模型在微批量中进行学习，并在一定时间后进行评估。只有在模型性能被评估为满意后，才会进行更广泛的部署。对于微博而言，它们的学习到部署模型更新的迭代周期为10分钟。

![](../Images/2b26a0ab4dcd1b6e180e6e7347bb5be9.png)

*[微博中的Flink机器学习](https://www.youtube.com/watch?v=WQ520rWgd9A) (Qian Yu, Flink Forward 2020).*

**用例**

TikTok 非常令人上瘾。它的秘密在于其 [推荐系统](https://newsroom.tiktok.com/en-us/how-tiktok-recommends-videos-for-you) 可以迅速学习你的偏好并建议你可能会观看的下一个视频，为用户提供了令人惊叹的滚动体验。这是因为 TikTok 的背后公司字节跳动建立了成熟的基础设施，使其推荐系统能够实时学习用户偏好（在他们的术语中称为“用户画像”）。

推荐系统是在线学习的完美候选者。它们具有自然标签——如果用户点击了推荐内容，那就是正确的预测。并非所有的推荐系统都需要在线学习。用户对房屋、汽车、航班、酒店等物品的偏好不太可能在短时间内改变，因此系统持续学习意义不大。然而，用户对在线内容（如视频、文章、新闻、推文、帖子、迷因）的偏好可以迅速变化（“我刚刚读到章鱼有时无缘无故地打鱼，现在我想看一个相关的视频”）。随着在线内容偏好的实时变化，广告系统也需要实时更新以展示相关广告。

在线学习对系统适应稀有事件至关重要。以黑色星期五的在线购物为例。由于黑色星期五一年只有一次，亚马逊或其他电商网站无法获得足够的历史数据来学习用户当天的行为，因此它们的系统需要在当天持续学习以适应。

或者考虑一下当某个名人发推特时的Twitter搜索。例如，当“四季总景观”的新闻一发布，很多人都会去搜索“总景观”。如果你的系统没有立即学习到“总景观”这里指的是新闻发布会，你的用户会得到很多园艺推荐。

在线学习也可以帮助解决冷启动问题。一个用户刚刚加入你的应用程序，而你还没有关于他们的信息。如果你没有任何形式的在线学习能力，你将不得不为用户提供通用推荐，直到下一次离线训练模型时。

**解决方案**

由于在线学习仍然比较新，而且大多数实施它的公司尚未公开详细信息，所以没有标准解决方案。

在线学习并不意味着“没有批量训练”。那些最成功地使用在线学习的公司通常也会将模型离线训练与在线版本结合起来。

**挑战**

在线学习面临许多挑战，包括理论上的和实际上的。

+   **理论**

在线学习颠覆了我们对机器学习的许多传统认识。在初级机器学习课程中，学生们可能会学习到“用足够的轮次训练模型直到收敛”的不同版本。然而，在在线学习中，没有轮次——你的模型每次只看到一个数据点。也没有所谓的收敛。你的基础数据分布不断变化，没有任何静态的东西可以收敛。

在线学习的另一个理论挑战是模型评估。在传统的批量训练中，你会在静态的保留测试集上评估模型。如果一个新模型在相同的测试集上表现优于现有模型，我们会说新模型更好。然而，在线学习的目标是使模型适应不断变化的数据。如果你的更新模型是为了适应现在的数据，而我们知道现在的数据与过去的数据不同，那么用旧数据来测试更新后的模型就没有意义了。

那么我们如何知道过去10分钟的数据训练的模型比20分钟前的数据训练的模型更好呢？我们必须在当前数据上比较这两个模型。在线训练要求在线评估，但提供一个未经用户测试的模型似乎是灾难的配方。

许多公司还是会这样做。新的模型首先会进行离线测试，以确保它们不会造成灾难，然后与现有模型通过复杂的A/B测试系统在线评估。只有当一个模型在公司关心的一些指标上表现优于现有模型时，它才能被广泛部署。（别让我开始谈选择在线评估指标的问题）。

+   **实际**

目前还没有标准的在线培训基础设施。一些公司已经趋向于使用[参数服务器](https://web.eecs.umich.edu/~mosharaf/Readings/Parameter-Server.pdf)的流式架构，但除了这些之外，我谈到的进行在线培训的公司必须在内部建立许多基础设施。我不愿意在线讨论这个问题，因为一些公司要求我保密这些信息，因为他们正在为其构建解决方案——这是他们的竞争优势。

### 中美MLOps竞争

我阅读了很多关于中美人工智能竞争的文章，但大多数比较似乎集中在[研究论文、专利、引用和资金](https://datainnovation.org/2019/08/who-is-winning-the-ai-race-china-the-eu-or-the-united-states/)的数量上。只有在我开始与中美两国公司讨论实时机器学习后，我才发现他们的MLOps基础设施存在惊人的差异。

很少有美国互联网公司尝试在线学习，即使在这些公司中，在线学习也仅用于如逻辑回归等简单模型。通过直接与中国公司交流以及与在中美两国公司工作过的人交谈，我的印象是在线学习在中国更为普遍，中国工程师更愿意尝试这种技术。你可以在[这里](https://twitter.com/chipro/status/1337077324936663040)和[这里](https://www.linkedin.com/posts/chiphuyen_mlops-machinelearning-activity-6742844916705177600-taRd)查看一些对话。

![](../Images/11a1db19b83783be99737342f17b6bea.png)

### 结论

机器学习正趋向实时，无论你是否准备好。虽然大多数公司仍在争论在线推理和在线学习的价值，但那些正确实施的公司已经看到了投资回报，他们的实时算法可能是帮助他们领先竞争对手的主要因素。

我对实时机器学习有很多想法，但这篇文章已经很长。如果你有兴趣讨论这个话题，可以给我发邮件。

### 致谢

这篇文章是许多与以下优秀工程师和学者对话的总结。我想感谢Robert Metzger、Neil Lawrence、Savin Goyal、Zhenzhong Xu、Ville Tuulos、Dat Tran、Han Xiao、Hien Luu、Ledio Ago、Peter Skomoroch、Piero Molino、Daniel Yao、Jason Sleight、Becket Qin、Tien Le、Abraham Starosta、Will Deaderick、Caleb Kaiser、Miguel Ramos。

[原文](https://huyenchip.com/2020/12/27/real-time-machine-learning.html)。经许可转载。

**简介：** [Chip Huyen](https://twitter.com/chipro) 是一位作家和计算机科学家。她致力于将最佳工程实践带入机器学习研究和生产中。她还撰写关于文化、人和科技的文章。

**相关：**

+   [概念漂移在流学习应用中的破坏及应对方法](https://www.kdnuggets.com/2019/12/ravages-concept-drift-stream-learning-applications.html)

+   [推荐引擎与实时个性化 – 下载指南](https://www.kdnuggets.com/2017/10/dataiku-recommendation-engines-real-time-personalization-download-guidebook.html)

+   [如何使用MLOps制定有效的AI战略](https://www.kdnuggets.com/2021/01/mlops-effective-ai-strategy.html)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 为你的组织提供IT支持

* * *

### 更多相关话题

+   [如何跟上人工智能领域的最新动态](https://www.kdnuggets.com/2022/03/stay-top-going-ai-world.html)

+   [Python中的情感分析：超越词袋模型](https://www.kdnuggets.com/sentiment-analysis-in-python-going-beyond-bag-of-words)

+   [每个机器学习工程师都应该掌握的5项机器学习技能…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)

+   [KDnuggets 新闻，12月14日：3个免费的机器学习课程…](https://www.kdnuggets.com/2022/n48.html)

+   [学习数据科学、机器学习和深度学习的稳固计划](https://www.kdnuggets.com/2023/01/mwiti-solid-plan-learning-data-science-machine-learning-deep-learning.html)

+   [人工智能、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)
