- en: Natural Language Processing Library for Apache Spark – free to use
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Spark 的自然语言处理库 – 免费使用
- en: 原文：[https://www.kdnuggets.com/2017/11/natural-language-processing-library-apache-spark.html](https://www.kdnuggets.com/2017/11/natural-language-processing-library-apache-spark.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/11/natural-language-processing-library-apache-spark.html](https://www.kdnuggets.com/2017/11/natural-language-processing-library-apache-spark.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [David Talby](https://twitter.com/davidtalby?lang=en), CTO Usermind**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [David Talby](https://twitter.com/davidtalby?lang=en)，Usermind 首席技术官**。'
- en: Apache Spark is a general-purpose cluster computing framework, with native support
    for distributed SQL, streaming, graph processing, and machine learning. Now, the
    Spark ecosystem also has an [Spark Natural Language Processing library](https://nlp.johnsnowlabs.com/).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是一个通用集群计算框架，原生支持分布式 SQL、流处理、图处理和机器学习。现在，Spark 生态系统还拥有一个 [Spark
    自然语言处理库](https://nlp.johnsnowlabs.com/)。
- en: Get it on [GitHub](https://github.com/johnsnowlabs/spark-nlp) or begin with
    the [quickstart tutorial](https://nlp.johnsnowlabs.com/quickstart.html).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [GitHub](https://github.com/johnsnowlabs/spark-nlp) 上获取或从 [快速入门教程](https://nlp.johnsnowlabs.com/quickstart.html)
    开始。
- en: 'The John Snow Labs NLP Library is under the Apache 2.0 license, written in
    Scala with no dependencies on other NLP or ML libraries. It natively extends the [Spark
    ML Pipeline API](https://blog.insightdatascience.com/spark-pipelines-elegant-yet-powerful-7be93afcdd42).
    You will benefit from:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: John Snow Labs NLP 库遵循 Apache 2.0 许可，使用 Scala 编写，不依赖其他 NLP 或 ML 库。它本地扩展了 [Spark
    ML Pipeline API](https://blog.insightdatascience.com/spark-pipelines-elegant-yet-powerful-7be93afcdd42)。你将受益于：
- en: Unmatched runtime performance, since processing is done directly on Spark DataFrames
    without any copying and taking full advantage of Spark’s caching, execution planning
    and optimized binary data format.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无与伦比的运行时性能，因为处理直接在 Spark DataFrames 上完成，无需任何复制，并充分利用 Spark 的缓存、执行计划和优化的二进制数据格式。
- en: Frictionless reuse of existing Spark libraries, including distributed topic
    modelling, word embeddings, n-gram calculation, string distance calculations and
    more.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无摩擦地重用现有的 Spark 库，包括分布式主题建模、词嵌入、n-gram 计算、字符串距离计算等。
- en: Higher productivity by using a unified API across the Natural Language Understanding,
    Machine Learning & Deep Learning parts of a data science pipeline.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在数据科学管道的自然语言理解、机器学习和深度学习部分使用统一的 API 提高生产力。
- en: “With John Snow Labs NLP, we’re delivering on the promise to enable customers
    to take advantage of the latest open source technology and academic breakthroughs
    in data science, all within a high performance, enterprise-grade code base.”,
    said the founding team. In addition, “John Snow Labs NLP encompasses a wide range
    of highly efficient Natural Language Understanding tools for text mining, question
    answering, chat bots, fact extraction, topic modelling or Search, running at a
    scale and performance that has not been available to date.”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: “通过 John Snow Labs NLP，我们兑现了使客户能够利用最新开源技术和数据科学中的学术突破的承诺，所有这些都在高性能的企业级代码库中。”，创始团队表示。此外，“John
    Snow Labs NLP 包含了一系列高效的自然语言理解工具，用于文本挖掘、问答、聊天机器人、事实提取、主题建模或搜索，运行规模和性能在现有技术中尚未出现。”
- en: 'The framework provides the concepts of annotators, and comes out of the box
    with:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 框架提供了标注器的概念，并且开箱即用：
- en: Tokenizer
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分词器
- en: Normalizer
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归一化器
- en: Stemmer
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词干提取器
- en: Lemmatizer
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词形还原器
- en: Entity Extractor
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实体提取器
- en: Date Extractor
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期提取器
- en: Part of Speech Tagger
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词性标注器
- en: Named Entity Recognition
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名实体识别
- en: Sentence boundary detection
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 句子边界检测
- en: Sentiment analysis
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析
- en: Spell checker
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拼写检查器
- en: In addition, given the tight integration with Spark ML, there is a lot more
    you can use right away when building your NLP pipelines. This includes word embeddings,
    topic modeling, stop word removal, a variety of feature engineering functions
    (tf-idf, n-grams, similarity metrics, …) and using NLP annotations as features
    in machine learning workflows. If you’re not familiar with these terms, this [guide
    to understanding NLP tasks](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/) is
    a good start.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑到与Spark ML的紧密集成，在构建NLP管道时你可以立即使用更多功能。这包括词嵌入、主题建模、停用词移除、各种特征工程函数（tf-idf、n-grams、相似度度量等）以及将NLP注释作为机器学习工作流中的特征。如果你不熟悉这些术语，这个
    [理解NLP任务的指南](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/)
    是一个好的起点。
- en: '![High Performance NLP Spark](../Images/90627fd777f2f745bd23d3810e3cfd11.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![高性能NLP Spark](../Images/90627fd777f2f745bd23d3810e3cfd11.png)'
- en: Our virtual team has been building commercial software that heavily depends
    on natural language understanding for several years now. As such, we have hands-on
    experience with [spaCy](https://spacy.io/), [CoreNLP](https://stanfordnlp.github.io/CoreNLP/), [OpenNLP](https://opennlp.apache.org/), [Mallet](https://mallet.cs.umass.edu/), [GATE](https://gate.ac.uk/), [Weka](https://www.cs.waikato.ac.nz/ml/weka/), [UIMA](https://uima.apache.org/), [nltk](https://www.nltk.org/), [gensim](https://radimrehurek.com/gensim/), [Negex](https://blulab.chpc.utah.edu/content/contextnegex), [word2vec](https://code.google.com/archive/p/word2vec/), [GloVe](https://nlp.stanford.edu/projects/glove/),
    and a few others.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的虚拟团队已经在构建严重依赖自然语言理解的商业软件多年。因此，我们对 [spaCy](https://spacy.io/)、 [CoreNLP](https://stanfordnlp.github.io/CoreNLP/)、
    [OpenNLP](https://opennlp.apache.org/)、 [Mallet](https://mallet.cs.umass.edu/)、
    [GATE](https://gate.ac.uk/)、 [Weka](https://www.cs.waikato.ac.nz/ml/weka/)、 [UIMA](https://uima.apache.org/)、
    [nltk](https://www.nltk.org/)、 [gensim](https://radimrehurek.com/gensim/)、 [Negex](https://blulab.chpc.utah.edu/content/contextnegex)、
    [word2vec](https://code.google.com/archive/p/word2vec/)、 [GloVe](https://nlp.stanford.edu/projects/glove/)
    和一些其他工具有实际的经验。
- en: We are big fans, and the many places where we’ve imitated these libraries are
    intended as the sincere form of flattery that they are. But we’ve also banged
    our heads too many times against their limitations – when we’ve had to deliver
    scalable, high-performance, high-accuracy software for real production use.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是这些库的大粉丝，我们模仿它们的许多地方旨在表达我们诚挚的赞美之情。然而，当我们需要交付可扩展、高性能、高准确度的实际生产软件时，我们也多次撞上了它们的限制。
- en: '**Performance**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能**'
- en: The first of three top-level requirements we tackled is runtime performance.
    You’d think this was largely a solved problem with the advent of [spaCy and its
    public benchmarks](https://spacy.io/docs/api/) which reflect a well thought-out
    and masterfully implemented set of tradeoffs. However, when building Spark applications
    on top of it, you’d still get unreasonably subpar throughput.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决的三个顶级需求中的第一个是运行时性能。你会认为随着 [spaCy及其公共基准](https://spacy.io/docs/api/) 的出现，这个问题已经基本解决，它们反映了一个经过深思熟虑和精心实现的权衡集合。然而，在其基础上构建Spark应用程序时，你仍会遇到不合理的低吞吐量。
- en: 'To understand why, consider that an NLP pipeline is always just a part of a
    bigger data processing pipeline: For example, question answering involves loading
    training, data, transforming it, applying NLP annotators, building features, training
    the value extraction models, evaluating the results (train/test split or cross-validation),
    and hyper-parameter estimation.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解原因，可以考虑NLP管道总是数据处理管道的一部分：例如，问题回答涉及加载训练数据、转换数据、应用NLP注释器、构建特征、训练价值提取模型、评估结果（训练/测试拆分或交叉验证）和超参数估计。
- en: Splitting your data processing framework (Spark) from your NLP frameworks means
    that most of your processing time gets spent serializing and copying strings.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据处理框架（Spark）与NLP框架分开意味着你大部分的处理时间都会花在序列化和复制字符串上。
- en: 'A great parallel is [TensorFrames](https://github.com/databricks/tensorframes) –
    which greatly improves the performance of running TensorFlow workflows on Spark
    data frames. This image is credited to [Tim Hunter’s excellent TensorFrames overview](https://www.slideshare.net/databricks/tensorframes-google-tensorflow-on-apache-spark):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的类比是 [TensorFrames](https://github.com/databricks/tensorframes)——它显著提高了在Spark数据框上运行TensorFlow工作流的性能。此图像归功于
    [Tim Hunter的优秀TensorFrames概述](https://www.slideshare.net/databricks/tensorframes-google-tensorflow-on-apache-spark)：
- en: '![Spark Communication](../Images/65ff80686b4d84caff0c9d06344ba82f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Communication](../Images/65ff80686b4d84caff0c9d06344ba82f.png)'
- en: Both Spark and TensorFlow are optimized to the extreme for performance and scale.
    However, since DataFrames live in the JVM and TensorFlow runs in a Python process,
    any integration between the two frameworks means that every object has to be serialized,
    go through inter-process communication (!) in both ways, and copied at least twice
    in memory. TensorFrames public benchmarks report a 4x speedup by just copying
    the data within the JVM process (and much more when using GPUs).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 和 TensorFlow 都在性能和规模上进行了极致优化。然而，由于 DataFrames 存在于 JVM 中，而 TensorFlow 运行在
    Python 进程中，因此两个框架之间的任何集成都意味着每个对象都必须序列化，经过双向的进程间通信 (!) 并在内存中至少复制两次。TensorFrames
    的公开基准报告显示，仅通过在 JVM 进程中复制数据就能获得 4 倍的加速（使用 GPU 时效果更显著）。
- en: 'We see the same issue when using spaCy with Spark: Spark is highly optimized
    for loading & transforming data, but running an NLP pipeline requires copying
    all the data outside the Tungsten optimized format, serializing it, pushing it
    to a Python process, running the NLP pipeline (this bit is lightning fast), and
    then re-serializing the results back to the JVM process. This naturally kills
    any performance benefits you would get from Spark’s caching or execution planner,
    requires at least twice the memory, and doesn’t improve with scaling. Using CoreNLP
    eliminates the copying to another process, but still requires copying all text
    from the data frames and copying the results back in.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当将 spaCy 与 Spark 一起使用时，我们遇到相同的问题：Spark 在加载和转换数据方面高度优化，但运行 NLP 管道需要将所有数据从 Tungsten
    优化格式外部复制，序列化，推送到 Python 进程中，运行 NLP 管道（这一部分非常快速），然后将结果重新序列化回 JVM 进程。这自然会消耗你从 Spark
    的缓存或执行计划中获得的任何性能收益，需要至少两倍的内存，并且在扩展时没有改善。使用 CoreNLP 消除了复制到另一个进程的需求，但仍然需要将所有文本从数据框中复制并将结果重新复制回来。
- en: 'So our first order of business is to perform the analysis directly on the optimized
    data frames, as Spark ML already does (credit: [ML Pipelines introduction post
    by Databricks](https://databricks.com/blog/2015/01/07/ml-pipelines-a-new-high-level-api-for-mllib.html)):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们首先的任务是直接对优化后的数据框进行分析，就像 Spark ML 已经做的那样（来源：[Databricks 的 ML Pipelines 介绍文章](https://databricks.com/blog/2015/01/07/ml-pipelines-a-new-high-level-api-for-mllib.html)）：
- en: '![Spark Pipeline Model](../Images/bbf4f7ab8883466cc9278044acac0b2f.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Pipeline Model](../Images/bbf4f7ab8883466cc9278044acac0b2f.png)'
- en: '**Ecosystem**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**生态系统**'
- en: Our second core requirement was frictionless reuse of existing Spark libraries.
    Part of it is our own pet peeve – why does every NLP library out there have to
    build its own topic modeling and word embedding implementations? The other part
    is pragmatic – we’re a small team under tight deadlines and need to make the most
    of what’s already there.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个核心要求是无摩擦地重用现有的 Spark 库。其中一部分是我们自己的痛点——为什么所有的 NLP 库都必须构建自己的主题建模和词嵌入实现？另一部分是务实的——我们是一个小团队，时间紧迫，需要充分利用现有资源。
- en: 'When we started thinking about a Spark NLP library, we first asked Databricks
    to point us to whoever is already building one. When the answer came there there
    isn’t one, the next ask was to help us make sure the design and API of the library
    fully meet Spark ML’s API guidelines. The result of this collaboration is that
    the library is a seamless extension of Spark ML, so that for example you can build
    this kind of pipeline:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始考虑一个 Spark NLP 库时，我们首先询问了 Databricks，指引我们找出已经在构建这个库的人。当得到的回答是没有这样一个库时，我们的下一个要求是帮助我们确保这个库的设计和
    API 完全符合 Spark ML 的 API 指南。这次合作的结果是这个库无缝扩展了 Spark ML，例如你可以构建这种管道：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this code, the document assembler, tokenizer, and stemmer come from the Spark
    NLP library – the com.jsl.nlp.* package. The TF hasher, IDF and labelDeIndex all
    come from MLlib’sorg.apache.spark.ml.feature.* package. The dtree stage is a spark.ml.classification.DecisionTreeClassifier.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，文档汇编器、分词器和词干提取器来自 Spark NLP 库——com.jsl.nlp.* 包。TF 哈希器、IDF 和 labelDeIndex
    都来自 MLlib 的 org.apache.spark.ml.feature.* 包。dtree 阶段是 spark.ml.classification.DecisionTreeClassifier。
- en: All these stages run within one pipeline that is configurable, serializable
    and testable in the exact same way. They also run on a data frame without any
    copying of data (unlike [spark-corenlp](https://spark-packages.org/package/databricks/spark-corenlp)),
    enjoying Spark’s signature in-memory optimizations, parallelism and distributed
    scale out.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些阶段都在一个管道内运行，该管道是可配置的、可序列化的和可测试的，并且以完全相同的方式进行。它们还在数据框上运行，而无需复制数据（与 [spark-corenlp](https://spark-packages.org/package/databricks/spark-corenlp)
    不同），享受 Spark 的标志性内存优化、并行性和分布式扩展。
- en: What this means is the John Snow Labs NLP library comes with fully distributed,
    heavily tested and optimized [topic modeling](https://medium.com/zero-gravity-labs/lda-topic-modeling-in-spark-mllib-febe84b9432), [word
    embedding](https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec),
    n-gram generation, and cosine similarity out of the box. We didn’t have to build
    them though – they come with Spark.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 John Snow Labs NLP 库附带了完全分布式、经过严格测试和优化的 [主题建模](https://medium.com/zero-gravity-labs/lda-topic-modeling-in-spark-mllib-febe84b9432)、[词嵌入](https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec)、n-gram
    生成和余弦相似度功能。我们不需要自己构建这些功能——它们是与 Spark 一起提供的。
- en: Most importantly, it means that your NLP and ML pipelines are now unified. The
    above code sample is typical, in the sense that it’s not “just” an NLP pipeline
    – NLP is used to generate features which are then used to train a decision tree.
    This is typical of question answering tasks. A more complex example would also
    apply named entity recognition, filtered by POS tags and coreference resolution;
    train a random forest, taking into account both NLP-based features and structured
    features from other sources; and use grid search for hyper-parameter optimization.
    Being able to use a unified API pays dividends whenever you need to test, reproduce,
    serialize or publish such a pipeline – even beyond the performance and reuse benefits.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，这意味着你的 NLP 和 ML 管道现在是统一的。上述代码示例是典型的，因为它不仅仅是一个 NLP 管道——NLP 用于生成特征，然后用这些特征训练决策树。这在问答任务中很常见。一个更复杂的例子还会应用命名实体识别，按
    POS 标签和共指解析过滤；训练随机森林，考虑 NLP 基于的特征和其他来源的结构化特征；并使用网格搜索进行超参数优化。能够使用统一的 API 在需要测试、重现、序列化或发布这样的管道时非常有利——甚至超出了性能和重用的好处。
- en: '**Enterprise Grade**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**企业级**'
- en: Our third core requirement is delivering a mission-critical, enterprise-grade
    NLP library. We make our living building production software. Many of the most
    popular NLP packages today have academic roots – which shows in design trade-offs
    that favor ease of prototyping over runtime performance, breadth of options over
    simple minimalist API’s, and downplaying of scalability, error handling, frugal
    memory consumption and code reuse.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第三个核心要求是提供一个任务关键型、企业级的 NLP 库。我们的工作是构建生产软件。许多当前最受欢迎的 NLP 包具有学术背景——这在设计权衡中表现出来，例如优先考虑原型设计的简便性而非运行时性能，选项的广度而非简单的简约
    API，以及对可扩展性、错误处理、节省内存和代码重用的轻视。
- en: 'The John Snow Labs NLP library is written in Scala. It includes Scala and Python
    APIs for use from Spark. It has no dependency on any other NLP or ML library.
    For each type of annotator, we do an academic literature review to find the state
    of the art, have a team discussion and decide which algorithm(s) to implement.
    Implementations are evaluated on three criteria:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: John Snow Labs NLP 库是用 Scala 编写的。它包括用于 Spark 的 Scala 和 Python API。它不依赖于任何其他
    NLP 或 ML 库。对于每种类型的注释器，我们会进行学术文献综述以找出最先进的技术，进行团队讨论并决定要实现哪些算法。实现根据三个标准进行评估：
- en: '**Accuracy** – there’s no point in a great framework, if it has sub-par algorithms
    or models.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性** – 如果框架有低于标准的算法或模型，那么再好的框架也没有意义。'
- en: '**Performance** – runtime should be on par or better than any public benchmark.
    No one should have to give up accuracy because annotators don’t run fast enough
    to handle a streaming use case, or don’t scale well in a cluster setting.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能** – 运行时应该与任何公共基准相当或更好。没有人应该因为注释器的速度不够快以处理流式用例，或在集群设置中扩展性不好而牺牲准确性。'
- en: '**Trainability or Configurability** – NLP is an inherently domain-specific
    problem. Different grammars and vocabularies are used in social media posts vs.
    academic papers vs. SEC filings vs. electronic medical records vs. newspaper articles.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可训练性或可配置性** – NLP 是一个固有的领域特定问题。社交媒体帖子、学术论文、SEC 文件、电子病历和报纸文章使用了不同的语法和词汇。'
- en: The library is already in use in enterprise projects – which means that the
    first level of bugs, refactoring, unexpected bottlenecks and serialization issues
    have been resolved. Unit test coverage and [reference documentation](https://nlp.johnsnowlabs.com/components.html) are
    at a level that made us comfortable to make the code open source.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 该库已经在企业项目中使用，这意味着第一层次的错误、重构、意外瓶颈和序列化问题已得到解决。单元测试覆盖率和 [参考文档](https://nlp.johnsnowlabs.com/components.html)
    已经达到让我们放心将代码开源的水平。
- en: '[John Snow Labs](https://www.johnsnowlabs.com/) is the company leading and
    sponsoring the development of the Spark NLP library. The company provides commercial
    support, indemnification and consulting for it. This provides the library with
    long-term financial backing, a funded active development team, and a growing stream
    of real-world projects that drives robustness and roadmap prioritization.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[John Snow Labs](https://www.johnsnowlabs.com/) 是领导和资助 Spark NLP 库开发的公司。该公司为该库提供商业支持、赔偿和咨询服务。这为库提供了长期的财务支持、资助的活跃开发团队以及不断增长的现实世界项目流，推动了库的稳定性和路线图优先级。'
- en: '**Getting involved**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**参与方式**'
- en: If you need NLP for your current project, head to the [John Snow Labs NLP for
    Apache Spark homepage](https://nlp.johnsnowlabs.com/) or quickstart guide and
    give it a try. Prebuilt maven central (Scala) and pip install (Python) versions
    are available. Send us questions or feedback to nlp@johnsnowlabs.com or via [Twitter](https://twitter.com/johnsnowlabs),
    [LinkedIn](https://www.linkedin.com/company/10349856/) or [Facebook](https://www.facebook.com/JohnSnowLabsInc).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要 NLP 用于当前项目，请访问 [John Snow Labs NLP for Apache Spark 主页](https://nlp.johnsnowlabs.com/)
    或快速入门指南进行尝试。提供预构建的 maven central (Scala) 和 pip 安装 (Python) 版本。通过 nlp@johnsnowlabs.com
    或 [Twitter](https://twitter.com/johnsnowlabs)、[LinkedIn](https://www.linkedin.com/company/10349856/)
    或 [Facebook](https://www.facebook.com/JohnSnowLabsInc) 发送问题或反馈。
- en: '[Let us know](https://ida-johnsnowlabs.youcanbook.me) what functionality you
    need next.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[告诉我们](https://ida-johnsnowlabs.youcanbook.me) 你下一步需要什么功能。'
- en: 'Here are some of the requests we’re getting, and are looking for more feedback
    to design and prioritize:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们收到的一些请求，我们期待更多反馈以设计和优先考虑：
- en: Provide a SparkR client
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个 SparkR 客户端
- en: Provide “Spark-free” Java and Scala versions
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供“无 Spark”版本的 Java 和 Scala
- en: Add a state of the art annotator for coreference resolution
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加最先进的共指消解标注器
- en: Add a state of the art annotators for polarity detection
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加最先进的极性检测标注器
- en: Add a state of the art annotator for temporal reasoning
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加最先进的时间推理标注器
- en: Publish sample applications for common use cases such as question answering,
    text summarization or information retrieval
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布适用于常见用例的示例应用程序，如问答、文本摘要或信息检索
- en: Train and publish models for new domains or languages
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为新领域或语言训练和发布模型
- en: Publish reproducible, peer reviewed accuracy and performance benchmarks
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布可重复、同行评审的准确性和性能基准
- en: If you’d like to extend or contribute to the library, start by cloning the [John
    Snow Labs NLP for Spark GitHub](https://www.github.com/johnsnowlabs/spark-nlp) repository.
    We use pull requests and GitHub’s issue tracker to manage code changes, bugs and
    features. The library is still in its early days and we highly appreciate contribution
    and feedback of any kind.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想扩展或贡献于该库，可以从克隆 [John Snow Labs NLP for Spark GitHub](https://www.github.com/johnsnowlabs/spark-nlp)
    仓库开始。我们使用拉取请求和 GitHub 的问题跟踪器来管理代码更改、错误和功能。该库仍处于初期阶段，我们非常欢迎各种形式的贡献和反馈。
- en: '**Bio: [David Talby](https://www.linkedin.com/in/davidtalby/)** is a Consulting
    CTO at Usermind, specializing in applying big data and data science in healthcare.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历: [David Talby](https://www.linkedin.com/in/davidtalby/)** 是 Usermind 的首席技术顾问，专注于在医疗保健领域应用大数据和数据科学。'
- en: '**Related**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**'
- en: '[**[eBook] A Gentle Introduction to Apache Spark(tm)**](https://www.kdnuggets.com/2017/11/databricks-ebook-gentle-introduction-apache-spark.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**[电子书] Apache Spark(tm) 轻松入门**](https://www.kdnuggets.com/2017/11/databricks-ebook-gentle-introduction-apache-spark.html)'
- en: '[**Building a Wikipedia Text Corpus for Natural Language Processing**](https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**为自然语言处理构建维基百科文本语料库**](https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html)'
- en: '[**Search Millions of Documents for Thousands of Keywords in a Flash**](https://www.kdnuggets.com/2017/09/search-millions-documents-thousands-keywords.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**瞬间搜索数百万份文档中的数千个关键词**](https://www.kdnuggets.com/2017/09/search-millions-documents-thousands-keywords.html)'
- en: '* * *'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT支持'
- en: '* * *'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Introducing the Testing Library for Natural Language Processing](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍自然语言处理的测试库](https://www.kdnuggets.com/2023/04/introducing-testing-library-natural-language-processing.html)'
- en: '[N-gram Language Modeling in Natural Language Processing](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理中的N-gram语言建模](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
- en: '[5 Free Books on Natural Language Processing to Read in 2023](https://www.kdnuggets.com/2023/06/5-free-books-natural-language-processing-read-2023.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2023年值得阅读的5本自然语言处理免费书籍](https://www.kdnuggets.com/2023/06/5-free-books-natural-language-processing-read-2023.html)'
- en: '[25 Free Books to Master SQL, Python, Data Science, Machine…](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握SQL、Python、数据科学、机器学习和自然语言处理的25本免费书籍](https://www.kdnuggets.com/25-free-books-to-master-sql-python-data-science-machine-learning-and-natural-language-processing)'
- en: '[5 Free Courses to Master Natural Language Processing](https://www.kdnuggets.com/5-free-courses-to-master-natural-language-processing)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握自然语言处理的5个免费课程](https://www.kdnuggets.com/5-free-courses-to-master-natural-language-processing)'
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像识别和自然语言处理的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
