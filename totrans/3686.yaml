- en: 'Baize: An Open-Source Chat Model (But Different?)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Baize: 一个开源聊天模型（但有所不同？）'
- en: 原文：[https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html](https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html](https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html)
- en: '![Baize: An Open-Source Chat Model (But Different?)](../Images/50548f8074b6acba37a44c61cd822558.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Baize: An Open-Source Chat Model (But Different?)](../Images/50548f8074b6acba37a44c61cd822558.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: I think it’s safe to say 2023 is the year of [Large Language Models (LLMs)](/2023/03/top-free-courses-large-language-models.html).
    From the widespread adoption of ChatGPT, which is built on the GPT-3 family of
    LLMs, to the release of [GPT-4](/2023/03/gpt4-everything-need-know.html) with
    enhanced reasoning capabilities, it has been a year of milestones in generative
    AI. And we wake up everyday to the release of [new applications](/2023/04/langchain-101-build-gptpowered-applications.html)
    in the NLP space that leverage the ChatGPT’s capabilities to address novel problems.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为可以说2023年是[大型语言模型（LLMs）](/2023/03/top-free-courses-large-language-models.html)的年份。从基于GPT-3家族的ChatGPT的广泛应用，到具备增强推理能力的[GPT-4](/2023/03/gpt4-everything-need-know.html)的发布，这一年在生成式AI领域取得了许多里程碑。而我们每天醒来时都会看到[新应用](/2023/04/langchain-101-build-gptpowered-applications.html)的发布，这些应用利用ChatGPT的能力来解决新问题。
- en: In this article, we’ll learn about **Baize**, a recently released open-source
    chat model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将了解**Baize**，一个最近发布的开源聊天模型。
- en: What is Baize?
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是Baize？
- en: '**Baize is an open-source chat model. Cool. But why another chat model? **'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**Baize是一个开源聊天模型。很酷。但为什么还需要另一个聊天模型？**'
- en: Well, in a typical session with a chatbot, you don't have a single question
    that you’re seeking an answer to. Rather, you’ll ask a series of questions that
    the bot answers. This conversation chain continues—until you get your answers
    or an acceptable solution to your problem—in this multi-turn chat.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，在与聊天机器人进行的典型会话中，你并不是只提出一个问题来寻求答案。相反，你会问一系列问题，聊天机器人会逐一回答。这种对话链会持续——直到你获得答案或问题的可接受解决方案——在这种多轮对话中。
- en: So if you want to start building your own chat models, such a **multi-turn chat
    corpus** is not super common to come by. Baize aims at facilitating the generation
    of such a corpus using ChatGPT and uses it to fine-tune a LLaMA model. This helps
    you build better chatbots with reduced training time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你想开始构建自己的聊天模型，这种**多轮对话语料库**并不常见。Baize旨在利用ChatGPT生成这样的语料库，并用它来微调LLaMA模型。这有助于你构建更好的聊天机器人，并减少训练时间。
- en: '[Project Baize](https://github.com/project-baize) is funded by the McAuley
    lab at UC San Diego, and is the result of collaboration between researchers at
    UC San Diego, Sun Yat-Sen university, and Microsoft Research, Asia.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[Project Baize](https://github.com/project-baize)由UC San Diego的McAuley实验室资助，并且是UC
    San Diego、孙中山大学和微软亚洲研究院研究人员合作的结果。'
- en: Baize is named after the Chinese mythical creature Baize that can understand
    human languages [1]. And understanding human languages is something we’d all like
    chat models to have, yes? The research paper for Baize was first uploaded to arxiv
    on 3rd April, 2023\. The model’s weights and code have all been made available
    on GitHub solely for research purposes. So now is a great time to explore this
    new open-source chat model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Baize的名字来源于中国神话中的白泽，白泽能够理解人类语言[1]。理解人类语言是我们都希望聊天模型具备的能力，对吧？Baize的研究论文首次上传至arxiv是在2023年4月3日。该模型的权重和代码已全部在GitHub上公开，仅供研究使用。所以现在是探索这个新开源聊天模型的好时机。
- en: And, yeah, let's learn more about Baize.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，让我们更多地了解Baize。
- en: How Does Baize Work?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Baize是如何工作的？
- en: 'The working of Baize can be (almost) summed up in two key points:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Baize的工作可以（几乎）总结为两个关键点：
- en: Generate a large corpus of multi-turn chat data by leveraging ChatGPT
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过利用ChatGPT生成大量的多轮对话数据
- en: Use the generated corpus to fine-tune LLaMA
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成的语料库来微调LLaMA
- en: '![Baize: An Open-Source Chat Model (But Different?)](../Images/8d6eabc389d5ff21e1ccc6acfb01aa06.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![Baize: An Open-Source Chat Model (But Different?)](../Images/8d6eabc389d5ff21e1ccc6acfb01aa06.png)'
- en: The Pipeline for Training Baize | [Image source](https://arxiv.org/abs/2304.01196v2)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 训练Baize的流程 | [图片来源](https://arxiv.org/abs/2304.01196v2)
- en: Data Collection with ChatGPT Self-Chatting
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ChatGPT自我对话进行数据收集
- en: We mentioned that Baize uses ChatGPT to construct the chat corpus. It does so
    using a process called **self-chatting** in which *ChatGPT has a conversation
    with itself*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到过，Baize使用ChatGPT来构建聊天语料库。它使用一种叫做**自我对话**的过程，其中*ChatGPT与自己对话*。
- en: A typical chat session requires a human and an AI. The **self-chatting** process
    in the data collection pipeline is designed such that ChatGPT has a conversation
    with itself—to supply both sides of the conversation. For the self-chatting process,
    a template is provided along with the requirements.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的聊天会话需要一个人类和一个AI。数据收集管道中的**自聊天**过程设计为ChatGPT与自己对话——以提供对话的双方。对于自聊天过程，提供了一个模板以及相关要求。
- en: The quality of conversations generated by ChatGPT is quite high (we’ve seen
    this more in our social media feeds than in our own ChatGPT sessions). So we get
    a high-quality dialogue corpus.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT生成的对话质量非常高（我们在社交媒体上看到的更多，而不是在我们自己的ChatGPT会话中）。因此，我们获得了高质量的对话语料库。
- en: 'Let''s take a look at the data used by Baize:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Baize使用的数据：
- en: There is a **seed** that *sets the topic* for the chat session. It can be a
    question or a phrase that supplies the central idea of the conversation. In the
    training of Baize, questions from StackOverflow and Quora were used as seeds.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个**种子**，*设置话题*以进行聊天会话。它可以是一个问题或一个提供对话中心思想的短语。在Baize的训练中，来自StackOverflow和Quora的问题被用作种子。
- en: In the training of Baize, ChatGPT (gpt-turbo-3.5) model is used in the self-chatting
    data collection pipeline. The generated corpus has about **115K** dialogues—with
    approximately 55K dialogues coming from each of the above sources.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Baize的训练中，ChatGPT（gpt-turbo-3.5）模型用于自聊天数据收集管道。生成的语料库大约有**115K**个对话——其中约55K个对话来自上述每个来源。
- en: In addition, data from Stanford Alpaca was also used.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，还使用了来自斯坦福Alpaca的数据。
- en: 'Currently three versions of the model: Baize-7B, Baize-13B, and Baize-30B have
    been released. (In Baize-XB, XB denotes X billion parameters.)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前已经发布了三个版本的模型：Baize-7B、Baize-13B和Baize-30B。（在Baize-XB中，XB表示X十亿参数。）
- en: The seed can also be sampled from a specific domain. Meaning we can run the
    data collection process to construct a domain-specific chat corpus. In this direction,
    the Baize-Healthcare model is available, trained on the publicly available [MedQuAD
    dataset](https://paperswithcode.com/dataset/medquad) to create a corpus of about
    47K dialogues.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 种子也可以从特定领域进行抽样。这意味着我们可以运行数据收集过程以构建特定领域的聊天语料库。在这个方向上，Baize-Healthcare模型已经发布，基于公开的[MedQuAD数据集](https://paperswithcode.com/dataset/medquad)进行训练，创建了大约47K个对话的语料库。
- en: Fine-Tuning in Low-Resource Settings
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 低资源设置中的微调
- en: The next part is the fine-tuning of the LLaMA model on the generated corpus.
    Model Fine-tuning is generally a resource-intensive task. As tuning all the parameters
    of a large language model is infeasible under resource constraints, Baize uses
    [Low-Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685) to fine tune the
    LLaMA model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下一部分是对生成语料库的LLaMA模型进行微调。模型微调通常是一个资源密集型的任务。由于在资源限制下调整大型语言模型的所有参数不可行，**Baize**使用[低秩适应（LoRA）](https://arxiv.org/abs/2106.09685)来微调LLaMA模型。
- en: In addition, at inference time, there’s a prompt that instructs Baize not to
    indulge in conversations that are unethical and sensitive. This mitigates the
    need for human intervention in moderation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在推理时，有一个提示指示Baize不要进行不道德和敏感的对话。这减少了对人工干预审查的需求。
- en: The [functional app](https://huggingface.co/spaces/project-baize/Baize-7B) fetches
    the LLaMA model and LoRA weights from the HugingFace hub.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[功能应用](https://huggingface.co/spaces/project-baize/Baize-7B)从HuggingFace中心获取LLaMA模型和LoRA权重。'
- en: Advantages and Limitations of Baize
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Baize的优点和局限性
- en: Next, let’s go over some of the advantages and limitations of Baize.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们回顾一下Baize的一些优点和局限性。
- en: Advantages
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优点
- en: 'Let’s start by stating some advantages of Baize:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始列举一些Baize的优点：
- en: '**High availability**: You can try out [Baize-7B on HuggingFaces spaces](https://huggingface.co/spaces/project-baize/Baize-7B)
    or [run it locally](https://github.com/project-baize/baize-chatbot#how-to-run-locally).
    Baize is not restricted by the number of API calls and alleviates concerns of
    availability in times of high demand.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高可用性**：你可以尝试[Baize-7B on HuggingFaces spaces](https://huggingface.co/spaces/project-baize/Baize-7B)或[本地运行](https://github.com/project-baize/baize-chatbot#how-to-run-locally)。Baize不受API调用次数的限制，缓解了高需求时期的可用性问题。'
- en: '**Built-in moderation support**: The prompts at inference time to stop indulging
    in conversations on sensitive and unethical topics is advantageous as it minimizes
    efforts needed to moderate conversations.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内置的审核支持**：在推理时的提示可以防止对敏感和不道德话题的讨论，这有利于减少需要审查对话的工作量。'
- en: '**Chat corpora generation**: As mentioned, Baize can help build large corpora
    of multi-turn conversations. This can be helpful in training chat models at scale.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天语料库生成**：如前所述，Baize 可以帮助构建大规模的多轮对话语料库。这在大规模训练聊天模型时非常有用。'
- en: '**Accessibility in low-resource settings**: As mentioned in [1], we can run
    Baize on a single GPU machine, which makes it accessible in low-resource settings
    that have limited access to computation resources.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低资源环境中的可访问性**：正如[1]中提到的，我们可以在单个 GPU 机器上运行 Baize，这使得在计算资源有限的低资源环境中也能使用它。'
- en: '**Domain-specific applications**: By carefully sampling the seed from a specific
    domain, we can have chat bots for domain-specific applications such as healthcare,
    agriculture, finance and more.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域特定的应用**：通过精心从特定领域采样种子，我们可以拥有用于领域特定应用（如医疗、农业、金融等）的聊天机器人。'
- en: '**Reproducibility and customization**: The code is publicly available and the
    data collection and training pipeline is reproducible. If you want to collect
    data from various specific sources to build a custom corpus, you can modify the
    <code>collection.py</code> script in the project’s codebase.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复性和定制化**：代码是公开的，数据收集和训练流程是可重复的。如果你想从各种特定来源收集数据以构建自定义语料库，你可以修改项目代码库中的 <code>collection.py</code>
    脚本。'
- en: Limitations
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 局限性
- en: 'Like all LLM-powered chat apps, Baize has the following limitations:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有 LLM 驱动的聊天应用一样，Baize 存在以下局限性：
- en: '**Inaccurate information**: Just the way ChatGPT’s responses are sometimes
    prone to inaccuracies resulting from outdated training data and contextual nuances,
    Baize’s responses might as well be technically inaccurate at times.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不准确的信息**：正如 ChatGPT 的回答有时可能因过时的训练数据和语境差异而出现不准确的情况，Baize 的回答也可能在某些时候技术上不准确。'
- en: '**Challenge with up-to-date information**: The LLaMA model is not trained on
    recent data. This makes it challenging for tasks that require up-to-date information
    for accurate and helpful response.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时信息的挑战**：LLaMA 模型没有在最新数据上进行训练。这使得需要实时信息以提供准确且有用回答的任务变得具有挑战性。'
- en: '**Bias and toxicity**: By changing the inference prompt, the behavior of the
    model to decline engaging in sensitive, unethical conversations can be manipulated.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见和毒性**：通过改变推理提示，可以操控模型拒绝参与敏感、不道德的对话。'
- en: Wrapping Up
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: That’s all for today! To explore more about Baize, be sure to try out the demo
    on HuggingFace spaces or run it locally. ChatGPT and GPT-4 have inspired a wide
    range of applications in the NLP space.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 今天就到这里！要了解更多关于 Baize 的信息，请务必在 HuggingFace spaces 上尝试演示版或在本地运行。ChatGPT 和 GPT-4
    启发了自然语言处理领域的广泛应用。
- en: With novel OpenAI wrappers hitting the developer space almost everyday, it can
    be overwhelming to keep up with these rapid advancements and releases. At the
    same time, we’re excited to see what the future of generative AI holds.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 随着新颖的 OpenAI 包装几乎每天都出现在开发者领域，跟上这些快速的进展和发布可能会让人感到不知所措。与此同时，我们很兴奋地期待生成式 AI 的未来会带来什么。
- en: References and Resources for Further Learning
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献和进一步学习的资源
- en: '[1] C Xu, D Guo, N Duan, J McAuley, [Baize: An Open-Source Model with Parameter-Efficient
    Tuning on Self-Chat Data](https://arxiv.org/abs/2304.01196v2), arXiv, 2023.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] C Xu, D Guo, N Duan, J McAuley, [Baize: 一种在自聊天数据上进行参数高效调整的开源模型](https://arxiv.org/abs/2304.01196v2),
    arXiv, 2023.'
- en: '[2] [Project Baize on GitHub](https://github.com/project-baize/baize-chatbot)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [GitHub 上的 Project Baize](https://github.com/project-baize/baize-chatbot)'
- en: '[3] [Demo on HuggingFace Spaces](https://huggingface.co/spaces/project-baize/Baize-7B)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [HuggingFace Spaces 上的演示](https://huggingface.co/spaces/project-baize/Baize-7B)'
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a technical
    writer who enjoys creating long-form content. Her areas of interest include math,
    programming, and data science. She shares her learning with the developer community
    by authoring tutorials, how-to guides, and more.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** 是一位技术作家，她喜欢创作长篇内容。她的兴趣领域包括数学、编程和数据科学。她通过撰写教程、操作指南等，向开发者社区分享她的学习经验。'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关话题
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[认识 Gorilla：加州大学伯克利分校和微软的 API 增强型 LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
- en: '[Your Ultimate Guide to Chat GPT and Other Abbreviations](https://www.kdnuggets.com/2023/06/ultimate-guide-chat-gpt-abbreviations.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[你终极的 Chat GPT 和其他缩写指南](https://www.kdnuggets.com/2023/06/ultimate-guide-chat-gpt-abbreviations.html)'
- en: '[Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建用于多聊天后端的微服务，使用 Llama 和 ChatGPT](https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt)'
- en: '[Introducing DataCamps AI-Powered Chat Interface: DataLab](https://www.kdnuggets.com/introducing-datacamps-ai-powered-chat-interface-datalab)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 DataCamp 的 AI 驱动聊天界面：DataLab](https://www.kdnuggets.com/introducing-datacamps-ai-powered-chat-interface-datalab)'
- en: '[5 Different Ways to Load Data in Python](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 种不同的 Python 数据加载方法](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)'
- en: '[The Ultimate Guide To Different Word Embedding Techniques In NLP](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[终极指南：NLP 中不同的词嵌入技术](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
