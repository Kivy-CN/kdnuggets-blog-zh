- en: What is a Support Vector Machine, and Why Would I Use it?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是支持向量机，为什么我要使用它？
- en: 原文：[https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html](https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html](https://www.kdnuggets.com/2017/02/yhat-support-vector-machine.html)
- en: This post originally appeared on the [Yhat blog](http://blog.yhat.com/). [**Yhat**](https://www.yhat.com/)
    is a Brooklyn based company whose goal is to make data science applicable for
    developers, data scientists, and businesses alike. Yhat provides a software platform
    for deploying and managing predictive algorithms as REST APIs, while eliminating
    the painful engineering obstacles associated with production environments like
    testing, versioning, scaling and security.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本文最初发表于[Yhat博客](http://blog.yhat.com/)。[**Yhat**](https://www.yhat.com/)是一家总部位于布鲁克林的公司，旨在使数据科学适用于开发者、数据科学家和企业。Yhat提供一个软件平台，用于以REST
    API的形式部署和管理预测算法，同时消除了与生产环境相关的测试、版本控制、扩展和安全等痛苦的工程障碍。
- en: '* * *'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: What is SVM?
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是SVM？
- en: SVM is a supervised machine learning algorithm which can be used for classification
    or regression problems. It uses a technique called the kernel trick to transform
    your data and then based on these transformations it finds an optimal boundary
    between the possible outputs. Simply put, it does some extremely complex data
    transformations, then figures out how to seperate your data based on the labels
    or outputs you've defined.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: SVM是一种监督式机器学习算法，可用于分类或回归问题。它使用一种称为核技巧的技术来转换数据，然后基于这些转换找到可能输出之间的最优边界。简单来说，它进行一些极其复杂的数据转换，然后根据你定义的标签或输出来找出如何分隔数据。
- en: So what makes it so great?
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那么，它的优点是什么？
- en: '* * *'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在IT领域'
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Well SVM it capable of doing both classification and regression. In this post
    I'll focus on using SVM for classification. In particular I'll be focusing on
    non-linear SVM, or SVM using a non-linear kernel. Non-linear SVM means that the
    boundary that the algorithm calculates doesn't have to be a straight line. The
    benefit is that you can capture much more complex relationships between your datapoints
    without having to perform difficult transformations on your own. The downside
    is that the training time is much longer as it's much more computationally intensive.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: SVM能够进行分类和回归。在这篇文章中，我将重点讨论使用SVM进行分类。特别是，我将专注于非线性SVM，即使用非线性核的SVM。非线性SVM意味着算法计算出的边界不一定是一条直线。其优点是可以捕捉到数据点之间更复杂的关系，而不必自己进行困难的转换。缺点是训练时间更长，因为计算量更大。
- en: Cows and Wolves
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 牛和狼
- en: So what is the kernel trick?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是核技巧？
- en: The kernel trick takes the data you give it and transforms it. In goes some
    great features which you think are going to make a great classifier, and out comes
    some data that you don't recognize anymore. It is sort of like unraveling a strand
    of DNA. You start with this harmelss looking vector of data and after putting
    it through the kernel trick, it's unraveled and compounded itself until it's now
    a much larger set of data that can't be understood by looking at a spreadsheet.
    But here lies the magic, in expanding the dataset there are now more obvious boundaries
    between your classes and the SVM algorithm is able to compute a much more optimal
    hyperplane.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 核技巧将你提供的数据进行变换。输入一些你认为会成为优秀分类器的特征，输出的数据会变得难以识别。这就像解开一段DNA链。你从一个看似无害的数据向量开始，经过核技巧处理后，它被解开并复合，直到变成一个更大的数据集，通过查看电子表格无法理解。但这里的魔力在于，通过扩展数据集，你的类别之间的边界变得更加明显，SVM算法能够计算出一个更为优化的超平面。
- en: For a second, pretend you're a farmer and you have a problem--you need to setup
    a fence to protect your cows from packs of wovles. But where do you build your
    fence? Well if you're a **really** data driven farmer one way you could do it
    would be to build a classifier based on the position of the cows and wolves in
    your pasture. Racehorsing a few different types of classifiers, we see that SVM
    does a great job at seperating your cows from the packs of wolves. I thought these
    plots also do a nice job of illustrating the benefits of using a non-linear classifiers.
    You can see the the logistic and decision tree models both only make use of straight
    lines.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 设想一下，你是一个农民，你有一个问题——你需要建立一个围栏来保护你的奶牛免受狼群的袭击。但是你该在哪里建围栏呢？如果你是一个**非常**数据驱动的农民，一种方法是基于奶牛和狼在牧场中的位置来建立一个分类器。通过测试几种不同类型的分类器，我们发现SVM在将奶牛与狼群分开方面表现出色。我觉得这些图表也很好地说明了使用非线性分类器的好处。你可以看到逻辑回归和决策树模型都仅使用了直线。
- en: '[![](../Images/fa3cca38f9e009f727c5587ad0f938fc.png)](http://blog.yhat.com/static/img/cows_and_wolves.png)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/fa3cca38f9e009f727c5587ad0f938fc.png)](http://blog.yhat.com/static/img/cows_and_wolves.png)'
- en: Want to recreate the analysis?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要重新创建分析吗？
- en: Want to create these plots for yourself? You can run the code in your terminal
    or in an IDE of your choice, but, big surprise, I'd recommend [Rodeo](https://www.yhat.com/products/rodeo).
    It has a great pop-out plot feature that comes in handy for this type of analysis.
    It also ships with Python already included for Windows machines. Besides that,
    it's now lightning fast thanks to the hard work of [TakenPilot](https://github.com/TakenPilot).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想自己创建这些图表？你可以在终端或你选择的IDE中运行代码，但，惊喜的是，我推荐[Rodeo](https://www.yhat.com/products/rodeo)。它有一个很棒的弹出图表功能，适合这种分析类型。它还带有Python，适用于Windows机器。此外，多亏了[TakenPilot](https://github.com/TakenPilot)的辛勤工作，它现在运行得非常迅速。
- en: Once you've [downloaded Rodeo](https://www.yhat.com/products/rodeo), you'll
    need to save the raw [cows_and_wolves.txt](https://gist.githubusercontent.com/glamp/4365660/raw/474658c2c5a8bb763c50278c810d45a27bd21c7e/cows_and_wolves.txt)
    file from my github. Make sure you've set your working directory to where you
    saved the file.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你[下载了Rodeo](https://www.yhat.com/products/rodeo)，你需要从我的GitHub上保存原始的[cows_and_wolves.txt](https://gist.githubusercontent.com/glamp/4365660/raw/474658c2c5a8bb763c50278c810d45a27bd21c7e/cows_and_wolves.txt)文件。确保你已经将工作目录设置为保存文件的位置。
- en: '![Rodeo](../Images/7e3d6ff60c708c9efbbce4383671e3d8.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Rodeo](../Images/7e3d6ff60c708c9efbbce4383671e3d8.png)'
- en: Alright, now just copy and paste the code below into Rodeo, and run it, either
    by line or the entire script. Don't forget, you can pop out your plots tab, move
    around your windows, or resize them.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在只需将下面的代码复制粘贴到Rodeo中，并运行，无论是逐行还是整个脚本。别忘了，你可以弹出你的绘图标签，移动窗口或调整大小。
- en: Let SVM do the hard work
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让SVM来完成艰巨的工作
- en: In the event that the relationship between a dependent variable and independent
    variable is non-linear, it's not going to be nearly as accurate as SVM. Taking
    transformations between variables (log(x), (x^2)) becomes much less important
    since it's going to be accounted for in the algorithm. If you're still having
    troubles picturing this, see if you can follow along with this example.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果依赖变量和独立变量之间的关系是非线性的，它的准确性不会像SVM那样高。变量之间的转换（log(x)，(x^2)）变得不那么重要，因为这些会在算法中被考虑。如果你仍然难以理解，可以尝试跟随这个例子。
- en: Let's say we have a dataset that consists of green and red points. When plotted
    with their coordinates, the points make the shape of a red circle with a green
    outline (and look an awful lot like Bangladesh's flag).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个包含绿色和红色点的数据集。当用其坐标绘制时，这些点形成一个红色圆圈，绿色轮廓（看起来非常像孟加拉国的国旗）。
- en: What would happen if somehow we lost 1/3 of our data. What if we couldn't recover
    it and we wanted to find a way to approximate what that missing 1/3 looked like.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们丢失了三分之一的数据，会发生什么呢？如果我们无法恢复这些数据，并且想要找到一种方法来近似缺失的那三分之一的数据会是什么样子呢？
- en: 'So how do we figure out what the missing 1/3 looks like? One approach might
    be to build a model using the 80% of the data we do have as a training set. But
    what type of model do we use? Let''s try out the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何确定缺失的三分之一是什么样的呢？一种方法可能是使用我们拥有的 80% 数据作为训练集来构建模型。但我们应该使用什么类型的模型呢？让我们尝试一下以下几种：
- en: Logistic model
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归模型
- en: Decision Tree
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: SVM
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM
- en: I trained each model and then used each to make predictions on the missing 1/3
    of our data. Let's take a look at what our predicted shapes look like...
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我训练了每个模型，然后使用它们对我们缺失的三分之一数据进行预测。让我们来看看我们预测的形状是什么样的……
- en: '[![](../Images/696b6daaaa488d77a7dd36895b576f32.png)](http://blog.yhat.com/static/img/flag.png)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/696b6daaaa488d77a7dd36895b576f32.png)](http://blog.yhat.com/static/img/flag.png)'
- en: Follow along
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟随
- en: Here's the code to compare your logistic model, decision tree and SVM.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用来比较你的逻辑回归模型、决策树和 SVM 的代码。
- en: '![Rodeo](../Images/85682926351dd57b4d477d4bd6a497de.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Rodeo](../Images/85682926351dd57b4d477d4bd6a497de.png)'
- en: Follow along in [Rodeo](https://github.com/yhat/rodeo) by copying and running
    the code above!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通过复制并运行上面的代码，跟随 [Rodeo](https://github.com/yhat/rodeo)！
- en: Results
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果
- en: From the plots, it's pretty clear that SVM is the winner. But why? Well if you
    look at the predicted shapes of the decision tree and GLM models, what do you
    notice? Straight boundaries. Our input model did not include any transformations
    to account for the non-linear relationship between x, y, and the color. Given
    a specific set of transformations we definitely could have made GLM and the DT
    perform better, but why waste time? With no complex transformations or scaling,
    SVM only misclassified 117/5000 points (98% accuracy as opposed to DT-51% and
    GLM-12%! Of those all misclassified points were red--hence the slight bulge.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，SVM 显然是赢家。但为什么呢？如果你查看决策树和 GLM 模型的预测形状，你会注意到什么？直线边界。我们的输入模型没有包含任何变换来考虑
    x、y 和颜色之间的非线性关系。给定一组特定的变换，我们肯定可以让 GLM 和 DT 表现得更好，但为什么要浪费时间呢？没有复杂的变换或缩放，SVM 仅错误分类了
    117/5000 个点（98% 的准确率，而 DT 为 51% 和 GLM 为 12%！所有这些错误分类的点都是红色的——因此略微膨胀。
- en: When not to use it
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 何时不使用
- en: So why not use SVM for everything? Well unfortunately the magic of SVM is also
    the biggest drawback. The complex data transformations and resulting boundary
    plane are very difficult to interpret. This is why it's often called a black box.
    GLM and decision trees on the contrary are exactly the opposite. It's very easy
    to understand exactly what and why DT and GLM are doing at the expense of performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么不把 SVM 用于所有情况呢？不幸的是，SVM 的魔力也是最大的缺点。复杂的数据变换和结果边界平面非常难以解释。这就是为什么它通常被称为黑箱。相反，GLM
    和决策树正好相反。它们的操作非常容易理解，尽管性能有所牺牲。
- en: More Resources
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多资源
- en: 'Want to know more about SVM? Here''s a few good resources I''ve come across:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于 SVM 的信息吗？这里有一些我遇到的很好的资源：
- en: 'Beginner [SVM Tutorial](http://web.mit.edu/zoya/www/SVM.pdf): Just the basics
    with a little bit of spoon feeding from Zoya Gavrilov at MIT'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初学者 [SVM 教程](http://web.mit.edu/zoya/www/SVM.pdf)：仅仅是基础知识，还有一点点 MIT 的 Zoya Gavrilov
    提供的辅助。
- en: 'Beginner How SVM algorithm works: [Video](https://youtu.be/1NxnPkZM9bc) by
    Thales Sehn Körting'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初学者 SVM 算法的工作原理：[视频](https://youtu.be/1NxnPkZM9bc) 由 Thales Sehn Körting 提供
- en: Intermediate [A Gentle Introduction to Support Vector Machiens in Biomedicine](https://www.med.nyu.edu/chibi/sites/default/files/chibi/Final.pdf)
    Slides from NYU & Vanderbilt
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中级 [生物医学中支持向量机的温和介绍](https://www.med.nyu.edu/chibi/sites/default/files/chibi/Final.pdf)
    由 NYU 和 Vanderbilt 提供的幻灯片
- en: Advanced [Tutorial on Support Vector Machines for Pattern Recognition](http://research.microsoft.com/en-us/um/people/cburges/papers/SVMTutorial.pdf)
    from Christopher Burges at Bell Labs
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级 [模式识别中的支持向量机教程](http://research.microsoft.com/en-us/um/people/cburges/papers/SVMTutorial.pdf)
    由 Bell Labs 的 Christopher Burges 提供
- en: '[Original](http://blog.yhat.com/posts/why-support-vector-machine.html). Reposted
    with permission.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](http://blog.yhat.com/posts/why-support-vector-machine.html)。经许可转载。'
- en: '**Related:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Support Vector Machines: A Concise Technical Overview](/2016/09/support-vector-machines-concise-technical-overview.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：简明技术概述](/2016/09/support-vector-machines-concise-technical-overview.html)'
- en: '[Support Vector Machines: A Simple Explanation](/2016/07/support-vector-machines-simple-explanation.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：简单解释](/2016/07/support-vector-machines-simple-explanation.html)'
- en: '[Random Forests in Python](/2016/12/random-forests-python.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python中的随机森林](/2016/12/random-forests-python.html)'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：直观方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机的温和介绍](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
- en: '[How Semantic Vector Search Transforms Customer Support Interactions](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语义向量搜索如何改变客户支持互动](https://www.kdnuggets.com/how-semantic-vector-search-transforms-customer-support-interactions)'
- en: '[Python Vector Databases and Vector Indexes: Architecting LLM Apps](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 向量数据库和向量索引：构建LLM应用程序](https://www.kdnuggets.com/2023/08/python-vector-databases-vector-indexes-architecting-llm-apps.html)'
- en: '[If I Had To Start Learning Data Science Again, How Would I Do It?](https://www.kdnuggets.com/2020/08/start-learning-data-science-again.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如果我要重新开始学习数据科学，我会怎么做？](https://www.kdnuggets.com/2020/08/start-learning-data-science-again.html)'
- en: '[When Would Ensemble Techniques be a Good Choice?](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[何时使用集成技术是一个好的选择？](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
