- en: Unlock the Secrets of LLMs in 60-Minute with Andrej Karpathy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在60分钟内解锁LLMs的秘密，与Andrej Karpathy
- en: 原文：[https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy](https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy](https://www.kdnuggets.com/unlock-the-secrets-of-llms-in-a-60-minute-with-andrej-karpathy)
- en: '![Unlock the Secrets of LLMs in a 60-Minute with Andrej Karpathy](../Images/0115dbe580574df16e470366c3365eec.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![在60分钟内解锁LLMs的秘密，与Andrej Karpathy](../Images/0115dbe580574df16e470366c3365eec.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：编辑
- en: 'Have you heard of [Andrej Karpathy](https://karpathy.ai/)? He''s a renowned
    computer scientist and AI researcher known for his work on deep learning and neural
    networks. He played a key role in the development of ChatGPT at OpenAI and was
    previously the Sr. Director of AI at Tesla. Even before that, he designed and
    was the primary instructor for the first deep learning class [Stanford - CS 231n:
    Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2016/).
    The class became one of the largest at Stanford and has grown from 150 enrolled
    in 2015 to 750 students in 2017\. I highly recommend anyone interested in deep
    learning to watch this on YouTube. I will not go into more detail about him, and
    we will shift our focus toward one of his most popular talks on YouTube which
    crossed **1.4 million views** "Introduction to Large Language Models." This talk
    is a busy-person introduction to LLMs and is a must-watch for anyone interested
    in LLMs.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过[Andrej Karpathy](https://karpathy.ai/)吗？他是一位著名的计算机科学家和人工智能研究员，以其在深度学习和神经网络方面的工作而闻名。他在OpenAI的ChatGPT开发中发挥了关键作用，曾担任特斯拉AI高级总监。在此之前，他设计并主讲了第一门深度学习课程[斯坦福
    - CS 231n：卷积神经网络用于视觉识别](http://cs231n.stanford.edu/2016/)。该课程成为斯坦福大学最大的课程之一，从2015年的150名学生增长到2017年的750名学生。我强烈推荐对深度学习感兴趣的人观看这个YouTube视频。我将不再详细介绍他，我们将转向他在YouTube上最受欢迎的讲座之一，观看量超过**140万**的“介绍大型语言模型”。这次讲座是一个忙碌人士了解LLMs的入门必看内容。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: I have provided a concise summary of this talk. If this sparks your interest,
    then I will highly recommend you go over the slides and YouTube link that will
    be provided at the end of this article.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我提供了这次演讲的简要总结。如果这引起了你的兴趣，我强烈建议你查看文章末尾提供的幻灯片和YouTube链接。
- en: Overview of the Talk
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 演讲概述
- en: 'This talk provides a comprehensive introduction to LLMs, their capabilities,
    and the potential risks associated with their use. It has been divided into 3
    major parts that are as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这次讲座提供了LLMs的全面介绍，包括它们的能力以及使用它们可能带来的潜在风险。它被分为以下三个主要部分：
- en: 'Part 1: LLMs'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1部分：LLMs
- en: '![Unlock the Secrets of LLMs in a 60-Minute with Andrej Karpathy](../Images/2e869eee5c552f500a823fcc845cfe5e.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![在60分钟内解锁LLMs的秘密，与Andrej Karpathy](../Images/2e869eee5c552f500a823fcc845cfe5e.png)'
- en: Slides by Andrej Karpathy
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 幻灯片由Andrej Karpathy提供
- en: 'LLMs are trained on a large corpus of text to generate human-like responses.
    In this part, Andrej discusses the Llama 2-70b model specifically. It is one of
    the largest LLMs with 70 billion parameters. The model consists of two main components:
    the parameters file and the run file. The parameters file is a large binary file
    that contains the weights and biases of the model. These weights and biases are
    essentially the "knowledge" that the model has learned during training. The run
    file is a piece of code that is used to load the parameters file and run the model.
    The training process of the model can be divided into the following two stages:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 在大量文本语料库上进行训练，以生成类似人类的回应。在这一部分中，Andrej 具体讨论了 Llama 2-70b 模型。它是最大的 LLM 之一，具有
    700 亿个参数。该模型由两个主要组件组成：参数文件和运行文件。参数文件是一个大型二进制文件，包含模型的权重和偏差。这些权重和偏差本质上是模型在训练过程中学习到的“知识”。运行文件是一段用于加载参数文件并运行模型的代码。模型的训练过程可以分为以下两个阶段：
- en: 1\. Pretraining
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 预训练
- en: This involves collecting a large chunk of text, about 10 terabytes, from the
    internet, and then using a GPU cluster to train the model on this data. The result
    of the training process is a base model that is the lossy compression of the internet.
    It is capable of generating coherent and relevant text but not directly answering
    questions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及从互联网收集大量文本，约10TB，然后使用 GPU 集群对这些数据进行模型训练。训练过程的结果是一个基本模型，它是互联网的有损压缩。它能够生成连贯和相关的文本，但不能直接回答问题。
- en: 2\. Finetuning
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 微调
- en: The pre-trained model is further trained on a high-quality dataset to make it
    more useful. This results in an assistant model. Andrej also mentions a third
    stage of fine-tuning, which involves using comparison labels. Instead of generating
    answers from scratch, the model is given multiple candidate answers and asked
    to choose the best one. This can be easier and more efficient than generating
    answers, and can further improve the model's performance. This process is called
    reinforcement learning from human feedback (RLHF).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型会在高质量的数据集上进一步训练，以使其更有用。这将产生一个助手模型。Andrej 还提到微调的第三阶段，即使用对比标签。模型不是从头生成答案，而是给出多个候选答案，并要求选择最佳答案。这比生成答案可能更简单、更高效，并且能进一步提高模型性能。这个过程称为从人类反馈中进行的强化学习（RLHF）。
- en: 'Part 2: Future of LLMs'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2部分：LLMs的未来
- en: '![Unlock the Secrets of LLMs in a 60-Minute with Andrej Karpathy](../Images/5182a5aad95602cce677ea2a91f42166.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![在与 Andrej Karpathy 的 60 分钟中揭开 LLM 的秘密](../Images/5182a5aad95602cce677ea2a91f42166.png)'
- en: Slides by Andrej Karpathy
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 幻灯片由 Andrej Karpathy 提供
- en: 'While discussing the future of large language models and their capabilities,
    the following key points are discussed:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论大型语言模型及其能力的未来时，讨论了以下关键点：
- en: 1\. Scaling Law
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 规模定律
- en: Model performance correlates with two variables—the number of parameters and
    the amount of training text. Larger models trained on more data tend to achieve
    better performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的性能与两个变量相关——参数数量和训练文本量。训练在更多数据上的较大模型往往能够取得更好的性能。
- en: 2\. Usage of Tools
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 工具的使用
- en: LLMs like ChatGPT can utilize tools such as a browser, calculator, and Python
    libraries to perform tasks that would otherwise be challenging or impossible for
    the model alone.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 像 ChatGPT 这样的语言模型（LLMs）可以利用浏览器、计算器和 Python 库等工具，执行对模型单独来说具有挑战性或不可能完成的任务。
- en: 3\. System One and System Two Thinking in LLMs
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. LLM中的系统一和系统二思维
- en: Currently, LLMs predominantly employ system one thinking—fast, instinctive,
    and pattern-based. However, there is interest in developing LLMs capable of engaging
    in system two thinking—slower, rational, and requiring conscious effort.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，LLMs 主要采用系统一思维——快速、本能和基于模式的。然而，人们对开发能够进行系统二思维——较慢、理性并且需要有意识努力的 LLMs 感兴趣。
- en: 4\. LLM OS
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. LLM 操作系统
- en: LLMs can be thought of as the kernel process of an emerging operating system.
    They can read and generate text, have extensive knowledge on various subjects,
    browse the internet or reference local files, use existing software infrastructure,
    generate images and videos, hear and speak, and think for extended periods using
    system 2\. The context window of an LLM is analogous to RAM in a computer, and
    the kernel process tries to page relevant information in and out of its context
    window to perform tasks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs可以被视为新兴操作系统的内核进程。它们可以读取和生成文本，拥有广泛的各种主题知识，浏览互联网或引用本地文件，使用现有的软件基础设施，生成图像和视频，听到和说话，并使用系统2进行长时间的思考。LLM的上下文窗口类似于计算机中的RAM，内核进程尝试将相关信息分页进出其上下文窗口以执行任务。
- en: 'Part 3: LLMs Security'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3部分：LLMs安全性
- en: '![Unlock the Secrets of LLMs in a 60-Minute with Andrej Karpathy](../Images/7cb3ab39debee876028b8a4ea75e8256.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![与Andrej Karpathy一起在60分钟内解锁LLM的秘密](../Images/7cb3ab39debee876028b8a4ea75e8256.png)'
- en: Slides by Andrej Karpathy
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 幻灯片由Andrej Karpathy制作
- en: 'Andrej highlights ongoing research efforts in addressing security challenges
    associated with LLMs. The following attacks are discussed:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Andrej强调了在解决LLMs相关安全挑战方面的持续研究工作。讨论了以下攻击：
- en: 1\. Jailbreak
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 越狱
- en: Attempts to bypass safety measures in LLMs to extract harmful or inappropriate
    information. Examples include role-playing to deceive the model and manipulating
    responses using optimized sequences of words or images.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试绕过LLM中的安全措施以提取有害或不适当的信息。示例包括通过角色扮演欺骗模型以及使用优化的单词或图像序列操控响应。
- en: 2\. Prompt Injection
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 提示注入
- en: Involves injecting new instructions or prompts into an LLM to manipulate its
    responses. Attackers can hide instructions within images or web pages, leading
    to the inclusion of unrelated or harmful content in the model's answers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及向LLM中注入新的指令或提示，以操控其响应。攻击者可以将指令隐藏在图像或网页中，从而导致模型的回答中包含无关或有害的内容。
- en: 3\. Data Poisoning /Backdoor Attack/Sleeper Agent Attack
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 数据中毒 / 后门攻击 / 睡眠代理攻击
- en: Involves training a large language model on malicious or manipulated data containing
    trigger phrases. When the model encounters the trigger phrase, it can be manipulated
    to perform undesirable actions or provide incorrect predictions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及在恶意或操控的数据上训练大型语言模型，这些数据包含触发短语。当模型遇到这些触发短语时，它可能被操控执行不良操作或提供错误预测。
- en: 'You can watch the comprehensive video on YouTube by clicking below:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过点击下面的链接在YouTube上观看全面的视频：
- en: '**Slides:** [Click here](https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**幻灯片：** [点击这里](https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view)'
- en: Conclusion
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'If you''re new to LLMs and looking for resources to kickstart your journey,
    then this comprehensive list is a great place to start! It contains both foundational
    and LLM-specific courses that will help you build a solid foundation. Additionally,
    if you''re interested in a more structured learning experience, [Maxime Labonne](https://github.com/mlabonne)
    recently launched his LLM course with three different tracks to choose from based
    on your needs and experience level. Here are the links to both resources for your
    convenience:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对LLMs是新手，并且正在寻找启动学习之旅的资源，那么这个全面的列表是一个很好的起点！它包含了基础课程和特定于LLM的课程，将帮助你建立扎实的基础。此外，如果你对更结构化的学习体验感兴趣，[Maxime
    Labonne](https://github.com/mlabonne)最近推出了他的LLM课程，有三个不同的课程轨道可以根据你的需求和经验水平进行选择。这里是两个资源的链接，供你参考：
- en: '[A Comprehensive List of Resources to Master Large Language Models by Kanwal
    Mehreen](/a-comprehensive-list-of-resources-to-master-large-language-models)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[掌握大型语言模型的全面资源列表（作者：Kanwal Mehreen](/a-comprehensive-list-of-resources-to-master-large-language-models)'
- en: '[Large Language Model Course by Maxime Labonne](https://github.com/mlabonne/llm-course)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Maxime Labonne的语言模型课程](https://github.com/mlabonne/llm-course)'
- en: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal is a machine learning engineer and a technical writer with a profound passion
    for data science and the intersection of AI with medicine. She co-authored the
    ebook "Maximizing Productivity with ChatGPT". As a Google Generation Scholar 2022
    for APAC, she champions diversity and academic excellence. She''s also recognized
    as a Teradata Diversity in Tech Scholar, Mitacs Globalink Research Scholar, and
    Harvard WeCode Scholar. Kanwal is an ardent advocate for change, having founded
    FEMCodes to empower women in STEM fields.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal是一位机器学习工程师和技术作家，对数据科学以及人工智能与医学的交集充满了深厚的热情。她共同撰写了电子书《利用ChatGPT最大化生产力》。作为2022年亚太地区的Google
    Generation Scholar，她倡导多样性和学术卓越。她还被认定为Teradata技术多样性学者、Mitacs Globalink研究学者和哈佛WeCode学者。Kanwal是变革的坚定倡导者，她创立了FEMCodes，旨在赋能女性进入STEM领域。'
- en: More On This Topic
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Unlock the Secrets to Choosing the Perfect Machine Learning Algorithm!](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解锁选择完美机器学习算法的秘密！](https://www.kdnuggets.com/2023/07/ml-algorithm-choose.html)'
- en: '[Unlock the Power of AI - A Special Release by KDnuggets and Machine…](https://www.kdnuggets.com/2023/07/mlm-unlock-power-ai-special-release-kdnuggets-machine-learning-mastery.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解锁人工智能的力量 - KDnuggets和Machine…的特别发布](https://www.kdnuggets.com/2023/07/mlm-unlock-power-ai-special-release-kdnuggets-machine-learning-mastery.html)'
- en: '[Unlock Your Potential with This FREE DevOps Crash Course](https://www.kdnuggets.com/2023/03/corise-unlock-potential-with-this-free-devops-crash-course.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这个免费的DevOps速成课程激发你的潜力](https://www.kdnuggets.com/2023/03/corise-unlock-potential-with-this-free-devops-crash-course.html)'
- en: '[ChatGPT-Powered Data Exploration: Unlock Hidden Insights in Your Dataset](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT驱动的数据探索：解锁数据集中的隐藏洞察](https://www.kdnuggets.com/2023/07/chatgptpowered-data-exploration-unlock-hidden-insights-dataset.html)'
- en: '[Unlock your next move: Save up to 67% on in-demand data upskilling](https://www.kdnuggets.com/2023/03/datacamp-unlock-next-move-save-67-indemand-data-upskilling.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解锁你的下一步行动：节省高达67%的数据技能提升费用](https://www.kdnuggets.com/2023/03/datacamp-unlock-next-move-save-67-indemand-data-upskilling.html)'
- en: '[Unlock DataOps Success with DataOps.live - Featured in Gartner…](https://www.kdnuggets.com/2023/07/dataopslive-unlock-dataops-success-featured-gartner-market-guide.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过DataOps.live解锁DataOps成功 - 被Gartner推荐…](https://www.kdnuggets.com/2023/07/dataopslive-unlock-dataops-success-featured-gartner-market-guide.html)'
