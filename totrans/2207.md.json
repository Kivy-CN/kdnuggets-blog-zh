["```py\n%%capture\n%pip install accelerate peft transformers datasets bitsandbytes\n```", "```py\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\nimport torch\n\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\n```", "```py\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n```", "```py\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n)\n```", "```py\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n```", "```py\ntrainable params: 33,554,432 || all params: 6,771,970,048 || trainable%: 0.49548996469513035\n```", "```py\nmodel.save_pretrained(\"llama-2-7b-chat-guanaco\")\n```", "```py\n!huggingface-cli login --token $secret_value_0\n```", "```py\nmodel.push_to_hub(\"llama-2-7b-chat-guanaco\")\n```", "```py\nfrom transformers import AutoModelForCausalLM\nfrom peft import PeftModel, PeftConfig\nimport torch\n\npeft_model = \"kingabzpro/llama-2-7b-chat-guanaco\"\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\nmodel = PeftModel.from_pretrained(base_model, peft_model)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = model.to(\"cuda\")\nmodel.eval()\n```", "```py\nprompt = \"What is Hacktoberfest?\"\ninputs = tokenizer(f\"<s>[INST] {prompt} [/INST]\", return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model.generate(\n        input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=100\n    )\n    print(\n        tokenizer.batch_decode(\n            outputs.detach().cpu().numpy(), skip_special_tokens=True\n        )[0]\n    ) \n```", "```py\n[INST] What is Hacktoberfest? [/INST] Hacktoberfest is an open-source software development event that takes place in October. It was created by the non-profit organization Open Source Software Institute (OSSI) in 2017\\. The event aims to encourage people to contribute to open-source projects, with the goal of increasing the number of contributors and improving the quality of open-source software.\n\nDuring Hacktoberfest, participants are encouraged to contribute to open-source \n```"]