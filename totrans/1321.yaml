- en: 5 Must-Read Data Science Papers (and How to Use Them)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/10/5-must-read-data-science-papers.html](https://www.kdnuggets.com/2020/10/5-must-read-data-science-papers.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49c4709a878e9936f82cec20829980e1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Photo by [Rabie Madaci](https://unsplash.com/@rbmadaci?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).*'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Data science might be a young field, but that doesn’t mean you won’t face expectations
    about having an awareness of certain topics. This article covers several of the
    most important recent developments and influential thought pieces.
  prefs: []
  type: TYPE_NORMAL
- en: Topics covered in these papers range from the **orchestration of the DS workflow** to **breakthroughs
    in faster neural networks** to a **rethinking of our fundamental approach to problem
    solving with statistics**. For each paper, I offer ideas for how you can apply
    these ideas to your own work
  prefs: []
  type: TYPE_NORMAL
- en: '#1 — [Hidden Technical Debt in Machine Learning Systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The team at Google Research provides **clear instructions on antipatterns to
    avoid** when setting up your data science workflow. This paper borrows the metaphor
    of technical debt from software engineering and applies it to data science.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7a3eb411e8454e50fc5b0cf639b5931.png)'
  prefs: []
  type: TYPE_IMG
- en: '*via [DataBricks](https://databricks.com/resources).*'
  prefs: []
  type: TYPE_NORMAL
- en: As the next paper explores in greater detail, building a machine learning product
    is a highly specialized subset of software engineering, so it makes sense that
    many lessons drawn from this discipline will apply to data science as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**How to use**: follow the experts’ [practical tips](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) to
    streamline development and production.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 — [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This classic post from [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----487cce9a2020--------------------------------) articulated
    the paradigm that machine learning models are **software applications with code
    based on data**.
  prefs: []
  type: TYPE_NORMAL
- en: If data science is software, what exactly are we building towards? Ben Bengafort
    explored this question in an influential blog post called “[The Age of the Data
    Product](https://districtdatalabs.silvrback.com/the-age-of-the-data-product).”
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/37f3758d76bb90a36b2120462fcdeb7a.png)'
  prefs: []
  type: TYPE_IMG
- en: '*The data product represents the operationalization phase of an ML project.
    Photo by [Noémi Macavei-Katócz](https://unsplash.com/@noemieke?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**How to use**: read more about how the data product fits into the [model selection
    process](https://medium.com/atlas-research/model-selection-d190fb8bbdda).'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 — [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this paper, the team at Google Research put forward the natural language
    processing (NLP) model that represented a step-function increase in our capabilities
    in for text analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Though there’s [some controversy](https://text-machine-lab.github.io/blog/2020/bert-secrets/) over
    exactly why BERT works so well, this is a great reminder that the machine learning
    field may have uncovered successful approaches without fully understanding how
    they work. [As with nature](https://www.youtube.com/watch?v=B7m0e-3u-1Y&t=1s),
    artificial neural networks are steeped in mystery.
  prefs: []
  type: TYPE_NORMAL
- en: '*In this delightful clip, the Director of Data Science at Nordstrom explains
    how artificial neural nets draw inspiration from nature.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**How to use**:'
  prefs: []
  type: TYPE_NORMAL
- en: The [BERT paper](https://arxiv.org/abs/1810.04805) is imminently readable and
    contains some suggested default hyperparameter settings as a valuable starting
    point (see Appendix A.3).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether or not you’re new to NLP, check out Jay Alammar’s [“A Visual Guide to
    Using BERT for the First Time](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)”
    for a charming illustration of BERT’s capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, check out [ktrain](https://arxiv.org/abs/2004.10703), a package that sits
    atop Keras (which in turn sits atop TensorFlow) that allows you to effortlessly
    implement BERT in your work. [Arun Maiya](https://medium.com/u/4581d07591d5?source=post_page-----487cce9a2020--------------------------------) developed
    this powerful library to enable speed to insight for NLP, image recognition, and
    graph-based approaches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#4 — [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While NLP models are getting larger (see GPT-3’s 175 billion parameters), there’s
    been an orthogonal effort to find smaller, faster, more efficient neural networks.
    These networks promise quicker runtimes, lower training costs, and less demand
    for compute resources.
  prefs: []
  type: TYPE_NORMAL
- en: In this groundbreaking paper, machine learning wiz kids Jonathan Frankle and
    Michael Carbin outline a pruning approach to uncover sparse sub-networks that
    can attain comparable performance to the original, significantly larger neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0bab24fe5c328bfb0161b39e85b4fbb3.png)'
  prefs: []
  type: TYPE_IMG
- en: '*via [Nolan Day](https://medium.com/u/6438fd23c99a?source=post_page-----487cce9a2020--------------------------------)’s
    “[Breaking down the Lottery Ticket Hypothesis](https://towardsdatascience.com/breaking-down-the-lottery-ticket-hypothesis-ca1c053b3e58).”*'
  prefs: []
  type: TYPE_NORMAL
- en: The Lottery Ticket refers to the connections with initial weights that make
    them particularly effective. The finding offers many advantages in storage, runtime,
    and computational performance - and won abest paper award at ICLR 2019\. Further
    research has built on this technique, [proving its applicability](https://arxiv.org/abs/2002.00585) and [applying
    it to an originally sparse network](https://arxiv.org/abs/1911.11134).
  prefs: []
  type: TYPE_NORMAL
- en: '**How to use**:'
  prefs: []
  type: TYPE_NORMAL
- en: Consider [pruning](https://jacobgil.github.io/deeplearning/pruning-deep-learning)
    your neural nets before putting them into production. Pruning network weights
    can reduce the number of parameters by 90%+ while still achieving the same level
    of performance as the original network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, check out this [episode of the Data Exchange podcast](https://thedataexchange.media/software-and-commodity-hardware-can-handle-deep-learning/)
    where Ben Lorica talks to [Neural Magic](https://neuralmagic.com/about/), a startup
    that’s looking to capitalize on techniques such as [pruning and quantization](https://www.youtube.com/watch?v=3JWRVx1OKQQ) with
    a slick UI that makes achieving sparsity easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Read more**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Check out this interesting sidebar](https://ml-retrospectives.github.io/neurips2019/accepted_retrospectives/2019/lottery-ticket/) from
    one of the “The Lottery Ticket” authors about flaws in how the machine learning
    community evaluates good ideas.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '#5 — [Releasing the death-grip of null hypothesis statistical testing (*p* <
    .05)](https://www.researchgate.net/publication/312395254_Releasing_the_death-grip_of_null_hypothesis_statistical_testing_p_05_Applying_complexity_theory_and_somewhat_precise_outcome_testing_SPOT)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Classical hypothesis testing leads to over-certainty and produces the false
    idea that causes have been identified via statistical methods. ([Read more](http://wmbriggs.com/public/Briggs.ReplacementForHypothesisTesting.pdf))
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hypothesis testing predates the use of computers. Given the challenges associated
    with this approach (such as the fact that [even statisticians find it nearly impossible
    to explain p-value](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/)),
    it may be time to consider alternatives such as somewhat precise outcome testing
    (SPOT).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb6b71489ba73c9b787f9ebd902bbff7.png)'
  prefs: []
  type: TYPE_IMG
- en: '*“Significant” via [xkcd](https://xkcd.com/882/).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**How to use**:'
  prefs: []
  type: TYPE_NORMAL
- en: Check out this blog post, “[The Death of the Statistical Tests of Hypotheses](https://www.datasciencecentral.com/profiles/blogs/the-death-of-the-statistical-test-of-hypothesis),”
    where a frustrated statistician outlines some of the challenges associated with
    the classical approach and explains an alternative utilizing confidence intervals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Sign up to get notified when “Resources to Supercharge your Data Science in
    the Last Months of 2020” comes out](https://page.co/ahje9p)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/must-read-data-science-papers-487cce9a2020).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio:** [Nicole Janeway Bills](http://www.linkedin.com/in/nicole-janeway-bills) is
    a machine learning engineer with experience in commercial and federal consulting.
    Proficient in Python, SQL, and Tableau, Nicole has business experience in natural
    language processing (NLP), cloud computing, statistical testing, pricing analysis,
    and ETL processes, and aims to use this background to connect data with business
    outcomes and continue to develop technical skillsets.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[AI Papers to Read in 2020](https://www.kdnuggets.com/2020/09/ai-papers-read-2020.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Must-read NLP and Deep Learning articles for Data Scientists](https://www.kdnuggets.com/2020/08/must-read-nlp-deep-learning-articles.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13 must-read papers from AI experts](https://www.kdnuggets.com/2020/05/13-must-read-papers-ai-experts.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets™ News 22:n06, Feb 9: Data Science Programming…](https://www.kdnuggets.com/2022/n06.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Programming Languages and When To Use Them](https://www.kdnuggets.com/2022/02/data-science-programming-languages.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Analytics: The Four Approaches to Analyzing Data and How To…](https://www.kdnuggets.com/2023/04/data-analytics-four-approaches-analyzing-data-effectively.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24 A/B Testing Interview Questions in Data Science Interviews and…](https://www.kdnuggets.com/2022/09/24-ab-testing-interview-questions-data-science-interviews-crack.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Breaking into Data Science: Essential Skills and How to Learn Them](https://www.kdnuggets.com/breaking-into-data-science-essential-skills-and-how-to-learn-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
