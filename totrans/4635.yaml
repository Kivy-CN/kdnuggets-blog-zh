- en: 7 Steps to Mastering Data Preparation for Machine Learning with Python — 2019
    Edition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 掌握数据准备的 7 个步骤 — 2019 版
- en: 原文：[https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html](https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html](https://www.kdnuggets.com/2019/06/7-steps-mastering-data-preparation-python.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: Interested in mastering data preparation with Python?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 有兴趣掌握使用 Python 进行数据准备吗？
- en: Data preparation, cleaning, pre-processing, cleansing, wrangling. Whatever term
    you choose, they refer to a roughly related set of pre-modeling data activities
    in the machine learning, data mining, and data science communities.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备、清理、预处理、净化、处理。无论你选择哪个术语，它们都指的是机器学习、数据挖掘和数据科学社区中一组大致相关的建模前数据活动。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Wikipedia defines [data cleansing](https://en.wikipedia.org/wiki/Data_cleansing)
    as:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科定义[数据清洗](https://en.wikipedia.org/wiki/Data_cleansing)为：
- en: '...is the process of detecting and correcting (or removing) corrupt or inaccurate
    records from a record set, table, or database and refers to identifying incomplete,
    incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying,
    or deleting the dirty or coarse data. Data cleansing may be performed interactively
    with data wrangling tools, or as batch processing through scripting.'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '...是从记录集、表格或数据库中检测和修正（或删除）损坏或不准确记录的过程，并且涉及识别数据中不完整、不正确、不准确或无关的部分，然后替换、修改或删除这些脏数据或粗糙数据。数据清洗可以通过数据处理工具交互式地进行，也可以通过脚本批处理完成。'
- en: '[Data wrangling](https://en.wikipedia.org/wiki/Data_wrangling), for comparison,
    is defined by Wikipedia as:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据处理](https://en.wikipedia.org/wiki/Data_wrangling)，根据维基百科的定义：'
- en: '...the process of manually converting or mapping data from one "raw" form into
    another format that allows for more convenient consumption of the data with the
    help of semi-automated tools. This may include further munging, data visualization,
    data aggregation, training a statistical model, as well as many other potential
    uses. Data munging as a process typically follows a set of general steps which
    begin with extracting the data in a raw form from the data source, "munging" the
    raw data using algorithms (e.g. sorting) or parsing the data into predefined data
    structures, and finally depositing the resulting content into a data sink for
    storage and future use.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '...手动将数据从一种“原始”形式转换或映射到另一种格式，以便通过半自动化工具更方便地使用数据。这可能包括进一步的数据处理、数据可视化、数据汇总、训练统计模型以及其他许多潜在用途。数据处理作为一个过程通常遵循一系列通用步骤，首先从数据源中以原始形式提取数据，然后使用算法（例如排序）或将数据解析为预定义的数据结构进行“处理”，最后将生成的内容存入数据存储以供存储和未来使用。'
- en: '![Figure](../Images/2ebc5d14359a29620a0fe3466edd6938.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/2ebc5d14359a29620a0fe3466edd6938.png)'
- en: Data preparation in both the [KDD Process](http://www2.cs.uregina.ca/~dbd/cs831/notes/kdd/1_kdd.html)
    (left) and the [CRISP-DM model](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)
    (right).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备在[知识发现过程](http://www2.cs.uregina.ca/~dbd/cs831/notes/kdd/1_kdd.html)（左）和[CRISP-DM模型](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)（右）中。
- en: I would say that it is "identifying incomplete, incorrect, inaccurate or irrelevant
    parts of the data and then replacing, modifying, or deleting the dirty or coarse
    data" in the context of "mapping data from one 'raw' form into another..." all
    the way up to "training a statistical model" which I like to think of data preparation
    as encompassing, or "everything from data sourcing right up to, but not including,
    model building." That is the vague-yet-oddly-precise definition we'll move forward
    with.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我会认为在“将数据从一种‘原始’形式映射到另一种...”的背景下，它是“识别数据中不完整、不正确、不准确或无关的部分，然后替换、修改或删除脏数据或粗糙数据”，以及“训练统计模型”，我喜欢将数据准备看作是涵盖的，或者“从数据来源到但不包括模型构建的所有内容。”这就是我们将继续使用的模糊却奇妙准确的定义。
- en: This article will [update a previous version from 2017](/2017/06/7-steps-mastering-data-preparation-python.html),
    in order to freshen up some of the materials throughout. I have tried to select
    a quality tutorial or two, along with video when appropriate, as a good representation
    of the particular lesson in each step.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将[更新2017年的版本](/2017/06/7-steps-mastering-data-preparation-python.html)，以刷新一些内容。我尝试选择一两个高质量的教程，并在适当时附上视频，以作为每一步特定课程的良好代表。
- en: Keep in mind that the article covers one particular set of data preparation
    techniques, and additional, or completely different, techniques may be used in
    a given circumstance, based on requirements. You should find that the prescription
    held herein is one which is both orthodox and general in approach.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，本文涵盖了一组特定的数据准备技术，而在特定情况下，根据需求可能会使用其他或完全不同的技术。你会发现这里的建议既是正统的，又是一般性的。
- en: Grab a snack and sit back, as we learn to master data preparation with Python.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 拿点零食坐下来，我们将学习如何使用Python掌握数据准备。
- en: 'Step 1: Preparing for the Preparation'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：为准备工作做准备
- en: 'First, let''s stress what everyone else has already told you: it could be argued
    that this data preparation phase is not a preliminary step prior to a machine
    learning task, but actually an integral component (or even a majority) of what
    a typical machine learning task would encompass. For our purposes, however, we
    will separate the data preparation from the modeling as its own regimen.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们强调一下其他人已经告诉你的：可以认为这个数据准备阶段不是机器学习任务之前的预备步骤，而实际上是典型机器学习任务中一个组成部分（甚至是大多数部分）。不过，出于我们的目的，我们将数据准备与建模分开作为一个独立的过程。
- en: As Python is the ecosystem in which we will be immersed, the following resources
    are a good jumping off point to ensure appropriate familiarity.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python是我们将要沉浸的生态系统，以下资源是确保适当熟悉的良好起点。
- en: '**[10 Minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)**'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[10分钟掌握Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)**'
- en: '**[Matplotlib Beginner''s Guide](https://matplotlib.org/users/beginner.html)**'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Matplotlib初学者指南](https://matplotlib.org/users/beginner.html)**'
- en: '**[Official seaborn tutorial](https://seaborn.pydata.org/tutorial.html)**'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[官方seaborn教程](https://seaborn.pydata.org/tutorial.html)**'
- en: Data preparation can be seen in the CRISP-DM model (though it can be reasonably
    argued that "data understanding" falls within our definition as well). We can
    also equate our data preparation with the framework of the KDD Process — specifically
    the first 3 major steps — which are **selection**, **preprocessing**, and **transformation**.
    We can break these down into finer granularity, but at a macro level, these steps
    of the KDD Process encompass what data wrangling is.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备可以在CRISP-DM模型中看到（尽管可以合理地认为“数据理解”也符合我们的定义）。我们还可以将我们的数据准备与KDD过程的框架等同——具体是前三个主要步骤——即**选择**、**预处理**和**转换**。我们可以将这些步骤分解得更细致，但从宏观层面来看，KDD过程中的这些步骤涵盖了数据整理的内容。
- en: 'While readers should be able to follow this guide with few additional resources,
    for those interested in a more holistic take on Pandas (likely the most important
    data preparation library in the Python ecosystem), helpful information can be
    found in the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管读者应该可以在很少额外资源的情况下跟随本指南，但对于那些对Pandas（可能是Python生态系统中最重要的数据准备库）有更全面了解兴趣的人，可以在以下内容中找到有用的信息：
- en: '**[Intro to pandas data structures](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/)**,
    by Greg Reda'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Pandas数据结构简介](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/)**，作者：Greg
    Reda'
- en: '**[Modern Pandas (in 7 parts)](http://tomaugspurger.github.io/modern-1-intro.html)**,
    by Tom Augspurger'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[现代Pandas（分7部分）](http://tomaugspurger.github.io/modern-1-intro.html)**，作者：Tom
    Augspurger'
- en: 'Finally, for some feedback on the data preparation process from 3 insiders
    — Sebastian Raschka, Clare Bernard, and Joe Boutros — read this interview on **[Data
    Preparation Tips, Tricks, and Tools: An Interview with the Insiders](/2016/10/data-preparation-tips-tricks-tools.html)**
    before moving on.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在继续之前，阅读 **[数据准备技巧、窍门和工具：与内部人士的访谈](/2016/10/data-preparation-tips-tricks-tools.html)**，了解来自三位内部人士——Sebastian
    Raschka、Clare Bernard 和 Joe Boutros——对数据准备过程的反馈。
- en: 'Step 2: Exploratory Data Analysis'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 2：探索性数据分析
- en: '[Exploratory data analysis](https://en.wikipedia.org/wiki/Exploratory_data_analysis)
    (EDA) is an integral aspect of any greater data analysis, data science, or machine
    learning project. Understanding data before working with it isn''t just a pretty
    good idea, it is a priority if you plan on accomplishing anything of consequence.
    [Andrew Andrade](https://datascienceguide.github.io/exploratory-data-analysis)
    concisely describes EDA as follows.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[探索性数据分析](https://en.wikipedia.org/wiki/Exploratory_data_analysis)（EDA）是任何更大数据分析、数据科学或机器学习项目的一个重要方面。在处理数据之前理解数据不仅仅是个不错的主意，如果你计划实现有意义的结果，它是一个优先事项。
    [Andrew Andrade](https://datascienceguide.github.io/exploratory-data-analysis)
    简洁地描述了 EDA。'
- en: The purpose of EDA is to use summary statistics and visualizations to better
    understand data, and find clues about the tendencies of the data, its quality
    and to formulate assumptions and the hypothesis of our analysis.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: EDA 的目的是利用汇总统计和可视化来更好地理解数据，并找出数据的趋势、质量的线索，以及制定我们的分析假设和假设。
- en: The basic gist is that we need to know the makeup of our data before we can
    effectively select predictive algorithms or map out the remaining steps of our
    data preparation. Throwing our dataset at the hottest algorithm and hoping for
    the best is not a strategy.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本要点是，在有效选择预测算法或规划数据准备的其余步骤之前，我们需要了解数据的组成。将数据集投入最热门的算法并寄希望于最好的结果不是一种策略。
- en: To gain some intuition, watch this video by Prof. Patrick Meyer of the University
    of Virginia which provides an overview of EDA.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得一些直观的认识，可以观看来自弗吉尼亚大学的 Patrick Meyer 教授的视频，该视频提供了 EDA 的概述。
- en: Then read Andrade's article on **[Exploratory data analysis](https://datascienceguide.github.io/exploratory-data-analysis)**,
    which provides additional details on how to go about EDA, and what its practical
    benefits are.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后阅读 Andrade 关于 **[探索性数据分析](https://datascienceguide.github.io/exploratory-data-analysis)**
    的文章，该文章提供了有关如何进行 EDA 的额外细节以及其实际好处。
- en: For a Python based approach tutorial on EDA, check out the article **[Exploratory
    Data Analysis (EDA) and Data Visualization with Python](https://kite.com/blog/python/data-analysis-visualization-python)**
    by Vigneshwer Dhinakaran, which actually goes a bit beyond traditional EDA in
    my view, and will introduce you to some of the additional concepts covered later
    in this article.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于 Python 的 EDA 方法教程，请查看 Vigneshwer Dhinakaran 撰写的文章 **[探索性数据分析（EDA）和使用 Python
    进行数据可视化](https://kite.com/blog/python/data-analysis-visualization-python)**，这实际上在我看来超越了传统的
    EDA，并将介绍本文后面涵盖的一些附加概念。
- en: A library which dramatically shortens the code you need to write to perform
    EDA is **[Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling)**,
    which creates HTML reports from Pandas DataFrames.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个显著缩短你需要编写的 EDA 代码的库是 **[Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling)**，它从
    Pandas DataFrames 创建 HTML 报告。
- en: Generates profile reports from a pandas `DataFrame`. The pandas `df.describe()`
    function is great but a little basic for serious exploratory data analysis. `pandas_profiling`
    extends the pandas DataFrame with `df.profile_report()` for quick data analysis.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从 pandas `DataFrame` 生成概况报告。pandas 的 `df.describe()` 函数非常好，但对于严肃的探索性数据分析来说有点基础。`pandas_profiling`
    通过 `df.profile_report()` 扩展了 pandas DataFrame，用于快速数据分析。
- en: 'You can run Pandas Profiling interactively in Jupyter notebooks with a single
    line of code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 Jupyter notebooks 中使用一行代码交互式地运行 Pandas Profiling：
- en: '`df.profile_report()`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`df.profile_report()`'
- en: Read the project's GitHub Readme for more information, and give it a try for
    yourself.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读项目的 GitHub Readme 以获取更多信息，并亲自尝试一下。
- en: 'Step 3: Missing Values'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3：缺失值
- en: There are many strategies for dealing with missing data, none of which are applicable
    universally. Some people will say "never use instances which include empty values."
    Others will argue "never use an attribute's mean value to replace missing values."
    Conversely, you may hear more complex methods endorsed wholesale, such as "only
    first clustering a dataset into the number of known classes and then using intra-cluster
    regression to calculate missing values is valid."
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Listen to none of this. "Never" and "only" and other inflexible assertions hold
    no value in the nuanced world of data finessing; different types of data and processes
    suggest different best practices for dealing with missing values. However, since
    this type of knowledge is both experience and domain based, we will focus on the
    more basic strategies which can be employed.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Some commonly used methods for dealing with missing values include:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: dropping instances with missing values
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dropping attributes with missing values
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: imputing the attribute { mean | median | mode } for all missing values
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: imputing the attribute missing values via linear regression
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Combination strategies may also be employed: drop any instances with more than
    2 missing values and use the mean attribute value imputation those which remain.
    Clearly the type of modeling methods being employed will have an effect on your
    decision — for example, decision trees are not amenable to missing values. Additionally,
    you could technically entertain any statistical method you could think of for
    determining missing values from the dataset, but the listed approaches are tried,
    tested, and commonly used.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Since we are focusing on the Python ecosystem, from the Pandas user guide you
    can read more about **[Working with missing data](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)**,
    as well as reference the API documentation on the **[Pandas `DataFrame` object's
    `fillna()` function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html)**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a lot of ways to accomplish filling missing values in a Pandas DataFrame.
    Here are a few basic examples:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: You can also watch this video from codebasics on handling missing values with
    Pandas.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Outliers'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is not a tutorial on drafting a strategy to deal with outliers in your
    data when modeling; there are times when including outliers in modeling is appropriate,
    and there are times when they are not (regardless of what anyone tries to tell
    you). This is situation-dependent, and no one can make sweeping assertions as
    to whether your situation belongs in column A or column B.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Outliers can be the result of poor data collection, or they can be genuinely
    good, anomalous data. These are 2 different scenarios, and must be approached
    differently, and so no "one size fits all" advice is applicable here, similar
    to that of dealing with missing values. A particularly good point of insights
    from the Analysis Factor article from above is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: One option is to try a transformation. Square root and log transformations both
    pull in high numbers. This can make assumptions work better if the outlier is
    a dependent variable and can reduce the impact of a single point if the outlier
    is an independent variable.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一种选择是尝试变换。平方根和对数变换都可以收敛高数字。如果异常值是因变量，这可以使假设更有效；如果异常值是自变量，这可以减少单个点的影响。
- en: 'Read this discussion, **[Outliers: To Drop or Not to Drop](http://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/)**
    on The Analysis Factor, and the discussion **[Is it OK to remove outliers from
    data?](https://stats.stackexchange.com/questions/200534/is-it-ok-to-remove-outliers-from-data/200923)**
    on Stack Exchange, for further insight into this issue.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读这个讨论，**[异常值：删除还是不删除](http://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/)**，以及在
    Stack Exchange 上的讨论 **[从数据中去除异常值可以吗？](https://stats.stackexchange.com/questions/200534/is-it-ok-to-remove-outliers-from-data/200923)**，以获得更多关于这个问题的见解。
- en: You can have a look at **[Removing Outliers Using Standard Deviation with Python](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)**
    as a simple example of removing outliers with Python. Then read this Stack Overflow
    discussion, **[Remove Outliers in Pandas DataFrame using Percentiles](https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles)**.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看 **[使用 Python 的标准差去除异常值](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html)**
    作为使用 Python 去除异常值的简单示例。然后阅读这篇 Stack Overflow 讨论，**[使用百分位数在 Pandas DataFrame 中去除异常值](https://stackoverflow.com/questions/35827863/remove-outliers-in-pandas-dataframe-using-percentiles)**。
- en: In the end, the decision as to whether or not to remove outliers will be task-dependent,
    and the reasoning and decision will be much more of a concern than the technical
    approach to doing so.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，是否去除异常值的决策将依赖于任务，理由和决策将比技术方法更为重要。
- en: 'Step 5: Imbalanced Data'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 5 步：不平衡数据
- en: 'So, what if your otherwise robust dataset is made up of 2 classes: one which
    includes 95 percent of the instances, and the other which includes a mere 5 percent?
    Or worse, 99.8 vs 0.2 percent?'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果你原本健壮的数据集由两个类别组成：一个包含 95% 的实例，另一个仅包含 5% 呢？或者更糟的是，99.8% 对 0.2%？
- en: '![Recognizing and dealing with imbalance is important](../Images/c9cbb484ef13d59bff657b921d1b6624.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![识别和处理不平衡数据很重要](../Images/c9cbb484ef13d59bff657b921d1b6624.png)'
- en: If so, your dataset is imbalanced, at least as far as the classes are concerned.
    This can be problematic, in ways which I'm sure do not need to be pointed out.
    But no need to to toss the data to the side yet; there are, of course, strategies
    for dealing with this.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，你的数据集是不平衡的，至少在类别方面是这样。这可能会造成问题，虽然这些问题我相信无需多言。但还不需要将数据抛到一边；当然有应对这些问题的策略。
- en: 'A good explanation of why we can run into imbalanced data, and why we can do
    so in some domains much more frequently than in others (from 7 Techniques to Handle
    Imbalanced Data, below):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关于为什么我们会遇到不平衡数据，以及为什么在某些领域会比其他领域更频繁地出现不平衡数据的一个很好的解释（见下文的 7 种处理不平衡数据的技术）：
- en: Data used in these areas often have less than 1% of rare, but “interesting”
    events (e.g. fraudsters using credit cards, user clicking advertisement or corrupted
    server scanning its network). However, most machine learning algorithms do not
    work very well with imbalanced datasets. The following seven techniques can help
    you, to train a classifier to detect the abnormal class.
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这些领域中使用的数据通常包含少于 1% 的稀有但“有趣”的事件（例如，使用信用卡的欺诈者、用户点击广告或被破坏的服务器扫描其网络）。然而，大多数机器学习算法在处理不平衡数据集时表现不佳。以下七种技术可以帮助你训练分类器来检测异常类别。
- en: Note that, while this may not genuinely be a data preparation task, such a dataset
    characteristic will make itself known early in the data preparation stage (the
    importance of EDA), and the validity of such data can certainly be assessed preliminarily
    during this preparation stage.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管这可能不是真正的数据准备任务，但这样的数据集特征将在数据准备阶段早期显现（EDA 的重要性），并且这样的数据的有效性在这个准备阶段可以进行初步评估。
- en: Tom Fawcett discusses this in his article **[Learning from Imbalanced Classes](/2016/08/learning-from-imbalanced-classes.html)**.
    Read it to get a better idea of the issue.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Tom Fawcett 在他的文章 **[学习如何处理不平衡类别](/2016/08/learning-from-imbalanced-classes.html)**
    中讨论了这个问题。阅读它可以更好地了解这个问题。
- en: Then read this article, **[7 Techniques to Handle Imbalanced Data](/2017/06/7-techniques-handle-imbalanced-data.html)**
    by Ye Wu & Rick Radewagen, which covers techniques for handling class imbalance.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后阅读这篇文章，**[处理不平衡数据的 7 种技术](/2017/06/7-techniques-handle-imbalanced-data.html)**，作者是
    Ye Wu 和 Rick Radewagen，涵盖了处理类别不平衡的技术。
- en: 'Step 6: Data Transformations'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 6：数据转换
- en: 'Wikipedia defines [data transformation](https://en.wikipedia.org/wiki/Data_transformation_(statistics))
    as:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科将 [数据转换](https://en.wikipedia.org/wiki/Data_transformation_(statistics))
    定义为：
- en: In statistics, data transformation is the application of a deterministic mathematical
    function to each point in a data set — that is, each data point zi is replaced
    with the transformed value *y[i]* = *f(z[i])*, where *f* is a function. Transforms
    are usually applied so that the data appear to more closely meet the assumptions
    of a statistical inference procedure that is to be applied, or to improve the
    interpretability or appearance of graphs.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在统计学中，数据转换是对数据集中每个点应用确定性数学函数的过程——即，每个数据点 zi 被替换为转换后的值 *y[i]* = *f(z[i])*，其中
    *f* 是一个函数。转换通常应用于使数据更符合将要应用的统计推断程序的假设，或提高图表的可解释性或外观。
- en: Transforming data is one of the most important aspects of data preparation,
    requiring more finesse than some others. When missing values manifest themselves
    in data, they are generally easy to find, and can be dealt with by one of the
    common methods outlined above — or by more complex measures gained from insight
    over time in a domain. However, when and if data transformations are required
    is often not as easily identifiable, to say nothing of the type of transformation
    required.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换是数据准备中最重要的方面之一，比其他一些方面需要更多的技巧。当数据中出现缺失值时，它们通常很容易被发现，可以通过上述常见方法之一或通过在特定领域内逐渐获得的复杂措施来处理。然而，何时需要数据转换往往不容易识别，更不用说所需的转换类型了。
- en: Let's look at a few specific transformations in order to get a better handle
    on them.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看几个具体的转换，以更好地理解它们。
- en: First, this overview of **[Preprocessing data](http://scikit-learn.org/stable/modules/preprocessing.html)**
    from Scikit-learn's documentation gives some rationale for some of the most important
    preprocessing transformations, namely standardization, normalization, binarization,
    and a few others.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，**[Scikit-learn 数据预处理](http://scikit-learn.org/stable/modules/preprocessing.html)**
    的概述提供了一些重要预处理转换的理由，即标准化、归一化、二值化以及其他几个方法。
- en: 'Standardization and normalization are a pair of often employed data transformations
    in machine learning projects. Both are data scaling methods: standardization refers
    to scaling the data to have a mean of 0 and a standard deviation of 1; normalization
    refers to the scaling the data values to fit into a predetermined range, generally
    between 0 and 1\. Read this article by Shay Geller, **[Normalization vs Standardization — Quantitative
    analysis](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)**,
    to understand how the transformations work, how to perform them in the Python
    ecosystem, and gain some insight into best practice from the author.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化和归一化是在机器学习项目中常用的数据转换方法。两者都是数据缩放方法：标准化指将数据缩放至均值为 0 和标准差为 1；归一化指将数据值缩放至预定范围内，通常在
    0 到 1 之间。阅读 Shay Geller 的这篇文章，**[归一化 vs 标准化——定量分析](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf)**，了解这些转换如何工作，如何在
    Python 生态系统中执行它们，并从作者那里获得一些最佳实践的见解。
- en: One-hot encoding is a method for transforming categorical features to a format
    which will better work for classification and regression. Watch this video on
    one-hot encoding to gain a better understanding of how it does so, and see how
    it can be accomplished with Python tools.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: One-hot 编码是一种将分类特征转换为更适合分类和回归格式的方法。观看这个关于 one-hot 编码的视频，以更好地理解其如何实现，以及如何使用 Python
    工具完成它。
- en: Logarithmic distribution transformation is useful for transforming non-linear
    models into linear models and working with skewed data. Read this Stack Exchange
    discussion, **[When (and why) should you take the log of a distribution (of numbers)?](https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers)**,
    for the intuition. You can also have a look at this short tutorial from Data Science
    Made Simple, **[Log and natural Logarithmic value of a column in pandas python](http://www.datasciencemadesimple.com/log-natural-logarithmic-value-column-pandas-python-2/)**,
    for a quick overview of using Numpy to accomplish the transformation in Python.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对数分布变换对将非线性模型转化为线性模型以及处理偏斜数据非常有用。阅读这个 Stack Exchange 讨论，**[何时（以及为什么）应该对分布（或数字）取对数？](https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers)**，可以获得直观的理解。你还可以查看这个来自
    Data Science Made Simple 的简短教程，**[在 pandas python 中对列进行对数和自然对数变换](http://www.datasciencemadesimple.com/log-natural-logarithmic-value-column-pandas-python-2/)**，快速了解如何使用
    Numpy 在 Python 中完成这种变换。
- en: This short tutorial from Ontario Tech University, **[Introduction to Exponential
    and Logarithmic Functions](https://nool.uoit.ca/mathematics/exponential-logarithmic-functions/basics/index.php)**,
    takes a mathematical approach to explaining logarithmic and exponential transformations,
    along with visualizations, and can add to your intuition of what is happening
    to underlying data distributions when these transformations are performed. There
    are 3 pages in the tutorial, with the third having 2 videos which help drive the
    point home.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个来自安大略理工大学的简短教程，**[指数函数和对数函数简介](https://nool.uoit.ca/mathematics/exponential-logarithmic-functions/basics/index.php)**，从数学角度解释了对数和指数变换及其可视化，可以增强你对这些变换在底层数据分布上所产生影响的直观理解。教程共有
    3 页，第三页有 2 个视频，有助于更好地理解要点。
- en: There are numerous additional standard data transformations which are regularly
    employed, depending on the data and your requirements. Experience with data preprocessing
    and preparation should provide intuition on what types of transformations are
    required in which circumstance.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据和你的需求，还有许多其他标准的数据变换常被使用。对数据预处理和准备的经验应能帮助你了解在不同情况下需要什么类型的变换。
- en: 'Step 7: Finishing Touches & Moving Ahead'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 7 步：最后的润色与前进
- en: Alright. Your data is "clean." But what do you do with it?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，你的数据已经“干净”了。那么你接下来要怎么做？
- en: If you want to go right to feeding your data into a machine learning algorithm
    in order to attempt building a model, you probably need your data in a more appropriate
    representation. In the Python ecosystem, that would generally be a Numpy ndarray
    (or matrix). This Stack Overflow discussion, **[Turning a Pandas Dataframe to
    an array and evaluate Multiple Linear Regression Model](https://stackoverflow.com/questions/28334091/turning-a-pandas-dataframe-to-an-array-and-evaluate-multiple-linear-regression-m)**,
    can give some preliminary ideas on getting there.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想直接将数据输入机器学习算法以尝试建立模型，你可能需要以更合适的方式表示数据。在 Python 生态系统中，这通常是一个 Numpy ndarray（或矩阵）。这个
    Stack Overflow 讨论，**[将 Pandas Dataframe 转换为数组并评估多元线性回归模型](https://stackoverflow.com/questions/28334091/turning-a-pandas-dataframe-to-an-array-and-evaluate-multiple-linear-regression-m)**，可以提供一些初步的思路。
- en: '![Very simple data preparation process](../Images/2b1892e803954b3888cf48f32e0c71b7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![非常简单的数据准备过程](../Images/2b1892e803954b3888cf48f32e0c71b7.png)'
- en: '*Note that most of our data preparation was performed in a combination of Pandas
    and Numpy in the preceding text; however, Pandas sits atop Numpy, and so learning
    how to manipulate the underlying Numpy matrix directly is a useful skill. [Learn
    a bit more about that here](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*请注意，我们在前文中大部分数据准备工作是结合 Pandas 和 Numpy 进行的；然而，Pandas 基于 Numpy，因此直接操作底层 Numpy
    矩阵是一个有用的技能。 [在这里了解更多](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)。*'
- en: What if you aren't quite ready to model the data yet, and instead want to store
    your clean Pandas DataFrame for later use? **[Quick HDF5 with Pandas](https://dzone.com/articles/quick-hdf5-pandas)**
    by Giuseppe Vettigli will show you one such way to do so.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有准备好建模数据，而是想保存你的干净 Pandas DataFrame 以便后用，**[快速 HDF5 与 Pandas](https://dzone.com/articles/quick-hdf5-pandas)**
    作者 Giuseppe Vettigli 将展示一种方法。
- en: Once you have clean data in a proper representation for machine learning in
    Python, why not get right to the machine learning? First you will want to read
    **[7 Steps to Mastering Basic Machine Learning with Python — 2019 Edition](/2019/01/7-steps-mastering-basic-machine-learning-python.html)**
    to gain an introductory understanding of machine learning in the Python ecosystem.
    Follow that up with **[7 Steps to Mastering Intermediate Machine Learning with
    Python — 2019 Edition](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)**
    to enhance your knowledge (and be on the look out for an "advanced" installment
    as well).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在Python中获得了干净且适合机器学习的数据，为什么不直接开始机器学习呢？首先，你需要阅读**[掌握基础机器学习的7个步骤——2019版](/2019/01/7-steps-mastering-basic-machine-learning-python.html)**，以获得对Python生态系统中机器学习的初步理解。接着阅读**[掌握中级机器学习的7个步骤——2019版](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)**来提升你的知识水平（同时也留意即将发布的“高级”版本）。
- en: 'For some differing viewpoints on data preparation, have a look at these:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据准备的一些不同观点，请查看这些内容：
- en: '**[Tidying Data in Python](/2017/01/tidying-data-python.html)**, by Jean-Nicholas
    Hould'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[在Python中整理数据](/2017/01/tidying-data-python.html)**，作者：让-尼古拉斯·霍尔德'
- en: '**[Doing Data Science: A Kaggle Walkthrough Part 3 – Cleaning Data](/2016/06/doing-data-science-kaggle-walkthrough-data-cleaning.html)**,
    by Brett Romero'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[数据科学实战：Kaggle教程第三部分——数据清理](/2016/06/doing-data-science-kaggle-walkthrough-data-cleaning.html)**，作者：布雷特·罗梅罗'
- en: '**[Machine Learning Workflows in Python from Scratch Part 1: Data Preparation](/2017/05/machine-learning-workflows-python-scratch-part-1.html)**'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[从零开始的Python机器学习工作流第一部分：数据准备](/2017/05/machine-learning-workflows-python-scratch-part-1.html)**'
- en: 'Note that this entire discussion is also fully and intentionally skipping any
    mention of feature selection for a specific reason: it deserves far more than
    a simple few sentences in this much more broad discussion. Be on the lookout for
    a similar guide for feature selection.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本讨论故意跳过了特征选择的内容，原因是：特征选择的内容远不止几句简单的讨论，它值得在这更广泛的讨论中有更多的关注。请留意类似的特征选择指南。
- en: '**Related**:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容**：'
- en: '[7 Steps to Mastering Basic Machine Learning with Python — 2019 Edition](/2019/01/7-steps-mastering-basic-machine-learning-python.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握基础机器学习的7个步骤——2019版](/2019/01/7-steps-mastering-basic-machine-learning-python.html)'
- en: '[7 Steps to Mastering Intermediate Machine Learning with Python — 2019 Edition](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握中级机器学习的7个步骤——2019版](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)'
- en: '[7 Steps to Mastering SQL for Data Science — 2019 Edition](/2019/05/7-steps-mastering-sql-data-science-2019-edition.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握SQL以进行数据科学的7个步骤——2019版](/2019/05/7-steps-mastering-sql-data-science-2019-edition.html)'
- en: More On This Topic
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为优秀数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位初学者数据科学家应掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应了解的三种R语言库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让Python成为创业公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
