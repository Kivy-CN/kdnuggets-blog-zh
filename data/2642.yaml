- en: Popular Machine Learning Interview Questions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的机器学习面试问题
- en: 原文：[https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Mo Daoud](https://mohamed-daoud214.medium.com/), Works in technology,
    AI enthusiast**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Mo Daoud](https://mohamed-daoud214.medium.com/)提供，科技工作者，AI 爱好者**。'
- en: Interviews are hard and stressful enough and my goal here is to help you prepare
    for ML interviews. This list is not conclusive of all interview questions nor
    guaranteed to help you pass the interview. It’s basically a list of questions
    I gathered from sitting on many interviews as an interviewer.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 面试足够困难和压力重重，我在这里的目标是帮助你为机器学习面试做好准备。这份清单并不包括所有面试问题，也不能保证帮助你通过面试。它基本上是一份我从担任面试官时收集的面试问题列表。
- en: '![](../Images/f49eb31594a18f38363ff2867a3a3e50.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f49eb31594a18f38363ff2867a3a3e50.png)'
- en: '*Photo by [Clem Onojeghuo](https://unsplash.com/@clemono?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*照片由[Clem Onojeghuo](https://unsplash.com/@clemono?utm_source=medium&utm_medium=referral)在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上提供。*'
- en: '*Q1\. What are different types of Machine Learning, and briefly explain them?*'
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q1\. 机器学习的不同类型是什么，简要说明一下？*'
- en: The expected answer should mention supervised, unsupervised, and reinforcement
    learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的答案应提到监督学习、无监督学习和强化学习。
- en: '**Supervised Learning** You give the algorithm labeled data and the algorithm
    has to learn from it and figure out how to solve future similar problems. Think
    of it as if you’re giving the algorithm problems and answers. The algorithm has
    to learn how these problems were solved in order to solve future problems in a
    similar manner. This is like the above example where the bank learns from your
    habits which credit card transactions are legit and which are fraudulent.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习** 你给算法标签数据，算法必须从中学习并弄清楚如何解决未来类似的问题。可以把它看作是给算法问题和答案。算法必须学习这些问题是如何解决的，以便以类似的方式解决未来的问题。这就像上面的例子，其中银行从你的习惯中学习哪些信用卡交易是真实的，哪些是欺诈的。'
- en: '**Unsupervised Learning** You give the algorithm a problem without any labeled
    data or any prior knowledge of what the answer could be. Think of it as if you’re
    giving the algorithm problems without any answers. The algorithm has to find the
    best answer by driving insights from the data. This is similar to a bank clustering
    its customers according to various parameters and deciding who’s eligible for
    a credit card offer, line of credit offer, and who isn’t eligible for any offers.
    This is usually done using a Machine Learning method called **K-Means**.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习** 你给算法一个没有标签的数据或对答案没有任何先验知识的问题。可以把它看作是给算法问题而没有答案。算法必须通过从数据中获取洞察力来找到最佳答案。这类似于银行根据各种参数对其客户进行聚类，决定谁有资格获得信用卡优惠、信用额度优惠，谁不符合任何优惠。这通常使用一种叫做**K-Means**的机器学习方法来完成。'
- en: '**Reinforcement Learning** This is when the algorithm learns from its own experience
    using reward and punishment. The easiest example is self-driving cars, where there
    is an agent that learns from each move it makes. A positive move toward the target
    earns the agent a reward, while a negative move away from the target earns the
    agent a punishment.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习** 这是当算法通过奖励和惩罚从自己的经验中学习。最简单的例子是自动驾驶汽车，其中有一个代理通过每一步的移动来学习。朝目标的正向移动会给代理带来奖励，而远离目标的负向移动会给代理带来惩罚。'
- en: '*Q2\. Give me an example of supervised learning and another for unsupervised
    learning?*'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q2\. 给我一个监督学习的例子，以及一个无监督学习的例子？*'
- en: Here I usually expect to hear the 3 words: **Classification**, **Regression**,
    and **clustering**. These are some of the most popular and basic uses for Machine
    Learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我通常期望听到3个词：**分类**、**回归**和**聚类**。这些是机器学习的一些最流行和基础的用法。
- en: Classification and Regression mainly use supervised learning, and the candidate
    can give an example showing how historical data is used to train the model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分类和回归主要使用监督学习，候选人可以举例说明如何使用历史数据来训练模型。
- en: For example, if someone steals your credit card and makes an online transaction.
    You will probably get an email or text from your bank asking to verify this transaction.
    Otherwise, the bank will consider it fraud. Your bank’s algorithm learned your
    credit card purchasing habits through your purchase history, and when an abnormal
    transaction was detected, the bank suspected it’s a fraud. This is a form of Machine
    Learning, and probably it’s decision tree **Classification**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果有人盗用了你的信用卡并进行了一次在线交易。你可能会收到来自银行的电子邮件或短信，要求你确认这笔交易。否则，银行会认为这是欺诈。你的银行算法通过你的购买历史学会了你的信用卡购买习惯，当检测到异常交易时，银行怀疑这是欺诈。这是一种机器学习形式，可能是决策树**分类**。
- en: Another example is a car company trying to predict sales for next year based
    on this year’s numbers and historical data, which is a form of Machine Learning
    and could be linear **Regression**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是一个汽车公司尝试根据今年的销售数字和历史数据预测明年的销售情况，这是一种机器学习形式，可能是线性**回归**。
- en: '**Clustering** mainly uses unsupervised learning where there is no historical
    data. A simple example is the spam email filter where the algorithm examines different
    parts of all incoming emails, group them together, then cluster the emails into
    spam and ham.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类**主要使用无监督学习，其中没有历史数据。一个简单的例子是垃圾邮件过滤器，其中算法检查所有传入邮件的不同部分，将它们组合在一起，然后将邮件分为垃圾邮件和正常邮件。'
- en: '*Q3\. You built a DL model, and while training it, you noticed that after a
    certain number of epochs, the accuracy is decreasing. What’s the problem and how
    to fix it?*'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q3\. 你构建了一个深度学习模型，在训练过程中，你注意到在经过一定数量的周期后，准确率在下降。是什么问题，如何解决？*'
- en: The answer should be around **overfitting**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 答案应该与**过拟合**有关。
- en: It seems the model is learning the exact dataset characteristics rather than
    capturing its features, and it is called overfitting the model. Probably the model
    is very complex in comparison to the dataset. The model is complex in terms of
    having many layers and neurons than needed.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎模型正在学习确切的数据集特征，而不是捕捉其特征，这被称为模型过拟合。可能模型相比数据集非常复杂。模型在层数和神经元方面比所需的要复杂。
- en: Depending on the situation, there are several ways to fix this overfitting model.
    The most common are **early stopping** and **dropout regularization**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据情况，有几种方法可以修复这个过拟合模型。最常见的方法是**早期停止**和**dropout 正则化**。
- en: 'Early stopping is what it sounds like: stop the training early once you start
    seeing the drop in the accuracy. Dropout regularization is dropping some outputs
    layers or nodes. Thus, the remaining nodes have different weights and have to
    do extra work to capture the characteristics.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 早期停止就是它听起来的意思：一旦开始看到准确率下降，就提前停止训练。Dropout 正则化是丢弃一些输出层或节点。因此，剩余的节点具有不同的权重，并且必须额外工作以捕捉特征。
- en: '*Q4\. What’s the difference between Bias and Variance in DL models? How to
    achieve a balance between them?*'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q4\. 深度学习模型中的偏差（Bias）和方差（Variance）有什么区别？如何在它们之间实现平衡？*'
- en: This is kinda related to the previous question. The answer should include simple
    models that underfit, complex models that overfit, and the fact that both Bias
    and Variance can’t be minimized at the same time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这与前一个问题有点相关。答案应该包括欠拟合的简单模型、过拟合的复杂模型，以及偏差和方差不能同时最小化的事实。
- en: '**High Bias **means the model is simple and can’t capture many features during
    the training phase, aka underfitting model. **High Variance** means the model
    is complex and is not only capturing features but also learning anything but those
    specific training set features, which is also referred to as overfitting.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**高偏差**意味着模型很简单，在训练阶段无法捕捉许多特征，也就是欠拟合模型。**高方差**意味着模型很复杂，不仅捕捉了特征，还学习了除了那些特定训练集特征之外的其他内容，这也被称为过拟合。'
- en: '![](../Images/1405d7cd027c2b6a521a8ab305bced4a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1405d7cd027c2b6a521a8ab305bced4a.png)'
- en: '*Image by Author.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像来源：作者。*'
- en: As you can see, there is a sweet spot in the middle to balance both Bias and
    Variance. If your model shift to the right side, then it’s getting more complicated,
    thus increasing variance and resulting in overfitting. If your model shifts to
    the left, then it’s getting too simple, thus increasing bias and results in underfitting.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在中间有一个甜点区域可以平衡偏差和方差。如果你的模型向右移动，则模型变得更加复杂，从而增加了方差，导致过拟合。如果你的模型向左移动，则变得过于简单，从而增加了偏差，导致欠拟合。
- en: A good data scientist knows how to tradeoff bias and variance by tuning the
    model’s hyperparameters, thus achieving optimum model complexity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的数据科学家知道如何通过调整模型的超参数来权衡偏差和方差，从而实现最佳模型复杂度。
- en: A simple model means a small number of neurons and fewer layers, while a complex
    model means a large number of neurons and several layers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 简单模型意味着少量的神经元和较少的层，而复杂模型意味着大量的神经元和几层。
- en: '*Q5\. What’s the confusion matrix? Is it used for both supervised and unsupervised
    learning? What are Type 1 and Type 2 errors?*'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q5\. 什么是混淆矩阵？它用于监督学习和无监督学习吗？类型 1 和类型 2 错误是什么？*'
- en: Confusion Matrix is used to assess the performance of supervised learning models
    only and can’t be used with unsupervised models.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵仅用于评估监督学习模型的性能，不能用于无监督模型。
- en: '![](../Images/89a8731e06ac36a6c7f326f945c1c3a1.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89a8731e06ac36a6c7f326f945c1c3a1.png)'
- en: '*Confusion Matrix. Source: [Everything You Wanted to Know about Machine Learning
    but Were Too Afraid to ask](https://medium.com/swlh/everything-you-wanted-to-know-about-machine-learning-but-were-too-afraid-to-ask-d7d92021038).*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*混淆矩阵。来源：[你想知道的机器学习知识但又太害怕去问的事](https://medium.com/swlh/everything-you-wanted-to-know-about-machine-learning-but-were-too-afraid-to-ask-d7d92021038).*'
- en: 'Confusion Matrix is a way to present the 4 outcomes of the model: True Positive,
    False Positive, False Negative, and True Negative. Recall, Precision, Accuracy,
    and F1 can all be calculated from the Confusion Matrix.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是一种展示模型四种结果的方法：真正例、假正例、假负例和真负例。召回率、精确度、准确率和 F1 分数都可以从混淆矩阵中计算得出。
- en: '**Type 1 error** is when your algorithm makes a positive prediction, but in
    fact, it’s negative. For example, your algorithm predicted a patient has cancer,
    but in fact, he doesn’t.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型 1 错误**是当你的算法做出正面预测，但实际上是负面的。例如，你的算法预测一个患者有癌症，但实际上他没有。'
- en: '**Type 2 error** is when your algorithm makes a negative prediction, but in
    fact, it’s positive. For example, your algorithm predicted a patient doesn’t have
    cancer, but in fact, they do.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**类型 2 错误**是当你的算法做出负面预测，但实际上是正面的。例如，你的算法预测一个患者没有癌症，但实际上他有。'
- en: '*Q6\. What is a model learning rate? Is a high learning rate always good?*'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q6\. 什么是模型学习率？高学习率总是好吗？*'
- en: The learning rate is a tuning parameter that determines the step size of each
    iteration (epoch) during model training. The step size is how fast (or slow) you
    update your neurons’ weights in response to an estimated error. Model weights
    are updated using the backpropagation error method. So, the input will flow from
    the input nodes of your model through the neurons to the output nodes then the
    error is determined and backpropagated to update the neuron’s (model) weights.
    How fast to update those neurons' weights is the learning rate.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是一个调整参数，它决定了每次迭代（epoch）的步长。步长是指你在估计错误后更新神经元权重的速度。模型权重通过反向传播错误方法进行更新。因此，输入会从模型的输入节点流经神经元到输出节点，然后确定错误并反向传播以更新神经元（模型）权重。更新这些神经元权重的速度就是学习率。
- en: '![](../Images/9f2391a298b360d81443d7746c588095.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f2391a298b360d81443d7746c588095.png)'
- en: '*Image by Author.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*图片作者。*'
- en: If the learning rate is high, thus the model weights are updated fast and frequently,
    then your model will converge fast, but it may overshoot the true error minima.
    This means a faster but erroneous model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果学习率高，则模型权重更新迅速且频繁，那么你的模型将快速收敛，但可能会超过真实错误的最小值。这意味着一个较快但有误的模型。
- en: If the learning rate is low, thus the model weights are updated slowly, then
    your model will take a long time to converge but will not overshoot the true error
    minima. This means a slower but more accurate model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果学习率低，则模型权重更新缓慢，那么你的模型将需要很长时间才能收敛，但不会超过真实错误的最小值。这意味着一个较慢但更准确的模型。
- en: '*Q7\. What vanishing gradient descent?*'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q7\. 什么是梯度消失？*'
- en: This question is related to the previous one. Here I expect a quick explanation
    of the gradient descent and how backpropagation affects it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题与前一个问题相关。这里我期待对梯度下降的快速解释以及反向传播如何影响它。
- en: Think of gradient descent as the weights used to update your neural network
    during the backpropagation from output to input nodes. Think of Activation as
    the equation tied to each neuron in your model. This equation decides if this
    neuron should be activated or not depending on the neuron’s input relevancy to
    the model prediction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将梯度下降视为在反向传播过程中用来更新神经网络的权重。将激活函数视为与模型中每个神经元相关联的方程。这个方程决定了该神经元是否应该被激活，这取决于神经元输入与模型预测的相关性。
- en: In some cases, when you have a deep neural network with several layers and based
    on your choice of the activation function (along with other hyper-parameters),
    the gradients will become very small and may vanish while backpropagating from
    the output to input nodes through the layers of the network. The problem here
    is the weights of the neurons in your model won’t get updated (or get updated
    with very small values). Thus, your model won’t learn (or will get minimal learning).
    This is a clear case of a vanishing gradient descent problem.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，当你有一个多层的深度神经网络，并且根据你选择的激活函数（以及其他超参数），梯度会变得非常小，并且可能在从输出到输入节点的反向传播过程中消失。这里的问题是模型中神经元的权重不会被更新（或被非常小的值更新）。因此，你的模型不会学习（或学习很少）。这明显是梯度消失问题的例子。
- en: '*Q8\. What’s the difference between KNN and K-means?*'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q8. KNN 和 K-means 之间有什么区别？*'
- en: I’m personally surprised by how many candidates confuse these two. The answer
    should state the fact that **KNN is a supervised** model used for classification,
    and **K-means is an unsupervised** model used for clustering. Then the candidate
    should give an example of classification and another of clustering.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人对有这么多候选人混淆这两个概念感到惊讶。答案应说明**KNN 是一种监督**模型用于分类，而**K-means 是一种无监督**模型用于聚类。然后候选人应提供一个分类的例子和一个聚类的例子。
- en: '*Q9\. What does it mean to cross-validate a machine learning model?*'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q9. 什么是交叉验证机器学习模型？*'
- en: This is another easy one where the answer should include testing the model on
    new data that the model has never seen before. The best example is when you use
    Scikit Learn (or any other library) to split your data into training and test
    set. The test set data is used to cross-validate your model after it is trained
    so you can assess how well your model is performing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个简单的例子，答案应包括在模型从未见过的新数据上进行测试。最佳的例子是当你使用 Scikit Learn（或任何其他库）将数据拆分为训练集和测试集时。测试集数据用于在模型训练后进行交叉验证，以便你可以评估模型的性能。
- en: '*Q10\. How to assess your supervised machine learning model? What’s Recall
    and Precision?*'
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q10. 如何评估你的监督学习模型？什么是召回率和准确率？*'
- en: '**Precision**: This is the answer for: out of all the times the model said
    positive, how many were really positive. You care about precision when False Positive
    is important to your output.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率**：这是指在所有模型预测为正的情况下，有多少实际是正的。当假阳性对你的输出很重要时，你需要关注准确率。'
- en: '![](../Images/13c8ee1afea09113fc5bddc49c9bfbaa.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13c8ee1afea09113fc5bddc49c9bfbaa.png)'
- en: '*Precision.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确率。*'
- en: Let’s say you’re a small company and you send samples to potential customers
    who might buy your product. You don’t want to send samples to customers that will
    never buy your product no matter what. The customer who gets a sample but doesn’t
    buy your product is false positive because you predicted they would buy your product
    (Predicted = 1), but actually, they never will (Actual = 0). In such cases, you
    want to decrease the FP as much as you can in order to have high precision.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一个小公司，你向潜在的客户发送样品，这些客户可能会购买你的产品。你不想将样品发送给那些无论如何都不会购买你产品的客户。那些收到样品但不购买你产品的客户是假阳性，因为你预测他们会购买你的产品（预测
    = 1），但实际上他们永远不会（实际 = 0）。在这种情况下，你希望尽可能减少假阳性，以获得高准确率。
- en: '![](../Images/46d5a3828cce992e3ba3227639559ec4.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46d5a3828cce992e3ba3227639559ec4.png)'
- en: '*Recall.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率。*'
- en: '**Recall**: This is the answer for: out of the actual positives, how many were
    classified correctly. You care about the recall when False Negative is important
    to your output. Let’s take an example of your credit card. Someone stole your
    credit card number and used it to purchase stuff online from a sketchy website
    that you never visit. That’s clearly a fraudulent transaction, but unfortunately,
    your banks’ algorithm didn’t catch it. What happened here is that your bank predicted
    it’s not a fraud (predicted = 0), but it was actually a fraud (actual = 1). In
    such a case, your bank should develop a fraud detection algorithm that decreases
    the FN, thus increases the recall.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**：这是对实际正例中有多少被正确分类的答案。当假阴性对输出很重要时，你会关心召回率。以你的信用卡为例。有人偷了你的信用卡号码，并在一个你从未访问过的可疑网站上购买了东西。这显然是欺诈交易，但不幸的是，你的银行算法没有检测到。发生的情况是，你的银行预测这不是欺诈（预测
    = 0），但实际上是欺诈（实际 = 1）。在这种情况下，你的银行应该开发一种减少 FN 从而提高召回率的欺诈检测算法。'
- en: '*Q11\. What’s the Curse of Dimensionality, and how to solve it?*'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*Q11。什么是维度诅咒，如何解决它？*'
- en: This is when your dataset has too many features, so it’s hard for your model
    to learn and extract those features.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于数据集具有过多特征时，这使得模型难以学习和提取这些特征。
- en: Two main things could happen
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会发生两种主要情况
- en: More features than observations thus the risk of overfitting the model
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征数量多于观察值，从而增加了过拟合模型的风险
- en: Too many features, observations become harder to cluster. Too many dimensions
    cause every observation in the dataset to appear equidistant from all others,
    and no meaningful clusters can be formed
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征过多，观察值变得更难以聚类。过多的维度导致数据集中的每个观察值都与所有其他观察值等距，从而无法形成有意义的簇
- en: The main technique to solve this problem is **Principal Component Analysis (PCA)**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 解决此问题的主要技术是**主成分分析（PCA）**。
- en: PCA is an unsupervised machine learning algorithm that attempts to reduce the
    dimensionality (number of features) within a dataset while still retaining as
    much information as possible. This is done by finding a new set of features called
    components, which are composites of the original features that are uncorrelated
    with one another. They are also constrained so that the first component accounts
    for the largest possible variability in the data, the second component the second
    most variability, and so on.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 是一种无监督机器学习算法，旨在降低数据集中维度（特征数量），同时尽可能保留更多信息。其方法是找到一组新的特征，称为主成分，这些主成分是原始特征的复合体，相互之间不相关。它们还受到约束，使得第一个主成分解释数据中可能的最大变异性，第二个主成分解释第二大变异性，依此类推。
- en: Finally, I hope these sample questions and answers help you prepare for your
    upcoming interview. They could also serve as a refresher to your Machine Learning
    knowledge.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，希望这些示例问题和答案能帮助你为即将到来的面试做准备。它们也可以作为你机器学习知识的复习材料。
- en: '[Original](https://towardsdatascience.com/popular-machine-learning-interview-questions-91d569afe147).
    Reposted with permission.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/popular-machine-learning-interview-questions-91d569afe147)。经许可转载。'
- en: '*Ready for more interview questions? Check out **[Part 2 of this article](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html)**!*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*准备好更多面试问题了吗？查看**[本文第 2 部分](https://www.kdnuggets.com/2021/01/popular-machine-learning-interview-questions-part2.html)**！*'
- en: '**Related:**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to Explain Key Machine Learning Algorithms at an Interview](https://www.kdnuggets.com/2020/10/explain-machine-learning-algorithms-interview.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在面试中解释关键的机器学习算法](https://www.kdnuggets.com/2020/10/explain-machine-learning-algorithms-interview.html)'
- en: '[Crack SQL Interviews](https://www.kdnuggets.com/2020/12/crack-sql-interviews.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[破解 SQL 面试](https://www.kdnuggets.com/2020/12/crack-sql-interviews.html)'
- en: '[The Data Science Interview Study Guide](https://www.kdnuggets.com/2020/01/data-science-interview-study-guide.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学面试学习指南](https://www.kdnuggets.com/2020/01/data-science-interview-study-guide.html)'
- en: '* * *'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你组织中的 IT'
- en: '* * *'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学，寻找目标，然后寻找目标去……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个 90 亿美元的 AI 失败，经过检讨](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么让 Python 成为初创公司理想的编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位数据科学家都应该知道的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
