- en: 7 common mistakes when doing Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: By Cheng-Tao Chu ([@chengtao_chu](https://twitter.com/chengtao_chu)) .
  prefs: []
  type: TYPE_NORMAL
- en: Statistical modeling is a lot like engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '![statistics1](../Images/0e70aa3c1fdb3fb7f30b800354621863.png) In engineering,
    there are various ways to build a key-value storage, and each design makes a different
    set of assumptions about the usage pattern. In statistical modeling, there are
    various algorithms to build a classifier, and each algorithm makes a different
    set of assumptions about the data.'
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with small amounts of data, it’s reasonable to try as many algorithms
    as possible and to pick the best one since the cost of experimentation is low.
    But as we hit “big data”, it pays off to analyze the data upfront and then design
    the modeling pipeline (pre-processing, modeling, optimization algorithm, evaluation,
    productionization) accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: As pointed out in my previous [post](http://ml.posthaven.com/why-building-a-data-science-team-is-hard),
    there are dozens of ways to solve a given modeling problem. Each model assumes
    something different, and it’s not obvious how to navigate and identify which assumptions
    are reasonable. In industry, most practitioners pick the modeling algorithm they
    are most familiar with rather than pick the one which best suits the data. In
    this post, I would like to share some common mistakes (the don't-s). I’ll save
    some of the best practices (the do-s) in a future post.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Take default loss function for granted**'
  prefs: []
  type: TYPE_NORMAL
- en: Many practitioners train and pick the best model using the default loss function
    (e.g., squared error). In practice, off-the-shelf loss function rarely aligns
    with the business objective. Take fraud detection as an example. When trying to
    detect fraudulent transactions, the business objective is to minimize the fraud
    loss. The off-the-shelf loss function of binary classifiers weighs false positives
    and false negatives equally. To align with the business objective, the loss function
    should not only penalize false negatives more than false positives, but also penalize
    each false negative in proportion to the dollar amount. Also, data sets in fraud
    detection usually contain highly imbalanced labels. In these cases, bias the loss
    function in favor of the rare case (e.g., through up/down sampling).
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Use plain linear models for non-linear interaction**'
  prefs: []
  type: TYPE_NORMAL
- en: When building a binary classifier, many practitioners immediately jump to logistic
    regression because it’s simple. But, many also forget that logistic regression
    is a linear model and the non-linear interaction among predictors need to be encoded
    manually. Returning to fraud detection, high order interaction features like "billing
    address = shipping address and transaction amount < $50" are required for good
    model performance. So one should prefer non-linear models like SVM with kernel
    or tree based classifiers that bake in higher-order interaction features.
  prefs: []
  type: TYPE_NORMAL
- en: '**3\. Forget about outliers**'
  prefs: []
  type: TYPE_NORMAL
- en: Outliers are interesting. Depending on the context, they either deserve special
    attention or should be completely ignored. Take the example of revenue forecasting.
    If unusual spikes of revenue are observed, it's probably a good idea to pay extra
    attention to them and figure out what caused the spike. But if the outliers are
    due to mechanical error, measurement error or anything else that’s not generalizable,
    it’s a good idea to filter out these outliers before feeding the data to the modeling
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![statistics-bars](../Images/4397b851f09b620efd73fc1acd8d17e3.png) Some models
    are more sensitive to outliers than others. For instance, AdaBoost might treat
    those outliers as "hard" cases and put tremendous weights on outliers while decision
    tree might simply count each outlier as one false classification. If the data
    set contains a fair amount of outliers, it''s important to either use modeling
    algorithm robust against outliers or filter the outliers out.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How To Tackle 3 Common Machine Learning Challenges](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Mistakes That Could Be Affecting the Accuracy of Your Data Analytics](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software Mistakes and Tradeoffs: New book by Tomasz Lelek and…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
